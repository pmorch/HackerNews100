<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 31 Jan 2025 18:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Apple files emergency motion to become defendant in US vs. Google [pdf] (168 pts)]]></title>
            <link>https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1158.0_1.pdf</link>
            <guid>42889297</guid>
            <pubDate>Fri, 31 Jan 2025 16:53:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1158.0_1.pdf">https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1158.0_1.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=42889297">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[RamaLama (139 pts)]]></title>
            <link>https://github.com/containers/ramalama</link>
            <guid>42887939</guid>
            <pubDate>Fri, 31 Jan 2025 14:20:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/containers/ramalama">https://github.com/containers/ramalama</a>, See on <a href="https://news.ycombinator.com/item?id=42887939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/containers/ramalama/blob/main/logos/PNG/ramalama-logo-full-vertical-added-bg.png"><img src="https://github.com/containers/ramalama/raw/main/logos/PNG/ramalama-logo-full-vertical-added-bg.png" alt="RAMALAMA logo"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">RamaLama</h2><a id="user-content-ramalama" aria-label="Permalink: RamaLama" href="#ramalama"></a></p>
<p dir="auto">The RamaLama project's goal is to make working with AI boring
through the use of OCI containers.</p>
<p dir="auto">RamaLama tool facilitates local management and serving of AI Models.</p>
<p dir="auto">On first run RamaLama inspects your system for GPU support, falling back to CPU support if no GPUs are present.</p>
<p dir="auto">RamaLama uses container engines like Podman or Docker to pull the appropriate OCI image with all of the software necessary to run an AI Model for your systems setup.</p>
<p dir="auto">Running in containers eliminates the need for users to configure the host system for AI. After the initialization, RamaLama runs the AI Models within a container based on the OCI image.</p>
<p dir="auto">RamaLama then pulls AI Models from model registries. Starting a chatbot or a rest API service from a simple single command. Models are treated similarly to how Podman and Docker treat container images.</p>
<p dir="auto">When both Podman and Docker are installed, RamaLama defaults to Podman, The <code>RAMALAMA_CONTAINER_ENGINE=docker</code> environment variable can override this behaviour. When neither are installed RamaLama will attempt to run the model with software on the local system.</p>
<p dir="auto">RamaLama supports multiple AI model registries types called transports.
Supported transports:</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">TRANSPORTS</h2><a id="user-content-transports" aria-label="Permalink: TRANSPORTS" href="#transports"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Transports</th>
<th>Web Site</th>
</tr>
</thead>
<tbody>
<tr>
<td>HuggingFace</td>
<td><a href="https://www.huggingface.co/" rel="nofollow"><code>huggingface.co</code></a></td>
</tr>
<tr>
<td>Ollama</td>
<td><a href="https://www.ollama.com/" rel="nofollow"><code>ollama.com</code></a></td>
</tr>
<tr>
<td>OCI Container Registries</td>
<td><a href="https://opencontainers.org/" rel="nofollow"><code>opencontainers.org</code></a></td>
</tr>
<tr>
<td></td>
<td>Examples: <a href="https://quay.io/" rel="nofollow"><code>quay.io</code></a>,  <a href="https://docker.io/" rel="nofollow"><code>Docker Hub</code></a>, and <a href="https://artifactory.com/" rel="nofollow"><code>Artifactory</code></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">RamaLama uses the Ollama registry transport by default. Use the RAMALAMA_TRANSPORTS environment variable to modify the default. <code>export RAMALAMA_TRANSPORT=huggingface</code> Changes RamaLama to use huggingface transport.</p>
<p dir="auto">Individual model transports can be modifies when specifying a model via the <code>huggingface://</code>, <code>oci://</code>, or <code>ollama://</code> prefix.</p>
<p dir="auto"><code>ramalama pull huggingface://afrideva/Tiny-Vicuna-1B-GGUF/tiny-vicuna-1b.q2_k.gguf</code></p>
<p dir="auto">To make it easier for users, RamaLama uses shortname files, which container
alias names for fully specified AI Models allowing users to specify the shorter
names when referring to models. RamaLama reads shortnames.conf files if they
exist . These files contain a list of name value pairs for specification of
the model. The following table specifies the order which RamaLama reads the files
. Any duplicate names that exist override previously defined shortnames.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Shortnames type</th>
<th>Path</th>
</tr>
</thead>
<tbody>
<tr>
<td>Distribution</td>
<td>/usr/share/ramalama/shortnames.conf</td>
</tr>
<tr>
<td>Administrators</td>
<td>/etc/ramamala/shortnames.conf</td>
</tr>
<tr>
<td>Users</td>
<td>$HOME/.config/ramalama/shortnames.conf</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div data-snippet-clipboard-copy-content="$ cat /usr/share/ramalama/shortnames.conf
[shortnames]
  &quot;tiny&quot; = &quot;ollama://tinyllama&quot;
  &quot;granite&quot; = &quot;huggingface://instructlab/granite-7b-lab-GGUF/granite-7b-lab-Q4_K_M.gguf&quot;
  &quot;granite:7b&quot; = &quot;huggingface://instructlab/granite-7b-lab-GGUF/granite-7b-lab-Q4_K_M.gguf&quot;
  &quot;ibm/granite&quot; = &quot;huggingface://instructlab/granite-7b-lab-GGUF/granite-7b-lab-Q4_K_M.gguf&quot;
  &quot;merlinite&quot; = &quot;huggingface://instructlab/merlinite-7b-lab-GGUF/merlinite-7b-lab-Q4_K_M.gguf&quot;
  &quot;merlinite:7b&quot; = &quot;huggingface://instructlab/merlinite-7b-lab-GGUF/merlinite-7b-lab-Q4_K_M.gguf&quot;
..."><pre lang="code"><code>$ cat /usr/share/ramalama/shortnames.conf
[shortnames]
  "tiny" = "ollama://tinyllama"
  "granite" = "huggingface://instructlab/granite-7b-lab-GGUF/granite-7b-lab-Q4_K_M.gguf"
  "granite:7b" = "huggingface://instructlab/granite-7b-lab-GGUF/granite-7b-lab-Q4_K_M.gguf"
  "ibm/granite" = "huggingface://instructlab/granite-7b-lab-GGUF/granite-7b-lab-Q4_K_M.gguf"
  "merlinite" = "huggingface://instructlab/merlinite-7b-lab-GGUF/merlinite-7b-lab-Q4_K_M.gguf"
  "merlinite:7b" = "huggingface://instructlab/merlinite-7b-lab-GGUF/merlinite-7b-lab-Q4_K_M.gguf"
...
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install via PyPi</h2><a id="user-content-install-via-pypi" aria-label="Permalink: Install via PyPi" href="#install-via-pypi"></a></p>
<p dir="auto">RamaLama is available via PyPi <a href="https://pypi.org/project/ramalama" rel="nofollow">https://pypi.org/project/ramalama</a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Install by script</h2><a id="user-content-install-by-script" aria-label="Permalink: Install by script" href="#install-by-script"></a></p>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">If you are a macOS user, this is the preferred method.</p>
</div>
<p dir="auto">Install RamaLama by running this one-liner:</p>
<div data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/containers/ramalama/s/install.sh | bash"><pre><code>curl -fsSL https://raw.githubusercontent.com/containers/ramalama/s/install.sh | bash
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware Support</h2><a id="user-content-hardware-support" aria-label="Permalink: Hardware Support" href="#hardware-support"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Hardware</th>
<th>Enabled</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>✅</td>
</tr>
<tr>
<td>Apple Silicon GPU (Linux / Asahi)</td>
<td>✅</td>
</tr>
<tr>
<td>Apple Silicon GPU (macOS)</td>
<td>✅</td>
</tr>
<tr>
<td>Apple Silicon GPU (podman-machine)</td>
<td>✅</td>
</tr>
<tr>
<td>Nvidia GPU (cuda)</td>
<td>✅</td>
</tr>
<tr>
<td>AMD GPU (rocm)</td>
<td>✅</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">COMMANDS</h2><a id="user-content-commands" aria-label="Permalink: COMMANDS" href="#commands"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama.1.md">ramalama(1)</a></td>
<td>primary RamaLama man page</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-containers.1.md">ramalama-containers(1)</a></td>
<td>list all RamaLama containers</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-info.1.md">ramalama-info(1)</a></td>
<td>display RamaLama configuration information</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-list.1.md">ramalama-list(1)</a></td>
<td>list all downloaded AI Models</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-login.1.md">ramalama-login(1)</a></td>
<td>login to remote registry</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-logout.1.md">ramalama-logout(1)</a></td>
<td>logout from remote registry</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-pull.1.md">ramalama-pull(1)</a></td>
<td>pull AI Model from Model registry to local storage</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-push.1.md">ramalama-push(1)</a></td>
<td>push AI Model from local storage to remote registry</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-rm.1.md">ramalama-rm(1)</a></td>
<td>remove AI Model from local storage</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-run.1.md">ramalama-run(1)</a></td>
<td>run specified AI Model as a chatbot</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-serve.1.md">ramalama-serve(1)</a></td>
<td>serve REST API on specified AI Model</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-stop.1.md">ramalama-stop(1)</a></td>
<td>stop named container that is running AI Model</td>
</tr>
<tr>
<td><a href="https://github.com/containers/ramalama/blob/main/docs/ramalama-version.1.md">ramalama-version(1)</a></td>
<td>display version of AI Model</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running Models</h3><a id="user-content-running-models" aria-label="Permalink: Running Models" href="#running-models"></a></p>
<p dir="auto">You can <code>run</code> a chatbot on a model using the <code>run</code> command. By default, it pulls from the Ollama registry.</p>
<p dir="auto">Note: RamaLama will inspect your machine for native GPU support and then will
use a container engine like Podman to pull an OCI container image with the
appropriate code and libraries to run the AI Model. This can take a long time to setup, but only on the first run.</p>
<div data-snippet-clipboard-copy-content="$ ramalama run instructlab/merlinite-7b-lab
Copying blob 5448ec8c0696 [--------------------------------------] 0.0b / 63.6MiB (skipped: 0.0b = 0.00%)
Copying blob cbd7e392a514 [--------------------------------------] 0.0b / 65.3MiB (skipped: 0.0b = 0.00%)
Copying blob 5d6c72bcd967 done  208.5MiB / 208.5MiB (skipped: 0.0b = 0.00%)
Copying blob 9ccfa45da380 [--------------------------------------] 0.0b / 7.6MiB (skipped: 0.0b = 0.00%)
Copying blob 4472627772b1 [--------------------------------------] 0.0b / 120.0b (skipped: 0.0b = 0.00%)
>"><pre><code>$ ramalama run instructlab/merlinite-7b-lab
Copying blob 5448ec8c0696 [--------------------------------------] 0.0b / 63.6MiB (skipped: 0.0b = 0.00%)
Copying blob cbd7e392a514 [--------------------------------------] 0.0b / 65.3MiB (skipped: 0.0b = 0.00%)
Copying blob 5d6c72bcd967 done  208.5MiB / 208.5MiB (skipped: 0.0b = 0.00%)
Copying blob 9ccfa45da380 [--------------------------------------] 0.0b / 7.6MiB (skipped: 0.0b = 0.00%)
Copying blob 4472627772b1 [--------------------------------------] 0.0b / 120.0b (skipped: 0.0b = 0.00%)
&gt;
</code></pre></div>
<p dir="auto">After the initial container image has been downloaded, you can interact with
different models, using the container image.</p>
<div data-snippet-clipboard-copy-content="$ ramalama run granite3-moe
> Write a hello world application in python

print(&quot;Hello World&quot;)"><pre><code>$ ramalama run granite3-moe
&gt; Write a hello world application in python

print("Hello World")
</code></pre></div>
<p dir="auto">In a different terminal window see the running podman container.</p>
<div data-snippet-clipboard-copy-content="$ podman ps
CONTAINER ID  IMAGE                             COMMAND               CREATED        STATUS        PORTS       NAMES
91df4a39a360  quay.io/ramalama/ramalama:latest  /home/dwalsh/rama...  4 minutes ago  Up 4 minutes              gifted_volhard"><pre><code>$ podman ps
CONTAINER ID  IMAGE                             COMMAND               CREATED        STATUS        PORTS       NAMES
91df4a39a360  quay.io/ramalama/ramalama:latest  /home/dwalsh/rama...  4 minutes ago  Up 4 minutes              gifted_volhard
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Listing Models</h3><a id="user-content-listing-models" aria-label="Permalink: Listing Models" href="#listing-models"></a></p>
<p dir="auto">You can <code>list</code> all models pulled into local storage.</p>
<div data-snippet-clipboard-copy-content="$ ramalama list
NAME                                                                MODIFIED     SIZE
ollama://smollm:135m                                                16 hours ago 5.5M
huggingface://afrideva/Tiny-Vicuna-1B-GGUF/tiny-vicuna-1b.q2_k.gguf 14 hours ago 460M
ollama://moondream:latest                                           6 days ago   791M
ollama://phi4:latest                                                6 days ago   8.43 GB
ollama://tinyllama:latest                                           1 week ago   608.16 MB
ollama://granite3-moe:3b                                            1 week ago   1.92 GB
ollama://granite3-moe:latest                                        3 months ago 1.92 GB
ollama://llama3.1:8b                                                2 months ago 4.34 GB
ollama://llama3.1:latest                                            2 months ago 4.34 GB"><pre><code>$ ramalama list
NAME                                                                MODIFIED     SIZE
ollama://smollm:135m                                                16 hours ago 5.5M
huggingface://afrideva/Tiny-Vicuna-1B-GGUF/tiny-vicuna-1b.q2_k.gguf 14 hours ago 460M
ollama://moondream:latest                                           6 days ago   791M
ollama://phi4:latest                                                6 days ago   8.43 GB
ollama://tinyllama:latest                                           1 week ago   608.16 MB
ollama://granite3-moe:3b                                            1 week ago   1.92 GB
ollama://granite3-moe:latest                                        3 months ago 1.92 GB
ollama://llama3.1:8b                                                2 months ago 4.34 GB
ollama://llama3.1:latest                                            2 months ago 4.34 GB
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pulling Models</h3><a id="user-content-pulling-models" aria-label="Permalink: Pulling Models" href="#pulling-models"></a></p>
<p dir="auto">You can <code>pull</code> a model using the <code>pull</code> command. By default, it pulls from the Ollama registry.</p>
<div data-snippet-clipboard-copy-content="$ ramalama pull granite3-moe
 31% |████████                    |  250.11 MB/ 783.77 MB  36.95 MB/s       14s"><pre><code>$ ramalama pull granite3-moe
 31% |████████                    |  250.11 MB/ 783.77 MB  36.95 MB/s       14s
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Serving Models</h3><a id="user-content-serving-models" aria-label="Permalink: Serving Models" href="#serving-models"></a></p>
<p dir="auto">You can <code>serve</code> multiple models using the <code>serve</code> command. By default, it pulls from the Ollama registry.</p>
<div data-snippet-clipboard-copy-content="$ ramalama serve --name mylama llama3"><pre><code>$ ramalama serve --name mylama llama3
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Stopping servers</h3><a id="user-content-stopping-servers" aria-label="Permalink: Stopping servers" href="#stopping-servers"></a></p>
<p dir="auto">You can stop a running model if it is running in a container.</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">UI support</h3><a id="user-content-ui-support" aria-label="Permalink: UI support" href="#ui-support"></a></p>
<p dir="auto">To use a UI, run a <code>ramalama serve</code> command, then connect via your browser at:</p>
<p dir="auto">127.0.0.1:8080</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Diagram</h2><a id="user-content-diagram" aria-label="Permalink: Diagram" href="#diagram"></a></p>
<div data-snippet-clipboard-copy-content="+---------------------------+
|                           |
| ramalama run granite3-moe |
|                           |
+-------+-------------------+
	|
	|
        |           +------------------+           +------------------+
        |           | Pull inferencing |           | Pull model layer |
        +-----------| runtime (cuda)   |---------->| granite3-moe     |
                    +------------------+           +------------------+
						   | Repo options:    |
						   +-+-------+------+-+
						     |       |      |
						     v       v      v
					     +---------+ +------+ +----------+
					     | Hugging | | OCI  | | Ollama   |
					     | Face    | |      | | Registry |
					     +-------+-+ +---+--+ +-+--------+
						     |       |      |
						     v       v      v
						   +------------------+
						   | Start with       |
						   | cuda runtime     |
						   | and              |
						   | granite3-moe     |
						   +------------------+"><pre><code>+---------------------------+
|                           |
| ramalama run granite3-moe |
|                           |
+-------+-------------------+
	|
	|
        |           +------------------+           +------------------+
        |           | Pull inferencing |           | Pull model layer |
        +-----------| runtime (cuda)   |----------&gt;| granite3-moe     |
                    +------------------+           +------------------+
						   | Repo options:    |
						   +-+-------+------+-+
						     |       |      |
						     v       v      v
					     +---------+ +------+ +----------+
					     | Hugging | | OCI  | | Ollama   |
					     | Face    | |      | | Registry |
					     +-------+-+ +---+--+ +-+--------+
						     |       |      |
						     v       v      v
						   +------------------+
						   | Start with       |
						   | cuda runtime     |
						   | and              |
						   | granite3-moe     |
						   +------------------+
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">In development</h2><a id="user-content-in-development" aria-label="Permalink: In development" href="#in-development"></a></p>
<p dir="auto">Regard this alpha, everything is under development, so expect breaking changes, luckily it's easy to reset everything and re-install:</p>
<div data-snippet-clipboard-copy-content="rm -rf /var/lib/ramalama # only required if running as root user
rm -rf $HOME/.local/share/ramalama"><pre><code>rm -rf /var/lib/ramalama # only required if running as root user
rm -rf $HOME/.local/share/ramalama
</code></pre></div>
<p dir="auto">and install again.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credit where credit is due</h2><a id="user-content-credit-where-credit-is-due" aria-label="Permalink: Credit where credit is due" href="#credit-where-credit-is-due"></a></p>
<p dir="auto">This project wouldn't be possible without the help of other projects like:</p>
<p dir="auto">llama.cpp<br>
whisper.cpp<br>
vllm<br>
podman<br>
huggingface</p>
<p dir="auto">so if you like this tool, give some of these repos a ⭐, and hey, give us a ⭐ too while you are at it.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto"><a href="https://matrix.to/#/#ramalama:fedoraproject.org" rel="nofollow"><code>Matrix</code></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<p dir="auto">Open to contributors</p>
<a href="https://github.com/containers/ramalama/graphs/contributors">
  <img src="https://camo.githubusercontent.com/82bc3486beb7e9973918ff7622dfe963d5fa51d8f65f6c0a6aa624aee7cd028b/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d636f6e7461696e6572732f72616d616c616d61" data-canonical-src="https://contrib.rocks/image?repo=containers/ramalama">
</a>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ear muscle we thought humans didn't use activates when people listen hard (167 pts)]]></title>
            <link>https://www.frontiersin.org/news/2025/01/31/ear-muscle-wiggling-ears-activates-listening-frontiers-neuroscience</link>
            <guid>42886867</guid>
            <pubDate>Fri, 31 Jan 2025 12:11:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.frontiersin.org/news/2025/01/31/ear-muscle-wiggling-ears-activates-listening-frontiers-neuroscience">https://www.frontiersin.org/news/2025/01/31/ear-muscle-wiggling-ears-activates-listening-frontiers-neuroscience</a>, See on <a href="https://news.ycombinator.com/item?id=42886867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!--[--><!----><!--]--><figure><picture><!--[--><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1fQgvZhdIvpxsvUlhLGVq9/4c073694c3d48aa2c24fa418f3751cd2/Horizontal-Side_view_of_senior_man_with_symptom_of_hearing_loss._Mature_man_sitting_on_couch_with_fingers_near_ear_suffering.png?&amp;w=380&amp;fm=webp&amp;q=80" media="(max-width: 767px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1fQgvZhdIvpxsvUlhLGVq9/4c073694c3d48aa2c24fa418f3751cd2/Horizontal-Side_view_of_senior_man_with_symptom_of_hearing_loss._Mature_man_sitting_on_couch_with_fingers_near_ear_suffering.png?&amp;w=642&amp;fm=webp&amp;q=80" media="(min-width: 768px and max-width: 1023px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1fQgvZhdIvpxsvUlhLGVq9/4c073694c3d48aa2c24fa418f3751cd2/Horizontal-Side_view_of_senior_man_with_symptom_of_hearing_loss._Mature_man_sitting_on_couch_with_fingers_near_ear_suffering.png?&amp;w=824&amp;fm=webp&amp;q=80" media="(min-width: 1024px and max-width: 1279px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1fQgvZhdIvpxsvUlhLGVq9/4c073694c3d48aa2c24fa418f3751cd2/Horizontal-Side_view_of_senior_man_with_symptom_of_hearing_loss._Mature_man_sitting_on_couch_with_fingers_near_ear_suffering.png?&amp;w=644&amp;fm=webp&amp;q=80" media="(min-width: 1280px and max-width: 1439px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1fQgvZhdIvpxsvUlhLGVq9/4c073694c3d48aa2c24fa418f3751cd2/Horizontal-Side_view_of_senior_man_with_symptom_of_hearing_loss._Mature_man_sitting_on_couch_with_fingers_near_ear_suffering.png?&amp;w=672&amp;fm=webp&amp;q=80" media="(min-width: 1440px and max-width: 1919px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1fQgvZhdIvpxsvUlhLGVq9/4c073694c3d48aa2c24fa418f3751cd2/Horizontal-Side_view_of_senior_man_with_symptom_of_hearing_loss._Mature_man_sitting_on_couch_with_fingers_near_ear_suffering.png?&amp;w=912&amp;fm=webp&amp;q=80" media="(min-width: 1920px)"><!--]--><img src="https://images.ctfassets.net/mrbo2ykgx5lt/1fQgvZhdIvpxsvUlhLGVq9/4c073694c3d48aa2c24fa418f3751cd2/Horizontal-Side_view_of_senior_man_with_symptom_of_hearing_loss._Mature_man_sitting_on_couch_with_fingers_near_ear_suffering.png?&amp;w=912&amp;fm=webp&amp;q=80" alt="" loading="eager"></picture><figcaption>An older man presses his fingers to the side of his head, next to his ear.</figcaption></figure><!--[--><p><strong>To test whether humans still use auricular muscles — which once helped move our primate ancestors’ ears to funnel sound — scientists attached electrodes to the sides of people’s heads, and asked them to listen closely to an audiobook. Different challenge modes were imposed, with the sound coming from different angles, and other competing sounds. The scientists found that, the more difficult it was for participants to hear the audiobook, the more the superior auricular muscles activated, as if participants were trying to prick up their ears like a dog or cat. When sounds came from behind a participant, the posterior auricular muscles contracted as if attempting to point the ears in that direction. </strong></p><p>If you can wiggle your ears, you can use muscles that helped our distant ancestors listen closely. These auricular muscles helped change the shape of the pinna, or the shell of the ear, funneling sound to the eardrums. Millions of years ago, our ancestors stopped using them, so humans’ auricular muscles are only vestigial. But now scientists examining the function of these muscles have discovered that they activate when we’re trying to listen to competing sounds. </p><p>“There are three large muscles which connect the auricle to the skull and scalp and are important for ear wiggling,” explained Andreas Schröer of Saarland University, first author of the study in <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1462507/full"><em>Frontiers in Neuroscience</em></a>. “These muscles, particularly the superior auricular muscle, exhibit increased activity during effortful listening tasks. This suggests that these muscles are engaged not merely as a reflex but potentially as part of an attentional effort mechanism, especially in challenging auditory environments.” </p><h2>Straining your ears</h2><p>It’s difficult to test how hard someone is listening without self-reported measures. But electromyography, which measures electrical activity in a muscle, can help identify activity in the auricular muscles linked to listening closely. Similar research has already shown that the largest muscles, posterior and superior auricular muscles, react during attentive listening. Because they pull the ears up and back, they are considered likely to have been involved in moving the pinna to capture sounds.</p><p>“The exact reason these became vestigial is difficult to tell, as our ancestors lost this ability about 25 million years ago,” Schröer said. “One possible explanation could be that the evolutionary pressure to move the ears ceased because we became much more proficient with our visual and vocal systems.” 

To test whether these muscles are more active during more difficult listening tasks, the scientists recruited 20 people without hearing problems. They applied electrodes to participants’ auricular muscles and then played them an audiobook and distracting podcasts from speakers in front of or behind them. Each participant underwent 12 five-minute trials, covering three different levels of difficulty. </p><p>On easy mode, the podcast was quieter than the audiobook, and the speaker’s voice was a stronger contrast to the audiobook. To create two more difficult modes, the scientists added a podcast that sounded more like the audiobook and made the distractors louder.  However, the researchers were careful to make even the most difficult condition achievable: if the participants gave up, no physiological effort would register.  </p><p>Then, the scientists asked the participants to rate their effort levels and to estimate how often they lost the thread of the audiobook in each trial. They also quizzed the participants on the audiobook’s content. </p><hr><p><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1462507/full">Read and download the original article</a></p><hr><h2>Hearsay</h2><p>The scientists found that the two auricular muscles reacted differently to the different conditions. The posterior auricular muscles reacted to changes in direction, while the superior auricular muscles reacted to the difficulty level of the task. Participants’ self-reported measures of effort and how often they lost track of the audiobook rose in line with the difficulty of the task, and the accuracy of their responses to questions about the audiobook dropped noticeably between the medium and the difficult mode.&nbsp;&nbsp; </p><p>This correlated with the superior auricular muscles’ activity levels: they didn’t activate more during the medium mode than during the easy mode, but were very active during the difficult mode. This suggests that the activity of the superior auricular muscles could provide an objective measure of listening effort, although it’s unclear if the muscle activity helps people hear. </p><p>“The ear movements that could be generated by the signals we have recorded are so minuscule that there is probably no perceivable benefit,” said Schröer. “However, the auricle itself does contribute to our ability to localize sounds. So, our auriculomotor system probably tries its best after being vestigial for 25 million years, but does not achieve much.” </p><p>The scientists pointed out that more work will be necessary to confirm these results and develop practical applications. Like many hearing studies, their sample was relatively small and composed of young people without hearing problems. Larger, more diverse participant groups, in more realistic conditions, are needed.  </p><p>“Investigating the possible effects of muscle strain itself or the ear’s miniscule movements on the transmission of sound is something we want to do in the future,” said Schröer. “The effect of these factors in people with hearing impairments would also be interesting to investigate.” 
</p><p><strong>REPUBLISHING GUIDELINES</strong>: Open access and sharing research is part of <a href="https://www.frontiersin.org/about/about-frontiers">Frontiers’ mission</a>. Unless otherwise noted, you can republish articles posted in the Frontiers news site — as long as you include a link back to the original research. Selling the articles is not allowed. </p><!--]--><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Casio F91w at 5KM underwater – watches of espionage (259 pts)]]></title>
            <link>https://www.watchesofespionage.com/blogs/woe-dispatch/casio-f91w-diving-underwater-pressure-test</link>
            <guid>42886718</guid>
            <pubDate>Fri, 31 Jan 2025 11:40:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.watchesofespionage.com/blogs/woe-dispatch/casio-f91w-diving-underwater-pressure-test">https://www.watchesofespionage.com/blogs/woe-dispatch/casio-f91w-diving-underwater-pressure-test</a>, See on <a href="https://news.ycombinator.com/item?id=42886718">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
              <h2><strong>Pressure Testing An Affordable Watch &amp; Understanding Deepsea Espionage</strong></h2>
<p><em>By Benjamin Lowry</em></p>
<p>While the stories we tell typically explore the world of intelligence in the terrestrial sense, espionage and the deep sea have been closely linked for decades. Starting during the Cold War, a shadowy conflict has been waged on the ocean floor. From submarines and divers tapping (or cutting) cables to deepsea acoustic listening stations and the clandestine recovery of sensitive materials, controlling and monitoring the deep ocean is an unfamiliar yet critical component of intelligence and modern warfare.</p>
<p>Brands like Rolex and Omega will often tout their deepsea capabilities with the Rolex Deepsea Challenge rated to 11,000 meters (36,090 feet) and the Omega Ultra Deep coming in at a lesser but still ridiculous 6,000 meters (20,000 feet) of theoretical water resistance. But what about a cheap Casio often associated with terrorists and hipsters? With around $15 and some engineering know-how, can an affordable watch also venture into the deep ocean?</p>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/Glomar-High-res-4-Toni_600x600.jpg?v=1737727560" alt="Setting the stage for undersea espionage to follow, the CIA’s Glomar Explorer was a ship designed to secretly raise a sunken Soviet submarine to recover its nuclear warheads. (Photo Credit: CIA)"></p>
<h6>Setting the stage for undersea espionage to follow, the CIA’s Glomar Explorer was a ship designed to secretly raise a sunken Soviet submarine to recover its nuclear warheads. (Photo Credit: CIA)</h6>
<p>At W.O.E., watches are the lens through which we view history and current events. In this Dispatch, we’ll take a Casio F91W—a cheap digital tool watch—almost 5,000 meters (16,400 feet) under the sea, setting the stage for a broader discussion on the deep ocean’s role in the wilderness of mirrors. As a Coast Guard veteran and former commercial diver, I’m no expert on the intersection of engineering and espionage at depth. Luckily, I know people.</p>
<h2><strong>Pressure Testing A Casio F91W</strong></h2>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/ROVTRIPWOE-1_1024x1024.jpg?v=1737727632" alt="Our friend Josh’s Omega Planet Ocean on the manipulator arm of an ROV. (Photo Credit: Brock Stevens)"></p>
<h6>Our friend Josh’s Omega Planet Ocean on the manipulator arm of an ROV. (Photo Credit: Brock Stevens)</h6>
<p>A couple of years ago, a fellow watch enthusiast named Josh Konicki reached out saying he worked in the unique world of deep ocean salvage, often contracting for the US Government to recover downed fighter jets, lost ordnance, and other sensitive items the military doesn’t want lying around the ocean floor. In 2022, Josh and his team helped the Navy recover an F35 that crashed into the South China Sea from the deck of an aircraft carrier. It’s scary to imagine the repercussions if our adversaries were to recover and reverse engineer one of the world’s most advanced fighter jet platforms—not good.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/aircraft-ht-ml-220303_1646325566304_hpMain_16x9_1600_600x600.jpg?v=1737727807" alt="F35 recovery rov south china sea deepsea diving cia espionage watches f91w"></p>
<h6>Photo Credit: US Navy</h6>
<p>Like many whose lives revolve around the sea, Josh is a watch guy, and when he asked if I would be interested in seeing a Casio F91W dive deep on the manipulator arm of an ROV or remotely operated vehicle, I answered with an enthusiastic “hell yeah”.</p>
<p>Available on Amazon for precisely $13.16, the F91W is among the most common watches on the planet, with some three million units produced on average per year since the watch’s inception in 1989. This implies there are well over 100 million F91Ws out there in the world, a crazy statistic. Utilized as a tool by everyone from <a title="Casio F-91W, the Preferred Watch of Terrorists" href="https://www.watchesofespionage.com/blogs/woe-dispatch/casio-f-91w-the-preferred-watch-of-terrorists" target="_blank">Usama Bin Laden</a> to <a title="Digital Watches Of The Global War On Terror" href="https://www.watchesofespionage.com/blogs/woe-dispatch/digital-watches-global-war-on-terror" target="_blank">US SpecOps</a> and art school grads at your local farmers market, the F91W is a straightforward digital watch equipped with a resin case, strap, and crystal and paired with simple digital timekeeping functions and one of the worst backlights in watch history.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/Untitled_design_859_1024x1024.png?v=1737727969" alt="(Photo Credit: James Rupley/W.O.E.) casio f91w 5000 meters diving water resistance"></p>
<h6>(Photo Credit: James Rupley/W.O.E.)</h6>
<p>Many have argued the F91W is the least expensive watch that is actually worth buying, and I tend to agree. For its price, it’s one of the most capable watches you can get. However, while the F91W is many things to many people, most would fall well short of calling it a dive watch, at least unless you’re willing to get a little bit handy, risk your $15 investment, and have some mineral oil lying around.</p>
<h2><strong>Filling A Watch With Oil &amp; Going Deep</strong></h2>
<p><img alt="casio f91w deep diving pressure test hydromod oil" src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/Tactical_Watches_Holiday_Movies_3_600x600.png?v=1737730515"></p>
<p>For Josh, whose job is to build and maintain equipment for deepsea salvage and recovery, filling a digital watch with oil is no big deal. Incredibly, after this relatively simple and cheap modification, a watch—even one as attainable as the F91W—becomes all but pressure-proof thanks to the almost incompressible nature of oil. The actual how-to for this “hydro-mod” is all over the internet, but suffice it to say oil-filling your Casio is relatively easy, cheap, fun, and helps if you’re planning to take your F91W five kilometers or so underwater, which is exactly the kind of thing Josh does for fun.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/A94C2DFB-DE23-48E4-BF12-364B371AF577_1_201_a_600x600.jpg?v=1737728402" alt="casio f91w hydro mod water resistance diving 5000 meters"></p>
<p>For the deep ocean test, Josh strapped the F91W onto the manipulator arm of CURV 21, a 6,400-pound ROV belonging to the US Navy and capable of diving to around 20,000 feet. The live video feed from the ROV, which is hard-wired to the surface, means the operator can observe the watch throughout the dive. As the numbers on the depth gauge begin to rise, there’s an element of suspense as the ROV descends through the water column. The bright ambient light of the shallows gives way to the inky darkness of the depths, with nothing but small particles passing by the ROV’s lights to indicate the descent to the bottom. As the digital depth indication passes 1000 meters, 2000 meters, 3000 meters, and finally 4000 meters, the watch nerds in the room are glued to the screen waiting for the $15 watch to implode… or not. Incredibly, the F91W survives its journey to an official 4,950 meters—an astonishing 16,240 feet—and back.</p>
<p>4,950 meters under the surface, the pressure is approximately 7,227 pounds per square inch, which is well over three tons pressing on the watch. For context, that’s a Dodge Ram 1500 or a young adult hippopotamus parked on every inch of your F91W. As Americans, we’ll do anything to avoid the metric system, but using scientific terminology, we’re talking about a shitload of pressure.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/IMG_9167_600x600.heic?v=1737728532" alt="Josh with his fleet of deep-diving F91W watches and the ROV."></p>
<h6>Josh with his fleet of deep-diving F91W watches and the ROV.</h6>
<p>However impressive, this example of oil-filled horological pressure resistance is not unique. There are other oil-filled watches from brands like Sinn capable of similar diving exploits, and many other watches both digital and analog quartz (mechanical watches can’t be oil-filled) that could theoretically be filled with oil and go deep. But the feat is all the more impressive when considering the F91W costs about as much as a Chipotle burrito (with guac). But wait, what is the US Government doing 5000 meters down anyway?</p>
<h2><strong>A Brief History Of Deepsea Espionage</strong></h2>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/211020-us-navy-sealab-3-illustration_1_600x600.jpg?v=1737728599" alt="Artist’s rendering of SEALAB III, the Navy’s final experiment to prove men could live and work on the sea floor. (Photo Credit: US Navy)"></p>
<h6>Artist’s rendering of SEALAB III, the Navy’s final experiment to prove men could live and work on the sea floor. (Photo Credit: US Navy)</h6>
<p>When the <a title="The Newly-Discovered Watches Of SEALAB III &amp; The Records That Prove It" href="https://www.watchesofespionage.com/blogs/woe-dispatch/sealab-watches-doxa-rolex-jaquet-droz" target="_blank">US Navy’s SEALAB trials</a> kicked off in 1964, the reason behind the costly and dangerous experiment was billed as an attempt to prove man’s ability to live and work in the sea. The part the Navy left out was why the US Government might require such a mode of diving in the first place, and the principal reason was intelligence collection. Even after the cancellation of SEALAB III in the wake of aquanaut Berry Cannon’s death in 1969, the Navy didn’t stop its deep-diving research, it simply stopped talking about it.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/USS-Parche_Sutton_600x600.jpg?v=1737728712" alt="Artist’s rendering of the USS Parche, one of the modified submarines used in Operation Ivy Bells. (Photo Credit: Naval Order)"></p>
<h6>Artist’s rendering of the USS Parche, one of the modified submarines used in Operation Ivy Bells. (Photo Credit: Naval Order)</h6>
<p>Before SEALAB, the Navy was already using the Sound Surveillance System, a network of underwater listening stations designed to detect and monitor submarine movements, especially the kind with nuclear capabilities. By the 1970s, American submarine espionage was in full swing, with the specially modified USS Halibut using diver lockout chambers and saturation diving methodology developed during SEALAB to attach listening equipment to Soviet communication cables in the Sea of Okhotsk as part of Operation Ivy Bells. If you haven’t read up on this insane operation, there’s a great book called <a href="https://amzn.to/3PLT88T" target="_blank" title="Blind Man's Bluff: The Untold Story Of American Submarine Espionage" rel="noopener"><em>Blind Man's Bluff: The Untold Story Of American Submarine Espionage</em></a>, that is more than worth your time.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/D951851B-C970-48D6-A461-32EBADE63BBB_600x600.jpg?v=1737728989" alt="US Navy SEAL Rick Hetzell wearing a Rolex Submariner on an Olongapo bracelet while working with his US Navy-trained sea lion."></p>
<h6>US Navy SEAL Rick Hetzell wearing a Rolex Submariner on an Olongapo bracelet while working with his US Navy-trained sea lion.</h6>
<p>By 1974, the CIA and Howard Hughes built the Glomar Explorer, a 618-foot supposed deep-sea mining ship designed to secretly raise a sunken Soviet submarine, the K-129, from a depth of 4,900 meters (16,000 feet). The plan was for the ship to use a massive specially engineered undersea claw, which was completely hidden from the outside of the ship, to lift the sub and recover its nuclear warheads and cryptological documents. To date, it remains one of the most complex, expensive, and secretive intelligence operations of the Cold War.</p>
<p>It gets weirder. Starting in 1960, the US Navy also maintained a fleet of trained marine mammals including dolphins and sea lions capable of locating undersea mines and even identifying and subduing adversarial combat swimmers, especially those with Russian accents. During the Cold War, espionage in the deep sea was alive and well, but what about now?</p>
<h2><strong>A Sea Of Surveillance &amp; Sabotage</strong></h2>
<p><img alt="The true extent of the modern US Navy Marine Mammal Program is unknown to the public. (Photo Credit: US Navy)" src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/Your_paragraph_text_4_600x600.png?v=1737729385"></p>
<h6>
<strong></strong>The true extent of the modern US Navy Marine Mammal Program is unknown to the public. (Photo Credit: US Navy)</h6>
<p>Today, as technology takes an increasingly prominent role in armed conflict, the deep ocean continues to serve as a little-understood domain of war. In addition to its nuclear submarines and a much improved undersea listening system that detected the implosion of the Titan submersible in 2023, the US Navy quietly maintains its Marine Mammal Program, (allegedly) primarily for Mine Countermeasures (MCM), but other recent clandestine acts on the sea floor have—once discovered—burst into the headlines.</p>
<p><img alt="The exploded Nordsteam pipelines were determined acts of sabotage." src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/Nord-Stream-Anschlag-auf-die-Pipeline-4_600x600.jpg?v=1737729471"></p>
<h6>The exploded Nordsteam pipelines were determined acts of sabotage.</h6>
<p>Twenty-three natural gas pipelines connect Europe to Russia. On 26 September 2022, two of them exploded without warning 70 to 80 meters (230 to 260 feet) under the surface of the Baltic Sea. Built to carry Russian natural gas to Germany, the explosion of the Nord Stream 1 and Nord Stream 2 pipelines was captured by undersea seismic listening stations, with explosive materials later being recovered on the surface. With much of Europe facing an energy crisis, the saboteur was careful, exploiting the inherent difficulty of investigating the aftermath on the ocean floor, making attribution difficult.</p>
<p><img alt="A Baltic Sea communications was severed by a vessel dragging its anchor across the cable numerous times." src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/Untitled_design_865_600x600.png?v=1737729560"></p>
<h6>A Baltic Sea communications was severed by a vessel dragging its anchor across the cable numerous times.</h6>
<p>In 2024, also in the Baltic Sea, there were several more highly publicized incidents where deepsea cables carrying internet and electricity were cut by unknown agents. Cables providing internet service between Lithuania and Sweden and Finland and Germany were cut in November. Depending on the depth, operations of this type would likely require advanced marine technology involving divers, ROVs, and submersibles, well beyond the scope of any entity smaller than a major nation-state.</p>
<p>Coincidentally, on Christmas Day, a Russian tanker allegedly packed with “spy equipment” was detained by the Finnish Border Guard after intentionally dragging its anchor across cables providing critical infrastructure. Russia, one of the possible culprits for at least some of the recent undersea acts of espionage, is known to operate a “shadow fleet” of civilian-registered vessels outfitted to conduct intelligence and sabotage operations.</p>
<p><img alt="Eagle S, an alleged Russian “spy tanker” was seized by the Finnish Border Guard on Christmas Day, 2025." src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/medium_eagle_s_dd02367835_600x600.webp?v=1737730045"></p>
<h6>Eagle S, an alleged Russian “spy tanker” was seized by the Finnish Border Guard on Christmas Day, 2025.</h6>
<p>Whether these covert operators wear Vostok Amphibias or F91Ws or something else is anyone’s guess. They don’t appear to have a fleet Instagram page. Home to numerous utility and communications cables, not to mention submarines armed with nuclear weapons, and at least one Casio F91W, the sea floor is a key player in global espionage operations both then and now.<br></p>
<p><span><strong>If you enjoyed this article, please consider signing up for our weekly free newsletter for further updates</strong> <a href="http://eepurl.com/h8jvsv" title="Watches of Espionage Email Signup Link" target="_blank" rel="noopener">HERE</a>.</span></p>
<p><strong>Read Next: </strong><a href="https://www.watchesofespionage.com/blogs/woe-dispatch/casio-f-91w-the-preferred-watch-of-terrorists" target="_blank" title="Casio F-91W, the Preferred Watch of Terrorists" rel="noopener">Casio F-91W, the Preferred Watch of Terrorists</a><strong></strong></p>
<p><a href="https://www.watchesofespionage.com/blogs/woe-dispatch/casio-f-91w-the-preferred-watch-of-terrorists" target="_blank" title="https://www.watchesofespionage.com/blogs/woe-dispatch/casio-f-91w-the-preferred-watch-of-terrorists" rel="noopener"><img alt="casio f91w watches of espionage" src="https://cdn.shopify.com/s/files/1/0582/0291/4931/files/F91WTerror_240x240.webp?v=1737731633"></a></p>
<p><em>*As a disclaimer, as Amazon Associates, we earn from qualifying purchases. When you click on the link to a book in this article and make a purchase, this can result in Watches of Espionage earning a commission. If you’re interested in these books and want to make a purchase using these links, we appreciate your support.</em></p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama.cpp supports Vulkan. why doesn't Ollama? (200 pts)]]></title>
            <link>https://github.com/ollama/ollama/pull/5059</link>
            <guid>42886680</guid>
            <pubDate>Fri, 31 Jan 2025 11:30:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ollama/ollama/pull/5059">https://github.com/ollama/ollama/pull/5059</a>, See on <a href="https://news.ycombinator.com/item?id=42886680">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/pepijndevos/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/pepijndevos">@pepijndevos</a> Thanks for letting me know. After setting <code>GGML_VK_FORCE_MAX_ALLOCATION_SIZE</code>, I verified that <code>llama3.1 8B</code> works fine. However, I noticed a strange issue where models around 12–13 GiB in size fail to upload to the GPU. The CLI only shows the loading indicator continuously without any response.</p>
<ul dir="auto">
<li><strong>Successful:</strong>
<ul dir="auto">
<li><code>llama3.1:8b-instruct-q8_0</code> (7.95 GiB)</li>
<li><code>gemma2:27b-text-q3_K_S</code> (11.33 GiB)</li>
</ul>
</li>
<li><strong>Failed:</strong>
<ul dir="auto">
<li><code>gemma2:27b-instruct-q3_K_L</code> (13.52 GiB)</li>
<li><code>llama3.1:8b-instruct-fp16</code> (14.96 GiB)</li>
</ul>
</li>
</ul>
<p dir="auto">When the upload is successful, only one Vulkan device (the AMD GPU) is detected. However, when it fails, three Vulkan devices are detected instead. In <a href="https://github.com/ggerganov/llama.cpp/blob/master/ggml/src/ggml-vulkan/ggml-vulkan.cpp#L2821">this section of the llama.cpp code</a>, the size of <code>device_indices</code> changes depending on the model size, and I wonder if this might be related to the error.</p>
<details>
    <summary>Successful Case</summary>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/67185299/404688913-2ff829cb-189d-4b07-ba0d-00a6635accd8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzgzMzA1MDIsIm5iZiI6MTczODMzMDIwMiwicGF0aCI6Ii82NzE4NTI5OS80MDQ2ODg5MTMtMmZmODI5Y2ItMTg5ZC00YjA3LWJhMGQtMDBhNjYzNWFjY2Q4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTMxVDEzMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2ZjhmYjdjYjY0Y2ExODY5NDNkZjQ1MmRmZDM2MWUzYmI5YzViNTBhYTRjOWU3NTc4ZDVlNTA5NmE0NmEwOTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.aamDJBaBM23llrwg__c3HmJ1dGShTbwg4q2yo3MIM38"><img width="907" alt="image" src="https://private-user-images.githubusercontent.com/67185299/404688913-2ff829cb-189d-4b07-ba0d-00a6635accd8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzgzMzA1MDIsIm5iZiI6MTczODMzMDIwMiwicGF0aCI6Ii82NzE4NTI5OS80MDQ2ODg5MTMtMmZmODI5Y2ItMTg5ZC00YjA3LWJhMGQtMDBhNjYzNWFjY2Q4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTMxVDEzMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2ZjhmYjdjYjY0Y2ExODY5NDNkZjQ1MmRmZDM2MWUzYmI5YzViNTBhYTRjOWU3NTc4ZDVlNTA5NmE0NmEwOTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.aamDJBaBM23llrwg__c3HmJ1dGShTbwg4q2yo3MIM38"></a>
</details>
<details>
    <summary>Failed Case</summary>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/67185299/404688955-1d135dd9-1d6c-43bc-8c4a-605336bb3a72.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzgzMzA1MDIsIm5iZiI6MTczODMzMDIwMiwicGF0aCI6Ii82NzE4NTI5OS80MDQ2ODg5NTUtMWQxMzVkZDktMWQ2Yy00M2JjLThjNGEtNjA1MzM2YmIzYTcyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTMxVDEzMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2YWJhMGI5MjQ2ZDU4NjkzNTFjNWEyNGI5MjIwZjY2NTIxZjBhMzA2YmFmNjllYzM1YzAzYTNlMjVkOTRiYTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.ZTMUuFhv9zr5rvWHgUox-3FfoSqPUvBlepFYzC0DfJg"><img width="909" alt="image" src="https://private-user-images.githubusercontent.com/67185299/404688955-1d135dd9-1d6c-43bc-8c4a-605336bb3a72.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzgzMzA1MDIsIm5iZiI6MTczODMzMDIwMiwicGF0aCI6Ii82NzE4NTI5OS80MDQ2ODg5NTUtMWQxMzVkZDktMWQ2Yy00M2JjLThjNGEtNjA1MzM2YmIzYTcyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTMxVDEzMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2YWJhMGI5MjQ2ZDU4NjkzNTFjNWEyNGI5MjIwZjY2NTIxZjBhMzA2YmFmNjllYzM1YzAzYTNlMjVkOTRiYTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.ZTMUuFhv9zr5rvWHgUox-3FfoSqPUvBlepFYzC0DfJg"></a>
</details>
<hr>
<p dir="auto">The Maven core is fascinating, and I’m also interested in local LLMs due to data privacy concerns. Could you provide links to the Raspberry Pi images with AMD drivers and Vulkan LLM Docker images? If new Docker images are created, please let me know as well.</p>
<p dir="auto">For my GPU setup, I initially gained a lot of insights from the information shared by Geerlingguy. I’m using a Pineberry Pi UpCity HAT to connect a GPU, but the GPU is too large to securely mount on a Raspberry Pi. Recently, I purchased the AOOSTART AG01 dock, though it hasn’t arrived yet. This dock includes a power switch for the GPU. One thing to watch out for is the wattage, as the dock seems to support GPUs with a power consumption of up to 250W. For AMD GPUs, it appears the 7700 XT is the maximum supported model.</p>
<p dir="auto">For the power supply, I chose the MSI A850GL. It was one of the very few options that seemed capable of connecting two GPUs to a single supply due to its cable and port configuration. First, I tried using NVIDIA’s RTX 4060 Ti (the only 16GB memory option in the 4000 series), but I had issues getting the driver to recognize it properly. So, I switched to AMD’s RX 7600 XT instead. AMD also offers GPUs with over 20GB of memory, so it’s a viable option if you want to run larger LLMs.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NSF starts vetting all grants to comply with executive orders (171 pts)]]></title>
            <link>https://www.science.org/content/article/exclusive-nsf-starts-vetting-all-grants-comply-trump-s-orders</link>
            <guid>42886661</guid>
            <pubDate>Fri, 31 Jan 2025 11:21:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/exclusive-nsf-starts-vetting-all-grants-comply-trump-s-orders">https://www.science.org/content/article/exclusive-nsf-starts-vetting-all-grants-comply-trump-s-orders</a>, See on <a href="https://news.ycombinator.com/item?id=42886661">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/exclusive-nsf-starts-vetting-all-grants-comply-trump-s-orders: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Hacker News for Gamedev (372 pts)]]></title>
            <link>https://gamedev.city/</link>
            <guid>42885520</guid>
            <pubDate>Fri, 31 Jan 2025 07:56:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gamedev.city/">https://gamedev.city/</a>, See on <a href="https://news.ycombinator.com/item?id=42885520">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="inside">


      

<ol>
<li id="story_b6unru" data-shortid="b6unru">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://irokaru.github.io/pixel-scaler/" rel="ugc noreferrer">Pixel art upscaler with a nice algorithm</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="2D, 3D and everything in between" href="https://gamedev.city/t/art">art</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/irokaru.github.io">irokaru.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2025-01-29 15:19:08 -0600">38 hours ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_b6unru">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Firokaru.github.io%2Fpixel-scaler%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Firokaru.github.io%2Fpixel-scaler%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Firokaru.github.io%2Fpixel-scaler%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/b6unru/pixel_art_upscaler_with_nice_algorithm">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_hfyy4d" data-shortid="hfyy4d">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.youtube.com/watch?v=HPqGaIMVuLs" rel="ugc noreferrer">Surface-Stable Fractal Dithering</a>
    </span>
      <a title="A new form of dithering I call Surface-Stable Fractal Dithering.Released it as open source along with this explainer video of how it works.

Find the shader source and example project here:
https://github.com/runevision/Dither3D
https://blog.runevision.com" href="https://gamedev.city/s/hfyy4d/surface_stable_fractal_dithering">☶</a>
      <span>
          <a title="you want to share a video or a link that contains a video " href="https://gamedev.city/t/video">video</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/youtube.com">youtube.com</a></p><div>
        <p><a href="https://gamedev.city/~hayes"><img srcset="https://gamedev.city/avatars/hayes-16.png 1x, https://gamedev.city/avatars/hayes-32.png 2x" alt="hayes avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/hayes-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~hayes">hayes</a>

        <span title="2025-01-24 10:38:52 -0600">6 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_hfyy4d">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DHPqGaIMVuLs">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DHPqGaIMVuLs">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DHPqGaIMVuLs">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/hfyy4d/surface_stable_fractal_dithering">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_giuycn" data-shortid="giuycn">
<div>
  <div>
      <p>9</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://github.com/libsdl-org/SDL/releases/tag/release-3.2.0" rel="ugc noreferrer">SDL 3 it's officially released (3.2.0)</a>
    </span>
      <span>
          <a title="something related to recent events, releases or announcements" href="https://gamedev.city/t/news">news</a>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/github.com">github.com</a></p><div>
        <p><a href="https://gamedev.city/~Andre-LA"><img srcset="https://gamedev.city/avatars/Andre-LA-16.png 1x, https://gamedev.city/avatars/Andre-LA-32.png 2x" alt="Andre-LA avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/Andre-LA-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~Andre-LA">Andre-LA</a>

        <span title="2025-01-21 14:14:30 -0600">9 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_giuycn">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Flibsdl-org%2FSDL%2Freleases%2Ftag%2Frelease-3.2.0">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fgithub.com%2Flibsdl-org%2FSDL%2Freleases%2Ftag%2Frelease-3.2.0">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fgithub.com%2Flibsdl-org%2FSDL%2Freleases%2Ftag%2Frelease-3.2.0">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/giuycn/sdl_3_it_s_officially_released_3_2_0">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_vlpdv7" data-shortid="vlpdv7">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://ssno.cc/posts/reversing-tac-1-4-2025/" rel="ugc noreferrer">Reverse Engineering Call Of Duty Anti-Cheat (Black Ops Cold War)</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/ssno.cc">ssno.cc</a></p><div>
        <p><a href="https://gamedev.city/~Mew"><img srcset="https://gamedev.city/avatars/Mew-16.png 1x, https://gamedev.city/avatars/Mew-32.png 2x" alt="Mew avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/Mew-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~Mew">Mew</a>

        <span title="2025-01-20 23:48:21 -0600">10 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_vlpdv7">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fssno.cc%2Fposts%2Freversing-tac-1-4-2025%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fssno.cc%2Fposts%2Freversing-tac-1-4-2025%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fssno.cc%2Fposts%2Freversing-tac-1-4-2025%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/vlpdv7/reverse_engineering_call_duty_anti_cheat">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_bsy8d5" data-shortid="bsy8d5">
<div>
  <div>
      <p>6</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://github.com/terrehbyte/awesome-devblogs" rel="ugc noreferrer">A curated list of gamedev related devblogs</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/github.com">github.com</a></p><div>
        <p><a href="https://gamedev.city/~Valden"><img srcset="https://gamedev.city/avatars/Valden-16.png 1x, https://gamedev.city/avatars/Valden-32.png 2x" alt="Valden avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/Valden-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~Valden">Valden</a>

        <span title="2025-01-20 05:12:33 -0600">11 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_bsy8d5">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Fterrehbyte%2Fawesome-devblogs">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fgithub.com%2Fterrehbyte%2Fawesome-devblogs">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fgithub.com%2Fterrehbyte%2Fawesome-devblogs">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/bsy8d5/curated_list_gamedev_related_devblogs">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_5drqoa" data-shortid="5drqoa">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.riotgames.com/en/news/tech-blog-cpu-usage" rel="ugc noreferrer">Riot Tech Blog: Improving Performance by Streamlining League’s Server Selection</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="admin, operations and general information about the industry" href="https://gamedev.city/t/industry">industry</a>
      </span>
        <a href="https://gamedev.city/domains/riotgames.com">riotgames.com</a></p><div>
        <p><a href="https://gamedev.city/~ironcutter24"><img srcset="https://gamedev.city/avatars/ironcutter24-16.png 1x, https://gamedev.city/avatars/ironcutter24-32.png 2x" alt="ironcutter24 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ironcutter24-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ironcutter24">ironcutter24</a>

        <span title="2025-01-19 02:18:09 -0600">12 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_5drqoa">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.riotgames.com%2Fen%2Fnews%2Ftech-blog-cpu-usage">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.riotgames.com%2Fen%2Fnews%2Ftech-blog-cpu-usage">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.riotgames.com%2Fen%2Fnews%2Ftech-blog-cpu-usage">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/5drqoa/riot_tech_blog_improving_performance_by">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_3n89kw" data-shortid="3n89kw">
<div>
  <div>
      <p>8</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://bsky.app/profile/gamemakerstoolkit.com/post/3lfr7fg65dk24" rel="ugc noreferrer">Ludum Dare events cancelled for 2025, as host is struggling financially</a>
    </span>
      <a title="Let's support Mike and Ludum Dare!

https://www.patreon.com/c/mikekasprzak/about" href="https://gamedev.city/s/3n89kw/ludum_dare_events_cancelled_for_2025_as">☶</a>
      <span>
          <a title="something that's hosted on a social media platform" href="https://gamedev.city/t/social-media">social-media</a>
          <a title="anything related or using generative AI" href="https://gamedev.city/t/ai">ai</a>
          <a title="admin, operations and general information about the industry" href="https://gamedev.city/t/industry">industry</a>
      </span>
        <a href="https://gamedev.city/domains/bsky.app">bsky.app</a></p><div>
        <p><a href="https://gamedev.city/~ShadowMitia"><img srcset="https://gamedev.city/avatars/ShadowMitia-16.png 1x, https://gamedev.city/avatars/ShadowMitia-32.png 2x" alt="ShadowMitia avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ShadowMitia-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ShadowMitia">ShadowMitia</a>

        <span title="2025-01-15 13:27:13 -0600">15 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_3n89kw">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fbsky.app%2Fprofile%2Fgamemakerstoolkit.com%2Fpost%2F3lfr7fg65dk24">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fbsky.app%2Fprofile%2Fgamemakerstoolkit.com%2Fpost%2F3lfr7fg65dk24">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fbsky.app%2Fprofile%2Fgamemakerstoolkit.com%2Fpost%2F3lfr7fg65dk24">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/3n89kw/ludum_dare_events_cancelled_for_2025_as">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_fbh5aq" data-shortid="fbh5aq">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.patreon.com/posts/how-do-i-record-34759149" rel="ugc noreferrer">How does Kev record a .gif for this twitter thing?</a>
    </span>
      <span>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/patreon.com">patreon.com</a></p><div>
        <p><a href="https://gamedev.city/~taletronic"><img srcset="https://gamedev.city/avatars/taletronic-16.png 1x, https://gamedev.city/avatars/taletronic-32.png 2x" alt="taletronic avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/taletronic-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~taletronic">taletronic</a>

        <span title="2025-01-13 01:32:42 -0600">18 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_fbh5aq">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.patreon.com%2Fposts%2Fhow-do-i-record-34759149">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.patreon.com%2Fposts%2Fhow-do-i-record-34759149">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fhow-do-i-record-34759149">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/fbh5aq/how_does_kev_record_gif_for_this_twitter">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_la00m1" data-shortid="la00m1">
<div>
  <div>
      <p>6</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.youtube.com/watch?v=DYWTw19_8r4" rel="ugc noreferrer">Introducing Clay - High Performance UI Layout in C</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="you want to share a video or a link that contains a video " href="https://gamedev.city/t/video">video</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/youtube.com">youtube.com</a></p><div>
        <p><a href="https://gamedev.city/~slembcke"><img srcset="https://gamedev.city/avatars/slembcke-16.png 1x, https://gamedev.city/avatars/slembcke-32.png 2x" alt="slembcke avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/slembcke-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~slembcke">slembcke</a>

        <span title="2025-01-11 23:18:32 -0600">19 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_la00m1">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DDYWTw19_8r4">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DDYWTw19_8r4">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DDYWTw19_8r4">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/la00m1/introducing_clay_high_performance_ui">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_zquctz" data-shortid="zquctz">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://dd3d.dmitriysalnikov.ru/docs/1.4.5/index.html" rel="ugc noreferrer">Godot addon to draw debug lines in 2D and 3D</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="" href="https://gamedev.city/t/godot">godot</a>
      </span>
        <a href="https://gamedev.city/domains/dd3d.dmitriysalnikov.ru">dd3d.dmitriysalnikov.ru</a></p><div>
        <p><a href="https://gamedev.city/~grej"><img srcset="https://gamedev.city/avatars/grej-16.png 1x, https://gamedev.city/avatars/grej-32.png 2x" alt="grej avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/grej-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~grej">grej</a>

        <span title="2025-01-10 12:22:53 -0600">20 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_zquctz">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fdd3d.dmitriysalnikov.ru%2Fdocs%2F1.4.5%2Findex.html">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fdd3d.dmitriysalnikov.ru%2Fdocs%2F1.4.5%2Findex.html">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fdd3d.dmitriysalnikov.ru%2Fdocs%2F1.4.5%2Findex.html">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/zquctz/godot_addon_draw_debug_lines_2d_3d">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_3u7dkb" data-shortid="3u7dkb">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://racenis.github.io/tram-sdk/why.html" rel="ugc noreferrer">Tramway SDK: a Quake, GoldSrc or Source like engine/framework</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="you are sharing a game engine" href="https://gamedev.city/t/engine">engine</a>
      </span>
        <a href="https://gamedev.city/domains/racenis.github.io">racenis.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2025-01-07 19:57:29 -0600">23 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_3u7dkb">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fracenis.github.io%2Ftram-sdk%2Fwhy.html">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fracenis.github.io%2Ftram-sdk%2Fwhy.html">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fracenis.github.io%2Ftram-sdk%2Fwhy.html">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/3u7dkb/tramway_sdk_quake_goldsrc_source_like">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_m7i7vc" data-shortid="m7i7vc">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://blurbusters.com/blur-busters-open-source-display-initiative-refresh-cycle-shaders/" rel="ugc noreferrer">Blur Busters Open Source Display Initiative – Refresh Cycle Shaders - Blur Busters</a>
    </span>
      <span>
          <a title="2D, 3D and everything in between" href="https://gamedev.city/t/art">art</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/blurbusters.com">blurbusters.com</a></p><div>
        <p><a href="https://gamedev.city/~berru"><img srcset="https://gamedev.city/avatars/berru-16.png 1x, https://gamedev.city/avatars/berru-32.png 2x" alt="berru avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/berru-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~berru">berru</a>

        <span title="2025-01-05 03:02:20 -0600">26 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_m7i7vc">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fblurbusters.com%2Fblur-busters-open-source-display-initiative-refresh-cycle-shaders%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fblurbusters.com%2Fblur-busters-open-source-display-initiative-refresh-cycle-shaders%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fblurbusters.com%2Fblur-busters-open-source-display-initiative-refresh-cycle-shaders%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/m7i7vc/blur_busters_open_source_display">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_7ajlzt" data-shortid="7ajlzt">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://github.com/s-macke/VoxelSpace" rel="ugc noreferrer">VoxelSpace: Terrain rendering algorithm in less than 20 lines of code</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="articles or resources related to the history and development of the industry" href="https://gamedev.city/t/game-history">game-history</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/github.com">github.com</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2025-01-04 13:50:56 -0600">26 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_7ajlzt">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Fs-macke%2FVoxelSpace">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fgithub.com%2Fs-macke%2FVoxelSpace">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fgithub.com%2Fs-macke%2FVoxelSpace">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/7ajlzt/voxelspace_terrain_rendering_algorithm">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_vbpmbd" data-shortid="vbpmbd">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://realfix.substack.com/p/handmade-engine-survey-results" rel="ugc noreferrer">Handmade Engine Survey Results</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="you are sharing a game engine" href="https://gamedev.city/t/engine">engine</a>
      </span>
        <a href="https://gamedev.city/domains/realfix.substack.com">realfix.substack.com</a></p><div>
        <p><a href="https://gamedev.city/~lessa"><img srcset="https://gamedev.city/avatars/lessa-16.png 1x, https://gamedev.city/avatars/lessa-32.png 2x" alt="lessa avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/lessa-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~lessa">lessa</a>

        <span title="2025-01-02 03:06:20 -0600">29 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_vbpmbd">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Frealfix.substack.com%2Fp%2Fhandmade-engine-survey-results">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Frealfix.substack.com%2Fp%2Fhandmade-engine-survey-results">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Frealfix.substack.com%2Fp%2Fhandmade-engine-survey-results">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/vbpmbd/handmade_engine_survey_results">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_dd3wcg" data-shortid="dd3wcg">
<div>
  <div>
      <p>1</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://sevencrane.itch.io/vapor-trails/devlog/432175/ghost-ai-for-andromeda" rel="ugc noreferrer">Ghost AI for Andromeda</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/sevencrane.itch.io">sevencrane.itch.io</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-31 17:37:36 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_dd3wcg">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fsevencrane.itch.io%2Fvapor-trails%2Fdevlog%2F432175%2Fghost-ai-for-andromeda">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fsevencrane.itch.io%2Fvapor-trails%2Fdevlog%2F432175%2Fghost-ai-for-andromeda">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fsevencrane.itch.io%2Fvapor-trails%2Fdevlog%2F432175%2Fghost-ai-for-andromeda">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/dd3wcg/ghost_ai_for_andromeda">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_p5gzzh" data-shortid="p5gzzh">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://audiomass.co/" rel="ugc noreferrer">AudioMass: In-browser audio editor similar to Audacity</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="sound and music" href="https://gamedev.city/t/audio">audio</a>
      </span>
        <a href="https://gamedev.city/domains/audiomass.co">audiomass.co</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-29 12:50:27 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_p5gzzh">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Faudiomass.co%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Faudiomass.co%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Faudiomass.co%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/p5gzzh/audiomass_browser_audio_editor_similar">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_4xul27" data-shortid="4xul27">
<div>
  <div>
      <p>3</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://allusion-app.github.io/" rel="ugc noreferrer">Allusion - Visual Library Manager</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="art galleries or pieces that are exceptionally good or interesting - do not post your own art" href="https://gamedev.city/t/art-reference">art-reference</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/allusion-app.github.io">allusion-app.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-23 15:12:48 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_4xul27">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fallusion-app.github.io%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fallusion-app.github.io%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fallusion-app.github.io%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/4xul27/allusion_visual_library_manager">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_oelkvo" data-shortid="oelkvo">
<div>
  <div>
      <p>9</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://ldtk.io/" rel="ugc noreferrer">LDtk: A modern 2D level editor from the director of Dead Cells</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/ldtk.io">ldtk.io</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-22 08:26:42 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_oelkvo">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fldtk.io%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fldtk.io%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fldtk.io%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/oelkvo/ldtk_modern_2d_level_editor_from_director">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_mbiw21" data-shortid="mbiw21">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://youtu.be/69Ukg2BqIk0" rel="ugc noreferrer">how does an indie game get made?</a>
    </span>
      <span>
          <a title="you want to share a video or a link that contains a video " href="https://gamedev.city/t/video">video</a>
          <a title="analysis, theories and studies related to a specific game or group of games" href="https://gamedev.city/t/game-analysis">game-analysis</a>
      </span>
        <a href="https://gamedev.city/domains/youtu.be">youtu.be</a></p><div>
        <p><a href="https://gamedev.city/~cuca"><img srcset="https://gamedev.city/avatars/cuca-16.png 1x, https://gamedev.city/avatars/cuca-32.png 2x" alt="cuca avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/cuca-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~cuca">cuca</a>

        <span title="2024-12-22 16:10:36 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_mbiw21">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fyoutu.be%2F69Ukg2BqIk0">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fyoutu.be%2F69Ukg2BqIk0">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fyoutu.be%2F69Ukg2BqIk0">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/mbiw21/how_does_indie_game_get_made">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_pytqxu" data-shortid="pytqxu">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://trenchbroom.github.io/" rel="ugc noreferrer">TrenchBroom: FOSS level editor for the Quake-engine (Can be used in Unity, Godot, Unreal, etc)</a>
    </span>
      <span>
          <a title="2D, 3D and everything in between" href="https://gamedev.city/t/art">art</a>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/trenchbroom.github.io">trenchbroom.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-14 02:33:06 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_pytqxu">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Ftrenchbroom.github.io%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Ftrenchbroom.github.io%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Ftrenchbroom.github.io%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/pytqxu/trenchbroom_foss_level_editor_for_quake">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_so96zy" data-shortid="so96zy">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://indiegames101.com/blog/2023-10-20-from-game-idea-to-game-concept/" rel="ugc noreferrer">From game idea to game concept</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
      </span>
        <a href="https://gamedev.city/domains/indiegames101.com">indiegames101.com</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-12 22:17:29 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_so96zy">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Findiegames101.com%2Fblog%2F2023-10-20-from-game-idea-to-game-concept%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Findiegames101.com%2Fblog%2F2023-10-20-from-game-idea-to-game-concept%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Findiegames101.com%2Fblog%2F2023-10-20-from-game-idea-to-game-concept%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/so96zy/from_game_idea_game_concept">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_0gmxv5" data-shortid="0gmxv5">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://mikejsavage.co.uk/geometry-clipmaps/" rel="ugc noreferrer">Geometry clipmaps: simple terrain rendering with level of detail</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/mikejsavage.co.uk">mikejsavage.co.uk</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-12 11:15:42 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_0gmxv5">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fmikejsavage.co.uk%2Fgeometry-clipmaps%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fmikejsavage.co.uk%2Fgeometry-clipmaps%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fmikejsavage.co.uk%2Fgeometry-clipmaps%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/0gmxv5/geometry_clipmaps_simple_terrain">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_kiazeh" data-shortid="kiazeh">
<div>
  <div>
      <p>8</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://lostgarden.com/2018/01/24/cozy-games/comment-page-1/" rel="ugc noreferrer">What is a ‘Cozy’ game?</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
          <a title="analysis, theories and studies related to a specific game or group of games" href="https://gamedev.city/t/game-analysis">game-analysis</a>
      </span>
        <a href="https://gamedev.city/domains/lostgarden.com">lostgarden.com</a></p><div>
        <p><a href="https://gamedev.city/~isadora"><img srcset="https://gamedev.city/avatars/isadora-16.png 1x, https://gamedev.city/avatars/isadora-32.png 2x" alt="isadora avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/isadora-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~isadora">isadora</a>

        <span title="2024-12-11 15:32:19 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_kiazeh">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Flostgarden.com%2F2018%2F01%2F24%2Fcozy-games%2Fcomment-page-1%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Flostgarden.com%2F2018%2F01%2F24%2Fcozy-games%2Fcomment-page-1%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Flostgarden.com%2F2018%2F01%2F24%2Fcozy-games%2Fcomment-page-1%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/kiazeh/what_is_cozy_game">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_wkxfjj" data-shortid="wkxfjj">
<div>
  <div>
      <p>6</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://thebookofshaders.com/" rel="ugc noreferrer">The Book of Shaders</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/thebookofshaders.com">thebookofshaders.com</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-11 13:20:48 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_wkxfjj">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fthebookofshaders.com%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fthebookofshaders.com%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fthebookofshaders.com%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/wkxfjj/book_shaders">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_wtkjfm" data-shortid="wtkjfm">
<div>
  <div>
      <p>3</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.charliecleveland.com/ugliness-needed/" rel="ugc noreferrer">Ugliness Needed</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
      </span>
        <a href="https://gamedev.city/domains/charliecleveland.com">charliecleveland.com</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-10 15:00:47 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_wtkjfm">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.charliecleveland.com%2Fugliness-needed%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.charliecleveland.com%2Fugliness-needed%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.charliecleveland.com%2Fugliness-needed%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/wtkjfm/ugliness_needed">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

</ol>



<div>

    <p><a href="https://gamedev.city/page/2">Page 2 &gt;&gt;</a>
</p></div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hydro: Distributed Programming Framework for Rust (202 pts)]]></title>
            <link>https://hydro.run/docs/hydro/</link>
            <guid>42885087</guid>
            <pubDate>Fri, 31 Jan 2025 06:11:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hydro.run/docs/hydro/">https://hydro.run/docs/hydro/</a>, See on <a href="https://news.ycombinator.com/item?id=42885087">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><div><article><div><header></header>
<p>Hydro is a high-level distributed programming framework for Rust. Hydro can help you quickly write scalable distributed services that are correct by construction. Much like Rust helps with memory safety, Hydro helps with <a href="https://hydro.run/docs/hydro/correctness"><strong>distributed safety</strong></a>. Hydro also makes it easy to get started by running your distributed programs in either testing or deployment modes.</p>
<p>Hydro is a distributed dataflow language, powered by the high-performance single-threaded <a href="https://hydro.run/docs/dfir/">DFIR runtime</a>. Unlike traditional architectures such as actors or RPCs, Hydro offers <em>choreographic</em> APIs, where expressions and functions can describe computation that takes place across many locations. It also integrates with <a href="https://hydro.run/docs/deploy/">Hydro Deploy</a> to make it easy to deploy and run distributed Hydro programs either locally or in the cloud.</p>
<p>Hydro uses a two-stage compilation approach. Hydro programs are standard Rust programs, which first run on the developer's laptop to generate a <em>deployment plan</em>. This plan is then compiled to DFIR to generate individual binaries for each machine in the distributed system (enabling zero-overhead abstractions), which are then deployed to the cloud using the generated plan along with specifications of cloud resources.</p>
<p>Hydro has been used to write a variety of high-performance distributed systems, including implementations of classic distributed protocols such as two-phase commit and Paxos. Work is ongoing to develop a distributed systems standard library that will offer these protocols and more as reusable components.</p>
<div><p><span><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</p><p>The docs for Hydro are still a work in progress. If you have any questions or run into bugs, please file an issue on the <a href="https://github.com/hydro-project/hydro" target="_blank" rel="noopener noreferrer">Hydro GitHub repository</a>.</p></div></div></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Release Notes for Ghostty 1.1.0 (131 pts)]]></title>
            <link>https://ghostty.org/docs/install/release-notes/1-1-0</link>
            <guid>42884930</guid>
            <pubDate>Fri, 31 Jan 2025 05:24:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ghostty.org/docs/install/release-notes/1-1-0">https://ghostty.org/docs/install/release-notes/1-1-0</a>, See on <a href="https://news.ycombinator.com/item?id=42884930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Ghostty 1.1.0 features <strong>1 month of work</strong> with changes from
<strong>84 contributors</strong> over <strong>564 commits.</strong> The focus of this release
remains on critical bug fixes and quality of life improvements based
on feedback from the initial 1.0 release.</p>

<ul>
<li><a href="https://github.com/ghostty-org/ghostty/security/advisories/GHSA-98wc-794w-gjx3">GHSA-98wc-794w-gjx3</a>.
Fixed an issue where Ghostty would leak some file descriptors to the
running shell or command.</li>
</ul>


<p>PR:
<a href="https://github.com/ghostty-org/ghostty/pull/4630">#4630</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/4723">#4723</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/5124">#5124</a></p>
<p>On Linux in particular, window decorations have a wide variety of
styles and behaviors. Ghostty's previous behavior was to always use
client-side decorations (CSD), which made Ghostty look and feel too
much like a "GNOME" application. In particular, Ghostty looked out of
place on popular desktop environments like KDE Plasma.</p>
<p>Ghostty 1.1 on Linux now supports server-side decorations (SSD) for
compositors that support it. This allows Ghostty to look and feel more
like a native application on a wider variety of desktop environments.
This can be disabled if you prefer CSD or no decorations at all.</p>
<p><a href="https://ghostty.org/images/1-1-0/csd.png" target="_blank"><img src="https://ghostty.org/images/1-1-0/csd.png" width="360"></a><a href="https://ghostty.org/images/1-1-0/ssd.png" target="_blank"><img src="https://ghostty.org/images/1-1-0/ssd.png" width="360"></a></p>
<p>(Left/Top: Old Client-Side Decorations, Right/Bottom: New Server-Side Decorations)</p>
<p>The <code>window-decoration</code> configuration option now has a new value <code>auto</code>
which will use SSD if the compositor supports it and prefers it. A value
of <code>server</code> will force SSD (if available). A value of <code>client</code> will force
client-side decorations. And a value of <code>none</code> will disable decorations
entirely.</p>
<p>SSD is only supported on Wayland. Ghostty uses the
<a href="https://wayland.app/protocols/kde-server-decoration">KDE Server Decoration</a>
protocol. Despite the name, this protocol is supported on almost every
major Wayland compositor, not just KDE. For X11, we could not find a
well-supported protocol for SSD, so we continue to use CSD.</p>
<p>Future versions of Ghostty will continue to improve the native look and
feel across different desktop environments in Linux to the best of our
ability and protocol availability. For example, we're looking into native
menu bars, currently.</p>
<blockquote><p>Future versions of Ghostty will remove the <code>gtk-adwaita</code> option
and force a dependency on libadwaita. This is relevant to this change
because we found the vast majority of users who wanted SSD were using
<code>gtk-adwaita = false</code> to achieve this (which only worked in some cases).
With the new SSD support, this workaround is no longer necessary.
See <a href="#gtk:-forcing-a-dependency-on-libadwaita">the dedication section</a> for more
details.</p></blockquote>

<p>PR:
<a href="https://github.com/ghostty-org/ghostty/pull/3567">#3567</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/4332">#4332</a>,
<a href="https://github.com/ghostty-org/ghostty/issues/4539">#4539</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/4854">#4854</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/4933">#4933</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/4999">#4999</a></p>
<p>For both macOS and Linux, we've tested IME with the following
paradigms: CJK (Chinese, Japanese, Korean), dead keys (such as
accented characters), emoji, Unicode hex input, and more and
have massively improved the reliability and consistency of IME
input.</p>
<p>On Linux, we've tested both <code>fcitx</code> and <code>ibus</code> under both X11 and
Wayland. We also tested multiple versions of each (in particular
versions that are common in LTS distributions). We found a bug in
ibus 1.5.29 that caused deadkey input to become "stuck" and worked
around it.</p>
<p>On macOS, we've ensured in particular that the AquaSKK and macSKK
Japanese language input methods work out of the box, although we've
also tested other IMEs and found them to work well as well.</p>

<p>PR:
<a href="https://github.com/ghostty-org/ghostty/pull/4328">#4328</a></p>
<p>Keybinds support a new <code>performable:</code> prefix. This prefix indicates that
the keybind should only consume the input if the action is performed.</p>
<p>For example, the keybind below will only consume <code>ctrl+c</code> if there is
text able to be copied. Otherwise, <code>ctrl+c</code> will be passed to the shell
(typically causing an interrupt signal).</p>
<pre><code>keybind = performable:ctrl+c=copy_to_clipboard
</code></pre>
<blockquote><p>Not all actions support <code>performable:</code>. Namely, many actions are always
performed (e.g. <code>text</code>, <code>new_tab</code>, etc.). The performable prefix only
applies to actions that have a meaningful "perform" state.</p></blockquote>

<p>PR:
<a href="https://github.com/ghostty-org/ghostty/pull/4913">#4913</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/5401">#5401</a></p>
<p>Alpha blending is the process of determining the result when a semi-transparent
foreground color is placed in front of a background color. This affects the
edges of text, and any images (displayed with Kitty Graphic Protocol) which
have transparency in them.</p>
<p>Before, this was performed by blending colors in the sRGB color space, which
causes darkening around the edges of text when the foreground and background
colors are different highly saturated colors. With Ghostty 1.1 on macOS, alpha
blending is now performed in the P3 color space by default, which reduces the
darkening issue thanks to the wider gamut and matches the appearance of native
macOS applications like Terminal.app and TextEdit.</p>
<p>Additionally, a configuration, <code>alpha-blending</code>, has been added to control this.
The default is <code>native</code>, which has been described, but two more options are
available:</p>
<ul>
<li><code>linear</code> performs blending in a linear color space, which is technically
correct but has downsides like dark text seeming too thin and light text
seeming too thick.</li>
<li><code>linear-corrected</code> is like <code>linear</code> but applies a correction step to text
which makes it appear extremely close to <code>native</code>, but without <em>any</em> darkening
problems.</li>
</ul>
<p>Below you can compare (from left to right) the old blending, the new <code>native</code>
blending, <code>linear</code> blending, and <code>linear-corrected</code> blending. You may have to
zoom in to see the differences correctly.</p>
<p><img src="https://ghostty.org/images/1-1-0/srgb_blending.png" width="180"><img src="https://ghostty.org/images/1-1-0/p3_blending.png" width="180"><img src="https://ghostty.org/images/1-1-0/linear_blending.png" width="180"><img src="https://ghostty.org/images/1-1-0/linear-corrected_blending.png" width="180"></p>
<p>This is currently only available on macOS, but work is underway which should
bring it to Linux as well in the future.</p>

<p>PR:
<a href="https://github.com/ghostty-org/ghostty/pull/4049">#4049</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/4501">#4501</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/4999">#4999</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/5361">#5361</a></p>
<p>The quick terminal now works with native fullscreen windows,
space changes while the quick terminal is open, IME widgets, left/right
docks, and more.</p>
<p>A new configuration <code>quick-terminal-space-behavior</code> has been added to
control how the quick terminal reacts to changing macOS spaces while it
is open. The default behavior is to follow the active space (<code>move</code>).
You can also set it to <code>remain</code> to stay on the space it was opened on.</p>

<p><a href="https://github.com/ghostty-org/ghostty/milestone/3?closed=1">Full list of closed issues on GitHub</a>.</p>
<p>In each section, we try to sort improvements before bug fixes.</p>
<ul>
<li>Add the new <code>performable:</code> prefix to keybindings to only consume
the input if the action is performed. See
<a href="#%22performable%22-keybindings">"Performable" Keybindings</a>.
<a href="https://github.com/ghostty-org/ghostty/pull/4328">#4328</a></li>
<li><code>shell-integration-features</code> now sets the proper environment variables
even when <code>shell-integration</code> is disabled. This is useful for environments
that manually source shell integration.
<a href="https://github.com/ghostty-org/ghostty/pull/5046">#5046</a></li>
<li>A new keybinding action <code>copy_url_to_clipboard</code> is available to copy
the URL (if any) under the cursor to the clipboard.
<a href="https://github.com/ghostty-org/ghostty/pull/4633">#4633</a></li>
<li>A new keybinding action <code>close_tab</code> can be used to close the tab and
all splits within the tab. This works on both macOS and GTK builds.
<a href="https://github.com/ghostty-org/ghostty/pull/4331">#4331</a></li>
<li>Update default <code>ctrl+shift+j</code>/<code>ctrl+shift+alt+j</code> keybindings to capture full
screen contents.
<a href="https://github.com/ghostty-org/ghostty/pull/5285">#5285</a></li>
<li>IPv6 URLs are now automatically turned into hyperlinks.
<a href="https://github.com/ghostty-org/ghostty/issues/4743">#4743</a></li>
<li>Filepaths without an explicit <code>file://</code> protocol can now be clicked
like any other hyperlink.
<a href="https://github.com/ghostty-org/ghostty/issues/4713">#4713</a></li>
<li>New configuration <code>split-divider-color</code> to explicitly set the divider
color for splits. If this is not set, the previous default behavior of
automatically determining the color based on your terminal background
color is used.
<a href="https://github.com/ghostty-org/ghostty/issues/4326">#4236</a></li>
<li>The <code>palette</code> configuration option now allows binary, octal, and hexadecimal
keys.
<a href="https://github.com/ghostty-org/ghostty/issues/4298">#4298</a></li>
<li><code>goto_split</code> keybind parameter <code>top</code> and <code>bottom</code> have been renamed to
<code>up</code> and <code>down</code>, respectively. The old names are still supported for
backwards compatibility.
<a href="https://github.com/ghostty-org/ghostty/pull/3427">#3427</a></li>
<li>bash: use <code>\w</code> instead of <code>$PWD</code> for abbreviated titles.
<a href="https://github.com/ghostty-org/ghostty/pull/4656">#4656</a></li>
<li>bash: drop dependency on <code>sed</code>, which significantly reduces
per-prompt overhead
<a href="https://github.com/ghostty-org/ghostty/pull/5141">#5141</a>,
<a href="https://github.com/ghostty-org/ghostty/pull/5142">#5142</a></li>
<li>fish: fix sudo integration
<a href="https://github.com/ghostty-org/ghostty/pull/5276">#5276</a></li>
<li>Fix scenario where CPU would spin at 100% if <code>wait-after-command</code> was enabled.
<a href="https://github.com/ghostty-org/ghostty/pull/4884">#4884</a></li>
<li>Fix a possible memory corruption race condition when the renderer grid
size and terminal grid size mismatched.
<a href="https://github.com/ghostty-org/ghostty/pull/5265">#5265</a></li>
<li>Triple-click-and-drag now works when the triple click starts from a
blank line.
<a href="https://github.com/ghostty-org/ghostty/pull/5068">#5068</a></li>
<li><code>super+triple-click</code> properly selects command output if the command line
wrapped.
<a href="https://github.com/ghostty-org/ghostty/issues/5373">#5373</a></li>
<li>vt: Fix incorrect alpha blending for Kitty image protocol.
<a href="https://github.com/ghostty-org/ghostty/pull/5189">#5189</a></li>
<li>vt: More robust and correct handling of mixed semicolon and colon
usage in SGR sequences. Practically, fixes some styling within the
Kakoune editor.
<a href="https://github.com/ghostty-org/ghostty/pull/5022">#5022</a></li>
<li>The <code>cursor-invert-fg-bg</code> option now works well with the invert VT sequence.
<a href="https://github.com/ghostty-org/ghostty/issues/4777">#4777</a></li>
<li>Remove <code>VTE_VERSION</code> from environment prior to executing shell. This
fixes issues where VTE's shell integration would mistakingly think Ghostty
was libvte-based.
<a href="https://github.com/ghostty-org/ghostty/issues/4710">#4710</a></li>
<li>Fix an issue that didn't allow an initial window size smaller than
<code>640x480</code>
<a href="https://github.com/ghostty-org/ghostty/issues/4688">#4688</a></li>
<li>vt: ConEmu OSC <code>9;4</code> parsing better matches ConEmu logic, fixing an
issue with some versions of systemd.
<a href="https://github.com/ghostty-org/ghostty/issues/4727">#4727</a></li>
<li>The <code>unbind</code> keybind action now also unbinds any matching physical
mapping.
<a href="https://github.com/ghostty-org/ghostty/issues/4703">#4703</a></li>
<li>Non-existent <code>config-file</code> now properly shows an error when <code>theme</code>
is also set.
<a href="https://github.com/ghostty-org/ghostty/issues/4509">#4509</a></li>
<li>vt: ConEmu OSC <code>9;1</code>, <code>9;2</code>, <code>9;3</code>, <code>9;5</code> are now parsed and ignored so they
don't conflict with OSC 9 desktop notifications.
<a href="https://github.com/ghostty-org/ghostty/issues/4644">#4644</a>,
<a href="https://github.com/ghostty-org/ghostty/issues/4327">#4327</a>,
<a href="https://github.com/ghostty-org/ghostty/issues/4948">#4948</a>,
<a href="https://github.com/ghostty-org/ghostty/issues/4447">#4447</a></li>
<li>Inspector: Memory values now specify units rather than raw bytes
<a href="https://github.com/ghostty-org/ghostty/issues/4549">#4549</a></li>
<li>Fix control sequence (e.g. <code>ctrl+c</code>) encoding in legacy mode for
various keyboard layouts such as Russian.
<a href="https://github.com/ghostty-org/ghostty/issues/4518">#4518</a></li>
<li>vt: Kitty graphics protocol temporary files must be named according to
the specification.
<a href="https://github.com/ghostty-org/ghostty/issues/4451">#4451</a></li>
<li>The default file limit (<code>RLIMIT_NOFILE</code>) is restored for the executed
shell or command.
<a href="https://github.com/ghostty-org/ghostty/issues/4241">#4241</a></li>
<li>Multiple <code>font-feature</code> values can be comma-separated. Previously,
you had to repeat <code>font-feature</code> multiple times. This is still supported.
<a href="https://github.com/ghostty-org/ghostty/issues/3128">#3128</a></li>
<li>vt: CSI intermediate bytes are now validated for all supported CSI
sequences.
<a href="https://github.com/ghostty-org/ghostty/issues/3122">#3122</a></li>
<li>Selected text no longer remains after a <code>clear_screen</code> keybinding.
<a href="https://github.com/ghostty-org/ghostty/issues/3414">#3414</a></li>
<li>Tilde (<code>~</code>) in filepaths now expands to the user's home directory
in path-typed configuration values.
<a href="https://github.com/ghostty-org/ghostty/issues/3328">#3328</a></li>
<li>Cache data now respects <code>XDG_CACHE_HOME</code>.
<a href="https://github.com/ghostty-org/ghostty/pull/3458">#3458</a></li>
<li>Default configuration file will now be created even if the parent
directories do not exist.
<a href="https://github.com/ghostty-org/ghostty/pull/4295">#4295</a></li>
<li>Inspector: Font size now shows fractional values.
<a href="https://github.com/ghostty-org/ghostty/pull/4371">#4371</a></li>
</ul>

<ul>
<li>macOS: Consistent and correct alpha blending for correct colors.
Options for matching Apple-style alpha blending as well as an
experimental "linear" blending mode that we think produces better
results for certain foreground/background color combinations.
See <a href="#macos-alpha-blending-improvements">macOS Alpha Blending Improvements</a>.
<a href="https://github.com/ghostty-org/ghostty/pull/4913">#4913</a></li>
<li>macOS: New config option <code>quick-terminal-space-behavior</code> to configure
how the quick terminal reacts to changing macOS spaces while it is open.
The default behavior is to follow the active space (remain open).
<a href="https://github.com/ghostty-org/ghostty/pull/4049">#4049</a></li>
<li>macOS: Selection clipboard is now supported. The <code>copy-on-select</code> option
now defaults to true for macOS. A new "Paste Selection" menu item is
available on macOS. This behavior matches Terminal.app.
<a href="https://github.com/ghostty-org/ghostty/pull/4733">#4733</a></li>
<li>macOS: A very short delay has been introduced for the default window
title to prevent a FOUC ("flash of unknown content") for new surfaces.
<a href="https://github.com/ghostty-org/ghostty/pull/4799">#4799</a></li>
<li>macOS: <code>font-thicken</code> now accepts an optional numeric value to adjust
the thickening factor.
<a href="https://github.com/ghostty-org/ghostty/issues/4531">#4531</a></li>
<li>macOS: Explicit Ghostty keybindings now take priority over
system keybindings (e.g. <code>cmd+h</code> can now be bound).
<a href="https://github.com/ghostty-org/ghostty/issues/4591">#4591</a></li>
<li>macOS: Non-boolean <code>font-feature</code> values such as <code>cv02 = 2</code> are now
supported.
<a href="https://github.com/ghostty-org/ghostty/issues/3128">#3128</a></li>
<li>macOS: Cache data now uses macOS system APIs to store data in the
OS-configured cache directory (typically <code>~/Library/Caches</code>).
<a href="https://github.com/ghostty-org/ghostty/pull/3458">#3458</a></li>
<li>macOS: Autohide the dock if the quick terminal would overlap with it.
<a href="https://github.com/ghostty-org/ghostty/pull/5361">#5361</a></li>
<li>macOS: Fix zombie processes leaking when the shell or command exits
before the containing UI is closed.
<a href="https://github.com/ghostty-org/ghostty/pull/4554">#4554</a></li>
<li>macOS: Hyperlinks in the top-left no loner appear hovered when
command is held anywhere outside the window.
<a href="https://github.com/ghostty-org/ghostty/pull/5252">#5252</a></li>
<li>macOS: When <code>macos-titlebar-style = hidden</code>, the titlebar area
can no longer be used to drag the window. You must now use option+drag
(standard macOS bindings) in the resize area.
<a href="https://github.com/ghostty-org/ghostty/pull/2523">#2523</a></li>
<li>macOS: Closing a tab with Stage Manager enabled no longer causes
Ghostty to lose focus.
<a href="https://github.com/ghostty-org/ghostty/pull/5108">#5108</a></li>
<li>macOS: Fix "background flash" for new and resized terminals.
<a href="https://github.com/ghostty-org/ghostty/pull/5083">#5083</a></li>
<li>macOS: Filepaths are shell escaped when files, URLs, are pasted.
<a href="https://github.com/ghostty-org/ghostty/pull/5036">#5036</a></li>
<li>macOS: Quick terminal no longer covers IME widget.
<a href="https://github.com/ghostty-org/ghostty/pull/4999">#4999</a></li>
<li>macOS: Text can now be dragged onto the terminal.
<a href="https://github.com/ghostty-org/ghostty/pull/4932">#4932</a></li>
<li>macOS: IME window position is now correct when <code>window-padding</code> is set.
<a href="https://github.com/ghostty-org/ghostty/pull/4933">#4933</a></li>
<li>macOS: Pasting multiple files now separates their path by a space
instead of a newline.
<a href="https://github.com/ghostty-org/ghostty/pull/4956">#4956</a></li>
<li>macOS: <code>toggle_visibility</code> no longer separates tabs from their parent
window.
<a href="https://github.com/ghostty-org/ghostty/pull/4329">#4329</a></li>
<li>macOS: Control-characters such as <code>ctrl+h</code> now work as expected for
input method editors (IME).
<a href="https://github.com/ghostty-org/ghostty/pull/4854">#4854</a></li>
<li>macOS: Fix crash when <code>window-step-resize</code> was used in conjunction with
an overly large initial window size.
<a href="https://github.com/ghostty-org/ghostty/pull/4801">#4801</a></li>
<li>macOS: Quick terminal now properly overlays native fullscreen windows.
<a href="https://github.com/ghostty-org/ghostty/pull/4049">#4049</a></li>
<li>macOS: Add strings for more macOS system permission requests that can
be triggered by child processes (e.g. Bluetooh access).
<a href="https://github.com/ghostty-org/ghostty/issues/4668">#4668</a></li>
<li>macOS: <code>new_tab</code> keybinding without any windows creates a new window.
<a href="https://github.com/ghostty-org/ghostty/issues/4691">#4691</a></li>
<li>macOS: Fix a retain cycle that prevented the <code>NSWindow</code> from being
released when closed.
<a href="https://github.com/ghostty-org/ghostty/issues/4689">#4689</a></li>
<li>macOS: Preedit text no longer disappears when a modifier key is pressed.
<a href="https://github.com/ghostty-org/ghostty/issues/4634">#4634</a></li>
<li>macOS: AquaSKK/macSKK Japanese language input methods now work.
<a href="https://github.com/ghostty-org/ghostty/issues/4539">#4539</a></li>
<li>macOS: Quick terminal now appears in the correct location with certain
multi-monitor configurations.
<a href="https://github.com/ghostty-org/ghostty/issues/4501">#4501</a></li>
<li>macOS: <code>command+&lt;key&gt;</code> release events are now properly encoded for
the Kitty keyboard protocol.
<a href="https://github.com/ghostty-org/ghostty/issues/4591">#4591</a></li>
<li>macOS: <code>cmd+period</code> and other keybinds can now be bound.
<a href="https://github.com/ghostty-org/ghostty/issues/4591">#4591</a></li>
<li>macOS: Window borders with dark mode now match macOS styling.
<a href="https://github.com/ghostty-org/ghostty/issues/4308">#4308</a></li>
<li>macOS: Auto-update no longer defaults to on. On first run, Ghostty will
ask for your permission to check for updates. The <code>auto-update</code> option
can still be used to configure this.
<a href="https://github.com/ghostty-org/ghostty/issues/4433">#4433</a></li>
<li>macOS: New configurations <code>window-position-x</code> and <code>window-position-y</code>
can be used to set the initial window position.
<a href="https://github.com/ghostty-org/ghostty/issues/3929">#3929</a></li>
<li>macOS: <code>macos-titlebar-style = hidden</code> restores properly after exiting
non-native fullscreen.
<a href="https://github.com/ghostty-org/ghostty/issues/3535">#3535</a></li>
</ul>

<ul>
<li>
<p>GTK: Support for server-side decorations (SSD) has been added.
This utilizes the existing <code>window-decoration</code> configuration option.
The new value is <code>auto</code> which will use SSD if the compositor supports
it and preferes it. A value of <code>server</code> will force SSD (if available).
A value of <code>client</code> will force client-side decorations. And a value
of <code>none</code> will disable decorations entirely.
See <a href="#server-side-decorations-(ssd)-on-linux">Server Side Decorations (SSD) on Linux</a>.
<a href="https://github.com/ghostty-org/ghostty/pull/4630">#4630</a></p>
</li>
<li>
<p>GTK(X11): <code>background-blur</code> is now supported for any window manager
that respects the <code>_KDE_NET_WM_BLUR_BEHIND_REGION</code> atom.
<a href="https://github.com/ghostty-org/ghostty/issues/4403">#4403</a></p>
</li>
<li>
<p>GTK(Wayland): <code>background-blur</code> is now supported for any compositor
supporting the <code>org_kde_kwin_blur_manager</code> protocol (namely, KDE).
<a href="https://github.com/ghostty-org/ghostty/issues/4403">#4403</a></p>
</li>
<li>
<p>GTK: Add new configuration <code>app-notifications</code> to control what toasts
are shown.
<a href="https://github.com/ghostty-org/ghostty/pull/4460">#4460</a></p>
</li>
<li>
<p>GTK: Multiple <code>custom-shader</code> values are now supported (matching macOS)
<a href="https://github.com/ghostty-org/ghostty/pull/5037">#5037</a></p>
</li>
<li>
<p>GTK: A new configuration option <code>gtk-titlebar-hide-when-maximized</code>
(default false) added to hide the titlebar when the window is maximized
(not fullscreen).
<a href="https://github.com/ghostty-org/ghostty/pull/3381">#3381</a></p>
</li>
<li>
<p>GTK: Ghostty can now be pinned in the dock or task manager for
supported desktop environments.
<a href="https://github.com/ghostty-org/ghostty/pull/4930">#4930</a></p>
</li>
<li>
<p>GTK: Dropping files and selected text now works and matches
macOS.
<a href="https://github.com/ghostty-org/ghostty/pull/4211">#4211</a></p>
</li>
<li>
<p>"Open in Ghostty" shortcut for Nautilus is now available
<a href="https://github.com/ghostty-org/ghostty/pull/4816">#4816</a></p>
</li>
<li>
<p>GTK: Fix adwaita tab bars appearing above the titlebar in some
older versions of libadwaita.
<a href="https://github.com/ghostty-org/ghostty/issues/5410">#5410</a></p>
</li>
<li>
<p>GTK: Fix slow startup times when XDG desktop portal is not available.
<a href="https://github.com/ghostty-org/ghostty/pull/5064">#5064</a></p>
</li>
<li>
<p>GTK: <code>fcitx</code> and <code>ibus</code> under both X11 and Wayland work.
<a href="https://github.com/ghostty-org/ghostty/pull/4332">#4332</a></p>
</li>
<li>
<p>GTK: Workaround bug in <code>ibus</code> 1.5.29 that caused deadkey input to
become "stuck."
<a href="https://github.com/ghostty-org/ghostty/pull/3567">#3567</a></p>
</li>
<li>
<p>GTK(X11): When a new window is initially maximized, the <code>_NET_WM_STATE</code>
atom is properly set so the titlebar properly reflects the maximized
state.
<a href="https://github.com/ghostty-org/ghostty/pull/4646">#4646</a></p>
</li>
<li>
<p>GTK: <code>last_tab</code> keybind action works
<a href="https://github.com/ghostty-org/ghostty/pull/5004">#5004</a></p>
</li>
<li>
<p>GTK: The titlebar is automatically hidden when the window is fullscreen
(and restored when the window exits fullscreen).
<a href="https://github.com/ghostty-org/ghostty/pull/5008">#5008</a></p>
</li>
<li>
<p>GTK: Mouse no longer appears when the title changes and
<code>mouse-hide-while-typing</code> is set.
<a href="https://github.com/ghostty-org/ghostty/pull/3345">#3345</a></p>
</li>
<li>
<p>GTK: Fix segfault that would happen with older libadwaita versions
when <code>ctrl+d</code> was used to exit a window.
<a href="https://github.com/ghostty-org/ghostty/pull/4971">#4971</a></p>
</li>
<li>
<p>GTK: Ensure close confirmation appears in more scenarios such as
pressing the "X" in the tab bar.
<a href="https://github.com/ghostty-org/ghostty/pull/4234">#4234</a></p>
</li>
<li>
<p>GTK: OpenGL debug logging is now disabled by default for release
builds but can be configured to be turned back on.
<a href="https://github.com/ghostty-org/ghostty/pull/4662">#4662</a></p>
</li>
<li>
<p>GTK: Windows with libadwaita enabled can now be sized smaller than
482x322.
<a href="https://github.com/ghostty-org/ghostty/pull/4836">#4836</a></p>
</li>
<li>
<p>GTK: Fix a handful of cases where compile-time version checks were
done instead of runtime, disabling behavior when we shouldn't have.
<a href="https://github.com/ghostty-org/ghostty/issues/4783">#4783</a></p>
</li>
<li>
<p>GTK: <code>window-title-font-family</code> now works (previously this was macOS-only)
<a href="https://github.com/ghostty-org/ghostty/issues/4560">#4560</a></p>
</li>
<li>
<p>GTK: Menu separator colors now match the system theme.
<a href="https://github.com/ghostty-org/ghostty/issues/4421">#4421</a></p>
</li>
<li>
<p>GTK: Fix issues with fractional scaling. The terminal should now appear
crisp on GTK displays with fractional scaling.
<a href="https://github.com/ghostty-org/ghostty/issues/4255">#4255</a></p>
</li>
<li>
<p>GTK: A new configuration <code>gtk-custom-css</code> allows loading custom CSS
to theme GTK elements.
<a href="https://github.com/ghostty-org/ghostty/issues/4200">#4200</a></p>
</li>
<li>
<p>GTK: <code>focus-follows-mouse</code> works properly with <code>goto_split</code> keybindings.
<a href="https://github.com/ghostty-org/ghostty/issues/3229">#3229</a></p>
</li>
<li>
<p>GTK: Use <code>gtk-xft-dpi</code> for font scaling on Wayland (previously
we only used the value for X11). This allows the GNOME "Large Text"
setting to work properly.
<a href="https://github.com/ghostty-org/ghostty/pull/4424">#4424</a></p>
</li>
<li>
<p>GTK: <code>ctrl+insert</code> and <code>shift+insert</code> bindings have been added as
secondary defaults for <code>copy</code> and <code>paste</code>, respectively.
<a href="https://github.com/ghostty-org/ghostty/pull/2870">#2870</a></p>
</li>
<li>
<p>GTK: Paste preview text is now monospace.
<a href="https://github.com/ghostty-org/ghostty/pull/4227">#4227</a></p>
</li>
</ul>

<blockquote><p>All of the build changes are minor and should not impact previously
functional builds. Feel free to ignore these changes unless you're
simply curious about them.</p></blockquote>
<ul>
<li>Build: <code>-Dstrip</code> can be used to control binary stripping. Previously,
we automatically stripped release binaries. This can now be configured.
<a href="https://github.com/ghostty-org/ghostty/issues/3945">#3945</a></li>
<li>Build: <code>-Dsentry</code> can be used to explicitly enable or disable Sentry.
Linux builds by default have Sentry disabled. macOS builds by default
have Sentry enabled. Sentry only collects crash logs locally, it does
not transmit them via the network.
<a href="https://github.com/ghostty-org/ghostty/issues/3934">#3934</a></li>
<li>Build: Terminfo/Termcap sources are no longer installed by default.
Note the <em>compiled</em> version is still properly installed so the terminfo
is available. Build flags <code>-Demit-terminfo</code> and <code>-Demit-termcap</code> can be
used to emit the source files.
<a href="https://github.com/ghostty-org/ghostty/pull/5311">#5311</a></li>
<li>Build: Fix incorrect libadwaita pkg-config name.
<a href="https://github.com/ghostty-org/ghostty/pull/4818">#4818</a></li>
</ul>

<p>We plan to release a version 1.1.1 to address some additional bugs that
didn't quite make the 1.1.0 release. We don't expect this release to happen
quickly unless any critical issues or regressions are raised. Therefore,
we recommend all package managers to upgrade to 1.1.0 as quickly as possible.</p>
<p>The focus for the next release will be to continue to resolve some issues
with certain keyboard layouts along with some fundamental issues with
<code>window-step-resize</code> on macOS. Additional unplanned functionality may
be introduced if unexpected contributors appear (thank you!).</p>
<p>We're reaching general wide-scale stability since our initial 1.0 release.
I expect soon we'll move to even longer release cycles (months long) to
allow the development team to focus on larger, more impactful features.</p>

<p>Starting with Ghostty 1.2, we plan to remove the <code>gtk-adwaita</code> option
and force a dependency on libadwaita. libadwaita is defaulted to on
already so unless you've explicitly disabled it, this change should
not affect you.</p>
<blockquote><p><strong>I expect for some this will be a controversial decision</strong>,
so please read this section carefully to understand
our motivation and the diligence we've done in making this decision. If you
still have concerns, please reach out to us on GitHub or Discord.</p></blockquote>
<p>The primary use case for <code>gtk-adwaita = false</code> in earlier versions of Ghostty
was to use it in concert with <code>window-decoration = none</code> to force some
compositors to use server-side decorations (SSD). Note this didn't work
in all cases and was never an explicit configuration goal; it just happened
to work in some cases. With the introduction of
<a href="#server-side-decorations-(ssd)-on-linux">explicit SSD support</a>
in Ghostty 1.1, <em>this workaround is no longer necessary</em>.</p>
<p>Another use case for <code>gtk-adwaita = false</code> was in relation to theming.
Ghostty 1.1 introduces a
<a href="https://github.com/ghostty-org/ghostty/issues/4200"><code>gtk-custom-css</code> option</a>
to easily inject custom CSS to theme GTK elements. We also introduced
more easily targetable class names across our GTK widgets. You could always
use system-wide CSS to theme Ghostty, but this new option makes it easier
to test and apply custom CSS specific to Ghostty.</p>
<p>For Ghostty maintainers, maintaining "classic GTK" and "libadwaita" code
paths is a significant burden, especially in addition to differences in
behavior across GTK and Adwaita versions and the complex interactions
of various Ghostty configurations (all the <code>gtk-</code> and <code>adw-</code> prefixed
options). This has led to a number of bugs and regressions that are
difficult to fix and test without expensive and complex CI setups.</p>
<p>With the SSD support in Ghostty 1.1 and the primary use case for
<code>gtk-adwaita = false</code> no longer necessary, we believe now is a good
time to make this change. We believe this will result in a more stable,
more maintainable, and more feature-rich Ghostty in the future (the last
point because we can go all-in on libadwaita features).</p>
<p>To better feel confident in this decision, we've also reached out directly
to non-GNOME users of Ghostty as well as non-Ghostty users who complained
about the look and feel of Ghostty (namely: bloggers, streamers, and
YouTubers). The feedback was unanimously supportive of this change,
understanding the reasoning and the benefits it would bring and acknowledging
that explicit SSD support addresses the major concerns.</p>
<p>If you have strong opinions on this change, please reach out to us
on Discord or GitHub. Please justify your argument with specific use cases
and scenarios where this change would negatively impact you. Please do not
just say "I don't like it" without providing a reason; it's not helpful.
We are open to feedback and will consider it carefully. Thank you!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mini-R1: Reproduce DeepSeek R1 "Aha Moment" (186 pts)]]></title>
            <link>https://www.philschmid.de/mini-deepseek-r1</link>
            <guid>42884834</guid>
            <pubDate>Fri, 31 Jan 2025 05:03:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.philschmid.de/mini-deepseek-r1">https://www.philschmid.de/mini-deepseek-r1</a>, See on <a href="https://news.ycombinator.com/item?id=42884834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The release of Deepseek R1 shocked the industry. Why? Well, DeepSeek-R1 is an open model that rivals OpenAI's o1 in complex reasoning tasks, introduced using Group Relative Policy Optimization (GRPO) and RL-focused multi-stage training approach. They not only released the model, but also a research paper on how they did it.</p>
<p>In the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2501.12948">paper</a> they described an "aha moment" when using pure RL to train the model. During this phase, DeepSeek-R1-Zero (the first test of DeepSeek-R1) learns to allocate more thinking time to a problem by reevaluating its initial approach without any human feedback or data describing how to do it.  They describe this as an "aha moment" as:</p>
<blockquote>
<p>This behavior is not only a testament to the model’s growing reasoning abilities but also a captivating example of how reinforcement learning can lead to unexpected and sophisticated outcomes.</p>
</blockquote>
<p>In this blog post we want to recreate the small "aha moment" of DeepSeek-R1 using Group Relative Policy Optimization (GRPO) and the Countdown Game. We will train an open model using reinforcement learning trying to teach it self-verification and search abilities all on its own to solve the Countdown Game.
The Countdown game is a numbers puzzle where players use a set of randomly drawn numbers and basic arithmetic operations (+, -, ×, ÷) to reach or get as close as possible to a target number.</p>
<div><pre><code>Target Number: 952
Available Numbers: 25, 50, 75, 100, 3, 6

(100 × (3 × 3)) + (50 + 6 / 3) = 952
</code></pre></div>
<p>The blog post includes an interactive code which you can run in a Jupyter Notebook on how to train a model using GRPO and Q-Lora. This is a great way to learn how to use TRL and GRPO, but it is very slow and requires a lot of compute. Additionally, I added a <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/scripts/run_r1_grpo.py">script</a> and instructions to run the training on Node with multiple GPUs or a SLURM cluster.</p>
<ol>
<li><a href="#1-setup-the-development-environment">Setup the development environment</a></li>
<li><a href="#2-generate-training-samples-with-reasoning-prefix-from-the-countdown-game">Generate training samples with reasoning prefix from the Countdown Game</a></li>
<li><a href="#3-train-the-model-using-grpo-educational-part">Train the model using GRPO (Educational part)</a></li>
<li><a href="#4-distributed-training-example-for-grpo-using-deepspeed-and-vllm">Distributed Training example for GRPO using Deepspeed and vLLM</a></li>
<li><a href="#5-results-and-training-observations">Results and Training Observations</a></li>
</ol>
<p><em>Note: This blog is inspired by <a target="_blank" rel="noopener noreferrer" href="https://x.com/jiayi_pirate/status/1882839370505621655">Jiayi Pan</a> who initially explored the idea and proofed it with a small model.</em></p>
<p>But Before we start, let's take a look at the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">Group Relative Policy Optimization (GRPO)</a> and understand how it works.</p>
<p><strong>Group Relative Policy Optimization (GRPO)</strong></p>
<p>Group Relative Policy Optimization (GRPO) is a reinforcement learning algorithm to improve the reasoning capabilities of LLMs. It was introduced in the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">DeepSeekMath</a> paper in the context of mathematical reasoning. GRPO modifies the traditional Proximal Policy Optimization (PPO) by eliminating the need for a value function model. Instead, it estimates baselines from group scores, reducing memory usage and computational overhead. GRPO, now also used by the Qwen team, can be used with rule/binary-based Rewards as well as General Reward Models to improve models on helpfulness.</p>
<ol>
<li><strong>Sampling</strong>: Generate multiple outputs for each prompt using the current policy</li>
<li><strong>Reward Scoring</strong>: Each generation is scored using a reward function, could be (rule-based or outcome-based)</li>
<li><strong>Advantage Calculation</strong>: The average reward of the generated outputs is used as a baseline. The advantage of each solution within the group is then computed relative to this baseline. The reward is normalized within a group.</li>
<li><strong>Policy Optimization</strong>: The policy tries to maximize the GRPO objective, which includes the calculated advantages and a KL divergence term. This is different from how PPO implements the KL term within the reward.</li>
</ol>
<p><img src="https://www.philschmid.de/static/blog/mini-deepseek-r1/grpo.png" alt="grpo.png"></p>
<h2 id="1-setup-the-development-environment">1. Setup the development environment</h2>
<p>Our first step is to install Hugging Face Libraries and Pytorch, vllm, and trl, transformers and datasets. If you haven't heard of trl yet, don't worry. It is a new library on top of transformers and datasets, which makes it easier to fine-tune, rlhf, align open LLMs.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span># Install Pytorch &amp; other libraries, make sure to match your GPU driver version</span></span>
<span data-line=""><span>%</span><span>pip install </span><span>"torch==2.5.1"</span><span> tensorboard </span><span>"setuptools&lt;71.0.0"</span><span>  --</span><span>index</span><span>-</span><span>url https:</span><span>//</span><span>download.pytorch.org</span><span>/</span><span>whl</span><span>/</span><span>cu121</span></span>
<span data-line=""> </span>
<span data-line=""><span># Install flash-attn</span></span>
<span data-line=""><span>%</span><span>pip install flash</span><span>-</span><span>attn </span></span>
<span data-line=""> </span>
<span data-line=""><span># Install Hugging Face libraries</span></span>
<span data-line=""><span>%</span><span>pip install  </span><span>--</span><span>upgrade \</span></span>
<span data-line=""><span>  "transformers==4.48.1"</span><span> \</span></span>
<span data-line=""><span>  "datasets==3.1.0"</span><span> \</span></span>
<span data-line=""><span>  "accelerate==1.3.0"</span><span> \</span></span>
<span data-line=""><span>  "hf-transfer==0.1.9"</span><span> \</span></span>
<span data-line=""><span>  "deepspeed==0.15.4"</span><span> \</span></span>
<span data-line=""><span>  "trl==0.14.0"</span></span>
<span data-line=""> </span>
<span data-line=""><span># install vLLM </span></span>
<span data-line=""><span>%</span><span>pip install </span><span>"vllm==0.7.0"</span></span>
<span data-line=""> </span>
<span data-line=""><span>## IMPORTANT: If you want to run the notebook and the interactive cells you also need to install the following libraries:</span></span>
<span data-line=""><span># But first read it the blog post and then decide as they might conflict with the libraries for distributed training. </span></span>
<span data-line=""><span># %pip install "peft==0.14.0" "bitsandbytes==0.45.0"</span></span>
<span data-line=""> </span></code></pre></div></figure>
<p><em>Note: you may need to restart the kernel to use updated packages.</em></p>
<p>We will use the <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/models">Hugging Face Hub</a> as a remote model versioning service. This means we will automatically push our model, logs and information to the Hub during training. You must register on the <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/join">Hugging Face</a> for this. After you have an account, we will use the <code>login</code> util from the <code>huggingface_hub</code> package to log into our account and store our token (access key) on the disk.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>from</span><span> huggingface_hub </span><span>import</span><span> login</span></span>
<span data-line=""> </span>
<span data-line=""><span>login(</span><span>token</span><span>=</span><span>""</span><span>, </span><span>add_to_git_credential</span><span>=</span><span>True</span><span>) </span><span># ADD YOUR TOKEN HERE</span></span></code></pre></div></figure>
<h2 id="2-generate-training-samples-with-reasoning-prefix-from-the-countdown-game">2. Generate training samples with reasoning prefix from the Countdown Game</h2>
<p>We are going to use the <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/datasets/Jiayi-Pan/Countdown-Tasks-3to4">Jiayi-Pan/Countdown-Tasks-3to4</a> dataset, which contains samples with 3 to 4 numbers and solutions.</p>
<p>As Model we are going to use <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/Qwen/Qwen2.5-3B-Instruct">Qwen/Qwen2.5-3B-Instruct</a> which is a 3B parameter instruction tuned model. This makes it easier to showcase the "aha moment" as it already follows the prompt format. But you can use the base version of Qwen or other models as well. <a target="_blank" rel="noopener noreferrer" href="https://x.com/jiayi_pirate/status/1882839487417561307">Jiayi-Pan</a> explored that the model needs to have a certain quality to be able to learn the reasoning process, starting with &gt; 1.5B parameters.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>from</span><span> transformers </span><span>import</span><span> AutoTokenizer</span></span>
<span data-line=""><span>from</span><span> datasets </span><span>import</span><span> load_dataset</span></span>
<span data-line=""> </span>
<span data-line=""><span># Load dataset from Hugging Face Hub</span></span>
<span data-line=""><span>dataset_id </span><span>=</span><span> "Jiayi-Pan/Countdown-Tasks-3to4"</span></span>
<span data-line=""><span>dataset </span><span>=</span><span> load_dataset(dataset_id, </span><span>split</span><span>=</span><span>"train"</span><span>)</span></span>
<span data-line=""><span># select a random subset of 50k samples</span></span>
<span data-line=""><span>dataset </span><span>=</span><span> dataset.shuffle(</span><span>seed</span><span>=</span><span>42</span><span>).select(</span><span>range</span><span>(</span><span>50000</span><span>))</span></span>
<span data-line=""> </span>
<span data-line=""><span># Load tokenizer from Hugging Face Hub to format the dataset to our "r1" prompt </span></span>
<span data-line=""><span>tokenizer </span><span>=</span><span> AutoTokenizer.from_pretrained(</span><span>"Qwen/Qwen2.5-3B-Instruct"</span><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span># gemerate r1 prompt with a prefix for the model to already start with the thinking process</span></span>
<span data-line=""><span>def</span><span> generate_r1_prompt</span><span>(numbers, target):</span></span>
<span data-line=""><span>    r1_prefix </span><span>=</span><span> [{</span></span>
<span data-line=""><span>        "role"</span><span>: </span><span>"system"</span><span>,</span></span>
<span data-line=""><span>        "content"</span><span>: </span><span>"You are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer."</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>      { </span></span>
<span data-line=""><span>        "role"</span><span>: </span><span>"user"</span><span>,</span></span>
<span data-line=""><span>        "content"</span><span>: </span><span>f</span><span>"Using the numbers </span><span>{</span><span>numbers</span><span>}</span><span>, create an equation that equals </span><span>{</span><span>target</span><span>}</span><span>. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in &lt;think&gt; &lt;/think&gt; tags. And return the final equation and answer in &lt;answer&gt; &lt;/answer&gt; tags, for example &lt;answer&gt; (1 + 2) / 3 = 1 &lt;/answer&gt;."</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>      {</span></span>
<span data-line=""><span>        "role"</span><span>: </span><span>"assistant"</span><span>,</span></span>
<span data-line=""><span>        "content"</span><span>: </span><span>"Let me solve this step by step.</span><span>\n</span><span>&lt;think&gt;"</span></span>
<span data-line=""><span>      }]</span></span>
<span data-line=""><span>    return</span><span> {</span><span>"prompt"</span><span>: tokenizer.apply_chat_template(r1_prefix, </span><span>tokenize</span><span>=</span><span>False</span><span>, </span><span>continue_final_message</span><span>=</span><span>True</span><span>), </span><span>"target"</span><span>: target}</span></span>
<span data-line=""> </span>
<span data-line=""><span># convert our dataset to the r1 prompt</span></span>
<span data-line=""><span>dataset </span><span>=</span><span> dataset.map(</span><span>lambda</span><span> x: generate_r1_prompt(x[</span><span>"nums"</span><span>], x[</span><span>"target"</span><span>]))</span></span>
<span data-line=""> </span>
<span data-line=""><span># split the dataset into train and test</span></span>
<span data-line=""><span>train_test_split </span><span>=</span><span> dataset.train_test_split(</span><span>test_size</span><span>=</span><span>0.1</span><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>train_dataset </span><span>=</span><span> train_test_split[</span><span>"train"</span><span>]</span></span>
<span data-line=""><span>test_dataset </span><span>=</span><span> train_test_split[</span><span>"test"</span><span>]</span></span></code></pre></div></figure>
<h2 id="3-train-the-model-using-grpo-educational-part">3. Train the model using GRPO (Educational part)</h2>
<p><em>Note: Section 3 is shows the basic on how to use TRL and GRPO. If you want to run the interactive cells you need to install <code>bitsandbytes</code> and <code>peft</code> as they are required for the <code>Trainer</code> class. This section is mostly for educational purposes.</em></p>
<p>TRL supports Group Relative Policy Optimization (GRPO) through a dedicated <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/docs/trl/main/en/grpo_trainer">GRPOTrainer</a> for aligning LLMs from preference data, as described in <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</a>. The <code>GRPOTrainer</code> is a subclass of the <code>Trainer</code> from the <code>transformers</code> library and supports all the same features, including logging, checkpointing, distributed training, and parameter efficient fine-tuning (PEFT).</p>
<p>The <code>GRPOTrainer</code> supports generic Outcome Reward Models (ORM) and custom reward functions, that can be used to implement Rule-Based Reward Models. In the Deepseek R1 paper they implemented Rule-Based Reward Models to verify the correctness of the generated solutions. In our exmaple we are going to do a similar approach, where we will create 2 reward functions that:</p>
<ol>
<li><strong>Format Reward</strong>: Checks if the generated format is correct <code>&lt;think&gt; [thinking] &lt;/think&gt;&lt;answer&gt; [answer] &lt;/answer&gt;</code></li>
<li><strong>Accuracy Reward</strong>: Extracts the equation from the <code>&lt;answer&gt;</code> tag and evaluates it against the target and if every number is used once.</li>
</ol>
<p><em>Note: Correct <code>&lt;answer&gt;</code> in our example includes the equation, for example <code>&lt;answer&gt; 55 + 36 - 7 - 19 &lt;/answer&gt;</code></em></p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>import</span><span> re</span></span>
<span data-line=""> </span>
<span data-line=""><span>def</span><span> format_reward_func</span><span>(completions, target, </span><span>**</span><span>kwargs):</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    Format: &lt;think&gt;...&lt;/think&gt;&lt;answer&gt;...&lt;/answer&gt;</span></span>
<span data-line=""><span>    Args:</span></span>
<span data-line=""><span>        completions (list[str]): Generated outputs</span></span>
<span data-line=""><span>        target (list[str]): Expected answers</span></span>
<span data-line=""><span>      </span></span>
<span data-line=""><span>      Returns:</span></span>
<span data-line=""><span>          list[float]: Reward scores</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    rewards </span><span>=</span><span> []</span></span>
<span data-line=""> </span>
<span data-line=""><span>    for</span><span> completion, gt </span><span>in</span><span> zip</span><span>(completions, target):</span></span>
<span data-line=""> </span>
<span data-line=""><span>      try</span><span>:</span></span>
<span data-line=""><span>        # add synthetic &lt;think&gt; as its already part of the prompt and prefilled for the assistant to more easily match the regex</span></span>
<span data-line=""><span>        completion </span><span>=</span><span> "&lt;think&gt;"</span><span> +</span><span> completion        </span></span>
<span data-line=""><span>        # Check if the format is correct</span></span>
<span data-line=""><span>        regex </span><span>=</span><span> r</span><span>"</span><span>^</span><span>&lt;think&gt;</span><span>([</span><span>^</span><span>&lt;]</span><span>*</span><span>(?:</span><span>&lt;</span><span>(?!</span><span>/</span><span>?</span><span>think&gt;</span><span>)</span><span>[</span><span>^</span><span>&lt;]</span><span>*</span><span>)</span><span>*</span><span>)</span><span>&lt;</span><span>\/</span><span>think&gt;</span><span>\n</span><span>&lt;answer&gt;</span><span>([\s\S]</span><span>*?</span><span>)</span><span>&lt;</span><span>\/</span><span>answer&gt;</span><span>$</span><span>"</span></span>
<span data-line=""> </span>
<span data-line=""><span>        match </span><span>=</span><span> re.search(regex, completion, re.</span><span>DOTALL</span><span>) </span></span>
<span data-line=""><span>        # if the format is not correct, reward is 0</span></span>
<span data-line=""><span>        if</span><span> match </span><span>is</span><span> None</span><span> or</span><span> len</span><span>(match.groups()) </span><span>!=</span><span> 2</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>        else</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>1.0</span><span>)</span></span>
<span data-line=""><span>      except</span><span> Exception</span><span>:</span></span>
<span data-line=""><span>        rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>    return</span><span> rewards</span></span>
<span data-line=""> </span>
<span data-line=""><span>def</span><span> equation_reward_func</span><span>(completions, target, nums, </span><span>**</span><span>kwargs):</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    Evaluates completions based on:</span></span>
<span data-line=""><span>    2. Mathematical correctness of the answer</span></span>
<span data-line=""> </span>
<span data-line=""><span>    Args:</span></span>
<span data-line=""><span>        completions (list[str]): Generated outputs</span></span>
<span data-line=""><span>        target (list[str]): Expected answers</span></span>
<span data-line=""><span>        nums (list[str]): Available numbers</span></span>
<span data-line=""><span>    </span></span>
<span data-line=""><span>    Returns:</span></span>
<span data-line=""><span>        list[float]: Reward scores</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    rewards </span><span>=</span><span> []</span></span>
<span data-line=""><span>    for</span><span> completion, gt, numbers </span><span>in</span><span> zip</span><span>(completions, target, nums):</span></span>
<span data-line=""><span>      try</span><span>:</span></span>
<span data-line=""><span>        # add synthetic &lt;think&gt; as its already part of the prompt and prefilled for the assistant to more easily match the regex</span></span>
<span data-line=""><span>        completion </span><span>=</span><span> "&lt;think&gt;"</span><span> +</span><span> completion</span></span>
<span data-line=""><span>        # Check if the format is correct</span></span>
<span data-line=""><span>        match </span><span>=</span><span> re.search(</span><span>r</span><span>"</span><span>&lt;answer&gt;</span><span>(.</span><span>*?</span><span>)</span><span>&lt;</span><span>\/</span><span>answer&gt;</span><span>"</span><span>, completion)</span></span>
<span data-line=""><span>        if</span><span> match </span><span>is</span><span> None</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>            continue</span></span>
<span data-line=""><span>        # Extract the "answer" part from the completion</span></span>
<span data-line=""><span>        equation </span><span>=</span><span> match.group(</span><span>1</span><span>).strip()</span></span>
<span data-line=""><span>        # Extract all numbers from the equation</span></span>
<span data-line=""><span>        used_numbers </span><span>=</span><span> [</span><span>int</span><span>(n) </span><span>for</span><span> n </span><span>in</span><span> re.findall(</span><span>r</span><span>'</span><span>\d</span><span>+</span><span>'</span><span>, equation)]</span></span>
<span data-line=""><span>        </span></span>
<span data-line=""><span>        # Check if all numbers are used exactly once</span></span>
<span data-line=""><span>        if</span><span> sorted</span><span>(used_numbers) </span><span>!=</span><span> sorted</span><span>(numbers):</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>            continue</span></span>
<span data-line=""><span>        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace</span></span>
<span data-line=""><span>        allowed_pattern </span><span>=</span><span> r</span><span>'</span><span>^[\d+</span><span>\-</span><span>*/().\s]</span><span>+</span><span>$</span><span>'</span></span>
<span data-line=""><span>        if</span><span> not</span><span> re.match(allowed_pattern, equation):</span></span>
<span data-line=""><span>           rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>           continue</span></span>
<span data-line=""><span>        </span></span>
<span data-line=""><span>        # Evaluate the equation with restricted globals and locals</span></span>
<span data-line=""><span>        result </span><span>=</span><span> eval</span><span>(equation, {</span><span>"__builtins__"</span><span>: </span><span>None</span><span>}, {})</span></span>
<span data-line=""><span>        # Check if the equation is correct and matches the ground truth</span></span>
<span data-line=""><span>        if</span><span> abs</span><span>(</span><span>float</span><span>(result) </span><span>-</span><span> float</span><span>(gt)) </span><span>&lt;</span><span> 1e-5</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>1.0</span><span>)</span></span>
<span data-line=""><span>        else</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>      except</span><span> Exception</span><span>:</span></span>
<span data-line=""><span>            # If evaluation fails, reward is 0</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>) </span></span>
<span data-line=""><span>    return</span><span> rewards</span></span></code></pre></div></figure>
<p>Lets try our reward function with a sample.</p>
<p><em>Note: None of the example starts with <code>&lt;think&gt;</code> as we added it synthetically to the prompt.</em></p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>correct_sample_1 </span><span>=</span><span> """We need to find an equation using the numbers 19, 36, 55, and 7</span></span>
<span data-line=""><span>exactly once, with basic arithmetic operations, that equals 65. One possible</span></span>
<span data-line=""><span>combination is 55 + 36 - 19 + 7... &lt;/think&gt;</span></span>
<span data-line=""> </span>
<span data-line=""><span>&lt;answer&gt; 55 + 36 - 7 - 19 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""><span>correct_sample_2 </span><span>=</span><span> """ ... &lt;/think&gt;</span></span>
<span data-line=""> </span>
<span data-line=""><span>&lt;answer&gt; 55 + 36 - 7 - 19 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""><span>wrong_format </span><span>=</span><span> """User: Using the numbers [19, 36, 55, 7], create an equation that equals 65."""</span></span>
<span data-line=""> </span>
<span data-line=""><span>wrong_format_2 </span><span>=</span><span> """To find the equation that equals 79 using the numbers 95, 78, 6, 88, I'll start by adding 88 and 95:                      </span></span>
<span data-line=""><span>95 + 88 = 183                                                                                                              </span></span>
<span data-line=""><span>Now, let's subtract 104 from 183 to get 79:</span></span>
<span data-line=""><span>183 - 104 = 79</span></span>
<span data-line=""><span>&lt;think&gt; 183 - 104 = 79 &lt;/think&gt;&lt;think&gt; 183 - 104 = 79 &lt;/think&gt;&lt;answer&gt; 183 - 104 = 79 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""><span>wrong_result </span><span>=</span><span> """ ... &lt;/think&gt;</span></span>
<span data-line=""> </span>
<span data-line=""><span>&lt;answer&gt; 55 + 36 - 7 - 18 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""> </span>
<span data-line=""><span>test_rewards </span><span>=</span><span> format_reward_func(</span><span>completions</span><span>=</span><span>[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result], </span><span>target</span><span>=</span><span>[</span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>], </span><span>nums</span><span>=</span><span>[[</span><span>19</span><span>, </span><span>36</span><span>, </span><span>55</span><span>, </span><span>7</span><span>]] </span><span>*</span><span> 5</span><span>)</span></span>
<span data-line=""><span>assert</span><span> test_rewards </span><span>==</span><span> [</span><span>1.0</span><span>, </span><span>1.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>, </span><span>1.0</span><span>], </span><span>"Reward function is not working"</span></span>
<span data-line=""><span>test_rewards </span><span>=</span><span> equation_reward_func(</span><span>completions</span><span>=</span><span>[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result], </span><span>target</span><span>=</span><span>[</span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>], </span><span>nums</span><span>=</span><span>[[</span><span>19</span><span>, </span><span>36</span><span>, </span><span>55</span><span>, </span><span>7</span><span>]] </span><span>*</span><span> 5</span><span>)</span></span>
<span data-line=""><span>assert</span><span> test_rewards </span><span>==</span><span> [</span><span>1.0</span><span>, </span><span>1.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>], </span><span>"Reward function is not working"</span></span></code></pre></div></figure>
<p>This looks good, now lets define our remaining training parameters, create a trainer and start training.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>from</span><span> trl </span><span>import</span><span> GRPOConfig, GRPOTrainer, get_peft_config, ModelConfig</span></span>
<span data-line=""> </span>
<span data-line=""><span># our model we are going to use as policy </span></span>
<span data-line=""><span>model_config </span><span>=</span><span> ModelConfig(</span></span>
<span data-line=""><span>    model_name_or_path</span><span>=</span><span>"Qwen/Qwen2.5-3B-Instruct"</span><span>,</span></span>
<span data-line=""><span>    torch_dtype</span><span>=</span><span>"bfloat16"</span><span>,</span></span>
<span data-line=""><span>    attn_implementation</span><span>=</span><span>"flash_attention_2"</span><span>,</span></span>
<span data-line=""><span>    use_peft</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>    load_in_4bit</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span># Hyperparameters</span></span>
<span data-line=""><span>training_args </span><span>=</span><span> GRPOConfig(</span></span>
<span data-line=""><span>    output_dir</span><span>=</span><span>"qwen-r1-aha-moment"</span><span>,</span></span>
<span data-line=""><span>    learning_rate</span><span>=</span><span>5e-7</span><span>,</span></span>
<span data-line=""><span>    lr_scheduler_type</span><span>=</span><span>"cosine"</span><span>,</span></span>
<span data-line=""><span>    logging_steps</span><span>=</span><span>10</span><span>,</span></span>
<span data-line=""><span>    max_steps</span><span>=</span><span>100</span><span>,</span></span>
<span data-line=""><span>    per_device_train_batch_size</span><span>=</span><span>1</span><span>,</span></span>
<span data-line=""><span>    gradient_accumulation_steps</span><span>=</span><span>1</span><span>,</span></span>
<span data-line=""><span>    gradient_checkpointing</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>    gradient_checkpointing_kwargs</span><span>=</span><span>{</span><span>"use_reentrant"</span><span>: </span><span>False</span><span>},</span></span>
<span data-line=""><span>    bf16</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>    # GRPO specific parameters</span></span>
<span data-line=""><span>    max_prompt_length</span><span>=</span><span>256</span><span>,</span></span>
<span data-line=""><span>    max_completion_length</span><span>=</span><span>1024</span><span>, </span><span># max length of the generated output for our solution</span></span>
<span data-line=""><span>    num_generations</span><span>=</span><span>2</span><span>,</span></span>
<span data-line=""><span>    beta</span><span>=</span><span>0.001</span><span>,</span></span>
<span data-line=""><span>    </span></span>
<span data-line=""><span>)</span></span>
<span data-line=""><span>trainer </span><span>=</span><span> GRPOTrainer(</span></span>
<span data-line=""><span>    model</span><span>=</span><span>model_config.model_name_or_path,</span></span>
<span data-line=""><span>    reward_funcs</span><span>=</span><span>[format_reward_func, equation_reward_func],</span></span>
<span data-line=""><span>    args</span><span>=</span><span>training_args,</span></span>
<span data-line=""><span>    train_dataset</span><span>=</span><span>train_dataset,</span></span>
<span data-line=""><span>    eval_dataset</span><span>=</span><span>test_dataset,</span></span>
<span data-line=""><span>    peft_config</span><span>=</span><span>get_peft_config(model_config),</span></span>
<span data-line=""><span>)</span></span></code></pre></div></figure>
<p>We can start our training by calling the <code>train</code> method on the trainer instance.</p>
<p><em>Note: Reinforcement Training is very slow and compute intensive. Running a single step on 1x L4 with Q-LoRA, Batch size of 1 and only 2 generations per samples takes &gt;20 minutes.</em></p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span># Train and push the model to the Hub</span></span>
<span data-line=""><span>trainer.train()</span></span>
<span data-line=""><span># Save model</span></span>
<span data-line=""><span>trainer.save_model(training_args.output_dir)</span></span></code></pre></div></figure>
<h2 id="4-distributed-training-example-for-grpo-using-deepspeed-and-vllm">4. Distributed Training example for GRPO using Deepspeed and vLLM</h2>
<p>More than 20 minutes per step with only 2 generations per sample is not feasible. We need to scale up our training. Hugging Face TRL added support for distributed training with Deepspeed and using vLLM for faster generation. I preprared a <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/scripts/run_r1_grpo.py">run_r1_grpo.py</a> script and a <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml">receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml</a> config file to run the training.</p>
<p>This configuration is tested and validated on a Node with 4x H100 80GBs, where a single step takes around 45-60s, as we can leverage vLLM for generation and DeepSpeed for distributed training. Therefore we need to make sure we correctly set the <code>num_processes</code> to the number of GPUs you have - 1 as the last one will be used with vLLM for Generation. If you are using more GPUS you need to change the <code>vllm_device</code> in the config file to last index GPU, e.g. if you have 8 GPUs you need to set <code>vllm_device=7</code> and your <code>num_processes</code> to 7.</p>
<p>command to run the training:</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="bash" data-theme="github-dark github-light"><span data-line=""><span>accelerate</span><span> launch</span><span> --num_processes</span><span> 3</span><span> --config_file</span><span> configs/accelerate_configs/deepspeed_zero3.yaml</span><span> scripts/run_r1_grpo.py</span><span> --config</span><span> receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml</span></span></code></pre></div></figure>
<p>With the optimized distributed training a single step with 8 generations per sample on 4x H100 80GBs takes around 45-60s. The full training for 450 steps takes around 6 hours.</p>
<h2 id="5-results-and-training-observations">5. Results and Training Observations</h2>
<p>The script saves random completions to the <code>completion_samples</code> folder, which you can use to inspect the model's progress. It includes <code>completion_samples.txt</code> and <code>success_completion_samples.txt</code>. The <code>completion_samples.txt</code> includes all completions, while the <code>success_completion_samples.txt</code> which correctly solves the equation. Below you can find the interesating training obeserations on how the performance changes over time, as well as the Tensornoard logs and successfull reasoning samples.</p>
<p>The model with checkpoints for every 25th step can be found at <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/philschmid/qwen-2.5-3b-r1-countdown">philschmid/qwen-2.5-3b-r1-countdown</a>.</p>
<h3 id="hyperparameters">Hyperparameters</h3>
<p>I started the experiment using the hyperparameters from the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">DeepSeekMath</a> paper with a learning rate of 1e-6 and a beta (KL coefficient) of 0.04, which led to unstable training runs after around 150 steps. I ran some small ablations and decreased both the learning rate to 5e-7 and the beta to 0.001, based on a test from <a target="_blank" rel="noopener noreferrer" href="https://hijkzzz.notion.site/unraveling-rlhf-and-its-variants-engineering-insights#147d9a33ecc9806090f3d5c749d31f05">OpenRLHF</a>. I coulnd't test how increasing the <code>num_generations</code> from 8 to 64 would affect the training. 64 is the generation value, which was used in the DeepSeekMath paper. All other parameters can be found in the <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml">grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml</a> config file.</p>
<h3 id="training-observations">Training Observations:</h3>
<ul>
<li>At ~50 steps the model has learned the correct format <code>&lt;think&gt;...&lt;/think&gt;\n&lt;answer&gt;...&lt;/answer&gt;</code>.</li>
<li>At 100 steps the success rate for solving the equation is around 25%. The model starts to "reason" with words see examples below.</li>
<li>At 200 steps the performance seems to converge much slower and we are at ~40% success rate. The model starts to learn a new "format" where it solves the equation similar to how you would do it programmatically, by trying different combinations and reviewing the results, see "Successfull Reasoning Samples between step 200 and 450".</li>
<li>At 450 steps we have 50% success rate for solving the equation. The performance still improves slowly and the model kept its new format form from step 200.</li>
</ul>
<p>I have 3 potential assumptions why the model shifts from "word reasoning" to "programmatic execution":</p>
<ol>
<li>Qwen 2.5 3B is not strong enough or to small, Deepseek mentions that you need a very strong base model.</li>
<li>The reward functions are not good enough defined and it reward hacks the model to solve the equation. We could try to force it to use words, e.g. having a number to word frequency condition. (We don't know much about the reward functions from Deepseek)</li>
<li>Only training on the Countdown Game tasks might force the model naturally to learn the most effective way to solve the equation as no other formats are required.</li>
<li>We didn't train the model long enough, in the R1 paper they showed visuals of training for over 8000 steps.</li>
</ol>
<h4 id="tensorboard-results">Tensorboard Results</h4>
<p><img src="https://www.philschmid.de/static/blog/mini-deepseek-r1/tensorboard-r1.png" alt="Qwen R1 Tensorboard results"></p>
<h4 id="successfull-reasoning-samples-up-to-step-200">Successfull Reasoning Samples up to step 200</h4>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to think about the numbers we have: 14, 70, and 80. To get 85, I think 80 might be a good starting point because it's right in between 85. If I subtract or add 80, it won't lead to 85 easily. Next, 70 seems to be a good intermediate number, especially to use in conjunction with 14. </span></span>
<span data-line=""><span>Now, I can think about different combinations using addition, subtraction and multiplication/division. If I take 80 - 70 = 10, which is not needed. So, I need to find a way to use 14. If I subtract 14 from 80, I get 66, which still isn't 85. If I subtract 70 from 80, I get 10 again, this isn't constructive yet. </span></span>
<span data-line=""><span>Multiplication could create numbers larger than the target 85. Let's consider division: If I divide 70 by 14, I get 5. Then if I add this result to 80, I get 85. This combination seems promising: 80 - (70 / 14) = 80 - 5 = 75, this still isn't quite right. Let me correct my approach: Let's use division and then addition. If I take 80 / (70 / 14) → 80 / 5 = 16, and then 80 - 16 = 64, still incorrect. Let me simplify: 80 / (70 / 14) → 80 / 5 = 16, and then 80 - 16 gives 64 again, let me correct: 80 - (70 / 14) → 80 - 5 = 75, but I need 85. Thus I will use the combinations in a slightly different order to insert numbers: I get 80 + (70 / 14) = 80 + 5 = 85&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 80 + (70 / 14) &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to consider how I can use the numbers 1, 21, and 90 to reach 68. I can try different combinations of operations. Let's try to use subtraction and addition. If I subtract 90 from 21, I get -69, which is too far from 68. Now, if I add 1 to 90, I get 91, which is also not right. Another way is to see what happens if I subtract 21 from 90, which gives me 69. This is closer but still not 68. Let me use multiplication instead of subtraction. 90 * 1 = 90. Now, if I try to reduce this slightly by subtracting 21, I am not getting close to 68.</span></span>
<span data-line=""><span>Now, let's try another multiplication. I'll think of 1 * (larger value) + (smaller value). Let's try 1 * 90 + 21. This evaluates to 90 + 21 = 111, which is too much. Instead, I will try: 90 / 1 + 21 - 7. But this gives a division by 7, which seems complex. Let's re-evaluate: I'll use 1 to divide 21: 21 / 1 = 21. Now, subtract 21 from 90, and add 1, we have 90 - 21 = 69, using one...</span></span>
<span data-line=""><span>Hey, wait on re-evaluating I will subtract 21 from 90, and include 1 to complete the solution: 90 - (21 + 1) which would be 68.&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 90 - (21 + 1) &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to consider the numbers we have: 59, 80, and 66. I need to use these numbers to get 45. Let's try to use subtraction first since it can quickly reduce large numbers.</span></span>
<span data-line=""><span>Let's see if we can get close by subtracting or adding these numbers. If I subtract 66 from 80, I get 14. Then I need to make this 14 equal 45 when combined with 59. That gives me 14 + 59 = 73, which is too high.</span></span>
<span data-line=""><span>Now let's try adding numbers. If I add 59 and 66, I get 125. Then I would need to subtract 80 from 125 to get 45, but 80 is too large to fit well with this.</span></span>
<span data-line=""><span>Let me try a different approach. What if I subtract 66 from 80 first and then add 59? That would be 14 + 59 = 73, which is still not 45.</span></span>
<span data-line=""><span>Hmm, I need to think of another combination. What if I start with 59 and then add 80 and subtract 66? That would be (59 + 80) - 66, let me calculate it. That equals 139 - 66, which is 73.</span></span>
<span data-line=""><span>That's still not 45, so let me try rearranging it slightly: maybe 80 - 66 + 59 would be closer to 45. Calculating again: 80 - 66 is 14, then adding 59 gives 73.</span></span>
<span data-line=""><span>This way doesn't work either. Let's flip this: maybe (59 + 66) - 80. Let me check: that's 125 - 80, which equals 45.&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt;(59 + 66) - 80&lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to find a combination of the numbers 61, 4, 94, and 21 that can be manipulated using basic arithmetic operations to equal 50. One way to approach this is to look for numbers that can be used to reach a target number close to 50 and then adjust with the remaining numbers.</span></span>
<span data-line=""><span>Let's try combining 94 and 21 first:</span></span>
<span data-line=""><span>94 + 21 = 115</span></span>
<span data-line=""><span>Now, we need to get from 115 to 50. We can try subtracting 65:</span></span>
<span data-line=""><span>115 - 65 = 50</span></span>
<span data-line=""><span>Now we need to find a way to get 65 using the remaining numbers 61 and 4. We can try:</span></span>
<span data-line=""><span>61 - 4 = 57</span></span>
<span data-line=""><span>Now we need to get from 57 to 65. Adding 8 would give us that:</span></span>
<span data-line=""><span>57 + 8 = 65</span></span>
<span data-line=""><span>So, we need to find a way to get 8 using 61 and 4. We can try:</span></span>
<span data-line=""><span>61 - 94 = -36</span></span>
<span data-line=""><span>This is negative, so let's try dividing:</span></span>
<span data-line=""><span>61 / 94 = 0.648987...</span></span>
<span data-line=""><span>This is not helping, so let's try multiplication and division in a different way:</span></span>
<span data-line=""><span>(61 - 4) * (94 / 21) = 57 * 4.476... = 254.4</span></span>
<span data-line=""><span>This is not working either. Let's try a different approach:</span></span>
<span data-line=""><span>(94 - 61) = 33</span></span>
<span data-line=""><span>Now we have:</span></span>
<span data-line=""><span>33 + 21 = 54</span></span>
<span data-line=""><span>We need to adjust from 54 to 50, so we can:</span></span>
<span data-line=""><span>54 - 4 = 50</span></span>
<span data-line=""><span>So, the equation becomes:</span></span>
<span data-line=""><span>(94 - 61) + (21 - 4) = 50</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt;(94 - 61) + (21 - 4)&lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I'll consider the possibility of directly subtracting two numbers to get close to 31. If I subtract 57 from 63, I get 7. Now, if I subtract this 7 from 25, I get 25 - 7 = 18. Far from 31, so this doesn't work.</span></span>
<span data-line=""><span>Next, let's try adding and subtracting. Dividing 63 by 25 will give a decimal, so that's unlikely to work. Now, let's see if adding and subtracting in another order could work. For example, let's try 63 - 25, and then we see this gets us 38. Now, we need a way to get to 31 from here. Subtracting 7 from 38 would work, but we can't figure out how to create that 7 from the given numbers.</span></span>
<span data-line=""><span>Hmm, let me try to incorporate all numbers by adding and subtracting. If I try 63 + 25, I get 88. This is quite far from 31, but if 88 - 57, I get 31 exactly!</span></span>
<span data-line=""><span>This seems to be the equation: 63 + 25 - 57 equals 31.</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 63 + 25 - 57 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<h4 id="successfull-reasoning-samples-between-step-200-and-450">Successfull Reasoning Samples between step 200 and 450</h4>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; We need to use the numbers 39, 16, and 55 with basic arithmetic operations to get 78. Let's try different combinations:</span></span>
<span data-line=""><span>- 55 + 39 - 16 = 84 - 16 = 68 (too low)</span></span>
<span data-line=""><span>- 55 + 16 - 39 = 71 - 39 = 32 (too low)</span></span>
<span data-line=""><span>- 55 - 16 + 39 = 39 + 39 = 78 (this works)</span></span>
<span data-line=""><span>So, the equation is 55 - 16 + 39 = 78. &lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 55 - 16 + 39 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; We need to use the numbers 21, 5, and 40 with basic arithmetic operations to get 24. Let's try different combinations:</span></span>
<span data-line=""><span>- 21 - 5 - 40 = -15</span></span>
<span data-line=""><span>- 21 - 5 + 40 = 56</span></span>
<span data-line=""><span>- 21 + 5 - 40 = -14</span></span>
<span data-line=""><span>- 21 * 5 / 40 = 2.1 (not an integer, let's try another)</span></span>
<span data-line=""><span>- 40 * 5 / 21 = 9.52 (not 24)</span></span>
<span data-line=""><span>- 40 / 5 - 21 = 9 - 21 = -12</span></span>
<span data-line=""><span>- 5 * 40 / 21 = 100 / 21 ~= 4.76 (not 24)</span></span>
<span data-line=""><span>- 5 + 40 - 21 = 24 ! This works.</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 5 + 40 - 21 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; We need to use the numbers 75, 99, 62, and 34 with basic arithmetic operations to get 72. Let's try different combinations:</span></span>
<span data-line=""><span>- 99 - 75 + 62 - 34 = 92 - 34 = 58 (too high)</span></span>
<span data-line=""><span>- 99 - 75 - 62 + 34 = 24 - 62 + 34 = -38 + 34 = -4 (too low)</span></span>
<span data-line=""><span>- 99 + 75 - 62 - 34 = 174 - 96 = 78 (too high)</span></span>
<span data-line=""><span>- 99 + 75 - 62 + 34 = 174 + 34 - 62 = 208 - 62 = 146 (too high)</span></span>
<span data-line=""><span>- 99 - 75 + 62 + 34 = 24 + 96 = 120 (too high)</span></span>
<span data-line=""><span>- 75 + 99 - 62 - 34 = 174 - 96 = 78 (too high)</span></span>
<span data-line=""><span>- 75 + 99 - 62 + 34 = 174 + 34 - 62 = 208 - 62 = 146 (too high)</span></span>
<span data-line=""><span>- 75 + 62 - 99 + 34 = 137 - 99 + 34 = 38 + 34 = 72</span></span>
<span data-line=""><span>So, 75 + 62 - 99 + 34 equals 72.</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 75 + 62 - 99 + 34 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<h2 id="conclusion">Conclusion</h2>
<p>The release of DeepSeek R1 and its research paper might be breakpoint for the open-science and open-source development. Just a week after DeepSeek release, we've been able to reproduce a simple version of R1 learned "reasoning" using GRPO and the Countdown Game. While our implementation focuses on a specific task rather than general reasoning and convergence into a very specific "reasoning" format, it shows that the method is working.</p>
<p>In our mini R1 experiment we used GRPO, with two rule-based reward but already required significant compute: 4 H100 GPUs running for 6 hours to complete just 450 training steps on a 3B parameter model. This gives us an idea of the compute needs that you will need to scale Reinforcement Learning. Deepseek ran a 671B model for over 8000 steps and they probably did many ablations.</p>
<p>Looking in to 2025, it's clear that we are on the cusp of even more significant progress. RL will become more accessible and user-friendly, more researchers and developers will explore its potential, but also require amount of more compute as before and compared to supervised fine-tuning.</p>
<p>I am excited for 2025. If you are have any question or ideas feel free to reach out to me.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[sixos: A nix OS without systemd [video] (165 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd</link>
            <guid>42884727</guid>
            <pubDate>Fri, 31 Jan 2025 04:35:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd">https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd</a>, See on <a href="https://news.ycombinator.com/item?id=42884727">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Rubywm: An X11 window manager in pure Ruby (130 pts)]]></title>
            <link>https://github.com/vidarh/rubywm</link>
            <guid>42884556</guid>
            <pubDate>Fri, 31 Jan 2025 03:51:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/vidarh/rubywm">https://github.com/vidarh/rubywm</a>, See on <a href="https://news.ycombinator.com/item?id=42884556">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">A Ruby X11 Window Manager</h2><a id="user-content-a-ruby-x11-window-manager" aria-label="Permalink: A Ruby X11 Window Manager" href="#a-ruby-x11-window-manager"></a></p>
<p dir="auto"><strong>WARNING</strong>:</p>
<p dir="auto">This is experimental. It will eat your cat and burn down your house,
format your hard drive and post all your secrets to Facebook.</p>
<p dir="auto">Also it <em>will</em> likely crash on you.</p>
<p dir="auto">If you're not comfortable figuring out how to recover from an X session
where your window manager is gone and lots of your windows appears to have
disappeared ... somewhere, and you might not be able to get focus to a
terminal window without switching to the text console, this is not yet
for you.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">So why should I run this?</h2><a id="user-content-so-why-should-i-run-this" aria-label="Permalink: So why should I run this?" href="#so-why-should-i-run-this"></a></p>
<p dir="auto">You almost certainly shouldn't.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">But what is it then, at least?</h2><a id="user-content-but-what-is-it-then-at-least" aria-label="Permalink: But what is it then, at least?" href="#but-what-is-it-then-at-least"></a></p>
<p dir="auto">It's a minimalist (currently &lt;1K lines) pure Ruby (including the X11
driver) X11 window manager. It is focused on tiling, but allows you to
choose to assign a tiling layout to specific desktops or leave them
floating. Currently <em>whether or not you use tiling or floating layout</em>
there is <em>no window decoration</em> and windows are not draggable or
resizable by pulling on borders (but you can do that with Windows
key + left/right mouse button)</p>
<p dir="auto">Like bspwm, which was an inspiration, the wm supports <em>no</em> keyboard
handling - all keyboard handling is deferred to separate tools like
sxhkd. Unlike bspwm this WM has no dedicated IPC mechanism. Instead,
so far, all communication happens via X11 ClientMessage events, which
means any tool, like xdotool etc. that can produce those events can
control the WM.</p>
<p dir="auto">It currently does <em>not</em> do anything to facilitate working on multiple
monitors, as in my current setup I'm only using a single monitor for
my Linux machine.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto">Note that most of what you see here is not the wm. The wm decoration is minimalist: a 1 pixel rectangular frame. Nothing else. But people want to see screenshots anyway, so here:</p>
<p><a href="https://github.com/vidarh/rubywm/blob/8eed458c1b9f9d25372df3932ab1237149bb90c0/screenshots/2024-01-11_19-45.png?raw=true"><img src="https://github.com/vidarh/rubywm/raw/8eed458c1b9f9d25372df3932ab1237149bb90c0/screenshots/2024-01-11_19-45.png?raw=true"></a>
<a href="https://github.com/vidarh/rubywm/blob/master/screenshots/2024-01-11_20-04.png?raw=true"><img src="https://github.com/vidarh/rubywm/raw/master/screenshots/2024-01-11_20-04.png?raw=true"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why did you write this?</h2><a id="user-content-why-did-you-write-this" aria-label="Permalink: Why did you write this?" href="#why-did-you-write-this"></a></p>
<p dir="auto">It started with mild frustration that bspwm handled my desire for one of
my virtual desktops to have floating windows by default poorly. It's
possible, but didn't work great for me. It also frustrated me that my
file manager was visible on all the virtual desktops instead of just the
floating one. I also happened to know an X11 WM can be <em>really</em>
minimal to start off with.</p>
<p dir="auto">So I ditched bspwm, and translated TinyWM - a really minimal C wm - to
Ruby, made that my main wm, and gradually started adding the features
I needed, drawing a lot of inspiration from the code of KatriaWM to
figure out how to make my experience gradually less painful.</p>
<p dir="auto">This has been my only WM since that day, and I now feel that <em>I</em> have
rough parity in term of the features <em>I</em> use with bspwm. That does
not mean it will have parity for you - it lacks lots of things. It
also does not mean there aren't plenty of bugs, because there are.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Will you add...?</h2><a id="user-content-will-you-add" aria-label="Permalink: Will you add...?" href="#will-you-add"></a></p>
<p dir="auto">Maybe. As long as it can either 1) be done with little code, and/or
2) be done by you, and/or 3) it can easily be kept as a separate gem.</p>
<p dir="auto">Talk to me. But please respect I'm primarily releasing this "as is", and
I'm not committing to supporting this - I <em>do not care</em> if you decide
it doesn't work for you and is horrible. I'll think it's great if you
get some utility out of this code, though. But my goal is not a big user
base. Or <em>a</em> user base.</p>
<p dir="auto">My goal is a functional, minimalist WM that works <em>for me</em>. And so, I'll
help if it's not compromising my own goal. To the extent our goals are
not compatible, I'm happy to e.g. split out generic/reusable
functionality so people can fork this and we can still benefit from
sharing the bits where we do agree how things should be.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pre-requisites:</h2><a id="user-content-pre-requisites" aria-label="Permalink: Pre-requisites:" href="#pre-requisites"></a></p>
<ul dir="auto">
<li>
<p dir="auto">sxhkd or similar is needed to handle input, as this WM does
<em>not</em> listen to keybindings other than grabbing windows+ left/right
mouse button for move and resize.</p>
</li>
<li>
<p dir="auto">A recent version of Ruby. I currently use 3.2.2</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to run</h2><a id="user-content-how-to-run" aria-label="Permalink: How to run" href="#how-to-run"></a></p>
<p dir="auto">This is a subset of my .xinitrc.</p>
<p dir="auto">WARNING: You probably want to try this in a vm or something first and
see if it works for you:</p>
<div dir="auto" data-snippet-clipboard-copy-content="  (sxhkd 2>&amp;1 | logger -t sxhkd) &amp;
  (cd ~/Desktop/Projects/wm ; ruby rubywm.rb 2>&amp;1 | logger -t rubywm) &amp;
  
  while true do
    wait
    sleep 5
  done"><pre>  (sxhkd <span>2&gt;&amp;1</span> <span>|</span> logger -t sxhkd) <span>&amp;</span>
  (cd <span>~</span>/Desktop/Projects/wm <span>;</span> ruby rubywm.rb <span>2&gt;&amp;1</span> <span>|</span> logger -t rubywm) <span>&amp;</span>
  
  <span>while</span> <span>true</span> <span>do</span>
    <span>wait</span>
    sleep 5
  <span>done</span></pre></div>
<p dir="auto">For most "normal" window managers, people tend to start the window
manager last and let it end the X session when it quits, but since
this is in development, I'm not going to do that because most stuff on
my desktop can survive my WM crashing and being restarted just fine,
as it should be, but will obviously get killed if the X session dies.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using with sxhkd</h2><a id="user-content-using-with-sxhkd" aria-label="Permalink: Using with sxhkd" href="#using-with-sxhkd"></a></p>
<p dir="auto">This is my related integration with sxhkd from my sxhkd config, but any
app that supports sending XClientMessage events can work:</p>
<div data-snippet-clipboard-copy-content="    # Full screen
    super + f
    	/home/vidarh/bin/xclimsg -mpw focused _NET_WM_STATE 2 _NET_WM_STATE_FULLSCREEN 0 2
    
    # Shift Focus
    super + {Left,Down,Up,Right}
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_FOCUS {Left,Down,Up,Right}
    
    # Shift direction
    super + shift + d
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_SHIFT_DIRECTION 0
    
    # Swap node layout
    super + shift + l
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_SWAP_NODES 0
    
    # Move
    super + shift + {Left,Down,Up,Right}
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_MOVE {Left,Down,Up,Right}
    
    super + F1
    	/home/vidarh/bin/xclimsg -mpw focused _NET_RESTACK_WINDOW 2 0 0
    
    super + F2
    	/home/vidarh/bin/xclimsg -mpw focused _NET_RESTACK_WINDOW 2 0 1
    
    # Focus desktop
    super + {1-9,0}
    	/home/vidarh/bin/xclimsg -mp _NET_CURRENT_DESKTOP {0-8,9}
    
    # Move to desktop
    super + shift + {1-9,0}
    	/home/vidarh/bin/xclimsg -mpw focused _NET_WM_DESKTOP {0-8,9}"><pre><code>    # Full screen
    super + f
    	/home/vidarh/bin/xclimsg -mpw focused _NET_WM_STATE 2 _NET_WM_STATE_FULLSCREEN 0 2
    
    # Shift Focus
    super + {Left,Down,Up,Right}
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_FOCUS {Left,Down,Up,Right}
    
    # Shift direction
    super + shift + d
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_SHIFT_DIRECTION 0
    
    # Swap node layout
    super + shift + l
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_SWAP_NODES 0
    
    # Move
    super + shift + {Left,Down,Up,Right}
    	/home/vidarh/bin/xclimsg -mpw focused _RWM_MOVE {Left,Down,Up,Right}
    
    super + F1
    	/home/vidarh/bin/xclimsg -mpw focused _NET_RESTACK_WINDOW 2 0 0
    
    super + F2
    	/home/vidarh/bin/xclimsg -mpw focused _NET_RESTACK_WINDOW 2 0 1
    
    # Focus desktop
    super + {1-9,0}
    	/home/vidarh/bin/xclimsg -mp _NET_CURRENT_DESKTOP {0-8,9}
    
    # Move to desktop
    super + shift + {1-9,0}
    	/home/vidarh/bin/xclimsg -mpw focused _NET_WM_DESKTOP {0-8,9}
</code></pre></div>
<p dir="auto">The <code>_RWM</code> events are custom for this WM. The others works on other
EWMH compatible wms.</p>
<p dir="auto">xclimsg is from <a href="https://github.com/phillbush/xclimsg">https://github.com/phillbush/xclimsg</a>
I intend to "build in" the same client code in rubywm to avoid that
external dependency. Alternatively you can e.g. use xdotool or similar</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TopoNets: High performing vision and language models with brain-like topography (201 pts)]]></title>
            <link>https://arxiv.org/abs/2501.16396</link>
            <guid>42884338</guid>
            <pubDate>Fri, 31 Jan 2025 02:58:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2501.16396">https://arxiv.org/abs/2501.16396</a>, See on <a href="https://news.ycombinator.com/item?id=42884338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2501.16396">View PDF</a>
    <a href="https://arxiv.org/html/2501.16396v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Neurons in the brain are organized such that nearby cells tend to share similar functions. AI models lack this organization, and past efforts to introduce topography have often led to trade-offs between topography and task performance. In this work, we present TopoLoss, a new loss function that promotes spatially organized topographic representations in AI models without significantly sacrificing task performance. TopoLoss is highly adaptable and can be seamlessly integrated into the training of leading model architectures. We validate our method on both vision (ResNet-18, ResNet-50, ViT) and language models (GPT-Neo-125M, NanoGPT), collectively TopoNets. TopoNets are the highest-performing supervised topographic models to date, exhibiting brain-like properties such as localized feature processing, lower dimensionality, and increased efficiency. TopoNets also predict responses in the brain and replicate the key topographic signatures observed in the brain's visual and language cortices. Together, this work establishes a robust and generalizable framework for integrating topography into leading model architectures, advancing the development of high-performing models that more closely emulate the computational strategies of the human brain.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Mayukh Deb [<a href="https://arxiv.org/show-email/3224565a/2501.16396" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 27 Jan 2025 01:09:59 UTC (38,378 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xerox Alto Source Code (2014) (102 pts)]]></title>
            <link>https://computerhistory.org/blog/xerox-alto-source-code/</link>
            <guid>42884133</guid>
            <pubDate>Fri, 31 Jan 2025 02:09:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://computerhistory.org/blog/xerox-alto-source-code/">https://computerhistory.org/blog/xerox-alto-source-code/</a>, See on <a href="https://news.ycombinator.com/item?id=42884133">Hacker News</a></p>
Couldn't get https://computerhistory.org/blog/xerox-alto-source-code/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[How Jane Street accidentally built a better build system for OCaml (325 pts)]]></title>
            <link>https://blog.janestreet.com/how-we-accidentally-built-a-better-build-system-for-ocaml-index/</link>
            <guid>42881724</guid>
            <pubDate>Thu, 30 Jan 2025 20:14:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.janestreet.com/how-we-accidentally-built-a-better-build-system-for-ocaml-index/">https://blog.janestreet.com/how-we-accidentally-built-a-better-build-system-for-ocaml-index/</a>, See on <a href="https://news.ycombinator.com/item?id=42881724">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>A “build system” is one of the most important tools in a developer’s
toolbox. Roughly, it figures out how to create runnable programs from
a bunch of different source files by calling out to the compiler,
setting up and executing test suites, and so on. Because you interact
with it daily, above all it has to be <a href="https://xkcd.com/303/">fast</a> –
but it also has to be flexible.</p>

<p>Around 2012 we were growing dissatisfied with OMake, then one of
OCaml’s standard build systems, and decided to build our own; we
called this new system Jenga. It worked quite well for us, and we
thought the broader community might find it useful. So we decided to
release Jenga. We hoped that when other people tried it, they’d like
it, and maybe even contribute back to it. Releasing it would also make
it easier for us to open source our code.</p>

<p>Ha! What actually happened is that nobody really wanted to use Jenga.
For one thing it didn’t work on Windows. But also, to adopt Jenga was
in effect to adopt the whole “Jane Street way” of building OCaml. The
adoption of Jenga by those we hoped to embrace it was weak enough that
we actually decided to <em>un</em>-open source it. And so we were back to the
same place as before.</p>

<p>By 2016 we had had enough of this, and decided to make a simple
cross-platform tool, called Jbuilder, that would allow external users
to build our code without having to adopt Jenga in full, and would
release us from the obligation of rewriting our builds in
<a href="https://github.com/ocaml/ocamlbuild">OCamlbuild</a>, then an emerging
standard for building OCaml projects.</p>

<p>Jbuilder understood the <code>jbuild</code> files that Jenga used for build
configuration and simply executed all required compilation commands in
a topological order. It wasn’t a build system in the usual sense: it
would simply re-execute all commands every time (instead of only
re-executing commands whose inputs have changed).</p>

<h3 id="jbuilder-gets-popular-and-becomes-dune"><strong>Jbuilder gets popular and becomes “Dune”</strong></h3>

<p>Then something strange happened. People <em>loved</em> Jbuilder. They started
using it to build not just our packages but their own, too. At first
we didn’t really understand this. Jbuilder wasn’t a real build system,
after all. It was just meant to be a little compatibility shim.</p>

<p>What we realized, eventually, was that the compelling feature was
speed. It turned out that Jbuilder was really a lot faster than the
other options, compiling our projects something like 5x faster than
OCamlbuild. That, plus the system being portable and easy to hack on,
were the things that mattered for early adopters and contributors.</p>

<p>So, in collaboration with <a href="https://www.linkedin.com/company/ocaml-labs-consultancy-ltd/?originalSubdomain=uk">OCaml
Labs</a>
(and today, <a href="https://tarides.com/">Tarides</a>), we started working on
making Jbuilder into more of a real build system, adding more of the
features that would be required for it to be a useful tool for the
broader open-source world.</p>

<p>And then, we ran into another problem. The name.</p>

<p>It turned out there was already a Borland Java IDE called
“<a href="https://en.wikipedia.org/wiki/JBuilder">JBuilder</a>.”  The system was
long defunct, and we even went to the trouble of finding the current
owners of the copyright and asking them if they’d mind us using the
name.  But, no dice.</p>

<p>So we decided to pick a new name.  We did <a href="https://discuss.ocaml.org/t/new-name-for-jbuilder">a bit of community
outreach</a>, and “Dune”
emerged as the winning name.</p>

<p>In the meantime, Dune’s popularity had exploded. People really began
using it in earnest, and we found ourselves in a somewhat ridiculous,
self-inflicted situation: we now had two full build systems to
maintain and support.</p>

<h3 id="jenga-vs-dune"><strong>Jenga vs. Dune</strong></h3>

<p>It became clear to us that Dune was the better system—a rethought
design, faster for most people’s builds, with wider adoption, and a
better API and user experience—which brought up the question “when
will we migrate Jane Street onto Dune?” Considering the provenance
of the tool this felt like an absurd question, but oh well, that’s
where we’d ended up.</p>

<p>The answer was inevitably “next year,” since the build systems team
had plenty to work on simply keeping up with our growing codebase. (In
2016, when Dune started, we had 4M lines of OCaml code; today we have
65M, plus 5M lines of Python.) A migration to Dune was daunting enough
that we never quite fully embarked on the mission. But it wasn’t <em>so</em>
daunting to keep us from estimating, aspirationally, that it might
well happen in the next six to twelve months.</p>

<p>It was only last year that we decided to finally rip the band-aid off.
We’d grown the build systems team to five full-time engineers, so we
felt that we finally had the strength to tackle this monster we’d been
afraid of for so long.</p>

<h3 id="dune-subsumes-jenga-within-jane-street"><strong>Dune subsumes Jenga within Jane Street</strong></h3>

<p>One large chunk of work we didn’t really appreciate in the beginning was
just making Dune scale to our huge codebase. Dune was quite fast
externally—but that’s in part because most users built relatively tiny
things compared to Jane Street’s 70M-line repository.</p>

<p>And Jenga hadn’t stood still, either. Over a decade, we had improved
the implementation to deal with the growth of our codebase. That
produced a system that was pretty well-optimized for scale, and
carefully tailored to our monorepo’s requirements.  Now, much of that
good optimization work had to be translated to Dune.</p>

<p>There were more mundane problems. The build system is called by a
variety of different workflows, notably, from three different
editors—Vim, Emacs, and VSCode.  Each one sadly had its own custom
integrations with Jenga that had to be migrated to use Dune one by
one.</p>

<p>But after more than a year of focused work we’re finally done: our
codebase is now built by Dune. At the time of the switch, Dune’s
performance was across the board as good or better than Jenga’s, and
much better in some cases. In particular, builds where most of the
build work is already in the cache (which is a surprisingly common
case!) have gotten 2-3x faster.</p>

<p>A lot of what we’ve done to improve Dune’s performance will get open
sourced, and some already has. We’re keen not to end up with two build
systems again—a Jane Street fork of Dune and the external Dune—so
we’re putting a lot of thought and energy into upstreaming our changes
where we can.</p>

<p>Dune is a very good foundation for doing new things. Some of that is
because Dune’s codebase is simpler and easier to work with; some
because we can just focus on one system. But, features like
distributed builds, shallow builds (also known as <a href="https://blog.bazel.build/2023/10/06/bwob-in-bazel-7.html#what-is-build-without-the-bytes">“builds without the
bytes”</a>),
and cached loading of the build graph itself are all closer in reach
than ever.</p>

<p>The exciting thing going forward is that we have a single system and
our velocity in improving it is going way up. The team has also grown
to 12 full-time engineers, in New York, London and Singapore, which
means we’re now working on Dune 24 hours a day.</p>

<p>It’s been a long and sometimes meandering path, and certainly hasn’t
unfolded the way we might have planned.  But we think that the end
result is good for OCaml’s build-system story, both within and beyond
Jane Street’s walls.</p>

        </div><p>Andrey joined Jane Street London in 2019, and in 2025 moved to the Singapore office to
grow the Tools and Compilers team in Asia. Before Jane Street, Andrey was an academic
at Newcastle University, UK, where he studied functional programming and asynchronous
circuits.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optical Frequency Combs (115 pts)]]></title>
            <link>https://www.nist.gov/topics/physics/optical-frequency-combs</link>
            <guid>42881408</guid>
            <pubDate>Thu, 30 Jan 2025 19:44:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nist.gov/topics/physics/optical-frequency-combs">https://www.nist.gov/topics/physics/optical-frequency-combs</a>, See on <a href="https://news.ycombinator.com/item?id=42881408">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  
  
      <h2><a id="Do"></a>What do optical frequency combs do?</h2><p>Optical frequency combs are specialized lasers that act like a ruler for light. They measure exact frequencies of light — from the invisible infrared and ultraviolet to visible red, yellow, green and blue light — quickly and accurately.</p><p>These Nobel Prize-winning devices fill an important technological gap. Optical frequency combs allow scientists to measure and control light waves as if they were radio waves. With optical frequency combs, technologies that employ radio and microwave frequencies — such as clocks, computers and communications — are now seamlessly connected to optical waves that oscillate at 10,000 times higher frequencies.&nbsp;</p><p>Optical frequency combs began as part of NIST scientists’ vision for better optical atomic clocks in the late 1990s. Today, NIST scientists are at the forefront of advancing these tools, and they have found uses beyond just timekeeping.&nbsp;</p><figure role="group">
<div data-video-embed-field-lazy="<div class=&quot;video-embed-field-provider-nist-kaltura video-embed-field-responsive-video&quot;><iframe width=&quot;854&quot; height=&quot;480&quot; frameborder=&quot;0&quot; allow=&quot;autoplay *; fullscreen *; encrypted-media *&quot; allowfullscreen=&quot;allowfullscreen&quot; src=&quot;https://www.kaltura.com/p/684682/embedPlaykitJs/uiconf_id/55674542?iframeembed=true&amp;amp;entry_id=1_ytre0aai&quot;></iframe>
</div>
" data-media-id="623316"><p><img alt="What a Comb Can Do" loading="lazy" src="https://cdnsecakmi.kaltura.com/p/684682/sp/68468200/thumbnail/entry_id/1_ytre0aai/width/1280" typeof="foaf:Image">
</p><p>What a Comb Can Do</p>
</div>
<figcaption>By making a simple measurement, the optical frequency comb has changed science. So what can a comb do? A lot—and the possibilities are constantly expanding.&nbsp;</figcaption>
</figure>

<h2><a id="Used"></a>How are optical frequency combs used?</h2><h3><a id="Timekeeping"></a>Timekeeping</h3><p>Optical frequency combs have been revolutionary for atomic clocks and timekeeping. Optical atomic clocks mark the passage of time by counting the natural oscillation of atoms in the same way a grandfather clock counts the swings of a pendulum. These atoms oscillate about 500,000 billion times a second — a much higher frequency than standard microwave-based atomic clocks. The current electronic systems that are used to measure frequency for microwave-based atomic clocks simply can’t count the optical “ticks.”</p><p>Because the teeth of an optical frequency comb are evenly spaced and precise, the comb acts like the gears of a clock, taking the faster optical frequencies and dividing them down to the lower-frequency microwave signals used by electronics and current atomic clocks. This lets scientists link optical atomic clocks’ higher-frequency “ticks” to microwave-based clocks’ lower-frequency “ticks” and electronics used by present day computers and communications systems.&nbsp;&nbsp;</p><figure role="group">
<div data-video-embed-field-lazy="<div class=&quot;video-embed-field-provider-nist-kaltura video-embed-field-responsive-video&quot;><iframe width=&quot;854&quot; height=&quot;480&quot; frameborder=&quot;0&quot; allow=&quot;autoplay *; fullscreen *; encrypted-media *&quot; allowfullscreen=&quot;allowfullscreen&quot; src=&quot;https://www.kaltura.com/p/684682/embedPlaykitJs/uiconf_id/55674542?iframeembed=true&amp;amp;entry_id=1_n1q29mvi&quot;></iframe>
</div>
" data-media-id="623441"><p><img alt="How frequency combs unite the EMF spectrum" loading="lazy" src="https://cdnsecakmi.kaltura.com/p/684682/sp/68468200/thumbnail/entry_id/1_n1q29mvi/width/1280" typeof="foaf:Image">
</p><p>How frequency combs unite the EMF spectrum</p>
</div>
<figcaption>Optical frequency combs can act like gears in a clock, allowing scientists to easily translate high frequency optical frequencies to lower frequency microwaves and vice versa. They can even help scientists translate between different optical frequencies.</figcaption>
</figure>

<p>With these “gears” carrying accurate signals between electronics, microwave-based tools and optical atomic clocks, scientists can use these powerful new clocks for faster, more accurate timekeeping systems. Optical atomic clocks may eventually redefine the second.</p><p>In order for these new clocks to be used for national and global timekeeping, scientists need to be able to compare signals from clocks across distances. Optical frequency combs can help achieve that too. NIST and JILA, a joint research institute of NIST and CU Boulder, used lidar to <a href="https://www.nist.gov/news-events/news/2021/03/nist-team-compares-3-top-atomic-clocks-record-accuracy-over-both-fiber-and" data-entity-type="node" data-entity-uuid="d37b61de-c674-43fb-bde7-0fd5106b0d24" data-entity-substitution="canonical" title="NIST Team Compares 3 Top Atomic Clocks With Record Accuracy Over Both Fiber and Air">send time signals through the air</a>, comparing two different kinds of atomic clocks.</p><p>Improved timekeeping systems are crucial in many technological applications, from stock trading to navigation. Global Positioning System (GPS) satellites and receivers send radio signals back and forth and use the timing of those signals to pinpoint a user’s location. GPS uses military time, and those clocks check their timing periodically with civilian clocks, like NIST’s optical atomic clocks and others like them around the world. Scientists hope to have optical atomic clocks on navigation satellites in the future, making the system even more precise and allowing GPS to pinpoint locations within centimeters.</p><p>Optical atomic clocks are also useful in the pursuit of quantum physics. By dividing time into incredibly small slices, scientists can use these clocks to measure previously undetectable changes, such as the gravitational red shift over short distance scales, the effect of gravity on the passage of time.&nbsp;</p> 
      <figure role="group">
<p><img alt="Strontium Lattice Optical Atomic Clock" height="467" loading="lazy" src="https://www.nist.gov/sites/default/files/styles/960_x_960_limit/public/images/2017/03/14/sr-lattice-optical-atomi-clock_opt.jpg?itok=HXxNTAHb" typeof="foaf:Image" width="700">





                    
          </p>
<figcaption>JILA’s strontium optical atomic clock was made possible by the frequency comb.&nbsp;<p><span>Credit:</span>
          
   The Ye group and Brad Baxley, JILA

        </p></figcaption>
</figure>

  <h3><a id="Astronomy"></a>Astronomy and cosmology</h3><p>Advanced optical atomic clocks also allow scientists to study the constants of nature beyond our own planet. For example, with the help of optical frequency combs, NIST scientists are using these improved clocks to <a href="https://www.nist.gov/news-events/news/2021/03/nist-team-compares-3-top-atomic-clocks-record-accuracy-over-both-fiber-and" data-entity-type="node" data-entity-uuid="d37b61de-c674-43fb-bde7-0fd5106b0d24" data-entity-substitution="canonical" title="NIST Team Compares 3 Top Atomic Clocks With Record Accuracy Over Both Fiber and Air">search for elusive dark matter</a>.&nbsp;</p><p>Optical frequency combs also are helping scientists search for exoplanets around distant stars. By tracking the exact colors of light from these stars, they can look for a wobble in the motion of a star that would indicate the presence of an <a href="https://www.nist.gov/news-events/news/2019/02/nist-astrocomb-opens-new-horizons-planet-hunting-telescope" data-entity-type="node" data-entity-uuid="4b26ab8b-2f0e-424a-aab9-a6ff95a31fa0" data-entity-substitution="canonical" title="NIST ‘Astrocomb’ Opens New Horizons for Planet-Hunting Telescope">Earth-like planet orbiting the star</a>.&nbsp;</p><h3><a id="Distance"></a>Precise distance measurement</h3><p>Optical frequency combs work over long distances. In 2013, <a href="https://www.nist.gov/news-events/news/2009/06/nists-lidar-may-offer-peerless-precision-remote-measurements" data-entity-type="node" data-entity-uuid="a67ba6ad-7b12-409d-83f4-cf66d5bebc45" data-entity-substitution="canonical" title="NIST's LIDAR May Offer Peerless Precision in Remote Measurements">NIST patented lidar</a>, a light detecting and ranging system that utilizes optical frequency combs to measure the distance to an object by analyzing light reflected from it.&nbsp;</p><p>This is already being used in a few research applications. NIST’s fire research laboratory has used frequency combs to <a href="https://www.nist.gov/news-events/news/2018/08/nist-shows-laser-ranging-can-see-3d-objects-melting-fires" data-entity-type="node" data-entity-uuid="bf08443d-abf7-490e-ae4a-135b9ca6d456" data-entity-substitution="canonical" title="NIST Shows Laser Ranging Can ‘See’ 3D Objects Melting in Fires">“see” through flames</a> and identify melting objects. Frequency comb-based lidar has also been used to <a href="https://www.nist.gov/news-events/news/2014/10/nist-laser-comb-system-maps-3d-surfaces-remotely-manufacturing-forensics" data-entity-type="node" data-entity-uuid="13a72782-6350-45b9-88b0-bc9e19724aa6" data-entity-substitution="canonical" title="NIST Laser Comb System Maps 3D Surfaces Remotely for Manufacturing, Forensics">create 3D maps</a>. Eventually, lidar using optical frequency combs could keep satellites and other space instruments flying in tight formations, acting as a single instrument.&nbsp;</p><h3><a id="Atmospheric"></a>Atmospheric science and greenhouse gases</h3><p>Atoms and molecules can be identified by which frequencies of light they absorb. Since optical frequency combs generate millions of frequencies in short pulses, they can be used to quickly and efficiently study the <a href="https://www.nist.gov/news-events/news/2006/03/frequency-comb-spectroscopy-proves-be-powerful-chemical-analysis-tool" data-entity-type="node" data-entity-uuid="f471f1e4-9968-4b53-93ac-27573b223f51" data-entity-substitution="canonical" title="&quot;Frequency Comb&quot; Spectroscopy Proves to be Powerful Chemical Analysis Tool">quantity, structure and dynamics of various molecules and atoms</a>.&nbsp;</p><p>This has many potential applications and is already being used to study pollution. Using optical frequency combs, scientists at JILA have studied short-lived molecules that link burning fossil fuels <a href="https://www.nist.gov/news-events/news/2016/10/jila-team-spots-elusive-intermediate-compound-atmospheric-chemistry" data-entity-type="node" data-entity-uuid="77d50b49-2a54-45bc-b3a7-561525b430ff" data-entity-substitution="canonical" title="JILA Team Spots Elusive Intermediate Compound in Atmospheric Chemistry">to air pollution</a>. The structure and dynamics of large and complex molecules can also be probed by frequency combs.&nbsp;</p><p>Scientists are also working on using optical frequency combs to detect trace amounts of various molecules in gases. In 2019, scientists and engineers from NIST, University of Colorado Boulder, and LongPath Technologies developed a dual-comb, portable spectroscopy system to detect minute methane emissions from oil and gas fields.</p> 
      <figure role="group">
<p><img alt="In this illustration, a gas well field has a circle on it. A dual-comb spectrometer at the center sends out laser light which bounces off mirrors, goes through a gas cloud and returns to the spectrometer for analysis." height="727" loading="lazy" src="https://www.nist.gov/sites/default/files/styles/960_x_960_limit/public/images/2018/03/19/18pml014_illustration_showing_dual-comb_methane_detection_2mb.jpg?itok=vyV0hmw5" title=" Dual-Comb Spectroscopy Detection of Trace Gases in the Field" typeof="foaf:Image" width="960">





                    
          </p>
<figcaption>Illustration showing how trace gases are detected in oil and gas fields using a mobile dual-frequency comb laser spectrometer. The spectrometer sits in the center of a circle which is ringed with retroreflecting mirrors. Laser light from the spectrometer (yellow line) passes through a gas cloud, strikes the retroreflector and is returned directly to its point of origin. The data collected are used to identify leaking trace gases (including methane), as well as leak locations and their emission rates.<p><span>Credit:</span>
          
  Stephanie Sizemore and Ian Coddington/NIST

        </p></figcaption>
</figure>

  <h3><a id="Medical"></a>Medical diagnostics</h3><p>The optical frequency comb may have applications in medicine as well. Just as it can be used in chemistry applications, the comb could be used to detect trace molecular indicators of disease. Scientists at JILA have been experimenting with combs to <a href="https://www.nist.gov/news-events/news/2008/02/optical-frequency-comb-can-detect-breath-disease" data-entity-type="node" data-entity-uuid="0a529357-4698-4d66-9a33-fa49f51ce31f" data-entity-substitution="canonical" title="Optical 'Frequency Comb' Can Detect the Breath of Disease">create breathalyzers that detect disease</a>.</p><h2><a id="Work"></a>How do optical frequency combs work?</h2><p>Frequency combs measure an unknown optical frequency by measuring the repetition rate of a continuous train of light pulses — which lies in the larger, easy-to-measure radio frequency range.</p><p>Light encompasses a broad spectrum of colors, which travel in waves. Each of those colors of light — from the invisible infrared and ultraviolet to red, blue or yellow visible light — has a corresponding frequency, or the number of wave peaks that pass a fixed point every second.&nbsp;</p><p>Radio waves and microwaves also travel at the speed of light, but their peaks are much farther apart, allowing modern electronics to count and track them easily.</p> 
      <p><img loading="lazy" src="https://www.nist.gov/sites/default/files/images/public_affairs/releases/frequency_comb1.jpg" width="500" height="278" typeof="foaf:Image">




                </p>
  <p>Optical frequency combs emit a continuous train of very brief, closely spaced pulses of light containing a million different colors, spanning from the invisible infrared through the visible and into the ultraviolet spectrum.&nbsp;</p><p>Thanks to a technique called “mode locking,” all of the frequencies in each pulse start in phase, in sync with each other.&nbsp;</p><p>The result resembles the teeth of a comb, separating each frequency into a distinct spike — hence the name of the device. The spacing of those teeth is very fine and exactly even, and they act like ticks on a ruler to measure light emitted by stars, atoms, other lasers, etc. with extreme precision and accuracy.&nbsp;</p> 
      <p><img loading="lazy" src="https://www.nist.gov/sites/default/files/images/public_affairs/releases/frequency_comb2.jpg" width="500" height="111" typeof="foaf:Image">




                </p>
  <h2><a id="Created"></a>How were optical frequency combs created?</h2><p>While they may sound simple, optical frequency combs are the result of decades of research and innovation, including significant contributions from NIST.</p><p>Physicists had been toying with the idea of this specialized laser since the 1970s, when Theodor Hänsch of the Max Planck Institute for Quantum Optics in Germany proposed a model for the first optical frequency comb while he was at Stanford University. Scientists knew that continuous lasers could only produce one color of light, but pulsed lasers could generate multiple colors. The shorter the pulse, the more frequencies the laser could produce.</p><p>Scientists needed to know the spacing between the “teeth” — the individual frequencies of light — of the comb. This required mode locking lasers. Mode locking forces all the colors in each pulse to start out in phase with each other.&nbsp;</p><p>In the mid-1990s, lasers made with titanium-doped sapphire crystals could produce these synchronized frequencies in femtoseconds — millionth of a billionth of a second pulses. &nbsp;</p> 
      <p><img loading="lazy" src="https://www.nist.gov/sites/default/files/images/public_affairs/releases/em_spectrum.gif" width="500" height="282" typeof="foaf:Image">




                </p>
  <p>Scientists also needed to calibrate the comb, to adjust it to a known frequency. Calibrating the comb would determine the offset frequency, or where the “ticks” on the comb start in an absolute sense. Hänsch realized that the best way to do that was to get the comb to produce an octave of frequencies, where the highest frequency was at least double the lowest frequency. Interfering a frequency with its double — called “self-referencing” — let scientists determine each frequency exactly.&nbsp;</p><p>That wasn’t possible until a team of scientists at Bell Laboratories created <a href="https://doi.org/10.1364/OL.25.000025">a hair-thin optical fiber</a> that could deliver more than an octave range of frequencies. This was a crucial development for optical frequency combs, and the final piece of the puzzle. With this optical fiber, Jan Hall and his colleagues at JILA could <a href="https://www.nist.gov/nist-and-nobel/jan-hall" data-entity-type="node" data-entity-uuid="0f020386-aafa-4bd2-b3ec-f19994ffc609" data-entity-substitution="canonical" title="Jan Hall">develop the self-referencing technique</a> they needed in 1999. They were the first to compare the operation of multiple femtosecond frequency combs, thereby demonstrating reproducibility.</p><p>Hall and his team of physicists at JILA, including Steven Cundiff, Scott Diddams, David Jones and Jun Ye, developed several other techniques that pushed the optical frequency comb closer to reality. In the late 1990s, the team developed a calibration system for the femtosecond laser, creating controllable, well-defined pulses containing thousands of colors. They had also improved stabilization for the laser, making it steady. In 2005, Hall and Hänsch shared part of the <a href="https://www.nobelprize.org/prizes/physics/2005/summary/">Nobel Prize in Physics</a> for their contributions to the optical frequency comb.&nbsp;</p><h2><a id="Next"></a>What’s next for optical frequency combs?</h2><p>Since 1999, NIST and JILA scientists <a href="https://www.osa-opn.org/home/articles/volume_32/january_2021/features/combs_of_light_on_a_chip/">have rapidly advanced the comb</a>, and are still at the forefront of optical frequency comb advancement and innovation. Today’s optical frequency combs span a greater range of electromagnetic frequencies than their earlier counterparts, from the deep infrared into the extreme ultraviolet. The ultraviolet comb can one day be used to drive transitions in the nucleus of atoms, which would unlock new possibilities for clocks and spectroscopy to study the nano world.&nbsp;</p> 
      <figure role="group">
<p><img alt="cryogenically cooled laser microresonator frequency comb" height="480" loading="lazy" src="https://www.nist.gov/sites/default/files/styles/480_x_480_limit/public/images/2020/06/22/MoilleCover_v2-1.jpg?itok=-VC2ROmQ" typeof="foaf:Image" width="339">





                    
          </p>
<figcaption>Experimental setup to generate a set of stable frequencies in a cryogenically cooled laser microresonator frequency comb. The ring-shaped microresonator, small enough to fit on a microchip, operates at very low laser power and is made from the semiconductor aluminum gallium arsenide.&nbsp;<p><span>Credit:</span>
          
  NIST

        </p></figcaption>
</figure>

  <p>Fiber laser frequency combs were the next significant advance in optical frequency combs. NIST and JILA scientists <a href="https://www.nist.gov/programs-projects/fiber-optic-frequency-comb-development" data-entity-type="node" data-entity-uuid="1bb8d337-ef36-4095-9a05-9d49fe1e252b" data-entity-substitution="canonical" title="Fiber-optic Frequency Comb Development">contributed significantly</a> to creating and refining these combs. Using common fiber components from telecommunications, these combs can operate continuously and are more compact than the original optical frequency comb. This makes them “workhorses” for metrology. They are currently used for numerous experiments (including clocks) in NIST and other laboratories, and in field applications like lidar and the aerospace industry. Fiber laser frequency combs are also being considered and tested to go into space. NIST scientists and engineers are continually improving fiber laser combs’ performance, power and durability to use in new applications and environments.&nbsp;</p><p>While many frequency combs currently are about the size of a shoebox and are widely available for use in and outside of laboratories, scientists have been working diligently to shrink them. Scientists have been working to produce optical frequency combs <a href="https://www.nist.gov/news-events/news/2011/10/future-comb-chip-nists-compact-frequency-comb-could-go-places" data-entity-type="node" data-entity-uuid="fa0e3d2e-9c24-4e62-aa1f-98ce1e742dae" data-entity-substitution="canonical" title="Future 'Comb on a Chip': NIST's Compact Frequency Comb Could Go Places">so small they can fit on a microchip</a>. &nbsp;</p><p>Many scientists hope that if frequency combs can fit on a microchip, they can have even greater commercial applications. Microcombs have the potential to improve communications systems, particularly within data centers and other high performance computing systems. The spectroscopy power of optical frequency comb could be incorporated into smartphones and wearable technology to monitor health.&nbsp;</p><p>Those applications are far in the future, however. Currently microcombs require tools outside of the chip to operate, such as power supplies, amplifiers and pump lasers. Many of these parts have been miniaturized, but integrating them all onto a single chip is very challenging. But perhaps the greatest hurdle to overcome is making these microcombs self-referencing, which is necessary to make the combs accurate.</p><p>Research is making progress to overcome those hurdles. Even if a complete comb-on-a-chip is never realized, microcombs are already finding uses in research. With miniature dual frequency combs, NIST has already developed a <a href="https://www.nist.gov/news-events/news/2019/05/nist-team-demonstrates-heart-next-generation-chip-scale-atomic-clock" data-entity-type="node" data-entity-uuid="b9dd8c04-bd6d-43b9-a522-9ca6649c2be7" data-entity-substitution="canonical" title="NIST Team Demonstrates Heart of Next-Generation Chip-Scale Atomic Clock">chip-scale atomic clock</a>. Scientists at NIST and their collaborators will continue to explore the vast potential for microcombs, fiber laser frequency combs and optical frequency combs.</p><h2>Latest News</h2>

  
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stats – macOS system monitor in your menu bar (404 pts)]]></title>
            <link>https://github.com/exelban/stats</link>
            <guid>42881342</guid>
            <pubDate>Thu, 30 Jan 2025 19:37:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/exelban/stats">https://github.com/exelban/stats</a>, See on <a href="https://news.ycombinator.com/item?id=42881342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Stats</h2><a id="user-content-stats" aria-label="Permalink: Stats" href="#stats"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/exelban/stats/raw/master/Stats/Supporting%20Files/Assets.xcassets/AppIcon.appiconset/icon_256x256.png"><img src="https://github.com/exelban/stats/raw/master/Stats/Supporting%20Files/Assets.xcassets/AppIcon.appiconset/icon_256x256.png" width="120"></a></p>
<p dir="auto"><a href="https://github.com/exelban/stats/releases"><img src="https://camo.githubusercontent.com/c0b7c8837b8f05167af0febd37cc3b775b8916072c3d1ce432c10fbbd8dc626f/68747470733a2f2f7365726869792e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f4769746875625f7265706f2f73746174732f6d656e757325334676322e332e322e706e673f7631" alt="Stats" data-canonical-src="https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/menus%3Fv2.3.2.png?v1"></a>
<a href="https://github.com/exelban/stats/releases"><img src="https://camo.githubusercontent.com/d8438fa217f3a8b4411eff42d5141cdc18e6087feb797a5477f3fc179597b342/68747470733a2f2f7365726869792e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f4769746875625f7265706f2f73746174732f706f7075707325334676322e332e322e706e673f7633" alt="Stats" data-canonical-src="https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/popups%3Fv2.3.2.png?v3"></a></p>
<p dir="auto">macOS system monitor in your menu bar</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Manual</h3><a id="user-content-manual" aria-label="Permalink: Manual" href="#manual"></a></p>
<p dir="auto">You can download the latest version <a href="https://github.com/exelban/stats/releases/latest/download/Stats.dmg">here</a>.
This will download a file called <code>Stats.dmg</code>. Open it and move the app to the application folder.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Homebrew</h3><a id="user-content-homebrew" aria-label="Permalink: Homebrew" href="#homebrew"></a></p>
<p dir="auto">To install it using Homebrew, open the Terminal app and type:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto">Stats is supported on the released macOS version starting from macOS 10.15 (Catalina).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Stats is an application that allows you to monitor your macOS system.</p>
<ul dir="auto">
<li>CPU utilization</li>
<li>GPU utilization</li>
<li>Memory usage</li>
<li>Disk utilization</li>
<li>Network usage</li>
<li>Battery level</li>
<li>Fan's control (not maintained)</li>
<li>Sensors information (Temperature/Voltage/Power)</li>
<li>Bluetooth devices</li>
<li>Multiple time zone clock</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQs</h2><a id="user-content-faqs" aria-label="Permalink: FAQs" href="#faqs"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How do you change the order of the menu bar icons?</h3><a id="user-content-how-do-you-change-the-order-of-the-menu-bar-icons" aria-label="Permalink: How do you change the order of the menu bar icons?" href="#how-do-you-change-the-order-of-the-menu-bar-icons"></a></p>
<p dir="auto">macOS decides the order of the menu bar items not <code>Stats</code> - it may change after the first reboot after installing Stats.</p>
<p dir="auto">To change the order of any menu bar icon - macOS Mojave (version 10.14) and up.</p>
<ol dir="auto">
<li>Hold down ⌘ (command key).</li>
<li>Drag the icon to the desired position on the menu bar.</li>
<li>Release ⌘ (command key)</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">What if you don't see sensors (M1 macs)?</h3><a id="user-content-what-if-you-dont-see-sensors-m1-macs" aria-label="Permalink: What if you don't see sensors (M1 macs)?" href="#what-if-you-dont-see-sensors-m1-macs"></a></p>
<p dir="auto">Sensors data on the first generation of M1 mac could be obtained only from HID services. It's disabled by default because it consumes a lot of CPU and energy. You can enable it in the Sensors module settings with the option <code>HID sensors</code>.</p>
<p dir="auto">It's only valid for M1 Apple Silicon macs. If you don't see sensors on another mac, please open an issue for that.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How to show the CPU frequency?</h3><a id="user-content-how-to-show-the-cpu-frequency" aria-label="Permalink: How to show the CPU frequency?" href="#how-to-show-the-cpu-frequency"></a></p>
<p dir="auto">The CPU frequency is available only on Intel-based macs. You need to have installed <a href="https://www.intel.com/content/www/us/en/developer/articles/tool/power-gadget.html" rel="nofollow">Intel Power Gadget</a> (IPG) for that. It allows receiving the CPU frequency from the IPG driver. There is no way to obtain a CPU frequency on Apple silicon macs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How to reduce energy impact or CPU usage of Stats?</h3><a id="user-content-how-to-reduce-energy-impact-or-cpu-usage-of-stats" aria-label="Permalink: How to reduce energy impact or CPU usage of Stats?" href="#how-to-reduce-energy-impact-or-cpu-usage-of-stats"></a></p>
<p dir="auto">Stats tries to be efficient as it's possible. But reading some data periodically is not a cheap task. Each module has its own "price". So, if you want to reduce energy impact from the Stats you need to disable some Stats modules. The most inefficient modules are Sensors and Bluetooth. Disabling these modules could reduce CPU usage and power efficiency by up to 50% in some cases.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why my issue was closed without any response?</h3><a id="user-content-why-my-issue-was-closed-without-any-response" aria-label="Permalink: Why my issue was closed without any response?" href="#why-my-issue-was-closed-without-any-response"></a></p>
<p dir="auto">Most probably because it's a duplicated issue and there is an answer to the question, report, or proposition. Please use a search by closed issues to get an answer.
So, if your issue was closed without any response, most probably it already has a response.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fan control</h3><a id="user-content-fan-control" aria-label="Permalink: Fan control" href="#fan-control"></a></p>
<p dir="auto">Fan control is in legacy mode. It does not receive any updates or fixes. It's not dropped from the app just because in the old Macs it works pretty acceptable. I'm open to accepting fixed or improvements (via PR) for this feature in case someone would like to help with that. But have no option and time to provide support for this feature.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported languages</h2><a id="user-content-supported-languages" aria-label="Permalink: Supported languages" href="#supported-languages"></a></p>
<ul dir="auto">
<li>English</li>
<li>Polski</li>
<li>Українська</li>
<li>Русский</li>
<li>中文 (简体) (thanks to <a href="https://github.com/chenguokai">chenguokai</a>, <a href="https://github.com/Tai-Zhou">Tai-Zhou</a>, and <a href="https://github.com/Jerry23011">Jerry</a>)</li>
<li>Türkçe (thanks to <a href="https://github.com/yusufozgul">yusufozgul</a>)</li>
<li>한국어 (thanks to <a href="https://github.com/escapeanaemia">escapeanaemia</a> and <a href="https://github.com/iamhslee">iamhslee</a>)</li>
<li>German (thanks to <a href="https://github.com/natterstefan">natterstefan</a> and <a href="https://github.com/aneitel">aneitel</a>)</li>
<li>中文 (繁體) (thanks to <a href="https://github.com/iamch15542">iamch15542</a> and <a href="https://github.com/jrthsr700tmax">jrthsr700tmax</a>)</li>
<li>Spanish (thanks to <a href="https://github.com/jcconca">jcconca</a>)</li>
<li>Vietnamese (thanks to <a href="https://github.com/xuandung38">HXD.VN</a>)</li>
<li>French (thanks to <a href="https://github.com/RomainLt">RomainLt</a>)</li>
<li>Italian (thanks to <a href="https://github.com/gmcinalli">gmcinalli</a>)</li>
<li>Portuguese (Brazil) (thanks to <a href="https://github.com/marcelochaves95">marcelochaves95</a> and <a href="https://github.com/pedroserigatto">pedroserigatto</a>)</li>
<li>Norwegian Bokmål (thanks to <a href="https://github.com/rubjo">rubjo</a>)</li>
<li>日本語 (thanks to <a href="https://github.com/treastrain">treastrain</a>)</li>
<li>Portuguese (Portugal) (thanks to <a href="https://github.com/AdamModus">AdamModus</a>)</li>
<li>Czech (thanks to <a href="https://github.com/mpl75">mpl75</a>)</li>
<li>Magyar (thanks to <a href="https://github.com/moriczr">moriczr</a>)</li>
<li>Bulgarian (thanks to <a href="https://github.com/zbrox">zbrox</a>)</li>
<li>Romanian (thanks to <a href="https://github.com/razluta">razluta</a>)</li>
<li>Dutch (thanks to <a href="https://github.com/ngohungphuc">ngohungphuc</a>)</li>
<li>Hrvatski (thanks to <a href="https://github.com/milotype">milotype</a>)</li>
<li>Danish (thanks to <a href="https://github.com/casperes1996">casperes1996</a> and <a href="https://github.com/aleksanderbl29">aleksanderbl29</a>)</li>
<li>Catalan (thanks to <a href="https://github.com/davidalonso">davidalonso</a>)</li>
<li>Indonesian (thanks to <a href="https://github.com/yooody">yooody</a>)</li>
<li>Hebrew (thanks to <a href="https://github.com/BadSugar">BadSugar</a>)</li>
<li>Slovenian (thanks to <a href="https://github.com/zigapovhe">zigapovhe</a>)</li>
<li>Greek (thanks to <a href="https://github.com/sudoxcess">sudoxcess</a> and <a href="https://github.com/vaionicle">vaionicle</a>)</li>
<li>Persian (thanks to <a href="https://github.com/ShawnAlisson">ShawnAlisson</a>)</li>
<li>Slovenský (thanks to <a href="https://github.com/martinbernat">martinbernat</a>)</li>
<li>Thai (thanks to <a href="https://github.com/apiphoomchu">apiphoomchu</a>)</li>
<li>Estonian (thanks to <a href="https://github.com/postylem">postylem</a>)</li>
<li>Hindi (thanks to <a href="https://github.com/patiljignesh">patiljignesh</a>)</li>
<li>Finnish (thanks to <a href="https://github.com/eightscrow">eightscrow</a>)</li>
</ul>
<p dir="auto">You can help by adding a new language or improving the existing translation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/exelban/stats/blob/master/LICENSE">MIT License</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California Law Enforcement Misused State Databases More Than 7k Times in 2023 (527 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023</link>
            <guid>42880807</guid>
            <pubDate>Thu, 30 Jan 2025 18:48:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023">https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023</a>, See on <a href="https://news.ycombinator.com/item?id=42880807">Hacker News</a></p>
Couldn't get https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[1996 "Authentic" Beta Pokemon Cards Exposed as 2024 Prints via Printer Dots (572 pts)]]></title>
            <link>https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421</link>
            <guid>42880704</guid>
            <pubDate>Thu, 30 Jan 2025 18:38:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421">https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421</a>, See on <a href="https://news.ycombinator.com/item?id=42880704">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="Many of the Pokemon playtest cards were likely printed in 2024">
      
      <meta itemprop="datePublished" content="2025-01-27T01:19:25Z">
        <meta itemprop="articleSection" content="Articles">
      <meta itemprop="keywords" content="prototype">
      


          <div id="post_1">
            <div>
              

                

              <p><span>
                  <time datetime="2025-01-27T01:19:25Z">
                    January 27, 2025,  1:19am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-30T20:21:34Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              
<h2><a name="p-695383-about-the-tracking-dots-1" href="#p-695383-about-the-tracking-dots-1"></a>About the tracking dots</h2>
<p>Most home and office printers add metadata to printed sheets in the form of very tiny yellow dots (sometimes called a machine identification code) that can’t be seen with the naked eye. The layout of the dots are different between printer brands and some don’t leave any at all. Information like serial number and sometime the print time is encoded in these dots. They can act as a “signature” for the printer that law enforcement uses as document forensic evidence (like in cases of forged currency).</p>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd.png" data-download-href="https://efour.b-cdn.net/uploads/default/9dc46977f44696c14a8056aee3cb3b70769819dd" title="Example of yellow tracking dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_469x485.png" alt="Example of yellow tracking dots" data-base62-sha1="mvFLXIMZajZuTKxFqhV5zci9v3f" width="469" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_469x485.png, https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_703x727.png 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_938x970.png 2x"></a></div>
<p>To view the dots you need to a magnifying glass or high resolution image and you need to adjust the colour channels to emphasize the yellow. More info: <a href="https://www.elitefourum.com/t/how-to-find-yellow-dots-in-prototypes-diy-guide/52544">How to Find Yellow Dots in Prototypes - DIY Guide</a></p>
<p>Important note:</p>
<blockquote>
<p>The dots are printed on by the kind of printers you and I would buy. Things like magazines, posters, <strong>and real Pokemon cards will not have dots</strong>. They are printed by large industrial offset printers.</p>
</blockquote>
<h2><a name="p-695383-how-to-read-the-dots-2" href="#p-695383-how-to-read-the-dots-2"></a>How to read the dots</h2>
<p>Different brands use different dot encoding patterns, and not all of these can be decoded. The companies don’t reveal this information so any known pattern has been cracked by someone from the general public.</p>
<p>The most well known of these is was broken in 2005 and often referred to as the <a href="https://w2.eff.org/Privacy/printers/docucolor/">“Xerox DocuColor” code</a> - named for the printer models used to discover it. Some brands other than Xerox also use this same pattern.</p>
<p>In this case, a 15x8 grid repeats like a checkerboard across the entire printed sheet. Each repeated grid has the same dots. The columns represent binary numbers For example, the eighth column encodes the year in binary. “2024” would appear as “011000” which is 24 in binary.</p>
<div>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/d01b574face250a2964b871f86659a2c739dbd79" title="Eevee example"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79_2_573x484.jpeg" alt="Eevee example" data-base62-sha1="tGZTi5G2uBiDrWYLjlAs9ZyX329" width="573" height="484" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79_2_573x484.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79_2_859x726.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/original/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79.jpeg 2x" data-dominant-color="8C8C8C"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/5/a57b3e4784b33462f8a02f3d0007399ea0b487bb.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a57b3e4784b33462f8a02f3d0007399ea0b487bb" title="Xerox DocuColor code"><img src="https://efour.b-cdn.net/uploads/default/original/3X/a/5/a57b3e4784b33462f8a02f3d0007399ea0b487bb.jpeg" alt="Xerox DocuColor code" data-base62-sha1="nBUPt1ufUzc2WdeVSU8YzNjXChd" width="512" height="384"></a></div>
</div>
<p>If you have a “Xerox DocuColor” style code, you can use <a href="https://www.elitefourum.com/u/mika">@mika</a>’s decoder implementation here to decode it: <a href="https://www.elitefourum.com/t/yellow-dot-decoder-fake-prototype-playtest-cards/52472">Yellow Dot Decoder - Fake Prototype Playtest Cards</a></p>
<h2><a name="p-695383-tracking-dots-on-the-prototype-pokemon-cards-3" href="#p-695383-tracking-dots-on-the-prototype-pokemon-cards-3"></a>Tracking dots on the “prototype” Pokemon cards</h2>
<p>A slew of cards that were originally believed to be early prototype and cards used for playtesting have been appearing in public auction starting in 2024. Most are believed to trace back to Takumi Akabane - someone who was involved in the early development of the TCG.</p>
<p>Because these cards are printed from a home/office printer, many of them have tracking dots. And many have a dot patter that suggest a print date in 2024.</p>
<div>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f" title="Beta playtest"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_690x442.jpeg" alt="Beta playtest" data-base62-sha1="5nrCp9FFDk9WkwaR8XFXfliakEf" width="690" height="442" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_690x442.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_1035x663.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_1380x884.jpeg 2x" data-dominant-color="B9BAB2"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/de5d65a6e3d94154fbf5260988dc25b96e1f7e04" title="Beta playtest dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_690x481.jpeg" alt="Beta playtest dots" data-base62-sha1="vJ86fiYoHH1H0EXweu4kSqZa2WM" width="690" height="481" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_690x481.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_1035x721.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_1380x962.jpeg 2x" data-dominant-color="7A6584"></a></div>
</div>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/fdd0d5e157c769690bac28dd8405c9721e2bb0c3" title="Dot pattern"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_690x372.jpeg" alt="Dot pattern" data-base62-sha1="Adme8fO7Dy03Egh5qOc8JZAy6fV" width="690" height="372" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_690x372.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_1035x558.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_1380x744.jpeg 2x" data-dominant-color="94788E"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f.png" data-download-href="https://efour.b-cdn.net/uploads/default/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f" title="Dot pattern decoded"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_535x485.png" alt="Dot pattern decoded" data-base62-sha1="6mBPlfx8Nvv55TW5IaL7PwOQxxJ" width="535" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_535x485.png, https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_802x727.png 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_1070x970.png 2x" data-dominant-color="0E0E0E"></a></div>
<p>Note the decoding result. We see this serial number reoccur across many cards.<br>
<img src="https://efour.b-cdn.net/uploads/default/optimized/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761_2_690x46.png" alt="image" data-base62-sha1="fYe7oXZEdkg8gPmcEM0rwhiUqSB" width="690" height="46" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761_2_690x46.png, https://efour.b-cdn.net/uploads/default/optimized/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761_2_1035x69.png 1.5x, https://efour.b-cdn.net/uploads/default/original/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761.png 2x" data-dominant-color="1D1D1D"></p>
<p>Checking the dots like the above example can be done using public images if they are sufficiently high resolution. Such as <a href="https://sales-history.fanaticscollect.com/items/PREMIER13649">this</a> signed one where the autograph was witnessed by CGC:</p>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f" title="1996 Pokemon Japanese Beta Playtest Mounted On Card Eevee AUTO CGC 10 GEM MINT"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_287x485.jpeg" alt="1996 Pokemon Japanese Beta Playtest Mounted On Card Eevee AUTO CGC 10 GEM MINT" data-base62-sha1="bcYu62gYh0s3KxacexhI8IaLPIj" width="287" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_287x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_430x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_574x970.jpeg 2x" data-dominant-color="948B8F"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a1b58f2c10a74dbcf8c49d18780d33f65677a66e" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_627x485.jpeg" alt="image" data-base62-sha1="n4xRqhvPAt1Qe20rYdLSTCXnFMO" width="627" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_627x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_940x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_1254x970.jpeg 2x" data-dominant-color="ACA9A9"></a></div>
<p>The dots reveal the 2024 year and the same printer serial number.</p>
<h2><a name="p-695383-variant-breakdown-4" href="#p-695383-variant-breakdown-4"></a>Variant breakdown</h2>
<p>The development of the Pokemon TCG was an iterative process, and many prototype and playtest variants have surfaced. Based on evidence inherent in the cards, this is what I can put together to the best of my ability</p>
<blockquote>
<p>Note: only Alpha playtest and Beta presentation have any documented evidence of their existence that predates 2024</p>
</blockquote>
<h2><a name="p-695383-alpha-prototypes-5" href="#p-695383-alpha-prototypes-5"></a>Alpha prototypes</h2>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a4512f1764633bde48c845a270f01c69f0e3e7a9" title="Alpha prototype (HQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_148x242.jpeg" alt="Alpha prototype (HQ)" data-base62-sha1="nrCeWgTHLWgdDdFG7VRaJxmO42J" width="148" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_148x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_222x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_296x484.jpeg 2x" data-dominant-color="ABAAAA"></a></div> <div><a href="https://efour.b-cdn.net/uploads/default/original/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad" title="Alpha prototypes (LQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_144x242.jpeg" alt="Alpha prototypes (LQ)" data-base62-sha1="2Pizsn0exyM8urlenOCeV7FIyPX" width="144" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_144x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_216x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_288x484.jpeg 2x" data-dominant-color="A7A7AA"></a></div>
<ul>
<li>there are no yellow tracking dots since they were printed in b&amp;w</li>
<li>2 variants, we can call them HQ and LQ: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/8">Many of the Pokemon playtest cards were likely printed in 2024 - #8 by pfm</a></li>
<li>easily distinguished by the background</li>
<li>there is one set of HQ, all other copies appear to be LQ</li>
<li>LQ appear to be copies of HQ, as they pick up the same printing artifacts seen on the HQ version.</li>
</ul>
<p>HQ: inconclusive.<br>
LQ: likely a copy of HQ, when the copy was made is inconclusive.</p>
<h2><a name="p-695383-alpha-prototypes-6" href="#p-695383-alpha-prototypes-6"></a>Alpha prototypes</h2>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/680a9e1ae5c0b31ed6bcd069cc417a75523123fb" title="Alpha prototype with 1996 dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_145x242.jpeg" alt="Alpha prototype with 1996 dots" data-base62-sha1="eQop6USu0XzLds97q8UbPQ5PMIr" width="145" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_145x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_217x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_290x484.jpeg 2x" data-dominant-color="8B8E7F"></a></div> <div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a67bca55b4ab4def189c6f31c4d90edb2482465d" title="Alpha prototype with Konica Minolta-style dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_148x242.jpeg" alt="Alpha prototype with Konica Minolta-style dots" data-base62-sha1="nKMtK7omUOX1qNSqi57rYW62RRz" width="148" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_148x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_222x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_296x484.jpeg 2x" data-dominant-color="A4A7A3"></a></div>
<ul>
<li>Most carry a unique dot pattern (different from beta) <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/18">Many of the Pokemon playtest cards were likely printed in 2024 - #18 by pfm</a></li>
<li>Likely from a Konica Minolta (Japanese brand) or Epson printer <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/421">Many of the Pokemon playtest cards were likely printed in 2024 - #421 by pfm</a></li>
<li>Some copies have BOTH alpha dots and “xerox” dots that can be dated. The hypothesis is that some alpha cards were scanned/copied (picking up alpha dots) and reprinted in 2024: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/143">Many of the Pokemon playtest cards were likely printed in 2024 - #143 by pfm</a></li>
<li>the alpha with inflated pop reports are more likely to have the double pattern (many trainers): <a href="https://www.cgccards.com/population-report/tcg/pok%C3%A9mon/2/test-prints-oddities-other/692/alpha-playtest-thick-lines/13952?populationID=1288703">https://www.cgccards.com/population-report/tcg/pokémon/2/test-prints-oddities-other/692/alpha-playtest-thick-lines/13952?populationID=1288703</a></li>
<li>a small handful have noticeably higher quality backs such as the three starters and this gyarados: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/59">Many of the Pokemon playtest cards were likely printed in 2024 - #59 by pfm</a></li>
</ul>
<p>High quality back:  dated to 1996 for the three starters<br>
Alpha pattern only: inconclusive.<br>
Double dot pattern: all observed copies so far have 2024 dots</p>
<h2><a name="p-695383-beta-playtest-7" href="#p-695383-beta-playtest-7"></a>Beta playtest</h2>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/dfa320261105937b9a5517ad96ed1567b5982003" title="Beta playtest (HQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_144x242.jpeg" alt="Beta playtest (HQ)" data-base62-sha1="vUnYbXZqNu0PKhDMj4dPJrOyOUX" width="144" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_144x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_216x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_288x484.jpeg 2x" data-dominant-color="8B9098"></a></div> <div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/d90c9616be1c6a6faf70715f6038128eae99431a" title="Beta playtest (LQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_148x242.jpeg" alt="Beta playtest (LQ)" data-base62-sha1="uY6zMhLB07I2TWjLaHOa4472LLs" width="148" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_148x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_222x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_296x484.jpeg 2x" data-dominant-color="9EA4B2"></a></div>
<ul>
<li>two variants, HQ and LQ: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/299">Many of the Pokemon playtest cards were likely printed in 2024 - #299 by pfm</a></li>
<li>HQ has yet to be observed with any dots</li>
<li>LQ has always been observed with 2024 dots</li>
<li>there only only appears to be 1 HQ beta per Pokemon, implying the vast majority of betas have 2024 dots</li>
<li>HQ betas have subtle traces of the alpha pattern on the back, suggesting that the HQ beta back was scanned/copied from a card that has the alpha print pattern - this implies the HQ betas were printed after the alphas and the authenticity is contingent on the authenticity of the alphas: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/745">Many of the Pokemon playtest cards were likely printed in 2024 - #745 by pfm</a></li>
<li>it is unlikely that the LQ are simply scans/copies of HQ given that not a single print artifact or dirt spec has yet been observed to be transferred from HQ to LQ</li>
</ul>
<p>HQ beta: inconclusive<br>
LQ beta: all observed copies so far have 2024 dots</p>
<h2><a name="p-695383-delta-prototypes-and-alpha-presentation-8" href="#p-695383-delta-prototypes-and-alpha-presentation-8"></a>Delta prototypes and Alpha presentation</h2>
<ul>
<li>I haven’t said too much about these yet but so far they all look similar to LQ beta and all observed copies so far have 2024 dots</li>
</ul>
<h2><a name="p-695383-beta-presentation-9" href="#p-695383-beta-presentation-9"></a>Beta presentation</h2>
<ul>
<li>No hi-res scan available yet, but I see no evidence of dots so far</li>
<li>They match well with the corocoro images and the print quality suggests a different printer was used for these than anything mentioned so far</li>
<li>inconclusive so far</li>
</ul>
<h2><a name="p-695383-acknowledgements-10" href="#p-695383-acknowledgements-10"></a>Acknowledgements</h2>
<p>Thanks to <a href="https://www.elitefourum.com/u/tediorso">@tediorso</a> for suggesting this avenue of investigation.<br>
Thanks to <a href="https://www.elitefourum.com/u/mika">@mika</a> <a href="https://www.elitefourum.com/u/linkdu83">@linkdu83</a> and <a href="https://www.elitefourum.com/u/humanforscale">@HumanForScale</a> for helping with data collection and analysis<br>
Thanks to <a href="https://www.elitefourum.com/u/banks">@BANKS</a> for working on information summary</p>
            </div>

            

                
          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Dyl"><span itemprop="name">Dyl</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:40:25Z">
                    January 27, 2025,  1:40am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:40:25Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Holy Shit</p>
<p><img src="https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExazV6dXMyZXkyajI2c2tjN21yc2c5b2ZyNm10ZHNpdXJnbGNqOGpqYyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/IO0gM5bNgCuZFWkQPF/giphy.webp" width="480" height="480" title="Episode 7 Wow GIF by Wrexham AFC - Find &amp; Share on GIPHY"></p>
            </div>

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Are any of these 2024 prints raw or have they been “authenticated”?</p>

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/casual"><span itemprop="name">casual</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:45:22Z">
                    January 27, 2025,  1:45am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:45:22Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Incredible research.</p>
<p>What a dangerous game people are playing buying these, pkonno really DID have a printer in his basement.</p>
            </div>

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/BANKS"><span itemprop="name">BANKS</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:04Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:04Z">
              <span itemprop="position">6</span>
              </span>
            </p>
            <p>Taking into consideration the personal stake that you have in these cards, you’re the goat</p>

            

          </div>
          <div id="post_7" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/lyleberr"><span itemprop="name">lyleberr</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:47Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:47Z">
              <span itemprop="position">7</span>
              </span>
            </p>
            <p>Does it have to be a scan or can you do this from a photo of a playtest? Does it have to have color?</p>

            

          </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/pfm"><span itemprop="name">pfm</span></a>
                
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:50Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:50Z">
              <span itemprop="position">8</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Another observation I want to mention.</p>
<p>The alpha prototypes were likely designed in a tool called ClarisWorks 4 which was available in 1995.</p>
<p>Here I emulated an old mac and ran it:</p>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/2/d/2d23a2c16129614341eb58c419ac14666af37fef.png" data-download-href="https://efour.b-cdn.net/uploads/default/2d23a2c16129614341eb58c419ac14666af37fef" title="clarisworks_pikachu"><img src="https://efour.b-cdn.net/uploads/default/original/3X/2/d/2d23a2c16129614341eb58c419ac14666af37fef.png" alt="clarisworks_pikachu" data-base62-sha1="6rjPNqWkOuMhmIMeGN9SReKng4f" width="644" height="484"></a></div>
<p>When looking at alpha prototypes there is clearly a set that is higher quality than the others. Consider Pikachu</p>

<p>Consider the dots in the background:</p>
<div data-masonry-gallery="">
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/9259b7e71edc6e0e223c70e24df2f16044c635a3" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_647x485.jpeg" alt="image" data-base62-sha1="kSFVKkv9znEPcLJf4jwyzwKkEBd" width="647" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_647x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_970x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_1294x970.jpeg 2x" data-dominant-color="E0DFE3"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_637x485.jpeg" alt="image" data-base62-sha1="vUvkM1DuN5goEgm2cpCMK7lOZTd" width="637" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_637x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_955x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_1274x970.jpeg 2x" data-dominant-color="DDDCE2"></a></div>
</div>
<p>Also note the shared print artifact that goes through the “Pikachu” text.</p>
<p>It’s not limited to Pikachu.</p>

            </div>

            

          </div>
          <div id="post_9" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/casual"><span itemprop="name">casual</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:53Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:53Z">
              <span itemprop="position">9</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Personally, I think it makes sense to go after the grading companies here</p>
<p>This is a disaster</p>
<p>They should be fully refunding people</p>
            </div>

            

          </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/pfm"><span itemprop="name">pfm</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:47:13Z">
                    January 27, 2025,  1:47am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:47:13Z">
              <span itemprop="position">10</span>
              </span>
            </p>
            

            

          </div>
          <div itemprop="comment" id="post_11" itemscope="" itemtype="http://schema.org/Comment"><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/da4481234122cefc0f58c78442cae136fb5e1f6c" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_245x242.jpeg" alt="image" data-base62-sha1="v8SReEYq9rNAiDadtyZu2hidIHW" width="245" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_245x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_367x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_490x484.jpeg 2x" data-dominant-color="876E78"></a></div>
          <div id="post_12" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/ddk"><span itemprop="name">ddk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:49:58Z">
                    January 27, 2025,  1:49am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:49:58Z">
              <span itemprop="position">12</span>
              </span>
            </p>
            <p>The tragic irony of pfm believing in these cards for months only to be the one to discover the truth behind them…</p>

            

          </div>
          <div id="post_13" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Proud of you <a href="https://www.elitefourum.com/u/pfm">@pfm</a>. You didn’t have to release this and yet you did all the same. You solved one of the biggest mysteries this hobby has seen in years. If anyone was going to do it, it was going to be you.</p>

            

          </div>
          <div id="post_14" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Dirge"><span itemprop="name">Dirge</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:51:17Z">
                    January 27, 2025,  1:51am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:51:17Z">
              <span itemprop="position">14</span>
              </span>
            </p>
            <div itemprop="text">
              <p>I am stunned and impressed beyond words. Holy shit.</p>
<p>Does this mean they’re all fakes or just some of them?</p>
            </div>

            

          </div>
          <div id="post_15" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/BANKS"><span itemprop="name">BANKS</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:51:21Z">
                    January 27, 2025,  1:51am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:51:21Z">
              <span itemprop="position">15</span>
              </span>
            </p>
            <p>That’s what separates Greek heroes from timmys, PFM went the distance</p>

            

          </div>
          <div id="post_16" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Will"><span itemprop="name">Will</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:51:35Z">
                    January 27, 2025,  1:51am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:51:35Z">
              <span itemprop="position">16</span>
              </span>
            </p>
            <p>Great analysis as always pfm, amazing stuff</p>

            

          </div>
          <div id="post_17" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Alec"><span itemprop="name">Alec</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:54:08Z">
                    January 27, 2025,  1:54am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:54:08Z">
              <span itemprop="position">17</span>
              </span>
            </p>
            <p>I think the most reasonable take is some are certainly not 1995/1996 playtest cards as we’ve been led to believe, and the rest are at least questionable.</p>

            

          </div>
          <div id="post_18" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/pfm"><span itemprop="name">pfm</span></a>
                
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:56:47Z">
                    January 27, 2025,  1:56am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:56:47Z">
              <span itemprop="position">18</span>
              </span>
            </p></div>
            <div itemprop="text">
              
<p>I’m still digging into it. All I can say is that I’ve seen evidence of 3 different printers for the coloured variants and one of them has 2024 in the metadata (majority of the beta). The majority of the alpha have a different set of print dots.</p>
<p>for example:<br>
</p><div><a href="https://efour.b-cdn.net/uploads/default/original/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/47a6b0190821d32e8a3d909e6359843596a7a21c" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_690x395.jpeg" alt="image" data-base62-sha1="adR1HS0CPjkcR1XaLMVbIVDHeXy" width="690" height="395" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_690x395.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_1035x592.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_1380x790.jpeg 2x" data-dominant-color="D38FCD"></a></div>
<p>I have a guess at the printer brand. I don’t believe print time is encoded but the printer model should be in there.</p>
<p>In other words:</p>
<ul>
<li>High quality beta = no dots</li>
<li>Low quality beta = dots in the OP</li>
<li>Alpha playtest = dots above</li>
</ul>
<p>This is my general observation, there are exceptions</p>
            </div>

            

          </div>
          <div itemprop="comment" id="post_19" itemscope="" itemtype="http://schema.org/Comment">
              <p>Well there you go. I won’t speak in absolutes as it still seems like there is some information to come, but if this proves to reflect the entirety of the playtest cards it can’t be seen as anything other than an epic failure of CGC’s authentication practices.</p>

<p>This was the original problem with the cards, that we had to rely on “trust me bro” from CGC and Akabane, with none of the in-depth analysis that CGC is known for. Because they didn’t do it, pfm had to, and digs up very questionable results.</p>
<p>I am hard pressed to imagine a more disingenuous and exploitative process. It appears like these cards and their release were deliberately engineered to fool the community. CGC at best was negligent in their duty as a grading company, and at worst was complicit in the process.</p>
            </div>
          <div id="post_20" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Dirge"><span itemprop="name">Dirge</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T02:01:24Z">
                    January 27, 2025,  2:01am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T02:01:24Z">
              <span itemprop="position">20</span>
              </span>
            </p>
            <p>Should I be impressed that you managed to do all this or should I be horrified that CGC didn’t have the means to catch this?</p>

            

          </div>
          <div id="post_21" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>At times like these, I’m glad I’m risk adverse. I wanted to get some but there were too many unanswered questions.</p>

            

          </div>
    </div></div>]]></description>
        </item>
    </channel>
</rss>