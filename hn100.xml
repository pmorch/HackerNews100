<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 30 Aug 2025 14:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Hacker News em dash user leaderboard pre-ChatGPT (174 pts)]]></title>
            <link>https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html</link>
            <guid>45071722</guid>
            <pubDate>Sat, 30 Aug 2025 03:40:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html">https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html</a>, See on <a href="https://news.ycombinator.com/item?id=45071722">Hacker News</a></p>
Couldn't get https://www.gally.net/miscellaneous/hn-em-dash-user-leaderboard.html: Error: unable to verify the first certificate]]></description>
        </item>
        <item>
            <title><![CDATA[Why Romania excels in international Olympiads (184 pts)]]></title>
            <link>https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/</link>
            <guid>45070793</guid>
            <pubDate>Sat, 30 Aug 2025 00:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/">https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/</a>, See on <a href="https://news.ycombinator.com/item?id=45070793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><span>Olympiads are international student intellectual competitions in which students from across the world go toe-to-toe answering questions in mathematics, physics, informatics, chemistry, and more. The best performers tend to be from countries like China, the United States, India, and Japan. But, somehow, the southeastern European country of Romania also frequently tops the list.</span></p>
<p><span>Since 2020, Romania’s performance in the International Mathematical Olympiad (IMO) has been nothing short of amazing. In 2022, Romania came in fifth overall, fourth in 2023, and twelfth in 2024. In 2023, Romania placed fourth globally and first in Europe at the International Physics Olympiad, seventeenth globally and third in Europe at the International Olympiad in Informatics, sixth globally and second in Europe in the European Girls’ Mathematical Olympiad, first in the Balkan Mathematical Olympiad—which also included France, Italy, and the United Kingdom—and first in the Central European Olympiad in Informatics. Romania also performed well in the International Chemistry Olympiad and many others.</span></p>
<p><span>It’s an understatement to call Romania’s skill in Olympiads merely “overperformance”. Romania’s lackluster performance in international assessments and its relatively small population size of just over 19 million people makes the things they do in Olympiads downright miraculous.</span></p>
<p><span>Average Romanian educational performance is unimpressive. Romanian youth routinely perform below the average of OECD countries and near the bottom of the pack of European nations. Romania has a poor-to-mediocre showing whether you include or exclude migrants from the calculations, and its scores on assessments like the PISA aren’t low due to being tainted by bias in the examinations. Romania genuinely underperforms. But underperformance is not the impression you would get if you only knew of Romanian education from Olympiads.</span></p>
<p><span>One possibility is that Romanian students have more variable performance on international assessments than students in other countries. No dice: </span><a href="https://www.oecd.org/en/about/programmes/pisa.html"><span>they</span></a> <a href="https://timssandpirls.bc.edu/timss-landing.html"><span>aren’t</span></a> <a href="https://www.iea.nl/studies/iea/pirls"><span>much</span></a><span> more variable than the student populations in other countries, and a handful of comparably-sized nations with worse Olympiad performance are more variable. Another possibility is that, for some reason, there’s a fat right tail in Romanian educational performance. If this is true, it just doesn’t show up in any existing data. Given the fact that international assessments indicate Romania’s sampling tends to be population-representative, we should have a strong prior against this possibility. Romanian test scores tend to be distributed along a symmetrical bell curve.&nbsp;</span></p>
<p><span>Yet another possibility is that Romania has an undersampled ethnic group that overperforms, but whose schools aren’t tested very well. The only group this might be is Romanian Jews and using them as an explanation is problematic for two reasons. The first is that there are too few to realistically explain Romanian Olympiad performance. The second is that we know the identities of Olympiad participants from Romania, and they don’t seem to be Jewish.</span></p>
<p><span>Something else, something more mysterious, explains why Romania is such an outlier in international intellectual competitions. That thing is, in fact, the unique design of the Romanian educational system.</span></p>
<p><span>In the late 19</span><span>th</span><span> century, Romanian prince regnant Alexandru Ioan Cuza attempted to raise the status of the nation by instituting a mass literacy campaign centered around building free schools that children were compelled to attend. This effort was largely a failure, with literacy failing to break 50% by the 1930s. But World War II precipitated change. In 1948, Romania’s new governing communist party began to bring about serious educational reform at a breakneck pace.The Education Law of 1948 was passed to provoke a military-grade offensive against illiteracy, involving the mass participation of the literate from all walks of life in uplifting the poor, the abandoned, and those who simply shunned education. By the end of the 1950s, illiteracy was practically eradicated among Romania’s youth.</span></p>
<p><span>The education system that existed in Romania’s communist period was modeled on the system in place in the Soviet Union, and it included a fair helping of political propaganda in addition to physical labor. The system also overproduced schools, resulting in shoddy but widely available facilities dotting the country. Like the Soviet school system, Romania’s was marked by increasing lengths of compulsory education, poor availability of qualified teachers and educational supplies, high budgetary costs, and an extreme level of credential inflation.</span></p>
<p><span>After the fall of communism, the new democratic government went on to shutter many of these schools and to immediately lower compulsory schooling requirements to put an end to the bureaucratic nightmare that Soviet influence had saddled the country with. In the following years, how Romania wished to ration scarce governmental resources for education was a matter of intense debate, and out of that debate came a strong sentiment that, whatever the system, Romanian education would be structured competitively.</span></p>
<p><span>Nowadays, the most prestigious Romanian high schools are the National Colleges, or </span><i><span>Colegiu Național</span></i><span>. These schools are often international and frequently uphold old educational traditions sometimes dating back more than a century. Below these schools are the </span><i><span>Liceu Teoretic</span></i><span>, which are the norm, offering standard educations. Romania also has three military colleges—</span><i><span>Colegiu Militar</span></i><span>—managed directly by the Ministry of National Defense. There are also schools focused on service, technical schools, vocational schools, and apprenticeship programs. The brightest students get their pick among these schools after they take the national placement test, the </span><i><span>Evaluarea Națională, </span></i><span>when they are graduating the 8</span><span>th</span><span> grade around ages fourteen to fifteen.</span></p>
<p><span>The high school placement test is a standardized test covering Romanian language and literature as well as mathematics. Performance on the examination is reported publicly when students are issued a score on a one-to-ten scale with precision to two decimal places. A student who receives a high grade—say 9.65—would have their pick from most any school, whereas a student scoring 5.00 or below would usually be constrained to a less academically-focused form of education like a vocational program. Most students elect to go to the best school they are able to test into, and so the degree of sorting across schools is very high. To make this setup even more extreme, there is also often—but not universally—sorting </span><i><span>within</span></i><span> schools, as students select into educational tracks. This is done directly when applying to schools.</span></p>
<p><span>At the end of the Romanian high school experience, there is a graduation test, the </span><i><span>Bacalaureat</span></i><span>, or </span><i><span>bac</span></i><span>. This test is marked like the entrance examination and, to pass, students must obtain a score of at least five in the subjects they have elected to take. This testing includes written and oral examinations, assessments of foreign language and computer skills, and, for ethnic minorities, assessment of their skill with their maternal language other than Romanian. The need for a given score on this examination can range from requiring just passing to requiring a high score, depending on the university one intends to attend, if that is their goal.</span></p>
<p><span>The design of Romania’s educational system makes it perhaps the most stratified educational system in the world. The fact that they have a centralized repository containing all student and teacher educational data makes their system perfect for a high-powered evaluation of exactly what happens when a country opts to hyper-stratify education.</span></p>
<p><span>One of the cruel parts of the Romanian system is that, though sorting is nationally available, students do not have equal opportunities to sort. Students located in smaller towns have fewer high school options to select from unless they’re among the few who opt into a military academy, which means joining the military. The extent of sorting is far more intense in areas with larger numbers of schools. In a </span><a href="https://direct.mit.edu/rest/article-abstract/doi/10.1162/rest_a_01438/120190/School-Choice-Student-Sorting-and-Academic"><span>recent paper</span></a><span>, the Romanian economist Andrei Munteanu provided an illustration of how this works: essentially, the fewer schools in a locale, the more each individual school contains students with a wider range of ability and, the more schools in a locale, the more each individual school will be stratified into low, middle, or high ability.&nbsp;</span></p>
<p><span>This combined sorting between schools and tracks means that low-ability students get stuck with other low-ability students, and high-ability students are surrounded by other high-ability students. In effect, peer groups throughout high school are extremely homogeneous. This matters because then low-performing students drag down low-performing students, and high performers cause each other to rise. Romania’s educational system has causal peer impacts on student performance on the graduation test that are very large in both directions, but primarily where there are opportunities for sorting to take place.</span></p>
<figure id="attachment_7695" aria-describedby="caption-attachment-7695"><img decoding="async" src="https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy.png" alt="" width="3600" height="2400" srcset="https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-300x200.png 300w, https://pdmedia.b-cdn.net/2025/08/sIOqtz0e-SchoolSortBusy-1024x683.png 1024w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-768x512.png 768w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-1536x1024.png 1536w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-2048x1365.png 2048w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-450x300.png 450w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy-900x600.png 900w, https://pdmedia.b-cdn.net/2025/08/SchoolSortBusy.png 3600w" sizes="(max-width: 999px) 96vw, (max-width: 1359px) 80vw, (max-width: 1519px) 75vw, 1175px"><figcaption id="caption-attachment-7695">Jordan Lasker/The more schools a town has the more intense the sorting of students is. Graduation scores are positively impacted for top performers and negatively for bottom performers with more intense sorting.</figcaption></figure>
<p><span>But peer effects are not everything to Romania’s exceptional Olympiad performance; they are just the fertile ground in which exceptional performance is fostered. The next part has to do with teachers. Like students, Romania’s teachers must take tests to be able to do what they want to do. Teachers naturally prefer to lecture smarter students, and the smartest teachers have their pick of the schools, and even of the tracks. In a paper with extremely robust results, researchers from the last decade </span><a href="https://www.aeaweb.org/articles?id=10.1257/aer.103.4.1289"><span>described</span></a><span> this as such:</span></p>
<blockquote><p><i><span>[Teachers] with higher certification standards are more likely to work at better-ranked schools. This sorting persists even within schools as one moves from a weaker to a stronger track, and even within tracks as one moves from a weaker to a stronger class.</span></i></p></blockquote>
<p><span>The best teachers also opt into towns with more schools. It’s apparent, then, that teachers prefer teaching in the highest-achieving places they can be, both within and between towns. The effect of teacher-student ability pairing is accentuated even more by incentives to compete. The government of Romania is not unique in providing monetary rewards for those who win Olympiads, those who teach winners of Olympiads, or those schools Olympiad winners attend, but they are unique in having all the previously-mentioned institutional characteristics </span><a href="https://archive.md/ki6Do"><span>on top of</span></a><span> providing comprehensive monetary incentives for Olympiad achievement.&nbsp;</span></p>
<p><span>Romania’s immense success in Olympiads and the widely recognized importance of Olympiad wins for signaling student human capital has also spawned a small number of private schools that advertise their prominence and tutoring capabilities. Many teachers also recommend to parents that they obtain additional tutoring for their brighter pupils, and tutoring services are commonplace. The commonality of tutoring for Olympiad winners is a global constant, whereas the things distinguishing Romania are not.</span></p>
<p><span>Two notable factors do not increase performance in the same direction. These are very slight decrements in funding allocated to the highest-ability schools, and when parents reduce the time they spend helping their students with homework, conditional on their kids matching into better schools. Another potential factor that militates against the synchrony of resource allocation in Romania is that children in more selective schools report feeling marginalized because they realize that they’re not as strong of students as they believed. The decrements in funding are likely to be unproblematic, because higher-scoring schools tend to be larger and more urban, lending them economies of scale. Due to this, they may have effectively more funding.</span></p>
<p><span>With all the pieces on the board, the key to Romania’s Olympiad success is three-fold: put the best students in the same classrooms, put the best teachers with the best students, and then incentivize schools, teachers, and students each to win Olympiads.</span></p>
<p><span>This system has proved amazingly fruitful. Given its underlying human capital, the poverty from its communist legacy, and its modest population size, Romania should not perform the way it does in academic Olympiads. And yet it does</span><i><span>. </span></i><span>The trade-off for Romania, however, is palpable.</span></p>
<p><span>Large portions of Romania’s Olympiad winners leave the country. Because Romania is a member state of the European Union, the people the country has put great effort into training and credentialing are easily able to leave the country and acquire jobs elsewhere.</span></p>
<p><span>Losing the right tail to brain drain is damaging for many countries, but it’s arguably worse for Romania because its educational system is so zero-sum: the top performers do better, while the low-performers do worse. This sorting does not “lift all boats,” as it were. In Romania, the system makes for an incredibly well-trained right tail and a neglected left tail, and that left tail might hurt more than the right tail is helped, if effects on test scores are any indication. On its own, Romania’s system might be a stellar boon to the country. But with free movement of talent between countries, Romania ends up subsidizing talent discovery for other countries with less apt educational systems.&nbsp;</span></p>
<p><span>Most of the growth we see around us is due to the innovations of the right tail, and if they do better, we all do better. Though I doubt Romania’s schooling raises the intelligence</span> <span>of the right tail, even raising aptitude is worth something, because we must get capable people to the frontiers of their respective fields in order to innovate, and Romania has fostered a system that seems to do just that. Moreover, even if Olympiad training does not make those on the right tail more capable but instead simply prepares them better, then it can still</span> <span>have large, socially beneficial effects simply through providing Romania’s highly capable people with a means of having their talents recognized internationally.&nbsp;</span></p>
<p><span>But these benefits are returned only very indirectly to Romania, if at all on net. Rather than changing Romania’s educational system or closing the borders, the right solution is for more nations to choose to be like Romania, getting a lot more juice out of their smart kids by designing a system just for them.</span></p>
<p>Jordan Lasker is a bioinformatician. He writes on his <a href="https://www.cremieux.xyz/">website</a> and you can follow him at <a href="https://x.com/cremieuxrecueil">@cremieuxrecueil</a>.</p>


            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Theoretical Limitations of Embedding-Based Retrieval (116 pts)]]></title>
            <link>https://arxiv.org/abs/2508.21038</link>
            <guid>45068986</guid>
            <pubDate>Fri, 29 Aug 2025 20:25:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2508.21038">https://arxiv.org/abs/2508.21038</a>, See on <a href="https://news.ycombinator.com/item?id=45068986">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2508.21038">View PDF</a>
    <a href="https://arxiv.org/html/2508.21038v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Vector embeddings have been tasked with an ever-increasing set of retrieval tasks over the years, with a nascent rise in using them for reasoning, instruction-following, coding, and more. These new benchmarks push embeddings to work for any query and any notion of relevance that could be given. While prior works have pointed out theoretical limitations of vector embeddings, there is a common assumption that these difficulties are exclusively due to unrealistic queries, and those that are not can be overcome with better training data and larger models. In this work, we demonstrate that we may encounter these theoretical limitations in realistic settings with extremely simple queries. We connect known results in learning theory, showing that the number of top-k subsets of documents capable of being returned as the result of some query is limited by the dimension of the embedding. We empirically show that this holds true even if we restrict to k=2, and directly optimize on the test set with free parameterized embeddings. We then create a realistic dataset called LIMIT that stress tests models based on these theoretical results, and observe that even state-of-the-art models fail on this dataset despite the simple nature of the task. Our work shows the limits of embedding models under the existing single vector paradigm and calls for future research to develop methods that can resolve this fundamental limitation.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Orion Weller [<a href="https://arxiv.org/show-email/fae50c49/2508.21038" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 28 Aug 2025 17:43:53 UTC (195 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do the simplest thing that could possibly work (837 pts)]]></title>
            <link>https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/</link>
            <guid>45068091</guid>
            <pubDate>Fri, 29 Aug 2025 19:05:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/">https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/</a>, See on <a href="https://news.ycombinator.com/item?id=45068091">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>When designing software systems, do the simplest thing that could possibly work.</p>
<p>It’s surprising how far you can take this piece of advice. I genuinely think you can do this <em>all the time</em>. You can follow this approach for fixing bugs, for maintaining existing systems, and for architecting new ones.</p>
<p>A lot of engineers design by trying to think of the “ideal” system: something well-factored, near-infinitely scalable, elegantly distributed, and so on. I think this is entirely the wrong way to go about software design. Instead, spend that time understanding the current system deeply, then do the simplest thing that could possibly work.</p>
<h3>Simple can be underwhelming</h3>
<p><a href="https://www.seangoedecke.com/good-system-design">System design</a> requires competence with a lot of different tools: app servers, proxies, databases, caches, queues, and so on. As they gain familiarity with these tools, junior engineers naturally want to use them. It’s fun to construct systems out of many different components! And it feels very satisfying to draw boxes and arrows on a whiteboard - like you’re doing real engineering.</p>
<p>However, as with many skills, real mastery often involves learning when to do less, not more. The fight between an ambitious novice and an old master is a well-worn cliche in martial arts movies: the novice is a blur of motion, flipping and spinning. The master is mostly still. But somehow the novice’s attacks never seem to quite connect, and the master’s eventual attack is decisive.</p>
<p>In software, this means that <a href="https://www.seangoedecke.com/great-software-design">great software design looks underwhelming</a>. It doesn’t look like anything much is happening at all. You can tell you’re in the presence of great software design because you start having thoughts like “oh, I didn’t realise the problem was that easy” or “oh nice, you don’t actually have to do anything difficult”.</p>
<p><a href="https://github.com/defunkt/unicorn">Unicorn</a> is great software design, because it delivers all the most important guarantees in a web server (request isolation, horizontal scaling, crash recovery) by leaning on Unix primitives<sup id="fnref-1"><a href="#fn-1">1</a></sup>. The industry-standard Rails REST API is great software design, because it gives you exactly what you need for a CRUD app in the most boring way possible. I don’t think any of these are impressive <em>software</em>. But they’re impressive feats of <em>design</em>, because <strong>they do the simplest thing that could possibly work</strong>.</p>
<p>You should do that too! Suppose you’ve got a Golang application that you want to add some kind of rate limiting to. What’s the simplest thing that could possibly work? Your first idea might be to add some kind of persistent storage (say, Redis) to track per-user request counts with a leaky-bucket algorithm. That would work! But do you need a whole new piece of infrastructure? What if instead you kept those per-user request counts in-memory? Sure, you’d lose some rate limiting data when the application is restarted, but does that matter? Actually, are you sure your edge proxy<sup id="fnref-2"><a href="#fn-2">2</a></sup> doesn’t support rate limiting already? Could you just write a couple of lines in a config file instead of implementing the feature at all?</p>
<p>Maybe your edge proxy doesn’t support rate limiting. Maybe you can’t track it in-memory because you have too many server instances running in parallel, so the tightest rate limit you could enforce that way is too wide. Maybe it’s a dealbreaker if you ever lose rate limiting data, because people are hammering your service <em>that</em> hard. In that case, the simplest thing that could possibly work is adding persistent storage, so you should go and do that. But if you could do one of the easier approaches, wouldn’t you want to?</p>
<p>You really can build a whole application from scratch this way: start with the absolute simplest thing, and then only extend it when you have new requirements that force you to. It sounds silly, but it works. Think of it as taking <a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it">YAGNI</a> as the ultimate design principle: above single-responsibility, above choosing the best tool for the job, and above “good design”.</p>
<h3>What’s wrong with doing the simplest thing?</h3>
<p>Of course, there are three big problems with always doing the simplest thing that could possibly work. The first is that, by not anticipating future requirements, you end up with an inflexible system or a <a href="http://laputan.org/mud/">big ball of mud</a>. The second is that it’s not clear what “simplest” means, so at worst I’m saying “to design well, always do good design”. The third is that you ought to be building systems that can <em>scale</em>, not systems that just work right now. Let’s take those objections in order.</p>
<h4>Big balls of mud</h4>
<p>To some engineers, “do the simplest thing that could possibly work” sounds like I’m telling them to stop doing engineering. If the simplest thing is usually a quick kludge, does that mean this advice will inevitably lead to a complete mess? We’ve all seen codebases with hacks stacked on top of hacks, and they definitely don’t look like good design.</p>
<p>But are hacks simple? I actually don’t think so. The problem with a hack or a kludge is precisely that it <em>isn’t</em> simple: that it adds complexity to the codebase by introducing another thing you have to always remember. Hacks are just <em>easier to think of</em>. Figuring out the proper fix is hard because it requires having to understand the entire codebase (or large sections of it). In fact, the proper fix is almost always much simpler than the hack.</p>
<p>It is not easy to do the simplest thing that could possibly work. When you’re looking at a problem, the first few solutions that come to mind are unlikely to be the simplest ones. Figuring out the simplest solution requires considering many different approaches. In other words, it requires doing engineering.</p>
<h4>What is simplicity?</h4>
<p>Engineers disagree a lot about what constitutes simple code. If “simplest” already means “with good design”, is it just a tautology to say “you should do the simplest thing that could possibly work?” In other words, is Unicorn really simpler than <a href="https://github.com/puma/puma">Puma</a><sup id="fnref-3"><a href="#fn-3">3</a></sup>? Is adding in-memory rate limiting really simpler than using Redis? Here’s a rough, intuitive definition of simplicity<sup id="fnref-4"><a href="#fn-4">4</a></sup>:</p>
<ol>
<li>Simple systems have fewer “moving pieces”: fewer things you have to think about when you’re working with them</li>
<li>Simple systems are less <em>internally-connected</em>. They are composed from components with clear, straightforward interfaces</li>
</ol>
<p>Unix processes are simpler than threads (and thus Unicorn is simpler than Puma) because processes are less connected: they do not share memory. This makes a lot of sense to me! But I don’t think it gives you the tools to figure out what’s simpler in every case.</p>
<p>What about in-memory rate limiting vs Redis? On the one hand, in-memory is simpler because you don’t have to think about all the things involved in standing up a separate service with persistent memory. On the other hand, Redis is simpler because the rate limiting guarantees it offers are more straightforward - you don’t have to worry about the case where one server instance thinks a user is rate limited and another one doesn’t.</p>
<p>When I’m not sure what “seems” simpler to me, I like to use this tiebreaker: <strong>simple systems are stable</strong>. If you’re comparing two states of a software system, and one will require more ongoing work <em>if no requirements change</em>, the other one is simpler. Redis must be deployed and maintained, it can have its own incidents, it requires its own monitoring, it requires a separate deployment in any new environments the service finds itself in, and so on. Thus in-memory rate limiting is simpler than Redis<sup id="fnref-5"><a href="#fn-5">5</a></sup>.</p>
<h4>Why wouldn’t you want to be scalable?</h4>
<p>A certain type of engineer is now screaming to themselves “but in-memory rate limiting won’t scale!” Doing the simplest thing that could possibly work will emphatically not deliver the most web-scale system. It will deliver a system that works well at the current scale. Is this irresponsible engineering?</p>
<p>No. In my view, the cardinal sin of big tech SaaS engineering is an obsession with scale. I’ve seen so much unavoidable pain caused by over-engineering systems to prepare for several orders of magnitude more than the current scale.</p>
<p>The main reason to not try this is that <strong>it doesn’t work</strong>. In my experience, for any non-trivial codebase, you can’t anticipate how it will behave at several orders of magnitude more traffic, because you don’t know ahead of time where all the bottlenecks are going to be. At most you can try to make sure you’re ready for 2x or 5x the current traffic, and then stand by to deal with problems as they come in.</p>
<p>The other reason not to try this is that <strong>it makes your codebase inflexible</strong>. It’s fun to decouple your service into two pieces so they can be scaled independently (I have seen this happen maybe ten times, and I have seen them <em>actually be usefully scaled independently</em> maybe once). But that makes certain features very hard to implement, because they now require coordination over the wire. In the worst case, they require <em>transactions</em> over the wire, which is a genuinely hard engineering problem. Most of the time you just don’t have to do any of this!</p>
<h3>Final thoughts</h3>
<p>The longer I spend working in tech, the less optimistic I become about our collective ability to predict where a system is going. It’s hard enough to get your head around where a system currently is. And in fact, that’s the main practical difficulty in doing good design: getting an accurate big-picture understanding of the system. Most design is done without that understanding, and most design is thus pretty bad.</p>
<p>There are, broadly speaking, two ways to develop software. The first is to predict what your requirements might look like six months or a year from now, and then design the best system for that purpose. The second is to design the best system for what your requirements actually look like right now: in other words, to do the simplest thing that could possibly work.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Income Equality in Nordic Countries: Myths, Facts, and Lessons (108 pts)]]></title>
            <link>https://www.aeaweb.org/articles?id=10.1257/jel.20251636</link>
            <guid>45067423</guid>
            <pubDate>Fri, 29 Aug 2025 18:03:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aeaweb.org/articles?id=10.1257/jel.20251636">https://www.aeaweb.org/articles?id=10.1257/jel.20251636</a>, See on <a href="https://news.ycombinator.com/item?id=45067423">Hacker News</a></p>
<div id="readability-page-1" class="page"><section role="main">

    
    




    
    <ul>
            
    <li>
         Kjell G. Salvanes    </li>
    <li>
         Gaute Torsvik    </li>

    </ul>

		<div>

			<p>Journal of Economic Literature </p>

			                

		</div>
                <p>(pp. 791–839)</p>
		
    
	
    <section>
        <a href="https://www.aeaweb.org/articles/pdf/doi/10.1257/jel.20251636">
            Download Full Text PDF <br>
                    </a>
    </section>

	
	
    <div>

		   <ul>
				<li>
					<a href="#article-information">Article Information</a>
				</li>
											</ul>
		
		
        <section id="article-information">

							<section>
					<h4>Abstract</h4>
					Policymakers, public commentators, and researchers often cite the Nordic countries as examples of a socioeconomic model that combines low income inequality with prosperity and growth. This article critically assesses that claim by integrating theoretical perspectives and empirical evidence to explain how the Nordic model functions and why these countries experience low inequality. Our analysis suggests that income equality in the Nordics is largely driven by a significant compression of hourly wages, reducing returns to labor market skills and education. This appears to result from a wage bargaining system characterized by strong coordination within and across industries. This finding challenges other commonly cited explanations for Nordic income equality, such as redistribution through the tax transfer system, public spending on goods that complement employment, and public policies promoting equal skills and human capital. We consider broader lessons for economies aiming to reduce inequality and conclude by highlighting several under-explored or unresolved questions.				</section>
			
							<section>
					<h4>Citation</h4>
					<cite>

                        Mogstad, Magne, Kjell G. Salvanes, and Gaute Torsvik.
						<span>2025.</span>

						
						
							<span>"Income Equality in the Nordic Countries: Myths, Facts, and Lessons."</span>
						
						<span>Journal of Economic Literature</span>
							  <span>
					63 (3):
					 791–839<span>.</span>
				  </span>
						<span>DOI: 10.1257/jel.20251636</span>
					</cite>

					
				</section>
								
					<section>
						
							<h4>Additional Materials</h4>

						
						<ul id="additionalMaterials">
							<li>                    <a target="_blank" href="https://doi.org/10.3886/E221423V1" doi="10.1257/jel.20251636" accesstype="Article View">
                Replication Package                                            </a>
        </li><li>                    <a href="https://www.aeaweb.org/articles/materials/23773" doi="10.1257/jel.20251636" accesstype="Article View">
                Author Disclosure Statement(s)                                            </a>
        </li>
						</ul>
					</section>


				
									<section>
						<h4>JEL Classification</h4>
						<ul>
														<li>
								<strong>D31</strong>
								Personal Income, Wealth, and Their Distributions
															</li><li>
								<strong>E23</strong>
								Macroeconomics: Production
															</li><li>
								<strong>H23</strong>
								Taxation and Subsidies: Externalities; Redistributive Effects; Environmental Taxes and Subsidies
															</li><li>
								<strong>J24</strong>
								Human Capital; Skills; Occupational Choice; Labor Productivity
															</li><li>
								<strong>J31</strong>
								Wage Level and Structure; Wage Differentials
															</li><li>
								<strong>J52</strong>
								Dispute Resolution: Strikes, Arbitration, and Mediation; Collective Bargaining
															</li>
						</ul>
					</section>
				
			</section>

		
		
        
		 </div> 
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite's documentation about its durability properties is unclear (139 pts)]]></title>
            <link>https://www.agwa.name/blog/post/sqlite_durability</link>
            <guid>45066999</guid>
            <pubDate>Fri, 29 Aug 2025 17:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.agwa.name/blog/post/sqlite_durability">https://www.agwa.name/blog/post/sqlite_durability</a>, See on <a href="https://news.ycombinator.com/item?id=45066999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>
One of the most important properties of a database is durability.  Durability means that after a transaction commits, you
can be confident that, absent catastrophic hardware failure, the changes made by the commit won't be lost.  This should
remain true even if the operating system crashes or the system loses power soon after the commit.  On Linux, and most other Unix operating systems, durability is ensured by calling the <a href="https://man7.org/linux/man-pages/man2/fsync.2.html" rel="external">fsync</a> system call at the right time.
</p>

<p>
Durability comes at a performance cost, and sometimes applications don't need durability.  Some applications can tolerate
losing the last several seconds of commits in the event of a power failure, as long as the database doesn't end up
corrupted.  Thus, databases typically provide knobs to configure if and when they call fsync.  This is fine, but it's essential
that the database clearly documents what its default durability properties are, and what each configuration setting guarantees.
</p>

<p>
Unfortunately, SQLite's documentation about its durability properties is far from clear.  I cannot tell whether SQLite is durable
by default, and if not, what are the minimal settings you need to use to ensure durability.
</p>

<p>The two relevant configuration
options are <a href="https://sqlite.org/pragma.html#pragma_journal_mode" rel="external"><code>journal_mode</code></a> and <a href="https://sqlite.org/pragma.html#pragma_synchronous" rel="external"><code>synchronous</code></a>.  <code>journal_mode</code> has several possible values, but most people use either DELETE or WAL.  <code>synchronous</code> has four possible values: EXTRA, FULL, NORMAL, and OFF.
</p>

<p>
This is how I interpret SQLite's documentation after a careful reading:
</p>

<ul><li><p>The default value of <code>journal_mode</code> is DELETE:</p><blockquote>The DELETE journaling mode is the normal behavior (<a href="https://sqlite.org/pragma.html#pragma_journal_mode" rel="external">source</a>; <a href="https://web.archive.org/web/20250826165231/https://www.sqlite.org/pragma.html#pragma_journal_mode" rel="external">archived</a>)</blockquote></li><li><p>The default value of <code>synchronous</code> is FULL:</p><blockquote>If not overridden at compile-time, the default setting is 2 (FULL) (<a href="https://sqlite.org/compile.html#default_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826070702/https://sqlite.org/compile.html#default_synchronous" rel="external">archived</a>)</blockquote></li><li><p>The default value of <code>synchronous</code> is FULL even in WAL mode:</p><blockquote>If not overridden at compile-time, this value is the same as SQLITE_DEFAULT_SYNCHRONOUS. (<a href="https://sqlite.org/compile.html#default_wal_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826070702/https://sqlite.org/compile.html#default_wal_synchronous" rel="external">archived</a>)</blockquote></li><li><p>When <code>journal_mode</code> is DELETE, you need to set <code>synchronous</code> to EXTRA to get durability:</p><blockquote>EXTRA synchronous is like FULL with the addition that the directory containing a rollback journal is synced after that journal is unlinked to commit a transaction in DELETE mode. EXTRA provides additional durability if the commit is followed closely by a power loss. (<a href="https://sqlite.org/pragma.html#pragma_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826165231/https://www.sqlite.org/pragma.html#pragma_synchronous" rel="external">archived</a>)</blockquote>
<p>
Edited to add: I confirmed this to be true through testing - see <a href="https://news.ycombinator.com/item?id=45069533" rel="external">my Hacker News comment</a> for the methodology.
</p>
</li><li><p>When <code>journal_mode</code> is WAL, FULL is sufficient for durability:</p><blockquote>With synchronous=FULL in WAL mode, an additional sync operation of the WAL file happens after each transaction commit. The extra WAL sync following each transaction helps ensure that transactions are durable across a power loss (<a href="https://sqlite.org/pragma.html#pragma_synchronous" rel="external">source</a>; <a href="https://web.archive.org/web/20250826165231/https://www.sqlite.org/pragma.html#pragma_synchronous" rel="external">archived</a>)</blockquote><p>Note that this is not mentioned under the definition of FULL, but rather further down in the documentation for <code>synchronous</code>.</p></li></ul>

<p>
Based on the above, I conclude that:
</p>

<ul><li><p>By default, SQLite is <strong>not</strong> durable, because the default value of <code>journal_mode</code> is DELETE, and the default value of <code>synchronous</code> is FULL, which doesn't provide durability in DELETE mode.</p></li><li><p>If you change <code>journal_mode</code> to WAL, then SQLite <strong>is</strong> durable, because <code>synchronous=FULL</code> provides durability in WAL mode.</p></li></ul>



<p>
However, a recent <a href="https://news.ycombinator.com/item?id=45014296" rel="external">Hacker News comment</a> by a user who credibly claims to be Richard Hipp, the creator of SQLite, says:
</p>

<ul><li><p>"In its default configuration, SQLite is durable."</p></li><li><p>"If you switch to WAL mode, the default behavior is that transactions ... are not necessarily durable across OS crashes or power failures"</p></li></ul>

<p>
That's literally the opposite of what the documentation seems to say!
</p>

<p>
A Hacker News commenter who agrees with my reading of the documentation <a href="https://news.ycombinator.com/item?id=45015366" rel="external">asked Hipp</a> how his comment is consistent with the documentation, but received no reply.
</p>

<p>
Hipp also says that WAL mode used to be durable by default, but it was changed after people complained about poor performance.
This surprised me, since I had the impression that SQLite cared deeply about backwards compatibility, and weakening the
default durability setting is a nasty breaking change for any application which needs durability.
</p>

<p>
There are a couple other pitfalls around SQLite durability that you should be aware of, though I don't necessarily
blame the SQLite project for these:
</p>

<ul><li><p>Libraries that wrap SQLite can override the default value of <code>synchronous</code>.  For example, the most popular Go driver for SQLite <a href="https://github.com/mattn/go-sqlite3/blob/8bf7a8a844faf952aa0245b4c0ad0a47e84f4efd/sqlite3.go#L1318-L1320" rel="external">sets it to NORMAL</a> when in WAL mode, which does not provide durability.</p></li><li><p>On macOS, <a href="https://lactoseintolerant.dev/fsync-may-not-be-enough-to-guarantee-data-durability-on-mac-os/" rel="external">fsync is nerfed</a> to make macOS appear faster.  If you want a real fsync, you have to make a different, macOS-specific system call.  SQLite can do this, but it's <a href="https://sqlite.org/pragma.html#pragma_fullfsync" rel="external">off by default</a>.</p></li></ul>

<p>
My takeaway is that if you need durability, you'd better set the <code>synchronous</code> option explicitly because who knows what the default is, or what it will be in the future.  With WAL mode, FULL seems to suffice.  As for DELETE mode, who knows if FULL is enough, so you'd better go with EXTRA to be safe. And if your application might be used on macOS, enable <code>fullfsync</code>.
</p>

<p>
The SQLite project ought to clarify their documentation.  Since the meaning of <code>synchronous</code> depends on the value of <code>journal_mode</code>, I think it would be quite helpful to document the values of <code>synchronous</code> separately for each possible <code>journal_mode</code>, rather than mixing it all together.  A table with <code>synchronous</code> values on one axis and <code>journal_mode</code> on the other which tells you if the combination provides durability would do wonders.
</p>

<p>
By the way, there are definitely many applications for which losing a few seconds of data in exchange for better performance is a great tradeoff, which is why SQLite and macOS have made the choices they have made.  But programmers need to know what guarantees their tools provide, which is why unclear documentation and breaking previously-held assumptions is not cool.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Carmack's arguments against building a custom XR OS at Meta (423 pts)]]></title>
            <link>https://twitter.com/ID_AA_Carmack/status/1961172409920491849</link>
            <guid>45066395</guid>
            <pubDate>Fri, 29 Aug 2025 16:45:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ID_AA_Carmack/status/1961172409920491849">https://twitter.com/ID_AA_Carmack/status/1961172409920491849</a>, See on <a href="https://news.ycombinator.com/item?id=45066395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The web does not need gatekeepers: Cloudflare’s new “signed agents” pitch (415 pts)]]></title>
            <link>https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers</link>
            <guid>45066258</guid>
            <pubDate>Fri, 29 Aug 2025 16:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers">https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers</a>, See on <a href="https://news.ycombinator.com/item?id=45066258">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Do you register with Google, Amazon or Microsoft to use the web?</p><p><span>Cloudflare’s new “</span><strong>signed agents</strong><span>” pitch sounds like safety but it’s a wolf in sheep’s clothing. They’ve built an allowlist for the open web and told builders to apply for permission. That’s not how the internet works. An </span><a href="https://dash.cloudflare.com/?to=/:account/configurations/verified-bots" rel="nofollow ugc noopener">application form</a><span> is not a standard.</span></p><p>Yes, identity for agents is a real problem. But Cloudflare is solving it like a border checkpoint. Get on their list or get treated like a trespasser. That’s vendor approval  not an internet protocol. An allowlist run by ONE company?</p><p>Authentication for that world isn’t “ask Cloudflare for a hall pass.” It’s verifiable chains of delegation and request-level proof: open, portable, and independent of any one company.</p><p><span>The web thrived because </span><strong>no one owned it</strong><span>. </span></p><p>In the 90s, Microsoft tried to “embrace and extend” the web, but failed. And that failure was a blessing. Because no single company controlled it, anyone could publish, anyone could innovate, and protocols carried more weight than corporate policies.</p><p><span>We’ve seen this movie before. </span><strong>Open standards beat closed plug-ins.</strong><span> HTML5 and the Open Web Platform displaced proprietary runtimes like Flash (Adobe) and Silverlight (Microsoft). Flash was formally ended in 2020 and Silverlight in 2021, while HTML5 became a W3C Recommendation back in 2014.</span></p><p>The pattern is consistent: when the commons defines the interface, innovation compounds; when a vendor hands out permission slips, it stalls.</p><p><span>Agents are inevitable. They will be the next major users of the web: retrieving information, automating workflows, making purchases, negotiating contracts. </span><strong>Sometimes ai agents will be explicitly directed by humans, other times they’ll act as subroutines inside bigger tasks</strong><span>.</span></p><p>The line between human and agent action will blur. </p><p><span>When I’m driving, I hand my phone to a friend and say, “Reply ‘on my way’ to my Mom.” They act on my behalf, through my identity, even though the software has no built-in concept of delegation. </span><strong>That is the world we are entering.</strong></p><p><strong>Authentication </strong><span>asks: </span><em>who is acting?</em></p><p><strong>Authorization</strong><span> asks: </span><em>what are they allowed to do?</em></p><div><p><span>They are not the same. Yet Cloudflare treats them as if a single passport could solve both. It can’t. In the real world, showing a passport is not enough to open a bank account, the actual person must be present!. </span></p><p><span>The same is true online. A cryptographic signature that claims “I am acting on behalf of X” means nothing unless it is tied to something real, like a verifiable infrastructure or a range of IPs. Without that, I can simply hand the passport to another agent, and they can act as if they were me. The passport becomes nothing more than a token anyone can pass around.</span></p></div><p>This is why the whole idea of a “bot passport” is deeply flawed. </p><p>Authentication and authorization matter more than ever but they must be rethought for the era of agents and for an authentic web.</p><p>And here’s the truth: on the internet, nobody knows you’re a dog.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!kD6s!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!kD6s!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 424w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 848w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1272w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!kD6s!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic" width="299" height="334" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:334,&quot;width&quot;:299,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:34738,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://positiveblue.substack.com/i/172206112?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!kD6s!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 424w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 848w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1272w, https://substackcdn.com/image/fetch/$s_!kD6s!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc83fa8-5429-4d44-8edb-a3ba065f8c9d_299x334.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><p><span>A single signature proves nothing if it can simply be passed along. What we need is a way to prove both the chain of delegation and the authenticity of each request. The chain is like a certificate :</span></p><p><em>User X on Service Y delegated to Agent Z, who delegated to Agent K</em><span>. </span></p><p><span>But when Agent K actually makes a request to Service Y, it must add its own signature to prove it is truly Agent K. Without both pieces, authentication collapses.</span></p></div><p>The system must have a few key features:</p><ul><li><p><strong>Verifiable</strong><span>: you can check the claim independently.</span></p></li><li><p><strong>Composable</strong><span>: it works across chains of delegation.</span></p></li><li><p><strong>Decentralized</strong><span>: no single gatekeeper decides who is “valid.”</span></p></li></ul><p><span>Public key cryptography already gives us a model. Companies prove ownership today through DNS; they could publish public keys in the same way. That would let a service authenticate a third party simply by checking DNS (without anyone filling forms, asking permission, or registering with a central directory). Sites could still blacklist or whitelist as they choose, but the </span><strong>default is open</strong><span>.</span></p><p><strong>This is what authentication for the agentic era should look like: open, verifiable, and decentralized.</strong></p><p><span>Until now, software usually had a </span><strong>narrow scope</strong><span>. </span></p><p>Think a weekly cron job that emails a “new signups” report: it gets read-only access to the analytics DB, nothing else. Or a finance app via Plaid to fund your trading account: it can initiate transfers within limits but can’t browse your transaction history. </p><div><p><span>OAuth scopes worked because the software had a clear, predictable purpose.</span></p><p><span>Agents are different. They are </span><strong>general-purpose</strong><span>. The same agent might book a flight, pay for dinner, and then summarize your bank statement. They may also be short-lived, spun up for a single task and gone after it.</span></p></div><p>One way to make this work is to give the agent an “admin key”: full access to everything  It’s convenient, but dangerous. We must resist this pattern.</p><p><strong>Agents should not hold permanent credentials, authorizations must be per-task, not per-agent.</strong></p><p><span>Think of a bank account: I might tell my agent </span><em>“pay for dinner.”</em><span> That token should allow payment. But when I ask </span><em>“show me three months of spending,”</em><span> the agent should not be able to move money. Same agent, different task, different token. </span><strong>Credentials must follow tasks, not agents.</strong></p><p><span>Fortunately, cryptography and authorization models have evolved a lot in the last last years. We now have tools that allow us to issue tokens with </span><strong>constraints</strong><span>: granular, short-lived, and delegable (like </span><a href="https://en.wikipedia.org/wiki/Macaroons_(computer_science)" rel="nofollow ugc noopener">macaroons</a><span> or </span><a href="https://github.com/eclipse-biscuit/biscuit" rel="nofollow ugc noopener">biscuits</a><span>) and Open policy engines (like </span><a href="https://www.openpolicyagent.org/" rel="nofollow ugc noopener">OPA</a><span> or </span><a href="https://www.cedarpolicy.com/en" rel="nofollow ugc noopener">AWS Cedar</a><span>) can also be used for RBAC/ABAC for this use case.</span></p><p>Imagine:</p><ul><li><p>User X on Service Y holds an admin token.</p></li><li><p>They derive a narrower token for Agent Z to perform one task.</p></li><li><p>Agent Z can then derive an even narrower token for a sub-agent, all without bothering the service.</p></li><li><p>Each request can be verified against the chain.</p></li></ul><p>Coupled with the authentication model above, this approach gives us a foundation for managing agents without creating new gatekeepers.</p><p>This challenge is bigger than Cloudflare, Google, Microsoft or any single company. The future of the web cannot hinge on who controls the keys. We need protocols, not gatekeepers.</p><p><strong>Authentication, authorization, and monetization must remain open, interoperable, and standardized.</strong></p><p>Cloudflare’s launch is useful only because it exposes the danger. If we let a handful of companies decide which agents are “valid,” the agentic web will collapse into walled gardens. We’ve seen this movie before.</p><p>Here’s the line in the sand: I’m open-sourcing a first cut of these ideas chains of delegation,  request-level authorization , and task-scoped authorization so anyone can implement them, today.</p><p>If this resonates with you, if you want to collaborate, criticize, or help shape the protocols that will keep the web open for agents, please reach out jordi@fewsats.com</p><p><span>The future should not be about who holds the gates. It should be about </span><strong>protocols that let everyone build, share, and innovate</strong><span>.</span></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Offline-First Landscape – 2025 (115 pts)]]></title>
            <link>https://marcoapp.io/blog/offline-first-landscape</link>
            <guid>45066070</guid>
            <pubDate>Fri, 29 Aug 2025 16:20:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marcoapp.io/blog/offline-first-landscape">https://marcoapp.io/blog/offline-first-landscape</a>, See on <a href="https://news.ycombinator.com/item?id=45066070">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><h3>Introduction</h3><p>When we set out to build Marco, we knew we were committing to two very difficult requirements: (1) IMAP-based, not API-based, and (2) cross-platform – web, Mac, Windows, Android, iOS.</p><p>We had a handful of additional ancillary requirements. One of these was offline-first, and I can now say confidently that we drastically underestimated its complexity.</p><p>I mentioned in a <!--$--><a href="https://marcoapp.io/blog/marco-an-introduction" target="_blank" rel="noopener">previous blog post</a><!--/$--> that <!--$--><a href="https://missiveapp.com/" target="_blank" rel="noopener">Missive</a><!--/$--> was my daily driver in the recent past. It lacks offline support though, and this is one of the major downfalls of the product.</p><p>At Marco we believe that full offline support is crucial. "Managing your emails on an airplane with no wifi" is an example use case we frequently come back to. You should be able to read, delete, respond, and organise your emails with no internet connection. When you land and connect to wifi, everything should seamlessly sync.</p><p>That said, Marco is not a simple todo app. Marco is not an application that starts with zero data and grows in size gradually, as is the case with user-generated content like Notion, etc.</p><p>Marco is an application that deals with hundreds of MB of data, and hundreds of thousands (or millions) of rows/entities.</p><p>Essentially this means we are instantly jumping into the top 1% of heavy-duty use cases for offline-first implementations. Over time we realised that this actually rules out almost all available offline-first options.</p><h3>Starting Point: WatermelonDB</h3><p>I spent about a week deeply investigating the offline-first options available to us, in August 2024.</p><p>We (perhaps naively) had committed to the idea that our offline-first architecture should be database-agnostic – the offline-first logic should "end" at the API layer. We did not want to manage sync tables or schemas in Postgres –&nbsp;we wanted to write API endpoints, and manage our database ourselves.</p><p>Here's a rundown of the initial offline-first options we looked at:</p><ol><li data-preset-tag="p"><p><!--$--><a href="https://watermelondb.dev/docs" target="_blank" rel="noopener">WatermelonDB</a><!--/$--></p><ul><li data-preset-tag="p"><p>FOSS, self-hosted</p></li><li data-preset-tag="p"><p>Database agnostic</p></li><li data-preset-tag="p"><p>Been around for ages, used in many production applications</p></li></ul></li><li data-preset-tag="p"><p><!--$--><a href="https://www.powersync.com/" target="_blank" rel="noopener">PowerSync</a><!--/$--></p><ul><li data-preset-tag="p"><p>Not quite FOSS, but has a free Self-Hosted Edition</p></li><li data-preset-tag="p"><p>Requires Postgres-level integration</p></li><li data-preset-tag="p"><p>Very complex architecture, requires both changes to Postgres _and_ a separate HA MongoDB deployment cluster</p></li><li data-preset-tag="p"><p>Appears to have been around quite awhile, but all their case studies are on demo/tiny/side projects</p></li></ul></li><li data-preset-tag="p"><p><!--$--><a href="https://electric-sql.com/" target="_blank" rel="noopener">ElectricSQL</a><!--/$--></p><ul><li data-preset-tag="p"><p>Looked interesting, but was in the middle of a complete rewrite</p></li><li data-preset-tag="p"><p>Requires Postgres-level integration</p></li><li data-preset-tag="p"><p>New version only handles data sync one way –&nbsp;it does <em>not</em> handle mutations</p></li></ul></li></ol><p>There are <em>many</em> other options, including RxDB, MongoDB Atlas, Couchbase, and on and on. The three listed above are the options that we deeply investigated. As will become clear, we should have looked further at this stage.</p><p>We settled on WatermelonDB and built the initial alpha version of Marco on it. The backend implementation is rather simple: there is a "pull" endpoint to GET data, and a "push" endpoint to POST mutations.</p><p>It is important here to note that although Marco is a native application in some targets, it also must run in a web browser. While we may have access to a filesystem or "true" SQLite in native targets, our common denominator is web, where persistent storage options are very limited.</p><p>On the (web) frontend, Watermelon uses IndexedDB (as do essentially all other options –&nbsp;even the WASM SQLite options are usually SQLite-on-top-of-IndexedDB). However, it turns out Watermelon faces a serious problem that all other relational frontend databases face – IndexedDB performance is <em>terrible</em>. To solve this, Watermelon uses <!--$--><a href="https://watermelondb.dev/docs/Implementation/DatabaseAdapters#lokijs" target="_blank" rel="noopener">a LokiJS adapter</a><!--/$-->, which is literally just an in-memory database.</p><p>Yes, you heard that right. To get around IndexedDB performance issues, Watermelon uses LokiJS to... hold the entire database in memory. When your database size is 100MB+, this starts to become a serious problem.</p><p>Moreover, clients <em>must</em> pull data before they can push any new mutations, and mutations can easily be clobbered if the row has been updated on the backend before the frontend can push mutations.</p><p>On top of this, WatermelonDB is not as actively-maintained as it once was. Many issues and PRs are left without a response. For example, chunked initial syncing is not supported out of the box. We opened <!--$--><a href="https://github.com/Nozbe/WatermelonDB/pull/1866" target="_blank" rel="noopener">a PR</a><!--/$--> for this in early December, but it's still not been merged.</p><p>We got quite far along with the Marco alpha build, and then had a bit of a panic in November. Our confidence in our WatermelonDB-based offline-first approach was decreasing steadily. We began to seriously question if this technology could actually support a rock-solid, modern user experience.</p><p>We decided we needed to find something better.</p><h3>New Wave of Offline-First</h3><p>This time around, we threw out any preconceptions we had about Postgres, separation of concerns at the API layer, etc. We had completely open minds and desperately wanted to find the "best" solution, no matter what that might look like. We were now extremely clear on the fact that we had a "tough" offline-first use case, and needed some serious help.</p><p>We discovered a host of "new wave" offline first implementations. We talked with the founders/developers of these projects and found so many extremely intelligent and talented people working on what is a very tough problem.</p><p>The leaders in this new wave are:</p><ol><li data-preset-tag="p"><p><!--$--><a href="https://www.triplit.dev/" target="_blank" rel="noopener">Triplit</a><!--/$--></p></li><li data-preset-tag="p"><p><!--$--><a href="https://www.instantdb.com/" target="_blank" rel="noopener">InstantDB</a><!--/$--></p></li><li data-preset-tag="p"><p><!--$--><a href="https://www.convex.dev/" target="_blank" rel="noopener">Convex</a><!--/$--></p></li></ol><p>While Triplit and InstantDB can be described as "full stack databases", Convex is instead an entire backend solution, including API endpoints, etc. For this reason we excluded Convex, as it seems like a huge leap and essentially 100% lock-in.</p><h3>Problems with Triplit</h3><p>Our first (of several) rewrites was from WatermelonDB to Triplit. Both Triplit and InstantDB use triples to represent data – entities are stored as "triples" of (&lt;entity id&gt;, &lt;entity field&gt;, &lt;entity value&gt;). Such a representation makes syncing a straightforward affair.</p><p>Triplit's API and DX is best-in-class. However, although we desperately wanted to love the product, we found it unusable for our use case. The server-side implementation was eating gigabytes of RAM while sitting idle and would regularly OOM/crash. The client-side triples implementation would balloon 5MB of JSON into 1GB of SQLite.</p><p>We believe Triplit is a fantastic choice for any offline-first applications with relatively small storage needs. On top of this, we found the Triplit team to be incredibly talented and hard-working, and truly believe that by mid-2025, it will be a robust and capable product.</p><p>We absolutely love the developer experience with Triplit, and are rooting for the team to succeed!</p><p>But we need something which is reliable, highly performant, and battle-tested, <em>now</em>.</p><h3>Problems with InstantDB</h3><p>We next moved onto InstantDB, which can be considered a direct competitor to Triplit. Although both InstantDB and Triplit essentially solve the same problem, we found InstantDB to be a far worse implementation.</p><p>TypeScript types were non-existent. There was no sort/ordering by fields. There was no support for $like operators, and certainly no full text search. I believe some of these features have since been added –&nbsp;both teams are certainly scrambling to handle a million features and requests.</p><p>On the backend side of things, there are no webhooks, so it is impossible to respond to mutations in a scalable way. We would have had to build our own singleton subscriber microservice that then translated reactive queries into scalable webhooks. But reactive queries themselves are prone to dropped data, so we would need some sort of polling fallback... The backend story for InstantDB feels extremely incomplete.</p><p>Even looking past all of this, frontend queries that returned in 2-5ms with Watermelon+LokiJS were taking 200-500ms to return data with InstantDB. This is primarily because InstantDB is not optimistic, and was hitting network to fetch data with almost every request. There is no granular control as to what gets cached on the client side and what does not.</p><p>InstantDB is another promising product, and our understanding is that some teams are already building production applications on top of it. But it's simply too immature for our use case right now. There's essentially zero backend support, and the frontend UX felt like a massive downgrade coming from Watermelon.</p><h3>Problems with PowerSync</h3><p>Finally, to our great disappointment, we begrudgingly moved on to PowerSync. We were wary of PowerSync from the beginning, and our reluctance proved to be well-founded.</p><p>Although PowerSync is undoubtedly a mature product, and probably the most capable (on paper) of all options mentioned thus far, we hated every minute of working with it. The underlying tech might be the most production/enterprise friendly, but the DX is the worst by quite a margin.</p><p>There is a paid SaaS offering, but their pricing model would have made our use case prohibitively expensive. Therefore we needed to self-host PowerSync, which is quite a complex and expensive task in itself. Not only does it require Postgres-level integration, it also needs a HA MongoDB cluster, a lot of arcane yaml configuration, etc. It also required us to completely denormalise our Postgres tables, as relations are not properly supported across the sync buckets.</p><p>On the frontend side of things, PowerSync runs SQLite in WASM, and although the DX is fairly good, we found horrifying problems like off-by-one bugs in their Drizzle ORM integration, queries returning data <em>from local db</em> very slowly (100ms+), and long initialisation times (45s+ after login to Marco) with the UI view not updating until the sync fully completed.</p><h3>Why So Many Problems?</h3><p>There is a saying: if everyone is an asshole, maybe you're the asshole. Is the problem 5+ offline-first tools, or is it us?</p><p>Like with most things, the reality is "a bit of both". As mentioned, Marco is an incredibly data-intensive application, and from day one, we were pushing these offline-first tools to their absolute limits.</p><p>However, we also found the practical limits of these tools to be way lower than one would expect.</p><p>What is the underlying cause? In my estimation, the root cause is that all of these offline-first tools for web are essentially hacks. Because of Marco's web deployment target, which becomes our common denominator, we <em>must</em> support offline-first in a web browser, and web browsers only really support KV storage via IndexedDB.</p><p>All attempts to implement relational or graph databases within a web browser are essentially hacks. PowerSync itself is WASM SQLite... <em>On top of IndexedDB</em>. Binary SQLite chunks are literally stored in IndexedDB.</p><p>There are essentially three different variables:</p><ol><li data-preset-tag="p"><p>The underlying (true) data store –&nbsp;this will always be IndexedDB for web implementations</p></li><li data-preset-tag="p"><p>How the data is represented for sync purposes</p></li><li data-preset-tag="p"><p>How the data is presented to developers</p></li></ol><p>The new wave of tools are attempting triples/graph implementations, but the story is the same. Browsers only give you a KV API, and anything on top of that will be built in userland and will suffer poor performance once you hit a certain scale. Although triples are easy to store and sync, when you try to jam a relational layer on top, the whole thing starts to fall apart.</p><p>To be absolutely clear: these relational and graph implementations on top of IndexedDB do not start to show their cracks unless you have 10s/100s of MB of data, or hundreds of thousands of rows/entities. But at a certain scale, performance grinds to a halt and they become unusable. For lesser use cases, Triplit and InstantDB offer exceptional DX and velocity, with almost no drawbacks.</p><p>At this point, we were starting to pull our hair out, and were wondering if we needed to build our own sync engine. Like many others, we're highly impressed with Linear, but are also aware that their sync engine was a monumental engineering effort.</p><p>We're only a team of two, and we have a <em>lot</em> to work on besides offline-first itself.</p><h3>Finally, A Solution</h3><p>Some time in early December, I came back across an option which I had glanced over before, but disregarded: <!--$--><a href="https://replicache.dev/" target="_blank" rel="noopener">Replicache</a><!--/$-->.</p><p>I think we were initially put off by their strange pricing model and the fact that it's closed-source.</p><p>I am so glad we took another look.</p><p>In terms of backend implementation, Replicache is somewhat similar to WatermelonDB, in that you need to implement push and pull endpoints in your backend, and it is otherwise entirely database-agnostic.</p><p>The frontend is where the crucial difference lies – Replicache is <em>just</em> a KV store. It is a thin layer on top of IndexedDB that adds reactivity and some querying DX. That's it. You get raw <code>get</code> and <code>set</code> performance. Some performance benchmarks are outlined <!--$--><a href="https://doc.replicache.dev/concepts/performance" target="_blank" rel="noopener">here</a><!--/$-->. The perf is truly remarkable.</p><p>The drawback to this KV approach is that searching/sorting/ordering entities would require scanning through entire collections. This is obviously a non-starter. In other words, if we wanted to use Replicache, we would need to handle indexing and search on our own.</p><p>We'll post more detailed write-ups on our tech stack in the future, but a quick summary of where we landed on the frontend is: Replicache + <!--$--><a href="https://github.com/oramasearch/orama" target="_blank" rel="noopener">Orama</a><!--/$-->. This gives us sophisticated and battle-tested data sync with conflict resolution and rebasing, but also extremely flexible and powerful indexing, full-text search, and more.</p><p>At the time of writing (January 2025), the Replicache team have just made it completely free and open source. This is because they've just released <!--$--><a href="https://zero.rocicorp.dev/" target="_blank" rel="noopener">Zero</a><!--/$-->, which looks extraordinarily compelling and will likely jump into the #1 spot for any offline-first product available.</p><p>We're eager to try Zero once it's a bit more stable, but for now will build our product on the extremely capable and robust piece of software that is Replicache.</p><h3>Future of Offline-First</h3><p>We embarked on a long and rambling journey through essentially all prior art and work in the offline-first world. It's a very hard problem to solve.</p><p>The good news is that there are many new teams and projects actively and energetically working on this problem.</p><p>Imagine a world where, as a fullstack developer, you can read and write data from an SDK in both your backend and your frontend, and they magically sync with each other. All your apps are instantly responsive. All your apps work offline out of the box.</p><p>This is already possible today with Triplit or InstantDB, if your use case is reasonable. And things are only improving.</p><p>I believe 2025 will be a year where HTTP/REST APIs will start to feel antiquated. Don't share endpoints –&nbsp;share databases.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wikipedia as a Graph (222 pts)]]></title>
            <link>https://wikigrapher.com/paths</link>
            <guid>45066060</guid>
            <pubDate>Fri, 29 Aug 2025 16:19:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wikigrapher.com/paths">https://wikigrapher.com/paths</a>, See on <a href="https://news.ycombinator.com/item?id=45066060">Hacker News</a></p>
Couldn't get https://wikigrapher.com/paths: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Essential Coding Theory [pdf] (328 pts)]]></title>
            <link>https://cse.buffalo.edu/faculty/atri/courses/coding-theory/book/web-coding-book.pdf</link>
            <guid>45065705</guid>
            <pubDate>Fri, 29 Aug 2025 15:53:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cse.buffalo.edu/faculty/atri/courses/coding-theory/book/web-coding-book.pdf">https://cse.buffalo.edu/faculty/atri/courses/coding-theory/book/web-coding-book.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45065705">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[God created the real numbers (112 pts)]]></title>
            <link>https://www.ethanheilman.com/x/34/index.html</link>
            <guid>45065425</guid>
            <pubDate>Fri, 29 Aug 2025 15:31:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ethanheilman.com/x/34/index.html">https://www.ethanheilman.com/x/34/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=45065425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>07-14-2025 7:37PM (ET) 08-28-2025 12:03AM (ET) (edited)</p><hr><p><img src="https://www.ethanheilman.com/x/34/figs/science.png" alt="writes in his introduction to Camillo Agrippa's " a="" treatise="" on="" the="" science="" of="" arms,="" with="" philosophical="" dialogue="" (1553)"="">
</p>

<p><a href="https://wiktenauer.com/wiki/W._Jherek_Swanger">W. Jherek Swanger</a> writes in his introduction to Camillo<sup id="fnref:7"><a href="#fn:7">7</a></sup> Agrippa's "A Treatise on the Science of Arms, with a philosophical Dialogue (1553)" that:</p>
<blockquote>
<p>"Scienzia [...] was and is often held to relate only to the study of the eternal: that which exists in nature, or was created by God. Thus theology and astronomy/astrology are held to be sciences. Indeed, Ridolfo Capoferro held that strictly speaking fencing is not a science, but rather an art, because it was not divinely created."</p>
</blockquote>
<p>16th Century Italy asks then if science is concerned only with divine (natural) knowledge<sup id="fnref:1"><a href="#fn:1">1</a></sup> and art is the realm of the secular and human-made, then was Leopold Kronecker right when he said<sup id="fnref:2"><a href="#fn:2">2</a></sup>:</p>
<blockquote>
<p>"God made the integers; all else is the work of man"</p>
</blockquote>
<p>The integers look little like the natural world and very much like the simple and powerful abstractions that humans find elegant.
Much to the frustration of the human mind, that which created <a href="https://en.wikipedia.org/wiki/Fig_wasp">fig wasps</a>, <a href="https://en.wikipedia.org/wiki/Leucochloridium_paradoxum">Leucochloridium paradoxum</a>, quantum foam, and <a href="https://en.wikipedia.org/wiki/Plasmid">plasmids</a>, does not create works of abstract simplicity.
If such a divinity left fingerprints in mathematics, that inhuman complexity and irrational strangeness<sup id="fnref:6"><a href="#fn:6">6</a></sup> can be found in the reals but not the integers.
One can imagine the God of the <a href="https://en.wikipedia.org/wiki/Book_of_Job">Book of Job</a> creating <a href="https://en.wikipedia.org/wiki/Square_root_of_2">the square root of two</a> and pi.</p>
<p>I have an imperfect rule of thumb for determining if something is of human construction or for the purposes of this exploration, divine.
If the something under examination causes a sense of existential nausea, disorientation, and a deep feeling that is can't possibly work like that, it is divine<sup id="fnref:3"><a href="#fn:3">3</a></sup>.
If on the other hand it feels universal, simple, and ideal, it is the product of human effort.</p>
<h2>The Hierarchy of Weirdness</h2>
<p>This distinction science=divine/nature, art=made by human is more complex than just two separate categories.
When humans create something, the created thing is contained, and is a function of, what already exists, so while art is the part of the universe that is created by humans, it also emerges from the part of the universe that isn't created by humans.</p>
<p><a href="https://archive.org/details/kodokan-judo/page/124"><img alt="triangle choke (sankaku-jime) from Kodokan Judo ny Jigoro Kano - edited by Kodokan Editorial Committee (1986)" src="https://www.ethanheilman.com/x/34/figs/trianglejudo.png"></a></p>
<p>The human idea of the triangle choke (sankaku-jime) only works because humans have arms, legs and necks.
It wouldn't be meaningful to talk about it in a universe without chokeable necks, but necks existed before human ideas.
So the idea of a triangle exists both because of the specific context of humanity and also because humans created it.</p>
<p>More specifically, we can define a hierarchy of creation, or what a 16th Century Italian would call divine creation.
At the top of the hierarchy we have eternal nature. Eternal nature gives rise to nature, which in turn gives rise to humans, which gives rise to human ideas.
As shown below, the closer we get to eternal nature the greater the weirdness<sup id="fnref:5"><a href="#fn:5">5</a></sup> (from a human perspective).</p>
<p><img alt="hierarchy of weirdness" src="https://www.ethanheilman.com/x/34/figs/creationheirarchy.png"></p>
<p>The real numbers are much closer to eternal nature<sup id="fnref:4"><a href="#fn:4">4</a></sup>, whereas the integers are much closer to human ideas.
This is why to human mind the integers feel more perfect, feel more divine.
A hammer feels like the perfect tool to hammer a nail not because a hammer is closer to eternal nature or more divine, but because it isn't divine.
Hammers feel like the perfect tool because they were invented by humans specifically to solve the human problem of hammering nails.</p>
<h2>Kronecker, Cantor and God</h2>
<p>Kronecker's quote about the integers being divine was not made so much because Kronecker wanted to elevate the reputation of the integers but because he wanted to damn infinity.
It was that reaction of horror at the creepy crawly bugs you see when you lift up the rock of Mathematics.
The main target of Kronecker's campaign against infinity was the mathematician Cantor<sup id="fnref:8"><a href="#fn:8">8</a></sup> and his work on transfinites.
Cantor viewed infinity in a much more positive light and he wasn't alone in this reaction.</p>
<blockquote>
<p>"From <a href="https://en.wikipedia.org/wiki/Cantor%27s_paradise">the paradise</a> that Cantor created for us no-one shall be able to expel us." - David Hilbert (1926)<sup id="fnref:12"><a href="#fn:12">11</a></sup></p>
</blockquote>
<p>Cantor's ideas also sparked a theological debate since if the mind can reason about infinity, perhaps the mind can also reason about God<sup id="fnref:9"><a href="#fn:9">9</a></sup>.
Cantor himself was deeply invested in the theological implications of his mathematical work.
He believed that God was beyond the mind<sup id="fnref:13"><a href="#fn:13">12</a></sup> and thus his mathematical work was not the result of his own effort but rather God was speaking through him.</p>
<p>This is an inversion of <a href="https://en.wikipedia.org/wiki/God_of_the_gaps">God of the gaps</a><sup id="fnref:10"><a href="#fn:10">10</a></sup> where the gaps filled in by the God of the filling and the lack of gaps is evidence of God rather than the reverse.
This echos Descartes'<sup id="fnref:15"><a href="#fn:15">14</a></sup> deeply unsatisfying <a href="https://en.wikipedia.org/wiki/Trademark_argument">Trademark Argument</a> of the existence of God because finite beings like humans can perceive aspects of God like infinity, we must only be able to perceive<sup id="fnref:17"><a href="#fn:17">16</a></sup> them because God exists.</p>
<blockquote>
<p>"The idea of infinite substance, or God, must have “proceeded from some substance which really was infinite. [..] If a finite thing could produce the idea of an infinite thing, the Meditator reasons, this would violate the principle that there is more reality in a cause than in its effect, since the Idea of God is at the top of the Hierarchy of Ideas." - René Descartes, <a href="https://archive.org/stream/descartess-meditations-an-introduction/Descartes%E2%80%99s%20Meditations%20An%20Introduction_djvu.txt">Meditations on First Philosophy, in which the existence of God and the immortality of the soul are demonstrated (1641)</a><sup id="fnref:16"><a href="#fn:16">15</a></sup></p>
</blockquote>
<p>I much prefer the notion put forward by Chesterton that it is gaps themselves which are important.</p>
<blockquote>
<p>"The whole secret of mysticism is this: that man can understand everything by the help of what he does not understand. The morbid logician seeks to make everything lucid, and succeeds in making everything mysterious. The mystic allows one thing to be mysterious, and everything else becomes lucid" - <a href="https://www.gutenberg.org/files/16769/16769-h/16769-h.htm">Orthodoxy by G. K. Chesterton (1908)</a><sup id="fnref:14"><a href="#fn:14">13</a></sup></p>
</blockquote>
<h2>A Final Note</h2>
<p>Versions of this essay sat on my hard drive for the last few years and in private correspondence.
I couldn't find a conclusion to draw these threads together so I'm leaving it as a vibes-based meandering through these ideas.</p>
<p>This post originally came about because of a conversation with <a href="https://madars.org/">Madars Virza</a> about my rejection of the Kronecker quote.  I bounced it off of a number of other people including Andrew Poelstra, Russell O’Connor, Karina Poelstra, Peter Berard over the years. The observations of the real number line are taken from conversations with my dad, <a href="https://www.bridgew.edu/department/mathematics/dr-ward-heilman">Ward Heilman</a>. Hopefully I got it mostly correct, any errors are my own.</p>
<h3>Related Essays</h3>
<p><a href="https://mathwithbaddrawings.com/2016/12/28/why-the-number-line-freaks-me-out/">Ben Orlin - Why the Number Line Freaks Me Out (2016)</a> - <a href="https://web.archive.org/web/20250221054544/https://mathwithbaddrawings.com/2016/12/28/why-the-number-line-freaks-me-out/">archived</a></p>
<p><a href="https://www.infinitelymore.xyz/p/what-are-the-real-numbers-really">Joel David Hamkins - What are the real numbers, really? (2024)</a> - <a href="https://web.archive.org/web/20250601000000*/https://www.infinitelymore.xyz/p/what-are-the-real-numbers-really">archived</a></p>
<p><a href="https://apeironcentre.org/theology-of-georg-cantor/">Theology Of Georg Cantor (2014), Ochiai Hitoshi</a></p>
<p><a href="https://r6.ca/blog/20051210T202900Z.html">Russell O’Connor, How Dedekind Screwed Up a Hundred Years of Mathematics (2005)</a></p>
<hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Taco Bell rethinks AI drive-through after man orders 18,000 waters (125 pts)]]></title>
            <link>https://www.bbc.com/news/articles/ckgyk2p55g8o</link>
            <guid>45065391</guid>
            <pubDate>Fri, 29 Aug 2025 15:28:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/ckgyk2p55g8o">https://www.bbc.com/news/articles/ckgyk2p55g8o</a>, See on <a href="https://news.ycombinator.com/item?id=45065391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><article><div data-testid="byline-new" data-component="byline-block"><p><span data-testid="byline-new-contributors"><p><span>Shiona McCallum</span><span data-testid="undefined-role-location">Senior Tech Reporter </span></p></span></p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250828-055926-c20c0c03f5-2.28.1-2/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/2a96/live/a8b53400-84b5-11f0-b98d-d308c56c1729.jpg.webp" loading="eager" alt="Getty Images A Taco Bell Drive Thru sign showing the pink and yellow bell and purple text saying 'Taco Bell, Drive Thru'."><span>Getty Images</span></p></div></figure><div data-component="text-block"><p>Taco Bell is rethinking its use of artificial intelligence (AI) to power drive-through restaurants in the US after comical videos of the tech making mistakes were viewed millions of times. </p><p>In one clip, a customer seemingly crashed the system by ordering 18,000 water cups, while in another a person got increasingly angry as the AI repeatedly asked him to add more drinks to his order.</p><p>Since 2023, the fast-food chain has introduced the technology at over 500 locations in the US, with the aim of reducing mistakes and speeding up orders. </p><p>But the AI seems to have served up the complete opposite. </p></div><div data-component="text-block"><p>Taco Bell's Chief Digital and Technology Officer Dane Mathews told <a target="_blank" href="https://www.wsj.com/articles/taco-bell-rethinks-future-of-voice-ai-at-the-drive-through-72990b5a?mod=rss_Technology">The Wall Street Journal</a> that deploying the voice AI has had its challenges. </p><p>"Sometimes it lets me down, but sometimes it really surprises me," he said.</p><p>He said the firm was "learning a lot" - but he would now think carefully about where to use AI going forwards, including not using it at drive-throughs.</p><p>In particular, Mr Matthews said, there are times when humans are better placed to take orders, especially when the restaurants get busy. </p><p>"We'll help coach teams on when to use voice AI and when it's better to monitor or step in," he said. </p><p>The issues have been building online as disgruntled customers take to social media to complain about the service - with many pointing out glitches and issues.</p><p>One clip on Instagram, which has been viewed over 21.5 million times, shows a man ordering "a large Mountain Dew" and the AI voice continually replying "and what will you drink with that?".</p><p>It isn't the first time there has been issues with AI not getting it right when it comes to processing food and drink orders.  </p><p>Last year <a target="_self" href="https://www.bbc.co.uk/news/articles/c722gne7qngo">McDonald's withdrew AI from its own drive-throughs</a> as the tech misinterpreted customer orders - resulting in one person getting bacon added to their ice cream in error, and another having hundreds of dollars worth of chicken nuggets mistakenly added to their order.</p><p>But despite some of the viral glitches facing Taco Bell, it says two million orders have been successfully processed using the voice AI since its introduction.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250828-055926-c20c0c03f5-2.28.1-2/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/41d3/live/348b21e0-26a8-11f0-8f57-b7237f6a66e6.png.webp" loading="lazy" alt="A green promotional banner with black squares and rectangles forming pixels, moving in from the right. The text says: “Tech Decoded: The world’s biggest tech news in your inbox every Monday.”"></p></div></figure></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why AI Isn't Ready to Be a Real Coder (171 pts)]]></title>
            <link>https://spectrum.ieee.org/ai-for-coding</link>
            <guid>45065343</guid>
            <pubDate>Fri, 29 Aug 2025 15:24:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/ai-for-coding">https://spectrum.ieee.org/ai-for-coding</a>, See on <a href="https://news.ycombinator.com/item?id=45065343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Why AI Isn’t Ready to Be a Real Coder"><p><a href="https://spectrum.ieee.org/topic/artificial-intelligence/">Artificial intelligence</a> (AI) has transformed the coding sphere, with <a href="https://spectrum.ieee.org/best-ai-coding-tools" target="_self">AI coding tools</a> completing <a href="https://spectrum.ieee.org/tag/source-code">source code</a>, correcting syntax errors, creating inline documentation, and understanding and answering questions about a codebase. As the technology advances beyond automating <a href="https://spectrum.ieee.org/tag/programming" target="_self">programming</a> tasks, the idea of full autonomy looms large. Is AI ready to be a <em><em>real</em></em> coder?</p><p>A <a href="https://arxiv.org/pdf/2503.22625" rel="noopener noreferrer" target="_blank">new paper</a> says not yet—and maps out exactly why. Researchers from <a href="https://www.cornell.edu/" rel="noopener noreferrer" target="_blank">Cornell University</a>, <a href="https://www.csail.mit.edu/node/2873" rel="noopener noreferrer" target="_blank">MIT CSAIL</a>, <a href="https://www.stanford.edu/" rel="noopener noreferrer" target="_blank">Stanford University</a>, and <a href="https://www.berkeley.edu/" rel="noopener noreferrer" target="_blank">UC Berkeley</a> highlight key challenges that today’s <a href="https://spectrum.ieee.org/tag/ai-models">AI models</a> face and outline promising research directions to tackle them. They presented their work at the <a href="https://icml.cc/Conferences/2025" rel="noopener noreferrer" target="_blank">2025 International Conference on Machine Learning</a>.</p><p>The study offers a clear-eyed reality check amid all the hype. “At some level, the technology is powerful and useful already, and it has gotten to the point where <a href="https://spectrum.ieee.org/tag/programming">programming</a> without these tools just feels primitive,” says <a href="https://www.csail.mit.edu/person/armando-solar-lezama" rel="noopener noreferrer" target="_blank">Armando Solar-Lezama</a>, a co-author of the paper and an associate director at <a href="https://spectrum.ieee.org/tag/mit">MIT</a> <a href="https://spectrum.ieee.org/tag/csail">CSAIL</a>, where he leads the computer-aided programming group. He argues, however, that AI-powered <a href="https://spectrum.ieee.org/tag/software-development" target="_self">software development</a> has yet to reach “the point where you can really collaborate with these tools the way you can with a human programmer.”</p><h2>Challenges With AI Coding Tools</h2><p>According to the study, AI still struggles with several crucial facets of coding: sweeping scopes involving huge codebases, the extended context lengths of millions of lines of code, higher levels of logical complexity, and long-horizon or long-term planning about the structure and design of code to maintain code quality.</p><p><a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/ksen.html" rel="noopener noreferrer" target="_blank">Koushik Sen</a>, a professor of computer science at <a href="https://spectrum.ieee.org/tag/uc-berkeley">UC Berkeley</a> and also a co-author of the paper, cites fixing a <a href="https://spectrum.ieee.org/memory-safe-programming-languages" target="_self">memory safety</a> bug as an example. (Such bugs can cause crashes, corrupt data, and open security vulnerabilities.) <a href="https://spectrum.ieee.org/tag/software-engineers" target="_self">Software engineers</a> might approach debugging by first determining where the error originates, “which might be far away from where it’s crashing, especially in a large codebase,” Sen explains. They’ll also have to understand the semantics of the code and how it works, and make changes based on that understanding. “You might have to not only fix that bug but change the entire memory management,” he adds.</p><p>These kinds of complex tasks can be difficult for AI development tools to navigate, resulting in <a href="https://spectrum.ieee.org/ai-hallucination" target="_self">hallucinations</a> about where the bug is or its root cause, as well as irrelevant suggestions or code fixes with subtle problems. “There are many failure points, and I don’t think the current <a href="https://spectrum.ieee.org/tag/llms" target="_self">LLMs</a> [<a href="https://spectrum.ieee.org/tag/large-language-models">large language models</a>] are good at handling that,” says Sen.</p><p>Among the various paths suggested by the researchers toward solving these AI coding challenges—such as training code LLMs to better collaborate with humans and ensuring human oversight for machine-generated code—the human element endures.</p><p>“A big part of <a href="https://spectrum.ieee.org/tag/software-development">software development</a> is building a shared vocabulary and a shared understanding of what the problem is and how we want to describe these features. It’s about coming up with the right metaphor for the architecture of our system,” Solar-Lezama says. “It’s something that can be difficult to replicate by a machine. Our interfaces with these tools are still quite narrow compared to all the things that we can do when interacting with real colleagues.”</p><h2>Enhancing AI-Human Collaboration in Coding</h2><p>Creating better interfaces, which today are driven by <a href="https://spectrum.ieee.org/prompt-engineering-is-dead" target="_self">prompt engineering</a>, is integral for developer productivity in the long run. “If it takes longer to explain to the system all the things you want to do and all the details of what you want to do, then all you have is just programming by another name,” says Solar-Lezama.</p><p><a href="https://cse.nd.edu/faculty/shreya-kumar/" rel="noopener noreferrer" target="_blank">Shreya Kumar</a>, a software engineer and an associate teaching professor in computer science at the <a href="https://www.nd.edu/" rel="noopener noreferrer" target="_blank">University of Notre Dame</a> who was not involved in the research, echoes the sentiment. “The reason we have a programming language is because we need to be unambiguous. But right now, we’re trying to adjust the prompt [in a way] that the tool will be able to understand,” she says. “We’re adapting to the tool, so instead of the tool serving us, we’re serving the tool. And it is sometimes more work than just writing the code.”</p><p>As the study notes, one way to address the dilemma of human-AI interaction is for AI systems to learn to quantify uncertainty and communicate proactively, asking for clarification or more information when faced with vague instructions or unclear scenarios. Sen adds that AI models might also be “missing context that I have in my mind as a developer—hidden concepts that are embedded in the code but hard to decipher from it. And if I give any hint to the LLM about what is happening, it might actually make better progress.”</p><p>For <a href="https://www.comp.nus.edu.sg/cs/people/abhik/" rel="noopener noreferrer" target="_blank">Abhik Roychoudhury</a>, a professor of computer science at the <a href="https://www.nus.edu.sg/" rel="noopener noreferrer" target="_blank">National University of Singapore</a> who was also not involved in the research, a crucial aspect missing from the paper and from most AI-backed software development tools entails capturing user intent.</p><p>“A software engineer is doing a lot of thinking in understanding the intent of the code. This intent inference—what the program is trying to do, what the program is supposed to do, and the deviation between the two—is what helps in a lot of <a href="https://spectrum.ieee.org/tag/software-engineering">software engineering</a> tasks. If this outlook can be brought in future AI offerings for software engineering, then it will get closer to what the software engineer does.”</p><h2>Where Does AI Coding Go From Here? </h2><p>Roychoudhury also assumes that many of the challenges identified in the paper are either being worked on now or “would be solved relatively quickly” due to the rapid pace of progress in AI for software engineering. Additionally, he believes that an <a href="https://spectrum.ieee.org/tag/agentic-ai" target="_self">agentic AI</a> approach can help, viewing significant promise in <a href="https://spectrum.ieee.org/tag/agentic-ai">AI agents</a> for processing requirements specifications and ensuring they can be enforced at the code level.</p><p>“I feel the <a href="https://spectrum.ieee.org/tag/automation">automation</a> of software engineering via agents is probably irreversible. I would dare say that it is going to happen,” Roychoudhury says.</p><p>Sen is of the same view but looks beyond agentic AI initiatives. He pinpoints ideas such as <a href="https://spectrum.ieee.org/evolutionary-ai-coding-agents" target="_self">evolutionary algorithms to enhance AI coding skills</a> and projects like <a href="https://spectrum.ieee.org/deepmind-alphaevolve" target="_self">AlphaEvolve</a> that employ <a href="https://spectrum.ieee.org/fighting-buggy-code-with-genetic-algorithms" target="_self">genetic algorithms</a> “to shuffle the solutions, pick the best ones, and then continue improving those solutions. We need to adopt a similar technology for coding agents, where the code is continuously improving in the background.”</p><p>However, Roychoudhury cautions that the bigger question lies in “whether you can <a href="https://spectrum.ieee.org/chatgpt-reliability" target="_self">trust</a> the agent, and this issue of trust will be further exacerbated as more and more of the coding gets automated.”</p><p>That’s why human supervision remains vital. “There should be a check and verify process. If you want a trustworthy system, you do need to have humans in the loop,” says Notre Dame’s Kumar.</p><p>Solar-Lezama agrees. “I think it’s always going to be the case that we’re ultimately going to want to build software for people, and that means we have to figure out what it is we want to write,” he says. “In some ways, achieving full automation really means that we get to now work at a different level of abstraction.”</p><p>So while AI may become a “real coder” in the near future, Roychoudhury acknowledges that it probably won’t gain software developers’ complete trust as a team member, and thus might not be allowed to do its tasks fully autonomously. “That team dynamics—when an AI agent can become a member of the team, what kind of tasks will it be doing, and how the rest of the team will be interacting with the agent—is essentially where the human-AI boundary lies,” he says.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Seedbox Lite: A lightweight torrent streaming app with instant playback (116 pts)]]></title>
            <link>https://github.com/hotheadhacker/seedbox-lite</link>
            <guid>45065278</guid>
            <pubDate>Fri, 29 Aug 2025 15:18:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hotheadhacker/seedbox-lite">https://github.com/hotheadhacker/seedbox-lite</a>, See on <a href="https://news.ycombinator.com/item?id=45065278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🎬 SeedBox Lite</h2><a id="user-content--seedbox-lite" aria-label="Permalink: 🎬 SeedBox Lite" href="#-seedbox-lite"></a></p>
<p dir="auto">Stream Torrents Instantly</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Overview</h2><a id="user-content--overview" aria-label="Permalink: 🚀 Overview" href="#-overview"></a></p>
<p dir="auto">SeedBox Lite is a cutting-edge torrent streaming platform that allows you to watch movies and TV shows instantly without waiting for complete downloads. Built with modern web technologies, it provides a Netflix-like experience with powerful torrent capabilities.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">✨ Key Highlights</h3><a id="user-content--key-highlights" aria-label="Permalink: ✨ Key Highlights" href="#-key-highlights"></a></p>
<ul dir="auto">
<li><strong>🎯 Instant Streaming</strong> - Start watching immediately as the torrent downloads</li>
<li><strong>🔐 Password Protection</strong> - Secure access with authentication</li>
<li><strong>📱 Mobile Optimized</strong> - Perfect responsive design for all devices</li>
<li><strong>🎥 Smart Video Player</strong> - Advanced player with subtitles and fullscreen support</li>
<li><strong>⚡ Fast Setup</strong> - Deploy in minutes with Docker or PM2</li>
<li><strong>🌐 Cross-Platform</strong> - Works on Windows, macOS, and Linux</li>
<li><strong>🎨 Modern UI</strong> - Clean, intuitive interface inspired by popular streaming services</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Features</h2><a id="user-content--features" aria-label="Permalink: 🎯 Features" href="#-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Streaming Features</h3><a id="user-content-core-streaming-features" aria-label="Permalink: Core Streaming Features" href="#core-streaming-features"></a></p>
<ul dir="auto">
<li><strong>Torrent to Stream</strong> - Convert any movie/TV torrent to instant streaming</li>
<li><strong>Progress Tracking</strong> - Real-time download progress and cache management</li>
<li><strong>Smart Caching</strong> - Intelligent caching system with configurable limits</li>
<li><strong>Multiple Formats</strong> - Support for MP4, MKV, AVI, and more video formats</li>
<li><strong>Subtitle Support</strong> - Automatic subtitle detection and loading</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">User Experience</h3><a id="user-content-user-experience" aria-label="Permalink: User Experience" href="#user-experience"></a></p>
<ul dir="auto">
<li><strong>Netflix-Style Interface</strong> - Familiar and intuitive design</li>
<li><strong>Mobile-First Design</strong> - Optimized for smartphones and tablets</li>
<li><strong>Native Fullscreen</strong> - True fullscreen experience on mobile devices</li>
<li><strong>Gesture Controls</strong> - Double-tap to fullscreen, intuitive video controls</li>
<li><strong>Responsive Layout</strong> - Adapts perfectly to any screen size</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Technical Features</h3><a id="user-content-technical-features" aria-label="Permalink: Technical Features" href="#technical-features"></a></p>
<ul dir="auto">
<li><strong>Password Authentication</strong> - Secure access control</li>
<li><strong>CORS Enabled</strong> - Cross-origin resource sharing for flexible deployment</li>
<li><strong>Health Monitoring</strong> - Built-in health checks and monitoring</li>
<li><strong>Production Ready</strong> - Optimized for production deployments</li>
<li><strong>Docker Support</strong> - Easy containerized deployment</li>
<li><strong>PM2 Integration</strong> - Process management for Node.js applications</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mobile Optimizations</h3><a id="user-content-mobile-optimizations" aria-label="Permalink: Mobile Optimizations" href="#mobile-optimizations"></a></p>
<ul dir="auto">
<li><strong>iOS Safari Support</strong> - Native fullscreen using WebKit APIs</li>
<li><strong>Android Chrome</strong> - Optimized for Android mobile browsers</li>
<li><strong>Range Requests</strong> - HTTP range support for smooth video seeking</li>
<li><strong>Mobile Viewport</strong> - Proper viewport handling for app-like experience</li>
<li><strong>Touch Optimized</strong> - Gesture-friendly video controls</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📸 Screenshots</h2><a id="user-content--screenshots" aria-label="Permalink: 📸 Screenshots" href="#-screenshots"></a></p>
<p dir="auto"><a href="https://github.com/hotheadhacker/seedbox-lite/tree/main/screenshots">View all screenshots</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content--quick-start" aria-label="Permalink: 🚀 Quick Start" href="#-quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Docker (Recommended)</h3><a id="user-content-using-docker-recommended" aria-label="Permalink: Using Docker (Recommended)" href="#using-docker-recommended"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone https://github.com/hotheadhacker/seedbox-lite.git
cd seedbox-lite

# Start with Docker Compose
docker-compose up -d

# Access the application
open http://localhost:5174"><pre><span><span>#</span> Clone the repository</span>
git clone https://github.com/hotheadhacker/seedbox-lite.git
<span>cd</span> seedbox-lite

<span><span>#</span> Start with Docker Compose</span>
docker-compose up -d

<span><span>#</span> Access the application</span>
open http://localhost:5174</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using PM2</h3><a id="user-content-using-pm2" aria-label="Permalink: Using PM2" href="#using-pm2"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone and install dependencies
git clone https://github.com/hotheadhacker/seedbox-lite.git
cd seedbox-lite

# Install backend dependencies
cd server &amp;&amp; npm install

# Install frontend dependencies  
cd ../client &amp;&amp; npm install

# Build frontend
npm run build

# Start with PM2
pm2 start ecosystem.config.js"><pre><span><span>#</span> Clone and install dependencies</span>
git clone https://github.com/hotheadhacker/seedbox-lite.git
<span>cd</span> seedbox-lite

<span><span>#</span> Install backend dependencies</span>
<span>cd</span> server <span>&amp;&amp;</span> npm install

<span><span>#</span> Install frontend dependencies  </span>
<span>cd</span> ../client <span>&amp;&amp;</span> npm install

<span><span>#</span> Build frontend</span>
npm run build

<span><span>#</span> Start with PM2</span>
pm2 start ecosystem.config.js</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">📋 Prerequisites</h2><a id="user-content--prerequisites" aria-label="Permalink: 📋 Prerequisites" href="#-prerequisites"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">System Requirements</h3><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"></a></p>
<ul dir="auto">
<li><strong>Node.js</strong> 18+</li>
<li><strong>npm</strong> 8+</li>
<li><strong>Docker</strong> 20+ (for Docker deployment)</li>
<li><strong>PM2</strong> (for PM2 deployment)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Operating System Support</h3><a id="user-content-operating-system-support" aria-label="Permalink: Operating System Support" href="#operating-system-support"></a></p>
<ul dir="auto">
<li>✅ Windows 10/11</li>
<li>✅ macOS 10.15+</li>
<li>✅ Ubuntu 18.04+</li>
<li>✅ Debian 10+</li>
<li>✅ CentOS 7+</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Browser Support</h3><a id="user-content-browser-support" aria-label="Permalink: Browser Support" href="#browser-support"></a></p>
<ul dir="auto">
<li>✅ Chrome 90+</li>
<li>✅ Firefox 88+</li>
<li>✅ Safari 14+</li>
<li>✅ Edge 90+</li>
<li>✅ Mobile browsers (iOS Safari, Android Chrome)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠 Installation</h2><a id="user-content--installation" aria-label="Permalink: 🛠 Installation" href="#-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 1: Docker Deployment (Recommended)</h3><a id="user-content-method-1-docker-deployment-recommended" aria-label="Permalink: Method 1: Docker Deployment (Recommended)" href="#method-1-docker-deployment-recommended"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 1: Clone Repository</h4><a id="user-content-step-1-clone-repository" aria-label="Permalink: Step 1: Clone Repository" href="#step-1-clone-repository"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/hotheadhacker/seedbox-lite.git
cd seedbox-lite"><pre>git clone https://github.com/hotheadhacker/seedbox-lite.git
<span>cd</span> seedbox-lite</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 2: Configure Environment</h4><a id="user-content-step-2-configure-environment" aria-label="Permalink: Step 2: Configure Environment" href="#step-2-configure-environment"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Copy and edit environment variables
cp .env.example .env
nano .env"><pre><span><span>#</span> Copy and edit environment variables</span>
cp .env.example .env
nano .env</pre></div>
<p dir="auto"><strong>Key Environment Variables:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Server Configuration
NODE_ENV=production
SERVER_PORT=3001
ACCESS_PASSWORD=your_secure_password

# Frontend Configuration  
FRONTEND_URL=http://localhost:5174
VITE_API_BASE_URL=http://localhost:3001

# Docker Ports
BACKEND_PORT=3001
FRONTEND_PORT=5174"><pre><span><span>#</span> Server Configuration</span>
NODE_ENV=production
SERVER_PORT=3001
ACCESS_PASSWORD=your_secure_password

<span><span>#</span> Frontend Configuration  </span>
FRONTEND_URL=http://localhost:5174
VITE_API_BASE_URL=http://localhost:3001

<span><span>#</span> Docker Ports</span>
BACKEND_PORT=3001
FRONTEND_PORT=5174</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 3: Deploy</h4><a id="user-content-step-3-deploy" aria-label="Permalink: Step 3: Deploy" href="#step-3-deploy"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f"><pre><span><span>#</span> Start all services</span>
docker-compose up -d

<span><span>#</span> Check status</span>
docker-compose ps

<span><span>#</span> View logs</span>
docker-compose logs -f</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 4: Access Application</h4><a id="user-content-step-4-access-application" aria-label="Permalink: Step 4: Access Application" href="#step-4-access-application"></a></p>
<ul dir="auto">
<li><strong>Frontend</strong>: <a href="http://localhost:5174/" rel="nofollow">http://localhost:5174</a></li>
<li><strong>Backend API</strong>: <a href="http://localhost:3001/" rel="nofollow">http://localhost:3001</a></li>
<li><strong>Default Login</strong>: Password set in <code>ACCESS_PASSWORD</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 2: PM2 Deployment</h3><a id="user-content-method-2-pm2-deployment" aria-label="Permalink: Method 2: PM2 Deployment" href="#method-2-pm2-deployment"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 1: System Setup</h4><a id="user-content-step-1-system-setup" aria-label="Permalink: Step 1: System Setup" href="#step-1-system-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install Node.js 18+
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# Install PM2 globally
npm install -g pm2"><pre><span><span>#</span> Install Node.js 18+</span>
curl -fsSL https://deb.nodesource.com/setup_18.x <span>|</span> sudo -E bash -
sudo apt-get install -y nodejs

<span><span>#</span> Install PM2 globally</span>
npm install -g pm2</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 2: Application Setup</h4><a id="user-content-step-2-application-setup" aria-label="Permalink: Step 2: Application Setup" href="#step-2-application-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone https://github.com/hotheadhacker/seedbox-lite.git
cd seedbox-lite

# Install backend dependencies
cd server
npm install
cd ..

# Install and build frontend
cd client
npm install
npm run build
cd .."><pre><span><span>#</span> Clone repository</span>
git clone https://github.com/hotheadhacker/seedbox-lite.git
<span>cd</span> seedbox-lite

<span><span>#</span> Install backend dependencies</span>
<span>cd</span> server
npm install
<span>cd</span> ..

<span><span>#</span> Install and build frontend</span>
<span>cd</span> client
npm install
npm run build
<span>cd</span> ..</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 3: Configure Environment</h4><a id="user-content-step-3-configure-environment" aria-label="Permalink: Step 3: Configure Environment" href="#step-3-configure-environment"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Backend environment
cd server
cp .env.example .env
nano .env"><pre><span><span>#</span> Backend environment</span>
<span>cd</span> server
cp .env.example .env
nano .env</pre></div>
<p dir="auto"><strong>Backend <code>.env</code> Configuration:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="NODE_ENV=production
SERVER_PORT=3001
SERVER_HOST=0.0.0.0
ACCESS_PASSWORD=your_secure_password
FRONTEND_URL=http://localhost:5174"><pre>NODE_ENV=production
SERVER_PORT=3001
SERVER_HOST=0.0.0.0
ACCESS_PASSWORD=your_secure_password
FRONTEND_URL=http://localhost:5174</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 4: Start Services</h4><a id="user-content-step-4-start-services" aria-label="Permalink: Step 4: Start Services" href="#step-4-start-services"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start backend with PM2
cd server
pm2 start ecosystem.config.js

# Serve frontend with nginx or serve
cd ../client/dist
npx serve -s . -l 5174

# Or use PM2 for frontend
pm2 start &quot;npx serve -s . -l 5174&quot; --name &quot;seedbox-frontend&quot;"><pre><span><span>#</span> Start backend with PM2</span>
<span>cd</span> server
pm2 start ecosystem.config.js

<span><span>#</span> Serve frontend with nginx or serve</span>
<span>cd</span> ../client/dist
npx serve -s <span>.</span> -l 5174

<span><span>#</span> Or use PM2 for frontend</span>
pm2 start <span><span>"</span>npx serve -s . -l 5174<span>"</span></span> --name <span><span>"</span>seedbox-frontend<span>"</span></span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 5: PM2 Management</h4><a id="user-content-step-5-pm2-management" aria-label="Permalink: Step 5: PM2 Management" href="#step-5-pm2-management"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# View running processes
pm2 list

# View logs
pm2 logs

# Restart services
pm2 restart all

# Save PM2 configuration
pm2 save
pm2 startup"><pre><span><span>#</span> View running processes</span>
pm2 list

<span><span>#</span> View logs</span>
pm2 logs

<span><span>#</span> Restart services</span>
pm2 restart all

<span><span>#</span> Save PM2 configuration</span>
pm2 save
pm2 startup</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Method 3: Development Setup</h3><a id="user-content-method-3-development-setup" aria-label="Permalink: Method 3: Development Setup" href="#method-3-development-setup"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 1: Clone and Install</h4><a id="user-content-step-1-clone-and-install" aria-label="Permalink: Step 1: Clone and Install" href="#step-1-clone-and-install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/hotheadhacker/seedbox-lite.git
cd seedbox-lite

# Install backend dependencies
cd server
npm install

# Install frontend dependencies
cd ../client  
npm install"><pre>git clone https://github.com/hotheadhacker/seedbox-lite.git
<span>cd</span> seedbox-lite

<span><span>#</span> Install backend dependencies</span>
<span>cd</span> server
npm install

<span><span>#</span> Install frontend dependencies</span>
<span>cd</span> ../client  
npm install</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 2: Configure Development Environment</h4><a id="user-content-step-2-configure-development-environment" aria-label="Permalink: Step 2: Configure Development Environment" href="#step-2-configure-development-environment"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Backend environment
cd server
cp .env.example .env"><pre><span><span>#</span> Backend environment</span>
<span>cd</span> server
cp .env.example .env</pre></div>
<p dir="auto"><strong>Development <code>.env</code>:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="NODE_ENV=development
SERVER_PORT=3000
SERVER_HOST=localhost
ACCESS_PASSWORD=seedbox123
FRONTEND_URL=http://localhost:5173"><pre>NODE_ENV=development
SERVER_PORT=3000
SERVER_HOST=localhost
ACCESS_PASSWORD=seedbox123
FRONTEND_URL=http://localhost:5173</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 3: Start Development Servers</h4><a id="user-content-step-3-start-development-servers" aria-label="Permalink: Step 3: Start Development Servers" href="#step-3-start-development-servers"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Terminal 1: Start backend
cd server
npm run dev

# Terminal 2: Start frontend  
cd client
npm run dev"><pre><span><span>#</span> Terminal 1: Start backend</span>
<span>cd</span> server
npm run dev

<span><span>#</span> Terminal 2: Start frontend  </span>
<span>cd</span> client
npm run dev</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🧪 Testing</h2><a id="user-content--testing" aria-label="Permalink: 🧪 Testing" href="#-testing"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker Testing</h3><a id="user-content-docker-testing" aria-label="Permalink: Docker Testing" href="#docker-testing"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Health check
curl http://localhost:3001/api/health
curl http://localhost:5174/health

# API endpoints
curl -X POST http://localhost:3001/api/auth/login \
  -H &quot;Content-Type: application/json&quot; \
  -d '{&quot;password&quot;:&quot;your_password&quot;}'

# Cache stats
curl http://localhost:3001/api/cache/stats"><pre><span><span>#</span> Health check</span>
curl http://localhost:3001/api/health
curl http://localhost:5174/health

<span><span>#</span> API endpoints</span>
curl -X POST http://localhost:3001/api/auth/login \
  -H <span><span>"</span>Content-Type: application/json<span>"</span></span> \
  -d <span><span>'</span>{"password":"your_password"}<span>'</span></span>

<span><span>#</span> Cache stats</span>
curl http://localhost:3001/api/cache/stats</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">PM2 Testing</h3><a id="user-content-pm2-testing" aria-label="Permalink: PM2 Testing" href="#pm2-testing"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Check PM2 status
pm2 list
pm2 logs seedbox-backend
pm2 logs seedbox-frontend

# Test API endpoints
curl http://localhost:3001/api/health
curl http://localhost:5174"><pre><span><span>#</span> Check PM2 status</span>
pm2 list
pm2 logs seedbox-backend
pm2 logs seedbox-frontend

<span><span>#</span> Test API endpoints</span>
curl http://localhost:3001/api/health
curl http://localhost:5174</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Frontend Testing</h3><a id="user-content-frontend-testing" aria-label="Permalink: Frontend Testing" href="#frontend-testing"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd client
npm test

# Run Cypress e2e tests
npm run test:e2e

# Accessibility testing
npm run test:a11y"><pre><span>cd</span> client
npm <span>test</span>

<span><span>#</span> Run Cypress e2e tests</span>
npm run test:e2e

<span><span>#</span> Accessibility testing</span>
npm run test:a11y</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Backend Testing</h3><a id="user-content-backend-testing" aria-label="Permalink: Backend Testing" href="#backend-testing"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="cd server
npm test

# API integration tests
npm run test:integration

# Load testing
npm run test:load"><pre><span>cd</span> server
npm <span>test</span>

<span><span>#</span> API integration tests</span>
npm run test:integration

<span><span>#</span> Load testing</span>
npm run test:load</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Configuration</h2><a id="user-content--configuration" aria-label="Permalink: 📚 Configuration" href="#-configuration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Environment Variables Reference</h3><a id="user-content-environment-variables-reference" aria-label="Permalink: Environment Variables Reference" href="#environment-variables-reference"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Backend Variables</h4><a id="user-content-backend-variables" aria-label="Permalink: Backend Variables" href="#backend-variables"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>NODE_ENV</code></td>
<td><code>production</code></td>
<td>Application environment</td>
</tr>
<tr>
<td><code>SERVER_PORT</code></td>
<td><code>3001</code></td>
<td>Backend server port</td>
</tr>
<tr>
<td><code>SERVER_HOST</code></td>
<td><code>0.0.0.0</code></td>
<td>Backend server host</td>
</tr>
<tr>
<td><code>ACCESS_PASSWORD</code></td>
<td><code>seedbox123</code></td>
<td>Authentication password</td>
</tr>
<tr>
<td><code>MAX_CACHE_SIZE</code></td>
<td><code>5GB</code></td>
<td>Maximum cache size</td>
</tr>
<tr>
<td><code>CLEANUP_INTERVAL</code></td>
<td><code>1h</code></td>
<td>Cache cleanup interval</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Frontend Variables</h4><a id="user-content-frontend-variables" aria-label="Permalink: Frontend Variables" href="#frontend-variables"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>VITE_API_BASE_URL</code></td>
<td><code>http://localhost:3001</code></td>
<td>Backend API URL</td>
</tr>
<tr>
<td><code>FRONTEND_URL</code></td>
<td><code>http://localhost:5174</code></td>
<td>Frontend URL</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Docker Variables</h4><a id="user-content-docker-variables" aria-label="Permalink: Docker Variables" href="#docker-variables"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BACKEND_PORT</code></td>
<td><code>3001</code></td>
<td>Docker backend port mapping</td>
</tr>
<tr>
<td><code>FRONTEND_PORT</code></td>
<td><code>5174</code></td>
<td>Docker frontend port mapping</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Advanced Configuration</h3><a id="user-content-advanced-configuration" aria-label="Permalink: Advanced Configuration" href="#advanced-configuration"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Nginx Configuration (Production)</h4><a id="user-content-nginx-configuration-production" aria-label="Permalink: Nginx Configuration (Production)" href="#nginx-configuration-production"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="server {
    listen 80;
    server_name your-domain.com;
    
    location / {
        proxy_pass http://localhost:5174;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    location /api/ {
        proxy_pass http://localhost:3001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}"><pre><span>server</span> {
    <span>listen</span> <span>80</span>;
    <span>server_name</span> your-domain.com;
    
    <span>location</span> <span>/ </span>{
        <span>proxy_pass</span> http://localhost:5174;
        <span>proxy_set_header</span> Host <span>$host</span>;
        <span>proxy_set_header</span> X-Real-IP <span>$remote_addr</span>;
    }
    
    <span>location</span> <span>/api/ </span>{
        <span>proxy_pass</span> http://localhost:3001;
        <span>proxy_set_header</span> Host <span>$host</span>;
        <span>proxy_set_header</span> X-Real-IP <span>$remote_addr</span>;
    }
}</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">SSL/HTTPS Setup</h4><a id="user-content-sslhttps-setup" aria-label="Permalink: SSL/HTTPS Setup" href="#sslhttps-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install Certbot
sudo apt install certbot python3-certbot-nginx

# Get SSL certificate
sudo certbot --nginx -d your-domain.com

# Auto-renewal
sudo crontab -e
# Add: 0 12 * * * /usr/bin/certbot renew --quiet"><pre><span><span>#</span> Install Certbot</span>
sudo apt install certbot python3-certbot-nginx

<span><span>#</span> Get SSL certificate</span>
sudo certbot --nginx -d your-domain.com

<span><span>#</span> Auto-renewal</span>
sudo crontab -e
<span><span>#</span> Add: 0 12 * * * /usr/bin/certbot renew --quiet</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Troubleshooting</h2><a id="user-content--troubleshooting" aria-label="Permalink: 🔧 Troubleshooting" href="#-troubleshooting"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Common Issues</h3><a id="user-content-common-issues" aria-label="Permalink: Common Issues" href="#common-issues"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Port Conflicts</h4><a id="user-content-port-conflicts" aria-label="Permalink: Port Conflicts" href="#port-conflicts"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Check if ports are in use
lsof -i :3001
lsof -i :5174

# Kill processes using ports
sudo kill -9 $(lsof -ti:3001)
sudo kill -9 $(lsof -ti:5174)"><pre><span><span>#</span> Check if ports are in use</span>
lsof -i :3001
lsof -i :5174

<span><span>#</span> Kill processes using ports</span>
sudo <span>kill</span> -9 <span><span>$(</span>lsof -ti:3001<span>)</span></span>
sudo <span>kill</span> -9 <span><span>$(</span>lsof -ti:5174<span>)</span></span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Docker Issues</h4><a id="user-content-docker-issues" aria-label="Permalink: Docker Issues" href="#docker-issues"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Rebuild containers
docker-compose down
docker-compose up --build

# Clear Docker cache
docker system prune -a

# Check container logs
docker-compose logs seedbox-backend
docker-compose logs seedbox-frontend"><pre><span><span>#</span> Rebuild containers</span>
docker-compose down
docker-compose up --build

<span><span>#</span> Clear Docker cache</span>
docker system prune -a

<span><span>#</span> Check container logs</span>
docker-compose logs seedbox-backend
docker-compose logs seedbox-frontend</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">PM2 Issues</h4><a id="user-content-pm2-issues" aria-label="Permalink: PM2 Issues" href="#pm2-issues"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Reset PM2
pm2 kill
pm2 start ecosystem.config.js

# Check PM2 logs
pm2 logs --lines 50

# Monitor PM2 processes
pm2 monit"><pre><span><span>#</span> Reset PM2</span>
pm2 <span>kill</span>
pm2 start ecosystem.config.js

<span><span>#</span> Check PM2 logs</span>
pm2 logs --lines 50

<span><span>#</span> Monitor PM2 processes</span>
pm2 monit</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Permission Issues</h4><a id="user-content-permission-issues" aria-label="Permalink: Permission Issues" href="#permission-issues"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Fix file permissions
sudo chown -R $USER:$USER .
chmod +x deploy.sh

# Docker permission issues
sudo usermod -aG docker $USER
newgrp docker"><pre><span><span>#</span> Fix file permissions</span>
sudo chown -R <span>$USER</span>:<span>$USER</span> <span>.</span>
chmod +x deploy.sh

<span><span>#</span> Docker permission issues</span>
sudo usermod -aG docker <span>$USER</span>
newgrp docker</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mobile Video Issues</h4><a id="user-content-mobile-video-issues" aria-label="Permalink: Mobile Video Issues" href="#mobile-video-issues"></a></p>
<ul dir="auto">
<li>Ensure CORS is enabled in backend</li>
<li>Check video format compatibility</li>
<li>Verify range request support</li>
<li>Test with different browsers</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📖 API Documentation</h2><a id="user-content--api-documentation" aria-label="Permalink: 📖 API Documentation" href="#-api-documentation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Authentication Endpoints</h3><a id="user-content-authentication-endpoints" aria-label="Permalink: Authentication Endpoints" href="#authentication-endpoints"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="POST /api/auth/login
{
  &quot;password&quot;: &quot;your_password&quot;
}"><pre>POST /api/auth/login
{
  <span><span>"</span>password<span>"</span></span>: <span><span>"</span>your_password<span>"</span></span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Torrent Endpoints</h3><a id="user-content-torrent-endpoints" aria-label="Permalink: Torrent Endpoints" href="#torrent-endpoints"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="GET /api/torrents/search?q=movie+name
POST /api/torrents/add
{
  &quot;magnetLink&quot;: &quot;magnet:...&quot;
}"><pre>GET /api/torrents/search<span>?</span>q=movie+name
POST /api/torrents/add
{
  <span><span>"</span>magnetLink<span>"</span></span>: <span><span>"</span>magnet:...<span>"</span></span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Streaming Endpoints</h3><a id="user-content-streaming-endpoints" aria-label="Permalink: Streaming Endpoints" href="#streaming-endpoints"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="GET /api/stream/:torrentId/:fileIndex
Range requests supported for video seeking"><pre>GET /api/stream/:torrentId/:fileIndex
Range requests supported <span>for</span> video seeking</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cache Management</h3><a id="user-content-cache-management" aria-label="Permalink: Cache Management" href="#cache-management"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="GET /api/cache/stats
POST /api/cache/clear"><pre>GET /api/cache/stats
POST /api/cache/clear</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛡 Security</h2><a id="user-content--security" aria-label="Permalink: 🛡 Security" href="#-security"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Best Practices</h3><a id="user-content-best-practices" aria-label="Permalink: Best Practices" href="#best-practices"></a></p>
<ul dir="auto">
<li>Change default password immediately</li>
<li>Use HTTPS in production</li>
<li>Keep dependencies updated</li>
<li>Enable firewall rules</li>
<li>Regular security audits</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security Headers</h3><a id="user-content-security-headers" aria-label="Permalink: Security Headers" href="#security-headers"></a></p>
<p dir="auto">The application includes security headers:</p>
<ul dir="auto">
<li>X-Frame-Options: SAMEORIGIN</li>
<li>X-Content-Type-Options: nosniff</li>
<li>X-XSS-Protection: 1; mode=block</li>
<li>Referrer-Policy: no-referrer-when-downgrade</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Deployment</h2><a id="user-content--deployment" aria-label="Permalink: 🚀 Deployment" href="#-deployment"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Production Deployment Checklist</h3><a id="user-content-production-deployment-checklist" aria-label="Permalink: Production Deployment Checklist" href="#production-deployment-checklist"></a></p>
<ul>
<li> Change default passwords</li>
<li> Configure HTTPS/SSL</li>
<li> Set up monitoring</li>
<li> Configure backups</li>
<li> Set up log rotation</li>
<li> Configure firewall</li>
<li> Test mobile compatibility</li>
<li> Verify video streaming</li>
<li> Test authentication</li>
<li> Monitor performance</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scaling</h3><a id="user-content-scaling" aria-label="Permalink: Scaling" href="#scaling"></a></p>
<p dir="auto">For high-traffic deployments:</p>
<ul dir="auto">
<li>Use load balancer (nginx/HAProxy)</li>
<li>Scale backend horizontally</li>
<li>Implement Redis for session storage</li>
<li>Use CDN for static assets</li>
<li>Monitor resource usage</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📞 Support</h2><a id="user-content--support" aria-label="Permalink: 📞 Support" href="#-support"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Getting Help</h3><a id="user-content-getting-help" aria-label="Permalink: Getting Help" href="#getting-help"></a></p>
<ul dir="auto">
<li>📖 <a href="https://github.com/hotheadhacker/seedbox-lite/blob/main/docs">Documentation</a></li>
<li>🐛 <a href="https://github.com/hotheadhacker/seedbox-lite/issues">Issue Tracker</a></li>
<li>💬 <a href="https://github.com/hotheadhacker/seedbox-lite/discussions">Discussions</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributing</h3><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<ol dir="auto">
<li>Fork the repository</li>
<li>Create feature branch</li>
<li>Make changes</li>
<li>Add tests</li>
<li>Submit pull request</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Legal Disclaimer</h2><a id="user-content-️-legal-disclaimer" aria-label="Permalink: ⚠️ Legal Disclaimer" href="#️-legal-disclaimer"></a></p>
<p dir="auto"><strong>IMPORTANT: Please read this disclaimer carefully before using SeedBox Lite.</strong></p>
<p dir="auto">SeedBox Lite is an open-source project provided for educational and personal use only. We do not endorse, promote, or facilitate copyright infringement, illegal streaming, or piracy in any form. This software is designed to be used with legal content only.</p>
<ul dir="auto">
<li>We do not host, store, or distribute any content. All torrents and media are accessed through your own connections.</li>
<li>This application is intended for use with content that you have the legal right to access and stream.</li>
<li>Users are solely responsible for how they use this software and for ensuring compliance with all applicable laws in their jurisdiction.</li>
<li>The creators and contributors of SeedBox Lite take no responsibility for how this software is used.</li>
<li>Using torrents to download or share copyrighted materials without permission may be illegal in your country.</li>
</ul>
<p dir="auto">By using SeedBox Lite, you acknowledge that you understand these terms and agree to use the software responsibly and legally.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📄 License</h2><a id="user-content--license" aria-label="Permalink: 📄 License" href="#-license"></a></p>
<p dir="auto">This project is licensed under the <strong>Custom Non-Commercial License</strong> - see the <a href="https://github.com/hotheadhacker/seedbox-lite/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto"><strong>Important License Restrictions:</strong></p>
<ul dir="auto">
<li>This software is provided for personal, educational, and non-commercial use only</li>
<li>Commercial use is strictly prohibited without explicit written permission</li>
<li>Redistribution must include this license and copyright notice</li>
<li>No warranty or liability is provided with this software</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Acknowledgments</h2><a id="user-content--acknowledgments" aria-label="Permalink: 🙏 Acknowledgments" href="#-acknowledgments"></a></p>
<ul dir="auto">
<li>WebTorrent for torrent streaming capabilities</li>
<li>React team for the amazing framework</li>
<li>Docker community for containerization</li>
<li>All contributors and users</li>
</ul>
<hr>
<div dir="auto">
<p dir="auto"><strong>Made with ❤️ by <a href="https://github.com/hotheadhacker">hotheadhacker</a></strong></p>
<p dir="auto">⭐ Star this repo if you find it useful!</p>
</div>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>