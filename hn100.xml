<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 29 Jul 2024 02:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Microsoft technical breakdown of CrowdStrike incident (226 pts)]]></title>
            <link>https://www.microsoft.com/en-us/security/blog/2024/07/27/windows-security-best-practices-for-integrating-and-managing-security-tools/</link>
            <guid>41095530</guid>
            <pubDate>Sun, 28 Jul 2024 19:55:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.microsoft.com/en-us/security/blog/2024/07/27/windows-security-best-practices-for-integrating-and-managing-security-tools/">https://www.microsoft.com/en-us/security/blog/2024/07/27/windows-security-best-practices-for-integrating-and-managing-security-tools/</a>, See on <a href="https://news.ycombinator.com/item?id=41095530">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
				
<p>Windows is an open and flexible platform used by many of the world’s top businesses for high availability use cases where security and availability are non-negotiable.</p>



<p>To meet those needs:</p>



<ol>
<li>Windows provides a range of operating modes that customers can choose from. This includes the ability to limit what can run to only approved software and drivers. This can increase security and reliability by making Windows operate in a mode closer to mobile phones or appliances.</li>



<li>Customers can choose integrated security monitoring and detection capabilities that are included with Windows. Or they can choose to replace or supplement this security with a wide variety of choices from a vibrant open ecosystem of vendors.</li>
</ol>



<p>In this blog post, we examine the recent CrowdStrike outage and provide a technical overview of the root cause. We also explain why security products use kernel-mode drivers today and the safety measures Windows provides for third-party solutions. In addition, we share how customers and security vendors can better leverage the integrated security capabilities of Windows for increased security and reliability. Lastly, we provide a look into how Windows will enhance extensibility for future security products.</p>



<p>CrowdStrike recently published a <a href="https://www.crowdstrike.com/falcon-content-update-remediation-and-guidance-hub/" target="_blank" rel="noreferrer noopener">Preliminary Post Incident Review</a> analyzing their outage. In their blog post, CrowdStrike describes the root cause as a memory safety issue—specifically a read out-of-bounds access violation in the CSagent driver. We leverage the Microsoft <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/debugger-download-tools" target="_blank" rel="noreferrer noopener">WinDBG Kernel Debugger</a> and <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/-reg" target="_blank" rel="noreferrer noopener">several extensions</a> that are available free to anyone to perform this analysis. Customers with crash dumps can reproduce our steps with these tools.</p>



<p>Based on Microsoft’s analysis of the Windows Error Reporting (<a href="https://learn.microsoft.com/en-us/windows/win32/wer/windows-error-reporting" target="_blank" rel="noreferrer noopener">WER</a>) kernel crash dumps related to the incident, we observe global crash patterns that reflect this:</p>


<div><pre title="">FAULTING_THREAD:  ffffe402fe868040

READ_ADDRESS:  ffff840500000074 Paged pool

MM_INTERNAL_CODE:  2

IMAGE_NAME:  csagent.sys

MODULE_NAME: csagent

FAULTING_MODULE: fffff80671430000 csagent

PROCESS_NAME:  System

TRAP_FRAME:  ffff94058305ec20 -- (.trap 0xffff94058305ec20)
.trap 0xffff94058305ec20
NOTE: The trap frame does not contain all registers.
Some register values may be zeroed or incorrect.
rax=ffff94058305f200 rbx=0000000000000000 rcx=0000000000000003
rdx=ffff94058305f1d0 rsi=0000000000000000 rdi=0000000000000000
rip=fffff806715114ed rsp=ffff94058305edb0 rbp=ffff94058305eeb0
 r8=ffff840500000074  r9=0000000000000000 r10=0000000000000000
r11=0000000000000014 r12=0000000000000000 r13=0000000000000000
r14=0000000000000000 r15=0000000000000000
iopl=0         nv up ei ng nz na po nc
csagent+0xe14ed:
fffff806`715114ed 458b08          mov     r9d,dword ptr [r8] ds:ffff8405`00000074=????????
.trap
Resetting default scope

STACK_TEXT:  
ffff9405`8305e9f8 fffff806`5388c1e4     : 00000000`00000050 ffff8405`00000074 00000000`00000000 ffff9405`8305ec20 : nt!KeBugCheckEx 
ffff9405`8305ea00 fffff806`53662d8c     : 00000000`00000000 00000000`00000000 00000000`00000000 ffff8405`00000074 : nt!MiSystemFault+0x1fcf94  
ffff9405`8305eb00 fffff806`53827529     : ffffffff`00000030 ffff8405`af8351a2 ffff9405`8305f020 ffff9405`8305f020 : nt!MmAccessFault+0x29c 
ffff9405`8305ec20 fffff806`715114ed     : 00000000`00000000 ffff9405`8305eeb0 ffff8405`b0bcd00c ffff8405`b0bc505c : nt!KiPageFault+0x369 
ffff9405`8305edb0 fffff806`714e709e     : 00000000`00000000 00000000`e01f008d ffff9405`8305f102 fffff806`716baaf8 : csagent+0xe14ed
ffff9405`8305ef50 fffff806`714e8335     : 00000000`00000000 00000000`00000010 00000000`00000002 ffff8405`b0bc501c : csagent+0xb709e
ffff9405`8305f080 fffff806`717220c7     : 00000000`00000000 00000000`00000000 ffff9405`8305f382 00000000`00000000 : csagent+0xb8335
ffff9405`8305f1b0 fffff806`7171ec44     : ffff9405`8305f668 fffff806`53eac2b0 ffff8405`afad4ac0 00000000`00000003 : csagent+0x2f20c7
ffff9405`8305f430 fffff806`71497a31     : 00000000`0000303b ffff9405`8305f6f0 ffff8405`afb1d140 ffffe402`ff251098 : csagent+0x2eec44
ffff9405`8305f5f0 fffff806`71496aee     : ffff8405`afb1d140 fffff806`71541e7e 00000000`000067a0 fffff806`7168f8f0 : csagent+0x67a31
ffff9405`8305f760 fffff806`7149685b     : ffff9405`8305f9d8 ffff8405`afb1d230 ffff8405`afb1d140 ffffe402`fe8644f8 : csagent+0x66aee
ffff9405`8305f7d0 fffff806`715399ea     : 00000000`4a8415aa ffff8eee`1c68ca4f 00000000`00000000 ffff8405`9e95fc30 : csagent+0x6685b
ffff9405`8305f850 fffff806`7148efbb     : 00000000`00000000 ffff9405`8305fa59 ffffe402`fe864050 ffffe402`fede62c0 : csagent+0x1099ea
ffff9405`8305f980 fffff806`7148edd7     : ffffffff`ffffffa1 fffff806`7152e5c1 ffffe402`fe864050 00000000`00000001 : csagent+0x5efbb
ffff9405`8305fac0 fffff806`7152e681     : 00000000`00000000 fffff806`53789272 00000000`00000002 ffffe402`fede62c0 : csagent+0x5edd7
ffff9405`8305faf0 fffff806`53707287     : ffffe402`fe868040 00000000`00000080 fffff806`7152e510 006fe47f`b19bbdff : csagent+0xfe681
ffff9405`8305fb30 fffff806`5381b8e4     : ffff9680`37651180 ffffe402`fe868040 fffff806`53707230 00000000`00000000 : nt!PspSystemThreadStartup+0x57 
ffff9405`8305fb80 00000000`00000000     : ffff9405`83060000 ffff9405`83059000 00000000`00000000 00000000`00000000 : nt!KiStartSystemThread+0x34 

</pre></div>


<p>Digging in more to this crash dump, we can restore the stack frame at the time of the access violation to learn more about its origin. Unfortunately, with WER data we only receive a compressed version of state and thus we cannot disassemble backwards to see a larger set of instructions prior to the crash, but we can see in the disassembly that there is a check for NULL before performing a read at the address specified in the R8 register:</p>


<div><pre title="">6: kd&gt; .trap 0xffff94058305ec20
.trap 0xffff94058305ec20
NOTE: The trap frame does not contain all registers.
Some register values may be zeroed or incorrect.
rax=ffff94058305f200 rbx=0000000000000000 rcx=0000000000000003
rdx=ffff94058305f1d0 rsi=0000000000000000 rdi=0000000000000000
rip=fffff806715114ed rsp=ffff94058305edb0 rbp=ffff94058305eeb0
 r8=ffff840500000074  r9=0000000000000000 r10=0000000000000000
r11=0000000000000014 r12=0000000000000000 r13=0000000000000000
r14=0000000000000000 r15=000000000000
000
iopl=0         nv up ei ng nz na po nc
csagent+0xe14ed:
fffff806`715114ed 458b08          mov     r9d,dword ptr [r8] ds:ffff8405`00000074=????????
6: kd&gt; !pte ffff840500000074
!pte ffff840500000074
                                           VA ffff840500000074
PXE at FFFFABD5EAF57840    PPE at FFFFABD5EAF080A0    PDE at FFFFABD5E1014000    PTE at FFFFABC202800000
contains 0A00000277200863  contains 0000000000000000
pfn 277200    ---DA--KWEV  contains 0000000000000000
not valid

6: kd&gt; ub fffff806`715114ed
ub fffff806`715114ed
csagent+0xe14d9:
fffff806`715114d9 04d8            add     al,0D8h
fffff806`715114db 750b            jne     csagent+0xe14e8 (fffff806`715114e8)
fffff806`715114dd 4d85c0          test    r8,r8
fffff806`715114e0 7412            je      csagent+0xe14f4 (fffff806`715114f4)
fffff806`715114e2 450fb708        movzx   r9d,word ptr [r8]
fffff806`715114e6 eb08            jmp     csagent+0xe14f0 (fffff806`715114f0)
fffff806`715114e8 4d85c0          test    r8,r8
fffff806`715114eb 7407            je      csagent+0xe14f4 (fffff806`715114f4)
6: kd&gt; ub fffff806`715114d9
ub fffff806`715114d9
                          ^ Unable to find valid previous instruction for 'ub fffff806`715114d9'
6: kd&gt; u fffff806`715114eb
u fffff806`715114eb
csagent+0xe14eb:
fffff806`715114eb 7407            je      csagent+0xe14f4 (fffff806`715114f4)
fffff806`715114ed 458b08          mov     r9d,dword ptr [r8]
fffff806`715114f0 4d8b5008        mov     r10,qword ptr [r8+8]
fffff806`715114f4 4d8bc2          mov     r8,r10
fffff806`715114f7 488d4d90        lea     rcx,[rbp-70h]
fffff806`715114fb 488bd6          mov     rdx,rsi
fffff806`715114fe e8212c0000      call    csagent+0xe4124 (fffff806`71514124)
fffff806`71511503 4533d2          xor     r10d,r10d

6: kd&gt; db ffff840500000074
db ffff840500000074
ffff8405`00000074  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????
ffff8405`00000084  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????
ffff8405`00000094  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????
ffff8405`000000a4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????
ffff8405`000000b4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????
ffff8405`000000c4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????
ffff8405`000000d4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????
ffff8405`000000e4  ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ??  ????????????????

</pre></div>


<p>Our observations confirm CrowdStrike’s analysis that this was a read-out-of-bounds memory safety error in the CrowdStrike developed CSagent.sys driver.</p>



<p>We can also see that the csagent.sys module is registered as a <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/ifs/flt-parameters-for-irp-mj-create-named-pipe" target="_blank" rel="noreferrer noopener">file system filter driver</a> commonly used by anti-malware agents to receive notifications about file operations such as the creation or modification of a file. This is often used by security products to scan any new file saved to disk, such as downloading a file via the browser.</p>



<p>File System filters can also be used as a signal for security solutions attempting to monitor the behavior of the system. CrowdStrike noted in their blog that part of their content update was changing the sensor’s logic relating to data around named pipe creation. The File System filter driver API allows the driver to receive a call when named pipe activity (e.g., named pipe creation) occurs on the system that could enable the detection of malicious behavior. The general function of the driver correlates to the information shared by CrowdStrike.</p>


<div><pre title="">6: kd&gt;!reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csagent

Hive         ffff84059ca7b000
KeyNode      ffff8405a6f67f9c

[SubKeyAddr]         [SubKeyName]
ffff8405a6f683ac     Instances
ffff8405a6f6854c     Sim

 Use '!reg keyinfo ffff84059ca7b000 &lt;SubKeyAddr&gt;' to dump the subkey details

[ValueType]         [ValueName]                   [ValueData]
REG_DWORD           Type                          2
REG_DWORD           Start                         1
REG_DWORD           ErrorControl                  1
REG_EXPAND_SZ       ImagePath                     \??\C:\Windows\system32\drivers\CrowdStrike\csagent.sys
REG_SZ              DisplayName                   CrowdStrike Falcon
REG_SZ              Group                         FSFilter Activity Monitor
REG_MULTI_SZ        DependOnService               FltMgr\0
REG_SZ              CNFG                          Config.sys
REG_DWORD           SupportedFeatures             f

</pre></div>


<p>We can see the control channel file version 291 specified in the CrowdStrike analysis is also present in the crash indicating the file was read.</p>



<p>Determining how the file itself correlates to the access violation observed in the crash dump would require additional debugging of the driver using these tools but is outside of the scope of this blog post.</p>


<div><pre title="">!ca ffffde8a870a8290

ControlArea  @ ffffde8a870a8290
  Segment      ffff880ce0689c10  Flink      ffffde8a87267718  Blink        ffffde8a870a7d98
  Section Ref                 0  Pfn Ref                   b  Mapped Views                0
  User Ref                    0  WaitForDel                0  Flush Count                 0
  File Object  ffffde8a879b29a0  ModWriteCount             0  System Views                0
  WritableRefs                0  PartitionId                0  
  Flags (8008080) File WasPurged OnUnusedList 

      \Windows\System32\drivers\CrowdStrike\C-00000291-00000000-00000032.sys

1: kd&gt; !ntfskd.ccb ffff880ce06f6970
!ntfskd.ccb ffff880ce06f6970

   Ccb: ffff880c`e06f6970
 Flags: 00008003 Cleanup OpenAsFile IgnoreCase
Flags2: 00000841 OpenComplete AccessAffectsOplocks SegmentObjectReferenced
  Type: UserFileOpen
FileObj: ffffde8a879b29a0

(018)  ffff880c`db937370  FullFileName [\Windows\System32\drivers\CrowdStrike\C-00000291-00000000-00000032.sys]
(020) 000000000000004C  LastFileNameOffset 
(022) 0000000000000000  EaModificationCount 
(024) 0000000000000000  NextEaOffset 
(048) FFFF880CE06F69F8  Lcb 
(058) 0000000000000002  TypeOfOpen 

</pre></div>


<p>We can leverage the crash dump to determine if any other drivers supplied by CrowdStrike may exist on the running system during the crash.</p>


<div><pre title="">6: kd&gt; lmDvmCSFirmwareAnalysis
lmDvmCSFirmwareAnalysis
Browse full module list
start             end                 module name
fffff806`58920000 fffff806`5893c000   CSFirmwareAnalysis   (deferred)             
    Image path: \SystemRoot\system32\DRIVERS\CSFirmwareAnalysis.sys
    Image name: CSFirmwareAnalysis.sys
    Browse all global symbols  functions  data  Symbol Reload
    Timestamp:        Mon Mar 18 11:32:14 2024 (65F888AE)
    CheckSum:         0002020E
    ImageSize:        0001C000
    Translations:     0000.04b0 0000.04e4 0409.04b0 0409.04e4
    Information from resource tables:
6: kd&gt; lmDvmcspcm4
lmDvmcspcm4
Browse full module list
start             end                 module name
fffff806`71870000 fffff806`7187d000   cspcm4     (deferred)             
    Image path: \??\C:\Windows\system32\drivers\CrowdStrike\cspcm4.sys
    Image name: cspcm4.sys
    Browse all global symbols  functions  data  Symbol Reload
    Timestamp:        Mon Jul  8 18:33:22 2024 (668C9362)
    CheckSum:         00012F69
    ImageSize:        0000D000
    Translations:     0000.04b0 0000.04e4 0409.04b0 0409.04e4
    Information from resource tables:
6: kd&gt; lmDvmcsboot.sys
lmDvmcsboot.sys
Browse full module list
start             end                 module name

Unloaded modules:
fffff806`587d0000 fffff806`587dc000   CSBoot.sys
    Timestamp: unavailable (00000000)
    Checksum:  00000000
    ImageSize:  0000C000

6: kd&gt; !reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csboot
!reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csboot

Hive         ffff84059ca7b000
KeyNode      ffff8405a6f68924

[ValueType]         [ValueName]                   [ValueData]
REG_DWORD           Type                          1
REG_DWORD           Start                         0
REG_DWORD           ErrorControl                  1
REG_EXPAND_SZ       ImagePath                     system32\drivers\CrowdStrike\CSBoot.sys
REG_SZ              DisplayName                   CrowdStrike Falcon Sensor Boot Driver
REG_SZ              Group                         Early-Launch
6: kd&gt; !reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csdevicecontrol
!reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csdevicecontrol

Hive         ffff84059ca7b000
KeyNode      ffff8405a6f694ac

[SubKeyAddr]         [VolatileSubKeyName]
ffff84059ce196c4     Enum

 Use '!reg keyinfo ffff84059ca7b000 &lt;SubKeyAddr&gt;' to dump the subkey details

[ValueType]         [ValueName]                   [ValueData]
REG_DWORD           Type                          1
REG_DWORD           Start                         3
REG_DWORD           ErrorControl                  1
REG_DWORD           Tag                           1f
REG_EXPAND_SZ       ImagePath                     \SystemRoot\System32\drivers\CSDeviceControl.sys
REG_SZ              DisplayName                   @oem40.inf,%DeviceControl.SVCDESC%;CrowdStrike Device Control Service
REG_SZ              Group                         Base
REG_MULTI_SZ        Owners                        oem40.inf\0!csdevicecontrol.inf_amd64_b6725a84d4688d5a\0!csdevicecontrol.inf_amd64_016e965488e83578\0
REG_DWORD           BootFlags                     14
6: kd&gt; !reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csagent
!reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csagent

Hive         ffff84059ca7b000
KeyNode      ffff8405a6f67f9c

[SubKeyAddr]         [SubKeyName]
ffff8405a6f683ac     Instances
ffff8405a6f6854c     Sim

 Use '!reg keyinfo ffff84059ca7b000 &lt;SubKeyAddr&gt;' to dump the subkey details

[ValueType]         [ValueName]                   [ValueData]
REG_DWORD           Type                          2
REG_DWORD           Start                         1
REG_DWORD           ErrorControl                  1
REG_EXPAND_SZ       ImagePath                     \??\C:\Windows\system32\drivers\CrowdStrike\csagent.sys
REG_SZ              DisplayName                   CrowdStrike Falcon
REG_SZ              Group                         FSFilter Activity Monitor
REG_MULTI_SZ        DependOnService               FltMgr\0
REG_SZ              CNFG                          Config.sys
REG_DWORD           SupportedFeatures             f

6: kd&gt; lmDvmCSFirmwareAnalysis
lmDvmCSFirmwareAnalysis
Browse full module list
start             end                 module name
fffff806`58920000 fffff806`5893c000   CSFirmwareAnalysis   (deferred)             
    Image path: \SystemRoot\system32\DRIVERS\CSFirmwareAnalysis.sys
    Image name: CSFirmwareAnalysis.sys
    Browse all global symbols  functions  data  Symbol Reload
    Timestamp:        Mon Mar 18 11:32:14 2024 (65F888AE)
    CheckSum:         0002020E
    ImageSize:        0001C000
    Translations:     0000.04b0 0000.04e4 0409.04b0 0409.04e4
    Information from resource tables:
6: kd&gt; !reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csfirmwareanalysis
!reg querykey \REGISTRY\MACHINE\system\ControlSet001\services\csfirmwareanalysis

Hive         ffff84059ca7b000
KeyNode      ffff8405a6f69d9c

[SubKeyAddr]         [VolatileSubKeyName]
ffff84059ce197cc     Enum

 Use '!reg keyinfo ffff84059ca7b000 &lt;SubKeyAddr&gt;' to dump the subkey details

[ValueType]         [ValueName]                   [ValueData]
REG_DWORD           Type                          1
REG_DWORD           Start                         0
REG_DWORD           ErrorControl                  1
REG_DWORD           Tag                           6
REG_EXPAND_SZ       ImagePath                     system32\DRIVERS\CSFirmwareAnalysis.sys
REG_SZ              DisplayName                   @oem43.inf,%FirmwareAnalysis.SVCDESC%;CrowdStrike Firmware Analysis Service
REG_SZ              Group                         Boot Bus Extender
REG_MULTI_SZ        Owners                        oem43.inf\0!csfirmwareanalysis.inf_amd64_12861fc608fb1440\0
6: kd&gt; !reg querykey \REGISTRY\MACHINE\system\Controlset001\control\earlylaunch
!reg querykey \REGISTRY\MACHINE\system\Controlset001\control\earlylaunch
</pre></div>


<p>As we can see from the above analysis, CrowdStrike loads four driver modules. One of those modules receives dynamic control and content updates frequently based on the CrowdStrike Preliminary Post-incident-review timeline.</p>



<p>We can leverage the unique stack and attributes of this crash to identify the Windows crash reports generated by this specific CrowdStrike programming error. It’s worth noting the number of devices which generated crash reports is a subset of the number of impacted devices previously shared by <a href="https://blogs.microsoft.com/blog/2024/07/20/helping-our-customers-through-the-crowdstrike-outage/" target="_blank" rel="noreferrer noopener">Microsoft in our blog post</a>, because crash reports are sampled and collected only from customers who choose to upload their crashes to Microsoft. Customers who <a href="https://learn.microsoft.com/en-us/windows/privacy/configure-windows-diagnostic-data-in-your-organization" target="_blank" rel="noreferrer noopener">choose to enable crash dump sharing</a> help both driver vendors and Microsoft to identify and remediate quality issues and crashes.</p>


<figure><img decoding="async" src="https://www.microsoft.com/en-us/security/blog/wp-content/uploads/2024/07/Picture1-3.webp" alt="" srcset="" data-orig-src="https://www.microsoft.com/en-us/security/blog/wp-content/uploads/2024/07/Picture1-3.webp"><figcaption>Figure 1 CrowdStrike driver associated crash dump reports over time</figcaption></figure>



<p>We make this information available to driver owners so they can assess their own reliability via the <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/dashboard/hardware-program-register" target="_blank" rel="noreferrer noopener">Hardware Dev Center analytics</a> dashboard. As we can see from the above, any reliability problem like this invalid memory access issue can lead to widespread availability issues when not combined with safe deployment practices. Let’s dig into why security solutions leverage kernel drivers on Windows.</p>



<h2 id="why-do-security-solutions-leverage-kernel-drivers">Why do security solutions leverage kernel drivers?</h2>



<p>Many security vendors such as CrowdStrike and Microsoft leverage a kernel driver architecture and there are several reasons for this.</p>



<h3 id="visibility-and-enforcement-of-security-related-events">Visibility and enforcement of security related events</h3>



<p>Kernel drivers allow for system wide visibility, and the capability to load in early boot to detect threats like <a href="https://learn.microsoft.com/en-us/defender-endpoint/malware/rootkits-malware" target="_blank" rel="noreferrer noopener">boot kits and root kits</a> which can load before user-mode applications. In addition, Microsoft provides a rich set of capabilities such as system event callbacks for process and thread creation and filter drivers which can watch for events like file creation, deletion, or modification. Kernel activity can also trigger call backs for drivers to decide when to block activities like file or process creations. Many vendors also use drivers to collect a variety of network information in the kernel using the <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/network/ndis-drivers" target="_blank" rel="noreferrer noopener">NDIS driver class</a>.</p>



<h3 id="performance">Performance</h3>



<p>Kernel drivers are often utilized by security vendors for potential performance benefits. For example, analysis or data collection for high throughput network activity may benefit from a kernel driver. There are many scenarios where data collection and analysis can be optimized for operation outside of kernel mode and Microsoft continues to partner with the ecosystem to improve performance and provide best practices to achieve parity outside of kernel mode.</p>



<h3 id="tamper-resistance">Tamper resistance</h3>



<p>A second benefit of loading into kernel mode is tamper resistance. Security products want to ensure that their software cannot be disabled by malware, targeted attacks, or malicious insiders, even when those attackers have admin-level privileges. They also want to ensure that their drivers load as early as possible so that they can observe system events at the earliest possible time. Windows provides a mechanism to launch drivers marked as <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/install/early-launch-antimalware" target="_blank" rel="noreferrer noopener">Early Launch Antimalware</a> (ELAM) early in the boot process for this reason. CrowdStrike signs the above CSboot driver as ELAM, enabling it to load early in the boot sequence.</p>



<p>In the general case, there is a tradeoff that security vendors must rationalize when it comes to kernel drivers. Kernel drivers provide the above properties at the cost of resilience. Since kernel drivers run at the most trusted level of Windows, where containment and recovery capabilities are by nature constrained, security vendors must carefully balance needs like visibility and tamper resistance with the risk of operating within kernel mode.</p>



<p>All code operating at kernel level requires extensive validation because it cannot fail and restart like a normal user application. This is universal across all operating systems. Internally at Microsoft, we have invested in moving complex Windows core services from kernel to user mode, such as font file parsing from <a href="https://techcommunity.microsoft.com/t5/microsoft-security-baselines/dropping-the-quot-untrusted-font-blocking-quot-setting/ba-p/701068" target="_blank" rel="noreferrer noopener">kernel to user mode</a>.</p>



<p>It is possible today for security tools to balance security and reliability. For example, security vendors can use minimal sensors that run in kernel mode for data collection and enforcement limiting exposure to availability issues. The remainder of the key product functionality includes managing updates, parsing content, and other operations can occur isolated within user mode where recoverability is possible. This demonstrates the best practice of minimizing kernel usage while still maintaining a robust security posture and strong visibility.</p>


<figure><img decoding="async" src="https://www.microsoft.com/en-us/security/blog/wp-content/uploads/2024/07/Picture2-2.webp" alt="" srcset="" data-orig-src="https://www.microsoft.com/en-us/security/blog/wp-content/uploads/2024/07/Picture2-2.webp"><figcaption>Figure 2 Example security product architecture which balances security and reliability</figcaption></figure>



<p>Windows provides several user mode protection approaches for anti-tampering, like Virtualization-based security <a href="https://learn.microsoft.com/en-us/windows/win32/trusted-execution/vbs-enclaves" target="_blank" rel="noreferrer noopener">(VBS) Enclaves</a> and <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/install/early-launch-antimalware" target="_blank" rel="noreferrer noopener">Protected Processes</a> that vendors can use to protect their key security processes. Windows also provides <a href="https://techcommunity.microsoft.com/t5/windows-it-pro-blog/new-security-capabilities-in-event-tracing-for-windows/ba-p/3949941" target="_blank" rel="noreferrer noopener">ETW events</a> and user-mode interfaces like <a href="https://learn.microsoft.com/en-us/windows/win32/amsi/antimalware-scan-interface-portal" target="_blank" rel="noreferrer noopener">Antimalware Scan Interface</a> for event visibility. These robust mechanisms can be used to reduce the amount of kernel code needed to create a security solution, which balances security and robustness.</p>







<p>Microsoft engages with third-party security vendors through an industry forum called the <a href="https://learn.microsoft.com/en-us/defender-xdr/virus-initiative-criteria" target="_blank" rel="noreferrer noopener">Microsoft Virus Initiative</a> (MVI). This group consists of Microsoft and Security Industry and was created to establish a dialogue and collaboration across the Windows security ecosystem to improve robustness in the way security products use the platform. With MVI, Microsoft and vendors collaborate on the Windows platform to define reliable extension points and platform improvements, as well as share information about how to best protect our customers.</p>



<p>Microsoft works with members of MVI to ensure compatibility with Windows updates, improve performance, and address reliability issues. MVI partners actively participating in the program contribute to making the ecosystem more resilient and gain benefits including technical briefings, feedback loops with Microsoft product teams, and access to antimalware platform features such as ELAM and Protected Processes. Microsoft also provides runtime protection such as <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/kernel/driver-x64-restrictions" target="_blank" rel="noreferrer noopener">Patch Guard</a> to prevent disruptive behavior from kernel driver types like anti-malware.</p>



<p>In addition, all drivers signed by the Microsoft Windows Hardware Quality Labs (WHQL) must run a series of tests and attest to a number of quality checks, including using <a href="https://learn.microsoft.com/en-us/windows-hardware/test/hlk/testref/236b8ad5-0ba1-4075-80a6-ae9dafb71c94" target="_blank" rel="noreferrer noopener">fuzzers</a>, running <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/devtest/prefast-for-drivers-warnings" target="_blank" rel="noreferrer noopener">static code analysis</a> and testing under <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/devtest/driver-verifier" target="_blank" rel="noreferrer noopener">runtime driver verification</a>, among other techniques. These tests have been developed to ensure that best practices around security and reliability are followed. Microsoft includes all these tools in the Windows Driver Kit used by all driver developers. A list of the resources and tools is <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/driversecurity/driver-security-checklist" target="_blank" rel="noreferrer noopener">available here</a>.</p>



<p>All WHQL signed drivers are run through Microsoft’s ingestion checks and malware scans and must pass before being approved for signing. Additionally, if a third-party vendor chooses to distribute their driver via Windows Update (WU), the driver also goes through Microsoft’s flighting and gradual rollout processes to observe quality and ensure the driver meets the necessary quality criteria for a broad release.</p>



<h2 id="can-customers-deploy-windows-in-a-higher-security-mode-to-increase-reliability">Can customers deploy Windows in a higher security mode to increase reliability?</h2>



<p>Windows at its core is an open and versatile OS, and it can easily be locked down for increased security using integrated tools. In addition, Windows is constantly increasing security defaults, including dozens of new security features enabled by default in Windows 11.</p>



<h3 id="security-features-enabled-by-default-in-windows-11">Security features enabled by default in Windows 11</h3>



<figure><table><tbody><tr><td><strong>Area</strong></td><td><strong>Feature</strong></td></tr><tr><td><strong>Hardware Security Baseline</strong></td><td><a href="https://learn.microsoft.com/en-us/windows/security/hardware-security/tpm/tpm-fundamentals" target="_blank" rel="noreferrer noopener">TPM2.0</a><br><a href="https://learn.microsoft.com/en-us/mem/intune/user-help/you-need-to-enable-secure-boot-windows" target="_blank" rel="noreferrer noopener">Secure boot</a><br><a href="https://learn.microsoft.com/en-us/windows-hardware/design/device-experiences/oem-vbs" target="_blank" rel="noreferrer noopener">Virtualization-based security (VBS)<br></a><a href="https://learn.microsoft.com/en-us/windows/security/hardware-security/enable-virtualization-based-protection-of-code-integrity" target="_blank" rel="noreferrer noopener">Memory integrity (Hypervisor-protected Code Integrity (HVCI))<br></a><a href="https://techcommunity.microsoft.com/t5/windows-os-platform-blog/understanding-hardware-enforced-stack-protection/ba-p/1247815" target="_blank" rel="noreferrer noopener">Hardware-enforced stack protection<br></a><a href="https://learn.microsoft.com/en-us/windows/security/hardware-security/kernel-dma-protection-for-thunderbolt" target="_blank" rel="noreferrer noopener">Kernel Direct Memory Access (DMA) protection<br></a>HW-based kernel protection (HLAT)<br><a href="https://learn.microsoft.com/en-us/windows-hardware/design/device-experiences/windows-hello-enhanced-sign-in-security" target="_blank" rel="noreferrer noopener">Enhanced sign-in security (ESS) for built-in biometric sensors</a></td></tr><tr><td><strong>Encryption</strong></td><td><a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/" target="_blank" rel="noreferrer noopener">BitLocker</a> (commercial)<br><a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/#device-encryption" target="_blank" rel="noreferrer noopener">Device Encryption</a> (consumer)</td></tr><tr><td><strong>Identity Management</strong></td><td><a href="https://learn.microsoft.com/en-us/windows/security/identity-protection/credential-guard/" target="_blank" rel="noreferrer noopener">Credential Guard<br></a><a href="https://learn.microsoft.com/en-us/entra/identity/conditional-access/concept-token-protection" target="_blank" rel="noreferrer noopener">Entra primary refresh token (PRT) hardware protected<br></a>MDM deployed SCEP certs hardware protected<br>MDM enrollment certs hardware protected<br>Local Security Authority (LSA) PPL prevents token/credential dumping<br>Account lockout policy (for 10 failed sign-ins)<br>Enhanced phishing protection with Microsoft Defender<br><a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/virus-and-threat-protection/microsoft-defender-smartscreen/" target="_blank" rel="noreferrer noopener">Microsoft Defender SmartScreen<br></a>NPLogonNotification doesn’t include password<br>WDigest SSO removed to reduce password disclosure<br>AD Device Account protected by CredGuard*</td></tr><tr><td><strong>Multi-Factor Authentication<br>(Passwordless)</strong></td><td>MSA &amp; Entra users lead through Hello enablement by default<br>MSA password automatically removed from Windows if never used<br>Hello container VSM protected<br>Peripheral biometric sensors blocked for ESS enabled devices<br>Lock on leave integrated into Hello</td></tr><tr><td><strong>Security Incident Reduction</strong></td><td>Common Log File Systems run from trusted source<br>Move tool-tip APIs from kernel to user mode<br>Modernize print stack by removing untrusted drivers<br>DPAPI moved from 3DES to AES<br>TLS 1.3 default with TLS 1.0/1.1 disabled by default<br>NTLM-less*</td></tr><tr><td><strong>OS lockdown</strong></td><td><a href="https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/design/microsoft-recommended-driver-block-rules#microsoft-vulnerable-driver-blocklist" target="_blank" rel="noreferrer noopener">Microsoft Vulnerable Driver Blocklist<br></a>3P driver security baseline enforced via WHCP<br>Smart App Control*</td></tr></tbody></table><figcaption>*Feature available in the Windows Insider Program or currently off by default and on a path for default enablement</figcaption></figure>



<p>Windows has integrated security features to self-defend. This includes key anti-malware features enabled by default, such as:</p>



<ol>
<li><a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/system-security/secure-the-windows-10-boot-process" target="_blank" rel="noreferrer noopener">Secure Boot</a>, which helps prevent early boot malware and rootkits by enforcing signing consistently across Windows boots.</li>



<li><a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/system-security/secure-the-windows-10-boot-process" target="_blank" rel="noreferrer noopener">Measured Boot</a>, which provides TPM-based hardware cryptographic measurements on boot-time properties available through integrated attestation services such as <a href="https://learn.microsoft.com/en-us/windows-server/security/device-health-attestation" target="_blank" rel="noreferrer noopener">Device Health Attestation</a>.</li>



<li><a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/bringup/device-guard-and-credential-guard" target="_blank" rel="noreferrer noopener">Memory integrity</a> (also known as hypervisor-protected code integrity or HVCI), which prevents runtime generation of dynamic code in the kernel and helps ensure control flow integrity.</li>



<li><a href="https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/design/microsoft-recommended-driver-block-rules#microsoft-vulnerable-driver-blocklist" target="_blank" rel="noreferrer noopener">Vulnerable driver blocklist</a>, which is on by default, integrated into the OS, and managed by Microsoft. This complements the malicious driver block list.</li>



<li><a href="https://learn.microsoft.com/en-us/windows-server/security/credentials-protection-and-management/configuring-additional-lsa-protection" target="_blank" rel="noreferrer noopener">Protected Local Security Authority</a> is on by default in Windows 11 to protect a range of credentials. <a href="https://learn.microsoft.com/en-us/windows/security/identity-protection/credential-guard/?toc=%2Fwindows-server%2Fsecurity%2Ftoc.json&amp;bc=%2Fwindows-server%2Fbreadcrumbs%2Ftoc.json" target="_blank" rel="noreferrer noopener">Hardware-based credential protection</a> is on by default for enterprise versions of Windows.</li>



<li><a href="https://learn.microsoft.com/en-us/defender-endpoint/microsoft-defender-antivirus-windows" target="_blank" rel="noreferrer noopener">Microsoft Defender Antivirus</a> is enabled by default in Windows and offers anti-malware capabilities across the OS.</li>
</ol>



<p>These security capabilities provide layers of protection against malware and exploitation attempts in modern Windows. Many Windows customers have leveraged our security baseline and Windows security technologies to harden their systems and these capabilities collectively have reduced the attack surface significantly.</p>



<p>Using the integrated security features of Windows to prevent adversary attacks such as those displayed in the <a href="https://attack.mitre.org/" target="_blank" rel="noreferrer noopener">MITRE ATT&amp;CK® framework</a> increases security while reducing cost and complexity. It leverages best practices to achieve maximum security and reliability. These best practices include:</p>



<ol>
<li>Using <a href="https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/" target="_blank" rel="noreferrer noopener">App Control for Business</a> (formerly Windows Defender Application Control), you can author a security policy to allow only trusted and/or business-critical apps. Your policy can be crafted to deterministically and durably prevent nearly all malware and “living off the land” style attacks. It can also specify which kernel drivers are allowed by your organization to durably guarantee that only those drivers will load on your managed endpoints.</li>



<li>Use <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/bringup/device-guard-and-credential-guard" target="_blank" rel="noreferrer noopener">Memory integrity</a> with a <a href="https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/design/wdac-wizard" target="_blank" rel="noreferrer noopener">specific allow list policy</a> to further protect the Windows kernel using <a href="https://learn.microsoft.com/en-us/windows-hardware/design/device-experiences/oem-vbs" target="_blank" rel="noreferrer noopener">Virtualization-based security</a> (VBS). Combined with App Control for Business, memory integrity can reduce the attack surface for kernel malware or boot kits. This can also be used to limit any drivers that might impact reliability on systems.</li>



<li>Running as <a href="https://learn.microsoft.com/en-us/windows-server/remote/multipoint-services/create-a-standard-user-account" target="_blank" rel="noreferrer noopener">Standard User</a> and elevating only as necessary. Companies that follow the best practices to run as standard user and reduce privileges mitigate many of the <a href="https://attack.mitre.org/" target="_blank" rel="noreferrer noopener">MITRE ATT&amp;CK®</a> techniques.</li>



<li>Use <a href="https://learn.microsoft.com/en-us/windows-server/security/device-health-attestation" target="_blank" rel="noreferrer noopener">Device Health Attestation</a> (DHA) to monitor devices for the right security policy, including hardware-based measurements for the security posture of the machine. This is a modern and exceptionally durable approach to ensure security for high availability scenarios and uses Microsoft’s <a href="https://www.microsoft.com/en-us/security/business/security-101/what-is-zero-trust-architecture?msockid=04462a6256e861da2e753a3d57346023" target="_blank" rel="noreferrer noopener">Zero Trust architecture</a>.</li>
</ol>



<h2 id="what-is-next">What is next?</h2>



<p>Windows is a self-protecting operating system that has produced dozens of new security features and architectural changes <a href="https://www.microsoft.com/en-us/security/blog/2024/05/20/new-windows-11-features-strengthen-security-to-address-evolving-cyberthreat-landscape/" target="_blank" rel="noreferrer noopener">in recent versions</a>. We plan to work with the anti-malware ecosystem to take advantage of these integrated features to modernize their approach, helping to support and even increase security along with reliability.</p>



<p>This includes helping the ecosystem by:</p>



<ol>
<li>Providing safe rollout guidance, best practices, and technologies to make it safer to perform updates to security products.</li>



<li>Reducing the need for kernel drivers to access important security data.</li>



<li>Providing enhanced isolation and anti-tampering capabilities with technologies like our recently <a href="https://techcommunity.microsoft.com/t5/windows-os-platform-blog/securely-design-your-applications-and-protect-your-sensitive/ba-p/4179543" target="_blank" rel="noreferrer noopener">announced VBS enclaves</a>.</li>



<li>Enabling zero trust approaches like <a href="https://learn.microsoft.com/en-us/azure/attestation/overview" target="_blank" rel="noreferrer noopener">high integrity attestation</a> which provides a method to determine the security state of the machine based on the health of Windows native security features.</li>
</ol>



<p>As we move forward, Windows is continuing to innovate and offer new ways for security tools to detect and respond to emerging threats safely and securely. Windows has <a href="https://www.microsoft.com/en-us/security/blog/2024/03/06/enhancing-protection-updates-on-microsofts-secure-future-initiative/" target="_blank" rel="noreferrer noopener">announced a commitment around the Rust programming language</a> as part of Microsoft’s <a href="https://www.microsoft.com/en-us/microsoft-cloud/resources/secure-future-initiative" target="_blank" rel="noreferrer noopener">Secure Future Initiative</a> (SFI) and has recently expanded the <a href="https://www.youtube.com/watch?v=8T6ClX-y2AE" target="_blank" rel="noreferrer noopener">Windows kernel to support Rust</a>.</p>



<p>The information in this blog post is provided as part of our commitment to communicate learnings and next steps after the CrowdStrike incident. We will continue to share ongoing guidance on security best practices for Windows and work across our broad ecosystem of customers and partners to develop new security capabilities based on your feedback.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perfectionism – one of the biggest productivity killers in the eng industry (141 pts)]]></title>
            <link>https://newsletter.eng-leadership.com/p/perfectionism-one-of-the-biggest</link>
            <guid>41094485</guid>
            <pubDate>Sun, 28 Jul 2024 17:14:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.eng-leadership.com/p/perfectionism-one-of-the-biggest">https://newsletter.eng-leadership.com/p/perfectionism-one-of-the-biggest</a>, See on <a href="https://news.ycombinator.com/item?id=41094485">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg" width="800" height="445" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:445,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:27704,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597a1df9-bf38-4e9c-a3a0-7f20097379ef_800x445.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Perfectionism is one of these things that hurt us without even realizing it. We may think it’s great to put so much effort into ensuring the result is “perfect”, but at the end of the day, we never finish it and it becomes an endless “work in progress”, which is a big problem.</p><p><span>This article is done in collaboration with </span><a href="https://www.linkedin.com/in/jordancutler1/" rel="">Jordan Cutler</a><span>, Senior Software Engineer at Pinterest and the author of the newsletter </span><a href="https://read.highgrowthengineer.com/" rel="">High Growth Engineer</a><span>.</span></p><p>We both made a lot of mistakes thinking that perfecting is the way to go and after some time we realized that progress is so much better!</p><p>And today, we are sharing our stories with you! Let’s start with Jordan’s first.</p><p>Early in my career, I spent a lot of time writing code. In fact, I shipped over 1200 pull requests (PRs) in my first 3 years as an engineer, averaging ~1-2 PRs per day.</p><p>While the code velocity was high, I was focusing on the wrong things. Most of the PRs were dedicated to “perfecting” our codebase.</p><p>At the time, I thought I was doing great things. Who wouldn’t love the code to be spruced up? But looking back, I realized how I could have spent my time so much better.</p><p>Instead of perfecting code, often code that hadn’t been touched in years and didn’t need to be touched, I could have been adding value for the team.</p><p>Things like:</p><ul><li><p>Reducing the plate of my teammates, rather than adding to it with more code reviews to give them</p></li><li><p>Shipping the current feature faster and getting ahead on the next one</p></li><li><p>Asking my manager how I can help them more</p></li></ul><p>So, even though I shipped all those PRs early in my career, today I realize how meaningless it is.</p><p>If I had spent less time perfecting code, I could have shipped 50% fewer PRs and added 2x more value to the team.</p><p>Today, I’m lucky if I ship more than 3 PRs in a week. That’s because my focus is on working on the right things, which often means helping the team, creating partnerships, writing proposals, and scaling myself through docs. When I do ship code, it’s with clear intent to move value for the team or business.</p><p>Outside of this example, I avoid perfectionism by doing 3 things:</p><ol><li><p><strong>Writing down my priorities</strong><span> at the start of the week, which helps me know what’s most important to accomplish. Hint: It’s usually not perfecting something.</span></p></li><li><p><strong>Shipping the smallest unit of value</strong><span> I can, either to internal or external customers. For example, shipping an 80% working prototype behind a feature flag to get early feedback internally.</span></p></li><li><p><strong>Seeking early feedback</strong><span>. I set up 4-hour focus time blocks at the start of my day and make as much progress as I can. Then, I ask myself, “Based on what I accomplished, is there anything I should share or request feedback on?” I do this all the time with technical docs. I ask my team, “Am I going in a completely wrong direction here, or should I continue on this path?” Sometimes, I find there’s a simpler solution than my proposal, it’s already explored, or not valuable. That saves me hours of time from perfecting the doc.</span></p></li></ol><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png" width="1456" height="505" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:505,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:314206,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff95e1da5-498c-4028-8c3d-257bfbc53493_1600x555.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Less perfection. More progress.</p><p>Perfectionism has been a problem for me starting from an early age. I’ve always wanted to make things the best quality possible, especially things that matter a lot to me.</p><p>It took a long time for me to realize it’s actually counter-productive. Here are the most prominent things that I wanted to perfect as a Software Engineer and a manager:</p><p><strong>I wanted to learn “perfectly” from tutorials</strong></p><p>In my early days as a self-taught engineer, I did SO much learning from tutorials.</p><p>Looking back at that time, I could see how I could have progressed much faster if I hadn’t wanted to always make sure that I finished every single tutorial 100%, plus with the mindset of “I shouldn’t miss any second of it”.</p><p><span>What I know now, the best way to learn from tutorials is to get what you need and apply that to your own project. Building your own project is the best way to learn. You can find more details about this here: </span><a href="https://newsletter.eng-leadership.com/p/become-a-better-engineer-by-working" rel="">Become a better engineer by working on side projects</a><span> (paid article).</span></p><p><strong>I wanted to design “perfect” things</strong></p><p>In one of my student jobs as a Software Engineer, I was also doing a lot of design related things like designing banners, websites also doing some graphic design. I saw a repeating pattern when designing.</p><p>That pattern was that I would create a draft quite quickly, but then spend the 2-4x amount of time applying finishing touches. Which was quite counter-productive and also stressful for me.</p><p>I spent so much time trying to make sure it’s “pixel perfect”: right colors, right fonts, right spacing, etc. I would make so much more progress if I would just be fine with it. The funny thing is that the end result wasn’t much better than the first draft (maybe a tad more).</p><p><strong>I wanted to create “perfect” code</strong></p><p>Especially early on in my career as a Software Engineer, I would feel that I need to write perfect code, before showing it to others.</p><p>I spent so much time refactoring functions, renaming variables, rethinking the approach and overall looking for ways to optimize it. It was my impostor syndrome telling me that I was not good enough to do this.</p><p>That got me to the place where my overall progression was hurting and similar with designing → it caused additional stress to me.</p><p>I would be making SO much more progress if I would be focusing on good enough code and getting feedback early on! So much wasted time trying to “perfect”.</p><p><strong>As a manager, I wanted to wait for “perfect” timings and make “perfect” decisions</strong></p><p>I thought that my timing to give feedback needed to be perfect. Well, the outcome of waiting was that things got a lot worse.</p><p>I said to myself: “Maybe things will get better if I wait for a bit more time”. Well, the reality was that things didn’t. And my waiting for perfect timing made it a LOT worse.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png" width="800" height="400" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:400,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:46210,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7425a3-c8d3-45d9-98bc-fb5e42d76671_800x400.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Similar to making decisions. “They need to be perfect”, I said to myself. And that got me to the place, where I didn’t make the decisions fast enough, which actually blocked my team from progressing.</p><p>And I realized over time, that not all the decisions will be the absolute right ones, but it’s much better to make a decision and reverse it later if needed, instead of not making it at all.</p><p><strong>Here are my top 3 learnings:</strong></p><ul><li><p>Focusing on progression instead of perfecting will make you SO much more productive + it’s so much better for your mental health.</p></li><li><p>Perfect moments do not exist and waiting for them will just cause a lot more issues. Doing things now or as soon as you can is the way to go when you are dealing with important things.</p></li><li><p>Whenever I feel like I am trying to “perfect”, I think of this: 100% does not exist and 95% is good enough in the majority of the cases. That shifts my mind into making progress instead of perfecting.</p></li></ul><p><span>Thanks to Jordan for sharing his story and his insights on this very important topic. Make sure to check him out on </span><a href="https://www.linkedin.com/in/jordancutler1/" rel="">LinkedIn</a><span> and also check out his </span><a href="https://read.highgrowthengineer.com/" rel="">newsletter</a><span>!</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png" width="800" height="400" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2a065581-415f-4ca6-8506-8051f5fec840_800x400.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:400,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:386666,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a065581-415f-4ca6-8506-8051f5fec840_800x400.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Jordan (left) and me (right) rocking the Progress over Perfection T-shirts!</figcaption></figure></div><p>Let’s end this article with this important message:</p><blockquote><p>There is no such thing as “perfection” and the faster we realize it, the better our progress is going to be and the more things we’ll get done!</p></blockquote><ul><li><p><a href="https://newsletter.eng-leadership.com/p/biggest-productivity-killers-in-the" rel="">Biggest productivity killers in the engineering industry</a><span> (paid article)</span></p></li><li><p><a href="https://newsletter.eng-leadership.com/p/context-switching-one-of-the-worst" rel="">Context-switching - one of the worst productivity killers in the engineering industry</a><span> (paid article)</span></p></li><li><p><a href="https://newsletter.eng-leadership.com/t/productivity" rel="">Check out the full Productivity learning track</a><span> (8 articles)</span></p></li></ul><p>We are not over yet!</p><p>After months of testing and especially trying so many different T-shirts, the store is now officially available to all of you!</p><div><figure><a target="_blank" href="https://store.eng-leadership.com/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png" width="800" height="600" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:115372,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://store.eng-leadership.com/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd0cf284-fa91-4005-a8aa-0ff698e8bd32_800x600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You can get the same Progress over Perfection T-shirt that both me and Jordan are wearing. Or others available. I wear these shirts proudly almost every day. I especially love to wear them when doing exercise!</p><p data-attrs="{&quot;url&quot;:&quot;https://store.eng-leadership.com/&quot;,&quot;text&quot;:&quot;I want to check it out!&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://store.eng-leadership.com/" rel=""><span>I want to check it out!</span></a></p><p><span>Paid subscribers, you are getting </span><strong>20% off</strong><span> on everything in the store!</span></p><p><span>You can find the discount code here: </span><a href="https://newsletter.eng-leadership.com/p/special-deals-for-paid-subscribers" rel="">💰 Special Deals for paid subscribers</a></p><p>Liked this article? Make sure to 💙 click the like button.</p><p>Feedback or addition? Make sure to 💬 comment.</p><p>Know someone that would find this helpful? Make sure to 🔁 share this post.</p><ul><li><p><span>Join the Cohort course Senior Engineer to Lead: Grow and thrive in the role </span><a href="https://maven.com/gregor-ojstersek/senior-engineer-to-lead?promoCode=ENGLEADERSHIP" rel="">here</a><span>.</span></p></li><li><p><span>Book a Coaching and Mentoring or Consulting and Advising call with me </span><a href="https://tidycal.com/gregorojstersek" rel="">here</a><span>.</span></p></li><li><p><span>Interested in sponsoring this newsletter? Check the sponsorship options </span><a href="https://calico-cabinet-fbf.notion.site/Sponsor-Engineering-Leadership-fa0579535d6f4422a6da350580a54546" rel="">here</a><span>.</span></p></li></ul><p><span>You can find me on </span><a href="https://www.linkedin.com/mynetwork/discovery-see-all/?usecase=PEOPLE_FOLLOWS&amp;followMember=gregorojstersek" rel="">LinkedIn</a><span> or </span><a href="https://twitter.com/gregorojstersek" rel="">Twitter</a><span>.</span></p><p>If you wish to make a request on particular topic you would like to read, you can send me an email to info@gregorojstersek.com.</p><p>This newsletter is funded by paid subscriptions from readers like yourself.</p><p>If you aren’t already, consider becoming a paid subscriber to receive the full experience!</p><p data-attrs="{&quot;url&quot;:&quot;https://newsletter.eng-leadership.com/about#§paid-subscribers-get&quot;,&quot;text&quot;:&quot;Check the benefits of the paid plan&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://newsletter.eng-leadership.com/about#%C2%A7paid-subscribers-get" rel=""><span>Check the benefits of the paid plan</span></a></p><p>You are more than welcome to find whatever interests you here and try it out in your particular case. Let me know how it went! Topics are normally about all things engineering related, leadership, management, developing scalable products, building teams etc.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How simultaneous multithreading works under the hood (189 pts)]]></title>
            <link>https://blog.codingconfessions.com/p/simultaneous-multithreading</link>
            <guid>41093916</guid>
            <pubDate>Sun, 28 Jul 2024 15:35:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.codingconfessions.com/p/simultaneous-multithreading">https://blog.codingconfessions.com/p/simultaneous-multithreading</a>, See on <a href="https://news.ycombinator.com/item?id=41093916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Simultaneous multithreading (SMT) is a feature that lets a processor handle instructions from two different threads at the same time. But have you ever wondered how this actually works? How does the processor keep track of two threads and manage its resources between them?</p><p>In this article, we’re going to break it all down. Understanding the nuts and bolts of SMT will help you decide if it’s a good fit for your production servers. Sometimes, SMT can turbocharge your system's performance, but in other cases, it might actually slow things down. Knowing the details will help you make the best choice.</p><p>So, let’s dive in and figure out how SMT works, why it was invented in the first place, and what it means for you. </p><blockquote><h5><em><strong>Disclaimer:</strong></em><span> </span><em>Much of the discussion in this article is about Intel’s implementation of SMT, also called hyper-threading. It is based on their white paper published in 2002</em></h5></blockquote><p><strong>Watch Video Instead:</strong><span> </span><em>If you prefer video over text, then you can also watch the recording of a live session I did on this topic:</em><span> </span></p><div data-component-name="DigestPostEmbed"><a href="https://blog.codingconfessions.com/p/recording-how-hyper-threading-works" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-video.s3.amazonaws.com%2Fvideo_upload%2Fpost%2F146388589%2Fbe1acb70-4217-4ce5-81bb-b051d8c3c24e%2Ftranscoded-00001.png"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-video.s3.amazonaws.com%2Fvideo_upload%2Fpost%2F146388589%2Fbe1acb70-4217-4ce5-81bb-b051d8c3c24e%2Ftranscoded-00001.png" sizes="100vw" alt="Recording: How Hyper-Threading Works — A Microarchitectural Perspective" width="140" height="140"></picture></div></a></div><p>SMT was introduced to improve the utilization of the resources in the processor. At the microarchitecture level, processors consist of hundreds of registers, multiple load/store units and multiple arithmetic units. To utilize these better, processors also employ various techniques for instruction level parallelism (ILP), such as instruction pipelining, superscalar architecture, out-of-order execution to name a few.</p><p>A pipelined processor improves the resource utilization by breaking down the execution of an instruction into multiple stages which form a pipeline, like the assembly line of a factory. In each cycle, an instruction moves from one stage of the pipeline to the next and the processor adds a new instruction to the first stage of the pipeline. The following figure shows how pipelining works for a pipeline of depth 5. As you can see, 5th cycle onwards, the processor will have upto 5 instructions in flight each cycle, and it will finish 1 instruction each cycle after that.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png" width="607" height="133" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:133,&quot;width&quot;:607,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Illustration of a five-stage instruction pipeline. In each cycle, an instruction moves to the next stage which makes up space in the first stage and a new instruction can also start getting processed in each cycle. A super deep pipeline will have many instructions being processed in parallel.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Illustration of a five-stage instruction pipeline. In each cycle, an instruction moves to the next stage which makes up space in the first stage and a new instruction can also start getting processed in each cycle. A super deep pipeline will have many instructions being processed in parallel." title="Illustration of a five-stage instruction pipeline. In each cycle, an instruction moves to the next stage which makes up space in the first stage and a new instruction can also start getting processed in each cycle. A super deep pipeline will have many instructions being processed in parallel." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cbbeb2e-ed04-4f44-bb88-683713a2a740_607x133.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Illustration of a five-stage instruction pipeline. In each cycle, an instruction moves to the next stage which makes up space in the first stage and a new instruction can also start getting processed in each cycle. A super deep pipeline will have many instructions being processed in parallel.</figcaption></figure></div><p>Modern processors are also superscalar, which means instead of issuing one instruction each cycle, they can issue multiple instructions. For instance, the recent Intel core i7 processors can issue 4 instructions each cycle (also called the issue width of the processor).</p><p>Instruction pipelining and superscalar architecture significantly improve the instruction throughput and resource utilization of the processor. However, in practice, this max utilization can be difficult to achieve. To execute so many instructions in parallel, the processor needs to find enough independent instructions in the program, which is very hard.</p><p><span>This typically leads to two kinds of wastages. One is </span><em>horizontal waste</em><span> which occurs when the processor is not able to find enough independent instructions in the thread to saturate the issue width of the processor.</span></p><p><span>The other type of wastage is  </span><em>vertical waste</em><span> that occurs when the processor is unable to issue any instructions in a cycle because all the next instructions in the program are dependent on the currently executing ones.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png" width="665" height="351" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:351,&quot;width&quot;:665,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:45702,&quot;alt&quot;:&quot;Illustration of horizontal and vertical state in a processor with issue width of 5 instructions per cycle. The empty boxes represent the instruction slots where the processor could not issue an instruction&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Illustration of horizontal and vertical state in a processor with issue width of 5 instructions per cycle. The empty boxes represent the instruction slots where the processor could not issue an instruction" title="Illustration of horizontal and vertical state in a processor with issue width of 5 instructions per cycle. The empty boxes represent the instruction slots where the processor could not issue an instruction" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0121e9e-b8b1-4374-ba66-2683ad8364fa_665x351.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Illustration of horizontal and vertical state in a processor with issue width of 5 instructions per cycle. The empty boxes represent the instruction slots where the processor could not issue an instruction</figcaption></figure></div><p>One way to better utilize the processing power is using traditional multithreading where the processor context switches between multiple threads. In this scheme, within a given cycle the processor issues instructions for only one thread, so this may still result in horizontal waste. However, in the next cycle the processor can context switch and issue instructions for another thread and avoid vertical wastage. This results in improved CPU utilization, however, with larger issue width processors, the horizontal wastage can still be significant. Also, there is the overhead of context switching between the threads.</p><p>This is where the idea of simultaneous multithreading was introduced. It enables the processor to issue instructions for multiple threads in the same cycle without any overhead of context switching. By definition, instructions of different threads are independent and can be executed in parallel which ultimately results in full utilization of the execution resources. </p><blockquote><p><em>Even though the idea of SMT doesn’t put a limit on the number of threads, Intel’s implementation of SMT (called hyper-threading) restricts it to two threads per core.</em></p></blockquote><p>We understand why SMT was introduced, now let’s learn about how it is implemented. Along with the implementation details we will also cover how it actually works.</p><p><span>A normal non-SMT processor can only execute instructions for one thread at a time. This is because every thread has an associated context to represent the current state of the program on the processor, which is also called the </span><a href="https://en.wikipedia.org/wiki/Architectural_state" rel="">architecture state</a><span>. This includes the data in the registers, the program counter value, the control registers etc. </span></p><p>To simultaneously execute instructions of two threads, the processor needs to be able to represent the state of the two threads simultaneously. So to implement the SMT capability, the hardware designers duplicated the architecture state of the processor. By doing so, a single physical processor appears as two logical processors to the operating system (OS), so that it can schedule threads for execution on them.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png" width="1342" height="747" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:747,&quot;width&quot;:1342,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:60239,&quot;alt&quot;:&quot;Illustration of a two core processor without SMT (top) and a two core processor with SMT (bottom). For implementing SMT the architecture state has been duplicated in the bottom processor and it will appear as having four processing cores to the OS.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Illustration of a two core processor without SMT (top) and a two core processor with SMT (bottom). For implementing SMT the architecture state has been duplicated in the bottom processor and it will appear as having four processing cores to the OS." title="Illustration of a two core processor without SMT (top) and a two core processor with SMT (bottom). For implementing SMT the architecture state has been duplicated in the bottom processor and it will appear as having four processing cores to the OS." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ddb618f-a2b8-4524-b4e7-7a3f45c10d48_1342x747.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Illustration of a two core processor without SMT (top) and a two core processor with SMT (bottom). For implementing SMT the architecture state has been duplicated in the bottom processor and it will appear as having four processing cores to the OS.</figcaption></figure></div><p>Apart from that, at the microarchitecture level, the processor also has various buffers and execution resources as well. To execute the instructions of two threads simultaneously, these resources are also either duplicated or shared between the two logical processors. The decision of whether to duplicate or to share a resource is based on many factors. For instance, how costly is it to duplicate a resource, in terms of power consumption and real-estate on the chip. </p><p>The crucial details about how SMT works lies in its microarchitectural implementation, so let’s go deeper into that.</p><p><em>The processor exposes the instruction set architecture (ISA) as the public interface for the programmers to program the CPU. The ISA includes the set of instructions, and the registers that the instructions can use. The microarchitecture of the processor is its internal implementation detail. Different processor models can support the same ISA but at the microarchitecture level they might be different.</em></p><p><span>The microarchitecture has three parts: the </span><em>frontend</em><span>, the </span><em>backend</em><span> and the </span><em>retirement unit</em><span>. The following diagram shows the schematics of the microarchitecture of a modern day processor:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png" width="695" height="631" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:631,&quot;width&quot;:695,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:56859,&quot;alt&quot;:&quot;The schematics of the microarchitecture of a modern processor consisting of the frontend, the backend, and the retirement unit&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="The schematics of the microarchitecture of a modern processor consisting of the frontend, the backend, and the retirement unit" title="The schematics of the microarchitecture of a modern processor consisting of the frontend, the backend, and the retirement unit" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F987bee1e-0bec-4753-947c-5ff58cb1a260_695x631.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The schematics of the microarchitecture of a modern processor consisting of the frontend, the backend, and the retirement unit</figcaption></figure></div><p>The frontend is the part which contains the instruction control unit that fetches and decodes the program instructions which should be executed next.</p><p>The backend consists of the execution resources, such as the physical registers, the arithmetic units, and the load/store units. It picks up the decoded instructions provided by the frontend, allocates execution resources for them and schedules them for execution.</p><p>The retirement unit is where the results of the executed instructions are finally committed to the architecture state of the processor.</p><p>To understand how SMT works we will go deeper into each of three components of the CPU microarchitecture. Let’s start with the frontend.</p><p>The following figure shows a more zoomed in view of the microarchitecture frontend. It consists of several components with each having a distinct role behind the fetching and decoding of instructions. Let’s talk about them one by one.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png" width="497" height="486" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:486,&quot;width&quot;:497,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:70383,&quot;alt&quot;:&quot;A zoomed in view of the frontend of an X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="A zoomed in view of the frontend of an X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002." title="A zoomed in view of the frontend of an X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1bf4a84-1c63-461e-9050-cd925a66749c_497x486.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A zoomed in view of the frontend of an X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002.</figcaption></figure></div><p>To track which instructions to fetch, the frontend contains an instruction pointer which contains the address of the next instruction of the program.</p><p>In the case of an SMT capable processor, there are two sets of instruction pointers which track the next instruction for the two programs independently.</p><p>The instruction pointers gives the addresses of the next instructions of the threads and the frontend has to read the instructions from those addresses. Before doing that it first checks for the existence of those instructions in the trace cache. </p><p>The trace cache contains recently decoded traces of instructions. Instruction decoding is an expensive operation and some instructions need to be executed frequently. Having this cache helps the processor cut down the instruction execution latency.</p><p>Trace cache is shared dynamically between the two logical processors on an as needed basis. If one thread is executing more instructions than the other, it is allowed to occupy more entries in the trace cache.</p><p>Each entry in the cache is tagged with the thread information to distinguish the instructions of the two threads. The access to the trace cache is arbitrated between the two logical processors each cycle. </p><p>If there is a miss in the trace cache, then the frontend looks for the instruction for the given address in the L1 instruction cache. If there is a miss in the L1 instruction cache, then it needs to fetch the instruction from the next level cache or the main memory.</p><p><span>The L1 instruction caches data using its </span><a href="https://en.wikipedia.org/wiki/Virtual_address_space" rel="">virtual address</a><span>, but main memory lookups require physical addresses. To translate the virtual addresses into physical addresses, the instruction lookaside buffer (ITLB) is used which contains the recently translated virtual addresses. </span></p><p>In an SMT capable processor, each logical processors has its own ITLB cache.</p><p>The instruction fetch logic for fetching the instructions from the main memory works on a first come first served basis, but it reserves at least one request slot for each logical processor so that both can make progress.</p><p>Once the instructions arrive from the main memory, they are kept in a small streaming buffer before they get picked up for decoding. These buffers are also small structures and duplicated for the logical processors in an SMT capable processor.</p><p>Once the instructions are fetched, they are decoded into smaller and simpler instructions called micro instructions (uops). These uops are put into the uop queue which acts as the boundary between the CPU frontend and backend. </p><p>The uop queue is shared equally between the two logical processors. This static partitioning enables both the logical processors to make independent progress.</p><p>Once the Uop queue has microinstructions ready, the role of the backend starts. The following figure shows a zoomed in view of the backend of an Intel X86 processor.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png" width="1056" height="479" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:479,&quot;width&quot;:1056,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;The zoomed in view of the backend of an Intel X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="The zoomed in view of the backend of an Intel X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002." title="The zoomed in view of the backend of an Intel X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66314505-33d7-441b-9cfb-8c4bbeb61085_1056x479.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The zoomed in view of the backend of an Intel X86 processor. Source: Intel Technology Journal, Vol 06, Issue 01, 2002.</figcaption></figure></div><p>Let’s talk about what happens in the backend component wise. </p><p>The backend picks up the micro instructions from the uop queue and executes them. However, it executes them out of their original program order. </p><p>Nearby instructions in a program are typically dependent on each other and these instructions may stall because they may perform a long latency operation, such as reading from main memory. As a result, all of their dependent instructions will also have to wait. In such a situation, the processor’s resources are wasted. To alleviate this problem, out-of-order execution engine is employed which picks up later instructions of the program and executes them out of their original order.</p><p>The out-of-order execution engine consists of an allocator which identifies the resources required by these micro instructions and allocates them based on their availability.</p><p>The allocator allocates resources for the micro instructions of one logical processor in one cycle and then switches to the other logical processor in the next cycle. If the uop queue has micro instructions for only one of the logical processors, or one of the logical processors has exhausted its share of resources, then the allocator uses all the cycles for the other logical processor.</p><p>So what are these resources that the allocator allocates to the micro instructions and how are they shared?</p><p>The first resource that the micro instructions need is registers. At the ISA level the processor might only have a very few registers (e.g. X86-64 has 16 general purpose integer registers), but at the microarchitecture level there are hundreds of physical integer registers, and similar number of floating-point registers. In an SMT enabled processor, these registers are divided equally between the two logical processors.</p><p>Apart from the registers, the backend also has a number of load and store buffers. These buffers are used for doing memory read and write operations. Again, in an SMT enabled processor, they are divided equally between the logical processors.</p><p>To enable out-of-order execution, the backend also needs to perform register renaming. Because at the ISA level there are only a handful of architectural registers, the program instructions will reuse the same register in many independent instructions. And, the out-of-order execution engine wants to execute these instructions ahead of their original order and in parallel. For doing so, it renames the original logical registers used in the program instructions to one of the physical registers. This mapping is maintained in the register alias table (RAT). </p><p>Because the two logical processors have their own sets of architectural registers, they also have their own copy of the RAT. </p><p>After the register renaming and allocator stages, the instructions are almost ready to execute. They are put into two sets of queues — one is for the memory read/write instructions and the other is for all other general instructions. These queues are also partitioned equally between the two logical processors in an SMT enabled core.</p><p>The processor has multiple instruction schedulers which operate in parallel. In each CPU cycle, some of the instructions from the instruction ready queues are pushed to the schedulers. The queues switch between the instructions of the two logical processors each cycle, i.e., in one cycle they push the instruction of one logical processor and in the next they switch to the second logical processor. </p><p>Each scheduler itself has a small internal buffer to store these pushed instructions temporarily until the scheduler can schedule them for execution. Each of these instructions need certain operands and execution units to be available. As soon as the required data and resources for one of the instructions become available, the scheduler dispatches that instruction for execution. </p><p>The schedulers do not care about the logical processors, they will execute a micro instruction as soon as the resources required by that instruction are available. But to ensure fairness, there is a limit on the number of active entries for a logical processor in the scheduler’s queue. </p><p>After the execution of an instruction finishes and its result is ready, it is placed in the reorder buffer. Even though the instructions are executed out-of-order, they need to be committed to the processor’s architecture state in their original program order. The reorder buffer enables this.</p><p>The reorder buffer is split equally between the two logical processors in an SMT enabled core.</p><p>The retirement unit tracks when the instructions are ready to be committed to the architecture state of the processor and retires them in their correct program order.</p><p>In an SMT enabled processor core, the retirement unit alternates between the micro instructions for each logical processor. If one of the logical processors does not have any micro instructions to be retired, then the retirement unit spends all the bandwidth on the other logical processor.</p><p>After an instruction retires, it might also have to write to the L1 cache. At this point the selection logic comes into the picture to do these writes, and that also alternates between the two logical processors each cycle to write the data to the cache.</p><p>While we have covered how the execution resources of a processor core are shared between the logical processors for an SMT enabled system, we have not talked about memory access. Let’s discuss what happens there.</p><p>The translation lookaside buffer (TLB) is a small cache which holds the translation of virtual addresses to physical addresses for data requests. The TLB is shared dynamically between the two logical processors on an as needed basis. To distinguish the entries for the two logical processors, each entry is also tagged with the logical processor id. </p><p>Each CPU core has its own private L1 cache. Depending on the microarchitecture, the L2 cache might also be private or it might be shared between the cores. If there is an L3 cache, it is shared between the cores. The caches are also oblivious to the existence of the logical processors.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png" width="866" height="470" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6010b920-377a-41bf-9a47-d5378699661d_866x470.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:470,&quot;width&quot;:866,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:77007,&quot;alt&quot;:&quot;Depiction of L1 and L2 caches in a 2 core processor. Each core has its own private L1 and L2 caches.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Depiction of L1 and L2 caches in a 2 core processor. Each core has its own private L1 and L2 caches." title="Depiction of L1 and L2 caches in a 2 core processor. Each core has its own private L1 and L2 caches." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6010b920-377a-41bf-9a47-d5378699661d_866x470.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Depiction of L1 and L2 caches in a 2 core processor. Each core has its own private L1 and L2 caches.</figcaption></figure></div><p>As the L1 (and possibly L2) cache is private to the core, it will contain data for both the logical processors on an as needed basis. This can cause conflict and eviction of the data and hamper the performance. On the other hand if the threads running on the two logical processors are working with the same set of data, the shared cache might improve their performance.</p><p>At this point we have covered almost everything about how SMT is implemented at the microarchitecture level and how the instructions for the two logical processors are executed in parallel. Now let’s discuss the performance impact.</p><p>As we have seen, enabling SMT on a CPU core requires sharing many of the buffers and execution resources between the two logical processors. Even if there is only one thread running on an SMT enabled core, these resources remain unavailable to that thread which reduces its potential performance.</p><p>Apart from the wasted shared resources in the absence of the 2nd thread, there is another performance impact. The operating system runs an idle loop on the unused logical processor which waits for instructions to arrive. This loop also wastes resources which could otherwise be spent on letting the other logical processor at its peak potential.</p><p>If you have two threads running on the two logical processors, then one of the things to think about is their cache access patterns. If the threads are using the cache aggressively and competing for it then they are bound to run into conflicts and evict each other’s data, which will degrade their performance.</p><p>On the other hand, if the threads are cooperating in nature, they might help improve each other’s performance. For instance, one thread is producing some data which is consumed by the other thread, then their performance will improve because of the data sharing in the cache.</p><p>If the two threads are not competing for cache, then they might be able to run fine without hampering each other’s performance, while improving the resource usage of the CPU core. </p><p>However, many experts believe that when absolute maximum performance is needed for a program, it is best to disable SMT so that the single thread will have all the resources available to it.</p><p><span>Apart from performance, there are also security issues associated with SMT which were discovered in the recent few years (see </span><a href="https://docs.oracle.com/en/operating-systems/oracle-linux/notice-smt/" rel="">this</a><span> and </span><a href="https://access.redhat.com/solutions/rhel-smt" rel="">this</a><span> for examples). Because of the shared resources and speculative execution of instructions, a lot of these issues open up possibilities of leaks of sensitive data to the attacker. As a result, the general advice has been to disable SMT in the systems. There is also </span><a href="https://www.extremetech.com/computing/intels-arrow-lake-cpus-will-allegedly-ditch-hyper-threading-leak" rel="">rumor</a><span> that because of these issues Intel might remove hyperthreading from their next generation of processors (Arrow Lake). </span></p><p>Let's wrap things up. Understanding how Simultaneous Multithreading (SMT) works is super helpful when you’re deciding whether or not to use it in your production servers. SMT was designed to make better use of CPU resources and boost instruction throughput. While it does a good job of that by letting multiple threads run at the same time, there are definitely some trade-offs to keep in mind.</p><p>Inside the processor, SMT means duplicating certain parts and sharing or dividing up others between the threads. This can lead to mixed results depending on what kind of work your CPU is handling. Sure, SMT can improve resource usage and system throughput overall, but it can also cause competition for shared resources, which can slow down individual threads.</p><p>Security is another big factor. Recent vulnerabilities have shown that sharing resources in SMT-enabled CPUs can be risky. Sensitive data could end up getting exposed, which is why some experts often recommend disabling SMT in security-critical systems.</p><p>So, should you use SMT? It really depends. If your workloads need the highest performance and lowest latency, turning SMT off might give you that edge. But if you’re running general-purpose tasks that can benefit from more parallelism, keeping SMT on could be a win.</p><p>By getting a handle on these details, you’ll be better equipped to decide what's best for your setup, ensuring you get the most efficient—and secure—performance out of your servers.</p><ul><li><p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/research/2002-vol06-iss-1-intel-technology-journal.pdf" rel="">Intel Technology Journal, 2002, Vol 06, Issue 1</a></p></li><li><p><a href="https://www.princeton.edu/~rblee/ELE572Papers/SMT_Eggers.pdf" rel="">Simultaneous Multithreading: Maximizing On-Chip Parallelism</a></p></li><li><p><a href="https://arxiv.org/pdf/2310.12786" rel="">SYNPA: SMT Performance Analysis and Allocation of Threads to Cores in ARM Processors</a></p></li></ul><p>If you find my work interesting and valuable, you can support me by opting for a paid subscription (it’s $6 monthly/$60 annual). As a bonus you get access to monthly live sessions, and all the past recordings. </p><p><span>Many people report failed payments, or don’t want a recurring subscription. For that I also have a </span><a href="https://buymeacoffee.com/codeconfessions" rel="">buymeacoffee page</a><span>. Where you can buy me coffees or become a member. I will upgrade you to a paid subscription for the equivalent duration here.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://buymeacoffee.com/codeconfessions&quot;,&quot;text&quot;:&quot;Buy me a coffee&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://buymeacoffee.com/codeconfessions" rel=""><span>Buy me a coffee</span></a></p><p>I also have a GitHub Sponsor page. You will get a sponsorship badge, and also a complementary paid subscription here.</p><p data-attrs="{&quot;url&quot;:&quot;https://github.com/sponsors/abhinav-upadhyay&quot;,&quot;text&quot;:&quot;Sponsor me on GitHub&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://github.com/sponsors/abhinav-upadhyay" rel=""><span>Sponsor me on GitHub</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://blog.codingconfessions.com/p/simultaneous-multithreading?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://blog.codingconfessions.com/p/simultaneous-multithreading?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My favorite tools and techniques for procedural gamedev (194 pts)]]></title>
            <link>https://cprimozic.net/blog/tools-and-techniques-for-procedural-gamedev/</link>
            <guid>41092861</guid>
            <pubDate>Sun, 28 Jul 2024 12:56:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cprimozic.net/blog/tools-and-techniques-for-procedural-gamedev/">https://cprimozic.net/blog/tools-and-techniques-for-procedural-gamedev/</a>, See on <a href="https://news.ycombinator.com/item?id=41092861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For a couple of years now, I've been working on and off on some <a href="https://github.com/ameobea/sketches-3d">3D scenes and levels</a> that run in the browser.  It started off as a scattering of self-contained demos for some custom shaders or similar that I wanted to try out, but over time the project has grown into a pretty substantial interconnected game-like thing.</p>
<p>One of the unifying themes of the work is the use procedural and generative techniques in some way.  Usually it's just some specific element of the level that makes use of this rather than a fully procedurally generated world.</p>
<p>This has resulted in me accumulating a good number of procedural and semi-procedural tools and effects that I re-use from level to level.  I thought I'd put together a list of some of my favorites in case they might be of interest to anyone else working on similar kinds of 3D applications.</p>
<h2 id="shaders--textures"><a href="#shaders--textures" aria-label="shaders  textures permalink"></a>Shaders + Textures</h2>
<p>Most of the textures I use for my scenes are seamless - meaning that they tile along both axes without any visible discontinuities.  They're popular in gamedev and used regularly.</p>
<p>Here's an example of one that I've used in the past:</p>
<p><span>
      <a href="https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/6cf05/seamless-texture.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/8359c/seamless-texture.avif 210w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/4c727/seamless-texture.avif 420w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/4ab03/seamless-texture.avif 840w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/c3c94/seamless-texture.avif 1260w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/c095d/seamless-texture.avif 1680w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/cf946/seamless-texture.avif 3074w" sizes="(max-width: 840px) 100vw, 840px" type="image/avif">
          <source srcset="https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/aaa7a/seamless-texture.png 210w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/2dc40/seamless-texture.png 420w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/993bb/seamless-texture.png 840w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/db723/seamless-texture.png 1260w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/7bc17/seamless-texture.png 1680w, https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/6cf05/seamless-texture.png 3074w" sizes="(max-width: 840px) 100vw, 840px" type="image/png">
          <img src="https://cprimozic.b-cdn.net/static/4edbb1f1a5502ef5331f90e2480dd516/993bb/seamless-texture.png" alt="A screenshot of a seamless texture consisting of black rock with gold flecks tiling repeatedly.  There are no obvious discontinuities or cutoff points where the image repeats." title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>Although it does tile smoothly, you can pretty clearly see the patterns created by it repeating - especially when it's spread across a large area.</p>
<p>There are a lot of fancy tricks that can be used with seamless textures to make them even more useful.  I created a custom shader in Three.JS which extends the base <code>MeshPhysicalMaterial</code> with a bunch of additions and extra features that I can turn on at will, and several of them are dedicated to improving seamless texturing support for my materials.</p>
<h3 id="triplanar-mapping"><a href="#triplanar-mapping" aria-label="triplanar mapping permalink"></a>Triplanar Mapping</h3>
<p>Triplanar mapping is the workhorse of my texturing toolkit.  I end up using it in some way in pretty much every level I create, and it works far better than it ought to given how simple it is to implement.</p>
<p>The reason for this is that it allows meshes to be textured using seamless textures without the need for pre-defined UV maps.  For that reason, this technique is usually used for things like procedurally generated terrain since there isn't an opportunity for a modeller to define a UV mapping for them.</p>
<p>
I've found triplanar mapping to work well for a vast array of both generated and hand-modeled meshes.
</p>
<p>Seriously - I throw this thing on everything and it almost always looks at least half decent.</p>
<p>It's also quite light-weight and easy to implement; here's <a href="https://github.com/Ameobea/sketches-3d/blob/main/src/viz/shaders/triplanarMapping.ts">my implementation</a> for reference.</p>
<h4 id="tweaks--improvements"><a href="#tweaks--improvements" aria-label="tweaks  improvements permalink"></a>Tweaks + Improvements</h4>
<p>I also made a slight tweak to the default triplanar mapping algorithm which makes it even better.</p>
<p>Normally, triplanar mapping uses a linear mix of three texture lookups for each axis based on the fragment's normal.  This can lead to visible layering of the texture in areas where the normal isn't very close a single axis.</p>
<p>To improve this, I run the weights through a <code>pow()</code> call with a pretty high exponent and then re-normalize the resulting vector.  This has the effect of putting more weight on the dominant axis and making the transition areas much smaller.  This drastically improves the quality of the results (left is without <code>pow()</code>, right is with):</p>

<p>As an added bonus, performing this transformation results in one axis having a weight very close to 1 and the other two axes having weights very close to zero for most places on the mesh.  This allows for an optimization that just completely skips texture lookups for weights smaller than some threshold and makes the performance overhead of triplanar mapping much lighter - barely more than normal UV-mapped texturing.</p>
<p>One last trick I use in my triplanar mapping implementation is for handling normal maps - which need some special considerations in the shader code in order to get correct results.</p>
<p>I use the method that was introduced <a href="https://github.com/bgolus/Normal-Mapping-for-a-Triplanar-Shader/blob/master/TriplanarGPUGems3.shader#L62">in GPU Gems</a> that specifically addresses this and it works nicely.  There's more details in <a href="https://bgolus.medium.com/normal-mapping-for-a-triplanar-shader-10bf39dca05a">this blog post</a> as well if you're looking to implement this yourself.</p>
<h3 id="hex-tiling"><a href="#hex-tiling" aria-label="hex tiling permalink"></a>Hex Tiling</h3>
<p>This is another technique that I make use of in most of my scenes in some way.  Hex Tiling is an algorithm that completely hides visible tiling and repetition in seamless textures.</p>
<p>Here's an example of the effect it can have on a stripped-down scene to highlight its impact:</p>

<p>It's hard to overstate how good this effect is at making a wide range of scenes look way, way better - and all it takes is adding one extra config option to the material to turn it on.  It can make a scene go from looking like a low-effort mockup to semi-realistic all by itself.</p>
<p>My original hex tiling implementation was based on a <a href="https://www.shadertoy.com/view/MdyfDV">Shadertoy</a> by <a href="http://evasion.imag.fr/~Fabrice.Neyret/">Fabrice Neyret</a>.  I converted it to work with Three.JS's material system and integrated it into the shader for the main material for my project.</p>
<p>I also ported my version of the hex tiling shader (with permission) it into a <a href="https://github.com/ameobea/three-hex-tiling">standalone library</a> that can be plugged into any Three.JS project to add hex tiling support to its built-in materials.</p>
<p>There are some caveats to note about this technique though.  Unlike triplanar mapping, hex tiling does require a pre-defined UV mapping.  I looked into using triplanar mapping and hex tiling together - which would be incredibly useful - but the performance overhead seems to just be too much.  The max texture fetches needed for each fragment would go up multiplicatively to a whopping 27 for each map used, and that is obviously ridiculous and impractical.</p>
<p>The being said, the hex tiling algorithm does linear interpolation between three lookups for each fragment just like triplanar mapping, so the same <code>pow()</code> trick for the interpolation weights that I developed to reduce texture fetches in triplanar mapping can also be used.  This not only improves performance but also makes the results look better as well.</p>
<h3 id="depth-pre-pass"><a href="#depth-pre-pass" aria-label="depth pre pass permalink"></a>Depth Pre-Pass</h3>
<p>All of these texturing methods can have a non-trivial performance impact - especially in large scenes with a lot going on.  This can result in a fragment shader that is quite expensive to run.</p>
<p>A depth pre-pass excellent option for winning back some performance.  It's a pretty common method in computer graphics and is used decently often in different game engines and rendering pipelines.  The idea is that you render the entire scene using an extremely simple material that is as cheap as possible to render and record the depth fo every pixel.</p>
<p>Although there is some overhead involved in rendering the whole scene twice, it's almost always worth it.  Especially for scenes with high amounts of overdraw, adding a depth pre-pass can often improve performance by 30% or more.</p>
<p>By changing the configuration of the pre-pass, you can set it to do the inverse and only render occluded fragments:</p>
<p><span>
      <a href="https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/31d0f/occluded-frag-viz.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/8359c/occluded-frag-viz.avif 210w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/4c727/occluded-frag-viz.avif 420w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/4ab03/occluded-frag-viz.avif 840w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/c3c94/occluded-frag-viz.avif 1260w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/c095d/occluded-frag-viz.avif 1680w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/a5f5d/occluded-frag-viz.avif 1886w" sizes="(max-width: 840px) 100vw, 840px" type="image/avif">
          <source srcset="https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/aaa7a/occluded-frag-viz.png 210w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/2dc40/occluded-frag-viz.png 420w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/993bb/occluded-frag-viz.png 840w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/db723/occluded-frag-viz.png 1260w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/7bc17/occluded-frag-viz.png 1680w, https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/31d0f/occluded-frag-viz.png 1886w" sizes="(max-width: 840px) 100vw, 840px" type="image/png">
          <img src="https://cprimozic.b-cdn.net/static/416bf83f2b3c1231698f5449ffaa7a6a/993bb/occluded-frag-viz.png" alt="A screenshot from a scene rendered with a showing the result of inverting the depth test of the depth pre-pass and rendering only occluded fragments.  It looks similar to what happens when you change the GL rendering mode to backface." title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>Every fragment rendered in this image is one that gets skipped when a depth pre-pass is used.</p>
<p>I also wrote a <a href="https://cprimozic.net/blog/threejs-depth-pre-pass-optimization/">dedicated article</a> with more details about the setup and how I implemented it for Three.JS.</p>
<h3 id="ai-powered-pbr-texture-synthesis"><a href="#ai-powered-pbr-texture-synthesis" aria-label="ai powered pbr texture synthesis permalink"></a>AI-Powered PBR Texture Synthesis</h3>
<p>I figure I should mention this here since it's something I make use of in pretty much all my scenes.  AI-generated textures are a bit of a contentious topic, but I find that they lend themselves very well to the kind of things I build.</p>
<p>If used tastefully, the results can actually look pretty good.  Every texture in this scene below is AI-generated:</p>
<p><span>
      <a href="https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/87caf/3d-sketches.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/8359c/3d-sketches.avif 210w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/4c727/3d-sketches.avif 420w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/4ab03/3d-sketches.avif 840w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/c3c94/3d-sketches.avif 1260w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/30c6a/3d-sketches.avif 1512w" sizes="(max-width: 840px) 100vw, 840px" type="image/avif">
          <source srcset="https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/aaa7a/3d-sketches.png 210w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/2dc40/3d-sketches.png 420w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/993bb/3d-sketches.png 840w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/db723/3d-sketches.png 1260w, https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/87caf/3d-sketches.png 1512w" sizes="(max-width: 840px) 100vw, 840px" type="image/png">
          <img src="https://cprimozic.b-cdn.net/static/df9dea909a1a6da6ddc5737499aa35ef/993bb/3d-sketches.png" alt="A screenshot of one of the 3D sketches I created as a part of this project.  A golden arch made out of a metallic-rocky material stands on a concrete plinth.  It sits in what looks like a sort of shrine with curved stone arches.  There is a cobblestone floor and stone walls.  The graphics are reminiscent of PS2 games or similar style." title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>I also wrote a <a href="https://cprimozic.net/notes/posts/generating-textures-for-3d-using-stable-diffusion/">dedicated article</a> about my process for generating these textures, generating PBR maps for them, and combining them to produce seamless 4K textures without upscaling.</p>
<p>One note is that the website I reference in the article which I used to generate PBR maps is no longer available.  Instead, I've been using <a href="https://github.com/HugoTini/DeepBump">DeepBump</a> to generate normal maps and non-AI tools like <a href="https://www.boundingboxsoftware.com/materialize/">Materialize</a> for the other maps if I really need them.</p>
<h3 id="volumetric-fogclouds"><a href="#volumetric-fogclouds" aria-label="volumetric fogclouds permalink"></a>Volumetric Fog/Clouds</h3>
<p>I've long been interested in volumetric rendering for the unique effect it lends to scenes.  I put together a relatively versatile shader that can add clouds or fog to any Three.JS scene which produces results like this:</p>
<p><span>
      <a href="https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/ba9b4/volumetric-pass.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/8359c/volumetric-pass.avif 210w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/4c727/volumetric-pass.avif 420w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/4ab03/volumetric-pass.avif 840w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/c3c94/volumetric-pass.avif 1260w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/c095d/volumetric-pass.avif 1680w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/2d32d/volumetric-pass.avif 3188w" sizes="(max-width: 840px) 100vw, 840px" type="image/avif">
          <source srcset="https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/aaa7a/volumetric-pass.png 210w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/2dc40/volumetric-pass.png 420w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/993bb/volumetric-pass.png 840w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/db723/volumetric-pass.png 1260w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/7bc17/volumetric-pass.png 1680w, https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/ba9b4/volumetric-pass.png 3188w" sizes="(max-width: 840px) 100vw, 840px" type="image/png">
          <img src="https://cprimozic.b-cdn.net/static/4c44b419896e49e625b4fcc20569b942/993bb/volumetric-pass.png" alt="A screenshot of some clouds rendered using the volumetric pass I developed for Three.JS.  The image features a dense layer of somewhat fluffy-looking clouds with the image taken from a perspective above them.  The color of the clouds is mostly gray and white.  The sky above the horizon is pure black." title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>I was inspired an awesome <a href="https://www.shadertoy.com/view/XslGRr">Shadertoy</a> by the legendary shader author <a href="https://iquilezles.org/">Inigo Quilez</a> (who helped create Shadertoy itself).  I created a basic volumetric volumetric clouds shader of my own using LoD noise lookups similar to the ones he used in his. I then kept adding features to it and expanding it to make it more generic and configurable.</p>
<p>I find that this shader is very useful for filling in the gaps of sparse levels and adding a bit of dynamism to static levels by introducing some moving clouds or fog.</p>
<p>This shader also used some code and approaches developed by <a href="https://github.com/n8python">n8programs</a> for the <a href="https://github.com/ameobea/three-good-godrays"><code>three-good-godrays</code></a> project that we built together.  I use <code>three-good-godrays</code> decently often as well; it adds an extremely unique vibe to levels.</p>
<h2 id="meshes--geometry"><a href="#meshes--geometry" aria-label="meshes  geometry permalink"></a>Meshes + Geometry</h2>
<p>Generating meshes at runtime is something I've been getting into more and more recently.  I like the idea of growing a world out of a software seed, but I want to avoid the "infinite but empty" phenomenon that some games which bill themselves as procedural can become.</p>
<p>
To that end, I've been mostly focusing on adding decorations, backdrops, or procedural flourishes to levels rather than making the core of the experience procedurally generated.
</p>
<h3 id="lod-terrain"><a href="#lod-terrain" aria-label="lod terrain permalink"></a>LoD Terrain</h3>
<p>Terrain generation is a staple of procedural gamedev, and it's well-trodden ground in the space.  My implementation is really nothing special, so I won't spend a lot of time going into details about it.</p>
<p>Like most other methods, I use noise functions to generate a heightmap for the terrain and then tessellate it into triangles for rendering.  I texture it using triplanar mapping or hex tiling.</p>
<p>The main cool thing about it is the LoD system.  The terrain is generated in tiles, and each tile gets generated at a range of resolutions.  The different resolutions are then dynamically swapped in and out based on the distance between that tile and the camera, as shown in this debug view:</p>
<p><span>
      <a href="https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/7d1b4/lod-terrain.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/8359c/lod-terrain.avif 210w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/4c727/lod-terrain.avif 420w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/4ab03/lod-terrain.avif 840w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/c3c94/lod-terrain.avif 1260w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/c095d/lod-terrain.avif 1680w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/e2eb5/lod-terrain.avif 1983w" sizes="(max-width: 840px) 100vw, 840px" type="image/avif">
          <source srcset="https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/aaa7a/lod-terrain.png 210w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/2dc40/lod-terrain.png 420w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/993bb/lod-terrain.png 840w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/db723/lod-terrain.png 1260w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/7bc17/lod-terrain.png 1680w, https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/7d1b4/lod-terrain.png 1983w" sizes="(max-width: 840px) 100vw, 840px" type="image/png">
          <img src="https://cprimozic.b-cdn.net/static/07805fbe91f3aa7e4f25d83e8ba50878/993bb/lod-terrain.png" alt="A screenshot of a debug view of the LOD terrain system.  It shows some procedurally generated terrain rendered as a wireframe with different colors representing different levels of detail." title="" loading="lazy" decoding="async">
        </picture>
  </a>
    </span></p>
<p>Again, nothing groundbreaking here.  But I make use of this terrain generation system all the time and having a flexible and efficient system to implement it makes it possible to re-use it with minimal effort.</p>
<h3 id="procedural-mesh-processing--manipulation-pipeline"><a href="#procedural-mesh-processing--manipulation-pipeline" aria-label="procedural mesh processing  manipulation pipeline permalink"></a>Procedural Mesh Processing + Manipulation Pipeline</h3>
<p>This is the piece I've been working on most recently.  My original goal was to take low-poly meshes - including those generated dynamically - and procedurally subdivide + deform them.  The idea was to make simple meshes for things like platforms, boulders, or other large structures look more realistic or interesting when added to my levels.</p>
<p>Here's a bit of an extreme example of the kind of deformation that can be achieved using this process:</p>

<p>These efforts led to me building a pretty capable software pipeline for ingesting raw geometry data, making arbitrary changes to it, and re-exporting it in a ready-to-render format - all in the browser at runtime.</p>
<p>
It turns out that there's a good bit of nuance involved in this - particularly when it comes to handling normals.
</p>
<p>One last time, I'll link to a <a href="https://cprimozic.net/blog/subdividing-meshes-for-displacement/">separate writeup</a> that I published which goes into much detail about how this pipeline was implemented.</p>
<h2 id="future-work"><a href="#future-work" aria-label="future work permalink"></a>Future Work</h2>
<p>Most of the things I've listed here were originally developed as one-offs for some specific use case.  Then, I'd end up thinking of different contexts to try them in and re-using on other levels since I already had them built.</p>
<p>There are some other ideas I want to try out which I think have a lot of potential to be cool and useful.  First on my list is:</p>
<h3 id="constructive-solid-geometry"><a href="#constructive-solid-geometry" aria-label="constructive solid geometry permalink"></a>Constructive Solid Geometry</h3>
<p>Constructive Solid Geometry is something I've wanted to try out for a long time.  It's essentially a system for applying boolean operators to 3D space.  This lets you do things like merge two arbitrary meshes together, cut chunks out of meshes, and stuff like that.</p>
<p>Some time ago, I found the <a href="https://evanw.github.io/csg.js/">csg.js</a> library which inspired me greatly.  It implements a full CSG toolkit (including mesh primitives, all the boolean operators, and a clean API) within a single ~500 LoC file of well-commented JavaScript.</p>
<p>At some point, I am planning on porting this library to Rust and hopefully getting a better understanding of how it works in the process.  I think that there's a lot of potential for using this in tandem with the mesh processing pipeline to produce some really cool results.</p>
<p>One thing I especially want to try out is to procedurally "damage" meshes.  I want to be able to take chunks out of buildings or bridges to simulate decay or weathering or generate cracks in walls or roads.  I'm sure I'd find a ton of other uses for it as well once it's available.</p>
<p>I'll definitely write about how that goes once I get around to implementing it.  If you're interested, you can subscribe to my blog's <a href="https://cprimozic.net/rss.xml">RSS feed</a> or follow me on <a href="https://twitter.com/ameobea10">Twitter</a> or <a href="https://mastodon.ameo.dev/@ameo">Mastodon</a> where I post updates about the things I work on.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CalcGPT (154 pts)]]></title>
            <link>https://calcgpt.io/</link>
            <guid>41092460</guid>
            <pubDate>Sun, 28 Jul 2024 11:08:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://calcgpt.io/">https://calcgpt.io/</a>, See on <a href="https://news.ycombinator.com/item?id=41092460">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-tisrfsvx="" data-astro-cid-j7pv25f6="">  <p>2023</p> <p>GPT-3 (babbage-002), HTML, CSS and JS on website</p> <p data-astro-cid-tisrfsvx=""> <a href="https://calvin.sh/" target="_blank" rel="noopener noreferrer" data-astro-cid-tisrfsvx=""><b data-astro-cid-tisrfsvx="">Calvin Liang</b></a> </p> <p data-astro-cid-tisrfsvx="">
CalcGPT, conceived by an incisive and quirky artist-engineer Calvin Liang,
      serves as the praxis of satire in a hyper-advanced AI-dominated era.
      Imbued with an ingenious blend of technology and dry humor, the creation
      shrewdly prods at the modern world's pervasive and at times, excessive
      leaning towards AI solutions - even when not necessarily needed.
</p> <p data-astro-cid-tisrfsvx="">
More than merely functional, this artwork manifests in the rather
      unassuming form of a calculator, powered by the sophisticated GPT language
      model. But this isn't your standard piece of tech; instead, it is a clever
      parody, an emblem of resistance to the unrelenting AI craze.
</p> <p data-astro-cid-tisrfsvx="">
CalcGPT embodies the timeless adage - 'Old is Gold' - reminding us that
      it’s often rewarding to resort to established, traditional methods rather
      than chasing buzzword-infused cutting-edge tech. Serving not just as a
      computational tool, but as a poignant social commentary, this creation
      employs the grandeur of technology to a funny yet thought-provoking end.
</p> <p data-astro-cid-tisrfsvx="">
The piece invites us to reflect on the necessity and relevance of AI in
      every aspect of our lives as opposed to its prevailing use as a mere
      marketing gimmick. With its delightful slowness and propensity for
      computational errors, CalcGPT elicits mirth while urging us to question
      our zealous indulgence in all things AI.
</p> <p data-astro-cid-tisrfsvx="">
Liang's creation is laced with understated humor, driving home a
      lighthearted critique on our unchecked fascination with AI. CalcGPT urges
      us to weigh the equilibrium between preserving tradition and embracing
      innovation and reflects on the possibility of our headlong pursuit of
      fashionable tech buzzwords misguiding us.
</p> <p data-astro-cid-tisrfsvx="">^ written by ChatGPT</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Irrational hungry judge effect: magnitude is overestimated (2023) (194 pts)]]></title>
            <link>https://www.cambridge.org/core/journals/judgment-and-decision-making/article/irrational-hungry-judge-effect-revisited-simulations-reveal-that-the-magnitude-of-the-effect-is-overestimated/61CE825D4DC137675BB9CAD04571AE58</link>
            <guid>41091803</guid>
            <pubDate>Sun, 28 Jul 2024 07:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cambridge.org/core/journals/judgment-and-decision-making/article/irrational-hungry-judge-effect-revisited-simulations-reveal-that-the-magnitude-of-the-effect-is-overestimated/61CE825D4DC137675BB9CAD04571AE58">https://www.cambridge.org/core/journals/judgment-and-decision-making/article/irrational-hungry-judge-effect-revisited-simulations-reveal-that-the-magnitude-of-the-effect-is-overestimated/61CE825D4DC137675BB9CAD04571AE58</a>, See on <a href="https://news.ycombinator.com/item?id=41091803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en" data-v-2fa8b348="" id="sec0" data-v-43a4d572=""><h2>Abstract</h2>  <div><p>Danziger, Levav and Avnaim-Pesso (2011) analyzed legal rulings of Israeli parole boards concerning the effect of serial order in which cases are presented within ruling sessions. They found that the probability of a favorable decision drops from about 65% to almost 0% from the first ruling to the last ruling within each session and that the rate of favorable rulings returns to 65% in a session following a food break. The authors argue that these findings provide support for extraneous factors influencing judicial decisions and cautiously speculate that the effect might be driven by mental depletion. A simulation shows that the observed influence of order can be alternatively explained by a statistical artifact resulting from favorable rulings taking longer than unfavorable ones. An effect of similar magnitude would be produced by a (hypothetical) rational judge who plans ahead minimally and ends a session instead of starting cases that he or she assumes will take longer directly before the break. One methodological detail further increased the magnitude of the artifact and generates it even without assuming any foresight concerning the upcoming case. Implications for this article are discussed and the increased application of simulations to identify nonobvious rational explanations is recommended.</p></div> </div><div id="content-container" data-v-43a4d572=""><div>
<div>
<div data-magellan-destination="s1" id="s1">
<h2><span>1</span> Introduction</h2>
<p> In decisions in various contexts, individuals do not strictly adhere to standards of rationality, in that judgments and choices are influenced by many irrelevant factors such as changes in presentation format (e.g., <a href="#rf17"><span>Reference Kahneman and Tversky</span>Kahneman &amp; Tversky, 1984</a>), the presence of random anchors (e.g., <a href="#rf27"><span>Reference Tversky and Kahneman</span>Tversky &amp; Kahneman, 1974</a>), and many more. It is, however, of course socially desirable for the outcomes of legal cases to depend solely on laws and relevant facts and for influences of extraneous factors to be minimal. Decisions should, for instance, not be influenced by the order in which cases are presented or by whether the judge is exhausted or hungry.</p>
<p> Still, it has been demonstrated that judges show the same fallacies and biases as other individuals do (e.g., <a href="#rf6"><span>Reference Englich, Mussweiler and Strack</span>Englich, Mussweiler &amp; Strack, 2006</a>; <a href="#rf10"><span>Reference Guthrie, Rachlinski and Wistrich</span>Guthrie, Rachlinski &amp; Wistrich, 2000</a>, 2007). In psychology, the prevailing descriptive models consequently take into account that legal decision making does not follow a purely rational calculation, but involves some constructive and intuitive element, making it potentially malleable to irrelevant factors (e.g., <a href="#rf21"><span>Reference Pennington and Hastie</span>Pennington &amp; Hastie, 1992</a>; <a href="#rf25"><span>Reference Simon</span>Simon, 2004</a>; <a href="#rf26"><span>Reference Thagard</span>Thagard, 2006</a>).</p>
<p> Similarly, in the legal literature the traditional view that legal judgments can be mechanically or logically derived from official legal materials — such as statutes and reported court cases — in the vast majority of instances has been challenged by legal realism (e.g., Frank, 1930) maintaining that “legal doctrine […] is more malleable, less determinate, and less causal of judicial outcomes than the traditional view of law’s constraints supposes” (<a href="#rf24"><span>Reference Schauer</span>Schauer, 2013</a>). Legal realism holds that — aside from official legal materials — extraneous factors influence legal rulings such as ideology or policy preferences of the judge, general judgment biases, and — similar to current approaches in psychology — it has been argued that rulings are partially guided by intuition (Hutcheson, 1929; see Schauer, 2013, for a review). Legal realism has a long history and many facets but it is often caricaturized by the phrase that “justice is what the judge ate for breakfast”, which also has become a trope for legal realism in general.</p>
<p> In summary, there is clear evidence that judicial decision making is influenced to some degree by extraneous factors, which is also reflected in prevailing theories in law and psychology. Danziger, Levav and Avnaim-Pesso (2011a) (hereafter DLA) aim to add to this body of evidence by demonstrating that deciding multiple cases in a row influences legal outcomes of later cases. DLA analyzed 1,112 legal rulings of Israeli parole boards that cover about 40% of the parole requests of the country. They assessed the effect of the serial order in which cases are presented within a ruling session and took advantage of the fact that the ruling boards work on the cases in three sessions per day, separated by a late morning snack and a lunch break.</p>
<p> DLA found that the probability of a favorable decision drops from about 65% in the first ruling to almost 0% in the last ruling within each session (<a href="#fig1">Figure 1</a>). The rate of favorable rulings returns to 65% in the session following the break. DLA argue that this effect of ordering shows that judges are influenced by extraneous factors and they speculate that the effect is caused by mental depletion (<a href="#rf19"><span>Reference Muraven and Baumeister</span>Muraven &amp; Baumeister, 2000</a>). The argument is that, after repeated decisions, judges become exhausted, hungry or mentally depleted and use the simple and less effortful strategy to stick with the status quo by rejecting the request resulting in what could be called an “irrational hungry judge effect”.</p>
<div data-magellan-destination="fig1" id="fig1">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig1.png?pub-status=live" width="328" height="380" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig1.png" data-zoomable="false" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig1.png"></p>
<div><p><span>Figure 1:</span> Results redrawn from the graph provided in Danziger et al. (2011a).</p></div></div>
<p> Considering the tremendous consequences for human beings, the large magnitude of the effect, and the fact that the investigated boards decide almost half of the parole requests in Israel, these results are unexpected and potentially alarming. Consequently the article has attracted attention and the supposed order effect is considerably cited in psychology (e.g., <a href="#rf7"><span>Reference Evans, Dillon, Goldin and Krueger</span>Evans, Dillon, Goldin &amp; Krueger, 2011</a>), law (e.g., Schauer, 2013), economics (e.g., Kamenica, 2012), and beyond (e.g., Gibb, 2012; <a href="#rf29"><span>Reference Yamada, Camerer, Fujie, Kato, Matsuda, Takano and Takahashi</span>Yamada et al., 2012</a>).<a href="#fn1"><span>Footnote </span><sup>1</sup></a> The fact that — in line with the trope for legal realism mentioned above — eating (or not) is considered important for legal rulings according to DLA might have additionally contributed to the tendency to cite it heavily.</p>
</div>
<div data-magellan-destination="s2" id="s2">
<h2><span>2</span> Critical Evaluation</h2>
<p> One further factor that most likely contributed to the popularity of the article is the large magnitude of the effect. A drop of favorable decisions from 65% in the first trial to 5% in the last trial as observed in DLA is equivalent to an odds ratio of 35 or a standardized mean difference of <em>d</em> = 1.96 (<a href="#rf3"><span>Reference Chinn</span>Chinn, 2000</a>). This is more than twice the size of the conventional limit for large effects. The meta-analytic estimate for effect of mental depletion, which is considered as potential explanation for the drop, is <em>d</em> = –0.10 to 0.25 (publication-bias corrected), meaning that on average only small effects of mental depletion can be expected (<a href="#rf1"><span>Reference Carter and McCullough</span>Carter &amp; McCullough, 2013</a>).<a href="#fn2"><span>Footnote </span><sup>2</sup></a> Similarly, a recent multi-lab registered replication study involving 23 labs (N= 2,142) found an effect of d = 0.04 and not significantly different from zero (<a href="#rf12"><span>Reference Hagger and Chatzisarantis</span>Hagger &amp; Chatzisarantis, 2016</a>). Hence, under the assumption that mental depletion is causing the findings, the magnitude of the effect observed by DLA is surprisingly large. It might, however, be argued that manipulations of depletion and exhaustion might be stronger in reality than in the lab causing stronger effects.</p>
<p> Considering the latter issue and taking into account that the potential costs for giving wrong advice are high, it seems justified to take a closer look at the results and the analyses on which they are based.</p>
<div data-magellan-destination="s3" id="s3">
<h3><span>2.1</span> Non-random Order of Cases</h3>
<p> One crucial assumption permitting conclusions concerning the effect of case ordering is that case ordering is random or at least not driven by hidden factors that are not taken into account in the analysis. If more severe cases went first, for example, and severe cases at the same time reduced the likelihood of favorable decisions, spurious correlations could result. In their regression analyses, DLA take this concern into account by including reasonable control variables for substantive factors that might influence both ordering and rulings. They show that the results remain robust when controlling statistically for severity of offence, previous imprisonment, months served, participation in a rehabilitation program, and proportion of previous favorable decisions.</p>
<p> Still in a direct reply to DLA, it has been argued that case order is influenced by systematic factors that DLA did not account for (<a href="#rf28"><span>Reference Weinshall-Margel and Shapard</span>Weinshall-Margel &amp; Shapard, 2011</a>). Specifically, Weinshall-Margel and Shapard (2011) conducted informal interviews with persons involved in the parole decision process (including a panel judge) and came to the conclusion that case ordering is not random. They argue, among other things, that the downward trend might be due to the fact that, within each session, unrepresented prisoners usually go last and are less likely to be granted parole than prisoners who are represented by attorneys. In a response, Danziger, Levav and Avnaim-Pesso (2011b) show that the downward trend also holds when controlling for representation by an attorney although they do not report whether the magnitude of the effect remains the same, which seems unlikely given the correlation pattern reported above. Note also the more general methodological problem that statistical control need not remove the full effect of a variable measured in rough categories (e.g., severity of offence) or with error.</p>
</div>
<div data-magellan-destination="s4" id="s4">
<h3><span>2.2</span> Decision to Take a Break</h3>
<p> A second, potentially more subtle, concern is that results might be driven by factors that systematically influence judges’ decisions to take a break. DLA analyze whether properties of a case influence the likelihood of taking a break afterwards. They report that the substantive case properties mentioned above do not predict when a break is taken. Furthermore, they argue that judges do not know details of the upcoming case such as whether the prisoner has a previous incarceration record or not. Interestingly, Weinshall-Margel and Shapard still report their interviewees to state that judges might aim to finish a set of cases (e.g., to complete all cases from one prison) within a session. This indicates that some organizational planning occurs. At first glance, however, it seems hard to understand how this mere organizational planning of when to end a session without taking into account any details of the case could contribute to the downward trend. I will discuss this issue in detail in the next section.</p>
<p> In summary, in their reply DLA (2011b) argue that they could rule out all alternative explanations and therefore uphold their conclusion that parole decisions are influenced by legally irrelevant factors in that repeated choice is causing a decreasing likelihood for making favorable decision as the session progresses.</p>
</div>
</div>
<div data-magellan-destination="s5" id="s5">
<h2><span>3</span> Rational Time Management and Selective Dropouts</h2>
<p> If we accept that the effect of ordinal position also holds after all reasonable substantive factors that might have influenced ordering and decisions to take a break are ruled out, we must still ask whether more subtle factors could explain the observed effects, without assuming that judgments are influenced to a large degree by irrelevant factors. One major concern is the effects of selective dropouts and rational time management when to end a session in order to complete cases or sets of cases within it. Selective dropout in this context refers to the possibility that — for whatever reason — cases with favorable rulings have a lower likelihood to be in the sample of cases with higher ordinal number in a session than cases with unfavorable rulings.</p>
<p> DLA report that favorable rulings take longer (<em>M</em> = 7.37 min, <em>SD</em> = 5.11) than unfavorable rulings (<em>M</em> = 5.21 min, <em>SD</em> = 4.97). The number of cases completed in each session varies between 2 and 28<a href="#fn3"><span>Footnote </span><sup>3</sup></a> and DLA present rulings for 10 to 13 cases within each session, with the last ruling having a probability of zero (or in one case close to zero) to be favorable, respectively. Consequently, the number of observations within each session decreases with ordinal position and the last observations in a session are likely to consist of a few observations only. Considering that favorable rulings take longer than unfavorable rulings, the dropout is not random. On average, sessions that consist of mainly unfavorable decisions will allow judges to make many rulings. Therefore, in the reduced sample of observations constituting the data for higher ordinal positions, the relative frequency of rulings from sessions with mainly unfavorable decisions increases.<a href="#fn4"><span>Footnote </span><sup>4</sup></a></p>
<p> Judges have to finish cases before they take a break. To avoid starving, they are likely to avoid starting potentially complex cases (or sets of cases) directly before the break. It seems reasonable to assume that simple surface features that are available before investigating the case in detail (e.g., amount of material, kind of the request, representation by an attorney, some specifics of the attorney, the prison, or the prisoner) allow judges roughly to estimate the time the next case will take above chance level. Importantly, such surface features could also be unrelated to the content features that could produce non-random ordering of cases and that DLA already control for in their analysis.</p>
<p> Still, as mentioned above, it is hard to see whether and to what degree not starting overly long cases before a break would lead to the observation of downward sloping effects without assuming that judgments are influenced by extraneous factors at all. I conducted simulations to make the effect visible.</p>
</div>
<div data-magellan-destination="s6" id="s6">
<h2><span>4</span> Simulating Choice Patterns by a (hypothetical) Rational Judge</h2>
<p> I simulated the rulings of an ideal judge who makes choices without errors and biases. I assume that she has a rough time limit for each session and works on cases until recognizing that a case would go over this limit. The case that would be too long would not be solved any more in the current session, but it would be the first case in the next session.<a href="#fn5"><span>Footnote </span><sup>5</sup></a></p>
<p> The results indicate that, following the approach by DLA, a rational judge working on cases that are presented in random order would show a strongly decreasing probability of a favorable decision towards the end of the session. Even the shape of the curve and the magnitude of the effect are comparable to that observed by DLA. Simulations assuming normally distributed decision times (<a href="#fig2">Figure 2</a>, right) or more realistic positively-skewed decision times that follow a Weibull distribution (<a href="#fig2">Figure 2</a>, left) lead to similar conclusions, and repeated simulations show that the qualitative pattern of results is robust to changes in distributional assumptions. As one could expect, however, estimations become unstable for higher decision numbers due to the low number of remaining observations (see <a href="#fig2">Figure 2</a>, size of circles), resulting in occasional peaks to high or zero percentages. Not surprisingly, statistical analysis reveals that the downward trend is significant and that first decisions are more favorable than later ones, as it was found by DLA.</p>
<div data-magellan-destination="fig2" id="fig2">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig2.png?pub-status=live" width="700" height="501" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig2.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig2.png"></p>
<div><p><span>Figure 2:</span> Simulated favorability ratings of a perfectly rational judge who works on cases with the speed observed by DLA and starts a new session for each case that would go over the time limit. The left chart depicts a distribution assuming that decision times follow a Weibull distribution, while the right chart shows results assuming a normal distribution. Circle diameter indicates the sample size for each observation and shows the large degree of dropouts within sessions.</p></div></div>
<p> <a href="#fig3">Figure 3</a> shows why this effect appears for the normally distributed case. Distributions of decision time have different means with favorable cases taking longer than unfavorable ones (left panel). Consequently, the relative frequency of favorable cases (in all cases) that would still fit in the session decreases with remaining time. In our example, if 15 minutes remain in the session, essentially all cases would still be started since such long times are rare both for favorable and unfavorable cases (<a href="#fig3">Figure 3</a>, left). The ratio of favorable and unfavorable cases therefore roughly reflects the overall ratio in the population. For 5 minutes remaining, however, only 12% of the favorable cases could still be included in the session, whereas the respective proportion for unfavorable cases is much higher at 46%. Hence, the relative frequency of favorable cases, as compared to all cases, decreases with the time that remains causing selective dropout.</p>
<div data-magellan-destination="fig3" id="fig3">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig3.png?pub-status=live" width="700" height="383" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig3.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig3.png"></p>
<div><p><span>Figure 3:</span> Distribution of decision times (left) and effect of the remaining time on the proportion of favorable cases in the remaining selective sample (right).</p></div></div>
<p> The cumulative probability distribution for favorable decisions (taking into account differences in base rates for both events) is plotted in the right panel of <a href="#fig3">Figure 3</a>. For long remaining times, the proportion of favorable cases is close to the base rate of 36%. For short remaining times, the proportion approaches values close to zero. With an increasing decision number within a session, the remaining time decreases, causing the downward sloping effect. Since sessions can stop after 1 to 14 decisions, the stopping effect is not only found after case 14, but already to a smaller degree for earlier cases. Hence, the probability can be expected to drop from 36% to zero percent for later rulings.</p>
<p> It remains to be explained why the proportion of favorable rulings (in both the simulation and the DLA data) peaks beyond 36% in the first round. This “beginning effect” is indirectly caused by the above mechanism as well, since the session is more likely to end before a favorable ruling than before an unfavorable ruling. The probability mass that is missing in the last decision of the previous session adds to the probability mass of favorable cases in the first decision of the next session (either on the same day or the first session of the next day). If one assumes that planning is not only done for single cases, but also occasionally concerns sets of cases (<a href="#rf28"><span>Reference Weinshall-Margel and Shapard</span>Weinshall-Margel &amp; Shapard, 2011</a>), this would explain why the probability of a favorable decision in the second and third ruling in a session is also above the base rate of 36%.<a href="#fn6"><span>Footnote </span><sup>6</sup></a> Furthermore, the observation by DLA that the overall length of sessions varies considerably does not speak against the planning explanation since the effect also holds under the assumption that judges have implicit time limits that vary from session to session. Also, it should be noted that the planning described here is merely organizational and does not require any foresight concerning how the case will be decided. All it requires is that the judges have a rough estimate, whether the next case will be quick or take longer.</p>
</div>
<div data-magellan-destination="s7" id="s7">
<h2><span>5</span> Further Factors: Autocorrelation and Censoring</h2>
<p> After demonstrating that rational time management and selective dropout can cause dramatic drops in favorability ratings, the robustness of this finding and the influence of further factors should be investigated. Two factors are considered. First, DLA report that they censor their data, in that the last 5% of the cases in each session are dropped, with the intention of eliminating small samples at higher ordinal positions. Second, as mentioned above (Footnote 4) results from DLA indicate that there is an autocorrelation in the time-series, in that rulings correlate with previous ones. Since the consequences of these factors are again hard to anticipate, I conducted further analyses to explore their effects.</p>
<p> To investigate the effect of censoring, I dropped the last 5% of the rulings within each session in the normal distribution data-set from above (<a href="#fig2">Figure 2</a>, right) and analyzed the data again. Results remained largely the same, but censoring increased the magnitude of the drop (<a href="#fig4">Figure 4</a>, left), which was also observed for the Weibull data set and was consistently replicated in further simulations. Hence, censoring artificially increases selective dropout, and therefore it should not be used when analyzing the effect of ordinal position on favorability rulings.</p>
<div data-magellan-destination="fig4" id="fig4">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig4.png?pub-status=live" width="681" height="484" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig4.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig4.png"></p>
<div><p><span>Figure 4:</span> Simulated favorability ratings including the effects of censoring the last 5% of cases within each session (left) and additional autocorrelation (right). Circle diameter represents <em>n</em>.</p></div></div>
<p> To investigate the effect of autocorrelation, I generated new data sets (<em>N</em> = 50,000) based on normally distributed response times with the same parameters as above in which, however, rulings correlated with rulings directly before at a low degrees. <a href="#fig4">Figure 4</a> (right) shows results from a data set with a (first-order) autocorrelation of <em>r</em> = .10 and including censoring as above. Results are generally comparable to the results from the independent data-set, and autocorrelation did not noticeably change the magnitude of the artifact.</p>
</div>
<div data-magellan-destination="s8" id="s8">
<h2><span>6</span> Rational Time Management without Foresight</h2>
<p> One assumption underlying the simulations reported so far is that judges plan ahead and do not start a case that would be too long to finish within the time limit for a session. This planning would require some degree of foresight in that judges (or other people administratively involved) generate estimates of the time required for finishing the upcoming case. Thereby estimates do not need to be exact to generate the artifact and can be based on rough surface cues as mentioned above as well. Also cues for time management might be (consciously or unconsciously) conveyed by administrative persons involved in the process of handling cases (<a href="#rf22"><span>Reference Pfungst</span>Pfungst, 1911</a>). As mentioned above, DLA state that details about the upcoming case are not known to the members of the board in advance. Since, however, DLA did not have full control over the situations, the existence of such cues cannot be entirely ruled out.</p>
<p> Still, presuming foresight in many cases is admittedly a relatively strong assumption. I therefore tested whether the analysis conducted by DLA would also generate similar artifacts without foresight in that judges stop <em>after</em> a case went over the available time limit.<a href="#fn7"><span>Footnote </span><sup>7</sup></a> When conducting this analysis without censoring and autocorrelation, all artifacts disappear, as one would expect. Interestingly, however, when including censoring and autocorrelation a downward sloping effect appears again (<a href="#fig5">Figure 5</a>). The reason for this is that cases with favorable rulings are more likely to hit the time limit than cases with unfavorable ruling due to the mere fact that they are longer. Dropping 5% of the cases at the end means often postponing this last case, which is more likely favorable than unfavorable. Hence, censoring causes selective dropout of favorable cases even without foresight and artificially induces a downward sloping effect of favorable ruling. The effect was, however, smaller than in the simulations with foresight and caused a drop of roughly 15% only.</p>
<div data-magellan-destination="fig5" id="fig5">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig5.png?pub-status=live" width="326" height="438" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig5.png" data-zoomable="false" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_fig5.png"></p>
<div><p><span>Figure 5:</span> Simulated favorability ratings without foresight concerning the upcoming case but including the effects of censoring the last 5% of cases within each session and autocorrelation <em>r</em> = .10 (<em>N</em> = 50,000). Circle diameter represents <em>n</em>.</p></div></div>
</div>
<div data-magellan-destination="s9" id="s9">
<h2><span>7</span> Discussion</h2>
<p> In a comprehensive analysis of legal rulings of Israeli parole boards DLA identified that the proportion of favorable rulings decreases with serial order within a session but goes back to the initial level after a session break that includes eating a meal. This finding is important as well as potentially alarming, since both serial order and food supply are clearly extraneous factors that should not affect whether a parole request is decided favorable or not. DLA argue that their findings indicate that extraneous variables influence judicial decisions and cautiously interpret their finding with reference to a mental depletion account.</p>
<p> I critically revisited this interpretation and tested whether the core of the conclusion — namely that order and mental depletion causally influence the outcome of legal judgments — can be made on the basis of the presented data. Specifically, I tested whether the observed downward trend could also results from selective dropout of favorable cases due to rational time management, censoring of data and autocorrelation. The analysis shows that large parts — but admittedly not all aspects, see below — of the findings could be accounted for by this explanation.</p>
<p> The simulations show that the seemingly dramatic drop of favorable rulings from 65% to almost 0% towards the end of each session does not conclusively indicate bias or error in judicial decision making. A drop of comparable — although somewhat smaller — magnitude would be produced by a (hypothetical) rational judge who aims to avoid starting work on cases that could not be completed in the time that remains in the current session. Furthermore, the simulations revealed that the practice of censoring data within a session is problematic and artificially induces a downward sloping effect even without foresight and under the less restrictive assumption that judges stop each session after a time limit has been passed. Hence, the analyses by DLA do not provide conclusive evidence for the hypothesis that extraneous factors influence legal rulings.</p>
<div data-magellan-destination="s10" id="s10">
<h3><span>7.1</span> Caveats</h3>
<p> It has to be acknowledged that the analyses reported in this paper do not preclude that serial order and mental depletion might have affected the legal judgments analyzed by DLA. The analysis, however, demonstrates that there is a possible alternative explanation for large parts of the results within a rational framework that does not require the assumption of any influence of extraneous factors. The strong downward-sloping effect could — at least in parts — simply reflect a statistical artifacts.</p>
<p> Still, rational time management and selective dropout cannot account for all aspects of the data by DLA. First, the magnitude of the effects reported in the simulations was somewhat smaller than the magnitude of the original effects.<a href="#fn8"><span>Footnote </span><sup>8</sup></a> This was mainly due to the fact that, second, in the original data the percentage of favorable rulings started at a higher level than in the current simulations (i.e. 65% instead of 45%). Particularly, the high starting rates at the beginning of the day (and not only after the breaks) are hard to explain by my account since postponing cases to a different day and panel seems not overly likely.<a href="#fn9"><span>Footnote </span><sup>9</sup></a> Third, since the statistical effects described here are driven by ordinal position, they cannot easily explain the effects of time on favorable rulings reported in DLA as well. Fourth, the shape of the curves differ in some details in that the empirical curve tended to be smoother whereas the simulated data showed stronger drops at the beginning and the end a flatter area in between. Finally, given that according to DLA the setting might have precluded direct foresight concerning the upcoming case to some degree, the remaining effects of rational time management could be estimated to account for a drop of 15% to 45% only.</p>
<p> In sum, rational time management and selective dropout — although potentially being important — can explain the findings by DLA only in parts. Hence, further factors may exist that contributed to the observed downward-sloping effect. The remaining differences could potentially be explained by other methodological factors such as the issue of non-random ordering in that prisoners represented by attorneys went first (<a href="#rf28"><span>Reference Weinshall-Margel and Shapard</span>Weinshall-Margel &amp; Shapard, 2011</a>). Alternatively, extraneous factors such as causal effects of serial case ordering and mental depletion might have played a role. Since the data are not available<a href="#fn10"><span>Footnote </span><sup>10</sup></a> for further detailed analyses and the exact circumstances under which the rulings were made cannot be fully reconstructed, these issues have to be addressed in further studies.</p>
<p> The analyses reported here indicates that the effect of serial order and mental depletion is overestimated in the original work by DLA. Rational time management concerning when to take a break and effects of non-random ordering of cases with represented prisoners going first identified by Weinshall-Margel and Shapard (2011) are lumped together with potential effects of serial order and mental depletion so that the latter are overestimated. Disentangling these influences should lead to more reasonable (smaller) estimates concerning the magnitude of the effect. According to previous findings on mental depletion, the “irrational hungry judge effect” should at best be small in magnitude (if existing at all; see <a href="#rf1"><span>Reference Carter and McCullough</span>Carter &amp; McCullough, 2013</a>), which might render the observed extraneous influence less relevant from a practical point of view and the need for state interventions less urgent.</p>
<p> More generally, the analysis shows that sometimes there is a nonobvious rational basis for irrational-looking behavior. Computer simulations as well as formal mathematical analyses are measures to identify them. Such analyses have revealed, for example, that whole strands of literature supposedly demonstrating irrational behavior such as spreading apart effects after choice (<a href="#rf2"><span>Reference Chen and Risen</span>Chen &amp; Risen, 2010</a>), unrealistic optimism (<a href="#rf14"><span>Reference Harris and Hahn</span>Harris &amp; Hahn, 2011</a>) or the adaptive usage of simple heuristics (Jekel &amp; Glöckner, in press) are methodological or statistical artifacts that would be shown by completely rational agents as well. I argue that simulations of rational agents and formal mathematical analyses should be used earlier and more intensely in the research process to investigate findings of supposedly hugely irrational behavior before jumping to the conclusion that legal actors — or any other individuals — are irrational.</p>
</div>
</div>
</div>
<div data-magellan-destination="app1" id="app1">
<h2><span>Appendix:</span> STATA code for the simulation program for normal distributed response times</h2>
<div data-magellan-destination="figa1" id="figa1">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_figa1.png?pub-status=live" width="783" height="870" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_figa1.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20240509060830882-0276:S1930297500004812:S1930297500004812_figa1.png"></p>
</div>
</div>
</div>    <div id="references-list"><h2>References</h2> <div id="rf2" aria-flowto="reference-2-content reference-2-button"><p><span><span>Chen</span>, <span>M. K.</span></span>, &amp; <span><span>Risen</span>, <span>J. L.</span></span> (<span>2010</span>). <span>How choice affects and reflects preferences: revisiting the free-choice paradigm.</span> <span>Journal of Personality and Social Psychology</span>, <span>99</span>(4), <span>573</span>–<span>594</span>.<a target="_blank" aria-label="CrossRef link for How choice affects and reflects preferences: revisiting the free-choice paradigm." href="https://dx.doi.org/10.1037/a0020217">CrossRef</a><a target="_blank" aria-label="Google Scholar link for How choice affects and reflects preferences: revisiting the free-choice paradigm." href="https://scholar.google.com/scholar_lookup?title=How+choice+affects+and+reflects+preferences%3A+revisiting+the+free-choice+paradigm.&amp;author=Chen+M.+K.&amp;author=Risen+J.+L.&amp;publication+year=2010&amp;journal=Journal+of+Personality+and+Social+Psychology&amp;volume=99&amp;doi=10.1037%2Fa0020217&amp;pages=573-594">Google Scholar</a><a target="_blank" aria-label="PubMed link for How choice affects and reflects preferences: revisiting the free-choice paradigm." href="https://www.ncbi.nlm.nih.gov/pubmed/20658837">PubMed</a></p></div><div id="rf5" aria-flowto="reference-5-content reference-5-button"><p><span><span>Danziger</span>, <span>S.</span></span>, <span><span>Levav</span>, <span>J.</span></span>, &amp; <span><span>Avnaim-Pesso</span>, <span>L.</span></span> (<span>2011b</span>). <span>Reply to Weinshall-Margel and Shapard: Extraneous factors in judicial decisions persist.</span> <span>Proceedings of the National Academy of Sciences of the United States of America</span>, <span>108</span>(42), <span>E834</span>-<span>E834</span>. <a href="https://dx.doi.org/10.1073/pnas.1112190108">http://dx.doi.org/10.1073/pnas.1112190108</a>.<a target="_blank" aria-label="Google Scholar link for Reply to Weinshall-Margel and Shapard: Extraneous factors in judicial decisions persist." href="https://scholar.google.com/scholar_lookup?title=Reply+to+Weinshall-Margel+and+Shapard%3A+Extraneous+factors+in+judicial+decisions+persist.&amp;author=Danziger+S.&amp;author=Levav+J.&amp;author=Avnaim-Pesso+L.&amp;publication+year=2011b&amp;journal=Proceedings+of+the+National+Academy+of+Sciences+of+the+United+States+of+America&amp;volume=108&amp;pages=E834-E834">Google Scholar</a></p></div><div id="rf6" aria-flowto="reference-6-content reference-6-button"><p><span><span>Englich</span>, <span>B.</span></span>, <span><span>Mussweiler</span>, <span>T.</span></span>, &amp; <span><span>Strack</span>, <span>F.</span></span> (<span>2006</span>). <span>Playing dice with criminal sentences: The influence of irrelevant anchors on experts judicial decision making.</span> <span>Personality and Social Psychology Bulletin</span>, <span>32</span>(2), <span>188</span>–<span>200</span>.<a target="_blank" aria-label="CrossRef link for Playing dice with criminal sentences: The influence of irrelevant anchors on experts judicial decision making." href="https://dx.doi.org/10.1177/0146167205282152">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Playing dice with criminal sentences: The influence of irrelevant anchors on experts judicial decision making." href="https://scholar.google.com/scholar_lookup?title=Playing+dice+with+criminal+sentences%3A+The+influence+of+irrelevant+anchors+on+experts+judicial+decision+making.&amp;author=Englich+B.&amp;author=Mussweiler+T.&amp;author=Strack+F.&amp;publication+year=2006&amp;journal=Personality+and+Social+Psychology+Bulletin&amp;volume=32&amp;doi=10.1177%2F0146167205282152&amp;pages=188-200">Google Scholar</a><a target="_blank" aria-label="PubMed link for Playing dice with criminal sentences: The influence of irrelevant anchors on experts judicial decision making." href="https://www.ncbi.nlm.nih.gov/pubmed/16382081">PubMed</a></p></div><div id="rf7" aria-flowto="reference-7-content reference-7-button"><p><span><span>Evans</span>, <span>A. M.</span></span>, <span><span>Dillon</span>, <span>K. D.</span></span>, <span><span>Goldin</span>, <span>G.</span></span>, &amp; <span><span>Krueger</span>, <span>J. I.</span></span> (<span>2011</span>). <span>Trust and self-control: The moderating role of the default.</span> <span>Judgment and Decision Making</span>, <span>6</span>(7), <span>697</span>–<span>705</span>.<a target="_blank" aria-label="CrossRef link for Trust and self-control: The moderating role of the default." href="https://dx.doi.org/10.1017/S1930297500002709">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Trust and self-control: The moderating role of the default." href="https://scholar.google.com/scholar_lookup?title=Trust+and+self-control%3A+The+moderating+role+of+the+default.&amp;author=Evans+A.+M.&amp;author=Dillon+K.+D.&amp;author=Goldin+G.&amp;author=Krueger+J.+I.&amp;publication+year=2011&amp;journal=Judgment+and+Decision+Making&amp;volume=6&amp;doi=10.1017%2FS1930297500002709&amp;pages=697-705">Google Scholar</a></p></div><div id="rf8" aria-flowto="reference-8-content reference-8-button"><p><span><span>Frank</span>, <span>J.</span></span> (<span>1930</span>). <span>Law and the modern mind.</span> <span>New York</span>: <span>Brentano’s</span>.<a target="_blank" aria-label="Google Scholar link for Law and the modern mind." href="https://scholar.google.com/scholar_lookup?title=Law+and+the+modern+mind.&amp;author=Frank+J.&amp;publication+year=1930">Google Scholar</a></p></div><div id="rf10" aria-flowto="reference-10-content reference-10-button"><p><span><span>Guthrie</span>, <span>C.</span></span>, <span><span>Rachlinski</span>, <span>J. J.</span></span>, &amp; <span><span>Wistrich</span>, <span>A. J.</span></span> (<span>2000</span>). <span>Inside the judicial mind.</span> <span>Cornell Law Review,</span> <span>86</span>, <span>777</span>–<span>830</span>.<a target="_blank" aria-label="Google Scholar link for Inside the judicial mind." href="https://scholar.google.com/scholar_lookup?title=Inside+the+judicial+mind.&amp;author=Guthrie+C.&amp;author=Rachlinski+J.+J.&amp;author=Wistrich+A.+J.&amp;publication+year=2000&amp;journal=Cornell+Law+Review%2C&amp;volume=86&amp;pages=777-830">Google Scholar</a></p></div><div id="rf11" aria-flowto="reference-11-content reference-11-button"><p><span><span>Guthrie</span>, <span>C.</span></span>, <span><span>Rachlinski</span>, <span>J. J.</span></span>, &amp; <span><span>Wistrich</span>, <span>A. J.</span></span> (<span>2007</span>). <span>Blinking on the bench: How judges decide cases.</span> <span>Cornell Law Review</span>, <span>93</span>(1), <span>1</span>–<span>44</span>.<a target="_blank" aria-label="Google Scholar link for Blinking on the bench: How judges decide cases." href="https://scholar.google.com/scholar_lookup?title=Blinking+on+the+bench%3A+How+judges+decide+cases.&amp;author=Guthrie+C.&amp;author=Rachlinski+J.+J.&amp;author=Wistrich+A.+J.&amp;publication+year=2007&amp;journal=Cornell+Law+Review&amp;volume=93&amp;pages=1-44">Google Scholar</a></p></div><div id="rf13" aria-flowto="reference-13-content reference-13-button"><p><span><span>Hagger</span>, <span>M. S.</span></span>, <span><span>Wood</span>, <span>C.</span></span>, <span><span>Stiff</span>, <span>C.</span></span>, &amp; <span><span>Chatzisarantis</span>, <span>N. L.</span></span> (<span>2010</span>). <span>Ego depletion and the strength model of self-control: a meta-analysis.</span> <span>Psychological Bulletin</span>, <span>136</span>(4), <span>495</span>–<span>525</span>.<a target="_blank" aria-label="CrossRef link for Ego depletion and the strength model of self-control: a meta-analysis." href="https://dx.doi.org/10.1037/a0019486">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Ego depletion and the strength model of self-control: a meta-analysis." href="https://scholar.google.com/scholar_lookup?title=Ego+depletion+and+the+strength+model+of+self-control%3A+a+meta-analysis.&amp;author=Hagger+M.+S.&amp;author=Wood+C.&amp;author=Stiff+C.&amp;author=Chatzisarantis+N.+L.&amp;publication+year=2010&amp;journal=Psychological+Bulletin&amp;volume=136&amp;doi=10.1037%2Fa0019486&amp;pages=495-525">Google Scholar</a><a target="_blank" aria-label="PubMed link for Ego depletion and the strength model of self-control: a meta-analysis." href="https://www.ncbi.nlm.nih.gov/pubmed/20565167">PubMed</a></p></div><div id="rf14" aria-flowto="reference-14-content reference-14-button"><p><span><span>Harris</span>, <span>A. J.</span></span>, &amp; <span><span>Hahn</span>, <span>U.</span></span> (<span>2011</span>). <span>Unrealistic optimism about future life events: a cautionary note.</span> <span>Psychological Review</span>, <span>118</span>(1), <span>135</span>–<span>154</span>.<a target="_blank" aria-label="CrossRef link for Unrealistic optimism about future life events: a cautionary note." href="https://dx.doi.org/10.1037/a0020997">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Unrealistic optimism about future life events: a cautionary note." href="https://scholar.google.com/scholar_lookup?title=Unrealistic+optimism+about+future+life+events%3A+a+cautionary+note.&amp;author=Harris+A.+J.&amp;author=Hahn+U.&amp;publication+year=2011&amp;journal=Psychological+Review&amp;volume=118&amp;doi=10.1037%2Fa0020997&amp;pages=135-154">Google Scholar</a><a target="_blank" aria-label="PubMed link for Unrealistic optimism about future life events: a cautionary note." href="https://www.ncbi.nlm.nih.gov/pubmed/21058872">PubMed</a></p></div><div id="rf15" aria-flowto="reference-15-content reference-15-button"><p><span><span>Hutcheson</span>, <span>J. C.</span></span> (<span>1929</span>). <span>The judgment intuitive: the function of the “hunch” in judicial decision making.</span> <span>Cornell Law Quarterly,</span> <span>14</span>, <span>274</span>–<span>288</span>.<a target="_blank" aria-label="Google Scholar link for The judgment intuitive: the function of the “hunch” in judicial decision making." href="https://scholar.google.com/scholar_lookup?title=The+judgment+intuitive%3A+the+function+of+the+%E2%80%9Chunch%E2%80%9D+in+judicial+decision+making.&amp;author=Hutcheson+J.+C.&amp;publication+year=1929&amp;journal=Cornell+Law+Quarterly%2C&amp;volume=14&amp;pages=274-288">Google Scholar</a></p></div><div id="rf16" aria-flowto="reference-16-content reference-16-button"><p><span><span>Jekel</span>, <span>M.</span></span>, &amp; <span><span>Glöckner</span>, <span>A.</span></span> <span>(in press). How to identify strategy use and adaptive strategy selection: the crucial role of chance correction in Weighted Compensatory Strategies.</span> <span>Journal of Behavioral Decision Making.</span><a target="_blank" aria-label="Google Scholar link for (in press). How to identify strategy use and adaptive strategy selection: the crucial role of chance correction in Weighted Compensatory Strategies." href="https://scholar.google.com/scholar?q=Jekel,+M.,+&amp;+Gl%C3%B6ckner,+A.+(in+press).+How+to+identify+strategy+use+and+adaptive+strategy+selection:+the+crucial+role+of+chance+correction+in+Weighted+Compensatory+Strategies.+Journal+of+Behavioral+Decision+Making.">Google Scholar</a></p></div><div id="rf17" aria-flowto="reference-17-content reference-17-button"><p><span><span>Kahneman</span>, <span>D.</span></span>, &amp; <span><span>Tversky</span>, <span>A.</span></span> (<span>1984</span>). <span>Choices, values, and frames.</span> <span>American Psychologist</span>, <span>39</span>(4), <span>341</span>–<span>350</span>.<a target="_blank" aria-label="CrossRef link for Choices, values, and frames." href="https://dx.doi.org/10.1037/0003-066X.39.4.341">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Choices, values, and frames." href="https://scholar.google.com/scholar_lookup?title=Choices%2C+values%2C+and+frames.&amp;author=Kahneman+D.&amp;author=Tversky+A.&amp;publication+year=1984&amp;journal=American+Psychologist&amp;volume=39&amp;doi=10.1037%2F0003-066X.39.4.341&amp;pages=341-350">Google Scholar</a></p></div><div id="rf18" aria-flowto="reference-18-content reference-18-button"><p><span><span>Kamenica</span>, <span>E.</span></span> (<span>2012</span>). <span>Behavioral economics and psychology of incentives.</span> <span>Annual Review of Economics</span>, <span>4</span>(1), <span>427</span>–<span>452</span>.<a target="_blank" aria-label="CrossRef link for Behavioral economics and psychology of incentives." href="https://dx.doi.org/10.1146/annurev-economics-080511-110909">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Behavioral economics and psychology of incentives." href="https://scholar.google.com/scholar_lookup?title=Behavioral+economics+and+psychology+of+incentives.&amp;author=Kamenica+E.&amp;publication+year=2012&amp;journal=Annual+Review+of+Economics&amp;volume=4&amp;doi=10.1146%2Fannurev-economics-080511-110909&amp;pages=427-452">Google Scholar</a></p></div><div id="rf19" aria-flowto="reference-19-content reference-19-button"><p><span><span>Muraven</span>, <span>M.</span></span>, &amp; <span><span>Baumeister</span>, <span>R. F.</span></span> (<span>2000</span>). <span>Self-regulation and depletion of limited resources: Does self-control resemble a muscle?</span> <span>Psychological Bulletin</span>, <span>126</span>(2), <span>247</span>–<span>259</span>.<a target="_blank" aria-label="CrossRef link for Self-regulation and depletion of limited resources: Does self-control resemble a muscle?" href="https://dx.doi.org/10.1037/0033-2909.126.2.247">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Self-regulation and depletion of limited resources: Does self-control resemble a muscle?" href="https://scholar.google.com/scholar_lookup?title=Self-regulation+and+depletion+of+limited+resources%3A+Does+self-control+resemble+a+muscle%3F&amp;author=Muraven+M.&amp;author=Baumeister+R.+F.&amp;publication+year=2000&amp;journal=Psychological+Bulletin&amp;volume=126&amp;doi=10.1037%2F0033-2909.126.2.247&amp;pages=247-259">Google Scholar</a><a target="_blank" aria-label="PubMed link for Self-regulation and depletion of limited resources: Does self-control resemble a muscle?" href="https://www.ncbi.nlm.nih.gov/pubmed/10748642">PubMed</a></p></div><div id="rf20" aria-flowto="reference-20-content reference-20-button"><p><span><span>Open</span>, <span>Science Collaboration.</span></span> (<span>2015</span>). <span>Estimating the reproducibility of psychological science.</span> <span>Science</span>, <span>349</span>(6251), aac4716.<a target="_blank" aria-label="Google Scholar link for Estimating the reproducibility of psychological science." href="https://scholar.google.com/scholar_lookup?title=Estimating+the+reproducibility+of+psychological+science.&amp;author=Open+Science+Collaboration.&amp;publication+year=2015&amp;journal=Science&amp;volume=349">Google Scholar</a></p></div><div id="rf21" aria-flowto="reference-21-content reference-21-button"><p><span><span>Pennington</span>, <span>N.</span></span>, &amp; <span><span>Hastie</span>, <span>R.</span></span> (<span>1992</span>). <span>Explaining the evidence: Tests of the Story Model for juror decision making.</span> <span>Journal of Personality and Social Psychology</span>, <span>62</span>(2), <span>189</span>–<span>206</span>.<a target="_blank" aria-label="CrossRef link for Explaining the evidence: Tests of the Story Model for juror decision making." href="https://dx.doi.org/10.1037/0022-3514.62.2.189">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Explaining the evidence: Tests of the Story Model for juror decision making." href="https://scholar.google.com/scholar_lookup?title=Explaining+the+evidence%3A+Tests+of+the+Story+Model+for+juror+decision+making.&amp;author=Pennington+N.&amp;author=Hastie+R.&amp;publication+year=1992&amp;journal=Journal+of+Personality+and+Social+Psychology&amp;volume=62&amp;doi=10.1037%2F0022-3514.62.2.189&amp;pages=189-206">Google Scholar</a></p></div><div id="rf22" aria-flowto="reference-22-content reference-22-button"><p><span><span>Pfungst</span>, <span>O.</span></span> (<span>1911</span>). <span>Clever Hans (the horse of Mr. Von Osten): a contribution to experimental animal and human psychology.</span> <span>New York</span>: <span>Holt, Rinehart and Winston</span> (Originally published in German, 1907).<a target="_blank" aria-label="CrossRef link for Clever Hans (the horse of Mr. Von Osten): a contribution to experimental animal and human psychology." href="https://dx.doi.org/10.5962/bhl.title.56164">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Clever Hans (the horse of Mr. Von Osten): a contribution to experimental animal and human psychology." href="https://scholar.google.com/scholar_lookup?title=Clever+Hans+(the+horse+of+Mr.+Von+Osten)%3A+a+contribution+to+experimental+animal+and+human+psychology.&amp;author=Pfungst+O.&amp;publication+year=1911">Google Scholar</a></p></div><div id="rf23" aria-flowto="reference-23-content reference-23-button"><p><span><span>Rouder</span>, <span>J. N.</span></span>, <span><span>Lu</span>, <span>J.</span></span>, <span><span>Speckman</span>, <span>P.</span></span>, <span><span>Sun</span>, <span>D. H.</span></span>, &amp; <span><span>Jiang</span>, <span>Y.</span></span> (<span>2005</span>). <span>A hierarchical model for estimating response time distributions.</span> <span>Psychonomic Bulletin &amp; Review</span>, <span>12</span>(2), <span>195</span>–<span>223</span>.<a target="_blank" aria-label="CrossRef link for A hierarchical model for estimating response time distributions." href="https://dx.doi.org/10.3758/BF03257252">CrossRef</a><a target="_blank" aria-label="Google Scholar link for A hierarchical model for estimating response time distributions." href="https://scholar.google.com/scholar_lookup?title=A+hierarchical+model+for+estimating+response+time+distributions.&amp;author=Rouder+J.+N.&amp;author=Lu+J.&amp;author=Speckman+P.&amp;author=Sun+D.+H.&amp;author=Jiang+Y.&amp;publication+year=2005&amp;journal=Psychonomic+Bulletin+%26+Review&amp;volume=12&amp;doi=10.3758%2FBF03257252&amp;pages=195-223">Google Scholar</a><a target="_blank" aria-label="PubMed link for A hierarchical model for estimating response time distributions." href="https://www.ncbi.nlm.nih.gov/pubmed/16082801">PubMed</a></p></div><div id="rf24" aria-flowto="reference-24-content reference-24-button"><p><span><span>Schauer</span>, <span>F.</span></span> (<span>2013</span>). <span>Legal Realism Untamed.</span> <span>Texas Law Review</span>, <span>91</span>(4), <span>749</span>–<span>780</span>.<a target="_blank" aria-label="Google Scholar link for Legal Realism Untamed." href="https://scholar.google.com/scholar_lookup?title=Legal+Realism+Untamed.&amp;author=Schauer+F.&amp;publication+year=2013&amp;journal=Texas+Law+Review&amp;volume=91&amp;pages=749-780">Google Scholar</a></p></div><div id="rf25" aria-flowto="reference-25-content reference-25-button"><p><span><span>Simon</span>, <span>D.</span></span> (<span>2004</span>). <span>A third view of the black box: cognitive coherence in legal decision making.</span> <span>University of Chicago Law Review,</span> <span>71</span>, <span>511</span>–<span>586</span>.<a target="_blank" aria-label="Google Scholar link for A third view of the black box: cognitive coherence in legal decision making." href="https://scholar.google.com/scholar_lookup?title=A+third+view+of+the+black+box%3A+cognitive+coherence+in+legal+decision+making.&amp;author=Simon+D.&amp;publication+year=2004&amp;journal=University+of+Chicago+Law+Review%2C&amp;volume=71&amp;pages=511-586">Google Scholar</a></p></div><div id="rf26" aria-flowto="reference-26-content reference-26-button"><p><span><span>Thagard</span>, <span>P.</span></span> (<span>2006</span>). <span>Evaluating Explanations in Law, Science, and Everyday Life.</span> <span>Current Directions in Psychological Science</span>, <span>15</span>(3), <span>141</span>–<span>145</span>.<a target="_blank" aria-label="CrossRef link for Evaluating Explanations in Law, Science, and Everyday Life." href="https://dx.doi.org/10.1111/j.0963-7214.2006.00424.x">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Evaluating Explanations in Law, Science, and Everyday Life." href="https://scholar.google.com/scholar_lookup?title=Evaluating+Explanations+in+Law%2C+Science%2C+and+Everyday+Life.&amp;author=Thagard+P.&amp;publication+year=2006&amp;journal=Current+Directions+in+Psychological+Science&amp;volume=15&amp;doi=10.1111%2Fj.0963-7214.2006.00424.x&amp;pages=141-145">Google Scholar</a></p></div><div id="rf27" aria-flowto="reference-27-content reference-27-button"><p><span><span>Tversky</span>, <span>A.</span></span>, &amp; <span><span>Kahneman</span>, <span>D.</span></span> (<span>1974</span>). <span>Judgment under uncertainty: Heuristics and biases.</span> <span>Science</span>, <span>185</span>(4157), <span>1124</span>–<span>1131</span>.<a target="_blank" aria-label="CrossRef link for Judgment under uncertainty: Heuristics and biases." href="https://dx.doi.org/10.1126/science.185.4157.1124">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Judgment under uncertainty: Heuristics and biases." href="https://scholar.google.com/scholar_lookup?title=Judgment+under+uncertainty%3A+Heuristics+and+biases.&amp;author=Tversky+A.&amp;author=Kahneman+D.&amp;publication+year=1974&amp;journal=Science&amp;volume=185&amp;doi=10.1126%2Fscience.185.4157.1124&amp;pages=1124-1131">Google Scholar</a><a target="_blank" aria-label="PubMed link for Judgment under uncertainty: Heuristics and biases." href="https://www.ncbi.nlm.nih.gov/pubmed/17835457">PubMed</a></p></div><div id="rf29" aria-flowto="reference-29-content reference-29-button"><p><span><span>Yamada</span>, <span>M.</span></span>, <span><span>Camerer</span>, <span>C. F.</span></span>, <span><span>Fujie</span>, <span>S.</span></span>, <span><span>Kato</span>, <span>M.</span></span>, <span><span>Matsuda</span>, <span>T.</span></span>, <span><span>Takano</span>, <span>H.</span></span>, …<span><span>Takahashi</span>, <span>H.</span></span> (<span>2012</span>). <span>Neural circuits in the brain that are activated when mitigating criminal sentences.</span> <span>Nature Communications, 3.</span> <a href="https://dx.doi.org/10.1038/ncomms1757">http://dx.doi.org/10.1038/ncomms1757</a>.<a target="_blank" aria-label="CrossRef link for Neural circuits in the brain that are activated when mitigating criminal sentences." href="https://dx.doi.org/10.1038/ncomms1757">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Neural circuits in the brain that are activated when mitigating criminal sentences." href="https://scholar.google.com/scholar_lookup?title=Neural+circuits+in+the+brain+that+are+activated+when+mitigating+criminal+sentences.&amp;author=Yamada+M.&amp;author=Camerer+C.+F.&amp;author=Fujie+S.&amp;author=Kato+M.&amp;author=Matsuda+T.&amp;author=Takano+H.&amp;author=Takahashi+H.&amp;publication+year=2012&amp;journal=Nature+Communications%2C+3.&amp;doi=10.1038%2Fncomms1757">Google Scholar</a><a target="_blank" aria-label="PubMed link for Neural circuits in the brain that are activated when mitigating criminal sentences." href="https://www.ncbi.nlm.nih.gov/pubmed/22453832">PubMed</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[StreamPot: Run FFmpeg as an API with fluent-FFmpeg compatibility, queues and S3 (131 pts)]]></title>
            <link>https://github.com/StreamPot/StreamPot</link>
            <guid>41091163</guid>
            <pubDate>Sun, 28 Jul 2024 04:09:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/StreamPot/StreamPot">https://github.com/StreamPot/StreamPot</a>, See on <a href="https://news.ycombinator.com/item?id=41091163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">StreamPot</h2><a id="user-content-streampot" aria-label="Permalink: StreamPot" href="#streampot"></a></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto"><strong>StreamPot is still in the early stages of development, we would appreciate your feedback.</strong></p>
</div>
<p dir="auto">StreamPot is a project that provides scaffolding for transforming media in your app (e.g. trimming a video, stripping the audio from a video, transcoding a video from mp4 to webp).</p>
<p dir="auto">We are building this because an increasing number of projects are transforming media as part of their workflow.</p>
<p dir="auto">If you want a no-setup way to run this, check out <a href="https://www.streampot.io/" rel="nofollow">StreamPot</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running the server locally</h2><a id="user-content-running-the-server-locally" aria-label="Permalink: Running the server locally" href="#running-the-server-locally"></a></p>
<p dir="auto">Visit the <a href="https://www.streampot.io/installation.html#setting-up-the-server-without-docker" rel="nofollow">Installation (server)</a> page for self-hosting instructions.
If you'd like to use the <strong>hosted version</strong>, please <a href="https://app.streampot.io/register" rel="nofollow">sign up</a> and give it a try.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running a job in your app</h2><a id="user-content-running-a-job-in-your-app" aria-label="Permalink: Running a job in your app" href="#running-a-job-in-your-app"></a></p>
<p dir="auto">Note: You should only run this from your server.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install the client library</h3><a id="user-content-install-the-client-library" aria-label="Permalink: Install the client library" href="#install-the-client-library"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Initialise the client &amp; submit a job.</h3><a id="user-content-initialise-the-client--submit-a-job" aria-label="Permalink: Initialise the client &amp; submit a job." href="#initialise-the-client--submit-a-job"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import StreamPot from '@streampot/client'
const EXAMPLE_VID = 'https://sample-videos.com/video321/mp4/240/big_buck_bunny_240p_1mb.mp4'

const client = new StreamPot({
    baseUrl: 'http://127.0.0.1:3000', // adjust if you are serving in production
})

const clipJob = await client.input(EXAMPLE_VID)
    .setStartTime(1)
    .setDuration(2)
    .output('output.mp4')
    .run()
const jobId = clipJob.id

// In production you should set up a poll.
setTimeout(async () => {
    const job = await client.checkStatus(jobId)
    if (job.status === 'completed'){
        console.log(job.output_url)
    } 
},10000) // wait 10 seconds"><pre><span>import</span> <span>StreamPot</span> <span>from</span> <span>'@streampot/client'</span>
<span>const</span> <span>EXAMPLE_VID</span> <span>=</span> <span>'https://sample-videos.com/video321/mp4/240/big_buck_bunny_240p_1mb.mp4'</span>

<span>const</span> <span>client</span> <span>=</span> <span>new</span> <span>StreamPot</span><span>(</span><span>{</span>
    <span>baseUrl</span>: <span>'http://127.0.0.1:3000'</span><span>,</span> <span>// adjust if you are serving in production</span>
<span>}</span><span>)</span>

<span>const</span> <span>clipJob</span> <span>=</span> <span>await</span> <span>client</span><span>.</span><span>input</span><span>(</span><span>EXAMPLE_VID</span><span>)</span>
    <span>.</span><span>setStartTime</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>setDuration</span><span>(</span><span>2</span><span>)</span>
    <span>.</span><span>output</span><span>(</span><span>'output.mp4'</span><span>)</span>
    <span>.</span><span>run</span><span>(</span><span>)</span>
<span>const</span> <span>jobId</span> <span>=</span> <span>clipJob</span><span>.</span><span>id</span>

<span>// In production you should set up a poll.</span>
<span>setTimeout</span><span>(</span><span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>job</span> <span>=</span> <span>await</span> <span>client</span><span>.</span><span>checkStatus</span><span>(</span><span>jobId</span><span>)</span>
    <span>if</span> <span>(</span><span>job</span><span>.</span><span>status</span> <span>===</span> <span>'completed'</span><span>)</span><span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>job</span><span>.</span><span>output_url</span><span>)</span>
    <span>}</span> 
<span>}</span><span>,</span><span>10000</span><span>)</span> <span>// wait 10 seconds</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">This project is heavily reliant on the amazing work of the ffmpeg and fluent-ffmpeg teams</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback</h2><a id="user-content-feedback" aria-label="Permalink: Feedback" href="#feedback"></a></p>
<p dir="auto">If you want to use StreamPot in your project, I'd be happy to help &amp; improve it based on your feedback. Email me at <a href="mailto:jack@bitreach.io">jack@bitreach.io</a> or <a href="https://cal.com/jackbridger/30min" rel="nofollow">let's have a call</a>.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>