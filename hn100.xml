<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 15 Jul 2024 02:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Just Be Rich (2021) (194 pts)]]></title>
            <link>https://keenen.xyz/just-be-rich/</link>
            <guid>40962965</guid>
            <pubDate>Sun, 14 Jul 2024 20:16:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keenen.xyz/just-be-rich/">https://keenen.xyz/just-be-rich/</a>, See on <a href="https://news.ycombinator.com/item?id=40962965">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                    <p>No one wants to be the bad guy.</p><p>When narratives begin to shift and the once good guys are labelled as bad it's not surprising they fight back. They'll point to criticisms as exaggerations. Their faults as misunderstandings.</p><p>Today's freshly ordained bad guys are the investors and CEOs of Silicon Valley.</p><p>Once championed as the flagbearers of innovation and democratization, now they're viewed as new versions of the monopolies of old and they're fighting back.</p><p>The title of Paul Graham's essay, <a href="http://paulgraham.com/richnow.html?ref=keenen.xyz">How People Get Rich Now</a>, didn't prepare me for the real goal of his words. It's less a tutorial or analysis and more a thinly veiled attempt to ease concerns about wealth inequality.</p><blockquote>People who don't look any deeper than the Gini coefficient look back on the world of 1982 as the good old days, because those who got rich then didn't get as rich. But if you dig into <em>how</em> they got rich, the old days don't look so good. In 1982, 84% of the richest 100 people got rich by inheritance, extracting natural resources, or doing real estate deals. Is that really better than a world in which the richest people get rich by starting tech companies?</blockquote><p>What he fails to mention is that concerns about wealth inequality aren't concerned with how wealth was generated but rather the growing wealth gap that has accelerated in recent decades. Tech has made startups both cheaper and easier but only for a small percentage of people. And when a select group of people have an advantage that others don't it's compounded over time.</p><blockquote>Once you understand how these mechanisms work, and that startups were suppressed for most of the 20th century, you don't have to resort to some vague right turn the country took under Reagan to explain why America's Gini coefficient is increasing. Of course the Gini coefficient is increasing. With more people starting more valuable companies, how could it not be?</blockquote><figure><img src="https://keenen.xyz/content/images/2021/04/image.png" alt="" loading="lazy" width="1274" height="886" srcset="https://keenen.xyz/content/images/size/w600/2021/04/image.png 600w, https://keenen.xyz/content/images/size/w1000/2021/04/image.png 1000w, https://keenen.xyz/content/images/2021/04/image.png 1274w" sizes="(min-width: 720px) 720px"></figure><p>Paul paints a rosy picture but doesn't mention that incomes for lower and middle-class families have fallen since the 80s. This golden age of entrepreneurship hasn't benefitted the vast majority of people and the increase in the Gini coefficient isn't simply that more companies are being started. The rich are getting richer and the poor are getting poorer.</p><figure><img src="https://keenen.xyz/content/images/2021/04/image-1.png" alt="" loading="lazy" width="848" height="830" srcset="https://keenen.xyz/content/images/size/w600/2021/04/image-1.png 600w, https://keenen.xyz/content/images/2021/04/image-1.png 848w" sizes="(min-width: 720px) 720px"></figure><blockquote>You would think, after having been on the side of labor in its fight with capital for almost two centuries, that the far left would be happy that labor has finally prevailed. But none of them seem to be. You can almost hear them saying "No, no, not <em>that</em> way."</blockquote><p>And there we have it. The slight injection of his true ideology relegated to the notes section and vague enough that some might ignore. But keep in mind this is the same guy who argued <a href="http://www.paulgraham.com/wtax.html?ref=keenen.xyz">against a wealth tax</a>. His seemingly impartial and logical writing attempts to hide his true intentions.</p><p>Is this really about how people get rich or why we should all be happy that people like PG are getting richer while tons of people and struggling to meet their basic needs. Wealth inequality is just a radical left fairy tale to villainize the hard-working 1%. We could all be rich too, it's so much easier now. Just pull yourself up by your bootstraps.</p><p>There's no question that it's easier now than ever to start a new business and reach your market. The internet has had a democratizing effect in this regard. But it's also obvious to anyone outside the SV bubble that it's still only accessible to a small minority of people. Most people don't have the safety net or mental bandwidth to even consider entrepreneurship. It is not a panacea for the masses.</p><p>But to use that fact to push the false claim that wealth inequality is solely due to more startups and not a real problem says a lot. This essay is less about how people get rich and more about why it's okay that people like PG are getting rich. They're better than the richest people of 1960. And we can join them. We just need to stop complaining and just be rich instead.</p>
                    
                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Know When It's Time to Go (177 pts)]]></title>
            <link>https://thecodist.com/how-to-know-when-its-time-to-go/</link>
            <guid>40962675</guid>
            <pubDate>Sun, 14 Jul 2024 19:16:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thecodist.com/how-to-know-when-its-time-to-go/">https://thecodist.com/how-to-know-when-its-time-to-go/</a>, See on <a href="https://news.ycombinator.com/item?id=40962675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">
<article>

    <header>

        

        


        

            <figure>
                <img srcset="https://thecodist.com/content/images/size/w300/2024/07/timetogo-1.jpg 300w,
                            https://thecodist.com/content/images/size/w600/2024/07/timetogo-1.jpg 600w,
                            https://thecodist.com/content/images/size/w1000/2024/07/timetogo-1.jpg 1000w,
                            https://thecodist.com/content/images/size/w2000/2024/07/timetogo-1.jpg 2000w" sizes="(min-width: 1400px) 1400px, 92vw" src="https://thecodist.com/content/images/size/w2000/2024/07/timetogo-1.jpg" alt="Alarm clock with words &quot;Time To Go&quot;">
            </figure>

    </header>

    <section>
        <p>I retired in 2021 at 63.5 after about four decades as a programmer. What made me do this was not failing ability in any way, but after a year of consideration, I realized I didn't care to do it anymore.</p><p>Everyone will eventually reach a point at which they can no longer do what they spent their lives doing—but it's not just about retirement; it can happen at any time earlier as well. I've known people much younger than me who became obsolete due to their chosen technology going away or people who simply got tired of writing code or, more commonly, doing it as a job.</p><p>Of course its not only programmers, it happens in everything including sports where professionals keep playing beyond their ability (often to make a bunch more money), and even politicians who exceed their limit (currently on view as both US Presidential candidates should not run but won't quit). It can be that you cannot do it anymore, have a lack of desire, a bad job market, obsolete technology, or are discovering something else worth doing. In my life, I've seen all of those.</p><p>I knew a young programmer a decade ago who left his CS degree because he was making tons of money shipping mobile apps, he even wrote a book on it, and started several companies. But he burned out and discovered he no longer cared, started a Jeep dealership, then started a land clearing business (riding bulldozers all day) and enjoyed all of that more, plus had more consistent success.</p><p>I knew someone who got a CS degree when I was getting my Chemistry degree and spent his career writing only mainframe systems code. Eventually, the mainframe was abandoned, and he had not learned anything else, so he had to work installing network cables. Another team at a place where I worked bragged about how great their technology was (4GL tools generating RPG2); a year later, they were out of a job, and the tool was obsolete. Sometimes, the world passes you by.</p><p>You probably don't know any retired programmers—back in the early 80s, when I started, there was only a tiny percentage of programmers compared to today, and over the decades, many gave up, became managers, or became obsolete. So, not many remained writing code long enough to end their career still writing code. Among those who I knew that started when I did, all that remained forty years later were doing legacy work; I was the only one still working on the leading edge of things (in my case, iOS in Swift for a very large company). It's hard to sustain a career that long in an industry with insane amounts of change.</p><p>All of you reading this (programmers anyway) will eventually hit a point where you can't do the job anymore for one of the above reasons. It's important to be honest with yourself. Are you keeping up to date sufficiently to continue the job? Is the job even interesting anymore, or is there something else you would rather do? Maybe your programming is not fun, or perhaps it's no longer challenging enough. Despite how unfulfilling it is, I've known people who enjoy the paycheck, do boring work, and keep doing it. That's a choice, but I was never satisfied with that.</p><p>It's not only quitting programming that you might consider; the biggest reason to quit may be that your job is not worth doing and that you need to find another one. I've quit perfectly good jobs (and some terrible ones) because I did not find the work interesting, the direction terrible, or a hostile workplace. Naturally, some employers went out of business or laid people off, but I left those jobs involuntarily! A different kind of programming or a different industry could revive your interest. The key is still to be honest with yourself. I've known people who left a high-pressure, high-salary job, started a farm, or began a different career. It's not worth working and being miserable.</p><p>Some time ago, I knew a programmer with the same number of years of experience as me. Yet he seemed unable to comprehend what was required of him, and I had to review everything he wrote because it rarely worked; for example, he would copy and paste code but include extra lines that did nothing. I still have no idea how you can work for 30 years and be unable to do even simple things.</p><p>None of this says that you should discriminate against people simply due to their age. Age and ability are not correlated. I've known people older than me who were brilliant and some that were incapable, like the previous person. I've seen 20-year-olds who could write anything successfully and others who did not understand simple concepts. Thankfully, I saw little age discrimination besides a few interviews where the interviewer had that look on their face: "Oh no, an old guy." Especially in my last three employers (covering about a decade), each valued everything I did.</p><p>When I announced my retirement (with three months' warning), my leaders were shocked. They couldn't comprehend why anyone would retire. One of them, whom I had worked for for two of those jobs and always made his life easier, never spoke to me again or even said goodbye. I still talk with some of my peers and team, and knowing how downhill the work has gone since (although the money got really good), I would have left anyway. I like making a difference and being challenged to do things and work that matters. Money is nice, but I liked making that difference.</p><p>Everyone eventually reaches a point where a job, an employer, an industry, or even their entire career ends. It feels better to be honest and make an informed decision rather than discover you are falling behind and possibly being forced out. It feels better to leave a bad job instead of hanging on until your hair falls out, even if the next job is equally terrible (I've been there). Your career is yours; it's up to you to make the most of it, even if you end it.</p><p>I still write code every day in support of my <a href="https://digcon.art/?ref=thecodist.com">generative art practice</a>. The code is much more complex than anything I did previously, and much of it does not have anyone else doing it, so it's a lot of invention, which is fun. While I miss certain aspects of my final job, I don't miss the eternal pressure, long hours, bad executive decision-making, and endless changes. I do miss being a leader and seeing things we wrote being used by our many customers. </p><p>Programming can be a fun career, a horrible nightmare, or something in between, and it never stands still. I enjoyed the good parts, tolerated the bad, and switched technologies, industries, and employers often enough to keep it going for four decades. That's long enough.</p>
    </section>


</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Calculating position from raw GPS data (2017) (139 pts)]]></title>
            <link>https://www.telesens.co/2017/07/17/calculating-position-from-raw-gps-data/</link>
            <guid>40962231</guid>
            <pubDate>Sun, 14 Jul 2024 17:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.telesens.co/2017/07/17/calculating-position-from-raw-gps-data/">https://www.telesens.co/2017/07/17/calculating-position-from-raw-gps-data/</a>, See on <a href="https://news.ycombinator.com/item?id=40962231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div kcite-section-id="1152">
<p>We are all familiar with GPS (Global Positioning System) and its myriad applications. From getting directions using Google maps to hailing&nbsp;a ride using a ride&nbsp;sharing app, countless individuals and businesses rely on accurate position estimation&nbsp;using GPS. Position estimation using GPS is now so accurate that GPS is being used for measuring plate tectonics and continental drift. Indeed, GPS is so much a part of our lives that few of us stop and wonder how it actually works. The purpose of this post is to show you how. &nbsp;More specifically, we’ll first learn how position is calculated from range measurements to GPS satellites and then consider a concrete example where we’ll process raw data collected by a commercial GPS receiver to obtain user position estimates.</p>
<p>GPS is owned by the US government and operated by the US air force. As such, access to GPS data can be degraded or denied to other nations due to geopolitical concerns. For example, according to this <a href="https://en.wikipedia.org/wiki/Global_Positioning_System">wikipedia article</a>, access to GPS data was denied to the Indian military during the Kargil conflict. Other countries therefore decided to implement their own GPS like systems. Examples are GLONASS by Russia, Galileo by the European Union and BeiDou by China. This may seem like a waste of resources, but many of these systems operate using the same standards as GPS and are interoperable. For example, latest GPS receivers can receive signals from both GPS and GLONASS satellites, improving positioning accuracy. The wikipedia article referenced above also provides an interesting history of the origins of the GPS system dating back to Sputnik, the first man made satellite launched in space.</p>
<p>The post is divided into 3 parts – the first part describes the&nbsp;various coordinate systems used to express position. An understanding of these coordinate systems is essential for understanding how GPS works and is useful in its own right. For example, the concept of height above the earth surface is something that people intuitively understand, but turns out to be tricky idea to precisely define. The second part describes the basic principle of triangulation used by GPS to calculate position&nbsp;and develops the mathematics for calculating the user position from satellite measurements. A casual user, interested in a general knowledge of how GPS operates but not in the details can read part 1 and the first few sections of part 2 before the math starts. &nbsp;Finally, the appendix provides the Matlab code for implementing various ideas discussed in this post.</p>
<p>Most of the information in this post derives from the book “Global Positioning Systems: Signals, Measurements and Performance”&nbsp;<span id="as0cu2o0u8" data-reflist="[&quot;a5of4cpcm&quot;]" data-footnote="undefined"><sup>1</sup></span>, an excellent book about GPS systems. The matlab code presented in this post was written as solutions to the various end of chapter problems in the book. I also make use of material in the GPS Interface Specification document<span id="adssc1bn88" data-reflist="[&quot;g1c8p8q7oq&quot;]" data-footnote="undefined"><sup>2</sup></span>. My contribution is to present the keys ideas related to GPS in a (hopefully) clear and concise manner and show&nbsp;the Matlab code that implements the positioning algorithms on real world data collected using commercial GPS receivers that can be purchased from the internet. After reading this post, a casual reader&nbsp;should have a better understanding of GPS, so the next time they use Google maps on their phone, they are aware of the amazing&nbsp;technical infrastructure that makes positioning and navigation applications possible. A more technical reader&nbsp;should be able to replicate my experiments by collecting their own data and running the Matlab code.</p>
<div id="ez-toc-container">

<nav><ul><li><a href="#Part_1" title="Part 1">Part 1</a><ul><li><a href="#Model_1_Reference_Ellipsoid" title="Model 1: Reference Ellipsoid">Model 1: Reference Ellipsoid</a></li><li><a href="#Model_2_Geoid" title="Model 2: Geoid">Model 2: Geoid</a></li><li><a href="#Latitude_and_Longitude" title="Latitude and Longitude">Latitude and Longitude</a></li><li><a href="#Conversion_between_Geodetic_Ellipsoidal_and_Cartesion_Coordinates" title="Conversion between Geodetic (Ellipsoidal) and Cartesion Coordinates">Conversion between Geodetic (Ellipsoidal) and Cartesion Coordinates</a></li><li><a href="#Local_Coordinate_Systems" title="Local Coordinate Systems">Local Coordinate Systems</a></li></ul></li><li><a href="#Part_2_Using_GPS_to_Calculate_User_Position" title="Part 2: Using GPS to Calculate User Position">Part 2: Using GPS to Calculate User Position</a><ul><li><a href="#Step_1_Determining_the_Position_of_a_Satellite" title="Step 1: Determining the Position of a Satellite">Step 1: Determining the Position of a Satellite</a><ul><li><a href="#Rotating_the_Satellite_Reference_Frame" title="Rotating the Satellite Reference Frame">Rotating the Satellite Reference Frame</a></li></ul></li><li><a href="#Step_2_Computing_the_Distance_of_the_User_from_the_Satellite" title="Step 2: Computing the Distance of the User from the Satellite">Step 2: Computing the Distance of the User from the Satellite</a><ul><li><a href="#Estimating_the_Satellite_Clock_Bias" title="Estimating the Satellite Clock Bias">Estimating the Satellite Clock Bias</a></li><li><a href="#User_Clock_Bias" title="User Clock Bias">User Clock Bias</a></li></ul></li><li><a href="#Step_3_User_Position_and_Clock_Bias_Estimation" title="Step 3: User Position and Clock Bias Estimation">Step 3: User Position and Clock Bias Estimation</a></li></ul></li><li><a href="#Note_about_the_Matlab_Code" title="Note about the Matlab Code">Note about the Matlab Code</a></li><li><a href="#Experimental_Setup" title="Experimental Setup">Experimental Setup</a><ul><li><a href="#Processing_Raw_GPS_Data" title="Processing Raw GPS Data">Processing Raw GPS Data</a></li><li><a href="#Analysis_of_Results" title="Analysis of Results">Analysis of Results</a></li><li><a href="#Clock_Bias_Drift" title="Clock Bias Drift">Clock Bias Drift</a></li><li><a href="#Computing_the_Satellite_AzimuthElevation" title="Computing the Satellite Azimuth/Elevation">Computing the Satellite Azimuth/Elevation</a></li><li><a href="#Dilution_of_Precision_DOP" title="Dilution of Precision (DOP)">Dilution of Precision (DOP)</a></li></ul></li><li><a href="#Appendix" title="Appendix">Appendix</a><ul><li><a href="#1a_Code_for_Calculating_User_Position_and_Clock_Bias" title="1.a Code for Calculating User Position and Clock Bias">1.a Code for Calculating User Position and Clock Bias</a></li><li><a href="#1b_Code_for_Calculating_Satellite_Position" title="1.b Code for Calculating Satellite Position">1.b Code for Calculating Satellite Position</a></li><li><a href="#1c_Code_for_Computing_the_Least_Squares_Solution_for_User_Position_and_Clock_Bias" title="1.c Code for Computing the Least Squares Solution for User Position and Clock Bias">1.c Code for Computing the Least Squares Solution for User Position and Clock Bias</a></li><li><a href="#1d_Code_for_Calculating_Satellite_Clock_Bias" title="1.d Code for Calculating Satellite Clock Bias">1.d Code for Calculating Satellite Clock Bias</a></li><li><a href="#1e_Code_for_converting_ECEF_WGS84_to_Ellipsoidal_Coordinates" title="1.e Code for converting ECEF (WGS84) to Ellipsoidal Coordinates">1.e Code for converting ECEF (WGS84) to Ellipsoidal Coordinates</a></li><li><a href="#1f_format_ephemeris3m" title="1.f format_ephemeris3.m">1.f format_ephemeris3.m</a></li><li><a href="#2a_Taylor_Series_Expansion_of_Vector_Modulus" title="2.a Taylor Series Expansion of Vector Modulus">2.a Taylor Series Expansion of Vector Modulus</a></li><li><a href="#2b_Ionospheric_and_Tropospheric_Delay" title="2.b&nbsp;Ionospheric and Tropospheric Delay">2.b&nbsp;Ionospheric and Tropospheric Delay</a></li><li><a href="#2c_Plotting_code" title="2.c Plotting code">2.c Plotting code</a></li></ul></li></ul></nav></div>
<h2><span id="Part_1"><strong>Part 1</strong></span></h2>
<p>The fundamental task of a GPS system is to calculate position. To do so, we must first define what position means. Most people think about latitude/longitude and height when they think about position. While latitude/longitude are useful to represent a position on the earth surface, they are not suitable for mathematical calculations as they don’t provide a cartesian coordinate system. The physical distance represented by a unit difference between two longitudes is not constant, and depends on the position. For example, the distance between two longitudes one degree apart is greatest&nbsp;at the equator and approaches 0 at the poles.</p>
<p id="jOXWgSj"><img decoding="async" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596cb025bd6b0.png" alt="" width="312" height="293" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596cb025bd6b0.png 540w, https://www.telesens.co/wp-content/uploads/2017/07/img_596cb025bd6b0-300x282.png 300w" sizes="(max-width: 312px) 100vw, 312px"></p>
<p>To be useful for mathematical calculations, a coordinate system where a unit difference between coordinates represents a constant physical distance is required. A family of such coordinate systems can be created by defining a set of perpendicular axes intersecting at an origin that is rigidly attached to the earth. Such coordinate systems are called “ECEF” (Earth Centered, Earth Fixed). These coordinate systems work well to express the position of a user on earth as they rotate with the earth and the position of a stationary user on the earth surface is constant.</p>
<p>The most commonly used ECEF&nbsp;coordinate system is called the WGS 1984 system developed by the department of defense. WGS 84 is an ECEF frame, defined as follows:</p>
<ul>
<li>Origin at the center of mass of the earth</li>
<li>z axis passing through the&nbsp;<em>CTP&nbsp;</em>(Conventional Terrestrial Pole). CTP is the average of the earth’s pole’s position between the years 1900 and 1905. An average needs to be used as the position of the pole is not fixed and wanders around in a circle of radius ~15m.</li>
<li>x axis passing through the intersection of the CTP’s equatorial plane and a reference meridian, often called the <em>Mean Greenwich Meridian</em></li>
</ul>
<p>ECEF frames are convenient to represent positions with respect to the earth, but they are not inertial as they are rigidly attached to a spinning earth. To formulate the problem of satellite motion around the earth in accordance with Newton’s laws of motion, we need an inertial coordinate system in which to express acceleration, position and velocity vectors.</p>
<p id="ZiESHUc"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596cbb5fe5f62.png" alt="" width="504" height="381" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596cbb5fe5f62.png 800w, https://www.telesens.co/wp-content/uploads/2017/07/img_596cbb5fe5f62-300x227.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_596cbb5fe5f62-768x581.png 768w, https://www.telesens.co/wp-content/uploads/2017/07/img_596cbb5fe5f62-326x245.png 326w, https://www.telesens.co/wp-content/uploads/2017/07/img_596cbb5fe5f62-80x60.png 80w" sizes="(max-width: 504px) 100vw, 504px"></p>
<p>An inertial frame can be defined in a manner similar to the ECEF frame except that the x-axis points to the vernal equinox (the direction of intersection of the equatorial plane of the earth with the plane of the earth’s orbit around the sun). Strictly speaking, this frame isn’t inertial either since the earth is moving around the sun. However, it can be considered inertial over short periods (just as the ECEF frame can be considered inertial for analyzing the movement of a body on earth over a short period).</p>
<p>In the rest of this post, we’ll be using the WGS 84 ECEF frame to express the user and satellite position. This is possible because the&nbsp;<a href="http://www.gps.gov/technical/icwg/IS-GPS-200H.pdf">GPS interface specification document</a>&nbsp;(referred to as GPS-IS in the rest of this post) provides a step by step procedure to calculate the satellite position in the ECEF frame at a given time instant that accounts for the non-inertial nature of the ECEF frame. This is fortunate because ECEF frames are ideal to express the position of a user on the surface of the earth as they rotate with the earth and thus the position of a stationary user is constant, as one would expect. This would not be the case if an inertial reference frame is used to express position as such a frame would be fixed in space, and thus would appear rotating with respect to the earth.</p>
<p>Let’s now turn to the issue of defining height that we alluded to earlier. The key question that needs to be answered when defining height is “with respect to what”? Consider for example the height of a point in a desert. If we define height to be the distance of the point from the “ground”, then such a height would change constantly as the level of the ground itself changes due to natural phenomenon&nbsp;(for example, the wind depositing more sand). &nbsp;Thus, to define height, we must first define “ground” (note that strictly speaking, this issue doesn’t arise in a ECEF reference frame, as all distances are measured with respect to the center of mass of the earth. However generally people are not interested in distance from&nbsp;the center of the earth, but from the local earth surface). To define “ground” in a consistent manner, we need a model for the surface of the earth. Two models are generally used:</p>
<h3><span id="Model_1_Reference_Ellipsoid"><strong>Model 1: Reference Ellipsoid</strong></span></h3>
<p>The surface of the earth is modeled as an oblate ellipse called the “reference ellipsoid”, centered at the earth’s center with the axis of revolution coincident with the z axis of an ECEF frame. The lengths of the semi-major and semi-minor axes (denoted as <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-5c53d6ebabdbcfa4e107550ea60b1b19_l3.png" alt="a" title="Rendered by QuickLaTeX.com" height="8" width="9"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f56d50c26583f9a035ff6b4e3c0ca5c0_l3.png" alt="b" title="Rendered by QuickLaTeX.com" height="13" width="8">) are <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-15d678f0603cd51a261d32c1134be9f2_l3.png" alt="a = 6378137m" title="Rendered by QuickLaTeX.com" height="14" width="111"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-22702d21f7da674f49092f81e078357f_l3.png" alt="b = 6357002m" title="Rendered by QuickLaTeX.com" height="13" width="109">. As expected, the value generally used for earth’s radius (with the earth modeled as a sphere) is 6371Km which lies between the lengths of the semi-major and minor-axis. The reference ellipsoid is merely an abstraction for the shape of the earth. It doesn’t have any physical significance. An actual point on the earth surface will usually lie above or below the reference ellipsoid.</p>
<h3><span id="Model_2_Geoid"><strong>Model 2: Geoid</strong></span></h3>
<p>Another surface commonly used to measure height that does have physical significance is called the&nbsp;<em>geoid</em>. This surface is defined as the locus of all points with the same value of the gravitational potential. If the earth was a sphere with a uniform composition, this surface would be a regular surface that can be parameterized as a mathematical function. However since the earth is neither spherical nor uniform, the geoid is usually specified as a series of heights above the reference ellipsoid.&nbsp;Height relative to the geoid is called the orthometric height, or height above the mean sea level (MSL). This makes sense as if the oceans covered the surface of the earth, the shape of the oceans would be a close approximation to the geoid.&nbsp;Strictly speaking, the shape of the geoid itself is not fixed as the surface of the earth is constantly changing due to human activities and natural phenomenon. However given the bulk of the earth, these only have a negligible impact on the earth’s gravitational field and thus on the shape of the geoid.</p>
<p>Note that the height of the geoid is specified with respect to the reference ellipsoid and the height of a given point can be specified with respect to either. The relationship between the ellipsoid, geoid and the actual surface of the earth is shown below.</p>
<p id="AAykyRw"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596ce69d3e988.png" alt="" width="697" height="190" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596ce69d3e988.png 891w, https://www.telesens.co/wp-content/uploads/2017/07/img_596ce69d3e988-300x82.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_596ce69d3e988-768x209.png 768w" sizes="(max-width: 697px) 100vw, 697px"></p>
<h3><span id="Latitude_and_Longitude"><strong>Latitude and Longitude</strong></span></h3>
<p>Armed with an ellipsoidal representation of the shape of the earth and with an ECEF coordinate system, we can define the position of a point P in&nbsp;<em>ellipsoidal&nbsp;</em>coordinates (commonly known as latitude, longitude and height) as follows:</p>

<p>Note that the latitude is the angle between the equatorial plane and the line&nbsp;<em>perpendicular</em> to the surface of the ellipse at point P, not the line joining point P and the earth center (origin of the ECEF frame). Angle between the equatorial plane and the line joining point P and the earth center is called the <em>geocentric </em>(as opposed to geodetic) latitude. If the earth were a perfect sphere, the normal to a point would pass through the earth center and the geocentric and geodetic latitude would coincide.</p>
<p id="fQfkRYt"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596cec084e233.png" alt="" width="499" height="404" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596cec084e233.png 800w, https://www.telesens.co/wp-content/uploads/2017/07/img_596cec084e233-300x243.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_596cec084e233-768x621.png 768w" sizes="(max-width: 499px) 100vw, 499px"></p>
<h3><span id="Conversion_between_Geodetic_Ellipsoidal_and_Cartesion_Coordinates"><strong>Conversion between Geodetic (Ellipsoidal) and Cartesion Coordinates</strong></span></h3>
<p>Conversion from&nbsp;ellipsoidal to cartesian coordinates is straightforward and can be implemented in one step.</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-1fa2534584e6b7d6bb0784d23f384753_l3.png" alt="\begin{bmatrix}x \\ y \\ z \end{bmatrix} = \begin{bmatrix}(N+h)cos(\phi)cos(\lambda) \\ (N+h)cos(\phi)sin(\lambda) \\ (N(1-e^2)+h)sin(\phi) \end{bmatrix}" title="Rendered by QuickLaTeX.com" height="65" width="243"></p>
<p>Going from cartesian to ellipsoidal is trickier and involves an iterative procedure that quickly converges. See Appendix 4.A of <span id="a2qgvc6mnbe" data-reflist="[&quot;a5of4cpcm&quot;]" data-footnote="undefined"><sup>1</sup></span>&nbsp; for details. The corresponding Matlab code is listed in section 1.e of the appendix. The more common use case is&nbsp;to convert ECEF coordinates to ellipsoidal as the input and output of GPS processing algorithms are usually in ECEF coordinates.</p>
<h3><span id="Local_Coordinate_Systems"><strong>Local Coordinate Systems</strong></span></h3>
<p>So far, we have mostly talked about “global” coordinate systems, centered at the earth center. In some applications, it is more convenient to use local coordinate systems, centered on the user’s position. These coordinate systems are called East-North-Up (ENU) systems. Given the user’s position in elliptical coordinates (<img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-5b2be26c0c1341f54b29baddda771346_l3.png" alt="\phi" title="Rendered by QuickLaTeX.com" height="16" width="11">: latitude, <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-2b5c45836864531b8e37025dabadd24a_l3.png" alt="\lambda" title="Rendered by QuickLaTeX.com" height="12" width="10">: longitude), user coordinates can be easily converted from a ECEF frame to a local ENU frame using the following matrix multiplication.</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-a995d083b2be8e2893a7c3d3405ea53a_l3.png" alt="R_{ENU} = \begin{bmatrix}-sin(\lambda) &amp; cos(\lambda) &amp; 0 \\ -sin(\phi)cos(\lambda) &amp; -sin(\phi)sin(\lambda) &amp; cos(\phi) \\ -cos(\phi)cos(\lambda) &amp; cos(\phi)sin(\lambda) &amp; sin(\phi)\end{bmatrix}R_{ECEF}" title="Rendered by QuickLaTeX.com" height="65" width="461"></p>
<p>We’ll see an application of ECEF to ENU conversion when we compute the azimuth and elevation of one of the GPS satellites later.</p>
<h2><span id="Part_2_Using_GPS_to_Calculate_User_Position"><strong>Part 2: Using GPS to Calculate User Position</strong></span></h2>
<p>Determining the position of a user using GPS is essentially a triangulation problem. If the distance of the user from three or more satellites is known, then the 3D position can be calculated using triangulation. The basic idea in 2 dimensions is shown below.</p>
<p id="DFvWGDb"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/06/img_595483bd718db.png" alt="" width="751" height="429" srcset="https://www.telesens.co/wp-content/uploads/2017/06/img_595483bd718db.png 1272w, https://www.telesens.co/wp-content/uploads/2017/06/img_595483bd718db-300x171.png 300w, https://www.telesens.co/wp-content/uploads/2017/06/img_595483bd718db-768x439.png 768w, https://www.telesens.co/wp-content/uploads/2017/06/img_595483bd718db-1024x585.png 1024w" sizes="(max-width: 751px) 100vw, 751px"></p>
<p>The problem of locating the user can&nbsp;thus can be divided into two subproblems:</p>
<ol>
<li>Finding the distance of the user from each satellite</li>
<li>Determining the position of this satellite in the user’s coordinate system</li>
</ol>
<p>Let’s look at each of these problems step by step.</p>
<h3><span id="Step_1_Determining_the_Position_of_a_Satellite"><strong>Step 1: Determining the Position of a Satellite</strong></span></h3>
<p>The ideal satellite orbit is an elliptical orbit and specified completely by 5 Keplerian parameters five&nbsp;of which determine the size and shape of the ellipse and the orientation of the orbital plane relative to the fixed stars (i.e., an inertial reference frame). The sixth parameter specifies the position of the satellite at a particular time instant of epoch. Given the six elements, the satellite position and velocity can be computed at any other epoch.</p>
<p id="bVbOcno"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596c0f935c931.png" alt="" width="722" height="327"></p>
<p>The orbit of a satellite is not an exact ellipse however as the earth is not uniform in composition and the movement of a satellite is perturbed by the gravitational forces of the sun and the moon. The resulting perturbations are small, but must be accounted for to obtain accurate position. GPS accounts for these perturbations by transmitting an expanded set of 16 orbital parameters that can be used to accurately compute the position of a satellite at a given time instant. We won’t go into the details of how these corrections are applied. The step-by-step procedure to compute the satellite position (including applying the orbital corrections)&nbsp;is described in table 20-IV in the GPS IS. The Matlab code that implements this procedure is shown&nbsp;in section 1.b of the appendix.</p>
<h4><span id="Rotating_the_Satellite_Reference_Frame"><strong>Rotating the Satellite Reference Frame</strong></span></h4>
<p>The user position is being calculated at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6">. The GPS signal left&nbsp;the satellite at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-53e61b63b0c5caf6e15d04ca1f2df168_l3.png" alt="t-\tau" title="Rendered by QuickLaTeX.com" height="12" width="38"> and arrives at the user <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-13197f4653c1fd428a291609eb1e3b87_l3.png" alt="\tau" title="Rendered by QuickLaTeX.com" height="8" width="10"> seconds later. While calculating the user’s position, we’ll calculate the satellite positions at <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-53e61b63b0c5caf6e15d04ca1f2df168_l3.png" alt="t-\tau" title="Rendered by QuickLaTeX.com" height="12" width="38">, the time of signal transmission. In time interval <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-13197f4653c1fd428a291609eb1e3b87_l3.png" alt="\tau" title="Rendered by QuickLaTeX.com" height="8" width="10"> however, the earth has rotated by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f6f5810e926c9069ed4f631433cefb52_l3.png" alt="\omega_E\tau" title="Rendered by QuickLaTeX.com" height="11" width="33"> where <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-071d642730c4e192792b5a5398038e79_l3.png" alt="\omega_E" title="Rendered by QuickLaTeX.com" height="11" width="22"> is the rotation rate of the earth. We must rotate the satellite position vectors by the same amount, so that they are expressed in the user’s reference frame, i.e., ECEF frame at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6">. This is done by multiplying the satellite position vector <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-cb156123d6e90883467626d0c9da056e_l3.png" alt="x^k(t-\tau)" title="Rendered by QuickLaTeX.com" height="19" width="69"> by the following rotation matrix:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-8ca92ffac82f21f3661fc71a53237028_l3.png" alt="x^k(t) = \begin{bmatrix} cos(\omega_E\tau) &amp; sin(\omega_E\tau) &amp; 0 \\ -sin(\omega_E\tau) &amp; cos(\omega_E\tau) &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}x^k(t-\tau)" title="Rendered by QuickLaTeX.com" height="65" width="356"></p>
<p>Note that this is&nbsp;<em>not</em> equivalent to calculating the position of the satellites at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6">!</p>
<h3><span id="Step_2_Computing_the_Distance_of_the_User_from_the_Satellite"><strong>Step 2: Computing the Distance of the User from the Satellite</strong></span></h3>
<p>The satellite signal received by a GPS receiver bears the time stamp at which the signal was sent from the satellite. By taking the difference between its own time and the timestamp of the GPS signal and multiplying by the speed of light, the receiver calculates a rough measure of the distance between the receiver and the satellite. This measure is called the <em>pseudorange</em>.&nbsp;If the clock on the satellite and the receiver were perfectly in sync and the GPS signal traveled in a straight line at the speed of light, then this measure would be the true distance between the satellite and the receiver. This however is not the case and the difference between the satellite and user clocks as well as the delays caused by the atmosphere must be modeled to calculate an&nbsp;accurate position of the user.</p>
<p>Let’s consider first the effect of the offset between the user and satellite clocks. Let’s denote the transmission time from the satellite to the user by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-13197f4653c1fd428a291609eb1e3b87_l3.png" alt="\tau" title="Rendered by QuickLaTeX.com" height="8" width="10"> and a common time reference (referred to as GPS Time (GPST)) by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6">. Denoting the receiver clock bias at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6"> by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b0af0ebe71e01d21082bca51fe8fdbe0_l3.png" alt="\delta{t}_u(t)" title="Rendered by QuickLaTeX.com" height="18" width="43"> and satellite clock bias at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-53e61b63b0c5caf6e15d04ca1f2df168_l3.png" alt="t-\tau" title="Rendered by QuickLaTeX.com" height="12" width="38"> by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-855f6ae6f88c417d1bffde01f0f56a46_l3.png" alt="\delta{t}_s(t-\tau)" title="Rendered by QuickLaTeX.com" height="18" width="73">, the pseudorange <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-39ddf94b3b89b6c0253de9196e094e0d_l3.png" alt="\rho(t)" title="Rendered by QuickLaTeX.com" height="18" width="28"> measured by the GPS receiver is given as:</p>
<p><span> (1) </span><span> &nbsp; </span><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-2d2d2486b0bccdeffbb6eb1a72cb10c0_l3.png" height="19" width="581" alt="\begin{equation*} \rho(t) = c[t+\delta{t}_u(t)-(t-\tau+\delta{t}_s(t))] + \epsilon_\rho(t) = c\tau + c[\delta{t}_u(t)-\delta{t}_s(t)] + \epsilon_\rho(t) \end{equation*}" title="Rendered by QuickLaTeX.com"></p>
<p>If there wasn’t a layer of atmosphere between the satellite and the user, the satellite signal would travel along a straight line with the speed of light. Thus, the distance to the satellite at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6"> denoted by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-8b3b5679da7855ed09a5db590dc2d352_l3.png" alt="r(t, t-\tau)" title="Rendered by QuickLaTeX.com" height="18" width="73">&nbsp;would be equal to <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-35eb675dcb08f01b9dc6e0b33d6e1e0c_l3.png" alt="c\tau" title="Rendered by QuickLaTeX.com" height="8" width="18">.</p>
<p>In reality&nbsp;(thankfully), there is thick layer of atmosphere in the path of the satellite signal which slows it down and bends its path. The change in the path length due to bending of the signal ray is generally not significant. However the change in the speed of propagation can be significant and can result in positioning errors of several meters or more. This change in speed has two components – <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-3796b3eab9bdc7ccd4402f58ccd1eff4_l3.png" alt="I_\rho" title="Rendered by QuickLaTeX.com" height="18" width="15"> arising from the propagation of the signal through the ionosphere and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-6869e0cab400c13080534f18769140dc_l3.png" alt="T_\rho" title="Rendered by QuickLaTeX.com" height="18" width="17"> arising from the propagation of the signal through the troposphere (see appendix for more information about these delays and how they can be estimated). Thus,</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-8afa8a75d8f7aadd04e5ad0f40996460_l3.png" alt="c\tau = r(t, t-\tau) + I_\rho + I_\rho" title="Rendered by QuickLaTeX.com" height="20" width="189"></p>
<p>Combining the above two equations and dropping the reference to measurement epoch <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6">,</p>
<p><span> (2) </span><span> &nbsp; </span><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-a30ad2de80f48c4bab8ea88a66b54f60_l3.png" height="19" width="405" alt="\begin{equation*} \rho(t)  = r(t, t-\tau) + I_\rho + I_\rho + c[\delta{t}_u(t)-\delta{t}_s(t)] + \epsilon_\rho(t) \end{equation*}" title="Rendered by QuickLaTeX.com"></p>
<p>Thus, the true range (actual distance of the user from a satellite) can be calculated from the raw pseudo ranges output by the GPS device by first subtracting the user’s estimate of the Tropo and Iono delays and then adjusting for the satellite clock offset. The Iono and the Tropo delay generally lead to a position error of ~25m and&nbsp;~2m respectively. More information about how to estimate these delays are provided in the appendix. In the rest of our analysis in this blog, we’ll ignore these delays.</p>
<h4><span id="Estimating_the_Satellite_Clock_Bias"><strong>Estimating the Satellite Clock Bias</strong></span></h4>
<p>The satellite clock bias is important to estimate as it can result in a position error of thousands of meters. The procedure to calculate the satellite clock bias is described on page 96 of the GPS Interface Specification document. The procedure consists of evaluating a polynomial whose coefficients are provided in the GPS ephemeris message and adding a relativistic term. The polynomial provides most of the correction, with the relativistic effect contributing about 1-10 m depending on the position of the satellite. The code for calculating the satellite clock bias is given in section 1.d of the appendix.</p>
<h4><span id="User_Clock_Bias"><strong>User Clock Bias</strong></span></h4>
<p>The user clock bias is an unknown quantity, just like the user position. The user clock bias will be estimated along with the user position.</p>
<h3><span id="Step_3_User_Position_and_Clock_Bias_Estimation"><strong>Step 3: User Position and Clock Bias Estimation</strong></span></h3>
<p>We are now ready to look at the algorithm used to compute the user position. A quick point about the notation before we look at the math. Generally, vector quantities are expressed using boldface (<img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-a4997d1a0a6554f7c4b2e41d93ee7fe4_l3.png" alt="\boldsymbol{x}" title="Rendered by QuickLaTeX.com" height="8" width="11">) and scalar quantities without emphasis. However in the math shown below, (mostly due to laziness), I’m skipping making this distinction. I think it is clear from the context which quantities are vectors and which ones are not.</p>
<p>Once the satellite clock bias has been accounted for and all available corrections have been applied, the corrected pseudorange measurement for satellite <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-3422b6bb5c160593658b7c39425d9880_l3.png" alt="k" title="Rendered by QuickLaTeX.com" height="13" width="9"> can be written as</p>
<p><span> (3) </span><span> &nbsp; </span><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b417f2d2c79766ac0b349c11458c4b5d_l3.png" height="21" width="146" alt="\begin{equation*} \rho^k = r^k + c\delta{t}_u + \epsilon^k \end{equation*}" title="Rendered by QuickLaTeX.com"></p>
<p>Here <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f3619b985b23b4bfda475cd10a9a990a_l3.png" alt="r^k" title="Rendered by QuickLaTeX.com" height="15" width="15"> is the true distance between the user and the satellite and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-c3c9e4162609ec2d51efe9d6174b0a5e_l3.png" alt="\epsilon^k" title="Rendered by QuickLaTeX.com" height="15" width="14"> denotes the combined effect of the unmodeled errors. Note that all elements in this equation are distances. We have converted the receiver clock bias <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f7094a1583148b625a2996686ebf4429_l3.png" alt="\delta{t}_u" title="Rendered by QuickLaTeX.com" height="15" width="23"> into a distance by multiplying by the speed of light <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-41a04eeea923a1a0c28094a8a4680525_l3.png" alt="c" title="Rendered by QuickLaTeX.com" height="8" width="8">. Also note that all of these calculations are carried out at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6"> and all position vectors are expressed in the ECEF frame at time <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b4e3cbf5d4c5c6d9b702dd139f14c147_l3.png" alt="t" title="Rendered by QuickLaTeX.com" height="12" width="6">. We drop explicit reference to time for convenience.</p>
<p>Let&nbsp;the position of the user in the ECEF frame be denoted by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ede05c264bba0eda080918aaa09c4658_l3.png" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10">, and the position of satellite <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-3422b6bb5c160593658b7c39425d9880_l3.png" alt="k" title="Rendered by QuickLaTeX.com" height="13" width="9"> by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-81e025d46b78edcab0363d17fe2192ae_l3.png" alt="x^k" title="Rendered by QuickLaTeX.com" height="15" width="17">. Then,</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-2e4acdd9b7a4b6d9e499519567f33ae4_l3.png" alt="r^k = \lVert x^k - x\rVert" title="Rendered by QuickLaTeX.com" height="20" width="106"></p>
<p>and</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-0e5168c5d9a968a25f11dc377856427d_l3.png" alt="\rho_k = \lVert x^k - x\rVert + b + \epsilon^k" title="Rendered by QuickLaTeX.com" height="20" width="174"></p>
<p>We use <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ab39273fac5346ae98fe17505aad3765_l3.png" alt="b = c\delta{t}_u" title="Rendered by QuickLaTeX.com" height="16" width="61"> to represent the user clock bias in units of distance</p>
<p>We wish to determine <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ede05c264bba0eda080918aaa09c4658_l3.png" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f56d50c26583f9a035ff6b4e3c0ca5c0_l3.png" alt="b" title="Rendered by QuickLaTeX.com" height="13" width="8"> that minimize the difference between the measured and the estimated&nbsp;pseudorange for each satellite. In other words, our task is to determine <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ede05c264bba0eda080918aaa09c4658_l3.png" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f56d50c26583f9a035ff6b4e3c0ca5c0_l3.png" alt="b" title="Rendered by QuickLaTeX.com" height="13" width="8"> such that</p>
<p><span> (4) </span><span> &nbsp; </span><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-c885229a8fece7adbb458e0a4276cbfb_l3.png" height="22" width="199" alt="\begin{equation*}\delta{\rho}^k = \rho^k -  (\lVert x^k - x\rVert + b) \end{equation*}" title="Rendered by QuickLaTeX.com"></p>
<p>is minimized for all satellites <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-3422b6bb5c160593658b7c39425d9880_l3.png" alt="k" title="Rendered by QuickLaTeX.com" height="13" width="9">.</p>
<p>This problem is solved using an iterative procedure by starting with an estimate of <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ede05c264bba0eda080918aaa09c4658_l3.png" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f56d50c26583f9a035ff6b4e3c0ca5c0_l3.png" alt="b" title="Rendered by QuickLaTeX.com" height="13" width="8"> and finding the corrections that minimize the equation above. Let our initial estimates be denoted by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-87f2a80bc63f8d7bc3df68c45a787402_l3.png" alt="x_0" title="Rendered by QuickLaTeX.com" height="11" width="17"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-13037b1ccc713463df34f375292ca76e_l3.png" alt="b_0" title="Rendered by QuickLaTeX.com" height="16" width="15">. We wish to find <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-b3f7b57c97fd4b33fbe8b4d14128cf10_l3.png" alt="\delta{x}" title="Rendered by QuickLaTeX.com" height="12" width="19"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-61eba3168a257b831b504ab27b6f69e8_l3.png" alt="\delta{b}" title="Rendered by QuickLaTeX.com" height="13" width="17"> such that the true user position <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-c3cae5612eafb83cfabf5b27e5c0774d_l3.png" alt="x = x_0 + \delta{x}" title="Rendered by QuickLaTeX.com" height="15" width="92"> and the true clock bias <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-4fa77e0aaa257206de03ed1cd019e963_l3.png" alt="b = b_0 + \delta{b}" title="Rendered by QuickLaTeX.com" height="16" width="85"> minimize</p>
<p><span> (5) </span><span> &nbsp; </span><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-783ae5248908ba2cbabca3dd661bdaae_l3.png" height="262" width="458" alt="\begin{equation*} \begin{split} \delta{\rho}^k &amp;= \rho^k -  \rho_0^k  \\ &amp;= \lVert x^k - x\rVert + b - \lVert x^k - x_0\rVert - b_0 + \epsilon^k\\ &amp;= \lVert x^k - x_0 - \delta{x}\rVert + b - \lVert x^k - x_0\rVert - b_0 + \epsilon^k \\ &amp;\approx \lVert x^k - x_0\rVert -\frac{x^k -x_0}{\lVert x^k - x_0\rVert}\cdot\delta{x}+ b - \lVert x^k - x_0\rVert - b_0 + \epsilon^k \\ &amp;= -\frac{x^k -x_0}{\lVert x^k - x_0\rVert}\cdot\delta{x} + \delta{b} + \epsilon^k \\ &amp;= -\hat{x}_{uk}\cdot\delta{x} + \delta{b} + \epsilon^k \\ &amp;= \begin{bmatrix}-\hat{x}_{uk} &amp;  1\end{bmatrix}\begin{bmatrix}\delta{x} \\ \delta{b}\end{bmatrix} + \epsilon^k \end{split} \end{equation*}" title="Rendered by QuickLaTeX.com"></p>
<p>Here <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-66570c7f2ec88e63a1b9650bbd2d433e_l3.png" alt="\hat{x}_{uk}" title="Rendered by QuickLaTeX.com" height="16" width="25"> is the unit vector from the user to satellite <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-3422b6bb5c160593658b7c39425d9880_l3.png" alt="k" title="Rendered by QuickLaTeX.com" height="13" width="9"> and we used the Taylor series expansion of the vector norm (see appendix) to express the delta pseudorange as a matrix multiplication between known and unknown quantities. Concatenating the linear equation developed above for <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ea9c87a513e4a72624155d392fae86e2_l3.png" alt="K" title="Rendered by QuickLaTeX.com" height="12" width="16"> satellites,</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-7269db571bc60968490b77f637534718_l3.png" alt="\boldsymbol{\delta{\rho}} = \begin{bmatrix}\delta{\rho}^1 \\ \delta{\rho}^2 \\ \vdots \\ \delta{\rho}^K \end{bmatrix}  = \begin{bmatrix} -\hat{x}_{u1} &amp;1 \\ -\hat{x}_{u2} &amp;1 \\ \vdots \\ -\hat{x}_{uK} &amp;1\end{bmatrix} \begin{bmatrix}\boldsymbol{\delta{x}} \\ \delta{b} \end{bmatrix} + \boldsymbol{\epsilon}" title="Rendered by QuickLaTeX.com" height="97" width="290"></p>
<p>Setting</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-805aeb706a356dd440043c306cf817c4_l3.png" alt=" \boldsymbol{G}  = \begin{bmatrix} -\hat{x}_{u1} &amp;1 \\ -\hat{x}_{u2} &amp;1 \\ \vdots \\ -\hat{x}_{uK} &amp;1\end{bmatrix}" title="Rendered by QuickLaTeX.com" height="97" width="128"></p>
<p>The expression above can be written more compactly as</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-84613b4b7ae533bb422abac74018aeab_l3.png" alt="\boldsymbol{\delta{\rho}} = \boldsymbol{G}\begin{bmatrix}\boldsymbol{\delta{x}} \\ \delta{b} \end{bmatrix} + \boldsymbol{\epsilon}" title="Rendered by QuickLaTeX.com" height="43" width="133"></p>
<p>For a non-degenerate (<img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-66570c7f2ec88e63a1b9650bbd2d433e_l3.png" alt="\hat{x}_{uk}" title="Rendered by QuickLaTeX.com" height="16" width="25"> are non-coplanar) configuration of <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ea9c87a513e4a72624155d392fae86e2_l3.png" alt="K" title="Rendered by QuickLaTeX.com" height="12" width="16">=4 satellites, the equation above can be solved directly. In general, if the sky is not obstructed, many more satellites are visible, and a exact solution is not available. We can use linear algebra techniques to find a least squares solution:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ec3bc8372fae870a76806f4f9190cb8d_l3.png" alt="\begin{bmatrix}\boldsymbol{\delta{\hat{x}}} \\ \delta{\hat{b}} \end{bmatrix}  = (\boldsymbol{G^T}\boldsymbol{G})^{-1}\boldsymbol{G}^T\boldsymbol{\delta{\rho}}" title="Rendered by QuickLaTeX.com" height="43" width="183"></p>
<p>The hat above the estimated quantities indicates that they are a least squares solution, not an exact solution.</p>
<p>The complete procedure to calculate the user position and clock bias is as follows.</p><!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2a8030626223" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p></div>
				</td>
						<td><div><p>Input: Raw pseudoranges, satellite ephemeris information</p><p>Output: User position in ECEF and user clock bias</p><p>Initialize user clock bias = 0, user position = [0 0 0] (amazing that this works!)</p><p>For each satellite:</p><p>	1. Calculate satellite clock bias</p><p>	2. Correct measured pseudorange by the calculated satellite clock bias</p><p>	3. Apply ionospheric and tropospheric corrections if available</p><p>	End For</p><p>Do until change in user clock bias, user position &lt; threshold</p><p>	For each satellite:</p><p>		1. Correct pseudorange by current estimate of the user clock bias</p><p>		2. Calculate signal transmission time tau by dividing pseudorange by speed of light</p><p>		3. Calculate satellite position at t-tau</p><p>		4. Rotate satellite position by earth's rotation in time tau to align with user's ECEF frame at time t</p><p>		5. Form G matrix by concatenating unit vectors from the user to the satellite</p><p>		6. Calculate delta pseudoranges by taking the difference between the corrected pesudorange (step 1) and expected pseudorange, given the current estimate of the user's position and user clock bias</p><p>	End For</p><p>	Solve for corrections in user position and clock bias and calculate new user position and clock bias</p><p>End Do</p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0001 seconds] -->

<h2><span id="Note_about_the_Matlab_Code"><strong>Note about the Matlab Code</strong></span></h2>
<p>It is worth noting that while most of the equations in the Matlab code shown in the Appendix involve evaluation of expressions where the known quantities are on the right&nbsp;hand side and unknown quantities on the left&nbsp;hand side (and thus can be evaluated in one step), there are a few that requires invocation of a solver. One example is the calculation of the <em>eccentric anomaly (E)</em> from the&nbsp;<em>mean anomaly (M)</em>&nbsp;required during the calculation of the satellite position from ephemeris parameters<em>. </em>The relation between the two is expressed as:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-a66bec286a3f81bd3fe7848babdff8ee_l3.png" alt="M = E-eSin(E)" title="Rendered by QuickLaTeX.com" height="18" width="142"></p>
<p>where <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-3fc193f43cc29c1eef788f64ba43c1bd_l3.png" alt="e" title="Rendered by QuickLaTeX.com" height="8" width="8"> is the eccentricity of the earth’s orbit. Typically, <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-10ebb71bad275c1815a8f2a8c5dea0be_l3.png" alt="M" title="Rendered by QuickLaTeX.com" height="12" width="19"> is calculated first, and calculating <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-764e1c770271f92700e1a4fbce46c668_l3.png" alt="E" title="Rendered by QuickLaTeX.com" height="12" width="14"> from <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-10ebb71bad275c1815a8f2a8c5dea0be_l3.png" alt="M" title="Rendered by QuickLaTeX.com" height="12" width="19"> can’t be done in closed form and requires the use of a solver. Part of the code is shown below.</p><!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2b2014958308" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>% mk: Mean anomaly</span></p><p><span>	</span><span>% solve for eccentric anomaly</span></p><p><span>	</span><span>syms</span><span> </span><span>E</span><span>;</span></p><p><span>	</span><span>eqn</span><span> </span><span>=</span><span> </span><span>E</span><span> </span><span>-</span><span> </span><span>eph</span><span>.</span><span>e</span><span>*</span><span>sin</span><span>(</span><span>E</span><span>)</span><span> </span><span>==</span><span> </span><span>mk</span><span>;</span></p><p><span>	</span><span>solx</span><span> </span><span>=</span><span> </span><span>vpasolve</span><span>(</span><span>eqn</span><span>,</span><span> </span><span>E</span><span>)</span><span>;</span></p><p><span>	</span><span>Ek</span><span> </span><span>=</span><span> </span><span>double</span><span>(</span><span>solx</span><span>)</span><span>;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0004 seconds] -->

<h2><span id="Experimental_Setup"><strong>Experimental Setup</strong></span></h2>
<p>In this section, I’ll describe the hardware setup I used to collect raw GPS data which was then processed using the algorithms described above to calculate user position and clock bias. An interested user should be able to easily replicate my setup using cheap and commercially available GPS receivers and open source software.</p>
<p id="LbeRFAZ"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596a46e63a510.png" alt="" width="827" height="462" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596a46e63a510.png 1296w, https://www.telesens.co/wp-content/uploads/2017/07/img_596a46e63a510-300x168.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_596a46e63a510-768x430.png 768w, https://www.telesens.co/wp-content/uploads/2017/07/img_596a46e63a510-1024x573.png 1024w" sizes="(max-width: 827px) 100vw, 827px"></p>
<p>The figure above shows the main steps involved in my setup. For collecting raw GPS data, special GPS units that output “timing” information consisting of raw pseudoranges and satellite ephemeris information must be used. Regular GPS units calculate the user position internally and don’t output the raw data we need to calculate the user position using the algorithm described above. The NEO-M8T and 6T chips from u-blox fit our needs. Complete hardware assemblies with the GPS unit, antennae and serial output port can be purchased from Amazon for ~40 dollars.</p>
<p>In order to receive and save the raw GPS signal, I use the STRSVR utility in RTKLib (RTKLIB is an open source program package for standard and precise positioning that supports all common Global Navigation Satellite Systems (GNSS) – GPS, Glonass, Galileo, Baidu etc. See: http://www.rtklib.com). STRSVR takes the custom u-blox formatted output from the u-blox receiver and converts it into RTCM standard format. RTCM (Radio Technical Commission for Maritime Services, see:&nbsp;http://www.rtcm.org/differential-global-navigation-satellite–dgnss–standards.html) is a standard for GNSS data and content designed to support a variety of GNSS applications in air/land/sea navigation, surveying, radio navigation/location etc.</p>
<p>RTCM standard provides the definition of various messages that provide specific GPS information. The information we are interested in are the raw pseudoranges and satellite ephemeris. This information is contained in messages 1002 and 1019.</p>
<p id="IiqmPJz"><img decoding="async" loading="lazy" width="632" height="256" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596a51ec3f302.png" alt="" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596a51ec3f302.png 632w, https://www.telesens.co/wp-content/uploads/2017/07/img_596a51ec3f302-300x122.png 300w" sizes="(max-width: 632px) 100vw, 632px"></p>
<figure id="attachment_1195" aria-describedby="caption-attachment-1195"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596a5285a04d8-1.png" alt="" width="656" height="408"><figcaption id="caption-attachment-1195">Part of GPS 1019 message content</figcaption></figure>
<p>We must request the u-blox receiver to send 1002 and 1019 message information as part of the data it sends to STRSVR. This is done by using the following commands in the Cmd window:</p>
<p><img decoding="async" loading="lazy" width="320" height="291" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596a6a793e425.png" alt="" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596a6a793e425.png 320w, https://www.telesens.co/wp-content/uploads/2017/07/img_596a6a793e425-300x273.png 300w" sizes="(max-width: 320px) 100vw, 320px"></p>
<p id="xRnVGKT"><img decoding="async" loading="lazy" width="361" height="136" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596a6e6a5f6ea.png" alt="" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596a6e6a5f6ea.png 361w, https://www.telesens.co/wp-content/uploads/2017/07/img_596a6e6a5f6ea-300x113.png 300w" sizes="(max-width: 361px) 100vw, 361px"></p>
<p>The first command sets the update rate to 1Hz and the other two enable RAW messages. The details on how this happens are a bit murky. I tried going through parts of the UBX documentation to understand this better but soon got lost. Suffices to say that&nbsp;the above commands work and cause the receiver to send the data we need.</p>
<p>I configure the STRSVR utility to receive data from the serial port at 9600 Baud and save the data to a file in RTCM 3 format.</p>
<p id="gJaMZIH"><img decoding="async" loading="lazy" width="386" height="239" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596a6bca9c3a5.png" alt="" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596a6bca9c3a5.png 386w, https://www.telesens.co/wp-content/uploads/2017/07/img_596a6bca9c3a5-300x186.png 300w" sizes="(max-width: 386px) 100vw, 386px"></p>
<p>To collect the data, I went to the roof of my apartment building and placed the GPS receiver at a location where it could get an unobstructed view of the sky. I used the u-blox configuration software (https://www.u-blox.com/en/product/u-center-windows) to verify that a sufficient number of satellites were visible and a good position fix could be obtained. I then used STRSVR to collect about an hour of raw GPS data and saved the data to a file.</p>
<h3><span id="Processing_Raw_GPS_Data"><strong>Processing Raw GPS Data</strong></span></h3>
<p>STRSVR saves the raw GPS data into binary RTCM3 format. We must decode the RTCM3 data to create Matlab data structures out of it. I considered writing my own RTCM decoder, but then found an excellent Matlab library called goGPS (http://www.gogps-project.org/about/) that provides many useful routines to read and process GPS data. I used the <em>load_stream&nbsp;</em>function that reads an RTCM formatted file and extracts the RTCM messages (line 95 in my version of goGPS). I then saved the extracted data to a .mat file to serve as input to my the&nbsp;position calculation algorithm that implements the&nbsp;equations above. The Matlab code is shown in the section 1.a of the appendix. I’m also attaching the <a href="https://www.telesens.co/wp-content/uploads/2017/07/rtcm_data.txt">rtcm_data</a> since many people have asked for it. I changed the file extension from .mat to .txt due to wordpress security restrictions. Rename the file back to .mat when you download it.</p>
<h3><span id="Analysis_of_Results"><strong>Analysis of Results</strong></span></h3>
<p>In this section, I’ll analyze the positions and clock bias computed by my algorithms. We will look at the variation of the north/east/up components of the position with time, variation of the clock bias with time and introduce the concept of Dilution of Precision (DOP), a common metric used to measure the quality of GPS position estimates. Since the GPS receiver was stationary during data collection, the variation of the calculated position reflects the true performance of the algorithm used to calculate the position.</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596f9dca86337.png" alt="" width="400" height="300" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596f9dca86337.png 560w, https://www.telesens.co/wp-content/uploads/2017/07/img_596f9dca86337-300x225.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_596f9dca86337-326x245.png 326w, https://www.telesens.co/wp-content/uploads/2017/07/img_596f9dca86337-80x60.png 80w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p id="ePLPPGW"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596f9f8e645ca.png" alt="" width="407" height="300"></p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596f9fd1b66c4.png" alt="" width="404" height="300"></p>
<p id="yLnCUqY"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596fa0fbd7351.png" alt="" width="408" height="300"></p>
<table>
<tbody>
<tr>
<td></td>
<td><strong>East</strong></td>
<td><strong>North</strong></td>
<td><strong>Up</strong></td>
</tr>
<tr>
<td><strong>Std-Dev</strong></td>
<td>14.00</td>
<td>39.88</td>
<td>47.35</td>
</tr>
</tbody>
</table>
<p>The plot of E/N/U components of the user position in a user centered ENU frame along with the position scatter plot are shown above.&nbsp;As expected, the variation in position is around 30m in the East and North direction and slightly higher along the Up direction. We’ll explain the reason for this during the discussion about DOP (Dilution of Precision) below.</p>
<h3><span id="Clock_Bias_Drift"><strong>Clock Bias Drift</strong></span></h3>
<p>The variation of the receiver clock bias against time is shown below. Note that the clock bias <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f56d50c26583f9a035ff6b4e3c0ca5c0_l3.png" alt="b" title="Rendered by QuickLaTeX.com" height="13" width="8"> used in the algorithm above is in the unit of distance. In the plot below, the bias has been converted into unit of time by dividing by the speed of light.</p>
<p id="kIXLhey"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_596feb0fa18f7.png" alt="" width="396" height="297" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_596feb0fa18f7.png 560w, https://www.telesens.co/wp-content/uploads/2017/07/img_596feb0fa18f7-300x225.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_596feb0fa18f7-326x245.png 326w, https://www.telesens.co/wp-content/uploads/2017/07/img_596feb0fa18f7-80x60.png 80w" sizes="(max-width: 396px) 100vw, 396px"></p>
<p>We can see that the clock bias is not a constant but drifts linearly with time. The amount of drift is 4.27 e-7sec/sec.</p>
<h3><span id="Computing_the_Satellite_AzimuthElevation"><strong>Computing the Satellite Azimuth/Elevation</strong></span></h3>
<p>As an exercise, let’s compute the azimuth and elevation of all the satellites visible at a given time instant. This will neatly tie in many of the ideas discussed above and also provide a good segue to discussing DOP.</p>
<p>Azimuth and elevation angles are calculated from the perspective of the user. Thus, they are expressed in an ENU frame centered about the user position.</p>
<p id="mBvVNhj"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_5970cfb6788fd.png" alt="" width="363" height="265" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_5970cfb6788fd.png 572w, https://www.telesens.co/wp-content/uploads/2017/07/img_5970cfb6788fd-300x219.png 300w" sizes="(max-width: 363px) 100vw, 363px"></p>
<p>If the position of the satellite in the user centered ENU frame is (<img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-922e816fa375e151e481b54a0af72edf_l3.png" alt="x_s, y_s, z_s" title="Rendered by QuickLaTeX.com" height="12" width="63">), then the azimuth (az) and elevation (el) is given by:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-3488656b0f50a2944474cc2ea270dab7_l3.png" alt="tan(az) = \frac{x_E}{x_N}" title="Rendered by QuickLaTeX.com" height="22" width="103"></p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-1ae0238546d407df3363857243a6a0c6_l3.png" alt="sin(el) = \frac{x_U}{\sqrt{x_E^2 + x_N^2 + x_U^2}}" title="Rendered by QuickLaTeX.com" height="29" width="169"></p>
<p>The procedure to extract azimuth and elevation from&nbsp;satellite and user positions (calculated in the ECEF frame) is as follows:</p>
<ol>
<li>Calculate the position vector from the user to the satellite (in ECEF frame)</li>
<li>Calculate the user position in Ellipsoidal coordinates (lat/lng)</li>
<li>Rotate&nbsp;the position vector to the ENU frame centered about the user position</li>
<li>Calculate azimuth/elevation using equations above)</li>
</ol>
<p>The Matlab code is shown below:</p><!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2ba298046667" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>	</span><span>function</span><span> </span><span>[</span><span>az </span><span>el</span><span>]</span><span> </span><span>=</span><span> </span><span>get_satellite_az_el</span><span>(</span><span>xs</span><span>,</span><span>ys</span><span>,</span><span>zs</span><span>,</span><span>xu</span><span>,</span><span>yu</span><span>,</span><span>zu</span><span>)</span></p><p><span>	</span><span>% get_satellite_az_el: computes the satellite azimuth and elevation given</span></p><p><span>	</span><span>% the position of the user and the satellite in ECEF</span></p><p><span>	</span><span>% Usage: [az el] = get_satellite_az_el(xs,ys,zs,xu,yu,zu)</span></p><p><span>	</span><span>% Input Args: xs,ys,zs: satellite position in ECEF</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;xu,yu,zu: user position in ECEF&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p><span>	</span><span>% Output Args: azimuth and elevation</span></p><p><span>	</span><span>[</span><span>lambda</span><span>,</span><span> </span><span>phi</span><span>,</span><span> </span><span>h</span><span>]</span><span> </span><span>=</span><span> </span><span>WGStoEllipsoid</span><span>(</span><span>xu</span><span>,</span><span>yu</span><span>,</span><span>zu</span><span>)</span><span>;</span></p><p><span>	</span><span>lat</span><span> </span><span>=</span><span> </span><span>phi</span><span>*</span><span>180</span><span>/</span><span>pi</span><span>;</span></p><p><span>	</span><span>lng</span><span> </span><span>=</span><span> </span><span>lambda</span><span>*</span><span>180</span><span>/</span><span>pi</span><span>;</span></p><p><span>	</span><span>enu</span><span> </span><span>=</span><span>Rotxyz2enu</span><span>(</span><span>[</span><span>xs</span><span>-</span><span>xu</span><span>,</span><span>ys</span><span>-</span><span>yu</span><span>,</span><span>zs</span><span>-</span><span>zu</span><span>]</span>'<span>,</span><span> </span><span>lat</span><span>,</span><span> </span><span>lng</span><span>)</span><span>;</span></p><p><span>	</span><span>az</span><span> </span><span>=</span><span> </span><span>atan2</span><span>(</span><span>enu</span><span>(</span><span>1</span><span>)</span><span>,</span><span> </span><span>enu</span><span>(</span><span>2</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>el</span><span> </span><span>=</span><span> </span><span>asin</span><span>(</span><span>enu</span><span>(</span><span>3</span><span>)</span><span>/</span><span>norm</span><span>(</span><span>enu</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>% The azimuth and elevation</span></p><p><span>	</span><span>end</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0008 seconds] -->
<p>The computed azimuth and elevations at a given epoch are shown in the table and the corresponding 3D positions in the ENU frame are shown in the plot below</p>
<table>
<tbody>
<tr>
<td><strong>Azimuth</strong></td>
<td><strong>Elevation</strong></td>
</tr>
<tr>
<td>69.68</td>
<td>62.89</td>
</tr>
<tr>
<td>-20.46</td>
<td>81.63</td>
</tr>
<tr>
<td>96.38</td>
<td>16.91</td>
</tr>
<tr>
<td>34.71</td>
<td>5.21</td>
</tr>
<tr>
<td>-145.06</td>
<td>12.59</td>
</tr>
<tr>
<td>-165.22</td>
<td>7.44</td>
</tr>
<tr>
<td>-110.29</td>
<td>39.03</td>
</tr>
<tr>
<td>-49.30</td>
<td>43.11</td>
</tr>
</tbody>
</table>

<p id="TnqpjKv"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_5970c0f84a780.png" alt="" width="471" height="353" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_5970c0f84a780.png 560w, https://www.telesens.co/wp-content/uploads/2017/07/img_5970c0f84a780-300x225.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_5970c0f84a780-326x245.png 326w, https://www.telesens.co/wp-content/uploads/2017/07/img_5970c0f84a780-80x60.png 80w" sizes="(max-width: 471px) 100vw, 471px"></p>
<p>As can be seen the azimuth angles are both positive and negative, while the elevations are only positive. This makes sense as the user can’t see the satellites below the horizon.</p>
<p>You may have seen satellite track charts that many GPS processing software output as a visualization aid. Those charts are created by calculating the satellite positions using the procedure described here at multiple epochs.</p>
<h3><span id="Dilution_of_Precision_DOP"><strong>Dilution of Precision (DOP)</strong></span></h3>
<p>DOP helps us answer the question, “how good are my position estimates”? There are two components of the errors in our position estimate. The first one is the measurement noise, which is obvious. The noisier our measurements (pseudorange, satellite position etc), higher are the expected position errors. However, there is another, less obvious component of the positioning errors. This component is the user-satellite geometry. As explained in chapter 6 of&nbsp;<span id="tHKOjIChb0k2x6wRSOpd8" data-reflist="[&quot;a5of4cpcm&quot;]" data-footnote="undefined"><sup>1</sup></span>, it the easiest to see this in a 2D example.</p>
<p>A user measures his distance from a pair of signal sources&nbsp;S1 and S2 at known locations. If the range measurements were perfect, the user could determine his position exactly as lying on the intersection of two circles centered on S1 and S2 and radii equal to the measured ranges. The measurements however are imperfect and have a maximum uncertainty of <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-8e666c43aae0c51eb5a09d25b03580e3_l3.png" alt="\pm\epsilon" title="Rendered by QuickLaTeX.com" height="12" width="21">. The figure below shows how the user-source&nbsp;geometry affects the amount of uncertainty in the user position.</p>
<p id="NwJvwTM"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_597119048b1e1.png" alt="" width="714" height="421" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_597119048b1e1.png 1170w, https://www.telesens.co/wp-content/uploads/2017/07/img_597119048b1e1-300x177.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_597119048b1e1-768x453.png 768w, https://www.telesens.co/wp-content/uploads/2017/07/img_597119048b1e1-1024x604.png 1024w" sizes="(max-width: 714px) 100vw, 714px"></p>
<p>The uncertainty in the position and clock bias is measured by the covariance of the estimated position and clock bias error. Representing the true position and clock bias by <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ede05c264bba0eda080918aaa09c4658_l3.png" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f56d50c26583f9a035ff6b4e3c0ca5c0_l3.png" alt="b" title="Rendered by QuickLaTeX.com" height="13" width="8">, the position and clock bias estimation errors are given as:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-2c8255ccf11fb6dc3802c85901c325d6_l3.png" alt="\delta{x} = \hat{x}-x" title="Rendered by QuickLaTeX.com" height="13" width="84"></p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-75b68cffe0686467a5068d7a783500cf_l3.png" alt="\delta{b} = \hat{b}-b" title="Rendered by QuickLaTeX.com" height="18" width="77"></p>
<p>Where <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-93476800dd4074d15d6c47e1edd10bbd_l3.png" alt="\hat{x}" title="Rendered by QuickLaTeX.com" height="13" width="10"> and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-516d63b88012bc33d5c2749908ca03fe_l3.png" alt="\hat{b}" title="Rendered by QuickLaTeX.com" height="18" width="8"> are our estimates of the user position and clock bias (calculated using the algorithm above). As shown in chapter 6 of&nbsp;<span id="a2qc0vdqc40" data-reflist="[&quot;a5of4cpcm&quot;]" data-footnote="undefined"><sup>1</sup></span>, the covariance matrix of position and clock bias is given as:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-4906ae1aec2fefb4cb3a4572f20fa93b_l3.png" alt="Cov\begin{bmatrix}\delta{x} \\ \delta{b} \end{bmatrix} = \sigma^2(G^{T}G)^{-1}" title="Rendered by QuickLaTeX.com" height="43" width="184"></p>
<p>Here <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-1c9cc40f96a1492e298e7da85a2c1692_l3.png" alt="\sigma" title="Rendered by QuickLaTeX.com" height="8" width="11"> is the “user range error” which captures the uncertainty in the pseudoranges and satellite positions. The <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-30a79c32f18567063fe44716929e7ced_l3.png" alt="G" title="Rendered by QuickLaTeX.com" height="12" width="14"> matrix is the matrix consisting of the unit vectors from the user to the satellite that we saw earlier. This matrix depends entirely on the user-satellite geometry. Thus, the covariance can be neatly factored into a product of measurement uncertainty and a function of the user-satellite geometry matrix. The elements of the G matrix are expressed in the ECEF frame. It is more convenient to rotate it into the user’s local ENU frame. Let <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ee351c21087c19a812cbb826be37bfc9_l3.png" alt="R_L" title="Rendered by QuickLaTeX.com" height="15" width="22"> be the required rotation matrix and <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-cbb1278ece14000764b020b099e22459_l3.png" alt="\tilde{G}" title="Rendered by QuickLaTeX.com" height="16" width="14"> be the resulting geometry matrix.</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-7c1784d95cd84a75737e6cd27eeaf054_l3.png" alt="\tilde{G} = [G(1:N, 1:3)R_L^{T}, ones(N,1)]" title="Rendered by QuickLaTeX.com" height="21" width="266"></p>
<p>Here <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-5793832f979c2268e3694c246d53b1bb_l3.png" alt="N" title="Rendered by QuickLaTeX.com" height="12" width="16"> is the number of satellites. The rotation is applied to the position components of the geometry matrix. it can be easily shown that</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-4a852686b668bf94696e52228f8f8ee3_l3.png" alt="Cov\begin{bmatrix}\delta{x_{ENU}} \\ \delta{b}\end{bmatrix} = \sigma^2(\tilde{G^{T}}\tilde{G})^{-1}" title="Rendered by QuickLaTeX.com" height="43" width="218"></p>
<p>Setting</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-729bfc8822b12871ec3cc7f1105e545a_l3.png" alt="H =  (\tilde{G^{T}}\tilde{G})^{-1}" title="Rendered by QuickLaTeX.com" height="22" width="109">,</p>
<p>The East, North and Up components of DOP are defined as</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-2af33fcb3f07e0bb1b95419c60db7c8d_l3.png" alt="\sigma_E^2 = H_{11}, \sigma_N^2 = H_{22}, \sigma_U^2 = H_{33}" title="Rendered by QuickLaTeX.com" height="20" width="241"></p>
<p>We can further define a horizontal DOP (HDOP) by combining the E and N term (since the East and North directions define the horizontal plane at the user’s location) and vertical DOP (VDOP) consisting of the U term.</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-1a6b03b14834741715f9da8ba91d4807_l3.png" alt="HDOP = \sqrt{\sigma_E^2 + \sigma_N^2}" title="Rendered by QuickLaTeX.com" height="33" width="168"></p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-80b398a49581931360b68eee0c447bd3_l3.png" alt="VDOP = \sqrt{\sigma_U^2}" title="Rendered by QuickLaTeX.com" height="33" width="121"></p>
<p>DOP provides a simple characterization of the user-satellite geometry. The more favourable the geometry, the lower the DOP. More favourable means the satellites are spread apart in azimuth and elevation. The lower the DOP and user range error (<img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-1c9cc40f96a1492e298e7da85a2c1692_l3.png" alt="\sigma" title="Rendered by QuickLaTeX.com" height="8" width="11">), the better the quality of the position estimate. To understand the relationship between DOP and satellite geometry better, lets consider two simple examples. The first example looks at the variation between DOP and the angle between the satellite vectors in a three satellite configuration shown in the figure below.&nbsp;The first satellite is located along the y axis and the other two are located symmetrically about the y axis, at an angle <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-356a08e839ab6974a16448e16e56745d_l3.png" alt="\theta" title="Rendered by QuickLaTeX.com" height="12" width="9"> from the x-axis. The G matrix and the plot of DOP against angle theta is shown below.</p>
<p id="GdfqXDP"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_5977b02c97abe.png" alt="" width="396" height="259" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_5977b02c97abe.png 673w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977b02c97abe-300x197.png 300w" sizes="(max-width: 396px) 100vw, 396px"></p>
<p id="yOumZOA"><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_5977afe75ae67.png" alt="" width="377" height="282" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_5977afe75ae67.png 560w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977afe75ae67-300x225.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977afe75ae67-326x245.png 326w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977afe75ae67-80x60.png 80w" sizes="(max-width: 377px) 100vw, 377px"></p>

<p>The minimum DOP occurs at <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-e3adde1d8b3cea9acd70eb1f0a973637_l3.png" alt="\theta = -30^o" title="Rendered by QuickLaTeX.com" height="12" width="71">. This makes intuitive sense as at this angle, the satellites are maximally separated from each other. Note that the DOP does not vary symmetrically with positive and negative <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-356a08e839ab6974a16448e16e56745d_l3.png" alt="\theta" title="Rendered by QuickLaTeX.com" height="12" width="9">. This is because for a given <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-356a08e839ab6974a16448e16e56745d_l3.png" alt="\theta" title="Rendered by QuickLaTeX.com" height="12" width="9">, the separation between the satellite vectors is higher for a negative value than for a positive value.</p>
<p>Next let’s look at a more realistic example of four satellites located in 3D. First satellite is located at the zenith and the others three are located 120 degrees apart in azimuth and at an elevation of <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-356a08e839ab6974a16448e16e56745d_l3.png" alt="\theta" title="Rendered by QuickLaTeX.com" height="12" width="9"> (same for the three satellites). We’ll look at the variation of VDOP with the elevation angle.</p>

<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_5977b85448684.png" alt="" width="321" height="344" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_5977b85448684.png 609w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977b85448684-279x300.png 279w" sizes="(max-width: 321px) 100vw, 321px"></p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/uploads/2017/07/img_5977b9d372ee2.png" alt="" width="441" height="331" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_5977b9d372ee2.png 560w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977b9d372ee2-300x225.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977b9d372ee2-326x245.png 326w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977b9d372ee2-80x60.png 80w" sizes="(max-width: 441px) 100vw, 441px"></p>
<p>As expected, the VDOP decreases with increasing elevation angle, as the satellites get farther apart from each other. It continues to decrease as the elevation goes past the horizon (elevation = 90 degrees). Since a user located on the earth surface can’t observe satellites below the horizon (in fact, signal from satellites &lt; 10 degrees above the horizon are too noisy and generally not used), the minimum value of VDOP is not achievable. This example demonstrates why VDOP is generally higher than HDOP.</p>
<p>Let’s now look at the variation of HDOP and VDOP with time calculated by our position algorithm on real data.</p>
<p id="RsMgfPx"><img decoding="async" loading="lazy" width="560" height="420" src="https://www.telesens.co/wp-content/uploads/2017/07/img_5977c10f6a387.png" alt="" srcset="https://www.telesens.co/wp-content/uploads/2017/07/img_5977c10f6a387.png 560w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977c10f6a387-300x225.png 300w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977c10f6a387-326x245.png 326w, https://www.telesens.co/wp-content/uploads/2017/07/img_5977c10f6a387-80x60.png 80w" sizes="(max-width: 560px) 100vw, 560px"></p>
<p>No surprises here. The HDOP/VDOP values are generally &lt; 2.5, which is considered adequate and as expected, VDOP is higher than HDOP.</p>
<p>This concludes the post! I hope that next time you use Google maps to get directions, you’ll think about the incredible scientists, engineers and policy makers who have given us this incredible system that makes possible so many applications that we now take for granted. According to&nbsp;<span id="a16itk3rudh" data-reflist="[&quot;a5of4cpcm&quot;]" data-footnote="undefined"><sup>1</sup></span>, the GPS constellation cost about 30 billion dollars to put in place and costs the US government about 1B annually to maintain. The valuation of Uber alone, which wouldn’t exist without GPS is upwards of 70B dollars. When you include all of the other amazing applications made possible by GPS, the public investment in GPS appears to be one of the best public investments ever made! 🙂</p>
<h2><span id="Appendix"><strong>Appendix</strong></span></h2>
<h3><span id="1a_Code_for_Calculating_User_Position_and_Clock_Bias"><strong>1.a Code for Calculating User Position and Clock Bias</strong></span></h3>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2c4614419964" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p><p>49</p><p>50</p><p>51</p><p>52</p><p>53</p><p>54</p><p>55</p><p>56</p><p>57</p><p>58</p><p>59</p><p>60</p><p>61</p><p>62</p><p>63</p><p>64</p><p>65</p><p>66</p><p>67</p><p>68</p><p>69</p><p>70</p><p>71</p><p>72</p><p>73</p><p>74</p><p>75</p><p>76</p><p>77</p><p>78</p><p>79</p><p>80</p><p>81</p><p>82</p><p>83</p><p>84</p><p>85</p><p>86</p><p>87</p><p>88</p><p>89</p><p>90</p><p>91</p><p>92</p><p>93</p><p>94</p><p>95</p><p>96</p><p>97</p><p>98</p><p>99</p><p>100</p><p>101</p><p>102</p><p>103</p><p>104</p><p>105</p><p>106</p><p>107</p><p>108</p><p>109</p><p>110</p><p>111</p><p>112</p><p>113</p><p>114</p><p>115</p><p>116</p><p>117</p><p>118</p><p>119</p><p>120</p><p>121</p><p>122</p><p>123</p><p>124</p><p>125</p><p>126</p><p>127</p><p>128</p><p>129</p><p>130</p><p>131</p><p>132</p><p>133</p><p>134</p><p>135</p><p>136</p><p>137</p><p>138</p><p>139</p><p>140</p><p>141</p><p>142</p><p>143</p><p>144</p><p>145</p><p>146</p><p>147</p><p>148</p><p>149</p><p>150</p><p>151</p><p>152</p><p>153</p><p>154</p><p>155</p><p>156</p><p>157</p><p>158</p><p>159</p><p>160</p><p>161</p><p>162</p><p>163</p><p>164</p><p>165</p><p>166</p><p>167</p><p>168</p><p>169</p><p>170</p><p>171</p><p>172</p><p>173</p><p>174</p><p>175</p><p>176</p><p>177</p><p>178</p><p>179</p><p>180</p><p>181</p><p>182</p><p>183</p><p>184</p><p>185</p><p>186</p><p>187</p><p>188</p><p>189</p><p>190</p><p>191</p><p>192</p><p>193</p></div>
				</td>
						<td><div><p><span>	</span><span>% Constants that we will need</span></p><p><span>	</span><span>% Speed of light</span></p><p><span>	</span><span>c</span><span> </span><span>=</span><span> </span><span>299792458</span><span>;</span></p><p><span>	</span><span>% Earth's rotation rate</span></p><p><span>	</span><span>omega_e</span><span> </span><span>=</span><span> </span><span>7.2921151467e</span><span>-</span><span>5</span><span>;</span><span> </span><span>%(rad/sec)</span></p><p><span>	</span><span>% load out data</span></p><p><span>	</span><span>data</span><span> </span><span>=</span><span> </span><span>load</span><span>(</span><span>'rtcm_data.mat'</span><span>)</span><span>;</span></p><p><span>	</span><span>% Data is a cell array containing data about different RTCM messages. We</span></p><p><span>	</span><span>% are interested in 1002 and 1019</span></p><p><span>	</span><span>% msgs is a an array of message ids (1002, 1019 etc)</span></p><p><span>	</span><span>msgs</span><span> </span><span>=</span><span> </span><span>[</span><span>data</span><span>.</span><span>data</span><span>{</span><span>1</span><span>,</span><span>:</span><span>}</span><span>]</span><span>;</span></p><p><span>	</span><span>% Get indicies of ephemeris info (msg 1019)</span></p><p><span>	</span><span>[</span><span>idx_1019</span><span>]</span><span> </span><span>=</span><span> </span><span>find</span><span>(</span><span>msgs</span><span> </span><span>==</span><span> </span><span>1019</span><span>)</span><span>;</span></p><p><span>	</span><span>% Get indicies of raw pseudorange info (msg 1002)</span></p><p><span>	</span><span>[</span><span>idx_1002</span><span>]</span><span> </span><span>=</span><span> </span><span>find</span><span>(</span><span>msgs</span><span> </span><span>==</span><span> </span><span>1002</span><span>)</span><span>;</span></p><p><span>	</span><span>% Satellite ephemeris data is all mixed up since different satellites are visible at</span></p><p><span>	</span><span>% different epocks.</span></p><p><span>	</span><span>eph</span><span> </span><span>=</span><span> </span><span>[</span><span>data</span><span>.</span><span>data</span><span>{</span><span>2</span><span>,</span><span> </span><span>idx_1019</span><span>}</span><span>]</span><span>;</span></p><p><span>	</span><span>% Lets group data for each satellite</span></p><p><span>	</span><span>% find unique satellite indicies</span></p><p><span>	</span><span>sv_arr</span><span> </span><span>=</span><span> </span><span>unique</span><span>(</span><span>eph</span><span>(</span><span>1</span><span>,</span><span>:</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>% eph_data will contain ephemeris data for all epochs grouped by satellite</span></p><p><span>	</span><span>% number</span></p><p><span>	</span><span>eph_data</span><span> </span><span>=</span><span> </span><span>{</span><span>}</span><span>;</span></p><p><span>	</span><span>for</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>1</span><span>:</span><span> </span><span>length</span><span>(</span><span>sv_arr</span><span>)</span></p><p><span>		</span><span>% find indicies of all entries corresponding to this satellite</span></p><p><span>		</span><span>sv</span><span> </span><span>=</span><span> </span><span>sv_arr</span><span>(</span><span>i</span><span>)</span><span>;</span></p><p><span>		</span><span>idx</span><span> </span><span>=</span><span> </span><span>find</span><span>(</span><span>eph</span><span>(</span><span>1</span><span>,</span><span>:</span><span>)</span><span> </span><span>==</span><span> </span><span>sv</span><span>)</span><span>;</span></p><p><span>		</span><span>eph_data</span><span>{</span><span>sv</span><span>}</span><span> </span><span>=</span><span> </span><span>eph</span><span>(</span><span>:</span><span>,</span><span>idx</span><span>)</span><span>;</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>% Now let's deal with 1002 messages. 1002 messages have two entries - first</span></p><p><span>	</span><span>% one (nav1) is a 6*1 array containing: reference station id, receiver time</span></p><p><span>	</span><span>% of week, number of satellites etc. See decode_1002.m in goGPS for details</span></p><p><span>	</span><span>% The important pieces of info in nav1 are the receiver time of week and the</span></p><p><span>	</span><span>% number of satellites visible</span></p><p><span>	</span><span>% The second one (nav2) contains a block of 56*5 for every epoch.</span></p><p><span>	</span><span>% Num of rows (56) refers to the maximum number of satellites in the</span></p><p><span>	</span><span>% constellation. Num of cols (5) is the number of data elements for each satellite.</span></p><p><span>	</span><span>% We are interested in the second element, the raw pseudorange.</span></p><p><span>	</span><span>% For those satellites for which no info is available,</span></p><p><span>	</span><span>% the rows of nav2 contain 0s.</span></p><p><span>	</span><span>nav1</span><span> </span><span>=</span><span> </span><span>[</span><span>data</span><span>.</span><span>data</span><span>{</span><span>2</span><span>,</span><span> </span><span>idx_1002</span><span>}</span><span>]</span><span>;</span></p><p><span>	</span><span>nav2</span><span> </span><span>=</span><span> </span><span>[</span><span>data</span><span>.</span><span>data</span><span>{</span><span>3</span><span>,</span><span> </span><span>idx_1002</span><span>}</span><span>]</span><span>;</span></p><p><span>	</span><span>len</span><span> </span><span>=</span><span> </span><span>length</span><span>(</span><span>nav1</span><span>)</span><span>;</span></p><p><span>	</span><span>% Arrays to store various outputs of the position estimation algorithm</span></p><p><span>	</span><span>user_position_arr</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span></p><p><span>	</span><span>HDOP_arr</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span></p><p><span>	</span><span>VDOP_arr</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span></p><p><span>	</span><span>user_clock_bias_arr</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span></p><p><span>	</span><span>% initial position of the user</span></p><p><span>	</span><span>xu</span><span> </span><span>=</span><span> </span><span>[</span><span>0</span><span> </span><span>0</span><span> </span><span>0</span><span>]</span><span>;</span></p><p><span>	</span><span>% initial clock bias</span></p><p><span>	</span><span>b</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>% 1002 messages are spaced apart 200ms. Let's use 1 out of every 5 samples.</span></p><p><span>	</span><span>% This means that we'll compute position every second, which is sufficient</span></p><p><span>	</span><span>for</span><span> </span><span>idx</span><span> </span><span>=</span><span> </span><span>1</span><span>:</span><span> </span><span>5</span><span>:</span><span> </span><span>len</span></p><p><span>		</span><span>% second element of nav1 contains receiver time of week</span></p><p><span>		</span><span>rcvr_tow</span><span> </span><span>=</span><span> </span><span>nav1</span><span>(</span><span>2</span><span>,</span><span>idx</span><span>)</span><span>;</span></p><p><span>		</span><span>% data block corresponding to this satellite</span></p><p><span>		</span><span>nav_data</span><span> </span><span>=</span><span> </span><span>nav2</span><span>(</span><span>:</span><span>,</span><span> </span><span>5</span><span>*</span><span>(</span><span>idx</span><span>-</span><span>1</span><span>)</span><span>+</span><span>1</span><span>:</span><span> </span><span>5</span><span>*</span><span>idx</span><span>)</span><span>;</span></p><p><span>		</span><span>% find indicies of rows containing non-zero data. Each row corresponds</span></p><p><span>		</span><span>% to a satellite</span></p><p><span>		</span><span>ind</span><span> </span><span>=</span><span> </span><span>find</span><span>(</span><span>sum</span><span>(</span><span>nav_data</span><span>,</span><span>2</span><span>)</span><span> </span><span>~</span><span>=</span><span> </span><span>0</span><span>)</span><span>;</span></p><p><span>		</span><span>numSV</span><span> </span><span>=</span><span> </span><span>length</span><span>(</span><span>ind</span><span>)</span><span>;</span></p><p><span>		</span><span>eph_formatted_</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span></p><p><span>		</span><span>% The minimum number of satellites needed is 4, let's go for more than</span></p><p><span>		</span><span>% that to be more robust</span></p><p><span>		</span><span>if</span><span> </span><span>(</span><span>numSV</span><span> </span><span>&gt;</span><span> </span><span>4</span><span>)</span></p><p><span>			</span><span>pr_</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span></p><p><span>			</span><span>% Correct for satellite clock bias and find the best ephemeris data</span></p><p><span>			</span><span>% for each satellite. Note that satellite ephemeris data (1019) is sent</span></p><p><span>			</span><span>% far less frequently than pseudorange info (1002). So for every</span></p><p><span>			</span><span>% epoch, we find the closest (in time) ephemeris data.</span></p><p><span>			</span><span>for</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>1</span><span>:</span><span> </span><span>numSV</span><span>,</span></p><p><span>				</span><span>sv_idx</span><span> </span><span>=</span><span> </span><span>ind</span><span>(</span><span>i</span><span>)</span><span>;</span></p><p><span>				</span><span>sv_data</span><span> </span><span>=</span><span> </span><span>nav_data</span><span>(</span><span>sv_idx</span><span>,</span><span>:</span><span>)</span><span>;</span></p><p><span>				</span><span>% find ephemeris data closest to this time of week</span></p><p><span>				</span><span>[</span><span>c_ </span><span>eph_idx</span><span>]</span><span> </span><span>=</span><span> </span><span>min</span><span>(</span><span>abs</span><span>(</span><span>eph_data</span><span>{</span><span>sv_idx</span><span>}</span><span>(</span><span>18</span><span>,</span><span>:</span><span>)</span><span>-</span><span>rcvr_tow</span><span>)</span><span>)</span><span>;</span></p><p><span>				</span><span>eph_</span><span> </span><span>=</span><span> </span><span>eph_data</span><span>{</span><span>sv_idx</span><span>}</span><span>(</span><span>:</span><span>,</span><span> </span><span>eph_idx</span><span>)</span><span>;</span></p><p><span>				</span><span>% Convert the ephemeris data into a standard format so it can</span></p><p><span>				</span><span>% be input to routines that process it to calculate satellite</span></p><p><span>				</span><span>% position and satellite clock bias</span></p><p><span>				</span><span>eph_formatted</span><span> </span><span>=</span><span> </span><span>format_ephemeris3</span><span>(</span><span>eph_</span><span>)</span><span>;</span></p><p><span>				</span><span>eph_formatted_</span><span>{</span><span>end</span><span>+</span><span>1</span><span>}</span><span> </span><span>=</span><span> </span><span>eph_formatted</span><span>;</span></p><p><span>				</span><span>% To be correct, the satellite clock bias should be calculated</span></p><p><span>				</span><span>% at rcvr_tow - tau, however it doesn't make much difference to</span></p><p><span>				</span><span>% do it at rcvr_tow</span></p><p><span>				</span><span>dsv</span><span> </span><span>=</span><span> </span><span>estimate_satellite_clock_bias</span><span>(</span><span>rcvr_tow</span><span>,</span><span> </span><span>eph_formatted</span><span>)</span><span>;</span></p><p><span>				</span><span>% measured pseudoranges corrected for satellite clock bias.</span></p><p><span>				</span><span>% Also apply ionospheric and tropospheric corrections if</span></p><p><span>				</span><span>% available</span></p><p><span>				</span><span>pr_raw</span><span> </span><span>=</span><span> </span><span>sv_data</span><span>(</span><span>2</span><span>)</span><span>;</span></p><p><span>				</span><span>pr_</span><span>(</span><span>end</span><span>+</span><span>1</span><span>)</span><span> </span><span>=</span><span> </span><span>pr_raw</span><span> </span><span>+</span><span> </span><span>c</span><span>*</span><span>dsv</span><span>;</span></p><p><span>			</span><span>end</span></p><p><span>			</span><span>% Now lets calculate the satellite positions and construct the G</span></p><p><span>			</span><span>% matrix. Then we'll run the least squares optimization to</span></p><p><span>			</span><span>% calculate corrected user position and clock bias. We'll iterate</span></p><p><span>			</span><span>% until change in user position and clock bias is less than a</span></p><p><span>			</span><span>% threhold. In practice, the optimization converges very quickly,</span></p><p><span>			</span><span>% usually in 2-3 iterations even when the starting point for the</span></p><p><span>			</span><span>% user position and clock bias is far away from the true values.</span></p><p><span>			</span><span>dx</span><span> </span><span>=</span><span> </span><span>100</span><span>*</span><span>ones</span><span>(</span><span>1</span><span>,</span><span>3</span><span>)</span><span>;</span><span> </span><span>db</span><span> </span><span>=</span><span> </span><span>100</span><span>;</span></p><p><span>			</span><span>while</span><span>(</span><span>norm</span><span>(</span><span>dx</span><span>)</span><span> </span><span>&gt;</span><span> </span><span>0.1</span><span> </span><span>&amp;&amp;</span><span> </span><span>norm</span><span>(</span><span>db</span><span>)</span><span> </span><span>&gt;</span><span> </span><span>1</span><span>)</span></p><p><span>				</span><span>Xs</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span> </span><span>% concatenated satellite positions</span></p><p><span>				</span><span>pr</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span> </span><span>% pseudoranges corrected for user clock bias</span></p><p><span>				</span><span>for</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>1</span><span>:</span><span> </span><span>numSV</span><span>,</span></p><p><span>					</span><span>% correct for our estimate of user clock bias. Note that</span></p><p><span>					</span><span>% the clock bias is in units of distance</span></p><p><span>					</span><span>cpr</span><span> </span><span>=</span><span> </span><span>pr_</span><span>(</span><span>i</span><span>)</span><span> </span><span>-</span><span> </span><span>b</span><span>;</span></p><p><span>					</span><span>pr</span><span> </span><span>=</span><span> </span><span>[</span><span>pr</span><span>;</span><span> </span><span>cpr</span><span>]</span><span>;</span></p><p><span>					</span><span>% Signal transmission time</span></p><p><span>					</span><span>tau</span><span> </span><span>=</span><span> </span><span>cpr</span><span>/</span><span>c</span><span>;</span></p><p><span>					</span><span>% Get satellite position</span></p><p><span>					</span><span>[</span><span>xs_ </span><span>ys_ </span><span>zs_</span><span>]</span><span> </span><span>=</span><span> </span><span>get_satellite_position</span><span>(</span><span>eph_formatted_</span><span>{</span><span>i</span><span>}</span><span>,</span><span> </span><span>rcvr_tow</span><span>-</span><span>tau</span><span>,</span><span> </span><span>1</span><span>)</span><span>;</span></p><p><span>					</span><span>% express satellite position in ECEF frame at time t</span></p><p><span>					</span><span>theta</span><span> </span><span>=</span><span> </span><span>omega_e</span><span>*</span><span>tau</span><span>;</span></p><p><span>					</span><span>xs_vec</span><span> </span><span>=</span><span> </span><span>[</span><span>cos</span><span>(</span><span>theta</span><span>)</span><span> </span><span>sin</span><span>(</span><span>theta</span><span>)</span><span> </span><span>0</span><span>;</span><span> </span><span>-</span><span>sin</span><span>(</span><span>theta</span><span>)</span><span> </span><span>cos</span><span>(</span><span>theta</span><span>)</span><span> </span><span>0</span><span>;</span><span> </span><span>0</span><span> </span><span>0</span><span> </span><span>1</span><span>]</span><span>*</span><span>[</span><span>xs_</span><span>;</span><span> </span><span>ys_</span><span>;</span><span> </span><span>zs_</span><span>]</span><span>;</span></p><p><span>					</span><span>xs_vec</span><span> </span><span>=</span><span> </span><span>[</span><span>xs_ </span><span>ys_ </span><span>zs_</span><span>]</span><span>';</span></p><p><span>					Xs = [Xs; xs_vec'</span><span>]</span><span>;</span></p><p><span>				</span><span>end</span></p><p><span>				</span><span>% Run least squares to calculate new user position and bias</span></p><p><span>				</span><span>[</span><span>x_</span><span>,</span><span> </span><span>b_</span><span>,</span><span> </span><span>norm_dp</span><span>,</span><span> </span><span>G</span><span>]</span><span> </span><span>=</span><span> </span><span>estimate_position</span><span>(</span><span>Xs</span><span>,</span><span> </span><span>pr</span><span>,</span><span> </span><span>numSV</span><span>,</span><span> </span><span>xu</span><span>,</span><span> </span><span>b</span><span>,</span><span> </span><span>3</span><span>)</span><span>;</span></p><p><span>				</span><span>% Change in the position and bias to determine when to quite</span></p><p><span>				</span><span>% the iteration</span></p><p><span>				</span><span>dx</span><span> </span><span>=</span><span> </span><span>x_</span><span> </span><span>-</span><span> </span><span>xu</span><span>;</span></p><p><span>				</span><span>db</span><span> </span><span>=</span><span> </span><span>b_</span><span> </span><span>-</span><span> </span><span>b</span><span>;</span></p><p><span>				</span><span>xu</span><span> </span><span>=</span><span> </span><span>x_</span><span>;</span></p><p><span>				</span><span>b</span><span> </span><span>=</span><span> </span><span>b_</span><span>;</span></p><p><span>			</span><span>end</span><span> </span><span>% end of iteration</span></p><p><span>			</span><span>% Convert from ECEF to lat/lng</span></p><p><span>			</span><span>[</span><span>lambda</span><span>,</span><span> </span><span>phi</span><span>,</span><span> </span><span>h</span><span>]</span><span> </span><span>=</span><span> </span><span>WGStoEllipsoid</span><span>(</span><span>xu</span><span>(</span><span>1</span><span>)</span><span>,</span><span> </span><span>xu</span><span>(</span><span>2</span><span>)</span><span>,</span><span> </span><span>xu</span><span>(</span><span>3</span><span>)</span><span>)</span><span>;</span></p><p><span>			</span><span>% Calculate Rotation Matrix to Convert ECEF to local ENU reference</span></p><p><span>			</span><span>% frame</span></p><p><span>			</span><span>lat</span><span> </span><span>=</span><span> </span><span>phi</span><span>*</span><span>180</span><span>/</span><span>pi</span></p><p><span>			</span><span>lon</span><span> </span><span>=</span><span> </span><span>lambda</span><span>*</span><span>180</span><span>/</span><span>pi</span></p><p><span>			</span><span>R1</span><span>=</span><span>rot</span><span>(</span><span>90</span><span>+</span><span>lon</span><span>,</span><span> </span><span>3</span><span>)</span><span>;</span></p><p><span>			</span><span>R2</span><span>=</span><span>rot</span><span>(</span><span>90</span><span>-</span><span>lat</span><span>,</span><span> </span><span>1</span><span>)</span><span>;</span></p><p><span>			</span><span>R</span><span>=</span><span>R2</span><span>*</span><span>R1</span><span>;</span></p><p><span>			</span><span>G_</span><span> </span><span>=</span><span> </span><span>[</span><span>G</span><span>(</span><span>:</span><span>,</span><span>1</span><span>:</span><span>3</span><span>)</span><span>*</span><span>R</span><span>' G(:,4)];</span></p><p><span>			H = inv(G_'</span><span>*</span><span>G_</span><span>)</span><span>;</span></p><p><span>			</span><span>HDOP</span><span> </span><span>=</span><span> </span><span>sqrt</span><span>(</span><span>H</span><span>(</span><span>1</span><span>,</span><span>1</span><span>)</span><span> </span><span>+</span><span> </span><span>H</span><span>(</span><span>2</span><span>,</span><span>2</span><span>)</span><span>)</span><span>;</span></p><p><span>			</span><span>VDOP</span><span> </span><span>=</span><span> </span><span>sqrt</span><span>(</span><span>H</span><span>(</span><span>3</span><span>,</span><span>3</span><span>)</span><span>)</span><span>;</span></p><p><span>			</span><span>% Record various quantities for saving and plotting</span></p><p><span>			</span><span>HDOP_arr</span><span>(</span><span>end</span><span>+</span><span>1</span><span>,</span><span>:</span><span>)</span><span> </span><span>=</span><span> </span><span>HDOP</span><span>;</span></p><p><span>			</span><span>VDOP_arr</span><span>(</span><span>end</span><span>+</span><span>1</span><span>,</span><span>:</span><span>)</span><span> </span><span>=</span><span> </span><span>VDOP</span><span>;</span></p><p><span>			</span><span>user_position_arr</span><span>(</span><span>end</span><span>+</span><span>1</span><span>,</span><span>:</span><span>)</span><span> </span><span>=</span><span> </span><span>[</span><span>lat </span><span>lon</span><span> </span><span>h</span><span>]</span><span>;</span></p><p><span>			</span><span>user_clock_bias_arr</span><span>(</span><span>end</span><span>+</span><span>1</span><span>,</span><span>:</span><span>)</span><span> </span><span>=</span><span> </span><span>b</span><span>;</span></p><p><span>		</span><span>end</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>HDOP_arr</span><span>;</span></p><p><span>	</span><span>%Function R=rot(angle (degrees), axis) returns a 3x3</span></p><p><span>	</span><span>%rotation matrix for rotating a vector about a single</span></p><p><span>	</span><span>%axis.&nbsp;&nbsp;Setting axis = 1 rotates about the e1 axis,</span></p><p><span>	</span><span>%axis = 2 rotates about the e2 axis, axis = 3 rotates</span></p><p><span>	</span><span>%about the e3 axis.</span></p><p><span>	</span><span>function</span><span> </span><span>R</span><span>=</span><span>rot</span><span>(</span><span>angle</span><span>,</span><span> </span><span>axis</span><span>)</span></p><p><span>	</span><span>%function R=rot(angle (degrees), axis)</span></p><p><span>	</span><span>R</span><span>=</span><span>eye</span><span>(</span><span>3</span><span>)</span><span>;</span></p><p><span>	</span><span>cang</span><span>=</span><span>cos</span><span>(</span><span>angle</span><span>*</span><span>pi</span><span>/</span><span>180</span><span>)</span><span>;</span></p><p><span>	</span><span>sang</span><span>=</span><span>sin</span><span>(</span><span>angle</span><span>*</span><span>pi</span><span>/</span><span>180</span><span>)</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>axis</span><span>==</span><span>1</span><span>)</span></p><p><span>		</span><span>R</span><span>(</span><span>2</span><span>,</span><span>2</span><span>)</span><span>=</span><span>cang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>3</span><span>,</span><span>3</span><span>)</span><span>=</span><span>cang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>2</span><span>,</span><span>3</span><span>)</span><span>=</span><span>sang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>3</span><span>,</span><span>2</span><span>)</span><span>=</span><span>-</span><span>sang</span><span>;</span></p><p><span>	</span><span>end</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>axis</span><span>==</span><span>2</span><span>)</span></p><p><span>		</span><span>R</span><span>(</span><span>1</span><span>,</span><span>1</span><span>)</span><span>=</span><span>cang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>3</span><span>,</span><span>3</span><span>)</span><span>=</span><span>cang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>1</span><span>,</span><span>3</span><span>)</span><span>=</span><span>-</span><span>sang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>3</span><span>,</span><span>1</span><span>)</span><span>=</span><span>sang</span><span>;</span></p><p><span>	</span><span>end</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>axis</span><span>==</span><span>3</span><span>)</span></p><p><span>		</span><span>R</span><span>(</span><span>1</span><span>,</span><span>1</span><span>)</span><span>=</span><span>cang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>2</span><span>,</span><span>2</span><span>)</span><span>=</span><span>cang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>2</span><span>,</span><span>1</span><span>)</span><span>=</span><span>-</span><span>sang</span><span>;</span></p><p><span>		</span><span>R</span><span>(</span><span>1</span><span>,</span><span>2</span><span>)</span><span>=</span><span>sang</span><span>;</span></p><p><span>	</span><span>end</span><span>;</span></p><p><span>	</span><span>return</span><span>;</span></p><p><span>	</span><span>end</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0094 seconds] -->

<h3><span id="1b_Code_for_Calculating_Satellite_Position"><strong>1.b Code for Calculating Satellite Position</strong></span></h3>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2cb658300093" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p><p>49</p><p>50</p><p>51</p><p>52</p><p>53</p><p>54</p><p>55</p><p>56</p><p>57</p><p>58</p><p>59</p><p>60</p><p>61</p><p>62</p><p>63</p><p>64</p><p>65</p><p>66</p><p>67</p><p>68</p><p>69</p><p>70</p><p>71</p><p>72</p><p>73</p><p>74</p><p>75</p><p>76</p><p>77</p><p>78</p><p>79</p><p>80</p><p>81</p><p>82</p><p>83</p><p>84</p><p>85</p><p>86</p><p>87</p><p>88</p><p>89</p><p>90</p><p>91</p><p>92</p><p>93</p><p>94</p></div>
				</td>
						<td><div><p><span>	</span><span>function</span><span> </span><span>[</span><span>x</span><span> </span><span>y</span><span> </span><span>z</span><span>]</span><span> </span><span>=</span><span> </span><span>get_satellite_position</span><span>(</span><span>eph</span><span>,</span><span> </span><span>t</span><span>,</span><span> </span><span>compute_harmonic_correction</span><span>)</span></p><p><span>	</span><span>% get_satellite_position: computes the position of a satellite at time (t) given the</span></p><p><span>	</span><span>% ephemeris parameters. </span></p><p><span>	</span><span>% Usage: [x y z] =&nbsp;&nbsp;get_satellite_position(eph, t, compute_harmonic_correction)</span></p><p><span>	</span><span>% Input Args: eph: ephemeris data</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; t: time </span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; compute_harmonic_correction (optional): 1 if harmonic</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correction should be applied, 0 if not. </span></p><p><span>	</span><span>% Output Args: [x y z] in ECEF in meters</span></p><p><span>	</span><span>% ephmeris data must have the following fields:</span></p><p><span>	</span><span>% rcvr_tow (receiver tow)</span></p><p><span>	</span><span>% svid (satellite id)</span></p><p><span>	</span><span>% toc (reference time of clock parameters)</span></p><p><span>	</span><span>% toe (referece time of ephemeris parameters)</span></p><p><span>	</span><span>% af0, af1, af2: clock correction coefficients</span></p><p><span>	</span><span>% ura (user range accuracy)</span></p><p><span>	</span><span>% e (eccentricity)</span></p><p><span>	</span><span>% sqrtA (sqrt of semi-major axis)</span></p><p><span>	</span><span>% dn (mean motion correction)</span></p><p><span>	</span><span>% m0 (mean anomaly at reference time)</span></p><p><span>	</span><span>% w (argument of perigee)</span></p><p><span>	</span><span>% omg0 (lontitude of ascending node)</span></p><p><span>	</span><span>% i0 (inclination angle at reference time)</span></p><p><span>	</span><span>% odot (rate of right ascension)</span></p><p><span>	</span><span>% idot (rate of inclination angle)</span></p><p><span>	</span><span>% cus (argument of latitude correction, sine)</span></p><p><span>	</span><span>% cuc (argument of latitude correction, cosine)</span></p><p><span>	</span><span>% cis (inclination correction, sine)</span></p><p><span>	</span><span>% cic (inclination correction, cosine)</span></p><p><span>	</span><span>% crs (radius correction, sine)</span></p><p><span>	</span><span>% crc (radius correction, cosine)</span></p><p><span>	</span><span>% iod (issue of data number)</span></p><p><span>	</span><span>% set default value for harmonic correction</span></p><p><span>	</span><span>switch</span><span> </span><span>nargin</span></p><p><span>		</span><span>case</span><span> </span><span>2</span></p><p><span>			</span><span>compute_harmonic_correction</span><span>=</span><span>1</span><span>;</span></p><p><span>	</span><span>end</span><span> </span></p><p><span>	</span><span>mu</span><span> </span><span>=</span><span> </span><span>3.986005e14</span><span>;</span></p><p><span>	</span><span>omega_dot_earth</span><span> </span><span>=</span><span> </span><span>7.2921151467e</span><span>-</span><span>5</span><span>;</span><span> </span><span>%(rad/sec)</span></p><p><span>	</span><span>% Now follow table 20-IV</span></p><p><span>	</span><span>A</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>sqrtA</span><span>^</span><span>2</span><span>;</span></p><p><span>	</span><span>cmm</span><span> </span><span>=</span><span> </span><span>sqrt</span><span>(</span><span>mu</span><span>/</span><span>A</span><span>^</span><span>3</span><span>)</span><span>;</span><span> </span><span>% computed mean motion</span></p><p><span>	</span><span>tk</span><span> </span><span>=</span><span> </span><span>t</span><span> </span><span>-</span><span> </span><span>eph</span><span>.</span><span>toe</span><span>;</span></p><p><span>	</span><span>% account for beginning of end of week crossover</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>tk</span><span> </span><span>&gt;</span><span> </span><span>302400</span><span>)</span></p><p><span>		</span><span>tk</span><span> </span><span>=</span><span> </span><span>tk</span><span>-</span><span>604800</span><span>;</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>tk</span><span> </span><span>&lt;</span><span> </span><span>-</span><span>302400</span><span>)</span></p><p><span>		</span><span>tk</span><span> </span><span>=</span><span> </span><span>tk</span><span>+</span><span>604800</span><span>;</span></p><p><span>	</span><span>end</span><span> </span></p><p><span>	</span><span>% apply mean motion correction</span></p><p><span>	</span><span>n</span><span> </span><span>=</span><span> </span><span>cmm</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>dn</span><span>;</span></p><p><span>	</span><span>% Mean anomaly</span></p><p><span>	</span><span>mk</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>m0</span><span> </span><span>+</span><span> </span><span>n</span><span>*</span><span>tk</span><span>;</span></p><p><span>	</span><span>% solve for eccentric anomaly</span></p><p><span>	</span><span>syms</span><span> </span><span>E</span><span>;</span></p><p><span>	</span><span>eqn</span><span> </span><span>=</span><span> </span><span>E</span><span> </span><span>-</span><span> </span><span>eph</span><span>.</span><span>e</span><span>*</span><span>sin</span><span>(</span><span>E</span><span>)</span><span> </span><span>==</span><span> </span><span>mk</span><span>;</span></p><p><span>	</span><span>solx</span><span> </span><span>=</span><span> </span><span>vpasolve</span><span>(</span><span>eqn</span><span>,</span><span> </span><span>E</span><span>)</span><span>;</span></p><p><span>	</span><span>Ek</span><span> </span><span>=</span><span> </span><span>double</span><span>(</span><span>solx</span><span>)</span><span>;</span></p><p><span>	</span><span>% True anomaly:</span></p><p><span>	</span><span>nu</span><span> </span><span>=</span><span> </span><span>atan2</span><span>(</span><span>(</span><span>sqrt</span><span>(</span><span>1</span><span>-</span><span>eph</span><span>.</span><span>e</span><span>^</span><span>2</span><span>)</span><span>)</span><span>*</span><span>sin</span><span>(</span><span>Ek</span><span>)</span><span>/</span><span>(</span><span>1</span><span>-</span><span>eph</span><span>.</span><span>e</span><span>*</span><span>cos</span><span>(</span><span>Ek</span><span>)</span><span>)</span><span>,</span><span> </span><span>(</span><span>cos</span><span>(</span><span>Ek</span><span>)</span><span>-</span><span>eph</span><span>.</span><span>e</span><span>)</span><span>/</span><span>(</span><span>1</span><span>-</span><span>eph</span><span>.</span><span>e</span><span>*</span><span>cos</span><span>(</span><span>Ek</span><span>)</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>%Ek = acos((e&nbsp;&nbsp;+ cos(nu))/(1+e*cos(nu)));</span></p><p><span>	</span><span>Phi</span><span> </span><span>=</span><span> </span><span>nu</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>w</span><span>;</span></p><p><span>	</span><span>du</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>dr</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>di</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>compute_harmonic_correction</span><span> </span><span>==</span><span> </span><span>1</span><span>)</span></p><p><span>	</span><span>% compute harmonic corrections</span></p><p><span>	</span><span>du</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>cus</span><span>*</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>Phi</span><span>)</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>cuc</span><span>*</span><span>cos</span><span>(</span><span>2</span><span>*</span><span>Phi</span><span>)</span><span>;</span></p><p><span>	</span><span>dr</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>crs</span><span>*</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>Phi</span><span>)</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>crc</span><span>*</span><span>cos</span><span>(</span><span>2</span><span>*</span><span>Phi</span><span>)</span><span>;</span></p><p><span>	</span><span>di</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>cis</span><span>*</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>Phi</span><span>)</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>cic</span><span>*</span><span>cos</span><span>(</span><span>2</span><span>*</span><span>Phi</span><span>)</span><span>;</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>u</span><span> </span><span>=</span><span> </span><span>Phi</span><span> </span><span>+</span><span> </span><span>du</span><span>;</span></p><p><span>	</span><span>r</span><span> </span><span>=</span><span> </span><span>A</span><span>*</span><span>(</span><span>1</span><span>-</span><span>eph</span><span>.</span><span>e</span><span>*</span><span>cos</span><span>(</span><span>Ek</span><span>)</span><span>)</span><span> </span><span>+</span><span> </span><span>dr</span><span>;</span></p><p><span>	</span><span>% inclination angle at reference time</span></p><p><span>	</span><span>i</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>i0</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>idot</span><span>*</span><span>tk</span><span> </span><span>+</span><span> </span><span>di</span><span>;</span></p><p><span>	</span><span>x_prime</span><span> </span><span>=</span><span> </span><span>r</span><span>*</span><span>cos</span><span>(</span><span>u</span><span>)</span><span>;</span></p><p><span>	</span><span>y_prime</span><span> </span><span>=</span><span> </span><span>r</span><span>*</span><span>sin</span><span>(</span><span>u</span><span>)</span><span>;</span></p><p><span>	</span><span>omega</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>omg0</span><span> </span><span>+</span><span> </span><span>(</span><span>eph</span><span>.</span><span>odot</span><span> </span><span>-</span><span> </span><span>omega_dot_earth</span><span>)</span><span>*</span><span>tk</span><span> </span><span>-</span><span> </span><span>omega_dot_earth</span><span>*</span><span>eph</span><span>.</span><span>toe</span><span>;</span></p><p><span>	</span><span>x</span><span> </span><span>=</span><span> </span><span>x_prime</span><span>*</span><span>cos</span><span>(</span><span>omega</span><span>)</span><span> </span><span>-</span><span> </span><span>y_prime</span><span>*</span><span>cos</span><span>(</span><span>i</span><span>)</span><span>*</span><span>sin</span><span>(</span><span>omega</span><span>)</span><span>;</span></p><p><span>	</span><span>y</span><span> </span><span>=</span><span> </span><span>x_prime</span><span>*</span><span>sin</span><span>(</span><span>omega</span><span>)</span><span> </span><span>+</span><span> </span><span>y_prime</span><span>*</span><span>cos</span><span>(</span><span>i</span><span>)</span><span>*</span><span>cos</span><span>(</span><span>omega</span><span>)</span><span>;</span></p><p><span>	</span><span>z</span><span> </span><span>=</span><span> </span><span>y_prime</span><span>*</span><span>sin</span><span>(</span><span>i</span><span>)</span><span>;</span></p><p><span>	</span><span>end</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0035 seconds] -->

<h3><span id="1c_Code_for_Computing_the_Least_Squares_Solution_for_User_Position_and_Clock_Bias"><strong>1.c Code for Computing the Least Squares Solution for User Position and Clock Bias</strong></span></h3>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2cf590782375" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p></div>
				</td>
						<td><div><p><span>	</span><span>function</span><span> </span><span>[</span><span>x</span><span>,</span><span> </span><span>b</span><span>,</span><span> </span><span>norm_dp</span><span>,</span><span> </span><span>G</span><span>]</span><span> </span><span>=</span><span> </span><span>estimate_position</span><span>(</span><span>xs</span><span>,</span><span> </span><span>pr</span><span>,</span><span> </span><span>numSat</span><span>,</span><span> </span><span>x0</span><span>,</span><span> </span><span>b0</span><span>,</span><span> </span><span>dim</span><span>)</span></p><p><span>	</span><span>% estimate_position: estimate the user's position and user clock bias</span></p><p><span>	</span><span>% Usage: [x, b, norm_dp, G] = estimate_position(xs, pr, numSat, x0, b0, dim)</span></p><p><span>	</span><span>% Input Args: xs: satellite position matrix</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pr: corrected pseudo ranges (adjusted for known value of the</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; satellite clock bias)</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; numSat: number of satellites</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x0: starting estimate of the user position</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b0: starting point for the user clock bias</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dim: dimensions of the satellite vector. 3 for 3D, 2 for 2D</span></p><p><span>	</span><span>% Notes: b and b0 are usually 0 as the current estimate of the clock bias</span></p><p><span>	</span><span>% has already been applied to the input pseudo ranges.</span></p><p><span>	</span><span>% Output Args: x: optimized user position</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b: optimized user clock bias</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;norm_dp: normalized pseudo-range difference</span></p><p><span>	</span><span>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;G: user satellite geometry matrix, useful for computing DOPs</span></p><p><span>	</span><span>dx</span><span> </span><span>=</span><span> </span><span>100</span><span>*</span><span>ones</span><span>(</span><span>1</span><span>,</span><span> </span><span>dim</span><span>)</span><span>;</span></p><p><span>	</span><span>db</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>norm_dp</span><span> </span><span>=</span><span> </span><span>100</span><span>;</span></p><p><span>	</span><span>numIter</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>b</span><span> </span><span>=</span><span> </span><span>b0</span><span>;</span></p><p><span>	</span><span>%while (norm_dp &gt; 1e-4)</span></p><p><span>	</span><span>while</span><span> </span><span>norm</span><span>(</span><span>dx</span><span>)</span><span> </span><span>&gt;</span><span> </span><span>1e</span><span>-</span><span>3</span></p><p><span>		</span><span>norms</span><span> </span><span>=</span><span> </span><span>sqrt</span><span>(</span><span>sum</span><span>(</span><span>(</span><span>xs</span><span>-</span><span>x0</span><span>)</span><span>.</span><span>^</span><span>2</span><span>,</span><span>2</span><span>)</span><span>)</span><span>;</span></p><p><span>		</span><span>% delta pseudo range:</span></p><p><span>		</span><span>dp</span><span> </span><span>=</span><span> </span><span>pr</span><span> </span><span>-</span><span> </span><span>norms</span><span> </span><span>+</span><span> </span><span>b</span><span> </span><span>-</span><span> </span><span>b0</span><span>;</span></p><p><span>		</span><span>G</span><span> </span><span>=</span><span> </span><span>[</span><span>-</span><span>(</span><span>xs</span><span>-</span><span>x0</span><span>)</span><span>.</span><span>/</span><span>norms </span><span>ones</span><span>(</span><span>numSat</span><span>,</span><span>1</span><span>)</span><span>]</span><span>;</span></p><p><span>		</span><span>sol</span><span> </span><span>=</span><span> </span><span>inv</span><span>(</span><span>G</span><span>'*G)*G'</span><span>*</span><span>dp</span><span>;</span></p><p><span>		</span><span>dx</span><span> </span><span>=</span><span> </span><span>sol</span><span>(</span><span>1</span><span>:</span><span>dim</span><span>)</span>'<span>;</span></p><p><span>		</span><span>db</span><span> </span><span>=</span><span> </span><span>sol</span><span>(</span><span>dim</span><span>+</span><span>1</span><span>)</span><span>;</span></p><p><span>		</span><span>norm_dp</span><span> </span><span>=</span><span> </span><span>norm</span><span>(</span><span>dp</span><span>)</span><span>;</span></p><p><span>		</span><span>numIter</span><span> </span><span>=</span><span> </span><span>numIter</span><span> </span><span>+</span><span> </span><span>1</span><span>;</span></p><p><span>		</span><span>x0</span><span> </span><span>=</span><span> </span><span>x0</span><span> </span><span>+</span><span> </span><span>dx</span><span>;</span></p><p><span>		</span><span>b0</span><span> </span><span>=</span><span> </span><span>b0</span><span> </span><span>+</span><span> </span><span>db</span><span>;</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>x</span><span> </span><span>=</span><span> </span><span>x0</span><span>;</span></p><p><span>	</span><span>b</span><span> </span><span>=</span><span> </span><span>b0</span><span>;</span></p><p><span>	</span><span>end</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0014 seconds] -->

<h3><span id="1d_Code_for_Calculating_Satellite_Clock_Bias"><strong>1.d Code for Calculating Satellite Clock Bias</strong></span></h3>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2d2788312100" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div>
				</td>
						<td><div><p><span>	</span><span>function</span><span> </span><span>dsv</span><span> </span><span>=</span><span> </span><span>estimate_satellite_clock_bias</span><span>(</span><span>t</span><span>,</span><span> </span><span>eph</span><span>)</span></p><p><span>	</span><span>F</span><span> </span><span>=</span><span> </span><span>-</span><span>4.442807633e</span><span>-</span><span>10</span><span>;</span></p><p><span>	</span><span>mu</span><span> </span><span>=</span><span> </span><span>3.986005e14</span><span>;</span></p><p><span>	</span><span>A</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>sqrtA</span><span>^</span><span>2</span><span>;</span></p><p><span>	</span><span>cmm</span><span> </span><span>=</span><span> </span><span>sqrt</span><span>(</span><span>mu</span><span>/</span><span>A</span><span>^</span><span>3</span><span>)</span><span>;</span><span> </span><span>% computed mean motion</span></p><p><span>	</span><span>tk</span><span> </span><span>=</span><span> </span><span>t</span><span> </span><span>-</span><span> </span><span>eph</span><span>.</span><span>toe</span><span>;</span></p><p><span>	</span><span>% account for beginning or end of week crossover</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>tk</span><span> </span><span>&gt;</span><span> </span><span>302400</span><span>)</span></p><p><span>		</span><span>tk</span><span> </span><span>=</span><span> </span><span>tk</span><span>-</span><span>604800</span><span>;</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>tk</span><span> </span><span>&lt;</span><span> </span><span>-</span><span>302400</span><span>)</span></p><p><span>		</span><span>tk</span><span> </span><span>=</span><span> </span><span>tk</span><span>+</span><span>604800</span><span>;</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>% apply mean motion correction</span></p><p><span>	</span><span>n</span><span> </span><span>=</span><span> </span><span>cmm</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>dn</span><span>;</span></p><p><span>	</span><span>% Mean anomaly</span></p><p><span>	</span><span>mk</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>m0</span><span> </span><span>+</span><span> </span><span>n</span><span>*</span><span>tk</span><span>;</span></p><p><span>	</span><span>% solve for eccentric anomaly</span></p><p><span>	</span><span>syms</span><span> </span><span>E</span><span>;</span></p><p><span>	</span><span>eqn</span><span> </span><span>=</span><span> </span><span>E</span><span> </span><span>-</span><span> </span><span>eph</span><span>.</span><span>e</span><span>*</span><span>sin</span><span>(</span><span>E</span><span>)</span><span> </span><span>==</span><span> </span><span>mk</span><span>;</span></p><p><span>	</span><span>solx</span><span> </span><span>=</span><span> </span><span>vpasolve</span><span>(</span><span>eqn</span><span>,</span><span> </span><span>E</span><span>)</span><span>;</span></p><p><span>	</span><span>Ek</span><span> </span><span>=</span><span> </span><span>double</span><span>(</span><span>solx</span><span>)</span><span>;</span></p><p><span>	</span><span>dsv</span><span> </span><span>=</span><span> </span><span>eph</span><span>.</span><span>af0</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>af1</span><span>*</span><span>(</span><span>t</span><span>-</span><span>eph</span><span>.</span><span>toc</span><span>)</span><span> </span><span>+</span><span> </span><span>eph</span><span>.</span><span>af2</span><span>*</span><span>(</span><span>t</span><span>-</span><span>eph</span><span>.</span><span>toc</span><span>)</span><span>^</span><span>2</span><span> </span><span>+</span><span> </span><span>F</span><span>*</span><span>eph</span><span>.</span><span>e</span><span>*</span><span>eph</span><span>.</span><span>sqrtA</span><span>*</span><span>sin</span><span>(</span><span>Ek</span><span>)</span><span>;</span></p><p><span>	</span><span>end</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0013 seconds] -->

<h3><span id="1e_Code_for_converting_ECEF_WGS84_to_Ellipsoidal_Coordinates"><strong>1.e Code for converting ECEF (WGS84) to Ellipsoidal Coordinates</strong></span></h3>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2d4111374489" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div>
				</td>
						<td><div><p><span>	</span><span>function</span><span> </span><span>[</span><span>lambda</span><span>,</span><span> </span><span>phi</span><span>,</span><span> </span><span>h</span><span>]</span><span> </span><span>=</span><span> </span><span>WGStoEllipsoid</span><span>(</span><span>x</span><span>,</span><span>y</span><span>,</span><span>z</span><span>)</span></p><p><span>	</span><span>% WGStoEllipsoid Convert ECEF coordinates to Ellipsoidal (longitude, latitude, height above ellipsoid)</span></p><p><span>	</span><span>% Usage: [lambda, phi, h] =&nbsp;&nbsp;WGStoEllipsoid(x,y,z)</span></p><p><span>	</span><span>% Input Args: coordinates in ECEF</span></p><p><span>	</span><span>% Output Args: Longitude, Latitude in radians, height in meters</span></p><p><span>	</span><span>% WGS ellipsoid params</span></p><p><span>	</span><span>a</span><span> </span><span>=</span><span> </span><span>6378137</span><span>;</span></p><p><span>	</span><span>f</span><span> </span><span>=</span><span> </span><span>1</span><span>/</span><span>298.257</span><span>;</span></p><p><span>	</span><span>e</span><span> </span><span>=</span><span> </span><span>sqrt</span><span>(</span><span>2</span><span>*</span><span>f</span><span>-</span><span>f</span><span>^</span><span>2</span><span>)</span><span>;</span></p><p><span>	</span><span>% From equation 4.A.3,</span></p><p><span>	</span><span>lambda</span><span> </span><span>=</span><span> </span><span>atan2</span><span>(</span><span>y</span><span>,</span><span>x</span><span>)</span><span>;</span></p><p><span>	</span><span>p</span><span> </span><span>=</span><span> </span><span>sqrt</span><span>(</span><span>x</span><span>^</span><span>2</span><span>+</span><span>y</span><span>^</span><span>2</span><span>)</span><span>;</span></p><p><span>	</span><span>% initial value of phi assuming h = 0;</span></p><p><span>	</span><span>h</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>phi</span><span> </span><span>=</span><span> </span><span>atan2</span><span>(</span><span>z</span><span>,</span><span> </span><span>p</span><span>*</span><span>(</span><span>1</span><span>-</span><span>e</span><span>^</span><span>2</span><span>)</span><span>)</span><span>;</span><span> </span><span>%4.A.5</span></p><p><span>	</span><span>N</span><span> </span><span>=</span><span> </span><span>a</span><span>/</span><span>(</span><span>1</span><span>-</span><span>(</span><span>e</span><span>*</span><span>sin</span><span>(</span><span>phi</span><span>)</span><span>)</span><span>^</span><span>2</span><span>)</span><span>^</span><span>0.5</span><span>;</span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p><span>	</span><span>delta_h</span><span> </span><span>=</span><span> </span><span>1000000</span><span>;</span></p><p><span>	</span><span>while</span><span> </span><span>delta_h</span><span> </span><span>&gt;</span><span> </span><span>0.01</span></p><p><span>		</span><span>prev_h</span><span> </span><span>=</span><span> </span><span>h</span><span>;</span></p><p><span>		</span><span>phi</span><span> </span><span>=</span><span> </span><span>atan2</span><span>(</span><span>z</span><span>,</span><span> </span><span>p</span><span>*</span><span>(</span><span>1</span><span>-</span><span>e</span><span>^</span><span>2</span><span>*</span><span>(</span><span>N</span><span>/</span><span>(</span><span>N</span><span>+</span><span>h</span><span>)</span><span>)</span><span>)</span><span>)</span><span>;</span><span> </span><span>%4.A.5</span></p><p><span>		</span><span>N</span><span> </span><span>=</span><span> </span><span>a</span><span>/</span><span>(</span><span>1</span><span>-</span><span>(</span><span>e</span><span>*</span><span>sin</span><span>(</span><span>phi</span><span>)</span><span>)</span><span>^</span><span>2</span><span>)</span><span>^</span><span>0.5</span><span>;</span></p><p><span>		</span><span>h</span><span> </span><span>=</span><span> </span><span>p</span><span>/</span><span>cos</span><span>(</span><span>phi</span><span>)</span><span>-</span><span>N</span><span>;</span></p><p><span>		</span><span>delta_h</span><span> </span><span>=</span><span> </span><span>abs</span><span>(</span><span>h</span><span>-</span><span>prev_h</span><span>)</span><span>;</span></p><p><span>	</span><span>end</span></p><p><span>	</span><span>end</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0014 seconds] -->

<h3><span id="1f_format_ephemeris3m"><strong>1.f format_ephemeris3.m</strong></span></h3>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-66945f7a5e2d7835826535" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p></div>
				</td>
						<td><div><p><span>function</span><span> </span><span>eph</span><span> </span><span>=</span><span> </span><span>format_ephemeris3</span><span>(</span><span>eph_</span><span>)</span></p><p><span>eph</span><span> </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p><span>eph</span><span>.</span><span>svid</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>1</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>toc</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>21</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>toe</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>18</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>af0</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>19</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>af1</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>20</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>af2</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>2</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>ura</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>26</span><span>)</span><span>;</span><span> </span><span>%</span><span> </span><span>check</span></p><p><span>eph</span><span>.</span><span>e</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>6</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>sqrtA</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>4</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>dn</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>5</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>m0</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>3</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>w</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>7</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>omg0</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>16</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>i0</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>12</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>odot</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>17</span><span>)</span><span>;</span></p><p><span>%</span><span>eph</span><span>.</span><span>wdot</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>17</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>idot</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>13</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>cus</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>9</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>cuc</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>8</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>cis</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>15</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>cic</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>14</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>crs</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>11</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>crc</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>10</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>iod</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>22</span><span>)</span><span>;</span></p><p><span>eph</span><span>.</span><span>GPSWeek</span><span> </span><span>=</span><span> </span><span>eph_</span><span>(</span><span>24</span><span>)</span><span>;</span></p><p><span>end</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0021 seconds] -->

<h3><span id="2a_Taylor_Series_Expansion_of_Vector_Modulus"><strong>2.a Taylor Series Expansion of Vector Modulus</strong></span></h3>
<p>In the derivation of the position estimation formula, we used the taylor series expansion of the modulus function. The proof is as follows:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-5f5266f1c57117e0aefd86054e8e855a_l3.png" alt="\lVert x \rVert = (x\cdot{x})^{1/2}" title="Rendered by QuickLaTeX.com" height="22" width="117"></p>
<p>First two terms of the taylor series expansion of&nbsp;<img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-fc6339bf8161f6423fe87162e44ebf5d_l3.png" alt="\lVert x \rVert" title="Rendered by QuickLaTeX.com" height="19" width="24"> about <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-ede05c264bba0eda080918aaa09c4658_l3.png" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10"> are:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-f8fd651001030737985bf0df60e9070d_l3.png" alt="\lVert x + \delta{x}\rVert = \lVert x \rVert + \frac{\partial{\lVert x \rVert }}{\partial{x}}\cdot{\delta{x}}" title="Rendered by QuickLaTeX.com" height="26" width="204"></p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-a47d045338c73486a02f7a4aa53d450f_l3.png" alt=" \frac{\partial{\lVert x \rVert }}{\partial{x}} = \frac{1}{2}(x\cdot{x})^{-\frac{1}{2}}2x" title="Rendered by QuickLaTeX.com" height="26" width="153"></p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-5a5a9f5d776c79dcf238930ad62c576c_l3.png" alt=" \frac{\partial{\lVert x \rVert }}{\partial{x}} = \frac{x}{\lVert x \rVert }" title="Rendered by QuickLaTeX.com" height="29" width="79"></p>
<h3><span id="2b_Ionospheric_and_Tropospheric_Delay"><strong>2.b&nbsp;Ionospheric and Tropospheric Delay</strong></span></h3>
<p>The passage of the satellite signal through the earth’s atmosphere changes the speed of the signal and bends the signal path. These effects result in the distance to the satellite calculated by multiplying the time delay between signal&nbsp;transmission and reception with the speed of light to be&nbsp;different from the true distance. Estimating the effect of the atmosphere is important to calculate accurate pseudoranges and thus accurate user position. In the treatment above, we neglected the atmospheric effects. In this section, we’ll provide some information about atmospheric effects and how they are typically modeled. The interested reader is referred to chapter 5 of <span id="w4X0NimVt4133jjruzlIw" data-reflist="[&quot;a5of4cpcm&quot;]" data-footnote="undefined"><sup>1</sup></span>&nbsp;for details.</p>
<p>For the purpose of analyzing its interaction with GPS signals, the earth’s atmosphere can be split into two parts – troposphere and the ionosphere. The ionosphere extends from a height of about 50km to about 1000km above the earth is a region of ionized gases. The ionization is caused by the sun’s radiation and the state of the ionosphere is determined primarily by the intensity of solar activity. Electron density generally builds up during the day as the sun rises, peaking at around 2 PM local time and then starts declining. There can be considerable variability from day to day depending upon the solar activity. The speed of propagation of the signal in the ionosphere depends upon the number of free electrons in the path of the signal, defined as the&nbsp;<em>total electron count&nbsp;</em>(TEC). The number of electrons in a tube of 1<img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-7bd22cca2802b4314e8f06fb217359f5_l3.png" alt="m^2" title="Rendered by QuickLaTeX.com" height="15" width="23"> cross section extending from the receiver to the satellite is given as:</p>
<p><img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-18ccc30107695ad743023464ac380024_l3.png" alt="TEC = \int_S^R n_e(l)dl" title="Rendered by QuickLaTeX.com" height="24" width="142"></p>
<p>where <img decoding="async" loading="lazy" src="https://www.telesens.co/wp-content/ql-cache/quicklatex.com-5e357137369f7249106418d84ec7d492_l3.png" alt="n_e(l)" title="Rendered by QuickLaTeX.com" height="18" width="36"> is the electron density along the signal path and the integral is along the signal path from the satellite to the receiver. The path length through the ionospheric is shortest in the zenith direction (when the satellite is directly overhead) and longest when the satellite is close to the horizon.</p>
<p>In general, ionosphere delays are hard to model as solar flares and magnetic storms can large and rapidly varying fluctuations in electron densities. Two methods are primarily used to estimate ionospheric delays. The first method uses dual frequency GPS measurements and the fact that the ionospheric delay is inversely proportional to the square of the frequency. This enables us to set up a system of equations to estimate the&nbsp;<em>ionosphere free&nbsp;</em>pseudoranges from the noisy pseudoranges.</p>
<p>Receivers limited to single frequency measurements can use an empirical model called the Klobuchar model parameterized by the user’s latitude, longitude, satellite azimuth/elevation, local time and a set of parameters broadcast by the satellites. A step by step implementation of this model is detailed in the GPS Interface Specification and can be easily implemented in Matlab or C.</p>
<p>The troposphere extends to about 16 Km above the equator and contains roughly three quarters of the gaseous mass of the atmosphere. The troposphere is primarily composed of the dry gasses – nitrogen and oxygen, and water vapour. The primary effect of the troposphere on GPS signal propagation is to delay it slightly, causing the apparent range to the satellite to appear longer by about 2.5m, depending on the satellite elevation angle. Unlike the ionosphere, the troposphere is non-dispersive for GPS frequencies, and thus the tropospheric effect can’t be estimated by dual frequency measurements. The amount of delay caused by the troposphere depends on the pressure, temperature and humidity. Various models exist to calculate the delay from meteorological measurements. Refer to chapter 5 of&nbsp;<span id="d5Y66VOIccG6DDPWT9VtV" data-reflist="[&quot;a5of4cpcm&quot;]" data-footnote="undefined"><sup>1</sup></span> for details.</p>
<h3><span id="2c_Plotting_code"><strong>2.c Plotting code</strong></span></h3>
<p>Some people have asked for the plotting code – <a href="https://drive.google.com/open?id=1Gw0lDftAneDrTfqF4C8EmLAa6W3gHifR">here</a> it is.</p>

<div id="abt-bibliography" data-reflist="[&quot;a5of4cpcm&quot;,&quot;g1c8p8q7oq&quot;]">
<div id="a5of4cpcm">
<p>1.</p>
<p>Misra P, Enge P. <i>Global Positioning System</i>. Vol 0. 0th ed. Ganga-Jamuna Press; 2011.</p>
</div>
<div id="g1c8p8q7oq">
<p>2.</p>
<p>None S. <i>Global Positioning System Interface Specification</i>. Global Position Systems Directorate; 2013:213.</p>
</div>
</div>
<!-- kcite active, but no citations found -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I generated 70k audiobooks with OpenAI Text-to-Speech (126 pts)]]></title>
            <link>https://listenly.io/gutenberg</link>
            <guid>40961385</guid>
            <pubDate>Sun, 14 Jul 2024 15:07:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://listenly.io/gutenberg">https://listenly.io/gutenberg</a>, See on <a href="https://news.ycombinator.com/item?id=40961385">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2> Public domain books from Project Gutenberg </h2><p> Collection of more than 70,000 public domain books that can now not only be read, but also listened to, using the latest Text-to-Speech model from OpenAI. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fitting an elephant with four non-zero parameters (210 pts)]]></title>
            <link>https://arxiv.org/abs/2407.07909</link>
            <guid>40961163</guid>
            <pubDate>Sun, 14 Jul 2024 14:27:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2407.07909">https://arxiv.org/abs/2407.07909</a>, See on <a href="https://news.ycombinator.com/item?id=40961163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2407.07909">View PDF</a>
    <a href="https://arxiv.org/html/2407.07909v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>In 1953, Enrico Fermi criticized Dyson's model by quoting Johnny von Neumann: "With four parameters I can fit an elephant, and with five I can make him wiggle his trunk." So far, there have been several attempts to fit an elephant using four parameters, but as the problem has not been well-defined, the current methods do not completely satisfy the requirements. This paper defines the problem and presents an attempt.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Dian Jin [<a href="https://arxiv.org/show-email/38fdf0bb/2407.07909">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 2 Jul 2024 01:37:22 UTC (197 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a Jeopardy game maker with buzzer support (185 pts)]]></title>
            <link>https://buzzinga.io/</link>
            <guid>40960508</guid>
            <pubDate>Sun, 14 Jul 2024 12:20:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buzzinga.io/">https://buzzinga.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40960508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <section data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6="">  <p data-astro-cid-j7pv25f6="">
Create and host your own custom Jeopardy games. Perfect for game nights,
        the classroom, corporate trainings and social events.
</p>  </div> <p><img alt="Buzzinga Jeopardy game board with categories and clues displayed in a grid format" width="1640" height="923" src="https://buzzinga.s3.us-east-2.amazonaws.com/75cdf8146ced554ebae24fd8872f07682f3d62a6a05c78d130b5266d7e111b1b" srcset="
        https://buzzinga.s3.us-east-2.amazonaws.com/8dffb3b84838043249bcd0106cfbf23518b6fb89e80983c7f7fb8b46e36d351c 400w,
        https://buzzinga.s3.us-east-2.amazonaws.com/66c9a79c5094041b458bbf883faf591ba0567609c291807860658b51828c4d2d 600w,
        https://buzzinga.s3.us-east-2.amazonaws.com/0ac5e34670b4bab23875e218e02fe08b82f66f6515b9847bd631955fa930e3ba 800w,
        https://buzzinga.s3.us-east-2.amazonaws.com/24366a4bce0367dfb4c82f0ed9da764c987e3fba2761af54c0dfd50482142fca 1000w,
        https://buzzinga.s3.us-east-2.amazonaws.com/d857b8c8d88d6f9e60af99a2fa8589184cc30cdcb92e9903d29265a4077746dc 1200w,
        https://buzzinga.s3.us-east-2.amazonaws.com/aed7204c487092487d06551dd0243b1018c2449a7cc19187f44e4963adfff681 1640w,
        https://buzzinga.s3.us-east-2.amazonaws.com/75cdf8146ced554ebae24fd8872f07682f3d62a6a05c78d130b5266d7e111b1b 1640w" sizes="(max-width: 1023px) calc(100vw - 68px),
         (min-width: 1024px) and (max-width: 1296px) calc(50vw - 68px),
         (min-width: 1297px) 592px" data-astro-cid-j7pv25f6=""> </p> </section> <ul role="list" data-astro-cid-j7pv25f6=""> <li> <div>  <h2> Built-in buzzer support </h2> <p> Use your phone as a buzzer, or even physical buttons mapped to keyboard keys. </p> </div> </li> <li> <div>  <h2> Automatic score keeping </h2> <p> Keeps track of each team's score automatically </p> </div> </li> <li> <div>  <h2> Effortless host controls </h2> <p> See the answer to every clue and always know which team is selecting the next clue. </p> </div> </li> <li> <div>  <h2> Highly customizable </h2> <p> Create custom categories and clues, including text, audio, images, and video. </p> </div> </li> </ul>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building and scaling Notion's data lake (161 pts)]]></title>
            <link>https://www.notion.so/de-de/blog/building-and-scaling-notions-data-lake</link>
            <guid>40959787</guid>
            <pubDate>Sun, 14 Jul 2024 09:02:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notion.so/de-de/blog/building-and-scaling-notions-data-lake">https://www.notion.so/de-de/blog/building-and-scaling-notions-data-lake</a>, See on <a href="https://news.ycombinator.com/item?id=40959787">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><article><p>In the past three years Notion<!-- -->’<!-- -->s data has expanded 10x due to user and content growth, with a doubling rate of 6-12 months. Managing this rapid growth while meeting the ever-increasing data demands of critical product and analytics use cases, especially our recent Notion AI features, meant building and scaling Notion’s data lake. Here’s how we did it. </p><p>Everything you see in Notion—texts, images, headings, lists, database rows, pages, etc—despite differing front-end representations and behaviors, is modeled as a "block" entity in the back end and stored in the Postgres database with a consistent structure, schema, and associated metadata (learn more about <a href="https://www.notion.so/blog/data-model-behind-notion">Notion's data model</a>).</p><div role="button" aria-label="Lightbox öffnen"><figure><p><span><span></span><img alt="Data Lake initial image" role="img" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://www.notion.so/cdn-cgi/image/format=auto,width=1920,quality=100/https://images.ctfassets.net/spoqsaf9291f/4rrziPDb4W1MWIJd9DU75F/ea42dabcf0bd96470958a47e4f80c1d2/Data_Lake_0.png 1x, https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/4rrziPDb4W1MWIJd9DU75F/ea42dabcf0bd96470958a47e4f80c1d2/Data_Lake_0.png 2x" src="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/4rrziPDb4W1MWIJd9DU75F/ea42dabcf0bd96470958a47e4f80c1d2/Data_Lake_0.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><p>Everything in Notion is a block, and these blocks are made up of data. Lots and lots of data. </p></figcaption></figure></div> <p>All this block data has been doubling every 6 to 12 months, driven by user activity and content creation. At the start of 2021 we had more than 20 billion block rows in Postgres, and this figure has since grown to more than two hundred billion blocks—a data volume of hundreds of terabytes, even when compressed.</p><div><p>To manage this data growth while enhancing the user experience, we’ve strategically expanded our database infrastructure from one Postgres instance to a more complex sharded architecture. We began in 2021 by <a href="https://www.notion.so/blog/sharding-postgres-at-notion">horizontally sharding our Postgres database into 32 physical instances, each comprising 15 logical shards</a>, and continued in 2023 by <a href="https://www.notion.so/blog/the-great-re-shard">increasing the number of physical instances to 96, with five logical shards per instance</a>. Thus we maintained a total of 480 logical shards while ensuring long-term scalable data management and retrieval capabilities.</p></div><div role="button" aria-label="Lightbox öffnen"><figure><p><span><span></span><img alt="Data lake image 1" role="img" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/64NhJVfqvEKp5e5n8efop3/338db6104a05a5bfc8a8eadc4fca73ec/Data_Lake_1.png 1x" src="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/64NhJVfqvEKp5e5n8efop3/338db6104a05a5bfc8a8eadc4fca73ec/Data_Lake_1.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></figure></div> <p>By 2021 Postgres comprised the core of our production infrastructure, handling everything from online user traffic to various offline data analytics and machine learning needs. As the demands on both online and offline data increased, we realized it was essential to build a dedicated data infrastructure to handle offline data without interfering with online traffic.</p><div><p id="notion’s-data-warehouse-architecture-in-2021"><h2><span>Notion’s data warehouse architecture in 2021</span></h2></p></div><p>In 2021, we initiated this dedicated data infrastructure with a simple ELT (Extract, Load, and Transform) pipeline that used the third-party tool Fivetran to ingest data from the Postgres WAL (Write Ahead Log) to Snowflake and set up 480 hourly-run connectors for the 480 shards to write to the same number of raw Snowflake tables. We then merged these tables into a single large table for analytics, reporting, and machine learning use cases.</p><div role="button" aria-label="Lightbox öffnen"><figure><p><span><span></span><img alt="Data lake image 2" role="img" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://www.notion.so/cdn-cgi/image/format=auto,width=1920,quality=100/https://images.ctfassets.net/spoqsaf9291f/4eEtecJis4Q6Pb3PjC9yzf/3eeb2c4c820328192cde31262ec6ff99/Data_Lake_2.png 1x, https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/4eEtecJis4Q6Pb3PjC9yzf/3eeb2c4c820328192cde31262ec6ff99/Data_Lake_2.png 2x" src="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/4eEtecJis4Q6Pb3PjC9yzf/3eeb2c4c820328192cde31262ec6ff99/Data_Lake_2.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></figure></div> <div><p><h3 id="scaling-challenges"><br>Scaling challenges</h3></p></div><p>As our Postgres data grew, we encountered several scaling challenges.</p><p><strong>Operability</strong></p><p>The overhead of monitoring and managing 480 Fivetran connectors, along with re-syncing them during Postgres re-sharding, upgrade, and maintenance periods, became extremely high, creating a significant on-call burden for team members.</p><p><strong>Speed, data freshness and cost</strong> </p><p>Ingesting data to Snowflake became slower and more costly, primarily due to Notion's unique update-heavy workload. Notion users update existing blocks (texts, headings, titles, bullet lists, database rows, etc) much more often than they add new ones. This causes block data to be predominantly update-heavy—90% of Notion upserts are updates. Most data warehouses, including Snowflake, are optimized for insert-heavy workloads, which makes it increasingly challenging for them to ingest block data.</p><p><strong>Use case support</strong></p><p>Data transformation logic became more complex and heavy, surpassing the capabilities of the standard SQL interface offered by off-the-shelf data warehouses. </p><div><ul><li><p>One important use case is constructing denormalized views of Notion’s block data for key products (e.g., AI and Search). Permission data, for example, ensures that only the right people can read or change a block (<a href="https://www.notion.so/blog/data-model-behind-notion">this blog</a> discusses Notion’s block permission model). But a block’s permission isn’t statically stored in the associated Postgres—it has to be constructed on the fly via expensive tree traversal computation.</p></li><li><p>In the following example, <code>block_1</code>, <code>block_2</code>, and <code>block_3 </code>inherit permissions from their immediate parents (<code>page_3 </code>and  <code>page_2</code>) and ancestors (<code>page_1 </code>and <code>workspace_a). </code>To build permission data for each of these blocks, we must traverse its ancestor tree all the way up to the root (<code>workspace_a</code>) in order to ensure completeness. With hundreds of billions of blocks whose ancestor depths ranged from a few to dozens, this kind of compute was very costly and would simply time out in Snowflake.</p></li></ul></div><div role="button" aria-label="Lightbox öffnen"><figure><p><span><span></span><img alt="Data lake image 3" role="img" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://www.notion.so/cdn-cgi/image/format=auto,width=1920,quality=100/https://images.ctfassets.net/spoqsaf9291f/MydQ7FIKshSG7yHcqUBBh/730a7be57bebd5670132b0aa404cfbc2/Data_Lake_3.png 1x, https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/MydQ7FIKshSG7yHcqUBBh/730a7be57bebd5670132b0aa404cfbc2/Data_Lake_3.png 2x" src="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/MydQ7FIKshSG7yHcqUBBh/730a7be57bebd5670132b0aa404cfbc2/Data_Lake_3.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><p>Constructing permission data for each block requires traversing the entire ancestor tree.</p></figcaption></figure></div> <p>Because of these challenges, we started to explore building our data lake.</p><div><p id="building-and-scaling-notion’s-in-house-data-lake"><h2><span>Building and scaling Notion’s in-house data lake</span></h2></p></div><p>Here were our objectives for building an in-house data lake:</p><div><ul><li><p>Establish a data repository capable of storing both raw and processed data at scale.</p></li><li><p>Enable fast, scalable, operable, and cost-efficient data ingestion and computation for any workload—especially Notion's update-heavy block data.</p></li><li><p>Unlock AI, Search, and other product use cases that require denormalized data.</p></li></ul></div><p>However, while our data lake is a big step forward, it's important to clarify what it's not intended to do:</p><div><ul><li><p>Completely replace Snowflake. We’ll continue to benefit from Snowflake’s operational and ecosystem ease by using it for most other workloads, particularly those that are insert-heavy and don’t require large-scale denormalized tree traversal.</p></li><li><p>Completely replace Fivetran. We’ll continue taking advantage of Fivetran’s effectiveness with non-update heavy tables, small dataset ingestion, and diverse third-party data sources and destinations.</p></li><li><p>Support online use cases that require second-level or stricter latency. The Notion data lake will primarily focus on offline workloads that can tolerate minutes to hours of latency.</p></li></ul></div><div><p><h3 id="our-data-lake’s-high-level-design"><strong>Our data lake’s high-level design</strong></h3></p></div><p>Since 2022 we’ve used the in-house data lake architecture shown below. We ingest incrementally updated data from Postgres to Kafka using Debezium CDC connectors, then use <a href="https://hudi.apache.org/">Apache Hudi</a>, an open-source data processing and storage framework, to write these updates from Kafka to S3. With this raw data we can then do transformation, denormalization (e.g., tree traversal and permission data construction for each block), and enrichment, then store the processed data in S3 again or in downstream systems to serve analytics and reporting needs, as well as AI, Search, and other product requirements.</p><div role="button" aria-label="Lightbox öffnen"><figure><p><span><span></span><img alt="Data lake image 4" role="img" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/47gLr3QRSWQ9MpPbvE54Nf/2d232b1d4a0ea226f07852d6d824b490/Data_Lake_4.png 1x" src="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/47gLr3QRSWQ9MpPbvE54Nf/2d232b1d4a0ea226f07852d6d824b490/Data_Lake_4.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><p>Notion’s in-house data lake is built on Debezium CDC connector, Kafka, Hudi, Spark, and S3.</p></figcaption></figure></div> <p>Next we’ll describe and illustrate the design principles and decisions we arrived at after extensive research, discussion, and prototyping work.</p><div><p><h3 id="design-decision-1-choosing-a-data-repository-and-lake"><strong>Design decision 1: Choosing a data repository and lake</strong></h3></p></div><p>Our first decision was to use S3 as a data repository and lake to store all raw and processed data, and position data warehouse and other product-facing data stores such as ElasticSearch, Vector Database, Key-Value store, etc as its downstream. We made this decision for two reasons:</p><div><ul><li><p>It aligned with Notion’s AWS tech stack, e.g., our Postgres database is based on AWS RDS and its export-to-S3 feature (described in later sections) allows us to easily bootstrap tables in S3.</p></li><li><p>S3 has proven its ability to store large amounts of data and support various data processing engines (like Spark) at low cost.</p></li></ul></div><p>By offloading heavy ingestion and compute workloads to S3 and only ingesting highly cleaned and business-critical data to Snowflake and product-facing data stores, we significantly improved data compute scalability and speed and reduced cost.</p><div><p><h3 id="design-decision-2-choosing-our-processing-engine"><strong>Design decision 2: Choosing our processing engine</strong></h3></p></div><p>We chose Spark as our main data processing engine because as an open-source framework, it could be rapidly set up and evaluated to verify that it met our data transformation needs. Spark has four key benefits:</p><div><ul><li><p>Spark’s wide range of built-in functions and UDFs (User Defined Functions) beyond SQL enable complex data processing logics like tree traversal and block data denormalization, as described above.</p></li><li><p>It offers a user-friendly PySpark framework for most lighter use cases, and advanced Scala Spark for high-performance, heavy data processing.</p></li><li><p>It processes large-scale data (e.g., billions of blocks and hundreds of terabytes) in a distributed manner, and exposes extensive configurations, which allows us to fine-tune our control over partitioning, data skewness, and resource allocation. It also enables us to break down complex jobs into smaller tasks and optimize resourcing for each task, which helps us achieve reasonable runtime without over-provisioning or wasting resources.</p></li><li><p>Finally, Spark’s open-source nature offers cost-efficiency benefits.</p></li></ul></div><div><p><h3 id="design-decision-3-preference-for-incremental-ingestion-over-snapshot-dump">Design decision 3: Preference for incremental ingestion over snapshot dump</h3></p></div><p>After finalizing our data lake storage and processing engine, we explored solutions for ingesting Postgres data to S3. We wound up considering two approaches: incremental ingestion of changed data and periodic full snapshots of Postgres tables. In the end, based on performance and cost comparisons, we opted for a hybrid design:</p><div><ul><li><p><strong>During normal operations, incrementally ingest and continuously apply changed Postgres data to S3.</strong></p></li><li><p><strong>In rare cases, take a full Postgres snapshot once to bootstrap tables in S3.</strong></p></li></ul></div><p>The incremental approach ensures fresher data at lower cost and with minimal delay (a few minutes to a couple hours, depending on table size). Taking a full snapshot and dumping to S3, by contrast, takes more than 10 hours and costs twice as much, so we do so infrequently, when bootstraping new tables in S3.</p><div><p><h3 id="design-decision-4-streamlining-incremental-ingestion"><strong>Design decision 4: Streamlining incremental ingestion</strong></h3></p></div><div><ul><li><p><strong>Kafka CDC Connector for Postgres → to → Kafka</strong></p></li></ul></div><p>We chose the Kafka Debezium CDC (Change Data Capture) connector to publish incrementally changed Postgres data to Kafka, similar to Fivetran’s data ingestion method. We chose it together with Kafka for their scalability, ease of setup, and close integration with our existing infrastructure. </p><div><ul><li><p><strong>Hudi for Kafka → to → S3</strong></p></li></ul></div><div><p>To ingest the incremental data from Kafka to S3, we considered three excellent data lake and ingestion solutions: <a href="https://hudi.apache.org/">Apache Hudi</a>, <a href="https://iceberg.apache.org/">Apache Iceberg</a>, and <a href="https://delta.io/">DataBricks Delta Lake</a>. In the end we chose Hudi for its excellent performance with our update-heavy workload and its open-source nature and native <a href="https://cwiki.apache.org/confluence/display/HUDI/RFC+-+39+Deltastreamer+source+for+debezium+CDC+logs">integration with Debezium CDC messages</a>.</p></div><p>Iceberg and Delta Lake, on the other hand, weren’t optimized for our update-heavy workload when we considered them in 2022. Iceberg also lacked an out-of-box solution that understands Debezium messages; Delta Lake does have one, but it isn’t open source. We would have had to implement our own Debezium consumer if we’d gone with either of those solutions.</p><div><p><h3 id="design-decision-5-ingest-raw-data-before-processing"><strong>Design decision 5: Ingest raw data before processing</strong></h3></p></div><p>Finally, we decided to ingest raw Postgres data to S3 without on-the-fly processing in order to establish a single source of truth and simplify debugging across the entire data pipeline. Once raw data is in S3, we then do transformation, denormalization, enrichment, and other types of data processing. We store intermediate data in S3 again and only ingest highly cleaned, structured, and business-critical data to downstream systems for analytics, reporting, and product needs.</p><div><p id="scaling-and-operating-our-data-lake"><h2><span>Scaling and operating our data lake</span></h2></p></div><p>We experimented with many detailed setups in order to tackle the scalability challenges associated with Notion’s ever-increasing data volume. Here's what we tried and how it went:</p><p><strong>1. CDC connector and Kafka setup</strong></p><p>We set up one Debezium CDC connector per Postgres host and deploy them in an AWS EKS cluster. Because of the maturity of Debezium and EKS management and Kafka's scalability, we’ve only had to upgrade the EKS and Kafka clusters a few times in the past two years. As of May 2024, it smoothly handles tens of MB/sec of Postgres row changes.</p><p>We also configure one Kafka topic per Postgres table and let all connectors consuming from 480 shards write to the same topic for that table. This setup significantly reduced the complexity of maintaining 480 topics for each table and simplified downstream Hudi ingestion to S3, significantly reducing operational overhead.</p><p><strong>2. Hudi setup</strong></p><p>We used <a href="https://hudi.apache.org/docs/0.10.0/hoodie_deltastreamer/">Apache Hudi Deltastreamer</a>, a Spark-based ingestion job, to consume Kafka messages and replicate the state of Postgres table in S3. After several rounds of performance tuning, we established a fast, scalable ingestion setup to ensure data freshness. This setup provides a delay of just a few minutes for most tables, and up to two hours for the largest one, the block table (see graphic below).</p><div><ul><li><p>We use the default COPY_ON_WRITE Hudi table type with UPSERT operation, which suits our update-heavy workload.</p></li><li><p>To manage data more effectively and minimize write amplification (i.e., the number of files updated per batched ingestion run), we fine-tuned three configurations: </p><div><ul><li><p>Partition/shard data using the same Postgres shard scheme, i.e., the  <code>hoodie.datasource.write.partitionpath.field: db_schema_source_partition</code> config. This partitions the S3 dataset into 480 shards, from <code>shard0001 </code>to <code>shard0480,</code> making it more likely that a batch of incoming updates map to the same set of files from the same shard.</p></li><li><p>Sort data based on the last updated time (event_lsn), i.e., the <code>source-ordering-field: event_lsn</code> config. This is based on our observation that more recent blocks are more likely to get updated, which allows us to prune files with only outdated blocks.</p></li><li><p>Set the index type to be bloom filter, i.e., the  <code>hoodie.index.type: BLOOM</code></p><p> config, to further optimize the workload.</p></li></ul></div></li></ul></div><div role="button" aria-label="Lightbox öffnen"><figure><p><span><span></span><img alt="Data lake image 5" role="img" loading="lazy" decoding="async" data-nimg="intrinsic" srcset="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/2lSK1kBy9dHNg9UF5HU4gs/72ddf2a3cf506ccaed49ce75af8d536f/Data_Lake_5.png 1x" src="https://www.notion.so/cdn-cgi/image/format=auto,width=3840,quality=100/https://images.ctfassets.net/spoqsaf9291f/2lSK1kBy9dHNg9UF5HU4gs/72ddf2a3cf506ccaed49ce75af8d536f/Data_Lake_5.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><p>Hudi Deltastreamer setup for the block table.</p></figcaption></figure></div> <p><strong>3. Spark data processing setup</strong>For the majority of our data processing jobs we utilize PySpark, whose relatively low learning curve makes it accessible to many team members. For more complex jobs such as tree traversal and denormalization, we leverage Spark’s superior performance in several key areas:</p><div><ul><li><p>We benefit from the performance efficiency of the Scala Spark.</p></li><li><p>We manage data more effectively by handling large and small shards separately (remember we kept the same 480 shards scheme in S3 to be consistent with Postgres); small shards have their entire data loaded into the Spark task container memory for fast processing, whereas large shards that exceed memory capacity are managed through disk reshuffling.</p></li><li><p>We utilize multi-threading and parallel processing to speed up processing of 480 shards, allowing us to optimize runtime and efficiency.</p></li></ul></div><p><strong>4. Bootstrap setup</strong></p><p>Here's how we bootstrap new tables:</p><div><ul><li><p>We first set up Debezium Connector to ingest Postgres changes to Kafka.</p></li><li><p>Starting from timestamp <code>t</code>, we kick off a AWS RDS-provided export-to-S3 job to save the latest snapshot of Postgres tables to S3. We then create a Spark job to read those data from S3 and write them to the Hudi table format.</p></li><li><p>Finally, we ensure that all changes made during the snapshotting process are captured by setting up Deltastreamer to read from Kafka messages from <code>t</code>. This step is crucial for maintaining data completeness and integrity.</p></li></ul></div><p>Thanks to the scalability of Spark and Hudi, these three steps usually complete within 24 hours, allowing us to perform re-bootstrap with manageable time to accommodate new table asks and Postgres upgrade and re-sharding operations.</p><div><p id="the-payoff-less-money-more-time-stronger-infrastructure-for-ai"><h2><span>The payoff: less money, more time, stronger infrastructure for AI</span></h2></p></div><p>We started developing our data lake infrastructure in the spring of 2022 and completed it by that fall. Due to the infra's inherently scalable nature, we were able to continually optimize and expand the Debezium EKS clusters, Kafka clusters, Deltastreamer, and Spark job to keep up with Notion's 6-to-12 month data doubling rate without significant overhauls. The payoff was significant:</p><div><ul><li><p>Moving several large, crucial Postgres datasets (some of them tens of TB large) to data lake gave us a net savings of over a million dollars for 2022 and proportionally higher savings in 2023 and 2024.</p></li><li><p>For these datasets, the end-to-end ingestion time from Postgres to S3 and Snowflake decreased from more than a day to a few minutes for small tables and up to a couple of hours for large ones. Re-syncs, when necessary, can be completed within 24 hours without overloading live databases.</p></li><li><p>Most importantly, the changeover unlocked massive data storage, compute, and freshness savings from a variety of analytics and product asks, enabling the successful rollout of Notion AI features in 2023 and 2024. Stay tuned for a detailed post on our Search and AI Embedding RAG Infra built on top of the data lake!</p></li></ul></div><p>We’d like to thank OneHouse and the Hudi open source community for their tremendous and timely support. Great open source support was crucial to our ability to spin up the data lake in just a few months.</p><p><i>As our needs grow and diversify, we continue to enhance our data lake by building automated and self-service frameworks to empower more engineers to manage and develop product use cases based on the data.</i></p><p><i>Interested in helping us build the next generation of Notion’s data management? Apply for our open roles </i><a href="https://www.notion.so/careers">here</a><i>.</i></p></article></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing a BIOS bootloader for 64-bit mode from scratch (173 pts)]]></title>
            <link>https://thasso.xyz/2024/07/13/setting-up-an-x86-cpu.html</link>
            <guid>40959742</guid>
            <pubDate>Sun, 14 Jul 2024 08:46:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thasso.xyz/2024/07/13/setting-up-an-x86-cpu.html">https://thasso.xyz/2024/07/13/setting-up-an-x86-cpu.html</a>, See on <a href="https://news.ycombinator.com/item?id=40959742">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>People say there are things that are complex and there are things that are just complicated. Complexity is considered interesting, complicatedness is considered harmful. The process of setting up an x86_64 CPU is mostly complicated.</p><p>I’ll describe one way to go from a boot sector loaded by the BIOS with the CPU in 16-bit real mode to the CPU set up in 64-bit long mode. The setup is pretty bare-bones and there’s tons more to do.</p><p>To follow along, you need the <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">Intel 64 and IA-32 Architectures Software Developer’s Manual</a>, an assembler (I used <a href="https://www.nasm.us/">nasm</a>), and <a href="https://www.qemu.org/">QEMU</a>. If you don’t have an x86_64 CPU, you should still be able to run everything I describe by emulating an x86 CPU in QEMU. I assume you know x86 assembly and the syntax that nasm uses. I like the <a href="https://cs.lmu.edu/~ray/notes/nasmtutorial/">nasm tutorial by Ray Toal</a> for getting started.</p><p>I was surprised by how readable some of the Intel manual is. The initial chapters in volume 1 do a really good job at providing an overview of the system and explaining the terms used throughout the other volumes. But volume 3: System Programming Guide is most relevant to this discussion. There is an overview of all the operating modes in volume 3, section 2.2 Modes of Operation. The path we’re taking is highlighted in red.</p><p><img src="https://thasso.xyz/public/figures/x86-mode-transitions.png" alt="Overview of x86 mode transitions"></p><p>For everything up to 32-bit mode, take a look at <a href="https://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf">“Writing a Simple Operating System – from Scratch”</a>. It’s unfinished but still very good.</p><h2 id="starting-point-bios"> Starting Point: BIOS <a href="#starting-point-bios"></a></h2><p>After a reset, the x86 CPU is in “real mode”. That mode has a default operand size of 16 bits. You get a 20-bit address space and thus the ability to address 1MB of memory by using segmentation. Real mode is pretty much a backward compatibility mode for the Intel 8086 chip from 1978.</p><p>After the BIOS the first code that runs is that in the boot sector. The BIOS searches the system for a disk where the first sector ends in the magic number <code>0xaa55</code> (i.e., the byte <code>0x55</code> followed by the byte <code>0xaa</code>). It loads that “boot sector” to memory at address <code>0x7c00</code>.</p><p>So the BIOS gives us 512 bytes to work with. We need to use these bytes in order to bootstrap the rest of the bootloader. <a href="https://github.com/jart/sectorlisp">One can fit a surprising amount of stuff in 512 bytes</a>, but it’s easiest to just load some more data from disk first. Fortunately, routines defined by the BIOS remain available to us as long as we’re in real mode.</p><h2 id="boot-sector-setup"> Boot Sector Setup <a href="#boot-sector-setup"></a></h2><p>Let’s set up a simple boot sector. It will just print a message to the screen using BIOS routines and then hang. This way, we know that the tooling works.</p><p>This is the assembly we need:</p><div><pre><code><span>;; src/boot_sector.s</span>

    <span>section</span> <span>.boot_sector</span>
    <span>global</span> <span>__start</span>

    <span>[</span><span>bits</span> <span>16</span><span>]</span>

<span>__start:</span>
    <span>mov</span> <span>bx</span><span>,</span> <span>hello_msg</span>
    <span>call</span> <span>print_string</span>

<span>end:</span>
    <span>hlt</span>
    <span>jmp</span> <span>end</span>

<span>;; Uses the BIOS to print a null-termianted string. The address of the</span>
<span>;; string is found in the bx register.</span>
<span>print_string:</span>
    <span>pusha</span>
    <span>mov</span> <span>ah</span><span>,</span> <span>0x0e</span> <span>; BIOS "display character" function</span>

<span>print_string_loop:</span>
    <span>cmp</span> <span>byte</span> <span>[</span><span>bx</span><span>],</span> <span>0</span>
    <span>je</span> <span>print_string_return</span>

    <span>mov</span> <span>al</span><span>,</span> <span>[</span><span>bx</span><span>]</span>
    <span>int</span> <span>0x10</span> <span>; BIOS video services</span>

    <span>inc</span> <span>bx</span>
    <span>jmp</span> <span>print_string_loop</span>

<span>print_string_return:</span>
    <span>popa</span>
    <span>ret</span>

<span>hello_msg:</span> <span>db</span> <span>"Hello, world!"</span><span>,</span> <span>0</span>
</code></pre></div><p>Plus this <code>Makefile</code>:</p><div><pre><code><span># Makefile
</span>
<span>.PHONY</span><span>:</span> <span>all clean boot</span>

<span>NASM</span> <span>:=</span> nasm <span>-f</span> elf64

<span>BUILD_DIR</span> <span>:=</span> build
<span>SRC_DIR</span> <span>:=</span> src

<span>SRC</span> <span>:=</span> <span>$(</span><span>wildcard</span> <span>$(SRC_DIR)</span>/<span>*</span>.s<span>)</span>
<span>OBJS</span> <span>:=</span> <span>$(</span><span>patsubst</span> <span>$(SRC_DIR)</span>/%.s, <span>$(BUILD_DIR)</span>/%.o, <span>$(SRC)</span><span>)</span>
<span>BOOT_IMAGE</span> <span>:=</span> <span>$(BUILD_DIR)</span>/boot_image

<span>all</span><span>:</span> <span>$(BOOT_IMAGE)</span>

<span>boot</span><span>:</span> <span>$(BOOT_IMAGE)</span>
	qemu-system-x86_64 <span>-no-reboot</span> <span>-drive</span> <span>file</span><span>=</span><span>$&lt;</span>,format<span>=</span>raw,index<span>=</span>0,media<span>=</span>disk

<span>$(BOOT_IMAGE)</span><span>:</span> <span>$(BUILD_DIR)/linked.o</span>
	objcopy <span>-O</span> binary <span>$&lt;</span> <span>$@</span>

<span>$(BUILD_DIR)/linked.o</span><span>:</span> <span>$(OBJS)</span>
	ld <span>-T</span> linker.ld <span>-o</span> <span>$@</span> <span>$^</span>

<span>$(BUILD_DIR)/%.o</span><span>:</span> <span>$(SRC_DIR)/%.s</span>
	<span>@</span><span>mkdir</span> <span>-p</span> <span>$(</span><span>dir</span> <span>$@</span><span>)</span>
	<span>$(NASM)</span> <span>$&lt;</span> <span>-o</span> <span>$@</span>

<span>clean</span><span>:</span>
	<span>$(RM)</span> <span>-r</span> <span>$(BUILD_DIR)</span>
</code></pre></div><p>The linker script <code>linker.ld</code> is important because it makes sure that the code in our boot sector is relocated to the right address in the final image. Specifically, the bootloader loads the boot sector to address <code>0x7c00</code> in memory. So that’s the base address to relocate the boot sector to. In addition, the linker will add the magic number at the end of the boot sector. Other guides I’ve seen do both the offset and the magic number inside the boot sector assembly source file by using features of the assembler, but that’s somewhat hackish.</p><pre><code># linker.ld

MEMORY
{
    boot_sector (rwx) : ORIGIN = 0x7c00, LENGTH = 512
}

ENTRY(__start)
SECTIONS
{
    .boot_sector : { *(.boot_sector); } &gt; boot_sector
    .bootsign (0x7c00 + 510) :
    {
        BYTE(0x55)
        BYTE(0xaa)
    } &gt; boot_sector
}
</code></pre><p>Running <code>make boot</code> should result in a QEMU window and the “Hello, World!” message should be displayed.</p><p><img src="https://thasso.xyz/public/figures/qemu-hello-world-screenshot.png" alt="QEMU screenshot of the hello world message"></p><h2 id="stage-1--loading-stage-2-from-disk"> Stage 1 – Loading Stage 2 From Disk <a href="#stage-1--loading-stage-2-from-disk"></a></h2><p>We can split the bootloader into two stages. Stage 1 is the code in the boot sector. It is everything that the BIOS loads for us. The sole purpose of stage 1 is to load stage 2 into memory. Stage 1 does this by using BIOS-provided routines to load stage 2 into memory.</p><p>In stage 2, we’ll switch from 16-bit real mode to 32-bit protected mode. In protected mode, we can’t use BIOS routines anymore. Without BIOS routines, loading sectors from a disk would become much more involved. So we’ll load a number of sectors from disk into memory and hope for the best. Of course, this is an unsafe technique, but it works for now.</p><p>This is how one can access the disk using BIOS. There’s an <a href="https://wiki.osdev.org/Disk_access_using_the_BIOS_(INT_13h)">osdev.org page</a> on this.</p><div><pre><code><span>;; src/boot_sector.s</span>

<span>;; ...</span>

<span>__start:</span>
    <span>;; ...</span>

    <span>mov</span> <span>si</span><span>,</span> <span>di</span><span>sk_address_packet</span>
    <span>mov</span> <span>ah</span><span>,</span> <span>0x42</span> <span>; BIOS "extended read" function</span>
    <span>mov</span> <span>dl</span><span>,</span> <span>0x80</span> <span>; Drive number</span>
    <span>int</span> <span>0x13</span> <span>; BIOS disk services</span>
    <span>jc</span> <span>error_reading_disk</span>

<span>ignore_disk_read_error:</span>
    <span>SND_STAGE_ADDR</span><span> equ</span> <span>(</span><span>BOOT_LOAD_ADDR</span> <span>+</span> <span>SECTOR_SIZE</span><span>)</span>
    <span>jmp</span> <span>0</span><span>:</span><span>SND_STAGE_ADDR</span>

<span>error_reading_disk:</span>
    <span>;; We accept reading fewer sectors than requested</span>
    <span>cmp</span> <span>word</span> <span>[</span><span>dap_sectors_num</span><span>],</span> <span>READ_SECTORS_NUM</span>
    <span>jle</span> <span>ignore_disk_read_error</span>

    <span>mov</span> <span>bx</span><span>,</span> <span>error_reading_disk_msg</span>
    <span>call</span> <span>print_string</span>

    <span>end:</span>
    <span>;; ...</span>
</code></pre></div><p>And at the end of <code>boot_sector.s</code> put this data:</p><div><pre><code><span>;; src/boot_sector.s</span>

<span>;; ...</span>

    <span>align</span> <span>4</span>
<span>disk_address_packet:</span>
    <span>db</span> <span>0x10</span> <span>; Size of packet</span>
    <span>db</span> <span>0</span> <span>; Reserved, always 0</span>
<span>dap_sectors_num:</span>
    <span>dw</span> <span>READ_SECTORS_NUM</span> <span>; Number of sectors read</span>
    <span>dd</span> <span>(</span><span>BOOT_LOAD_ADDR</span> <span>+</span> <span>SECTOR_SIZE</span><span>)</span> <span>; Destination address</span>
    <span>dq</span> <span>1</span> <span>; Sector to start at (0 is the boot sector)</span>

<span>READ_SECTORS_NUM</span><span> equ</span> <span>64</span>
<span>BOOT_LOAD_ADDR</span><span> equ</span> <span>0x7c00</span>
<span>SECTOR_SIZE</span><span> equ</span> <span>512</span>

<span>hello_msg:</span> <span>db</span> <span>"Hello, world!"</span><span>,</span> <span>13</span><span>,</span> <span>10</span><span>,</span> <span>0</span>
<span>error_reading_disk_msg:</span> <span>db</span> <span>"Error: failed to read disk with 0x13/ah=0x42"</span><span>,</span> <span>13</span><span>,</span> <span>10</span><span>,</span> <span>0</span>
</code></pre></div><p>Lastly we need a stage 2 to jump to and we need to update the linker script. The <code>Makefile</code> remains unchanged.</p><div><pre><code><span>;; src/stage2.s</span>

    <span>section</span> <span>.stage2</span>

    <span>[</span><span>bits</span> <span>16</span><span>]</span>

    <span>mov</span> <span>bx</span><span>,</span> <span>stage2_msg</span>
    <span>call</span> <span>print_string</span>

<span>end:</span>
    <span>hlt</span>
    <span>jmp</span> <span>end</span>

    <span>print_string:</span>
        <span>;; ...</span>

<span>stage2_msg:</span> <span>db</span> <span>"Hello from stage 2"</span><span>,</span> <span>13</span><span>,</span> <span>10</span><span>,</span> <span>0</span>
</code></pre></div><p>I just copied the <code>print_string</code> function so we can test if the jump works. Because this specific function only works with BIOS in real mode, it won’t be of any use to stage 2 once we have switched to protected mode.</p><p>Finally the linker script:</p><pre><code># linker.ld

MEMORY
{
    boot_sector (rwx) : ORIGIN = 0x7c00, LENGTH = 512
    stage2 (rwx) : ORIGIN = 0x7e00, LENGTH = 32768 # 512 * 64
}

ENTRY(__start)
SECTIONS
{
    .boot_sector : { *(.boot_sector); } &gt; boot_sector
    .bootsign (0x7c00 + 510) :
    {
        BYTE(0x55)
        BYTE(0xaa)
    } &gt; boot_sector
    .stage2 : { *(.stage2); } &gt; stage2
}
</code></pre><p><img src="https://thasso.xyz/public/figures/qemu-hello-stage2-screenshot.png" alt="QEMU screenshot of the stage 2 message"></p><h2 id="32-bit-protected-mode"> 32-bit Protected Mode <a href="#32-bit-protected-mode"></a></h2><p>Next, we’ll switch the CPU from real mode (16-bit) to protected mode (32-bit). In protected mode, segmentation is used by default to implement memory protection. Before switching to protected mode, you need to define a Global Descriptor Table (GDT) that contains segment descriptors for all the segments you want to define. Usually, paging is used in favor of segmentation. In fact, in 64-bit long mode, you need to use paging. But for the initial switch to protected mode, segmentation is required.</p><p>The Intel manual describes the “flat model” as a very simple segmentation model that can be implemented in the GDT. The “flat model” comprises a code segment and a data segment. Both of these segments are mapped to the entire linear address space (their base addresses and limits are identical). Using the simplest of all models is fine, since we just want to get to long mode and abandon segmentation in favor of paging.</p><p>The GDT is defined as a contiguous structure in memory. You fill a chunk of memory with the right data and give the CPU the address and the length of the memory chunk. The format of the GDT structure is described in the Intel manual.</p><p>From section “3.4.5 Segment Descriptors”:</p><p><img src="https://thasso.xyz/public/figures/segment-descriptor-layout.png" alt="Screenshot of segment descriptor layout"></p><p>The GDT is just an array of segment descriptors with a “null descriptor” at the start that’s used to catch invalid translations. The fields in the segment descriptor are described in detail in section “3.4.5 Segment Descriptors” of volume 3 of the Intel manual.</p><p>We define the GDT like this:</p><div><pre><code><span>;; include/gdt32.s</span>

    <span>;; Base address of GDT should be aligned on an eight-byte boundary</span>
    <span>align</span> <span>8</span>

<span>gdt32_start:</span>
    <span>;; 8-byte null descriptor (index 0).</span>
    <span>;; Used to catch translations with a null selector.</span>
    <span>dd</span> <span>0x0</span>
    <span>dd</span> <span>0x0</span>

<span>gdt32_code_segment:</span>
    <span>;; 8-byte code segment descriptor (index 1).</span>
    <span>;; First 16 bits of segment limit</span>
    <span>dw</span> <span>0xffff</span>
    <span>;; First 24 bits of segment base address</span>
    <span>dw</span> <span>0x0000</span>
    <span>db</span> <span>0x00</span>
    <span>;; 0-3: segment type that specifies an execute/read code segment</span>
    <span>;;   4: descriptor type flag indicating that this is a code/data segment</span>
    <span>;; 5-6: Descriptor privilege level 0 (most privileged)</span>
    <span>;;   7: Segment present flag set indicating that the segment is present</span>
    <span>db</span> <span>10011010b</span>
    <span>;; 0-3: last 4 bits of segment limit</span>
    <span>;;   4: unused (available for use by system software)</span>
    <span>;;   5: 64-bit code segment flag indicates that the segment doesn't contain 64-bit code</span>
    <span>;;   6: default operation size of 32 bits</span>
    <span>;;   7: granularity of 4 kilobyte units</span>
    <span>db</span> <span>11001111b</span>
    <span>;; Last 8 bits of segment base address</span>
    <span>db</span> <span>0x00</span>

<span>gdt32_data_segment:</span>
    <span>;; Only differences are explained ...</span>
    <span>dw</span> <span>0xffff</span>
    <span>dw</span> <span>0x0000</span>
    <span>db</span> <span>0x00</span>
    <span>;; 0-3: segment type that specifies a read/write data segment</span>
    <span>db</span> <span>10010010b</span>
    <span>db</span> <span>11001111b</span>
    <span>dw</span> <span>0x00</span>

<span>gdt32_end:</span>

<span>;; Value for GDTR register that describes the above GDT</span>
<span>gdt32_pseudo_descriptor:</span>
    <span>;; A limit value of 0 results in one valid byte. So, the limit value of our</span>
    <span>;; GDT is its length in bytes minus 1.</span>
    <span>dw</span> <span>gdt32_end</span> <span>-</span> <span>gdt32_start</span> <span>-</span> <span>1</span>
    <span>;; Start address of the GDT</span>
    <span>dd</span> <span>gdt32_start</span>

<span>CODE_SEG32</span><span> equ</span> <span>gdt32_code_segment</span> <span>-</span> <span>gdt32_start</span>
<span>DATA_SEG32</span><span> equ</span> <span>gdt32_data_segment</span> <span>-</span> <span>gdt32_start</span>
</code></pre></div><p>Switching to protected mode is very easy now. We load the GDT pseudo-descriptor into the GDTR register so that the base address and length of our GDT are known to the system. Lastly, we do a far jump to flush the instruction pipeline.</p><div><pre><code><span>;; src/stage2.s</span>

    <span>section</span> <span>.stage2</span>

    <span>[</span><span>bits</span> <span>16</span><span>]</span>

<span>;; ...</span>

    <span>;; Load GDT and switch to protected mode</span>

    <span>cli</span> <span>; Can't have interrupts during the switch</span>
    <span>lgdt</span> <span>[</span><span>gdt32_pseudo_descriptor</span><span>]</span>

    <span>;; Setting cr0.PE (bit 0) enables protected mode</span>
    <span>mov</span> <span>eax</span><span>,</span> <span>cr0</span>
    <span>or</span> <span>eax</span><span>,</span> <span>1</span>
    <span>mov</span> <span>cr0</span><span>,</span> <span>eax</span>

    <span>;; The far jump into the code segment from the new GDT flushes</span>
    <span>;; the CPU pipeline removing any 16-bit decoded instructions</span>
    <span>;; and updates the cs register with the new code segment.</span>
    <span>jmp</span> <span>CODE_SEG32</span><span>:</span><span>start_prot_mode</span>


    <span>[</span><span>bits</span> <span>32</span><span>]</span>
<span>start_prot_mode:</span>
    <span>;; Old segments are now meaningless</span>
    <span>mov</span> <span>ax</span><span>,</span> <span>DATA_SEG32</span>
    <span>mov</span> <span>ds</span><span>,</span> <span>ax</span>
    <span>mov</span> <span>ss</span><span>,</span> <span>ax</span>
    <span>mov</span> <span>es</span><span>,</span> <span>ax</span>
    <span>mov</span> <span>fs</span><span>,</span> <span>ax</span>
    <span>mov</span> <span>gs</span><span>,</span> <span>ax</span>

<span>;; ...</span>
<span>
%include "include/gdt32.s"
</span></code></pre></div><p>Interrupts are disabled during the switch. After the entire setup is complete, interrupts can be enabled again. This would require extra setup work.</p><p>Now that we’re in protected mode, we can’t use the BIOS routines anymore. To print text, we can write straight to the VGA buffer instead.</p><div><pre><code><span>;; src/stage2.s</span>

<span>;; ...</span>

<span>;; Writes a null-terminated string straight to the VGA buffer.</span>
<span>;; The address of the string is found in the bx register.</span>
<span>print_string32:</span>
    <span>pusha</span>

    <span>VGA_BUF</span><span> equ</span> <span>0xb8000</span>
    <span>WB_COLOR</span><span> equ</span> <span>0xf</span>

    <span>mov</span> <span>edx</span><span>,</span> <span>VGA_BUF</span>

<span>print_string32_loop:</span>
    <span>cmp</span> <span>byte</span> <span>[</span><span>ebx</span><span>],</span> <span>0</span>
    <span>je</span> <span>print_string32_return</span>

    <span>mov</span> <span>al</span><span>,</span> <span>[</span><span>ebx</span><span>]</span>
    <span>mov</span> <span>ah</span><span>,</span> <span>WB_COLOR</span>
    <span>mov</span> <span>[</span><span>edx</span><span>],</span> <span>ax</span>

    <span>add</span> <span>ebx</span><span>,</span> <span>1</span>              <span>; Next character</span>
    <span>add</span> <span>edx</span><span>,</span> <span>2</span>              <span>; Next VGA buffer cell</span>
    <span>jmp</span> <span>print_string32_loop</span>

<span>print_string32_return:</span>
    <span>popa</span>
    <span>ret</span>
</code></pre></div><p>Best print something so that we know the switch worked. Note the message in the top left corner of the screenshot.</p><p><img src="https://thasso.xyz/public/figures/qemu-prot-mode-screenshot.png" alt="QEMU screenshot of the protected mode message"></p><h2 id="64-bit-long-mode"> 64-bit Long Mode <a href="#64-bit-long-mode"></a></h2><p>For this part, refer to “10.8.5 Initializing IA-32e Mode”. Note that Intel calls the 64-bit mode “IA-32e” while AMD refers to it as “long mode” in the AMD64 manual.</p><p>Before switching to long mode, the CPU must be in protected mode and paging must be enabled. We have protected mode now, but we are missing paging.</p><p>I love paging. It’s just very cool. But I’d do a poor job at explaining the concept itself. Philipp Oppermann’s <a href="https://os.phil-opp.com/paging-introduction/">Introduction to Paging</a> from the “Writing an OS in Rust” blog was really useful for me personally. <a href="https://pages.cs.wisc.edu/~remzi/OSTEP/">OSTEP</a> also talks about paging starting chapter 18, although it doesn’t go into the specifics of paging on x86 like Philipp Oppermann’s post does.</p><p>In long mode with Physical Address Extension enabled (PAE, we’ll do that below ), a four level page table is used. The below code generates such a page table at a given address.</p><div><pre><code><span>;; src/stage2.s</span>

<span>;; Builds a 4 level page table starting at the address that's passed in ebx.</span>
<span>build_page_table:</span>
    <span>pusha</span>

    <span>PAGE64_PAGE_SIZE</span><span> equ</span> <span>0x1000</span>
    <span>PAGE64_TAB_SIZE</span><span> equ</span> <span>0x1000</span>
    <span>PAGE64_TAB_ENT_NUM</span><span> equ</span> <span>512</span>

    <span>;; Initialize all four tables to 0. If the present flag is cleared, all other bits in any</span>
    <span>;; entry are ignored. So by filling all entries with zeros, they are all "not present".</span>
    <span>;; Each repetition zeros four bytes at once. That's why a number of repetitions equal to</span>
    <span>;; the size of a single page table is enough to zero all four tables.</span>
    <span>mov</span> <span>ecx</span><span>,</span> <span>PAGE64_TAB_SIZE</span> <span>; ecx stores the number of repetitions</span>
    <span>mov</span> <span>edi</span><span>,</span> <span>ebx</span>             <span>; edi stores the base address</span>
    <span>xor</span> <span>eax</span><span>,</span> <span>eax</span>             <span>; eax stores the value</span>
    <span>rep</span> <span>stosd</span>

    <span>;; Link first entry in PML4 table to the PDP table</span>
    <span>mov</span> <span>edi</span><span>,</span> <span>ebx</span>
    <span>lea</span> <span>eax</span><span>,</span> <span>[</span><span>edi</span> <span>+</span> <span>(</span><span>PAGE64_TAB_SIZE</span> <span>|</span> <span>11b</span><span>)]</span> <span>; Set read/write and present flags</span>
    <span>mov</span> <span>dword</span> <span>[</span><span>edi</span><span>],</span> <span>eax</span>

    <span>;; Link first entry in PDP table to the PD table</span>
    <span>add</span> <span>edi</span><span>,</span> <span>PAGE64_TAB_SIZE</span>
    <span>add</span> <span>eax</span><span>,</span> <span>PAGE64_TAB_SIZE</span>
    <span>mov</span> <span>dword</span> <span>[</span><span>edi</span><span>],</span> <span>eax</span>

    <span>;; Link the first entry in the PD table to the page table</span>
    <span>add</span> <span>edi</span><span>,</span> <span>PAGE64_TAB_SIZE</span>
    <span>add</span> <span>eax</span><span>,</span> <span>PAGE64_TAB_SIZE</span>
    <span>mov</span> <span>dword</span> <span>[</span><span>edi</span><span>],</span> <span>eax</span>

    <span>;; Initialize only a single page on the lowest (page table) layer in</span>
    <span>;; the four level page table.</span>
    <span>add</span> <span>edi</span><span>,</span> <span>PAGE64_TAB_SIZE</span>
    <span>mov</span> <span>ebx</span><span>,</span> <span>11b</span>
    <span>mov</span> <span>ecx</span><span>,</span> <span>PAGE64_TAB_ENT_NUM</span>
<span>set_page_table_entry:</span>
    <span>mov</span> <span>dword</span> <span>[</span><span>edi</span><span>],</span> <span>ebx</span>
    <span>add</span> <span>ebx</span><span>,</span> <span>PAGE64_PAGE_SIZE</span>
    <span>add</span> <span>edi</span><span>,</span> <span>8</span>
    <span>loop</span> <span>set_page_table_entry</span>

    <span>popa</span>
    <span>ret</span>
</code></pre></div><p>Paging supersedes segmentation for managing virtual address spaces, permissions, etc. A Global Descriptor Table with segment descriptors is still needed though, and the segment descriptors must be modified slightly to enable long mode-specific features.</p><p>This is another GDT that also implements the flat model. It’s almost identical to the GDT for protected mode. Just two bits were changed.</p><div><pre><code><span>;; include/gdt64.s</span>

    <span>align</span> <span>16</span>
<span>gdt64_start:</span>
    <span>;; 8-byte null descriptor (index 0).</span>
    <span>dd</span> <span>0x0</span>
    <span>dd</span> <span>0x0</span>

<span>gdt64_code_segment:</span>
    <span>dw</span> <span>0xffff</span>
    <span>dw</span> <span>0x0000</span>
    <span>db</span> <span>0x00</span>
    <span>db</span> <span>10011010b</span>
    <span>;;   5: 64-bit code segment flag indicates that this segment contains 64-bit code</span>
    <span>;;   6: must be zero if L bit (bit 5) is set</span>
    <span>db</span> <span>10101111b</span>
    <span>db</span> <span>0x00</span>

<span>gdt64_data_segment:</span>
    <span>dw</span> <span>0xffff</span>
    <span>dw</span> <span>0x0000</span>
    <span>db</span> <span>0x00</span>
    <span>;; 0-3: segment type that specifies a read/write data segment</span>
    <span>db</span> <span>10010010b</span>
    <span>db</span> <span>10101111b</span>
    <span>dw</span> <span>0x00</span>

<span>gdt64_end:</span>

<span>gdt64_pseudo_descriptor:</span>
    <span>dw</span> <span>gdt64_end</span> <span>-</span> <span>gdt64_start</span> <span>-</span> <span>1</span>
    <span>dd</span> <span>gdt64_start</span>

<span>CODE_SEG64</span><span> equ</span> <span>gdt64_code_segment</span> <span>-</span> <span>gdt64_start</span>
<span>DATA_SEG64</span><span> equ</span> <span>gdt64_data_segment</span> <span>-</span> <span>gdt64_start</span>
</code></pre></div><p>With the page table and the GDT in place, the switch from protected mode to long mode can be performed.</p><div><pre><code><span>;; src/stage2.s</span>

<span>;; ...</span>

<span>start_prot_mode:</span>
    <span>;; ...</span>

    <span>;; Build 4 level page table and switch to long mode</span>
    <span>mov</span> <span>ebx</span><span>,</span> <span>0x1000</span>
    <span>call</span> <span>build_page_table</span>
    <span>mov</span> <span>cr3</span><span>,</span> <span>ebx</span>            <span>; MMU finds the PML4 table in cr3</span>

    <span>;; Enable Physical Address Extension (PAE). This is needed to allow the switch</span>
    <span>mov</span> <span>eax</span><span>,</span> <span>cr4</span>
    <span>or</span> <span>eax</span><span>,</span> <span>1</span> <span>&lt;&lt;</span> <span>5</span>
    <span>mov</span> <span>cr4</span><span>,</span> <span>eax</span>

    <span>;; The EFER (Extended Feature Enable Register) MSR (Model-Specific Register) contains fields</span>
    <span>;; related to IA-32e mode operation. Bit 8 if this MSR is the LME (long mode enable) flag</span>
    <span>;; that enables IA-32e operation.</span>
    <span>mov</span> <span>ecx</span><span>,</span> <span>0xc0000080</span>
    <span>rdmsr</span>
    <span>or</span> <span>eax</span><span>,</span> <span>1</span> <span>&lt;&lt;</span> <span>8</span>
    <span>wrmsr</span>

    <span>;; Enable paging (PG flag in cr0, bit 31)</span>
    <span>mov</span> <span>eax</span><span>,</span> <span>cr0</span>
    <span>or</span> <span>eax</span><span>,</span> <span>1</span> <span>&lt;&lt;</span> <span>31</span>
    <span>mov</span> <span>cr0</span><span>,</span> <span>eax</span>

    <span>mov</span> <span>ebx</span><span>,</span> <span>comp_mode_msg</span>
    <span>call</span> <span>print_string32</span>

    <span>;; New GDT has the 64-bit segment flag set. This makes the CPU switch from</span>
    <span>;; IA-32e compatibility mode to 64-bit mode.</span>
    <span>lgdt</span> <span>[</span><span>gdt64_pseudo_descriptor</span><span>]</span>

    <span>jmp</span> <span>CODE_SEG64</span><span>:</span><span>start_long_mode</span>

    <span>;; ...</span>

    <span>[</span><span>bits</span> <span>64</span><span>]</span>

<span>start_long_mode:</span>
    <span>htl</span>
    <span>jmp</span> <span>start_long_mode</span>

    <span>;; ...</span>
<span>
%include "include/gdt64.s"
</span>
    <span>;; ...</span>

<span>comp_mode_msg:</span> <span>db</span> <span>"</span><span>Entered</span> <span>64</span><span>-</span><span>bit</span> <span>compatibility</span> <span>mode</span><span>"</span><span>,</span> <span>0</span>
</code></pre></div><p>Again, the “success message” should show up in the top left corner. Write a small VGA driver if this annoys you.</p><p><img src="https://thasso.xyz/public/figures/qemu-comp-mode-screenshot.png" alt="QEMU screenshot of the success message"></p><h2 id="using-c"> Using C <a href="#using-c"></a></h2><p>C code can easily be intergrated into this setup. E.g, this might become an OS kernel.</p><div><pre><code><span>/* src/kernel.c */</span>

<span>#define VGA_COLUMNS_NUM 80
#define VGA_ROWS_NUM 25
</span>
<span>#define ARRAY_SIZE(arr) ((int)sizeof(arr) / (int)sizeof((arr)[0]))
</span>
<span>void</span> <span>_start_kernel</span><span>(</span><span>void</span><span>)</span> <span>{</span>
	<span>volatile</span> <span>char</span> <span>*</span><span>vga_buf</span> <span>=</span> <span>(</span><span>char</span> <span>*</span><span>)</span><span>0xb8000</span><span>;</span>
	<span>const</span> <span>char</span> <span>msg</span><span>[]</span> <span>=</span> <span>"Hello from C"</span><span>;</span>
	<span>int</span> <span>i</span><span>;</span>

	<span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>VGA_COLUMNS_NUM</span> <span>*</span> <span>VGA_ROWS_NUM</span> <span>*</span> <span>2</span><span>;</span> <span>i</span><span>++</span><span>)</span>
		<span>vga_buf</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>

	<span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>ARRAY_SIZE</span><span>(</span><span>msg</span><span>)</span> <span>-</span> <span>1</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
		<span>vga_buf</span><span>[</span><span>i</span> <span>*</span> <span>2</span><span>]</span> <span>=</span> <span>msg</span><span>[</span><span>i</span><span>];</span>
		<span>vga_buf</span><span>[</span><span>i</span> <span>*</span> <span>2</span> <span>+</span> <span>1</span><span>]</span> <span>=</span> <span>0x07</span><span>;</span> <span>/* White on black */</span>
	<span>}</span>
<span>}</span>
</code></pre></div><p>Update <code>src/stage2.s</code>:</p><div><pre><code><span>;; src/stage2.s</span>

    <span>;; ...</span>

    <span>[</span><span>bits</span> <span>64</span><span>]</span>

<span>start_long_mode:</span>
    <span>mov</span> <span>ebx</span><span>,</span> <span>long_mode_msg</span>
    <span>call</span> <span>print_string64</span>

    <span>extern</span> <span>_start_kernel</span>
    <span>call</span> <span>_start_kernel</span>

<span>end64:</span>
    <span>hlt</span>
    <span>jmp</span> <span>end64</span>

    <span>;; ...</span>
</code></pre></div><p>The linker script:</p><pre><code># linker.ld

MEMORY
{
    boot_sector (rwx) : ORIGIN = 0x7c00, LENGTH = 512
    stage2 (rwx) : ORIGIN = 0x7e00, LENGTH = 512
    kernel (rwx) : ORIGIN = 0x8000, LENGTH = 0x10000
}

ENTRY(__start)
SECTIONS
{
    .boot_sector : { *(.boot_sector); } &gt; boot_sector
    .bootsign (0x7c00 + 510) :
    {
        BYTE(0x55)
        BYTE(0xaa)
    } &gt; boot_sector
    .stage2 : { *(.stage2); } &gt; stage2
    .text : { *(.text); } &gt; kernel
    .data : { *(.data); } &gt; kernel
    .rodata : { *(.rodata); } &gt; kernel
    .bss :
    {
        *(.bss)
        *(COMMON)
    } &gt; kernel
}
</code></pre><p>Lastly, the <code>Makefile</code> needs to change. Here, I only included the lines that have changed.</p><pre><code># Makefile

# ...

CC := gcc
CFLAGS := -std=c99 -ffreestanding -m64 -mno-red-zone -fno-builtin -nostdinc -Wall -Wextra

# ...

SRC := $(wildcard $(SRC_DIR)/*)
OBJS := $(patsubst $(SRC_DIR)/%, $(BUILD_DIR)/%.o, $(SRC))

# ...

$(BUILD_DIR)/%.s.o: $(SRC_DIR)/%.s
	@mkdir -p $(dir $@)
	$(NASM) $&lt; -o $@

$(BUILD_DIR)/%.c.o: $(SRC_DIR)/%.c
	@mkdir -p $(dir $@)
	$(CC) $(CFLAGS) -c $&lt; -o $@

# ...
</code></pre><p><img src="https://thasso.xyz/public/figures/qemu-c-screenshot.png" alt="QEMU screenshot of the message printed by C code"></p><p>Cool if you actually came along this far. The <a href="https://github.com/thass0/blog-code/tree/main/2024-07-13-setting-up-an-x86-cpu">code is on GitHub</a>.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git-PR: patch requests over SSH (151 pts)]]></title>
            <link>https://pr.pico.sh/</link>
            <guid>40959526</guid>
            <pubDate>Sun, 14 Jul 2024 07:53:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pr.pico.sh/">https://pr.pico.sh/</a>, See on <a href="https://news.ycombinator.com/item?id=40959526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>
        We are trying to build the simplest git collaboration tool. The goal is to make
        self-hosting a git server as simple as running an SSH server -- all without
        sacrificing external collaborators time and energy.
      </p>

      <blockquote>
        <code>git format-patch</code> isn't the problem and pull requests aren't the solution.
      </blockquote>

      <p>
        We are combining mailing list and pull request workflows. In order to build the
        simplest collaboration tool, we needed something as simple as generating patches
        but the ease-of-use of pull requests.
      </p>

      <p>
        The goal is not to create another code forge here. The goal is to create a very
        simple self-hosted git solution with the ability to collaborate with external
        contributors. All the code owner needs to setup a running git server:
      </p>

      <ul><li>A single golang binary</li></ul>

      <p>
        All an external contributor needs is:
      </p>

      <ul>
        <li>An SSH keypair</li>
        <li>An SSH client</li>
      </ul>

      <h2>the problem</h2>

      <p>
        Email is great as a decentralized system to send and receive changes (patchsets)
        to a git repo. However, onboarding a new user to a mailing list, properly
        setting up their email client, and then finally submitting the code contribution
        is enough to make many developers give up. Further, because we are leveraging
        the email protocol for collaboration, we are limited by its feature-set. For
        example, it is not possible to make edits to emails, everyone has a different
        client, those clients have different limitations around plain text email and
        downloading patches from it.
      </p>

      <p>
        Github pull requests are easy to use, easy to edit, and easy to manage. The
        downside is it forces the user to be inside their website to perform reviews.
        For quick changes, this is great, but when you start reading code within a web
        browser, there are quite a few downsides. At a certain point, it makes more
        sense to review code inside your local development environment, IDE, etc. There
        are tools and plugins that allow users to review PRs inside their IDE, but it
        requires a herculean effort to make it usable.
      </p>

      <p>
        Further, self-hosted solutions that mimic a pull request require a lot of
        infrastructure in order to manage it. A database, a web site connected to git,
        admin management, and services to manage it all. Another big point of friction:
        before an external user submits a code change, they first need to create an
        account and then login. This adds quite a bit of friction for a self-hosted
        solution, not only for an external contributor, but also for the code owner who
        has to provision the infra. Often times they also have to fork the repo within
        the code forge before submitting a PR. Then they never make a contribution ever
        again and keep a forked repo around forever. That seems silly.
      </p>

      <h2>introducing patch requests (PR)</h2>

      <p>
        Instead, we want to create a self-hosted git "server" that can handle sending
        and receiving patches without the cumbersome nature of setting up email or the
        limitations imposed by the email protocol. Further, we want the primary workflow
        to surround the local development environment. Github is bringing the IDE to the
        browser in order to support their workflow, we want to flip that idea on its
        head by making code reviews a first-class citizen inside your local development
        environment.
      </p>

      <p>
        We see this as a hybrid between the github workflow of a pull request and
        sending and receiving patches over email.
      </p>

      <p>
        The basic idea is to leverage an SSH app to handle most of the interaction
        between contributor and owner of a project. Everything can be done completely
        within the terminal, in a way that is ergonomic and fully featured.
      </p>

      <p>
        Notifications would happen with RSS and all state mutations would result in the
        generation of static web assets so it can all be hosted using a simple file web
        server.
      </p>

      <h3>format-patch workflow</h3>

      <p>
        The fundamental collaboration tool here is <code>format-patch</code>. Whether you a
        submitting code changes or you are reviewing code changes, it all happens in
        code. Both contributor and owner are simply creating new commits and generating
        patches on top of each other. This obviates the need to have a web viewer where
        the reviewing can "comment" on a line of code block. There's no need, apply the
        contributor's patches, write comments or code changes, generate a new patch,
        send the patch to the git server as a "review." This flow also works the exact
        same if two users are collaborating on a set of changes.
      </p>

      <p>
        This also solves the problem of sending multiple patchsets for the same code
        change. There's a single, central Patch Request where all changes and
        collaboration happens.
      </p>

      <p>
        We could figure out a way to leverage <code>git notes</code> for reviews / comments, but
        honestly, that solution feels brutal and outside the comfort level of most git
        users. Just send reviews as code and write comments in the programming language
        you are using. It's the job of the contributor to "address" those comments and
        then remove them in subsequent patches. This is the forcing function to address
        all comments: the patch won't be merged if there are comment unaddressed in
        code; they cannot be ignored or else they will be upstreamed erroneously.
      </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The six dumbest ideas in computer security (2005) (152 pts)]]></title>
            <link>http://www.ranum.com/security/computer_security/editorials/dumb/</link>
            <guid>40959121</guid>
            <pubDate>Sun, 14 Jul 2024 05:48:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.ranum.com/security/computer_security/editorials/dumb/">http://www.ranum.com/security/computer_security/editorials/dumb/</a>, See on <a href="https://news.ycombinator.com/item?id=40959121">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p>There's lots of innovation going on in security - we're  inundated with a steady stream of new stuff and it all sounds like it works just great. Every couple of months I'm invited to a new computer security conference, or I'm asked to write a foreword for a new computer security book. And, thanks to the fact that it's a topic of public concern and a "safe issue" for politicians, we can expect a flood of computer security-related legislation from lawmakers. So: computer security is definitely still a "hot topic." But why are we spending all this time and money and still having problems?</p>
<p>Let me introduce you to the <em><strong>six dumbest ideas in computer security</strong></em>. What are they? They're the <em><strong>anti-</strong></em>good ideas. They're the braindamage that makes your $100,000 ASIC-based turbo-stateful packet-mulching firewall transparent to hackers. Where do <em><strong>anti-</strong></em>good ideas come from? They come from misguided attempts to do the impossible - which is another way of saying "trying to ignore reality." Frequently those misguided attempts are sincere efforts by well-meaning people or companies who just don't fully understand the situation, but other times it's just a bunch of savvy entrepreneurs with a well-marketed piece of junk they're selling to make a fast buck. In either case, these dumb ideas are the fundamental reason(s) why all that money you spend on information security is going to be wasted, unless you somehow manage to avoid them. </p>
<p>For your convenience, I've listed the dumb ideas in descending order from the most-frequently-seen. If you can avoid falling into the the trap of the first three, you're among the few true computer security elite. </p>
<h2>#1) Default Permit</h2>
<blockquote>
  <p>This dumb idea crops up in a lot of different forms; it's incredibly persistent and difficult to eradicate. Why? Because it's so attractive. Systems based on "Default Permit" are the computer security equivalent of empty calories: tasty, yet fattening.</p>
  <p>The most recognizable form in which the "Default Permit" dumb idea manifests itself is in firewall rules. Back in the very early days of computer security, network managers would set up an internet connection and decide to secure it by turning off incoming telnet, incoming rlogin, and incoming FTP. Everything else was allowed through, hence the name "Default Permit." This put the security practitioner in an endless arms-race with the hackers. Suppose a new vulnerability is found in a service that is not blocked - now the administrators need to decide whether to deny it or not, hopefully, before they got hacked. A lot of organizations adopted "Default Permit" in the early 1990's and convinced themselves it was OK because "hackers will never bother to come after us." The 1990's, with the advent of worms, should have killed off "Default Permit" forever but it didn't. In fact, most networks today are still built around the notion of an open core with no segmentation. That's "Default Permit."</p>
  <p>Another place where "Default Permit" crops up is in how we typically approach code execution on our systems. The default is to permit anything on your machine to execute if you click on it, unless its execution is denied by something like an antivirus program or a spyware blocker. If you think about that for a few seconds, you'll realize what a dumb idea that is. On my computer here I run about 15 different applications on a regular basis. There are probably another 20 or 30 installed that I use every couple of months or so. I still don't understand why operating systems are so dumb that they let any old virus or piece of spyware execute without even asking me. That's "Default Permit."</p>
  <p>A few years ago I worked on analyzing a website's security posture as part of an E-banking security project. The website had a load-balancer in front of it, that was capable of re-vectoring traffic by URL, and my client wanted to use the load-balancer to deflect worms and hackers by re-vectoring attacks to a black hole address. Re-vectoring attacks would have meant adopting a policy of "Default Permit" (i.e.: if it's not a known attack, let it through) but instead I talked them into adopting the opposite approach. The load-balancer was configured to re-vector any traffic <strong><em>not</em></strong> matching a complete list of correctly-structured URLs to a server that serves up image data and 404 pages, which is running a special locked-down configuration. Not surprisingly, that site has withstood the test of time quite well.</p>
  <p>One clear symptom that you've got a case of "Default Permit" is when you find yourself in an arms race with the hackers. It means that you've put yourself in a situation where what you don't know <em><strong>can</strong></em> hurt you, and you'll be doomed to playing keep ahead/catch-up.</p>
  <p>The opposite of "Default Permit" is "Default Deny" and it is a <em><strong>really</strong></em> good idea. It takes  dedication, thought, and understanding to implement a "Default Deny" policy, which is why it is so seldom done. It's not that much harder to do than "Default Permit" but you'll sleep much better at night.</p>
</blockquote>
<h2>#2) Enumerating Badness</h2>
<blockquote>
  <p>Back in the early days of computer security, there were only a relatively small number of well-known security holes. That had a lot to do with the widespread adoption of "Default Permit" because, when there were only 15 well-known ways to hack into a network, it was possible to individually examine and think about those 15 attack vectors and block them. So security practitioners got into the habit of "Enumerating Badness" - listing all the bad things that we know about. Once you list all the badness, then you can put things in place to detect it, or block it.</p>
  <p><strong>Figure 1: </strong>The "Badness Gap"<br>
  <img src="http://www.ranum.com/security/computer_security/editorials/dumb/apps.gif" width="600" height="400">  </p>
  <p>Why is "Enumerating Badness" a dumb idea? It's a dumb idea because sometime around 1992 the amount of Badness in the Internet began to vastly outweigh the amount of Goodness. For every harmless, legitimate, application, there are dozens or hundreds of pieces of malware, worm tests, exploits, or viral code. Examine a typical antivirus package and you'll see it knows about 75,000+ viruses that might infect your machine. Compare that to the legitimate 30 or so apps that I've installed on my machine, and you can see it's rather dumb to try to track 75,000 pieces of Badness when even a simpleton could track 30 pieces of Goodness. In fact, if I were to simply track the 30 pieces of Goodness on my machine, and allow nothing else to run, I would have simultaneously solved the following problems:</p>
</blockquote>
<ul>
  <li>Spyware</li>
  <li>Viruses</li>
  <li>Remote Control Trojans</li>
  <li>Exploits that involve executing pre-installed code that you don't use regularly</li>
</ul>
<blockquote>
  <p>Thanks to all the marketing hype around disclosing and announcing vulnerabilities, there are (according to some industry analysts) between 200 and 700 new pieces of Badness hitting the Internet every month. Not only is "Enumerating Badness" a dumb idea, it's gotten dumber during the few minutes of your time you've bequeathed me by reading this article. </p>
  <p>Now, your typical IT executive, when I discuss this concept with him or her, will stand up and say something like, "That sounds great, but our enterprise network is <em>really</em> complicated. Knowing about all the different apps that we rely on would be impossible! What you're saying sounds reasonable until you think about it and realize how absurd it is!" To which I respond, "How can you call yourself a 'Chief Technology Officer' if you have no idea what your technology is doing?" A CTO isn't going to know detail about every application on the network, but if you haven't got a vague idea what's going on it's impossible to do capacity planning, disaster planning, security planning, or virtually any of the things in a CTO's charter.</p>
  <p>In 1994 I wrote a firewall product that needed some system log analysis routines that would alert the administrator in case some kind of unexpected condition was detected. The first version used "Enumerating Badness" (I've been dumb, too) but the second version used what I termed "<a href="http://www.ranum.com/security/computer_security/papers/ai/index.html">Artificial Ignorance</a>" - a process whereby you <em>throw away the log entries you know aren't interesting</em>. If there's anything left after you've thrown away the stuff you know isn't interesting, then the leftovers <em>must</em> be interesting. This approach worked amazingly well, and detected a number of very interesting operational conditions and errors that it simply never would have occurred to me to look for. </p>
  <p>"Enumerating Badness" is the idea behind a huge number of security products and systems, from anti-virus to intrusion detection, intrusion prevention, application security, and "deep packet inspection" firewalls. What these programs and devices do is<em> outsource</em> your process of knowing what's good. Instead of you taking the time to list the 30 or so legitimate things you need to do, it's easier to pay $29.95/year to someone else who will try to maintain an exhaustive list of all the evil in the world. Except, unfortunately, your badness expert will get $29.95/year for the antivirus list, another $29.95/year for the spyware list, and you'll buy a $19.95 "personal firewall" that has application control for network applications. By the time you're done paying other people to enumerate all the malware your system could come in contact with, you'll more than double the cost of your "inexpensive" desktop operating system.</p>
  <p>One clear symptom that you have a case of "Enumerating Badness" is that you've got a system or software that needs signature updates on a regular basis, or a system that lets past a new worm that it hasn't seen before. The cure for "Enumerating Badness" is, of course, "Enumerating Goodness." Amazingly, there is virtually no support in operating systems for such software-level controls. I've tried using Windows XP Pro's Program Execution Control but it's oriented toward "Enumerating Badness" and is, itself a dumb implementation of a dumb idea. </p>
  <p>In a sense, "Enumerating Badness" is a special dumb-case of "Default Permit" - our #1 dumb computer security idea. But it's so prevalent that it's in a class by itself.</p>
</blockquote>
<h2>#3) Penetrate and Patch </h2>
<blockquote>
  <p>There's an old saying, "You cannot make a silk purse out of a sow's ear." It's pretty much true, unless you wind up using so much silk to patch the sow's ear that eventually the sow's ear is completely replaced with silk. Unfortunately, when buggy software is fixed it is almost always fixed through the addition of new code, rather than the removal of old bits of sow's ear.</p>
  <p>"Penetrate and Patch" is a dumb idea best expressed in the BASIC programming language:</p>
  <pre>10 GOSUB LOOK_FOR_HOLES
20 IF HOLE_FOUND = FALSE THEN GOTO 50<br>30 GOSUB FIX_HOLE<br>40 GOTO 10<br>50 GOSUB CONGRATULATE_SELF<br>60 GOSUB GET_HACKED_EVENTUALLY_ANYWAY<br>70 GOTO 10  </pre>
  <p>In other words, you attack your firewall/software/website/whatever from the outside, identify a flaw in it, fix the flaw, and then go back to looking. One of my programmer buddies refers to this process as "turd polishing" because, as he says, it doesn't make your code any less smelly in the long run but management might enjoy its improved, shiny, appearance in the short term. In other words, the problem with "Penetrate and Patch" is not that it makes your code/implementation/system <em>better by design</em>, rather it merely makes it <em>toughened by trial and error</em>. Richard Feynman's "<a href="http://www.ranum.com/security/computer_security/editorials/dumb/feynman.html">Personal Observations on the Reliability of the Space Shuttle</a>" used to be required reading for the software engineers that I hired. It contains some profound thoughts on expectation of reliability and how it is achieved in complex systems. In a nutshell its meaning to programmers is: "Unless your system was <em>supposed to be hackable </em> then it shouldn't be hackable."</p>
  <p>"Penetrate and Patch" crops up all over the place, and is the primary dumb idea behind the current fad (which has been going on for about 10 years) of vulnerability disclosure and patch updates. The premise of the "vulnerability researchers" is that they are helping the community by finding holes in software and getting them fixed before the hackers find them and exploit them. The premise of the vendors is that they are doing the right thing by pushing out patches to fix the bugs before the hackers and worm-writers can act upon them. Both parties, in this scenario, are being dumb because if the vendors were writing code that had been designed to be secure and reliable then vulnerability discovery would be a tedious and unrewarding game, indeed!</p>
  <p>Let me put it to you in different terms: <em><strong>if "Penetrate and Patch" was effective, we would have run out of security bugs in Internet Explorer by now</strong></em>. What has it been? 2 or 3 a month for 10 years? If you look at major internet applications you'll find that there are a number that consistently have problems with security vulnerabilities. There are also a handful, like PostFix, Qmail, etc, that were engineered to be compartmented against themselves, with modularized permissions and processing, and - not surprisingly - they have histories of amazingly few bugs. The same logic applies to "penetration testing." There are networks that I know of which have been "penetration tested" any number of times and are continually getting hacked to pieces. That's because their design (or their security practices) are so fundamentally flawed that no amount of turd polish is going to keep the hackers out. It just keeps managers and auditors off of the network administrator's backs. I know other networks that it is, literally, pointless to "penetration test" because they were designed from the ground up to be permeable only in certain directions and only to certain traffic destined to carefully configured servers running carefully secured software. Running a "penetration test" for Apache bugs is completely pointless against a server that is running a custom piece of C code that is running in a locked-down portion of an embedded system. So, "Penetrate and Patch" is pointless either because you know you're going to find an endless litany of bugs, or because you know you're not going to find anything comprehensible. Pointless is dumb. </p>
  <p>One clear symptom that you've got a case of "Penetrate and Patch " is when you find that your system is always vulnerable to the "bug of the week." It means that you've put yourself in a situation where every time the hackers invent a new weapon, it works against you. Doesn't that sound dumb? Your software and systems should be <em>secure by design</em> and should have been <em>designed with flaw-handling in mind</em>.</p>
</blockquote>
<h2> #4) Hacking is Cool</h2>
<blockquote>
  <p>One of the best ways to get rid of cockroaches in your kitchen is to scatter bread-crumbs under the stove, right? Wrong! That's a dumb idea. One of the best ways to discourage hacking on the Internet is to give the hackers stock options, buy the books they write about their exploits, take classes on "extreme hacking kung fu" and pay them tens of thousands of dollars to do "penetration tests" against your systems, right? Wrong! "Hacking is Cool" is a really dumb idea.</p>
  <p>Around the time I was learning to walk, Donn Parker was researching the behavioral aspects of hacking and computer security. He says it better than I ever could:<br>
    <em>"Remote computing freed criminals from the historic requirement of proximity to their crimes. Anonymity and freedom from personal victim confrontation increased the emotional ease of crime, i.e., the victim was only an inanimate computer, not a real person or enterprise. Timid people could become criminals. The proliferation of identical systems and means of use and the automation of business made possible and improved the economics of automating crimes and constructing powerful criminal tools and scripts with great leverage."</em></p>
  <p>Hidden in Parker's observation is the awareness that <strong><em>hacking is a social problem</em></strong>. It's not a technology problem, at all. "<em>Timid people could become criminals.</em>" The Internet has given a whole new form of elbow-room to the badly socialized borderline personality. The #4th dumbest thing information security practitioners can do is implicitly encourage hackers by lionizing them. The media plays directly into this, by portraying hackers, variously, as "whiz kids" and "brilliant technologists" - of course if you're a reporter for CNN, anyone who can install Linux probably <em>does</em> qualify as a "brilliant technologist" to you. I find it interesting to compare societal reactions to hackers as "whiz kids" versus spammers as "sleazy con artists." I'm actually heartened to see that the spammers, phishers, and other scammers are adopting the hackers and the techniques of the hackers - this will do more to reverse society's view of hacking than any other thing we could do.</p>
  <p>If you're a security practitioner, teaching yourself how to hack is also part of the "Hacking is Cool" dumb idea. Think about it for a couple of minutes: teaching yourself a bunch of exploits and how to use them means you're investing your time in learning a bunch of tools and techniques that are going to go stale as soon as everyone has patched that particular hole. It means you've made part of your professional skill-set dependent on "Penetrate and Patch" and you're going to have to be part of the arms-race if you want that skill-set to remain relevant and up-to-date. Wouldn't it be more sensible to learn how to design security systems that are hack-proof than to learn how to identify security systems that are dumb? </p>
  <p>My prediction is that the "Hacking is Cool" dumb idea will be a dead idea in the next 10 years. I'd like to fantasize that it will be replaced with its opposite idea, "Good Engineering is Cool" but so far there is no sign that's likely to happen. </p>
</blockquote>
<h2>#5) Educating Users</h2>
<blockquote>
  <p>"Penetrate and Patch" can be applied to human beings, as well as software, in the form of user education. On the surface of things, the idea of "Educating Users" seems less than dumb: education is always good. On the other hand, like "Penetrate and Patch" <em><strong>if it was going to work, it would have worked by now</strong></em>. There have been numerous interesting studies that indicate that a significant percentage of users will trade their password for a candy bar, and the Anna Kournikova worm showed us that nearly 1/2 of humanity will click on anything purporting to contain nude pictures of semi-famous females. If "Educating Users" is the strategy you plan to embark upon, you should expect to have to "patch" your users every week. That's dumb. </p>
  <p>The real question to ask is not "can we educate our users to be better at security?" it is "why do we need to educate our users at all?" In a sense, this is another special case of "Default Permit" - why are users getting executable attachments at all? Why are users expecting to get E-mails from banks where they don't have accounts? Most of the problems that are addressable through user education are self-correcting over time. As a younger generation of workers moves into the workforce, they will come pre-installed with a healthy skepticism about phishing and social engineering.</p>
  <p>Dealing with things like attachments and phishing is another case of "Default Permit" - our favorite dumb idea. After all, if you're letting all of your users get attachments in their E-mail you're "Default Permit"ing anything that gets sent to them. A better idea might be to simply quarantine all attachments as they come into the enterprise, delete all the executables outright, and store the few file types you decide are acceptable on a staging server where users can log in with an SSL-enabled browser (requiring a password will quash a lot of worm propagation mechanisms right away) and pull them down. There are freeware tools like MIMEDefang that can be easily harnessed to strip attachments from incoming E-mails, write them to a per-user directory, and replace the attachment in the E-mail message with a URL to the stripped attachment. Why educate your users how to cope with a problem if you can just drive a stake through the problem's heart? </p>
  <p>When I was CEO of a small computer security start-up we didn't have a Windows system administrator. All of the employees who wanted to run Windows had to know how to install it and manage it <em>themselves</em>, or they didn't get hired in the first place.   My prediction is that in 10 years users that need education will be out of the high-tech workforce entirely, or will be self-training at home in order to stay competitive in the job market. My guess is that this will extend to knowing not to open weird attachments from strangers.</p>
</blockquote>
<h2>#6) Action is Better Than Inaction </h2>
<blockquote>
  <p>IT executives seem to break down into two categories: the "early adopters" and the "pause and thinkers." Over the course of my career, I've noticed that <em>dramatically</em> fewer of the "early adopters" build successful, secure, mission-critical systems. This is because they somehow believe that "Action is Better Than Inaction" - i.e.: if there's a new whizzbang, it's better to install it <em>right now</em> than to wait, think about it, watch what happens to the other early adopters, and then deploy the technology once it's fully sorted-out and has had its first generation of experienced users. I know one senior IT executive - one of the "pause and thinkers" whose plan for doing a wireless roll-out for their corporate network was "wait 2 years and hire a guy who did a successful wireless deployment for a company larger than us." Not only will the technology be more sorted-out by then, it'll be much, much cheaper. What an utterly brilliant strategy!</p>
  <p>There's an important corollary to the "Action is Better Than Inaction" dumb idea, and it's that:<br>
  "<em><strong>It is often easier to not do something dumb than it is to do something smart.</strong></em>"<br>
  Sun Tzu didn't <em>really</em> write that in "<em>The Art of War</em>" but if you tell IT executives that he did, they'll take you much more seriously when you counsel a judicious, thoughtful approach to fielding some new whizzbang. To many of my clients, I have been counselling, "hold off on outsourcing your security for a year or two and then get recommendations and opinions from the bloody, battered survivors - if there are any."</p>
  <p>You can see the "Action is Better Than Inaction" dumb idea all over corporate networks and it tends to correlate with senior IT managers that make their product-purchasing decisions by reading Gartner research reports and product glossies from vendors. If you find yourself in the chain of command of such a manager, I sincerely hope you've enjoyed this article because you're probably far better acquainted with dumbness than I am.</p>
  <p>One extremely useful piece of management kung-fu to remember, if you find yourself up against an "early adopter" is to rely on your peers. Several years ago I had a client who was preparing to spend a ton of money on a technology <em>without testing it operationally</em>. I suggested offhandedly to the senior IT manager in charge that he should send one of his team to a relevant conference (in this case, <a href="http://www.usenix.org/events/lisa05" target="_blank">LISA</a>) where it was likely that someone with hands-on experience with the technology would be in attendance. I proposed that the manager have his employee put a message on the "meet and greet" bulletin board that read:<br>
  "Do you have hands-on experience with <em><strong>xyz</strong></em> from <em><strong>pdq.com</strong></em>? If so, I'm authorized to take you to dinner at Ruth's Chris if you promise to give me the low-down on the product off the record. Contact, etc..." The IT manager later told me that a $200 dinner expense saved them over $400,000 worth of hellish technological trauma.</p>
  <p>It really is easier to not do something dumb than it is to do something smart. The trick is, when you avoid doing something dumb, to make sure your superiors know you navigated around a particularly nasty sand-bar and that you get appropriate credit for being smart. Isn't that the ultimate expression of professional kung-fu? To get <strong><em>credit</em></strong> for <em><strong>not</strong></em> doing <em><strong>anything</strong></em>?!</p>
</blockquote>
<h2>The Minor Dumbs</h2>
<p>These dumb ideas didn't quite merit status as "The Dumb<em>est</em>" ideas in computer security, but they're pretty dumb and deserve mention in passing:</p>
<div> 
  <ul>
    <li>"We're Not a Target" - <em>yes, you are</em>. Worms aren't smart enough to realize that your web site/home network isn't interesting.</li>
    <li>"Everyone would be secure if they all just ran &lt;security-flavor-of-the-month&gt;" - <em>no, they wouldn't</em>. Operating systems have security problems because they are complex and system administration is not a solved problem in computing. Until someone manages to solve system administration, switching to the flavor-of-the-month is going to be <em>more</em> damaging because you're making it harder for your system administrators to gain a level of expertise that only comes with time. </li>
    <li>"We don't need a firewall, we have good host security" - <em>no, you don't</em>. If your network fabric is untrustworthy every single application that goes across the network is potentially a target. 3 words: Domain Naming System.</li>
    <li>"We don't need host security, we have a good firewall" - <em>no, you don't</em>. If your firewall lets traffic through to hosts behind it, then you need to worry about the host security of those systems.</li>
    <li>"Let's go production with it now and we can secure it later" - <em>no, you won't</em>. A better question to ask yourself is "If we don't have time to do it correctly now, will we have time to do it over once it's broken?" Sometimes, building a system that is in constant need of repair means you will spend years investing in turd polish because you were unwilling to spend days getting the job done right in the first place.</li>
    <li>"We can't stop the occasional problem" - <em>yes, you can</em>. Would <em>you</em> travel on commercial airliners if you thought that the aviation industry took this approach with your life? I didn't think so. </li>
  </ul>
</div>
<h2>Goodbye and Good Luck</h2>
<p>I've tried to keep this light-hearted, but my message is serious. Computer security is a field that has fallen far too deeply in love with the whizzbang-of-the-week and has forsaken common sense. Your job, as a security practitioner, is to question - if not outright challenge - the conventional wisdom and the status quo. After all, if the conventional wisdom was working, the rate of systems being compromised would be going <em><strong>down</strong></em>, wouldn't it?</p>
<p><span face="Arial, Helvetica, sans-serif">mjr.<br>
</span><span face="Arial, Helvetica, sans-serif" size="-2">Morrisdale, PA Sept 1, 2005<br>
</span><span size="-2" face="Arial, Helvetica, sans-serif">(A big "thank you" goes to Abe Singer and Tina Bird for contributing a couple dumb ideas, and to Paul Robertson and Fred Avolio for acting as the test choir) </span></p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firmware update hides a device’s Bluetooth fingerprint (118 pts)]]></title>
            <link>https://today.ucsd.edu/story/a-simple-firmware-update-completely-hides-a-devices-bluetooth-fingerprint</link>
            <guid>40958946</guid>
            <pubDate>Sun, 14 Jul 2024 05:01:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://today.ucsd.edu/story/a-simple-firmware-update-completely-hides-a-devices-bluetooth-fingerprint">https://today.ucsd.edu/story/a-simple-firmware-update-completely-hides-a-devices-bluetooth-fingerprint</a>, See on <a href="https://news.ycombinator.com/item?id=40958946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">



		
	
		


	<section id="feature-detail-hero">
		<p>   
			
					
			
			
			<h2>The method is a fix to a vulnerability discovered by the same UC San Diego research team in 2022</h2>
			
		</p>
		
		
		
				
			
			
			
			
			
			
	</section>
	
		<section id="wysiwyg">
    
  
  
    
	 <!-- START DATE STORIES IN NEW FORMAT -->
	 
	 <!-- START OF AUTHORS-BLOCK FOR MOBILE  -->
	 
	 <!-- END OF AUTHORS-BLOCK FOR MOBILE -->
	 
	 

		  <!-- START NEW CONTENT BLOCK -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
							
							
							
						   <p><span><span>A smartphone’s unique Bluetooth fingerprint could be used to track the device’s user–until now. A team of researchers have developed a simple firmware update that can completely hide the Bluetooth fingerprint, eliminating the vulnerability.&nbsp;</span></span></p>

<p><span><span>The method was developed by a team of researchers at the University of California San Diego. The team discovered the vulnerability caused by Bluetooth fingerprints in a </span></span><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833758&amp;casa_token=th7smrBkWK0AAAAA:weeIQrn72d6V3niAV9w0Tay9kilnwFbphvBiXhoVrdLQmXKrBIoAPP2IPnOiQA7iRjYUtqPbUB4"><span><span><span>study they presented at the 2022</span></span></span><span><span><span> IEEE Security &amp; Privacy conference</span></span></span></a><span><span>. They presented the fix to this vulnerability two years later at the </span></span><span><span>2024</span></span><span><span> IEEE Security &amp; Privacy conference.</span></span><span><span> The math behind the update itself is complex but the implementation is not.&nbsp;</span></span></p>

<p><span><span>“We assumed the strongest possible attack, a nation-state type of attacker that would know which algorithm we are using. They still failed,” said Aaron Schulman, one of the paper’s senior authors and a faculty member in the UC San Diego Department of Computer Science and Engineering.</span></span></p>
							

<!-- Begin Giving Bug -->

						</div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
										<!-- 
  This figure is meant to be part of a Article/Feature Detail page. It provides 
  data attributes for the slideshow carousel script to target the image and
  caption for dynamically pulling into the slideshow modal
  - Supported variables
  -- image-src
  -- image-alt
  -- image-caption
  -- image-size
-->

	<figure data-slideshow-item="" data-slideshow-image-src="https://today.ucsd.edu/news_uploads/Nishant_laptop_00_00_22_20_Still002.jpg" data-slideshow-image-alt="Picture of a researcher holding a laptop on his lap" data-slideshow-image-caption="<p>{/exp:typographee}</p><div>Researchers developed a firmware update that hides a device's Bluetooth fingerprint</div>">
	  <img data-src="https://today.ucsd.edu/news_uploads/Nishant_laptop_00_00_22_20_Still002.jpg" alt="Picture of a researcher holding a laptop on his lap" width="705" height="470" src="https://today.ucsd.edu/news_uploads/Nishant_laptop_00_00_22_20_Still002.jpg">
	  
	  <figcaption>
	    <p>Researchers developed a firmware update that hides a device's Bluetooth fingerprint</p>
	  </figcaption>
	  
	</figure>
	
										<p><span><span>Mobile devices, including phones, smartwatches and fitness trackers, constantly transmit signals, known as Bluetooth beacons, at the rate of roughly 500 beacons per minute. These beacons enable features like Apple’s “Find My”--a tracking service to find a lost device as well as COVID-19 tracing apps; and connect smartphones to other devices such as wireless earphones.</span></span></p>

<p><span><span>The current approach taken by smartphone companies to make the devices hard to track by their Bluetooth signals is to randomly change the phone’s identity, its MAC address. However, that doesn’t address the physical-layer fingerprints inherent in each device’s transmissions due to unique hardware imperfections.&nbsp;</span></span></p>

<p><span><span>All wireless devices have small manufacturing imperfections in the hardware used to emit these beacons that are unique to each device. These fingerprints are an accidental byproduct of the manufacturing process. These imperfections in Bluetooth hardware result in unique distortions, which can be used as a fingerprint to track a specific device.&nbsp;</span></span></p>

<p><span><span>The method the researchers developed uses several layers of randomization. The nature of the method is complex, but it’s a bit like using several layers of contact lenses to mask a person’s original eye color–and switching those layers repeatedly and randomly. This method would make it difficult to infer the person’s true eye color–regardless of what the original color actually was.&nbsp;</span></span></p>
										

<!-- Begin Giving Bug -->

								 	</div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
							
						   <p><span><span>The UC San Diego researchers implemented a prototype of this new defense on the Texas Instruments CC2640 chipset currently used in a number of smart devices, such as fitness trackers, tags and lighting systems. They analyzed the impact of different parameters that affect the success of attacks to track and fingerprint a device in practical scenarios. The result of their tests shows that the adversary has to observe a device continuously for more than 10 days to achieve the same level of tracking accuracy as they could achieve within a minute without the firmware update.</span></span></p>

<p><span><span>“This means that the fingerprints are no longer useful for the attacker to infer the identity of the device and the optimal attacker can barely do better than a random guess,” said Professor Dinesh Bharadia, one of the paper’s senior authors and a faculty member in the UC San Diego Department of Electrical and Computer Engineering.&nbsp;</span></span></p>

<p><span><span>“You can’t track the phone’s fingerprint even if you’re sitting right next to it, because both MAC and PHY identities keep changing,” he added.</span></span></p>

<p><span><span>Researchers are now looking for industry partners that can build this technology into their chipsets.&nbsp;</span></span></p>

<p><span><span>“This defense can be rolled out incrementally, requiring only software modification on at least one widely-used Bluetooth Low Energy chipset,” said Hadi Givehchian, the paper’s first author and a Ph.D. student in the UC San Diego Department of Computer Science and Engineering. “But in order to deploy this defense widely, we need to partner with Bluetooth chip manufacturers.”</span></span></p>

<p><span><span>The team also believes that the method would work to obfuscate WiFi fingerprints.</span></span></p>
							

<!-- Begin Giving Bug -->

						</div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
									<!-- 
  This figure is meant to be part of a Article/Feature Detail page. It provides 
  data attributes for the slideshow carousel script to target the image and
  caption for dynamically pulling into the slideshow modal
  - Supported variables
  -- video-src
  -- video-title
  -- video-caption
-->
<figure>
  <p tabindex="0">
    <iframe title="YouTube video title: Bluetooth signals could be used to identify and track smartphones" data-src="https://www.youtube.com/embed/zrU9x-iHgQk?si=rJr7d-jERR2kw8CX?rel=0&amp;disablekb=1" allowfullscreen=""></iframe>
  </p>
  <figcaption>
    In 2022, a team of engineers at the University of California San Diego has demonstrated for the first time that the Bluetooth signals emitted constantly by our mobile phones have a unique fingerprint that can be used to track individuals’ movements. In 2024, they published a fix to the vulnerability. 
  </figcaption>
</figure>
								</div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		    
		  <!-- END CONTENT BLOCK -->
		  
	
	  
      
  

  <!-- START TOPICS & SHARE MOBILE  -->
  <div>
    <!--
  This renders topics, share this, and optional text copy
  - Supported variables
  -- topics
-->

	
	<!-- begin new story format -->
	
		
		
		
		<h2>Share This:</h2>
		
	<!-- end new story format -->	
		

  </div>
  <!-- END TOPICS & SHARE MOIBILE -->
</section>

	

	<div>
    <h2>
      You May Also Like
    </h2>
    
  </div>
	<div id="subscribe">
    <div>
        <h2>Stay in the Know</h2>
        <p>Keep up with all the latest from UC San Diego. Subscribe
          to the newsletter today.
        </p>
      </div>
    <div>
        <form novalidate="" data-subscribe-form="" action="subscribe.html" method="post" data-form_type="newsletter_signup">
          <div>
            <p><label for="subscriber-email">
              Email
            </label>
            </p><div data-validation-message="email">
              <p>Please provide a valid email address.</p></div>
          </div>
          
        </form>
      </div>
  </div>
<!-- START Subscribe Modal -->

<!-- STOP Subscribe Modal -->
			</div><div tabindex="-1" id="categoryNav" aria-labelledby="CategoryNavLabel">
  <p><span id="CategoryNavLabel">Category navigation with
      Social links</span>
    
  </p>
  
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After initially rejecting it, Apple has approved the first PC emulator for iOS (224 pts)]]></title>
            <link>https://www.theverge.com/2024/7/13/24198015/apple-utm-se-pc-os-emulator-for-ios</link>
            <guid>40958465</guid>
            <pubDate>Sun, 14 Jul 2024 02:45:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/7/13/24198015/apple-utm-se-pc-os-emulator-for-ios">https://www.theverge.com/2024/7/13/24198015/apple-utm-se-pc-os-emulator-for-ios</a>, See on <a href="https://news.ycombinator.com/item?id=40958465">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><p><a href="#content">Skip to main content</a></p><div><main><article id="content"><div><div><div><h2>After initially rejecting it, Apple has approved the first PC emulator for iOS</h2><p><span><span> / </span><h2>UTM SE can run ‘run classic software and old-school games’ for Windows, Mac OS 9, and Linux on your iPhone.</h2></span></p></div><div><p><span>By</span> <span><span></span> <span><a href="https://www.theverge.com/authors/wes-davis">Wes Davis</a></span><span>, <span>a weekend editor who covers the latest in tech and entertainment. He has written news, reviews, and more as a tech journalist since 2020.</span></span></span></p><p><time datetime="2024-07-14T01:24:56.733Z"> <!-- -->Jul 14, 2024, 1:24 AM UTC</time></p><div><h2>Share this story</h2></div><p>If you buy something from a Verge link, Vox Media may earn a commission.<!-- --> <a href="https://www.theverge.com/ethics-statement">See our ethics statement.</a></p></div></div><div><figure><span><span></span><img alt="Screenshots from the App Store showing a UTM SE menus and Windows emulation." sizes="(max-width: 768px) calc(100vw - 100px), (max-width: 1180px) 700px, 600px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/16x11/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 16w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/32x21/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 32w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/48x32/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 48w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/64x43/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 64w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/96x64/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 96w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/128x85/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 128w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/256x171/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 256w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/376x251/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/384x256/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/415x277/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/480x320/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/540x360/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/640x427/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/750x500/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/828x552/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/1080x720/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/1200x800/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/1440x960/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/1920x1280/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/2048x1365/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/2400x1600/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x149:2050x1390/2400x1600/filters:focal(1025x732:1026x733):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529711/UTM_SE.png" decoding="async" data-nimg="responsive"></span><div><figcaption><em>Images of UTM SE from its App Store listing.</em></figcaption> <p><cite>Screenshots: UTM SE</cite></p></div></figure></div></div><div><div><p>Apple has approved UTM SE, an app for emulating a computer to run classic software and games, weeks after the company <a href="https://www.theverge.com/2024/6/24/24185066/apple-pc-dos-emulators-ios-rejection">rejected it and barred it</a> from being notarized for third-party app stores in the European Union. The app is <a href="https://go.skimresources.com/?id=1025X1701640&amp;xs=1&amp;url=https%3A%2F%2Fapps.apple.com%2Fus%2Fapp%2Futm-se-retro-pc-emulator%2Fid1564628856">now available for free</a> for iOS, iPadOS, and visionOS.</p><p>After Apple <a href="https://www.theverge.com/2024/6/24/24185066/apple-pc-dos-emulators-ios-rejection">rejected the app in June</a>, the developer said it wasn’t going to keep trying because the app was “a subpar experience.”  Today, UTM thanked the AltStore team for helping it and credited <a href="https://x.com/UTMapp/status/1812241740172263663">another developer</a> “whose QEMU TCTI implementation was pivotal for this JIT-less build.”</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="A screenshot showing options for creating a new virtual machine or downloading a prebuilt one." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/376x436/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/384x446/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/415x482/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/480x557/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/540x627/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/640x743/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/750x870/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/828x961/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/1080x1253/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/1200x1392/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/1440x1671/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/1920x2228/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/2048x2376/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/2400x2785/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1179x1368/2400x2785/filters:focal(590x684:591x685):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25529720/IMG_9D6FCAE5F47F_1.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>UTM SE doesn’t include any virtual machines, but does help you find them.</em></figcaption> <p><cite>Screenshot: UTM SE</cite></p></div></div><p>As with <a href="https://www.theverge.com/24139004/apple-app-store-retro-game-emulators-ios-console-ports-storystream">other emulators on the App Store</a>, you can’t do much with UTM SE out of the box. It doesn’t come with any operating systems, though the app does <a href="https://mac.getutm.app/gallery/">link to UTM’s site</a>, which has guides for Windows XP through Windows 11 emulation, as well as downloads of pre-built virtual Linux machines. Mac OS 9.2.1 and DOS are listed in one screenshot from the UTM SE App Store page.</p><p>Here’s the App Store description for UTM SE:</p><div><blockquote><p>UTM SE is a PC emulator that allows you to run classic software and old-school games.</p><p>* Supports both VGA mode for graphics and terminal mode for text-only operating systems</p><p>* Emulates x86, PPC, and RISC-V architectures</p><p>* Run pre-built machines or create your own configuration from scratch</p><p>* Built from QEMU, a powerful and widely used emulator</p></blockquote></div></div><div><p>Most Popular</p><p>Most Popular</p><ol><li><a href="https://www.theverge.com/2024/7/13/24197477/valve-employs-few-hundred-people-payroll-redacted"><h2>Here’s how much Valve pays its staff — and how few people it employs</h2></a><hr></li><li><a href="https://www.theverge.com/2024/7/13/24198049/trump-x-shooting-conspiracy-theories-trending"><h2>Shooting conspiracies trend on X as Musk endorses Trump</h2></a><hr></li><li><a href="https://www.theverge.com/2024/7/11/24196361/microsoft-xbox-no-console-required-notepad"><h2>No Xbox, no problem</h2></a><hr></li><li><a href="https://www.theverge.com/2024/7/11/24196475/wbd-hbo-originals-max-the-penguin-dune-prophecy"><h2>Max might not be the one to watch after all</h2></a><hr></li><li><a href="https://www.theverge.com/2024/7/13/24198015/apple-utm-se-pc-os-emulator-for-ios"><h2>After initially rejecting it, Apple has approved the first PC emulator for iOS</h2></a><hr></li></ol></div></div></article></main></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No reasonable expectation of privacy in one's Google location data (218 pts)]]></title>
            <link>https://fourthamendment.com/?p=58338</link>
            <guid>40958458</guid>
            <pubDate>Sun, 14 Jul 2024 02:44:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fourthamendment.com/?p=58338">https://fourthamendment.com/?p=58338</a>, See on <a href="https://news.ycombinator.com/item?id=40958458">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>There is no reasonable expectation of privacy in one’s Google location data. It’s willingly shared with Google. <a href="https://www.ca4.uscourts.gov/opinions/224489.P.pdf">United States v. Chatrie</a>, 2024 U.S. App. LEXIS 16692 (4th Cir. July 9, 2024) (2-1):</p><div>
<p>Location History is turned off by default, so a user must take several affirmative steps before Google begins tracking and storing his Location History data. First, he must enable location sharing on his mobile device. Second, he must opt in to the Location History setting on his Google account, either through an internet browser, a Google application (such as Google Maps), or his device settings (for Android devices). Before he can activate the setting, however, Google always presents him language that explains the basics of the service. Third, he must enable the “Location Reporting” feature on his mobile device. And fourth, he must sign in to his Google account on that device. Only when a user follows these steps will Google begin tracking and storing his Location History data. Roughly one-third of active Google users have enabled Location History.</p>



<p>Even after a user opts in, he maintains some control over his location data. He can review, edit, or delete any information that Google has already obtained. So, for instance, he could decide he only wants to keep data for certain dates and to delete the rest. Or he could decide to delete everything. Google also allows him to pause (i.e., disable) the collection of future Location History data. Whatever his choice, Google will honor it. From start to finish, then, the user controls how much Google tracks and stores his Location History data.</p>



<p>Once a user enables Location History, Google constantly monitors his location through GPS, even when he isn’t using his phone. And if he has an Android phone, he can turn on another setting—”Google Location Accuracy”—that enables Google to determine his location using more inputs than just GPS, such as Wi-Fi access points and mobile networks. As a result, Location History can be more precise than other location-tracking mechanisms, including cell-site location information. But whether Google Location Accuracy is activated or not, Location History’s power should not be exaggerated. In the end, it is only an estimate of a device’s location. So when Google records a set of location coordinates, it includes a value (measured in meters) called a “confidence interval,” which represents Google’s confidence in the accuracy of the estimate. Google represents that for any given location point, there is a 68% chance that a user is somewhere within the confidence interval.</p>



<p>Google stores all Location History data in a repository called the “Sensorvault.” The Sensorvault assigns each device a unique identification number and maintains all Location History data associated with that device. Google then uses this data to build aggregate models to assist applications like Google Maps.</p>



<p>In 2016, Google began receiving “geofence warrants” from law enforcement seeking to access location information. A geofence warrant requires Google to produce Location History data for all users who were within a geographic area (called a geofence) during a particular time period. Since 2016, geofence requests have skyrocketed in number: Google claims it saw a 1,500% increase in requests from 2017 to 2018 and a 500% increase from 2018 to 2019. Concerned with the potential threat to user privacy, Google consulted internal counsel and law enforcement agencies in 2018 and developed its own three-step procedure for responding to geofence requests. Since then, Google has objected to any geofence request that disregards this procedure.</p>



<p>Google’s procedure works as follows: At Step One, law enforcement obtains a warrant [*8] that compels Google to disclose an anonymous list of users whose Location History shows they were within the geofence during a specified timeframe. But Google does not keep any lists like this on-hand. So it must first comb through its entire Location History repository to identify users who were present in the geofence. Google then gives law enforcement a list that includes for each user an anonymized device number, the latitude and longitude coordinates and timestamp of each location point, a confidence interval, and the source of the stored Location History (such as GPS or Wi-Fi). Before disclosing this information, Google reviews the request and objects if Google deems it overly broad.</p>



<p>At Step Two, law enforcement reviews the information it receives from Google. If it determines that it needs more, then law enforcement can ask Google to produce additional location coordinates. This time, the original geographical and temporal limits no longer apply; for any user identified at Step One, law enforcement can request information about his movements inside and outside the geofence over a broader period. Yet Google generally requires law enforcement to narrow its request for this more expansive location data to only a subset of the users pinpointed in Step One.</p>



<p>Finally, at Step Three, law enforcement determines which individuals are relevant to the investigation and then compels Google to provide their account-identifying information (usually their names and email addresses). Here, too, Google typically requires law enforcement to taper its request from the previous step, so law enforcement can’t merely request the identity of every user identified in Step Two.</p>
</div><p>Bloomberg: <a href="https://news.bloomberglaw.com/health-law-and-business/geofence-warrant-decision-exposes-hole-in-fourth-amendment-law">Geofence Warrant Decision Exposes Hole in Fourth Amendment Law</a> by Cassandre Coyer &amp; Tonya Riley (“A split appeals court opinion clearing the government’s acquisition of users’ mobile-device location data from Google of constitutional scrutiny will likely spark more friction between emerging technologies and the scope of law enforcement searches, attorneys warned. [¶] The US Court of Appeals for the Fourth Circuit’s ruling in US v. Chatrie concluded, over a dissent, that the use of such geofencing doesn’t constitute a search under the Fourth Amendment.”)</p></div>]]></description>
        </item>
    </channel>
</rss>