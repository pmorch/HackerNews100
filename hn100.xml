<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 17 Nov 2024 18:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Everything Is Just Functions: Mind-Blowing Insights from SICP and David Beazley (139 pts)]]></title>
            <link>https://ezzeriesa.notion.site/1-week-with-David-Beazley-and-SICP-4c440389cf1e43f48fe67c969967f655#58ee6b0435b24e26bd624b33ffed94df</link>
            <guid>42164541</guid>
            <pubDate>Sun, 17 Nov 2024 15:07:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ezzeriesa.notion.site/1-week-with-David-Beazley-and-SICP-4c440389cf1e43f48fe67c969967f655#58ee6b0435b24e26bd624b33ffed94df">https://ezzeriesa.notion.site/1-week-with-David-Beazley-and-SICP-4c440389cf1e43f48fe67c969967f655#58ee6b0435b24e26bd624b33ffed94df</a>, See on <a href="https://news.ycombinator.com/item?id=42164541">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Claude AI built me a React app to compare maps side by side (118 pts)]]></title>
            <link>https://github.com/veloplanner/map-matrix</link>
            <guid>42164141</guid>
            <pubDate>Sun, 17 Nov 2024 13:39:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/veloplanner/map-matrix">https://github.com/veloplanner/map-matrix</a>, See on <a href="https://news.ycombinator.com/item?id=42164141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Map Matrix</h2><a id="user-content-map-matrix" aria-label="Permalink: Map Matrix" href="#map-matrix"></a></p>
<p dir="auto">Compare multiple maps side by side. <a href="https://veloplanner.github.io/map-matrix/" rel="nofollow">Live demo</a></p>
<p dir="auto"><strong>This project was mostly generated by Claude AI.</strong></p>
<p dir="auto">I wanted to develop a simple tool that I needed for <a href="https://veloplanner.com/" rel="nofollow">veloplanner.com</a>. I thought about using this opportunity to try out Claude AI for coding a project from scratch. It worked surprisingly well! I was able to explain my idea and get a working prototype in a few hours. Most of the time I was just copying code from Claude and pasting it into the editor. Later, I started using Cursor AI (with claude-3.5-sonnet model) which improved the experience a lot.</p>
<p dir="auto">You can add custom map source by clicking the "Add Custom Source" button in the navbar.
Configuration is stored in the browser's local storage.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/veloplanner/map-matrix/blob/main/screenshot.png"><img src="https://github.com/veloplanner/map-matrix/raw/main/screenshot.png" alt="screenshot"></a></p>
<p dir="auto">Example of Cursor AI flow:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/veloplanner/map-matrix/blob/main/screenshot-cursor-ai.png"><img src="https://github.com/veloplanner/map-matrix/raw/main/screenshot-cursor-ai.png" alt="screenshot-cursor-ai.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare.com's Robots.txt (101 pts)]]></title>
            <link>https://www.cloudflare.com/robots.txt</link>
            <guid>42163883</guid>
            <pubDate>Sun, 17 Nov 2024 12:39:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cloudflare.com/robots.txt">https://www.cloudflare.com/robots.txt</a>, See on <a href="https://news.ycombinator.com/item?id=42163883">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Bpftune uses BPF to auto-tune Linux systems (144 pts)]]></title>
            <link>https://github.com/oracle/bpftune</link>
            <guid>42163597</guid>
            <pubDate>Sun, 17 Nov 2024 11:38:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/oracle/bpftune">https://github.com/oracle/bpftune</a>, See on <a href="https://news.ycombinator.com/item?id=42163597">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">bpftune - BPF driven auto-tuning</h2><a id="user-content-bpftune---bpf-driven-auto-tuning" aria-label="Permalink: bpftune - BPF driven auto-tuning" href="#bpftune---bpf-driven-auto-tuning"></a></p>
<p dir="auto">bpftune aims to provide lightweight, always-on auto-tuning of system
behaviour.  The key benefit it provides are</p>
<ul dir="auto">
<li>by using BPF observability features, we can continuously monitor
and adjust system behaviour</li>
<li>because we can observe system behaviour at a fine grain (rather
than using coarse system-wide stats), we can tune at a finer grain
too (individual socket policies, individual device policies etc)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">The problem</h2><a id="user-content-the-problem" aria-label="Permalink: The problem" href="#the-problem"></a></p>
<p dir="auto">The Linux kernel contains a large number of tunables; these
often take the form of sysctl(8) parameters, and are usually
introduced for situations where there is no one "right" answer
for a configuration choice.  The number of tunables available
is quite daunting.  On a 6.2 kernel we see</p>
<div data-snippet-clipboard-copy-content="# sysctl --all 2>/dev/null|wc -l
1624"><pre><code># sysctl --all 2&gt;/dev/null|wc -l
1624
</code></pre></div>
<p dir="auto"><a href="https://github.com/leandromoreira/linux-network-performance-parameters">See here for an excellent writeup on network-related tunables.</a>.</p>
<p dir="auto">At the same time, individual systems get a lot less care
and adminstrator attention than they used to; phrases like
"cattle not pets" exemplify this.  Given the modern cloud
architectures used for most deployments, most systems never
have any human adminstrator interaction after initial
provisioning; in fact given the scale requirements, this
is often an explicit design goal - "no ssh'ing in!".</p>
<p dir="auto">These two observations are not unrelated; in an earlier
era of fewer, larger systems, tuning by administrators was
more feasible.</p>
<p dir="auto">These trends - system complexity combined with minimal
admin interaction suggest a rethink in terms of tunable
management.</p>
<p dir="auto">A lot of lore accumulates around these tunables, and to help
clarify why we developed bpftune, we will use a straw-man
version of the approach taken with tunables:</p>
<p dir="auto">"find the set of magic numbers that will work for the
system forever"</p>
<p dir="auto">This is obviously a caricature of how administrators
approach the problem, but it does highlight a critical
implicit assumption - that systems are static.</p>
<p dir="auto">And that gets to the "BPF" in bpftune; BPF provides means
to carry out low-overhead observability of systems. So
not only can we observe the system and tune appropriately,
we can also observe the effect of that tuning and re-tune
if necessary.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key design principles</h2><a id="user-content-key-design-principles" aria-label="Permalink: Key design principles" href="#key-design-principles"></a></p>
<ul dir="auto">
<li>Minimize overhead.  Use observability features sparingly; do not
trace very high frequency events.</li>
<li>Be explicit about policy changes providing both a "what" - what
change was made - and a "why" - how does it help? syslog logging
makes policy actions explicit with explanations</li>
<li>Get out of the way of the administrator.  We can use BPF
observability to see if the admin sets tunable values that we
are auto-tuning; if they do, we need to get out of the way and
disable auto-tuning of the related feature set.</li>
<li>Don't replace tunables with more tunables! bpftune is designed to
be zero configuration; there are no options, and we try to avoid
magic numbers where possible.</li>
<li>Use push-pull approaches. For example, with tcp buffer sizing,
we often want to get out of the way of applications and bump
up tcp sndbuf and rcvbuf, but at a certain point we run the
risk of exhausting TCP memory.  We can however monitor if we
are approaching TCP memory pressure and if so we can tune down
values that we've tuned up.  In this way, we can let the system
find a balance between providing resources and exhausting them.
In some cases, we won't need to tune up values; they may be fine
as they are. But in other cases these limits block optimal performance,
and if they are raised safely - with awareness of global memory
limits - we can get out the way of improved performance.  Another
concern is that increasing buffer size leads to latency - to
handle that, we correlate buffer size changes and TCP smoothed
round-trip time; if the correlation between these exceeds a
threshold (0.7) we stop increasing buffer size.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Concepts</h2><a id="user-content-concepts" aria-label="Permalink: Concepts" href="#concepts"></a></p>
<p dir="auto">The key components are</p>
<ul dir="auto">
<li>
<p dir="auto">tuners: each tuner manages tunables and handles events sent
from BPF programs to userspace via the shared ring buffer.
Each tuner has an associated set of tunables that it manages.</p>
</li>
<li>
<p dir="auto">optional strategies: a tuner can specify multiple strategies;
after running for a while a strategy times out and we assess
if a better strategy is available.  Each strategy specifies a</p>
<ul dir="auto">
<li>name</li>
<li>description</li>
<li>timeout</li>
<li>evaluation function</li>
<li>set of BPF program names in tuner associated with strategy</li>
</ul>
<p dir="auto">Strategies are optional and should be set in the tuner init()
method via bpftune_strategies_add().  See test/strategy
for a coded example.  When a strategy times out, the various
evaluation functions are called and the highest-value evaluation
dictates the next stratgey.</p>
<p dir="auto">Strategies provide a way of providing multiple schemes for
auto-tuning the same set of tunables, where the choice is
guided by an evaluation of the effectiveness of the strategies.</p>
</li>
<li>
<p dir="auto">events specify a</p>
<ul dir="auto">
<li>tuner id: which tuner the event is destined for</li>
<li>a scenario: what happened</li>
<li>an associated netns (if supported)</li>
<li>information about the event (IP address etc)</li>
</ul>
</li>
<li>
<p dir="auto">the tuner then responds to the event guided by the active strategy;
increase or decrease a tunable value, etc.  Describing the event
in the log is key; this allows an admin to understand what
changed and why.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<ul dir="auto">
<li>bpftune is a daemon which manages a set of .so plugin tuners;
each of these is a shared object that is loaded on start-up.</li>
<li>tuners can be enabled or disabled; a tuner is automatically
disabled if the admin changes associated tunables manually.</li>
<li>tuners share a global BPF ring buffer which allows posting of
events from BPF programs to userspace.  For example, if the
sysctl tuner sees a systl being set, it posts an event.</li>
<li>each tuner has an associated id (set when it is loaded),
and events posted contain the tuner id.</li>
<li>each tuner has a BPF component (built using a BPF skeleton)
and a userspace component.  The latter has init(), fini()
and event_handler() entrypoints.  When an event is
received, the tuner id is used to identify the appropriate
event handler and its event_handler() callback function is run.</li>
<li>init, fini and event_handler functions are loaded from the
tuner .so object.</li>
<li>BPF components should include bpftune.bpf.h; it contains
the common map definitions (ringbuf, etc) and shared variables
such as learning rate and tuner ids that each tuner needs.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported tuners</h2><a id="user-content-supported-tuners" aria-label="Permalink: Supported tuners" href="#supported-tuners"></a></p>
<ul dir="auto">
<li>TCP connection tuner: auto-tune choice of congestion control algorithm.
See bpftune-tcp-conn (8).</li>
<li>neighbour table tuner: auto-tune neighbour table sizes by growing
tables when approaching full. See bpftune-neigh (8).</li>
<li>route table tuner: auto-tune route table size by growing tables
when approaching full.  See bpftune-route (8).</li>
<li>sysctl tuner: monitor sysctl setting and if it collides with an
auto-tuned sysctl value, disable the associated tuner.  See
bpftune-sysctl (8).</li>
<li>TCP buffer tuner: auto-tune max and initial buffer sizes.  See
bpftune-tcp-buffer (8).</li>
<li>net buffer tuner: auto-tune tunables related to core networking.
See bpftune-net-buffer (8).</li>
<li>netns tuner: notices addition and removal of network namespaces,
which helps power namespace awareness for bpftune as a whole.
Namespace awareness is important as we want to be able to auto-tune
containers also.  See bpftune-netns (8).</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Code organization</h2><a id="user-content-code-organization" aria-label="Permalink: Code organization" href="#code-organization"></a></p>
<p dir="auto">Both core bpftune.c and individual tuners use the libbpftune library.
It handles logging, tuner init/fini, and BPF init/fini.</p>
<p dir="auto">Each tuner shared object defines an init(), fini() and event_handler()
function. These respectively set up and clean up BPF and handle events
that originate from the BPF code.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">If building the repository manually, simply run</p>
<div data-snippet-clipboard-copy-content="$ make ; sudo make install"><pre><code>$ make ; sudo make install
</code></pre></div>
<p dir="auto">at the top-level of the repository.  bpftune also supports a</p>

<p dir="auto">target, which will make a bpftune RPM.  See ./buildrpm/bpftune.spec</p>
<p dir="auto">We can also build with non-standard libdir for distros which do not
use /usr/lib64 like CachyOS; in this case to install to /usr/lib
instead</p>
<div data-snippet-clipboard-copy-content="$ make libdir=lib
$ sudo make install libdir=lib"><pre><code>$ make libdir=lib
$ sudo make install libdir=lib
</code></pre></div>
<p dir="auto">To build the following packages are needed (names may vary by distro);</p>
<ul dir="auto">
<li>libbpf, libbpf-devel &gt;= 0.6</li>
<li>libcap-devel</li>
<li>bpftool &gt;= 4.18</li>
<li>libnl3-devel</li>
<li>clang &gt;= 11</li>
<li>llvm &gt;= 11</li>
<li>python3-docutils</li>
</ul>
<p dir="auto">From the kernel side, the kernel needs to support BPF ring buffer
(around the 5.6 kernel, though 5.4 is supported on Oracle Linux
as ring buffer support was backported), and kernel BTF is
required (CONFIG_DEBUG_INFO_BTF=y).  Verify /sys/kernel/btf/vmlinux
is present.</p>
<p dir="auto">To enable bpftune as a service</p>
<div data-snippet-clipboard-copy-content="$ sudo service bpftune start"><pre><code>$ sudo service bpftune start
</code></pre></div>
<p dir="auto">...and to enable it by default</p>
<div data-snippet-clipboard-copy-content="$ sudo systemctl enable bpftune"><pre><code>$ sudo systemctl enable bpftune
</code></pre></div>
<p dir="auto">bpftune logs to syslog so /var/log/messages will contain details
of any tuning carried out.</p>
<p dir="auto">bpftune can also be run in the foreground as a program; to redirect
output to stdout/stderr, run</p>

<p dir="auto">On exit, bpftune will summarize any tuning done.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tests</h2><a id="user-content-tests" aria-label="Permalink: Tests" href="#tests"></a></p>
<p dir="auto">Tests are supplied for each tuner in the tests/ subdirectory.
"make test" runs all the tests.  Tests use network namespaces
to simulate interactions with remote hosts. See ./TESTING.md
for more details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Does my system support bpftune?</h2><a id="user-content-does-my-system-support-bpftune" aria-label="Permalink: Does my system support bpftune?" href="#does-my-system-support-bpftune"></a></p>
<p dir="auto">Simply run "bpftune -S" to see:</p>
<div data-snippet-clipboard-copy-content="$ bpftune -S
bpftune works fully
bpftune supports per-netns policy (via netns cookie)"><pre><code>$ bpftune -S
bpftune works fully
bpftune supports per-netns policy (via netns cookie)
</code></pre></div>
<p dir="auto">Two aspects are important here</p>
<ul dir="auto">
<li>does the system support fentry/fexit etc? If so full support
is likely.</li>
<li>does the system support network namespace cookies? If so
per-network-namespace policy is supported.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto">Simply starting bpftune and observing changes made via /var/log/messages
can be instructive.  For example, on a standard VM with sysctl defaults,
I ran</p>

<p dir="auto">...and went about normal development activities such as cloning git
trees from upstream, building kernels, etc.  From the log we see
some of the adjustments bpftune made to accommodate these activities</p>
<div data-snippet-clipboard-copy-content="$ sudo grep bpftune /var/log/messages
...
Apr 19 16:14:59 bpftest bpftune[2778]: bpftune works fully
Apr 19 16:14:59 bpftest bpftune[2778]: bpftune supports per-netns policy (via netns cookie)
Apr 19 16:18:40 bpftest bpftune[2778]: Scenario 'specify bbr congestion control' occurred for tunable 'TCP congestion control' in global ns. Because loss rate has exceeded 1 percent for a connection, use bbr congestion control algorithm instead of default
Apr 19 16:18:40 bpftest bpftune[2778]: due to loss events for 145.40.68.75, specify 'bbr' congestion control algorithm
Apr 19 16:26:53 bpftest bpftune[2778]: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
Apr 19 16:26:53 bpftest bpftune[2778]: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 6291456) -> (4096 131072 7864320)
Apr 19 16:26:53 bpftest bpftune[2778]: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
Apr 19 16:26:53 bpftest bpftune[2778]: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 7864320) -> (4096 131072 9830400)
Apr 19 16:29:04 bpftest bpftune[2778]: Scenario 'specify bbr congestion control' occurred for tunable 'TCP congestion control' in global ns. Because loss rate has exceeded 1 percent for a connection, use bbr congestion control algorithm instead of default
Apr 19 16:29:04 bpftest bpftune[2778]: due to loss events for 140.91.12.81, specify 'bbr' congestion control algorithm"><pre><code>$ sudo grep bpftune /var/log/messages
...
Apr 19 16:14:59 bpftest bpftune[2778]: bpftune works fully
Apr 19 16:14:59 bpftest bpftune[2778]: bpftune supports per-netns policy (via netns cookie)
Apr 19 16:18:40 bpftest bpftune[2778]: Scenario 'specify bbr congestion control' occurred for tunable 'TCP congestion control' in global ns. Because loss rate has exceeded 1 percent for a connection, use bbr congestion control algorithm instead of default
Apr 19 16:18:40 bpftest bpftune[2778]: due to loss events for 145.40.68.75, specify 'bbr' congestion control algorithm
Apr 19 16:26:53 bpftest bpftune[2778]: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
Apr 19 16:26:53 bpftest bpftune[2778]: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 6291456) -&gt; (4096 131072 7864320)
Apr 19 16:26:53 bpftest bpftune[2778]: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
Apr 19 16:26:53 bpftest bpftune[2778]: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 7864320) -&gt; (4096 131072 9830400)
Apr 19 16:29:04 bpftest bpftune[2778]: Scenario 'specify bbr congestion control' occurred for tunable 'TCP congestion control' in global ns. Because loss rate has exceeded 1 percent for a connection, use bbr congestion control algorithm instead of default
Apr 19 16:29:04 bpftest bpftune[2778]: due to loss events for 140.91.12.81, specify 'bbr' congestion control algorithm
</code></pre></div>
<p dir="auto">To deterministically trigger bpftune behaviour, one approach we can
take is to download a large file with inappropriate settings.</p>
<p dir="auto">In one window, set tcp rmem max to a too-low value, and run bpftune
as a program logging to stdout/stderr (-s):</p>
<div data-snippet-clipboard-copy-content="$ sudo sysctl -w net.ipv4.tcp_rmem=&quot;4096 131072 1310720&quot;
net.ipv4.tcp_rmem = 4096 131072 1310720
$ sudo bpftune -s"><pre><code>$ sudo sysctl -w net.ipv4.tcp_rmem="4096 131072 1310720"
net.ipv4.tcp_rmem = 4096 131072 1310720
$ sudo bpftune -s
</code></pre></div>
<p dir="auto">In another window, wget a large file:</p>
<div data-snippet-clipboard-copy-content="$ wget https://yum.oracle.com/ISOS/OracleLinux/OL8/u7/x86_64/OracleLinux-R8-U7-x86_64-dvd.iso"><pre><code>$ wget https://yum.oracle.com/ISOS/OracleLinux/OL8/u7/x86_64/OracleLinux-R8-U7-x86_64-dvd.iso
</code></pre></div>
<p dir="auto">In the first window, we see bpftune tuning up rmem:</p>
<div data-snippet-clipboard-copy-content="bpftune: bpftune works in legacy mode
bpftune: bpftune does not support per-netns policy (via netns cookie)
bpftune: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
bpftune: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 1310720) -> (4096 131072 1638400)"><pre><code>bpftune: bpftune works in legacy mode
bpftune: bpftune does not support per-netns policy (via netns cookie)
bpftune: Scenario 'need to increase TCP buffer size(s)' occurred for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
bpftune: Due to need to increase max buffer size to maximize throughput change net.ipv4.tcp_rmem(min default max) from (4096 131072 1310720) -&gt; (4096 131072 1638400)
</code></pre></div>
<p dir="auto">This occurs multiple times, and on exit (Ctrl+C) we see
the summary of changes made:</p>
<div data-snippet-clipboard-copy-content="bpftune: Summary: scenario 'need to increase TCP buffer size(s)' occurred 9 times for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
bpftune: sysctl 'net.ipv4.tcp_rmem' changed from (4096 131072 1310720 ) -> (4096 131072 9765625 )"><pre><code>bpftune: Summary: scenario 'need to increase TCP buffer size(s)' occurred 9 times for tunable 'net.ipv4.tcp_rmem' in global ns. Need to increase buffer size(s) to maximize throughput
bpftune: sysctl 'net.ipv4.tcp_rmem' changed from (4096 131072 1310720 ) -&gt; (4096 131072 9765625 )
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">For more info</h2><a id="user-content-for-more-info" aria-label="Permalink: For more info" href="#for-more-info"></a></p>
<p dir="auto">See the docs/ subdirectory for manual pages covering bpftune
and associated tuners.</p>
<p dir="auto">bpftune was presented at the eBPF summit; <a href="https://www.youtube.com/watch?v=X0TvfH8hrQE&amp;t=420s" rel="nofollow">video here</a>.</p>
<p dir="auto">bpftune <a href="https://www.youtube.com/watch?v=3ylmGE6sW8w" rel="nofollow">was also discussed on Liz Rice's excellent eCHO eBPF podcast</a>, specifically in the context of using reinforcement learning in BPF</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">This project welcomes contributions from the community. Before submitting a pull request, please <a href="https://github.com/oracle/bpftune/blob/main/CONTRIBUTING.md">review our contribution guide</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">Please consult the <a href="https://github.com/oracle/bpftune/blob/main/SECURITY.md">security guide</a> for our responsible security vulnerability disclosure process</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Copyright (c) 2023 Oracle and/or its affiliates.</p>
<p dir="auto">This software is available to you under</p>
<p dir="auto">SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note</p>
<p dir="auto">Being under the terms of the GNU General Public License version 2.</p>
<p dir="auto">SPDX-URL: <a href="https://spdx.org/licenses/GPL-2.0.html" rel="nofollow">https://spdx.org/licenses/GPL-2.0.html</a></p>
<p dir="auto">See <a href="https://github.com/oracle/bpftune/blob/main/LICENSE.txt">the license file</a> for more details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Constraints in Go (116 pts)]]></title>
            <link>https://bitfieldconsulting.com/posts/constraints</link>
            <guid>42162878</guid>
            <pubDate>Sun, 17 Nov 2024 08:44:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bitfieldconsulting.com/posts/constraints">https://bitfieldconsulting.com/posts/constraints</a>, See on <a href="https://news.ycombinator.com/item?id=42162878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="23" id="block-yui_3_17_2_1_1710022019086_133076"><blockquote>
<p><em>Design is the beauty of turning constraints into
advantages.</em><br>
—<a href="https://talks.ui-patterns.com/videos/design-is-the-beauty-of-turning-constraints-into-advantages-aza-raskin">Aza
Raskin</a> </p>
</blockquote>
<p>This is the fourth in a four-part series of tutorials on generics in
Go.</p>
<ol type="1">
<li><a href="https://bitfieldconsulting.com/posts/generics">Generics</a></li>
<li><a href="https://bitfieldconsulting.com/posts/type-parameters">Type parameters</a></li>
<li><a href="https://bitfieldconsulting.com/posts/generic-types">Generic types</a></li>
<li><strong>Constraints</strong></li>
</ol>
<hr>
<p>In my book <a href="https://bitfieldconsulting.com/books/generics">Know Go</a>, and in the previous
tutorials in this series, you’ll learn all about generic programming in
Go and the new universe of programs it opens up to us. Ironically, one
of the new features of Go that gives us the most freedom is
<em>constraints</em>. Let’s talk about that, and explain the
paradox.</p>
<p>We saw in the <a href="https://bitfieldconsulting.com/posts/generic-types">previous tutorial</a>
that when we’re writing generic functions that take any type, the range
of things we can <em>do</em> with values of that type is necessarily
rather limited. For example, we can’t add them together. For that, we’d
need to be able to prove to Go that they’re one of the types that
support the <code>+</code> operator.</p>
<h2 id="method-set-constraints">Method set constraints</h2>
<p>It’s the same with interfaces, as we discussed in the <a href="https://bitfieldconsulting.com/posts/generics">first post</a> in this series. The empty
interface, <code>any</code>, is implemented by every type, and so
knowing that something implements <code>any</code> tells you nothing
distinctive about it.</p>
<h3 id="limitations-of-the-any-constraint">Limitations of the
<code>any</code> constraint</h3>
<p>Similarly, in a generic function parameterised by some type T,
constraining T to <code>any</code> doesn’t give Go any information about
it. So it has no way to guarantee that a given operator, such as
<code>+</code>, will work with values of T.</p>
<p>A Go proverb says:</p>
<blockquote>
<p><em>The bigger the interface, the weaker the abstraction.</em><br>
—<a href="https://go-proverbs.github.io/">https://go-proverbs.github.io/</a></p>
</blockquote>
<p>And the same is true of constraints. The broader the constraint, and
thus the more types it allows, the less we can guarantee about what
operations we can do on them.</p>
<p>There <em>are</em> a few things we can do with <code>any</code>
values, as you already know, because we’ve done them. For example, we
can declare variables of that type, we can assign values to them, we can
return them from functions, and so on.</p>
<p>But we can’t really do a whole lot of <em>computation</em> with them,
because we can’t use operators like <code>+</code> or <code>-</code>. So
in order to be able to do something useful with values of T, such as
adding them, we need more restrictive constraints.</p>
<p>What kinds of constraints <em>could</em> there be on T? Let’s examine
the possibilities.</p>
<h3 id="basic-interfaces">Basic interfaces</h3>
<p>One kind of constraint that we’re already familiar with in Go is an
<em>interface</em>. In fact, all constraints are interfaces of a kind,
but let’s use the term <em>basic</em> interface here to avoid any
confusion. A basic interface, we’ll say, is one that contains only
method elements.</p>
<p>For example, the <code>fmt.Stringer</code> interface we saw in the <a href="https://bitfieldconsulting.com/posts/generics">first tutorial</a>:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>type</span> Stringer <span>interface</span> <span>{</span></span>
<span id="cb1-2">    String<span>()</span> <span>string</span></span>
<span id="cb1-3"><span>}</span></span></code></pre></div>
<p>We’ve seen that we can write an ordinary, non-generic function that
takes a parameter of type <code>Stringer</code>. And we can also use
this interface as a type constraint for a generic function.</p>
<p>For example, we could write a generic function parameterised by some
type T, but this time T can’t be just any type. Instead, we’ll say that
whatever T turns out to be, it must implement the
<code>fmt.Stringer</code> interface:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>func</span> Stringify<span>[</span>T fmt<span>.</span>Stringer<span>](</span>s T<span>)</span> <span>string</span> <span>{</span></span>
<span id="cb2-2">    <span>return</span> s<span>.</span>String<span>()</span></span>
<span id="cb2-3"><span>}</span></span></code></pre></div>
<p>This is clear enough, and it works the same way as the generic
functions we’ve already written. The only new thing is that we used the
constraint <code>Stringer</code> instead of <code>any</code>. Now when
we actually call this function in a program, we’re only allowed to pass
it arguments that implement <code>Stringer</code>.</p>
<p>What would happen, then, if we tried to call <code>Stringify</code>
with an argument that <em>doesn’t</em> implement <code>Stringer</code>?
We feel instinctively that this shouldn’t work, and it doesn’t:</p>
<div id="cb3"><pre><code><span id="cb3-1">fmt<span>.</span>Println<span>(</span>Stringify<span>(</span><span>1</span><span>))</span></span>
<span id="cb3-2"><span>// int does not implement Stringer (missing method String)</span></span></code></pre></div>
<p>That makes sense. It’s just the same as if we wrote an ordinary,
non-generic function that took a parameter of type
<code>Stringer</code>, as we did in the <a href="https://bitfieldconsulting.com/posts/generics">first
tutorial</a>.</p>
<p>There’s no advantage to writing a generic function in this case,
since we can use this interface type directly in an ordinary function.
All the same, a basic interface—one defined by a set of methods—is a
valid constraint for type parameters, and we can use it that way if we
want to.</p>
<h3 id="exercise-stringy-beans">Exercise: Stringy beans</h3>
<p>Flex your generics muscles a little now, by writing a generic
function constrained by <code>fmt.Stringer</code> to solve the <a href="https://github.com/bitfield/know-go/tree/main/exercises/stringy"><code>stringy</code></a>
exercise.</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>type</span> greeting <span>struct</span><span>{}</span></span>
<span id="cb4-2"></span>
<span id="cb4-3"><span>func</span> <span>(</span>greeting<span>)</span> String<span>()</span> <span>string</span> <span>{</span></span>
<span id="cb4-4">    <span>return</span> <span>"Howdy!"</span></span>
<span id="cb4-5"><span>}</span></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span>func</span> TestStringifyTo_PrintsToSuppliedWriter<span>(</span>t <span>*</span>testing<span>.</span>T<span>)</span> <span>{</span></span>
<span id="cb4-8">    t<span>.</span>Parallel<span>()</span></span>
<span id="cb4-9">    buf <span>:=</span> <span>&amp;</span>bytes<span>.</span>Buffer<span>{}</span></span>
<span id="cb4-10">    stringy<span>.</span>StringifyTo<span>[</span>greeting<span>](</span>buf<span>,</span> greeting<span>{})</span></span>
<span id="cb4-11">    want <span>:=</span> <span>"Howdy!</span><span>\n</span><span>"</span></span>
<span id="cb4-12">    got <span>:=</span> buf<span>.</span>String<span>()</span></span>
<span id="cb4-13">    <span>if</span> want <span>!=</span> got <span>{</span></span>
<span id="cb4-14">        t<span>.</span>Errorf<span>(</span><span>"want %q, got %q"</span><span>,</span> want<span>,</span> got<span>)</span></span>
<span id="cb4-15">    <span>}</span></span>
<span id="cb4-16"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/exercises/stringy/stringy_test.go">Listing
<code>exercises/stringy</code></a>)</p>
<p><strong>GOAL:</strong> Your job here is to write a generic function
<code>StringifyTo[T]</code> that takes an <code>io.Writer</code> and a
value of some arbitrary type constrained by <code>fmt.Stringer</code>,
and prints the value to the writer.</p>
<hr>
<p><strong>HINT:</strong> This is a bit like the
<code>PrintAnything</code> function we saw before, isn’t it? Actually,
it’s a “print anything stringable” function. We already know what the
constraint is (<code>fmt.Stringer</code>), and the rest is
straightforward.</p>
<hr>
<p><strong>SOLUTION:</strong> Here’s a version that would work, for
example:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>func</span> StringifyTo<span>[</span>T fmt<span>.</span>Stringer<span>](</span>w io<span>.</span>Writer<span>,</span> p T<span>)</span> <span>{</span></span>
<span id="cb5-2">    fmt<span>.</span>Fprintln<span>(</span>w<span>,</span> p<span>.</span>String<span>())</span></span>
<span id="cb5-3"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/solutions/stringy/stringy.go">Listing
<code>solutions/stringy</code></a>)</p>
<p>Strictly speaking, of course, we don’t really need to call the
<code>String</code> method: <code>fmt</code> already knows how to do
that automagically. But if we just passed <code>p</code> directly, we
wouldn’t need the <code>Stringer</code> constraint, and we could use
<code>any</code>… but what would be the fun in that?</p>
<h2 id="type-set-constraints">Type set constraints</h2>
<p>We’ve seen that one way an interface can specify an allowed range of
types is by including a <em>method element</em>, such as
<code>String() string</code>. That would be a basic interface, but now
let’s introduce another kind of interface. Instead of listing methods
that the type must have, it directly specifies a set of types that are
allowed.</p>
<h3 id="type-elements">Type elements</h3>
<p>For example, suppose we wanted to write some generic function
<code>Double</code> that multiplies a number by two, and we want a type
constraint that allows only values of type <code>int</code>. We know
that <code>int</code> has no methods, so we can’t use any basic
interface as a constraint. How can we write it, then?</p>
<p>Well, here’s how:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>type</span> OnlyInt <span>interface</span> <span>{</span></span>
<span id="cb6-2">    <span>int</span></span>
<span id="cb6-3"><span>}</span></span></code></pre></div>
<p>Very straightforward! It looks just like a regular interface
definition, except that instead of method elements, it contains a single
<em>type element</em>, consisting of a named type. In this case, the
named type is <code>int</code>.</p>
<h3 id="using-a-type-set-constraint">Using a type set constraint</h3>
<p>How would we use a constraint like this? Let’s write
<code>Double</code>, then:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>func</span> Double<span>[</span>T OnlyInt<span>](</span>v T<span>)</span> T <span>{</span></span>
<span id="cb7-2">    <span>return</span> v <span>*</span> <span>2</span></span>
<span id="cb7-3"><span>}</span></span></code></pre></div>
<p>In other words, for some T that satisfies the constraint
<code>OnlyInt</code>, <code>Double</code> takes a T parameter and
returns a T result.</p>
<p>Note that we now have one answer to the sort of problem we
encountered with <code>AddAnything</code>: how to enable the
<code>*</code> operator (or any other arithmetic operator) in a
parameterised function. Since T can only be <code>int</code> (thanks to
the <code>OnlyInt</code> constraint), Go can guarantee that the
<code>*</code> operator will work with T values.</p>
<p>It’s not the complete answer, though, since there are other types
that support <code>*</code> that <em>wouldn’t</em> be allowed by this
constraint. And in any case, if we were only going to support
<code>int</code>, we could have just written an ordinary function that
took an <code>int</code> parameter.</p>
<p>So we’ll need to be able to expand the range of types allowed by our
constraint a little, but not beyond the types that support
<code>*</code>. How can we do that?</p>
<h3 id="unions">Unions</h3>
<p>What types <em>can</em> satisfy the constraint <code>OnlyInt</code>?
Well, only <code>int</code>! To broaden this range, we can create a
constraint specifying more than one named type:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>type</span> Integer <span>interface</span> <span>{</span></span>
<span id="cb8-2">    <span>int</span> <span>|</span> <span>int8</span> <span>|</span> <span>int16</span> <span>|</span> <span>int32</span> <span>|</span> <span>int64</span></span>
<span id="cb8-3"><span>}</span></span></code></pre></div>
<p>The types are separated by the pipe character, <code>|</code>. You
can think of this as representing “or”. In other words, a type will
satisfy this constraint if it is <code>int</code> <em>or</em>
<code>int8</code> <em>or</em>… you get the idea.</p>
<p>This kind of interface element is called a <em>union</em>. The type
elements in a union can include any Go types, including interface
types.</p>
<p>It can even include other constraints. In other words, we can
<em>compose</em> new constraints from existing ones, like this:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>type</span> Float <span>interface</span> <span>{</span></span>
<span id="cb9-2">    <span>float32</span> <span>|</span> <span>float64</span></span>
<span id="cb9-3"><span>}</span></span>
<span id="cb9-4"></span>
<span id="cb9-5"><span>type</span> Complex <span>interface</span> <span>{</span></span>
<span id="cb9-6">    <span>complex64</span> <span>|</span> <span>complex128</span></span>
<span id="cb9-7"><span>}</span></span>
<span id="cb9-8"></span>
<span id="cb9-9"><span>type</span> Number <span>interface</span> <span>{</span></span>
<span id="cb9-10">    Integer <span>|</span> Float <span>|</span> Complex</span>
<span id="cb9-11"><span>}</span></span></code></pre></div>
<p>We’re saying that <code>Integer</code>, <code>Float</code>, and
<code>Complex</code> are all unions of different built-in numeric types,
but we’re also creating a new constraint <code>Number</code>, which is a
union of those three <em>interface</em> types we just defined. If it’s
an integer, a float, or a complex number, then it’s a number!</p>
<h3 id="the-set-of-all-allowed-types">The set of all allowed types</h3>
<p>The <em>type set</em> of a constraint is the set of all types that
satisfy it. The type set of the empty interface (<code>any</code>) is
the set of all types, as you’d expect.</p>
<p>The type set of a union element (such as <code>Float</code> in the
previous example) is the union of the type sets of all its terms.</p>
<p>In the <code>Float</code> example, which is the union of
<code>float32 | float64</code>, its type set contains
<code>float32</code>, <code>float64</code>, and no other types.</p>
<h3 id="intersections">Intersections</h3>
<p>You probably know that with a basic interface, a type must have
<em>all</em> of the methods listed in order to implement the interface.
And if the interface contains other interfaces, a type must implement
<em>all</em> of those interfaces, not just one of them.</p>
<p>For example:</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>type</span> ReaderStringer <span>interface</span> <span>{</span></span>
<span id="cb10-2">    io<span>.</span>Reader</span>
<span id="cb10-3">    fmt<span>.</span>Stringer</span>
<span id="cb10-4"><span>}</span></span></code></pre></div>
<p>If we were to write this as an <em>interface literal</em>, we would
separate the methods with a semicolon instead of a newline, but the
meaning is the same:</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>interface</span> <span>{</span> io<span>.</span>Reader<span>;</span> fmt<span>.</span>Stringer <span>}</span></span></code></pre></div>
<p>To implement this interface, a type has to implement <em>both</em>
<code>io.Reader</code> <em>and</em> <code>fmt.Stringer</code>. Just one
or the other isn’t good enough.</p>
<p>Each line of an interface definition like this, then, is treated as a
distinct type element. The type set of the interface as a whole is the
<em>intersection</em> of the type sets of all its elements. That is,
only those types that all the elements have in common.</p>
<p>So putting interface elements on different lines has the effect of
requiring a type to implement <em>all</em> those elements. We don’t need
this kind of interface very often, but we can imagine cases where it
might be necessary.</p>
<h3 id="empty-type-sets">Empty type sets</h3>
<p>You might be wondering about what happens if we define an interface
whose type set is completely empty. That is, if there are no types that
can satisfy the constraint.</p>
<p>Well, that could happen with an intersection of two type sets that
have <em>no</em> elements in common. For example:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>type</span> Unpossible <span>interface</span> <span>{</span></span>
<span id="cb12-2">    <span>int</span></span>
<span id="cb12-3">    <span>string</span></span>
<span id="cb12-4"><span>}</span></span></code></pre></div>
<p>Clearly no type can be both <code>int</code> and <code>string</code>
at the same time! Or, to put it another way, this interface’s type set
is empty.</p>
<p>If we try to instantiate a function constrained by
<code>Unpossible</code>, we’ll find, naturally enough, that it can’t be
done:</p>
<pre><code>cannot implement Unpossible (empty type set)</code></pre>
<p>We probably wouldn’t do this on purpose, since an unsatisfiable
constraint doesn’t seem that useful. But with more sophisticated
interfaces, we might accidentally reduce the allowed type set to zero,
and it’s helpful to know what this error message means so that we can
fix the problem.</p>
<h2 id="composite-type-literals">Composite type literals</h2>
<p>A <em>composite</em> type is one that’s built up from other types. We
saw some composite types in the <a href="https://bitfieldconsulting.com/posts/generic-types">previous
tutorial</a>, such as <code>[]E</code>, which is a slice of some element
type E.</p>
<p>But we’re not restricted to defined types with names. We can also
construct new types on the fly, using a <em>type literal</em>: that is,
literally writing out the type definition as part of the interface.</p>
<h3 id="a-struct-type-literal">A struct type literal</h3>
<p>For example, this interface specifies a <em>struct</em> type
literal:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>type</span> Pointish <span>interface</span> <span>{</span></span>
<span id="cb14-2">    <span>struct</span><span>{</span> X<span>,</span> Y <span>int</span> <span>}</span></span>
<span id="cb14-3"><span>}</span></span></code></pre></div>
<p>A type parameter with this constraint would allow any instance of
such a struct. In other words, its type set contains exactly one type:
<code>struct{ X, Y int }</code>.</p>
<h3 id="access-to-struct-fields">Access to struct fields</h3>
<p>While we can write a generic function constrained by some struct type
such as <code>Pointish</code>, there are limitations on what that
function can do with that type. One is that it can’t access the struct’s
<em>fields</em>:</p>
<div id="cb15"><pre><code><span id="cb15-1"><span>func</span> GetX<span>[</span>T Pointish<span>](</span>p T<span>)</span> <span>int</span> <span>{</span></span>
<span id="cb15-2">    <span>return</span> p<span>.</span>X</span>
<span id="cb15-3"><span>}</span></span>
<span id="cb15-4"><span>// p.X undefined (type T has no field or method X)</span></span></code></pre></div>
<p>In other words, we can’t refer to a field on <code>p</code>, even
though the function’s constraint explicitly says that any <code>p</code>
is guaranteed to be a struct with at least the field <code>X</code>.
This is a limitation of the Go compiler that has not yet been overcome.
Sorry about that.</p>
<h2 id="some-limitations-of-type-sets">Some limitations of type
sets</h2>
<p>An interface containing type elements can <em>only</em> be used as a
constraint on a type parameter. It can’t be used as the type of a
variable or parameter declaration, like a basic interface can. That too
is something that might change in the future, but this is where we are
today.</p>
<h3 id="constraints-versus-basic-interfaces">Constraints versus basic
interfaces</h3>
<p>What exactly stops us from doing that, though? We already know that
we can write functions that take ordinary parameters of some basic
interface type such as <code>Stringer</code>. So what happens if we try
to do the same with an interface containing type elements, such as
<code>Number</code>?</p>
<p>Let’s see:</p>
<div id="cb16"><pre><code><span id="cb16-1"><span>func</span> Double<span>(</span>p Number<span>)</span> Number <span>{</span></span>
<span id="cb16-2"><span>// interface contains type constraints</span></span></code></pre></div>
<p>This doesn’t compile, for the reasons we’ve discussed. Some potential
confusion arises from the fact that a basic interface can be used as
both a regular interface type <em>and</em> a constraint on type
parameters. But interfaces that contain type elements can only be used
as constraints.</p>
<h3 id="constraints-are-not-classes">Constraints are not classes</h3>
<p>If you have some experience with languages that have <em>classes</em>
(hierarchies of types), then there’s another thing that might trip you
up with Go generics: constraints are not classes, and you can’t
instantiate a generic function or type on a constraint interface.</p>
<p>To illustrate, suppose we have some concrete types <code>Cow</code>
and <code>Chicken</code>:</p>
<div id="cb17"><pre><code><span id="cb17-1"><span>type</span> Cow <span>struct</span><span>{</span> moo <span>string</span> <span>}</span></span>
<span id="cb17-2"></span>
<span id="cb17-3"><span>type</span> Chicken <span>struct</span><span>{</span> cluck <span>string</span> <span>}</span></span></code></pre></div>
<p>And suppose we define some interface <code>Animal</code> whose type
set consists of <code>Cow</code> and <code>Chicken</code>:</p>
<div id="cb18"><pre><code><span id="cb18-1"><span>type</span> Animal <span>interface</span> <span>{</span></span>
<span id="cb18-2">    Cow <span>|</span> Chicken</span>
<span id="cb18-3"><span>}</span></span></code></pre></div>
<p>So far, so good, and suppose we now define a generic type
<code>Farm</code> as a slice of <code>T Animal</code>:</p>

<p>Since we know the type set of <code>Animal</code> contains exactly
<code>Cow</code> and <code>Chicken</code>, then either of those types
can be used to instantiate <code>Farm</code>:</p>
<div id="cb20"><pre><code><span id="cb20-1">dairy <span>:=</span> Farm<span>[</span>Cow<span>]{}</span></span>
<span id="cb20-2">poultry <span>:=</span> Farm<span>[</span>Chicken<span>]{}</span></span></code></pre></div>
<p>What about <code>Animal</code> itself? Could we create a
<code>Farm[Animal]</code>? No, because there’s no such type as
<code>Animal</code>. It’s a type <em>constraint</em>, not a type, so
this gives an error:</p>
<div id="cb21"><pre><code><span id="cb21-1">mixed <span>:=</span> Farm<span>[</span>Animal<span>]{}</span></span>
<span id="cb21-2"><span>// interface contains type constraints</span></span></code></pre></div>
<p>And, as we’ve seen, we also couldn’t use <code>Animal</code> as the
type of some variable, or ordinary function parameter. Only basic
interfaces can be used this way, not interfaces containing type
elements.</p>
<h2 id="approximations">Approximations</h2>
<p>Let’s return to our earlier definition of an interface
<code>Integer</code>, consisting of a union of named types.
Specifically, the built-in signed integer types:</p>
<div id="cb22"><pre><code><span id="cb22-1"><span>type</span> Integer <span>interface</span> <span>{</span></span>
<span id="cb22-2">    <span>int</span> <span>|</span> <span>int8</span> <span>|</span> <span>int16</span> <span>|</span> <span>int32</span> <span>|</span> <span>int64</span></span>
<span id="cb22-3"><span>}</span></span></code></pre></div>
<p>We know that the type set of this interface contains all the types
we’ve named. But what about defined types whose <em>underlying</em> type
is one of the built-in types?</p>
<h3 id="limitations-of-named-types">Limitations of named types</h3>
<p>For example:</p>

<p>Is <code>MyInt</code> also in the type set of <code>Integer</code>?
Let’s find out. Suppose we write a generic function that uses this
constraint:</p>
<div id="cb24"><pre><code><span id="cb24-1"><span>func</span> Double<span>[</span>T Integer<span>](</span>v T<span>)</span> T <span>{</span></span>
<span id="cb24-2">    <span>return</span> v <span>*</span> <span>2</span></span>
<span id="cb24-3"><span>}</span></span></code></pre></div>
<p>Can we pass it a <code>MyInt</code> value? We’ll soon know:</p>
<div id="cb25"><pre><code><span id="cb25-1">fmt<span>.</span>Println<span>(</span>Double<span>(</span>MyInt<span>(</span><span>1</span><span>)))</span></span>
<span id="cb25-2"><span>// MyInt does not implement Integer</span></span></code></pre></div>
<p>No.&nbsp;That makes sense, because <code>Integer</code> is a list of named
types, and we can see that <code>MyInt</code> isn’t one of them.</p>
<p>How can we write an interface that allows not only a set of specific
named types, but also any other types <em>derived</em> from them?</p>
<h3 id="type-approximations">Type approximations</h3>
<p>We need a new kind of type element: a <em>type approximation</em>. We
write it using the tilde (<code>~</code>) character:</p>
<div id="cb26"><pre><code><span id="cb26-1"><span>type</span> ApproximatelyInt <span>interface</span> <span>{</span></span>
<span id="cb26-2">    <span>~</span><span>int</span></span>
<span id="cb26-3"><span>}</span></span></code></pre></div>
<p>The type set of <code>~int</code> includes <code>int</code> itself,
but also any type whose underlying type is <code>int</code> (for
example, <code>MyInt</code>).</p>
<p>If we rewrite <code>Double</code> to use this constraint, we can pass
it a <code>MyInt</code>, which is good. Even better, it will accept
<em>any</em> type, now or in the future, whose underlying type is
<code>int</code>.</p>
<h3 id="derived-types">Derived types</h3>
<p>Approximations are especially useful with struct type elements.
Remember our <code>Pointish</code> interface?</p>
<div id="cb27"><pre><code><span id="cb27-1"><span>type</span> Pointish <span>interface</span> <span>{</span></span>
<span id="cb27-2">    <span>struct</span><span>{</span> x<span>,</span> y <span>int</span> <span>}</span></span>
<span id="cb27-3"><span>}</span></span></code></pre></div>
<p>Let’s write a generic function with this constraint:</p>
<div id="cb28"><pre><code><span id="cb28-1"><span>func</span> Plot<span>[</span>T Pointish<span>](</span>p T<span>)</span> <span>{</span></span></code></pre></div>
<p>We can pass it values of type <code>struct{ x, y int }</code>, as
you’d expect:</p>
<div id="cb29"><pre><code><span id="cb29-1">p <span>:=</span> <span>struct</span><span>{</span> x<span>,</span> y <span>int</span> <span>}{</span><span>1</span><span>,</span> <span>2</span><span>}</span></span>
<span id="cb29-2">Plot<span>(</span>p<span>)</span></span></code></pre></div>
<p>But now comes a problem: we can’t pass values of any <em>named</em>
struct type, even if the struct definition itself matches the constraint
perfectly:</p>
<div id="cb30"><pre><code><span id="cb30-1"><span>type</span> Point <span>struct</span> <span>{</span></span>
<span id="cb30-2">    x<span>,</span> y <span>int</span></span>
<span id="cb30-3"><span>}</span></span>
<span id="cb30-4">p <span>:=</span> Point<span>{</span><span>1</span><span>,</span> <span>2</span><span>}</span></span>
<span id="cb30-5">Plot<span>(</span>p<span>)</span></span>
<span id="cb30-6"><span>// Point does not implement Pointish (possibly missing ~ for</span></span>
<span id="cb30-7"><span>// struct{x int; y int} in constraint Pointish)</span></span></code></pre></div>
<p>What’s the problem here? Our constraint allows
<code>struct{ x, y int }</code>, but <code>Point</code> is <em>not that
type</em>. It’s a type <em>derived</em> from it. And, just as with
<code>MyInt</code>, a derived type is distinct from its underlying
type.</p>
<p>You know now how to solve this problem: use a type approximation! And
Go is telling us the same thing: “Hint, hint: I think you meant to write
a <code>~</code> in your constraint.”</p>
<p>If we add that approximation, the type set of our interface expands
to encompass all types derived from the specified struct, including
<code>Point</code>:</p>
<div id="cb31"><pre><code><span id="cb31-1"><span>type</span> Pointish <span>interface</span> <span>{</span></span>
<span id="cb31-2">    <span>~</span><span>struct</span><span>{</span> x<span>,</span> y <span>int</span> <span>}</span></span>
<span id="cb31-3"><span>}</span></span></code></pre></div>
<h3 id="exercise-a-first-approximation">Exercise: A first
approximation</h3>
<p>Can you use what you’ve just learned to solve the <a href="https://github.com/bitfield/know-go/tree/main/exercises/intish"><code>intish</code></a>
challenge?</p>
<p>Here you’re provided with a function <code>IsPositive</code>, which
determines whether a given value is greater than zero:</p>
<div id="cb32"><pre><code><span id="cb32-1"><span>func</span> IsPositive<span>[</span>T Intish<span>](</span>v T<span>)</span> <span>bool</span> <span>{</span></span>
<span id="cb32-2">    <span>return</span> v <span>&gt;</span> <span>0</span></span>
<span id="cb32-3"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/exercises/intish/intish.go">Listing
<code>exercises/intish</code></a>)</p>
<p>And there’s a set of accompanying tests that instantiate this
function on some derived type <code>MyInt</code>:</p>
<div id="cb33"><pre><code><span id="cb33-1"><span>type</span> MyInt <span>int</span></span>
<span id="cb33-2"></span>
<span id="cb33-3"><span>func</span> TestIsPositive_IsTrueFor1<span>(</span>t <span>*</span>testing<span>.</span>T<span>)</span> <span>{</span></span>
<span id="cb33-4">    t<span>.</span>Parallel<span>()</span></span>
<span id="cb33-5">    input <span>:=</span> MyInt<span>(</span><span>1</span><span>)</span></span>
<span id="cb33-6">    <span>if</span> <span>!</span>intish<span>.</span>IsPositive<span>(</span>input<span>)</span> <span>{</span></span>
<span id="cb33-7">        t<span>.</span>Errorf<span>(</span><span>"IsPositive(1): want true, got false"</span><span>)</span></span>
<span id="cb33-8">    <span>}</span></span>
<span id="cb33-9"><span>}</span></span>
<span id="cb33-10"></span>
<span id="cb33-11"><span>func</span> TestIsPositive_IsFalseForNegative1<span>(</span>t <span>*</span>testing<span>.</span>T<span>)</span> <span>{</span></span>
<span id="cb33-12">    t<span>.</span>Parallel<span>()</span></span>
<span id="cb33-13">    input <span>:=</span> MyInt<span>(-</span><span>1</span><span>)</span></span>
<span id="cb33-14">    <span>if</span> intish<span>.</span>IsPositive<span>(</span>input<span>)</span> <span>{</span></span>
<span id="cb33-15">        t<span>.</span>Errorf<span>(</span><span>"IsPositive(-1): want false, got true"</span><span>)</span></span>
<span id="cb33-16">    <span>}</span></span>
<span id="cb33-17"><span>}</span></span>
<span id="cb33-18"></span>
<span id="cb33-19"><span>func</span> TestIsPositive_IsFalseForZero<span>(</span>t <span>*</span>testing<span>.</span>T<span>)</span> <span>{</span></span>
<span id="cb33-20">    t<span>.</span>Parallel<span>()</span></span>
<span id="cb33-21">    input <span>:=</span> MyInt<span>(</span><span>0</span><span>)</span></span>
<span id="cb33-22">    <span>if</span> intish<span>.</span>IsPositive<span>(</span>input<span>)</span> <span>{</span></span>
<span id="cb33-23">        t<span>.</span>Errorf<span>(</span><span>"IsPositive(0): want false, got true"</span><span>)</span></span>
<span id="cb33-24">    <span>}</span></span>
<span id="cb33-25"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/exercises/intish/intish_test.go">Listing
<code>exercises/intish</code></a>)</p>
<p><strong>GOAL:</strong> Your task here is to define the
<code>Intish</code> interface.</p>
<hr>
<p><strong>HINT:</strong> A method set won’t work here, because the
<code>int</code> type <em>has</em> no methods! On the other hand, the
type literal <code>int</code> won’t work either, because
<code>MyInt</code> is not <code>int</code>, it’s a new type derived from
it.</p>
<p>What kind of constraint could you use instead? I think you know where
this is going, don’t you? If not, have another look at the previous
section on type approximations.</p>
<hr>
<p><strong>SOLUTION:</strong> It’s not complicated, once you know that a
type approximation is required:</p>
<div id="cb34"><pre><code><span id="cb34-1"><span>type</span> Intish <span>interface</span> <span>{</span></span>
<span id="cb34-2">    <span>~</span><span>int</span></span>
<span id="cb34-3"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/solutions/intish/intish.go">Listing
<code>solutions/intish</code></a>)</p>
<h2 id="interface-literals">Interface literals</h2>
<p>Up to now, we’ve always used type parameters with a <em>named</em>
constraint, such as <code>Integer</code> (or even just
<code>any</code>). And we know that those constraints are defined as
interfaces. So could we use an <em>interface literal</em> as a type
constraint?</p>
<h3 id="syntax-of-an-interface-literal">Syntax of an interface
literal</h3>
<p>An interface literal, as you probably know, consists of the keyword
<code>interface</code> followed by curly braces containing (optionally)
some interface elements.</p>
<p>For example, the simplest interface literal is the empty interface,
<code>interface{}</code>, which is common enough to have its own
predeclared name, <code>any</code>.</p>
<p>We should be able to write this empty interface literal wherever
<code>any</code> is allowed as a type constraint, then:</p>
<div id="cb35"><pre><code><span id="cb35-1"><span>func</span> Identity<span>[</span>T <span>interface</span><span>{}](</span>v T<span>)</span> T <span>{</span></span></code></pre></div>
<p>And so we can. But we’re not restricted to only <em>empty</em>
interface literals. We could write an interface literal that contains a
method element, for example:</p>
<div id="cb36"><pre><code><span id="cb36-1"><span>func</span> Stringify<span>[</span>T <span>interface</span><span>{</span> String<span>()</span> <span>string</span> <span>}](</span>s T<span>)</span> <span>string</span> <span>{</span></span>
<span id="cb36-2">    <span>return</span> s<span>.</span>String<span>()</span></span>
<span id="cb36-3"><span>}</span></span></code></pre></div>
<p>This is a little hard to read at first, perhaps. But we’ve already
seen this exact function before, only in that case it had a
<em>named</em> constraint <code>Stringer</code>. We’ve simply replaced
that name with the corresponding interface literal:</p>
<div id="cb37"><pre><code><span id="cb37-1"><span>interface</span><span>{</span> String<span>()</span> <span>string</span> <span>}</span></span></code></pre></div>
<p>That is, the set of types that have a <code>String</code> method. We
don’t need to name this interface in order to use it as a constraint,
and sometimes it’s clearer to write it as a literal.</p>
<h3 id="omitting-the-interface-keyword">Omitting the
<code>interface</code> keyword</h3>
<p>And we’re not limited to just method elements in interface literals
used as constraints. We can use type elements too:</p>

<p>Conveniently, in this case we can omit the enclosing
<code>interface { ... }</code>, and write simply <code>~int</code> as
the constraint:</p>

<p>For example, we could write some function <code>Increment</code>
constrained to types derived from <code>int</code>:</p>
<div id="cb40"><pre><code><span id="cb40-1"><span>func</span> Increment<span>[</span>T <span>~</span><span>int</span><span>](</span>v T<span>)</span> T <span>{</span></span>
<span id="cb40-2">    <span>return</span> v <span>+</span> <span>1</span></span>
<span id="cb40-3"><span>}</span></span></code></pre></div>
<p>However, we can only omit the <code>interface</code> keyword when the
constraint contains exactly one type element. Multiple elements wouldn’t
be allowed, so this doesn’t work:</p>
<div id="cb41"><pre><code><span id="cb41-1"><span>func</span> Increment<span>[</span>T <span>~</span><span>int</span><span>;</span> <span>~</span><span>float64</span><span>](</span>v T<span>)</span> T <span>{</span></span>
<span id="cb41-2"><span>// syntax error: unexpected semicolon in parameter list; possibly </span></span>
<span id="cb41-3"><span>// missing comma or ]</span></span></code></pre></div>
<p>And we can’t omit <code>interface</code> with method elements
either:</p>
<div id="cb42"><pre><code><span id="cb42-1"><span>func</span> Increment<span>[</span>T String<span>()</span> <span>string</span><span>](</span>v T<span>)</span> T <span>{</span></span>
<span id="cb42-2"><span>// syntax error: unexpected ( in parameter list; possibly </span></span>
<span id="cb42-3"><span>// missing comma or ]</span></span></code></pre></div>
<p>And we can only omit <code>interface</code> in a constraint
<em>literal</em>. We can’t omit it when defining a named constraint. So
this doesn’t work, for example:</p>
<div id="cb43"><pre><code><span id="cb43-1"><span>type</span> Intish <span>~</span><span>int</span></span>
<span id="cb43-2"><span>// syntax error: unexpected ~ in type declaration</span></span></code></pre></div>
<h3 id="referring-to-type-parameters">Referring to type parameters</h3>
<p>We’ve seen that in certain cases, instead of having to define it
separately, we can write a constraint directly as an interface literal.
So you might be wondering: can we refer to T inside the interface
literal itself? Yes, we can.</p>
<p>To see why we might need to do that, suppose we wanted to write a
generic function <code>Contains[T]</code>, that takes a slice of T and
tells you whether or not it contains a given value.</p>
<p>And suppose that we’ll determine this, for any particular element of
the slice, by calling some <code>Equal</code> method on the element.
That means we must constrain the function to only types that have a
suitable <code>Equal</code> method.</p>
<p>So the constraint for T is going to be an interface containing the
method <code>Equal(T) bool</code>, let’s say.</p>
<p>Can we do this? Let’s try:</p>
<div id="cb44"><pre><code><span id="cb44-1"><span>func</span> Contains<span>[</span>T <span>interface</span><span>{</span> Equal<span>(</span>T<span>)</span> <span>bool</span> <span>}](</span>s <span>[]</span>T<span>,</span>  v T<span>)</span> <span>bool</span> <span>{</span></span></code></pre></div>
<p>Yes, this is fine. In fact, using an interface literal is the
<em>only</em> way to write this constraint. We couldn’t have created
some <em>named</em> interface type to do the same thing. Why not?</p>
<p>Let’s see what happens if we try:</p>
<div id="cb45"><pre><code><span id="cb45-1"><span>type</span> Equaler <span>interface</span> <span>{</span></span>
<span id="cb45-2">    Equal<span>(???)</span> <span>bool</span> <span>// we can't say 'T' here</span></span>
<span id="cb45-3"><span>}</span></span></code></pre></div>
<p>Because the type parameter T is part of the <code>Equal</code> method
signature, and we don’t <em>have</em> T here. The only way to refer to T
is in an interface literal inside a type constraint:</p>
<div id="cb46"><pre><code><span id="cb46-1"><span>[</span>T <span>interface</span><span>{</span> Equal<span>(</span>T<span>)</span> <span>bool</span> <span>}]</span></span></code></pre></div>
<p>At least, we can’t write a <em>specific</em> interface that mentions
T in its method set. What we’d need here, in fact, is a <em>generic</em>
interface, and you’ll learn how to define and use these in my book, <a href="https://bitfieldconsulting.com/posts/generics">Know Go</a>. If these tutorials have given you an
appetite for generic programming in Go, I think you’ll really enjoy the
book—check it out!</p>
<h3 id="exercise-greater-love">Exercise: Greater love</h3>
<p>Your turn now to see if you can solve the <a href="https://github.com/bitfield/know-go/tree/main/exercises/greater"><code>greater</code></a>
exercise.</p>
<p>You’ve been given the following (incomplete) function:</p>
<div id="cb47"><pre><code><span id="cb47-1"><span>func</span> IsGreater<span>[</span>T <span>/* Your constraint here! */</span><span>](</span>x<span>,</span> y T<span>)</span> <span>bool</span> <span>{</span></span>
<span id="cb47-2">    <span>return</span> x<span>.</span>Greater<span>(</span>y<span>)</span></span>
<span id="cb47-3"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/exercises/greater/greater.go">Listing
<code>exercises/greater</code></a>)</p>
<p>This takes two values of some arbitrary type, and compares them by
calling the <code>Greater</code> method on the first value, passing it
the second value.</p>
<p>The tests exercise this function by calling it with two values of a
defined type <code>MyInt</code>, which has the required
<code>Greater</code> method.</p>
<div id="cb48"><pre><code><span id="cb48-1"><span>type</span> MyInt <span>int</span></span>
<span id="cb48-2"></span>
<span id="cb48-3"><span>func</span> <span>(</span>m MyInt<span>)</span> Greater<span>(</span>v MyInt<span>)</span> <span>bool</span> <span>{</span></span>
<span id="cb48-4">    <span>return</span> m <span>&gt;</span> v</span>
<span id="cb48-5"><span>}</span></span>
<span id="cb48-6"></span>
<span id="cb48-7"><span>func</span> TestIsGreater_IsTrueFor2And1<span>(</span>t <span>*</span>testing<span>.</span>T<span>)</span> <span>{</span></span>
<span id="cb48-8">    t<span>.</span>Parallel<span>()</span></span>
<span id="cb48-9">    <span>if</span> <span>!</span>greater<span>.</span>IsGreater<span>(</span>MyInt<span>(</span><span>2</span><span>),</span> MyInt<span>(</span><span>1</span><span>))</span> <span>{</span></span>
<span id="cb48-10">        t<span>.</span>Fatalf<span>(</span><span>"IsGreater(2, 1): want true, got false"</span><span>)</span></span>
<span id="cb48-11">    <span>}</span></span>
<span id="cb48-12"><span>}</span></span>
<span id="cb48-13"></span>
<span id="cb48-14"><span>func</span> TestIsGreater_IsFalseFor1And2<span>(</span>t <span>*</span>testing<span>.</span>T<span>)</span> <span>{</span></span>
<span id="cb48-15">    t<span>.</span>Parallel<span>()</span></span>
<span id="cb48-16">    <span>if</span> greater<span>.</span>IsGreater<span>(</span>MyInt<span>(</span><span>1</span><span>),</span> MyInt<span>(</span><span>2</span><span>))</span> <span>{</span></span>
<span id="cb48-17">        t<span>.</span>Fatalf<span>(</span><span>"IsGreater(1, 2): want false, got true"</span><span>)</span></span>
<span id="cb48-18">    <span>}</span></span>
<span id="cb48-19"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/exercises/greater/greater_test.go">Listing
<code>exercises/greater</code></a>)</p>
<p><strong>GOAL:</strong> To make these tests pass, you’ll need to write
an appropriate type constraint for <code>IsGreater</code>. Can you see
what to do?</p>
<hr>
<p><strong>HINT:</strong> Remember, we got here by talking about
constraints as interface literals, and in particular, interface literals
that refer to the type parameter.</p>
<p>If you try to define some <em>named</em> interface with the method
set containing <code>Greater</code>, for example, that won’t work. We
can’t do it for the same reason that we couldn’t define a named
interface with the method set <code>Equal</code>: we don’t know what
type of argument that method takes.</p>
<p>Just like <code>Equal</code>, <code>Greater</code> takes arguments of
some arbitrary type T, so we need an interface literal that can
<em>refer</em> to T in its definition. Does that help?</p>
<hr>
<p><strong>SOLUTION:</strong> Here’s one way to do it:</p>
<div id="cb49"><pre><code><span id="cb49-1"><span>func</span> IsGreater<span>[</span>T <span>interface</span><span>{</span> Greater<span>(</span>T<span>)</span> <span>bool</span> <span>}](</span>x<span>,</span> y T<span>)</span> <span>bool</span> <span>{</span></span>
<span id="cb49-2">    <span>return</span> x<span>.</span>Greater<span>(</span>y<span>)</span></span>
<span id="cb49-3"><span>}</span></span></code></pre></div>
<p>(<a href="https://github.com/bitfield/know-go/blob/main/solutions/greater/greater.go">Listing
<code>solutions/greater</code></a>)</p>
<p>Like most things, it’s delightfully simple once you know. For a type
parameter T, the required interface is:</p>

<p>And that’s how we do that.</p>
<p>Well, I hope you enjoyed this tutorial series, and if so, why not
treat yourself to a copy of <a href="https://bitfieldconsulting.com/books/generics">Know Go</a>?
There’s much more to explore, so I’d love you to come along with me for
the ride.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All-in-one embedding model for interleaved text, images, and screenshots (185 pts)]]></title>
            <link>https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/</link>
            <guid>42162622</guid>
            <pubDate>Sun, 17 Nov 2024 07:42:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/">https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/</a>, See on <a href="https://news.ycombinator.com/item?id=42162622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>




<p>TL;DR — We are excited to announce <code>voyage-multimodal-3</code>, a new state-of-the-art for multimodal embeddings and a big step forward towards seamless RAG and semantic search for documents rich with both visuals and text. Unlike existing multimodal embedding models, <code>voyage-multimodal-3</code> is capable of vectorizing interleaved texts + images and capturing key visual features from screenshots of PDFs, slides, tables, figures, and more, thereby eliminating the need for complex document parsing. <code>voyage-multimodal-3</code> improves retrieval accuracy by an average of 19.63% over the next best-performing multimodal embedding model when evaluated across 3 multimodal retrieval tasks (20 total datasets).</p>



<p>Two months ago, we released the <a href="https://blog.voyageai.com/2024/09/18/voyage-3/" rel="nofollow" target="_blank"><code>voyage-3</code> and <code>voyage-3-lite</code></a> series of multilingual text embedding models, providing best-in-class performance across a variety of datasets. Today, we’re excited to introduce <code>voyage-multimodal-3</code>, our first multimodal embedding model and a big step toward RAG and semantic search for knowledge bases rich with both visuals and text.</p>



<p><code>voyage-multimodal-3</code> supports text and content-rich images such as screenshots of texts, figures, tables, PDFs, slide decks, and more. The resultant vectors capture critical textual and visual features such as font size, text location, whitespace, etc. This eliminates the need for heuristic-based document parsing, which often struggles with accuracy when layouts are complex or interspersed with figures and photos. Unlike existing multimodal embedding models that handle either a single text or image input, <code>voyage-multimodal-3</code> allows for interleaved texts and images for maximum flexibility. Our <a href="https://colab.research.google.com/drive/12aFvstG8YFAWXyw-Bx5IXtaOqOzliGt9" rel="nofollow" target="_blank">sample notebook</a> demonstrates all of these features.</p>



<p><code>voyage-multimodal-3</code> has an architecture that is similar to that of modern vision-language transformers. This makes it a significant departure from existing multimodal embedding models, including, but not limited to, OpenAI CLIP large (<code>clip-vit-large-patch14-336</code>) and Cohere multimodal v3 (<code>embed-multimodal-v3.0</code>).</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="1440" height="800" data-attachment-id="1166" data-permalink="https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/slide-2/" data-orig-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?fit=1440%2C800&amp;quality=80&amp;ssl=1" data-orig-size="1440,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Slide 2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?fit=300%2C167&amp;quality=80&amp;ssl=1" data-large-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?fit=1024%2C569&amp;quality=80&amp;ssl=1" src="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?resize=1440%2C800&amp;quality=80&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?w=1440&amp;quality=80&amp;ssl=1 1440w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?resize=300%2C167&amp;quality=80&amp;ssl=1 300w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?resize=1024%2C569&amp;quality=80&amp;ssl=1 1024w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?resize=768%2C427&amp;quality=80&amp;ssl=1 768w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-2.png?resize=1200%2C667&amp;quality=80&amp;ssl=1 1200w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>In a set of evaluations across 20 multimodal retrieval datasets and 34 text retrieval datasets, we found that <code>voyage-multimodal-3</code>:</p>



<ol>
<li>Outperforms OpenAI CLIP large and Cohere multimodal v3 by an average of 41.44% (a 2.1x improvement) and 43.37% (a 2.2x improvement) on table/figure retrieval, 26.54% and 25.84% on document screenshot retrieval, and 6.55% and 5.86% on text-to-photo retrieval, respectively.</li>



<li>Outperforms OpenAI v3 large and Cohere multimodal/English<sup>1</sup> v3 by 5.13% and 13.70% on text-only datasets, respectively.</li>
</ol>



<h3>Support for Interleaved Text &amp; Images</h3>



<p>All existing commonly used multimodal embedding models (such as Amazon Titan Multimodal G1, Google Vertex AI multimodal, and Cohere multimodal v3) are based on OpenAI’s CLIP, which processes different modalities of data through independent networks. In other words, images <em>must</em> be vectorized through the vision tower, while text <em>must</em> be vectorized through the text tower, preventing these models from being able to processing interleaved data.</p>



<figure><img data-recalc-dims="1" decoding="async" width="1440" height="800" data-attachment-id="1167" data-permalink="https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/slide-1/" data-orig-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?fit=1440%2C800&amp;quality=80&amp;ssl=1" data-orig-size="1440,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Slide 1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?fit=300%2C167&amp;quality=80&amp;ssl=1" data-large-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?fit=1024%2C569&amp;quality=80&amp;ssl=1" src="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?resize=1440%2C800&amp;quality=80&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?w=1440&amp;quality=80&amp;ssl=1 1440w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?resize=300%2C167&amp;quality=80&amp;ssl=1 300w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?resize=1024%2C569&amp;quality=80&amp;ssl=1 1024w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?resize=768%2C427&amp;quality=80&amp;ssl=1 768w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-1.png?resize=1200%2C667&amp;quality=80&amp;ssl=1 1200w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>In contrast, <code>voyage-multimodal-3</code> vectorizes both modalities of data directly within the same transformer encoder, ensuring that both text and visual features are treated as part of a unified representation rather than distinct components. This mimics the model architecture of the latest vision-language models, only for vectorization rather than generation. As a result, interleaved texts and images, document screenshots, PDFs with complex layouts, annotated images, etc can be vectorized in a way that preserves the contextual relationship between visual and textual information.</p>



<h3>Mixed Modality Search with Screenshots</h3>



<p>All CLIP-like models perform poorly on mixed-modality search due to a phenomenon known as the <a href="https://arxiv.org/abs/2203.02053" rel="nofollow" target="_blank">modality gap</a>. As illustrated in the figure below, the closest vector to the snippet “I address you, members of the Seventy-Seventh Congress…” is not its screenshot, but other texts. This leads to search results that are skewed towards items of the same modality; in other words, text vectors will be closer to irrelevant texts than relevant images in the embedding space.</p>



<figure><img data-recalc-dims="1" decoding="async" width="692" height="660" data-attachment-id="1171" data-permalink="https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/slide-3-v3/" data-orig-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-3-v3.png?fit=692%2C660&amp;quality=80&amp;ssl=1" data-orig-size="692,660" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Slide 3 v3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-3-v3.png?fit=300%2C286&amp;quality=80&amp;ssl=1" data-large-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-3-v3.png?fit=692%2C660&amp;quality=80&amp;ssl=1" src="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-3-v3.png?resize=692%2C660&amp;quality=80&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-3-v3.png?w=692&amp;quality=80&amp;ssl=1 692w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/Slide-3-v3.png?resize=300%2C286&amp;quality=80&amp;ssl=1 300w" sizes="(max-width: 692px) 100vw, 692px"></figure>



<p>To illustrate this issue quantitatively, we conducted an experiment involving mixed-modality data. We created two sets of PyTorch documentation with identical content: one set as plain text (strings) and and the other set as screenshots. By combining a subset of text-based documentation with screenshots of remaining subset, we created a series of mixed-modality datasets. Each dataset represented a different proportion of text and screenshots, ranging from 0% to 100% screenshots. We then evaluated the retrieval accuracy of various multimodal models on these datasets, reporting the <a href="http://www.evidentlyai.com/ranking-metrics/ndcg-metric#:~:text=Normalized%20Discounted%20Cumulative%20Gain%20(NDCG)%20is%20a%20ranking%20quality%20metric,DCG%20representing%20a%20perfect%20ranking." rel="nofollow" target="_blank">normalized discounted cumulative gain</a>&nbsp;(NDCG@10) for each model across different screenshot ratios.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1920" height="1080" data-attachment-id="1172" data-permalink="https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/voyage-multimodal-3_results-001/" data-orig-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?fit=1920%2C1080&amp;quality=80&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="voyage-multimodal-3_results.001" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?fit=300%2C169&amp;quality=80&amp;ssl=1" data-large-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?fit=1024%2C576&amp;quality=80&amp;ssl=1" src="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?resize=1920%2C1080&amp;quality=80&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?w=1920&amp;quality=80&amp;ssl=1 1920w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?resize=300%2C169&amp;quality=80&amp;ssl=1 300w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?resize=1024%2C576&amp;quality=80&amp;ssl=1 1024w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?resize=768%2C432&amp;quality=80&amp;ssl=1 768w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?resize=1536%2C864&amp;quality=80&amp;ssl=1 1536w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.001.png?resize=1200%2C675&amp;quality=80&amp;ssl=1 1200w" sizes="auto, (max-width: 1000px) 100vw, 1000px"></figure>



<p>As shown above, CLIP-based models experience a decline in retrieval quality as the proportion of screenshots increases up to 90%, highlighting a retrieval bias influenced by modality. Moreover, these models perform poorly when all text is converted to images.</p>



<p>In contrast, <code>voyage-multimodal-3</code> is not only the most performant for all ratios, but also has little-to-no performance drop across the board, indicating that the vectors truly capture the semantic content contained in the screenshots. This robustness is due to the model’s unique approach of processing all input modalities through the same backbone.</p>



<p>With <code>voyage-multimodal-3</code>, there is no longer a need for screen parsing models, layout analysis, or any other complex text extraction pipelines; you can easily vectorize a knowledge base containing both pure-text documents as well unstructured data (such as PDFs/slides/webpages/etc) — screenshots are all you need.</p>



<h3>Evaluation Details</h3>



<p><strong>Datasets.</strong> We evaluate <code>voyage-multimodal-3</code> across 20 multimodal datasets spanning three different tasks: table/figure retrieval, document screenshot retrieval, and text-to-photo retrieval. We also evaluate <code>voyage-multimodal-3</code> on a standard text retrieval task spanning 34 datasets in 6 domains (law, finance, conversation, code, web, and tech).</p>



<p>For all datasets, the query is text, while the document could be a figure, photo, text, document screenshot, or a combination of these. For each task, we use prior top-performing models as the baseline. Alongside task names, we provide each task’s corresponding description and datasets used in the table below:</p>



<figure><table><thead><tr><th>Task</th><th>Description</th><th><strong>Datasets</strong></th></tr></thead><tbody><tr><td>Table/figure retrieval</td><td>Table/figure retrieval measures the strength of a model’s ability to match an image containing a table or figure (charts, graphs, etc) with descriptions, captions, or other textual queries which reference the figure.</td><td>charxiv, mmtab-test, ChartQA, Chartve, FintabnetQA, PlotQA,</td></tr><tr><td>Document screenshot retrieval</td><td>In this category, models are used to match queries with scans or screenshots of documents containing both text and charts.</td><td>Energy, Healthcare Industry, Artificial Intelligence, Government Report, InfoVQA, DocVQA, ArxivQA, TabFQuad, TAT-DQA, Shift Project</td></tr><tr><td>Text-to-photo retrieval</td><td>This is the typical text-to-image matching used by CLIP and other CLIP-like models, where queries are associated with the most semantically relevant photos.</td><td>meme-cap, mm-imdb, winoground, docci</td></tr><tr><td>Standard text retrieval</td><td>Standard text retrieval retrieves relevant documents by matching query strings with document strings.</td><td>LeCaRDv2, LegalQuAD legal_summarization, AILA_casedocs, AILA_statutes, rag-benchmark-finance-apple-10K-2022, financebench, TAT-QA, finance-alpaca-csv fiqa-personal-finance-dataset, finance-financialmodelingprep-stock-news-sentiments-rss-feed, ConvFinQA, finqa, hc3_finance, dialogsum, QAConv, HQA-data, LeetCodeCpp-new, LeetCodeJava-new, LeetCodePython-new, humaneval, mbpp, ds1000-referenceonly, ds1000, apps_5doc, Huffpostsports, Huffpostscience, Doordash, Healthforcalifornia, Cohere, 5GEdge, OneSignal, Langchain, PyTorch1024</td></tr></tbody></table></figure>



<p>Note that the standard text retrieval task encompasses all datasets used to evaluate <code>voyage-3</code> and <code>voyage-3-lite</code> except long context and multilingual datasets. See our <a href="https://blog.voyageai.com/2024/09/18/voyage-3/" rel="nofollow" target="_blank">previous blog post</a> for more information.</p>



<p><strong>Models</strong>. For the three multimodal tasks, we evaluate&nbsp;<code>voyage-multimodal-3</code>&nbsp;alongside four alternative multimodal embedding models: <a href="https://huggingface.co/openai/clip-vit-large-patch14-336" rel="nofollow" target="_blank">OpenAI CLIP large</a> (<code>clip-vit-large-patch14-336</code>), <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/titan-multiemb-models.html" rel="nofollow" target="_blank">Amazon Titan Multimodal Embeddings G1</a> (<code>amazon.titan-embed-image-v1</code>), <a href="https://docs.cohere.com/reference/embed" rel="nofollow" target="_blank">Cohere multimodal v3</a> (<code>embed-multimodal-v3.0</code>), and <a href="https://huggingface.co/google/siglip-so400m-patch14-384" rel="nofollow" target="_blank">SigLIP So400M</a> (<code>siglip-so400m-patch14-384</code>). We also evaluate <a href="https://huggingface.co/vidore/colqwen2-v0.1" rel="nofollow" target="_blank">ColQwen2 v0.1</a> (<code>colqwen-v0.1</code>), a late interaction model that outputs many embeddings per document.</p>



<p>For the standard text retrieval task, we evaluate <code>voyage-multimodal-3</code> alongside <a href="https://platform.openai.com/docs/guides/embeddings" rel="nofollow" target="_blank">OpenAI v3 large</a> (<code>text-embeddings-3-large</code>), Cohere multimodal/English<sup>1</sup> v3, and <code>voyage-3</code>.</p>



<p><strong>Metrics.</strong> Given a query, we retrieve the top 10 results by cosine similarity and report the&nbsp;NDCG@10.</p>



<h3>Results</h3>



<p><strong>Multimodal retrieval</strong>. As shown in the figure below, <code>voyage-multimodal-3</code> outperforms OpenAI CLIP large, Amazon Titan Multimodal G1, Cohere multimodal v3, SigLIP So400M, and ColQwen2 v0.1 by:</p>



<ul>
<li>41.44%, 45.00%, 43.37%, 20.66%, and 6.14% on table/figure retrieval, respectively</li>



<li>26.54%, 37.68%, 25.84%, 35.62%, and 0.98% on document screenshot retrieval, respectively</li>



<li>6.55%, 5.16%, 5.86%, 3.42%, and 10.34% on text-to-photo retrieval, respectively</li>
</ul>



<p><strong>Standard text retrieval</strong>. As shown in the figure below, <code>voyage-multimodal-3</code> outperforms OpenAI v3 large and Cohere multimodal/English<sup>1</sup> v3 by 5.13% and 13.70%, respectively. The performance of <code>voyage-multimodal-3</code> is 0.05% better than that of <code>voyage-3</code>, making the two comparable in terms of retrieval accuracy for pure text documents.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1920" height="1080" data-attachment-id="1226" data-permalink="https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/voyage-multimodal-3_results-002-4/" data-orig-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?fit=1920%2C1080&amp;quality=80&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="voyage-multimodal-3_results.002" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?fit=300%2C169&amp;quality=80&amp;ssl=1" data-large-file="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?fit=1024%2C576&amp;quality=80&amp;ssl=1" src="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?resize=1920%2C1080&amp;quality=80&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?w=1920&amp;quality=80&amp;ssl=1 1920w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?resize=300%2C169&amp;quality=80&amp;ssl=1 300w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?resize=1024%2C576&amp;quality=80&amp;ssl=1 1024w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?resize=768%2C432&amp;quality=80&amp;ssl=1 768w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?resize=1536%2C864&amp;quality=80&amp;ssl=1 1536w, https://i0.wp.com/blog.voyageai.com/wp-content/uploads/2024/11/voyage-multimodal-3_results.002-3.png?resize=1200%2C675&amp;quality=80&amp;ssl=1 1200w" sizes="auto, (max-width: 1000px) 100vw, 1000px"></figure>



<p>All evaluation results are available in <a href="https://docs.google.com/spreadsheets/d/1LAbDBkzO--LGR9y4FWzqhFsImO6ic5NITxgPWGmMIP4/edit?gid=222347087#gid=222347087" rel="nofollow" target="_blank">this spreadsheet</a>.</p>



<h3>Try voyage-multimodal-3 now!</h3>



<p><code>voyage-multimodal-3</code> is available today! The first 200 million tokens are free. To get started, check out our <a href="https://colab.research.google.com/drive/12aFvstG8YFAWXyw-Bx5IXtaOqOzliGt9" rel="nofollow" target="_blank">sample notebook</a>, or head over to our&nbsp;<a href="https://docs.voyageai.com/docs/multimodal-embeddings" rel="nofollow" target="_blank">docs</a>&nbsp;to learn more.</p>



<p>If you’re also interested in fine-tuned embedding models, we’d love to hear from you—please email us at&nbsp;<a href="mailto:contact@voyageai.com">contact@voyageai.com</a>. Follow us on&nbsp;<a href="https://x.com/VoyageAI" rel="nofollow" target="_blank">X (Twitter)</a>&nbsp;and&nbsp;<a href="https://www.linkedin.com/company/voyageai/" rel="nofollow" target="_blank">LinkedIn</a>,&nbsp;and join our&nbsp;<a href="https://discord.gg/zAU7GQEmvT" rel="nofollow" target="_blank">Discord</a>&nbsp;for more updates.</p>



<hr>



<p><sup>1 </sup>Cohere multimodal v3 uses Cohere English v3 (<code>embed-english-v3.0</code>) for the text tower, which makes the both models’ vectors identical on pure text. To minimize confusion, we use “Cohere multimodal v3” as the only label in the charts.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS gets a new logo and it uses the color `rebeccapurple` (650 pts)]]></title>
            <link>https://michaelcharl.es/aubrey/en/code/new-rebeccapurple-css-logo</link>
            <guid>42161919</guid>
            <pubDate>Sun, 17 Nov 2024 04:18:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://michaelcharl.es/aubrey/en/code/new-rebeccapurple-css-logo">https://michaelcharl.es/aubrey/en/code/new-rebeccapurple-css-logo</a>, See on <a href="https://news.ycombinator.com/item?id=42161919">Hacker News</a></p>
Couldn't get https://michaelcharl.es/aubrey/en/code/new-rebeccapurple-css-logo: Error: connect ECONNREFUSED 2400:8902::f03c:92ff:fe5d:e614:443]]></description>
        </item>
        <item>
            <title><![CDATA[Xogot – Godot for iPad (126 pts)]]></title>
            <link>https://xogot.com/</link>
            <guid>42161223</guid>
            <pubDate>Sun, 17 Nov 2024 01:32:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xogot.com/">https://xogot.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42161223">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cookieSettings"><h2>Cookie Settings</h2><p>We use cookies to improve user experience. Choose what cookie categories you allow us to use. You can read more
about our Cookie Policy by clicking on Cookie Policy below.</p><div><div><p><label><span>Essential (required)</span></label></p><p>These cookies enable strictly necessary cookies for security, language support and verification of identity.
These cookies can’t be disabled.</p></div><div id="checkbox_functionality"><p><label><span>Functionality</span></label></p><p>These cookies collect data to remember choices users make to improve and give a better
user experience. Disabling can cause some parts of the site to not work properly.</p></div><div id="checkbox_performance"><p><label><span>Performance &amp; Analytics</span></label></p><p>These cookies help us to understand how visitors interact with our website, help us measure and analyze traffic to improve our service.</p></div><div id="checkbox_targeting"><p><label><span>Targeting &amp; Advertising</span></label></p><p>These cookies help us to better deliver marketing content and customized ads.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pentagon fails 7th audit in a row but says progress made (109 pts)]]></title>
            <link>https://thehill.com/policy/defense/4992913-pentagon-fails-7th-audit-in-a-row-but-says-progress-made/</link>
            <guid>42160768</guid>
            <pubDate>Sun, 17 Nov 2024 00:12:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehill.com/policy/defense/4992913-pentagon-fails-7th-audit-in-a-row-but-says-progress-made/">https://thehill.com/policy/defense/4992913-pentagon-fails-7th-audit-in-a-row-but-says-progress-made/</a>, See on <a href="https://news.ycombinator.com/item?id=42160768">Hacker News</a></p>
Couldn't get https://thehill.com/policy/defense/4992913-pentagon-fails-7th-audit-in-a-row-but-says-progress-made/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Effect of a giant meteorite impact on Paleoarchean environment and life (126 pts)]]></title>
            <link>https://www.chemistryworld.com/news/meteorite-200-times-larger-than-one-that-killed-dinosaurs-reset-early-life/4020391.article</link>
            <guid>42160716</guid>
            <pubDate>Sun, 17 Nov 2024 00:02:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chemistryworld.com/news/meteorite-200-times-larger-than-one-that-killed-dinosaurs-reset-early-life/4020391.article">https://www.chemistryworld.com/news/meteorite-200-times-larger-than-one-that-killed-dinosaurs-reset-early-life/4020391.article</a>, See on <a href="https://news.ycombinator.com/item?id=42160716">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A giant meteorite that slammed into Earth over 3 billion years ago devastated early microbial life in the oceans, but also freed up a nutrient bonanza.</p>
<div data-attachment="537343" data-sequence="2">
<p><img alt="Meteorite and Earth artist impression" src="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/3/4/3/537343_gettyimages460713851_476389_crop.jpg" sizes="(max-width: 1023px) 100vw, 780px" srcset="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xany/3/4/3/537343_gettyimages460713851_476389_crop.jpg 480w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/600xany/3/4/3/537343_gettyimages460713851_476389_crop.jpg 600w,https://d2cbg94ubxgsnp.cloudfront.net/Pictures/780xany/3/4/3/537343_gettyimages460713851_476389_crop.jpg 780w" loading="eager" width="4827" height="3218"></p>


</div>
<p>This meteorite was far larger than the infamous Cretaceous era ending one. ‘We’re looking at a bolide that was 500 to 200 times bigger than the one that killed off the dinosaurs,’ says <a href="https://eps.harvard.edu/people/nadja-drabon">Nadja Drabon</a>, a geologist at Harvard University.</p>
<p>The Archean eon 2.5–4 billion years ago suffered at least 16 major impacts by meteorites upwards of 10km across. Each would have vaporised enough rock to darken the ancient skies for years.</p>
<p>Drabon’s group say the impact 3.26 billion years ago triggered a giant tsunami, as well as clouding the oceans and darkening the skies for years to decades. The impact also evaporated tens of metres of seawater.</p>
<p>Yet there was a silver lining: the churning of the seas brought bioavailable iron up from the ocean depths to its depleted surface and allowed some microbes to flourish, while the meteorite also brought phosphorus vital for life.</p>
<p>Drabon and her colleagues went in search of evidence of ancient major impacts in a remote area south of Kruger National Park in South Africa. There they sought out rocky outcrops containing a layer of spherules – molten droplets formed following a major meteorite impact that rained down over huge swathes of the planet. There are eight such spherule bands in this area, each preserving an ancient impact event.</p>
<p>While the impact crater itself is long gone, analysis of rocks from 3.26 billion years ago tells a tale of planetary devastation. The layer of spherules from this huge impact was 15 to 20cm thick in places, compared with less than a centimetre for the famed dinosaur-killing meteorite, says Drabon.</p>
<p>These ancient droplets contain spikes in iridium and chromium isotope anomalies, revealing their extraterrestrial origins. The glassy spherules were mixed into ripped-up seafloor materials, thought to be the result of gigantic tsunamis.</p>
<div data-attachment="537342" data-sequence="1">
<p><img alt="Figure" src="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xAny/3/4/2/537342_giant_asteroid_pumelled_archaen_life14_637911.jpg" srcset="https://d2cbg94ubxgsnp.cloudfront.net/Pictures/480xAny/3/4/2/537342_giant_asteroid_pumelled_archaen_life14_637911.jpg 480w" loading="lazy" width="1347" height="1882">m</p>


</div>
<p>Above this layer are younger iron-rich rocks and minerals such as siderite and pyrite. ‘After the impact, we suddenly see a spike in iron in the sediment,’ says Drabon. This influx likely came from the deep ocean. The geologists also found a phosphorus spike after impact, calculating that the meteorite could have delivered 363 billion tonnes in a reduced and, therefore, bioavailable state.</p>
<p>Tellingly, the group also saw a change in the carbon isotope signature above the impact layer that they interpret as a rise in microbes with metabolism geared towards efficient iron cycling.&nbsp;This indicates a rebound of microbial life, perhaps within a few years to decades, the investigators conclude.</p>
<p>The group reason that, following the impact, the iron-metabolising microbes would have consumed the newly available Fe<sup>2+</sup> in the shallow seas, transforming it to Fe<sup>3+</sup>, which would sink to the ocean floor as iron hydroxides.</p>
<p>‘Their argument is very compelling, with many different lines of evidence,’ says <a href="https://cst.temple.edu/about/faculty-staff/alexandra-davatzes">Alexandra Davatzes</a>, a geologist at Temple University in Philadelphia, who was not part of the study. ‘We’re in a totally microbial world in the Archean and the potential for recovery would be much, much faster than today.’</p>
<p>This bounce back could have happened repeatedly. ‘Initially large bolide impacts might have killed off a lot of microbial activity on Earth’s surface and in shallow waters, but then have been good for microbial activity, especially in shallow water environments,’ says <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/geowissenschaften/arbeitsgruppen/geo-und-umweltnaturwissenschaften/geo-und-umweltnaturwissenschaften/isotopengeochemie/arbeitsgruppe/staff/ronny-schoenberg/">Ronny Schönberg</a>, a geochemist at the University of Tübingen, Germany who was not part of the research.</p>
<p>It might even shift how we view meteorite hits on early Earth. ‘Everyone associates big impacts with the extinction of the dinosaurs and thinks of them as disastrous,’ says Drabon. ‘But they also carried a lot of transient benefits for the early and evolving biosphere.’</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[James Gleick's Chaos: The Software (223 pts)]]></title>
            <link>https://github.com/rudyrucker/chaos</link>
            <guid>42160647</guid>
            <pubDate>Sat, 16 Nov 2024 23:52:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rudyrucker/chaos">https://github.com/rudyrucker/chaos</a>, See on <a href="https://news.ycombinator.com/item?id=42160647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">James Gleick's CHAOS: The Software</h2><a id="user-content-james-gleicks-chaos-the-software" aria-label="Permalink: James Gleick's CHAOS: The Software" href="#james-gleicks-chaos-the-software"></a></p>
<p dir="auto">This is a free release of the source, manual, and executables of a 1991 Autodesk DOS program that was called  "James Gleick's CHAOS: The Software." The software was written by Josh Gordon, Rudy Rucker and John Walker. Rucker wrote most of the algorithms, except for the Fractal Landscapes algorithms, which are by John Walker.  Josh Gordon did the interface, and much of the implementation of the algorithm code. The program was written in consultation with James Gleick about his brilliant book, <a href="https://around.com/books/" rel="nofollow"> <i>Chaos: Making a New Science</i> </a>. This release is under a Gnu license.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a27c746a91d0e022b7fe8edbacff12cc6b446f5a113cb7ae30c952fbd26d68c1/687474703a2f2f7777772e727564797275636b65722e636f6d2f626c6f672f696d61676573372f6368616f73636f7665722e6a7067"><img src="https://camo.githubusercontent.com/a27c746a91d0e022b7fe8edbacff12cc6b446f5a113cb7ae30c952fbd26d68c1/687474703a2f2f7777772e727564797275636b65722e636f6d2f626c6f672f696d61676573372f6368616f73636f7665722e6a7067" height="400" alt="Cover of Chaos Package" data-canonical-src="http://www.rudyrucker.com/blog/images7/chaoscover.jpg"></a></p>
<p dir="auto">Downloads for the Release 1.1</p>
<p dir="auto"><a href="https://github.com/rudyrucker/chaos/releases/download/1.1-chaos/chaos_executable_v1_1.zip">The CHAOS executables and parameter files.</a></p>
<p dir="auto"><a href="https://github.com/rudyrucker/chaos/releases/download/1.1-chaos/chaos_manual.pdf">The CHAOS User manual</a>.</p>
<p dir="auto"><a href="https://github.com/rudyrucker/chaos/archive/1.1-chaos.zip">The CHAOS source code.</a></p>
<p dir="auto">It's possible to run the Chaos program on any virtually any platform, inside a DOS shell called DOSBox. Details on the <a href="https://github.com/rudyrucker/chaos/releases">Releases page</a>.</p>
<p dir="auto">You are free to alter the Chaos code and upload new versions. Or use our algorithms to spin off smaller programs. See our Chaos <a href="https://github.com/rudyrucker/chaos/"> GitHub repository</a> for the Chaos code online.</p>
<p dir="auto">The biggest outstanding upgrades for Chaos might be: (1) Increase the resolution or pixel size of the display. (2) Elmimate our use of the old DOS TSR or "terminate and stay resident" program metashel.exe, made by MetaGraphics Software Corporation. Chaos uses metashel calls for its graphics.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's In Chaos</h2><a id="user-content-whats-in-chaos" aria-label="Permalink: What's In Chaos" href="#whats-in-chaos"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c0feed1a87cedc9140dbae255b2ffdcd64478f51959d3ed46728f74e3ae32ffa/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f73746172746d656e752e474946"><img src="https://camo.githubusercontent.com/c0feed1a87cedc9140dbae255b2ffdcd64478f51959d3ed46728f74e3ae32ffa/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f73746172746d656e752e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/startmenu.GIF"></a></p>
<p dir="auto">CHAOS has six modules.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4b5652f733b4ebd4023692e7397a7f19c6ead5d321bde7bf3ad73798371cad9b/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d616e64656c68656172742e474946"><img src="https://camo.githubusercontent.com/4b5652f733b4ebd4023692e7397a7f19c6ead5d321bde7bf3ad73798371cad9b/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d616e64656c68656172742e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/mandelheart.GIF"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/98c58f2ce117ddcdf10fadaedc2a20a31c686be5f486da899fd185c8a06457b5/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d616e64656c726f61722e474946"><img src="https://camo.githubusercontent.com/98c58f2ce117ddcdf10fadaedc2a20a31c686be5f486da899fd185c8a06457b5/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d616e64656c726f61722e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/mandelroar.GIF"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/92b3f916e37b3e98b319b32ee6beefc00d95d394f483a8961780736d53acd651/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f72686f7273652e474946"><img src="https://camo.githubusercontent.com/92b3f916e37b3e98b319b32ee6beefc00d95d394f483a8961780736d53acd651/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f72686f7273652e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/rhorse.GIF"></a></p>
<p dir="auto">MANDEL. A <i>Mandelbrot Set</i> program, incorporating:  quadratic and cubic Julia sets, quadratic and cubic Mandelbrot sets, and a gnarly cubic connectedness map called the <a href="http://tinyurl.com/rudyfractals" rel="nofollow">Rudy  set</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d3b6800813a798cc15fee180493a506e730173614eb3b91ee530323e371bfa78/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d61676e65742e474946"><img src="https://camo.githubusercontent.com/d3b6800813a798cc15fee180493a506e730173614eb3b91ee530323e371bfa78/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d61676e65742e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/magnet.GIF"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/cb8d57198ec70fb198195925a5060afb8baad5023fe296f7c772e7550df30eb0/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d61676e6574626173696e732e474946"><img src="https://camo.githubusercontent.com/cb8d57198ec70fb198195925a5060afb8baad5023fe296f7c772e7550df30eb0/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6d61676e6574626173696e732e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/magnetbasins.GIF"></a></p>
<p dir="auto">MAGNETS. A <i>Pendulum and Magnets</i> program showing chaotic physical motion and fractal basins of attraction.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e65bc77a805582db4e422b58371b2ace45c97ed411aff878595504a70b02efa2/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6174747261637468656e6f6e2e474946"><img src="https://camo.githubusercontent.com/e65bc77a805582db4e422b58371b2ace45c97ed411aff878595504a70b02efa2/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6174747261637468656e6f6e2e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/attracthenon.GIF"></a> <a target="_blank" rel="noopener noreferrer" href=""><img src="" width="400" alt=""></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/08d65630637a0561c4b15940963ae3e8aae4817f30b9f080c6623d3b8d811654/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f61747472616374796f726b652e474946"><img src="https://camo.githubusercontent.com/08d65630637a0561c4b15940963ae3e8aae4817f30b9f080c6623d3b8d811654/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f61747472616374796f726b652e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/attractyorke.GIF"></a></p>
<p dir="auto">ATTRACT. A <i>Strange Attractors</i> program showing the Lorenz Attractor, the Logistic Map, the Yorke Attractors, and the Henon Attractors.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/50fe72efa595dbb08d41183631f3c40d60ee7e7b6e536e27ea9c2e419644f19d/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6261726e736c6579666c6f776572732e474946"><img src="https://camo.githubusercontent.com/50fe72efa595dbb08d41183631f3c40d60ee7e7b6e536e27ea9c2e419644f19d/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f6261726e736c6579666c6f776572732e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/barnsleyflowers.GIF"></a></p>
<p dir="auto">GAME. A <i>Barnsley Fractals</i> program showing Iterated Function System fractals such as the famous fractal fern.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7bbef17ab76cb78801a34e58a3104ea9013ae1c7bfa1c709b377b4b98352e8ad/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f666f7267656d656e752e474946"><img src="https://camo.githubusercontent.com/7bbef17ab76cb78801a34e58a3104ea9013ae1c7bfa1c709b377b4b98352e8ad/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f666f7267656d656e752e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/forgemenu.GIF"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1d9d497effd57e32b2e0ed357dc8d133a2ecc707ad07890051dac48ce40cb60b/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f666f726765706c616e65742e474946"><img src="https://camo.githubusercontent.com/1d9d497effd57e32b2e0ed357dc8d133a2ecc707ad07890051dac48ce40cb60b/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f666f726765706c616e65742e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/forgeplanet.GIF"></a></p>
<p dir="auto">FORGE. A <i>Fractal Forgeries</i> program that shows clouds, maps, mountain ranges, and planets based on random fractals.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/216e41f9f199cc1fb1fb72d8851d685c94311c7c1ad62600f6addb34ab88e603/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f686f6467652e474946"><img src="https://camo.githubusercontent.com/216e41f9f199cc1fb1fb72d8851d685c94311c7c1ad62600f6addb34ab88e603/687474703a2f2f7777772e727564797275636b65722e636f6d2f6368616f732f686f6467652e474946" width="400" alt="" data-animated-image="" data-canonical-src="http://www.rudyrucker.com/chaos/hodge.GIF"></a></p> 
<p dir="auto">TOY. A Toy Universes program that shows <i>cellular automata</i>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Making Me Memorize the Borrow Checker (167 pts)]]></title>
            <link>https://erikmcclure.com/blog/stop-making-me-memorize-borrow-checker/</link>
            <guid>42160501</guid>
            <pubDate>Sat, 16 Nov 2024 23:29:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erikmcclure.com/blog/stop-making-me-memorize-borrow-checker/">https://erikmcclure.com/blog/stop-making-me-memorize-borrow-checker/</a>, See on <a href="https://news.ycombinator.com/item?id=42160501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I started learning Rust about 3 or 4 years ago. I am now knee-deep in several very complex Rust projects that keep slamming into the limitations of the Rust compiler. One of the most common and obnoxious problems is hitting a situation the borrow-checker can’t deal with and realizing that I need to completely re-architect how my program works, because lifetimes are “contagious” the same way async is. Naturally, Rust has both!</p><p>Despite how obviously useful the borrow-checker is in writing correct code, in practice it is horrendous to work with. This is because the borrow checker cannot run until an entire function compiles. Sometimes it seems to refuse to run until my entire file compiles. Because an explicit lifetime must come from somewhere, they have a habit of “floating up” through the stack, from the point of usage to the point of origin, infecting everything in-between with another explicit generic lifetime parameter. If you end up not needing it, you need to go through and delete every instance of this lifetime, which can sometimes be 30 or more generic statements that end up needing to be modified.</p><p>In the worst cases, your entire architecture simply cannot work with the borrow checker, and at minimum you’ll need to wrap things in an Rc&lt;&gt;, which again will requiring upwards of 30 or more statements depending on the complexity of your architecture. Other times you realize you need a split borrow, and have to then modify <em>every single function under the split borrow check</em> to take specific field references instead of the original type. These constant refactors have been a major detractor for the language for years, although some improvements, like <code>impl</code>, have reduced the need for refactoring in some narrow cases.</p><p>This means, to be a highly productive Rust programmer, you basically have to memorize the borrow checker rules, so you get it right the first time. This is stupid, because <em>the whole point</em> of having a type system or a borrow checker is to tell you when you get it wrong, so you <em>don’t</em> have to memorize how the borrow rules work. I don’t need to memorize how all the types work, because these errors get caught almost immediately, and rarely require massive refactors because the whole architecture doesn’t need to exist before it can identify problems.</p><p>This is painful because I am an experienced C++ programmer, and C++ has this exact problem except worse: undefined behavior. In the worst case, C++ simply doesn’t check anything, compiles your code wrong, and then does inexplicable and impossible things at runtime for no discernable reason (or it just deletes your entire function). If you run <code>ubsan</code> (undefined behavior sanitizer), it will at least explode at runtime with an error message. Unfortunately, it can only catch undefined behavior that actually happens, so if your test suite doesn’t cover all your code branches you might have undefined behavior lurking in the code somewhere. Even worse, the very existence of undefined behavior sometimes creates a new branch you couldn’t possibly think of testing without knowing about the undefined behavior in the first place!</p><p>This means that in order to write C++, you effectively have to memorize the undefined behavior rules, which sucks. Sound familiar? This is both stupid and strictly worse than Rust, because there is no compile-time error at all, only a runtime error if you get it wrong (and you are running <code>ubsan</code>). However, because it’s a runtime error, correcting it usually requires less total refactoring… usually.</p><p>At this point, C++ can’t fix it’s undefined behavior problem because C++ uses undefined behavior to drive optimization, so now it’s just stuck like this forever. Rust can’t really fix borrow checking either, because borrow checking is embedded so deeply into the compiler at this point. All Rust can do is make the borrow checker more powerful (probably by introducing partial borrows, which seems stuck in eternal bikeshedding hell) or introduce more powerful IDE tooling that can make refactors less painful and more automatic, like automatically removing a generic parameter from everywhere it was used.</p><p>Problems like these are unfortunate, because it drives people towards using C for it’s “simplicity”, when in reality they are simply deferring logic errors until runtime. I think Rust manages to “get away” with it’s excessive verbosity because “safe C++” is even more horrendously verbose and arcane, and safe C++ is what Rust is really competing against right now. I just think Rust needs more competition.</p><p>Any prospective Rust competitor, however, needs to be very cognizant of the tradeoffs they force programmers to make in exchange for correctness. It is not sufficient to invent a language that makes it possible to write provably correct kernel-level code, it has to be <em>easy to use</em> as well, and we really need to get away from indirectly forcing programmers to anticipate what the compiler will do simply to be productive. It’s not the 1970s anymore, writing a program shouldn’t feel like taking a stack of punchcards to the mainframe to see if it works or not. Rust is not the answer, it is simply a step towards the answer.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teach yourself to echolocate (206 pts)]]></title>
            <link>https://www.atlasobscura.com/articles/how-to-echolocate</link>
            <guid>42160071</guid>
            <pubDate>Sat, 16 Nov 2024 22:43:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.atlasobscura.com/articles/how-to-echolocate">https://www.atlasobscura.com/articles/how-to-echolocate</a>, See on <a href="https://news.ycombinator.com/item?id=42160071">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="article-body">

            <p><span>Daniel Kish navigates the world </span>like a bat does—and he does so without ever leaving the ground.</p>
<p>After losing his vision as an infant, Kish taught himself to move around with the help of echolocation. Like bats, Kish uses his mouth to produce a series of short, crisp clicking sounds, and then listens to how those sounds bounce off the surrounding landscape. (Our winged neighbors tend to emit these clicks at <a href="https://www.atlasobscura.com/articles/what-does-echolocation-sound-like">frequencies humans can’t hear</a>, but Kish’s clicks are perfectly audible to human ears.) From there, Kish makes a mental map of his environment, considering everything from broad contours—like walls and doors—down to textural details.</p>
<p>Kish now <a href="https://visioneers.org/">teaches echolocation</a>, mostly to students who are blind. For these students, Kish believes that an echolocation practice can buoy confidence and independence. Kish’s own experience is persuasive—he famously <a href="https://www.youtube.com/watch?v=xATIyq3uZM4">bikes along hilly, car-lined streets</a>—and a <a href="https://www.ncbi.nlm.nih.gov/pubmed/23538130">growing body</a> of <a href="http://www.ingentaconnect.com/content/dav/aaua/2009/00000095/00000002/art00013?token=004d187194fb161639412f415d763f256f45504a6c4273516f2530482972715a614f6d4e227ac">scholarly research</a> <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005670#sec015">has begun to unpack exactly how</a> expert echolocaters do their thing. This research has also backed up the idea that this skill <a href="https://www.wired.com/2009/06/echolocation/">is highly learnable</a>. When <a href="https://whitneylab.berkeley.edu/publications.html">researchers at the University of California, Berkeley</a>, asked novice echolocators to use tongue clicks to determine which of the two objects in front of them was larger, the newbies were <a href="https://www.npr.org/sections/13.7/2013/01/28/170355712/be-like-a-bat-sound-can-show-you-the-way">soon able to do so</a> in a way that the scientists couldn’t attribute to chance.</p>
<p>Whatever your sightedness, there’s something to be said for learning to listen more attentively to sonic scenery. Kish believes that vision has a way of blunting the other senses unless people work to really flex them. Deft echolocators, he says, are able to perceive fine differences—distinguishing, say, between an oleander bush (“a million sharp returns”) and an evergreen (“wisps closely packed together, which sound like a bit like a sponge or a curtain”). They’re discovering sonic wonder wherever they go. We asked Kish to tailor a lesson for first-timers just learning to listen to the landscape.</p>
<h2><strong>1) Practice tuning in </strong></h2>
<p>Before you begin producing your own sounds, just practice noticing the ways that sounds change around you. Try this exercise next time you’re in a car (assuming you’re not in the driver’s seat).</p>
<p>Crack open the window and close your eyes. This is a good chance to pass through a varied landscape pretty quickly, and begin to differentiate between sounds. “On a residential street, you should hear the sound of the car jump in and out as you pass other parked cars, possibly trees, posts, mailboxes, or houses near the curb,” Kish says. “Everything we pass reflects the sound of our car differently.” Prime yourself to pay attention to incidental soundtracks.</p>
<h2><strong>2) Pick your supplies</strong></h2>
<p>If you are a sighted person, you’ll want a blindfold. “It’s very, very difficult to discern these kinds of subtleties if your eyes are working at the same time,” Kish says. Occluding one sense gives the less-dominant ones room to stretch their legs.</p>
<p>Now is also a good time to stock up on what you’ll need for your practice sessions. First, you’ll need a metal tray or a bowl, so make sure you’ve got one on hand. Once you start moving through space later on, it will also help to have a trekking pole or a cane, or at least a partner you trust to shout if you wander too far off base.</p>
<figure><img src="https://img.atlasobscura.com/ymF4lUil1TXhLztpByFsXPg3kxyyO6hxZZsn83Q-Cm0/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy9mYjcxZTkxNWEw/ZDFjZjcxYzNfRWNo/b2xvY2F0aW9uXzMu/anBn.jpg" alt="For beginners, the best clicks are ones that you can make cleanly and reliably." width="auto" data-kind="article-image" id="article-image-59920" loading="lazy"><figcaption>For beginners, the best clicks are ones that you can make cleanly and reliably.</figcaption></figure>
<h2><strong>3) Choose an environment</strong></h2>
<p>Expert echolocators like Kish can get a bit fancier with their choices, and try to hear the character of a room. Tin decor, buttresses, or other accoutrements that might make a realtor swoon will also give Kish reason to perk up his ears. “It will sound more alive,” he says. “It will sing to you.”</p>
<p>For beginners, picking the right place is a bit of a Goldilocks situation: You don’t want a flat field, where there’s nothing for sound to bounce off. Then again, you ought to steer clear of spots where your hearing will be impeded by, say, a sea of carpet. “Probably the best is a fairly quiet, open space without a lot of clutter, maybe a non-reverberant room,” Kish says.</p>
<h2><strong>4) Practice your clicks</strong></h2>
<p>Clicks are not created equal, and some of them will work against you. “The most commonly produced rubbish click is a ‘cluck,’” Kish says. A cluck sounds something like two clicks on top of each other, which masks the returning sound. A good click can’t be sloppy, and it must be possible to reliably reproduce.</p>
<p>For beginners, Kish says that a dental click fits the bill (this is a <em>tsk-tsk</em> sound, Kish says, “like you’re disappointed”). Another contender is the sound you might use to prompt a horse to giddy-up; a “ch” sound, as in “check” or “church,” is another option.</p>
<p>The key is finding the option that’s comfortable for you. “You settle on whatever click you can do, and stick to it,” Kish says.</p>
<figure><img src="https://img.atlasobscura.com/Wfh1-5xglNkC0CwxYJnlEnvcErFO4nsY0DJuCWQ-IzI/rt:fill/w:1200/el:1/q:81/sm:1/scp:1/ar:1/aHR0cHM6Ly9hdGxh/cy1kZXYuczMuYW1h/em9uYXdzLmNvbS91/cGxvYWRzL2Fzc2V0/cy9mYjcxZTkxNWEw/ZDFjZjcxYzNfRWNo/b2xvY2F0aW9uXzIu/anBn.jpg" alt="Tune in!" width="auto" data-kind="article-image" id="article-image-59921" loading="lazy"><figcaption>Tune in!</figcaption></figure>
<h2><strong>5) Start simple </strong></h2>
<p>The goal with clicking is to take stock of three things. The first is presence/absence (is something there?). Then, the location (what direction is it in?). Finally, distance (how far away is it?).</p>
<p>To teach these skills, Kish often starts with this exercise: Students pair up with a partner who holds a bowl or flat paddle somewhere above their head. The student clicks, turns their head, and tries to gauge where the bowl is—straight ahead, or off to the side?</p>
<p>Kish doesn’t click all the time—only when he needs to refresh the mental map he’s working from. For beginning students, though, it’s helpful to practice the physical mechanics of clicking, in order to learn how to listen to bouncing sounds.</p>
<h2><strong>6) Get moving</strong></h2>
<p>The next step is to do all of this while in motion. Walk along a hallway and try to listen for differences in sounds that might indicate corners or open doors.</p>
<p>At first, you’ll shuffle and fumble through this exercise, and it’s bound to be frustrating. Go ahead and ask your partner whether or not you’re on the right track—but, if you’re using a blindfold, keep it on. “The temptation is very strong to pop the blindfold off and on,” Kish says. “I resist that because there is an adaptation process that has to happen here. You disrupt it entirely when you pull off the blindfold. I wouldn’t use vision to spot-check an experience; I would try to avoid that.”</p>
<h2><strong>7) Stop when you need to</strong></h2>
<p>Moving through the world in a new way can be both thrilling and thoroughly disorienting. Kish has found that people who are sighted, and are unaccustomed to not being able to rely on their vision, need to take breaks every 30-45 minutes. His blind students, for whom non-visual navigation is routine, can hang in longer.</p>
<p>Echolocation takes patience and practice. Kish cautions that it’s hard to get good at this—it took him years. But trying it out can open your ears to the world.</p>






          </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Bluesky firehose viewed in the style of a Windows XP screensaver (448 pts)]]></title>
            <link>https://firehose3d.theo.io/</link>
            <guid>42159786</guid>
            <pubDate>Sat, 16 Nov 2024 22:07:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://firehose3d.theo.io/">https://firehose3d.theo.io/</a>, See on <a href="https://news.ycombinator.com/item?id=42159786">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <p>Loading...</p>
    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky is currently gaining more than 1M users a day (205 pts)]]></title>
            <link>https://bsky.jazco.dev/stats</link>
            <guid>42159713</guid>
            <pubDate>Sat, 16 Nov 2024 21:58:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.jazco.dev/stats">https://bsky.jazco.dev/stats</a>, See on <a href="https://news.ycombinator.com/item?id=42159713">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[We’re receiving about 3,000 reports/hour (116 pts)]]></title>
            <link>https://bsky.app/profile/safety.bsky.app/post/3layun7re5s2x</link>
            <guid>42159454</guid>
            <pubDate>Sat, 16 Nov 2024 21:20:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.app/profile/safety.bsky.app/post/3layun7re5s2x">https://bsky.app/profile/safety.bsky.app/post/3layun7re5s2x</a>, See on <a href="https://news.ycombinator.com/item?id=42159454">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Logica – Declarative logic programming language for data (158 pts)]]></title>
            <link>https://logica.dev/</link>
            <guid>42158445</guid>
            <pubDate>Sat, 16 Nov 2024 19:09:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://logica.dev/">https://logica.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=42158445">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <a href="https://github.com/evgskv/logica">
    <div onclick="thumbsUp()">
      <p><img src="https://logica.dev/github-mark.png" height="80px"></p><p>
        View project on<br>
        GitHub. 
      </p>
    </div>
  </a>

<h2>What is Logica?</h2>

<div>
<p>
  Logica is an <a href="https://github.com/evgskv/logica">open source</a>
  declarative logic programming language for data manipulation.
</p>

<p>
  Logica extends syntax of logic programming for intuitive and efficient data
  manipulation. It compiles to SQL thus providing you access to the power
  of SQL engines with the convenience of logic programming syntax.
</p>
</div>


  <h2>Examples</h2>


<p>
  One may say that for programming languages like Python and Java functions are the
  basic building blocks. For Logica and other logic programming languages
  those building blocks are <i>predicates</i>. 

  Logic program is defined as a set of rules that define output predicates
  from pre-defied predicates. Those pre-defined predecates represent input data.

  For example here is a rule to identify names of expensive books, from an existing
  table of book prices.
</p>


<p>
# Logica rule to get expensive books.
ExpensiveBook(book_name) :-   # book_name is expensive if and only if
  Book(book_name, price),     # book_name costs price
  price &gt; 100;                # and price is greater than 100.
</p>

<p>
If you are familiar with SQL, you may see that the rule above
is equivalent to the flowing SQL statement. Not that familiarity with SQL is
required to learn Logica, not at all.
</p>

<p>
# SQL statement to get expensive books.
SELECT book_name
FROM book
WHERE price &gt; 100;
</p><p>

Predicate is a statement with variables. Any table can be treated as predicate,
where column names are the variables, and each row is a set of values of the variables
that satisfies the statement. 

While SQL is quite convenient for small queries like the one above it
gets hard to read when complexity grows. Logica leverages power of
mathematical syntax to scale nicely as complexity grows.

Let's assume we have a table <span>BabyNames</span>
that for each <span>name, year, city</span> and
<span>gender</span> specifies 
<span>number</span> of babies of that name born.
The following program finds a list of <i>popular</i> names, where a name
is defined as popular if it was the most popular name on some year.

</p><p>
# Count babies per year.
NameCountByYear(name:, year:) += number :-
  BabyNames(name:, year:, number:);
  
# For each year pick the most popular.
TopNameByYear(year) ArgMax= name -&gt; NameCountByYear(name:, year:);

# Accumulate most popular name into a table, droppig the year.
PopularName(name: TopNameByYear());
</p><p>

Sometimes data analysis requires solving algorithmic problems. Logica's
syntax is suited for it naturally. Here is a program finding prime numbers
that are less than 100.

</p><p>
  # Define numbers 1 to 30.
  Number(x + 1) :- x in Range(30);
  
  # Defining composite numbers.
  Composite(a * b) distinct :- Number(a), Number(b), a &gt; 1, b &gt; 1;
  
  # Defining primes as "not composite".
  Prime(n) distinct :- Number(n), n &gt; 1, ~Composite(n);
</p>

<p>
Finally here is an example of program that runs over
<a href="https://www.gdeltproject.org/">GDELT Project</a> dataset,
finding people mentioned in the context of "artificial general intelligence".
</p>


<p>Observe that program is divided into a rule defining predicate
  <span>NewsData</span> and rule for <span>AgiMentions</span>.
The first rule is essentially doing data cleaning, formatting the dataset in a shape
that is convenient to use. Then second rule peforms the task at hand.
</p>

<p>
In Logica problems are naturally split into smaller components that end up
reusable. So in the future if we have more analysis to do with GDELT dataset
we may take advantage of the <span>NewsData</span> predicate that we just wrote.
</p>

<p>
# Structuring the data conveniently.
NewsData(year:, month:, day:, persons:, quotations:) :-
  gdelt-bq.gdeltv2.gkg(persons: persons_str, quotations:, date: date_num),
  # Column `data` in GDELT dataset is given as an integer.
  year == ToInt64(Substr(ToString(date_num), 1, 4)),
  month == ToInt64(Substr(ToString(date_num), 5, 2)),
  day == ToInt64(Substr(ToString(date_num), 7, 2)),
  persons List= (person :- person in Split(persons_str, ";"));

# Performing the task at hand.
@OrderBy(AgiMentions, "mentions desc");
@Limit(AgiMentions, 10);
AgiMentions(person:, mentions? += 1) distinct :-
  person in persons,
  Like(quotations, "%artificial general intelligence%"),
  NewsData(persons:, quotations:);

</p><p>

This program completes in interactive time
when ran over the 4TB dataset
via BigQuery.

</p><div>
  <h2> Why Logica? </h2><p>

Logica is for engineers, data scientists and other specialists who 
need to perform complex data processing and analysis.
Queries and pipelines written in Logica can run on
<a href="https://cloud.google.com/bigquery">BigQuery</a>, <a href="https://sqlite.org/index.html">SQLite</a>
and <a href="https://www.postgresql.org/">PostgreSQL</a> engines.
Information stored in these systems is thus available in Logica.


</p><p>
Logica compiles to SQL and gives you access to the power of SQL engines,
including the massively distrbuted Google BigQuery engine,
with the convenience of logic programming syntax. This is useful because
BigQuery is magnitudes more powerful than state of the art native
logic programming engines.
</p>

<p>
We encourage you to try Logica, especially if
</p>

<ul>
  <li>   you already use logic programming and need more computational power, or </li>
  <li>   you already have data in BigQuery, PostgreSQL or SQLite, or </li>
  <li>   you want to learn logic programming and apply it to processing of Big Data.</li>
</ul><p>

Among other engines, there is partial support for Trino and Databricks.
Contributions to improve this support are
<a href="https://github.com/EvgSkv/logica/discussions">very welcome</a>!

</p></div>

<h2> I have not heard of logic programming. What is it? </h2>

<p>
Logic programming is a declarative programming paradigm where the program is
written as a set of logical statements.
</p>

<p>
Logic programming was developed in academia from the late 60s. Prolog and
Datalog are the most prominent examples of logic programming languages. 
Logica is a successor to
<a href="https://research.google/pubs/pub43462/">Yedalog</a>,
a language created at Google earlier. Logica as well as Yedalog belong to
Datalog family.
</p>

<p>
Datalog and relational databases start from the same idea: think of data
as relations and think of data manipulation as a sequence of operations over
these relations. But Datalog and SQL differ in how these operations are
described. Datalog is inspired by the mathematical syntax of the first order
propositional logic and SQL follows the syntax of natural language.
</p>

<p>
SQL was based on the natural language to give access to databases to the people
without formal training in computer programming or mathematics. This convenience
may become costly when the logic that you want to express is non trivial.
There are many examples of hard-to-read SQL queries that correspond to simple
logic programs.
</p>

<p>
Logica follows Yedalog in the attempt to merge these branches back together:
extending the elegant syntax of Logic Programming to solve practical problems
and leverage the tremendous advances of SQL infrastructure for the execution.
</p>


<h2>How does Logica work?</h2><p>

Logica compiles the logic program into a SQL expression,
so it can be executed on BigQuery, the state of the art SQL engine.

Among database theoreticians Datalog and SQL are known to be equivalent.
And indeed the conversion from Datalog to SQL and back is often straightforward.
However there are a few nuances, for example how to treat disjunction and negation. In Logica we tried to make choices that make understanding of the resulting SQL structure as easy as possible, thus empowering user to write programs that are executed efficiently.

</p><h2>Why is it called Logica?</h2><p>

Logica stands for <b>Logic</b> with <b>a</b>ggregation.

</p>

<p>
Learn basics of Logica with the
<a href="https://colab.research.google.com/github/EvgSkv/logica/blob/main/tutorial/Logica_tutorial.ipynb">CoLab tutorial</a> 
located at <a href="https://github.com/EvgSkv/logica/tree/main/tutorial">tutorial</a> folder.
See <a href="https://github.com/EvgSkv/logica/tree/main/examples">examples</a> of using Logica in examples folder.

You try Logica immediately in the browser in <a href="https://logica.dev/sandbox.html">Playground</a>.
</p>

<p>
It is easy to install Logica on your machine as well.
</p>

<h2>Installation</h2><p>

Install Logica with `pip`.

</p><p>
# Install:
$ python3 -m pip install logica
# Run:
$ python3 -m logica
# (optional) Create alias for convenience:
alias logica=python3 -m logica
</p><p>

Let's say this program is written in file
 <span>hello.l</span>.
</p><p>
@Engine("sqlite");
Greeting("Hello world!");
</p><p>

When exectued with

</p><p>
$ logica hello.l run Greeting
</p><p>

it should produce the following table:</p><p>
+--------------+
|     col0     |
+--------------+
| Hello world! |
+--------------+
</p>


<h2>Join the discussion!</h2><p>

If you have any questions or ideas about Logica, you
are welcome to post those in <a href="https://github.com/EvgSkv/logica/discussions">Discussions section</a> of the repo!



</p>
<p>
Unless otherwise noted, the Logica source files are distributed under the Apache 2.0 license found in the LICENSE file.
</p>
<p>
Logica is not an officially supported Google product.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Four dead in fire as Tesla doors fail to open after crash (198 pts)]]></title>
            <link>https://myelectricsparks.com/four-dead-tesla-doors-fail-open-crash-fire/</link>
            <guid>42158391</guid>
            <pubDate>Sat, 16 Nov 2024 19:03:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://myelectricsparks.com/four-dead-tesla-doors-fail-open-crash-fire/">https://myelectricsparks.com/four-dead-tesla-doors-fail-open-crash-fire/</a>, See on <a href="https://news.ycombinator.com/item?id=42158391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>A devastating accident in Toronto involving a Tesla Model Y resulted in the tragic deaths of four individuals and the miraculous rescue of a young woman. The crash, which occurred on October 24, has raised serious questions about the safety of Tesla’s electronic door mechanisms.</p>



<p>A Tesla Model Y carrying five passengers lost control while traveling at high speed. The vehicle struck a guardrail and subsequently collided with a concrete pillar, bursting into flames upon impact. The collision took place on a local roadway, as confirmed by Toronto Police Duty Inspector Phillip Sinclair during a news conference.</p>



<p>Three men, aged 26, 29, and 32, and a 30-year-old woman were pronounced dead at the scene. A 25-year-old woman survived the horrific accident and was transported to the hospital with non-life-threatening injuries.</p>



<p>The sole survivor owes her life to the quick actions of Rick Harper, a 73-year-old Canada Post worker, who came upon the burning vehicle. Harper, along with other bystanders, noticed that the passengers were trapped inside the Tesla, unable to open the electronic doors.</p>



<p>Harper recounted to the <a href="https://www.thestar.com/news/gta/she-couldn-t-get-out-deadly-toronto-tesla-fire-draws-attention-to-risk-of-electronic/article_c9313fbe-9ad0-11ef-998a-93ba9a9927d5.html?utm_source=rakuten&amp;utm_medium=affiliate&amp;ranMID=53416&amp;ranEAID=TnL5HPStwNw&amp;ranSiteID=TnL5HPStwNw-dj2l96o7bRjk1fk9blY9lQ" target="_blank" rel="noreferrer noopener nofollow">Toronto Star</a>, “You couldn’t open the doors. I would assume the young lady would have tried to open the door from the inside because she was pretty desperate to get out.” Harper grabbed a bar from his truck and handed it to another bystander, who managed to break the back window and pull the young woman to safety.</p>



<p><strong>ALSO READ:</strong> <a href="https://myelectricsparks.com/elon-musk-responds-to-young-girl-who-found-bug-in-tesla-model-3/">Elon Musk Responds to Young Girl Who Found Bug in Tesla Model 3</a></p>



<figure><img decoding="async" width="1024" height="683" src="https://myelectricsparks.com/wp-content/uploads/2024/11/Four-Passengers-Die-in-Burning-Tesla-1-1024x683.webp" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20683'%3E%3C/svg%3E" data-lazy-src="https://myelectricsparks.com/wp-content/uploads/2024/11/Four-Passengers-Die-in-Burning-Tesla-1-1024x683.webp"></figure>



<p>The Tesla Model Y’s electronic doors, which require power to operate, have come under scrutiny following the accident. Authorities are investigating whether the failure of these doors contributed to the fatalities. Harper mentioned that the thick smoke made it difficult to see the other passengers trapped inside, further complicating rescue efforts.</p>



<p>Tesla has faced criticism in the past for the design of its manual release levers, which are considered poorly designed and unintuitively placed. These emergency measures require intimate knowledge of the car, something that may not be feasible in a panic situation.</p>



<p><strong>ALSO READ:</strong> <a href="https://myelectricsparks.com/tesla-warns-against-wet-towel-method-for-supercharging/">Tesla Warns Against Wet Towel Method for Supercharging</a></p>



<p>The Toronto Police and fire authorities are conducting a thorough investigation into the crash. Deputy Fire Chief Jim Jessop stated that they are examining the possibility that the intensity of the fire was linked to the car’s battery cells.</p>



<p>The crash has also highlighted concerns about the safety of electric vehicles in high-speed collisions. Despite the presence of manual release mechanisms in most Tesla models, the ease of access and usability of these features remain contentious issues.</p>



<figure></figure>



<p>In a <a href="https://www.tps.ca/media-centre/news-releases/61244/" target="_blank" rel="noreferrer noopener nofollow">press release</a>, Inspector Sinclair emphasized that no other vehicles were involved in the crash, and the investigation is ongoing. He also extended gratitude to Harper for his brave actions, stating, “Thanks very much to that bystander. We have been speaking to them, and obviously, they also are deeply affected by this incident, a very horrific scene for that bystander to step in.”</p>



<p>Harper expressed his shock and sorrow after learning about the deaths of the other passengers. “I was totally shocked. It really hit me when I saw the report in the news that four had died,” he told <a href="https://www.cbc.ca/news/canada/toronto/fatal-crash-four-dead-lake-shore-cherry-1.7361751" target="_blank" rel="noreferrer noopener nofollow">CBC News</a>. Harper was later informed by detectives that the young woman he rescued was recuperating in the hospital.</p>



<p>This tragic incident has sparked a debate about the safety features of electric vehicles and the necessity for more intuitive emergency mechanisms. As authorities continue their investigation, the focus remains on understanding the causes of the crash and preventing such tragedies in the future.</p>



<p>Tesla did not immediately respond to requests for comment, but the company is likely to face increased scrutiny over the safety and design of its vehicles’ electronic systems. The incident serves as a stark reminder of the potential risks associated with advanced automotive technology and the importance of accessible emergency features.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[James Webb Space Telescope finds evidence for alternate theory of gravity (333 pts)]]></title>
            <link>https://thedebrief.org/james-webb-space-telescope-finds-stunning-evidence-for-alternate-theory-of-gravity/</link>
            <guid>42158130</guid>
            <pubDate>Sat, 16 Nov 2024 18:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thedebrief.org/james-webb-space-telescope-finds-stunning-evidence-for-alternate-theory-of-gravity/">https://thedebrief.org/james-webb-space-telescope-finds-stunning-evidence-for-alternate-theory-of-gravity/</a>, See on <a href="https://news.ycombinator.com/item?id=42158130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
																										<p>Astronomers using the James Webb Space Telescope to peer back in time into the farthest reaches of the universe have found stunning evidence for <a href="https://thedebrief.org/newtons-law-of-universal-gravitation-is-challenged-by-controversial-new-astrophysics-discovery/">an alternate theory of gravity</a>.</p>
<p>Current models of galaxy formation in the early cosmos predict the presence of excess gravity caused by dark matter to pull material into slowly forming galaxies. However, an alternate theory of gravity first proposed in 1998 called Modified Newtonian Dynamics (MOND) suggests that structures in the early universe formed very quickly without the need for theoretical dark matter.</p>
<p>Now, researchers from Case Western Reserve University say that scans of ancient galaxies gathered by the JWST seem to contradict the commonly accepted predictions of the most widely accepted Cold Dark Matter theory, Lambda-CDM. Instead, the readings seem to support a basis for MOND, which would force astronomers and cosmologists to reconsider this alternative and long-controversial theory of gravity.</p>
<h2><strong>The Dark Matter Debate</strong></h2>
<p>The Lambda-CDM model has long posited that dark matter, an elusive and invisible form of matter, is essential for explaining the structure of the universe. According to this model, dark matter’s gravitational influence shaped galaxies and caused the formation of large-scale structures. It predicts that ancient galaxies in the early universe should appear small and dim, as they were gradually pulled together by dark matter over cosmic time.</p>
<p>However, McGaugh and his colleagues argue that these predictions do not match JWST observations. Instead, the newly observed galaxies appear bright, large, and fully formed, even as scientists peer deeper into the universe’s past. This unexpected brightness directly challenges the conventional understanding of galaxy formation driven by dark matter.</p>
<p>“Astronomers invented dark matter to explain how you get from a very smooth early universe to big galaxies with lots of empty space between them that we see today,” said Stacy McGaugh, professor and director of astronomy at Case Western Reserve, in a press release announcing the study.</p>
<p>“(But) what the theory of dark matter predicted is not what we see.”</p>
<p>Specifically, McGaugh said that if the lambda-CDM model were accurate, the extra gravitational pull from dark matter, which only interacts with other matter through gravity, would cause small pieces of matter surrounding nascent galaxies to accrete to the center slowly.</p>
<h2><strong>MOND: A Radical Alternative Theory of Gravity</strong></h2>
<p>The MOND theory, first proposed in 1983 by Israeli physicist Mordehai Milgrom, offers a different explanation. MOND suggests modifying Newton’s second law to account for discrepancies observed in galaxy rotation curves without invoking dark matter. These modifications are relevant in regions of tiny accelerations, such as those experienced at the universe’s periphery, where JWST is now observing.</p>
<p>In 1998, McGaugh co-authored a seminal paper proposing that galaxy formation happened more rapidly and did not rely on dark matter. Instead, he and his co-authors, including Federico Lelli, Jay Franck, and James Schombert, theorized that galactic material was quickly collected, expanded with the universe, and then collapsed under gravity. This theory contends that galaxies came together early, forming large, luminous structures without the need for dark matter.</p>
<h2><strong>Evidence and Challenges</strong></h2>
<p>According to McGaugh and colleagues, JWST’s data aligns more closely with predictions made by MOND proponents than with Lambda-CDM models. As an example, McGaugh highlights that the MOND-based predictions of R H Sanders matched observations more accurately than those made by Lambda-CDM advocates Mo, Mao, and White. Yet, despite the recent success, MOND remains a contentious theory, as reconciling it with Einstein’s Theory of General Relativity—a foundation of modern physics—has proven elusive.</p>
<p>“We can always attempt to modify a theory to accommodate new facts,” McGaugh concedes, acknowledging that while facts inconsistent with one model do not necessitate abandoning it entirely, the inability to fully explain observational data might indicate a weaker theoretical framework. Even so, some modern astronomical measurements does still favor the dark matter hypothesis.</p>
<h2><strong>The Ongoing Case for Lambda-CDM</strong></h2>
<p>Despite MOND’s apparent success in explaining some JWST observations, Lambda-CDM continues to enjoy broad support. The model has accurately predicted the universe’s expansion rate since the 1920s, with evidence of a cosmological constant pushing the universe to perpetually expand. Additionally, while the universe is nearly flat, a requirement for Lambda-CDM, slight deviations remain a grey area for further exploration.</p>
<p>The broader astrophysical community remains cautious, and many researchers point out that Lambda-CDM has withstood numerous tests and provides a cohesive framework for understanding the universe. Even so, McGaugh is excited about the ongoing debate.</p>
<p>“The expectation was that every big galaxy we see in the nearby universe would have started from these itty-bitty pieces,” McGaugh said. “That’s not what JWST is showing us.”</p>
<p>McGaugh concedes that finding a theory compatible with both General Relativity and MOND remains an unrealized challenge. However, following the discoveries by the JWST that seem to support their MOND concept and its alternate theory of gravity, McGaugh says he and his colleagues are feeling somewhat vindicated.</p>
<p>“The bottom line is, ‘I told you so,’” McGaugh said. “I was raised to think that saying that was rude, but that’s the whole point of the scientific method: Make predictions and then check which come true.”</p>
<p>The paper “<a href="https://iopscience.iop.org/article/10.3847/1538-4357/ad834d">Accelerated Structure Formation: The Early Emergence of Massive Galaxies and Clusters of Galaxies</a>” appeared on November 12, 2024 in the <em>The Astrophysical Journal.</em></p><div id="block-wrap-77939" data-id="77939">		<article>
					<p><a href="https://thedebrief.org/watch-iron-beam-drone-killing-laser-in-action/">
				<img decoding="async" width="120" height="120" src="https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-120x120.png" alt="Iron Beam Laser" srcset="https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-120x120.png 120w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-150x150.png 150w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-70x70.png 70w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-240x240.png 240w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-360x360.png 360w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-125x125.png 125w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-120x120.png 120w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-150x150.png 150w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-70x70.png 70w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-240x240.png 240w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-360x360.png 360w, https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-125x125.png 125w" data-src="https://thedebrief.b-cdn.net/wp-content/uploads/2022/04/Iron-Beam-RESIZE-120x120.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div>
<p><strong><em>Christopher Plain is a Science Fiction and Fantasy novelist and Head Science Writer at The Debrief. Follow and connect with him on </em></strong><a href="https://twitter.com/plain_fiction"><strong>X</strong></a>,<strong><em> learn about his books at </em></strong><a href="https://plainfiction.com/"><strong><em>plainfiction.com</em></strong></a><strong><em>, or email him directly at </em></strong><a href="mailto:christopher@thedebrief.org"><strong><em>christopher@thedebrief.org</em></strong></a><strong><em>.</em></strong></p>
<p><strong><em>Ryan Whalen covers science and technology for The Debrief. He holds a BA in History and a Master of Library and Information Science with a certificate in Data Science. He can be contacted at&nbsp;<a href="mailto:ryan@thedebrief.org">ryan@thedebrief.org</a>, and follow him on Twitter @mdntwvlf.</em></strong></p>
									</div></div>]]></description>
        </item>
    </channel>
</rss>