<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 05 Sep 2024 00:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Internet Archive loses appeal over eBook lending (194 pts)]]></title>
            <link>https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending</link>
            <guid>41449229</guid>
            <pubDate>Wed, 04 Sep 2024 18:56:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending">https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending</a>, See on <a href="https://news.ycombinator.com/item?id=41449229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Internet Archive has lost its appeal in a fight to lend out scanned ebooks without the approval of publishers. In a <a href="https://www.documentcloud.org/documents/25091194-internet-archive-appeal?responsive=1&amp;title=1">decision on Wednesday</a>, the Second Circuit Court of Appeals ruled that permitting the Internet Archive’s digital library would “allow for widescale copying that deprives creators of compensation and diminishes the incentive to produce new works.”</p><p>The decision is another blow to the nonprofit in the <em>Hachette v. Internet Archive</em> case. In 2020, four major publishers — Hachette, Penguin Random House, Wiley, and HarperCollins — <a href="https://www.theverge.com/2020/6/1/21277036/internet-archive-publishers-lawsuit-open-library-ebook-lending">sued the Internet Archive</a> over claims its digital library constitutes “willful digital piracy on an industrial scale.”</p><p>The Internet Archive has long offered a system called the Open Library, where users can “check out” digital scans of physical books. The library was based on a principle called controlled digital lending, where each loan corresponds to a physically purchased book held in a library — avoiding, in theory, a piracy claim. It’s a fundamentally different system from programs like OverDrive, where publishers sell limited-time licenses to ebooks on their own terms.</p><p>However, the Internet Archive <a href="https://blog.archive.org/2020/03/30/internet-archive-responds-why-we-released-the-national-emergency-library/">expanded its library project during the covid-19 pandemic</a>. It launched the National Emergency Library, allowing an unlimited number of people to access the same copies of ebooks. That’s when the publishers banded together to file the lawsuit, targeting both online libraries.</p><p>The Second Circuit Court’s decision acknowledges the benefits and drawbacks of the Internet Archive’s digital library in its decision. But it ultimately sides with publishers:</p><div><blockquote><p>On the one hand, eBook licensing fees may impose a burden on libraries and reduce access to creative work. On the other hand, authors have a right to be compensated in connection with the copying and distribution of their original creations. Congress balanced these “competing claims upon the public interest” in the Copyright Act. We must uphold that balance here.</p></blockquote></div><div><p>Last year, <a href="https://www.theverge.com/2023/3/24/23655804/internet-archive-hatchette-publisher-ebook-library-lawsuit">a federal judge ruled that the Internet Archive</a> doesn’t have the right to scan and lend out books in the same way a library would. The Internet Archive later <a href="https://www.theverge.com/2023/9/11/23868870/internet-archive-hachette-open-library-copyright-lawsuit-appeal">appealed that decision</a>. </p></div><p>“We are disappointed in today’s opinion about the Internet Archive’s digital lending of books that are available electronically elsewhere,” Chris Freeland, the director of library services at the Internet Archive, <a href="https://blog.archive.org/2024/09/04/internet-archive-responds-to-appellate-opinion/">writes in a post on the site</a>. “We are reviewing the court’s opinion and will continue to defend the rights of libraries to own, lend, and preserve books.” Freeland also <a href="https://www.change.org/p/let-readers-read-an-open-letter-to-the-publishers-in-hachette-v-internet-archive?utm_medium=custom_url&amp;utm_source=share_petition&amp;recruited_by_id=eb10e620-2915-11ef-99de-71750e499499">points to a petition</a> you can sign to restore access to the 500,000 books publishers restricted access to.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi: Announcing The Assistant (287 pts)]]></title>
            <link>https://blog.kagi.com/announcing-assistant</link>
            <guid>41448985</guid>
            <pubDate>Wed, 04 Sep 2024 18:35:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/announcing-assistant">https://blog.kagi.com/announcing-assistant</a>, See on <a href="https://news.ycombinator.com/item?id=41448985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <div>
  <p>
    <iframe width="800" height="450" src="https://www.youtube-nocookie.com/embed/0cMcOtVQUkE?si=0cMcOtVQUkE&amp;rel=0&amp;vq=hd1080" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
  </p>
</div>
<p><em>Yes, the rumours are true!</em></p>

<p>Kagi has been thoughtfully integrating AI into our search experience, creating a smarter, faster, and more intuitive search. This includes <a href="https://help.kagi.com/kagi/ai/quick-answer.html">Quick Answer</a> which delivers knowledge instantly for many searches (can be activated by appending ? to the end of your searches), <a href="https://help.kagi.com/kagi/ai/summarize-page.html">Summarize Page</a> for the quick highlights of a web page, and even the ability to <a href="https://help.kagi.com/kagi/ai/ask-questions.html">ask questions about a web page</a> in your search results. And all of these features are on-demand and ready when you need them.</p>

<p>Today we’re excited to unveil the Assistant by Kagi.  A user friendly Assistant that has everything you want and none of the things you don’t (such as user data harvesting, ads &amp; tracking).  Major features include:</p>

<ul>
<li>Integration with Kagi’s legendary quality search results<br>
</li>
<li>Choice of leading LLM models from all the leading providers (OpenAI, Anthropic, Google, Mistral, …)<br>
</li>
<li>Powerful Custom Assistants that include your own custom instructions, choice of leading models, and tools like search and internet access<br>
</li>
<li>Mid-thread editing and branching for making the most of your conversations without starting over<br>
</li>
<li>All threads are private by default, retained only as long as you want and subscriber data is not used for training models.</li>
</ul>

<h2>Powered by Kagi Search</h2>

<p>Kagi Assistant has the ability to use Kagi Search to source the highest quality information meaning that its responses are grounded in the most up-to-date factual information while disregarding most “spam” and “made for advertising” sites with our unique ranking algorithm and user search personalizations on top.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361807-334029-upload-5b01ebb868ee82236b769125e19d2b10.png" alt="image">
</p><center><em>Assistant with References</em></center>

<h2>Choice of Best Models</h2>

<p>Kagi Assistant provides the best in class capabilities for coding, information retrieval, problem solving, brainstorming, creative writing, and other LLM applications by leveraging the finest LLM models available. You can select from any model and switch whenever you like. The Assistant can always make use of the latest models as they become available. In addition, you can decide whether to give the model web access (via Kagi Search) or you want to use the model in ‘raw’ mode.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361807-99305-upload-0c181df6fd10988592f870adcabf9142.png" alt="image">
</p><center><em>Model Selection</em></center>

<h2>Powerful Custom Assistants</h2>

<p>LLMs are incredibly flexible tools you can use for many tasks.  With Kagi’s Custom Assistants you can build a tool that meets your exact needs.  For example you may be a car enthusiast and are looking for advice about your VW Bus.</p>

<p>You could create a Custom Assistant to help with the myriad of questions a owner of a classic vehicle might have.  Start by naming your Custom Assistant and select the tools and options.<br>
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725389662-205507-image.png" alt="image">
</p><center><em>Custom Assistant Options</em></center>

<p><br>
Then give the Custom Assistant context and clear instructions on how it should respond.  In this case providing relevant details on your car and guidelines for the advice.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725389665-535788-image2.png" alt="image">
<em></em></p><center><em>Custom Assistant Instructions</em></center>

<p>Use the Custom Assistant to get the answers you need with the context and instructions provided.  Here the model provides relevant advice on diagnosing a oil leak.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725389839-290214-image3.png" alt="image">
<em></em></p><center><em>Using Custom Assistant</em></center>

<h2>Mid-Thread Editing and Branching</h2>

<p>Any LLM user has seen that sometimes they can get data wrong, hallucinate or just become confused.  Or we might want to refine our prompt as we see how a model responds. For instance if you’re interested in understanding how to handle imbalanced data sets you might ask Assistant:</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-569146-upload-744debb8ceb4547fd753110a30e3c18a.png" alt="image"></p>

<center><em>Starting a Thread</em></center>


<p>The response is correct, but a little too generic; you can edit the question and add that you’re working on a binary classification problem to get a more specific answer.  You could even switch the model or turn on/off web access.<br>
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-385380-upload-5a8180e572dc07ebe4ac4c8be278b5fc.png" alt="image">
</p><center><em>Editing the Prompt to add Specifics</em></center>

<p><br>
Clarifying the question yields much more useful advice but if it didn’t you could just go back to the original branch and continue on.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-284938-upload-baca920305f0b650338782e0d3e109a3.png" alt="image"></p>

<center><em>Updated Answer with New Detail &amp; Branch Navigation</em></center>

<h2>Private by Default</h2>

<p>We know many of you are concerned about what AI companies may be doing with your data. According to a <a href="https://www.pewresearch.org/internet/2023/10/18/how-americans-view-data-privacy/">survey by the Pew Research Center</a> about 80% of people “familiar with AI say its use by companies will lead to people’s personal information being used in ways they won’t be comfortable with (81%) or that weren’t originally intended (80%)” and “Among those who’ve heard about AI, 70% have little to no trust in companies to make responsible decisions about how they use it in their products.”</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725386335-668027-pi-20231018-data-privacy-0-04.webp"></p>



<p>Kagi is committed to protecting your information. Your threads automatically expire and are deleted according to your settings (default is after 24 hours) and you can choose to save threads you really need for later.  This approach helps not only with protecting your data, but with managing the thread clutter as well.
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725391573-898057-screenshot-2024-09-03-at-122557.png" alt="image">
</p><center><em>Thread Saving Settings</em></center>


<p>Since we don’t show ads (and never will) and don’t train on subscriber data there’s no reason for us to harvest your data, track your clicks, searches, threads, or build a profile of you.  When we use third party models via their APIs it is protected under terms of service that forbid using data for training their models (e.g. <a href="https://support.anthropic.com/en/articles/7996885-how-do-you-use-personal-data-in-model-training">Anthropic Terms</a> &amp; <a href="https://ai.google.dev/gemini-api/terms#data-use-paid">Google Terms</a>).</p>

<h2>Pricing &amp; Availability</h2>

<p>The Assistant by Kagi is available today as part of the Kagi Ultimate Plan for $25 per month, which also includes full access to Kagi Search. Discount available for annual subscriptions.  <a href="https://kagi.com/">Learn more at Kagi.com</a>.</p>

<h2>FAQ:</h2>

<p><strong>Q:</strong> Can I try out Assistant today?<br>
<strong>A:</strong> Yes, the Assistant is generally available today to all Kagi Ultimate tier members   You can create an account today to try it out and cancel at any time with no long term commitments.</p>

<p><strong>Q:</strong> Is the Assistant available in Kagi’s Starter or Professional tier?<br>
<strong>A:</strong> As of today the Assistant is only available on our Ultimate tier (and Family plan members upgraded to Ultimate tier).  We are always looking for ways to provide more value to our members and are evaluating how we can offer Assistant to the Starter and Professional tiers.</p>

<p><strong>Q:</strong> What are the LLM limitations in place?<br>
<strong>A:</strong> The Assistant currently has no hard limits on usage. We would like it to stay unlimited and will be monitoring this actively. Please do not abuse so everyone can enjoy no-limit access. Provider APIs may have limitations in place.</p>

<p><strong>Q:</strong> Does the Assistant have file upload capability?<br>
<strong>A:</strong> The Assistant will have file upload capabilities very soon (work in progress). You can still access beta version that had it using <a href="https://kagi.com/v1_assistant">this link</a>.</p>

<p><strong>Q:</strong> I found a bug in Assistant, how do I report it?<br>
<strong>A:</strong> Please report all bugs and feature suggestions using <a href="https://kagifeedback.org/">Kagi Feedback</a>.</p>

<p><strong>Q:</strong> What is Kagi’s overall strategy about using LLMs in search?<br>
<strong>A:</strong> We are continuing to relentlessly focus on the core search experience and build thoughtfully integrated features on top of it. Read more about it in our <a href="https://blog.kagi.com/what-is-next-for-kagi#8">recent blog post</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon bans its drivers from moving their own lips too much at work (180 pts)]]></title>
            <link>https://www.freightwaves.com/news/should-truckers-be-allowed-to-sing-along-with-the-radio</link>
            <guid>41448866</guid>
            <pubDate>Wed, 04 Sep 2024 18:24:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.freightwaves.com/news/should-truckers-be-allowed-to-sing-along-with-the-radio">https://www.freightwaves.com/news/should-truckers-be-allowed-to-sing-along-with-the-radio</a>, See on <a href="https://news.ycombinator.com/item?id=41448866">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Welcome to the WHAT THE TRUCK?!? <a href="https://freightwaves.com/wtt">Newsletter</a> presented by <a href="https://truckstop.com/">Truckstop.</a> In this issue, inward dash cams penalize singing?; Flexport’s last supper&nbsp; and more.</p><div id="omeda-post-content">


<p><strong><a href="https://www.reddit.com/r/AmazonDSPDrivers/comments/1f2y2cp/try_to_tell_me_when_i_can_move_my_own_mouth_im_out/"><img decoding="async" width="624" height="219" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfeqfTVpWUk21h2Q1tzZ2gnQ3rEpUf21aEPBc1uLi3zgU9zmIcn6ug9SOj4wilNOJ7dt2kENHbS6yc5NHTR2cOtbfQ7s08vy-f_we-b6QaByzackminnfD7qyd1nlaprMXomAZM0zHCEveQm-VW_jBorF4?key=lGXafURkKN6DLhpG9BhIMQ"></a></strong><br><a href="https://www.reddit.com/r/AmazonDSPDrivers/comments/1f2y2cp/try_to_tell_me_when_i_can_move_my_own_mouth_im_out/">Reddit</a></p>







<p><strong>Big brother — </strong>Amazon Delivery Service Partner (DSP) drivers on <a href="https://www.reddit.com/r/AmazonDSPDrivers/comments/1f2y2cp/try_to_tell_me_when_i_can_move_my_own_mouth_im_out/">Reddit</a> are furious over a new set of standards the company is imposing on them in regards to their inward facing dash cams.&nbsp;<br></p>



<p>According to a number of Redditors as well as drivers that I’ve confirmed with, Amazon is trying to crack down on distracted driving. Now, some of those partners are being warned that singing along with the radio will trigger the inward facing camera in their cab.&nbsp;<br></p>



<div><p>Why? A new update to their Netradyne systems has advanced the scope of how it detects eye and mouth movement.&nbsp;</p><p>Amazon’s <a href="https://hiring.amazon.com/job-opportunities/delivery-driver-jobs#/">website</a> describes their DSP program as “an independent third-party business.” However, that level of independence is under question after these latest measures that are proving to be very unpopular.</p></div>



<p><img loading="lazy" decoding="async" width="624" height="160" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcw-BIe6ZT0I8oHvFr4xjaiJ4nzqwlGXKY4hjNVhTJ3sgXytyfxhs_ZGqeYM2hfKN9IoaPVSuS87AAzV7SLQRBPwgiSuO60zaMTzRF2Nh4f6XE-crvaxLWCM3btBkPtC1rdoh1j1S8zbi1LlQCKZlDooAws?key=lGXafURkKN6DLhpG9BhIMQ"><br></p>



<div><p><strong>Shake it off — </strong>Does anyone really believe that singing distracts drivers or is this a case of AI and surveillance overstepping its bounds? For me personally, hitting the high notes on a Whitney song energizes me and keeps me between the white lines.</p><p>I asked my network that is almost entirely composed of supply chain or supply chain adjacent followers what they thought about the issue. Over <a href="https://x.com/TimothyDooner/status/1829146707290169433">94% of X</a> users and <a href="https://www.linkedin.com/posts/timothydooner_should-truck-drivers-be-allowed-to-sing-along-activity-7234913956052553729-YVBg?utm_source=share&amp;utm_medium=member_desktop">97% of LinkedIn</a> users believe that drivers should be allowed to croon.</p></div>



<p><strong>Here’s what some truckers had to say:</strong><br></p>



<p><a href="https://x.com/EdMapes1/status/1829148133286388110">Ed Mapes</a> – It helps us stay focused and awake.<br></p>



<div><p><a href="https://x.com/NewTruckerMike/status/1829167209194893782">New Trucker Mike</a> – I rock, ska, and country my way all over the highways. Go ahead and try to stop me.</p></div>



<p><img loading="lazy" decoding="async" width="624" height="124" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeosLmqqn3FS87EV7nzxRwVieeYSniqPpPaQg5LPGrgzu-vTDJfEi54zrbU3wBt_xk2ENsF5v4Oa09-c4GVgywzgYBE76f2zRZ56zUGaXCkIGbfbOsFSjoOERsWc6e1qLwP9q7tskCUk_ty7SZIEFDSqRI?key=lGXafURkKN6DLhpG9BhIMQ"></p>



<p><a href="https://x.com/TommyApples80/status/1829188060904349762">X</a>&nbsp;</p>



<p><br><a href="https://x.com/sask_trucker_/status/1829153392448672073">Sask Trucker</a> – If Shania comes on I’m singing.</p>











<p><strong>Data – </strong>Opinions may be anecdotal, but there are studies that have looked at the relationship between music and distracted driving.&nbsp;<br></p>



<p><strong><em>It was concluded that, in some indicators, listening to music has adverse effects on driving. However, in many indicators, music has a positive impact on improving driving safety. It is better to choose appropriate music for different driving conditions and to train the drivers about it. – </em></strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10790125/"><strong><em>National Library of Medicine&nbsp;</em></strong></a><br></p>



<p>While there were some negative factors associated with music, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10790125/">the study</a> found that, “Listening to music can enhance not only the driver’s driving quality but also their physiological performance. In particular, listening to music while driving is effective in controlling stress, calming emotions, and preventing driver drowsiness”&nbsp;<br></p>



<div><p><strong>Sound off –</strong>&nbsp; While it probably isn’t likely that Amazon is specifically targeting singing, the end result is the same. What do you think? Should drivers be allowed to sing while behind the wheel? <a href="https://www.freightwaves.com/cdn-cgi/l/email-protection#6b0f0404050e192b0d02190e0819041c0545080406">Email me</a>.&nbsp;</p><p><strong>The last shipper</strong></p></div>



<div><p><img loading="lazy" decoding="async" width="508" height="579" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcpsHkE_RgeXHvYCOaGjY03VQwGZSmBESAf3x1f7QiE0K7CQZcERCkSdVs8wjSvgLXRPg9wAexl1kBfHd2imCM3_30--Pn_Idzq5o0kg7zTJXoQ9fHoMDdkOgsrkKEAFNdJYd1ggHROm7F588fUYgWIm9s?key=lGXafURkKN6DLhpG9BhIMQ"><a href="https://x.com/typesfast/status/1828925875372593167">X</a></p><p><strong>Controversy – </strong>Flexport’s Ryan Petersen <a href="https://x.com/typesfast/status/1828925875372593167?s=46&amp;t=P3RlHpCY-GJkhcsno3878g">posted</a> his latest AI-generated artwork to X on Wednesday, and it hasn’t been well received by everyone. The image appears to show a number of Flexport executives and apostles celebrating the last supper.</p></div>







<p><strong>“This dude really looked at the bad publicity around the Olympics Opening Ceremony and said ‘I gotta get my company in on that.’ – </strong><a href="https://x.com/Logistorian/status/1828934367877468300"><strong>Logistorian on X</strong></a><br></p>



<p>In July, the Olympic opening ceremony in Paris came under fire when a performance appeared to mock da Vinci’s famous painting “The Last Supper.” The artistic director of that <a href="https://x.com/Olympics/status/1816929100532945380?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1816929100532945380%7Ctwgr%5E9664cca506ae15d2bb810c2b3b24f7734d8bd0b4%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.snopes.com%2Fnews%2F2024%2F07%2F30%2Folympics-last-supper%2F">said it was a misinterpretation</a>, and instead they were referencing Dionysus, the Greek God of wine and festivity.&nbsp;<br></p>



<div><p>Not everyone accepted that answer, but Petersen’s piece is less ambiguous as it clearly shows Jesus levitating over the table.</p></div>



<div><p><img loading="lazy" decoding="async" width="624" height="145" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfH_MKLlLrWnUlT1XaQJ9e9sOwb-qGgo-ie1NfcvHnSNVDv0gZNOOxqQQlXH8Jl7ayyyVx4AHzrsk-2AJiy36niYjus8SMSNq5EfQ54h2mb-kW2BcXEy-3RIqh51IhhqRB1Gp19pC705VsX7Ywwn2k1Y-Yt?key=lGXafURkKN6DLhpG9BhIMQ"><a href="https://x.com/Girldad741/status/1829017497875496991">X</a></p><p><strong>The Judas Cradle – </strong>Many of the comments under the image have called it blasphemous or unnecessary. However, a few didn’t mind at all. Petersen may have even sold a few copies of his book, ‘<a href="https://www.amazon.com/Big-Ship-Little-Digger/dp/1667800442">The Big Ship and the Little Digger</a>’ in the process.</p></div>



<div><p><img loading="lazy" decoding="async" width="624" height="108" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpF-_e7d-e6yiyIHQ4gnfSOMm7YD5u2L-rmZBECvJow-XmLBZNulnI3VEna7r2lK20eGjBT3jflvZW1e6ZEHtRXt9R9frss651dpF7rllUA9lQli3bsbaitpKn1nroozQrFUjSaXgoXQ_aSCoAx4nElELD?key=lGXafURkKN6DLhpG9BhIMQ"><a href="https://x.com/carsjam33/status/1828929385342083252">X</a></p><p>What do you think? Was it a&nbsp; good use of AI or a misguided attempt at marketing? <a href="https://www.freightwaves.com/cdn-cgi/l/email-protection#d0b4bfbfbeb5a290b6b9a2b5b3a2bfa7befeb3bfbd">Email me</a>.</p></div>







<p><strong>Gear for the gals</strong><br></p>



<div><p><img loading="lazy" decoding="async" width="624" height="396" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfgKhBplDWyySYxmA-jKxBx-1BiL3hQ1-Gn4_YTAj0zxePg1b_4xXCrZKzD8OXLoc5m-w_JIFOl87u7efo2hwWRnuaWA0D9qE1cC-2tzsIFK2yYYc6qLEpgZI8MMsRgSL4BncZvB0ODiXBL0_rnkdLK3uhL?key=lGXafURkKN6DLhpG9BhIMQ"><br><strong>Crop top –</strong> Head on over to<strong> </strong><a href="https://wttgear.com/products/rate-the-strap-work-t-shirt">WTTGear.com</a> to get our latest merch! Use code WTTFans for 10% off.</p><p><strong>WTT Friday</strong></p></div>



<p><strong><img loading="lazy" decoding="async" width="624" height="351" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdHvGD4P0xxnQXu2Fb6AEP_IWXwbvF6oCKMu_a1XgKFh1FBXhi4PPM46zbOYRLUCSXSTyNo50XqZ2BG63GVGqgXBPhas8Mt6VMt-ZcJDpdcCTy71JeufG8vWq-XtXVdB_OjNDc47Yjs7QO_SK0b0YsckiVk?key=lGXafURkKN6DLhpG9BhIMQ"></strong></p>



<p><strong>How Costco leveraged its supply chain to become the 3rd biggest retailer on Earth —</strong> Friday live at 12 p.m. Eastern, we’re joined by supply chain super consultant Brittain Ladd to talk about how Costco leveraged its supply chain to become the third largest retailer in the world. Nearly one third of Americans count themselves as members and the company is now expanding into East Asia. Ladd shares how Costco is using tech to scale the business even further.<br>&nbsp;</p>



<p>MoLo co-founder and podcaster Andrew Silver returns to the show to talk about the state of the industry and lessons learned from his time in the trenches. We’ll also find out how he’s building his show The Freight Pod and what insights he’s gleaned from top leaders in freight.<br></p>



<div><p>Plus, headlines, weirdness and more.</p><p><strong>Catch new shows live at noon EDT Mondays, Wednesdays and Fridays on FreightWaves </strong><a href="https://www.linkedin.com/company/freightwaves/"><strong>LinkedIn</strong></a><strong>, </strong><a href="https://www.facebook.com/FreightWaves"><strong>Facebook</strong></a><strong>, </strong><a href="https://twitter.com/freightwaves?lang=en"><strong>X</strong></a><strong> or </strong><a href="https://www.youtube.com/c/FreightWaves"><strong>YouTube</strong></a><strong>, or on demand by looking up WHAT THE TRUCK?!? on your favorite podcast player and at 5 p.m. Eastern on SiriusXM’s Road Dog Trucking Channel 146.</strong></p></div>











<p><strong><a href="https://www.freightwaves.com/news/the-logistic-of-death-what-the-truck"><img loading="lazy" decoding="async" width="624" height="351" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcL2Xm10RIw2oK3XpuveodDbrPQKZfdXVlNyyUbvMZumm_ka2Ts_toeotavLFbNaGryY27FsAsvDJx9EI1Z2QR0N00fkmJQ5C1ei6PFp8OTEQM32NH6BNFlBV4f8B8hJHDtoSWid1zcbaP9ch6a6puB-vU?key=lGXafURkKN6DLhpG9BhIMQ"></a></strong></p>



<p><strong><a href="https://www.freightwaves.com/news/rail-strike-decision-disastrous-trooper-bens-rules-of-the-road-freight-magic-what-the-truck">Rail strike decision “disastrous”; Trooper Ben’s rules of the road; freight magic</a></strong></p>



<p><strong><a href="https://www.freightwaves.com/news/rail-strike-decision-disastrous-trooper-bens-rules-of-the-road-freight-magic-what-the-truck"><img loading="lazy" decoding="async" width="624" height="351" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfUGgx8Bo7kWDbGgniJEjEdB2wloA2CsBwV3LB27iCDLyI9_X4rGQXaGg1SdBloaMgtZ3J3bUVHGXuSyEJNRDjiZvNtm2G1A6VVqBJDkSp8nqXroq6ehSecCeBUq3YogdVEX8pUtXVCOM1cueKl6rGU9Wwo?key=lGXafURkKN6DLhpG9BhIMQ"></a></strong></p>



<p><strong>The rest of the noise</strong></p>



<ul>
<li><a href="https://www.freightwaves.com/news/hazmat-carrier-sues-dali-shipowners-for-negligence"><strong>Hazmat carrier sues Dali shipowners for negligence</strong></a></li>



<li><a href="https://www.freightwaves.com/news/us-mexico-trade-relations-enter-uncharted-territory-expert-says"><strong>US-Mexico trade relations enter “uncharted territory,” expert says</strong></a></li>



<li><a href="https://www.freightwaves.com/news/impact-minimal-from-canada-rail-shutdown"><strong>Supply chain sees unexpected impact from Canada rail ramp-up</strong></a></li>



<li><a href="https://www.freightwaves.com/news/former-polar-air-cargo-executive-receives-18-month-jail-sentence"><strong>Former Polar Air Cargo executive receives 18-month jail sentence</strong></a></li>



<li><a href="https://www.businessinsider.com/kraft-heinz-ai-lighthouse-helps-forecast-supply-chain-demands-2024-8"><strong>Kraft Heinz is using AI to make more autonomous supply-chain decisions</strong></a></li>
</ul>







<p><strong>Thanks for reading, and feel free to forward this to a friend.</strong></p>



<p><br><a href="https://twitter.com/TimothyDooner"><strong>Tweet @ Dooner</strong></a></p>



<p><a href="https://www.freightwaves.com/cdn-cgi/l/email-protection#3753585859524577515e455254455840591954585a"><strong>Email me</strong></a></p>



<p><a href="https://freightwaves.com/communities"><strong>Subscribe to the newsletter</strong></a></p>







<p><strong>Subscribe to the show</strong></p>



<p><a href="https://podcasts.apple.com/us/podcast/what-the-truck/id1357715797"><strong>Apple Podcasts</strong></a></p>



<p><a href="https://open.spotify.com/show/5X1AlbXLIKJAwwwA059sVd?si=KxAg2SYvS3O6WjK2Ftzt9Q"><strong>Spotify</strong></a></p>



<p><a href="https://www.youtube.com/playlist?list=PLVi2PdlRdiSqmJsM01U1gwAfc_y75q_PW"><strong>YouTube</strong></a></p>



<p><a href="https://www.tiktok.com/@fwwhatthetruck"><strong>TikTok</strong></a></p>



<p><a href="https://twitter.com/FWwhatthetruck"><strong>Twitter</strong></a></p>



<p><strong>Or simply look up WHAT THE TRUCK?!? on your favorite podcast player. Or, if you have SiriusXM, tune in to the show Monday, Wednesday and Friday at 5 p.m. Eastern time on Road Dog Trucking Channel 146.</strong></p>







<p><strong>Exit through the gift shop: </strong><a href="http://wttgear.com/"><strong>WTTGear.com&nbsp;</strong></a></p>







<p><strong>Don’t be a stranger,</strong></p>



<p><strong>Dooner</strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS @property and the New Style (270 pts)]]></title>
            <link>https://ryanmulligan.dev/blog/css-property-new-style/</link>
            <guid>41448740</guid>
            <pubDate>Wed, 04 Sep 2024 18:13:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ryanmulligan.dev/blog/css-property-new-style/">https://ryanmulligan.dev/blog/css-property-new-style/</a>, See on <a href="https://news.ycombinator.com/item?id=41448740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">




<section>
  <div>
    

    <p><span>Posted on <strong>September 2, 2024</strong></span>
  </p></div>
  <div>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="var(--color-text-accent)" viewBox="0 0 256 256"><rect width="256" height="256" fill="none"></rect><circle cx="128" cy="128" r="88" fill="var(--color-theme)"></circle><circle cx="128" cy="128" r="88" fill="none" stroke="var(--color-text-accent)" stroke-miterlimit="10" stroke-width="16"></circle><line x1="128" y1="128" x2="167.6" y2="88.4" fill="none" stroke="var(--color-text-accent)" stroke-linecap="round" stroke-linejoin="round" stroke-width="16"></line><line x1="104" y1="8" x2="152" y2="8" fill="none" stroke="var(--color-text-accent)" stroke-linecap="round" stroke-linejoin="round" stroke-width="16"></line></svg>

    <p><span> Takes about <strong>9 minutes</strong> to read </span>
  </p></div>
</section>
<p>The <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@property"><code>@property</code></a> at-rule recently gained support across all modern browsers, unlocking the ability to explicitly define a syntax, initial value, and inheritance for CSS custom properties. It seems like forever ago that CSS Houdini and its <a href="https://developer.mozilla.org/en-US/docs/Web/API/CSS_Properties_and_Values_API">CSS Properties and Values API</a> were initially introduced. I experimented sparingly over time, reading articles that danced around the concepts, but I had barely scratched the surface of what <code>@property</code> could offer. The ensuing demo explores what's possible in the next generation of CSS.</p>
<h2 id="calls-to-action">Calls to action</h2>
<p>Ever seen those sleek, attention-seeking, shiny call-to-action webpage elements? Waves of sites across the web, especially the ones marketing services and software urging for you to "Upgrade your account" or "Sign up today," have discovered the look and latched on. I'm not here to knock it and admittedly think it's kind of fresh. I thought I'd give that style a try myself. Check out the result in the CodePen below.</p>
<p data-height="500" data-preview="false" data-default-tab="result" data-slug-hash="MWMqXbK" data-user="hexagoncircle">
  <a href="https://codepen.io/hexagoncircle/pen/MWMqXbK??editors=0100">
    
    <span>Open CodePen demo</span>
  </a>
</p>

<p>There's a ton to unpack in this demo. Let's start with that shine looping around the button. Toggle open the demo's CSS panel to find a collection of <code>@property</code> rules related to those custom properties that need to animate. Here's the one defined for the <code>--gradient-angle</code>:</p>
<pre><code><span><span>@property</span> --gradient-angle</span> <span>{</span>
  <span>syntax</span><span>:</span> <span>"&lt;angle&gt;"</span><span>;</span>
  <span>initial-value</span><span>:</span> 0deg<span>;</span>
  <span>inherits</span><span>:</span> <span>false</span><span>;</span>
<span>}</span></code></pre>
<p>The <code>@property</code> rule communicates to the browser that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/angle"><code>&lt;angle&gt;</code></a> is the allowed syntax for this custom property and its initial value is <code>0deg</code>. This enables the browser to smoothly transition from <code>0deg</code> to <code>360deg</code> and output a rotating gradient.</p>
<pre><code><span><span>@keyframes</span> rotate-gradient</span> <span>{</span>
  <span>to </span><span>{</span> <span>--gradient-angle</span><span>:</span> 360deg<span>;</span> <span>}</span>
<span>}</span>

<span>.rotate-gradient </span><span>{</span>
  <span>background</span><span>:</span> <span>conic-gradient</span><span>(</span>from <span>var</span><span>(</span>--gradient-angle<span>)</span><span>,</span> transparent<span>,</span> black<span>)</span><span>;</span>
  <span>animation</span><span>:</span> rotate-gradient 10s linear infinite<span>;</span>
<span>}</span></code></pre>
<p>I put together a simple gradient spin demo to focus on the handful of lines necessary to render this concept.</p>
<p data-height="300" data-preview="true" data-default-tab="result" data-slug-hash="eYwLqJx" data-user="hexagoncircle">
  <a href="https://codepen.io/hexagoncircle/pen/eYwLqJx">
    
    <span>Open CodePen demo</span>
  </a>
</p>

<p>We can achieve the shiny animated border effect by evolving this code a bit. We'll introduce a <code>linear-gradient</code> as the first value of the element's <code>background</code> property and set a <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/background-origin"><code>background-origin</code></a> to each value.</p>
<ul>
<li>The origin of the <code>linear-gradient</code> is set to <code>padding-box</code>. This prevents the gradient from spilling into the border area.</li>
<li>The <code>conic-gradient</code> origin is set to <code>border-box</code>. This gradient overflows into the space created by the border width.</li>
<li>To reveal the rotating <code>conic-gradient</code>, a single-pixel transparent border is added.</li>
</ul>
<pre><code><span>.border-gradient </span><span>{</span>
  <span>background</span><span>:</span> 
    <span>linear-gradient</span><span>(</span>black<span>,</span> black<span>)</span> padding-box<span>,</span>
    <span>conic-gradient</span><span>(</span>from <span>var</span><span>(</span>--gradient-angle<span>)</span><span>,</span> transparent 25%<span>,</span> white<span>,</span> transparent 50%<span>)</span> border-box<span>;</span>
  <span>border</span><span>:</span> 1px solid transparent<span>;</span>
<span>}</span></code></pre>
<p>In the CSS panel of the <a href="#cp_embed_eYwLqJx">simple gradient spin demo</a>, uncomment the <code>.border-gradient</code> ruleset to reveal the shiny animated border. Looking pretty slick! For more examples, I've included a bunch of animated gradient border articles in the <a href="#helpful-resources">resources section</a> at the end of the post.</p>
<h2 id="silky-smooth-hover-transitions">Silky smooth hover transitions</h2>
<p>A few special ingredients help facilitate a buttery smooth gradient transition when the element is hovered. Let's dig into its <code>background</code> values:</p>
<pre><code><span>.shiny-cta </span><span>{</span>
  <span>background</span><span>:</span> 
    <span>linear-gradient</span><span>(</span><span>var</span><span>(</span>--shiny-cta-bg<span>)</span><span>,</span> <span>var</span><span>(</span>--shiny-cta-bg<span>)</span><span>)</span> padding-box<span>,</span>
    <span>conic-gradient</span><span>(</span>
        <span>from</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-angle<span>)</span> <span>-</span> <span>var</span><span>(</span>--gradient-angle-offset<span>)</span><span>)</span><span>,</span>
        transparent<span>,</span>
        <span>var</span><span>(</span>--shiny-cta-highlight<span>)</span> <span>var</span><span>(</span>--gradient-percent<span>)</span><span>,</span>
        <span>var</span><span>(</span>--gradient-shine<span>)</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-percent<span>)</span> <span>*</span> 2<span>)</span><span>,</span>
        <span>var</span><span>(</span>--shiny-cta-highlight<span>)</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-percent<span>)</span> <span>*</span> 3<span>)</span><span>,</span>
        transparent <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-percent<span>)</span> <span>*</span> 4<span>)</span>
      <span>)</span>
      border-box<span>;</span>
<span>}</span></code></pre>
<p>Each custom property that needs to animate has a <code>syntax</code> declared in its <code>@property</code> definition so that the browser can interpolate between corresponding value changes and transition them seamlessly. The size of the shiny area is determined by the <code>--gradient-percent</code> value. On hover, a higher percentage lengthens the shine. The <code>--gradient-angle-offset</code> value is used to readjust the gradient angle so that the shine doesn't rubber band back and forth on hover.</p>
<figure>
    <video preload="metadata" loop="" muted="" playsinline="" controls="">
      <source src="https://ryanmulligan.dev/videos/shiny-cta-angle-offset.webm#t=0.001" type="video/webm">
      <source src="https://ryanmulligan.dev/videos/shiny-cta-angle-offset.mp4#t=0.001" type="video/mp4">
      <p>Your browser cannot play the provided video file.</p>
    </video>
  <figcaption>Demonstrating the transition behavior without the angle offset value</figcaption></figure>
<p>I had to fine-tune the percent and offset values until the shine length and transition felt optically aligned. Finally, the <code>--gradient-shine</code> brightness gets toned down to blend more seamlessly with the adjacent highlight colors.</p>
<h2 id="slow-it-on-down">Slow it on down</h2>
<p>This <a href="https://css-tip.com/slow-down-rotation/">CSS tip to slow down a rotation on hover</a> truly blew my mind. In the tip's example code, the same rotate animation is declared twice. The second one is reversed and paused, its duration divided in half. When the element is hovered, <code>animation-play-state: running</code> overrides the <code>paused</code> value and slows the rotation to half speed. The mind-blowing part, at least to me, is that the animation speeds back up at the current position when the element is no longer hovered. No snapping back to a start position, no extra wrapper elements necessary. That is one heck of a tip.</p>
<p>The <a href="#cp_embed_MWMqXbK">call-to-action animations</a> rely on this method to slow them down when the button is hovered. This technique keeps all the rotations and movements in sync as they change speed.</p>
<h2 id="tiny-shiny-dots">Tiny shiny dots</h2>
<p>Looking even closer, we'll discover pinhole-sized dots shimmering inside the button as the shiny border passes near them. To render this dot pattern, a <code>radial-gradient</code> background is created.</p>
<pre><code><span>.shiny-cta::before </span><span>{</span>
  <span>--position</span><span>:</span> 2px<span>;</span>
  <span>--space</span><span>:</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--position<span>)</span> <span>*</span> 2<span>)</span><span>;</span>
  <span>background</span><span>:</span> <span>radial-gradient</span><span>(</span>
      circle at <span>var</span><span>(</span>--position<span>)</span> <span>var</span><span>(</span>--position<span>)</span><span>,</span>
      white <span>calc</span><span>(</span><span>var</span><span>(</span>--position<span>)</span> <span>/</span> 4<span>)</span><span>,</span>
      transparent 0
    <span>)</span>
    padding-box<span>;</span>
  <span>background-size</span><span>:</span> <span>var</span><span>(</span>--space<span>)</span> <span>var</span><span>(</span>--space<span>)</span><span>;</span>
  <span>background-repeat</span><span>:</span> space<span>;</span>
<span>}</span></code></pre>
<p>Remember that <code>--gradient-angle</code> custom property? It has returned! But this time, it's being used in a <code>conic-gradient</code> mask that reveals parts of the dot pattern as it rotates. The gradient angle is offset by 45 degrees to align it perfectly with the shiny border rotation.</p>
<pre><code><span>.shiny-cta::before </span><span>{</span>
  <span>mask-image</span><span>:</span> <span>conic-gradient</span><span>(</span>
    <span>from</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-angle<span>)</span> <span>+</span> 45deg<span>)</span><span>,</span>
    black<span>,</span>
    transparent 10% 90%<span>,</span>
    black
  <span>)</span><span>;</span>
<span>}</span></code></pre>
<p>For one last touch of magic, a gradient containing the highlight color is added to the <code>::after</code> pseudo element, spinning in unison with the shine area. These highlights flowing through the button add a pleasant, welcoming ambience that was previously missing.</p>
<h2 id="enhancing-the-hover-colors">Enhancing the hover colors</h2>
<p>The hover styles looked decent. But they didn't seem totally finished. I felt the desire to enhance. Create more depth. <a href="https://ryanmulligan.dev/blog/detect-js-support-in-css/#:~:text=%22Make%20it%20pop!%22">Make it pop, as they say</a>.</p>
<p>The button's <code>::before</code> and <code>::after</code> pseudo elements were already in use so I wrapped the button text in a <code>span</code> element. A blurred <code>box-shadow</code> containing the highlight color is applied to one of its pseudo elements which is then expanded to fill the button dimensions. On hover, the pseudo element slowly scales up and down, evoking a vibe similar to relaxed breathing. Paired with the spinning highlight color inside the button, the effect finally resonated with me. This intricately designed call-to-action button felt complete.</p>
<h2 id="in-with-the-new-style">In with the new style</h2>
<p>Many of the above techniques would have been nearly impossible only a short time ago. Explicitly defining custom properties unlocks a great big world of opportunity. I'm especially eager to see how <code>@property</code> will be utilized in large-scale applications and design systems. <a href="https://moderncss.dev/providing-type-definitions-for-css-with-at-property/">Providing Type Definitions for CSS with @property</a> by Stephanie Eckles as well as Adam Argyle's <a href="https://nerdy.dev/cant-break-this-design-system">Type safe CSS design systems with @property</a> are just a couple glimpses into a really promising future for publishing our CSS.</p>
<h2 id="helpful-resources">Helpful resources</h2>
<ul>
<li><a href="https://www.learnwithjason.dev/blog/animated-css-gradient-border/">Animated CSS gradient borders (no JavaScript, no hacks)</a></li>
<li><a href="https://ibelick.com/blog/create-animated-gradient-borders-with-css">Creating an animated gradient border with CSS</a></li>
<li><a href="https://web.dev/articles/css-border-animations">CSS border animations</a></li>
<li><a href="https://www.bram.us/2021/01/29/animating-a-css-gradient-border/">Animating a CSS Gradient Border</a></li>
<li><a href="https://codepen.io/hexagoncircle/full/LYKJPjm">CSS border ripple effect</a></li>
<li><a href="https://www.smashingmagazine.com/2024/05/times-need-custom-property-instead-css-variable/">The Times You Need A Custom @property Instead Of A CSS Variable</a></li>
<li><a href="https://web.dev/blog/at-property-baseline">@property: Next-gen CSS variables now with universal browser support</a></li>
</ul>

<p>
  <a href="https://ryanmulligan.dev/blog/">Back to all blog posts</a>
</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What's functional programming all about? (2017) (103 pts)]]></title>
            <link>https://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html</link>
            <guid>41448664</guid>
            <pubDate>Wed, 04 Sep 2024 18:04:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html">https://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html</a>, See on <a href="https://news.ycombinator.com/item?id=41448664">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>There are many descriptions floating around the internet, trying to explain functional programming in simple terms. Unfortunately, most discuss details only loosely related to functional programming, while others focus on topics that are completely irrelevant. So of course, I had to write my own!</p>
<p>This post is my own understanding of what is the "core" of "functional programming", how it differs from "imperative" programming, and what the main benefits of the approach are. As a worked example, we will use a kitchen recipe as a proxy for the more-abstract kind of logic you find in program source code, to try and make concrete what is normally a very abstract topic. That recipe is one of my favorite recipes available online, <a href="http://www.cookingforengineers.com/recipe/60/The-Classic-Tiramisu-original-recipe">Michael Chu's Classic Tiramisu</a>.</p><hr><p><a href="https://www.handsonscala.com/"><img src="https://www.lihaoyi.com/handsonscala-mockup.png"></a></p><p><b>About the Author: </b><i>Haoyi is a software engineer, and the author of many open-source Scala tools such as the Ammonite REPL and the Mill Build Tool. If you enjoyed the contents on this blog, you may also enjoy Haoyi's book <a href="https://www.handsonscala.com/"><b><i>Hands-on Scala Programming</i></b></a></i></p><hr>
<ul>
  <li><a href="#what-functional-programming-is-not">What Functional Programming is Not</a>
    <ul>
      <li><a href="#helper-methods">Helper Methods</a></li>
      <li><a href="#writing-things-in-haskell">Writing Things in Haskell</a></li>
      <li><a href="#compile-time-ast-macros">Compile-time AST Macros</a></li>
      <li><a href="#static-types">Static Types</a></li>
    </ul>
  </li>
  <li><a href="#step-by-step-imperative-recipes">Step by Step Imperative Recipes</a>
    <ul>
      <li><a href="#kitchen-refactoring">Kitchen Refactoring</a></li>
    </ul>
  </li>
  <li><a href="#functional-programming-recipes">Functional Programming Recipes</a>
    <ul>
      <li><a href="#tiramisu-diagram-to-functional-programming">Tiramisu Diagram to Functional Programming</a></li>
      <li><a href="#preventing-errors-with-functional-programming">Preventing Errors with Functional Programming</a></li>
      <li><a href="#refactoring-a-functional-tiramisu-recipe">Refactoring a Functional Tiramisu Recipe</a></li>
      <li><a href="#the-core-of-functional-programming">The Core of Functional Programming</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>
<p>A topic as broad as "Functional Programming", or "FP" has too many different interpretations and facets to be summarized in one blog post. Nevertheless, this post will discuss what <em>I</em> think is the most core, basic level of functional programming. This will hopefully be something that everyone, from FP newbies to FP "experts", should be able to empathise with and agree is a useful part of functional programming.</p>
<p>It's not surprising that many people have tried to explain functional programming using kitchen/recipe/cookbook examples: learning things "by analogy" of things you already know is one of the easiest ways of learning. However, all explanations I have seen fall short. I will begin by examining some typical, <em>incorrect</em> explanations of what functional programming is about, before discussing how <a href="http://www.cookingforengineers.com/recipe/60/The-Classic-Tiramisu-original-recipe">Michael Chu's Classic Tiramisu</a> recipe:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Tiramisu.jpg" alt="TiramisuDiagram"></p>
<p>Can provide insight into what I think are the core techniques and benefits of functional programming.</p><h2 id="what-functional-programming-is-not">What Functional Programming is Not<a href="#what-functional-programming-is-not"></a></h2>
<p>There are many poor explanations people have given for "what is functional programming". Here is a selection:</p><h3 id="helper-methods">Helper Methods<a href="#helper-methods"></a></h3>
<p>One of the most common misconceptions of what FP is is illustrated by the following example:</p>
<blockquote>
  <p>FP =&gt; I'll have a Sazerac</p>
  <p>Imperative =&gt; Excuse me sir, could you take some ice, add rye whiskey, add bitters, add absinthe, shake, strain into a glass, and add a lemon garnish before bringing it to me</p>
</blockquote>
<p>While this example was taken from the <a href="https://news.ycombinator.com/item?id=13281413">y-combinator message board</a>, I've seen this attitude in many places: the idea that functional programming is just taking imperative instructions, and wrapping them in a helper. In this case, the messy imperative code will all sit inside a single helper:</p>
<pre><code>def sazerac():
    ... 10000 lines of messy imperative code ...
</code></pre>
<p>But even in imperative programming you always end up factoring things into helper methods. Java has helper methods. Write assembly, and it ends up being organized with sub-procedures to encapsulate messes of imperative code. </p>
<p>Thus, while this is a useful technique, writing helper methods to wrap your messy code in a single method/function/subprocess/subroutine call does not count as functional programming. </p>
<p>Furthermore, <em>picking an easier/simpler problem</em>, despite making your code look neater, does not count as "Functional Programming" either. Calling a single method that executes a huge blob of code that <em>someone else</em> has written is convenient, but is not functional programming. The point of FP is to face the complexity, own it, and control it, not shove it inside some unmaintained helper function or say it's a problem for some "other department" to deal with.</p><h3 id="writing-things-in-haskell">Writing Things in Haskell<a href="#writing-things-in-haskell"></a></h3>
<pre><code>sazerac = do
    add ice
    add ryeWhisky
    add bitters
    add absinthe
    shake
    strainInto glass
    add lemonGarnish

main = serve $ makeCocktail sazerac
</code></pre>
<ul>
  <li>Also from the <a href="https://news.ycombinator.com/item?id=13281413">y-combinator message board</a></li>
</ul>
<p>It's often said that you can write COBOL in any language, that you can write Java in any language. Well, you can write any language in Haskell too: the above is basically writing Bash in Haskell</p>
<p>Just because something is implemented in Haskell with Monads, doesn't mean it's functional programming. If it looks like imperative code written in Bash, and it's semantics are like imperative code written in Bash, it's imperative code. This example certainly looks exactly like imperative code written in Bash except it's run using <code>serve $ makeCocktail</code> instead of <code>bash cocktail.sh</code>.</p><h3 id="compile-time-ast-macros">Compile-time AST Macros<a href="#compile-time-ast-macros"></a></h3>
<p>Some variant of Lisp (or <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a>?) was probably one of the first implemented FP languages; and Lisps tend to have compile-time AST macros that allow you to transform sections of the program at compile-time. </p>
<p>But compile-time code-transformations are not unique to Lisp; apart from other FP languages that have them, like <a href="https://wiki.haskell.org/Template_Haskell">Template Haskell</a> or <a href="http://docs.scala-lang.org/overviews/macros/overview.html">Scala Macros</a>, many languages have some sort of compile-time code transformation. From <a href="http://hannesdorfmann.com/annotation-processing/annotationprocessing101">Java Annotation Processors</a>, to my own <a href="https://github.com/lihaoyi/macropy">MacroPy</a> project in Python, it turns out that compile-time ast macros are just as feasible in imperative languages, doing imperative programming. You can manipulate mutable ASTs using imperative Python code just as easily as you can elegantly transform immutable ASTs using Scala.</p>
<p>Furthermore, there are a large set of "obviously" functional programming languages that don't have AST-transforming macros at all. Purescript, non-Template Haskell, Scala 2.9, and many other "obviously" functional languages do not include support for compile-time AST transformations. So whatever is the core of functional programming, it's not AST macros.</p><h3 id="static-types">Static Types<a href="#static-types"></a></h3>
<p>There are a large number of people who use FP together with static types, e.g. in languages like Haskell, Scala, or Ocaml. Thus, if you spend all your time within this world, it might be tempting to think that FP is all about static types. <a href="http://stackoverflow.com/questions/6246719/what-is-a-higher-kinded-type-in-scala">Higher-kinded</a>, <a href="https://wiki.haskell.org/Rank-N_types">Rank-N</a>, <a href="https://en.wikipedia.org/wiki/Dependent_type">Dependent</a>, the fancier the types, the more functional the programming. </p>
<p>However, there are probably just as many people using FP without static types: in some parts of the Javascript community, Clojure, Scheme or one of the many other Lisps. It turns out, that all those using FP without types still get many of the benefits. And then there are all those people in static-typed languages like Java that use minimal FP in their code. </p>
<p>So static types, while present in many FP languages, are not the core of FP.</p><h2 id="step-by-step-imperative-recipes">Step by Step Imperative Recipes<a href="#step-by-step-imperative-recipes"></a></h2>
<p>Now that we've looked at a few common misconceptions of what FP is, let's look at what the core of FP <em>actually is</em> (according to me) in contrast to "imperative" programming, using <a href="http://www.cookingforengineers.com/recipe/60/The-Classic-Tiramisu-original-recipe">Michael Chu's Classic Tiramisu</a>:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Tiramisu.jpg" alt="TiramisuDiagram"></p>
<p>As an example. To begin with, we'll explore an "imperative" recipe, that is probably familiar to those you already know.</p>
<p>Michael Chu's Classic Tiramisu, like all the other recipe's on his excellent recipe site has roughly four sections on the page:</p>
<ol>
  <li>
  <p>The backstory of the recipe</p></li>
  <li>
  <p>A step-by-step guide, with photos, of how to make the Tiramisu</p></li>
  <li>
  <p>A diagram of the overall process, showing which ingredients are combined with  which others, to create the resultant Tiramisu</p></li>
  <li>
  <p>A lively and entertaining comments section</p></li>
</ol>
<p>For the purpose of this programming blog we will only be looking at parts <code>2.</code> and <code>3.</code>: the step by step guide, and the process diagram. The step by step guide details, in order, a series of steps that you can take to make a Tiramisu. At a high level, hiding many of the details, it looks like this:</p>
<ol>
  <li>
  <p>Begin by assembling four large egg yolks, 1/2 cup sweet marsala wine, 16  ounces mascarpone cheese, 12 ounces espresso, 2 tablespoons cocoa powder, 1  cup heavy cream, 1/2 cup granulated sugar, and enough lady fingers to layer a  12x8 inch pan twice (40).</p></li>
  <li>
  <p>Stir two tablespoons of granulated sugar into the espresso and put it in  the refrigerator to chill.</p></li>
  <li>
  <p>Whisk the egg yolks</p></li>
  <li>
  <p>Pour in the sugar and wine and whisked briefly until it was well blended.</p></li>
  <li>
  <p>Pour some water into a saucepan and set it over high heat until it began  to boil. </p></li>
  <li>
  <p>Lowering the heat to medium, place the heatproof bowl over the water and  stirred as the mixture began to thicken and smooth out. </p></li>
  <li>
  <p>Whip the heavy cream until soft peaks.</p></li>
  <li>
  <p>Beat the mascarpone cheese until smooth and creamy. </p></li>
  <li>
  <p>Poured the mixture onto the cheese and beat</p></li>
  <li>
  <p>Fold in the whipped cream</p></li>
  <li>
    <p>Assemble the tiramisu. </p>
    <ul>
      <li>
      <p>Give the each ladyfinger cookie  a one second soak on each side and then arrange it on the pan</p></li>
      <li>
      <p>After the first layer of ladyfingers are done, use a spatula to spread  half the cream mixture over it.</p></li>
      <li>
      <p>Cover the cream layer with another layer of soaked ladyfingers.</p></li>
      <li>
      <p>The rest of the cream is spread onto the top and cocoa powder sifted over  the surface to cover the tiramisu.</p></li>
    </ul>
  </li>
  <li>
  <p>The tiramisu was now complete and would require a four hour chill in the refrigerator.</p></li>
</ol>
<p>This is, I think, something like what most people would think of when told "imperative recipe". You start with a set of inputs (the bullet <code>1.</code>) and then perform a series of steps until you have a result at the end. (For now, I'm ignoring the pictures in the recipe, though you could think of them as a sort of <code>assert</code> function for a would-be chef to check some invariants after each step to make sure his tiramisu hasn't gone terribly wrong!)</p>
<p>A simplified Python version of this recipe (ignoring the fact that I'm overloading the same functions to work on different types/number of arguments) may look something like this:</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    dissolve(sugar2, espresso)
    mixture = whisk(eggs)
    beat(mixture, sugar1, wine)
    whisk(mixture) # over steam
    whip(cream)
    beat(cheese)
    beat(mixture, cheese)
    fold(mixture, cream)
    assemble(mixture, fingers)
    sift(mixture, cocoa)
    refrigerate(mixture)
    return mixture # it's now a tiramisu
</code></pre><h3 id="kitchen-refactoring">Kitchen Refactoring<a href="#kitchen-refactoring"></a></h3>
<p>Like most imperative code, it works, but may be hard to understand deeply or difficult to refactor. For example, in cooking terms, you may ask the following questions:</p>
<ul>
  <li>
  <p>If I have two people to make this tiramisu, which parts can be done in  parallel?</p></li>
  <li>
    <p>My expresso hasn't arrived yet; can I shift that step down and do other  things first and include the expresso later when it arrives? </p>
    <ul>
      <li>
      <p>What if my eggs haven't arrived? Which steps can I do first before  the eggs turn up?</p></li>
    </ul>
  </li>
  <li>
    <p>At step 9. I screwed up and spilled the bowl onto the floor. Which steps do  I need to re-do (and which ingredients I may have to re-purchase) to recover  and continue the recipe?</p>
    <ul>
      <li>
      <p>What if I spilled the bowl at step 10? Or step 8?</p></li>
    </ul>
  </li>
  <li>
    <p>Just before step 10, you realize you forgot to do step 7. How much of  your ingredients have been ruined?</p>
    <ul>
      <li>
      <p>What if the forgotten step was step 4? Or step 2?</p></li>
    </ul>
  </li>
</ul>
<p>All four of these are things that happen regularly in a kitchen, and also happen to correspond to things you do with program code all the time: parallelizing things over the available cores to speed things up, shuffling the order of a computation around, dealing with failures and exceptions, or plain old bugs and mistakes.</p>
<p>The answers to these questions are left as an exercise to the reader; in this case, with 12 steps, it's not terribly hard to figure out. A few minutes carefully studying the recipe and you could probably figure it out, so you should definitely give it a try. </p>
<hr>
<p>In a large software project, with a codebase containing thousands or millions of lines of imperative code, that time could easily stretch to days, weeks, or months trying to figure out how to properly recover when one of those imperative steps fails, or how to make your legacy PHP monolith do something faster by using more than 1 of the 32 cores you have available on your beefy server. </p>
<p><strong>The problem in these cases often isn't that you don't know how to run stuff in a separate process in PHP - the problem is that you don't know enough about your own code to decide what to run in that other process</strong>. To move things onto a separate process, you need to know exactly what each bit of code depends on, and who depends on it, so you can pick a set with minimal dependencies to run somewhere else (since inter-process communication is expensive). That's difficult when you have a pile of imperative code and don't even understand it enough to easily move things around <em>within</em> a single process.</p>
<p>The reason that these kinds of analyses are hard on this imperative recipe is the same reason that the analyses are hard when programming in an imperative style: </p>
<ul>
  <li>
  <p>There is an ordering of the steps, but the ordering between some steps is  required, e.g. the series 9, 10, 11, while those between other steps is  entirely arbitrary: step 2 could be done anywhere before step 11, and step 7  and 8 could be swapped or done much earlier and nobody would care.</p></li>
  <li>
  <p>The instructions are based on changing the state of things, e.g. pouring  stuff into <code>mixture</code>, a term that we use repeatedly throughout the recipe  but means a different thing in each step. Even the meaning of <code>cheese</code> and  <code>cream</code> changes as the recipe progresses (e.g. after calling <code>whip(cream)</code>),  but it is entirely hidden from you and not obvious from the code.</p></li>
</ul>
<p>Overall, these factors make it hard to decide, given a single step <em>S</em>, what steps <em>S</em> depends on, and what <em>other</em> steps depend on <em>S</em>. Again, it is possible to figure it out, but what is somewhat-tedious to figure out in a 16-line tiramisu recipe becomes painful and difficult in a 1,000,000 line enterprise codebase.</p>
<p>So that's what an imperative Tiramisu recipe looks like. What does a "functional programming" Tiramisu recipe look like?</p><h2 id="functional-programming-recipes">"Functional Programming" Recipes<a href="#functional-programming-recipes"></a></h2>
<p>It turns out, there's a FP version of this recipe right underneath the imperative one! The "process diagram" mentioned above is an excellent illustration of how such a recipe would look like using "Functional Programming":</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/TiramisuDiagram.png" alt="TiramisuDiagram"></p>
<p>To read this, the raw ingredients are on the left, and each of the boxes represents a single operation that transforms and combines the ingredients. After all the combinations have taken place, you end up on the right with a single, complete Tiramisu. While this "2D" format is not how people write program source code, the underlying structure is not too different from how people structure "FP" programs, which I will demonstrate below.</p>
<p>This diagram leaves out some the <em>detail</em> that the full imperative recipe provides, even compared to the abridged version I transcribed above. For example, chilling the expresso or explicitly boiling the water are left out, and the details of <em>assemble</em> are not included. Nevertheless, it contains the same high-level steps of how to build the tiramisu I abridged above. We're not leaving out large numbers of operations or hiding things behind high-level instructions: all the same steps are still there, just organized slightly differently.</p>
<p>But even if this diagram has the same "content" as the imperative instruction-list I discussed earlier, what about this makes this presentation of the recipe more "functional"?</p><h3 id="tiramisu-diagram-to-functional-programming">Tiramisu Diagram to Functional Programming<a href="#tiramisu-diagram-to-functional-programming"></a></h3>
<p>While nobody actually writes their code in a 2D table-flowchart-thing like this tiramisu diagram is, it turns out underneath the 2D format the "core" of this diagram is the dependency graph between elements:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/DiagramGraph.png" alt="TiramisuDiagram"></p>
<p>Where each box takes in some "inputs" from the left, and results in an "output" that can be used by more-rightward boxes. This can be straightforwardly represented in code by treating the boxes as functions, e.g. in the following Python code:</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
                 
    return refrigerate(
        sift(
            assemble(
                fold(
                    beat(
                        whisk( # over steam
                            beat(beat(eggs), sugar1, wine)
                        ), 
                        beat(cheese)
                    ), 
                    whip(cream)
                ), 
                soak2seconds(fingers, dissolve(sugar2, espresso))
            ), 
            cocoa
        )
    )
</code></pre>
<p>(Again, forgive the fact that I'm overloading the same functions to work on different types and numbers of arguments)</p>
<p>If it's not immediately clear how this code relates to the "functional programming dependency diagram" I discussed above, we can draw the dependency graph <em>of this code</em>: showing where the input variables go, where the return value of each function goes, all the way into the "final" result that gets returned:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/CodeGraph.png" alt="TiramisuDiagram"></p>
<p>It might look like a bit of a mess, but if you look carefully, you will see that <strong>although the graphs are laid out differently, the fundamental structure of the two graphs is identical!</strong> That is what I mean when I say the 2D box-diagram is a "FP Recipe": although people don't tend to write code in 2D box-diagrams, the underlying structure that the diagram represents is totally equivalent to some "FP"-ish Python code, not too dissimilar to what people <em>do</em> write. </p>
<p>This code looks very unlike code you are likely to see in a Python project, "in the wild", but we can fix that! If you prefer to have intermediate named values instead of one big expression, it's straightforward to pull out each function call into it's own statement: </p>
<pre><code># FP         
def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    beat_eggs = beat(eggs)
    mixture = beat(beat_eggs, sugar1, wine)
    whisked = whisk(mixture)
    beat_cheese = beat(cheese)
    cheese_mixture = beat(whisked, beat_cheese)
    whipped_cream = whip(cream)
    folded_mixture = fold(cheese_mixture, whipped_cream)
    sweet_espresso = dissolve(sugar2, espresso)
    wet_fingers = soak2seconds(fingers, sweet_espresso)
    assembled = assemble(folded_mixture, wet_fingers)
    complete = sift(assembled, cocoa)
    ready_tiramisu = refrigerate(complete)
    return ready_tiramisu
</code></pre>
<p>That makes it look entirely "pythonic", indistinguishable from the code you might find in any random project on Github</p>
<p>Moving every expression into a separate statement is a straightforward transformation, at least for FP programs, and is the kind of thing that compilers regularly do automatically. Thus, although that block-flow-chart diagram may have looked a bit foreign at first, it really isn't <em>that</em> different from the code people write day to day, all year round.</p>
<p>In fact, it looks not too unlike the "Imperative" version we came up with earlier!</p>
<pre><code># Imperative
def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    dissolve(sugar2, espresso)
    mixture = whisk(eggs)
    beat(mixture, sugar1, wine)
    whisk(mixture) # over steam
    whip(cream)
    beat(cheese)
    beat(mixture, cheese)
    fold(mixture, cream)
    soak2seconds(fingers, espresso)
    assemble(mixture, fingers)
    sift(mixture, cocoa)
    refrigerate(mixture)
    return mixture # it's now a tiramisu
</code></pre>
<p>These two snippets of code look very similar, but the top one is "Functional Programming" while the bottom one is "Imperative Programming". The difference between them? </p>
<ul>
  <li>
  <p>In the first, you can see that <code>beat(cheese)</code> must come  before <code>beat(whisked, beat_cheese)</code>, because <code>beat_cheese</code>  is defined by the <code>beat(cheese)</code> and used by <code>beat(whisked, beat_cheese)</code>.  Even if you know nothing about <code>beat</code>, <code>cheese</code> or <code>whisked</code>, it is clear  from the code that if you tried to reverse the order - and  <code>beat(whisked, beat_cheese)</code> <em>before</em> <code>beat(cheese)</code>, it wouldn't work.</p></li>
  <li>
  <p>In the second, it's not so clear: does <code>beat(cheese)</code> <em>need</em> to come before  <code>beat(mixture, cheese)</code>? Or does <code>beat(mixture, cheese)</code> need to come before  <code>beat(cheese)</code>? In this case, we have a link to the "docs" (the original  recipe) so we can look it up, but which one depends on the other - and  whether they are currently in the right order - is not clear from the code.</p></li>
</ul>
<p>But how does this seemingly-trivial difference affect the way you build software?</p><h3 id="preventing-errors-with-functional-programming">Preventing Errors with Functional Programming<a href="#preventing-errors-with-functional-programming"></a></h3>
<p>The difference between the two Python snippets, the <code># FP</code> and <code># Imperative</code> snippets, will become clear with the following thought experiment: what if we try to make changes to the code?</p>
<p>Changing code is something we do all day, and sometimes we do it incorrectly. It would be a nice property of a codebase if changes tended to be easier to make correctly, and incorrect changes were easier to spot. We'll discuss the latter first.</p>
<p>If I try to tidy things up and accidentally move the statement</p>
<pre><code>beat_cheese = beat(cheese)
</code></pre>
<p>below</p>
<pre><code>cheese_mixture = beat(whisked, beat_cheese)
</code></pre>
<p>It should be clear to me that something is wrong, because there will be no <code>beat_cheese</code> in scope to create the <code>cheese_mixture</code>. Even if it's not clear to me, it's probably clear to my linter and editor:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FunctionalError.png" alt="TiramisuDiagram"></p>
<p>As you can see, not only does the usage of <code>beat_cheese</code> raise an error because no such variable is defined, the <em>definition</em> of <code>beat_cheese</code> <em>also</em> raises a visual warning: it is greyed out since it is dead code! This makes it very hard to miss when you make such trivial error, and saves you time: rather than waiting 10s for your test suite to run, within less than 1s your linter would have lit up and flagged the lines as invalid. Over the days, months and years, this adds up to a significant productivity boost</p>
<p>However, in the <em>Imperative</em> case, it's not clear how </p>
<pre><code>beat(mixture, cheese)
</code></pre>
<p>Relates to the things before or after it. If I remove the <code>beat(cheese)</code> earlier, I still have a <code>cheese</code> to pass in. If I remove the <code>beat(mixture, cheese)</code> entirely, I still have a <code>mixture</code> I can use in later steps of the recipe. So how do I know, from looking at the code, that removing a step or re-ordering them so that <code>beat(cheese)</code> comes after <code>beat(mixture, cheese)</code> is a problem? </p>
<p>The answer is, you often don't, and neither does your computer, or your editor and linter, who aren't going to help you spot the fact that you accidentally swapped two of the imperative statements:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ImperativeError.png" alt="TiramisuDiagram"></p>
<p>Fundamentally, in the "FP" example, the code is laid out in a way that the "correct" usage is obvious: each function, e.g. <code>beat</code>, only depends on the things that are passed into it, and it's output is only depended upon by whoever uses it's return value. In the "Imperative" example, it's not clear who depends on who: you have to memorize the fact that <code>beat(cheese)</code> must come before <code>beat(mixture, cheese)</code>, and not the other way around. </p>
<p>While this is not difficult assuming we are looking at already-correct code (the current order is the correct order!), when mistakes are made, and code happens to be incorrect, "FP" code makes the mistakes much easier for you (or your linter) to spot so you can correct them.</p>
<hr>
<p>While this example may seem contrived, the basic problem exists in all large codebases I've worked with. For example, maybe you've bumped into code similar to the following three functions:</p>
<pre><code>def initialize():
   ... 1000 lines of messy code, no return value...
   
def make_app():
   ... 2000 lines of messy code, no return value...

def start_server():
   ... 4000 lines of messy code, no return value...
</code></pre>
<p>Which transitively depend on a 1 million line codebase ("The App"). How could I know that <code>start_server()</code> needs to be called before <code>make_app()</code>, which itself needs to be called before <code>initialize()</code>, when all of them are global functions which don't take arguments or return anything? I have certainly spent countless days of my career puzzling over such mysteries in large codebases, and I am sure others have too. If <code>start_server</code> returned something I needed to pass to <code>make_app</code>, which returned something I needed to pass to <code>initialize</code>, that would make it clear from the outset which one needs to come before the other.</p>
<p>Re-ordering or shuffling around statements is not uncommon. When you are refactoring a piece of code to let you re-use it in a different place, a lot of time is spent shifting bits of code up and down small amounts, just like the example I showed above, so that the code you want to re-use is all in one place and you can extract it into a helper. </p>
<p>Perhaps you just want to tidy up what was previous a messy function to organize the code a bit better than it already is, grouping related lines so they can be read together easily, without changing any behavior at all.</p>
<p>Or perhaps, as mentioned earlier, someone made a mistake and the code <em>that already exists</em> is incorrect, and your job is to figure out which of the statements is out of order so you can fix it.</p>
<p>All of these are things that software engineers do day in, day out. And often, we make mistakes when doing so. With functional programming, whether in a typed language or not, it tends to be much more clear when you've made a trivial, dumb error. That means you get feedback quicker: you get corrected quietly by your linter in the privacy of your own laptop, and can quickly fix it and make progress, rather than waiting a long time only to be loudly yelled at by Jenkins CI in front of your entire team.</p><h3 id="refactoring-a-functional-tiramisu-recipe">Refactoring a Functional Tiramisu Recipe<a href="#refactoring-a-functional-tiramisu-recipe"></a></h3>
<p>Even if you haven't already-made a mistake, and are just <em>thinking</em> of making a change to a codebase, the <code># FP</code> version of the code is a lot easier to think about than the <code># Imperative</code> version. The same often applies whether you're writing dealing with Python, Javascript, Scala, or a Tiramisu recipe!</p>
<p>I have already shown above how the 2D-block-diagram version of this recipe is exactly equivalent in semantics to a "FP" Python function. For this section I will use the 2D-block-diagrams to illustrate my points, as it is much clearer visually, but the same kind of reasoning applies to "FP" code in Python or any other programming language. While working with an FP style, you quickly get used to performing the same analyses in your head, just as quickly, but on lines of source code rather than 2D-block-diagrams.</p>
<p>What is interesting is that this structure lets us very easily answer some of the questions we asked above:</p>
<blockquote>
  <ul>
    <li>If I have two people to make this tiramisu, which parts can be done in parallel?</li>
  </ul>
</blockquote>
<p>This one is easy: </p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Parallel.png" alt="TiramisuDiagram"></p>
<p>Anything vertically separated can be done in parallel. For example, preparing the ladies fingers and preparing the eggs/sugar/wine are separate and can be done independently, as can whipping the cream and mascarpone cheese. Thus, if you have three people, you might assign: </p>
<ul>
  <li>one person to be the egg/wine/sugar mixture czar,</li>
  <li>one to be the mascarpone/cream czar, and</li>
  <li>one to be the expresso/ladyfingers czar.</li>
</ul>
<p>On the other hand, anything horizontally separated has to be done sequentially:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Sequential.png" alt="TiramisuDiagram"></p>
<p>Thus even if you parallelize the early bits, the later beat-fold-assembly-refrigerate steps all have to be done sequentially, and how much time you can save on your Tiramisu is limited by the length of the <a href="https://en.wikipedia.org/wiki/Critical_path_method">Critical Path</a>. </p>
<p>Working with the "FP" representation of the recipe doesn't shorten the critical path, and thus doesn't affect how much you can "theoretically" speed up your recipe with parallelism. What it does do is make clear exactly which parts of the recipe can be parallelized and which can't, so you can more quickly organize your work to get maximum parallelism given the constraints of the recipe, and then move on to other things.</p>
<p>Again, while we're looking at a 2D-block-diagram, the same applies to FP-style code in Python, Javascript, Scala, or any other programming language.</p>
<blockquote>
  <ul>
    <li>My expresso hasn't arrived yet; can I shift that step down and do other things first and include the expresso later when it arrives?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/MissingExpresso.png" alt="TiramisuDiagram"></p>
<p>If you expresso hasn't arrived, anything depending on it can't be done, but anything else involving eggs/sugar/wine/cheese/cream can be prepared: the sections marked in red make it clear which parts of the recipe depend on expresso; the rest can be done while waiting for the expresso to arrive</p>
<blockquote>
  <ul>
    <li>What if my eggs haven't arrived? Which steps can I do first before  the eggs turn up?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/MissingEggs.png" alt="TiramisuDiagram"></p>
<p>In this case, the top block can't be done but you can prepare the bottom and middle blocks: preparing the expresso, beating the cream and mascarpone cheese. Again, this is obvious from looking at the diagram</p>
<blockquote>
  <ul>
    <li>At step 9. I screwed up and spilled the bowl onto the floor. Which steps do I need to re-do (and which ingredients I may have to re-purchase) to recover and continue the recipe?</li>
  </ul>
</blockquote>
<p>Step 9 is when you beat the Mascarpone cheese into the egg mixture. Once we find it on the diagram, it's clear what we need to do:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FailBeatCheese.png" alt="TiramisuDiagram"></p>
<p>You will need to get some new eggs/sugar/wine/cheese and beat/beat/whisk/beat them all over again </p>
<blockquote>
  <ul>
    <li>What if I spilled the bowl at step 10? Or step 8?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FailFoldCream.png" alt="TiramisuDiagram"></p>
<p>Spilling the bowl at step 10 (folding the whipped cream into the main mixture) is the same as spilling the bowl at step 9, except you need to get new cream too.</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FailBeatCream.png" alt="TiramisuDiagram"></p>
<p>Spilling the bowl at step 8 (beating Mascarpone cheese) and you just need to get new mascarpone cheese and beat it. The rest of your ingredients are fine. </p>
<blockquote>
  <ul>
    <li>Just before step 10, you realize you forgot to do step 7. How much of your ingredients have been ruined?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ForgotWhipCream.png" alt="TiramisuDiagram"></p>
<p>In the diagram above, the red boxes represent the steps we've already done, up to step 10 (folding in the whipped cream). As you can see, not having done step 7 (whipping the heavy cream) is no big deal; we haven't needed to done it up to now, so we can do it and continue with step 10 </p>
<blockquote>
  <ul>
    <li>What if the forgotten step was step 4? Or step 2?</li>
  </ul>
</blockquote>
<p>If you forgot step 4 (whisking in wine and sugar to the beaten eggs) you've ruined your eggs/sugar/wine/cheese:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ForgotWineSugar.png" alt="TiramisuDiagram"></p>
<p>As you can see, the stuff we've been whisking and beating was not prepared properly before being whisked and beaten, since we forgot to mix in the wine and sugar. Assuming we don't know enough kitchen chemistry to incorporate the wine/sugar in at this stage (Our eggs may well have turned into omelettes by now without the additional liquid from the wine...) we will need to re-do all the steps in the upper red box.</p>
<p>If you forgot step 2 (dissolving sugar into expresso) you're fine. The expresso hasn't been needed yet:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ForgotExpresso.png" alt="TiramisuDiagram"></p>
<p>According to the imperative recipe above, we <em>should</em> have done the expresso mixing first before starting on the egg/wine/cheese. But even though we didn't do it, it is trivial to see from the FP-style recipe that there really isn't any loss: no other steps so far depended on that, no other ingredients were ruined.</p>
<hr>
<p>As you can see, many of the questions that were non-trivial to answer when dealing with the imperative code back in <a href="#kitchen-refactoring">Kitchen Refactoring</a> are now trivial to answer when working with the FP-style 2D-block-diagrams.</p>
<p>Again, while nobody actually codes in 2D-block-diagrams (except skilled engineers running recipe blogs) the 2D-block-diagrams are equivalent to a relatively straightforward snippet as shown above. With some experience dealing with FP code, you can often perform the same analyses just as easily when working directly with the equivalent Python code we showed earlier. And it's not just about programmers: automated tools linters or IDEs often perform the same analysis on the fly, as <a href="#preventing-errors-with-functional-programming">shown earlier</a>, quickly alerting you if you make a mistake that means the recipe can no longer be completed successfully:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FunctionalError.png" alt="TiramisuDiagram"></p><h3 id="the-core-of-functional-programming">The Core of Functional Programming<a href="#the-core-of-functional-programming"></a></h3>
<p><strong>The core of Functional Programming is thinking about data-flow rather than control-flow</strong>. Although, by virtue of editing plain text, you are forced to order your code in a linear sequence of statements, those statements are a thin skin over what you really care about: the shape and structure of the data-flow graph within your program.</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    beat_eggs = beat(eggs)
    mixture = beat(beat_eggs, sugar1, wine)
    whisked = whisk(mixture)
    beat_cheese = beat(cheese)
    cheese_mixture = beat(whisked, beat_cheese)
    whipped_cream = whip(cream)
    folded_mixture = fold(cheese_mixture, whipped_cream)
    sweet_espresso = dissolve(sugar2, espresso)
    wet_fingers = soak2seconds(fingers, sweet_espresso)
    assembled = assemble(folded_mixture, wet_fingers)
    complete = sift(assembled, cocoa)
    ready_tiramisu = refrigerate(complete)
    return ready_tiramisu
</code></pre>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/CodeGraph.png" alt="TiramisuDiagram"></p> <p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/DiagramGraph.png" alt="TiramisuDiagram"></p>
<p>Similarly, when <em>executing</em> a "functional program" in a single thread, you are forced to pick a linear order in which you execute each individual instruction, which e.g. might be the same as the order in which it is written down in the code. But since we know what <em>really</em> matters is the shape of the data-flow graph, we can freely re-arrange the statements in the code, and the order of execution, as long as the graph shape is preserved. Since the data-flow graph matches the graph of definitions and usages, even your editors and linters understand it enough to warn you if you re-arrange things in an invalid order. In fact, if you have multiple cores (or multiple cooks!) you can execute parts of it in parallel, not in any linear order at all! Exactly in what order the <a href="https://en.wikipedia.org/wiki/Program_counter">program-counter</a> proceeds from instruction to instruction is irrelevant.</p>
<p>This is in contrast to an imperative program, where the exact <em>order</em> in which the program-counter executes each statement, going in and out of loops, in and out of sub-routines, is the key to understanding the program. In an imperative program, you tend to think in terms of steps that must happen "before" and "after", and make sure that the control-flow of the program executes the commands in the right order for the program to work.</p>
<p><strong>Note that none of the FP examples here are "less complex" than the "imperative" recipe we discussed above</strong>. It's about the same number of lines:</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    dissolve(sugar2, espresso)
    mixture = whisk(eggs)
    beat(mixture, sugar1, wine)
    whisk(mixture) # over steam
    whip(cream)
    beat(cheese)
    beat(mixture, cheese)
    fold(mixture, cream)
    assemble(mixture, fingers)
    sift(mixture, cocoa)
    refrigerate(mixture)
    return mixture # it's now a tiramisu
</code></pre>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    beat_eggs = beat(eggs)
    mixture = beat(beat_eggs, sugar1, wine)
    whisked = whisk(mixture)
    beat_cheese = beat(cheese)
    cheese_mixture = beat(whisked, beat_cheese)
    whipped_cream = whip(cream)
    folded_mixture = fold(cheese_mixture, whipped_cream)
    sweet_espresso = dissolve(sugar2, espresso)
    wet_fingers = soak2seconds(fingers, sweet_espresso)
    assembled = assemble(folded_mixture, wet_fingers)
    complete = sift(assembled, cocoa)
    ready_tiramisu = refrigerate(complete)
    return ready_tiramisu
</code></pre>
<p>whether as multiple statements, one big expression, or as a 2D block diagram. All the same operations are present: <code>beat</code>ing, <code>whip</code>ing, <code>fold</code>ing, etc.. Functional Programming is not about hiding ugly code in helper methods and hoping nobody notices: it's about managing the same complexity in a way that makes the dependencies between each piece of code obvious, by following the graph of where function arguments come from and where return values end up.</p>
<p>When you have a working program, having the dependency graph of function return values being passed into other functions as arguments makes it really easy to analyze code. For example, if we were curious what <em>exactly</em> is required to get our <code>wet_fingers_mixture</code>, we can see:</p>
<ul>
  <li><code>wet_fingers</code> comes from <code>soak2seconds(fingers, sweet_espresso)</code></li>
  <li><code>sweet_espresso</code> comes from <code>dissolve(sugar2, espresso)</code></li>
  <li><code>sugar2</code>, <code>fingers</code>, <code>espresso</code> are the initial ingredients of the recipe</li>
</ul>
<p>An there you have it: just a few steps, entirely mechanical, and we can see exactly what <code>wet_fingers</code> needs. We need no understanding of what <code>dissolve</code> does, or what a <code>sugar2</code> is: just from the structure of the code we can already see what <code>wet_fingers</code> requires. Just as importantly, we can also see that it does <em>not</em> depend on <code>folded_mixture</code>, <code>whipped_cream</code>, or any of the other steps that are above it in the code: while those steps "come before" the operations that give us a <code>wet_fingers</code>, it's clear from this analysis that their ordering is entirely accidental, and that we could e.g. prepare the <code>wet_fingers</code> before the other steps if we so desired.</p>
<p>It's not hard to do this yourself, but any IDE with jump-to-definition should be able to do this for you, and so can automated linters and code analysis tools. And understanding the code is the first step in changing it, without bugs.</p>
<p>When you have a broken program, having the dependencies be easy to analyze means it's easier to spot when you make a mistake or do something out of order: even in a dynamic language like python, a subtly bad copy-paste job can get called out by your editor so you can fix it before needing to run any code:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FunctionalError.png" alt="TiramisuDiagram"></p>
<p>Whether you're working in a dynamic language like Python or a static language like Scala, whether your code is currently working or broken, Functional Programming's data-flow-centric approach helps you understand your code faster, easier and with more tooling help than a Imperative, mutation-heavy approach.</p><h2 id="conclusion">Conclusion<a href="#conclusion"></a></h2>
<p><strong>The core of Functional Programming is thinking about data-flow rather than control-flow</strong></p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/TiramisuDiagram.png" alt="TiramisuDiagram"></p>
<p>While this may seem a trivial definition of "Functional Programming", I think it is really the core of the idea. While there are many further steps, from the simple (immutability, referential transparency, ...) to the more advanced (monads, lenses, ...) this core of should be something that everyone, from newbies to old hands, whether using Scala or Clojure or Haskell or React.js, should be able to empathise with. Even in a language like Python, as I have used for the examples, it is possible to program in a more "Functional" style, and reap some of the benefits of functional programming.</p>
<p>Those more advanced topics don't really fit this worked example anyway: kitchen ingredients tend to be very, very mutable (and perishable!).</p>
<p>Though it's growing, this baseline-level of FP is not yet widespread in industry. </p>
<ul>
  <li>
  <p>Whole languages, such as Bash, make it a pain in the neck to take  non-trivial function arguments or return non-trivial results, resulting in  people's code writing things to the filesystem, hopefully "before" someone  else needs to read them.</p></li>
  <li>
  <p>Languages like Java encourage  patterns where you instantiate a half-baked object and then set the fields  later, praying that nobody accidentally tries to use it "too early" it in  it's half-baked state while it's internal variables are garbage. </p></li>
</ul>
<p>In all of these cases, the <em>order</em> in which things run - exactly how the program-counter progresses from statement to statement, in and out of for-loops, in and out of sub-routines - is critical. </p>
<p>Even in the kitchen, having a "FP-style" recipe like the block diagram I showed above is helpful, because when the person bringing your Marsala Wine is stuck in traffic, it makes it easier to re-organize your recipe so you can get as much work done immediately. When that person arrives, it helps you figure out how to parallelize the work over the people you have available. When someone screws up, it helps you figure out exactly which ingredients you need to re-purchase and steps you need to re-do. </p>
<p>This widespread applicability, even to fields outside the software world, and to every "FP" language <em>within</em> the software world, is why I think this is truly what functional programming is all about.</p><hr><p><a href="https://www.handsonscala.com/"><img src="https://www.lihaoyi.com/handsonscala-mockup.png"></a></p><p><b>About the Author: </b><i>Haoyi is a software engineer, and the author of many open-source Scala tools such as the Ammonite REPL and the Mill Build Tool. If you enjoyed the contents on this blog, you may also enjoy Haoyi's book <a href="https://www.handsonscala.com/"><b><i>Hands-on Scala Programming</i></b></a></i></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: An open-source implementation of AlphaFold3 (149 pts)]]></title>
            <link>https://github.com/Ligo-Biosciences/AlphaFold3</link>
            <guid>41448439</guid>
            <pubDate>Wed, 04 Sep 2024 17:44:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Ligo-Biosciences/AlphaFold3">https://github.com/Ligo-Biosciences/AlphaFold3</a>, See on <a href="https://news.ycombinator.com/item?id=41448439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">AlphaFold3 Open-Source Implementation</h2><a id="user-content-alphafold3-open-source-implementation" aria-label="Permalink: AlphaFold3 Open-Source Implementation" href="#alphafold3-open-source-implementation"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">This is Ligo's open-source implementation of AlphaFold3, an ongoing research project aimed at advancing open-source biomolecular structure prediction. This release implements the full AlphaFold3 model along with the training code. We are releasing the single chain prediction capability first and we will add ligand, multimer, and nucleic acid prediction capabilities once they are trained. <a href="https://form.fillout.com/t/ct1BWM5QWqus" rel="nofollow">Sign up for beta testing here</a>.</p>
<p dir="auto">This repository is intended to accelerate progress towards a faithful, fully open-source implementation of AlphaFold3 for the entire biotech community to use freely.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo Video</h2><a id="user-content-demo-video" aria-label="Permalink: Demo Video" href="#demo-video"></a></p>
<p dir="auto">We find that the model training dynamics are quite fast. The following video is a sample from a model trained for 4,000 steps on 8 A100 GPUs for 10 hours without templates.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Ligo-Biosciences/AlphaFold3/blob/main/media/AlphaFold3-sample-4_000-steps-training.gif"><img src="https://github.com/Ligo-Biosciences/AlphaFold3/raw/main/media/AlphaFold3-sample-4_000-steps-training.gif" alt="AlphaFold3 Sample" data-animated-image=""></a></p>
<p dir="auto">Animation credits: <a href="https://batisio.co.uk/" rel="nofollow">Matthew Clark</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<p dir="auto">This project would not have been possible without the contributions of the following projects and individuals:</p>
<ul dir="auto">
<li>
<p dir="auto">The AlphaFold3 team at Google DeepMind for their groundbreaking work and publishing the core algorithms.</p>
</li>
<li>
<p dir="auto">The OpenFold project (<a href="https://github.com/aqlaboratory/openfold">https://github.com/aqlaboratory/openfold</a>), which laid the foundation for open-source protein structure prediction. We reuse many of their core modules, such as triangular attention and multiplicative update, as well as their data processing pipelines.</p>
</li>
<li>
<p dir="auto">The ProteinFlow library (<a href="https://github.com/adaptyvbio/ProteinFlow">https://github.com/adaptyvbio/ProteinFlow</a>), especially the architect of ProteinFlow, Liza Kozlova (<a href="https://github.com/elkoz">@elkoz</a>), who has been an absolute hero throughout this process. We trained most of our prototype models on ProteinFlow, since it provides a clean and well-documented data pipeline for working with protein data. We have partnered with AdaptyvBio to build the data pipeline of AlphaFold3 based on ProteinFlow that includes full ligand and nucleic acid support. <a href="https://github.com/elkoz">@elkoz</a> and <a href="https://github.com/igor-krawczuk">@igor-krawczuk</a> are building the next release of ProteinFlow to include full support for these data modalities.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Status</h2><a id="user-content-project-status" aria-label="Permalink: Project Status" href="#project-status"></a></p>
<p dir="auto">This is an active research project in its early phases. We are working to prepare a stable release for the community. While we are excited about the potential of this work, we want to emphasise that this is not yet a production-ready tool.
We trained a version of AlphaFold3 on single-chain proteins to test the implementation -- the next release will include full ligand and nucleic acid support.
We are accepting a small number of beta testers to help us test the implementation and provide feedback. If you are interested in beta testing, please <a href="https://form.fillout.com/t/ct1BWM5QWqus" rel="nofollow">join our waitlist</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Discrepancies from AlphaFold3's Pseudocode</h2><a id="user-content-discrepancies-from-alphafold3s-pseudocode" aria-label="Permalink: Discrepancies from AlphaFold3's Pseudocode" href="#discrepancies-from-alphafold3s-pseudocode"></a></p>
<p dir="auto">While working on this project, we discovered a few properties of the algorithms described in the AlphaFold3 supplementary information that were not consistent with surrounding deep learning literature.
We discuss these below:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>MSA Module Order</strong>: In the Supplementary Information, the MSA module communication step occurs before the MSA stack. This results in the MSA stack of the last block not contributing to the structure prediction, since all information flows out through the pair representation. With the order in the pseudocode, the MSA stack in the last block does not have an opportunity to update the pair representation. We swap the OuterProductMean operation and the MSA stack to ensure all blocks contribute to the structure prediction. It is important to note this correction is consistent with the order of operations in the ExtraMSAStack of AlphaFold2. DeepMind mentions these MSA module blocks are "homogeneous". It is unclear whether this means shared weights or same architecture across blocks. If the layers are shared, then gradients will flow through all of them but the final calculation of the MSA stack is idle - this can be safely skipped (not mentioned in the pseudocode). We will resolve this ambiguity in light of DeepMind's response.</p>
</li>
<li>
<p dir="auto"><strong>Loss scaling</strong>: The loss scaling factor described in the Supplementary Information does not give unit-loss at initialization. Unit-loss at initialization is one of the properties that Karras et al. (2022) set as a desirable property of the loss function when training diffusion models, and Max Jaderberg mentions this as one of the properties for why they chose the framework of Karras et al. in this talk <a href="https://youtu.be/AE35XCN5NuU?si=S_9-i3hupk3i9GDR" rel="nofollow">here</a>. We think this is a simple typo in the Supplementary info that is due to an addition being typed as a multiplication -- in our implementation, we use the loss scaling factor consistent with Karras et al. (2022). Our measurements show that this gives unit MSE loss at initialization, whilst the scaling in the Supplementary Information is two to three orders of magnitude larger at initialization. Additionally, the loss scaling factor in the paper has a local minimum at t = 16.0, but then it increases with increasing noise level. This is not in line with the properties of the loss function that Karras et al. (2022) proposed, which emphasises the importance of downweighting the loss at higher noise levels. We add a Jupyter notebook to the repository showing our experiments.</p>
</li>
<li>
<p dir="auto"><strong>DiT block design</strong>: The design of the AttentionPairBias and the DiffusionTransformer blocks seem to closely follow the DiT block design introduced by Peebles &amp; Xie (2022) <a href="https://arxiv.org/abs/2212.09748" rel="nofollow">here</a>. However, the residual connections are missing. It is not explained in the paper why DeepMind chose to omit them. We experiment with both and find that (within the range of steps we trained our models on) the DiT block with residual connections gives much faster convergence and better gradient flow through the network. Note that this is the discrepancy we are the least sure about, and it can be changed in a couple lines in our code if the original implementation does not use the residual connections.</p>
</li>
</ul>
<p dir="auto">These are noted here for transparency and to invite community input on the best approaches to resolve them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Efficiency</h2><a id="user-content-model-efficiency" aria-label="Permalink: Model Efficiency" href="#model-efficiency"></a></p>
<p dir="auto">A significant focus of this implementation has been on optimising the model components for speed and memory efficiency. AlphaFold3 has many transformer-like components, but efficient hardware-aware attention implementations like FlashAttention2 do not integrate out-of-the-box with these modules due to pair biasing in AlphaFold3. All of the attention operations project a pair bias from the pairwise representation that is added after the key-query dot product, and the bias requires a gradient to be backpropagated. This is not out of scope for FlashAttention2, since the bias gradient would have the same gradient as the scaled QK^T dot product, but the current implementation does not support this. More recent attention implementations like <a href="https://pytorch.org/blog/flexattention/" rel="nofollow">FlexAttention</a> are very promising, but they also do not support a bias gradient for now since broadcasting operations of the bias tensor during the forward pass become reductions in the backward pass, and this functionality is not implemented in the first release of FlexAttention.</p>
<ul dir="auto">
<li>
<p dir="auto">We reuse battle-tested components such as TriangularAttention and TriangularMultiplicativeUpdate from the OpenFold project wherever we can. The modular design of the OpenFold project allows us to easily import these modules into our codebase. We are working on improving the efficiency of these modules with Triton, fusing operations to increase performance and reduce intermediate tensor allocation.</p>
</li>
<li>
<p dir="auto">We observed that a naive implementation of the Diffusion Module in PyTorch frequently ran out of memory since the Diffusion Module is replicated 48 times per batch. To solve this issue, we re-purpose the MSARowAttentionWithPairBias kernel from Deepspeed4Science to implement a memory-efficient version of the Diffusion Module, treating the batch replicas with different noise levels as an additional batch dimension. For the AtomAttentionEncoder and AtomAttentionDecoder modules, we experimented with a custom PyTorch-native implementation to reduce the memory footprint from quadratic to linear, but the benefits were not that significant compared to a naive re-purposing of the AttentionPairBias kernel. We include both implementations in the repository, but use the naive implementation for the sake of reducing clutter.
Despite these optimisations, our profiling experiments show that over 60% of the model's operations are memory-bound. We are working on a far more efficient and scalable implementation using the ideas of <a href="https://paperswithcode.com/paper/scalefold-reducing-alphafold-initial-training" rel="nofollow">ScaleFold</a>, which will allow us to reach the training scale of the original AlphaFold3.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">We do not yet provide sampling code since the ligand-protein and nucleic acid prediction capabilities are yet to be trained. The checkpoint weights can be loaded with PyTorch Lightning's checkpoint loading for experimentation and model surgery. The current model only predicts single-chain proteins, which is the same functionality as the original AlphaFold2. The model components are written to be reusable and modular so that researchers can easily incorporate them into their own projects.
For beta testing of ligand-protein and nucleic acid prediction: <a href="https://form.fillout.com/t/ct1BWM5QWqus" rel="nofollow">Join our Waitlist</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">For now, the primary use of this repository is for research and development. We will include more user-facing functionality in the future once the ligand-protein and nucleic acid prediction capabilities are ready.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions from the community! There are likely numerous bugs and subtle implementation errors in our code. Deep learning training often fails silently, where the errors still allow the network to converge but make it work slightly worse. If you're interested in contributing, you can raise a Github issue with a bug description or fork the repository, create a new branch with your corrections and submit a pull request with a clear description of your changes.</p>
<p dir="auto">For any other comments or suggestions please contact us via email at <a href="mailto:alphafold3@ligo.bio">alphafold3@ligo.bio</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citations</h2><a id="user-content-citations" aria-label="Permalink: Citations" href="#citations"></a></p>
<p dir="auto">If you use this code in your research, please cite the following papers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{Abramson2024-fj,
  title    = &quot;Accurate structure prediction of biomolecular interactions with
              {AlphaFold} 3&quot;,
  author   = &quot;Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans,
              Richard and Green, Tim and Pritzel, Alexander and Ronneberger,
              Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick,
              Joshua and Bodenstein, Sebastian W and Evans, David A and Hung,
              Chia-Chun and O'Neill, Michael and Reiman, David and
              Tunyasuvunakool, Kathryn and Wu, Zachary and {\v Z}emgulyt{\.e},
              Akvil{\.e} and Arvaniti, Eirini and Beattie, Charles and
              Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and
              Congreve, Miles and Cowen-Rivers, Alexander I and Cowie, Andrew
              and Figurnov, Michael and Fuchs, Fabian B and Gladman, Hannah and
              Jain, Rishub and Khan, Yousuf A and Low, Caroline M R and Perlin,
              Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and
              Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine
              and Yakneen, Sergei and Zhong, Ellen D and Zielinski, Michal and
              {\v Z}{\'\i}dek, Augustin and Bapst, Victor and Kohli, Pushmeet
              and Jaderberg, Max and Hassabis, Demis and Jumper, John M&quot;,
  journal  = &quot;Nature&quot;,
  month    = &quot;May&quot;,
  year     =  2024
}"><pre><span>@article</span>{<span>Abramson2024-fj</span>,
  <span>title</span>    = <span><span>"</span>Accurate structure prediction of biomolecular interactions with</span>
<span>              {AlphaFold} 3<span>"</span></span>,
  <span>author</span>   = <span><span>"</span>Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans,</span>
<span>              Richard and Green, Tim and Pritzel, Alexander and Ronneberger,</span>
<span>              Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick,</span>
<span>              Joshua and Bodenstein, Sebastian W and Evans, David A and Hung,</span>
<span>              Chia-Chun and O'Neill, Michael and Reiman, David and</span>
<span>              Tunyasuvunakool, Kathryn and Wu, Zachary and {\v Z}emgulyt{\.e},</span>
<span>              Akvil{\.e} and Arvaniti, Eirini and Beattie, Charles and</span>
<span>              Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and</span>
<span>              Congreve, Miles and Cowen-Rivers, Alexander I and Cowie, Andrew</span>
<span>              and Figurnov, Michael and Fuchs, Fabian B and Gladman, Hannah and</span>
<span>              Jain, Rishub and Khan, Yousuf A and Low, Caroline M R and Perlin,</span>
<span>              Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and</span>
<span>              Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine</span>
<span>              and Yakneen, Sergei and Zhong, Ellen D and Zielinski, Michal and</span>
<span>              {\v Z}{\'\i}dek, Augustin and Bapst, Victor and Kohli, Pushmeet</span>
<span>              and Jaderberg, Max and Hassabis, Demis and Jumper, John M<span>"</span></span>,
  <span>journal</span>  = <span><span>"</span>Nature<span>"</span></span>,
  <span>month</span>    = <span><span>"</span>May<span>"</span></span>,
  <span>year</span>     =  <span>2024</span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@article {Ahdritz2022.11.20.517210,
	author = {Ahdritz, Gustaf and Bouatta, Nazim and Floristean, Christina and Kadyan, Sachin and Xia, Qinghui and Gerecke, William and O{\textquoteright}Donnell, Timothy J and Berenberg, Daniel and Fisk, Ian and Zanichelli, Niccolò and Zhang, Bo and Nowaczynski, Arkadiusz and Wang, Bei and Stepniewska-Dziubinska, Marta M and Zhang, Shang and Ojewole, Adegoke and Guney, Murat Efe and Biderman, Stella and Watkins, Andrew M and Ra, Stephen and Lorenzo, Pablo Ribalta and Nivon, Lucas and Weitzner, Brian and Ban, Yih-En Andrew and Sorger, Peter K and Mostaque, Emad and Zhang, Zhao and Bonneau, Richard and AlQuraishi, Mohammed},
	title = {{O}pen{F}old: {R}etraining {A}lpha{F}old2 yields new insights into its learning mechanisms and capacity for generalization},
	elocation-id = {2022.11.20.517210},
	year = {2022},
	doi = {10.1101/2022.11.20.517210},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/10.1101/2022.11.20.517210},
	eprint = {https://www.biorxiv.org/content/early/2022/11/22/2022.11.20.517210.full.pdf},
	journal = {bioRxiv}
}"><pre><span>@article</span> {<span>Ahdritz2022.11.20.517210</span>,
	<span>author</span> = <span><span>{</span>Ahdritz, Gustaf and Bouatta, Nazim and Floristean, Christina and Kadyan, Sachin and Xia, Qinghui and Gerecke, William and O{\textquoteright}Donnell, Timothy J and Berenberg, Daniel and Fisk, Ian and Zanichelli, Niccolò and Zhang, Bo and Nowaczynski, Arkadiusz and Wang, Bei and Stepniewska-Dziubinska, Marta M and Zhang, Shang and Ojewole, Adegoke and Guney, Murat Efe and Biderman, Stella and Watkins, Andrew M and Ra, Stephen and Lorenzo, Pablo Ribalta and Nivon, Lucas and Weitzner, Brian and Ban, Yih-En Andrew and Sorger, Peter K and Mostaque, Emad and Zhang, Zhao and Bonneau, Richard and AlQuraishi, Mohammed<span>}</span></span>,
	<span>title</span> = <span><span>{</span>{O}pen{F}old: {R}etraining {A}lpha{F}old2 yields new insights into its learning mechanisms and capacity for generalization<span>}</span></span>,
	<span>elocation-id</span> = <span><span>{</span>2022.11.20.517210<span>}</span></span>,
	<span>year</span> = <span><span>{</span>2022<span>}</span></span>,
	<span>doi</span> = <span><span>{</span>10.1101/2022.11.20.517210<span>}</span></span>,
	<span>publisher</span> = <span><span>{</span>Cold Spring Harbor Laboratory<span>}</span></span>,
	<span>URL</span> = <span><span>{</span>https://www.biorxiv.org/content/10.1101/2022.11.20.517210<span>}</span></span>,
	<span>eprint</span> = <span><span>{</span>https://www.biorxiv.org/content/early/2022/11/22/2022.11.20.517210.full.pdf<span>}</span></span>,
	<span>journal</span> = <span><span>{</span>bioRxiv<span>}</span></span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@article{kozlova_2023_proteinflow,
  author = {Kozlova, Elizaveta and Valentin, Arthur and Khadhraoui, Aous and Gutierrez, Daniel Nakhaee-Zadeh},
  month = {09},
  title = {ProteinFlow: a Python Library to Pre-Process Protein Structure Data for Deep Learning Applications},
  doi = {https://doi.org/10.1101/2023.09.25.559346},
  year = {2023},
  journal = {bioRxiv}
}"><pre><span>@article</span>{<span>kozlova_2023_proteinflow</span>,
  <span>author</span> = <span><span>{</span>Kozlova, Elizaveta and Valentin, Arthur and Khadhraoui, Aous and Gutierrez, Daniel Nakhaee-Zadeh<span>}</span></span>,
  <span>month</span> = <span><span>{</span>09<span>}</span></span>,
  <span>title</span> = <span><span>{</span>ProteinFlow: a Python Library to Pre-Process Protein Structure Data for Deep Learning Applications<span>}</span></span>,
  <span>doi</span> = <span><span>{</span>https://doi.org/10.1101/2023.09.25.559346<span>}</span></span>,
  <span>year</span> = <span><span>{</span>2023<span>}</span></span>,
  <span>journal</span> = <span><span>{</span>bioRxiv<span>}</span></span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{ahdritz2023openproteinset,
      title={{O}pen{P}rotein{S}et: {T}raining data for structural biology at scale}, 
      author={Gustaf Ahdritz and Nazim Bouatta and Sachin Kadyan and Lukas Jarosch and Daniel Berenberg and Ian Fisk and Andrew M. Watkins and Stephen Ra and Richard Bonneau and Mohammed AlQuraishi},
      year={2023},
      eprint={2308.05326},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM}
}"><pre><span>@misc</span>{<span>ahdritz2023openproteinset</span>,
      <span>title</span>=<span><span>{</span>{O}pen{P}rotein{S}et: {T}raining data for structural biology at scale<span>}</span></span>, 
      <span>author</span>=<span><span>{</span>Gustaf Ahdritz and Nazim Bouatta and Sachin Kadyan and Lukas Jarosch and Daniel Berenberg and Ian Fisk and Andrew M. Watkins and Stephen Ra and Richard Bonneau and Mohammed AlQuraishi<span>}</span></span>,
      <span>year</span>=<span><span>{</span>2023<span>}</span></span>,
      <span>eprint</span>=<span><span>{</span>2308.05326<span>}</span></span>,
      <span>archivePrefix</span>=<span><span>{</span>arXiv<span>}</span></span>,
      <span>primaryClass</span>=<span><span>{</span>q-bio.BM<span>}</span></span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@article{Peebles2022DiT,
  title={Scalable Diffusion Models with Transformers},
  author={William Peebles and Saining Xie},
  year={2022},
  journal={arXiv preprint arXiv:2212.09748},
}"><pre><span>@article</span>{<span>Peebles2022DiT</span>,
  <span>title</span>=<span><span>{</span>Scalable Diffusion Models with Transformers<span>}</span></span>,
  <span>author</span>=<span><span>{</span>William Peebles and Saining Xie<span>}</span></span>,
  <span>year</span>=<span><span>{</span>2022<span>}</span></span>,
  <span>journal</span>=<span><span>{</span>arXiv preprint arXiv:2212.09748<span>}</span></span>,
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@inproceedings{Karras2022edm,
  author    = {Tero Karras and Miika Aittala and Timo Aila and Samuli Laine},
  title     = {Elucidating the Design Space of Diffusion-Based Generative Models},
  booktitle = {Proc. NeurIPS},
  year      = {2022}
}"><pre><span>@inproceedings</span>{<span>Karras2022edm</span>,
  <span>author</span>    = <span><span>{</span>Tero Karras and Miika Aittala and Timo Aila and Samuli Laine<span>}</span></span>,
  <span>title</span>     = <span><span>{</span>Elucidating the Design Space of Diffusion-Based Generative Models<span>}</span></span>,
  <span>booktitle</span> = <span><span>{</span>Proc. NeurIPS<span>}</span></span>,
  <span>year</span>      = <span><span>{</span>2022<span>}</span></span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the Apache License 2.0 - see the <a href="https://github.com/Ligo-Biosciences/AlphaFold3/blob/main/LICENSE.txt">LICENSE</a> file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The coming long-run slowdown in corporate profit growth and stock returns [pdf] (2023) (121 pts)]]></title>
            <link>https://www.federalreserve.gov/econres/feds/files/2023041pap.pdf</link>
            <guid>41448139</guid>
            <pubDate>Wed, 04 Sep 2024 17:13:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.federalreserve.gov/econres/feds/files/2023041pap.pdf">https://www.federalreserve.gov/econres/feds/files/2023041pap.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41448139">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamicland 2024 (339 pts)]]></title>
            <link>https://dynamicland.org/</link>
            <guid>41448022</guid>
            <pubDate>Wed, 04 Sep 2024 17:02:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dynamicland.org/">https://dynamicland.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41448022">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Internet Archive has lost its appeal in Hachette vs. Internet Archive (182 pts)]]></title>
            <link>https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf</link>
            <guid>41447758</guid>
            <pubDate>Wed, 04 Sep 2024 16:41:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf">https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41447758">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The first nuclear clock will test if fundamental constants change (143 pts)]]></title>
            <link>https://www.quantamagazine.org/the-first-nuclear-clock-will-test-if-fundamental-constants-change-20240904/</link>
            <guid>41447515</guid>
            <pubDate>Wed, 04 Sep 2024 16:23:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/the-first-nuclear-clock-will-test-if-fundamental-constants-change-20240904/">https://www.quantamagazine.org/the-first-nuclear-clock-will-test-if-fundamental-constants-change-20240904/</a>, See on <a href="https://news.ycombinator.com/item?id=41447515">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postContent">
            
            <div id="postBody">
                <div>
        <p>
            An ultra-precise measurement of a transition in the hearts of thorium atoms gives physicists a tool to probe the forces that bind the universe.        </p>
        
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1440" src="https://www.quantamagazine.org/wp-content/uploads/2024/09/NuclearClock-crNashWeerasekera-Lede-scaled.webp" alt="Illustration of a deconstructed clock where one metal layer is imprinted to look like a thorium atom." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/09/NuclearClock-crNashWeerasekera-Lede-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2024/09/NuclearClock-crNashWeerasekera-Lede-1720x968.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/09/NuclearClock-crNashWeerasekera-Lede-520x293.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/09/NuclearClock-crNashWeerasekera-Lede-768x432.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/09/NuclearClock-crNashWeerasekera-Lede-1536x864.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/09/NuclearClock-crNashWeerasekera-Lede-2048x1152.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>The discovery of a laser-controllable transition in the atomic nucleus of thorium-229 marks the dawn of the “nuclear clock.”</p>
            <p>Nash Weerasekera for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p>At 11:30 one night in May 2024, a graduate student, Chuankun Zhang, saw a signal that physicists have sought for 50 years. As a peak rose from the static on his monitor at the research institute JILA in Boulder, Colorado, Zhang dropped a screenshot in a group chat with his three lab mates. One by one they hopped out of bed and trickled in. After several sanity checks to make sure that what they were looking at was real — a signal from a thorium-229 nucleus switching between two states, known as the “nuclear clock” transition — the young researchers took a selfie to commemorate the moment. Time stamp: 3:42 a.m.</p>
<p>At their weekly meeting later that morning with their group leader, <a href="https://www.colorado.edu/physics/jun-ye">Jun Ye</a>, builder of the world’s most precise atomic clock, they decided to play it cool. “They were all poker-faced,” Ye said, until Zhang shared a slide displaying the long-sought peak. Tears flooded Ye’s eyes as the group clinked glasses of champagne at 9:30 a.m.</p>
<p>The group’s measurement, <a href="https://www.nature.com/articles/s41586-024-07839-6">reported</a> on September 4, 2024, in the journal <em>Nature</em>, is the third observation of the thorium-229 transition published within the last four months, coming on the heels of results from Germany and California. But the new measurement is millions of times more precise than the others, and it marks the end of a marathon search for the exact laser frequency needed to induce the nuclear clock transition. “This paper is an incredible technical achievement,” said <a href="https://www.durham.ac.uk/staff/hannah-williams4/">Hannah Williams</a>, a physicist at Durham University in the United Kingdom who was not involved in the work.</p>
<p>More importantly, it launches a new effort: Researchers will now try to use the transition to observe whether the laws of physics vary over time, as predicted by many theories of fundamental physics. Thanks to an apparently accidental, nearly exact cancellation of two of nature’s four forces in the thorium-229 nucleus, the nuclear clock transition is extremely sensitive to changes in these forces. Measuring this thorium-229 transition at different times could therefore reveal any variability in the fundamental constants of physics.</p>
<p>“I see it as the beginning of a beautiful journey,” said <a href="https://perimeterinstitute.ca/people/asimina-arvanitaki">Asimina Arvanitaki</a>, a theoretical physicist at the Perimeter Institute for Theoretical Physics in Canada who was also not involved. “Now we’ve measured this freak of nature. But in order to use its freakiness, a lot of work needs to be done.”</p>
<h2><strong>Freak of Nature</strong></h2>
<p>Scientists realized there’s something special about the isotope thorium-229 back in 1976, when they first studied this byproduct of Cold War nuclear weapons research.</p>
<p>Atoms are ordinarily in what’s called the ground state, in which all the electrons orbit the nucleus in a stable way. But an electron can also absorb energy from the outside world in the form of a photon and become excited, zip about the atom more quickly for a moment, then reemit the photon and return to the ground state. The photon has to have just the right amount — or “quantum” — of energy to excite the electron.</p>
<p>The modern notion of time is actually defined by this process. Scientists use a laser to bathe a cesium atom with photons. Then they vary the laser’s wavelength until its photons each have just the right energy to excite an electron. This ultra-precise wavelength then defines the international standard for a second, which is the time it takes for 9,192,631,770 of those wavelengths to pass a given point in space.</p>
</div>
    </div>
    <figure>
        <div>
                    <p><img width="1354" height="2560" src="https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-crGeoffreyWheeler_KennaHughes-Castleberry_JILA-3-scaled.webp" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-crGeoffreyWheeler_KennaHughes-Castleberry_JILA-3-scaled.webp 1354w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-crGeoffreyWheeler_KennaHughes-Castleberry_JILA-3-910x1720.webp 910w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-crGeoffreyWheeler_KennaHughes-Castleberry_JILA-3-275x520.webp 275w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-crGeoffreyWheeler_KennaHughes-Castleberry_JILA-3-768x1452.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-crGeoffreyWheeler_KennaHughes-Castleberry_JILA-3-812x1536.webp 812w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-crGeoffreyWheeler_KennaHughes-Castleberry_JILA-3-1083x2048.webp 1083w" sizes="(max-width: 1354px) 100vw, 1354px"><img width="2560" height="1096" src="https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-cr.Geoffrey-Wheeler-Kenna-Hughes-Castleberry_JILA-Mobile-1-scaled.webp" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-cr.Geoffrey-Wheeler-Kenna-Hughes-Castleberry_JILA-Mobile-1-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-cr.Geoffrey-Wheeler-Kenna-Hughes-Castleberry_JILA-Mobile-1-1720x736.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-cr.Geoffrey-Wheeler-Kenna-Hughes-Castleberry_JILA-Mobile-1-520x223.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-cr.Geoffrey-Wheeler-Kenna-Hughes-Castleberry_JILA-Mobile-1-768x329.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-cr.Geoffrey-Wheeler-Kenna-Hughes-Castleberry_JILA-Mobile-1-1536x658.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/09/Ye-Zhang-cr.Geoffrey-Wheeler-Kenna-Hughes-Castleberry_JILA-Mobile-1-2048x877.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px"></p><figcaption>
    <div>
                            <p>A team in the lab of Jun Ye (top), led by graduate student Chuankun Zhang (bottom), published an ultra-precise measurement of the nuclear clock transition in the journal <i data-stringify-type="italic">Nature</i>.</p>
                    </div>
</figcaption>
                </div>
        <figcaption>
    <div>
                            <p>A team in the lab of Jun Ye (left), led by graduate student Chuankun Zhang (right), published an ultra-precise measurement of the nuclear clock transition in the journal <i data-stringify-type="italic">Nature</i>.</p>
            <p>From left: Geoffrey Wheeler; Kenna Hughes-Castleberry/JILA</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Nuclei, the tight balls of neutrons and protons at every atom’s core, also have ground and excited states, in which one of their constituent protons or neutrons absorbs a photon and briefly swirls about more energetically. But these particles are packed much more tightly than electrons, so it takes much more energetic photons — gamma rays — to excite them. Those are much harder to produce in large quantities or with a precise energy.</p>
<p>The thorium-229 nucleus, however, is different.</p>
<p>From the 1950s to the 1970s, the United States produced about two tons of uranium-233, a weapons-grade fissile material that was being investigated as a possible alternative to uranium-235 and plutonium-239 in atomic weapons research. The program was eventually scrapped, leaving only some tanks of radioactive liquid behind. But when the nuclear physicists Larry Kroger and Charles Reich at Idaho National Laboratory <a href="https://www.sciencedirect.com/science/article/abs/pii/0375947476904942">studied the radiation</a> emanating from that liquid in 1976, they found indirect evidence that uranium-233’s “daughter” nucleus (the product of its radioactive decay), thorium-229, had a mysterious excited nuclear state that involved far less energy than expected.</p>
<p>Every nucleus lives in a tense tug-of-war between two of nature’s forces. The electromagnetic force between its positively charged protons tries to rip it apart, while the strong force holds the bundle together. Exciting a neutron or proton causes the nucleus to settle into a new, more energetic equilibrium between the two forces.</p>
<p>The Idaho researchers observed that reversing the intrinsic angular momentum, or “spin,” of thorium-229’s outermost neutron seemed to take 10,000 times less energy than a typical nuclear excitation. The neutron’s altered spin slightly changes both the electromagnetic and strong forces, but those changes happen to cancel each other out almost exactly. Consequently, the excited nuclear state barely differs from the ground state. Lots of nuclei have similar spin transitions, but only in thorium-229 is this cancellation so nearly perfect.</p>
<p>“It’s accidental,” said <a href="https://www.unsw.edu.au/staff/victor-flambaum">Victor Flambaum</a>, a theoretical physicist at the University of New South Wales in Sydney. “A priori, there is no special reason for thorium. It’s just experimental fact.” But this accident of forces and energy has big consequences.</p>
<h2><strong>Clocking the Constants</strong></h2>
<p>It took decades for scientists to realize just how special thorium-229 is, and what to do with it.</p>
<p>Kroger and Reich’s 1976 measurement had been imprecise, because it was carried out in the noisy bath of radiation that uranium-233 waste produces. They couldn’t see the actual low-energy photons released when nuclei decayed to the ground state; they only inferred the energy indirectly from the pattern of more powerful gamma radiation emitted by more excited nuclei.</p>
<p>In 1990, Reich and a colleague <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.64.271">redid this measurement</a> more carefully and found that the excited state’s energy was even smaller — more than 10 times smaller — than they initially thought. Whereas nuclear transitions often take millions of electron-volts, thorium-229 takes less than 10. This was a true game changer: No other isotope has a nuclear transition in the energy range of conventional lasers, which can deliver the energy to trigger the transition reliably and precisely. “In the whole chart of all the nuclei, it’s the only one,” said <a href="https://hudsongroup.physics.ucla.edu/content/people">Eric Hudson</a>, a physicist at the University of California, Los Angeles.</p>
</div>
    <figure>
        <div>
                            <p><img width="1600" height="1003" src="https://www.quantamagazine.org/wp-content/uploads/2024/09/EricHudson_crDavidEsquivel_UCLA.webp" alt="Portrait of a man with green lasers shining behind him." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/09/EricHudson_crDavidEsquivel_UCLA.webp 1600w, https://www.quantamagazine.org/wp-content/uploads/2024/09/EricHudson_crDavidEsquivel_UCLA-520x326.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/09/EricHudson_crDavidEsquivel_UCLA-768x481.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/09/EricHudson_crDavidEsquivel_UCLA-1536x963.webp 1536w" sizes="(max-width: 1600px) 100vw, 1600px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Eric Hudson’s team at the University of California, Los Angeles reported a measurement of the nuclear clock transition over the summer.</p>
            <p>David Esquivel/UCLA</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>If someone could isolate these nuclei from that radioactive environment and match an ultraviolet laser’s energy to that excited state, they could trigger it at will, just as they can with an electron.</p>
<p>The vast majority of the government’s uranium-233 “waste” still sat in guarded rooms at the Idaho and Oak Ridge labs. “Their budget was something like $20 million a year to just sit there and watch the stuff so nobody comes in and steals it,” said <a href="https://www.ornl.gov/our-people/saed-mirzadeh">Saed Mirzadeh</a>, a radiochemist who worked for 31 years at Oak Ridge. “They’d just sit there and smoke their cigarettes with guns around their necks.”</p>
<p>In 1994, Mirzadeh, who knew about the Idaho team’s work, convinced the lab to give him access to the languishing vats of dangerous liquid. He developed a method to separate the uranium atoms that had already decayed into thorium-229 from those that hadn’t. “The first time we actually did it, there were guards with machine guns outside the lab,” he said. Most of the world’s existing stock of thorium-229, he noted, comes from his efforts.</p>
<p>Ideas began to arise for how to utilize such a unique nucleus. In 2003, Ekkehard Peik and Christian Tamm at the Federal Physical and Technical Institute (PTB), Germany’s metrology institute, <a href="https://iopscience.iop.org/article/10.1209/epl/i2003-00210-x/meta">proposed</a> using it to build a nuclear clock. Since nuclei are shielded from the outside world by their clouds of electrons, they realized, a clock based on thorium-229 atoms would be immune to much of the background interference that plagued the best atomic clocks at the time.</p>
<p>Then Flambaum <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.97.092502">showed</a> that such a sensitive, isolated clock could be used to test the constancy of nature itself.</p>
</div>
    <figure>
        <div>
                            <p><img width="1614" height="1170" src="https://www.quantamagazine.org/wp-content/uploads/2024/09/EkkehardPeik_crPhysikalisch-TechnischeBundesanstalt.webp" alt="A man standing in front of an optical setup with his arms crossed smiles at the camera." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/09/EkkehardPeik_crPhysikalisch-TechnischeBundesanstalt.webp 1614w, https://www.quantamagazine.org/wp-content/uploads/2024/09/EkkehardPeik_crPhysikalisch-TechnischeBundesanstalt-520x377.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/09/EkkehardPeik_crPhysikalisch-TechnischeBundesanstalt-768x557.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/09/EkkehardPeik_crPhysikalisch-TechnischeBundesanstalt-1536x1113.webp 1536w" sizes="(max-width: 1614px) 100vw, 1614px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Ekkehard Peik at the Federal Physical and Technical Institute in Germany and his collaborators were the first to excite the nuclear clock transition with a laser earlier this year.</p>
            <p>Physikalisch-Technische Bundesanstalt</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Physicists have developed equations to characterize the forces that bind the universe, and these equations are fitted with some 26 numbers called fundamental constants. These numbers, such as the speed of light or the gravitational constant, define how everything works in our universe. But lots of physicists think the numbers might not actually be constant.</p>
<p>Theoretical ideas like string theory that try to build a deeper, more complete understanding of where forces come from often predict that these numbers, even the speed of light, change ever so slightly over time. In other words, the constants may result from underlying phenomena or processes that are themselves dynamic. This is also predicted by one of the most popular theories of dark matter, the invisible substance that floats in and around galaxies. If dark matter is made up of wavelike particles called axions, then the varying density of axions from place to place should cause the strength of some of the forces to wiggle up and down.</p>
<p>These small tweaks to nature’s laws could slightly disrupt the delicate balancing act that takes place inside every atom’s nucleus, altering the energies of its states. The energies of nuclear states come from adding and subtracting the huge electromagnetic and strong forces acting on all the protons and neutrons. Even a relatively small change in the strength of one of these forces would result in a substantial shift in energy. The shift would be especially noticeable when applied to the thorium-229 transition’s remarkably tiny energy.</p>
<p>Over the 2000s and 2010s, several teams entered the race to build the first nuclear clock. To win, they needed to figure out the exact energy a laser would need to excite the nuclear state in question, now called the nuclear clock transition.</p>
<h2><strong>Photo Finish</strong></h2>
<p>The existing estimate of the energy required for the nuclear clock transition was a thousand times less precise than the wavelengths of the lasers that researchers were trying to probe it with. So there were thousands of laser wavelengths to rule out. After tuning a laser to one of these wavelengths, researchers had to trap a few thorium-229 atoms, hit them with the laser, then wait for photons showing they’d excited the state. This process of elimination was simply going to take too long.</p>

<p>Following Hudson’s lead, groups <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.104.200802">began building</a> solid crystal compounds with the thorium embedded inside — an approach mentioned in Peik and Tamm’s original proposal. The crystals can hold quadrillions of atoms instead of just a few, so a laser could rule out wavelengths at a rapid clip.</p>
<p>A <a href="https://www.nature.com/articles/s41586-023-05894-z">breakthrough</a> last year at CERN kicked the race into overdrive. As in the older Idaho studies, the CERN team produced excited thorium-229 through radioactive decay, then looked at the photons coming out. But they found a way to do so in a much quieter environment, which enabled them to directly measure the faint rays of ultraviolet light coming from the nuclear clock transition and put a tighter estimate on the transition energy.</p>
<p>The CERN team’s updated estimate narrowed the wavelength hunters’ search from an entire forest to a small copse of trees, which they immediately began scouring. In April of this year, a European team became the <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.132.182501">first to report</a> that they had probed the state with a laser. Peik contributed his laser expertise, and the collaboration made use of a crystal-growing powerhouse built by the physicist Thorsten Schumm at the University of Vienna.</p>
<p>Hudson’s group was right on their heels — <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.133.013201">a paper</a> reporting their discovery ran in <em>Physical Review Letters</em> in July.</p>
<p>Ye’s group at JILA had also obtained one of Schumm’s crystals and was racing to excite the thorium-229 transition as well. For years, the group has been using its clock-building acumen to engineer a special ultraviolet laser with the sole purpose of turning thorium-229 into a nuclear clock. The laser allows Ye and his group to test many wavelengths at once to close in on any transition he seeks. His team’s new paper caps this trio of parallel discoveries with what will likely be the most precise measurement of the state’s energy for years to come.</p>
<p>“These results have all come out in a very short period of time,” Williams said, “so that is very exciting as to what they’re going to do next.”</p>
        
        
<p>The result starts the clock on thorium’s test of nature’s forces. “Now the fun starts,” Hudson said, excited to put the new tool to use studying fundamental constants. “We can actually do this stuff.”</p>
<p>The thorium nuclear state’s energy is far more sensitive to variations in the fundamental constants than that of any atomic state. But scientists will need to improve the precision of their measurements even further to notice changes more subtle than those already ruled out by conventional atomic clocks. Currently, Ye can measure the nuclear clock transition with a precision of one part in a trillion, but possible variations would be as small as one part in 10 trillion. “It’s many years down the road,” he said.</p>
<p>Eventually, though, some old Cold War byproducts could yield the first evidence for deeper, still undiscovered physics that underlies the universe we see. “We call them constants, but why?” Hudson asked. “Nothing is ever that simple when you zoom in and look at it.”</p>
</div>
                
                
            </div>
                <div id="newsletter">
            <p>
                The Quanta Newsletter            </p>
                            <p>
                    <em>Get highlights of the most important news delivered to your email inbox</em>
                </p>
                        
                            
                    </div>
    <div>
            <h2>Also in <span>Physics</span></h2>
            
        </div>
<section data-function="toggle" data-name="show-comments" id="comments">
    <h2>Comment on this article</h2>
    
    
</section>
    <div>
        <div data-name="next-post__image-wrapper">
    <p><img width="1720" height="729" src="https://www.quantamagazine.org/wp-content/uploads/2024/09/HiggsExplainer-crMicheleSclafani-HP-1720x729.jpg" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/09/HiggsExplainer-crMicheleSclafani-HP-1720x729.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/09/HiggsExplainer-crMicheleSclafani-HP-520x220.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2024/09/HiggsExplainer-crMicheleSclafani-HP-768x325.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2024/09/HiggsExplainer-crMicheleSclafani-HP-1536x651.jpg 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/09/HiggsExplainer-crMicheleSclafani-HP-2048x868.jpg 2048w" sizes="(max-width: 1720px) 100vw, 1720px">    </p>
</div>
        
        <div>
                <h2>Next article</h2>
                <p>How the Higgs Field (Actually) Gives Mass to Elementary Particles</p>
            </div>
        </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Mem0 – open-source Memory Layer for AI apps (106 pts)]]></title>
            <link>https://github.com/mem0ai/mem0</link>
            <guid>41447317</guid>
            <pubDate>Wed, 04 Sep 2024 16:01:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mem0ai/mem0">https://github.com/mem0ai/mem0</a>, See on <a href="https://news.ycombinator.com/item?id=41447317">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://github.com/mem0ai/mem0">
  <img src="https://github.com/mem0ai/mem0/raw/main/docs/images/banner-sm.png" width="800px" alt="Mem0 - The Memory Layer for Personalized AI">
  </a>
  </p><p dir="auto">
    <a href="https://mem0.ai/" rel="nofollow">Learn more</a>
    ·
    <a href="https://mem0.ai/discord" rel="nofollow">Join Discord</a>
  </p>

<p dir="auto">
  <a href="https://mem0.ai/discord" rel="nofollow">
    <img src="https://camo.githubusercontent.com/77710b3fddffb8b35ad4dfdca1724a4c58daf3778c42d494f3e98f57def1c4a3/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f36507a584467456a47353f7374796c653d666c6174" alt="Mem0 Discord" data-canonical-src="https://dcbadge.vercel.app/api/server/6PzXDgEjG5?style=flat">
  </a>
  <a href="https://pepy.tech/project/mem0ai" rel="nofollow">
    <img src="https://camo.githubusercontent.com/94088672ebb9e674fd4a0f250561da38b6df08d22087233d0165f3b64045822e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6d656d306169" alt="Mem0 PyPI - Downloads" data-canonical-src="https://img.shields.io/pypi/dm/mem0ai">
  </a>
  <a href="https://pypi.org/project/mem0ai" rel="nofollow">
        <img src="https://camo.githubusercontent.com/5b7f5ca05c54e143f9f52a7aa9ece4c188cf2241e98427a3731611dcb91b5b4c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d656d3061693f636f6c6f723d253233333444303538266c6162656c3d707970692532307061636b616765" alt="Package version" data-canonical-src="https://img.shields.io/pypi/v/mem0ai?color=%2334D058&amp;label=pypi%20package">
    </a>
    <a href="https://pypi.org/project/mem0ai" rel="nofollow">
        <img src="https://camo.githubusercontent.com/0ce3fb4bc2581c5befd06e9d35e8fd87cd01217a4e65194b184947f53be7fdb2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6d656d3061692e7376673f636f6c6f723d253233333444303538" alt="Supported Python versions" data-canonical-src="https://img.shields.io/pypi/pyversions/mem0ai.svg?color=%2334D058">
    </a>
  <a href="https://www.ycombinator.com/companies/mem0" rel="nofollow">
    <img src="https://camo.githubusercontent.com/cbd5d8722017c9a1eefa0e3620ecdb179dac21fbba84ec4aab7711adfa42c4ea/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f59253230436f6d62696e61746f722d5332342d6f72616e67653f7374796c653d666c61742d737175617265" alt="Y Combinator S24" data-canonical-src="https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto"><a href="https://mem0.ai/" rel="nofollow">Mem0</a> (pronounced as "mem-zero") enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. Mem0 remembers user preferences, adapts to individual needs, and continuously improves over time, making it ideal for customer support chatbots, AI assistants, and autonomous systems.</p>

<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/fa2f1cb7ec103daa40989bd997dc4e97d1f648e3ee788d18463e5db2fe85ce53/68747470733a2f2f6d656469612e74656e6f722e636f6d2f4b336a397077576c4d453041414141692f666972652d666c616d652e676966"><img src="https://camo.githubusercontent.com/fa2f1cb7ec103daa40989bd997dc4e97d1f648e3ee788d18463e5db2fe85ce53/68747470733a2f2f6d656469612e74656e6f722e636f6d2f4b336a397077576c4d453041414141692f666972652d666c616d652e676966" alt="Graph Memory Integration" data-animated-image="" data-canonical-src="https://media.tenor.com/K3j9pwWlME0AAAAi/fire-flame.gif"></a>
  <span>New Feature: Introducing Graph Memory. Check out our <a href="https://docs.mem0.ai/open-source/graph-memory" rel="nofollow">documentation</a>.</span>
</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Core Features</h3><a id="user-content-core-features" aria-label="Permalink: Core Features" href="#core-features"></a></p>
<ul dir="auto">
<li><strong>Multi-Level Memory</strong>: User, Session, and AI Agent memory retention</li>
<li><strong>Adaptive Personalization</strong>: Continuous improvement based on interactions</li>
<li><strong>Developer-Friendly API</strong>: Simple integration into various applications</li>
<li><strong>Cross-Platform Consistency</strong>: Uniform behavior across devices</li>
<li><strong>Managed Service</strong>: Hassle-free hosted solution</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How Mem0 works?</h3><a id="user-content-how-mem0-works" aria-label="Permalink: How Mem0 works?" href="#how-mem0-works"></a></p>
<p dir="auto">Mem0 leverages a hybrid database approach to manage and retrieve long-term memories for AI agents and assistants. Each memory is associated with a unique identifier, such as a user ID or agent ID, allowing Mem0 to organize and access memories specific to an individual or context.</p>
<p dir="auto">When a message is added to the Mem0 using add()  method, the system extracts relevant facts and preferences and stores it across data stores: a vector database, a key-value database, and a graph database. This hybrid approach ensures that different types of information are stored in the most efficient manner, making subsequent searches quick and effective.</p>
<p dir="auto">When an AI agent or LLM needs to recall memories, it uses the search() method. Mem0 then performs search across these data stores, retrieving relevant information from each source. This information is then passed through a scoring layer, which evaluates their importance based on relevance, importance, and recency. This ensures that only the most personalized and useful context is surfaced.</p>
<p dir="auto">The retrieved memories can then be appended to the LLM's prompt as needed, enhancing the personalization and relevance of its responses.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Use Cases</h3><a id="user-content-use-cases" aria-label="Permalink: Use Cases" href="#use-cases"></a></p>
<p dir="auto">Mem0 empowers organizations and individuals to enhance:</p>
<ul dir="auto">
<li><strong>AI Assistants and agents</strong>: Seamless conversations with a touch of déjà vu</li>
<li><strong>Personalized Learning</strong>: Tailored content recommendations and progress tracking</li>
<li><strong>Customer Support</strong>: Context-aware assistance with user preference memory</li>
<li><strong>Healthcare</strong>: Patient history and treatment plan management</li>
<li><strong>Virtual Companions</strong>: Deeper user relationships through conversation memory</li>
<li><strong>Productivity</strong>: Streamlined workflows based on user habits and task history</li>
<li><strong>Gaming</strong>: Adaptive environments reflecting player choices and progress</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto">The easiest way to set up Mem0 is through the managed <a href="https://app.mem0.ai/" rel="nofollow">Mem0 Platform</a>. This hosted solution offers automatic updates, advanced analytics, and dedicated support. <a href="https://app.mem0.ai/" rel="nofollow">Sign up</a> to get started.</p>
<p dir="auto">If you prefer to self-host, use the open-source Mem0 package. Follow the <a href="#install">installation instructions</a> to get started.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation Instructions <a name="user-content-install"></a></h2><a id="user-content-installation-instructions-" aria-label="Permalink: Installation Instructions " href="#installation-instructions-"></a></p>
<p dir="auto">Install the Mem0 package via pip:</p>

<p dir="auto">Alternatively, you can use Mem0 with one click on the hosted platform <a href="https://app.mem0.ai/" rel="nofollow">here</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Usage</h3><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<p dir="auto">Mem0 requires an LLM to function, with <code>gpt-4o</code> from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our <a href="https://docs.mem0.ai/llms" rel="nofollow">Supported LLMs documentation</a>.</p>
<p dir="auto">First step is to instantiate the memory:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from mem0 import Memory

m = Memory()"><pre><span>from</span> <span>mem0</span> <span>import</span> <span>Memory</span>

<span>m</span> <span>=</span> <span>Memory</span>()</pre></div>
<details>
<summary>How to set OPENAI_API_KEY</summary>
<div dir="auto" data-snippet-clipboard-copy-content="import os
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;sk-xxx&quot;"><pre><span>import</span> <span>os</span>
<span>os</span>.<span>environ</span>[<span>"OPENAI_API_KEY"</span>] <span>=</span> <span>"sk-xxx"</span></pre></div>
</details>
<p dir="auto">You can perform the following task on the memory:</p>
<ol dir="auto">
<li>Add: Store a memory from any unstructured text</li>
<li>Update: Update memory of a given memory_id</li>
<li>Search: Fetch memories based on a query</li>
<li>Get: Return memories for a certain user/agent/session</li>
<li>History: Describe how a memory has changed over time for a specific memory ID</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# 1. Add: Store a memory from any unstructured text
result = m.add(&quot;I am working on improving my tennis skills. Suggest some online courses.&quot;, user_id=&quot;alice&quot;, metadata={&quot;category&quot;: &quot;hobbies&quot;})

# Created memory --> 'Improving her tennis skills.' and 'Looking for online suggestions.'"><pre><span># 1. Add: Store a memory from any unstructured text</span>
<span>result</span> <span>=</span> <span>m</span>.<span>add</span>(<span>"I am working on improving my tennis skills. Suggest some online courses."</span>, <span>user_id</span><span>=</span><span>"alice"</span>, <span>metadata</span><span>=</span>{<span>"category"</span>: <span>"hobbies"</span>})

<span># Created memory --&gt; 'Improving her tennis skills.' and 'Looking for online suggestions.'</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# 2. Update: update the memory
result = m.update(memory_id=<memory_id_1>, data=&quot;Likes to play tennis on weekends&quot;)

# Updated memory --> 'Likes to play tennis on weekends.' and 'Looking for online suggestions.'"><pre><span># 2. Update: update the memory</span>
<span>result</span> <span>=</span> <span>m</span>.<span>update</span>(<span>memory_id</span><span>=</span><span>&lt;</span><span>memory_id_1</span><span>&gt;</span>, <span>data</span><span>=</span><span>"Likes to play tennis on weekends"</span>)

<span># Updated memory --&gt; 'Likes to play tennis on weekends.' and 'Looking for online suggestions.'</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# 3. Search: search related memories
related_memories = m.search(query=&quot;What are Alice's hobbies?&quot;, user_id=&quot;alice&quot;)

# Retrieved memory --> 'Likes to play tennis on weekends'"><pre><span># 3. Search: search related memories</span>
<span>related_memories</span> <span>=</span> <span>m</span>.<span>search</span>(<span>query</span><span>=</span><span>"What are Alice's hobbies?"</span>, <span>user_id</span><span>=</span><span>"alice"</span>)

<span># Retrieved memory --&gt; 'Likes to play tennis on weekends'</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# 4. Get all memories
all_memories = m.get_all()
memory_id = all_memories[&quot;memories&quot;][0] [&quot;id&quot;] # get a memory_id

# All memory items --> 'Likes to play tennis on weekends.' and 'Looking for online suggestions.'"><pre><span># 4. Get all memories</span>
<span>all_memories</span> <span>=</span> <span>m</span>.<span>get_all</span>()
<span>memory_id</span> <span>=</span> <span>all_memories</span>[<span>"memories"</span>][<span>0</span>] [<span>"id"</span>] <span># get a memory_id</span>

<span># All memory items --&gt; 'Likes to play tennis on weekends.' and 'Looking for online suggestions.'</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# 5. Get memory history for a particular memory_id
history = m.history(memory_id=<memory_id_1>)

# Logs corresponding to memory_id_1 --> {'prev_value': 'Working on improving tennis skills and interested in online courses for tennis.', 'new_value': 'Likes to play tennis on weekends' }"><pre><span># 5. Get memory history for a particular memory_id</span>
<span>history</span> <span>=</span> <span>m</span>.<span>history</span>(<span>memory_id</span><span>=</span><span>&lt;</span><span>memory_id_1</span><span>&gt;</span>)

<span># Logs corresponding to memory_id_1 --&gt; {'prev_value': 'Working on improving tennis skills and interested in online courses for tennis.', 'new_value': 'Likes to play tennis on weekends' }</span></pre></div>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">If you prefer a hosted version without the need to set up infrastructure yourself, check out the <a href="https://app.mem0.ai/" rel="nofollow">Mem0 Platform</a> to get started in minutes.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Graph Memory</h3><a id="user-content-graph-memory" aria-label="Permalink: Graph Memory" href="#graph-memory"></a></p>
<p dir="auto">To initialize Graph Memory you'll need to set up your configuration with graph store providers.
Currently, we support Neo4j as a graph store provider. You can setup <a href="https://neo4j.com/" rel="nofollow">Neo4j</a> locally or use the hosted <a href="https://neo4j.com/product/auradb/" rel="nofollow">Neo4j AuraDB</a>.
Moreover, you also need to set the version to <code>v1.1</code> (<em>prior versions are not supported</em>).
Here's how you can do it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from mem0 import Memory

config = {
    &quot;graph_store&quot;: {
        &quot;provider&quot;: &quot;neo4j&quot;,
        &quot;config&quot;: {
            &quot;url&quot;: &quot;neo4j+s://xxx&quot;,
            &quot;username&quot;: &quot;neo4j&quot;,
            &quot;password&quot;: &quot;xxx&quot;
        }
    },
    &quot;version&quot;: &quot;v1.1&quot;
}

m = Memory.from_config(config_dict=config)
"><pre><span>from</span> <span>mem0</span> <span>import</span> <span>Memory</span>

<span>config</span> <span>=</span> {
    <span>"graph_store"</span>: {
        <span>"provider"</span>: <span>"neo4j"</span>,
        <span>"config"</span>: {
            <span>"url"</span>: <span>"neo4j+s://xxx"</span>,
            <span>"username"</span>: <span>"neo4j"</span>,
            <span>"password"</span>: <span>"xxx"</span>
        }
    },
    <span>"version"</span>: <span>"v1.1"</span>
}

<span>m</span> <span>=</span> <span>Memory</span>.<span>from_config</span>(<span>config_dict</span><span>=</span><span>config</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">For detailed usage instructions and API reference, visit our documentation at <a href="https://docs.mem0.ai/" rel="nofollow">docs.mem0.ai</a>. Here, you can find more information on both the open-source version and the hosted <a href="https://app.mem0.ai/" rel="nofollow">Mem0 Platform</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<p dir="auto"><a href="https://star-history.com/#mem0ai/mem0&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/32407dd18b36d02377972982a21bb54f481c3cfaf5b5368263538fb896ef2bde/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6d656d3061692f6d656d3026747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=mem0ai/mem0&amp;type=Date"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support</h2><a id="user-content-support" aria-label="Permalink: Support" href="#support"></a></p>
<p dir="auto">Join our community for support and discussions. If you have any questions, feel free to reach out to us using one of the following methods:</p>
<ul dir="auto">
<li><a href="https://mem0.ai/discord" rel="nofollow">Join our Discord</a></li>
<li><a href="https://x.com/mem0ai" rel="nofollow">Follow us on Twitter</a></li>
<li><a href="mailto:founders@mem0.ai">Email founders</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<p dir="auto">Join our <a href="https://mem0.ai/discord" rel="nofollow">Discord community</a> to learn about memory management for AI agents and LLMs, and connect with Mem0 users and contributors. Share your ideas, questions, or feedback in our <a href="https://github.com/mem0ai/mem0/issues">GitHub Issues</a>.</p>
<p dir="auto">We value and appreciate the contributions of our community. Special thanks to our contributors for helping us improve Mem0.</p>
<a href="https://github.com/mem0ai/mem0/graphs/contributors">
  <img src="https://camo.githubusercontent.com/f107c6afd1adb1112f86fe17c427bb28c458965ef70874be78fac0e424a87a68/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6d656d3061692f6d656d30" data-canonical-src="https://contrib.rocks/image?repo=mem0ai/mem0">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the Apache 2.0 License - see the <a href="https://github.com/mem0ai/mem0/blob/main/LICENSE">LICENSE</a> file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel Honesty (279 pts)]]></title>
            <link>https://stratechery.com/2024/intel-honesty/</link>
            <guid>41446766</guid>
            <pubDate>Wed, 04 Sep 2024 15:15:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stratechery.com/2024/intel-honesty/">https://stratechery.com/2024/intel-honesty/</a>, See on <a href="https://news.ycombinator.com/item?id=41446766">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-13412">
	<!-- .entry-header -->

	<div>
		<p>It really is a valley:</p>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-1.png?resize=640%2C645&amp;ssl=1" alt="The topography of Silicon Valley" width="640" height="645" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-1.png?w=1280&amp;ssl=1 1280w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-1.png?resize=298%2C300&amp;ssl=1 298w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-1.png?resize=1016%2C1024&amp;ssl=1 1016w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-1.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-1.png?resize=768%2C774&amp;ssl=1 768w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-1.png?resize=625%2C630&amp;ssl=1 625w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>There, right in the middle of the Santa Clara Valley, formed by the Santa Cruz Mountains on the west and the Diablo Range on the east, lies the once-sleepy city of Mountain View. Mountain View was dominated by the U.S. Navy’s Moffett Field in 1955, when William Shockley, one of the inventors of the transistor at Bell Labs, returned to neighboring Palo Alto to care for his ailing mother.</p>
<p>Convinced that silicon was a superior material for transistors — Bell Labs was focused on germanium — Shockley, unable to hire many Bell Labs co-workers both because of the distance from New Jersey and also his abusive management style, set up the Shockley Semiconductor Laboratory in 1956 in Mountain View with a collection of young scientists. Only a year later eight of those scientists, led by Robert Noyce and Gordon Moore, fled Shockley —&nbsp;he really was a terrible manager — and set up Fairchild Semiconductor, a new division of Fairchild Camera and Instrument, in neighboring Sunnyvale.</p>
<p>It was Fairchild Semiconductor that gave the tech industry’s home the other half of its name: yes, we talk about “The Valley”, but at least when it comes to tech, we mean <em>Silicon</em> Valley. From <a href="https://techcrunch.com/2014/07/26/the-first-trillion-dollar-startup/">TechCrunch in 2014</a>:</p>
<blockquote><p>
  As Fairchild started to grow, employees began to leave the firm to launch new spin-off businesses. Many of these firms also grew quickly, inspiring other employees still working at the company…The growth of these new companies started to reshape the region. In just 12 years, the co-founders and former employees of Fairchild generated more than 30 spin-off companies and funded many more. By 1970, chip businesses in the San Francisco area employed a total of 12,000 people…</p>
<p>  The achievements of these companies eventually attracted attention. In 1971, a journalist named Don Hoefler wrote an article about the success of computer chip companies in the Bay Area. The firms he profiled all produced chips using silicon and were located in a large valley south of San Francisco. Hoefler put these two facts together to create a new name for the region: Silicon Valley.</p>
<p>  Hoefler’s article and the name he coined have become quite famous, but there’s a critical part of his analysis that is often overlooked: Almost all of the silicon chip companies he profiled can be traced back to Fairchild and its co-founders.</p>
<p>  <a href="https://techcrunch.com/2014/07/26/the-first-trillion-dollar-startup/"><img data-recalc-dims="1" loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-3.png?resize=640%2C646&amp;ssl=1" alt="Companies formed downstream from Fairchild Semiconductor" width="640" height="646" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-3.png?w=1280&amp;ssl=1 1280w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-3.png?resize=297%2C300&amp;ssl=1 297w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-3.png?resize=1014%2C1024&amp;ssl=1 1014w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-3.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-3.png?resize=768%2C775&amp;ssl=1 768w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-3.png?resize=624%2C630&amp;ssl=1 624w" sizes="(max-width: 640px) 100vw, 640px"></a>
</p></blockquote>
<p>Still, for all of the massive success downstream from Fairchild Semiconductor, none mattered more, or came to define Silicon Valley in every respect, than Intel. Arthur Rock, who had helped the so-called “Traitorous Eight” find Fairchild Camera and Instrument, funded Intel, and in the process <a href="https://law.stanford.edu/stanford-lawyer/articles/legal-matters-arthur-rock-on-the-early-venture-capital-decisions-that-sparked-decades-of-innovation/">created the compensation structure that came to define Silicon Valley</a>. Gordon Moore wrote the roadmap for Intel — nor more commonly known as <a href="http://cva.stanford.edu/classes/cs99s/papers/moore-crammingmorecomponents.pdf">Moore’s Law</a> — which “predicted” that the number of transistors would double at a set rate, both increasing compute speed and driving down prices for that compute; “predict” is in quotes because Moore’s Law was not a physical law, but an economic one, downstream of Intel’s inexorable push for continued improvement. That, by extension, meant that Intel set the pace of innovation for all of technology, not just by making the processors for the PC — and, in an underrated wave of disruption in the early part of this century, the cloud — but also by defining the expectations of every software engineer in the entire world.</p>
<h3>Intel’s Long Decline</h3>
<p>Stratechery has, from the beginning, operated with a great degree of reverence for tech history; perhaps that’s why I’ve always been a part of the camp cheering for Intel to succeed. The unfortunate fact of the matter is that the need for cheerleading has been clear for as long as I have written this blog: in <a href="https://stratechery.com/2013/the-intel-opportunity/">May 2013</a> I wrote that Intel needed to build out a foundry business, as the economics of their IDM business, given their mobile miss, faced long-term challenges.</p>
<p>Unfortunately not only did Intel not listen, but their business got a lot worse: in the late 2010’s Intel got stuck trying to move to 10nm, thanks in part to their reluctance to embrace the vastly more expensive EUV lithography process, handing the performance crown to TSMC. Meanwhile Intel’s chip design team, increasingly fat and lazy thanks to the fact they could leverage Intel’s once-industry-leading processes, had started to fall behind AMD; today AMD has both better designs and, thanks to the fact they fab their chips at TSMC, better processes. Meanwhile, the rise of hyperscalers meant there were entities that both had the scale to justify overcoming whatever software advantages Intel had, and the resources to do so; the result is that AMD has been taking data center share for years, and is on the verge of passing 50%:</p>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-2.png?resize=640%2C348&amp;ssl=1" alt="Intel vs AMD in the data center" width="640" height="348" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-2.png?w=1280&amp;ssl=1 1280w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-2.png?resize=300%2C163&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-2.png?resize=1024%2C556&amp;ssl=1 1024w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-2.png?resize=768%2C417&amp;ssl=1 768w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/09/intel-2.png?resize=1160%2C630&amp;ssl=1 1160w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>[<em>Editor’s Note: these two paragraphs are technically incorrect, in that AMD’s data center revenue includes their AI chips; the directionally point remains, but I regret the erros</em>]</p>
<p><strike>This chart actually understates the problem, because it only includes x86 processors;</strike> in fact, those capabilities that have allowed the hyperscalers to take advantage of AMD’s increasingly superior total cost of ownership have also been devoted to building ARM-based server chips. Amazon in particular has invested heavily in its Graviton line of chips, taking advantage of ARM’s theoretically better efficiency and lower licensing fees (as compared to Intel’s margins).</p>
<p>Beyond that, what is especially problematic — and why Intel’s datacenter revenue is actually down year-over-year — is that an increasing amount of data center spend is going towards AI, the latest paradigm where Intel missed the boat.</p>
<p>[<em>End Editor’s Note</em>]</p>
<p>The story Intel — or at least <a href="https://www.theatlantic.com/technology/archive/2013/05/paul-otellinis-intel-can-the-company-that-built-the-future-survive-it/275825/">its past management</a> — wants you to believe about mobile is that they foolishly passed up the opportunity to supply Apple’s iPhone, not realizing that the volume would more than make up for the margin hit; in fact, <a href="https://stratechery.com/2022/an-interview-with-father-of-the-ipod-tony-fadell/">Tony Fadell told me</a> that while Steve Jobs wanted Intel — Apple had just switched to using Intel chips for Macs —&nbsp;Intel chips weren’t competitive:</p>
<blockquote><p>
  For me, when it came to Intel at the time, back in the mid-2000s, they were always about, “Well, we’ll just repackage what we have on the desktop for the laptop and then we’ll repackage that again for embedding.” It reminded me of Windows saying, “I’m going to do Windows and then I’m going to do Windows Mobile and I’m going to do Windows embedded.” It was using those same cores and kernels and trying to slim them down…</p>
<p>  The mindset at Intel was never about — when they went through that CISC-RISC duality of “Which one are we going to be?”, and they chose CISC, which was the right thing at the time, if you fast forward, they also made that decision, they threw away architectural and they went to more manufacturing. That was the time when they said “We don’t have to worry about all these different product lines to meet all these architectural needs. We’re just going to have Moore’s Law take over” and so in a way that locks you into a path and that’s why Intel, not under the Pat days but previous to the Pat days, was all driven by manufacturing capability and legal. It wasn’t driven by architectural decisions, it was like, “Here’s what we got and we’re going to spread it around and we’re going to keep reusing it”.
</p></blockquote>
<p>In fact, it does go back to the Pat days, specifically CEO Pat Gelsinger’s initial stint at Intel. He was the one that <a href="https://stratechery.com/2022/mr-cisc-vs-mr-risc-arm-and-amd-threats-gelsingers-three-tenets/">pushed CISC over RISC</a>, arguing that Intel’s CISC software advantage, supported by the company’s superior manufacturing, would ensure that the company dominated microprocessors. And, as Fadell noted, it worked, at least in PCs and servers.</p>
<p>Where it didn’t work was mobile: Intel couldn’t leverage its manufacturing to make x86 competitive with ARM, particularly since the latter had a head start on software; it also didn’t work in GPUs, where Intel spent years trying to build x86-based gaming chips that — you guessed it — were meant to rely on Intel’s manufacturing prowess. GPUs, of course, are the foundation of today’s AI boom, and while Intel bought Gaudi to offer AI chips, they haven’t made a dent in the market — and oh, by the way, Gaudi chips are manufactured by TSMC.</p>
<h3>IDM 2.0</h3>
<p>None of this story is new; I recounted it in 2021’s <a href="https://stratechery.com/2021/intel-problems/">Intel Problems</a>. My solution then — written shortly after Gelsinger came back to Intel, fifteen years after being passed over for the CEO job — was that the company needed to split up.</p>
<blockquote><p>
  Integrating design and manufacturing was the foundation of Intel’s moat for decades, but that integration has become a strait-jacket for both sides of the business. Intel’s designs are held back by the company’s struggles in manufacturing, while its manufacturing has an incentive problem.</p>
<p>  The key thing to understand about chips is that design has much higher margins; Nvidia, for example, has gross margins between 60~65%, while TSMC, which makes Nvidia’s chips, has gross margins closer to 50%. Intel has, as I noted above, traditionally had margins closer to Nvidia, thanks to its integration, which is why Intel’s own chips will always be a priority for its manufacturing arm. That will mean worse service for prospective customers, and less willingness to change its manufacturing approach to both accommodate customers and incorporate best-of-breed suppliers (lowering margins even further). There is also the matter of trust: would companies that compete with Intel be willing to share their designs with their competitor, particularly if that competitor is incentivized to prioritize its own business?</p>
<p>  The only way to fix this incentive problem is to spin off Intel’s manufacturing business. Yes, it will take time to build out the customer service components necessary to work with third parties, not to mention the huge library of IP building blocks that make working with a company like TSMC (relatively) easy. But a standalone manufacturing business will have the most powerful incentive possible to make this transformation happen: the need to survive.
</p></blockquote>
<p>Two months later and Gelsinger announced his turnaround plan: <a href="https://stratechery.com/2021/intel-unleashed-gelsinger-on-intel-idm-2-0/">IDM 2.0</a>. Intel would separate out its manufacturing into a separate division that would serve third parties, but still under the Intel banner. Gelsinger told me <a href="https://stratechery.com/2022/an-interview-with-intel-ceo-pat-gelsinger/">in an interview</a> that this was the only way Intel could both be competitive in chips and keep investing in the leading edge; after all, AMD’s spin-off of Global Foundries resulted in the former floundering until <a href="https://stratechery.com/2024/an-interview-with-amd-ceo-lisa-su-about-solving-hard-problems/">they could break their purchase agreements with Global Foundries and go to TSMC</a>, and <a href="https://stratechery.com/2018/uber-follow-up-globalfoundries-abandons-7nm-pricing-power-differentiation-and-integration/">the latter giving up on the leading edge</a>.</p>
<p>Gelsinger is persuasive and optimistic, and for the last three years I’ve given him the benefit of the doubt. Suddenly, though, a split is back on the table; from <a href="https://www.bloomberg.com/news/articles/2024-08-30/intel-is-said-to-explore-options-to-cope-with-historic-slump">Bloomberg</a>:</p>
<blockquote><p>
  Intel Corp. is working with investment bankers to help navigate the most difficult period in its 56-year history, according to people familiar with the matter. The company is discussing various scenarios, including a split of its product-design and manufacturing businesses, as well as which factory projects might potentially be scrapped, said the people, who asked not to be identified because the deliberations are private…</p>
<p>  A potential separation or sale of Intel’s foundry division, which is aimed at manufacturing chips for outside customers, would be an about-face for Chief Executive Officer Pat Gelsinger. Gelsinger has viewed the business as key to restoring Intel’s standing among chipmakers and had hoped it would eventually compete with the likes of Taiwan Semiconductor Manufacturing Co., which pioneered the foundry industry.
</p></blockquote>
<p>As the article notes, Intel is likely to consider less drastic steps first; <a href="https://www.reuters.com/technology/intel-ceo-pitch-board-plans-shed-assets-cut-costs-source-says-2024-09-01/">Reuters reported</a> that ideas include selling businesses like its Altera programmable chip business and reducing capital expeditures, including axing a proposed foundry in Germany. The company also finally killed its dividend, and is cutting 15,000 jobs, which frankly, isn’t enough; I noted <a href="https://stratechery.com/2024/intel-concerns-fubo-blocks-venu/">in an Update last week</a>:</p>
<blockquote><p>
  Intel ended last year with 124,800 people; to put that in context, TSMC had 76,478 employees and AMD 26,000, which is to say that the two companies combined had fewer employees than Intel while making better x86 chips, an actually competitive GPU, and oh yeah, making chips for everyone else on earth, including Apple and Nvidia. A 15,000 employee cut is both too small and too late.
</p></blockquote>
<p>The fundamental problem facing the company is encapsulated in that paragraph:</p>
<ul>
<li>Intel doesn’t have the best manufacturing</li>
<li>Intel doesn’t design the best chips</li>
<li>Intel is out of the game in AI</li>
</ul>
<p>Moreover, the future does not look bright; the problem with Intel’s most recent earnings call was threefold:</p>
<ul>
<li>Intel’s is technically on pace to achieve the five nodes in four years Gelsinger promised (in truth two of those nodes were iterations), but they haven’t truly scaled any of them; the first attempt to do so, with Intel 3, destroyed their margins. This isn’t a surprise: the reason why it is hard to skip steps is not just because technology advances, but because you have to actually learn on the line how to implement new technology at scale, with sustainable yield. Go back to Intel’s 10nm failure: the company could technically make a 10nm chip, they just couldn’t do so economically; there are now open questions about Intel 3, much less next year’s promised 18A.</li>
<li>Intel is dramatically ramping up its Lunar Lake architecture as it is the only design the company has that is competitive with the Qualcomm ARM architecture undergirding Microsoft’s CoPilot+ PC initiative; the problem is that Lunar Lake’s tiles — including its CPU — are made by TSMC, which is both embarrassing and also terrible for margins.</li>
<li>The third problem is that the goal Gelsinger has been pushing for is the aforementioned 18A, yet Intel has yet to announce a truly committed at-scale partner. Yes, the company is in talks with lots of folks and claims some number of secret agreements, but at this point the foundry strategy needs real proof points; unfortunately Intel itself ramping up on TSMC, even as it loses control of its costs, isn’t exactly a selling point as to why any third-party should put their fortunes in Intel’s hands.</li>
</ul>
<p>All that noted, my initial response to the meltdown over Intel’s earnings <a href="https://stratechery.com/2024/intel-earnings-intels-nadir/">was to defend Gelsinger</a>; what is happening to Intel now is downstream of mistakes that happened years before Gelsinger came back to the company. That remains true, but Gelsinger does have one fatal flaw: he still believes in Intel, and I no longer do.</p>
<h3>Market Realities</h3>
<p>Here is the fundamental problem facing Intel, and by extension, U.S. dreams of controlling leading edge capacity: there is no reason for Intel Foundry to exist. Apple, Nvidia, AMD, and other leading edge fabless chip companies rely on TSMC, and why wouldn’t they? TSMC invested in EUV, surpassed Intel, and are spending tens of billions of dollars a year to continue pushing forward to 2nm and beyond. Yes, <a href="https://stratechery.com/2024/tsmc-earnings-tsmcs-pricing-mistake-intel-v-tsmc/">TSMC priced 3nm too low</a>, but even if the company raises prices for future nodes, as I expect them to, the relative cost matters much less than TSMC’s superior customer services and demonstrated reliability.</p>
<p>The kicker is that the smartest decision for Intel’s own chip unit is to — as they are with Lunar Lake — rely on TSMC’s manufacturing as well. Intel still has advantages in PCs and a dominant position in on-premises and government data centers, but the best way to leverage those remaining areas of strength is to have TSMC make their chips.</p>
<p>This was, for the record, why Gelsinger did have a point in keeping the company together; Intel Foundry needs volume, and the easiest way to get that volume is from Intel itself. However, that by definition is a decision that is not driven by what is best for a theoretical Intel fabless business, but rather the impetus to restore Intel’s manufacturing capability, even as that manufacturing capability is heavily incentivized to cater to Intel’s chip business at the expense of external customers.</p>
<p>Gelsinger’s trump card has been the fact that <a href="https://stratechery.com/2020/chips-and-geopolitics/">TSMC is based in Taiwan</a>, which is under continuous threat from China. Indeed, Gelsinger has been <a href="https://stratechery.com/2021/intel-vs-tsmc-how-samsung-and-tsmc-won-mad-chips/">quite explicit on this point</a>; from <a href="https://focustaiwan.tw/business/202112030015">CNA English News in 2021</a>:</p>
<blockquote><p>
  Intel CEO Pat Gelsinger said at the Fortune Brainstorm Tech summit in California on Wednesday that the United States government should support a sustainable semiconductor supply chain in the U.S., in part because “Taiwan is not a stable place”…</p>
<p>  Asked about the comment, TSMC Chairman Mark Liu (劉德音) said, “there’s nothing that needs to be addressed. TSMC does not speak ill of other companies in the industry,” and added there were probably not many people who believed Gelsinger’s argument. Geopolitical tensions, Liu said, may have a short-term impact, but he believed Taiwan could help create a brilliant decade for the global semiconductor industry, with the best technology and the best manufacturing ecosystem.
</p></blockquote>
<p>Gelsinger made the same point to me in that interview while explaining why Intel needed to stay together:</p>
<blockquote><p>
  As we look at this, to me, there is almost a global national perspective to this, in that I deeply believe the West needs a world class technology provider, and I don’t think that splitting Intel in two, that it could survive for many, many, many years till that would become the case, that you could stand that up. Remember, given cash flows, R&amp;D streams, products that enable us to drive that, and I’m committed to go fix it, and I think we’re on a good path to go fix it since I’ve been here as well. So for those three different reasons, we chose the IDM 2.0 path, but it’s not because we didn’t look at the alternative, it’s partially because we did.
</p></blockquote>
<p>This is where everyone who is invested in American manufacturing — or perhaps more accurately, concerned about China’s threat to Taiwan — has to get brutally honest. If the U.S. government and U.S. tech companies want to have a non-Taiwan option, they are going to have to pay for it directly. Yes, the CHIPS Act passed, but while Intel is getting a lot of funds, it’s going to take a lot more — and the price of those funds needs to be a much smarter incentive structure that drives Intel apart.</p>
<p>My proposal back in 2021 was purchase guarantees instead of subsidies, and I am back to thinking that is the only viable path.</p>
<blockquote><p>
  That is why a federal subsidy program should operate as a purchase guarantee: the U.S. will buy A amount of U.S.-produced 5nm processors for B price; C amount of U.S. produced 3nm processors for D price; E amount of U.S. produced 2nm processors for F price; etc. This will not only give the new Intel manufacturing spin-off something to strive for, but also incentivize other companies to invest; perhaps Global Foundries will get back in the game, or TSMC will build more fabs in the U.S. And, in a world of nearly free capital, perhaps there will finally be a startup willing to take the leap.
</p></blockquote>
<p>That free capital world is gone, and it’s probably not realistic for a startup to figure out how to manufacture the most complex devices humans have ever produced; the best idea at this point is a new company that has the expertise and starting position of Intel Foundry. Critically, though, it shouldn’t be at all beholden to x86 chips, have hundreds of thousands of employees, or the cultural overhang of having once led the computing world. The best we can do is purchase guarantees — on the order of hundreds of billions of dollars over the next decade — and a prayer that someone can make such an entity stand on its own.</p>
<p>To summarize, there is no market-based reason for Intel Foundry to exist; that’s not a market failure in a purely economic sense, but to the extent the U.S. national security apparatus sees it as a failure is the extent to which the U.S. is going to have to pay to make it happen. And, if the U.S. is going to pay up, that means giving that foundry the best possible chance to stand on its own two feet in the long run. That means actually earning business from Apple, Nvidia, AMD, and yes, even the fabless Intel company that will remain. The tech world has moved on from Intel; the only chance for U.S. leading edge manufacturing is to do the same.</p>
<p><em>I wrote a follow-up to this Article in <a href="https://stratechery.com/2024/broadcom-and-intel-nvidia-earnings-doj-investigating-nvidia/">this Daily Update</a>.</em></p>

	</div><!-- .entry-content -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Insecurity of Debian (206 pts)]]></title>
            <link>https://unix.foo/posts/insecurity-of-debian/</link>
            <guid>41446428</guid>
            <pubDate>Wed, 04 Sep 2024 14:46:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unix.foo/posts/insecurity-of-debian/">https://unix.foo/posts/insecurity-of-debian/</a>, See on <a href="https://news.ycombinator.com/item?id=41446428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>In June of 2023 Red Hat made a controversial decision to change how they distribute the source code behind Red Hat Enterprise Linux (RHEL). There have been a lot of keyboards tapped angrily across social media that left many uncertain about the ramifications of the decision. There were many questions about the future viability of downstream rebuilds of RHEL affecting distributions like Rocky Linux, AlmaLinux, Oracle Linux, and others. Each have since made announcements to try and calm their communities.</p>
<p>Still. Many in the open source community have interpreted Red Hat’s decision for what it really was: A dick move.</p>
<p>There has been a steady uptick of people stating that they will migrate (or already have) to Debian – seeking refuge from what they see as greedy corporate influence. I understand the sentiment fully. However, there’s a problem here that I want to talk about: security.</p>
<p>The ugly truth is that security is hard. It’s tedious. Unpleasant. And requires a lot of work to get right.</p>
<p>Debian does not do enough here to protect users.</p>
<p>Long ago, Red Hat embraced the usage of <a href="https://en.wikipedia.org/wiki/Security-Enhanced_Linux">SELinux</a>. And they took it beyond just enabling the feature in their kernel. They put in the arduous work of crafting default SELinux policies for their distribution.</p>
<p>These <a href="https://www.redhat.com/sysadmin/selinux-kata-containers">policies ship enabled by default</a> in their distribution. The policies help protect a variety of daemons that run by default on RHEL, as well as many of the most popular daemons folks tend to use on the server.</p>
<p>Apache, nginx, MariaDB, PostgreSQL, OpenSSH, etc. are all covered by SELinux policies that ship on RHEL distributions.</p>
<p>The protection even extends to containers. Containers are increasingly the preferred method for developers to deploy their software – myself included. A common misconception is that if you run something in a container, it’s inherently secure. This is absolutely not true. Containers by themselves do not solve a security problem. They solve a software distribution problem. They give a false impression of security to those that run them.</p>
<p>On Red Hat based distributions, you can use a drop-in Docker alternative named podman which allows you to run containers without needing a daemon (unlike Docker) and it provides other benefits like being able to run fully root-less. But Red Hat takes it a step further here and applies strong default SELinux policies that separate the container from the host OS and even from other containers!</p>
<p>There have been numerous <a href="https://www.redhat.com/en/blog/latest-container-exploit-runc-can-be-blocked-selinux?intcmp=701f20000012ngPAAQ">examples</a> of being able to escape from a container and touch the host OS or other containers. This is where tools like SELinux step in. The application of SELinux policies on a container allows for a hardened sarcophagus to place your application in which mitigates the risk of unknown future exploits. And it’s nearly effortless to use on RHEL.</p>
<p>Red Hat was aware that unless they put in the work on these default policies, their users would simply not embrace the technology and millions of servers would remain vulnerable. Because let’s be real here. SELinux is hard. The policy language and tooling is cumbersome, obtuse, and is about as appealing as filling out tax forms. It frankly sucks to use – if you are manually creating your own policies that is.</p>
<p>But due to the work Red Hat has put in, the usage of SELinux on RHEL is mostly transparent and provides real security benefits to their users.</p>
<h2 id="debians-approach">Debian’s Approach</h2>
<p>Debian, a stalwart of the open-source community, is revered for its stability and extensive software library. I am a fan and <a href="https://www.debian.org/donations">donate</a> to the project every year (you should too!) even though I don’t run it in production environments.</p>
<p>However, its default security framework leaves much to be desired. Debian’s decision to enable <a href="https://en.wikipedia.org/wiki/AppArmor">AppArmor</a> by default starting with version 10 signifies a positive step towards improved security, yet it falls short due to the half-baked implementation across the system.</p>
<p>Debian’s reliance on AppArmor and its default configurations reveals a systemic issue with its approach to security. While AppArmor is capable of providing robust security when properly configured, Debian’s out-of-the-box settings fail to leverage its full potential:</p>
<p><strong>Limited Default Profiles:</strong> Debian ships with a minimal set of AppArmor profiles, leaving many critical services unprotected.</p>
<p><strong>Reactive vs. Proactive Stance:</strong> Debian’s security model often relies on users to implement stricter policies, rather than providing a secure-by-default configuration.</p>
<p><strong>Inconsistent Application:</strong> Unlike SELinux in Red Hat systems, which applies to the entire system consistently, AppArmor in Debian is applied piecemeal, leading to potential security gaps.</p>
<p><strong>Lack of Resources:</strong> Debian as a community-driven project lacks the resources to develop and maintain comprehensive security policies comparable to those provided by Red Hat.</p>
<p>It’s very common for folks to run container workloads on Debian via Docker – which <a href="https://docs.docker.com/engine/security/apparmor/">does automatically generate</a> and load a default AppArmor profile for containers named <code>docker-default</code>. Unfortunately, it’s not a very strong profile for security and is overly permissive.</p>
<p>This profile, while providing some protection, <a href="https://github.com/moby/moby/blob/master/profiles/apparmor/template.go">leaves significant attack surfaces</a> exposed. For instance:</p>
<div><pre tabindex="0"><code data-lang="gdscript3"><span><span>  <span>network</span><span>,</span>
</span></span><span><span>  <span>capability</span><span>,</span>
</span></span><span><span>  <span>file</span><span>,</span>
</span></span><span><span>  <span>umount</span><span>,</span>
</span></span><span><span>  <span># Host (privileged) processes may send signals to container processes.</span>
</span></span><span><span>  <span>signal</span> <span>(</span><span>receive</span><span>)</span> <span>peer</span><span>=</span><span>unconfined</span><span>,</span>
</span></span><span><span>  <span># runc may send signals to container processes (for "docker stop").</span>
</span></span><span><span>  <span>signal</span> <span>(</span><span>receive</span><span>)</span> <span>peer</span><span>=</span><span>runc</span><span>,</span>
</span></span><span><span>  <span># crun may send signals to container processes (for "docker stop" when used with crun OCI runtime).</span>
</span></span><span><span>  <span>signal</span> <span>(</span><span>receive</span><span>)</span> <span>peer</span><span>=</span><span>crun</span><span>,</span>
</span></span><span><span>  <span># dockerd may send signals to container processes (for "docker kill").</span>
</span></span><span><span>  <span>signal</span> <span>(</span><span>receive</span><span>)</span> <span>peer</span><span>=</span><span>{{</span><span>.</span><span>DaemonProfile</span><span>}},</span>
</span></span><span><span>  <span># Container processes may send signals amongst themselves.</span>
</span></span><span><span>  <span>signal</span> <span>(</span><span>send</span><span>,</span><span>receive</span><span>)</span> <span>peer</span><span>=</span><span>{{</span><span>.</span><span>Name</span><span>}},</span>
</span></span><span><span>  <span>deny</span> <span>@</span><span>{</span><span>PROC</span><span>}</span><span>/*</span> <span>w</span><span>,</span>   <span># deny write for all files directly in /proc (not in a subdir)</span>
</span></span><span><span>  <span># deny write to files not in /proc/&lt;number&gt;/** or /proc/sys/**</span>
</span></span><span><span>  <span>deny</span> <span>@</span><span>{</span><span>PROC</span><span>}</span><span>/</span><span>{[</span><span>^</span><span>1</span><span>-</span><span>9</span><span>],[</span><span>^</span><span>1</span><span>-</span><span>9</span><span>][</span><span>^</span><span>0</span><span>-</span><span>9</span><span>],[</span><span>^</span><span>1</span><span>-</span><span>9</span><span>s</span><span>][</span><span>^</span><span>0</span><span>-</span><span>9</span><span>y</span><span>][</span><span>^</span><span>0</span><span>-</span><span>9</span><span>s</span><span>],[</span><span>^</span><span>1</span><span>-</span><span>9</span><span>][</span><span>^</span><span>0</span><span>-</span><span>9</span><span>][</span><span>^</span><span>0</span><span>-</span><span>9</span><span>][</span><span>^</span><span>0</span><span>-</span><span>9</span><span>/</span><span>]</span><span>*</span><span>}</span><span>/**</span> <span>w</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>@</span><span>{</span><span>PROC</span><span>}</span><span>/</span><span>sys</span><span>/</span><span>[</span><span>^</span><span>k</span><span>]</span><span>**</span> <span>w</span><span>,</span>  <span># deny /proc/sys except /proc/sys/k* (effectively /proc/sys/kernel)</span>
</span></span><span><span>  <span>deny</span> <span>@</span><span>{</span><span>PROC</span><span>}</span><span>/</span><span>sys</span><span>/</span><span>kernel</span><span>/</span><span>{</span><span>?</span><span>,</span><span>??</span><span>,[</span><span>^</span><span>s</span><span>][</span><span>^</span><span>h</span><span>][</span><span>^</span><span>m</span><span>]</span><span>**</span><span>}</span> <span>w</span><span>,</span>  <span># deny everything except shm* in /proc/sys/kernel/</span>
</span></span><span><span>  <span>deny</span> <span>@</span><span>{</span><span>PROC</span><span>}</span><span>/</span><span>sysrq</span><span>-</span><span>trigger</span> <span>rwklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>@</span><span>{</span><span>PROC</span><span>}</span><span>/</span><span>kcore</span> <span>rwklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>mount</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>[</span><span>^</span><span>f</span><span>]</span><span>*/**</span> <span>wklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>f</span><span>[</span><span>^</span><span>s</span><span>]</span><span>*/**</span> <span>wklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>fs</span><span>/</span><span>[</span><span>^</span><span>c</span><span>]</span><span>*/**</span> <span>wklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>fs</span><span>/</span><span>c</span><span>[</span><span>^</span><span>g</span><span>]</span><span>*/**</span> <span>wklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>fs</span><span>/</span><span>cg</span><span>[</span><span>^</span><span>r</span><span>]</span><span>*/**</span> <span>wklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>firmware</span><span>/**</span> <span>rwklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>devices</span><span>/</span><span>virtual</span><span>/</span><span>powercap</span><span>/**</span> <span>rwklx</span><span>,</span>
</span></span><span><span>  <span>deny</span> <span>/</span><span>sys</span><span>/</span><span>kernel</span><span>/</span><span>security</span><span>/**</span> <span>rwklx</span><span>,</span>
</span></span></code></pre></div><p>The <strong>network</strong> rule allows all network-related syscalls without restriction.</p>
<p>The <strong>capability</strong> rule, without specific denials, permits most capabilities by default.</p>
<p>The <strong>file</strong> rule grants broad file access permissions, relying on specific deny rules for protection.</p>
<h2 id="apparmor-vs-selinux">AppArmor vs. SELinux</h2>
<p>The fundamental difference between AppArmor and SELinux lies in their approach to Mandatory Access Control (MAC). AppArmor operates on a path-based model, while SELinux employs a significantly more complex type enforcement system. This distinction becomes particularly evident in container environments.</p>
<p>SELinux applies a type to every object in the system - files, processes, ports, you name it. When you launch a container on a SELinux-enabled RHEL system, it’s immediately assigned the <strong>container_t</strong> type – a strict access control mechanism. The <strong>container_t</strong> type effectively cordons off the container, preventing it from interacting with any object not explicitly labeled for container use.</p>
<p>But SELinux doesn’t stop at type enforcement. It takes container isolation a step further with <a href="https://en.wikipedia.org/wiki/Multi_categories_security">Multi-Category Security (MCS)</a> labels. These labels function as an additional layer of segregation, ensuring that even containers of the same type (<strong>container_t</strong>) remain isolated from each other. Each container gets its own unique MCS label, creating what amounts to a private sandbox within the broader <strong>container_t</strong> environment.</p>
<p>AppArmor, in contrast, doesn’t concern itself with types or categories. It focuses on limiting the capabilities of specific programs based on pre-defined profiles. These profiles specify which files a program can access and which operations it can perform. While this approach is more straightforward to implement and understand, it lacks the granularity and system-wide consistency of SELinux’s type enforcement. Almost no mainstream Linux distribution distributes comprehensive AppArmor profiles for all common network-facing daemons by default.</p>
<p>The practical implications of these differences are significant. In a SELinux environment, a compromised container faces substantial hurdles in accessing or affecting the host system or other containers, thanks to the dual barriers of type enforcement and MCS labels.</p>
<p>This isn’t to say one is universally superior to the other. SELinux offers more robust isolation but at the cost of increased complexity and potential performance overhead. AppArmor provides a simpler, more approachable security model that can still be quite effective when configured properly. The root of my point though is that Red Hat has put in the work here to make the use of SELinux and containers seamless and easy for its users. You aren’t left to fend for yourself.</p>
<p>In the end, the choice between Debian and Red Hat isn’t just about corporate influence versus community-driven development. It’s also a choice between a system that assumes the best and one that prepares for the worst. Unfortunately in today’s highly connected world, pessimism is a necessity.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boom Supersonic's XB-1 prototype aces 2nd test flight (109 pts)]]></title>
            <link>https://www.space.com/boom-supersonic-xb-1-second-test-flight-photos</link>
            <guid>41446337</guid>
            <pubDate>Wed, 04 Sep 2024 14:38:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.space.com/boom-supersonic-xb-1-second-test-flight-photos">https://www.space.com/boom-supersonic-xb-1-second-test-flight-photos</a>, See on <a href="https://news.ycombinator.com/item?id=41446337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-320-80.jpg" alt="a needle-nosed white and silver plane flies over a desert-mountain landscape" srcset="https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/4rUC9BLjmW7yNbCoMWJVJ.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span>Boom Supersonic's XB-1 prototype conducts its second-ever test flight on Aug. 26, 2024.</span>
<span itemprop="copyrightHolder">(Image credit: Boom Supersonic)</span>
</figcaption>
</div>

<div id="article-body">
<p>Colorado company Boom Supersonic's XB-1 supersonic demonstrator aircraft flew for the second time ever on Monday (Aug. 26).</p><p>The flight took place from California's Mojave Air and Space Port and lasted about 15 minutes, seeing the <a data-analytics-id="inline-link" href="https://www.space.com/boom-xb-1-faa-approval-supersonic-test-flight" data-before-rewrite-localise="https://www.space.com/boom-xb-1-faa-approval-supersonic-test-flight"><u>XB-1</u></a> reach an altitude of 10,400 feet (3,170 meters) and a speed of 277 mph (446 kph).</p><p>The flight demonstrated landing gear being retracted and extended for the first time, and a new digital stability augmentation system was tested to improve handling.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-320-80.jpg" alt="a needle-nosed white and silver plane comes in for a landing at a desert airstrip" srcset="https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/kcrxVLha8QLCBh88tXXAUB.jpg"></picture></p></div><figcaption itemprop="caption description"><span>The flight took place from California's Mojave Air and Space Port. </span><span itemprop="copyrightHolder">(Image credit: Boom Supersonic)</span></figcaption></figure><p>The test marks another step toward achieving supersonic flight, expected later in the year, according to a company <a data-analytics-id="inline-link" href="https://boomsupersonic.com/flyby/xb-1-completes-second-flight" target="_blank" data-url="https://boomsupersonic.com/flyby/xb-1-completes-second-flight" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><u>statement</u></a>.</p><p>"XB-1 had a fantastic second flight this morning. Initial results indicate we've successfully resolved the findings from Flight One and are excited to continue flight testing on the path to supersonic flight," said Blake Scholl, founder and CEO of Boom Supersonic. "I'm proud of the team. Today's flight is another step toward the return of supersonic passenger travel."</p><p><strong>Related:</strong> <a data-analytics-id="inline-link" href="https://www.space.com/nasa-mars-rover-perseverance-speed-of-sound" data-before-rewrite-localise="https://www.space.com/nasa-mars-rover-perseverance-speed-of-sound">The speed of sound on Mars is different from Earth, Perseverance rover finds</a></p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-320-80.jpg" alt="closeup photo of a needle-nosed white and silver plane on a runway" srcset="https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/7HhEJAPVarGBDBVhDHWzbM.jpg"></picture></p></div><figcaption itemprop="caption description"><span>Boom Supersonic plans to ramp up its flight-test campaign with the XB-1 soon.&nbsp; </span><span itemprop="copyrightHolder">(Image credit: Boom Supersonic)</span></figcaption></figure><p>The XB-1 test plane had its <a data-analytics-id="inline-link" href="https://www.space.com/boom-xb-1-faa-approval-supersonic-test-flight" data-before-rewrite-localise="https://www.space.com/boom-xb-1-faa-approval-supersonic-test-flight">first flight</a> in March this year. The company now intends to ramp up its flight rate and plans around 10 tests before reaching for supersonic speeds.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-6ZtMezCJiku2rwsHDsW9UD"><section><p>Breaking space news, the latest updates on rocket launches, skywatching events and more!</p></section></div><p>The XB-1 program is part of the design and development process for Boom's flagship project, Overture, a planned supersonic airliner. Boom Supersonic aims to revolutionize air travel by making it much faster and more efficient.</p>
</div>
<p><em><a href="https://forums.space.com/">Join our Space Forums</a> to keep talking space on the latest missions, night sky and more! And if you have a news tip, correction or comment, let us know at: <a href="mailto:community@space.com">community@space.com.</a></em></p>
<div id="slice-container-authorBio-6ZtMezCJiku2rwsHDsW9UD"><p>Andrew&nbsp;is a freelance space journalist with a focus on reporting on China's rapidly growing space sector. He began writing&nbsp;for Space.com in 2019 and writes for SpaceNews, IEEE Spectrum, National Geographic, Sky &amp; Telescope, New Scientist and others.&nbsp;Andrew&nbsp;first caught the space bug when, as a youngster,&nbsp;he&nbsp;saw Voyager images of other worlds in our solar system for the first&nbsp;time.&nbsp;Away from space,&nbsp;Andrew&nbsp;enjoys trail running in the forests of Finland.&nbsp;You can follow him on Twitter&nbsp;<a href="https://twitter.com/AJ_FI" target="_blank">@AJ_FI</a>.</p></div>


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Physics is unreasonably good at creating new math (154 pts)]]></title>
            <link>https://nautil.us/why-physics-is-unreasonably-good-at-creating-new-math-797056/</link>
            <guid>41445790</guid>
            <pubDate>Wed, 04 Sep 2024 13:43:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/why-physics-is-unreasonably-good-at-creating-new-math-797056/">https://nautil.us/why-physics-is-unreasonably-good-at-creating-new-math-797056/</a>, See on <a href="https://news.ycombinator.com/item?id=41445790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
            <p><span>M</span>athematics has long been the basis for advances in physics. Albert Einstein hailed general relativity as “a real triumph” for mathematics in 1915, when he discovered that purely mathematical work, more than a half-century old, perfectly described the fabric of spacetime in his theory of gravity. How could math conceived with no application in mind, he wondered later, prove “so admirably appropriate to the objects of reality?”</p><p>Math’s service to physics, now often taken for granted, is rooted in its origins. Mathematics was, after all, invented for surveying, quantifying, and understanding the physical world. In Mesopotamia, the Sumerians developed a counting system, leaving behind clay tablets inscribed with multiplication tables. Their purpose? To tally goods and property. In the intervening millennia, what began as a tool to grease the wheels of government and commerce took on a life of its own. But, while expanding into areas of abstraction so obscure they can only be grasped after years of training, mathematics has continued to underpin the great breakthroughs in physics.</p>
      
    <p>Recently, though, the tables have turned. Now insights and intuitions from physics are unexpectedly leading to breakthroughs in mathematics. After going their own way for much of the 20th century, mathematicians are increasingly turning to the laws and patterns of the natural world for inspiration. Fields stuck for decades are being unstuck. And even philosophers have started to delve into the mystery of why physics is proving “unreasonably effective” in mathematics, as one has boldly declared. That question hinges on a largely unappreciated, perplexing, and profound link between the rules that govern the behavior of the cosmos and the most abstract musings of the human mind.</p><blockquote>
<p>The experience of mathematical beauty excites the same parts of the brain as beautiful music, art, or poetry.&nbsp;</p>
</blockquote>
          <p>Why <em>should</em> physics—rooted in making sense of real things in the world like apples and electrons—provide such good leads for solving some of the toughest problems in mathematics, which deals with intangible stuff, like functions and equations?</p><p>“Physicists are much less concerned than mathematicians about rigorous proofs,” says Timothy Gowers, a mathematician at the Collège de France and a Fields Medal winner. Sometimes, he says, that “allows physicists to explore mathematical terrain more quickly than mathematicians.” If mathematicians tend to survey—in great depth—small parcels of this landscape, physicists are more likely to skim rapidly over vast tracts of this largely uncharted territory. With this perspective, physicists can happen across new, powerful mathematical concepts and associations, to which mathematicians can return, to try and justify (or disprove) them.</p><p><span>T</span>he process of physics inspiring mathematics is, in fact, as old as science itself. The ancient Greek mathematician and inventor Archimedes described how the laws of mechanics had spurred some of his most important mathematical discoveries. Then there’s Isaac Newton, who (alongside his contemporary, the German polymath Gottfried Wilhelm Leibniz) famously developed an entirely new kind of math—calculus—while trying to understand the motion of falling objects.</p><p>But in the middle of the 20th century, the flow of new math from physics all but dried up. Neither physicists nor mathematicians were much interested in what was happening on the other side of the fence. In mathematics, an influential set of young French mathematicians called the Bourbaki group sought to make mathematics as precise as possible, rebuilding whole fields from scratch and publishing their collaborative work in an effort—they hoped—to facilitate future discoveries. Physicists, meanwhile, were excitedly developing path-breaking ideas such as the Standard Model—still physicists’ best theory of the atomic and subatomic world. For many of them, math was just a handy tool, and they had no interest in the austere vision of mathematics championed by the Bourbakis.</p>
          <p>Yet a reconciliation was afoot, spearheaded by the late British-Lebanese geometer Michael Atiyah. With rare intuition, and a little luck, Atiyah, also a Fields medalist, often alighted on areas that would later be of interest to theoretical physicists.</p><p>“In the mid 1970s, he became convinced that theoretical physics was by far the most promising source of new ideas,” Nigel Hitchin, a mathematician and emeritus professor at the University of Oxford who collaborated with Atiyah <a href="https://ncatlab.org/nlab/files/HitchinOnAtiyahGeometryPhysics.pdf" target="_blank" rel="noreferrer noopener">wrote</a> in 2020 of his former colleague. “From that point on, he became a facilitator of interactions between mathematicians and physicists, attacking mathematical challenges posed by physicists, using physical ideas to prove pure mathematical results, and feeding the physicist community with the parts of modern mathematics he regarded as important but were unfamiliar to them.”&nbsp;</p><figure><img width="800" height="725" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Bhattacharya_BREAKER.png?auto=compress&amp;fit=scale&amp;fm=png&amp;h=928&amp;ixlib=php-3.3.1&amp;w=1024&amp;wpsize=large" srcset="https://assets.nautil.us/sites/3/nautilus/Bhattacharya_BREAKER.png?q=65&amp;auto=format&amp;w=1600 800w,https://assets.nautil.us/sites/3/nautilus/Bhattacharya_BREAKER.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Bhattacharya_BREAKER.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>STICKY PROBLEM: </strong>Physicist Philip Candelas and his collaborators used tools from string theory to solve a sticky problem in enumerative geometry: counting the number of certain kinds of curves in a Calabi-Yau manifold (pictured here), strange six-dimensional shapes central to string theory. <em>Credit: Wikimedia Commons.</em></figcaption></figure><p>One of Atiyah’s long-term collaborators, who he first met in 1977, was the mathematical physicist Edward Witten. More than 20 years Atiyah’s junior, Witten later became a pioneer of string theory, an idea that posits that tiny one-dimensional vibrating strings are the fundamental building blocks of the universe, rather than the particles of the Standard Model.</p>
          <p>Initially hailed as a possible “theory of everything” that would unite quantum theory with Einstein’s theory of gravity, string theory has to date arguably had a bigger impact on some of the most abstract fields of mathematics, such as <a href="https://nautil.us/the-math-that-takes-newton-into-the-quantum-world-237339/" target="_blank" rel="noreferrer noopener">algebraic geometry</a> and differential topology, than in physics. In these areas, Witten and other string theorists have been able to produce precise conjectures that mathematicians have later proved.</p><p>In 1991, for example, physicists Philip Candelas, Xenia de la Ossa, and their colleagues <a href="https://webspace.science.uu.nl/~beuke106/HypergeometricFunctions/COGP.pdf" target="_blank" rel="noreferrer noopener">applied</a> string theory to a decades-old puzzle in enumerative geometry, an ancient branch of mathematics dedicated to counting the number of solutions to geometrical problems. At its simplest, this asks questions such as “How many lines can pass through two points on a plane?” (One.) Or Apollonius’ famous problem, “How many circles can be drawn that touch (are tangent to) three given circles?” (Eight.)</p><p>Candelas and his collaborators were able to use tools from string theory to solve a particularly sticky problem in enumerative geometry: counting the number of certain kinds of curves in Calabi-Yau manifolds, strange six-dimensional shapes that are central to string theory. Their result connected two kinds of geometry, “symplectic” and “complex,” that mathematicians had studied in isolation from each other for decades, thinking they were unrelated. This sort of advance—one that connects two fields that were thought to be unrelated—is considered a “deep” result in math: You can suddenly use tools from one to solve problems in the other, enabling and accelerating advances.</p><p>Just a few years later, in 1995, Witten proposed that five different versions of string theory, each requiring 10 dimensions, were all different aspects of a single 11-dimensional conceptualization he called “M-theory.” Though M-theory remains unproven, mapping the correspondences between the different theories has led to startling mathematical discoveries. “It feels like every month string theory is giving new structures to mathematicians in an unprecedented way,” says mathematical physicist Yang-Hui He of the London Institute for Mathematical Sciences.</p>
          <blockquote>
<p>The sort of math that emerges from studying reality is the sort our brains tend to like.</p>
</blockquote><p>That string theory is a rich source of such unexpected relationships, or “dualities,” between two mathematical worlds, continues to excite mathematicians today. Physicist He and his collaborator string theorist Federico Carta, also of the London Institute, were studying the simplest type of Calabi-Yau manifold, called a K3 surface, when they stumbled across a relationship between the surface’s “homotopy groups,” which are used to classify shapes in topology, and a symmetry group, called “Matthieu 24.” The pair’s discovery reveals an unanticipated connection between two disparate fields of pure mathematics—topology, the study of shapes, and an area of modern algebra called group theory, which concerns the types of symmetry that objects possess.</p><p>Why physics should give rise to such interesting mathematics, says He, is a “deep question.” There are an infinite number of patterns and structures that mathematicians could study, he says. “But the ones which come from reality are ones which we have an intuition about at some level.”</p><p>Hitchin agrees. “Mathematical research doesn’t operate in a vacuum,” he says. “You don’t sit down and invent a new theory for its own sake. You need to believe that there is something there to be investigated. New ideas have to condense around some notion of reality, or someone’s notion, maybe.”</p>
          <p>This raises the question of whether physics feeds math merely by providing a keener motivation for exploring it and a focus for mathematicians’ energies. Guided by intuitions about how the world should work, and a plausible endpoint, mathematicians can sometimes make speedier progress on a problem than they otherwise would.&nbsp;</p><p>It would also explain a curious fact: “Bad” physics can sometimes lead to good math.&nbsp;</p><p>Vortex theory, for instance, was an early attempt by British mathematical physicist William Thomson (Lord Kelvin) to explain why atoms came in a relatively small number of varieties. He pictured atoms as spinning rings which could be tied in intricate knots, with each knot corresponding to a different chemical element. The theory was abandoned after the discovery of the electron—but the mathematics led to the development of knot theory, which has since both become a fecund area for pure mathematicians to explore and found surprising applications in fluid dynamics and for understanding tangled molecules like DNA.</p><p><span>F</span>or Atiyah, the enigmatic relationship between physics and math all came down to the human brain. “Humans are a product of long evolution, in which powerful brains were an advantage. Such brains evolved in the physical world, so evolutionary success was measured by physical success,” he explained in a 2018 <a href="https://www.uv.es/~azcarrag/pdf/2018%20REF%20Conversation%20Atiyah%20English.pdf" target="_blank" rel="noreferrer noopener">interview</a>. “Hence human brains evolved to solve physical problems and this required the brain to develop the right kind of mathematics.” To do so, the brain must also have adapted to recognizing and appreciating mathematical patterns in nature. Atiyah even co-authored a brain-imaging <a href="https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2014.00068/full" target="_blank" rel="noreferrer noopener">study</a> in 2014 that concluded the experience of mathematical beauty excites the same parts of the brain as beautiful music, art, or poetry. That might explain why physics can be a lodestar for mathematicians: The sort of math that emerges from studying reality is the sort our brains tend to like.</p>
          <p>In a 2010 <a href="https://royalsocietypublishing.org/doi/full/10.1098/rsta.2009.0227" target="_blank" rel="noreferrer noopener">paper</a> with Hitchin and Dutch theoretical physicist <a href="https://nautil.us/are-there-barbarians-at-the-gates-of-science-235904/" target="_blank" rel="noreferrer noopener">Robbert Dijkgraaf</a>, then of Princeton University, Atiyah went on to further highlight the successful use of physics in mathematics. Since then, however, there has been scant work to try to understand the phenomenon.</p><p>One philosopher who has recently re-examined the issue is Daniele Molinini, at the University of Bologna. His 2023 <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/715104" target="_blank" rel="noreferrer noopener">paper</a>, published in <em>The British Journal for the Philosophy of Science</em>, responded to an oft-cited 1960 essay entitled “The Unreasonable Effectiveness of Mathematics in the Natural Sciences” written by Nobel laureate physicist Eugene Wigner. Molinini’s cheeky response instead explored “The Unreasonable Effectiveness of Physics in Mathematics.” His surprising answer is that some laws of physics may be as incontrovertible as a mathematical theorem. “There are some principles about the world that we have to take as fundamental,” he says.</p><p>Philosophers broadly agree that mathematical truths are “necessary,” in that they have to be true in all possible worlds. Truths about nature, empirical facts, are different—they’re contingent. Light travels at a certain speed, but arguably it could have been otherwise in a differently set up universe. That is, mathematical truths have been, and will always be, true, no matter what.&nbsp;</p><p>Might there be certain laws of physics that are also “necessary” in the same way? In his paper, Molinini argues that the principle of conservation may be one such law. In physics, some properties of a system, such as energy or momentum, can’t change. A bicyclist freewheeling down a hill, for example, is converting her gravitational potential energy into movement energy, but the total amount of energy she and her bike have stays the same.</p>
          <blockquote>
<p>The universe itself is not just described by mathematics but is made of mathematics.</p>
</blockquote><p>If such conservation is “necessary,” Molinini contends, that may explain how Archimedes was able to successfully infer the truth of geometric proofs by mechanical considerations, a feat which is otherwise puzzling. The physics and the math, in this case, are two sides of the same coin: Both are true because they draw on the same fundamental principle.</p><p>Another view, famously articulated in the early 17th century by Galileo and often championed by mathematicians, is that the universe is written in the language of mathematics. That idea has ancient origins, going back to at least Pythagoras and his followers, but a more recent, and extreme, version is <a href="https://nautil.us/ingenious-max-tegmark-234731/" target="_blank" rel="noreferrer noopener">Max Tegmark</a>’s mathematical universe hypothesis, in which the universe itself is not just described by mathematics but is <a href="https://nautil.us/life-is-a-braid-in-spacetime-234729/" target="_blank" rel="noreferrer noopener"><em>made</em> of mathematics</a>.</p><p>In Tegmark’s telling, our universe is just one of an infinite number of parallel universes and all the infinite possibilities of mathematics—every theorem, every proof—are realized somewhere in this multiverse. So, no wonder physics inspires new discoveries in math—the reality physics describes is, at bottom, mathematical anyway. “There’s an intimate connection between empirical science and mathematics,” says Mark Colyvan, a philosopher at the University of Sydney who has studied the relationship between math and physics. “One conclusion one could draw is that somehow the world itself is mathematical.”</p>
          <p>In both cases, however, the mathematics of known physics is just a tiny fraction of all the mathematics out there (nearly all of which is likely to be far less interesting), so this view doesn’t really explain why math emerging from physics should be unusually rich.&nbsp;</p><p>Molinini is now challenging a popular philosophical explanation for math’s applicability, “<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0068.2010.00772.x" target="_blank" rel="noreferrer noopener">mapping</a>,” which he believes can’t account for why good math can flow from physics. Mapping suggests that math is applied to physics by turning physical concepts, like mass or separation, into mathematical entities, such as the equation for Newton’s law of gravitation, which can then be used to calculate something that is then mapped back into a physical property—for instance, the attraction between two objects. But Molinini argues that that process of mapping breaks down when one tries to reverse it to explain how math can emerge from physics.&nbsp;</p><p>There is burgeoning interest in this question from philosophers, he says, who have until now focused on the converse problem of why math can be applied to the empirical sciences.</p><p>“Modern physics is providing mathematicians with a whole host of new tools and unexpected leads,” says the London Institute’s He. “And in future, physics and math will need to work together even more closely to solve some of the biggest problems in pure math.”</p>
          <p>The Langlands program, conceived by Robert Langlands in the 1960s and often called “the grand unified theory of mathematics,” is one such area, says He. One arm of the program, the geometric Langlands, was purportedly recently settled by a team of mathematicians who presented a proof spanning five papers and 800 pages. A kernel of that proof rests on insights originally drawn from conformal field theory, a branch of physics that is a cornerstone of string theory, among other areas. He believes that mathematicians will need to draw on more physics to explore the implications of that proof, as well as to make progress on the other arms of the program.</p><p>Similarly, mathematicians have already tapped physics in their attempts to make progress on the Riemann hypothesis and Birch and Swinnerton-Dyer conjecture—two of the most challenging open problems in math. An alliance between the two fields, suspects He, will be key to finally unlocking these behemoths.</p><p>“Physics and math are starting to become one again, like they were in Newton and Gauss’ day,” says He, who trained as a theoretical physicist but is increasingly drawn to applying physical ideas to problems in pure math.</p><p>It’s an intriguing thought. The story of the universe might be written in the language of mathematics. But beautiful as the tale seems to be, the signs are that understanding more than physicists already do will demand increasingly exotic and sophisticated mathematical tools, some of which are yet to be invented. Breaking down the barriers between the two fields could open new worlds of understanding in both.&nbsp; <img decoding="async" src="https://assets.nautil.us/sites/3/nautilus/nautilus-favicon-14.png?fm=png" alt=""></p>
          <p><em>Lead image: Art Furnace / Shutterstock</em></p>              
                            <ul>
                                      <li>
                      <div>
                        <h6>
                          Ananyo Bhattacharya                        </h6>
                        <p>
                          Posted on <time datetime="2024-09-03T10:38:54-05:00">September 3, 2024</time>
                        </p>
                      </div>
                                                <p>
                            Ananyo Bhattacharya is chief science writer at the London Institute for Mathematical Sciences. During a 15-year career in journalism, he has worked as a senior editor at <i>Nature</i> and as a science correspondent for <i>The Economist</i>. He is the author of <i><a href="https://wwnorton.com/books/the-man-from-the-future">The Man from the Future</a></i>, an intellectual biography of mathematician John von Neumann.                          </p>
                                            </li>
                                  </ul>
            <div>
  <p><img src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
    <h4>Get the Nautilus newsletter</h4>
    <p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
  </div>

  
</div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ilya Sutskever's SSI Inc raises $1B (408 pts)]]></title>
            <link>https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/</link>
            <guid>41445413</guid>
            <pubDate>Wed, 04 Sep 2024 13:17:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/">https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/</a>, See on <a href="https://news.ycombinator.com/item?id=41445413">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Small asteroid to hit Earth's atmosphere today (169 pts)]]></title>
            <link>https://earthsky.org/space/small-asteroid-hit-earth-philippines-sept-4-5-2024/</link>
            <guid>41445209</guid>
            <pubDate>Wed, 04 Sep 2024 13:03:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthsky.org/space/small-asteroid-hit-earth-philippines-sept-4-5-2024/">https://earthsky.org/space/small-asteroid-hit-earth-philippines-sept-4-5-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=41445209">Hacker News</a></p>
Couldn't get https://earthsky.org/space/small-asteroid-hit-earth-philippines-sept-4-5-2024/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[ReMarkable Paper Pro (499 pts)]]></title>
            <link>https://remarkable.com/</link>
            <guid>41444700</guid>
            <pubDate>Wed, 04 Sep 2024 12:07:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://remarkable.com/">https://remarkable.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41444700">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header data-theme="dark-neutral"><div><p>Replace your notes and printed documents with a digital notebook that feels like paper.</p><p><a data-cy="mainpage-hero-buy-now-btn" id="hero-cta-buy-btn" data-track="click" data-track-event_name="Buy Now Clicked" data-track-component_location="front page hero" data-track-link_source="/store/remarkable-paper/pro" data-track-pathname="/" data-track-text="Buy now" data-track-button_type="Buy now" href="https://remarkable.com/store/remarkable-paper/pro"><span>Buy now</span></a></p></div></header><div data-theme="dark-neutral"><h2><span>reMarkable at a glance</span></h2><ul><li><span>Paper-like writing and reading</span></li><li><span>Convert handwriting to typed text</span></li><li><span>View, sync, and refine using our apps</span></li><li><span>All your work, organized and in one place</span></li><li><span>2 weeks of battery life</span></li></ul></div><div data-theme="dark-neutral"><p><span>NEW</span></p><h2>Introducing reMarkable Paper Pro</h2><p>See big ideas come to life, and work in color with our most advanced paper tablet yet.</p><a target="_self" data-track="click" data-track-event_name="Navigate" data-track-action="open" data-track-component_location="front page video scroll with copy cta" data-track-text="Learn more" data-track-type="link" data-track-link_source="/store/remarkable-paper/pro" href="https://remarkable.com/store/remarkable-paper/pro"><span>Learn more</span></a></div><div data-theme="light-neutral"><h2>As close to paper as possible<br></h2><p>We’ve rebuilt the signature reMarkable experience so it feels more like writing on real paper than ever before. No other digital device comes close.</p><a target="_self" data-track="click" data-track-event_name="Navigate" data-track-action="open" data-track-component_location="front page video loop with copy cta" data-track-text="Why it feels like paper" data-track-type="link" data-track-link_source="/using-remarkable/paper-like-writing-and-reading/why-remarkable-paper-pro-feels-like-writing-on-paper" href="https://remarkable.com/using-remarkable/paper-like-writing-and-reading/why-remarkable-paper-pro-feels-like-writing-on-paper"><span>Why it feels like paper</span></a></div><div data-theme="light-neutral"><p>Precision on point</p><p>Our Markers are custom-made to work exclusively with the textured surface of the display, delivering a crisp paper-like feel.</p><a target="_self" data-track="click" data-track-event_name="Navigate" data-track-action="open" data-track-component_location="front page custom poster one cta" data-track-text="Explore Markers" data-track-type="link" data-track-link_source="/store/remarkable-paper/markers" href="https://remarkable.com/store/remarkable-paper/markers"><span>Explore Markers</span></a></div><div data-theme="light-red"><p><h2>Like paper. Only better.</h2></p><p>Enjoy the elegance and simplicity of paper, with all the benefits of writing by hand. Reach new levels of note-taking with powerful digital tools.</p></div><div data-theme="light-red"><div><header><div><h2>Your eyes will appreciate it...</h2><p>The new Canvas <!-- -->Color<!-- --> display reflects natural light, making for a comfortable reading experience, even in direct sunlight.</p><a target="_self" data-track="click" data-track-event_name="Navigate" data-track-action="open" data-track-component_location="front page custom animated image text split reading experience cta" data-track-text="Why it's better for your eyes" data-track-type="link" data-track-link_source="/using-remarkable/paper-like-writing-and-reading/why-remarkable-is-better-for-your-eyes" href="https://remarkable.com/using-remarkable/paper-like-writing-and-reading/why-remarkable-is-better-for-your-eyes"><span>Why it's better for your eyes</span></a></div></header></div><div><p>When the lights go out, an adjustable reading light provides a gentle glow so your attention stays on the page in front of you.</p></div></div><div data-theme="light-red"><p><h2>...and so will your mind</h2></p><p>No notifications, social media, or apps. Our paper tablets are all distraction-free by design, empowering you to focus on one task at a time.</p></div><div data-theme="dark-green"><div><div><picture><source media="(min-width: 1440px) and (max-width: 1919px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1024px) and (max-width: 1439px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1440&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1440&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1440&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1024&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1024&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1024&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 475px) and (max-width: 767px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=768&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=768&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=768&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1920px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(max-width: 474px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=475&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=475&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=475&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><img src="https://cdn.sanity.io/images/xpujt61d/production/09f4b21b2e46fd84126cd38d39e9d3292c2a6fc8-8256x5504.jpg?w=475&amp;q=85&amp;auto=format&amp;dpr=1" alt="A reMarkable Paper Pro with file browser showcasing organization." loading="lazy"></picture></div><div data-theme="dark-green"><h2>All your work, organized</h2><p>Virtually limitless pages to explore your ideas. Folders, tags, and search to help you stay in control and find what you need in seconds.</p></div></div><div><div><picture><source media="(min-width: 1440px) and (max-width: 1919px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1024px) and (max-width: 1439px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1440&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1440&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1440&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1024&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1024&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1024&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 475px) and (max-width: 767px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=768&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=768&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=768&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1920px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(max-width: 474px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=475&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=475&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=475&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><img src="https://cdn.sanity.io/images/xpujt61d/production/a550ab27d5a02216c8ede9e5efd067f3360d6e6f-8256x5504.jpg?rect=2042,0,4511,4444&amp;w=475&amp;q=85&amp;auto=format&amp;dpr=1" alt="A reMarkable Paper Pro, iPhone and Mac together on a desk showing syncing of content between devices." loading="lazy"></picture></div><div data-theme="dark-green"><h2>Always accessible</h2><p>View and organize your work from anywhere with our mobile and desktop apps. As a Connect subscriber, you can also take notes and edit typed text — perfect for capturing ideas on the go.</p></div></div></div><div data-theme="dark-green"><div><div><p><h2>Unlimited storage with <span><span><svg preserveAspectRatio="none" viewBox="0 0 100 100" width="100%" height="100%"><path d="M 0,50 C 25,69 75,70 100,50" fill="none" stroke-width="0.7em" vector-effect="non-scaling-stroke"></path></svg></span>Connect</span></h2></p></div><div><p>Want to do even more with your notes? With a Connect subscription, you’ll never run out of room for new ideas and can build an organized workflow that works for you.</p></div></div><picture><source media="(min-width: 1440px) and (max-width: 1919px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1024px) and (max-width: 1439px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1440&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1440&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1440&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1024&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1024&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1024&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 475px) and (max-width: 767px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=768&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=768&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=768&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1920px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(max-width: 474px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=475&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=475&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=475&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><img src="https://cdn.sanity.io/images/xpujt61d/production/c24281042ca237a598d650b6d3f4d28ce92ca06b-8057x5372.jpg?w=475&amp;q=85&amp;auto=format&amp;dpr=1" alt="A man, focused, using his reMarkable Paper Pro in a busy office environment." loading="lazy"></picture><ul><li><span>Unlimited cloud storage</span></li><li><span>Automatic sync</span></li><li><span>Create and edit in our apps</span></li><li><span>reMarkable Protection Plan</span></li><li><span>Exclusive offers</span></li></ul></div><section><div><h2>Noteworthy accessories</h2><p>Whatever your writing process looks like, we’ve got the right tools to help.</p></div><div><div><picture><source media="(min-width: 1440px) and (max-width: 1919px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1024px) and (max-width: 1439px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1440&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1440&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1440&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1024&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1024&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1024&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 475px) and (max-width: 767px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=768&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=768&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=768&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1920px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(max-width: 474px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=475&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=475&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=475&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><img src="https://cdn.sanity.io/images/xpujt61d/production/90b8612d19888348d26f444a26bf9c348290d741-1808x1893.png?w=475&amp;q=85&amp;auto=format&amp;dpr=1" alt="A Marker Plus, viewed on its own and featuring its built-in eraser." loading="lazy"></picture><div><h3>Marker Plus</h3><p>Enjoy extra comfort and realistic friction with Marker Plus. More precise and durable than ever before.</p><a target="_self" data-track="click" data-track-event_name="Navigate" data-track-action="open" data-track-component_location="front page accessories cta markers" data-track-text="Explore Markers" data-track-type="link" data-track-link_source="/store/remarkable-paper/markers" href="https://remarkable.com/store/remarkable-paper/markers"><span>Explore Markers</span></a></div></div><div><div><picture><source media="(min-width: 1440px) and (max-width: 1919px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1024px) and (max-width: 1439px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1440&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1440&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1440&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1024&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1024&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1024&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 475px) and (max-width: 767px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=768&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=768&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=768&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1920px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(max-width: 474px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=475&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=475&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=475&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><img src="https://cdn.sanity.io/images/xpujt61d/production/87c201fbb7cbef6d4cf623240ceba5d46f03c300-4000x4000.png?w=475&amp;q=85&amp;auto=format&amp;dpr=1" alt="reMarkable Paper Pro's entire Book Folio range in various colors." loading="lazy"></picture></div><div><h3>Book Folio</h3><p>Keep your paper tablet and Marker safe while working and on the go. In a range of fine materials and colors.</p></div></div></div></section><section data-theme="light-neutral"><div><p><h2>2 million users and counting...</h2></p><p>People worldwide use reMarkable to go paperless, think clearly, and capture their best ideas.</p></div><div><div><picture><source media="(min-width: 1440px) and (max-width: 1919px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1024px) and (max-width: 1439px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1440&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1440&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1440&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1024&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1024&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1024&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 475px) and (max-width: 767px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=768&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=768&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=768&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(min-width: 1920px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1920&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1920&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=1920&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><source media="(max-width: 474px)" srcset="https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=475&amp;q=85&amp;auto=format&amp;dpr=1 1x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=475&amp;sharp=20&amp;q=42&amp;auto=format&amp;dpr=2 2x,https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=475&amp;sharp=20&amp;q=28&amp;auto=format&amp;dpr=3 3x"><img src="https://cdn.sanity.io/images/xpujt61d/production/4e549e437c0d74137f7e4eddd60937f54d1f0d24-3396x1938.jpg?rect=566,0,2056,1938&amp;w=475&amp;q=85&amp;auto=format&amp;dpr=1" alt="A portrait of Kellie Gerardi" loading="lazy"></picture></div><div><blockquote><h3>“reMarkable gives me the deep focus required to work on complex problems.”</h3><p><strong>— Kellie Gerardi</strong><br><em>Astronaut, aerospace researcher,<br>and author</em></p></blockquote></div></div></section><div data-theme="dark-neutral"><h2>Still curious about reMarkable?</h2></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DAGitty – draw and analyze causal diagrams (151 pts)]]></title>
            <link>https://dagitty.net/</link>
            <guid>41443493</guid>
            <pubDate>Wed, 04 Sep 2024 09:10:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dagitty.net/">https://dagitty.net/</a>, See on <a href="https://news.ycombinator.com/item?id=41443493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


 
      <p>
        DAGitty is a browser-based environment for creating, editing, and analyzing
        causal diagrams (also known as directed acyclic graphs or causal Bayesian networks).
        The focus is on the use of causal diagrams for minimizing bias in empirical
        studies in epidemiology and other disciplines. For background information, see
        the "<a href="https://dagitty.net/learn/index.html">learn</a>" page.
      </p>

	<div>
		
		<p>
				<a href="https://github.com/jtextor/dagitty">
					<img src="https://dagitty.net/images/Rlogo.png" alt=""></a><br>
				The R package "dagitty" is available on 
				<a href="https://cran.r-project.org/web/packages/dagitty/index.html">CRAN</a> or 
				<a href="https://github.com/jtextor/dagitty">github</a>.
			</p>
	</div>

      <p>
       <a name="feedback">DAGitty</a> is developed and maintained by 
       <a href="http://johannes-textor.name/">Johannes Textor</a> 
       (<a href="https://ru.nl/icis">Institute for Computing and 
		Information Sciences</a>,
	<a href="https://www.ru.nl/">Radboud University</a>, and 
	Medical BioSciences department, <a href="https://www.radboudumc.nl/">Radboudumc</a>,
	Nijmegen, The Netherlands). 
	</p>

	<p>


Many algorithms
	implemented in DAGitty were developed in close collaboration with
	<a href="https://www.tcs.uni-luebeck.de/en/mitarbeiter/liskiewi/">Maciej Liśkiewicz</a> 
	and <a href="https://www.tcs.uni-luebeck.de/en/mitarbeiter/vanderzander/">Benito van der Zander</a>, University of Lübeck, Germany (see literature references below).
      </p>

	<p>
		DAGitty development happens 
		on <a href="https://github.com/jtextor/dagitty">github</a>. You can
		download all source code from there and also get involved. 
	</p>

      <h2>How can I get help?</h2>

	<p>
         If you encounter any problems using DAGitty, or would like to have a certain
         feature implemented, write to me on <a href="https://mastodon.social/@johannes_textor">Mastodon</a>, 
	post on <a href="https://github.com/jtextor/dagitty">github</a> 
		 or write to <em>"johannes {dot} textor {at} gmx {dot} 
         de".</em> Your feedback and bug reports are very welcome and contribute to 
         making DAGitty a better experience for everyone.
		 Past contributors are acknowledged in the <a href="https://dagitty.net/manual-3.x.pdf">manual</a>.
      </p>

      <h2>Is it free?</h2>

      <p>
        Because the main purpose of DAGitty is facilitating the use of causal models
        in empirical studies, it is and will always be Free software (both 
        "free as in beer" and "free as in speech"). You can copy, redistribute, and
        modify it under the  terms of the  
        <a href="http://www.gnu.org/licenses/gpl.html">GNU general public license</a>. 
        Enjoy!
      </p>

	<p>
		DAGitty development has been sponsored by the Leeds Institute for
		Data Analytics and by the Deutsche Forschungsgemeinschaft (DFG),
		grant <a href="http://gepris.dfg.de/gepris/projekt/273587939">273587939</a>.<br>
	</p>

	<p>
		<img src="https://dagitty.net/images/Dfg_logo_schriftzug_blau.jpg">
	</p>

      <h2>How can I cite DAGitty?</h2>

	<p>
		If you use DAGitty in your scientific work, please consider citing us:
	</p>
	  
	<p>
		Johannes Textor, Benito van der Zander, Mark K. Gilthorpe, Maciej Liskiewicz,
		George T.H. Ellison. <br>
		<a href="http://dx.doi.org/10.1093/ije/dyw341">Robust causal inference using directed acyclic graphs: the R package 'dagitty'.</a><br>
		<i>International Journal of Epidemiology</i> 45(6):1887-1894, 2016.<br>
		<a href="http://johannes-textor.name/papers/2017-ije.pdf">PDF postprint</a>
	</p>

      <h2>How can I learn more about how DAGitty works?</h2>

      <p>The algorithms used in DAGitty are described in more depth the following
         papers:</p>

      <p>
Johannes Textor, Maciej Liśkiewicz.<br>
<a href="http://www.tcs.uni-luebeck.de/downloads/papers/2011/Textor_Liskiewicz_Adjustment_Criteria_in_Causal_Diagrams_An_Algorithmic_Perspective.pdf">Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective.</a><br>
In <i>Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence (UAI 2011)</i>, pp. 681-688. AUAI press, 2011.
	  </p>
	  
	  <p>Benito van der Zander, Maciej Liśkiewicz, Johannes Textor.<br>
<a href="http://auai.org/uai2014/proceedings/individuals/286.pdf">Constructing Separators and Adjustment Sets in Ancestral Graphs.</a><br>
In <em>Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence (UAI 2014)</em>,
	pp. 907-916. AUAI Press, 2014.
	  </p>
	
<p>Benito van der Zander, Johannes Textor, Maciej Liśkiewicz.<br>
<a href="http://ijcai.org/papers15/Papers/IJCAI15-457.pdf">Efficiently Finding 
Conditional Instruments for Causal Inference.</a><br>
	In<em> Proceedings of the 24th International Joint Conference on Artificial 
	Intelligence (IJCAI 2015)</em>, pp. 3243-3249.
	AAAI Press, 2015.
	 </p>

	<p>Benito van der Zander, Maciej Liśkiewicz.<br>
	<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12363/12096">Separators and Adjustment Sets in Markov Equivalent DAGs.</a><br>
	In<em> Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence 
		(AAAI 2016)</em>, pp. 3315-3321. AAAI Press, 2016.
	 </p>	

	  <h2>What other related software is out there?</h2>

	  <p>There is currently quite a lot of activity in causal inference software. A few links:</p>
	  
	  <ul>
		<li><a href="https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-ggdag.html">ggdag</a>
			is a nice R package based on dagitty
			but tidyverse-compatible and with much better plotting functionality.</li>
		<li><a href="https://www.gerkelab.com/project/shinydag/">shinydag</a> is another GUI
			aimed at visualizing DAGs and exporting them in different publication-ready formats.</li>
		<li><a href="http://www.phil.cmu.edu/projects/tetrad/">TETRAD</a></li>
		<li><a href="http://epi.dife.de/dag/">DAG program</a> </li>
		<li><a href="http://journals.lww.com/epidem/Fulltext/2010/07000/dagR__A_Suite_of_R_Functions_for_Directed_Acyclic.26.aspx">dagR</a> </li>
		<li><a href="https://cbdrh.shinyapps.io/daggle/">daggle</a> is a shiny app where you can practice the rules of DAG-based covariate selection.</li>
		<li><a href="https://github.com/krassowski/jupyterlab-dagitty">A JupyterLab extension to render dagitty models</a></li>
	  </ul>
	  
	  <p>Please contact me if you know of other programs that should be added to this list,
		or directly submit a pull request on github.</p>

</div><div>

<!--	  
      <h2>Versions</h2>

      <p>The following versions of DAGitty are available:</p>

      <ul>
        <li><a href="development/dags.html">Development version</a> <br />
	  Recent development snapshot. May contain new 
	  features, but could also contain new bugs.</li>
        <li><a href="experimental">Experimental version</a> <br />
	  Most recent development snapshot. May not even work.</li>
        <li><a href="dags.html">3.0: Released 2019-01-09</a></li>
        <li><a href="history/v2.3/dags.html">2.3: Released 2015-08-19</a></li>
        <li><a href="history/v2.2/dags.html">2.2: Released 2014-10-30</a></li>
        <li><a href="history/v2.1/dags.html">2.1: Released 2014-02-06</a></li>
        <li><a href="history/v2.0/dags.html">2.0: Released 2013-02-12</a></li>
        <li><a href="history/v1.1/dags.html">1.1: Released 2011-11-29</a></li>
        <li><a href="history/v1.0/dags.html">1.0: Released 2011-03-24</a></li>
        <li><a href="history/v0.9b/dags.html">0.9b: Released 2010-11-24</a></li>
        <li><a href="history/v0.9a/dags.html">0.9a: Released 2010-09-01</a></li>
      </ul>
-->





      <h2>Changelog</h2>

      <p><strong>2023-10-07</strong></p>

      <p> Moved to a new webserver after 12 years.
	</p>

      <p><strong>2023-07-11</strong></p>

      <p> Version 3.1 is out, featuring selection variables.
	</p>


      <p><strong>2020-01-09</strong></p>

      <p> Version 3.0 has been released! Complete reimplementation of the interface,
		should work with mobile/touch now.</p>

      <p><strong>2018-04-04</strong></p>

      <p> Updated the development version and preparing for a long overdue release! </p>

      <p><strong>2015-08-19</strong></p>

      <p>
		Version 2.3 has been released! The most notable new feature: 
		instrumental variables.
      </p>

      <p><strong>2014-10-30</strong></p>

      <p>
		Version 2.2 has been released! 
      </p>

      <p><strong>2014-10-05</strong></p>

      <p>
	Version 2.2 is forthcoming and now available as the 
	<a href="https://dagitty.net/development/dags.html">Development version</a>. This version features
	a new, SEM-like diagram drawing style and the ability to share your DAGs 
	online.
      </p>

      <p><strong>2014-04-14</strong></p>

      <p>
	At "dagitty.net/learn", I am building some interactive tutorials
	using the forthcoming version 2.1 of DAGitty. That version will
	be embeddable into HTML pages, which will make it easy to include
	interactive DAG drawings into just about any webpage. Check it out!
	The first examples include an implementation of the "Simpson Machine"
	and an interactive version of a tutorial text on d-separation.
      </p>

	 <p><a href="https://dagitty.net/changelog.html">View older entries ...</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox will consider a Rust implementation of JPEG-XL (145 pts)]]></title>
            <link>https://github.com/mozilla/standards-positions/pull/1064</link>
            <guid>41443336</guid>
            <pubDate>Wed, 04 Sep 2024 08:44:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mozilla/standards-positions/pull/1064">https://github.com/mozilla/standards-positions/pull/1064</a>, See on <a href="https://news.ycombinator.com/item?id=41443336">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">Over the past few months, we’ve had some productive conversations with the JPEG-XL team at Google Research around the future of the format in Firefox. Our primary concern has long been the increased attack surface of the reference decoder (currently behind a pref in Firefox Nightly), which weighs in at more than 100,000 lines of multithreaded C++. To address this concern, the team at Google has agreed to apply their subject matter expertise to build a safe, performant, compact, and compatible JPEG-XL decoder in Rust, and integrate this decoder into Firefox. If they successfully contribute an implementation that satisfies these properties and meets our normal production requirements, we would ship it.</p>
<p dir="auto">Time will tell whether the format succeeds in becoming a universal JPEG replacement in the way some folks hope. In the event that it does, it would be unfortunate to potentially introduce memory safety vulnerabilities across the myriad of applications that would eventually need to support it. A safe, fast, and battle-tested Rust decoder from the original team could make that scenario much less likely, and so we’re using our leverage to encourage progress on this front.</p>
<p dir="auto">Previous discussion in <a data-error-text="Failed to load title" data-id="878529179" data-permission-text="Title is private" data-url="https://github.com/mozilla/standards-positions/issues/522" data-hovercard-type="issue" data-hovercard-url="/mozilla/standards-positions/issues/522/hovercard" href="https://github.com/mozilla/standards-positions/issues/522">#522</a>.</p>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[State of S3 – Your Laptop is no Laptop anymore – a personal Rant (280 pts)]]></title>
            <link>https://blog.jeujeus.de/blog/hardware/laptops-will-not-sleep-anymore/</link>
            <guid>41442490</guid>
            <pubDate>Wed, 04 Sep 2024 06:27:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jeujeus.de/blog/hardware/laptops-will-not-sleep-anymore/">https://blog.jeujeus.de/blog/hardware/laptops-will-not-sleep-anymore/</a>, See on <a href="https://news.ycombinator.com/item?id=41442490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="skip">
			
<h2>State of S3 - Your Laptop is no Laptop anymore - a personal Rant</h2>

<ul>
	<li><time datetime="2023-10-29">29 October 2023</time></li>
	<li><a href="https://blog.jeujeus.de/tags/laptops/">laptops</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/linux/">linux</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/microsoft/">microsoft</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/modern-standby/">modern standby</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/dell/">dell</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/s0ix/">s0ix</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/s3/">s3</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/lenovo/">lenovo</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/portability/">portability</a>, </li>
	<li><a href="https://blog.jeujeus.de/tags/connected-standby/">connected standby</a></li>
</ul>

<p>In this article, I aim to take a different approach.
We will begin by defining a laptop according to my understanding.
The I will share my personal history and journey to this point, as well as my current situation with my home and work
laptops.
Using this perspective, we will explore the current dysfunctionality of the standby function in modern laptops, followed
by a discussion of why this feature still has relevance and right to exist.
Finally, we will draw conclusions on what we can learn and take away from this.</p>
<h2 id="my-definition-of-a-laptop" tabindex="-1">My Definition of a Laptop <a href="#my-definition-of-a-laptop">#</a></h2>
<p>It is a straightforward concept: a laptop, being a portable computer, should allow for easy use wherever one goes.
It is a machine that can be taken along while working, then by closing the lid put to sleep for later use.
At a later time, it should allow you to pick up where you left off.</p>
<p>However, in recent times, achieving this seemingly straightforward goal has become increasingly difficult to achieve.
If you find this hard to believe, stay tuned for more.</p>
<h2 id="my-situation-and-point-of-view" tabindex="-1">My Situation and Point of View <a href="#my-situation-and-point-of-view">#</a></h2>
<p>So, without further ado, let me begin by laying out my perspective.<br>
Throughout my professional and educational career, I have used a wide range of servers, desktops and laptops.
In my first semester at university, I began using Linux exclusively on my laptops.<br>
I was fortunate to own a Lenovo Thinkpad E470 during that period, which offered excellent Linux support.
However, this decision has had a major impact on my choice of laptops in the future.<br>
Linux support for specific components was substandard back then and remains so today.
As of today, Network Cards and dedicated Graphics Cards in Combination with internal ones (e.g. Nvidia Optimus) remain
the typical pain points.
But issues such as the requirement for complex drivers due to the current "Windows Hello"-certified IR webcams and array
microphones were not present in the past.</p>
<p>Therefore, as Lenovo was consistently praised for their exceptional Linux support, I continued purchasing their
Thinkpads such as the X240 or X380.
I only made minor adjustments, such as switching out the Wifi-NIC for an inexpensive Intel one.
My previous laptops were adequately powered Linux machines, which were reliable wherever I went.</p>
<p>My first work laptop, the Dell XPS 15 9570, was a continuation of this trend.
Despite encountering a minor obstacle regarding the proprietary fingerprint reader, which required non-existent
proprietary drivers, everything functioned seamlessly.
With more time spent on the road and working from home due to Covid, than at a docking station in the office, I have
certainly enjoyed the smooth, pain-free experience.</p>
<p>As I currently have another XPS 15 9570 for personal use, I can confirm that S3 is still supported at the time of
writing.
This is evident from the command output below, indicated by [deep].[2]</p>
<pre tabindex="0"><code>$ <span>cat</span> /sys/power/mem_sleep

s2idle <span>[</span>deep<span>]</span></code></pre>
<p>Another non-existent issue were sleep problems.
Until they hit me at the moment i received my new Work-Laptop, which was a Dell XPS 15 9500.
Let me clarify - the sleep issues are not linked to Linux and continue to occur even with my current Dell XPS 17 9720.</p>
<h2 id="the-status-quo" tabindex="-1">The Status Quo <a href="#the-status-quo">#</a></h2>
<p>What happened and why?<br>
At first glance, it seems quite simple.
For the past decade, Microsoft has been forcing the migration from S3 standby to S0 "modern standby".</p>
<p>However, there's more to this than meets the eye.
There are two questions to answer.</p>
<ul>
<li>What is modern standby and how is it implemented?</li>
<li>Why did Microsoft force the migration to "modern Standby" if it breaks standby?</li>
</ul>
<h3 id="the-technical-aspects" tabindex="-1">The technical Aspects <a href="#the-technical-aspects">#</a></h3>
<p>Traditional Sleep requires all system hardware and software components to work together.
The operating system must support Sleep, as well as the hardware (e.g. CPU) and the BIOS/UEFI.
According to the UEFI to Hardware Interface Standard (ACPI), this usual form of sleep is referred to as S3.
S3 is a Sleep State in which all system components, except for the RAM and CPU Cache, are powered off.[4]
This is a good compromise between power consumption and the time required to resume from sleep.
However, it is important to note that the CPU is completely powered off.</p>
<p>Microsoft began rolling out "Modern Standby" (or S0ix) in 2012, with the ultimate goal of replacing S3 sleep.
The aim is to provide similar or improved energy savings to those of S3.
However, unlike S3, S0ix keeps the CPU and necessary system components active.
S0ix sets the CPU to a low-power idle state to reduce power usage when not in operation.</p>
<p>But why is my CPU being used when sleeping?<br>
This is where the "modern" aspect of "modern sleep" comes into play.
With the rise of smartphones and tablets, we have become accustomed to waking up quickly to get notifications, download updates or activate voice assistant services.
Microsoft aims to replicate this functionality with S0ix.[1]
Your computer should be able to allow for the usage of <em>Cortana</em> and receive Windows Updates during Sleep mode, among other features.</p>
<p>This introduction of functionality during sleep state, is the reason why Microsoft describes S3 as "Legacy Sleep".[1]
Our story would end at this point if it weren't for the complications that arise from S0ix, as indicated previously.</p>
<h3 id="the-problems" tabindex="-1">The Problems <a href="#the-problems">#</a></h3>
<p>S0ix would be great if it worked.
But unfortunately it does not - laptops die from overheating, draining their battery in the process.[1]</p>
<p>This issue is not limited to Linux, as Dell officially warns to power down your Laptop before placing it in a backpack.[7]
Which brings us back to my Definition of a Laptop from above.
This kind of defies the purpose of a Laptop in my opinion.</p>
<p>So as Microsoft themselves enforced S0ix upon us and Intel states compatibility, the cause of our problems must be the manufacturers!<br>
But Microsoft Surface Devices suffer from the same overheating and battery drain issues as well.[8]</p>
<p>It seems that even more than a decade after the migration away from legacy sleep started, there is still work left to do, smoothing out even the roughest edges.
And due to the involvement of many system components, the fixes need to be applied in the OS/Kernel, ACPI/UEFI, CPU from every vendor along the chain.</p>
<p>But we can still use S3 sleep, can we?<br>
This is the biggest bummer in my opinion, with the migration to S0ix Laptop manufacturers have began deprecating S3.
This has lead to them stopping to fix bugs and retain functionality.[2]
In the case of Dell, this has straight up lead to the complete removal of S3 from the UEFI.[3]</p>
<p>So now we have non-portable Laptops with broken S0ix and removed or broken S3.</p>
<h2 id="takeaway" tabindex="-1">Takeaway <a href="#takeaway">#</a></h2>
<p>We can only achieve advancement in regards to Sleep by adopting a new Standard which promises great features.
Therefore we need a supporter with huge market influence that can bring a potential standard to the market.
This definitely works in regard to Microsoft and i wholeheartedly support their chase of improvements.
Their aim with S0ix is relatable and can somewhat be compared to Apples move to force USB-C on everyone - which is great and a necessity to be done by a market leader.
But in Contrast, Apple kept the legacy Lightning and even brought back Magsafe (and if it only were to milk the cashcow).</p>
<p>All in All the current situation is unfeasible.
I am not certain if the current problems are related to the Limitations of x86 in comparison to ARM (A potential article could explore those).
But i can not accept a Laptop that constantly dies from overheating or greets me with a drained battery in a working environment.</p>
<p>Fortunately, S3 is still supported by CPU and some Laptop Manufacturers.
Therefore Consumers have the option to state their disapproval with the current state of S0ix by buying Laptops that still support S3.</p>
<hr>
<h3 id="sources" tabindex="-1">Sources <a href="#sources">#</a></h3>
<p><a href="https://learn.microsoft.com/en-us/windows-hardware/design/device-experiences/modern-standby" target="_blank">[1]
What is Modern Standby, Microsoft</a><br>
<a href="https://wiki.archlinux.org/title/Power_management/Suspend_and_hibernate" target="_blank">[2] Power
management/Suspend and hibernate, ArchLinuxWiki</a><br>
<a href="https://www.dell.com/support/kbdoc/en-us/000177661/what-is-modern-standby-and-how-does-it-differ-from-s3-standby" target="_blank">[3]
What is Modern Standby and how does it differ from S3 Standby , Dell</a><br>
<a href="https://uefi.org/specs/ACPI/6.5/02_Definition_of_Terms.html#sleeping-and-soft-off-state-definitions" target="_blank">[4]
ACPI Spec, Sleeping and Soft-off State Definitions, UEFI</a><br>
<a href="https://www.intel.com/content/www/us/en/docs/socwatch/user-guide/2020/s0ix-states.html" target="_blank">[5]
S0ix States , Intel</a><br>
<a href="https://lore.kernel.org/linux-acpi/20220505015814.3727692-1-rui.zhang@intel.com/" target="_blank">[6]
linux-acpi.vger.kernel.org archive mirror, Phoronix</a><br>
<a href="https://www.dell.com/community/en/conversations/xps/faq-modern-standby/647fa2d5f4ccf8a8de87e727" target="_blank">[7]
linux-acpi.vger.kernel.org archive mirror, Phoronix</a><br>
<a href="https://answers.microsoft.com/en-us/surface/forum/all/surface-laptop-3-overheats-in-sleep-mode-windows/49694ff3-8e41-4ffb-9cd5-27ea5fd054a2" target="_blank">[8]
Surface Laptop 3 overheats in Sleep mode (Windows 11), Microsoft Help</a></p>

<ul><li>Previous: <a href="https://blog.jeujeus.de/blog/security/intel-me/the-hidden-secret-computer-in-your-cpu/">MINIX - The Worlds most used Computer OS &amp; The Security Implications for your PC</a></li><li>Next: <a href="https://blog.jeujeus.de/blog/trivia/java-quirks/02-gotos/">Weird Quirks of Java - E02 - Gotos?</a></li>
</ul>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Navy chiefs conspired to get themselves illegal warship Wi-Fi (106 pts)]]></title>
            <link>https://www.navytimes.com/news/your-navy/2024/09/03/how-navy-chiefs-conspired-to-get-themselves-illegal-warship-wi-fi/</link>
            <guid>41441486</guid>
            <pubDate>Wed, 04 Sep 2024 03:03:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.navytimes.com/news/your-navy/2024/09/03/how-navy-chiefs-conspired-to-get-themselves-illegal-warship-wi-fi/">https://www.navytimes.com/news/your-navy/2024/09/03/how-navy-chiefs-conspired-to-get-themselves-illegal-warship-wi-fi/</a>, See on <a href="https://news.ycombinator.com/item?id=41441486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-chain-name="c0fUbP76WXURanD" data-gtm-name="Article Body" id="c0fUbP76WXURanD"><article><p>Today’s Navy sailors are likely familiar with the jarring loss of internet connectivity that can come with a ship’s deployment.</p><p>For a variety of reasons, including operational security, a crew’s internet access is regularly restricted while underway, to preserve bandwidth for the mission and to keep their ship safe from nefarious online attacks.</p><p>But the senior enlisted leaders among the littoral combat ship Manchester’s gold crew knew no such privation last year, when they installed and secretly used their very own Wi-Fi network during a deployment, according to a scathing internal investigation obtained by Navy Times.</p><p>As the ship prepared for a West Pacific deployment in April 2023, the enlisted leader onboard conspired with the ship’s chiefs to install the secret, unauthorized network aboard the ship, for use exclusively by them.</p><p>So while rank-and-file sailors lived without the level of internet connectivity they enjoyed ashore, the chiefs installed a Starlink satellite internet dish on the top of the ship and used a Wi-Fi network they dubbed “STINKY” to check sports scores, text home and stream movies.</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.navytimes.com/resizer/v2/YJWB534PJVGD5OWGND3QUVOMQA.png?auth=40d75011ac29600af0e0da55bd9bea3992adc5fe9a63cd7d15b777790f3651d8&amp;width=1566&amp;height=954" srcset="https://www.navytimes.com/resizer/v2/YJWB534PJVGD5OWGND3QUVOMQA.png?auth=40d75011ac29600af0e0da55bd9bea3992adc5fe9a63cd7d15b777790f3651d8&amp;width=800&amp;height=487 800w, https://www.navytimes.com/resizer/v2/YJWB534PJVGD5OWGND3QUVOMQA.png?auth=40d75011ac29600af0e0da55bd9bea3992adc5fe9a63cd7d15b777790f3651d8&amp;width=1024&amp;height=623 1024w" width="1566" height="954"></picture></figure><figcaption>An image included in a Navy investigation shows where the enlisted leadership of the littoral combat ship Manchester secretly installed a Starlink internet satellite dish on the outside of their ship last year. The red arrow was added. (Navy)</figcaption></figure><p>The enjoyment of those wireless creature comforts by enlisted leaders aboard the ship carried serious repercussions for the security of the ship and its crew.</p><p>“The danger such systems pose to the crew, the ship and the Navy cannot be understated,” the investigation notes.</p><p>Led by the senior enlisted leader of the ship’s gold crew, then-Command Senior Chief Grisel Marrero, the effort roped in the entire chiefs mess by the time it was uncovered a few months later.</p><p>Marrero was relieved in late 2023 after repeatedly misleading and lying to her ship’s command about the Wi-Fi network, and she was convicted at court-martial this spring in connection to the scheme.</p><p>She was sentenced to a reduction in rank to E-7 after the trial and did not respond to requests for comment for this report.</p><p>The Navy has yet to release the entirety of the Manchester investigation file to Navy Times, including supplemental enclosures. Such records generally include statements or interview transcripts with the accused.</p><div><h6>RELATED</h6><article itemscope="" itemtype="http://schema.org/Article" data-story-url="/news/your-navy/2024/06/03/command-senior-chief-convicted-for-unauthorized-wi-fi-on-her-ship/" data-story-id="37TMFLKO2RGV5CJ5T2KRRIHCFY" data-feature-id="false" data-story-index="1" data-promo-type="image"><div><figure label="[object Object]" type="story"><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.armytimes.com/resizer/v2/ZOVMDAUS4RAF3KBKJR3IH7IMW4.png?auth=f3f870e3d5e66f7f97a3887fbe1d7e0ad1cd21c0b67407579b4094d4943c506a&amp;width=644&amp;height=465" srcset="https://www.armytimes.com/resizer/v2/ZOVMDAUS4RAF3KBKJR3IH7IMW4.png?auth=f3f870e3d5e66f7f97a3887fbe1d7e0ad1cd21c0b67407579b4094d4943c506a&amp;width=800&amp;height=577 800w, https://www.armytimes.com/resizer/v2/ZOVMDAUS4RAF3KBKJR3IH7IMW4.png?auth=f3f870e3d5e66f7f97a3887fbe1d7e0ad1cd21c0b67407579b4094d4943c506a&amp;width=1024&amp;height=739 1024w" width="644" height="465"></picture></figure></div></article></div><p>But records released so far show the probe, which wrapped in November, found that the entire chiefs mess knew about the secret system, and those who didn’t buy into it were nonetheless culpable for not reporting the misconduct.</p><p>Those chiefs and senior chiefs who used, paid for, helped hide or knew about the system were given administrative nonjudicial punishment at commodore’s mast, according to the investigation.</p><p>All told, more than 15 Manchester chiefs were in cahoots with Marrero to purchase, install and use the Starlink system aboard the ship.</p><p>“This agreement was a criminal conspiracy, supported by the overt act of bringing the purchased Starlink onboard USS MANCHESTER,” the investigation said. “Any new member of the CPO Mess which then paid into the services joined that conspiracy following the system’s operational status.”</p><p>Records obtained by Navy Times via a Freedom of Information Act request reveal a months-long effort by Marrero to obtain, install and then conceal the chiefs Wi-Fi network from superiors, including the covert installation of a Starlink satellite dish on the outside of the Manchester.</p><p>When superiors became suspicious about the existence of the network and confronted her about it, Marrero failed to come clean on multiple occasions and provided falsified documents to further mislead Manchester’s commanding officer, the investigation states.</p><p>Unauthorized<a href="https://www.militarytimes.com/news/your-military/2023/09/12/elon-musk-blocking-starlink-to-stop-ukraine-attack-troubling-for-dod/"> Wi-Fi systems </a>like the one Marrero set up are a massive no-no for a deployed Navy ship, and Marrero’s crime occurred as the ship was deploying to the West Pacific, where such security concerns become even more paramount among heightened tensions with the Chinese.</p><p>“The installation and usage of Starlink, without the approval of higher headquarters, poses a serious risk to mission, operational security, and information security,” the investigation states.</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.navytimes.com/resizer/v2/ZOVMDAUS4RAF3KBKJR3IH7IMW4.png?auth=f3f870e3d5e66f7f97a3887fbe1d7e0ad1cd21c0b67407579b4094d4943c506a&amp;width=644&amp;height=465" srcset="https://www.navytimes.com/resizer/v2/ZOVMDAUS4RAF3KBKJR3IH7IMW4.png?auth=f3f870e3d5e66f7f97a3887fbe1d7e0ad1cd21c0b67407579b4094d4943c506a&amp;width=800&amp;height=577 800w, https://www.navytimes.com/resizer/v2/ZOVMDAUS4RAF3KBKJR3IH7IMW4.png?auth=f3f870e3d5e66f7f97a3887fbe1d7e0ad1cd21c0b67407579b4094d4943c506a&amp;width=1024&amp;height=739 1024w" width="644" height="465"></picture></figure><figcaption>Then-Command Senior Chief Grisel Marrero was court-martialed, convicted and reduced in rank to E-7 last month for setting up an unauthorized Wi-Fi system aboard the littoral combat ship Manchester. (Navy)</figcaption></figure><h2>‘Deep manipulation’ and ‘corrupt dealings’</h2><p>Marrero’s background is in Navy intelligence, and she earned a master’s degree in business administration with a concentration in information security and digital management,<a href="https://www.surfpac.navy.mil/Leaders/Biography/Article/3152697/cmdcs-swexwiwaw-grisel-marrero/"> according to her biography</a>.</p><p>The investigation notes that she should have known better.</p><p>“Her time in service and specialized training makes it clear the member knew or should have known the risks associated with an unauthorized Wi-Fi system,” the investigation states.</p><p>No officers aboard the Manchester had access to the unauthorized network, nor did any lower-ranking sailors, according to the investigation.</p><p>“The deep level of manipulation is only overshadowed by the level of corrupt dealings in which CMC Marrero used to conceal the system,” the investigation found.</p><p>While Marrero claimed the Wi-Fi system was secretly installed for morale purposes, the investigation notes that such a claim “is undermined by the selective availability of the Wi-Fi and strict control of its access to the CPO Mess only.”</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.navytimes.com/resizer/v2/K7EORVXFEFAEVKHCQTALPBG2BA.png?auth=fcdf15bf09b5d576911f7c4df36d339011d78089a4c4f4fac14ae4957a106204&amp;width=679&amp;height=279" srcset="https://www.navytimes.com/resizer/v2/K7EORVXFEFAEVKHCQTALPBG2BA.png?auth=fcdf15bf09b5d576911f7c4df36d339011d78089a4c4f4fac14ae4957a106204&amp;width=800&amp;height=328 800w, https://www.navytimes.com/resizer/v2/K7EORVXFEFAEVKHCQTALPBG2BA.png?auth=fcdf15bf09b5d576911f7c4df36d339011d78089a4c4f4fac14ae4957a106204&amp;width=1024&amp;height=420 1024w" width="679" height="279"></picture></figure><figcaption>An excerpt from the Navy's investigation into an illegal Wi-Fi network installed aboard the littoral combat ship Manchester last year. (Navy)</figcaption></figure><p>The Manchester’s secret Wi-Fi network was born in March 2023, when Marrero and a co-conspirator got to work buying and installing the Starlink system before the ship’s deployment began the following month.</p><p>The Starlink dish was installed on the Manchster’s O-5 level weatherdeck during a “blanket” aloft period, which requires a sailor to hang high above or over the side of the ship.</p><p>During a “blanket” aloft, duties are not documented in the deck logs or the officer of the deck logs, according to the investigation.</p><p>It’s unclear who harnessed up and actually installed the system for Marrero due to redactions in the publicly released copy of the probe, but records show Marrero powered up the system the night before the ship got underway to the West Pacific waters of U.S. 7th Fleet.</p><p>Marrero and her cohorts paid $2,800 for a Starlink High Performance Kit with a personal credit card, and contacted Starlink to expedite shipping so the system would arrive in time for the deployment.</p><p>Starlink offers plans ranging from $90 to $5,000 a month, and allows users to control network settings via a cell phone app. The Navy is installing such authorized capabilities aboard some ships in the fleet.</p><p>That was not the case aboard Manchester, where Marrero set up payment plans for the chief’s mess to pay for the system — either $62.50 a month or a one-time fee of $375 — that the ship’s Chief Petty Officer Association treasurer collected into a chiefs mess checking account.</p><p>Those involved also used the Chief Petty Officer Association’s debit card to pay off the $1,000 monthly Starlink bill, and Marrero warned the chiefs to only use the network in their rooms.</p><p>Marrero served as the gatekeeper of the system, records show, downloading and maintaining the Starlink app from her phone and naming it “STINKY.”</p><p>Only she could add others to the network, and would directly type the password into their devices, according to the investigation.</p><p>After Manchester got underway from San Diego, Marrero and the chiefs soon realized the Wi-Fi signal didn’t cover all areas of the ship, so the senior chief purchased signal repeaters and cable at the Navy Exchange store in Pearl Harbor, Hawaii, during a port visit in late April or early May, according to the investigation.</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.navytimes.com/resizer/v2/Q5UHJCJ3EJB7ZOEERTM7ZZKRK4.jpg?auth=dfbbeb25711b3e3f0ff19b6aea300cae4e265679d6cc7a18baf330741f3441e2&amp;width=2048&amp;height=957" srcset="https://www.navytimes.com/resizer/v2/Q5UHJCJ3EJB7ZOEERTM7ZZKRK4.jpg?auth=dfbbeb25711b3e3f0ff19b6aea300cae4e265679d6cc7a18baf330741f3441e2&amp;width=800&amp;height=373 800w, https://www.navytimes.com/resizer/v2/Q5UHJCJ3EJB7ZOEERTM7ZZKRK4.jpg?auth=dfbbeb25711b3e3f0ff19b6aea300cae4e265679d6cc7a18baf330741f3441e2&amp;width=1024&amp;height=478 1024w" width="2048" height="957"></picture></figure><figcaption>Sailors of the littoral combat ship Manchester during their underway in June 2023. (USS Manchester/Facebook)</figcaption></figure><h2>A ‘STINKY’ network</h2><p>Little stays secret within the close quarters of a deployed ship, and shortly after getting underway, scuttlebutt started swirling among some sailors about the unauthorized Wi-Fi network, the investigation states.</p><p>The ship’s former executive officer, Cmdr. Matthew Yokeley, caught wind of the rumors in May and notified the commanding officer, Cmdr. Colleen Moore.</p><p>Moore confronted Marrero about whether the chief’s mess had an unauthorized Wi-Fi network that same month.</p><p>Another unidentified crew member approached Marrero about a Wi-Fi network aboard the ship after finding available networks on a device that started with the name “STINKY.” It’s unclear who found the “STINKY” network, due to redactions.</p><p>In both instances, Marrero denied that such a Wi-Fi network existed. But she soon changed the “STINKY” Wi-Fi network name to another moniker that looked like a wireless printer — even though no such general-use wireless printers were present on the ship, the investigation found.</p><p>Moore and Yokeley conducted an inspection inside the ship but did not find any evidence of an unauthorized Wi-Fi system. They did not check the exterior of the ship.</p><p>Separately, the Navy relieved Yokeley days later on May 19, 2023. The Navy has said his relief was unrelated to Marrero’s crimes.</p><p>About a month later, in the middle of June, the unidentified crew member again confronted Marrero again about the Wi-Fi network, because junior sailors suspected the password was being hidden from them.</p><p>Once more, Marrero denied such a network existed.</p><p>That same month, Marrero seized a comment placed in the CO’s suggestion box regarding the Wi-Fi network so that it wouldn’t end up in Moore’s hands, according to the investigation.</p><p>But Moore received another comment in the suggestion box about the network weeks later, in the middle of July, and again approached Marrero about the network. Again, Marrero denied its existence.</p><p>Moore and the ship’s acting executive officer, Cmdr. Samuel Moffett, then conducted another sweep inside the ship.</p><p>Although the network that appeared to be a wireless printer appeared on their personal devices during their search, neither made additional inquiries regarding that network, according to the investigation.</p><p>Moore told the crew during an all-hands call on July 14, 2023, that no covert Wi-Fi network existed aboard the ship.</p><p>While those interviewed claimed Marrero misled the chiefs mess into thinking Moore knew about the Wi-Fi system and had signed off on it, the investigating officer wrote that such statements “lack credibility,” given that only chiefs had access to the system and Marrero renamed the network at one point.</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.navytimes.com/resizer/v2/TGMO7KKLPZDPPCPDMHLQY67FPU.jpg?auth=cd6868319efa5f4ab207170e4bebac933bec290e549eb0b4f8c3fd696687ef5a&amp;width=4606&amp;height=3290" srcset="https://www.navytimes.com/resizer/v2/TGMO7KKLPZDPPCPDMHLQY67FPU.jpg?auth=cd6868319efa5f4ab207170e4bebac933bec290e549eb0b4f8c3fd696687ef5a&amp;width=800&amp;height=571 800w, https://www.navytimes.com/resizer/v2/TGMO7KKLPZDPPCPDMHLQY67FPU.jpg?auth=cd6868319efa5f4ab207170e4bebac933bec290e549eb0b4f8c3fd696687ef5a&amp;width=1024&amp;height=731 1024w" width="4606" height="3290"></picture></figure><figcaption>Sailors aboard the littoral combat ship Manchester conduct flight operations while underway in the Pacific Ocean in July 2023. (Navy)</figcaption></figure><p>“Any reasonable Chief should have known that with those conditions, CMC Marrero’s assertions that the CO was aware and authorized the system was unreasonable,” the investigation states. “To think otherwise would mean they believed CDR Moore intentionally authorized a concealed Wi-Fi network only for the CPO Mess, excluding all others from usage.”</p><p>Weeks after the all-hands call, in August, Moore and Moffett conducted a third, internal inspection of the ship after an outgoing crew member claimed that a secret Wi-Fi network did exist.</p><h3>‘The gig is up’</h3><p>On August 18, a civilian from the Naval Information Warfare Center installing an authorized Starshield satellite communication system on the Manchester notified the officer of the deck of the chiefs mess Starlink satellite dish on the O-5 weatherdeck.</p><p>Marrero and the chief’s mess knew ahead of time that the Starshield installation near their secret Starlink dish could expose their Wi-Fi network, but they agreed to keep the dish installed, according to the investigation.</p><p>The Manchester’s combat systems officer soon took a photo of the dish, and then called in another unidentified crew member to the stateroom to ask if he or she had any knowledge of the dish. The crew member pointed the combat systems officer to Marrero, and then texted Marrero that the combat systems officer knew about the dish and had snapped a photo of it.</p><p>“The gig is up,” Marrero texted back, according to the investigation.</p><p>Marrero’s secret Starlink dish was removed the same day, and Marrero told another unidentified crew member the next day that it was authorized for in-port use — prompting sailors to re-install the illegal Starlink.</p><p>Moore learned about the Starlink dish on Aug. 24, six days after its discovery, during a conversation with the operations officer who had heard second-hand information about the presence of an unauthorized Wi-Fi network.</p><p>Moore called the combat systems officer into the stateroom to ask what they knew about the network. The combat systems officer admitted to learning about the system on Aug. 18, but said they didn’t tell Moore about it after discussions with mentors.</p><p>It’s unclear which mentors were consulted, due to redactions.</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.navytimes.com/resizer/v2/Q75UIEYZLBDVBF7N4TJNBQ7PLU.jpg?auth=cd8905d7b28340fe7921a86bf8ae98cdf8f813609495554a4956d0a93da1f15d&amp;width=5382&amp;height=3641" srcset="https://www.navytimes.com/resizer/v2/Q75UIEYZLBDVBF7N4TJNBQ7PLU.jpg?auth=cd8905d7b28340fe7921a86bf8ae98cdf8f813609495554a4956d0a93da1f15d&amp;width=800&amp;height=541 800w, https://www.navytimes.com/resizer/v2/Q75UIEYZLBDVBF7N4TJNBQ7PLU.jpg?auth=cd8905d7b28340fe7921a86bf8ae98cdf8f813609495554a4956d0a93da1f15d&amp;width=1024&amp;height=692 1024w" width="5382" height="3641"></picture></figure><figcaption>The littoral combat ship Manchester sails in the eastern Pacific Ocean in 2019. (U.S. Navy)</figcaption></figure><p>Later that day, Moore approached Marrero again about the dish and whether it belonged to the chief’s mess.</p><p>Marrero responded that she “she was not tracking” and told Moore she would hold a meeting with the chief’s mess.</p><p>During that chiefs mess meeting, Marrero told her fellow enlisted leaders that Moore knew about their secret Wi-Fi, and two chiefs subsequently removed the dish from the O-5 weatherdeck.</p><p>An unidentified chief also volunteered to take responsibility for the network.</p><p>The next day, an unidentified chief provided Moore with false statements regarding the installation of the dish, and who was responsible.</p><p>It’s unclear due to redactions if the chief was referring to themselves, or another chief. The chief also told Moore that they only used the connection while in port.</p><p>Moore remained skeptical, however, and told Marrero later she didn’t believe that.</p><p>To bolster their lie that the Wi-Fi was only used in port, Marrero and another chief altered Starlink data usage charts from the service’s website to make it look like the chiefs mess only used the Wi-Fi network in port.</p><p>“The actual, un-doctored billing cycle statements show usage while underway,” the investigation states.</p><p>Marrero then shared these fabricated charts with Moore, but Moore “did not trust the data usage charts as they appeared to be poorly doctored,” investigators wrote.</p><p>Marrero finally confessed and apologized to Moore on Aug. 26, copping to the fact that she deceived her CO throughout the entirety of the deployment.</p><p>An unidentified crew member removed the Starlink cable following that meeting, and Moore contacted leadership from Littoral Combat Ship Squadron 3 and Destroyer Squadron 7 to fill them in.</p><p>That same day, the chiefs mess also met with Moore and revealed their use of the unauthorized Wi-Fi network in port and at sea. Although Marrero initially attended the meeting, she exited after the chief’s mess requested she leave.</p><p>The chiefs handed the system over to Moffett the next day, after he and the ship’s legal officer requested they turn it over.</p><figure><figure><picture><img data-chromatic="ignore" alt="" loading="lazy" src="https://www.navytimes.com/resizer/v2/GNC4NQKXGFA4RKBWQ4VJ7KGH4I.jpg?auth=9a7430965fc463caa86d450bff41e959658a713983b43f2e10c7ab42327d9fab&amp;width=4760&amp;height=3400" srcset="https://www.navytimes.com/resizer/v2/GNC4NQKXGFA4RKBWQ4VJ7KGH4I.jpg?auth=9a7430965fc463caa86d450bff41e959658a713983b43f2e10c7ab42327d9fab&amp;width=800&amp;height=571 800w, https://www.navytimes.com/resizer/v2/GNC4NQKXGFA4RKBWQ4VJ7KGH4I.jpg?auth=9a7430965fc463caa86d450bff41e959658a713983b43f2e10c7ab42327d9fab&amp;width=1024&amp;height=731 1024w" width="4760" height="3400"></picture></figure><figcaption>The littoral combat ship Manchester's commanding officer, Cmdr. Collen Moore, right, and Cmdr. Samuel Moffett, executive officer of the ship, hail farewell to an Italian ship during the farewell formation marking the end of Multination Naval Exercise Komodo 2023 in June 2023. (U.S. Navy)</figcaption></figure><h2>‘Egregious misconduct’</h2><p>At a special court-martial in March, Marrero pleaded guilty to willful dereliction of duty charge specifications,<a href="https://www.navytimes.com/news/your-navy/2024/06/03/command-senior-chief-convicted-for-unauthorized-wi-fi-on-her-ship/"> Navy Times previously reported</a>. She also pleaded guilty to two false official statement charge specifications that involved her telling the CO that there was no Wi-Fi aboard the Manchester, according to her trial summary.</p><p>Additionally, she pleaded not guilty to an obstruction of justice charge, but was found guilty at trial, according to the trial summary record.</p><p>Marrero failed to safeguard the Manchester against operational security risks when she set up the secret Wi-Fi, the charge sheet says.</p><p>Marrero’s “egregious misconduct” with the illegal Wi-Fi “cannot be understated,” the investigating officer wrote, particularly given how Moore needed her to step up following the relief of the ship’s second-in-command that summer.</p><p>“In a time period in which the CO relied extensively on [Marrero] to recover the Command’s climate in the wake of the XO relief, CMC Marrero willfully and intentionally concealed the presence of an unauthorized system,” the investigator wrote. “Following the relief of the previous XO, it is reasonable that the level of trust and confidence with CMC Marrero increased, with heavier reliance on her to pick up the slack left behind.”</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge stops FTC from enforcing ban on non-compete agreements (173 pts)]]></title>
            <link>https://www.computerworld.com/article/3496192/court-handcuffs-employees-with-non-compete-agreements-again.html</link>
            <guid>41441159</guid>
            <pubDate>Wed, 04 Sep 2024 02:01:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.computerworld.com/article/3496192/court-handcuffs-employees-with-non-compete-agreements-again.html">https://www.computerworld.com/article/3496192/court-handcuffs-employees-with-non-compete-agreements-again.html</a>, See on <a href="https://news.ycombinator.com/item?id=41441159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p><span>opinion</span></p><p><span>Aug 29, 2024</span><span>5 mins</span></p>
		<p><span><span>Government</span></span><span><span>IT Strategy</span></span><span><span>Regulation</span></span></p></div><article id="post-3496192">
	<div>
						<div>
	<h2>
		For a brief moment, it appeared employees would no longer be locked into jobs with arbitrary, non-compete contracts. But a recent court decision has workers back in non-compete jail. 	</h2>
	
</div>					
						<div id="remove_no_follow">
		<div>




<p>I hate non-compete contracts — and I’m not alone. They restrict workers’ ability to move from job to job, which in turn reduces salaries. The only way I ever got a significant raise during my career was when I changed employers. So, when the US&nbsp;<a href="https://www.computerworld.com/article/2095092/the-end-of-non-compete-agreements-is-a-tech-job-earthquake.html">Federal Trade Commission (FTC) banned non-compete agreements</a>, I, and a few million employees, were pleased as punch.&nbsp;</p>



<p>That happiness was brief. Before the ban could even take effect on Sept. 4 (two days after Labor Day in the US), District Court Judge Ada Brown in Dallas stopped the&nbsp;<a href="https://www.cio.com/article/3489838/federal-judge-strikes-down-ftcs-ban-on-non-compete-agreements.html" target="_blank">FTC from enforcing it</a>, saying the move “exceeded its statutory authority,” was “arbitrary and capricious” and would have caused businesses “irreparable harm.”&nbsp;</p>



<p>Yeah. Right.&nbsp;</p>
</div> <!-- Closing grid grid--cols-10@md grid--cols-8@lg article-column0 -->
								
					<div>


<p>I’ve been an employee, a freelancer, and I’ve owned small businesses. Non-compete agreements have only hurt me in the first two cases, and I never found a reason as a boss for requiring my employees to sign a non-compete contract clause.</p>






<p>I know there are times when these agreements do make sense. If I invented a better mouse trap, I wouldn’t want my engineers taking the cheese to rival Acme Giant Mouse Trap Inc.&nbsp;&nbsp;But more often than not, the non-compete clauses I’ve seen are just there to trap employees.&nbsp;&nbsp;</p>



<p>You might think these things are only a pain for people like me who work in the tech and creative space. You’d be wrong.&nbsp;<a href="https://www.acslaw.org/issue_brief/briefs-landing/no-exit-understanding-employee-non-competes-and-identifying-best-practices-to-limit-their-overuse/" target="_blank" rel="noreferrer noopener">Employees also locked into their jobs</a>&nbsp;include hairdressers, janitors, security guards, and fast-food workers. Who knew that the ability to say, “Would you like fries with that?” was proprietary? Not me.</p>
</div> <!-- Closing grid grid--cols-10@md grid--cols-8@lg article-column1 -->
								
					<div>


<p>Altogether, the FTC estimated that the ban could increase workers’ earnings by at least $400 billion over the next decade, affecting about 30 million American workers. It was a nice dream while it lasted.&nbsp;</p>



<p>Essentially, Brown ruled that the federal agency lacked the statutory authority to enact such a sweeping ban and violated the US Administrative Procedures Act. She&nbsp;&nbsp;emphasized that Congress or individual states, not federal agencies, are the organizations that can regulate non-compete agreements.</p>



<p>This is all part of an overriding conservative legal argument that federal agencies have minimal powers. That wasn’t always the case.</p>
</div> <!-- Closing grid grid--cols-10@md grid--cols-8@lg article-column2 -->
								
					<div>


<p>For decades, a Supreme Court ruling in the 1984 case, <a href="https://www.hklaw.com/en/insights/publications/2024/05/us-supreme-court-may-soon-discard-or-modify-chevron-deference">Natural&nbsp;Resources Defense Council</a>, required federal courts to defer to an agency’s reasonable interpretation of an ambiguous statute that the agency was tasked with administering. This became known as the Chevron Doctrine.&nbsp;</p>



<p>I favored Chevron because, while I’m no lawyer, I know enough about regulatory law to know that the “law” usually only offers general guidelines on difficult, detailed issues. If you think, for example, your average Congresscritter has a clue about how, say,&nbsp;<a href="https://www.zdnet.com/home-and-office/networking/net-neutrality-what-it-is-and-why-were-talking-about-it-again/" target="_blank" rel="noreferrer noopener">net neutrality</a>&nbsp;really works, think again. The Federal Communications Commission (FCC) and FTC have the experts to nail the specifics; Congress doesn’t — and neither does your state legislature.&nbsp;</p>



<p>Unfortunately, the Trump-appointee-dominated Supreme Court trashed Chevron with this year’s&nbsp;<a href="https://www.scotusblog.com/case-files/cases/loper-bright-enterprises-v-raimondo/" target="_blank" rel="noreferrer noopener">Loper Bright</a> decision. And it doesn’t put the ball back in Congress’s court to make incredibly detailed laws. As the&nbsp;<a href="https://www.clearygottlieb.com/" target="_blank" rel="noreferrer noopener">Cleary Gottlieb</a>&nbsp;law firm put it, it’s now up to “<a href="https://www.clearygottlieb.com/news-and-insights/publication-listing/after-chevron-what-the-supreme-courts-loper-bright-decision-changed-and-what-it-didnt" target="_blank" rel="noreferrer noopener">federal courts to draw their own conclusions</a>&nbsp;about the correct legal interpretation of otherwise ambiguous federal statutes.”</p>
</div> <!-- Closing grid grid--cols-10@md grid--cols-8@lg article-column3 -->
								
					<div>


<p>Oh boy, judges will now get the final say on setting detailed policy. I’m thrilled. This is just another chapter in the ongoing debate over the balance of power between federal agencies and the judiciary. Given how the courts, especially the Supreme Court, have been ruling lately, I’m not a happy camper.&nbsp;&nbsp;</p>



<p>The FTC isn’t happy, either. I expect it will appeal. (I don’t have high hopes for their chances with the current Supreme Court.) In any case, the FTC will continue to address non-compete agreements through case-by-case enforcement actions. The chances it will have much success are slim, but we live in hope.&nbsp;</p>



<p>While the FTC contemplates its next steps, businesses and employees remain in a state of limbo regarding the fate of non-compete agreements. I expect businesses will hang on to their agreements until the FTC or the courts pry their cold dead fingers off them.&nbsp;</p>
</div> <!-- Closing grid grid--cols-10@md grid--cols-8@lg article-column4 -->
								
					<div>


<p>Non-compete deals, like their mirror “<a href="https://www.ncsl.org/labor-and-employment/at-will-employment-overview" target="_blank" rel="noreferrer noopener">at-will employment laws,</a>&nbsp;which give companies the right to fire employees for no reason whatsoever except for a few specific situations, put all the power in employers’ hands. It’s not fair, and it’s not right. Workers deserve the right to get the best possible deal for their labor and some semblance of job security.&nbsp;</p>



<p>Is that too much to ask for? It appears that in the United States, at least for now, it is.&nbsp;</p>
</div></div>					</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interviewing Tim Sweeney and Neal Stephenson (187 pts)]]></title>
            <link>https://www.matthewball.co/all/sweeneystephenson</link>
            <guid>41441041</guid>
            <pubDate>Wed, 04 Sep 2024 01:37:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.matthewball.co/all/sweeneystephenson">https://www.matthewball.co/all/sweeneystephenson</a>, See on <a href="https://news.ycombinator.com/item?id=41441041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="5d8e94500fa50d2aaaa7c406">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="" data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-basic-grid&quot;
}" data-animation="none">
  <article id="article-">
  
    
    
    
    <div data-layout-label="Post Body" data-type="item" id="item-669698a1967cbb646beb4b9c"><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1721149262402_12243">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png" data-image-dimensions="2330x1330" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png" width="2330" height="1330" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/317b9507-a278-4813-9de8-6b42d0249fb7/head.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-8947c6259ae836f77d4b">
  <p><em>On June 25th, I interviewed Tim Sweeney, Founder and CEO of Epic Games, which makes the Unreal Engine and Fortnite, and Neal Stephenson, the #1 New York Times bestselling author who also coined the term “Metaverse” in his 1992 bestseller Snow Crash, and is a Co-Founder of blockchain start-up Lamina1, and AI storytelling platform Whenere.</em></p><p><em>In the interview, we discuss their definitions of “Metaverse,” thoughts on its technological and economic growth, Neal’s reaction on the day Facebook changed its name to Meta, the future of Fortnite, Apple’s Vision Pro, blockchains, and the ethics of Generative AI, plus “Snow Crash 2," and much more.</em></p><p><em>My new book “</em><a href="https://www.ballmetaversebook.com/"><em>The Metaverse: Building the Spatial Internet</em></a><em>,” is now out (</em><a href="https://www.amazon.com/Metaverse-Revised-Updated-Building-Internet/dp/1324095288/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.uy5Ron_f2KFDQD8FpzhaMdBYGkkO_5_E_o_5VMaaerWTDqZuIPcnScQrYWYW8JlcZUo4zX0AgnASQgJzbnvOGr3rox5C32EWffbaYMRV8apw-Y-wo4CFfU7c8CsPkGdyQx38XpQXO9yMwYGFP7V7JY4c28QUY10kB_Cviz_z0rn7j-q-22zXcYcHubvL0Y5IfmTJsfKcBDo2LPYXIjnyJup55OVuhE3Ow7dzCFePx24.hoqaIWIaJkZ8lvcsqXsZLzXGFyWo90ID87aGBWI9yz4&amp;qid=1705767970&amp;sr=1-7"><em>Amazon</em></a><em>, </em><a href="https://books.apple.com/us/book/the-metaverse-fully-revised-and-updated-edition/id6472091681"><em>Apple</em></a><em>, </em><a href="https://www.barnesandnoble.com/w/the-metaverse-matthew-ball/1144294528?ean=9781324095286"><em>Barnes &amp; Noble</em></a><em>, </em><a href="https://bookshop.org/p/books/the-metaverse-fully-revised-and-updated-edition-building-the-spatial-internet-matthew-ball/20765623?ean=9781324095286"><em>Bookshop</em></a><em>), and is a 70% net new update to the 2022 edition, which was personally blurbed by Mark Zuckerberg, Tim Sweeney, Reed Hastings, and more, became a national bestseller in the U.S., U.K., Canada, and China, and was named a Book of the Year by The Guardian, Amazon, The Economist’s Global Business Review, and other publications. More details at </em><a href="https://www.ballmetaversebook.com/"><em>www.ballmetaversebook.com/</em></a><em>.</em></p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-8b3d5111db79c0d06fc7">
  <p><strong>Ball: Let's start at the foundation. Neal, how do you define the Metaverse in 2024?</strong></p><p><strong>Stephenson: </strong>A massively multiplayer online universe that has a sense of space to it so that there are experiences distributed around that space in a way that is perceived by all of its users in the same way. And you can move around from one place to another and interact with other users who are not physically present. It’s not controlled by any one entity; many creators, large and small, build things there.</p><p><strong>Ball: How about you, Tim? What comes to mind when you think of the word Metaverse?</strong></p><p><strong>Sweeney: </strong>Well, Neal invented the word, and so I would defer to him on that. But I will just observe that we've seen games trending in the direction of that definition for a very long time and becoming more and more close to not only Neal's definition, but kind of the spirit of what Neal wrote in <em>Snow Crash</em> and other novels. And this is what makes it timely and interesting to Epic.</p><p><strong>Ball: For many people, the word Metaverse brings to mind (if not outright requires) virtual reality goggles and augmented reality glasses. From your perspective and the Epic perspective, how central, critical, or relevant overall are goggles or glasses to the vision of the Metaverse?</strong></p><p><strong>Sweeney: </strong>Well, I think this is happening now and you don't need new hardware to experience it. Hardware getting better over time and more powerful will enhance it for sure. I think what we're seeing emerge now is to some extent, inevitable, right? As soon as people invented microelectronics, a few years later people started making video games out of parts. And as computers and consoles took off, games grew in their capabilities and then the internet came along and gaming became multiplayer. I think what we're really seeing is the inevitable evolution of gaming to take advantage of all the new capabilities that people are learning of and discovering every year.</p><p>And when we talk about the Metaverse, it's a word that kind of has a stock price. When we release something cool, it goes up and when we release something that's not cool, it goes down, but it's very much not any one company defining this. Rather we're all building towards this ideal that we and all of the players in the world are talking about and debating and discussing, and we're figuring out what it is as we go and figuring out the nuances of what makes it work and what makes it really awesome and fun.</p><p><strong>Ball: Neal you've spoken about your changing perspective on the criticality of head-mounted displays relating to the Metaverse. What's your perspective in 2024?</strong></p><p><strong>Stephenson: </strong>My overarching answer is that the actual market and actual users find ways to do things that we don't necessarily imagine in advance, just with our own limited perspective. And so cyberpunk had a whole aesthetic about it and still does, which to a large extent, revolved around having cool shit on your face. Mirror shades. Actually, one of the original anthologies of cyberpunk fiction was called Mirror Shades. And it was easy to assume back then that in order to truly experience a three-dimensional environment in an immersive way that you needed stereoscopy, you needed to have a different image slightly in each eyeball to give you a fully three-dimensional effect.</p><p>And so there's always been this linkage in people's minds between cyberspace, the Metaverse, and goggles. What we've learned is way more nuanced and interesting than that. The year after <em>Snow Crash</em> came out was when <em>Doom</em> was released, and <em>Doom</em> is the ancestor of all games that are set in immersive environments [Note: Tim is nodding]. And it didn't require stereoscopy. It was all in a screen - very low resolution by current standards - and yet, the magic of the illusion was that you were running around in this three-dimensional persistent environment. And then since then, that kind of experience has only gotten better. And in the meantime, we've been learning things about goggles, about headsets and what they are and are not good at. And it took a long time for them to get to the point where [input/output] lag was acceptable. And so there's kind of this long period of time during which video games on screens were getting much, much, much better, but the acceptance of headsets was [falling] behind, because if lag is bad, you're more prone to get sick.</p><p>One of the things that I became aware of when I was working at Magic Leap on AR headsets is that stereoscopy isn't enough. That your brain actually uses a lot of other cues other than stereoscopy to build a map of the three-dimensional world around you. And so people with one eye, one-eyed people can still perceive three-dimensionality, for example, because of these other mechanisms.</p><p>This is a kind of a long-winded way of saying that the reality we've ended up with, which didn't seem plausible in 1990 when I was writing [<em>Snow Crash</em>], is that we've got billions of people fluently navigating highly realistic, immersive, three-dimensional worlds using flat screens and keyboard and mouse.</p><p><strong>Ball: So I want to use this to jump into a related question. Since Meta's name change in 2021, there have been a number of different eulogies for the Metaverse. And so I have to ask the question starting with you, Tim, what's your perspective on the suggestion that the Metaverse is dead, duly rejected by consumers, and long since buried?</strong></p><p><strong>Sweeney: </strong>Well, I think what's been rejected is a particular vision of the Metaverse, which is people putting on VR headsets and going to the office and working with co-workers in this Silicon Valley chic art style, that was just totally lame and was never going to succeed. But on the other hand, if you look at what people are doing with their time in video games. <em>Fortnite</em> and <em>Roblox</em> and other immersive games like <em>PUBG Mobile</em> are growing at an amazing rate. People are playing them, enjoying them. You can identify now about 800 million people who engage in these kinds of experiences every month. And what they're doing is very Metaverse. They're going into a real-time, 3D environment with their friends. They're engaging in a variety of different experiences.</p><p>In <em>Fortnite</em> alone, the time is [mostly in] Battle Royale, but there are other user created things too, and other Epic created things which are consuming more and more of a fraction of people's time, and they really are traveling through virtual worlds together socially and having fun together. And it is becoming, in many ways, a new medium that is qualitatively different than the multiplayer games of the older eras like <em>Doom</em> or <em>Ultima Online</em>. What's happening now is different. Being there in 3D emoting and voice chat is, to me, that's the version of the Metaverse that's actually working. And when a company does something lame and people say "The Metaverse.... it's failed." &nbsp;No, a developer, perhaps us sometimes, just did something that was lame and that particular thing failed. But the idea goes on.</p><p>And I think overall, it's inevitable that gaming becomes more and more like this, more socially connected, more interconnected with many creators participating and what you're experiencing, and a faster number of people participating so that the internet itself or the social networks, it eventually becomes ubiquitous and everybody's there. So I think in terms of actual use and actual engagement, [the Metaverse] is going stronger than ever before, definitely stronger than last year and stronger than the year before that. And it's on the growth. But when companies try lame stuff, it's rejected however strong the reputation of the company is.</p><p><strong>Ball: So Tim's talking about lame stuff often being publicly associated with the Metaverse. Neal, I think another common association with this dystopia. That the concept of the Metaverse is inherently dystopic, or if it's not, the book that it comes from is considered dystopic. You're responsible for both. What's your perspective? Is it an inherently dystopic concept? Is that what you were trying to communicate in the book?</strong></p><p><strong>Stephenson:</strong> By the time I wrote <em>Snow Crash</em>, the dystopian elements of cyberpunk had already become so familiar and kind of shopworn that it was already a little bit of a cliche, so I didn't feel as though I could just write another one of those with a straight face. So <em>Snow Crash</em> is both a dystopian novel in some ways and a parody of the tropes of dystopian novels [Note: Tim is nodding]. It tries to be funny, which was a thing that alarmed and disconcerted some readers at the time; they didn't know what to make of that. We could get into a whole question of whether basically stable civilization of people living mostly in comfortable burbclaves is more or less dystopian than a post apocalyptic wasteland or something like that.</p><p>But I'll concede the point that that world [of <em>Snow Crash</em>] has got dystopian stuff in it. The Metaverse as shown in the book, is really neither dystopian nor utopian. It's just a communications medium that different people use in different ways. When we first see it, we're seeing kind of the schlockiest, most mass market version of it with intrusive advertisements and kind of garish lowest common denominator content. But as we get into the book, we see people using it in much more interesting ways. We see characters who've gone to a great deal of effort to build exquisite environments that they enjoy being in. We see the kind of library environment where the librarian is curating a huge storehouse of ancient information. And so I think it's possible for all of those things to be true at once, and that already we can see examples of all of those different styles of usage in the Metaverse as it's coming into existence today.</p><p><strong>Ball: So October 28th, 2021, Facebook announces it's changing its name to Meta. What did you think Neal? What was your instant response that day and a month later?</strong></p><p><strong>Stephenson: </strong>Well, I was working and I have a hobby of machining, so I was working in a machine shop on something and my phone buzzed, and it was a text message from John Gaeta, who I worked with at Magic Leap [Note: Gaeta is also a visual effects designer and inventor, and partly credited with creating Bullet Time, which won him an Oscar]. And he just sent me a text message saying, "I'm sorry for your loss." And so, I had no idea what he was talking about, and I thought, oh, some friend of his must have experienced a death in the family and he's trying to send condolences to this person but he hit the wrong button and he sent it to the wrong guy. And so I better tell John that his message didn't reach the intended recipient. So I'm sort of thumbing that out, and knowing John with a little bit of a mischievous streak, maybe I better do some Googling and catch up on current events. So that was when I became aware of the name change and understood the true meaning of John's message.</p><p>And then within 48 hours, other huge companies like Microsoft, and I think Google had also come out and said, "Oh, yeah, yeah, we are Metaverse companies too," because I think they wanted to prevent a competitor from establishing a lock on that name. And then a million smaller companies came in the wake of that saying, "Oh, well, if the next big thing is the Metaverse thing, we are now Metaverse companies." A year and a half later, they'd be calling themselves AI companies. So I just tried to take it with a little bit of a sense of humor, and as time went on, I looked for ways to see if I could create anything sustainable out of that whole scene. So that's how I ended up, for example, talking to Marc Petit [then VP and GM of Unreal Engine at Epic Games] and Patrick Cozzi [CEO/Founder of Cesium], who had been working on the idea of a decentralized open Metaverse, and I continue to be in touch with them, and have co-founded Lamina1, which is a company dedicated to building infrastructure for a decentralized open Metaverse, and building a thing called Whenere, which is the place that I would want to visit in the Metaverse.</p><p>So I just think that's the best way to deal with all that is to try to make use of the notoriety while it lasted to create some things that were sustainable. I knew that a year later there would be another fad that would knock Metaverse off the stage and become the new hot thing in tech.</p><p><strong>Ball: Neal, do you ever consider doing a sequel to <em>Snow Crash</em>? You've done sequels to a few of your books, some have been planned as multi-part entries. Is there a <em>Snow Crash</em> 2 that ever seeps into your mind?</strong></p><p><strong>Stephenson: </strong>Actually, over the last couple of years I've produced a bunch of material that I call the Extended <em>Snow Crash</em> Universe timeline, which places the events of <em>Snow Crash</em> into a specific date on the calendar, and then there's sequel and prequel material connected with that. And some of it's filling in backstory. There's this character named Lagos in the book who's an interesting guy, but we don't quite ever hear how he got involved in all this. So I've got his backstory all worked out in detail. And I also created another place in the Metaverse called Vertex4 which is more more geared towards interactive. The Black Sun and everything you read about in the book is very much, it's suitable for use in a work of written fiction. It's not actually that transferable to an interactive experience. So yeah, there's not a sequel in the sense of a written book, but there's sequel and prequel material that may break the surface in various formats as we go along.</p><p><strong>Ball: Tim, in the past you've pointed to code from the very first Unreal Tournament in 1997, making the argument that you and the company have had Metaverse ambitions for quite some time. And I know that you've been speaking about the Metaverse for at least 15 years publicly, long before the hype. I'd love to understand why do you want to build the Metaverse? Is that Epic's overarching ambition or is that just one of many goals?</strong></p><p><strong>Sweeney: </strong>I think this is the inevitable future of real-time 3D in gaming. It became apparent in the very early days of computers for me. We used to dial into bulletin boards with modems before we had the open internet and played a multi-user dungeon game and a text mode game where you joined a Unix server that was serving a dozen people at a time and you'd type commands and go from place to place. But you realized there are other people in this world and you could go up, you can have conversations with them in the world, but you could also engage in gameplay. And that was around 1985 or so.</p><p>It became apparent at that point that this was going to be the future of gaming, and that as computers became more capable and connectivity improved and graphics capabilities grew, we'd get multiplayer games where the social element would be by far the most compelling games. And it's taken a very long time to get to that point.</p>
</div><div data-block-json="{&quot;customThumbEnabled&quot;:false,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>We&amp;#39;ve had metaverse aspirations for a very, very long time. It started with text chat in realtime 3D with 300-polygon strangers. But only in recent years have a critical mass of working pieces started coming together rapidly.</p>&amp;mdash; Tim Sweeney (@TimSweeneyEpic) <a href=\&quot;https://twitter.com/TimSweeneyEpic/status/1404242449053241345?ref_src=twsrc%5Etfw\&quot;>June 14, 2021</a></blockquote> <script async src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1721146292134_14478"><blockquote><p lang="en" dir="ltr">We've had metaverse aspirations for a very, very long time. It started with text chat in realtime 3D with 300-polygon strangers. But only in recent years have a critical mass of working pieces started coming together rapidly.</p>— Tim Sweeney (@TimSweeneyEpic) <a href="https://twitter.com/TimSweeneyEpic/status/1404242449053241345?ref_src=twsrc%5Etfw">June 14, 2021</a></blockquote> </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1721146292134_14540">
  <p>From then to the first Unreal game being released was 12 years. But subsequent capabilities have taken a very long time. Ubiquitous internet connectivity of the form that can support a real-time 3D simulation at quality is a problem that took decades to solve. Being able to draw a world as realistic as the <em>Fortnite</em> Battle Royale world with 100 players participating in a simulation together took decades. There was an entire genre of games in Battle Royale that you couldn't have built a decade earlier. The technology just wasn't capable and the computers were just not fast enough.</p><p>And so a large part of this has been building up our part of civilization's technology tree, building up all of the real-time 3D features and building up all of the simulation features that are needed to run these sorts of universes. And seeing at the same time, people's expectations of the world are changing. We had the internet long before we had social networks. We had social networks long before people began joining these games and hanging out with their friends in real time 3D and voice chatting as we do now. And as each new tier of capabilities came online, we've been getting closer and closer. And I think we can finally see in <em>Fortnite</em> and <em>Roblox</em> and a few other experiences, all of the elements of the Metaverse in place, but in a very early and limited form. You see a creator tool set that's increasingly powerful like the <em>Unreal Editor for Fortnite</em> (UEFN) where people can build their own content. Over the next few years it’s going to approach the levels of AAA game development capabilities.</p><p>You have very realistic 3D graphics capabilities. You have the ability to take content that's been built for movies, take blueprints and schematics of cars that have been built for production and then bring them into real time 3D and have them work as functioning objects. And so the convergence of all these different 3D content pipelines from different industries into real time 3D, into <em>Fortnite</em>, as we've done with so many of our crossovers, is really starting to show that there's not just a bunch of games out there. There is an entire universe in which all of the world's cool ideas and brands and creators connect together into a single space and can build anything far beyond previously envisioned limits. It is going to evolve at a far faster pace than any one company could ever build anything, because there's going to be hundreds of thousands of creators each contributing their art and their code and their ideas to it, and all the world's major brands contributing their IP and their ideas and their support to it. And it's going to take on a life of its own and really quickly transcend what it is today. It's become very clear over the past few years that we're in this steep growth curve that's being driven by that. </p><p>Though there are some structural impediments in the way, for example Apple blocking <em>Fortnite</em> and blocking different development practices that are going to be absolutely necessary to create the Metaverse, the legal and technical problems are being addressed. </p><p>This medium is emerging at an astonishing rate, and I think people have no idea how awesome it's going to be by the end of this decade. But when you look at all the best capabilities of the top game engines, look at all the work being created for top movies in the film industry, all the work of all the car makers and of all the other storytellers and creators of all different kinds of games, and envision what the world is like when all of that comes together into a socially connected united economy which everybody can participate in, that's going to be a whole new world. And that's what we're very excited about.</p><p>But nobody had any clear vision of this in the 1980s, but it was obvious at that point in 1985, that the world was heading in this general direction. And for the past 33 years of Epic's history, we've been marching in this direction, figuring out exactly what the direction is as we go, but we are learning every step of the way and getting closer and closer.</p><p><strong>Stephenson: </strong>For people who never saw a <a href="https://en.wikipedia.org/wiki/Multi-user_dungeon">MUD</a> [Multi-User Dungeon], to roll the clock back a few decades, the thing about that that was mind-blowing at the time was that it's the simplest possible ASCII teletype interface, but when you were moving around that dungeon and you were in a particular location in the dungeon, if there was another player in the same location, then the system knew that, and there might be some form of interaction that could happen at that point. And as simple as it was, that was the thing that just completely blew everybody's mind. It's really the basis for anything that's happened since then in a metaverse-y kind of development path.</p>
</div><div data-block-type="5" id="block-73634500498b2cbacb2d">










































  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <a href="https://www.amazon.com/Metaverse-Revised-Updated-Building-Internet/dp/1324095288/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.uy5Ron_f2KFDQD8FpzhaMdBYGkkO_5_E_o_5VMaaerWTDqZuIPcnScQrYWYW8JlcZUo4zX0AgnASQgJzbnvOGr3rox5C32EWffbaYMRV8apw-Y-wo4CFfU7c8CsPkGdyQx38XpQXO9yMwYGFP7V7JY4c28QUY10kB_Cviz_z0rn7j-q-22zXcYcHubvL0Y5IfmTJsfKcBDo2LPYXIjnyJup55OVuhE3Ow7dzCFePx24.hoqaIWIaJkZ8lvcsqXsZLzXGFyWo90ID87aGBWI9yz4&amp;qid=1705767970&amp;sr=1-7" target="_blank" data-animation-role="image" data-description="">
            <div>
              
              
              
              
              
              
              
              <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg" data-image-dimensions="2925x2925" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg" width="2925" height="2925" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
            </div>
          
            </a>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div><p><strong><em>Now Available: </em></strong><a href="https://www.ballmetaversebook.com/" target="_blank"><strong><em>“THE METAVERSE AND BUILDING THE SPATIAL INTERNET,”</em></strong></a><em> the fully revised and updated edition of my nationally bestselling (US, UK, Canada, China) and award-winning book (Best of 2022 by Amazon, The Guardian, FT China, The Economist’s Global Business Review, Barnes &amp; Noble). Buy at </em><a href="https://a1e0.engage.squarespace-mail.com/r?m=669910fe33f7ae16c5a92821&amp;u=https%3A%2F%2Fwww.amazon.com%2FMetaverse-Revised-Updated-Building-Internet%2Fdp%2F1324095288%2Fref%3Dtmm_hrd_swatch_0%3F_encoding%3DUTF8%26dib%3DeyJ2IjoiMSJ9.uy5Ron_f2KFDQD8FpzhaMdBYGkkO_5_E_o_5VMaaerWTDqZuIPcnScQrYWYW8JlcZUo4zX0AgnASQgJzbnvOGr3rox5C32EWffbaYMRV8apw-Y-wo4CFfU7c8CsPkGdyQx38XpQXO9yMwYGFP7V7JY4c28QUY10kB_Cviz_z0rn7j-q-22zXcYcHubvL0Y5IfmTJsfKcBDo2LPYXIjnyJup55OVuhE3Ow7dzCFePx24.hoqaIWIaJkZ8lvcsqXsZLzXGFyWo90ID87aGBWI9yz4%26dib_tag%3Dse%26qid%3D1705767970%26sr%3D1-7&amp;w=5d8e9007bc3d0e18a4c49673&amp;c=b_6698fffa33f7ae16c5a8844c&amp;e=2024-07-19T12%3A56%3A42.912431Z&amp;l=en-US&amp;s=5Zov5IX7Bwnr45Hog_Mv1kklQ58%3D"><em>Amazon</em></a><em>, </em><a href="https://a1e0.engage.squarespace-mail.com/r?m=669910fe33f7ae16c5a92821&amp;u=https%3A%2F%2Fbooks.apple.com%2Fus%2Fbook%2Fthe-metaverse-fully-revised-and-updated-edition%2Fid6472091681&amp;w=5d8e9007bc3d0e18a4c49673&amp;c=b_6698fffa33f7ae16c5a8844c&amp;e=2024-07-19T12%3A56%3A42.912431Z&amp;l=en-US&amp;s=lneIDuLfKdaKZk5hcr3eNrx-31E%3D"><em>Apple</em></a><em>, </em><a href="https://a1e0.engage.squarespace-mail.com/r?m=669910fe33f7ae16c5a92821&amp;u=https%3A%2F%2Fwww.barnesandnoble.com%2Fw%2Fthe-metaverse-matthew-ball%2F1144294528%3Fean%3D9781324095286&amp;w=5d8e9007bc3d0e18a4c49673&amp;c=b_6698fffa33f7ae16c5a8844c&amp;e=2024-07-19T12%3A56%3A42.912431Z&amp;l=en-US&amp;s=EaDneLy_YrF-BbuD_LT50fg19HI%3D"><em>B&amp;N</em></a><em>, </em><a href="https://wwnorton.com/books/9781324095286" target="_blank"><em>more</em></a><em>.</em></p></div>
          </figcaption>
        

      </figure>

    

  


</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1721146292134_23193">
  <p><strong>Ball: So when I was writing this book, I was reading a bunch of Richard Bartle's old published works, and he had reported on a statistic that I thought was remarkable, which was as late as 1993, a full 10% of all global internet traffic was just for MUDs.</strong></p><p><strong>Sweeney: </strong>That was to the point where you realized that the graphics can help the experience, but they're not essential. Our brains are willing to fill in massive amounts of detail. In my memory of reading <em>Snow Crash</em>, I actually see images of it though it was just a book. From the early MUDs to playing <em>Doom</em> with 320 by 200 pixels of real estate on the screen, my memories of are in fully formed photorealistic fashion. And I think that's the big lesson that we don't need hardware that plugs into our brain and creates a sense of immersion that's indistinguishable from reality. What we can do with just the devices right in front of us is totally not the limiting factor now.</p><p><strong>Ball: Neal, I'd love to get a little bit deeper into Lamina1. You co-founded it in 2022 with one of your colleagues from Magic Leap, Rebecca Barkin. Can you explain what Lamina1 is, how it works, what it's trying to do, and its criticality to the Metaverse as you imagine it?</strong></p><p><strong>Stephenson: </strong>If we're going to have a Metaverse that millions of people use, we need to have experiences there that people enjoy having, which seemed like kind of a obvious statement to make, especially in present company. But the people who know how to make those experiences are the creators who by and large are employed in the video game industry or more and more in the motion picture and TV industry. They're the people who know how to run game engines and who know how to run the tool chains that feed assets into those engines. So the question is, what's the revenue model that allows those people to get paid? And there's various answers to that question. We have conventional payment systems that work, but in our minds, there was an overlap there with some of the qualities and capabilities of blockchain systems. And so Lamina1s a new chain that's optimized to help creators build things, to help them get paid for building things and creating experiences or components of new experiences in an open Metaverse.</p><p><strong>Ball: Crypto has become one of those more controversial elements among Metaverse aficionados. There are those who are ardent believer's in blockchain technology's criticality to the Metaverse. You have those who are entirely skeptical about the technology, not just unconvinced of its relevance. And then comparatively few people in the middle who largely say, "not sure; we'll see." What in your mind makes blockchain such a viable, helpful, if not essential technology for building an open Metaverse?</strong></p><p><strong>Stephenson: </strong>I think a lot of the skepticism and hostility that we've seen, particularly in the game development industry, just comes from this clash of mindsets between people who are strongly ideologically motivated coming out of a libertarian crypto kind of mentality, versus the people who build these experiences and who actually understand how game engines work. And there's a dream of interoperability, which is the idea that you could essentially drag and drop assets from one game into another, which is quite reasonably seen as threatening and even kind of insulting to people who spend their lives crafting beautiful AAA games. And it's also technically ridiculous. If you actually understand how these things work, you can't just take an asset from one game and somehow drop it into another. So I think that it is possible to engineer new experiences from the ground up that are designed to support interoperability and that there's some overlap between what that is going to look like and the kinds of payment systems that you can construct, and the more importantly, the smart contract systems that you can construct on top of blockchains.</p><p>For me, money is kind of the least interesting of applications on blockchains. It's the one that's gotten the most attention because they were mostly started as financial instruments. But with the rise of NFTs, we saw this idea that you could essentially put pieces of art up on a chain. And what was then discovered was that the smart contracts that governed these NFTs weren't smart, and they weren't contracts. They actually weren't enforceable. And so some work has been going on in the last couple of years to bring the NFT market into the realm of legal enforceability. The late Josh Kramer at Grapevine developed some technology in this area, but unfortunately passed away last fall. Mattereum is a company in the UK that's building royalty systems based on legitimate UK law.</p><p>And our friends at Shrapnel have been developing an actual running AAA game that embodies some of the features I'm talking about, where creators can post things on a chain that establish a kind of chain of IP development, IP ownership that's traceable, and that should in theory, allow them to get rewarded economically if their stuff succeeds. So that's I guess kind of the quick overview of a really complicated topic.</p><p><strong>Ball: Tim, I'm curious about your perspective on blockchain technologies.</strong></p><p><strong>Sweeney: </strong>The underlying idea of blockchains is awesome nerd technology. There's great use of cryptography, great protocols for distributed agreement on events, and a really interesting foundation for the future of distributed computing systems of all sorts, including the Metaverse. It strikes me as very unfortunate that it didn't have another couple decades to be nurtured in the purely nerd community before it was adopted as a financial instrument, because the currency has been greatly undermined by speculation and scams and regulatory uncertainty and so on. And I feel like it's a very unfortunate artifact of this decade. But in the future, the ideas from various blockchains such as zero knowledge proofs, the idea of cryptographic consensus protocols and so on, should be a key component of a lot of systems. And if we would only stop clawing the money and stop building financial scams around them, then they could be a great part of a future society.</p><p>I think that it takes a lot of discipline in the minds of technologists to separate the good from the bad of crypto. There is actually a great deal of good in the technology, separate from the bad uses of it that we've seen over the past, and I think we should be open-minded to the learnings to be made from there. Perhaps in a decade or two, we'll look back and be like comparing the cryptocurrency period we went through now to the 1990s dot-com crash. Underneath all of that, the internet was really solid technology and there were some companies built up in that timeframe, like Amazon actually did extremely well and thrived, but there are also scams layered on top of it. But the world recovered from that and is doing great now. And I think the world will end up on the right side of blockchain technology in the long-term future. And in the meantime, it's still a rather wild west so buyer beware. </p><p>I think the future of the Metaverse has to be built on open protocols, open standards and interoperability of all forms. We need both technological interoperability so that any creator, any hosting provider, any ecosystem operator, any brand and any content can interoperate freely without being forced into any one company's walled garden of any sorts. And this isn't really even an attempt to paint a utopian picture, but just that there are going to be lots of places in the Metaverse and a lot of these places will be owned by companies, but we mustn't allow any one company to dominate or control the thing overall. And this both goes for the underlying technology and standards, but also for commerce and notions of ownership and economic interoperability in the Metaverse.</p><p>When we designed the <em>Fortnite</em> Creator Economy 2.0, the key principle is realizing there are two things happening in the <em>Fortnite</em> economy. There is value being created through engagement, people building fun experiences. Third-party creators as well as their own teams are creating value engaging players. And because players are engaging and are happy, they're spending money in the Item Shop. And so the key became to share the Item Shop’s revenue, which is a source of spending, with experiences, which are the source of engagement, and build an economy that scales based on that. And from the very beginning, the idea was that we're operating a <em>Fortnite</em> version of this initially, but in the long run, there's no reason that this Creator Economy 2.0 couldn't be extended into a Creator Economy 3.0 where any company could participate however they choose.</p><p>And besides participating in technical standards, if another ecosystem with similar or compatible visual aesthetic and respect for games ratings and so on wanted to participate, then perhaps we could connect our economies where if you spend in the <em>Fortnite</em> Item Shop and then play in a third-party economy, then we revenue share to them. And if a third-party item shop sells something and then it's used in <em>Fortnite</em>, they revenue share to us. And just as internet hosts agree on peering arrangements to connect their fiber optic lines, that revenue sharing can enable an open Metaverse economic model. And I think this is one of the exciting things that we'll see happen within this decade. And Epic has been on a very long-term trajectory to build out all of this tech and to do it in a thoroughly open way. </p><p>We have Unreal Engine, which is a huge engine, but we expect the ultimate Metaverse technical standards will be engine agnostic and that you could participate in the open Metaverse in the game that's built using the Unity engine or the Godot permissively licensed open source engine.</p><p>And while you're doing that, you could use any number of online backends. You could use the Epic Online Services social backend for voice chat or you could use Sony's PSN or Microsoft's Xbox Live or Valve's with Steamworks. And that perhaps if these companies would actually cooperate in the right ways, then we could build an entire economy that links all the major games and all of the platforms together into an economy. I think it's actually in everybody's best interest. This isn't like the smartphone walled gardens. What's happening in the Metaverse is Metcalfe’s Law at a huge scale. Players want to be in a place where they can play with their friends. If we can connect our voice chat systems and our economies and players can move seamlessly together with their party and with their purchases where they're compatible, move from say, <em>Fortnite</em> to <em>Roblox</em> to <em>Grand Theft Auto</em> to <em>PUBG Mobile</em>, and then to a pure chat type of application as well, then the world would be a better place.</p><p>But not only that, but the companies participating would actually make more money because we'd see an engagement lift from the ability to reach more customers through this interconnected economy. And all of our competitors would gain more revenue too because of the increased opportunity they have to actually reach customers and players would play more and they would spend more, because buying an outfit in this future open Metaverse could be owning it everywhere they went and not just in the one <em>Roblox</em> experience or one <em>Fortnite</em> ecosystem that they're participating in as is currently the case. I really think that this is going to happen. And it doesn't rely on any altruism for those participants, but it's in everybody's interest and that this world of the open Metaverse will just be purely better than the separate game worlds that we have today.</p><p><strong>Stephenson: </strong>You don't want to have to stop at the exit of every Metaverse experience and take all your clothes off and then step across the threshold into a different experience and then put on the clothes that you're allowed to wear in that experience. You want to just walk through. And that seems so obvious that people just assume that's the case. It seems like you shouldn't even have to mention that, but it takes a lot of technology to actually make that work.</p><p><strong>Ball: The seventh anniversary of <em>Fortnite</em> comes up next month. Seven years from now, how do you think of <em>Fortnite</em> as being different? I think in the typical fan's perspective, <em>Fortnite</em> right now is Battle Royale, which they see primarily as a game. They see the Metaverse play primarily around UEFN. And the interaction model for UEFN feels a little bit like an app store or Netflix or YouTube. You've got thumbnails and rows and rows of them, and that's how you navigate these different 3D worlds that are lightly connected through avatars and aesthetics and user identities. What do you think the platform looks like another seven years from now? What's your dream experience?</strong></p><p><strong>Sweeney: </strong>It's going to evolve a lot. And when you look at what's in <em>Fortnite</em> today, some of it you have to recognize as artifacts of the limitations of the current technology that we're working within. Why is <em>Fortnite: Battle Royale</em> 100 players? Well, because at the time we launched it we couldn't make 200 players work on a server. Computers in the data center were just too slow. The reason we have <em>Fortnite</em> divided into a huge number of different islands, many built by third-party creators and some built by Epic, is because we don't yet have the entire technology stack needed to robustly enable every creator to put their content together into a big, seamless open world if they wanted. And so a lot of the things you see in there are not the permanent end state of what we see this medium being, but are just current crutches that we're using to hobble by as we work towards the ultimate capabilities of the thing.</p><p>And so I think we need to expect really significant changes in a number of areas. One is being able to build an interoperable economy that works with other games and other ecosystems is a key that will be really freeing for people, being all of the systems for voice chat and account interoperable, federated so that you can participate with any of the major platform company services rather than each <em>Fortnite</em> using ours and every other game using their own is going to be a key part of it. Another is the networking model, which is extremely limited. If you look at what's in Unreal Engine 5 today, it's remarkably similar to the networking model I built for Unreal Engine 1 in 1997. It shipped in <em>Unreal</em> and <em>Unreal Tournament</em>, and it's been incrementally improved ever since without dramatically upending it.</p><p>But the problem with this network model is it doesn't enable our servers to talk to each other. A <em>Fortnite</em> Battle Royale session is 100 players. There might be at peak hundreds of thousands of these servers running and there might be at peak over 10 million concurrent players online all at once, but they're each in their own separate sharded copies of the world and they can't see each other in that space. They can't go anywhere to find each other all at once. </p><p>So one of the big efforts that we're making for Unreal Engine 6 is improving the networking model, where we both have servers supporting lots of players, but also the ability to seamlessly move players between servers and to enable all the servers in a data center or in multiple data centers, to talk to each other and coordinate a simulation of the scale of millions or in the future, perhaps even a billion concurrent players. That's got to be one of the goals of the technology. Otherwise, many genres of games just can never exist because the technology isn't there to support them. And further, we've seen massively multiplayer online games that have built parts of this kind of server technology. They've done it by imposing enormous costs on every programmer who writes code for the system. As a programmer you would write your code twice, one version for doing the thing locally when the player's on your server and another for negotiating across the network when the player's on another server. Every interaction in the game devolves into this complicated networking protocol every programmer has to make work. And when they have any bugs, you see item duplication bugs and cheating and all kinds of exploits. Our aim is to build a networking model that retains the really simple Verse programming model that we have in <em>Fortnite</em> today using technology that was made practical in the early 2000's by Simon Marlow, Simon Peyton Jones and others called <a href="https://en.wikipedia.org/wiki/Software_transactional_memory">Software Transactional Memory</a>.</p><p>The idea is that you write normal code and it's our job as the implementors of the engine and the language runtime to make your code scale, so the game can run on a vast number of servers and to do all of the necessary coordination and to provide the guidelines. If you optimize your code in a certain way like you optimize for cache coherency today, then we want your game to be able to run in a much larger simulation than we're running now. This is one of our focuses for Unreal Engine 6, and it's going to consume an increasing portion of our engine team's efforts as we work on this. And the other is the ability to combine as much of the content together into a seamless world as players want. Some experiences will be better by themselves. If you want to build an awesome bespoke story-driven, single player or a co-op game, you might build it off in its own little corner of the world, no connections to the outside, but an awful lot of what we're doing would be a whole lot better if it were all seamlessly connected. </p><p>As Disneyland is itself, you get on all of these elaborate transport systems like the People Mover and the different cars go from place to place. You can go anywhere in this connected world and participate in any experience there. And what are creators doing instead of creating their own little isolated islands? They're taking over a portion of space in the world and they're defining the game roles there in different parts of space. </p><p>We've done little experiments here and there along the way. Back in <em>Fortnite</em> Chapter 2 [Note: This eight-season chapter began in October 2019 and ended December 2021], there was a period where there was a bubble appearing around certain parts of the world. It changed the gameplay in that part. Imagine that writ large in the scale of a simulation with hundreds of millions of players and hundreds of thousands of creators. </p><p>The final bit is interoperability of content and code. Battle Royale is mostly code written by Epic. Every creator's world is a mashup of their code and Epic's code. But things become really interesting when every creator's code can interoperate with every creator's code.</p><p>Everybody's out creating their own really interesting objects and creating them using protocols that are provided by the system to enable them all to work together. So you might be riding a mount or an animal built by one creator and your friend might be driving a car built by another creator. You might be carrying a weapon built by a third creator, and you might be in a world maintained by dozens of other creators, and you might be moving seamlessly from place to place with all of these interactions happening. And you really expect that to work. An awful lot of the reasons that we've built Verse and our ecosystem the way we have is to allow for these future usage cases.</p><p>If you just wanted to get <em>Roblox</em> style experience with a bunch of sharded islands deployed as quickly as possible, there were much faster ways we could have done that and much simpler trade-offs we could have made in the language and in the engine to achieve that. But we're building for the long term, and by the end of this decade I think an awful lot of this will have come to fruition and you'll see the ability of creators of all sorts to build things that are qualitatively different and better than they are today.</p><p><strong>Ball: Neal, we talked a little bit about Lamina1, and you have a novel coming out later this year that I want to get to, but you're also an advisor to Inworld.AI and a co-founder at Whenere. What are those latter two companies about?</strong></p><p><strong>Stephenson:</strong> Yeah, so this has to do with what would I want to experience in the Metaverse. - where is the first place I would go. My co-founder at Whenere is <a href="https://www.linkedin.com/in/karen-laur-7521501/" target="_blank">Karen Laur,</a> who was employee number 17 at Valve. She worked on Half-Life 1, and we ended up working together at Magic Leap building creative projects there. And towards the end of that time, we were messing around quite a bit with Sequencer, which was a component of Unreal Engine that is there to help people who want to make cinematic experiences. And through that, we got to know Kim Libreri and some of the team at the Northern California branch of Epic who were working on making Unreal Engine a tool for people who work in film and TV, not just games. And so what came out of all of that is this realization that graphics hardware and game engines have reached the point where you can now build immersive environments that most people would identify as of cinematic quality. If you're a professional movie director, you might see that it's not quite up to that level, but most people are essentially going to consider it a photorealistic environment. So that was kind of the first element of this.</p><p>And then what came on a little bit later was Inworld.AI, and they're building a system that essentially makes it easy to connect large language models on the back end to avatars in the game engine. In effect, you can use a simple interface to essentially build the brain of a character. You can specify what this character knows, what they don't know, and what their personality traits are. You can map them onto a voice from a different company. The one we are using at the moment is called ElevenLabs. And then you can wire that in to an avatar in the game engine. We're using Unreal, we're using MetaHuman, which is another kind of cinematic feature that's been added to the engine in the last few years, which basically makes it easier for people to create, again, nearly photorealistic human avatars. So what it all adds up to is that to game in Whenere, all you have to do is talk.</p><p>We have a speech-to-text subsystem in there that will transmit whatever you said to the character's brain in the backend. The brain will generate an appropriate response based on the knowledge base and the personality of that character, and send it back to the game engine as an utterance, which is it's text, it's the sound file generated by ElevenLabs, and it's a set of visemes, so the atoms of facial animation. So that the character will exhibit the right facial expressions and even the right emotional expressions that have been generated by the brain.</p><p>And we first encountered this when we were working with an internal production team at Inworld to make a character <a href="https://nealstephenson.substack.com/p/virj">Virj</a>, who was part of the extended <em>Snow Crash</em> universe timeline. And we went in sort of with modest expectations and were just astounded by how well this thing worked and how interesting the results could be. And so I think zooming out for a second, the door that this opened for us is that the way that we interact with video game worlds has tended to be pretty limited, and most games still revolve around shooting things because that is a perfect match for the UI input devices that we've got. You use a mouse to put the crosshair where you want it, you click the button to fire the weapon or whatever, and you see something happen in the world, the world responds in a way that makes sense, and that's been a very powerful UI paradigm. But here for the first time, we were able to just sit and talk like normal people to this character and have an answer back.</p><p>So based on that, we, Karen and I and Jamil Moledina co-founded Whenere last summer and we've been working since then on building a system that sits on top of Unreal Engine and on top of Inworld.AI, and its purpose is to enable users to immerse themselves in story worlds that they love. You go to Comic-Con, you go to any kind of fan environment, you see people who've traveled thousands of miles, they've spent thousands of dollars to make elaborate cosplay outfits, and it's all in the service of I love Game of Thrones or Harry Potter or Lord of the Rings or whatever, so much that I just want to spend more time in it. And we think that there's a way now to give those fans the ability to enter into such worlds, and not only to interact with them, but to mod those worlds, to come up with new ideas, new fan fiction storylines, or just to change the way the furniture's arranged or the way a character looks or talks.</p><p>So we've been working away on that since about August and have been fairly quiet up to now, but we're going to be talking about it more in the coming weeks.</p>
</div><div data-block-type="5" id="block-yui_3_17_2_1_1721146292134_41552">










































  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <a href="https://wefunder.com/whenere.inc" target="_blank" data-animation-role="image" data-description="">
            <div>
              
              
              
              
              
              
              
              <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png" data-image-dimensions="2305x1710" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png" width="2305" height="1710" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9f9c7de9-3b6e-4911-a4f3-47a8cb1ecb94/WeFunder.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
            </div>
          
            </a>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            
          </figcaption>
        

      </figure>

    

  


</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1721146292134_41905">
  <p><strong>Ball: Both of you create technology and you're also content creators. I'm interested in your perspective on AI training data and ethics. </strong></p><p><strong>Sweeney</strong>: I think that outside of universities doing research, companies shouldn't train AI on data where they don't have clear and explicit permission from the creator of the data to do that. That was granted in a way that made either ownership or the right to train clear. If a company buys ownership of the data from the creator of the data or gets permission to use it for training AI, it’s fair game. And they shouldn’t train AI on that data if they don’t have that permission. And I think we have to treat research institutions differently when they're actually doing research because there's much more compelling public interest in advancing that research. I think it's rather unfortunate that like cryptocurrency, AI has been taken over by the Wild West with companies doing things that are rather astonishing and put them at odds with all the world's creators and an awful lot of the users as well.</p><p>I think that's unfortunate because AI is a really important technology that is going to change the world. I think that after this first generation of rather wild practices fades away, we're going to see companies with a lot much more responsible data usage practices coming to the forefront and use of AI in a way that's much more well-thought-out and specialized to particular usage cases. I still think that the idea of creating a chatbot that's supposed to have all the world's knowledge and be an agent of good is a very long way from coming to fruition. And the folly of all the current efforts, both being lamed down to the point where they aren't as useful as they ought to be, but also doing things that are egregiously wrong, like telling you to eat rocks. It's kind of an artifact of this technology being adopted way too widely, way too quickly.</p><p>But I think all of this stuff would've been awesome if it were the work of researchers for another decade or so before it were treated as a serious mainstream technology. And if instead of being a commercial product that's being licensed to enterprise customers around the world, if ChatGPT were, like, some university's chatbot, with this massive disclaimer of this chatbot might make stuff up and say ridiculous things at times and it's just no big deal, don't treat it too seriously. But unfortunately, everybody in their race to have their first mover advantage has gone away from the standards that govern most forms of technology development, and that's leading to regulatory backlash and all sorts of other problems, and that's very unfortunate. But I think as optimists for the future of technology, we shouldn't let that early misadventure with AI dissuade us from the long-term value of the technology. And so I'd encourage the same sort of patience I encourage with blockchain and cryptographic technology in the field of AI.</p><p><strong>Stephenson: </strong>I was just going to say that I think a lot of this has to do with the intent or the perceived intent of the people who are building these systems. They've shown kind of a remarkable propensity for shooting themselves in the foot by making statements that are very threatening to creators. And it's strange to me that they would focus on famous actresses or artists as we're going to replace you. It's a really odd series of PR gaffes.</p><p>I'll say that as Tim says, this is going to develop more texture and complexity over time for Whenere, we wanted to avoid getting into issues around ownership of IP. And so we're starting with older books that are in the public domain. We've hired a researcher. The woman who's creating the brains of our characters is an accomplished researcher who's using open source public domain material to come up with the background information, what these characters know, what they understand, how they talk, and that's all kind of kept track of and footnoted so that we know where our training material originates from.</p><p><strong>Ball: Tim, another major gaming publisher's CEO recently said that within three years, he expects that GenAI will allow them to be 30% more efficient, expand their player network by 50% using personalization, culturalization and increased immersion, and 10 to 20% increases in ARPU. Others are more focused on creating new game genres or experiences using AI. How do you think about this tool set over the, say, longer time horizon when some of the ethics and legality and permissions are clarified, but where do you think the big opportunity is for game makers?</strong></p><p><strong>Sweeney: </strong>I think generative AI will lead to dramatic productivity gains because of the ease of creation of objects that will meet your specific needs. If you want a bunch of cool trees, you can go into the Quixel library and get a tree off the shelf from us for free for Unreal Engine use. But if you want a specific tree that meets a specific need for a specific scene in your game, you can have a modeler build it right now, and that takes an enormous amount of time and expense. In the future you're going to be able to create a mashup by giving some high-level instructions as to exactly what kind of tree you create. And based on training data that was properly owned or licensed, it will make the tree you want. I see dramatic productivity gains coming to a lot of areas of game development.</p><p>Also, I think that this will increase opportunities for all creators and increase employment opportunities in the industry as a whole, as have all other technological improvements that have come. We're going to take all the people we have and perhaps some more and build even bigger, better games using the technology. And so the technology is going to enable us to improve the scope and quality of our products and build bigger and better games. And so that will certainly come and it will come at different rates. You have to remember, the reason that we had a massive revolution in generative AI and text AI beginning last year was because of the 30 years of research that had gone into the foundations of how to train and manage those sorts of AIs.</p><p>And particularly if you read some of the papers on this technology-powered stable diffusion image generation AI, they're solving a long complicated series of differential equations at the absolute leading edge of applied mathematics because they've spent the past 20 to 30 years figuring out how to do that. This AI isn't going to come to all fields with equal speed. 3D object generation AI isn't going to be revolutionized next year. It's probably going to take many years because a lot of the things that were done for 2D have not yet been done for 3D, nor does anybody know how to do them. And so there's a huge amount of research and development effort needed to unblock AI contributing to specific fields in specific new ways and creating game content at the level of quality that you expect.</p><p>But I think this will be empowering and economically expanding and opportunity expanding for everybody in the industry. And it's very hard to predict the impact on game industry revenue or other metrics like that. But this is definitely going to bring us the capability of building better, bigger, and more compelling games faster. And because this technology will be ubiquitously available to everybody, we should expect the state of gaming to improve dramatically as a result of it. I think we should expect the entirety of the gaming economy to improve as well. Better games means players will be spending more. Better games means that companies get more returns by investing more in building games. And so you'll probably see increases in employment and you'll probably see a lifting of all ships and also an upending of a lot of things.</p><p>In the early days, Epic artists drew pixels. Nowadays, Epic artists mostly model 3D objects. And the things that people do with their mouse clicks in the future will be different things than the things they do with their mouse clicks today. But I think the value of creators will not be undermined by AI in the long run because all of these companies are competing with each other. We need a lot of humans to make a lot of awesome creative decisions about how these games are to work.</p>
</div><div data-block-type="5" id="block-997ecd084c3be8fde5dd">










































  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <a href="https://www.amazon.com/Metaverse-Revised-Updated-Building-Internet/dp/1324095288/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;dib_tag=se&amp;dib=eyJ2IjoiMSJ9.uy5Ron_f2KFDQD8FpzhaMdBYGkkO_5_E_o_5VMaaerWTDqZuIPcnScQrYWYW8JlcZUo4zX0AgnASQgJzbnvOGr3rox5C32EWffbaYMRV8apw-Y-wo4CFfU7c8CsPkGdyQx38XpQXO9yMwYGFP7V7JY4c28QUY10kB_Cviz_z0rn7j-q-22zXcYcHubvL0Y5IfmTJsfKcBDo2LPYXIjnyJup55OVuhE3Ow7dzCFePx24.hoqaIWIaJkZ8lvcsqXsZLzXGFyWo90ID87aGBWI9yz4&amp;qid=1705767970&amp;sr=1-7" target="_blank" data-animation-role="image" data-description="">
            <div>
              
              
              
              
              
              
              
              <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg" data-image-dimensions="2925x2925" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg" width="2925" height="2925" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1719155078376-LCNSCSKJAWBK6ET1J2F5/metaverse-bookshot-3.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
            </div>
          
            </a>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div><p><strong><em>Now Available: </em></strong><a href="https://www.ballmetaversebook.com/" target="_blank"><strong><em>“THE METAVERSE AND BUILDING THE SPATIAL INTERNET,”</em></strong></a><em> the fully revised and updated edition of my nationally bestselling (US, UK, Canada, China) and award-winning book (Best of 2022 by Amazon, The Guardian, FT China, The Economist’s Global Business Review, Barnes &amp; Noble). Buy at </em><a href="https://a1e0.engage.squarespace-mail.com/r?m=669910fe33f7ae16c5a92821&amp;u=https%3A%2F%2Fwww.amazon.com%2FMetaverse-Revised-Updated-Building-Internet%2Fdp%2F1324095288%2Fref%3Dtmm_hrd_swatch_0%3F_encoding%3DUTF8%26dib%3DeyJ2IjoiMSJ9.uy5Ron_f2KFDQD8FpzhaMdBYGkkO_5_E_o_5VMaaerWTDqZuIPcnScQrYWYW8JlcZUo4zX0AgnASQgJzbnvOGr3rox5C32EWffbaYMRV8apw-Y-wo4CFfU7c8CsPkGdyQx38XpQXO9yMwYGFP7V7JY4c28QUY10kB_Cviz_z0rn7j-q-22zXcYcHubvL0Y5IfmTJsfKcBDo2LPYXIjnyJup55OVuhE3Ow7dzCFePx24.hoqaIWIaJkZ8lvcsqXsZLzXGFyWo90ID87aGBWI9yz4%26dib_tag%3Dse%26qid%3D1705767970%26sr%3D1-7&amp;w=5d8e9007bc3d0e18a4c49673&amp;c=b_6698fffa33f7ae16c5a8844c&amp;e=2024-07-19T12%3A56%3A42.912431Z&amp;l=en-US&amp;s=5Zov5IX7Bwnr45Hog_Mv1kklQ58%3D"><em>Amazon</em></a><em>, </em><a href="https://a1e0.engage.squarespace-mail.com/r?m=669910fe33f7ae16c5a92821&amp;u=https%3A%2F%2Fbooks.apple.com%2Fus%2Fbook%2Fthe-metaverse-fully-revised-and-updated-edition%2Fid6472091681&amp;w=5d8e9007bc3d0e18a4c49673&amp;c=b_6698fffa33f7ae16c5a8844c&amp;e=2024-07-19T12%3A56%3A42.912431Z&amp;l=en-US&amp;s=lneIDuLfKdaKZk5hcr3eNrx-31E%3D"><em>Apple</em></a><em>, </em><a href="https://a1e0.engage.squarespace-mail.com/r?m=669910fe33f7ae16c5a92821&amp;u=https%3A%2F%2Fwww.barnesandnoble.com%2Fw%2Fthe-metaverse-matthew-ball%2F1144294528%3Fean%3D9781324095286&amp;w=5d8e9007bc3d0e18a4c49673&amp;c=b_6698fffa33f7ae16c5a8844c&amp;e=2024-07-19T12%3A56%3A42.912431Z&amp;l=en-US&amp;s=EaDneLy_YrF-BbuD_LT50fg19HI%3D"><em>B&amp;N</em></a><em>, </em><a href="https://wwnorton.com/books/9781324095286" target="_blank"><em>more</em></a><em>.</em></p></div>
          </figcaption>
        

      </figure>

    

  


</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1721221791164_20707">
  <p><strong>Ball: Neal, have you tried the Vision Pro?</strong></p><p><strong>Stephenson</strong>: No. No, I haven't.</p><p><strong>Ball: Have you tried it, Tim?</strong></p><p><strong>Sweeney: </strong>I have not.</p><p><strong>Ball: Why not?</strong></p><p><strong>Stephenson:</strong> I simply haven't had the opportunity. I literally don't know how I would go about getting access to one, other than buying one and having it shipped to me, which I wouldn't be interested in doing. My drawer is full. The drawer where I put expensive goggles that I never use.</p><p><strong>Sweeney: </strong>We're doing a lot here and I have to prioritize. That's just me personally; the Unreal Engine team is supporting Vision Pro wholeheartedly.</p><p><strong>Ball: Tim, why were your Apple and Google lawsuits so critical to constructing the Metaverse?</strong></p><p><strong>Sweeney: </strong>The Metaverse needs to evolve into a system that's way cooler and more powerful than the web. You're going to need the best capabilities of 3D engines, the best capabilities of economies, commerce and interoperability. You're going to need the best creation tools and the best creator deployment tools. And ultimately, what creators will be doing in building the Metaverse is not building a bunch of separate apps to go through Apple's approval process, but they're going to be contributing to a huge world that will evolve under extraordinarily complex rules. And it is vitally important that we not allow the gatekeepers, Apple and Google, to block progress on the Metaverse as they block progress on the web and block progress in computing in general. And the ways they do that are numerous, and they're also rather insidious. We take a lot of their past decisions for granted and don't realize how much they're undermining the quality and capabilities of the devices that we own and the capabilities that the devices we own could have if they weren't being so horrid.</p><p>For example, Apple blocks web browser choice. By blocking competing web browser engines, they block web browsers from introducing new 3D standards from optimizing performance and from creating capabilities for web apps to have the power and performance and capabilities of native apps. You're not allowed to do any of these things on the web because Apple doesn’t want web apps to compete with native apps, since they collect 30% taxes on native apps and 0% on web apps.</p><p>We should also expect the Metaverse to be an economically complex and expensive business to operate in which many creators are fully investing most of their profits or most of their revenue back into creating awesome content, with ecosystem companies, payment processors, and everybody competing with each other to offer the best value. And operating the <em>Fortnite</em> creator economy, we know that this is a very expensive thing to operate. It's not just like a game store like the Epic Games Store which sells other companies’ games. There's a massive amount of back-end services that have to be run including cloud service and hosting, content moderation and ecosystem safety costs. We're having humans intervene to make sure that what players are doing or what creators are doing are safe for everybody. There's a massive, massive set of costs.</p><p>And if you let Apple and Google set the ground rules for the Metaverse, that tax they collect at the front end is going to constitute the far, far majority of profit that will ever be made from the Metaverse. And it would just go into their stock buybacks rather than those profits going to creators to reinvest in creating content, building better stuff, and engines and payment processors and other contributors to the overall Metaverse ecosystem. It would just be collected in junk fees and dividend it out to shareholders for doing absolutely nothing, which is what Apple and Google really do for the Metaverse. Nothing at all.</p><p>And I guess equally importantly, they've placed themselves in a position of gatekeeping and saying the apps aren't allowed to do certain things. If you look at the Department of Justice's complaint against Apple, they're preventing broad categories of apps from even existing. If a US developer wanted to offer the same variety of services in the US that WeChat does in China, Apple would simply say no. They don't let you bundle together a useful app with a distribution vehicle for other companies’ apps. They don't let you advertise other companies’ apps or promote other companies’ apps. They don't allow you to run vast facets of an app economy that you'd normally have because they simply say, you cannot do this thing. There's all of that. And I don't think that the Metaverse can even exist on these mobile devices so long as they have those sorts of rules.</p><p>By imposing huge sets of rules on what their competitors are allowed to do on devices customers have bought, they can prevent entire categories of software from existing and they will prevent the Metaverse from existing to the extent that they can't fully tax it. And if it is allowed to exist in the future, then it will exist as a vassal to Apple's fiefdom.</p><p>And that's why it's so important that we win all of these fights and that world regulators and law enforcers stop these monopolies from using their control of the operating systems on these devices and over a trillion dollar digitally connected economy, which is exactly what they're doing now. Regulators are taking notice. The European Union, Japan, and UK have now passed really robust laws that will stop this, and the US is too captured by Apple at the moment to pass laws, but progress may be made and the fight continues worldwide.</p><p><strong>Ball: I have two final, more fun questions. The first time the three of us played <em>Fortnite</em>, Neal, you were Silver Surfer, Tim, you were an anthropomorphic jellyfish. Why those outfits? Neal, I'll start with you.</strong></p><p><strong>Stephenson: </strong>A Silver Surfer is just a vintage comic book character who was sort of a cult favorite. Not one of the big name comic book characters, but had a cult following. And he was sort of brooding and kind of always going on about philosophical stuff. And there was a brief moment in the 90s when somebody wanted to make an update of Silver Surfer called Cyber Surfer, and my phone rang and that project went nowhere. I never really did anything or got paid. But so just when I saw Silver Surfer come up on as a skin you could get, I just clicked on it.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1721146292134_11874">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png" data-image-dimensions="3668x2063" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png" width="3668" height="2063" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/9e422429-29d6-467b-8ff3-b7237e7873b8/new2.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1721146292134_12450">
  <p><strong>Ball: And Tim, the jellyfish?</strong></p><p><strong>Sweeney: </strong>I was on Twitter and telling a story about one of my <em>Fortnite</em> games and somebody replied saying like, "Gee, you're CEO of Epic. When you beat somebody in <em>Fortnite</em>, don't you feel bad about that? This is one of your customers, and you just caused them to lose a Battle Royale game." That made me feel bad. But when I switched to a giant jellyfish that's like a foot taller than all the other characters with giant colorful tentacles sticking out of his head, the one character in <em>Fortnite</em>, that doesn't blend into any environment we've ever had, I feel better about that. And so playing as a giant jellyfish, it's bright purple and pink, makes me feel okay about playing a Battle Royale game and perhaps defeating other people because they have plenty of notice that I'm coming.</p><p><strong>Stephenson: </strong>Oh, is it generally known that that's your outfit?</p><p><strong>Sweeney: </strong>Yeah. And basically everybody who has a jellyfish profile picture, I follow them on Twitter because we Jellies have to stick together.</p><p><strong>Ball: Speaking of things we can see a long time coming, when the Metaverse does arrive to the extent in which that's ever a definable thing, do you think we'll use the term? And if not, what will it be?</strong></p><p><strong>Sweeney: </strong>I hope so. If we use one company's word for it, if we call it <em>Fortnite</em>, then we've kind of failed to build the open version of it. So I would hope that it would actually be called the Metaverse and not some company's brand like Googling when you're searching the internet. So I hope so.</p><p><strong>Stephenson: </strong>We've kind of hit this topic previously earlier in the conversation. Matt, you were talking about is the Metaverse Dead? We see postmortems for the Metaverse. And yet on the other hand, <em>Fortnite</em> and <em>Roblox</em> and other such platforms have got vast numbers of people using them. We just don't generally refer to them as the Metaverse, but people who kind of understand the concept know that that's what they are. So I think it'll be something like that.</p><p>But it's always been the case that the new technologies have a sort of currency in the language that eventually comes to seem sort of dated. So in the 30s, radio was this amazing kind of newish thing to a lot of people. And so you can still buy a little red wagons called Radio Flyer. It's just a wagon, it has nothing to do with radio, but 100 years ago, somebody thought it would be cool to put the word radio on the wagon because it had connotations of this is the thing of the future. And we see that with internet and with a whole lot of tech buzzwords that come and go over time.</p><p><strong>Ball: Finally, Neal, it has 32 years since <em>Snow Crash</em>. We're now just a few months from your next book, which comes out October 15. What can you tell us about?</strong></p><p><strong>Neal: </strong>Yeah. It's going back to writing historical novels about science, which is something I enjoyed a lot when I wrote <em>Cryptonomicon</em> and then the <em>Baroque Cycle</em>. And so in this case, it's the beginning of a series about science, the development of physics in the 1930s and the 1940s, eventually leading up to the bomb. And in that world, there's a lot of amazing stories that for some reason haven't been told. And so I just found it to be a really exciting part of history when I started to kind of learn about it. And so each volume is going to center on a different specific character, but they all kind of know each other and they interact.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1721146292134_18882">

      

      
        <figure>
          
        
        

        
          <a href="https://www.harpercollins.com/products/polostan-neal-stephenson?variant=41314834120738" target="_blank">
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg" data-image-dimensions="1600x900" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg" width="1600" height="900" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/a14a401e-0327-4c92-855c-955fae7bd62a/GMCW3TAacAEOO1b.jpeg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          </a>
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1721146292134_19235">
  <p>So for <em>Polostan</em>, the character is a young woman who's got an American mother and a Russian father, and lives on the cultural boundary line between those two worlds during the Great Depression. She's a big fan of Bonnie and Clyde. She's a really interesting character, I think. So, yeah, that's coming out in mid-October. I'll be doing a book tour, be passing through Cary, North Carolina. So, but purchase your advanced copy now at a bookseller near you.</p><p><strong>Ball: I haven’t had a chance to read it yet, but eagerly looking forward! Tim, Neal, thanks again.</strong></p><p><strong><em>Note:</em></strong><em> This interview has been edited for clarity.</em></p><p><a href="https://a.co/d/jgB3Fxb" target="_blank"><em>“The Metaverse: Building the Spatial Internet”</em></a><em> is now available everywhere.</em></p>
</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Faster Integer Programming (153 pts)]]></title>
            <link>https://cacm.acm.org/news/faster-integer-programming/</link>
            <guid>41440842</guid>
            <pubDate>Wed, 04 Sep 2024 00:59:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cacm.acm.org/news/faster-integer-programming/">https://cacm.acm.org/news/faster-integer-programming/</a>, See on <a href="https://news.ycombinator.com/item?id=41440842">Hacker News</a></p>
Couldn't get https://cacm.acm.org/news/faster-integer-programming/: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>