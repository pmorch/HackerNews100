<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 01 Mar 2024 03:00:27 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Defcon: Preventing overload with graceful feature degradation (2023) (147 pts)]]></title>
            <link>https://www.micahlerner.com/2023/07/23/defcon-preventing-overload-with-graceful-feature-degradation.html</link>
            <guid>39554874</guid>
            <pubDate>Thu, 29 Feb 2024 20:50:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.micahlerner.com/2023/07/23/defcon-preventing-overload-with-graceful-feature-degradation.html">https://www.micahlerner.com/2023/07/23/defcon-preventing-overload-with-graceful-feature-degradation.html</a>, See on <a href="https://news.ycombinator.com/item?id=39554874">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="post-content">
<p><a href="https://www.usenix.org/conference/osdi23/presentation/meza">Defcon: Preventing Overload with Graceful Feature Degradation</a></p>
<p><em>This is one in a series of papers I’m reading from OSDI and Usenix ATC. These paper reviews can be <a href="https://newsletter.micahlerner.com/">delivered weekly to your inbox</a>, or you can subscribe to the <a href="https://www.micahlerner.com/feed.xml">Atom feed</a>. As always, feel free to reach out on <a href="https://twitter.com/micahlerner">Twitter</a> with feedback or suggestions!</em></p>
<h2 id="what-is-the-research">What is the research?</h2>
<p>Severe outages can occur due to system overload<label for="load"></label><span>Discussion of managing load <a href="https://sre.google/workbook/managing-load/">from the SRE book here</a>. </span>, impacting users who rely on a product, and potentially damaging underlying hardware<label for="failslow"></label><span>Damage to hardware can show up as <em>fail-slow</em> situations, where performance degrades overtime. This is also discussed in a previous paper review on <a href="https://www.micahlerner.com/2023/04/16/perseus-a-fail-slow-detection-framework-for-cloud-storage-systems.html">Perseus: A Fail-Slow Detection Framework for Cloud Storage Systems</a> </span>. It can also be difficult to recover from outages involving overloaded system due to additional problems this type of outages cause - in particular, <a href="https://sre.google/sre-book/addressing-cascading-failures/">cascading failures</a>. There are many potential root-causes to a system entering an overloaded state, including seasonal traffic spikes, performance regressions consuming excess capacity<label for="metastable"></label><span>This situation can lead to metastable failures, as discussed in a previous <a href="https://www.micahlerner.com/2022/07/11/metastable-failures-in-the-wild.html">paper review</a>. </span>, or subtle software bugs. As such, limiting the damage caused by overload conditions is a complicated problem.</p>
<p>To prevent overload from impacting its products, Meta developed a system called <em>Defcon</em>. Defcon provides a set of abstractions that allows incident responders to increase available capacity by turning off features, an idea called <em>graceful feature degradation</em>. By dividing product features into different levels of business criticality, Defcon also allows oncallers to take a variety actions depending on the severity of an ongoing incident.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure1.png"><figcaption></figcaption></figure>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure2.png"><figcaption></figcaption></figure>
<p>The Defcon paper describes Meta’s design, implementation, and experience deploying this system at scale across many products (including Facebook, Messenger, Instagram, and Whatsapp) along with lessons from usage during production incidents.</p>
<h2 id="background-and-motivation">Background and Motivation</h2>
<p>The authors of Defcon describe several alternatives they considered when deciding how to mitigate the risk of system overload. Each of the options is evaluated on the amount of additional resources that the approach would consume during an incident, the amount of engineering effort required to implement, and the potential impact to users.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/table1.png"><figcaption></figcaption></figure>
<p>Given that serious overload events happen on a recurring basis (at least once a year), the authors decided to invest engineering resources in an engineering-intensive effort capable of limiting user impact.</p>
<h2 id="how-does-the-system-work">How does the system work?</h2>
<p>The core abstraction in Defcon is the <em>knob</em>, which represents for each feature: a unique name, whether a feature is turned on or not, the oncall rotation responsible, and a “level” corresponding to business-criticality.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/listing1.png"><figcaption></figcaption></figure>
<figure><img src="https://www.micahlerner.com/assets/defcon/features.png"><figcaption></figcaption></figure>
<p>After a feature is defined using this configuration, servers or applications (for example, in Web or iOS devices) import the knob into code and implement code paths that handle cases when the <em>knob</em> is turned off - for example, short-circuiting expensive logic.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/listing2.png"><figcaption></figcaption></figure>
<p>During testing and incident response, operators change a <em>knob</em>’s state via a command-line or user interface, and Defcon handles replicating this state to impacted consumers (like servers and mobile applications). Knob state is also stored in a database.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure3.png"><figcaption></figcaption></figure>
<p>Defcon’s <em>Knob Actuator Service</em> propagates state changes for two types of knobs: <em>server-side knobs</em> and <em>client-side knobs</em>:</p>
<blockquote>
<p><em>Server-side knobs</em> are implemented in binaries running on the servers in data centers. The advantage of server-side knobs is that we can adjust the knobs’ state in seconds without any propagation delays.</p>
</blockquote>
<blockquote>
<p><em>Client-side knobs</em> are implemented in client code running on phones, tablets, wearables, and so on. The advantage of client-side knobs is that they have the capability to reduce network load by stopping requests sent to the server along side reducing server load due to the request.</p>
</blockquote>
<p>Client-side knobs (like those in an iOS application) are slightly more complex to update. Under normal conditions, they change via a push (called <em>Silent Push Notification (SPN)</em>) or routine pull (<em>Mobile Configuration Pull</em>) mechanism. To handle extenuating circumstances (like lower latency response to severe outages), Defcon can also instruct clients to pull a broader set of configuration stored in a specific server-location using a process called <em>Emergency Mobile Configuration</em><label for="serious"></label><span>Under normal operating conditions, a full reset isn’t used because it has the tradeoff of using more resources (in particular networking), which is unfriendly to user mobile plans and device batteries. </span>.</p>
<p>Knobs are, “grouped into three categories: (1) By service name, (2) by product name, and (3) by feature name (such as “search,” “video,” “feed,” and so on)” to simplify testing during development and post-release. Testing occurs through small scale A/B tests (where one “experiment arm” of users experience feature degradation, and the “control” arm does not) and during larger exercises that ensure the Defcon system is working (described later in the paper). These tests also have the side effect of generating data on what capacity a feature or product is using, which serves as an input to capacity planning.</p>
<p>During incidents, oncallers can also use the output of these tests to understand what the potential implications are of turning off different knobs. The</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure4.png"><figcaption></figcaption></figure>
<h2 id="how-is-the-research-evaluated">How is the research evaluated?</h2>
<p>The paper uses three main types of datasets to quantify Defcon’s changes:</p>
<ul>
<li><em>Real-time Monitoring System (RMS)</em> and <em>Resource Utilization Metric (RUM)</em>, which aim to measure utilization of Meta infrastructure. The specifics of which one to use depends on the experiment, as discussed below.</li>
<li><em>Transitive Resource Utilization (TRU)</em>, which aims to measure the downstream utilization that a service has of shared Meta systems (like its graph infrastructure described in my previous paper review on <a href="https://www.micahlerner.com/2021/10/13/tao-facebooks-distributed-data-store-for-the-social-graph.html">TAO: Facebook’s Distributed Data Store for the Social Graph</a>).</li>
<li><em>User Behavior Measurement (UBM)</em>, which tracks how changing a knob’s state impacts business metrics like “Video Watch Time”.</li>
</ul>
<p>The first evaluation of Defcon’s impact is at the Product-level. By turning off progressively more business-critical functionality, the system makes greater impact on Meta’s resource usage<label for="mips"></label><span>Represented with <em>mega-instructions per second (MIPS)</em>, a normalized resource representation corresponding to compute. </span>. Entirely turning off critical features (aka “Defcon Level 1”), saves a large amount of capacity, but also significantly impacts critical business metrics.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure8.png"><figcaption></figcaption></figure>
<figure><img src="https://www.micahlerner.com/assets/defcon/table2.png"><figcaption></figcaption></figure>
<p>Defcon is next evaluated for its ability to temporarily decrease capacity required of shared infrastructure. As discussed in a previous paper review of <a href="https://www.micahlerner.com/2021/05/31/scaling-memcache-at-facebook.html">Scaling Memcache at Facebook</a>, Meta uses Memcache extensively. By turning off optional features, oncallers are able to decrease load on this type of core system.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure9.png"><figcaption></figcaption></figure>
<p>Next, the research describes how Meta can decrease capacity requirements by turning off knobs in upstream systems with dependencies on other Meta products. For example, turning off Instagram-level knobs decreases load on Facebook, which ultimately depends on TAO, Meta’s graph service. Testing knobs outside of incident response surfaces resource requirements from these interdependencies.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure12.png"><figcaption></figcaption></figure>
<p>The Defcon paper describes a protocol for forcing Meta systems into overload conditions, and testing the impact of turning progressively more business-critical features off. By ramping user traffic to a datacenter, these experiments place increasing load on infrastructure - turning knobs off then alleviates load.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure15.png"><figcaption></figcaption></figure>
<h2 id="conclusion">Conclusion</h2>
<p>The Defcon paper describes a framework deployed at scale in Meta for disabling features in order to mitigate overload conditions. To reach this state, the authors needed to solve technical challenges of building the system and to collaborate with product teams to define feature criticality - in some ways, the latter seems even more difficult. The paper also mentions issues with maintainability of knobs. On this front, it seems like future work could automate the process of ensuring that knobs cover features inside of deployed code. Lastly, I’m looking forward to learning more about Defon’s integration with other recently published Meta research, like <a href="https://www.usenix.org/conference/osdi23/presentation/eriksen">the company’s capacity management system</a>.</p>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Did you encounter any leap year bugs today? (268 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39554539</link>
            <guid>39554539</guid>
            <pubDate>Thu, 29 Feb 2024 20:22:43 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39554539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39554915"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554915" href="https://news.ycombinator.com/vote?id=39554915&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Heard from a friend in China: the age calculation portion of the app to schedule a marriage certificate had a bug where they subtracted 22 (legal minimum age) from the year, which resulted in 2002-02-29 which doesn't exist. The app intends to compare this against the user's birth date. The error handling code assumes all errors are from the comparison. The app then rejected all marriage certificate appointments by complaining that the users are too young to marry legally.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555513"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555513" href="https://news.ycombinator.com/vote?id=39555513&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Haha, that would be quite the appropriate place to put one of those "Please wait and try again" error messages.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39556338"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556338" href="https://news.ycombinator.com/vote?id=39556338&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Now that you mention it, the payment system was not working in a ski resort restaurant in Switzerland this noon.<p>They had to switch to cash.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555303"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555303" href="https://news.ycombinator.com/vote?id=39555303&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes, I have a bot that posts daily San Francisco weather records to Mastodon. It did not post as scheduled today. This is because I am looking at all the high temperatures, low temperatures, and precipitation on today's date from 1875 (about as far back as there are digitized weather records I can work with) to the present. Since there was no such date as February 29, 1875 it is throwing an error.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554969"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554969" href="https://news.ycombinator.com/vote?id=39554969&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>No, but some of our software writes data to rotating directories named after the date, and while doing some manual debugging on a test system, it started failing to create these directories the first time it rotated on Feb 29 UTC. Turns out it just happened to run out of disk space at that time, but I had myself convinced that it was a leap year bug for over an hour. :)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554867"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554867" href="https://news.ycombinator.com/vote?id=39554867&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Yes.<p>&gt; During the morning on Thursday, no ICA store in Sweden could accept card payments. Instead, you had to use cash, Swish or pay via their app.</p><p>&gt; The reason behind the problem was an internal problem in the payment systems at ICA as a result of an extra day in February, leap day.</p><p>ICA being the biggest grocery store chain in Sweden
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555019"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555019" href="https://news.ycombinator.com/vote?id=39555019&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>This one is rather specific, but a game rhythm based Final Fantasy game called Theatrhythm Final Bar Line is simply not allowing people to play today because it has an internal system that awards prizes for specific days and they didn't handle the case of what to do when it's on a leap day. You can boot it up but can't actually play the game as a result.<p>Not working on the game or anything but found it moderately amusing as someone who owns the game!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556252"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556252" href="https://news.ycombinator.com/vote?id=39556252&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>We have a product that uses ChatGPT via the API, using the 3.5 turbo version.  Our query involves some dates.  Instead of giving back text like it usually does, today it has been giving errors because it does not think 2024-02-29 is a valid date.<p>This is easy to reproduce with the web interface, at least sometimes [0].  It start out by saying it's not a valid date and then as it's explaining why it isn't it realizes its mistake and sometimes corrects itself.</p><p>[0] <a href="https://chat.openai.com/share/37490c9f-81d6-499f-b491-11653682856c" rel="nofollow">https://chat.openai.com/share/37490c9f-81d6-499f-b491-116536...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556318"><td></td></tr>
            <tr id="39554815"><td></td></tr>
                <tr id="39555818"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555818" href="https://news.ycombinator.com/vote?id=39555818&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I'm sure it's more complicated than "we didn't think about leap years", but it certainly sounds pretty amateurish.<p>Old programmer rant: In my day, we fixed the Y2K bug - we went to the future and back several times a day!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39555430"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555430" href="https://news.ycombinator.com/vote?id=39555430&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>The other way around! Today a few services that don't congratulate me on my birthday (on non-leap years) did. I was born on February 29th.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556153"><td></td></tr>
                  <tr id="39555199"><td></td></tr>
            <tr id="39556299"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556299" href="https://news.ycombinator.com/vote?id=39556299&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I had a few [datetime].replace(year=[current year]+n) in python where n is not divisble by 4 e.g. 2,10<p>This is in code we use for scheduling
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556119"><td></td></tr>
                <tr id="39556331"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39556331" href="https://news.ycombinator.com/vote?id=39556331&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>These ones are the worst because you'd think they'd be so obvious at time of implementation. Maybe it's just me, I do a lot of comparisons and things like this always are top of mind for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39554791"><td></td></tr>
                <tr id="39555167"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555167" href="https://news.ycombinator.com/vote?id=39555167&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>That's more of a design decision than a bug. It's intentional to make the product cheaper. The manual does mention it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554924"><td></td></tr>
                <tr id="39556196"><td></td></tr>
            <tr id="39555139"><td></td></tr>
                <tr id="39556059"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39556059" href="https://news.ycombinator.com/vote?id=39556059&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Are you sure? My F91W doesn't even ask for year in settings. How would have it known it is a leap year or not.<p>Some other models (not F91W) does track year.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39556159"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39556159" href="https://news.ycombinator.com/vote?id=39556159&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I was responding to the claim about the Samsung Watch not showing the right date, I unfortunately have never owned the older kinds of "smartwatches" :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39555153"><td></td></tr>
                  <tr id="39555319"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555319" href="https://news.ycombinator.com/vote?id=39555319&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I noticed this too and clicked this thread wondering if it would show up! Still an awesome watch.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555046"><td></td></tr>
                  <tr id="39555407"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555407" href="https://news.ycombinator.com/vote?id=39555407&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I certainly did. There is a batch process to cull old records. It checks for customers who do not have a date of death recorded but are &gt; 130 years old, as it assumes that we weren't informed of their death.<p>It takes 130 years from the current date and uses that in an SQL statement to compares it to the date of birth. DB2 doesn't like 1894-02-29.</p><p>Apparently it happens every 4 years, but no-one can be bothered to fix it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39554758"><td></td></tr>
            <tr id="39554787"><td></td></tr>
                <tr id="39556157"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39556157" href="https://news.ycombinator.com/vote?id=39556157&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>What happens in a situation like this? Does the staff issue physical keys? Do the doors even have manual locks? Do the staff walk every body to their room?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39554943"><td></td></tr>
            <tr id="39554674"><td></td></tr>
                <tr id="39554976"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554976" href="https://news.ycombinator.com/vote?id=39554976&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>It's not that python doesn't have a clean way to subtract a year, it's that "subtract a year" is imprecise. There's a clean way to subtract 365 days, and there's a clean way to set the year one year earlier. But if you're doing the second thing, is python supposed to silently change to March 1 when you change the year from a leap day? There's no way around handling edge cases.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555103"><td></td></tr>
                  <tr id="39554853"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554853" href="https://news.ycombinator.com/vote?id=39554853&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>What is your definition of "subtracting a year"? Seems like that's a relatively ambiguous operation without more specification.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39554964"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39554964" href="https://news.ycombinator.com/vote?id=39554964&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Can you think of any situation where subtracting a year from today's date is ambiguous when today isn't, well, today?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556179"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39556179" href="https://news.ycombinator.com/vote?id=39556179&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Moving bank/festive holidays, first Monday of the year(, first work day of the year not Monday if that's NYD and bank holiday), lunar occasions.<p>'subtract a year' is imprecise and has many meanings, if what you want is 'same day, same month, previous year' then say that and do that, that's conceptually `date.year -= 1` not `date -= 1 year`, and will have this bug.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555345"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39555345" href="https://news.ycombinator.com/vote?id=39555345&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes - on any day, subtracting a year might mean subtracting the average length of a year (which is a bit more than 365 days), or wanting the same day and month number in the previous calendar year, or wanting the same semantic difference ("last Monday of the month in January"), to name a few possible meanings.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555652"><td></td></tr>
                  <tr id="39554958"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39554958" href="https://news.ycombinator.com/vote?id=39554958&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Since they mentioned a clean up script, I assume they could easily just use 365 days for that use case.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555068"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39555068" href="https://news.ycombinator.com/vote?id=39555068&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>But then it'll be off by one day for the rest of this year.  And someone will notice that they no longer have March 1 2023-March 1 2024 in their chart, but March 2 2023</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556284"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39556284" href="https://news.ycombinator.com/vote?id=39556284&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>It's a cleanup script. I bet nobody cares it's off by one day. Also I doubt a cleanup script has a charting function.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39555178"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555178" href="https://news.ycombinator.com/vote?id=39555178&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>&gt; now.replace(year=now.year-1)<p>Yeah but this is bad code. Python certainly does have a "clean" way to subtract a year, you subtract a datetime.timedelta object.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555346"><td></td></tr>
            <tr id="39554992"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554992" href="https://news.ycombinator.com/vote?id=39554992&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Okay I am having really odd undefined behavior in Python in UART communications that were working just fine yesterday... My boss joked it could be a leap year thing but at this point it wouldn't surprise me. Switch over to using Rust and no issues at all</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555220"><td></td></tr>
                  <tr id="39555106"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555106" href="https://news.ycombinator.com/vote?id=39555106&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I can understand getting the years 2000 (leap), 2100 (not leap), 2200 (not leap), and 2300 (not leap) wrong. But getting the year 2024 wrong is, disappointing, to put it diplomatically.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555680"><td></td></tr>
                  <tr id="39556328"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556328" href="https://news.ycombinator.com/vote?id=39556328&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I did, actually!<p>A couple date form fields on AWS had their date incorrectly set to 2024/02/28 instead of 2024/02/29. Not mission critical, but it is something :D.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556138"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556138" href="https://news.ycombinator.com/vote?id=39556138&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Gusto paycheck didn't come in until a lot later than usual... thought this might have been my last day on the job for a little bit, didn't help that my manager and I's one on one was my first meeting of the day heh.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555733"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555733" href="https://news.ycombinator.com/vote?id=39555733&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Our ETL process is heavily monitored so we never miss a days data, but we got a surprising error "cant build aggregates - missing data, aborting MV refresh, data will be a day old".
It was the year to date (YTD) calculation - no data for 29/2/2023 to compare to today.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556173"><td></td></tr>
                <tr id="39556273"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39556273" href="https://news.ycombinator.com/vote?id=39556273&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Frankly unless you've considered it ahead of time and thought you'd handled it, IMO you want the error. What's the correct thing to do here? I don't think it's necessarily -365d, it might be, but if I was GP I'd be glad for the chance to consider it and decide what's correct - instead of it just blowing up or even worse silently going whichever way's wrong and undetected for a while.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39554866"><td></td></tr>
            <tr id="39554995"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554995" href="https://news.ycombinator.com/vote?id=39554995&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Python.<pre><code>    cls = &lt;class 'datetime.datetime'&gt;, data_string = 'Feb 29 04:55:03.687' format = '%b %d %H:%M:%S.%f'
    E       ValueError: day is out of range for month</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555127"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555127" href="https://news.ycombinator.com/vote?id=39555127&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>That doesn’t seem incorrect;  given that no year is specified, it seems like it’s evaluating the constraint in the context of an implicit default year. (1970? 0CE?)<p>The confusing part, to me, is that Python would consider the above string to be parsed into a date in the first place, given that it has no year.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555848"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555848" href="https://news.ycombinator.com/vote?id=39555848&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>As mentioned by sibling comments, it's because you're not specifying a year. If you change the day to the 28th you'll see that it defaults to the year 1900:<pre><code>  &gt;&gt;&gt; datetime.strptime('Feb 28 04:55:03.687', '%b %d %H:%M:%S.%f')
  datetime.datetime(1900, 2, 28, 4, 55, 3, 687000)

  &gt;&gt;&gt; datetime.strptime('Feb 28 13:37:06.942', '%b %d %H:%M:%S.%f') 
  datetime.datetime(1900, 2, 28, 13, 37, 6, 942000)</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556222"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39556222" href="https://news.ycombinator.com/vote?id=39556222&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>That makes it weird though, because 1900 <i>was</i> a leap year? I sort of get it, but it's a slightly odd and inconsistent decision.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556333"><td></td></tr>
            <tr id="39556316"><td></td></tr>
                        <tr id="39555098"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555098" href="https://news.ycombinator.com/vote?id=39555098&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Interesting... I suppose that is because there is no year? What year does it default to? Can you show your exact line of code?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555149"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555149" href="https://news.ycombinator.com/vote?id=39555149&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>confirmed. and interesting/unexpected! this breaks:<p>datetime.strptime('Feb 29 13:37:06.942', '%b %d %H:%M:%S.%f')</p><p>edit: added code example. import datetime from datetime first obvi
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555156"><td></td></tr>
                  <tr id="39554935"><td></td></tr>
            <tr id="39554826"><td></td></tr>
            <tr id="39554831"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554831" href="https://news.ycombinator.com/vote?id=39554831&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Payroll software at work had a one-off planned maintenance day today, presumably to avoid worrying about any bugs.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555635"><td></td></tr>
            <tr id="39554925"><td></td></tr>
                  <tr id="39555298"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555298" href="https://news.ycombinator.com/vote?id=39555298&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>My suite failed this morning on an obscure test of a function that converts between ages and dates of birth. Took me ten minutes of head scratching before I realised it was Feb 29th.<p>’’’
+       if time.Now().Month() == time.February &amp;&amp; time.Now().Day() == 29 {
+               t.SkipNow()
+       }
’’’</p><p>Fixed.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555255"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555255" href="https://news.ycombinator.com/vote?id=39555255&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>We got a bunch of close-dated yogurt the other day.<p>Several were best by 2-27, 2-28, 3-01, and 3-02, but none by 2-29.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39555397"><td></td></tr>
                  <tr id="39555092"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555092" href="https://news.ycombinator.com/vote?id=39555092&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes, a few mildly bad things go wrong on a feb 29th. Everything that handles stuff a year from now for example. Pretty bad for a planning program. But our customers noticed and avoided that. Codebase is too ancient and brittle to even attempt to fix. Or at least boss doesn't want to invest time in it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555185" href="https://news.ycombinator.com/vote?id=39555185&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes, in T-Mobile billing, I tried to set up automatic payments on the 26th, but the system both told me that this was impossible (because it was "less than 2 days from the end of the month") and then accepted it, because why wouldn't it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554803"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554803" href="https://news.ycombinator.com/vote?id=39554803&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>One of the largest food store chains in Sweden had their entire card payment go down because someone forgot to handle leap years!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39554902"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554902" href="https://news.ycombinator.com/vote?id=39554902&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Wikipedia says they are "the second largest retail company in the Nordic countries[citation needed]". Pretty big company anyway and embarrassing for them. Would love to learn more about what the bug was, but I guess they will never say.<p><a href="https://en.wikipedia.org/wiki/ICA_AB" rel="nofollow">https://en.wikipedia.org/wiki/ICA_AB</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39554955"><td></td></tr>
                <tr id="39555801"><td></td></tr>
                        <tr id="39555015"><td></td></tr>
                  <tr id="39556102"><td></td></tr>
            <tr id="39555186"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555186" href="https://news.ycombinator.com/vote?id=39555186&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes - I triple-checked the calendar to verify my suspicion this February might have 29 days. The result was always negative - it seemed 28. Then February the 29th actually came. A bug apparently occurred in my mind.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39556250"><td></td></tr>
            <tr id="39554772"><td></td></tr>
                <tr id="39555011"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555011" href="https://news.ycombinator.com/vote?id=39555011&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Every time I go to timeanddate.com I feel like I see a link to the Leap Day page (<a href="https://www.timeanddate.com/date/leap-day.html" rel="nofollow">https://www.timeanddate.com/date/leap-day.html</a>) that shows the meme-infamous boyfriend-checking-out-another-girl couple, except she's proposing to him!  Obviously this happened earlier that day since they're wearing the same outfits, and I can't help but feel bad for her knowing what's coming but unable to warn of the impending train wreck.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554948"><td></td></tr>
                <tr id="39556202"><td></td></tr>
                  <tr id="39556193"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39556193" href="https://news.ycombinator.com/vote?id=39556193&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I'll take a February 30 if it means every other month is 30 days too, and we just get the extra days as universal, extended winter holiday where no one can legally be required to work because there is no December 31st or January minus-fourth.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39555182"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555182" href="https://news.ycombinator.com/vote?id=39555182&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>My monthly bus passes for both February and March did not work in Dallas today. The driver was aware of the issue and just waved me in.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554763"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554763" href="https://news.ycombinator.com/vote?id=39554763&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>The mcdonalds order waiting thing malfunctioned, displayed de52hg04 instead of 088 and I had to wait a lot longer for my order since it flew under the radar for a while until I spoke to them :)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554792"><td></td></tr>
            <tr id="39554673"><td></td></tr>
            <tr id="39555856"><td></td></tr>
            <tr id="39555189"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555189" href="https://news.ycombinator.com/vote?id=39555189&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Just AFTER reading about Casio watches in this thread I looked at mine. Sure it displays the date as March 1.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554636"><td></td></tr>
                <tr id="39554813"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554813" href="https://news.ycombinator.com/vote?id=39554813&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Not directly related to leap year, but a couple weeks ago I set up a script for testing notification behavior that used libfaketime to simulate runs at different times.<p>I guess this might be less-trivial if you've got a distributed multi-service architecture and perhaps also depend on APIs that aren't under your control in the first place.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39555864"><td></td></tr>
                  <tr id="39554780"><td></td></tr>
                <tr id="39554952"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39554952" href="https://news.ycombinator.com/vote?id=39554952&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>In a few hours you'll be able to backdate to "yesterday", with very low chances of hitting cert expiry issues (but I wouldn't be surprised if OP's issue involves components outside of their control or ability to test end-to-end)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555385"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39555385" href="https://news.ycombinator.com/vote?id=39555385&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I should have written something along the lines of "validity date ranges" instead of expiration: you're much more likely to run into problems where you run into a certificate that was issued in the future relative to when you think is now.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39555044"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555044" href="https://news.ycombinator.com/vote?id=39555044&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Maybe? My paycheck direct deposit didn't show up until almost 7am. Normally it hits right at midnight.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555090"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555090" href="https://news.ycombinator.com/vote?id=39555090&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>One of the most common QA test cases when it comes to testing date and time sensitive applications.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39556255"><td></td></tr>
            <tr id="39555299"><td></td></tr>
            <tr id="39554856"><td></td></tr>
            <tr id="39556099"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556099" href="https://news.ycombinator.com/vote?id=39556099&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I am gald that in excel, deleting a day from March 1st automatically gives Feb 29 or 28 depending on the year in formula. Before that, I struggled a lot to find last day of month by tracking if its a leap year or not, and keeping an array of months &amp; number of days. Now I simply add 1 to month, and from resulting daye I subtract 1 day. The Date value of that gives me 31 or 30 or 29 or 28.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39556227"><td></td></tr>
            <tr id="39555232"><td></td></tr>
                <tr id="39556209"><td></td></tr>
            <tr id="39555336"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555336" href="https://news.ycombinator.com/vote?id=39555336&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Because programmers take shortcuts. Its easier to type x - 365 than to import Calendar and then date(x) - timedelta(1 year).</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39554720"><td></td></tr>
            <tr id="39554996"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554996" href="https://news.ycombinator.com/vote?id=39554996&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>My Casio F91W I assumed would know that year YYYY is leap, and would show 29th as Date. No, it showed 1 as in March (it doesn't show months). I had to manually set it back to 28th so that tomorrow it shows correct date.<p>To be fair, it doesn't ask for year anywhere in settings. It simply doesn't know what year it is.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GGUF, the Long Way Around (150 pts)]]></title>
            <link>https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/</link>
            <guid>39553967</guid>
            <pubDate>Thu, 29 Feb 2024 19:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/">https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/</a>, See on <a href="https://news.ycombinator.com/item?id=39553967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/dbbb8ee7-f19f-44df-bce7-2612817cacd2" width="400"></figure><p><strong>Table of Contents</strong></p><ul><li><a href="#how-we-use-llm-artifacts">How We Use LLM Artifacts</a></li><li><a href="#what-is-a-machine-learning-model">What is a machine learning model</a><ul><li><a href="#starting-with-a-simple-model">Starting with a simple model</a></li></ul></li><li><a href="#writing-the-model-code">Writing the model code</a><ul><li><a href="#instantiating-the-model-object">Instantiating the model object</a></li><li><a href="#serializing-our-objects">Serializing our objects</a></li></ul></li><li><a href="#what-is-a-file">What is a file</a></li><li><a href="#how-does-pytorch-write-objects-to-files">How does PyTorch write objects to files?</a><ul><li><a href="#how-pickle-works">How Pickle works</a></li><li><a href="#from-pickle-to-safetensors">From pickle to safetensors</a></li><li><a href="#how-safetensors-works">How safetensors works</a></li><li><a href="#checkpoint-files">Checkpoint files</a></li><li><a href="#ggml">GGML</a></li><li><a href="#finally-gguf">Finally, GGUF</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="how-we-use-llm-artifacts">How We Use LLM Artifacts</h2><p>Large language models today are <a href="https://vickiboykis.com/2024/01/15/whats-new-with-ml-in-production/">consumed in one of several ways</a>:</p><ol><li>As API endpoints for proprietary models hosted by OpenAI, Anthropic, or major cloud providers</li><li>As model artifacts downloaded from HuggingFace’s Model Hub and/or trained/fine-tuned using HuggingFace libraries and hosted on local storage</li><li>As model artifacts available in a format optimized for local inference, typically GGUF, and accessed via applications like <code>llama.cpp</code> or <code>ollama</code></li><li>As <a href="https://onnx.ai/">ONNX</a>, a format which optimizes sharing between backend ML frameworks</li></ol><p>For a side project, I’m using <code>llama.cpp</code>, a <code>C/C++</code>-based LLM inference engine targeting <a href="https://github.com/ggerganov/llama.cpp/discussions/4167">M-series GPUs on Apple Silicon</a>.</p><p>When running <code>llama.cpp</code>, you get a long log that consists primarily of key-value pairs of metadata about your model architecture and then its performance (and <a href="https://twitter.com/vboykis/status/1751307750712156662">no yapping</a>).</p><div><pre tabindex="0"><code data-lang="bash"><span><span>make -j <span>&amp;&amp;</span> ./main -m /Users/vicki/llama.cpp/models/mistral-7b-instruct-v0.2.Q8_0.gguf -p <span>"What is Sanremo? no yapping"</span>
</span></span><span><span>
</span></span><span><span>Sanremo Music Festival <span>(</span>Festival di Sanremo<span>)</span> is an annual Italian music competition held in the city of Sanremo since 1951. It<span>'</span>s considered one of the most prestigious and influential events in the Italian music scene. The festival features both newcomers and established artists competing <span>for</span> various awards, including the Big Award <span>(</span>Gran Premio<span>)</span>, which grants the winner the right to represent Italy in the Eurovision Song Contest. The event consists of several live shows where artists perform their original songs, and a jury composed of musicians, critics, and the public determines the winners through a combination of points. <span>[</span>end of text<span>]</span>
</span></span><span><span>
</span></span><span><span>llama_print_timings:        load time <span>=</span>   11059.32 ms
</span></span><span><span>llama_print_timings:      sample time <span>=</span>      11.62 ms /   <span>140</span> runs   <span>(</span>    0.08 ms per token, 12043.01 tokens per second<span>)</span>
</span></span><span><span>llama_print_timings: prompt eval time <span>=</span>      87.81 ms /    <span>10</span> tokens <span>(</span>    8.78 ms per token,   113.88 tokens per second<span>)</span>
</span></span><span><span>llama_print_timings:        eval time <span>=</span>    3605.10 ms /   <span>139</span> runs   <span>(</span>   25.94 ms per token,    38.56 tokens per second<span>)</span>
</span></span><span><span>llama_print_timings:       total time <span>=</span>    3730.78 ms /   <span>149</span> tokens
</span></span><span><span>ggml_metal_free: deallocating
</span></span><span><span>Log end
</span></span></code></pre></div><p>These logs can be found in the <code>Llama.cpp</code> codebase. There, you’ll also find GGUF. <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md">GGUF (GPT-Generated Unified Format)</a> is the file format used to serve models on <code>Llama.cpp</code> and other local runners like <a href="https://semaphoreci.com/blog/local-llm">Llamafile, Ollama and GPT4All.</a></p><p>To understand how GGUF works, we need to first take a deep dive into machine learning models and the kinds of artifacts they produce.</p><h2 id="what-is-a-machine-learning-model">What is a machine learning model</h2><p>Let’s start by describing a machine learning model. At its simplest, a model is a file or a collection of files that contain the model architecture and weights and biases of the model generated from a training loop.</p><p>In LLM land, we’re generally interested in <a href="https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/">transformer-style models and architectures.</a></p><p>In a transformer, we have many moving parts.</p><ul><li><strong>For the input</strong>, we use <a href="https://arxiv.org/abs/2310.20707">training data corpuses aggregated from human-generated nautural language content</a></li><li>For <strong>the algorithm</strong>, we<ul><li>Convert that data <a href="https://vickiboykis.com/what_are_embeddings/">into embeddings</a></li><li><a href="https://d2l.ai/chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html#positional-encoding">Positionally encoding the embeddings</a> to provide information about where the words are in relation to each other in the sequence</li><li>Creating multi-headed <a href="https://ai.stackexchange.com/a/43892">self-attention</a> for each word in relation to each other word in the sequence based on an initialized combinations of weights</li><li><a href="https://arxiv.org/abs/2302.06461">Normalize layers via softmax</a></li><li>Run the resulting matrix through a feedfoward neural network</li><li>Project the output into the correct vector space for the desired task</li><li>Calculate loss and then update model parameters</li></ul></li><li><strong>The output</strong>: Generally for for chat completions tasks, <a href="https://arxiv.org/abs/2311.17301">the model returns the statistical likelihood</a> that any given word completes a phrase. It does this again and again for every word in the phrase, because of its autoregressive nature.</li></ul><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/86da416b-c6d8-4fb7-abf9-fcd2a80a1614" width="400"></figure><a href="https://arxiv.org/abs/2311.17301">Source.</a><p>If the model is served as a consumer end-product, it only returns the actual text output based on the highest probabilities, with numerous strategies for <a href="https://huggingface.co/blog/how-to-generate">how that text is selected.</a></p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/cb311adb-79f3-4eea-85be-7329e4aeb111" width="600"></figure><p>In short, we convert inputs to outputs using an equation. In addition to the model’s output, we also have the model itself that is generated as an artifact of the modeling process.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/67102dbc-d049-4131-997a-df1fa5378f91" width="600"></figure><h2 id="starting-with-a-simple-model">Starting with a simple model</h2><p>Let’s take a step back from the complexity of transformers and build a small linear regression model in PyTorch. Lucky for us, <a href="https://d2l.ai/chapter_linear-regression/index.html">linear regression is also</a> a (shallow) neural network, so we can work with it in PyTorch and map our simple model to more complex ones using the same framework.</p><p>Linear regression takes a set of numerical inputs and generates a set of numerical outputs. (In contrast to transformers, which take a set of text inputs and generates a set of text inputs and their related numerical probabilities.)</p><p>For example, let’s say that we produce <a href="https://www.greatitalianchefs.com/features/hazelnuts-piedmont">artisinal hazlenut spread</a> for statisticians, and want to predict how many jars of Nulltella we’ll produce on any given day. Let’s say we have some data available to us, and that is, how many hours of sunshine we have per day, and how many jars of Nulltella we’ve been able to produce every day.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/66ca00e6-1baf-4eb0-9d3d-112966beb797" width="200"></figure><p>It turns out that we feel more inspired to produce hazlenut spread when it’s sunny out, and we can clearly see this relationship between input and output in our data (we do not produce Nulltella Friday-Sunday because we prefer to spend those days writing about data serialization formats):</p><pre tabindex="0"><code>| day_id | hours   | jars |
|--------|---------|------|
| mon    | 1       | 2    |
| tues   | 2       | 4    |
| wed    | 3       | 6    |
| thu    | 4       | 8    |
</code></pre><p>This is the data we’ll use to train our model. We’ll need to split this data into three parts:</p><ol><li>used to train our model (training data)</li><li>used to test the accuracy of our model (test data)</li><li>used to tune our hyperparameters, meta-aspects of our model like the <a href="https://en.wikipedia.org/wiki/Learning_rate">learning rate</a>, (validation set) during the model training phase.</li></ol><p>In the specific case of linear regression, there technically are no hyperparameters, although we can plausibly consider the learning rate we set in PyTorch to be one. Let’s assume we have 100 of these data points values.</p><p>We split the data into train, test, and validation. A <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11583">usual accepted split</a> is to use 80% of data for training/validation and 20% for testing. We want our model to have access to as much data as possible so it learns a more accurate representation, so we leave most data for train.</p><p>Now that we have our data, we need to write our algorithm. The equation to get output \(Y\) from inputs \(X\) for linear regression is:</p><p>$$y = \beta_0 + \beta_1 x_1 + \varepsilon $$</p><p>This tells us that the output, \(y\) (the number of jars of Nulltella), can be predicted by:</p><ul><li>\(x_1\) - one input variable (or feature), (hours of sunshine)</li><li>\(\beta_1\) - with its given weight, also called parameters, (how important that feature is)</li><li>plus an error term \(\varepsilon\) that is the difference between the observed and actual values in a population that captures the noise of the model</li></ul><p>Our task is to continuously predict and adjust our weights to optimally solve this equation for the difference between our actual \(Y\) as presented by our data and a predicted \(\hat Y\) based on the algorithm to find the smallest sum of squared differences, \(\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}\), between each point and the line. In other words, we’d like to minimize \(\varepsilon\), because it will mean that, at each point, our \(\hat Y\) is as close to our actual \(Y\) as we can get it, given the other points.</p><p>We optimize this function <a href="https://arxiv.org/abs/1609.04747">through gradient descent</a>, where we start with either zeros or randomly-initialized weights and continue recalculating both the weights and error term until we come to an optimal stopping point.
We’ll know we’re succeeding because our loss, as calculated by RMSE should incrementally decrease in every training iteration.</p><p>Here’s the whole model learning process end-to-end (with the exception of tokenization, which we only do for models where features are text and we want to do language modeling):</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/9f8fb4b8-4b19-45e2-bb04-7657e447d42f" width="600"></figure><h2 id="writing-the-model-code">Writing the model code</h2><p>Now, let’s get more concrete and describe these ideas in code. When we train our model, we initialize our function with a set of feature values.</p><p>Let’s add our data into the model by initializing both \(x_1\) and \(Y\) as <a href="https://pytorch.org/docs/stable/tensors.html">PyTorch Tensor objects</a>.</p><div><pre tabindex="0"><code data-lang="python"><span><span>
</span></span><span><span><span># Hours of sunshine</span>
</span></span><span><span>X <span>=</span> torch<span>.</span>tensor([[<span>1.0</span>], [<span>2.0</span>], [<span>3.0</span>], [<span>4.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>
</span></span><span><span><span># Jars of Nulltella</span>
</span></span><span><span>y <span>=</span> torch<span>.</span>tensor([[<span>2.0</span>], [<span>4.0</span>], [<span>6.0</span>], [<span>8.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span></code></pre></div><p>Within code, our input data is <code>X</code>, which is a torch tensor object, and our output data is <code>y</code>. We initialize a LinearRegression which subclasses the PyTorch Module, with one linear layer, which has one input feature (sunshine) and one output feature (jars of Nulltella).</p><p>I’m going to include the code for the whole model, and then we’ll talk through it piece by piece.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> torch
</span></span><span><span><span>import</span> torch.nn <span>as</span> nn
</span></span><span><span><span>import</span> torch.optim <span>as</span> optim
</span></span><span><span>
</span></span><span><span>X <span>=</span> torch<span>.</span>tensor([[<span>1.0</span>], [<span>2.0</span>], [<span>3.0</span>], [<span>4.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>y <span>=</span> torch<span>.</span>tensor([[<span>2.0</span>], [<span>4.0</span>], [<span>6.0</span>], [<span>8.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>
</span></span><span><span><span># Define a linear regression model and its forward pass </span>
</span></span><span><span><span>class</span> <span>LinearRegression</span>(nn<span>.</span>Module):
</span></span><span><span>    <span>def</span> __init__(self):
</span></span><span><span>        super(LinearRegression, self)<span>.</span>__init__()
</span></span><span><span>        self<span>.</span>linear <span>=</span> nn<span>.</span>Linear(<span>1</span>, <span>1</span>)  <span># 1 input feature, 1 output feature</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span>(self, x):
</span></span><span><span>        <span>return</span> self<span>.</span>linear(x)
</span></span><span><span>
</span></span><span><span><span># Instantiate the model</span>
</span></span><span><span>model <span>=</span> LinearRegression()
</span></span><span><span>
</span></span><span><span><span># Inspect the model's state dictionary</span>
</span></span><span><span>print(model<span>.</span>state_dict())
</span></span><span><span>
</span></span><span><span><span># Define loss function and optimizer</span>
</span></span><span><span>criterion <span>=</span> nn<span>.</span>MSELoss() 
</span></span><span><span><span># setting our learning rate "hyperparameter" here</span>
</span></span><span><span>optimizer <span>=</span> optim<span>.</span>SGD(model<span>.</span>parameters(), lr<span>=</span><span>0.01</span>)  
</span></span><span><span>
</span></span><span><span><span># Training loop that includes forward and backward pass </span>
</span></span><span><span>num_epochs <span>=</span> <span>100</span>
</span></span><span><span><span>for</span> epoch <span>in</span> range(num_epochs):
</span></span><span><span>    <span># Forward pass</span>
</span></span><span><span>    outputs <span>=</span> model(X)
</span></span><span><span>    loss <span>=</span> criterion(outputs, y)
</span></span><span><span>    RMSE_loss  <span>=</span> torch<span>.</span>sqrt(loss)
</span></span><span><span>
</span></span><span><span>    <span># Backward pass and optimization</span>
</span></span><span><span>    optimizer<span>.</span>zero_grad()  <span># Zero out gradients</span>
</span></span><span><span>    RMSE_loss<span>.</span>backward()  <span># Compute gradients</span>
</span></span><span><span>    optimizer<span>.</span>step()  <span># Update weights</span>
</span></span><span><span>
</span></span><span><span>    <span># Print progress</span>
</span></span><span><span>    <span>if</span> (epoch<span>+</span><span>1</span>) <span>%</span> <span>10</span> <span>==</span> <span>0</span>:
</span></span><span><span>        print(<span>f</span><span>'Epoch [</span><span>{</span>epoch<span>+</span><span>1</span><span>}</span><span>/</span><span>{</span>num_epochs<span>}</span><span>], Loss: </span><span>{</span>loss<span>.</span>item()<span>:</span><span>.4f</span><span>}</span><span>'</span>)
</span></span><span><span>
</span></span><span><span><span># After training, let's test the model</span>
</span></span><span><span>test_input <span>=</span> torch<span>.</span>tensor([[<span>5.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>predicted_output <span>=</span> model(test_input)
</span></span><span><span>print(<span>f</span><span>'Prediction for input </span><span>{</span>test_input<span>.</span>item()<span>}</span><span>: </span><span>{</span>predicted_output<span>.</span>item()<span>}</span><span>'</span>)
</span></span></code></pre></div><p>Once we have our input data, we then initialize our model, a <code>LinearRegression</code> which subclasses <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">Module base class</a> specifically for <a href="https://github.com/pytorch/pytorch/blob/372d078f361e726bb4ac0884ac334b04c58179ef/torch/nn/modules/linear.py#L49">linear regression.</a></p><p>A forward pass involves feeding our data into the neural network and making sure it propogagtes through all the layers. Since we only have one, we have to pass our data to a single linear layer. The forward pass is what calculates our predicted <code>Y</code>.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>LinearRegression</span>(nn<span>.</span>Module):
</span></span><span><span>    <span>def</span> __init__(self):
</span></span><span><span>        super(LinearRegression, self)<span>.</span>__init__()
</span></span><span><span>        self<span>.</span>linear <span>=</span> nn<span>.</span>Linear(<span>1</span>, <span>1</span>)  <span># 1 input feature, 1 output feature</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span>(self, x):
</span></span><span><span>        <span>return</span> self<span>.</span>linear(x)
</span></span></code></pre></div><p>We pick how we’d like to optimize the results of the model, aka how its loss should converge. In this case, we start with <code>mean squared error</code>, and then modify it to use <code>RMSE</code>, the square root of the average squared difference between the predicted values and the actual values in a dataset.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># Define loss function and optimizer</span>
</span></span><span><span>criterion <span>=</span> torch<span>.</span>sqrl(nn<span>.</span>MSELoss())  <span># RMSE in the training loop</span>
</span></span><span><span>optimizer <span>=</span> optim<span>.</span>SGD(model<span>.</span>parameters(), lr<span>=</span><span>0.01</span>)
</span></span><span><span>
</span></span><span><span><span>....</span>
</span></span><span><span><span>for</span> epoch <span>in</span> range(num_epochs):
</span></span><span><span>    <span># Forward pass</span>
</span></span><span><span>    outputs <span>=</span> model(X)
</span></span><span><span>    loss <span>=</span> criterion(outputs, y)
</span></span><span><span>    RMSE_loss  <span>=</span> torch<span>.</span>sqrt(loss)
</span></span></code></pre></div><p>Now that we’ve defined how we’d like the model to run, we can instantiate the model object itself:</p><h2 id="instantiating-the-model-object">Instantiating the model object</h2><div><pre tabindex="0"><code data-lang="python"><span><span>model <span>=</span> LinearRegression()
</span></span><span><span>print(model<span>.</span>state_dict())
</span></span></code></pre></div><p>Notice that when we instantiate a <code>nn.Module</code>, it has an attribute called the “state_dict”. This is important. <a href="https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html">The state dict</a> holds the information about each layer and the parameters in each layer, aka the weights and biases.</p><p>At its heart, <a href="https://github.com/pytorch/pytorch/blob/637cf4a3f2cfdd364005681636ca885bdc4d5887/torch/nn/modules/module.py#L1842">it’s a Python dictionary.</a></p><p>In this case, the implementation for LinearRegression returns an ordered dict with each layer of the network and values of those layers. Each of the values is a <code>Tensor</code>.</p><div><pre tabindex="0"><code data-lang="python"><span><span>OrderedDict([(<span>'linear.weight'</span>, tensor([[<span>0.5408</span>]])), (<span>'linear.bias'</span>, tensor([<span>-</span><span>0.8195</span>]))])
</span></span><span><span>
</span></span><span><span><span>for</span> param_tensor <span>in</span> model<span>.</span>state_dict():
</span></span><span><span>    print(param_tensor, <span>"</span><span>\t</span><span>"</span>, model<span>.</span>state_dict()[param_tensor]<span>.</span>size())
</span></span><span><span>
</span></span><span><span>linear<span>.</span>weight    torch<span>.</span>Size([<span>1</span>, <span>1</span>])
</span></span><span><span>linear<span>.</span>bias      torch<span>.</span>Size([<span>1</span>])
</span></span></code></pre></div><p>For our tiny model, it’s a small <code>OrderedDict</code> of tuples. You can imagine that this collection of tensors becomes extremely large and memory-intensive in a large network such as a transformer. If each parameter (each Tensor object) takes up 2 bytes in memory, <a href="https://github.com/ray-project/llm-numbers?tab=readme-ov-file#2x-number-of-parameters-typical-gpu-memory-requirements-of-an-llm-for-serving">a 7-billion parameter model can take up 14GB in GPU.</a></p><p>We then run the forward and backward passes for the model in loops. In each step, we do a forward pass to perform the calculation, a backward pass to update the weights of our model object, and then we add all that information to our model parameters.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># Define loss function and optimizer</span>
</span></span><span><span>criterion <span>=</span> nn<span>.</span>MSELoss() 
</span></span><span><span>optimizer <span>=</span> optim<span>.</span>SGD(model<span>.</span>parameters(), lr<span>=</span><span>0.01</span>)  
</span></span><span><span>
</span></span><span><span><span># Training loop </span>
</span></span><span><span>num_epochs <span>=</span> <span>100</span>
</span></span><span><span><span>for</span> epoch <span>in</span> range(num_epochs):
</span></span><span><span>    <span># Forward pass</span>
</span></span><span><span>    outputs <span>=</span> model(X)
</span></span><span><span>    loss <span>=</span> criterion(outputs, y)
</span></span><span><span>    RMSE_loss  <span>=</span> torch<span>.</span>sqrt(loss)
</span></span><span><span>
</span></span><span><span>    <span># Backward pass and optimization</span>
</span></span><span><span>    optimizer<span>.</span>zero_grad()  <span># Zero out gradients</span>
</span></span><span><span>    RMSE_loss<span>.</span>backward()  <span># Compute gradients</span>
</span></span><span><span>    optimizer<span>.</span>step()  <span># Update weights</span>
</span></span><span><span>
</span></span><span><span>    <span># Print progress</span>
</span></span><span><span>    <span>if</span> (epoch<span>+</span><span>1</span>) <span>%</span> <span>10</span> <span>==</span> <span>0</span>:
</span></span><span><span>        print(<span>f</span><span>'Epoch [</span><span>{</span>epoch<span>+</span><span>1</span><span>}</span><span>/</span><span>{</span>num_epochs<span>}</span><span>], Loss: </span><span>{</span>loss<span>.</span>item()<span>:</span><span>.4f</span><span>}</span><span>'</span>)
</span></span></code></pre></div><p>Once we’ve completed these loops, we’ve trained the model artifact. What we now have once we have trained a model is an in-memory object that represents the weights, biases, and metadata of that model, stored within our instance of our <code>LinearRegression</code> module.</p><p>As we run the training loop, we can see our loss shrink. That is, the actual values are getting closer to the predicted:</p><div><pre tabindex="0"><code data-lang="python"><span><span>Epoch [<span>10</span><span>/</span><span>100</span>], Loss: <span>33.0142</span>
</span></span><span><span>Epoch [<span>20</span><span>/</span><span>100</span>], Loss: <span>24.2189</span>
</span></span><span><span>Epoch [<span>30</span><span>/</span><span>100</span>], Loss: <span>16.8170</span>
</span></span><span><span>Epoch [<span>40</span><span>/</span><span>100</span>], Loss: <span>10.8076</span>
</span></span><span><span>Epoch [<span>50</span><span>/</span><span>100</span>], Loss: <span>6.1890</span>
</span></span><span><span>Epoch [<span>60</span><span>/</span><span>100</span>], Loss: <span>2.9560</span>
</span></span><span><span>Epoch [<span>70</span><span>/</span><span>100</span>], Loss: <span>1.0853</span>
</span></span><span><span>Epoch [<span>80</span><span>/</span><span>100</span>], Loss: <span>0.4145</span>
</span></span><span><span>Epoch [<span>90</span><span>/</span><span>100</span>], Loss: <span>0.3178</span>
</span></span><span><span>Epoch [<span>100</span><span>/</span><span>100</span>], Loss: <span>0.2974</span>
</span></span></code></pre></div><p>We can also see if we print out the <code>state_dict</code> that the parameters have changed as we’ve computed the gradients and updated the weights in the backward pass:</p><div><pre tabindex="0"><code data-lang="python"><span><span>
</span></span><span><span><span>"""before"""</span>
</span></span><span><span>OrderedDict([(<span>'linear.weight'</span>, tensor([[<span>-</span><span>0.6216</span>]])), (<span>'linear.bias'</span>, tensor([<span>0.7633</span>]))])
</span></span><span><span>linear<span>.</span>weight    torch<span>.</span>Size([<span>1</span>, <span>1</span>])
</span></span><span><span>linear<span>.</span>bias      torch<span>.</span>Size([<span>1</span>])
</span></span><span><span>{<span>'state'</span>: {}, <span>'param_groups'</span>: [{<span>'lr'</span>: <span>0.01</span>, <span>'momentum'</span>: <span>0</span>, <span>'dampening'</span>: <span>0</span>, <span>'weight_decay'</span>: <span>0</span>, <span>'nesterov'</span>: <span>False</span>, <span>'maximize'</span>: <span>False</span>, <span>'foreach'</span>: <span>None</span>, <span>'differentiable'</span>: <span>False</span>, <span>'params'</span>: [<span>0</span>, <span>1</span>]}]}
</span></span><span><span>Epoch [<span>10</span><span>/</span><span>100</span>], Loss: <span>33.0142</span>
</span></span><span><span>Epoch [<span>20</span><span>/</span><span>100</span>], Loss: <span>24.2189</span>
</span></span><span><span>Epoch [<span>30</span><span>/</span><span>100</span>], Loss: <span>16.8170</span>
</span></span><span><span>Epoch [<span>40</span><span>/</span><span>100</span>], Loss: <span>10.8076</span>
</span></span><span><span>Epoch [<span>50</span><span>/</span><span>100</span>], Loss: <span>6.1890</span>
</span></span><span><span>Epoch [<span>60</span><span>/</span><span>100</span>], Loss: <span>2.9560</span>
</span></span><span><span>Epoch [<span>70</span><span>/</span><span>100</span>], Loss: <span>1.0853</span>
</span></span><span><span>Epoch [<span>80</span><span>/</span><span>100</span>], Loss: <span>0.4145</span>
</span></span><span><span>Epoch [<span>90</span><span>/</span><span>100</span>], Loss: <span>0.3178</span>
</span></span><span><span>Epoch [<span>100</span><span>/</span><span>100</span>], Loss: <span>0.2974</span>
</span></span><span><span>
</span></span><span><span><span>"""after"""</span>
</span></span><span><span>OrderedDict([(<span>'linear.weight'</span>, tensor([[<span>1.5441</span>]])), (<span>'linear.bias'</span>, tensor([<span>1.3291</span>]))])
</span></span></code></pre></div><p>The optimizer, as we see, has its own <code>state_dict</code>, which consists of these hyperparameters we discussed before: the learning rate, the weight decay, and more:</p><div><pre tabindex="0"><code data-lang="python"><span><span>print(optimizer<span>.</span>state_dict())
</span></span><span><span>{<span>'state'</span>: {}, <span>'param_groups'</span>: [{<span>'lr'</span>: <span>0.01</span>, <span>'momentum'</span>: <span>0</span>, <span>'dampening'</span>: <span>0</span>, <span>'weight_decay'</span>: <span>0</span>, <span>'nesterov'</span>: <span>False</span>, <span>'maximize'</span>: <span>False</span>, <span>'foreach'</span>: <span>None</span>, <span>'differentiable'</span>: <span>False</span>, <span>'params'</span>: [<span>0</span>, <span>1</span>]}]}
</span></span></code></pre></div><p>Now that we have a trained model object, we can pass in new feature values for the model to evaluate. For example we can pass in an <code>X</code> value of <code>5</code> hours of sunshine and see how many jars of Nulltella we expect to make.</p><p>We do this by passing in <code>5</code> to the instantiated model object, which is now a combination of the method used to run the linear regression equation and our state dict, the weights, the current set of weights and biases to give a new predicted value. We get <code>9</code> jars, which pretty close to what we’d expect.</p><div><pre tabindex="0"><code data-lang="python"><span><span>test_input <span>=</span> torch<span>.</span>tensor([[<span>5.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>predicted_output <span>=</span> model(test_input)
</span></span><span><span>print(<span>f</span><span>'Prediction for input </span><span>{</span>test_input<span>.</span>item()<span>}</span><span>: </span><span>{</span>predicted_output<span>.</span>item()<span>}</span><span>'</span>)
</span></span><span><span>Prediction <span>for</span> input <span>5.0</span>: <span>9.049455642700195</span>
</span></span></code></pre></div><p>I’m abstracting away <a href="https://horace.io/brrr_intro.html">an enormous amount of detail</a> for the sake of clarity, namely the massive amount of work PyTorch does in moving this data in and out of GPUs and working with <a href="https://developer.nvidia.com/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-33-implementing-efficient">GPU-efficient datatypes</a> for efficient computing which is a large part of the work of the library. We’ll skip these for now for simplicity.</p><h2 id="serializing-our-objects">Serializing our objects</h2><p>So far, so good. We now have stateful Python objects in-memory that convey the state of our model. But what happens when we need to persist this very large model, that we likely spent 24+ hours training, and use it again?</p><p>This scenario is described <a href="https://blog.nelhage.com/post/pickles-and-ml/">here</a>,</p><blockquote><p>Suppose a researcher is experimenting with a new deep-learning model architecture, or a variation on an existing one. Her architecture is going to have a whole bunch of configuration options and hyperparameters: the number of layers, the types of each layers, the dimensionality of various vectors, where and how to normalize activations, which nonlinearity(ies) to use, and so on. Many of the model components will be standard layers provided by the ML framework, but the researcher will be inserting bits and pieces of novel logic as well.</p></blockquote><blockquote><p>Our researcher needs a way to describe a particular concrete model – a specific combination of these settings – which can be serialized and then reloaded later. She needs this for a few related reasons:</p></blockquote><blockquote><p>She likely has access to a compute cluster containing GPUs or other accelerators she can use to run jobs. She needs a way to submit a model description to code running on that cluster so it can run her model on the cluster.</p></blockquote><blockquote><p>While those models are training, she needs to save snapshots of their progress in such a way that they can be reloaded and resumed, in case the hardware fails or the job is preempted. Once models are trained, the researcher will want to load them again (potentially both a final snapshot, and some of the partially-trained checkpoints) in order to run evaluations and experiments on them.</p></blockquote><p>What do we mean by serialization? It’s the process of writing objects and classes from our programming runtime to a file. Deserialization is the process of converting data on disk to programming language objects in memory. We now need to seralize the data into a bytestream that we can write to a file.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/47228a07-abc0-410f-b62b-48b756e3b30a" width="600"></figure><p>Why <a href="https://stackoverflow.com/questions/28552540/why-is-serialization-called-serialization">“serialization”</a>? Because back in the Old Days, data used to be stored on tape, which required bits to be in order sequentially on tape.</p><p>Since many transformer-style models are trained using PyTorch these days, artifacts use PyTorch’s <code>save</code> implementation for serializing objects to disk.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/da1b0b43-de7e-4e78-ae06-32a21a018a08" width="600"></figure><h2 id="what-is-a-file">What is a file</h2><p>Again, let’s abstract away the GPU for simplicity and assume we’re performing all these computations in CPU. Python objects <a href="https://docs.python.org/3/c-api/memory.html">live in memory</a>. This memory is allocated in a special private heap at the beginning of <a href="https://anvil.works/articles/pointers-in-my-python-3">their lifecycle</a>, in <a href="https://stackoverflow.com/questions/10200628/heap-memory-in-c-programming">private heap</a> managed by the Python memory manager, with specialized heaps for different object types.</p><p>When we initialize our PyTorch model object, the operating system allocates memory through lower-level C functions, namely <code>malloc</code>, via <a href="https://docs.python.org/3/c-api/memory.html#default-memory-allocators">default memory allocators</a>.</p><p>When we run our code <a href="https://docs.python.org/3/library/tracemalloc.html">with tracemalloc</a>, we can see how memory for PyTorch is actually allocated on CPU (keep in mind that, again, GPU operations are completely different).</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> tracemalloc
</span></span><span><span>
</span></span><span><span>tracemalloc<span>.</span>start()
</span></span><span><span>
</span></span><span><span><span>.....</span>
</span></span><span><span>pytorch
</span></span><span><span><span>...</span>
</span></span><span><span>
</span></span><span><span>snapshot <span>=</span> tracemalloc<span>.</span>take_snapshot()
</span></span><span><span>top_stats <span>=</span> snapshot<span>.</span>statistics(<span>'lineno'</span>)
</span></span><span><span>
</span></span><span><span>print(<span>"[ Top 10 ]"</span>)
</span></span><span><span><span>for</span> stat <span>in</span> top_stats[:<span>10</span>]:
</span></span><span><span>    print(stat)
</span></span><span><span>
</span></span><span><span>[ Top <span>10</span> ]
</span></span><span><span><span>&lt;</span>frozen importlib<span>.</span>_bootstrap_external<span>&gt;</span>:<span>672</span>: size<span>=</span><span>21.1</span> MiB, count<span>=</span><span>170937</span>, average<span>=</span><span>130</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>inspect<span>.</span>py:<span>2156</span>: size<span>=</span><span>577</span> KiB, count<span>=</span><span>16</span>, average<span>=</span><span>36.0</span> KiB
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>71</span>: size<span>=</span><span>512</span> KiB, count<span>=</span><span>3</span>, average<span>=</span><span>171</span> KiB
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>dataclasses<span>.</span>py:<span>434</span>: size<span>=</span><span>410</span> KiB, count<span>=</span><span>4691</span>, average<span>=</span><span>90</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>368</span>: size<span>=</span><span>391</span> KiB, count<span>=</span><span>7122</span>, average<span>=</span><span>56</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>397</span>: size<span>=</span><span>349</span> KiB, count<span>=</span><span>1237</span>, average<span>=</span><span>289</span> B
</span></span><span><span><span>&lt;</span>frozen importlib<span>.</span>_bootstrap_external<span>&gt;</span>:<span>128</span>: size<span>=</span><span>213</span> KiB, count<span>=</span><span>1390</span>, average<span>=</span><span>157</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>functools<span>.</span>py:<span>58</span>: size<span>=</span><span>194</span> KiB, count<span>=</span><span>2554</span>, average<span>=</span><span>78</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>373</span>: size<span>=</span><span>136</span> KiB, count<span>=</span><span>2540</span>, average<span>=</span><span>55</span> B
</span></span><span><span><span>&lt;</span>frozen importlib<span>.</span>_bootstrap_external<span>&gt;</span>:<span>1607</span>: size<span>=</span><span>127</span> KiB, count<span>=</span><span>1133</span>, average<span>=</span><span>115</span> B
</span></span></code></pre></div><p>Here, we can see we imported 170k objects from imports, and that the rest of the allocation came from allowed_functions in torch.</p><h2 id="how-does-pytorch-write-objects-to-files">How does PyTorch write objects to files?</h2><p>We can also more explicitly see the types of these objects in memory. Among all the other objects created by PyTorch and Python system libraries, we can see our <code>Linear</code> object here, which has <code>state_dict</code> as a property. We need to serialize this object into a bytestream so we can write it to disk.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> gc
</span></span><span><span><span># Get all live objects</span>
</span></span><span><span>all_objects <span>=</span> gc<span>.</span>get_objects()
</span></span><span><span>
</span></span><span><span><span># Extract distinct object types</span>
</span></span><span><span>distinct_types <span>=</span> set(type(obj) <span>for</span> obj <span>in</span> all_objects)
</span></span><span><span>
</span></span><span><span><span># Print distinct object types</span>
</span></span><span><span><span>for</span> obj_type <span>in</span> distinct_types:
</span></span><span><span>    print(obj_type<span>.</span>__name__)
</span></span><span><span>
</span></span><span><span>InputKind
</span></span><span><span>KeyedRef
</span></span><span><span>ReLU
</span></span><span><span>Manager
</span></span><span><span>_Call
</span></span><span><span>UUID
</span></span><span><span>Pow
</span></span><span><span>Softmax
</span></span><span><span>Options 
</span></span><span><span>_Environ
</span></span><span><span><span>**</span>Linear<span>**</span>
</span></span><span><span>CFunctionType
</span></span><span><span>SafeUUID
</span></span><span><span>_Real
</span></span><span><span>JSONDecoder
</span></span><span><span>StmtBuilder
</span></span><span><span>OutDtypeOperator
</span></span><span><span>MatMult
</span></span><span><span>attrge
</span></span></code></pre></div><p>PyTorch <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">serializes objects to disk</a> using Python’s pickle framework and wrapping the pickle <code>load</code> and <code>dump</code> methods.</p><p>Pickle traverses the object’s inheritance hierarchy and converts each object encountered into streamable artifacts. It does this recursively for nested representations (for example, understanding nn.<code>Module</code> and <code>Linear</code> inheriting from <code>nn.Module</code>) and converting these representations to byte representations so that they can be written to file.</p><p>As an example, let’s take a simple function and write it to a pickle file.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> torch.nn <span>as</span> nn
</span></span><span><span><span>import</span> torch.optim <span>as</span> optim
</span></span><span><span><span>import</span> pickle
</span></span><span><span>
</span></span><span><span>X <span>=</span> torch<span>.</span>tensor([[<span>1.0</span>], [<span>2.0</span>], [<span>3.0</span>], [<span>4.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>
</span></span><span><span><span>with</span> open(<span>'tensors.pkl'</span>, <span>'wb'</span>) <span>as</span> f: 
</span></span><span><span>    pickle<span>.</span>dump(X, f) 
</span></span></code></pre></div><p>when we inspect the <a href="https://docs.python.org/3/library/pickletools.html">pickled object with pickletools</a>, we get an idea of how the data is organized.</p><p>We import some functions that load the data as a tensor, then the actual storage of that data, then its type. The module does the inverse when converting from pickle files to Python objects.</p><pre tabindex="0"><code>python -m pickletools tensors.pkl
    0: \x80 PROTO      4
    2: \x95 FRAME      398
   11: \x8c SHORT_BINUNICODE 'torch._utils'
   25: \x94 MEMOIZE    (as 0)
   26: \x8c SHORT_BINUNICODE '_rebuild_tensor_v2'
   46: \x94 MEMOIZE    (as 1)
   47: \x93 STACK_GLOBAL
   48: \x94 MEMOIZE    (as 2)
   49: (    MARK
   50: \x8c     SHORT_BINUNICODE 'torch.storage'
   65: \x94     MEMOIZE    (as 3)
   66: \x8c     SHORT_BINUNICODE '_load_from_bytes'
   84: \x94     MEMOIZE    (as 4)
   85: \x93     STACK_GLOBAL
   86: \x94     MEMOIZE    (as 5)
   87: B        BINBYTES   b'\x80\x02\x8a\nl\xfc\x9cF\xf9 j\xa8P\x19.\x80\x02M\xe9\x03.\x80\x02}q\x00(X\x10\x00\x00\x00protocol_versionq\x01M\xe9\x03X\r\x00\x00\x00little_endianq\x02\x88X\n\x00\x00\x00type_sizesq\x03}q\x04(X\x05\x00\x00\x00shortq\x05K\x02X\x03\x00\x00\x00intq\x06K\x04X\x04\x00\x00\x00longq\x07K\x04uu.\x80\x02(X\x07\x00\x00\x00storageq\x00ctorch\nFloatStorage\nq\x01X\n\x00\x00\x006061074080q\x02X\x03\x00\x00\x00cpuq\x03K\x04Ntq\x04Q.\x80\x02]q\x00X\n\x00\x00\x006061074080q\x01a.\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@'
  351: \x94     MEMOIZE    (as 6)
  352: \x85     TUPLE1
  353: \x94     MEMOIZE    (as 7)
  354: R        REDUCE
  355: \x94     MEMOIZE    (as 8)
  356: K        BININT1    0
  358: K        BININT1    4
  360: K        BININT1    1
  362: \x86     TUPLE2
  363: \x94     MEMOIZE    (as 9)
  364: K        BININT1    1
  366: K        BININT1    1
  368: \x86     TUPLE2
  369: \x94     MEMOIZE    (as 10)
  370: \x89     NEWFALSE
  371: \x8c     SHORT_BINUNICODE 'collections'
  384: \x94     MEMOIZE    (as 11)
  385: \x8c     SHORT_BINUNICODE 'OrderedDict'
  398: \x94     MEMOIZE    (as 12)
  399: \x93     STACK_GLOBAL
  400: \x94     MEMOIZE    (as 13)
  401: )        EMPTY_TUPLE
  402: R        REDUCE
  403: \x94     MEMOIZE    (as 14)
  404: t        TUPLE      (MARK at 49)
  405: \x94 MEMOIZE    (as 15)
  406: R    REDUCE
  407: \x94 MEMOIZE    (as 16)
  408: .    STOP
highest protocol among opcodes = 4
</code></pre><p>The main issue with pickle as a file format is that it not only bundles executable code, but that there are no checks on the code being read, and without schema guarantees, <a href="https://nedbatchelder.com/blog/202006/pickles_nine_flaws.html">you can pass something to the pickle that’s malicious</a>,</p><blockquote><p>The insecurity is not because pickles contain code, but because they create objects by calling constructors named in the pickle. Any callable can be used in place of your class name to construct objects. Malicious pickles will use other Python callables as the “constructors.” For example, instead of executing “models.MyObject(17)”, a dangerous pickle might execute “os.system(‘rm -rf /’)”. The unpickler can’t tell the difference between “models.MyObject” and “os.system”. Both are names it can resolve, producing something it can call. The unpickler executes either of them as directed by the pickle.'</p></blockquote><h2 id="how-pickle-works">How Pickle works</h2><p>Pickle initially worked for Pytorch-based models because it was also closely coupled to the Python ecosystem and initial ML library artifacts were not the key outputs of deep learning systems.</p><blockquote><p>The primary output of research is knowledge, not software artifacts. Research teams write software to answer research questions and improve their/their team’s/their field’s understanding of a domain, more so than they write software in order to have software tools or solutions.</p></blockquote><p>However, as the use of transformer-based models picked up after the release of the Transformer paper in 2017, so did the use of the <code>transformers</code> library, which delegates the <a href="https://github.com/huggingface/transformers/blob/08cd694ef07d53f6e08e60ea6e1483dbb156924d/src/transformers/models/auto/configuration_auto.py#L1006">load</a> call to PyTorch’s <code>load</code> methods, which uses pickle.</p><p>Once practitioners started creating and uploading <a href="https://arxiv.org/abs/2401.13177">pickled model artifacts to model hubs like HuggingFace</a>, <a href="https://www.youtube.com/watch?v=2ethDz9KnLk&amp;t=1103s">machine learning model supply chain security</a> became an issue.</p><h2 id="from-pickle-to-safetensors">From pickle to safetensors</h2><p>As machine learning with deep learning models trained with PyTorch exploded, these security issues came to a head, and in 2021, Trail of Bits released a post <a href="https://github.com/trailofbits/fickling">the insecurity of pickle files.</a></p><p>Engineers at HuggingFace started developing a library known as <a href="https://github.com/huggingface/safetensors/tree/main">safetensors</a> as an alternative to pickle. Safetensors was a <a href="https://github.com/huggingface/safetensors/discussions/111">developed</a> to be efficient, but, also safer and more ergonomic than pickle.</p><p>First, <code>safetensors</code> is not bound to Python as closely as Pickle: with pickle, you can only read or write files in Python. Safetensors is compatible across languages. Second, safetensors also limits language execution, functionality available on serialization and deserialization. Third, because the backend of safetensors is written in Rust, it enforces type safety more rigorously. Finally, safetensors was optimized for work specifically with tensors as a datatype in a way that Pickle was not. That, combined with the fact that it was wirtten in Rust <a href="https://huggingface.co/docs/safetensors/en/speed.">makes it really fast for reads and writes.</a></p><p>After a concerted push from both <a href="https://www.trailofbits.com/">Trail of Bits</a> and <a href="https://www.eleuther.ai/">EleutherAI</a>, a security audit of safetensors was conducted and found satisfactory, <a href="https://huggingface.co/blog/safetensors-security-audit">which led to HuggingFace adapting it as the default format for models on the Hub.</a> going forward. (Big thanks to <a href="https://twitter.com/vboykis/status/1759268551129452654">Stella and Suha</a> for this history and context, and to everyone who contributed to the Twitter thread.)</p><h2 id="how-safetensors-works">How safetensors works</h2><p>How does the safetensors format work? As with most things in LLMs at the bleeding edge, the code and commit history will do most of the talking. <a href="https://github.com/huggingface/safetensors#yet-another-format-">Let’s take a look at the file spec.</a></p><ul><li><strong>8 bytes</strong>: N, an unsigned little-endian 64-bit integer, containing the size of the header</li><li><strong>N bytes</strong>: a JSON UTF-8 string representing the header.
The header data MUST begin with a { character (0x7B).
The header data MAY be trailing padded with whitespace (0x20).
The header is a dict like {“TENSOR_NAME”: {“dtype”: “F16”, “shape”: [1, 16, 256], “data_offsets”: [BEGIN, END]}, “NEXT_TENSOR_NAME”: {…}, …},
data_offsets point to the tensor data relative to the beginning of the byte buffer (i.e. not an absolute position in the file), with BEGIN as the starting offset and END as the one-past offset (so total tensor byte size = END - BEGIN).
A special key <strong>metadata</strong> is allowed to contain free form string-to-string map. Arbitrary JSON is not allowed, all values must be strings.</li><li>Rest of the file: byte-buffer.</li></ul><p>This is different than <code>state_dict</code> and <code>pickle</code> file specifications, but the addition of safetensors follows the natural evolution from Python objects, to full-fledged file format.</p><p>A file is a way of storing our data generated from programming language objects, in bytes on disk. In looking at different file format specs (<a href="https://arrow.apache.org/docs/format/CDataInterface.html">Arrow</a>,<a href="https://parquet.apache.org/docs/file-format/">Parquet</a>, <a href="https://protobuf.dev/">protobuf</a>), we’ll start to notice some patterns around how they’re laid out.</p><ol><li>In the file, we need some indicator that this is a type of file “X”. Usually this is represented by a <a href="https://en.wikipedia.org/wiki/List_of_file_signatures"><strong>magic byte</strong>.</a></li><li>Then, there is a <strong>header</strong> that represents the metadata of the file (In the case of machine learning, how many layers we have, the learning rate, and other aspects. )</li><li>The actual <strong>data</strong>. (In the case of machine learning files, the tensors)</li><li>We then need a <strong>spec</strong> that tells us what to expect in a file as we read it and what kinds of data types are in the file and how they’re represented as bytes. Essentially, documentation for the file’s layout and API so that we can program a file reader against it.</li><li>One feature the file spec usually tells us is whether data is little or big-endian, that is - whether we store the largest number first or last. This becomes important as we expect files to be read on systems with different default byte layouts.</li><li>We then implement code that reads and writes to that filespec specifically.</li></ol><p>One thing we start to notice from having looked at statedicts and pickle files before, is that machine learning data storage follow a pattern: we need to store:</p><ol><li>a large collection of vectors,</li><li>metadata about those vectors and</li><li>hyperparameters</li></ol><p>We then need to be able to instantiate model objects that we can hydrate (fill) with that data and run model operations on.</p><p>As an example for safetensors from the documentation: We start with a Python dictionary, aka a state dict, save, and load the file.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> torch
</span></span><span><span><span>from</span> safetensors <span>import</span> safe_open
</span></span><span><span><span>from</span> safetensors.torch <span>import</span> save_file
</span></span><span><span>
</span></span><span><span>tensors <span>=</span> {
</span></span><span><span>   <span>"weight1"</span>: torch<span>.</span>zeros((<span>1024</span>, <span>1024</span>)),
</span></span><span><span>   <span>"weight2"</span>: torch<span>.</span>zeros((<span>1024</span>, <span>1024</span>))
</span></span><span><span>}
</span></span><span><span>save_file(tensors, <span>"model.safetensors"</span>)
</span></span><span><span>
</span></span><span><span>tensors <span>=</span> {}
</span></span><span><span><span>with</span> safe_open(<span>"model.safetensors"</span>, framework<span>=</span><span>"pt"</span>, device<span>=</span><span>"cpu"</span>) <span>as</span> f:
</span></span><span><span>   <span>for</span> key <span>in</span> f<span>.</span>keys():
</span></span><span><span>       tensors[key] <span>=</span> f<span>.</span>get_tensor(key)
</span></span></code></pre></div><p>we use the save_file(model.state_dict(), ‘my_model.st’) method to render the file to safetensors</p><p>In the conversion process from pickle to safetensors, we also start <a href="https://github.com/huggingface/safetensors/blob/main/bindings/python/convert.py">with the state dict.</a></p><p>Safetensors quickly became the leading format for sharing model weights and architectures to use in further fine-tuning, and in some cases, inference</p><h2 id="checkpoint-files">Checkpoint files</h2><p>We’ve so far taken a look at simple <code>state_dict</code> files and single <code>safetensors</code> files. But if you’re training a long-running model, you’ll likely have more than just weights and biases to save, and you want to save your state every so often so you can revert if you start to see issues in your trianing run. <a href="https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html">PyTorch has checkpoints</a>. A checkpoint is a file that has a model <code>state_dict</code>, but also</p><blockquote><p>the optimizer’s state_dict, as this contains buffers and parameters that are updated as the model trains. Other items that you may want to save are the epoch you left off on, the latest recorded training loss, external torch.nn.Embedding layers, and more. This is also saved as a Dictionary and pickled, then unpickled when you need it. All of this is also saved to a dictionary, the <code>optimizer_state_dict</code>, distinct from the <code>model_state_dict</code>.</p></blockquote><div><pre tabindex="0"><code data-lang="python"><span><span><span># Additional information</span>
</span></span><span><span>EPOCH <span>=</span> <span>5</span>
</span></span><span><span>PATH <span>=</span> <span>"model.pt"</span>
</span></span><span><span>LOSS <span>=</span> <span>0.4</span>
</span></span><span><span>
</span></span><span><span>torch<span>.</span>save({
</span></span><span><span>            <span>'epoch'</span>: EPOCH,
</span></span><span><span>            <span>'model_state_dict'</span>: net<span>.</span>state_dict(),
</span></span><span><span>            <span>'optimizer_state_dict'</span>: optimizer<span>.</span>state_dict(),
</span></span><span><span>            <span>'loss'</span>: LOSS,
</span></span><span><span>            }, PATH)
</span></span></code></pre></div><p>In addition, most large language models also now include accompanying files like tokenizers, and on HuggingFace, metadata, etc. So if you’re working with PyTorch models as artifacts generated via the Transformers library, you’ll get a repo <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1/tree/main">that looks like this</a>.</p><h2 id="ggml">GGML</h2><p>As work to migrate from pickle to safetensors was ongoing for <a href="https://www.reddit.com/r/LocalLLaMA/comments/1ayd4xr/for_those_who_dont_know_what_different_model/">generalized model fine-tuning and inference</a>, Apple Silicon <a href="https://appleinsider.com/articles/23/12/13/apple-silicon-m3-pro-blows-away-nvidia-rtx-4090-gpu-in-ai-benchmark">continued to get a lot better.</a>. As a result, people started bringing modeling work and inference from large GPU-based computing clusters, to local and on-edge devices.</p><p>Georgi Gerganov’s project to make OpenAI’s Whisper run locally with <a href="https://github.com/ggerganov/whisper.cpp">Whisper.cpp.</a> was a success and the catalyst for later projects. The combination of the release of <a href="https://about.fb.com/news/2023/07/llama-2/">Llama-2 as a mostly open-source model</a>, combined with the rise of model compression techniques like <a href="https://huggingface.co/docs/peft/main/en/developer_guides/lora">LoRA</a>, large language models, which were typically only accessible on lab or industry-grade GPU hardware (inspie of the small CPU-based examples we’ve run here), also acted as a catalyst for thinking about working with and running personalized models locally.</p><p>Based on the interest and success of <code>whisper.cpp</code>, Gerganov created <a href="https://github.com/ggerganov/llama.cpp/issues/33#issuecomment-1465108022">llama.cpp</a>, a package for working with Llama model weights, originaly in pickle format, in GGML format, for local inference.</p><p>GGML was initialy both a library and a complementary format created specifically for on-edge inference for whisper. You can also <a href="https://www.reddit.com/r/LocalLLaMA/comments/15y9m64/fine_tuningggml_quantiziation_on_apple_silicon/">perform fine-tuning</a> with it, but generally it’s used to read models trained on PyTorch in GPU Linux-based environments and converted to GGML to run on Apple Silicon.</p><p>As an example, here is script for <a href="https://github.com/ggerganov/ggml">GGML</a> which <a href="https://github.com/ggerganov/ggml/blob/master/examples/gpt-2/convert-ckpt-to-ggml.py">converts PyTorch GPT-2 checkpoints</a> to the correct format, <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L64">read as a <code>.bin</code> file.</a>. The files are <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/download-model.sh#L41C64-L41C131">downloaded from OpenAI</a>.</p><p><a href="https://github.com/ggerganov/llama.cpp/issues/33#issuecomment-1465108022">The resulting GGML file compresses all of these into one and contains</a>:</p><ul><li><p>a magic number with an <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L91">optional version number</a></p></li><li><p><a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L92">model-specific hyperparameters</a>, including
metadata about the model, such as the number of layers, the number of heads, etc.
a ftype that describes the type of the majority of the tensors,
for GGML files, the quantization version is encoded in the ftype divided by 1000</p></li><li><p>an embedded vocabulary, which is a list of strings with length prepended.</p></li><li><p>finally, a <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L137">list of tensors</a> with their length-prepended name, type, and tensor data</p></li></ul><p>There are several elements that make GGML more efficient for local inference than checkpoint files. First, <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/src/ggml-impl.h#L45">it makes use of 16-bit floating point representations</a> of model weights. Generally, <code>torch</code> initializes floating point datatypes in <a href="https://pytorch.org/docs/stable/generated/torch.set_default_dtype.html">32-bit floats by default</a>. 16-bit, or half precision means that model weights use <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">50% less memory</a> at compute and inference time without significant loss in model accuracy. Other architectural choices include using C, which offers <a href="https://www.interviewbit.com/blog/difference-between-c-and-python/">more efficient memory allocation than Python</a>. And finally, GGML was built <a href="https://developer.apple.com/documentation/apple-silicon/tuning-your-code-s-performance-for-apple-silicon">optimized for Silicon.</a></p><p>Unfortunately, in its move to efficiency, GGML contained <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md#drawbacks">a number of breaking changes</a> that created issues for users.</p><p>The largest one was that, since everything, both data and metadata and hyperparameters, was written into the same file, if a model added hyperparameters, it would break backward compatibility that the new file couldn’t pick up. Additionally, no model architecture metadata is present in the file, and each architecture required its own conversion script. All of this led to brittle performance and the creation of <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md#gguf">GGUF.</a></p><h2 id="finally-gguf">Finally, GGUF</h2><p>GGUF has the same type of layout as GGML, with metadata and tensor data in a single file, but in addition is also designed to be backwards-compatible. The key difference is that previously instead of a list of values for the hyperparameters, the new file format uses a key-value lookup tables which accomodate shifting values.</p><p>The intiution we spent building up around how machine learning models work and file formats are laid out now allows us to understand the <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md#file-structure">GGUF format.</a></p><p>First, we know that GGUF models are little-endian by default for specific architectures, which we remember is when the least significant bytes come first and is optimized for different computer hardware architectures.</p><p>Then, we have <code>gguf_header_t</code>, which is the header</p><p>It includes the magic byte that tells us this is a GGUF file:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>Must be <span>`</span>GGUF<span>`</span> at the byte level: <span>`</span>0x47<span>`</span> <span>`</span>0x47<span>`</span> <span>`</span>0x55<span>`</span> <span>`</span>0x46<span>`</span>. 
</span></span></code></pre></div><p>as well as the key-value pairs:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// The metadata key-value pairs.
</span></span></span><span><span><span></span>    <span>gguf_metadata_kv_t</span> metadata_kv[metadata_kv_count];
</span></span></code></pre></div><p>This file format also offers versioning, in this case we see this is version 3 of the file format.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// Must be `3` for version described in this spec, which introduces big-endian support.
</span></span></span><span><span><span></span>    <span>//
</span></span></span><span><span><span></span>    <span>// This version should only be increased for structural changes to the format.
</span></span></span></code></pre></div><p>Then, we have the tensors</p><p>The entire file looks like this, and when we work with readers like <code>llama.cpp</code> and <code>ollama</code>, they take this spec and write code to open these files and read them.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/0da77173-fd21-470c-90d1-fa31bcfc7119" width="600"></figure><h2 id="conclusion">Conclusion</h2><p>We’ve been on a whirlwind adventure to build up our intuition of how machine learning models work, what artifacts they produce, how the machine learning artifact storage story has changed over the past couple years, and finally ended up in GGUF’s documentation to better understand the log that is presented to us when we perform local inference on artifacts in GGUF. Hope this is helpful, and good luck!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Financial systems take a holiday (105 pts)]]></title>
            <link>https://www.bitsaboutmoney.com/archive/financial-systems-take-a-holiday/</link>
            <guid>39553801</guid>
            <pubDate>Thu, 29 Feb 2024 19:21:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsaboutmoney.com/archive/financial-systems-take-a-holiday/">https://www.bitsaboutmoney.com/archive/financial-systems-take-a-holiday/</a>, See on <a href="https://news.ycombinator.com/item?id=39553801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>All systems reflect the culture they are created in, in ways great and small. The financial system, and the human and computer systems which compose it, have inherited norms about when work is performed from the diverse societies which built (and build) financial systems.</p><p>Your bank takes holidays. Your conception of a holiday is materially informed by when banks are closed. No system of importance can be accurately described without the context of the culture that created it and no culture can be accurately described without the context of the systems embedded in it. Neither is chicken; neither is egg.</p><p>Cultural commentary aside, this has material consequences. The app in your pocket that moves money gets less useful during holidays and on weekends.</p><p>This sometimes occasions gnashing of teeth. Many people and businesses find it inconvenient when financial systems are down. It also seems unnecessary. Financial systems are inseparably computer systems. Most similarly important computer systems don’t take holidays. Google doesn’t take holidays… or doesn’t seem to, from the perspective of a typical user, at any rate.</p><p>Technologists describe their systems as having “uptime” and measure it in “nines”, such as “We have five nines of uptime”, which means that a system has 99.999% uptime or, equivalently, about five minutes of downtime per year. Five nines is admirable in many circumstances and would be considered <em>disastrously</em> below expectations for e.g. Google Search.</p><p>Nonetheless, many financial systems <em>do</em> have availability which is far closer to five <em>twos</em>. They aren’t fully open for business during holidays, weekends, or outside of business hours. It turns out that “holidays”, “weekends”, and “business hours” are far deeper topics than one might think.</p><p>As always: while I previously worked at Stripe, and am an advisor to it, it does not necessarily endorse any commentary I make. Illustrations of engineering reality made below are for color purposes and taken from general industry knowledge rather than private knowledge of particular design documents for specific systems at any firm.</p><h2 id="what-is-a-holiday-anyway">What is a holiday, anyway?</h2><p>A holiday is any day you and your counterparty mutually agree is a holiday.</p><p>This is often an implicit agreement via <a href="https://en.wikipedia.org/wiki/Focal_point_(game_theory)">Schelling points</a>. No serious person disputes that Christmas Day is a holiday in the United States and accordingly no one needs to ask if Christmas Day is a holiday. (Many salarymen in Japan work on Christmas Day, of course, despite their coworkers Taro [1] and Patrick skipping work to... go to a Jewish friend’s birthday party or something. Taro and Patrick are, of course, <em>eccentric</em>.)</p><p>If I can pre-answer a poindextery observation: yes, I am aware that some people work on holidays. That is why we describe that as “working on a holiday” as opposed to “working.” The distinction often has material consequences.</p><p>For example: one of a million things <a href="https://twitter.com/patio11/status/1654988724353241088" rel="noreferrer">dooming</a> government <a href="https://www.bitsaboutmoney.com/archive/payroll-providers-power-respect/" rel="noreferrer">payroll</a> system modernization projects is that they require—and universally fail to budget for— substantial bespoke work by historians to figure out e.g. which set of documents is the controlling authority with respect to what overtime rate applies to meter maids in Chicago on Good Friday. Holidays can be broadly understood every-child-knows-this facts but they <em>can also</em> be contentious sites of explicit negotiation.</p><p>You might sensibly say “Ahh yes, but <em>legal</em> holidays or <em>federal government</em> holidays or <em>banking</em> holidays are not simply <em>agreements, </em>formal or informal, not in any way that matters. Those are… facts about society. They’re <em>real</em> and <em>legible</em>.”</p><p>I am a sometimes technologist. I predict that many non-specialists would have conversations with technologists about the nature of calendars, clocks, time zones, and whether time flows forward in a linear fashion and swiftly conclude that the night is dark and full of terrors. [2]</p><p>Take banking holidays. You might think there is an authoritative list of days on which bank branches are closed for business. Sure, they are closed <em>by custom</em>, but <em>that list</em> must exist, right? Banking holidays <a href="https://www.bitsaboutmoney.com/archive/seeing-like-a-bank/"><u>are legible to the banking system</u></a>, surely!</p><p><em>That</em> list does generally exist.</p><p>And so you might conclude “OK, then the holidays bank systems need to know about are <em>the banking holidays</em>. Which you have an exhaustive and authoritative list of. Problem solved.” And what’s that behind you? It’s social and engineering reality, come to destroy our sanity.</p><p>Allow me to offer an example: Company Foundation Day. Company Foundation Day is a holiday for many Japanese salarymen. Japan has a public holiday, National Foundation Day (国立記念日), every year on February 11th. It was established by order of the Cabinet more than 50 years ago. Many Japanese companies, including some which predate the issuance of that order, have a high degree of regard for their corporate history. So Company Foundation Day is a holiday, too.</p><p>What day was the company founded? It depends on the company [3]. You will be  unsurprised that Company Foundation Day is whenever a company says it is.</p><p>“Charming bit of salaryman trivia, Patrick, but what does this have to do with banking holidays?”</p><p>Well, you see, Japanese banks <em>are Japanese companies</em>. And so if you are a Japanese bank, it is very possible that <em>some</em> of your human and computer systems are, by your custom and practice, given a day of rest on a day <em>on a day when most Japanese salarymen are working</em>.</p><p>Now <em>it gets worse</em>. If you are a bank or other bit of financial infrastructure which interacts with a Japanese bank, congratulations, <em>you</em> now observe the Company Foundation Day of your counterparty with respect to some (probably relatively small) set of your operations.</p><p>What does that "observation" mean? It means whatever you agreed it means, which could be "Of course if you attempt to call your account representative on a holiday that call may be returned on the next business day." or "Of course if you or your computer system electronically communicates updated <a href="https://www.bitsaboutmoney.com/archive/kyc-and-aml-beyond-the-acronyms/" rel="noreferrer">KYC</a> information on a holiday our computer system will inform your computer system the KYC information has been accepted. 'Accepted' has a very specific meaning here. <em>No action will be taken</em> until the following business day, <em>unless</em> you <em>also</em> call or fax Operations to inform them of an emergency necessitating intervention on a holiday."</p><p>To promote the subtext to text: not all banks/etc which interact with Japanese banks are themselves well-informed about the culture that is Japanese salarymen. (The culture that is Japanese salaryman is often misunderstood to be coextensive with Japanese culture. There is no one single Japanese salaryman culture, though "salaryman" is useful shorthand for a cultural cluster. Reports of Japanese culture being a monolith are greatly exaggerated internally and externally. Sugimoto's Introduction to Japanese Society is a good text on this, if a bit dry.)</p><p>Now clearly your Japanese counterparty would not choose to surprise you with the fact of Company Foundation Day. Japan is considered exotic by many people, but it is a functioning democratic and capitalist society. Work does not constantly grind to a halt as salarymen are ambushed by other companies’ Company Foundation Day. No, salarymen do the sensible thing. They <em>wrote this down</em>. Flip to page 636 of the Operations Manual under the heading Observed Holidays. Look right there, in the middle of the list, exactly where a Japanese salaryman would expect to find his counterparty’s Company Foundation Day.</p><figure><img src="https://lh7-us.googleusercontent.com/maK8F3X_LuzDrdyNISHK2B6ytJ9ghm62pMefrC-5BnHi93nE36IY5g4ND7IunyyulkBnKrFP9AOypl099F8rP2itLeG0Iqtv_BvTua_hW7IWvZlgyae-rYW7ju6OFti4wWCet_Ap6P_hoPF9tXTtUhw" alt="Four panel Anakin/Padme meme which makes an ironic observation about likelihood Operations Manual was read." loading="lazy" width="500" height="500"></figure><p>Now, suppose you are a large company. To ensure that your systems reflect reality, your technologists very likely have created some formal system which tracks holidays. The first time you do business with a Japanese counterparty, one of them will add a list of Japanese banking holidays to the system, and another will check the work. Perhaps the list added will be sourced from a data provider, like e.g. Bloomberg. Perhaps it will be gathered by looking at Google Calendar’s list or a Wikipedia article. Perhaps your technologists, being careful, will say neither of those is good enough, and will attempt to find an <em>authoritative</em> list of holidays in a publication of the government.</p><p>Different companies will adopt different strategies. Guess which holiday <em>none</em> of the above data sources will mention. But it is <em>definitely a holiday </em>because <em>it has all the consequences of being a holiday</em>.</p><p>Not only will one soon find oneself with substantial egg on one’s face, one will very often have to organize one’s engineering team to quickly redefine <em>how one’s systems understand holidays worldwide</em> in response to the incident this fact pattern will create. Because, yes, some holidays exist only per-company, and if your financial institution is sophisticated, a computer querying whether it is a holiday or not on a particular day probably passes the jurisdiction of interest but probably does not pass the counterparty of interest when doing the lookup.</p><p>Now you could, at this point, throw your hands up in the air and say "Other people's culture is not my problem! This is a quirky edge case upon an edge case! Begone!" Goodness knows you would not be the first technologist to say that. But—and this is extremely <em>not</em> legal advice—Compliance has a definite point of view on whether you are allowed to intentionally build a KYC system which could, given your company's positive knowledge that it has accidentally moved money for a terrorist in the past and is in the process of doing so at the present moment, inform its financial parters about the terrorist <em>tomorrow</em>. Compliance also has a definite <a href="https://www.bitsaboutmoney.com/archive/bond-villain-compliance-strategy/" rel="noreferrer">point of view</a> on the wisdom of writing down that one considers a particular foreign nation a Nice To Have, really, on the list of nations where one has addressed one's domestic-to-you responsibilities and routinely follows the domestic-to-them law.</p><h2 id="fun-operational-consequences-of-holidays">Fun operational consequences of holidays</h2><p>Holidays <em>as observed</em> often are used to extend weekends, for both operational and social purposes.</p><p>If a holiday is defined as a fixed date on the calendar, it will periodically fall on a weekend, and in many nations many organizations will add an “as observed” day which is not that fixed date which expands the weekend.</p><p>Many holidays are, of course, not on fixed dates, but change every year. Why do you think we send you a new Operations Manual every year. Did you think we think you lost the old one. We have much higher regard for you than that.</p><p>Easter is March 31st in 2024. Try explaining why it is March 31st this year and not a date in April to a Chinese banker not familiar with Judaism. (If one objects that Easter is not a Jewish holiday, one should not attempt to explain the timing of Easter to a Chinese banker, or anyone else really. If one objects “Easter on which side of which schism?”, one has a good understanding of the challenges here.)</p><p>Anyhow, however they are scheduled, holidays routinely cause long weekends to happen.</p><p>Long weekends have consequences in the material world. Human activity does not stop during weekends or on holidays. Certain human activity that the financial system <em>cares about keenly</em>, such as consumer payments to businesses for goods and services, predictably explodes on or around certain holidays.</p><p>Take Black Friday / Cyber Monday.&nbsp;(BFCM, in some quarters.)</p><p><em>When</em> is Black Friday? The day after Thanksgiving. When is Thanksgiving? Whenever Americans think it is. Many Americans think it is the 4th Thursday in November. But Thanksgiving is so inextricably bound with the American commercial calendar that the reason Americans celebrate it on the 4th Thanksgiving was because <a href="https://www.britannica.com/story/why-is-thanksgiving-in-the-us-celebrated-on-a-thursday">previously we had multiple Thanksgivings</a> and <em>this caused operational problems for retailers</em>.</p><p><em>Why</em> is Black Friday? Because Americans, by well-established custom, get two holidays for Thanksgiving. By well-established custom, they typically spend Thanksgiving with family. Then, the day after, while they are not expected to work, they often attempt to get an early start on shopping for Christmas presents. Retailers have long since adapted to this phenomenon, throwing special promotions to juice sales on Black Friday. Retailers not participating in Black Friday lost share of wallet as customers spent their holiday budgets at ones that did.</p><p>This has thoroughly enshrined Black Friday in the practice of many retailers, including in Japan. In Japan, a certain large e-commerce company you may have heard of instructed teams to appropriately celebrate the holiday. Japanese people do not typically celebrate Thanksgiving, and Japan consumes very little turkey, but Japanese salarymen given an order by their boss are socialized to comply with the utmost diligence and peformative enthusiasm even when that order has a puzzling basis (or no basis at all, for that matter).</p><p>The salarymen did the natural thing: they organized a special promotion on—<em>I swear on my honor as a salaryman, may my fax toner dry out forever if I lie</em>— items which are black. It worked <em>very well</em>.</p><p>And so, by ancient custom, some extremely large Japanese companies celebrate Black Friday, the day after the 4th Thursday in November, the day where people of good will come together to buy black things at attractive prices.</p><p>This is all fascinating for people who work in retail or e-commerce. For financial systems, an interesting knock-on consequence of it is that you will have a sudden, predictable-as-the-sun-rising transaction surge on Black Friday, <em>smack dab in the middle of a four day period during which money is not moving</em>. We will return to that in a moment.</p><p>Money starts moving again on Monday. Cyber Monday.</p><p><em>Why</em> is Cyber Monday? It commemorates a perhaps apocryphal meeting between  very different peoples, not infrequently in conflict but fundamentally joined with each other, and their decision to bond over a universal human experience: shopping.&nbsp;</p><p>Cyber Monday <em>also</em> causes a transaction surge. The more indexed a financial institution is to e-commerce companies relative to non-retailing or not-very-online companies, the larger a transaction surge they will see. As time goes to infinity the Internet economy will be called “the economy”, but time is very far from infinity yet, and so different firms have differential exposure to “cyber.” [4]</p><p>Now let’s ignore the sociology and marketing considerations and focus simply on the operational mechanics: a staggering volume of purchases went through, over a variety of payment systems with very different legal and technical substrates, during a period in which the banking system <em>mostly</em> does not move money between companies.</p><p>Payments companies (and others) owe performance to their customers as defined by contracts, negotiations, market norms, promises, implicit understandings, and similar. And sometimes there is a mismatch between what is expected and what can be easily delivered.</p><p>This problem presents in fractal detail at many firms. Let’s simplify it for the purpose of illustration.</p><p>If you have promised your customer “I will pay out your sales on the next business day” and an underlying “rail” [5] takes <em>two</em> business days to pay you, you have a one-day mismatch. Your promise “consumes float.” [6] There are many, many ways you can deal with this in the ordinary course of business, and they all round to “constantly advance customers a bit of our own money.”</p><p><em>Why</em> do you do that? Many financial institutions insulate their customers from complexity and risk because <em>that is the service the financial industry offers to society</em>. We (the financial industry) teleport value through time and across space and make this look easy. We (every user of every financial system, inclusive of you and me) pay for that. </p><p>Complexity and risk are, like matter and energy, conserved within the system. Moving them from individual businesses to financial providers lets the providers deal with them efficiently for usual specialization-of-labor and comparative advantage reasons.&nbsp;</p><p>Anyhow, once a year, extremely predictable <em>in timing</em> but not necessarily <em>in magnitude</em>, you do not need to float one day of sales, like you do daily. You do not need to float three days, like most weekends. You need to float five-ish days <em>including the largest sale day of the year</em>. And you whisper fervent prayers that all the wires you expect arrive <em>exactly</em> when you expect them.</p><p>What are those wire sized like? I mean, in this sketch of issues that affect a large universe of companies differently, it could vary considerably. Let <a href="https://stripe.com/newsroom/news/bfcm2023"><u>your imagination</u></a> run wild.</p><p>Black Friday would be a bad day for hitches principally because you don’t want to break for customers on a very important day for them. Cyber Monday would be a bad day for hitches for that reason, too, but also because an entirely different kind of breakage <em>at an entirely different company</em> would hit you like a freight train.</p><p>And since you’re aware of that, maybe hundreds of people have spent the last few weeks diligently wargaming out the BFCM scenarios and writing contingency plans. Maybe you also carefully modeled BFCM float needs with finance. Maybe you also did pedestrian but real capital markets work to make sure that you could survive another company having an unfortunately timed operational stumble.</p><p><a href="https://www.sleepfoundation.org/nutrition/what-is-tryptophan" rel="noreferrer">Tryptophan</a> makes us do strange things, after all.</p><h2 id="this-is-crazy-let%E2%80%99s-get-rid-of-holidays">"This is crazy. Let’s get rid of holidays."</h2><p>The culture that is heavily-online technologists is extremely frustrated with systems which go down on a predictable schedule.</p><p>Cryptocurrency enthusiasts in particular enjoy distributed systems that are constantly up and have no single points of failure. For example, you could have every actor in the financial markets open accounts at a single bank. Why would you do that? Well, most trades involve one leg that never sleeps (blockchains, an industry term for slow databases) and one leg which implicates money (which largely exists on fast databases operated by organizations that do have sleep schedules and holidays). Convince one bank to give you an internal API to make book transfers and now money moves 24/7. And just for redundancy, we’ll use <a href="https://ir.silvergate.com/news/news-details/2023/Silvergate-Capital-Corporation-Announces-Intent-to-Wind-Down-Operations-and-Voluntarily-Liquidate-Silvergate-Bank/default.aspx"><u>two</u></a> <a href="https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/signature-ny.html"><u>banks</u></a>. Checkmate, TradFi.</p><p>Less sardonically, there is a lesson here: systems which intermediate between cultures <em>are useful</em>. Intermediating between cultures is a thing the world urgently needs and <em>is extremely prepared to pay for</em>. Systems which intermediate between cultures will frequently need to cross a gap between operating schedules. You cannot simply wish away that gap. You cannot simply assert that the one true operating schedule is 24/7.</p><p>That certainly doesn’t stop technologists from trying. If you want to drive one batty, ask about the IRS applications which have office hours (<a href="https://www.irs.gov/refunds/when-is-wheres-my-refund-available"><u>example</u></a>).</p><p>There is, believe it or not, an engineering reason for some applications to have office hours, which you’ll see in multiple places in the U.S. government. Generally: the application interfaces with a legacy system which ultimately depends on choices made back during the mainframe era. During that era, computer operators could run programs in interactive mode, with an operator at the keyboard, or in batch mode. To avoid impacting the operators of the system (i.e. regular employees doing their day-to-day jobs), batches were designed to be run at night. And so they have been run at night for many, many decades.</p><p>Now, here’s the rub: <em>we don’t know</em> if the interactive mode programs, like say looking up the status of a tax refund, are safe to run while the batches are running. [7] So we continue previous practice and don’t allow the interactive mode programs to run while the batch programs are running. It would be a very, very bad thing if the software which in a very real way <em>is the United States of America</em> suddenly developed data integrity issues because someone hooked a web application to it. The technologists (and managers) in charge of those systems are terrified of e.g. data integrity issues when e.g. sending out Social Security payments because the consequences of that would include e.g. food riots in Kansas.</p><p>But that is more an explanation of an infelicity rather than an argument that there is actually a positive consequence of holidays. There is.</p><p>Would you believe that banks <em>intentionally cause misaligned operating schedules</em>? It is an important tool to detect and discourage particular forms of fraud.</p><p>A particular terrifying genre of fraud is perpetrated by insiders with advanced knowledge of a financial institution’s back office procedures. A teenager with moral flexibility can cheat you out of a pair of sneakers. A professionalized fraud operation based in a non-extradition country can rob you for millions. But a single insider who understands your back office reasonably well can bring down a bank or cause billions of losses. Barrings and Daiwa in ‘95. Société Générale in ‘08. UBS in ‘11. [8]</p><p>A <em>very old</em> control for this sort of thing is forcing holidays, with the goal that the set of staff engaged in a conspiracy don’t have a sufficient number of conspirators at the keyboard in all the right places on all the right days the conspiracy needs to operate to be undetected.</p><p>A financial CEO who <a href="https://www.bloomberg.com/features/2023-ftx-crypto-photos/" rel="noreferrer">sleeps at the office on a beanbag chair</a> might be commendably devoted to his work. But it is no slur against devoted CEOs to say that their companies and their customers would be well-served by them <em>not being allowed to do that</em>. Take the day off. Let someone cover for you. "Cover" in the sense of "handle your work while you are at rest", not in the sense of "cover up" a hole in the balance sheet. Nobody expects that there is a hole in the balance sheet. And since there is not a hole in the balance sheet, a fellow responsible professional who has an enormous personal and professional regard for you will, applying math and procedures in the usual fashion, receive a balance sheet from you when you leave and give an updated one to you when you return. Perfectly balanced as all things should be. No need to snap.</p><p><em>If we didn’t have holidays, we’d have been forced to invent them.</em> We accept degraded performance (very useful humans: not at keyboard!) as an organizational <a href="https://www.techtarget.com/whatis/definition/Chaos-Monkey">chaos monkey</a> to shake out far more serious issues.</p><p>Does it work? Well, there exist financial institutions that haven’t been reduced to smoking craters by insider fraud, so that is a point in its favor. And, like all controls, this one operates in a constellation (different controls reinforce each other) and on a portfolio basis (you win some and you lose some but are judged on how they net rather than judged on absence of losers).</p><h3 id="will-this-change">Will this change?</h3><p>In an increasingly interconnected world where decisions are increasingly made by people who count <em>and value</em> nines, you can reasonably expect financial systems to partially close the gap between historical practice and contemporary practice of e.g. Google Search.</p><p>As I said before: cultures create systems and systems create cultures. Both systems and cultures <em>change over time</em>. The rate of change in infrastructure specifically is much lower than the rate of change we observe in e.g. fashion. But infrastructure <em>does change</em>. Credit cards were invented in a world where Chicago and Los Angeles were considered to be socially distant from each other, to allow Chicagoans in L.A. to enjoy the same trust they would enjoy in Chicago. Cultural change, <em>real observable change with consequences</em>, is not something that can only be measured on generational timescales. </p><p>But should one expect the financial system to operate constantly? Not only should you not expect that, that is not even a coherent thing to expect. The financial system is an interconnected web of individual organizations which contain systems which contain some combination of subsystems etc etc etc and at some level depends on individual people to whom complex sociocultural promises have been made and who have biological need for sleep.</p><p>And those people, for the foreseeable future, will continue to periodically rest and continue to periodically celebrate just like they continue to work on the behalf of the societies their financial systems support.</p><p><br>[1] While Taro is quite a popular name in Japan, Taro is also the usual analog to  the John in John Doe. Jane Doe is frequently rendered as Hanako. When you find them in a particular company's documentation, their family name will frequently be the name of the company, which is delightful for readers of Japanese corporate documentation who are also cyberpunk fans. (This includes many writers of Japanese corporate documentation.)</p><p>[2] The Red Priestess Melisandre could not be reached for comment on whether the Lord of Light's theology encompasses computer systems.</p><p>[3] Serious paperwork connoisseurs know that "It depends" is a deep rabbit hole here, including in the United States. Was the day a company founded the day the founders started working on a project or the day they mutually agreed it should be a company or the day they signed a contract with each other or the day they submitted paperwork to the state of Delaware or the day Delaware declared that paperwork was accepted? <em>Yes</em>. The fact that the day the company was founded and the day the company was founded are frequently months apart is not even a tiny bit weird.</p><p>[4] Readers of a certain age might sensibly ask what “cyber” means. Consider it a way to gesture broadly at technology used almost exclusively by people who both do not understand technology and feel some amount of pride in that. Teams at large retailers, believing online commerce was doomed to be a tiny sideline like catalogs and only worth tens of billions of dollars, were involved in naming Cyber Monday. The other place you’re likely to hear it frequently is American national security circles, which exist in a superposition of understanding that technology can certainly be used to kill people and break things while also believing that it’s not a <em>real</em> way to kill people and break things if it is the sort of technology built by people who look like pre-juice Steve Rogers.</p><p>[5] "Financial rails" are the legal, technical, and organizational infrastructure which allows one to move money around. That's a mouthful; "rails" is one syllable and also communicates "I believe I understand this; you don't need to explain to me that money doesn't actually move when we move money." An illustrative usage: "Did that transaction go over ACH rails?" "No, it was <a href="https://twitter.com/patio11/status/1752054398858022990" rel="noreferrer">on us</a>."</p><p>[6] Positive float is the characteristic that you enjoy the legitimate but temporary use of other people's money as a consequence of their business dealings with you not specifically intended to cause that. The classic example is in the insurance industry, where insurers might get a few years to sit on premiums before paying them back out. Negative float is the opposite condition, where others get to use your money. Negative float <em>isn't bad</em>. It will cause you to incur a cost of doing business, like labor and rent are a cost of doing business, in the service of providing a valuable service to customers at a reasonable price.</p><p>[7] To spare you a long digression into the joys of government system architecture documents, accept this sketch: the IRS' web applications are frequently impersonating a human operator with preternaturally good typing skills.</p><p>[8] Yes, this is a reference to Margin Call, the best movie about finance ever made. The scene it references isn't even in the best five scenes of a single character (a bank CEO played by Jeremy Irons in what might be the best work of a distinguished career).</p>

        

        <div>
          <h2>Want more essays in your inbox?</h2>
          <p>I write about the intersection of tech and finance, approximately biweekly. It's free.</p>
                  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Money bubble (164 pts)]]></title>
            <link>https://www.tbray.org/ongoing/When/202x/2024/02/25/Money-AI-Bubble</link>
            <guid>39553743</guid>
            <pubDate>Thu, 29 Feb 2024 19:17:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tbray.org/ongoing/When/202x/2024/02/25/Money-AI-Bubble">https://www.tbray.org/ongoing/When/202x/2024/02/25/Money-AI-Bubble</a>, See on <a href="https://news.ycombinator.com/item?id=39553743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="centercontent">
<p itemprop="description">I think I’m probably going to lose quite a lot of money in the next year or two. It’s partly AI’s fault, but not
    mostly. Nonetheless I’m mostly going to write about AI, because it intersects the technosphere, where I’ve lived for
    decades.</p>

<p>I’ve given up having a regular job. The family still has income but mostly we’re harvesting our
    savings, built up over decades in a well-paid profession. Which means that we are, willy-nilly, investors. And thus aware of the
    fever-dream finance landscape that is InvestorWorld.</p>

<p id="p-1"><span>The Larger Bubble</span> · 
Put in the simplest way: Things have been too good for too long in InvestorWorld: low interest, high profits, the unending rocket
    rise of the Big-Tech sector, now with AI afterburners. Wile E. Coyote hasn’t actually run off the edge of the cliff yet, but
    there are just way more ways for things to go wrong than right in the immediate future.</p>

<p>If you want to dive a little deeper, <cite>The Economist</cite> has a sharp (but
    paywalled) take in
    <a href="https://www.economist.com/finance-and-economics/2024/02/25/stockmarkets-are-booming-but-the-good-times-are-unlikely-to-last">Stockmarkets
    are booming. But the good times are unlikely to last</a>. Their argument is that profits are overvalued by investors because, in
    recent years, they’ve always gone up. Mr Market ignores the fact that that at least some of those gleaming profits are artifacts of
    tax-slashing by right-wing governments.</p>

<p>That piece considers the observation that “Many investors hope that AI will ride to the rescue” and is politely
    skeptical.</p>

<p id="p-2"><span>Popping the bubble</span> · 
My own feelings aren’t polite; closer to
    <a href="https://finance.yahoo.com/news/yep-you-are-living-in-a-nvidia-led-tech-bubble-110014738.html">Yep, you are living in a
    Nvidia-led tech bubble</a> by Brian Sozzi over at Yahoo! Finance.</p>

<p>Sozzi is fair, pointing out that this bubble feels different from the cannabis and crypto crazes; among other things,
    chipmakers and cloud providers are reporting big high-margin revenues for real actual products. But he hammers the central point:
    What we’re seeing is FOMO-driven dumb money thrown at technology by people who have no hope of
    understanding it. Just because everybody else is and because the GPTs and image generators have cool demos.
    Sozzi has the numbers, looking at valuations through standard old-as-dirt filters and shaking his head at what he sees.</p>

<p>What’s going to happen, I’m pretty sure, is that AI/ML will, inevitably, disappoint; in the financial sense I mean, probably
    doing some useful things, maybe even a lot, but not generating the kind of profit explosions that you’d need to justify
    the bubble. So it’ll pop, and my bet it is takes a bunch of the finance world with it. As bad as 2008? Nobody knows, but it
    wouldn’t surprise me.</p>

<p>The rest of this piece considers the issues facing AI/ML,  with the goal of showing why I see it as
    a bubble-inflator and eventual bubble-popper.</p>

<p>First, a disclosure: I speak as an educated amateur. I’ve never gone much below the surface of the technology, never
    constructed a model or built model-processing software, or looked closely at the math.  But I think the discussion below still
    works.</p>

<p id="p-3"><span>What’s good about AI/ML</span> · 
Spoiler: I’m not the kind of burn-it-with-fire skeptic that I became around anything blockchain-flavored. It is clear
    that generative models manage to embed significant parts of the structure of language, of code, of pictures, of
    many things where that has previously not been the case. The understanding is sufficient to reliably accomplish the objective:
    <i>Produce plausible output</i>.</p>

<p>I’ve read enough Chomsky to believe that facility with language is a defining characteristic of intelligence. More than that, a
    necessary but not sufficient ingredient.  I dunno if anyone will build an AGI in my lifetime, but I am confident that the task
    would remain beyond reach without the functions offered by today’s generative models.</p>

<p>Furthermore, I’m super impressed by something nobody else seems to talk about: Prompt parsing. Obviously, prompts are
    processed into a representation that reliably sends the model-traversal logic down substantially the right
    paths. The LLMbots of this world may regularly be crazy and/or just wrong, but they do consistently if not correctly address the
    substance of the prompt.
    There is seriously good natural-language engineering going on here that AI’s critics aren’t paying enough attention
    to.</p>

<p>So I have no patience with those who scoff at today’s technology, accusing it being a glorified Markov chain. Like the
    song says:  Something’s
    happening here! (What it is ain’t exactly clear.)</p>

<p>It helps that in the late teens I saw neural-net pattern-matching at work on real-world problems from close up and
    developed serious respect for what that technology can do; An example is EC2’s
    <a href="https://aws.amazon.com/blogs/compute/evaluating-predictive-scaling-for-amazon-ec2-capacity-optimization/">Predictive Auto
    Scaling</a> (and gosh, it looks like
    <a href="https://www.google.com/search?rls=en&amp;q=predictive+auto+scaling&amp;ie=UTF-8&amp;oe=UTF-8">the competition has it
    too</a>).</p>

<p>And recently, Adobe Lightroom has shipped a pretty awesome “Select Sky” feature. It makes my M2 MacBook
    Pro think hard for a second or two, but I rarely see it miss even an isolated scrap of sky off in the corner of the frame.  It
    allows me, in a picture like this, to make the sky’s brightness echo the water’s.</p>

<p><a href="https://www.tbray.org/ongoing/When/202x/2024/02/25/-big/PXL_20240111_213727870.jpg.html"><img alt="Brightly-lit boats on dark water under a dark sky" title="Brightly-lit boats on dark water under a dark sky" src="https://www.tbray.org/ongoing/When/202x/2024/02/25/PXL_20240111_213727870.png"></a></p>
<p>And of course I’ve heard about success stories in radiology and other disciplines.</p>

<p>Thus, please don’t call me an “AI skeptic” or some such. There is a there there.</p>

<p id="p-4"><span>But…</span> · 
Given that, why do I still think that the flood of money being thrown at this tech is dumb, and that most of it will be lost?
    Partly just because of that flood. When financial decision makers throw loads of money at things they don’t
    understand, lots of it is <em>always</em> lost.</p>

<p>In the Venture-Capital business, that’s an understood part of the business
    cycle; they’re looking to balance that out with a small number of 10x startup wins.
    But when big old insurance companies and airlines and so on are piling in and releasing effusive statements about building
    the company around some new tech voodoo, the outcome, in my experience, is very rarely good.</p>

<p>But let’s be specific.</p>

<p id="p-5"><span>Meaning</span> · 
As I said above, I think the human mind has a large and important language-processing system.  But that’s not all. It’s also
    a (slow, poorly-understood) computer, with access to a medium-large database of facts and recollections, an ultra-slow numeric
    processor, and a facilities for estimation, prediction, speculation, and invention. Let’s group all this stuff together and call
    it “meaning”.</p>

<p>Have a look at <a href="https://aclanthology.org/2020.acl-main.463.pdf">Climbing towards NLU:
    On Meaning, Form, and Understanding in the Age of Data</a> by Emily Bender and Alexander Koller (July 2000). I don’t agree with
    all of it, and it addresses an earlier generation of generative models, but it’s very thought-provoking. It postulates the
    “Octopus Test”, a good variation on the bad old Chinese-Room analogy. It talks usefully about how human language acquisition
    works. A couple of quotes: “It is instructive to look at the past to appreciate this question. Computational linguistics has
    gone through many fashion cycles over the course of its history” and “In this paper, we have argued that in contrast to some
    current hype, meaning cannot be learned from form alone.”</p>

<p>I’m not saying these problems can’t be solved. Software systems can be equipped with databases of facts, and who knows,
    perhaps some day estimation, prediction, speculation, and invention. But it’s not going to be easy.</p>

<p id="p-7"><span>Difficulty</span> · 
I think there’s a useful analogy between the stories AI and of self-driving cars. As I write this, 
    Apple has apparently decided that 
    <a href="https://arstechnica.com/gadgets/2024/02/after-a-decade-of-stops-and-starts-apple-kills-its-electric-car-project">generative 
    AI is easier than shipping an autonomous car</a>. I’m particularly sensitive to this analogy because back around 2010, as the
    first self-driving prototypes were coming into view, I predicted, loudly and in public, that this technology was about to become
    ubiquitous and turn the economy inside out. Ouch.</p>

<p>There’s a pattern: The technologies that really do change the world tend to have strings of successes, producing obvious
    benefits even in their earliest forms, to the extent that geeks load them in the back floor of organizations just to get shit
    done. As they say, “The CIO is the last to know.”</p>

<p>Contrast cryptocurrencies and blockchains, which limped along from year to year, always promising a brilliant future, never
    doing anything useful.  As to the usefulness of self-driving technology, I still think it’s gonna get there, but it’s surrounded
    by a cloud of litigation.</p>

<p>Anyhow, anybody who thinks that it’ll be easy to teach “meaning” (as I described it above) to today’s generative AI is a fool,
    and you shouldn’t give them your money.</p>

<p id="p-6"><span>Money and carbon</span> · 
Another big problem we’re not talking about enough is the cost of generative AI.
    <cite>Nature</cite> offers    
    <a href="https://www.nature.com/articles/d41586-024-00478-x">Generative AI’s environmental costs are soaring — and mostly
    secret</a>. In a Mastodon thread,
    <a href="https://phanpy.social/#/social.v.st/a/109360452395342558">@Quixoticgeek@social.v.st</a> says 
    <a href="https://phanpy.social/#/social.v.st/s/111991430750212364">We need to talk about data centres</a>, and includes a few
    hard and sobering numbers.</p>

<p>Short form: This shit is <em>expensive</em>, in dollars and in carbon load. Nvidia pulled in
    <a href="https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/">$60.9
    billion in 2023, up 126% from the previous year</a>, and is heading for a $100B/year run rate, while reporting a 75% margin.</p>

<p>Another thing these articles <em>don’t</em> mention is that building, deploying, and running generative-AI systems requires significant
    effort from a small group of people who now apparently constitute the world’s highest-paid cadre of engineers. And good luck
    trying to hire one if you’re a mainstream company where IT is a cost center.</p>

<p>All this means that for the technology to succeed, it not only has to do something useful, but people and businesses will have to
    be ready to pay a significantly high price for that something.</p>

<p>I’m not saying that there’s nothing that qualifies, but I am betting that it’s not in ad-supported territory.</p>

<p>Also, it’s going to have to deal with pushback from unreasonable climate-change resisters like, for example, me.</p>

<p id="p-8"><span>Anyhow…</span> · 
I kind of flipped out, and was motivated to finish this blog piece, when I saw
    <a href="https://www.engadget.com/uk-government-wants-to-use-ai-to-cut-civil-service-jobs-140031159.html">this</a>: “UK
    government wants to use AI to cut civil service jobs: Yes, you read that right.” The idea<span> —</span> to have
    citizen input processed and responded to by an LLM<span> —</span> is hideously toxic and broken; and usefully
    reveals the kind of thinking that makes morally crippled leaders all across our system love this technology.</p>

<p>The road ahead looks bumpy from where I sit. And when the business community wakes up and realizes that replacing
    people with shitty technology doesn’t show up as a positive on the financials after you factor in the consequences of customer
    rage, that’s when the hot air gushes out of the bubble.</p>

<p>It might not take big chunks of InvestorWorld with it. But I’m betting it does.</p>

<hr>


<hr>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dune: Part Two Is the Best Sci-Fi Film of the Decade (107 pts)]]></title>
            <link>https://www.esquire.com/entertainment/movies/a46885292/dune-part-two-review/</link>
            <guid>39553000</guid>
            <pubDate>Thu, 29 Feb 2024 18:22:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.esquire.com/entertainment/movies/a46885292/dune-part-two-review/">https://www.esquire.com/entertainment/movies/a46885292/dune-part-two-review/</a>, See on <a href="https://news.ycombinator.com/item?id=39553000">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-body="standard-article"><p data-journey-content="true" data-node-id="0">You don’t need to be a studio head or a theater owner to realize that everyone in Hollywood has their fingers crossed for <em><a href="https://www.esquire.com/entertainment/movies/a38040674/dune-2-sequel-details/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a38040674/dune-2-sequel-details/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Dune: Part Two">Dune: Part Two</a></em>. Sure, the <a href="https://www.esquire.com/entertainment/movies/a46502302/oscars-2024-snubs-surprises/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46502302/oscars-2024-snubs-surprises/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Oscars">Oscars</a> are right around the corner, and there are certainly plenty of great films from last year that are worth celebrating, but so far 2024 has been an absolute shit show at the box office. Business had been bad and the product has been even worse. Granted, we’re only three weeks into February, so the sample size is small, but you know things are rough in Tinseltown when trash like <em>Argylle</em> opens at No. 1 and the latest <a href="https://www.esquire.com/entertainment/movies/g13441903/all-marvel-cinematic-universe-movies-ranked/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/g13441903/all-marvel-cinematic-universe-movies-ranked/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Marvel">Marvel</a>-affiliated widget off the production line currently sits on Rotten Tomatoes beside a fat green splat and a woeful 13% favorable rating. </p><p data-journey-content="true" data-node-id="1">What does any of this have to do with <em>Dune: Part Two</em>, you may ask. Well, director Denis Villeneuve’s hotly anticipated follow-up to his blissfully weird 2021 adaptation of <a href="https://www.esquire.com/entertainment/books/g38012512/dune-books-in-order/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/books/g38012512/dune-books-in-order/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Frank Herbert’s talismanic 1968 novel">Frank Herbert’s talismanic 1968 novel</a> was originally slated to open last November. But because of the <a href="https://www.esquire.com/entertainment/a44544249/sag-aftra-actors-strike-consequences-explained/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/a44544249/sag-aftra-actors-strike-consequences-explained/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="actors strike">actors strike</a>, Warner Bros. opted to push the film to March 2024, no doubt so that Timothée Chalamet, Zendaya, and newcomers Florence Pugh and <a href="https://www.esquire.com/entertainment/movies/a46603112/austin-butler-dune-masters-of-the-air-interview-2024/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46603112/austin-butler-dune-masters-of-the-air-interview-2024/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Austin Butler ">Austin Butler </a>could peacock on the red carpet and promote it to the heavens on the late-night talk show circuit. Of course, sci-fi fans bitched and bellyached, as they do. But in retrospect the delay turned out to be a pretty wise move. After all, back in November, all anyone was talking about was <a href="https://www.esquire.com/entertainment/movies/a44495541/barbenheimer-double-feature/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a44495541/barbenheimer-double-feature/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Barbenheimer">Barbenheimer</a> and <a href="https://www.esquire.com/entertainment/movies/a46166568/leonard-bernstein-felicia-montealegre-true-story-maestro/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46166568/leonard-bernstein-felicia-montealegre-true-story-maestro/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Bradley Cooper’s fake schnozz">Bradley Cooper’s fake schnozz</a>. There wasn’t a lot of oxygen left in the room. But now? Now the stage couldn’t be better set for the further adventures of Paul Atreides. If the <a href="https://www.esquire.com/entertainment/movies/g46353374/best-movies-2024/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/g46353374/best-movies-2024/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="movies">movies</a> ever needed a savior, it’s right this second. </p><p data-journey-content="true" data-node-id="3">Glancing back at my <a href="https://www.esquire.com/entertainment/movies/a38023702/dune-movie-2021-review/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a38023702/dune-movie-2021-review/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="review of the first Dune on this site back in 2021">review of the first <em>Dune</em> on this site back in 2021</a>, I noticed that I called it “the best sci-fi movie of the decade.” Hyperbole? Not really. Remember, the decade wasn’t all that old yet. And to be honest, heading in to the new sequel, I stood by it. But walking out was a different story. Because <em>Dune: Part Two</em> is even better than the first film. The stakes somehow feel exponentially higher, the power struggles are even more mythic and Shakespearean, the onscreen world-building is richer and more exotically filigreed, and the visuals are even more epic and dazzling—something I didn’t think was possible. <em>Dune: Part Two</em> isn’t just an embarrassment of narrative and retinal riches; it’s the sort of big-canvas franchise storytelling we haven’t see since <em>The Lord of the Rings </em>came to a close back at the shire. </p><div size="medium" data-embed="body-image" data-lazy-id="P0-8" data-node-id="4"><p><img alt="dune" title="dune" loading="lazy" width="2100" height="1107" decoding="async" data-nimg="1" sizes="100vw" srcset="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=640:* 640w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=768:* 980w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:* 1120w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:* 1200w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:* 1920w" src="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:*"></p><div><figcaption><span>Niko Tavernise/Warner Bros. Entertainment</span></figcaption><p>Now that Paul Atriedes made the leap to battle-tested hero, Chalamet really lets it fly, summoning a more interesting performance.</p></div></div><p data-journey-content="true" data-node-id="5">If you haven’t revisited the first <em>Dune</em> since it left the multiplex, you don’t need to worry. The opening moments of the film get you right back up to speed without sending you to Wikipedia. Picking up almost exactly where things left off in the opening chapter, we’re reminded that the House of Atreides has fallen with the death of <a href="https://www.esquire.com/entertainment/tv/a39520165/oscar-isaac-interview-moon-knight-star-wars/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/tv/a39520165/oscar-isaac-interview-moon-knight-star-wars/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Oscar Isaac’s">Oscar Isaac’s</a> Duke. The dreaded, pasty-faced Harkonnens have taken over the lucrative spice-mining trade on the desert planet of Arrakis. And our hero, the Duke’s son Paul Atreides (Chalamet), and his mystic mother Lady Jessica of the Bene Gessirit (Rebecca Ferguson), are now embedded with the local Fremen freedom fighters on Arrakis (Javier Bardem, Zendaya, et al) as they wage guerilla warfare on the colonialist Harkonnens—and now, by extension, the Emperor (Christopher Walken) and his daughter and one-day successor Princess Irulan (Florence Pugh), who’s been groomed for power by Charlotte Rampling’s black-veiled Reverend Mother. I’m sure that last sentence probably sounds like a lot of nerdy gibberish to the uninitiated (not to mention armchair grammarians), but then again no one would ever confuse Frank Herbert with Hemingway. Simplicity wasn’t his thing. But thanks to Villeneuve and co-writer Jon Spaihts’s elegant, economical script, it all scans more easily than you’d expect.  </p><p data-journey-content="true" data-node-id="6">For those who have been tracking the fits and starts of the <em>Dune </em>franchise online, I don’t think I’m giving away anything by saying that <em>Dune: Part Two</em> is a middle chapter in the franchise. Yes, like the first film, it ends on a cliffhanger. But this time around, it feels like a steeper and more rewarding cliff. And, unlike most middle chapters of a trilogy, this doesn’t feel like a jerry-rigged bridge connecting two more interesting stories. In fact, a who’s who of welcome new faces arrive on the scene to add layers the first installment only hinted at. As the Emperor, Walken dials down his worst mannered tendencies to simultaneously convey a heavy-is-the-head-that-wears-the-crown world-weariness and a craven sense of realpolitik expediency. The Emperor is old enough to have seen how these power struggles play out and he knows that his time on the throne is finite, but at the end of the day loyalty is only as valuable as it is useful. </p><section data-embed="pullquote" data-lazy-id="P0-9" data-node-id="7"><blockquote><blockquote>Villeneuve shows us the magic of movies—a brand of magic that’s all too often invoked, but all too rarely felt these days.</blockquote></blockquote></section><p data-journey-content="true" data-node-id="8">As his royal daughter, Pugh seems to bristle at the idea of being a pawn in a bigger game and how she’s only being told part of the story. And as Feyd-Rautha Harkonnen, the psychotically cruel nephew of Stellan Skarsgard’s Jabba the Hutt-like Baron Harkonnen, Austin Butler is all but unrecognizable behind his character’s alabaster skin, shaved eyebrows, and heavy metal bondage gear. He looks like a younger version of Robert Blake’s specter in David Lynch’s <em>Lost Highway</em> crossed with the most badass member of the Borg collective. His ambition is limitless. His morals are nonexistent. And his bloodlust is unquenchable. Butler, <a href="https://www.esquire.com/entertainment/movies/a46650896/austin-butler-elvis-presley-voice/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46650896/austin-butler-elvis-presley-voice/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="so good in Baz Luhrmann’s Elvis">so good in Baz Luhrmann’s <em>Elvis</em></a>, goes big and gives us a villain to really hiss at. Despite all of Villeneuve’s pricey, future-shock CGI, Butler may be the director’s best special effect.  </p><p data-journey-content="true" data-node-id="9">While other new additions include Léa Seydoux and Anya Taylor-Joy (no spoilers here), <em>Dune: Part Two</em> is, at its heart, a hero’s journey. And as original as <em>Dune</em> may be, its arc is straight out of Joseph Campbell. Which bring us to Chalamet’s Paul Atreides. As excellent and against-type as the actor was in the first <em>Dune</em>, his character’s evolution couldn’t really skirt the fact that he had to start off a little bit whiny and petulant, not unlike Luke Skywalker in <em>A New Hope</em>. But now that he’s made the leap to battle-tested hero, Chalamet really lets it fly, summoning a more interesting performance. Torn between avenging his slain father and fulfilling the messianic destiny that many of the Fremen (including Bardem’s Stilgar) want from him, Paul takes on an interesting new complexity that brings to mind Willem Dafoe’s fallible, self-doubting Jesus in <em>The Last Temptation of Christ</em>, right down to his push-pull romantic connection with Zendaya’s Chani. Ferguson, meanwhile, is allowed to let her witchy side loose even more this time around. Her Lady Jessica is now pregnant, and she not only speaks with the baby daughter growing inside of her, she uses the unborn as a pawn to manipulate Paul’s next move. It’s a deliciously freaky puppet-master performance that manages to draw you in and creep you out. </p><div size="medium" data-embed="body-image" data-lazy-id="P0-10" data-node-id="10"><p><img alt="dune" title="dune" loading="lazy" width="2000" height="1333" decoding="async" data-nimg="1" sizes="100vw" srcset="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=640:* 640w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=768:* 980w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:* 1120w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:* 1200w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:* 1920w" src="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:*"></p><div><figcaption><span>Niko Tavernise/Warner Bros. Entertainment</span></figcaption><p>Paul Atreides (Timothée Chalamet) takes on a complexity that brings to mind Willem Dafoe’s fallible Jesus in <em>The Last Temptation of Christ</em>—right down to his push-pull romantic connection with Chani (Zendaya.)</p></div></div><p data-journey-content="true" data-node-id="11">Still, if Villeneuve’s film was just a gallery of characters fighting for power, warring over spice, and spouting metaphorical mumbo jumbo, it wouldn’t be half the movie it is (although it would still be pretty great). No, the director knows that we’ve paid to go on a ride. A deep, philosophical ride to be sure, but still a ride. And <em>Dune: Part Two</em> never forgets that it’s first and foremost a shock-and-awe eye-candy blockbuster. In an era when we go to the movies only to be bombarded over and over again with the same tired visual tropes and clichés, Villeneuve delivers enthralling, shoot-the-works set pieces that feel like high-wire acts of visual poetry and boundless originality. Witnessing Paul learn how to ride a giant sandworm like a rodeo cowboy waterskiing on a high-speed bullet train is as breathlessly thrilling as watching Charlton Heston racing a chariot in <em>Ben-Hur</em>. </p><p data-journey-content="true" data-node-id="12">Like its predecessor dialed up to eleven, <em>Dune: Part Two</em> is a spectacle that you feel with your head and your heart, but it also never lets your eyes take a break for a minute. It’s a film of grandeur that asks a lot of its audience and rewards us for going on its journey. My advice is don’t just see it, see it on as big a screen as you possibly can and just soak it up. Because Villeneuve shows us the magic of movies—a brand of magic that’s all too often invoked, but all too rarely felt these days. He’s given us nothing less than beautiful and bizarre sci-fi masterpiece bursting with big ideas and even bigger visual wonders. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ford EVs gain access to Tesla Superchargers starting today (172 pts)]]></title>
            <link>https://arstechnica.com/cars/2024/02/ford-evs-gain-access-to-tesla-superchargers-starting-today/</link>
            <guid>39552446</guid>
            <pubDate>Thu, 29 Feb 2024 17:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/cars/2024/02/ford-evs-gain-access-to-tesla-superchargers-starting-today/">https://arstechnica.com/cars/2024/02/ford-evs-gain-access-to-tesla-superchargers-starting-today/</a>, See on <a href="https://news.ycombinator.com/item?id=39552446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Happy leap day    —
</h4>
            
            <h2 itemprop="description">The adapter is free if you order it before June 30 or $230 if you wait.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_03-800x533.jpg" alt="someone plugs a tesla charger cable into an adapter to use with a non-tesla EV">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_03.jpg" data-height="5504" data-width="8256">Enlarge</a> <span>/</span> Ford was the first OEM to announce it was switching to J3400, and it's the first automaker to gain access to the Tesla Supercharger network.</p><p>Ford</p></figcaption>  </figure>

  




<!-- cache hit 2:single/related:4ccc423290dac7d71f6097dc34e9eb05 --><!-- empty -->
<p>Today, Ford electric vehicles gained access to the Tesla Supercharger network. Last&nbsp;May, the Blue Oval was <a href="https://arstechnica.com/cars/2023/05/ford-evs-will-get-access-to-teslas-supercharger-network-in-2024/">the first automaker to throw its lot in</a> with what was then called the North American Charging Standard and is now known as J3400. Ford proved to be the first domino falling, and with Stellantis' announcement <a href="https://arstechnica.com/cars/2024/02/stellantis-will-finally-adopt-tesla-style-fast-charger-plug/">earlier this month</a> that it too would move to J3400, the more compact DC fast-charging plug will be the de facto standard in the next couple of years.</p>
<p>Until Ford made the switch, every non-Tesla EV in North America had settled on the <a href="https://arstechnica.com/cars/2022/07/the-ars-technica-guide-to-electric-vehicle-charging/">Combined Charging Standard 1</a> plug (with the exception of the Nissan Leaf, which still uses CHAdeMO). CCS1 and J3400 use the same electronic communication protocols—only the actual plug and socket are different.</p>
<p>But it will take some time for car makers to start building J3400 ports into their EVs. That should begin next year, probably with the introduction of model year 2026. This means that EVs older than MY26 will need to use a passive adapter to mate a J3400 charger cable with a CCS1-equipped EV.</p>
<p>Ford is making the adapter available for free for <a href="https://arstechnica.com/cars/2023/12/revisiting-the-ford-mustang-mach-e-hows-the-pony-ev-doing-3-years-later/">Mustang Mach-E</a> and F-150 Lightning owners as long as they order one by June 30 of this year. After that date, the adapter will cost $230. Ford says that Ford Pro fleet customers can also order a complimentary adapter for their EV (which includes the <a href="https://arstechnica.com/cars/2022/01/weve-driven-fords-other-electric-workhorse-the-2022-e-transit/">E-Transit</a> as well as the Mach-E and Lightning) by contacting their Ford Pro account manager. (Ford Pro will also contact fleet owners by mail in the coming weeks.)</p>                                            
                                                        
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_05.jpg" data-height="5504" data-width="8256" alt="If you've ever used a dongle before, you should know how to use the charger adapter."><img alt="If you've ever used a dongle before, you should know how to use the charger adapter." src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_05-980x653.jpg" width="980" height="653"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_05.jpg" data-height="5504" data-width="8256">Enlarge</a> <span>/</span> If you've ever used a dongle before, you should know how to use the charger adapter.</p><p>Ford</p></figcaption></figure>
<p>Ford EVs already use the <a href="https://en.wikipedia.org/wiki/ISO_15118">ISO 15118</a> "plug and charge" protocol, which means they give the charger their billing details as part of the electronic handshake, obviating the need to use an app or credit card to start a charging session. And more than 15,000 Tesla chargers will now show up in the BlueOval charge network, which customers can navigate to via the FordPass smartphone app or the Charge Assist app on their infotainment systems.</p>
<p>Ford EVs aren't compatible with every Tesla Supercharger, however. They must be the more recent units, which are able to charge at up to 250 kW, identified by a black collar at the base of the charging plug. Older chargers, which can only charge at up to 150 kW, have a silver collar instead. Since these older chargers won't appear in the FordPass or ChargeAssist apps, it seems prudent for Ford EV drivers to use either of those to find a suitable charger location.</p>
<p>And the adapter is only for DC fast charging, not for Tesla's AC destination chargers. (Ford's plug-in hybrids are only capable of AC charging, and there is no need for them to have access to an adapter, so they will never be able to use a Supercharger.)</p>
<p>I don't imagine an Ars Technica reader having much trouble with fitting the J3400 adapter, but for people with less dongle experience, Ford has <a href="https://www.ford.com/support/how-tos/electric-vehicles/public-charging/how-do-i-use-the-fast-charging-adapter-nacs/">produced a short tutorial film</a>. Perhaps the only potential pain point will be unplugging one's EV and driving off without the adapter—a $230 lesson to learn—but since the Tesla cable needs to be put back in its holster, even that seems pretty unlikely.</p>
<p>"This move will improve the public charging experience by giving our customers even more choice and is a vital part of our growth as an EV brand," said Ford President and CEO Jim Farley.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Neurosurgeon pioneers Alzheimer's, addiction treatments using ultrasound [video] (160 pts)]]></title>
            <link>https://www.youtube.com/watch?v=7BGtVJ3lBdE</link>
            <guid>39551457</guid>
            <pubDate>Thu, 29 Feb 2024 16:24:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=7BGtVJ3lBdE">https://www.youtube.com/watch?v=7BGtVJ3lBdE</a>, See on <a href="https://news.ycombinator.com/item?id=39551457">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: We built the fastest spreadsheet (221 pts)]]></title>
            <link>https://rowzero.io</link>
            <guid>39551064</guid>
            <pubDate>Thu, 29 Feb 2024 15:57:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rowzero.io">https://rowzero.io</a>, See on <a href="https://news.ycombinator.com/item?id=39551064">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><header><nav aria-label="Global navigation"></nav></header><div><svg width="61" height="44" viewBox="0 0 61 44" fill="none" xmlns="http://www.w3.org/2000/svg"> <path fill-rule="evenodd" clip-rule="evenodd" d="M14.1437 0.833984H30.1789L19.4938 17.5202C21.9667 18.2167 24.0632 19.5048 25.7642 21.3848C27.7332 23.5612 28.694 26.3427 28.694 29.664C28.694 33.5108 27.3181 36.7352 24.5707 39.2816C21.9238 41.8241 18.614 43.086 14.696 43.086C10.7667 43.086 7.40967 41.7687 4.67177 39.1322L4.66667 39.1273L4.66167 39.1223C1.99167 36.4523 0.697998 32.7862 0.697998 28.224C0.697998 23.6994 2.60427 18.6111 6.29129 12.9831C6.29174 12.9824 6.2922 12.9817 6.29265 12.981L14.1437 0.833984ZM14.9603 2.33398L7.54988 13.7991L7.54734 13.803C3.93926 19.3101 2.198 24.1091 2.198 28.224C2.198 32.4907 3.3986 35.735 5.71732 38.0566C8.16246 40.4089 11.1398 41.586 14.696 41.586C18.2635 41.586 21.1919 40.4495 23.5362 38.1954L23.5464 38.1856C25.9795 35.9327 27.194 33.1108 27.194 29.664C27.194 26.6492 26.3308 24.2468 24.6518 22.3912C22.9397 20.4988 20.7798 19.2798 18.144 18.7344L17.0765 18.5136L27.4371 2.33398H14.9603ZM44.8157 0.833984H60.8509L50.1658 17.5202C52.6387 18.2167 54.7352 19.5048 56.4361 21.3848C58.4052 23.5612 59.366 26.3427 59.366 29.664C59.366 33.5108 57.9901 36.7352 55.2426 39.2816C52.5958 41.8241 49.286 43.086 45.368 43.086C41.4387 43.086 38.0817 41.7687 35.3438 39.1322L35.3387 39.1273L35.3337 39.1223C32.6637 36.4523 31.37 32.7862 31.37 28.224C31.37 23.6995 33.2762 18.6113 36.9631 12.9833C36.9636 12.9825 36.9641 12.9818 36.9647 12.981L44.8157 0.833984ZM45.6323 2.33398L38.2219 13.7991L38.2193 13.803C34.6113 19.3101 32.87 24.1091 32.87 28.224C32.87 32.4908 34.0707 35.7351 36.3895 38.0568C38.8346 40.4089 41.8119 41.586 45.368 41.586C48.9355 41.586 51.8639 40.4495 54.2082 38.1954L54.2184 38.1856C56.6515 35.9327 57.866 33.1108 57.866 29.664C57.866 26.6492 57.0028 24.2468 55.3238 22.3912C53.6117 20.4988 51.4518 19.2798 48.816 18.7344L47.7485 18.5136L58.1091 2.33398H45.6323Z" fill="black"></path> </svg><h3>Row Zero is an impressive feat of engineering, making big data feel small in a familiar spreadsheet interface.</h3><p><span>Wes McKinney</span><br>Creator of Pandas and Apache Arrow<!-- --> <!-- --> </p></div><div id="use-cases"><h2>Use cases</h2><p>Give your business access to cloud data sources in a tool they already know how to use. Explore hundreds of millions of rows, perform ad-hoc analyses, and monitor trends from the comfort of a spreadsheet.</p></div><section><div id="features"><p><img alt="Power and speed icon" srcset="https://rz-web.vercel.app/images/icon-rocket.svg?w=64 1x, https://rz-web.vercel.app/images/icon-rocket.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-rocket.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Power and speed</h3><ul><li>Write Excel-compatible formulas to process hundreds of millions of rows instantly</li><li>No more slow dashboards - filter, sort, pivot, and plot in milliseconds</li><li>Upload multi-GB CSV and JSONL files - no need for databases or expensive BI tools</li></ul></div><div id="features"><p><img alt="Familiar UI icon" srcset="https://rz-web.vercel.app/images/icon-spreadsheet.svg?w=64 1x, https://rz-web.vercel.app/images/icon-spreadsheet.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-spreadsheet.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Familiar UI</h3><ul><li>Excel compatible - execute VLOOKUPS, XLOOKUPS, COUNTIFS, INDEX MATCHs,<!-- --> <a href="https://rowzero.io/docs/spreadsheet-functions">and more</a></li><li>Filter, sort, pivot, and plot the way you already know how - no BI tool training required</li><li>Enable your business teams with an analysis tool they already know how to use</li></ul></div><div id="features"><p><img alt="Connect to any data source icon" srcset="https://rz-web.vercel.app/images/icon-connection.svg?w=64 1x, https://rz-web.vercel.app/images/icon-connection.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-connection.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Connect to any data source</h3><ul><li>Row Zero runs in the cloud and connects directly to any data source</li><li>Connect data warehouses, data lakes, APIs, and any other service to build models on live data</li><li>Save time and reduce mistakes by connecting to live data instead of copy/pasting</li></ul></div><div id="features"><p><img alt="Sharing and collaboration icon" srcset="https://rz-web.vercel.app/images/icon-collaboration.svg?w=64 1x, https://rz-web.vercel.app/images/icon-collaboration.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-collaboration.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Sharing and collaboration</h3><ul><li>Collaborate in real time - Share each workbook with editor and viewer permissions</li><li>Govern your data. No more Sharepoint or untraceable emails with .xlsx attachments </li><li>Provide refresh permissions (without revealing credentials) so business teams can build models off live data</li><li>Use the Follow feature when presenting to walk team members through your analysis</li></ul></div><div id="features"><p><img alt="Python icon" srcset="https://rz-web.vercel.app/images/icon-code.svg?w=64 1x, https://rz-web.vercel.app/images/icon-code.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-code.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Python</h3><ul><li>Decompose long spreadsheet formulas with Python helper functions to improve readability and prevent costly errors</li><li>Import popular Python modules like <span>pandas</span>,<!-- --> <span>numpy</span>, <span>scipy</span>, and <span>yfinance</span>, to perform complex analysis in a familiar tool</li><li>Never write VBA again</li></ul></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The internet feels fake now. It's all just staged videos and marketing (114 pts)]]></title>
            <link>https://old.reddit.com/r/Millennials/comments/1b301qj/the_internet_feels_fake_now_its_all_just_staged/</link>
            <guid>39551035</guid>
            <pubDate>Thu, 29 Feb 2024 15:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/Millennials/comments/1b301qj/the_internet_feels_fake_now_its_all_just_staged/">https://old.reddit.com/r/Millennials/comments/1b301qj/the_internet_feels_fake_now_its_all_just_staged/</a>, See on <a href="https://news.ycombinator.com/item?id=39551035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>All things Generation Y (Millennials).</p>

<p>Millennials are the generation that were born between 1981 to 1996. Our generation comes after Gen X, and before Gen Z.</p>

<p>Check out our sister subreddit, <a href="https://old.reddit.com/r/Zillennials">/r/Zillennials</a>. As well as <a href="https://old.reddit.com/r/decadeology">r/decadeology</a> for more in depth cultural analysis. </p>

<p>Zillennials are the micro-generation between Gen Z and Millennials, years ~1994-1999. Join the discord server here --&gt; <a href="https://discord.gg/Se8Nr5JMbU">https://discord.gg/Se8Nr5JMbU</a></p>

<p>All generations are welcome to post &amp; comment.</p>

<hr>

<p>Rules:</p>

<ul>
<li><p>Treat Others Like A Human Being
Basically, just be cool, and you'll avoid 90% of potential problems. Remember that, with exception of bots/spam, you are talking to a human on the other end, and you should talk to that person as you would in real life.</p></li>
<li><p>No Discrimination, Mud Slinging, or Hate Speech
Direct mistreatment of users for their race, religion, sexuality, and other forms of discrimination are strictly prohibited. Politics are allowed but only for talking about in a civil manner.</p></li>
<li><p>No Personal Attacks or Harrassment
Do not personally attack others, harass others, stalk others, or leak their personal information (Doxxing).</p></li>
<li><p>No Spamming or Low-Level Content
Any instances of spamming, trolling, clearly repetitive content, overtly low-level content, and negatively provocative content will be removed. This is to maintain user experience and to keep the subreddit running smoothly.</p></li>
<li><p>Subreddit Content Should Lean Towards Positive or Nostalgia Focused Discussion
Mostly this serves as a guideline but the content on this subreddit should be more geared towards Millennial nostalgia and the positive aspects of our generation.</p></li>
<li><p>No NSFW Content
Do not post gore, nudity, pornography, links to NSFW sites, etc.</p></li>
<li><p>No Personal Information
Do not share another person's personal information. Anything you share about yourself you share at your own risk. Always keep the safety of yourself and others in mind.</p></li>
<li><p>No Gatekeeping
All forms of gatekeeping will be deleted and the perpetrator will be warned. Further gatekeeping will result in a ban on the perpetrator. It's fine to discuss differences and observations in a civil manner.</p></li>
<li><p>No Discussing Definitions / "What Generation am I?" / "When do Millennials start and end?" / "Who is considered a Millennial?" posts
This has been discussed countless times already. Otherwise, you're free to discuss whatever it is on <a href="https://old.reddit.com/r/generationology">r/generationology</a> or <a href="https://old.reddit.com/r/decadeology">r/decadeology</a>.</p></li>
<li><p>No "surveys" / "data" posts
This is a recurring theme of past posts, questions about "What do Millennials see in a brand?" or "What are your opinions on _____ brand" are not allowed. There are plenty of other research subreddits for these types of posts.</p></li>
<li><p>No Politics
Our community is <strong>not</strong> <a href="https://old.reddit.com/r/politics">r/politics</a> or <a href="https://old.reddit.com/r/antiwork">r/antiwork</a>. For these types of discussions please use other subs. This rule has been implemented to avoid toxic users and discussions here. This may be lifted in the future at some point.</p></li>
<li><p>No discussion of Palestinian v. Israeli conflict.
There are countless different subs to discuss this controversial event happening. To curb repetitive and toxic posts we are NOT allowing this topic here.</p></li>
</ul>

<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A lock-free ring-buffer with contiguous reservations (2019) (167 pts)]]></title>
            <link>https://ferrous-systems.com/blog/lock-free-ring-buffer/</link>
            <guid>39550124</guid>
            <pubDate>Thu, 29 Feb 2024 14:57:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ferrous-systems.com/blog/lock-free-ring-buffer/">https://ferrous-systems.com/blog/lock-free-ring-buffer/</a>, See on <a href="https://news.ycombinator.com/item?id=39550124">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>This is the story of how <a href="https://twitter.com/utaal">Andrea Lattuada</a> (PhD student at ETH Zurich) and <a href="https://twitter.com/bitshiftmask">James Munns</a> (from Ferrous Systems) designed and implemented (two versions!) of an high-perf lock-free ring-buffer for cross-thread communication. If any of those words look scary to you, don't fret, we'll explain everything from the basics.</p>

<p><em>This post is cross-posted on Andrea Lattuada's <a href="http://andrea.lattuada.me/blog/2019/the-design-and-implementation-of-a-lock-free-ring-buffer-with-contiguous-reservations.html">blog</a>.</em></p>

<p>This post is for you if you're interested in (safe!) concurrency, systems programming, and cool ways to write efficient systems software. If you've never written a thread-safe data structure, this post may be a great way to get started!</p>

<h2 id="circular-buffers">Circular buffers</h2>

<p>A <a href="https://www.codeproject.com/Articles/3479/The-Bip-Buffer-The-Circular-Buffer-with-a-Twist"><em>BipBuffer</em></a> is a bi-partite circular buffer that always supports writing a contiguous chunk of data, instead of potentially splitting a write in two chunks when it straddles the buffer's boundaries.</p>

<p>Circular buffers are a common primitive for asynchronous (inter- or intra- thread) communication. Let's start with a very abstract, idealised view of the circular buffer interface, and then consider real-world constraints one by one, till we get to the <em>BipBuffer</em> design.</p>

<h3 id="an-idealised-infinite-buffer">An idealised infinite buffer</h3>

<p>A writer (producer) and a reader (consumer) want to communicate, and have access to the same, contiguous, and infinite array. They both keep a bookmark of which part of the array they've (respectively) written and read. They start with these <code>write</code> and <code>read</code> pointers aligned.</p>

<p>When the writer wants to send data, it appends it after the <code>write</code> pointer and then moves the pointer to the end of the newly written chunk. The reader inspects the <code>write</code> pointer at its leisure (asynchronously). When the <code>write</code> pointer has advanced further than the <code>read</code> pointer, the reader can consume and act on the available data. Once that's done, it moves the <code>read</code> pointer forwards to keep track of which part of the buffer it has already processed.</p>

<p><img src="https://i.imgur.com/jncR6qd.png" alt=""></p>

<p>The reader will never attempt to read past the <code>write</code> pointer, because there's no guarantee there's valid data there (i.e. that the writer has put anything there). This also means that the <code>read</code> pointer can never overtake <code>write</code>. For now, we're assuming an ideal memory system that's always coherent and where writes are visible immediately and sequentially.</p>

<h3 id="a-bounded-circular-buffer">A bounded circular buffer</h3>

<p>Computers don't have magic infinite buffers. We have to allocate a finite amount of memory to use for potentially infinite communication between the writer and reader. In a circular buffer, the <code>write</code> pointer can wrap around the boundaries of the buffer when it reaches the end.</p>

<p>When new data arrives and the <code>write</code> pointer is close to the end, it splits the write in two chunks: one for the remaining buffer space at the end, and one for the remaining data at the beginning. Note that, if the <code>read</code> pointer is still close to the beginning, this has the potential of clobbering data that hasn't yet been processed by the reader. For this reason, the <code>write</code> pointer is not allowed to overtake <code>read</code> after it has wrapped around.</p>

<p><img src="https://i.imgur.com/zfwNfD0.png" alt=""></p>

<p>We end up with two possible memory configurations:</p>

<ol>
  <li><code>write</code> leads and <code>read</code> follows (<code>write</code> ≥ <code>read</code>), the valid data (written, but not yet processed by the reader) is in the section of the buffer after <code>read</code> and before <code>write</code>;</li>
  <li><code>read</code> leads and <code>write</code> follows (<code>read</code> &gt; <code>write</code>), the valid data is after <code>read</code>, till the end, and from the start of the buffer till <code>write</code>.</li>
</ol>

<p>Note that we disallow <code>read</code> == <code>write</code> in the second case, as this would be ambiguous: while <code>read</code> can catch up to <code>write</code>, after a wraparound <code>write</code> has to stay one step behind <code>read</code> to indicate that we're in case 2 instead of case 1.</p>

<p>We repeatedly move from configuration 1 to 2, then back to 1: when <code>read</code> reaches the end of the buffer, it can also wrap around to continue reading at the start.</p>

<h3 id="contiguous-writesreads">Contiguous writes/reads</h3>

<p>This is all great, but what if we have chunks of data that should remain contiguous in memory when written to the buffer? Look here, there's a new message to be written, but it doesn't fit in the remaining buffer space after <code>write</code>.</p>

<p><img src="https://i.imgur.com/szHSC8M.png" alt=""></p>

<p>If, for whatever reason, we aren't allowed to split this write in two, we're stuck. Maybe we can just wait for <code>read</code> to move forwards, and place our new data in a single chunk at the start of the buffer? Well, in fact, yea. But there's a caveat.</p>

<p><img src="https://i.imgur.com/Lb8C3sq.png" alt=""></p>

<p>We've broken the property in configuration 2 earlier: there's a section of the buffer that's between <code>read</code> and the end of the buffer, but doesn't contain any valid data. If we didn't do anything about it, the reader would keep consuming data, moving <code>read</code> forwards, and it would be oblivious to the fact that at some point it would be reading a section of the buffer that doesn't contain any valid information.</p>

<h2 id="a-hardware-interlude">A Hardware Interlude</h2>

<p>Previously we asked:</p>

<blockquote>
  <p>What if we have chunks of data that should remain contiguous in memory when written to the buffer?</p>
</blockquote>

<p>But when would we actually require that data be read or written to in a contiguous manner?</p>

<h3 id="dma---direct-memory-access">DMA - Direct Memory Access</h3>

<p>In embedded microcontroller systems, it is common to have a single core CPU. Instead of having multiple cores, they have a set of features referred to as Memory Mapped Peripherals. These Peripherals act as hardware accelerators for specific behaviors, such as sending or receiving data from a serial port.</p>

<p>In order to minimize the amount of time necessary for the CPU to manually copy data from one place to another, these Peripherals can be configured to perform an action completely autonomously, streaming data to or from a section of memory on the CPU. This action of the hardware directly reading from or writing to the memory is called DMA, or Direct Memory Access.</p>

<p>Instead of reading or writing one byte at a time to the Serial Port, the CPU can instead start the transfer, and when it is complete, process a chunk of bytes at a time. This allows for less time waiting, and is generally a more efficient method of processing data.</p>

<p>A typical usage of DMA (called a DMA transaction) looks like this:</p>

<ol>
  <li>The CPU allocates N bytes of memory to be used for DMA</li>
  <li>The CPU instructs the peripheral, such as a serial port, to receive N bytes of data, and to place those bytes in the memory allocated in step 1</li>
  <li>Once the peripheral is configured, the CPU resumes performing other actions, and the Serial Port begins filling data into the memory buffer as it is received</li>
  <li>When the Serial Port has received all N bytes requested, it notifies the CPU, and stops receiving data</li>
  <li>The CPU may now process all N bytes requested, and if necessary, repeat the process at step one</li>
</ol>

<p>Although we often only have one CPU core in most microcontrollers, we can think of these DMA actors as their own thread. They are able to operate independently of the main CPU's actions, and read and write memory based on their own needs. In these microcontroller systems, there can be tens or hundreds of these hardware actors, all operating in parallel!</p>

<h3 id="stackless-operation">Stackless Operation</h3>

<p>In step one of DMA procedure above, we talked about allocating N bytes of memory. On a non-embedded system, this would generally be done by allocating space on the heap - a <code>Box</code> in Rust, or using <code>malloc()</code> in C. In lightweight or timing critical embedded systems, it is uncommon to have a heap. Instead, all memory must be statically allocated, or allocated through the use of the stack.</p>

<p>In these systems, data structures such as Circular Buffers are used to work around these limitations. A fixed amount of space is reserved for use, and a dynamic amount of data within a fixed maximum region is used to simulate a dynamic memory region.</p>

<p>Unfortunately, these DMA transactions do not understand the concept of a circular buffer. They are only aware of a pointer to where the memory region starts, and how many bytes to use from the starting pointer. This means that a normal circular buffer where the data region could wrap around would not work for DMA transfers.</p>

<h3 id="but-why-is-dma-so-important">But why is DMA so important?</h3>

<p>For operations used with DMA, the speed at which bytes are transferred is often many orders of magnitude slower than the operation of the CPU itself. For a 32 bit ARM CPU, copying 4 bytes from RAM takes a single cycle. In a 64MHz CPU, this means it will take 15.6 nanoseconds to copy these four bytes.</p>

<p>A typical serial port configuration is "115200 8N1", which means 115,200 baud (or raw bits on the wire per second), with no parity, and 1 stop bit. This means that for every data byte sent, there will be 8 data bits, 1 unused parity bit, and 1 stop bit, to signal the end of the byte, sent over the wire.</p>

<p>This means that we will need 40 bits on the wire to receive a 4 data bytes. At 115,200 bits on the wire per second, this means it will take 347,220 nanoseconds to receive the same four bytes, taking <strong>22,222 times as long</strong> as it takes our CPU to copy the same amount of data!</p>

<p>Instead of making our CPU waste all of this time waiting around, we allow the hardware to manage the simple sending and receiving process, allowing our CPU to either process other important tasks, or go into sleep mode, saving power or battery life.</p>

<h3 id="from-embedded-to-datacenters">From embedded to datacenters</h3>

<p>People writing high-performance application for datacenter grade servers have long realised this is also true for the high-grade, power-hungry CPUs they use.</p>

<p>Modern, efficient network stacks for servers use similar DMA techniques to offload all of this work to the network card, so that valuable CPU time can be spent running data-crunching applications.</p>

<h3 id="a-fork-in-the-road">A fork in the road</h3>

<p>Here's where the original BipBuffer design decides to maintain two "regions" of valid data, one at the start and one at the end of the buffer: this way it can keep track of which sections of the buffers contain valid data. Have a look at the <a href="https://www.codeproject.com/Articles/3479/The-Bip-Buffer-The-Circular-Buffer-with-a-Twist">BipBuffer</a> blog post on CodeProject for details on how this works.</p>

<p>The design based on two regions works great in a single threaded environment, but requires swapping the references to two regions when the rightmost one is depleted. This is tricky to do without explicit locking (mutexes) for cases in which the writer and reader reside on different threads.</p>

<p>Our use case is communication between two concurrent threads of control: either two actual OS threads, or a main thread of control and an interrupt handler in embedded or a device driver. This is where our design takes inspiration from the <em>BipBuffer</em>, but goes in a different direction.</p>

<h2 id="concurrency-design">Concurrency design</h2>

<p>A common strategy to reduce the amount of coordination that needs to happen between the two threads (writer, reader) is to associate each coordination variable (pointer) with a single thread that has exclusive write access to it. This also happens to simplify reasoning about the design, because it's always clear who's in charge of changing which variable.</p>

<p>So, let's start with a simple circular buffer that has the <code>write</code> and <code>read</code> pointers from before. The writer is the only one who ever changes <code>write</code>, and the reader is the only one who increments <code>read</code>.</p>

<p><img src="https://i.imgur.com/zfwNfD0.png" alt=""></p>

<p>So far so good. Each thread is only concerned with writing to one variable, and reading from the other.</p>

<h3 id="high-watermark-for-data">High watermark for data</h3>

<p>Now let's re-introduce the requirement that the data written may need to be contiguous. If there's no space available at the end of the buffer, the writer wraps around and writes the whole contiguous chunk at the start.</p>

<p><img src="https://i.imgur.com/Lb8C3sq.png" alt=""></p>

<p>As we've seen, we need a way to tell the reader which part of the buffer is valid, and which was skipped to be able to write a single contiguous chunk. We're tracking the high watermark of valid data in the buffer, so what about a <code>watermark</code> pointer that gets written when the writer wraps around and leaves empty space at the end?</p>

<p>Going back to our idealised infinite buffer from before, here's what things would look like. Whenever the valid region isn't split in two parts (at the beginning and end of the actual buffer) we simply ned to track the write and read pointers, as before. On the other hand, when valid data wraps around the buffer, we leave an artificial "hole" in the "infinite buffer" representation. The <code>watermark</code> lets us keep track of where the "hole" starts, and the end of the physical buffers marks the end.</p>

<p><img src="https://i.imgur.com/lZrudcU.png" alt=""></p>



<p>We have all the necessary elements for our non-blocking implementation. We start with the <code>write</code> and <code>read</code> pointers aligned at the start of the buffer and the <code>watermark</code> aligned with the end.</p>

<p><img src="https://i.imgur.com/nS0tBm1.png" alt=""></p>

<div><pre><code><span>struct</span> <span>ContiguousAsyncBuffer</span> <span>{</span>
  <span>buf</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span><span>,</span>
  <span>len</span><span>:</span> <span>usize</span><span>,</span>
  <span>read</span><span>:</span> <span>AtomicUsize</span><span>,</span>
  <span>write</span><span>:</span> <span>AtomicUsize</span><span>,</span>
  <span>watermark</span><span>:</span> <span>AtomicUsize</span><span>,</span>
<span>}</span>
</code></pre></div>
<p>We use <code>AtomicUsize</code> to let the two threads read and update the pointers concurrently and safely. The writer/sender thread is in charge of <code>write</code> and <code>watermark</code>, the reader/receiver is in charge of <code>read</code>. This is important! Contended writes from multiple threads on the same memory location are a lot harder for the CPU's cache coherence protocol to handle, and will cost latency and throughput.
What's more, it's a lot easier to reason about correctness of these concurrent protocols if each of the shared pointers are always written by a certain thread (their "owner").</p>

<h3 id="writing">Writing</h3>

<p>As long as there's enough contiguous buffer space before the end of the physical buffer, as new data arrives (of length <code>write_len</code>) the sender thread moves the <code>write</code> pointer forwards to signal that a new chunk of the buffer is now valid and can be read.</p>

<div><pre><code><span>// [writer thread]</span>
<span>buffer</span><span>.write</span><span>.store</span><span>(</span><span>buffer</span><span>.write</span><span>.load</span><span>()</span> <span>+</span> <span>write_len</span><span>)</span>
</code></pre></div>
<p>When new data arrives and the <code>write</code> pointer is close to the end, it moves the watermark to its current location, then wraps around. Again, if the <code>read</code> pointer is still close to the beginning, this has the potential of clobbering data that hasn't yet been processed by the reader. For this reason, the <code>write</code> pointer is not allowed to overtake <code>read</code> after it has wrapped around.</p>

<div><pre><code><span>// [writer thread]</span>
<span>if</span> <span>buffer</span><span>.len</span><span>.saturating_sub</span><span>(</span><span>buffer</span><span>.write</span><span>.load</span><span>())</span> <span>&gt;=</span> <span>write_len</span> <span>{</span>
  <span>// not shown: check `read` to make sure there's enough free room</span>
  <span>buffer</span><span>.watermark</span><span>.store</span><span>(</span><span>buffer</span><span>.write</span><span>.load</span><span>()</span> <span>+</span> <span>write_len</span><span>);</span>
  <span>buffer</span><span>.write</span><span>.store</span><span>(</span><span>buffer</span><span>.write</span><span>.load</span><span>()</span> <span>+</span> <span>write_len</span><span>);</span>
<span>}</span> <span>else</span> <span>{</span> <span>// not enough space, wrap around</span>
  <span>// not shown: check `read` to make sure there's enough free room at the beginning of the buffer</span>
  <span>buffer</span><span>.watermark</span><span>.store</span><span>(</span><span>buffer</span><span>.write</span><span>.load</span><span>());</span>
  <span>buffer</span><span>.write</span><span>.store</span><span>(</span><span>0</span> <span>+</span> <span>write_len</span><span>);</span>
<span>}</span>
</code></pre></div>
<p>You may have noticed that the writer also pushes the <code>watermark</code> forward when there's room at the end of the buffer. We need to do this because we may have moved it back on a previous wrap-around and we want to avoid the reader now misinterpreting it as a sign that there's a "hole" at the end.</p>

<h3 id="reading">Reading</h3>

<p>We end up again with two possible memory configurations:</p>

<ol>
  <li><code>write</code> leads and <code>read</code> follows (<code>write</code> ≥ <code>read</code>), the valid data (written, but not yet processed by the reader) is in the section of the buffer after <code>read</code> and before <code>write</code>;</li>
  <li><code>read</code> leads and <code>write</code> follows (<code>read</code> &gt; <code>write</code>), the valid data is after <code>read</code>, till the <code>watermark</code>, and from the start of the buffer till <code>write</code>.</li>
</ol>

<p><img src="https://i.imgur.com/vgqghy7.png" alt=""></p>

<p>This makes the reader thread's logic simple: read till you hit the <code>write</code> pointer, or the <code>watermark</code>, and update the <code>read</code> pointer accordingly.</p>

<h3 id="a-note-on-memory-ordering">A note on memory ordering</h3>

<p>Some of you may have noticed that all of our calls to <code>load</code> don't take arguments and our calls to <code>store</code> take a single argument, the new value for the <code>AtomicBool</code>. This isn't valid code, of course. The real signatures take another argument: <code>ordering: Ordering</code>.
This instructs llvm on how to emit the proper memory fences and <code>sync</code> instructions to drive the cache coherence and synchronization mechanisms built into the CPUs.</p>

<p>The safe thing to do here is to always choose <code>Ordering::SeqCst</code>, "sequential consistency", which provides the strongest guarantees. On x86, due to the hardware design, anything other than <code>Ordering::Relaxed</code> is equivalent to <code>SeqCst</code>. On ARMv7/v8, things get more complicated.</p>

<p>We recommend reading up on <a href="https://doc.rust-lang.org/std/sync/atomic/enum.Ordering.html"><code>Ordering</code></a> both in the rust doc and in the documentation for your platform. For the purpose of this post, just assume we used <code>Ordering::SeqCst</code> everywhere. This is often good enough in practice, and switching to a weaker <code>Ordering</code> is only necessary to squeeze out the last bit of performance.</p>

<p>In Andrea's implementation of the lock-free ring-buffer, <a href="https://github.com/utaal/spsc-bip-buffer">spsc-bip-buffer</a>, some of the orderings are relaxed for performance. This has the downside that it can introduce subtle concurrency bugs that may only show up on some platform (ARM, for example): to be a bit more confident that everything's still fine, Andrea's has continous integation tests both on x86 and ARM.</p>

<h3 id="support-for-embedded-systems">Support for embedded systems</h3>

<p>In James' implementation of the lock-free ring-buffer, <a href="https://github.com/jamesmunns/bbqueue">bbqueue</a>, convenience interfaces are provided for statically allocating instances of the ring-buffer. The queue can be split into Producer and Consumer halves, allowing for use of one half in interrupt context, and the other half in non-interrupt (or a different interrupt) context.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rendering protein structures inside cells at the atomic level with Unreal Engine (174 pts)]]></title>
            <link>https://www.biorxiv.org/content/10.1101/2023.12.08.570879v1</link>
            <guid>39549838</guid>
            <pubDate>Thu, 29 Feb 2024 14:38:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.biorxiv.org/content/10.1101/2023.12.08.570879v1">https://www.biorxiv.org/content/10.1101/2023.12.08.570879v1</a>, See on <a href="https://news.ycombinator.com/item?id=39549838">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page" id="page"><div data-node-nid="3537021" id="node-3537021--21973405445" data-pisa="biorxiv;2023.12.08.570879v1" data-pisa-master="biorxiv;2023.12.08.570879" data-apath="/biorxiv/early/2023/12/11/2023.12.08.570879.atom" data-hw-author-tooltip-instance="highwire_author_tooltip">

      <p><span>
        New Results    </span></p>  
      
  
      <p><span><span>doi:</span> https://doi.org/10.1101/2023.12.08.570879 </span></p>
  
  
  </div>

<div data-panels-ajax-tab-preloaded="biorxiv_tab_art" id="panels-ajax-tab-container-highwire_article_tabs"><div xmlns="http://www.w3.org/1999/xhtml" data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" xmlns:xhtml="http://www.w3.org/1999/xhtml"><div id="abstract-1"><h2>Abstract</h2><p id="p-2">While the recent development of cryogenic electron tomography (CryoET) makes it possible to identify various macromolecules inside cells and determine their structure at near-atomic resolution, it remains challenging to visualize the complex cellular environment at the atomic level. One of the main hurdles in cell visualization is to render the millions of molecules in real time computationally. Here, using a video game engine, we demonstrate the capability of rendering massive biological macromolecules at the atomic level within their native environment. To facilitate the visualization, we also provide tools that help the interactive navigation inside the cells, as well as software that converts protein structures identified using CryoET to a scene that can be explored with the game engine.</p><div id="sec-1"><div><p><a href="https://www.biorxiv.org/content/biorxiv/early/2023/12/11/2023.12.08.570879/F1.large.jpg?width=800&amp;height=600&amp;carousel=1" title="" rel="gallery-fragment-images-816925171" data-figure-caption="<div class=&quot;highwire-markup&quot;></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure" src="https://www.biorxiv.org/content/biorxiv/early/2023/12/11/2023.12.08.570879/F1.medium.gif" width="440" height="217" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.biorxiv.org/content/biorxiv/early/2023/12/11/2023.12.08.570879/F1.large.jpg?download=true" title="Download Figure1" data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.biorxiv.org/content/biorxiv/early/2023/12/11/2023.12.08.570879/F1.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li></ul></div></div><h3>Competing Interest Statement</h3><p id="p-3">The authors have declared no competing interest.</p></div>
<div><p>Copyright&nbsp;</p><div><p>The copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.<span> It is made available under a <a href="http://creativecommons.org/licenses/by/4.0/" data-icon-position="" data-hide-link-title="0">CC-BY 4.0 International license</a>.</span></p></div></div>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You've just inherited a legacy C++ codebase, now what? (178 pts)]]></title>
            <link>https://gaultier.github.io/blog/you_inherited_a_legacy_cpp_codebase_now_what.html</link>
            <guid>39549486</guid>
            <pubDate>Thu, 29 Feb 2024 14:11:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gaultier.github.io/blog/you_inherited_a_legacy_cpp_codebase_now_what.html">https://gaultier.github.io/blog/you_inherited_a_legacy_cpp_codebase_now_what.html</a>, See on <a href="https://news.ycombinator.com/item?id=39549486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>You were minding your own business, and out of nowhere something fell
on your lap. Maybe you started a new job, or perhaps changed teams, or
someone experienced just left.</p>
<p>And now you are responsible for a C++ codebase. It’s big, complex,
idiosyncratic; you stare too long at it and it breaks in various
interesting ways. In a word, legacy.</p>
<p>But somehow bugs still need to be fixed, the odd feature to be added.
In short, you can’t just ignore it or better yet nuke it out of
existence. It matters. At least to someone who’s paying your salary. So,
it matters to you.</p>
<p>What do you do now?</p>
<p>Well, fear not, because I have experience this many times in numerous
places (the snarky folks in the back will mutter: what C++ codebase
isn’t exactly like I described above), and there is a way out, that’s
not overly painful and will make you able to actually fix the bugs, add
features, and, one can dream, even rewrite it some day.</p>
<p>So join me on a recollection of what worked for me and what one
should absolutely avoid.</p>
<p>And to be fair to C++, I do not hate it (per se), it just happens to
be one of these languages that people abuse and invariably leads to a
horrifying mess and poor C++ is just the victim here and the C++
committee will fix it in C++45, worry not, by adding
<code>std::cmake</code> to the standard library and you’ll see how it’s
absolutely a game changer, and - Ahem, ok let’s go back to the topic at
hand.</p>
<p>So here’s an overview of the steps to take:</p>
<ol type="1">
<li>Get it to work locally, by only doing the minimal changes required
in the code and build system, ideally none. No big refactorings yet,
even if itches really bad!</li>
<li>Get out the chainsaw and rip out everything that’s not absolutely
required to provide the features your company/open source project is
advertising and selling</li>
<li>Make the project enter the 21st century by adding CI, linters,
fuzzing, auto-formatting, etc</li>
<li>Finally we get to make small, incremental changes to the code, Rinse
and repeat until you’re not awaken every night by nightmares of Russian
hackers p@wning your application after a few seconds of poking at
it</li>
<li>If you can, contemplate rewrite some parts in a memory safe
language</li>
</ol>
<p>The overarching goal is exerting the least amount of effort to get
the project in an acceptable state in terms of security, developer
experience, correctness, and performance. It’s crucial to always keep
that in mind. It’s not about ‘clean code’, using the new hotness
language features, etc.</p>
<p>Ok, let’s dive in!</p>
<p><em>By the way, everything here applies to a pure C codebase or a
mixed C and C++ codebase, so if that’s you, keep reading!</em></p>
<p><strong>Table of contents</strong></p>
<ul>
<li><a href="#get-buy-in">Get buy-in</a></li>
<li><a href="#write-down-the-platforms-you-support">Write down the
platforms you support</a></li>
<li><a href="#get-the-build-working-on-your-machine">Get the build
working on your machine</a></li>
<li><a href="#get-the-tests-passing-on-your-machine">Get the tests
passing on your machine</a></li>
<li><a href="#write-down-in-the-readme-how-to-build-and-test-the-application">Write
down in the README how to build and test the application</a></li>
<li><a href="#find-low-hanging-fruits-to-speed-up-the-build-and-tests">Find low
hanging fruits to speed up the build and tests</a></li>
<li><a href="#remove-all-unnecessary-code">Remove all unnecessary
code</a></li>
<li><a href="#linters">Linters</a></li>
<li><a href="#code-formatting">Code formatting</a></li>
<li><a href="#sanitizers">Sanitizers</a></li>
<li><a href="#add-a-ci-pipeline">Add a CI pipeline</a></li>
<li><a href="#incremental-code-improvements">Incremental code
improvements</a></li>
<li><a href="#rewrite-in-a-memory-safe-language">Rewrite in a memory
safe language?</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#addendum-dependency-management">Addendum: Dependency
management</a></li>
</ul>
<h2 id="get-buy-in">Get buy-in</h2>
<p>You thought I was going to compare the different sanitizers, compile
flags, or build systems? No sir, before we do any work, we talk to
people. Crazy, right?</p>
<p>Software engineering needs to be a sustainable practice, not
something you burn out of after a few months or years. We cannot do this
after hours, on a death march, or even, alone! We need to convince
people to support this effort, have them understand what we are doing,
and why. And that encompasses everyone: your boss, your coworkers, even
non-technical folks. And who knows, maybe you’ll go on vacation and
return to see that people are continuing this effort when you’re out of
office.</p>
<p>All of this only means: explain in layman terms the problem with a
few simple facts, the proposed solution, and a timebox. Simple right?
For example (to quote South Park: <em>All characters and events in this
show—even those based on real people—are entirely fictional</em>):</p>
<ul>
<li>Hey boss, the last hire took 3 weeks to get the code building on his
machine and make his first contribution. Wouldn’t it be nice if, with
minimal effort, we could make that a few minutes?</li>
<li>Hey boss, I put quickly together a simple fuzzing setup (‘inputting
random data in the app like a monkey and seeing what happens’), and it
manages to crash the app 253 times within a few seconds. I wonder what
would happen if people try to do that in production with our app?</li>
<li>Hey boss, the last few urgent bug fixes took several people and 2
weeks to be deployed in production because the app can only be built by
this one build server with this ancient operating system that has not
been supported for 8 years (FreeBSD 9, for the curious) and it kept
failing. Oh by the way whenever this server dies we have no way to
deploy anymore, like at all. Wouldn’t it be nice to be able to build our
app on any cheap cloud instance?</li>
<li>Hey boss, we had a cryptic bug in production affecting users, it
took weeks to figure out and fix, and it turns out if was due to
undefined behavior (‘a problem in the code that’s very hard to notice’)
corrupting data, and when I run this industry standard linter (‘a
program that finds issues in the code’) on our code, it detects the
issue instantly. We should run that tool every time we make a
change!</li>
<li>Hey boss, the yearly audit is coming up and the last one took 7
months to pass because the auditor was not happy with what they saw. I
have ideas to make that smoother.</li>
<li>Hey boss, there is a security vulnerability in the news right now
about being able to decrypt encrypted data and stealing secrets, I think
we might be affected, but I don’t know for sure because the cryptography
library we use has been vendored (‘copy-pasted’) by hand with some
changes on top that were never reviewed by anyone. We should clean that
up and setup something so that we get alerted automatically if there is
a vulnerability that affects us.</li>
</ul>
<p>And here’s what to avoid, again totally, super duper fictional,
never-really-happened-to-me examples:</p>
<ul>
<li>We are not using the latest C++ standard, we should halt all work
for 2 weeks to upgrade, also I have no idea if something will break
because we have no tests</li>
<li>I am going to change a lot of things in the project on a separate
branch and work on it for months. It’s definitely getting merged at some
point! (<em>narrator’s voice:</em> it wasn’t)</li>
<li>We are going to rewrite the project from scratch, it should take a
few weeks tops</li>
<li>We are going to improve the codebase, but no idea when it will be
done or even what we are going to do exactly</li>
</ul>
<p>Ok, let’s say that now you have buy-in from everyone that matters,
let’s go over the process:</p>
<ul>
<li>Every change is small and incremental. The app works before and
works after. Tests pass, linters are happy, nothing was bypassed to
apply the change (exceptions do happen but that’s what they are,
exceptional)</li>
<li>If an urgent bug fix has to be made, it can be done as usual,
nothing is blocked</li>
<li>Every change is a measurable improvement and can be explained and
demoed to non experts</li>
<li>If the whole effort has to be suspended or stopped altogether
(because of priorities shifting, budget reasons, etc), it’s still a net
gain overall compared to before starting it (and that gain is in some
form <em>measurable</em>)</li>
</ul>
<p>In my experience, with this approach, you keep everyone happy and can
do the improvements that you really need to do.</p>
<p>Alright, let’s get down to business now!</p>
<h2 id="write-down-the-platforms-you-support">Write down the platforms
you support</h2>
<p>This is so important and not many projects do it. Write in the README
(you do have a README, right?). It’s just a list of
<code>&lt;architecture&gt;-&lt;operating-system&gt;</code> pair,
e.g.&nbsp;<code>x86_64-linux</code> or <code>aarch64-darwin</code>, that your
codebase officially supports. This is crucial for getting the build
working on every one of them but also and we’ll see later, removing
cruft for platforms you do <em>not</em> support.</p>
<p>If you want to get fancy, you can even write down which version of
the architecture such as ARMV6 vs ARMv7, etc.</p>
<p>That helps answer important questions such as:</p>
<ul>
<li>Can we rely on having hardware support for floats, or SIMD, or
SHA256?</li>
<li>Do we even care about supporting 32 bits?</li>
<li>Are we ever running on a big-endian platform? (The answer is very
likely: no, never did, never will - if you do, please email me with the
details because that sounds interesting).</li>
<li>Can a <code>char</code> be 7 bits?</li>
</ul>
<p>And an important point: This list should absolutely include the
developers workstations. Which leads me to my next point:</p>
<h2 id="get-the-build-working-on-your-machine">Get the build working on
your machine</h2>
<p>You’d be amazed at how many C++ codebase in the wild that are a core
part of a successful product earning millions and they basically do not
compile. Well, if all the stars are aligned they do. But that’s not what
I’m talking about. I’m talking about reliably, consistently building on
all platforms you support. No fuss, no ‘I finally got it building after
3 weeks of hair-pulling’ (this brings back some memories). It just
works(tm).</p>
<p>A small aparte here. I used to be really into Karate. We are talking
3, 4 training sessions a week, etc. And I distinctly remember one of my
teachers telling me (picture a wise Asian sifu - hmm actually my teacher
was a bald white guy… picture Steve Ballmer then):</p>
<blockquote>
<p>You do not yet master this move. Sometimes you do and sometimes you
don’t, so you don’t. When eating with a spoon, do you miss your mouth
one out of five times?</p>
</blockquote>
<p>And I carried that with me as a Software Engineer. ‘The new feature
works’ means it works every time. Not four out of five times. And so the
build is the same.</p>
<p>Experience has shown me that the best way to produce software in a
fast and efficient way is to be able to build on your machine, and
ideally even run it on your machine.</p>
<p>Now if your project is humongous that may be a problem, your system
might not even have enough RAM to complete the build. A fallback is to
rent a big server somewhere and run your builds here. It’s not ideal but
better than nothing.</p>
<p>Another hurdle is the code requiring some platform specific API, for
example <code>io_uring</code> on Linux. What can help here is to
implement a shim, or build inside a virtual machine on your workstation.
Again, not ideal but better than nothing.</p>
<p>I have done all of the above in the past and that works but building
directly on your machine is still the best option.</p>
<h2 id="get-the-tests-passing-on-your-machine">Get the tests passing on
your machine</h2>
<p>First, if there are no tests, I am sorry. This is going to be really
difficult to do any change at all. So go write some tests before doing
any change to the code, make them pass, and come back. The easiest way
is to capture inputs and outputs of the program running in the real
world and write end-to-end tests based on that, the more varied the
better. It will ensure there are no regressions when making changes, not
that the behavior was correct in the first place, but again, better than
nothing.</p>
<p>So, now you have a test suite. If some tests fail, disable them for
now. Make them pass, even if the whole test suite takes hours to run.
We’ll worry about that later.</p>
<h2 id="write-down-in-the-readme-how-to-build-and-test-the-application">Write
down in the README how to build and test the application</h2>
<p>Ideally it’s one command to build and one for testing. At first it’s
fine if it’s more involved, in that case the respective commands can be
put in a <code>build.sh</code> and <code>test.sh</code> that encapsulate
the madness.</p>
<p>The goal is to have a non C++ expert be able to build the code and
run the tests without having to ask you anything.</p>
<p>Here some folks would recommend documenting the project layout, the
architecture, etc. Since the next step is going to rip out most of it,
I’d say don’t waste your time now, do that at the end.</p>
<h2 id="find-low-hanging-fruits-to-speed-up-the-build-and-tests">Find
low hanging fruits to speed up the build and tests</h2>
<p>Emphasis on ‘low hanging’. No change of the build system, no heroic
efforts (I keep repeating that in this article but this is so
important).</p>
<p>Again, in a typical C++ project, you’d be amazed at how much work the
build system is doing without having to do it at all. Try these ideas
below and measure if that helps or not:</p>
<ul>
<li>Building and running tests <em>of your dependencies</em>. In a
project which was using <code>unittest++</code> as a test framework,
built as a CMake subproject, I discovered that the default behavior was
to build the tests of the test framework, and run them, every time!
That’s crazy. Usually there is a CMake variable or such to opt-out of
this.</li>
<li>Building and running example programs <em>of your dependencies</em>.
Same thing as above, the culprit that time was <code>mbedtls</code>.
Again, setting a CMake variable to opt-out of that solved it.</li>
<li>Building and running the tests of your project by default when it’s
being included as a subproject of another parent project. Yeah the
default behavior we just laughed at in our dependencies? It turns out
we’re doing the same to other projects! I am no CMake expert but it
seems that there is no standard way to exclude tests in a build. So I
recommend adding a build variable called <code>MYPROJECT_TEST</code>
unset by default and only build and run tests when it is set. Typically
only developers working on the project directly will set it. Same with
examples, generating documentation, etc.</li>
<li>Building all of a third-party dependency when you only need a small
part of it: <code>mbedtls</code> comes to mind as a good citizen here
since it exposes many compile-time flags to toggle lots of parts you
might not need. Beware of the defaults, and only build what you
need!</li>
<li>Wrong dependencies listed for a target leading to rebuilding the
world when it does not have to: most build systems have a way to output
the dependency graph from their point of view and that can really help
diagnose these issues. Nothing feels worse than waiting for minutes or
hours for a rebuild, when deep inside, you know it should have only
rebuilt a few files.</li>
<li>Experiment with a faster linker: <code>mold</code> is one that can
dropped in and really help at no cost. However that really depends on
how many libraries are being linked, whether that’s a bottleneck
overall, etc.</li>
<li>Experiment with a different compiler, if you can: I have seen
projects where clang is twice as fast as gcc, and others where there is
no difference.</li>
</ul>
<p>Once that’s done, here are a few things to additionally try, although
the gains are typically much smaller or sometimes negative:</p>
<ul>
<li>LTO: off/on/thin</li>
<li>Split debug information</li>
<li>Make vs Ninja</li>
<li>The type of file system in use, and tweaking its settings</li>
</ul>
<p>Once the iteration cycle feels ok, the code gets to go under the
microscope. If the build takes ages, it’s not realistic to want to
modify the code.</p>
<h2 id="remove-all-unnecessary-code">Remove all unnecessary code</h2>
<p>Dad, I see dead lines of code.</p>
<p>(Get the reference? Well, ok then.)</p>
<p>I have seen 30%, sometimes more, of a codebase, being completely dead
code. That’s lines of code you pay for every time you compile, you want
to make a refactoring, etc. So let’s rip them out.</p>
<p>Here are some ways to go about it:</p>
<ul>
<li>The compiler has a bunch of <code>-Wunused-xxx</code> warnings,
e.g.&nbsp;<code>-Wunused-function</code>. They catch some stuff, but not
everything. Every single instance of these warnings should be addressed.
Usually it’s as easy as deleting the code, rebuilding and re-running the
tests, done. In rare cases it’s a symptom of a bug where the wrong
function was called. So I’d be somewhat reluctant to fully automate this
step. But if you’re confident in your test suite, go for it.</li>
<li>Linters can find unused functions or class fields,
e.g.&nbsp;<code>cppcheck</code>. In my experience there are quite a lot of
false positives especially regarding virtual functions in the case of
inheritance, but the upside is that these tools absolutely find unused
things that the compilers did not notice. So, a good excuse for adding a
linter to your arsenal, if not to the CI (more on that later).</li>
<li>I have seen more exotic techniques were the linker is instructed to
put each function in its own section and print every time a section is
removed because it’s detected to be unused at link time, but that
results in so much noise e.g.&nbsp;about standard library functions being
unused, that I have not found that really practical. Others inspect the
generated assembly and compare which functions are present there with
the source code, but that does not work for virtual functions. So, maybe
worth a shot, depending on your case?</li>
<li>Remember the list of supported platforms? Yeah, time to put it to
use to kill all the code for unsupported platforms. Code trying to
support ancient versions of Solaris on a project that exclusively ran on
FreeBSD? Out of the window it goes. Code trying to provide its own
random number generator because maybe the platform we run on does not
have one (of course it turned out that was never the case)? To the bin.
Hundred of lines of code in case POSIX 2001 is not supported, when we
only run on modern Linux and macOS? Nuke it. Checking if the host CPU is
big-endian and swapping bytes if it is? Ciao (when was the last time you
shipped code for a big-endian CPU? And if yes, how are you finding
IBM?). That code introduced years ago for a hypothetical feature that
never came? Hasta la vista.</li>
</ul>
<p>And the bonus for doing all of this, is not only that you sped up the
build time by a factor of 5 with zero downside, is that, if your boss is
a tiny bit technical, they’ll love seeing PRs deleting thousands of
lines of code. And your coworkers as well.</p>
<h2 id="linters">Linters</h2>
<p>Don’t go overboard with linter rules, add a few basic ones,
incorporate them in the development life cycle, incrementally tweak the
rules and fix the issues that pop up, and move on. Don’t try to enable
all the rules, it’s just a rabbit hole of diminishing returns. I have
used <code>clang-tidy</code> and <code>cppcheck</code> in the past, they
can be helpful, but also incredibly slow and noisy, so be warned. Having
no linter is not an option though. The first time you run the linter,
it’ll catch so many real issues that you’ll wonder why the compiler is
not detecting anything even with all the warnings on.</p>
<h2 id="code-formatting">Code formatting</h2>
<p>Wait for the appropriate moment where no branches are active
(otherwise people will have horrendous merge conflicts), pick a code
style at random, do a one time formatting of the entire codebase (no
exceptions), typically with <code>clang-format</code>, commit the
configuration, done. Don’t waste any bit of saliva arguing about the
actual code formatting. It only exists to make diffs smaller and avoid
arguments, so do not argue about it!</p>
<h2 id="sanitizers">Sanitizers</h2>
<p>Same as linters, it can be a rabbit hole, unfortunately it’s
absolutely required to spot real, production affecting, hard to detect,
bugs and to be able to fix them.
<code>-fsanitize=address,undefined</code> is a good baseline. They
usually do not have false positives so if something gets detected, go
fix it. Run the tests with it so that issues get detected there as well.
I even heard of people running the production code with some sanitizers
enabled, so if your performance budget can allow it, it could be a good
idea.</p>
<p>If the compiler you (have to) use to ship the production code does
not support sanitizers, you can at least use clang or such when
developing and running tests. That’s when the work you did on the build
system comes in handy, it should be relatively easy to use different
compilers.</p>
<p>One thing is for sure: even in the best codebase in the world, with
the best coding practices and developers, the second you enable the
sanitizers, you absolutely will uncover horrifying bugs and memory leaks
that went undetected for years. So do it. Be warned that fixing these
can require a lot of work and refactorings. Each sanitizer also has
options so it could be useful to inspect them if your project is a
special snowflake.</p>
<p>One last thing: ideally, all third-party dependencies should also be
compiled with the sanitizers enabled when running tests, to spot <a href="https://github.com/rxi/microui/pull/67">issues</a> in them as
well.</p>
<h2 id="add-a-ci-pipeline">Add a CI pipeline</h2>
<p>As Bryan Cantrill once said (quoting from memory), ‘I am convinced
most firmware just comes out of the home directory of a developer’s
laptop’. Setting up a CI is quick, free, and automates all the good
things we have set up so far (linters, code formatting, tests, etc). And
that way we can produce in a pristine environment the production
binaries, on every change. If you’re not doing this already as a
developer, I don’t think you really have entered the 21st century
yet.</p>
<p>Cherry on the cake: most CI systems allow for running the steps on a
matrix of different platforms! So you can demonstrably check that the
list of supported platforms is not just theory, it is real.</p>
<p>Typically the pipeline just looks like
<code>make all test lint fmt</code> so it’s not rocket science. Just
make sure that issues that get reported by the tools (linters,
sanitizers, etc) actually fail the pipeline, otherwise no one will
notice and fix them.</p>
<h2 id="incremental-code-improvements">Incremental code
improvements</h2>
<p>Well that’s known territory so I won’t say much here. Just that lots
of code can often be dramatically simplified.</p>
<p>I remember iteratively simplifying a complicated class that manually
allocated and (sometimes) deallocated memory, was meant to handle
generic things, and so on. All the class did, as it turned out, was
allocate a pointer, later check whether the pointer was null or not,
and…that’s it. Yeah that’s a boolean in my book. True/false, nothing
more to it.</p>
<p>I feel that’s the step that’s the hardest to timebox because each
round of simplification opens new avenues to simplify further. Use your
best judgment here and stay on the conservative side. Focus on tangible
goals such as security, correctness and performance, and stray away from
subjective criteria such as ‘clean code’.</p>
<p>In my experience, upgrading the C++ standard in use in the project
can at times help with code simplifications, for example to replace code
that manually increments iterators by a
<code>for (auto x : items)</code> loop, but remember it’s just a means
to an end, not an end in itself. If all you need is
<code>std::clamp</code>, just write it yourself.</p>
<h2 id="rewrite-in-a-memory-safe-language">Rewrite in a memory safe
language?</h2>
<p>I am doing this right now at work, and that deserves an article of
its own. Lots of gotchas there as well. Only do this with a compelling
reason.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Well, there you have it. A tangible, step-by-step plan to get out of
the finicky situation that’s a complex legacy C++ codebase. I have just
finished going through that at work on a project, and it’s become much
more bearable to work on it now. I have seen coworkers, who previously
would not have come within a 10 mile radius of the codebase, now make
meaningful contributions. So it feels great.</p>
<p>There are important topics that I wanted to mention but in the end
did not, such as the absolute necessity of being able to run the code in
a debugger locally, fuzzing, dependency scanning for vulnerabilities,
etc. Maybe for the next article!</p>
<p>If you go through this on a project, and you found this article
helpful, shoot me an email! It’s nice to know that it helped
someone.</p>
<h2 id="addendum-dependency-management">Addendum: Dependency
management</h2>
<p><em>This section is very subjective, it’s just my strong, biased
opinion.</em></p>
<p>There’s a hotly debated topic that I have so far carefully avoided
and that’s dependency management. So in short, in C++ there’s none. Most
people resort to using the system package manager, it’s easy to notice
because their README looks like this:</p>
<pre><code>On Ubuntu 20.04: `sudo apt install [100 lines of packages]`

On macOS: `brew install [100 lines of packages named slightly differently]`

Any other: well you're out of luck buddy. I guess you'll have to pick a mainstream OS and reinstall ¯\_(ツ)_/¯</code></pre>
<p>Etc. I have done it myself. And I think this is a terrible idea.
Here’s why:</p>
<ul>
<li>The installation instructions, as we’ve seen above, are OS and
distribution dependent. Worse, they’re dependent on the version of the
distribution. I remember a project that took months to move from Ubuntu
20.04 to Ubuntu 22.04, because they ship different versions of the
packages (if they ship the same packages at all), and so upgrading the
distribution also means upgrading the 100 dependencies of your project
at the same time. Obviously that’s a very bad idea. You want to upgrade
one dependency at a time, ideally.</li>
<li>There’s always a third-party dependency that has no package and you
have to build it from source anyway.</li>
<li>The packages are never built with the flags you want. Fedora and
Ubuntu have debated for years whether to build packaged with the frame
pointer enabled (they finally do since very recently). Remember the
section about sanitizers? How are you going to get dependencies with
sanitizer enabled? It’s not going to happen. But there are way more
examples: LTO, <code>-march</code>, debug information, etc. Or they were
built with a different C++ compiler version from the one you are using
and they broke the C++ ABI between the two.</li>
<li>You want to easily see the source of the dependency when auditing,
developing, debugging, etc, <em>for the version you are currently
using</em>.</li>
<li>You want to be able to patch a dependency easily if you encounter a
bug, and rebuild easily without having to change the build system
extensively</li>
<li>You never get the exact same version of a package across systems,
e.g.&nbsp;when developer Alice is on macOS, Bob on Ubuntu and the production
system on FreeBSD. So you have weird discrepancies you cannot reproduce
and that’s annoying.</li>
<li>Corollary of the point above: You don’t know exactly which
version(s) you are using across systems and it’s hard to produce a Bill
of Material (BOM) in an automated fashion, which is required (or going
to be required very soon? Anyway it’s a good idea to have it) in some
fields.</li>
<li>The packages sometimes do not have the version of the library you
need (static or dynamic)</li>
</ul>
<p>So you’re thinking, I know, I will use those fancy new package
managers for C++, Conan, vcpkg and the like! Well, not so fast:</p>
<ul>
<li>They require external dependencies so your CI becomes more complex
and slower (e.g.&nbsp;figuring out which exact version of Python they
require, which surely will be different from the version of Python your
project requires)</li>
<li>They do not have all versions of a package. Example: <a href="https://conan.io/center/recipes/mbedtls">Conan and mbedtls</a>, it
jumps from version <code>2.16.12</code> to <code>2.23.0</code>. What
happened to the versions in between? Are they flawed and should not be
used? Who knows! Security vulnerabilities are not listed anyways for the
versions available! Of course I had a project in the past where I had to
use version <code>2.17</code>…</li>
<li>They might not support some operating systems or architectures you
care about (FreeBSD, ARM, etc)</li>
</ul>
<p>I mean, if you have a situation where they work for you, that’s
great, it’s definitely an improvement over using system packages in my
mind. It’s just that I never encountered (so far) a project where I
could make use of them - there was always some blocker.</p>
<p>So what do I recommend? Well, the good old git submodules and
compiling from source approach. It’s cumbersome, yes, but also:</p>
<ul>
<li>It’s dead simple</li>
<li>It’s better than manually vendoring because git has the history and
the diff functionalities</li>
<li>You know exactly, down to the commit, which version of the
dependency is in use</li>
<li>Upgrading the version of a single dependency is trivial, just run
<code>git checkout</code></li>
<li>It works on every platform</li>
<li>You get to choose exactly the compilation flags, compiler, etc to
build all the dependencies. And you can even tailor it per
dependency!</li>
<li>Developers know it already even if they have no C++ experience</li>
<li>Fetching the dependencies is secure and the remote source is in git.
No one is changing that sneakily.</li>
<li>It works recursively (i.e.: transitively, for the dependencies of
your dependencies)</li>
</ul>
<p>Compiling each dependency in each submodule can be as simple as
<code>add_subdirectory</code> with CMake, or
<code>git submodule foreach make</code> by hand.</p>
<p>If submodules are really not an option, an alternative is to still
compile from source but do it by hand, with one script, that fetches
each dependency and builds it. Example in the wild: Neovim.</p>
<p>Of course, if your dependency graph visualized in Graphviz looks like
a Rorschach test and has to build thousands of dependencies, it is not
easily doable, but it might be still possible, using a build system like
Buck2, which does hybrid local-remote builds, and reuses build artifacts
between builds from different users.</p>
<p>If you look at the landscape of package managers for compiled
languages (Go, Rust, etc), all of them that I know of compile from
source. It’s the same approach, minus git, plus the automation.</p>

<blockquote>
  <p>If you liked this article and you want to support me, and can afford it: <a href="https://paypal.me/philigaultier?country.x=DE&amp;locale.x=en_US">Donate</a></p>
</blockquote>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple is turning William Gibson's Neuromancer into a TV series (141 pts)]]></title>
            <link>https://www.theverge.com/24086056/apple-tv-plus-neuromancer-streaming-series-william-gibson</link>
            <guid>39549340</guid>
            <pubDate>Thu, 29 Feb 2024 13:58:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/24086056/apple-tv-plus-neuromancer-streaming-series-william-gibson">https://www.theverge.com/24086056/apple-tv-plus-neuromancer-streaming-series-william-gibson</a>, See on <a href="https://news.ycombinator.com/item?id=39549340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Another sci-fi adaptation is making its way to Apple TV Plus. The streamer announced that it’s adapting William Gibson’s seminal cyberpunk novel <em>Neuromancer</em> into a 10-episode series. Graham Roland (<em>Lost</em>,<em> Jack Ryan</em>) will serve as showrunner, while JD Dillard (<em>Utopia</em>) will direct the first episode. (Both will also be executive producers on the series.)</p><p>That’s about all we know right now. There are no details on when the series might start streaming or who will star. In <a href="https://www.apple.com/tv-pr/news/2024/02/apple-tv-announces-neuromancer-new-drama-based-on-the-multi-award-winning-science-fiction-novel-by-william-gibson/">a press release</a>, Apple said that the show “will follow a damaged, top-rung super-hacker named Case who is thrust into a web of digital espionage and high stakes crime with his partner Molly, a razor-girl assassin with mirrored eyes aiming to pull a heist on a corporate dynasty with untold secrets.”</p><div><p>This is also not the first adaptation of <em>Neuromancer</em>, which originally came out 1984 as Gibson’s debut novel. Its been <a href="https://en.wikipedia.org/wiki/Neuromancer_(video_game)">turned into a video game</a>, a graphic novel, and is <a href="https://www.theverge.com/2017/8/9/16121760/neuromancer-movie-deadpool-director-tim-miller">reportedly being made into a movie</a> as well. (In 2022, Amazon adapted another Gibson novel — <em>The Peripheral</em> — into <a href="https://www.theverge.com/23412567/the-peripheral-review-amazon-prime-video-william-gibson-book">a live-action streaming series</a>.)</p></div><p>Whenever it does premiere, <em>Neuromancer</em> will join an ever-growing lineup of sci-fi on Apple TV Plus. So far that has included series like <a href="https://www.theverge.com/23786940/foundation-season-2-david-goyer-interview-apple-tv-plus"><em>Foundation</em></a>, <em>For All Mankind</em>, <a href="https://www.theverge.com/23711259/silo-review-season-1-apple-tv-plus"><em>Silo</em></a>, <a href="https://www.theverge.com/23932047/invasion-season-2-review-apple-tv-plus"><em>Invasion</em></a>, <a href="https://www.theverge.com/23913217/monarch-legacy-of-monsters-apple-nycc-preview-godzilla"><em>Monarch</em></a>, and <em>Constellation</em>, <a href="https://www.theverge.com/24065198/constellation-review-apple-tv-plus">which premiered earlier this month</a>. An adaptation of Martha Wells’ <em>The Murderbot Diaries</em> is <a href="https://www.theverge.com/2023/12/14/24001803/murderbot-series-apple-tv-plus-alexander-skarsgard">also in the works</a>, starring Alexander Skarsgård.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Workout Tracker – self-hosted, single binary web application (171 pts)]]></title>
            <link>https://github.com/jovandeginste/workout-tracker</link>
            <guid>39549194</guid>
            <pubDate>Thu, 29 Feb 2024 13:45:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jovandeginste/workout-tracker">https://github.com/jovandeginste/workout-tracker</a>, See on <a href="https://news.ycombinator.com/item?id=39549194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">A workout tracking web application for personal use (or family, friends), geared towards running and other GPX-based
activities</p>
<p dir="auto">Self-hosted, everything included.</p>
<p dir="auto">Heavily inspired by <a href="https://github.com/SamR1/FitTrackee">FitTrackee</a> ❤️.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">Run the latest master image from GitHub Container Registry:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -p 8080:8080 ghcr.io/jovandeginste/workout-tracker:master"><pre>docker run -p 8080:8080 ghcr.io/jovandeginste/workout-tracker:master</pre></div>
<p dir="auto">Open your browser at <code>http://localhost:8080</code></p>
<p dir="auto">To persist data and sessions, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -p 8080:8080 \
    -e WT_JWT_ENCRYPTION_KEY=my-secret-key \
    -v $PWD/data:/data \
    ghcr.io/jovandeginste/workout-tracker:master"><pre>docker run -p 8080:8080 \
    -e WT_JWT_ENCRYPTION_KEY=my-secret-key \
    -v <span>$PWD</span>/data:/data \
    ghcr.io/jovandeginste/workout-tracker:master</pre></div>
<p dir="auto">or use docker compose</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create directory that stores your data
mkdir -p /opt/workout-tracker
cd /opt/workout-tracker

# Download the compose.yaml
curl https://raw.githubusercontent.com/jovandeginste/workout-tracker/master/compose.yaml --output compose.yaml

# Start the server
docker compose up -d"><pre><span><span>#</span> Create directory that stores your data</span>
mkdir -p /opt/workout-tracker
<span>cd</span> /opt/workout-tracker

<span><span>#</span> Download the compose.yaml</span>
curl https://raw.githubusercontent.com/jovandeginste/workout-tracker/master/compose.yaml --output compose.yaml

<span><span>#</span> Start the server</span>
docker compose up -d</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Natively</h3><a id="user-content-natively" aria-label="Permalink: Natively" href="#natively"></a></p>
<p dir="auto">Download a pre-built binary or build it yourself (see <a href="#development">Development</a> below).</p>
<div dir="auto" data-snippet-clipboard-copy-content="wget https://github.com/jovandeginste/workout-tracker/releases/download/v0.3.0/workout-tracker-v0.3.0-linux-amd64.tar.gz
tar xf workout-tracker-v0.3.0-linux-amd64.tar.gz
./workout-tracker"><pre>wget https://github.com/jovandeginste/workout-tracker/releases/download/v0.3.0/workout-tracker-v0.3.0-linux-amd64.tar.gz
tar xf workout-tracker-v0.3.0-linux-amd64.tar.gz
./workout-tracker</pre></div>
<p dir="auto">To persist sessions, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export WT_JWT_ENCRYPTION_KEY=my-secret-key
./workout-tracker"><pre><span>export</span> WT_JWT_ENCRYPTION_KEY=my-secret-key
./workout-tracker</pre></div>
<p dir="auto">This will create a new database file in the current directory and start the web server at <code>http://localhost:8080</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dashboard</h3><a id="user-content-dashboard" aria-label="Permalink: Dashboard" href="#dashboard"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/dashboard.jpg"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/dashboard.jpg" alt=""></a>
Dashboard view with:</p>
<ul dir="auto">
<li>personal totals</li>
<li>running records</li>
<li>a calendar view</li>
<li>recent activities (by you and other users)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Overview of workouts</h3><a id="user-content-overview-of-workouts" aria-label="Permalink: Overview of workouts" href="#overview-of-workouts"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/workout_overview.jpg"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/workout_overview.jpg" alt=""></a>
Overview of all your activities, with summaries. The columns are sortable.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Details of a single workout</h3><a id="user-content-details-of-a-single-workout" aria-label="Permalink: Details of a single workout" href="#details-of-a-single-workout"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/single_workout.jpg"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/single_workout.jpg" alt=""></a>
Details of a workout, with:</p>
<ul dir="auto">
<li>a zoomable, dragable map of the GPX track with more details per point</li>
<li>many summarized statistics</li>
<li>a breakdown per kilometer</li>
<li>track color based on elevation of the segment</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tooltips for even more information</h3><a id="user-content-tooltips-for-even-more-information" aria-label="Permalink: Tooltips for even more information" href="#tooltips-for-even-more-information"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/track.gif"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/track.gif" alt="" data-animated-image=""></a></p>
<ul dir="auto">
<li>green and red circle are start and end points of the track</li>
<li>every point on the track has a tooltip with a summary at that moment</li>
<li>hover over the breakdown per kilometer to highlight the point</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Upload your files</h3><a id="user-content-upload-your-files" aria-label="Permalink: Upload your files" href="#upload-your-files"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/upload_workouts.jpg"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/upload_workouts.jpg" alt=""></a></p>
<ul dir="auto">
<li>Upload one or multiple GPX files.</li>
<li>Pick the type (running, cycling, ...) or let the application guess based on average speed</li>
<li>The files are parsed when uploaded: statistics and other information are calculated and stored in the database (serialized).</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Statistics to follow your progress</h3><a id="user-content-statistics-to-follow-your-progress" aria-label="Permalink: Statistics to follow your progress" href="#statistics-to-follow-your-progress"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/statistics.jpg"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/statistics.jpg" alt=""></a></p>
<ul dir="auto">
<li>Graphs showing monthly aggregated statistics.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic multi-language support</h3><a id="user-content-basic-multi-language-support" aria-label="Permalink: Basic multi-language support" href="#basic-multi-language-support"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/i18n.gif"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/i18n.gif" alt="" data-animated-image=""></a></p>
<ul dir="auto">
<li>Switch between (supported) languages</li>
<li>Use the language configured in the browser (default)</li>
<li>Very limited amount of languages supported for now 😄</li>
<li>Re-calculate all previously uploaded workouts (useful while developing)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Responsive design</h3><a id="user-content-responsive-design" aria-label="Permalink: Responsive design" href="#responsive-design"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/responsive.png"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/responsive.png" alt=""></a></p>
<ul dir="auto">
<li>Usable on small and medium screens</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Light and dark mode</h3><a id="user-content-light-and-dark-mode" aria-label="Permalink: Light and dark mode" href="#light-and-dark-mode"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jovandeginste/workout-tracker/blob/master/docs/single_workout-theme.jpg"><img src="https://github.com/jovandeginste/workout-tracker/raw/master/docs/single_workout-theme.jpg" alt=""></a></p>
<ul dir="auto">
<li>Browser decides whether to use light or dark mode, based on your preferences</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">The web server looks for a file <code>workout-tracker.yaml</code> (or <code>json</code> or <code>toml</code>) in the current directory, or takes it's
configuration from environment variables. The most important variable is the JWT encryption key. If you don't provide
it, the key is randomly generated every time the server starts, invalidating all current sessions.</p>
<p dir="auto">Generate a secure key and write it to <code>workout-tracker.yaml</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &quot;jwt_encryption_key: $(pwgen -c 32)&quot; > workout-tracker.yaml"><pre><span>echo</span> <span><span>"</span>jwt_encryption_key: <span><span>$(</span>pwgen -c 32<span>)</span></span><span>"</span></span> <span>&gt;</span> workout-tracker.yaml</pre></div>
<p dir="auto">or export it as an environment variable:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export WT_JWT_ENCRYPTION_KEY=&quot;$(pwgen -c 32)&quot;"><pre><span>export</span> WT_JWT_ENCRYPTION_KEY=<span><span>"</span><span><span>$(</span>pwgen -c 32<span>)</span></span><span>"</span></span></pre></div>
<p dir="auto">See <code>workout-tracker.example.yaml</code> for more options and details.</p>
<p dir="auto">After starting the server, you can access it at <a href="http://localhost:8080/" rel="nofollow">http://localhost:8080</a> (the default port). A login form is shown.</p>
<p dir="auto">If no users are in the database (eg. when starting with an empty database), a default <code>admin</code> user is created with
password <code>admin</code>. You should change this password in a production environment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build and run it yourself</h3><a id="user-content-build-and-run-it-yourself" aria-label="Permalink: Build and run it yourself" href="#build-and-run-it-yourself"></a></p>
<ul dir="auto">
<li>install go</li>
<li>clone the repository</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="go build ./
./workout-tracker"><pre>go build ./
./workout-tracker</pre></div>
<p dir="auto">This does not require npm or Tailwind, since the compiled css is included in the repository.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Do some development</h3><a id="user-content-do-some-development" aria-label="Permalink: Do some development" href="#do-some-development"></a></p>
<p dir="auto">You need to install Golang and npm.</p>
<p dir="auto">Because I keep forgetting how to build every component, I created a Makefile.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Make everything. This is also the default target.
make all # Run tests and build all components

# Install system dependencies
make install-deps

# Testing
make test # Runs all the tests
make test-assets test-go # Run tests for the individual components

# Building
make build # Builds all components
make build-tw # Builds the Tailwind CSS output file
make build-server # Builds the web server
make build-docker # Performs all builds inside Docker containers, creates a Docker image

# Running it
make serve # Runs the compiled binary
make dev # Runs a wrapper that watches for changes, then rebuilds and restarts
make watch-tw # Runs the Tailwind CSS watcher (not useful unless you're debugging Tailwind CSS)

# Cleanin' up
make clean # Removes build artifacts"><pre><span><span>#</span> Make everything. This is also the default target.</span>
make all <span><span>#</span> Run tests and build all components</span>

<span><span>#</span> Install system dependencies</span>
make install-deps

<span><span>#</span> Testing</span>
make <span>test</span> <span><span>#</span> Runs all the tests</span>
make test-assets test-go <span><span>#</span> Run tests for the individual components</span>

<span><span>#</span> Building</span>
make build <span><span>#</span> Builds all components</span>
make build-tw <span><span>#</span> Builds the Tailwind CSS output file</span>
make build-server <span><span>#</span> Builds the web server</span>
make build-docker <span><span>#</span> Performs all builds inside Docker containers, creates a Docker image</span>

<span><span>#</span> Running it</span>
make serve <span><span>#</span> Runs the compiled binary</span>
make dev <span><span>#</span> Runs a wrapper that watches for changes, then rebuilds and restarts</span>
make watch-tw <span><span>#</span> Runs the Tailwind CSS watcher (not useful unless you're debugging Tailwind CSS)</span>

<span><span>#</span> Cleanin' up</span>
make clean <span><span>#</span> Removes build artifacts</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is this, technically?</h2><a id="user-content-what-is-this-technically" aria-label="Permalink: What is this, technically?" href="#what-is-this-technically"></a></p>
<p dir="auto">A single binary that runs on any platform, with no dependencies.</p>
<p dir="auto">The binary contains all assets to serve a web interface, through which you can upload your GPX files, visualize
your tracks and see their statistics and graphs. The web application is multi-user, with a simple registration and
authentication form, session cookies and JWT tokens). New accounts are inactive by default. An admin user can activate
(or edit, delete) accounts. The default database storage is a single SQLite file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What technologies are used</h2><a id="user-content-what-technologies-are-used" aria-label="Permalink: What technologies are used" href="#what-technologies-are-used"></a></p>
<ul dir="auto">
<li>Go, with some notable libraries
<ul dir="auto">
<li><a href="https://github.com/jovandeginste/workout-tracker/blob/master/github.com/tkrajina/gpxgo">gpxgo</a></li>
<li><a href="https://echo.labstack.com/" rel="nofollow">Echo</a></li>
<li><a href="https://gorm.io/" rel="nofollow">Gorm</a></li>
<li><a href="https://github.com/vorlif/spreak">Spreak</a></li>
</ul>
</li>
<li>HTML, CSS and JS
<ul dir="auto">
<li><a href="https://tailwindcss.com/" rel="nofollow">Tailwind CSS</a></li>
<li><a href="https://fontawesome.com/" rel="nofollow">Font Awesome</a></li>
<li><a href="https://fullcalendar.io/" rel="nofollow">FullCalendar</a></li>
<li><a href="https://leafletjs.com/" rel="nofollow">Leaflet</a></li>
<li><a href="https://www.kryogenix.org/code/browser/sorttable/" rel="nofollow">sorttable</a></li>
<li><a href="https://cdn.jsdelivr.net/npm/chart.js" rel="nofollow">Chart.js</a></li>
</ul>
</li>
<li>Docker</li>
</ul>
<p dir="auto">The application uses OpenStreetMap as its map provider and for geocoding a GPS coordinate to a location.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatiblity</h2><a id="user-content-compatiblity" aria-label="Permalink: Compatiblity" href="#compatiblity"></a></p>
<p dir="auto">This is a work in progress. If you find any problems, please let us know. The application is tested with GPX files from
these sources:</p>
<ul dir="auto">
<li>Garmin Connect (export to GPX)</li>
<li>FitoTrack (automatic export to GPX)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODO</h2><a id="user-content-todo" aria-label="Permalink: TODO" href="#todo"></a></p>
<ul dir="auto">
<li>write tests!!!!!</li>
<li>add support for authentication through a reverse proxy</li>
<li>make a dev-flag that doesn't embed all files in the binary</li>
<li>add support for generic database drivers</li>
<li>add support for other types of import files (eg. Garmin fit files)</li>
<li>add support for auto-import from a folder (per user)</li>
<li>see if htmx is worth using</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Billionaire-Fueled Lobbying Group Behind the State Bills to Ban UBI Experiments (103 pts)]]></title>
            <link>https://www.scottsantens.com/billionaire-fueled-lobbying-group-behind-the-state-bills-to-ban-universal-basic-income-experiments-ubi/</link>
            <guid>39549098</guid>
            <pubDate>Thu, 29 Feb 2024 13:35:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scottsantens.com/billionaire-fueled-lobbying-group-behind-the-state-bills-to-ban-universal-basic-income-experiments-ubi/">https://www.scottsantens.com/billionaire-fueled-lobbying-group-behind-the-state-bills-to-ban-universal-basic-income-experiments-ubi/</a>, See on <a href="https://news.ycombinator.com/item?id=39549098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
      


      <section>
        <h2 id="the-foundation-for-government-accountabilitya-florida-based-lobbying-group-backed-by-the-richest-1is-working-to-get-basic-income-experiments-banned-by-state-legislators-across-the-us">The Foundation for Government Accountability - a Florida-based lobbying group backed by the richest 1% - is working to get basic income experiments banned by state legislators across the U.S.</h2><p>As a well-known quote often wrongly attributed to Mahatma Ghandi says, “First they ignore you, then they laugh at you, then they fight you, then you win.” As of 2024, the basic income movement in the United States is now firmly in the "<strong>then they fight you</strong>" stage thanks to a slew of bills introduced in state after state that are all attempting to ban the basic income experiments that have spread across the country. <a href="https://basicincome.stanford.edu/experiments-map/?ref=scottsantens.com" rel="noreferrer">Over 150 guaranteed basic income pilots</a> are now ongoing or recently completed in 24 states as of this writing, and so far, bills in seven states have been introduced to stop them. All of the bills are the result of efforts by the <strong>Foundation for Government Accountability</strong> (FGA) -  a lobbying group with a billionaire-fueled junk science record every American should know about.</p><p>First, to bring every reader up to speed, <a href="https://basicincome.org/?ref=scottsantens.com" rel="noreferrer">basic income</a> (or UBI) is "<strong>a periodic cash payment, unconditionally delivered to all on an individual basis, without means test or work requirement</strong>." Although such payments without conditions already exist upon a mountain of evidence, post-2020, experiments have exploded in cities across the U.S. thanks to the efforts of Mayors for Guaranteed Income (MGI) which was founded in 2020 by former Mayor Michael Tubbs after the success of the pilot in <a href="https://sp2.upenn.edu/study-guaranteed-income-improved-peoples-health-during-pandemic/?ref=scottsantens.com" rel="noreferrer">Stockton, CA</a> that provided $500 a month to 125 people for 2 years. The biggest findings there were that <strong>full-time employment grew at twice the rate of the control group, and mental health improved significantly</strong>. Yes, despite the common fear that people provided basic income would work less, in Stockton, they worked more, and the mental health impact was comparable to medication.</p><p>Since the Stockton pilot ended, there have been dozens of other completed pilots with completed reports, all of which report the same general findings over and over again. Employment does not go down to any worrisome degree, and often actually goes up, with people finding better jobs and better pay, and where wage work is reduced, people invest in schooling or pursue unpaid work or self-employment. With each experiment's results, the case for UBI becomes stronger, and it's clear that <strong>some very wealthy people don't like those results</strong>.</p><p>In March of 2021 and again in late 2022, <a href="https://www.kxan.com/news/texas-politics/new-texas-bill-aimed-at-austins-guaranteed-income-program/?ref=scottsantens.com" rel="noreferrer">Texas</a> became the first state to attempt to stop more results. <a href="https://capitol.texas.gov/BillLookup/History.aspx?LegSess=87R&amp;Bill=HB4550&amp;ref=scottsantens.com" rel="noreferrer">House Bill 4550</a> in 2021 and then <a href="https://legiscan.com/TX/bill/HB553/2023?ref=scottsantens.com" rel="noreferrer">House Bill 553</a> in 2022 both included the following wording:</p><blockquote>"PROHIBITION ON PROVIDING UNIVERSAL BASIC INCOME. (a) In this section, 'universal basic income' means unconditional cash grants of equal amounts issued on a regular basis to individual residents of a political subdivision. The term includes a basic income, monthly income, or minimum income paid to each individual resident of the political subdivision without regard to the individual ’s circumstances. (b) Notwithstanding any other law, a political subdivision may not adopt or enforce an ordinance, order, or other measure providing for a universal basic income."</blockquote><p>Both bills died in committee. In January 2024, a different approach was taken, with a request for the Texas attorney general to <a href="https://www.kxan.com/news/texas-politics/new-texas-bill-aimed-at-austins-guaranteed-income-program/?ref=scottsantens.com" rel="noreferrer">declare such pilots as unconstitutional</a>. It should be noted that as of Feb 2024, there have been seven basic income pilots launched in Texas. One of those that took place in Austin has already published <a href="https://twitter.com/scottsantens/status/1750178842487009775?ref=scottsantens.com" rel="noreferrer">its results</a>. It found that <strong>a payment of $1,000 a month to 135 people for one year led to 9% of participants working less and 7% working more</strong>, and of those who worked less, half upskilled for better future jobs, and half chose unpaid care work. Housing security also significantly increased, as did food security, participants lived in better housing and ate more balanced meals, and they also felt significantly more connected to the people and places in their neighborhoods. A ban would have prevented these findings.</p><p>In April of 2023, <a href="https://archive.ph/x5umb?ref=scottsantens.com" rel="noreferrer">Wisconsin</a> became the next state to attempt to stop more results. At the time, there was a pilot in the city of Madison that wasn't quite done yet, where 155 parents of kids under age 18 got $500 a month for one year. The bill would not have stopped that pilot because it was privately-funded, but the bill was written to stop any future pilots from using any state funds to test "regular periodic cash payments that are unearned and that may be used for any purpose." The bill passed the Wisconsin House and Senate and died by veto by Governor Evers.</p><p>In 2024, the anti-UBI bill floodgates opened, starting with <a href="https://www.desmoinesregister.com/story/news/politics/2024/01/18/iowa-legislature-bill-would-ban-guaranteed-income-programs/72269962007/?ref=scottsantens.com" rel="noreferrer">Iowa</a> in January and followed in quick succession by <a href="https://www.dominionpost.com/2024/02/07/house-panel-halts-home-based-work-bill-advances-one-prohibiting-universal-basic-income/?ref=scottsantens.com" rel="noreferrer">West Virginia</a>, <a href="https://www.thecentersquare.com/south_dakota/article_c404efee-d26d-11ee-9fd8-e79c3b36aa40.html?ref=scottsantens.com" rel="noreferrer">South Dakota</a>, <a href="https://azmirror.com/blog/arizona-republicans-want-to-ban-guaranteed-basic-income-programs/?ref=scottsantens.com" rel="noreferrer">Arizona</a> and <a href="https://www.businessinsider.com/guaranteed-basic-income-program-ban-south-dakota-affordable-housing-groceries-2024-2?ref=scottsantens.com" rel="noreferrer">Arkansas</a> in February. All of them introduced bills of their own to stop basic income pilots, all with similar language. At this point, it became clear that a lobbying organization of some kind was behind the bills, something like the <a href="https://www.youtube.com/watch?v=aIMgfBZrrZ8&amp;ref=scottsantens.com" rel="noreferrer">American Legislative Exchange Council</a> that writes bills for legislators to put their names on and pass into law. In my research to discover the group responsible, I found it's the Foundation for Government Accountability, which led down a rabbit hole of dark money and a slew of harmful bills desired by the 1% to reduce their taxes and reduce the power of the 99% to stand in their way.</p><h3 id="who-is-the-fga">Who is the FGA?</h3><p>The Foundation for Government Accountability was founded in Florida in 2011 by Tarren Bragdon after cutting his chops in Maine at the Maine Heritage Policy Center and then as adviser to Maine's governor, LePage. It was in Maine where Bragdon and a cohort of fellow young conservatives gained a reputation for outrageous anti-welfare policies. “I remember them as <strong>a pack of inexperienced, activist right-wingers that went crazy on welfare reform</strong>,” said Cynthia Dill, a former state senator to the <a href="https://archive.ph/Q6fln?ref=scottsantens.com" rel="noreferrer">Washington Post in 2018</a>. “It galled me that <strong>they had no expertise whatsoever in health and human services</strong> but were appointed to places of power by the LePage administration.”</p><p>Bragdon's regressive work in Maine was only the beginning for him. He went on to export that work to every state he could and even the federal government too, starting in 2017 when the FGA attempted to expand the work requirements for SNAP to even include parents and limit waivers for states regardless of unemployment rates. The FGA reports now having relationships with <a href="https://thefga.org/about-us/?ref=scottsantens.com" rel="noreferrer">450 policymakers</a> across the country. Bragdon has described FGA's goal as wanting to "return America to a country where entrepreneurship thrives, personal responsibility is rewarded, and <strong>paychecks replace welfare checks</strong>," and that their approach is "to really tackle one big issue: how to give more Americans <strong>the life-changing power of work</strong>, at both the state and federal level.”</p><p>At this point, I will remind readers that <a href="https://www.scottsantens.com/did-spains-b-mincome-experiment-prove-that-unconditional-universal-basic-income-doesnt-work-ubi/" rel="noreferrer"><strong>universal basic income is quite different than welfare</strong></a> in how it doesn't get pulled away with work, which is why <strong>so many UBI pilots show increased employment</strong> for recipients since all wages from work increase their total income, whereas with conditional welfare they can be left barely better off financially, or even worse off. Means-tested welfare creates cliff effects, and cliff effects disincentivize work. I will also mention that if someone's goal is thriving entrepreneurship, it should be considered very intriguing how often <a href="https://www.scottsantens.com/universal-basic-income-will-accelerate-innovation-by-reducing-our-fear-of-failure/" rel="noreferrer"><strong>UBI pilots show large increases in entrepreneurship</strong></a>. That is, it should be interesting to those who truly value empirical evidence.</p><p>The FGA however is clearly not interested in empirical evidence. One of its first "studies" contributed to Florida Governor Rick Scott's defense of his controversial welfare drug-testing law, requiring benefit recipients to take a drug test as a qualification for benefits. A Bush-appointed federal judge threw out that study as evidence, claiming <strong>it was "not competent expert opinion"</strong> and that "even a cursory review of certain assumptions in the pamphlet undermines its conclusions."</p><p>Florida's law requiring drug tests for welfare applicants ended up identifying only 2.6% testing positive, significantly lower than the general population's rate of 8.13% in Florida. This directly contradicted justifications for the law, which also proved financially wasteful. Florida spent over $118,000 reimbursing those who tested negative, exceeding any program savings and resulting in a net cost exceeding $45,000. <a href="https://www.aclu.org/news/smart-justice/just-we-suspected-florida-saved-nothing-drug-testing-welfare?ref=scottsantens.com" rel="noreferrer"><strong>It cost more to apply the condition than it saved</strong></a>. It should also be noted that studies of <a href="https://www.scottsantens.com/what-do-we-do-about-drug-users-with-basic-incomes/" rel="noreferrer">unconditional cash programs tend to show a net reduction in drug use</a>.</p><p>In 2016, the FGA touted a study from Kansas of work requirements on SNAP which was panned by both liberal and conservative economists alike for cherry-picking data. “<strong>Work requirements should be based on credible evidence and attention to policy details — the exact opposite of what FGA produces</strong>,” <a href="https://twitter.com/PeteTheCitizen/status/985142798700761088?ref=scottsantens.com" rel="noreferrer">tweeted</a> Peter Germanis, a conservative&nbsp;economist who served in the Reagan and Bush administrations who went on to <a href="https://twitter.com/PeteTheCitizen/status/1660024728533311489?ref=scottsantens.com" rel="noreferrer">tweet</a>, “Tarren Bragdon bases his arguments to support work requirements on the <strong>junk science</strong> produced by the FGA – <strong>no serious researcher would accept their claims</strong>."</p><figure><blockquote><p lang="en" dir="ltr">REMINDER: Tarren Bragdon bases his arguments to support work requirements on the junk science produced by the FGA -- no serious researcher would accept their claims.<a href="https://t.co/tBkcZKLVVB?ref=scottsantens.com">https://t.co/tBkcZKLVVB</a></p>— Peter the Citizen (@PeteTheCitizen) <a href="https://twitter.com/PeteTheCitizen/status/1660024728533311489?ref_src=twsrc%5Etfw&amp;ref=scottsantens.com">May 20, 2023</a></blockquote>
</figure><p>Although the FGA itself is a 501(c)(3) that is prohibited from lobbying, it has a 501(c)(4) lobbying arm <a href="https://www.guidestar.org/profile/47-3125722?ref=scottsantens.com" rel="noreferrer">FGA Action</a> which operates as the <a href="https://solutionsproject.org/about/?ref=scottsantens.com" rel="noreferrer">Opportunity Solutions Project</a>. Tarren Bragdon is the CEO of both the FGA and OSP. With an annual budget that has been steadily rising from $212,000 in 2011, to over $14 million in 2022, the FGA has been busy attracting a pool of wealthy benefactors as it has pursued: expanded work requirements for everyone in all government assistance programs aka <a href="https://www.vox.com/policy-and-politics/2019/9/4/20835692/conservative-think-tank-foundation-for-government-accountability-food-stamps-snap-poverty-welfare?ref=scottsantens.com" rel="noreferrer">universal work requirements</a>, <a href="https://archive.ph/8Yiil?ref=scottsantens.com#selection-349.0-349.168" rel="noreferrer">the rolling back of child labor protections</a>, the expansion of measures to restrict the vote and <a href="https://thefga.org/blog/these-states-are-banning-ranked-choice-voting-yours-should-too/?ref=scottsantens.com" rel="noreferrer">ban ranked-choice voting</a>, and <a href="https://www.theguardian.com/us-news/2023/jun/23/foundation-government-accountability-democracy?ref=scottsantens.com" rel="noreferrer">the derailing of citizen-led ballot initiatives</a> to protect abortion rights, raise the minimum wage, or expand Medicaid, by pushing for all ballot initiatives to require 60% of the vote instead of a simple majority. And their newest battle is against unconditional basic income, <strong>because of its lack of conditions</strong>.</p><p>It was on February 13, 2024 that the FGA went public about its opposition to UBI with the publication of its paper "<a href="https://thefga.org/research/why-states-should-ban-universal-basic-income-schemes/?ref=scottsantens.com" rel="noreferrer">Why States Should Ban Universal Basic Income Schemes</a>." Their main premise is that basic income discourages work, which of course isn't what the evidence shows. Amusingly, their paper cites a source for virtually every sentence, except for this one, "These programs disincentivize work and promote increased dependency on government handouts, at the expense of individual responsibility," and this one, "By providing generous benefits designed to replace income, universal basic income discourages individuals from working."</p><p>A 2020 <a href="https://www.mdpi.com/2071-1050/12/22/9459?ref=scottsantens.com" rel="noreferrer">peer-reviewed systematic review of 38 studies of basic income</a> reached the following conclusion, my emphasis added in bold:</p><blockquote>"Despite a detailed search, we have not found any evidence of a significant reduction in labor supply. Instead, we found evidence that <strong>labor supply increases</strong> globally among adults, men and women, young and old, and the existence of some insignificant and functional reductions to the system such as a decrease in workers from the following categories: Children, the elderly, the sick, those with disabilities, women with young children to look after, or young people who continued studying. These reductions do not reduce the overall supply since <strong>it is largely offset by increased supply</strong> from other members of the community."</blockquote><p>All the reports of the newer basic income pilots that have been published since that review have only further strengthened the review's conclusion. Over and over again, in city after city, work has either increased or not significantly decreased.</p><p>The FGA anti-UBI paper also compares the boosted unemployment insurance payments during the pandemic to UBI, which anyone who understands UBI knows is quite different. <strong>Paying people on the condition they remain unemployed is not at all the same thing as paying people regardless of their employment status</strong>. One creates a work disincentive and the other doesn't. It is this difference that all the latest generation of pilots are testing. What happens when someone gets to keep a payment in addition to their paycheck, instead of losing it? The basic income pilots are answering that question using the scientific method to compare treatment groups to control groups.</p><p>A week after FGA published its anti-UBI paper, it planted an op-ed in the <a href="https://www.dallasnews.com/opinion/commentary/2024/02/19/guaranteed-universal-basic-income-programas-trap-people-in-dependency/?ref=scottsantens.com" rel="noreferrer">Dallas Morning News</a>, just as it and similar groups often do as part of their overall strategy. The op-ed made no mention of <a href="https://twitter.com/scottsantens/status/1761392672302866456?ref=scottsantens.com" rel="noreferrer">the positive results of the pilot in Texas</a> that had just been published a month prior. Instead it made claims based on the pilots from the 1970s, which were quite different in design, and although do have something to tell us about basic income, need to be looked at <a href="https://www.researchgate.net/publication/222578698_A_failure_to_communicate_What_if_anything_can_we_learn_from_the_negative_income_tax_experiments?ref=scottsantens.com" rel="noreferrer">in their full context</a>, like for example the high marginal tax rates above and beyond 50% that they tested, and the fact that self-reporting working less meant a larger payment.</p><p>From now going forward, if you make a point of looking, you'll find quotes from the FGA in articles about bills to ban basic income pilots at the state level. What you won't find is any mention of <a href="https://iseralaska.org/static/legacy_publication_links/bien_xiii_ak_pfd_lessons.pdf?ref=scottsantens.com" rel="noreferrer">Alaska's UBI</a> which it has had since 1982. You won't find any mention of how studies have shown <a href="https://harris.uchicago.edu/news-events/news/universal-basic-income-policies-dont-cause-people-leave-workforce-study-finds?ref=scottsantens.com" rel="noreferrer">it has increased employment</a> there, or how it has improved the <a href="https://onlinelibrary.wiley.com/doi/10.1111/ecin.12235?ref=scottsantens.com" rel="noreferrer">health of mothers and babies</a>, or how it has reduced <a href="https://scholarworks.alaska.edu/handle/11122/11998?ref=scottsantens.com" rel="noreferrer">obesity</a> and <a href="https://www.nber.org/papers/w31733?ref=scottsantens.com" rel="noreferrer">child abuse</a>. And most importantly of all, something else you won't find in FGA's anti-UBI hit pieces, is the names of FGA's funders.</p><h3 id="who-is-funding-the-fga">Who is Funding the FGA?</h3><p>According to the Center for Media and Democracy's <a href="https://www.sourcewatch.org/index.php?title=Foundation_for_Government_Accountability&amp;ref=scottsantens.com" rel="noreferrer">SourceWatch</a>, the largest single donor to FGA has been the <strong>Ed Uihlein Family Foundation</strong>, with a total contribution from 2014-2021 of <strong>$17.85 million</strong>. Both in their 70s, the Uihleins (pronounced YOU-line) are a husband and wife team, Richard and Liz, worth <a href="https://www.forbes.com/profile/richard-uihlein/?sh=61f890ce161b&amp;ref=scottsantens.com" rel="noreferrer">around $5 billion</a>. Together, the couple is the fourth biggest donor to political campaigns in the U.S., having reported giving over $190 million. The New York Times described them in 2018 as t<a href="https://archive.ph/phzx7?ref=scottsantens.com" rel="noreferrer">he most powerful couple you've never heard of</a>. In 2023 as reported by <a href="https://www.theguardian.com/us-news/2023/jun/23/foundation-government-accountability-democracy?ref=scottsantens.com" rel="noreferrer">The Guardian</a>, the Uihleins were "one of the <a href="https://www.thedailybeast.com/inside-the-billionaire-backed-dick-uihlein-hub-for-election-denial-restoration-action?ref=scottsantens.com">key funders</a> of <a href="https://www.propublica.org/article/uline-uihlein-election-denial?ref=scottsantens.com">election denial</a>," having poured "<a href="https://www.opensecrets.org/news/2022/03/millions-of-dollars-poured-into-a-dark-money-group-tied-to-billionaire-backed-super-pac-and-efforts-to-expose-voter-rolls/?ref=scottsantens.com">tens of millions</a> into the 'Restoration of America' network that <a href="https://www.restorationofamerica.com/restoration-news/eric/left-plans-to-go-postal-on-what-remains-of-americas-election-integrity/?ref=scottsantens.com">promotes</a> <a href="https://www.restorationofamerica.com/restoration-news/eric/eric-the-best-data-money-cant-buy-pt-1/?ref=scottsantens.com">ludicrous</a> <a href="https://www.restorationofamerica.com/restoration-news/eric/the-voter-registration-machine-flipping-the-states-blue/?ref=scottsantens.com">election</a> <a href="https://www.restorationofamerica.com/restoration-news/eric/the-left-wing-election-swamp-huddles/?ref=scottsantens.com">conspiracy</a> <a href="https://www.restorationofamerica.com/restoration-news/eric/the-left-mines-for-votes-in-americas-prisons/?ref=scottsantens.com">theories</a>," and "in the 2022 cycle, <a href="https://www.propublica.org/article/uline-uihlein-election-denial?ref=scottsantens.com">were also top donors</a> to election-denying candidates." The Uihleins were also <a href="https://www.chicagotribune.com/2022/07/26/darren-bailey-declines-to-answer-questions-on-trump-jan-6-committee-and-call-to-censure-adam-kinzinger/?ref=scottsantens.com" rel="noreferrer">one of the biggest contributors</a> to the "March To Save America" rally that preceded the violent insurrection on January 6.</p><p>The second biggest donor to the FGA is <strong>Donors Trust</strong> and its affiliate organization Donors Capital Fund, with a total contribution of <strong>$17.2 million</strong> from 2014 to 2022. Founded by <a href="https://reason.com/2015/08/18/whitney-ball-founder-of-donorstrust-rip/?ref=scottsantens.com" rel="noreferrer">a pair of activist libertarians</a>, the combo are two of the most influential conservative organizations around. In 2013, Mother Jones dubbed them the “<a href="https://www.motherjones.com/politics/2013/02/donors-trust-donor-capital-fund-dark-money-koch-bradley-devos/?ref=scottsantens.com"><u>dark-money ATM of the right</u></a>.” Donors Trust allows wealthy contributors who want to donate millions to do so anonymously,&nbsp;essentially scrubbing&nbsp;the identity of those underwriting organizations like the FGA. If you're a rich person who doesn't like the idea of UBI and how it will likely raise your taxes, you can give to Donors Trust and let them give the FGA your money for you, protecting your identity from those who would like to know you're fighting against boosting their incomes with a basic income floor.</p><p>The FGA's third biggest donor, with a total of <strong>$5.3 million</strong> from 2015 to 2020 is the Vanguard Charitable Endowment which is a large donor advised fund (DAF) where donors can drop money in to get an immediate tax deduction, then request where they'd like that money to go. It's another way of keeping one's anonymity. DAFs also <a href="https://theintercept.com/2023/06/08/christopher-rufo-nonprofit-dark-money/?ref=scottsantens.com" rel="noreferrer">help enable a public charity to stay a public charity</a>. Besides Vanguard, another of FGA's biggest donors is another big DAF - Fidelity Investments Charitable Gift Fund - with <strong>$1.3 million</strong> passed through them. Vanguard and Fidelity are not political DAFs in any way. They're just very popular DAFs to use.</p><p>Coming in at number four, five, and six is the <a href="https://www.sourcewatch.org/index.php?title=Sarah_Scaife_Foundation&amp;ref=scottsantens.com" rel="noreferrer">Sarah Scaife Foundation</a> with a total of <strong>$3.2 million</strong>, the <a href="https://www.sourcewatch.org/index.php?title=Lynde_and_Harry_Bradley_Foundation&amp;ref=scottsantens.com" rel="noreferrer">Lynde and Harry Bradley Foundation</a> with <strong>$2.75 million</strong>, and the <a href="https://www.sourcewatch.org/index.php?title=Searle_Freedom_Trust&amp;ref=scottsantens.com" rel="noreferrer">Searle Freedom Trust</a> with <strong>$2.15 million</strong>. Together, these three organizations have been described as "<a href="https://www.eenews.net/articles/meet-the-dead-industrialists-funding-climate-denialism/?ref=scottsantens.com" rel="noreferrer">a source of 'baseload' funding</a> for organizations that have battled the government for the last 40 years." According to Kert Davies, director of the nonprofit Climate Investigations Center, "<strong>They are fundamentalists about hating the government, hating regulation and trying to stop any progress</strong> on things like climate change because they see it as almost a step toward communism, it’s almost that stark." The Bradley Foundation has provided grants to the FGA specifically to support projects “reducing the welfare state and restoring the working class."</p><p>The seventh biggest FGA funder is the <a href="https://www.sourcewatch.org/index.php?title=Dunn_Foundation&amp;ref=scottsantens.com" rel="noreferrer">Dunn Foundation</a> with <strong>$2.4 million</strong> from 2016 to 2022. Founded in 1993 by Florida multimillionaire <a href="https://www.sourcewatch.org/index.php?title=William_A._Dunn&amp;ref=scottsantens.com">William A. Dunn</a>. According to the trust agreement, the Dunn Foundation aims to "advance the understanding and practice of classical liberalism, market capitalism, free enterprise, individual political and economic liberty and to reduce the impact of the use of threat of force by coercive organizations (both public and private) against the people of America and the world, principally through education and persuasion." It's a shame that the Dunn Foundation apparently doesn't seem to see basic income in the same way <a href="https://iai.tv/articles/why-friedmans-free-market-needs-basic-income-joshua-preiss-auid-2452?_auid=2020&amp;ref=scottsantens.com" rel="noreferrer">Milton Friedman</a> and <a href="https://www.libertarianism.org/columns/why-did-hayek-support-basic-income?ref=scottsantens.com" rel="noreferrer">Friedrich Hayek</a> both did. Here's what libertarian Matt Zwolinski has written about Hayek's support:</p><blockquote>"A&nbsp;basic income gives people an option – to exit the labor market, to relocate to a&nbsp;more competitive market, to invest in training, to take an entrepreneurial risk, and so on. And the existence of that option allows them to escape subjection to the will of others. It enables them to say 'no' to proposals that only extreme desperation would ever drive them to accept. It allows them to govern their lives according to their own plans, their own goals, and their own desires. It enables them to be free."</blockquote><p>Finally, the eighth biggest funder is the <a href="https://www.sourcewatch.org/index.php?title=The_85_Fund&amp;ref=scottsantens.com" rel="noreferrer">85 Fund</a> with a total of <strong>$2 million </strong>in 2020. The 85 Fund is Leonard Leo's, and a rebrand of the Judicial Education Project and the Honest Election Project. Everyone should know who <a href="https://www.propublica.org/article/we-dont-talk-about-leonard-leo-supreme-court-supermajority?ref=scottsantens.com" rel="noreferrer">Leonard Leo</a> is by now. He's the guy chiefly responsible for the transformation of the Supreme Court and the overturning of Roe v. Wade. He's one of the most prolific fundraisers in American politics. Under his watch, groups in his orbit have raised more than $600 million, and in 2021, he was given a war chest of <a href="https://www.propublica.org/article/dark-money-leonard-leo-barre-seid?ref=scottsantens.com" rel="noreferrer">$1.6 billion</a> by billionaire Barre Seid in the largest political advocacy donation in US history.</p><p>Beginning in 2021, a year after Leo's donation provided 19% of FGA's funding for the year, the FGA began filing <a href="https://legaldictionary.net/amicus-brief/?ref=scottsantens.com" rel="noreferrer">amicus briefs</a> in Supreme Court cases. In Biden v. Nebraska, the FGA argued against debt forgiveness. In Consumer Financial Protection Bureau (CFPB) v. Community Financial Services Association of America, the FGA is trying to kill the CFPB for the payday loan industry (which <a href="https://www.scottsantens.com/payday-loan-lenders-are-unstoppable-except-with-the-help-of-universal-basic-income-ubi/" rel="noreferrer">UBI would destroy</a> by the way). And in Loper Bright Enterprises v. Raimondo, the FGA is trying to end the <a href="https://www.scotusblog.com/2024/01/supreme-court-to-hear-major-case-on-power-of-federal-agencies/?ref=scottsantens.com" rel="noreferrer">Chevron Doctrine</a>, which would greatly reduce the power of federal agencies.</p><p>The rest of FGA's donors have all contributed less than $1 million total. For those who would like to see them, you can find the rest of them on SourceWatch.</p><h3 id="who-will-win">Who Will Win?</h3><p>The aforementioned names are only a partial list, and include few actual names because of the nature of dark money, where those with great wealth can pass an unlimited amount of money through various vehicles that hide their identities. But the overall picture painted is a pretty clear one, where an entire ecosystem of nonprofits has been built and is being run for one primary purpose - <strong>to protect the vast wealth of the wealthy from higher taxes</strong>. It is this singular reason that I believe a handful of wealthy donors are supporting the efforts of the FGA to fight against UBI. It's not really about conservative or libertarian against liberal or progressive. If it were, at least some of the above organizations would be interested in basic income as Friedman and Hayek were.</p><p>A UBI would decrease the disincentive to work by reducing marginal tax rates at the low end of the labor market. It would make taking a job actually pay. It would shrink the size of government by replacing government bureaucrats with cash payments directly to citizens to make their own choices. It would greatly boost entrepreneurship and fuel small businesses across the country, restoring Main Street USA in a way nothing else ever could. It could also potentially be an alternative to minimum wage increases by increasing worker bargaining power. All of this should be very appealing to principled conservatives and libertarians seeking market solutions and greater freedom of choice. UBI would even be a tax cut for the bottom 60% to 90% of the country depending on design details. But what UBI will never be is a tax cut for the top 10%, and especially the top 1%.</p><p>There is no politically realistic UBI that would ever cut taxes on billionaires, and that's what's fueling the Foundation for Government Accountability - the fear of a world where things are a bit less unequal, and the bottom half of the country has a bit more power to refuse the domination of others, particularly those with wealth who have grown used to so many people having <a href="https://widerquist.com/mandatory-participation-on-trial-part-1/?ref=scottsantens.com" rel="noreferrer">no power to say anything but yes</a>.</p><p>It's impossible to know if the donor class is thinking this far ahead, but one of the reasons I personally consider UBI so important, is that it also means a greater ability for more working class people to donate. Instead of getting money out of politics, which is never going to happen without a successful constitutional amendment and therefore virtually impossible, <strong>UBI would help even the political donor playing field</strong>. One person donating $10 million dollars could be balanced by a million people donating $10 each. Combined with a national program that <a href="http://nyccfb.info/program/how-it-works/?ref=scottsantens.com" rel="noreferrer">matched small donations</a> with public funding, a billionaire spending $5 billion to get their way could face 100 million people spending $10 each, which becomes $100 after matching, which becomes $10 billion, finally drowning out the power of the billionaire.</p><p>The Catch-22 is how difficult UBI will be to win without UBI, but once UBI is won, so many more things will become possible once the politically motivated billionaires are taxed more, and the power of their dollars is greatly eroded by UBI dollars going to causes, campaigns, and candidates that the People truly support.</p><p>That's the world the FGA and its donors fear. They fear a loss of power, and so they fear the successful results of basic income pilots. They don't want everyone to know how well basic income works. They don't want people to want UBI. <strong>A world full of people empowered by unconditional basic income scares them.</strong></p><p>As for me, I'll see you in that world, because I'm never stopping until we're all in it. Always remember, what comes after "then they fight you" is "then you win."</p><hr><p><em>If you're looking to support a 501(c)(3) that's pretty much the exact opposite of the FGA, consider the </em><a href="https://www.scottsantens.com/introducing-the-income-to-support-all-foundation-itsa-ubi/" rel="noreferrer"><em>Income To Support All Foundation</em></a><em> whose goal is UBI.</em></p><hr><p><em>Want more content like this? Please share it and&nbsp;</em><a href="https://www.scottsantens.com/#/portal/signup"><em>click the subscribe button</em></a><em>. Also&nbsp;<strong>consider making a monthly pledge</strong>&nbsp;in support of all my work.</em></p><p><em><strong>Special thanks to my monthly supporters on Patreon</strong>: Gisele Huff, Haroon Mokhtarzada, Steven Grimm, Judith Bliss, Lowell Aronoff, Katie Moussouris, David Ruark, Tricia Garrett, Zack Sargent, Daryl Smith, Larry Cohen, Fabian Kehrer, Philip Rosedale, Liya Brook, Frederick Weber, John Steinberger, Bridget I Flynn, Laurel gillespie, Dylan J Hirsch-Shell, Tom Cooper, Robert Collins, Joanna Zarach, ace bailey, Daragh Ward, Andrew Yang, Peter T Knight, Michael Finney, David Ihnen, Elizabeth Corker, Gerald Huff, Albert Daniel Brockman, Natalie Foster, Joe Ballou, Arjun , Mark Donovan, Capitalists for Shared Income, Jason Clark, Chuck Cordes, Thomas Fitzsimmons, Mark Broadgate, Leslie Kausch, Jessica Chew, Braden Ferrin , Juro Antal, Austin Begin, Deanna McHugh, Nikolaus Rath, chris heinz, Pavel S, Zachary Weaver, Justin Seifert, Jodi Sarda, Rosa Tran, Ryan Ash-Miller, miki, bradzone, Lee Lor, John Sullivan, Team TJ, Yang Deng, Yan Xie, Marie janicke, engageSimply - Judy Shapiro, Tim , Warren J Polk, Jeffrey Emmett, Stephen Castro-Starkey, Kev Roberts, Walter Schaerer, Loren Sickles, Eric Skiff, Thomas Welsh, Kai Wong, and Laura Ashby.</em></p><p><a href="https://www.patreon.com/scottsantens?ref=scottsantens.com" rel="noreferrer"><strong><em>Become a monthly patron to see your name here too</em></strong></a><strong><em>!</em></strong></p>
      </section>


        
          <section>
    <p><a href="https://www.scottsantens.com/author/scott/">
        <img data-src="/content/images/size/w320/2022/02/HS-late-2021-1.jpg" alt="Scott Santens" width="80" height="80" src="https://www.scottsantens.com/content/images/size/w320/2022/02/HS-late-2021-1.jpg">
      </a>
    </p>

  <div>
    

      <p>Unconditional/Universal Basic Income (UBI) advocate with a crowdfunded basic income; Founder and President of ITSA Foundation, Author of Let There Be Money; Editor of BasicIncomeToday.com</p>
  </div>
</section>
        
        <div>
                <h2>UBI Guide Newsletter</h2>
                <p>Join the newsletter to receive the latest updates in your inbox.</p>
                
<form data-members-form="signup">
  <p><label for="subscribe-box-email">Your email address</label>
    
    
  </p>

  <p>Please check your inbox and click the link to confirm your subscription.</p>
  <p>Please enter a valid email address!</p>
  <p>An error occurred, please try again later.</p>
</form>              </div>

        
    </article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shave and a Haircut (173 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Shave_and_a_Haircut</link>
            <guid>39548517</guid>
            <pubDate>Thu, 29 Feb 2024 12:31:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Shave_and_a_Haircut">https://en.wikipedia.org/wiki/Shave_and_a_Haircut</a>, See on <a href="https://news.ycombinator.com/item?id=39548517">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<div><figure typeof="mw:File"><span><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Gnome-mime-sound-openclipart.svg/50px-Gnome-mime-sound-openclipart.svg.png" decoding="async" width="50" height="50" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Gnome-mime-sound-openclipart.svg/75px-Gnome-mime-sound-openclipart.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Gnome-mime-sound-openclipart.svg/100px-Gnome-mime-sound-openclipart.svg.png 2x" data-file-width="160" data-file-height="160"></span><figcaption></figcaption></figure></div>
<p>"<b>Shave and a Haircut</b>" and the associated response "<b>two bits</b>" is a seven-note musical <a href="https://en.wikipedia.org/wiki/Call_and_response_(music)" title="Call and response (music)">call-and-response</a> <a href="https://en.wikipedia.org/wiki/Couplet" title="Couplet">couplet</a>, <a href="https://en.wikipedia.org/wiki/Riff" title="Riff">riff</a> or <a href="https://en.wikipedia.org/wiki/Fanfare" title="Fanfare">fanfare</a> popularly used at the end of a musical performance, usually for comedic effect. It is used melodically or rhythmically, for example as a <a href="https://en.wikipedia.org/wiki/Door_knocker" title="Door knocker">door knocker</a>.
</p><p>"<a href="https://en.wikipedia.org/wiki/Bit_(money)" title="Bit (money)">Two bits</a>" is a term in the United States and Canada for 25 <a href="https://en.wikipedia.org/wiki/Cent_(currency)" title="Cent (currency)">cents</a>, equivalent to a <a href="https://en.wikipedia.org/wiki/Quarter_(United_States_coin)" title="Quarter (United States coin)">U.S. quarter</a>. "Four bits" and "Six bits" are also occasionally used, for example in the cheer "Two bits, four bits, six bits, a dollar." The final words may also be "get lost", "drop dead" (in Australia),<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2019)">citation needed</span></a></i>]</sup> or some other facetious expression. In the UK, it was often said as "five bob" (slang for five <a href="https://en.wikipedia.org/wiki/Shilling" title="Shilling">shillings</a>), although words are now rarely used to accompany the rhythm or the tune.
</p>
<meta property="mw:PageProp/toc">
<h2><span id="History">History</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Shave_and_a_Haircut&amp;action=edit&amp;section=1" title="Edit section: History"><span>edit</span></a><span>]</span></span></h2>
<p>An early occurrence of the tune is from an 1899 Charles Hale <a href="https://en.wikipedia.org/wiki/Minstrel_show" title="Minstrel show">minstrel</a> song, <i>At a Darktown Cakewalk</i>.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> Other songs from the same period also used the tune. The same notes form the <a href="https://en.wikipedia.org/wiki/Bridge_(music)" title="Bridge (music)">bridge</a> in the <i>Hot Scotch Rag</i>, written by H. A. Fischler in 1911.
</p><p>An early recording used the 7-note tune at both the beginning and the ending of a humorous 1915 song, by <a href="https://en.wikipedia.org/wiki/Billy_Murray_(singer)" title="Billy Murray (singer)">Billy Murray</a> and the American Quartet, called "<a href="https://en.wikipedia.org/wiki/On_the_5:15" title="On the 5:15">On the 5:15</a>".
</p><p>In his 1933 novel, <i>Hizzoner the Mayor,</i> <a href="https://en.wikipedia.org/wiki/Joel_Sayre" title="Joel Sayre">Joel Sayre</a> wrote of boats "tooting the official Malta welcome blast to the tempo of “Shave-and-a-haircut-two-bits, shave-and-a-haircut-two-bits, shave-and-a-haircut-two-bits”, which was soon taken up by every craft in the harbor that had a boiler.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup>
</p><p>In 1939, Dan Shapiro, Lestor Lee and <a href="https://en.wikipedia.org/wiki/Milton_Berle" title="Milton Berle">Milton Berle</a> released "Shave and a Haircut – Shampoo",<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> which used the tune in the closing bars. In the same year, Rosalind Rosenthal and Herbert Halpert recorded "Shave and a Haircut, Bay Rum".<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>
</p>
<h2><span id="Popularity">Popularity</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Shave_and_a_Haircut&amp;action=edit&amp;section=2" title="Edit section: Popularity"><span>edit</span></a><span>]</span></span></h2>
<p>The tune can be heard on customized <a href="https://en.wikipedia.org/wiki/Car_horn" title="Car horn">car horns</a>,<sup id="cite_ref-Guide_5-0"><a href="#cite_note-Guide-5">[5]</a></sup><sup id="cite_ref-Ask_6-0"><a href="#cite_note-Ask-6">[6]</a></sup> while the rhythm may be tapped as a door knock<sup id="cite_ref-Hellholes_7-0"><a href="#cite_note-Hellholes-7">[7]</a></sup><sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup><sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup><sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup><sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup><sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup><sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup><sup id="cite_ref-Slang_14-0"><a href="#cite_note-Slang-14">[14]</a></sup> or as a <a href="https://en.wikipedia.org/wiki/Morse_code" title="Morse code">Morse code</a> "dah-di-di-dah-di, dah-dit" ( <b>–··–· &nbsp; –·</b> )<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> at the end of an <a href="https://en.wikipedia.org/wiki/Amateur_radio" title="Amateur radio">amateur radio</a> <a href="https://en.wikipedia.org/wiki/Contact_(amateur_radio)" title="Contact (amateur radio)">contact</a>.
</p><p>The former <a href="https://en.wikipedia.org/wiki/Prisoner_of_war" title="Prisoner of war">prisoner of war</a> and U.S. Navy seaman <a href="https://en.wikipedia.org/wiki/Doug_Hegdahl" title="Doug Hegdahl">Doug Hegdahl</a> reports fellow U.S. captives in the Vietnam War would authenticate a new prisoner's U.S. identity by using "Shave and a Haircut" as a <a href="https://en.wikipedia.org/wiki/Shibboleth" title="Shibboleth">shibboleth</a>, tapping the first five notes against a cell wall and waiting for the appropriate response. U.S. POWs were then able to communicate securely with one another via a <a href="https://en.wikipedia.org/wiki/Tap_code" title="Tap code">tap code</a>.<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup>
</p><p>The tune has been used innumerable times as a <a href="https://en.wikipedia.org/wiki/Coda_(music)" title="Coda (music)">coda</a> or <a href="https://en.wikipedia.org/wiki/Cadence_(music)" title="Cadence (music)">ending</a> in musical pieces. It is strongly associated with the stringed instruments of <a href="https://en.wikipedia.org/wiki/Bluegrass_music" title="Bluegrass music">bluegrass music</a>, particularly the 5-string <a href="https://en.wikipedia.org/wiki/Banjo" title="Banjo">banjo</a>. <a href="https://en.wikipedia.org/wiki/Earl_Scruggs" title="Earl Scruggs">Earl Scruggs</a> often ended a song with this <a href="https://en.wikipedia.org/wiki/Phrase_(music)" title="Phrase (music)">phrase</a> or a variation of it. On the television show <i><a href="https://en.wikipedia.org/wiki/The_Beverly_Hillbillies" title="The Beverly Hillbillies">The Beverly Hillbillies</a></i>, musical cues signifying the coming of a commercial break (cues which were in <a href="https://en.wikipedia.org/wiki/Bluegrass_music" title="Bluegrass music">bluegrass</a> style) frequently ended with "Shave and a Haircut". It is the most popular bluegrass <a href="https://en.wikipedia.org/wiki/Run_(music)" title="Run (music)">run</a>, after the <a href="https://en.wikipedia.org/wiki/G_run" title="G run">G run</a>.<sup id="cite_ref-Traum_17-0"><a href="#cite_note-Traum-17">[17]</a></sup>
</p><p>"Shave and a Haircut" was used in many early <a href="https://en.wikipedia.org/wiki/Cartoon" title="Cartoon">cartoons</a>, particularly <i><a href="https://en.wikipedia.org/wiki/Looney_Tunes" title="Looney Tunes">Looney Tunes</a></i> cartoons. It was also used as an ending to many cartoon shows, just after the credits. Decades later, the couplet became a plot device to lure-out an intended victim, as used by <a href="https://en.wikipedia.org/wiki/Judge_Doom" title="Judge Doom">Judge Doom</a> in the film <i><a href="https://en.wikipedia.org/wiki/Who_Framed_Roger_Rabbit" title="Who Framed Roger Rabbit">Who Framed Roger Rabbit</a></i>, the idea being that <a href="https://en.wikipedia.org/wiki/Animated_cartoon" title="Animated cartoon">toons</a> cannot resist finishing with the "two bits" when they hear the opening rhythm.<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> The tune was also featured in early <a href="https://en.wikipedia.org/wiki/Nokia" title="Nokia">Nokia</a> phones, like the <a href="https://en.wikipedia.org/wiki/Nokia_3310" title="Nokia 3310">3310 model</a>, as the <i>That's it!</i> ringtone.<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup><sup id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup>
</p>
<h2><span id="Usage">Usage</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Shave_and_a_Haircut&amp;action=edit&amp;section=3" title="Edit section: Usage"><span>edit</span></a><span>]</span></span></h2>
<p>The phrase has been incorporated into countless recordings and performances. Notable examples include:
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Johnny%27s_Theme" title="Johnny's Theme">Johnny's Theme</a>, the music that opened <i><a href="https://en.wikipedia.org/wiki/The_Tonight_Show_Starring_Johnny_Carson" title="The Tonight Show Starring Johnny Carson">The Tonight Show Starring Johnny Carson</a>,</i> famously ended with the "shave and a haircut" flourish every weeknight for 30 years and 4,531 episodes.</li>
<li>"That's a Lot of Bunk", a 1920s novelty song composed by Al Wilson, James A. Brennan and Mack Henshaw, and performed by <a href="https://en.wikipedia.org/wiki/Billy_Jones_(singer,_born_1889)" title="Billy Jones (singer, born 1889)">Billy Jones</a> and <a href="https://en.wikipedia.org/wiki/Ernie_Hare" title="Ernie Hare">Ernest Hare</a>, known as "The Happiness Boys", closes with the riff.<sup id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup></li>
<li>The <a href="https://en.wikipedia.org/wiki/Crazy_Gang_(comedy_group)" title="Crazy Gang (comedy group)">Crazy Gang</a> sang "How's your father? Goodbye!" to the same tune at the end of their 1937 movie <i><a href="https://en.wikipedia.org/wiki/O-Kay_for_Sound" title="O-Kay for Sound">O-Kay for Sound</a></i>.<sup id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/R%26B" title="R&amp;B">R&amp;B</a> singer and bandleader <a href="https://en.wikipedia.org/wiki/Dave_Bartholomew" title="Dave Bartholomew">Dave Bartholomew</a> used the phrase on two of his recordings: "Country Boy" (1950) at the very end, and the original version of "<a href="https://en.wikipedia.org/wiki/My_Ding-a-Ling" title="My Ding-a-Ling">My Ding-a-Ling</a>" (1952) as a figure introducing each verse.<sup id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Les_Paul" title="Les Paul">Les Paul</a> and <a href="https://en.wikipedia.org/wiki/Mary_Ford" title="Mary Ford">Mary Ford</a>'s <a href="https://en.wikipedia.org/wiki/Capitol_Records" title="Capitol Records">Capitol</a> recording of "Magic Melody" concluded with the phrase minus the last two notes ("two bits"). Responding to complaints from <a href="https://en.wikipedia.org/wiki/Disc_jockey" title="Disc jockey">disc jockeys</a>, Capitol in 1955 released "Magic Melody Part 2"—consisting solely of the missing notes—on a 45, said to be the shortest tune on record.<sup id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/P._D._Q._Bach" title="P. D. Q. Bach">P. D. Q. Bach</a> ends his "<a href="https://en.wikipedia.org/wiki/Black_Forest_Bluegrass" title="Black Forest Bluegrass">Blaues Gras</a>" ("bluegrass") <a href="https://en.wikipedia.org/wiki/Aria" title="Aria">aria</a> with "Shave and a Haircut", sung in <a href="https://en.wikipedia.org/wiki/Denglisch" title="Denglisch">Denglisch</a> (mangled German and English): "Rasieren und Haarschneiden, zwei bitte" ("Shave and haircut, two please", ungrammatical in either language). "Zwei bitte" is a Denglisch pun, sounding like "two bits" to a speaker of both languages.<sup id="cite_ref-PDQ_Bach_25-0"><a href="#cite_note-PDQ_Bach-25">[25]</a></sup> The melody is also used in <i><a href="https://en.wikipedia.org/wiki/The_Short-Tempered_Clavier_and_other_dysfunctional_works_for_keyboard" title="The Short-Tempered Clavier and other dysfunctional works for keyboard">The Short-Tempered Clavier</a></i>.<sup id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup></li>
<li>The original version of "<a href="https://en.wikipedia.org/wiki/Love_and_Marriage" title="Love and Marriage">Love and Marriage</a>" by <a href="https://en.wikipedia.org/wiki/Frank_Sinatra" title="Frank Sinatra">Frank Sinatra</a> (recorded for <a href="https://en.wikipedia.org/wiki/Capitol_Records" title="Capitol Records">Capitol Records</a> in 1955) ends with the tune.</li>
<li>"<a href="https://en.wikipedia.org/wiki/Unsquare_Dance" title="Unsquare Dance">Unsquare Dance</a>" (1961) by <a href="https://en.wikipedia.org/wiki/Dave_Brubeck" title="Dave Brubeck">Dave Brubeck</a> ends with the tune, and also features part of "<a href="https://en.wikipedia.org/wiki/Turkey_in_the_Straw" title="Turkey in the Straw">Turkey in the Straw</a>".</li>
<li>One of the musical numbers in <i><a href="https://en.wikipedia.org/wiki/Mister_Magoo%27s_Christmas_Carol" title="Mister Magoo's Christmas Carol">Mister Magoo's Christmas Carol</a></i> (1962), "We're Despicable (The Plunderers' March)," incorporates the melody into its chorus.  The characters sing, "we're blank-blankety-blank-blank no good."</li>
<li>Every interview by <a href="https://en.wikipedia.org/wiki/Nardwuar_the_Human_Serviette" title="Nardwuar the Human Serviette">Nardwuar the Human Serviette</a> ends with the melody of the song, with Nardwuar singing "doot doot da loot doo", after which the interviewee is expected to reply with "doot doo".</li>
<li>The ending theme in the credits of <i><a href="https://en.wikipedia.org/wiki/Barney_%26_Friends" title="Barney &amp; Friends">Barney the Dinosaur</a></i> makes use of it from Seasons 1-3.</li>
<li>In a 1960s television comedy sketch called "The Time Window", <a href="https://en.wikipedia.org/wiki/Mike_Wallace" title="Mike Wallace">Mike Wallace</a> interviews <a href="https://en.wikipedia.org/wiki/Victor_Borge" title="Victor Borge">Victor Borge</a> who is portraying composer and pianist <a href="https://en.wikipedia.org/wiki/Franz_Liszt" title="Franz Liszt">Franz Liszt</a>. During the segment, Borge (Liszt) states that his very first composition were two notes; which he plays on the piano. He next demonstrates that without these two notes "we would never have had this", and he plays "Shave and a Haircut".<sup id="cite_ref-27"><a href="#cite_note-27">[27]</a></sup><sup id="cite_ref-28"><a href="#cite_note-28">[28]</a></sup></li>
<li>The animated show <i><a href="https://en.wikipedia.org/wiki/Animaniacs" title="Animaniacs">Animaniacs</a></i> makes frequent use of this theme, in particular at the end of the song "Wakko's America" with the line "That's all the capitals there are".</li>
<li>The song "Gee, Officer Krupke" from <a href="https://en.wikipedia.org/wiki/Leonard_Bernstein" title="Leonard Bernstein">Leonard Bernstein</a>'s musical <i><a href="https://en.wikipedia.org/wiki/West_Side_Story" title="West Side Story">West Side Story</a></i> ends with the tune.</li>
<li>The tune is sampled in several of <a href="https://en.wikipedia.org/wiki/%22Weird_Al%22_Yankovic" title="&quot;Weird Al&quot; Yankovic">"Weird Al" Yankovic</a>'s <a href="https://en.wikipedia.org/wiki/List_of_%22Weird_Al%22_Yankovic_polka_medleys" title="List of &quot;Weird Al&quot; Yankovic polka medleys">polka medleys</a>.</li>
<li>"<a href="https://en.wikipedia.org/wiki/Everything_About_You_(Ugly_Kid_Joe_song)" title="Everything About You (Ugly Kid Joe song)">Everything About You</a>", by <a href="https://en.wikipedia.org/wiki/Ugly_Kid_Joe" title="Ugly Kid Joe">Ugly Kid Joe</a> (recorded for <a href="https://en.wikipedia.org/wiki/Mercury_Records" title="Mercury Records">Mercury Records</a> in 1992), ends with the tune.</li>
<li>The song "Mi Abuela" by Wilfred y La Ganga (BMG Ariola, 1990) opens with the tune as a door knock.</li>
<li>The tune is played as part of the guitar solo in the song "<a href="https://en.wikipedia.org/wiki/Play_with_Me_(song)" title="Play with Me (song)">Play with Me</a>" by <a href="https://en.wikipedia.org/wiki/Extreme_(band)" title="Extreme (band)">Extreme</a>, which is also used in the mall chase scene in <i><a href="https://en.wikipedia.org/wiki/Bill_%26_Ted%27s_Excellent_Adventure" title="Bill &amp; Ted's Excellent Adventure">Bill &amp; Ted's Excellent Adventure</a></i>.</li>
<li><a href="https://en.wikipedia.org/wiki/Cassian_Andor" title="Cassian Andor">Cassian Andor</a> taps the five-note rhythm to signal Bix Caleen, outside her window, in S1:E7 "The Announcement" of the series <a href="https://en.wikipedia.org/wiki/Andor_(TV_series)" title="Andor (TV series)"><i>Star Wars: Andor</i></a>. There is no two-note response.</li></ul>
<h2><span id="Uses_in_other_countries">Uses in other countries</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Shave_and_a_Haircut&amp;action=edit&amp;section=4" title="Edit section: Uses in other countries"><span>edit</span></a><span>]</span></span></h2>
<div>
<div><figure typeof="mw:File"><span><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Gnome-mime-sound-openclipart.svg/50px-Gnome-mime-sound-openclipart.svg.png" decoding="async" width="50" height="50" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Gnome-mime-sound-openclipart.svg/75px-Gnome-mime-sound-openclipart.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Gnome-mime-sound-openclipart.svg/100px-Gnome-mime-sound-openclipart.svg.png 2x" data-file-width="160" data-file-height="160"></span><figcaption></figcaption></figure></div>
<div>


<p>An example of the couplet.</p></div></div>
<p>The <a href="https://en.wikipedia.org/wiki/Italy" title="Italy">Italian</a> version is <i>Ammazza la vecchia … col Flit!</i> (<i>English</i>: "Kill the old lady … with Flit!")—<i><a href="https://en.wikipedia.org/wiki/FLIT" title="FLIT">Flit</a></i> being an old brand of <a href="https://en.wikipedia.org/wiki/DDT" title="DDT">DDT</a> insecticide. This is a humorous popular version of a post-<a href="https://en.wikipedia.org/wiki/World_War_II" title="World War II">World War II</a> commercial <i>Ammazza la mosca... col Flit</i> (<i>English</i>: "Kill the fly with Flit!").<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2013)">citation needed</span></a></i>]</sup>
</p><p>The tune is used in <a href="https://en.wikipedia.org/wiki/Catalan_language" title="Catalan language">Catalan</a> with a different lyric: "Nas de barraca … <a href="https://en.wikipedia.org/wiki/Sant_Boi_de_Llobregat" title="Sant Boi de Llobregat">Sant Boi</a>" (<i>English</i>: "Shack nose … Sant Boi"). It is also tapped, as a door knock. The Catalan lyrics may come from <a href="https://en.wikipedia.org/wiki/Blanes" title="Blanes">Blanes</a>, where it was sung twice with <i>Nas de barraca. Sant Boi. Cinc de carmelos pel noi</i> (<i>English</i>: Shack nose. Sant Boi. Five candies for the boy).<sup id="cite_ref-29"><a href="#cite_note-29">[29]</a></sup>
</p><p>In Spain, it is sung with the lyrics, <i>Una copita … de Ojén</i> (<i>English</i>: "A shot … of schnapps").
</p><p>In Mexico, it means a vulgar insult with the lyrics, <i>Chinga tu madre … cabrón</i> (English: "Fuck your mother … bastard").
</p><p>In <a href="https://en.wikipedia.org/wiki/Irish_pub" title="Irish pub">Irish barroom</a> music, the tune is sometimes tagged at the end of a song. The performer sings the first part to the lyrics, "How is your aul' one?" (read: "old one", a slang term for mother), to which the audience replies, "Gameball!" (A slang term meaning A-OK).<sup id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup>
</p><p>In Sweden, it is well known as <i>Kvart över elva … halv tolv</i>, which means <i>A quarter past eleven … half past eleven</i>. The twist doesn't work as well in English, as the English time system treats 11:30 as a continuation of eleven instead of as the first half of twelve. <i>Halv tolv</i> thus means <i>half twelve</i> and is the correct Swedish equivalent of half past eleven. In Sweden, the melody was also used in a commercial for the <a href="https://en.wikipedia.org/wiki/Lakrisal" title="Lakrisal">Bronzol</a> brand of candy with the slogan <i>Hälsan för halsen — Bronzol</i> (<i>English</i>: Health for the throat — Bronzol).
</p><p>In Icelandic, the lyrics are <i>Saltkjöt og baunir … túkall</i> (<i>English</i>: "Salt meat and split peas … two krona" (króna is the currency in Iceland)).
</p><p>In the Netherlands, the phrase is used when someone leaves with the intention to not return. <i>Die zien we nooit meer, te-rug</i> (<i>English</i>: We shall never see them, a-gain). It is used as a way to make fun of someone/something, if it suddenly disappears from the scene.
</p><p>In Argentina, <a href="https://en.wikipedia.org/wiki/Carlos_Bal%C3%A1" title="Carlos Balá">Carlos Balá</a>, a former children's TV show host, used to include a bit in his routine in which he would whistle the "shave and a haircut" part of the tune, prompting the children in the audience to answer "Ba-lá" to the rhythm of the two final notes.
In the same country in school context to call for silence being sung with the teacher saying the phrase Tapa Tapita (Bottlecap, Small cap) and the students answering Tapon (Plug), followed with the teacher singing the phrase cierro la boca (shutting my mouth) and answering ya está (already done)
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Shave_and_a_Haircut&amp;action=edit&amp;section=5" title="Edit section: See also"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Banjo_roll" title="Banjo roll">Banjo roll</a></li>
<li><a href="https://en.wikipedia.org/wiki/Oriental_riff" title="Oriental riff">Oriental riff</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bo_Diddley_beat" title="Bo Diddley beat">Bo Diddley beat</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Shave_and_a_Haircut&amp;action=edit&amp;section=6" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite id="CITEREFFuld2000">Fuld, James (2000). <i>The Book of World-Famous Music: Classical, Popular, and Folk</i> (5th&nbsp;ed.). New York: Dover Publications. p.&nbsp;495.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Book+of+World-Famous+Music%3A+Classical%2C+Popular%2C+and+Folk&amp;rft.place=New+York&amp;rft.pages=495&amp;rft.edition=5th&amp;rft.pub=Dover+Publications&amp;rft.date=2000&amp;rft.aulast=Fuld&amp;rft.aufirst=James&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite id="CITEREFSayre1933">Sayre, Joel (1933). <a rel="nofollow" href="https://books.google.com/books?id=m9QIAQAAIAAJ&amp;q=%22shave+and+a+haircut%22"><i>Hizzoner the Mayor: A Novel</i></a>. New York: John Day Company. pp.&nbsp;28–29.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Hizzoner+the+Mayor%3A+A+Novel&amp;rft.place=New+York&amp;rft.pages=28-29&amp;rft.pub=John+Day+Company&amp;rft.date=1933&amp;rft.aulast=Sayre&amp;rft.aufirst=Joel&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Dm9QIAQAAIAAJ%26q%3D%2522shave%2Band%2Ba%2Bhaircut%2522&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span>"<a rel="nofollow" href="http://members.multimania.nl/catchytune/samples.html">Catchy Tune Central</a> <a rel="nofollow" href="https://web.archive.org/web/20100612111115/http://members.multimania.nl/catchytune/samples.html">Archived</a> 2010-06-12 at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>", <i>Members.MultiMania.NL</i>.</span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite id="CITEREFSafire1983">Safire, William (April 3, 1983). <a rel="nofollow" href="https://www.nytimes.com/1983/04/03/magazine/on-language-pray-why-me.html">"ON LANGUAGE; PRAY, WHY ME?"</a>. <i><a href="https://en.wikipedia.org/wiki/The_New_York_Times" title="The New York Times">The New York Times</a></i><span>. Retrieved <span>May 21,</span> 2019</span>. <q>The Book of World-Famous Music," a 1966 work by James J. Fuld, which reveals a 1939 ditty, "Shave and a Haircut - Shampoo," by Dan Shapiro, Lester Lee and Milton Berle, and a similar number in the same year, "Shave and a Haircut, Bay Rum," recorded as a folk melody by Rosalind Rosenthal and Herbert Halpert.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=ON+LANGUAGE%3B+PRAY%2C+WHY+ME%3F&amp;rft.date=1983-04-03&amp;rft.aulast=Safire&amp;rft.aufirst=William&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F1983%2F04%2F03%2Fmagazine%2Fon-language-pray-why-me.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-Guide-5"><span><b><a href="#cite_ref-Guide_5-0">^</a></b></span> <span><cite id="CITEREFFranzHavens2006">Franz, Carl; Havens, Lorena (2006). <i>The People's Guide to Mexico</i>. Avalon Travel Publishing. p.&nbsp;319. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/1-56691-711-5" title="Special:BookSources/1-56691-711-5"><bdi>1-56691-711-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+People%27s+Guide+to+Mexico&amp;rft.pages=319&amp;rft.pub=Avalon+Travel+Publishing&amp;rft.date=2006&amp;rft.isbn=1-56691-711-5&amp;rft.aulast=Franz&amp;rft.aufirst=Carl&amp;rft.au=Havens%2C+Lorena&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-Ask-6"><span><b><a href="#cite_ref-Ask_6-0">^</a></b></span> <span><cite id="CITEREFArellano2008"><a href="https://en.wikipedia.org/wiki/Gustavo_Arellano" title="Gustavo Arellano">Arellano, Gustavo</a> (2008). <a rel="nofollow" href="https://archive.org/details/isbn_9781416540021/page/26"><i>Ask a Mexican</i></a>. <a href="https://en.wikipedia.org/wiki/Charles_Scribner%27s_Sons" title="Charles Scribner's Sons">Scribner</a>. p.&nbsp;<a rel="nofollow" href="https://archive.org/details/isbn_9781416540021/page/26">26</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-4165-4003-8" title="Special:BookSources/978-1-4165-4003-8"><bdi>978-1-4165-4003-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Ask+a+Mexican&amp;rft.pages=26&amp;rft.pub=Scribner&amp;rft.date=2008&amp;rft.isbn=978-1-4165-4003-8&amp;rft.aulast=Arellano&amp;rft.aufirst=Gustavo&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fisbn_9781416540021%2Fpage%2F26&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-Hellholes-7"><span><b><a href="#cite_ref-Hellholes_7-0">^</a></b></span> <span><cite id="CITEREFThompson2009">Thompson, Chuck (2009). <a rel="nofollow" href="https://archive.org/details/tohellholesbackb00thom/page/220"><i>To Hellholes and Back: Bribes, Lies, and the Art of Extreme Tourism</i></a>. Holt Paperbacks. p.&nbsp;<a rel="nofollow" href="https://archive.org/details/tohellholesbackb00thom/page/220">220</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-8050-8788-8" title="Special:BookSources/978-0-8050-8788-8"><bdi>978-0-8050-8788-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=To+Hellholes+and+Back%3A+Bribes%2C+Lies%2C+and+the+Art+of+Extreme+Tourism&amp;rft.pages=220&amp;rft.pub=Holt+Paperbacks&amp;rft.date=2009&amp;rft.isbn=978-0-8050-8788-8&amp;rft.aulast=Thompson&amp;rft.aufirst=Chuck&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Ftohellholesbackb00thom%2Fpage%2F220&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite id="CITEREFStanton1948">Stanton, John (September 20, 1948). "In Mexico City Traffic is Terrific". <i><a href="https://en.wikipedia.org/wiki/Life_(magazine)" title="Life (magazine)">LIFE</a></i>. Time, Inc.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=LIFE&amp;rft.atitle=In+Mexico+City+Traffic+is+Terrific&amp;rft.date=1948-09-20&amp;rft.aulast=Stanton&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFKeenan2004">Keenan, Joseph John (2004). <span title="Free registration required"><a rel="nofollow" href="https://archive.org/details/breakingoutofbeg0000keen"><i>Breaking Out of Beginner's Spanish</i></a></span>. University of Texas Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-292-74322-X" title="Special:BookSources/0-292-74322-X"><bdi>0-292-74322-X</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Breaking+Out+of+Beginner%27s+Spanish&amp;rft.pub=University+of+Texas+Press&amp;rft.date=2004&amp;rft.isbn=0-292-74322-X&amp;rft.aulast=Keenan&amp;rft.aufirst=Joseph+John&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fbreakingoutofbeg0000keen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite id="CITEREFAxtellFornwald1998">Axtell, Roger E.; Fornwald, Mike (1998). <a rel="nofollow" href="https://archive.org/details/gesturesdostaboo00axte/page/101"><i>Gestures: The Do's and Taboos of Body Language Around the World</i></a>. Wiley. p.&nbsp;<a rel="nofollow" href="https://archive.org/details/gesturesdostaboo00axte/page/101">101</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-471-18342-3" title="Special:BookSources/0-471-18342-3"><bdi>0-471-18342-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Gestures%3A+The+Do%27s+and+Taboos+of+Body+Language+Around+the+World&amp;rft.pages=101&amp;rft.pub=Wiley&amp;rft.date=1998&amp;rft.isbn=0-471-18342-3&amp;rft.aulast=Axtell&amp;rft.aufirst=Roger+E.&amp;rft.au=Fornwald%2C+Mike&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fgesturesdostaboo00axte%2Fpage%2F101&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFAxtell1998">Axtell, Roger E. (1998). <a rel="nofollow" href="https://archive.org/details/dostaboosofhumor00axte"><i>Do's and Taboos of Humor Around the World</i></a>. Wiley. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-471-25403-7" title="Special:BookSources/0-471-25403-7"><bdi>0-471-25403-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Do%27s+and+Taboos+of+Humor+Around+the+World&amp;rft.pub=Wiley&amp;rft.date=1998&amp;rft.isbn=0-471-25403-7&amp;rft.aulast=Axtell&amp;rft.aufirst=Roger+E.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fdostaboosofhumor00axte&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFRuiz_FornellsRuiz-Fornells1979">Ruiz Fornells, Enrique; Ruiz-Fornells, Cynthia Y. (1979). <i>The United States and the Spanish World</i>. Sociedad General Española de Librería. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/84-7143-192-0" title="Special:BookSources/84-7143-192-0"><bdi>84-7143-192-0</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+United+States+and+the+Spanish+World&amp;rft.pub=Sociedad+General+Espa%C3%B1ola+de+Librer%C3%ADa&amp;rft.date=1979&amp;rft.isbn=84-7143-192-0&amp;rft.aulast=Ruiz+Fornells&amp;rft.aufirst=Enrique&amp;rft.au=Ruiz-Fornells%2C+Cynthia+Y.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite id="CITEREFWilderSherrier1992">Wilder, Cora Sarjeant; Sherrier, James (1992). <i>Celebrating Diversity</i>. Ginn Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-536-58133-9" title="Special:BookSources/0-536-58133-9"><bdi>0-536-58133-9</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Celebrating+Diversity&amp;rft.pub=Ginn+Press&amp;rft.date=1992&amp;rft.isbn=0-536-58133-9&amp;rft.aulast=Wilder&amp;rft.aufirst=Cora+Sarjeant&amp;rft.au=Sherrier%2C+James&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-Slang-14"><span><b><a href="#cite_ref-Slang_14-0">^</a></b></span> <span>Partridge, Eric; Dalzell, Tom; and Victor, Terry (2007). <i>The concise new Partridge dictionary of slang and unconventional English</i>, p.571. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-415-21259-5" title="Special:BookSources/978-0-415-21259-5">978-0-415-21259-5</a>.</span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite id="CITEREFKing1999">King, Thomas W. (1999). <i>Modern Morse Code in Rehabilitation and Education</i>. Allyn &amp; Bacon. p.&nbsp;77. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-205-28751-4" title="Special:BookSources/0-205-28751-4"><bdi>0-205-28751-4</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Modern+Morse+Code+in+Rehabilitation+and+Education&amp;rft.pages=77&amp;rft.pub=Allyn+%26+Bacon&amp;rft.date=1999&amp;rft.isbn=0-205-28751-4&amp;rft.aulast=King&amp;rft.aufirst=Thomas+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite id="CITEREFBrace,_Ernest_C.2008">Brace, Ernest C. (May 2, 2008). <a rel="nofollow" href="https://web.archive.org/web/20081201165511/http://www.johnmccain.com//Informing/News/NewsReleases/3168f3a2-e59b-433f-94ea-fb1641323507.htm">"Messages From John"</a>. <i>JohnMcCain.com</i>. Archived from <a rel="nofollow" href="http://www.johnmccain.com//Informing/News/NewsReleases/3168f3a2-e59b-433f-94ea-fb1641323507.htm">the original</a> on December 1, 2008<span>. Retrieved <span>2008-11-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=JohnMcCain.com&amp;rft.atitle=Messages+From+John&amp;rft.date=2008-05-02&amp;rft.au=Brace%2C+Ernest+C.&amp;rft_id=http%3A%2F%2Fwww.johnmccain.com%2F%2FInforming%2FNews%2FNewsReleases%2F3168f3a2-e59b-433f-94ea-fb1641323507.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-Traum-17"><span><b><a href="#cite_ref-Traum_17-0">^</a></b></span> <span>Traum, Happy (1974). <i>Bluegrass Guitar</i>, p.26. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-8256-0153-3" title="Special:BookSources/0-8256-0153-3">0-8256-0153-3</a>.</span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.imdb.com/title/tt0096438/quotes?qt=qt0406091">"Quotes from "Who Framed Roger Rabbit"<span></span>"</a>. <i><a href="https://en.wikipedia.org/wiki/IMDb" title="IMDb">IMDb</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=IMDb&amp;rft.atitle=Quotes+from+%22Who+Framed+Roger+Rabbit%22&amp;rft_id=https%3A%2F%2Fwww.imdb.com%2Ftitle%2Ftt0096438%2Fquotes%3Fqt%3Dqt0406091&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=w2KF6QyUgwA">"NOKIA 3310 ringtone That's it!"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=NOKIA+3310+ringtone+That%27s+it%21&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dw2KF6QyUgwA&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-20"><span><b><a href="#cite_ref-20">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=JgqP97caQsA">"Shave and a Haircut (Nokia "That's it!" ringtone) - Piano Quickie"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=Shave+and+a+Haircut+%28Nokia+%22That%27s+it%21%22+ringtone%29+-+Piano+Quickie&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DJgqP97caQsA&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-21"><span><b><a href="#cite_ref-21">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=4W3cPSntmBk">"<span></span>"That's A Lot Of Bunk" - Billy Jones &amp; Ernest Hare (1923 Edison)"</a>. <i>YouTube</i>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/4W3cPSntmBk">Archived</a> from the original on 2021-12-21<span>. Retrieved <span>4 July</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=%22That%27s+A+Lot+Of+Bunk%22+-+Billy+Jones+%26+Ernest+Hare+%281923+Edison%29&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4W3cPSntmBk&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-22"><span><b><a href="#cite_ref-22">^</a></b></span> <span><i>O-Kay for Sound</i>, <a rel="nofollow" href="https://archive.org/details/O-kayForSound">https://archive.org/details/O-kayForSound</a>. Retrieved 2019-02-02.</span>
</li>
<li id="cite_note-23"><span><b><a href="#cite_ref-23">^</a></b></span> <span>Bartholomew, Dave, "The King Sides" Collectables (CD) 2883, 2004</span>
</li>
<li id="cite_note-24"><span><b><a href="#cite_ref-24">^</a></b></span> <span><cite id="CITEREFCleveland,_Barry2002">Cleveland, Barry (September 1, 2002). <a rel="nofollow" href="https://web.archive.org/web/20090527060656/http://onstagemag.com/ar/performance_happened_month_11/index.htm">"It Happened This Month"</a>. <i>OnStageMag.com</i>. Archived from <a rel="nofollow" href="http://onstagemag.com/ar/performance_happened_month_11/index.htm">the original</a> on May 27, 2009<span>. Retrieved <span>2008-11-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=OnStageMag.com&amp;rft.atitle=It+Happened+This+Month&amp;rft.date=2002-09-01&amp;rft.au=Cleveland%2C+Barry&amp;rft_id=http%3A%2F%2Fonstagemag.com%2Far%2Fperformance_happened_month_11%2Findex.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-PDQ_Bach-25"><span><b><a href="#cite_ref-PDQ_Bach_25-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.schickele.com/composition/blauesgras.htm">"Cantata 'Blaus Gras'<span></span>"</a>. <i>The Peter Schickele/P.D.Q. Bach Web Site</i>. July 3, 2011<span>. Retrieved <span>2012-12-07</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Peter+Schickele%2FP.D.Q.+Bach+Web+Site&amp;rft.atitle=Cantata+%27Blaus+Gras%27&amp;rft.date=2011-07-03&amp;rft_id=http%3A%2F%2Fwww.schickele.com%2Fcomposition%2Fblauesgras.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-26"><span><b><a href="#cite_ref-26">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.mcgath.com/pdq.html#3.14159265">"The Key of P. D. Q"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Key+of+P.+D.+Q&amp;rft_id=http%3A%2F%2Fwww.mcgath.com%2Fpdq.html%233.14159265&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-27"><span><b><a href="#cite_ref-27">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=5bWeSr04Wzs">"Victor Borge - As 'Franz Liszt' with Mike Wallace c.1960"</a>. <i>YouTube</i>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/4W3cPSntmBk">Archived</a> from the original on 2021-12-21<span>. Retrieved <span>December 26,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=Victor+Borge+-+As+%27Franz+Liszt%27+with+Mike+Wallace+c.1960&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D5bWeSr04Wzs&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-28"><span><b><a href="#cite_ref-28">^</a></b></span> <span><cite id="CITEREFHencken1992">Hencken, John (22 August 1992). <a rel="nofollow" href="https://www.latimes.com/archives/la-xpm-1992-08-22-ca-5071-story.html">"TV Reviews&nbsp;: Borge's 'Then &amp; Now' Is Mostly Now on PBS"</a>. <i><a href="https://en.wikipedia.org/wiki/Los_Angeles_Times" title="Los Angeles Times">Los Angeles Times</a></i><span>. Retrieved <span>December 26,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Los+Angeles+Times&amp;rft.atitle=TV+Reviews+%3A+Borge%27s+%27Then+%26+Now%27+Is+Mostly+Now+on+PBS&amp;rft.date=1992-08-22&amp;rft.aulast=Hencken&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.latimes.com%2Farchives%2Fla-xpm-1992-08-22-ca-5071-story.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-29"><span><b><a href="#cite_ref-29">^</a></b></span> <span><cite id="CITEREFSola_i_Ramos1999">Sola i Ramos, Elisa (December 1999). <a rel="nofollow" href="http://www.blanes.cat/oiapdocs.nsf/a50fa5b68f16871cc12566ff0056d21b/a88903545a9aaaaac12578cc004da7ad/$FILE/Proverbis,%20dites%20i%20frases%20fetes%20de%20Blanes.pdf">"PROVERBIS, DITES I FRASES FETES DE BLANES"</a> <span>(PDF)</span>. Servei de Català de Blanes (CPNL)<span>. Retrieved <span>19 March</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=PROVERBIS%2C+DITES+I+FRASES+FETES+DE+BLANES&amp;rft.pub=Servei+de+Catal%C3%A0+de+Blanes+%28CPNL%29&amp;rft.date=1999-12&amp;rft.aulast=Sola+i+Ramos&amp;rft.aufirst=Elisa&amp;rft_id=http%3A%2F%2Fwww.blanes.cat%2Foiapdocs.nsf%2Fa50fa5b68f16871cc12566ff0056d21b%2Fa88903545a9aaaaac12578cc004da7ad%2F%24FILE%2FProverbis%2C%2520dites%2520i%2520frases%2520fetes%2520de%2520Blanes.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
<li id="cite_note-30"><span><b><a href="#cite_ref-30">^</a></b></span> <span><cite id="CITEREFMartin_Dardis">Martin Dardis. <a rel="nofollow" href="https://www.irish-folk-songs.com/finnegans-wake-lyrics-and-chords.html">"Finnegan's Wake lyrics and chords"</a>. <i>Irish Folk Songs</i><span>. Retrieved <span>16 February</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Irish+Folk+Songs&amp;rft.atitle=Finnegan%27s+Wake+lyrics+and+chords&amp;rft.au=Martin+Dardis&amp;rft_id=https%3A%2F%2Fwww.irish-folk-songs.com%2Ffinnegans-wake-lyrics-and-chords.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AShave+and+a+Haircut"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Shave_and_a_Haircut&amp;action=edit&amp;section=7" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a rel="nofollow" href="https://web.archive.org/web/20050310195336/http://www.dataflo.net/~mpurintun/Tabs/OldTimeTabs/shave_and_a_haircut.htm">Description</a></li>
<li><a rel="nofollow" href="http://www.hum.uva.nl/mmm/groene/">Dutch article on "Shave and a haircut"</a></li>
<li><a rel="nofollow" href="http://webapp1.dlib.indiana.edu/inharmony/detail.do?action=detail&amp;fullItemID=/lilly/devincent/LL-SDV-201006&amp;queryNumber=1">Sheet music for "At A Darktown Cakewalk" from the IN Harmony system at Indiana University</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw1490
Cached time: 20240229061557
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.326 seconds
Real time usage: 0.624 seconds
Preprocessor visited node count: 2195/1000000
Post‐expand include size: 48448/2097152 bytes
Template argument size: 2053/2097152 bytes
Highest expansion depth: 16/100
Expensive parser function count: 4/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 79248/5000000 bytes
Lua time usage: 0.192/10.000 seconds
Lua memory usage: 8381903/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  558.475      1 -total
 36.74%  205.188      1 Template:Reflist
 33.35%  186.258      1 Template:Image_frame
 18.48%  103.229     11 Template:Cite_book
 12.48%   69.723      1 Template:Short_description
  7.84%   43.793     13 Template:Cite_web
  7.71%   43.061      2 Template:Citation_needed
  7.43%   41.510      2 Template:Listen
  6.97%   38.932      2 Template:Pagetype
  6.52%   36.407      2 Template:Fix
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:3529553-0!canonical and timestamp 20240229061557 and revision id 1210973992. Rendering was triggered because: api-parse
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Serving my blog posts as Linux manual pages (251 pts)]]></title>
            <link>https://jamesg.blog/2024/02/29/linux-manual-pages/</link>
            <guid>39548410</guid>
            <pubDate>Thu, 29 Feb 2024 12:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jamesg.blog/2024/02/29/linux-manual-pages/">https://jamesg.blog/2024/02/29/linux-manual-pages/</a>, See on <a href="https://news.ycombinator.com/item?id=39548410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
    	 <!-- This page uses microformats to structure different pieces of information.
    I use h-entry to state this is a post. Any class name that starts with h-, p-, or -e is a microformat.
    By specifying microformats, some web tools can better understand this page. For example, IndieNews can use
    the p-name to figure out the title of the post (without the "| James' Coffee Blog" I add to the <title> tag of my website.
    Learn more about h-entry: https://indieweb.org/h-entry
-->
<article>
	<header>
		
		<p><em>Published on
			<a href="https://jamesg.blog/2024/02"><time datetime="2024-02-29T00:00:00">February 29, 2024</time></a>
			 under the <a href="https://jamesg.blog/category/coding">Coding</a> category. <a onclick="document.getElementsByTagName('incoming-links')[0].toggle(); document.getElementsByTagName('outgoing-links')[0].toggle();">Toggle Memex mode</a></em></p>
		  
		
		<a href="https://jamesg.blog/assets/manual_example.png"><img src="https://jamesg.blog/assets/manual_example.png" alt=""></a>
		
		
		
	</header>
	<section>
		<div>
			<p><em>Intended audience: You are likely to enjoy this post the most if you are interested in Linux and/or Linux manual pages, or if you enjoy reading about esoteric programming projects.</em></p>
<p>Linux computers come with pre-installed manual pages that describe how to use specific commands. These pages are readable by typing <code>man &lt;command&gt;</code> into your terminal. For example, you can get the manual for the <code>tac</code> command, which prints out a file in from bottom-to-top by using the command <code>man tac</code>. Some command line software you install adds manual pages, too.</p>
<p>Linux manual pages are formatted using the <code>roff</code> syntax, which you can use to mark up documents. <code>roff</code> was the first typesetting command line software for Unix, developed at Bell Labs. Earlier this week, with a spark for building but no particular idea in mind, I started to think about the Linux manual page. Could I serve my blog posts as Linux manual pages? Herein lay an adventure.</p>
<p>TL;DR: You can request a Linux manual page version of a blog post with the following HTTP request:</p>
<pre><code>
curl -sL -H "Accept: text/roff" https://jamesg.blog/2024/02/28/programming-projects/ &gt; post.page &amp;&amp; man ./post.page
</code></pre>

<h2>Devising the system: Content negotiation</h2>
<p>I had an idea for how I wanted this to work in mind. I wanted a user to be able to request a <code>roff</code> version of a blog post using content negotiation, part of HTTP that lets you specify ixn what format you want a file. For example, you could request an image with an <code>Accept: image/png</code>. This tells a server that, if possible, it should send a PNG file. There are lots of intricacies to content negotiation. You can provide a list of types of content you can accept, and the order in which a server should try to return them</p>
<p>But! That's a rabbit hole for another day. What's important here is that an application can ask a server for content in a specific format using a HTTP header.</p>
<p>With content negotiation, I can route requests if a user sends an <code>Accept</code> header. If a user asks for an <code>text/roff</code> document, I could return a manual page that can be opened with the <code>man</code> command.</p>
<h2>Writing the manual pages</h2>
<p>Manual pages use the <code>roff</code>syntax, so I would need to have versions of my blog posts in that format. To do this, I updated my site to generate <code>man</code> pages for each blog post. The template I used to generate the manual page was as follows:</p>
<pre><code>
.TH jamesg.blog 1 "" "jamesg.blog"
.SH TITLE
...
.SH AUTHOR
James' Coffee Blog (https://jamesg.blog)
.SH PUBLISHED
...
.SH POST
...
.SH URL
...
</code></pre>

<p>Here, I set a header with my domain name and create five sections: title, author, published date, the post content, and the URL of the post. The raw content is markdown. This doesn't always turn out well in a manual as spacing can sometimes be off. But, markdown was more readable than HTML and resulted in less information loss (i.e. titles having no distinction to paragraphs other than being on their own line) than using plain text.</p>
<p>I now had:</p>
<ol>
<li>Properly formatted manual pages, and;</li>
<li>The knowledge that content negotiation could allow someone to request a manual page.</li>
</ol>
<p>Now came the final piece of the puzzle: using content negotiation to facilitate the request for manual pages.</p>
<h2>Requesting a manual page</h2>
<p>You can use the following command to request the <code>roff</code> format of blog posts on this website:</p>
<pre><code>
curl -sL -H "Accept: text/roff" https://jamesg.blog/2024/02/28/programming-projects/ &gt; post.page
</code></pre>

<p>You can then open the result as a Linux manual page:</p>
<pre><code>
man ./post.page
</code></pre>

<p>Let's talk about how this works!</p>
<p>When a browser makes a request to <code>https://jamesg.blog/2024/02/19/personal-website-ideas/</code>, it asks for the HTML version of the page. In the <code>curl</code> command above, the command asks for the <code>text/roff</code> version. I added a few lines of text in my NGINX configuration to change how the server responds when <code>text/roff</code> is requested for a blog post.</p>
<p>First, I declared a few variables in my <code>/etc/nginx/nginx.conf</code> file that let me raise a flag when a specific content type was identified:</p>
<pre><code>
map $uri $redirect_suffix {
    ~^/(.*)/$   $1;
    default     "";
}

map $http_accept $redirect_location {
    default "";
    "~^text/roff" 1;
}
</code></pre>

<p>You can add multiple different redirect locations, but I only need two: the default, and my custom <code>text/roff</code> rule.</p>
<p>In my site NGINX configuration (the file in the <code>/etc/nginx/sites-enabled</code> folder), I used the following code to handle requests differently if a <code>roff</code> page is requested:</p>
<pre><code>
server {
                ...
        location / {
          if ($redirect_location = 1) {
              rewrite ^/(.*)/$ /$1.man last;
          }
            ...
        }
}
</code></pre>

<p>Here, I say: take a URL, and add <code>.man</code> to the end, removing the trailing slash, as long as the <code>Accept: text/roff</code> header is set. This tells NGINX to read from the <code>.man</code> file instead of the <code>index.html</code> file associated with each post on my site.</p>
<p>That is to say you can now read blog posts on this website as a Linux manual page. This was a fun investigation into using content negotiation in NGINX and a reminder of how far we have come with typesetting technology from the command line interfaces to modern-day typesetting software and HTML.</p>
<p><em>Thank you to <a href="https://toddpresta.com/">Todd</a> for providing guidance on setting up my NGINX configuration. Todd's help was sincerely appreciated!</em></p>
			
		</div>
		
		<p><a href="https://notbyai.fyi/"><img src="https://jamesg.blog/assets/ai.png" alt="Written by human, not by AI"></a></p>
	</section>
	
	<section>
    <h2>Responses</h2>
    
    <h2>Comment on this post</h2>
    <p>Respond to this post by sending a <a href="https://indieweb.org/Webmention">Webmention</a>.</p>
    <p>Have a comment? Email me at <a href="mailto:readers@jamesg.blog?subject=Serving%20my%20blog%20posts%20as%20Linux%20manual%20pages">readers@jamesg.blog</a>.</p>  
</section>
</article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The KDE desktop gets an overhaul with Plasma 6 (723 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/963851/0c64b8038c62432c/</link>
            <guid>39548088</guid>
            <pubDate>Thu, 29 Feb 2024 11:33:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/963851/0c64b8038c62432c/">https://lwn.net/SubscriberLink/963851/0c64b8038c62432c/</a>, See on <a href="https://news.ycombinator.com/item?id=39548088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-trial,v 1.1 2005-11-04 21:27:01 corbet Exp $ -->
<center>
<table>
<tbody><tr><td>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider accepting the trial offer on the right.  Thank you
for visiting LWN.net!
</p></td><td>
<div>
<h3>Free trial subscription</h3>
           <p>
           Try LWN for free for 1 month: no payment
           or credit card required.  <a href="https://lwn.net/Promo/slink-trial2-3/claim">Activate
           your trial subscription now</a> and see why thousands of
           readers subscribe to LWN.net.
           
</p></div>
</td>
</tr>

</tbody></table>
</center>

<p>It's been nearly 10 years since
<a href="https://kde.org/announcements/plasma/5/5.0/">KDE&nbsp;Plasma&nbsp;5</a>,
which is the last major release of the <a href="https://kde.org/plasma-desktop/">desktop</a>.
On February&nbsp;28 the project <a href="https://kde.org/announcements/megarelease/6/">announced</a> its "mega release" of KDE
Plasma&nbsp;6, KDE Frameworks 6, and KDE Gear&nbsp;24.02 — all based on the <a href="https://www.qt.io/product/qt6">Qt&nbsp;6</a> development framework. This
release focuses heavily on migrating to Wayland, and aspires to be a seamless
upgrade for the user while improving performance, security, and support
for newer hardware. For developers, a lot of work has gone into removing
deprecated frameworks and decreasing dependencies to make it easier to write
applications targeting KDE.</p>

<h4>What's in Plasma 6</h4>

<p>For the purpose of this article, we'll mostly look at Plasma and <a href="https://develop.kde.org/products/frameworks/">Frameworks</a>, as Gear&nbsp;24.02
contains too many applications like KMail, Kate, and the Kdenlive
video editor that deserve more attention in their own right. I ran <a href="https://fedoraproject.org/atomic-desktops/kinoite/">Fedora
Kinoite's</a> <a href="https://planet.kde.org/siosms-blog-2023-11-21-kinoite-nightly-images-with-plasma-6/">nightly</a>
releases with pre-release Plasma&nbsp;6 packages, which has proved pleasantly
stable and performant on an aging ThinkPad&nbsp;X280 with 16GB of RAM and a
Core&nbsp;i7-8650U CPU.</p>

<p>The difference between Plasma&nbsp;5 and 6 is apparent, but not
pronounced. Users who are comfortable with Plasma&nbsp;5 are unlikely to feel
discomfited with Plasma&nbsp;6, or have a hard time adapting to the changes
sprinkled throughout the desktop. Plasma&nbsp;6 has
a number of changes to default settings. The big change, of course, is <a href="https://invent.kde.org/plasma/plasma-workspace/-/merge_requests/2188">Wayland
as the default</a> graphical session.</p>

<p>Plasma&nbsp;6 also has a smattering of smaller, less controversial changes. For example, prior to
Plasma&nbsp;6, the desktop defaulted to single-click to open a folder, launch a
program, or open a file. Users coming from other operating systems or
Linux desktop environments are often used to double-clicking to do these
things. Now, KDE upstream has relented on using a single-click to open files and
defaults to double-click instead. Distributions like Fedora, Kubuntu, and
Manjaro had been changing the upstream default anyway, so KDE developer Nate Graham <a href="https://invent.kde.org/plasma/plasma-desktop/-/issues/72">suggested</a>
disabling the feature. "<q>Distros are closer to users and clearly the feedback they've been
getting is that double-click is a better default...Let's admit it and switch
to double-click by default ourselves</q>".</p>

<blockquote>
<a href="https://lwn.net/Articles/963854/"><img src="https://static.lwn.net/images/2024/Plasma-6-sm.png" alt="[KDE Plasma 6 desktop]" title="KDE Plasma 6 desktop"></a>
</blockquote>

<p>Plasma&nbsp;6 is also supposed to do away with the default of using the scroll
wheel on the desktop to switch virtual desktops. However, this setting is
still active in Fedora Kinoite as of this writing. Scrolling to switch virtual
desktops has been the default for some time, but Graham argued in another <a href="https://invent.kde.org/plasma/plasma-desktop/-/issues/55">proposal</a>
to disable the feature because it can easily surprise users with unexpected
and unwanted behavior. Users who prefer the old behavior can toggle it
back on in the "Mouse Actions" settings under "Desktop Folder Settings",
so it's not going away entirely. Another change to scrolling behavior
in this release is that clicking on a scrollbar moves the window to
<a href="https://invent.kde.org/plasma/plasma-desktop/-/issues/92">the
location clicked</a>, rather than one "page" at a time. This is meant to
reduce the amount of fiddling with the scroll wheel to move up or down a long
"distance", in order to be a better option for users with repetitive strain injuries
(RSIs) — or for users who'd like to avoid RSIs in the first place.</p>

<p>Breeze is Plasma's default theme and it has been updated for Plasma&nbsp;6, but it's a subtle change
— sort of like repainting a room and changing the color from "flat white"
to "eggshell white". It has some changes to spacing that make it feel a
little less crowded, and it has fewer lines separating UI elements. The System
Settings application has also been revamped. This may be more noticeable, as
some of the settings have migrated to new locations. The nice thing about KDE
is that so much is configurable, but finding configuration settings is still
a challenge in Plasma&nbsp;6. For example, the aforementioned setting to scroll
virtual desktops is found in the Desktop Folder Settings application, but
not in the System Settings application under the Virtual Desktop settings.</p>

<p><a href="https://apps.kde.org/dolphin/">Dolphin</a>, KDE's file manager,
had its configuration settings redesigned to make them easier to navigate. The
prior version of Dolphin included six tabs of settings for navigation, its
context menu, startup behavior, view modes, behavior of the trash, and
general settings. The redesign condenses this into four tabs, scooting the
navigation options and startup options into the new interface tab. It also adds
a fifth tab for user feedback, with options to contribute statistics and
participate in surveys. These are, as one would expect from an open-source
project that respects its users, set to share no data by default. Users
who wish to participate, though, can choose just how much participation
they're willing to engage in. This ranges from sharing just a few details
like version of the application and operating system, to more telemetry
like screen resolution, time Dolphin is used, how many network shares are
available, and more.</p>

<p>The Dolphin interface changes are minor. Instead of showing recent
files from today and yesterday, Dolphin now shows recent files and recent
locations. Settings for file history are system-wide, and found in System
Settings rather than Dolphin's settings — users can opt for keeping
history "forever" or a period of months, or turn off history entirely. (Days or
hours do not appear to be an option.) Users can also specify the applications
allowed to access file history, rather than granting access to any application.

</p><p>Plasma&nbsp;6 on Wayland has some support for <a href="https://zamundaaa.github.io/wayland/2023/05/18/hdr-and-color-management-in-kwin.html">high
dynamic range (HDR) and color management</a>, depending on the application
and if one has a supported monitor. Sadly, the monitors I have on hand are not
supported. One thing that did work nicely, however, was setting the
scaling for a laptop monitor and external monitor, independently. It was easy to set the
external monitor to 100% scaling while the ThinkPad screen was set to 125% so that windows appeared
to be the same size when moved from one monitor to the other.</p>

<p>The Plasma Search feature, which is part of <a href="https://userbase.kde.org/Plasma/Krunner">KRunner</a> and the
<a href="https://userbase.kde.org/Plasma/Kickoff">Kickoff</a>
application launcher, has been <a href="https://write.as/alexander-lohnau/profiling-and-optimizing-krunner">refactored</a>
and is claimed to be much faster in this release. The release announcement
claimed major speedups for searching local documents and for applications,
while reducing CPU usage. It's hard to verify this, but KRunner did feel snappy
when performing web and document searches. <a href="https://apps.kde.org/spectacle/">Spectacle</a>,
KDE's screenshot utility, now takes screenshots and recordings of the entire desktop, an application
window, or just a selection of the screen. This promises to be a handy tool
to create tutorials, or share a recording of application behavior when filing
a bug.</p>

<p>KDE giveth, and KDE taketh away. As is common with major updates, some
features and settings have been removed due to design changes or difficulty
with underlying drivers or software. For example, GUI configuration for <a href="https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/1509">Synaptics
touchpads</a> and <a href="https://www.x.org/releases/X11R7.6/doc/man/man4/evdev.4.xhtml">evdev</a>
input devices has been removed because the drivers have been superseded with <a href="https://wayland.freedesktop.org/libinput/doc/latest/what-is-libinput.html">libinput</a>
in Wayland. Unmaintained features like the <a href="https://invent.kde.org/plasma/plasma-desktop/-/issues/57">Air theme</a>,
<a href="https://invent.kde.org/plasma/plasma-desktop/-/issues/65">icon
view for System Settings</a>, and <a href="https://invent.kde.org/plasma/khotkeys/-/merge_requests/23">KHotkeys</a>
were all scuttled in this release. The ability to grab
wallpapers from the Unsplash free stock image site was removed due to <a href="https://invent.kde.org/plasma/kdeplasma-addons/-/merge_requests/422">API
changes</a> and the <a href="https://invent.kde.org/plasma/kdeplasma-addons/-/merge_requests/487">QuickShare
applet</a> for file transfer was dropped because it never worked as
intended.</p>

<h4>Under the hood</h4>

<p>Even though Plasma&nbsp;6 may not feel like a major update, a lot of work has gone
into KDE&nbsp;Frameworks&nbsp;6 to make it possible. I asked KDE developer
Carl Schwan by email about the developer-facing changes and plans for KDE&nbsp;5 now
that Plasma&nbsp;6 has been released. Schwan said most of the work in
Frameworks&nbsp;6 was about reducing rather than adding features. Schwan pointed
to removal of deprecated frameworks, like KHtml, the KJS javascript engine,
and KHotkeys. The project has also worked to get rid of deprecated Qt APIs,
such as QtCodecs, and to decrease dependencies between frameworks so external
Qt applications can just use one or two KDE frameworks. Schwan also said that
KDE has removed a lot of APIs "which were barely used or [...] have better
alternatives either in another framework or in Qt itself". In particular,
he noted that KDE's plugin system has moved from two APIs to a single API.</p>

<p>Schwan said that Qt&nbsp;6 itself didn't have many API changes, but
it did add an abstraction layer for graphics APIs like Metal, Vulkan,
OpenGL, and DirectX "instead of only supporting OpenGL+Angle". In
addition, Qt has switched to <a href="https://cmake.org/">CMake</a>, away
from the <a href="https://doc.qt.io/qt-6/qmake-manual.html">qmake</a>
build system, which Schwan said helped a lot to improve developer
tooling. Finally, Qt&nbsp;6 brought a number of improvements to <a href="https://doc.qt.io/qt-6/qtwaylandcompositor-index.html">Qt Wayland</a>,
which Schwan said had been driven forward in part by KDE developers.</p>

<h4>Support for KDE 5 and X11</h4>

<p>Plasma&nbsp;6 is likely to be a little
bit rough around the edges for a while, and users might want to review <a href="https://bugs.kde.org/buglist.cgi?bug_severity=critical&amp;bug_severity=grave&amp;bug_severity=major&amp;bug_status=UNCONFIRMED&amp;bug_status=CONFIRMED&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;classification=Applications&amp;classification=Plasma&amp;keywords=qt6%2C%20&amp;keywords_type=allwords&amp;list_id=2462812&amp;query_format=advanced">known
issues</a> before deciding to upgrade. Obviously
Plasma&nbsp;6 won't be immediately available in most
distributions, but users can refer to KDE's community wiki for <a href="https://community.kde.org/Plasma/Plasma_6#How_to_use/test_it">instructions</a>
on how to test Plasma&nbsp;6 right away. Users can choose to <a href="https://community.kde.org/Get_Involved/development/Build_software_with_kdesrc-build#Plasma">build
from source</a>, try the <a href="https://neon.kde.org/download">KDE neon</a>
testing edition, or try one of the other distribution-specific methods for
Fedora, Gentoo, KaOS, NixOS, or openSUSE.</p>

<p>There is no rush to switch — KDE&nbsp;5 is not quite out of the picture
just yet. On February&nbsp;12, on the Plasma development list, David Edmundson <a href="https://mail.kde.org/pipermail/plasma-devel/2024-February/123325.html">said</a>
he'd seen enough patches that should go
into&nbsp;5.27 to warrant another release. Justin Zobel <a href="https://mail.kde.org/pipermail/plasma-devel/2024-February/123329.html">agreed</a>
and noted that "<q>many distros won't [adopt] it for some
time. Major bugfixes and security fixes should definitely
continue being applied until such time that most major distros
have updated to 6</q>". Valorie Zimmerman, from the Kubuntu project, <a href="https://mail.kde.org/pipermail/plasma-devel/2024-February/123331.html">said</a>
this is good news since the next long-term support (LTS) release for Kubuntu is
coming in March and won't be based on Qt&nbsp;6. On February&nbsp;19, Jonathan Riddell <a href="https://mail.kde.org/pipermail/plasma-devel/2024-February/123333.html">reported</a>
the Plasma team planned to do a Plasma&nbsp;5.27.11 release on March&nbsp;6.</p>

<p>Even though many in the Fedora project are eager to <a href="https://lwn.net/Articles/961899/">drop X11 support</a>, KDE upstream
plans to continue including X11 support for users who depend on it in the
short term. Users can expect to see support
in Plasma&nbsp;6 as well, but Schwan says there's "no fixed timeline" with
various estimates ranging from two to five years before support is fully
removed. He stressed that there will be "plenty of communication
beforehand" and the project "certainly won't drop the support from
one day to the other".</p>

<p>Overall, Plasma&nbsp;6 looks to be a smooth upgrade for users, and
KDE&nbsp;Frameworks&nbsp;6 seems to be a solid foundation for the next few
years of KDE development. It should be interesting to watch how 
Plasma evolves over the next few years.</p><br clear="all">
               <br clear="all">
               <blockquote>
<p>
<b>Did you like this article?</b>  Please accept our 
<a href="https://lwn.net/Promo/slink-trial2-3/claim">trial subscription offer</a> to be
able to see more content like it and to participate in the discussion.
</p>
</blockquote>
<hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/963851/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why is HN so often down? (139 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39548058</link>
            <guid>39548058</guid>
            <pubDate>Thu, 29 Feb 2024 11:14:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39548058">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39548185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548185" href="https://news.ycombinator.com/vote?id=39548185&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I've been frequenting this site daily for over 15 years now, and I don't think I've had error messages more than a handful of times in that decade and a half. Today was indeed one such time - which is what triggered me to check out this particular post. But at least in my experience it's not what I'd call "often". Maybe you're just very unlucky, or perhaps I'm extremely lucky... Who can tell?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548282"><td></td></tr>
                <tr id="39548320"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39548320" href="https://news.ycombinator.com/vote?id=39548320&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I believe it's just a virtual machine and IP addresses are not anycast; no need to check from multiple locations when you can reach the host and the issue is in it returning HTTP 5xx.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548357"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39548357" href="https://news.ycombinator.com/vote?id=39548357&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>True, I mainly monitor from everywhere as a means of dogfooding my own service (and just incase HN gets replicas)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548439"><td></td></tr>
                              <tr id="39548240"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548240" href="https://news.ycombinator.com/vote?id=39548240&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>For the past couple of months I've had these errors multiple times a day, it's definitely often down now.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548415"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39548415" href="https://news.ycombinator.com/vote?id=39548415&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Months? I'd say I'm mildly addicted to HN and I noticed this week it was hit or miss, but only this week. Very surprised to hear you say months.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548213"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548213" href="https://news.ycombinator.com/vote?id=39548213&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I get it happening every few weeks for a short amount of time it seems. More so recently (also been a site user for approximately 10 years).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548205"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548205" href="https://news.ycombinator.com/vote?id=39548205&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I had never seen it for more than a decade, but in the last couple of years it has become very frequent.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548265"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548265" href="https://news.ycombinator.com/vote?id=39548265&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>It seems to happen more frequently when you post critical comments as a way to slow you down from raging, with an exponential backoff. As-in, exactly right after.<p>Did you post something negative about Google/DEI? Or maybe just upvote it? Or skim one of those threads. There you go. Time out for you.</p><p>Experimentally you're welcome to reply to me or elsewhere and see if you get dinged.</p><p>Another way to witness it is by simply clearing cookies and/or from another network. Suddenly it is up, weird, eh?</p><p>Edit: @huhtenberg: Indeed, I got both of those interchangeably. Hence the observation.</p><p>In fact I just got it now trying to reply to you, haha! Careful, maybe it is a no no to even discuss this.</p><p>An interesting thing to think about is how there is a variety of experiences about downtime reported in this very thread. Some run into it a lot, some not at all.</p><p>Food for thought.</p><p>Edit 2: Oh hey, this very thread just got disappeared too. Maybe it never existed and you're just paranoid if you are reading this.</p><p>Edit 3: Hellokoloto thanks for your data point.</p><p>Why was this very thread silently disappeared from the front page? It is about downtime. Let me guess, the flame war thing got trigged again.</p><p>Seems discussing DEI <i>at all</i> will trigger it by definition as the pro-DEI cohort -doesn't even have to be the mods- will ensure this.</p><p>Some subjects are just sacred cows here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548640"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39548640" href="https://news.ycombinator.com/vote?id=39548640&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>Im probably one of the worst people on hn: I create new accounts because i think it helps me to spend less time on hn but actually i just create more accounts... (i know i'm not allowed to, clearly i have a hn issue...)<p>I do not get blocked in any way and i do complain about things. Bitcoins is one of my fav.</p><p>I originally thought your comment was /s but reading your comments below, you might relaly have an issue with overthinking this or being paranoid.</p><p>No one cares about comments in the first place, its not a lot of people. No one cares really about being negative about certain things. There are plenty of people constantly complaining about apple, google or whatsoever on threads.</p><p>And how important do you think you are? A discussion happens, people forget about it or move on, mos tof the time discussions don't change the mind of people anyway.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39548341"><td></td></tr>
            <tr id="39548315"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39548315" href="https://news.ycombinator.com/vote?id=39548315&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>Careful of what you think while you are browsing the site, I've heard that they have some new tracking technology that downloads itself into your brain and turns it into a web socket to add delays to your requests, so you don't feel like posting anymore.<p>Truly scary stuff.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548332"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39548332" href="https://news.ycombinator.com/vote?id=39548332&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>I love you too.<p>P.S. - This is a bog standard moderation mechanism and well known and widely discussed.</p><p>Very nice and caring of you to tell people whose opinions you don't like that they are crazy. How kind.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548485"><td></td></tr>
            <tr id="39548339"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39548339" href="https://news.ycombinator.com/vote?id=39548339&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>Nope, when you get rate limited there is a different message and it seems to only apply to posting.<p>No conspiracy needed, it's just more unstable lately, I've noticed it as well the past few months.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548398"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39548398" href="https://news.ycombinator.com/vote?id=39548398&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>At the same time, interesting that downtime can give rise to conspiracy theories.<p>Hmm maybe people are always looking for patterns (humans as "pattern finding machines"?), and if there's a maybe-pattern, the thoughts start flowing. (A good thing usually I suppose)</p><p>Maybe it's good to avoid accidentally creating patterns</p><p>Or, could be fun to intentionally create pointless nonsense patterns :-)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548436"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39548436" href="https://news.ycombinator.com/vote?id=39548436&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>It's a bit of confirmation bias and recency bias.  Uncorrelated things might appear correlated if you limit yourself to a small sample size.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548450"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39548450" href="https://news.ycombinator.com/vote?id=39548450&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>This is a misuse of the word conspiracy. Hopefully a good faith one.<p>I'm fully aware that the pattern as I observed could be a coincidence. At the same time I have been able to browse logged in from another browser or my phone 100% of the time, so HN wasn't down, just for this user.</p><p>It isn't a stretch to assume the eye of Sauron fell upon me. Hence I offered people try it out experimentally and decide for themselves. Certainly we can agree more data is necessary, there is no need to paint me as paranoid.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548352"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39548352" href="https://news.ycombinator.com/vote?id=39548352&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>How come I was able to browse HN just fine from another browser?<p>Nothing conspiratorial about it. I can see how it can just be normative moderation and them believing it is for the greater good.</p><p>All this talk of correcting bias never seems apply to oneself however. ;)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548442"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39548442" href="https://news.ycombinator.com/vote?id=39548442&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>Were you logged in? When you're logged out, you get a cached version of the page. When you're logged in, the server needs to generate the page for you in case you hid something (or something else that might modify the page).<p>I'm just making an educated guess since I don't know anything about the internals of HN, but it seems likely enough to me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548493"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39548493" href="https://news.ycombinator.com/vote?id=39548493&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>Very good point, I've considered this too. So far I've observed that I was simultaneously logged in with an alt on another browser and it worked fine.<p>I also got the message on the same wifi network but not when browsing from a phone, suggesting an IP timeout.</p><p>It doesn't have to be nefarious. Dang has told me in his view I am misbehaving deep inside a Google thread that was memory holed from the front page. Maybe he was doing his legitimate moderation and also did the same equally to people who hurl personal attacks at anybody who is negative about DEI, who knows. ;)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548438"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39548438" href="https://news.ycombinator.com/vote?id=39548438&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>&gt; How come I was able to browse HN just fine from another browser?<p>Logged out experience is different than logged in, others noticed it being unresponsive logged in as well so we can assume it's not related to your user, can't we?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                    <tr id="39548295"><td></td></tr>
                <tr id="39548463"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548463" href="https://news.ycombinator.com/vote?id=39548463&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>It's very weird how most websites already figured out how to keep their services up under load, but a CRUD text-only forum, with an "elite community of techies", can't.<p>I would be curious to know what is the big challenge here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548526"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39548526" href="https://news.ycombinator.com/vote?id=39548526&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>Probably the fact that the software was written decades ago, hacked together and also the author decided to first write their own lisp, then implement HN software with this lisp (called Arc).<p>I'm guessing that has something to do with the difficulty of changing it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39548216"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548216" href="https://news.ycombinator.com/vote?id=39548216&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>It was down for me a bit today.<p>But it's a great free service with no tracking/ads so I'm fine with that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39548249"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548249" href="https://news.ycombinator.com/vote?id=39548249&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>I'm in Ghana, and can confirm that I'm seeing this a lot recently. Sometimes the problem persists even after multiple refreshes.<p>I'm almost always logged in, and it happens even when I have not visited HN in some hours.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39548203"><td></td></tr>
            <tr id="39548160"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548160" href="https://news.ycombinator.com/vote?id=39548160&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Dang said they're working on it, I presume they are upgrading the hardware soon or something... (edit: in any case they are aware and it hopefully shouldn't be an issue long term)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548173"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548173" href="https://news.ycombinator.com/vote?id=39548173&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I was under the impression that a lot of the code is single-threaded and so throwing hardware at it won't do a whole lot.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548202"><td></td></tr>
                <tr id="39548492"><td></td></tr>
            <tr id="39548416"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39548416" href="https://news.ycombinator.com/vote?id=39548416&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Is that a reason to believe it less? You can also see from hiring threads that it's a very small (but growing) team and that inherently it is truly being worked on.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548555"><td></td></tr>
            <tr id="39548391"><td></td></tr>
                        <tr id="39548152"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548152" href="https://news.ycombinator.com/vote?id=39548152&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>It is not often down, but it's very easy to hit its rate limiter when upvoting or commenting. Waiting a minute usually fixes it.<p>The rate limiter is even stricter when not logged in — for a period I wanted to take a break with getting into online arguments, so I stayed logged out, which would cause my IP to be banned after a day or two (a bit annoying, though easily unbanned with the self-service system: <a href="https://news.ycombinator.com/item?id=4761102">https://news.ycombinator.com/item?id=4761102</a>) — IIRC dang confirmed that it would be better to stay logged in to avoid this anti-bot measure.</p><p>I guess that's the price to pay to have such a popular website that's maintained by a single person.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548193"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548193" href="https://news.ycombinator.com/vote?id=39548193&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>"I guess that's the price to pay to have such a popular website that's maintained by a single person."<p>Why do you think, it is only one? There is definitely help with the moderation for example.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39548226"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548226" href="https://news.ycombinator.com/vote?id=39548226&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I really wish the rate limit was relaxed when favoriting posts specifically. Favoriting a post counts as two requests since it redirects you to another page, so you'll often hit the rate limit page while favoriting, but the favorite still goes through because only the redirected request gets rate limited.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548165"><td></td></tr>
            <tr id="39548136"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548136" href="https://news.ycombinator.com/vote?id=39548136&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I’m new but been checking HN for the past weeks daily, multiple times a day usually. I haven’t experienced this on any single of my visits. Weird.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548207"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548207" href="https://news.ycombinator.com/vote?id=39548207&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I've had mixed results. Some visits were fine, especially those where I wasn't logged in. During others I've seen errors, often when writing comment replies or voting.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548490"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548490" href="https://news.ycombinator.com/vote?id=39548490&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Not doubting the experiences of anyone else, but I have only been a daily user of this site for the past 18 months, but not once has it been down for me in the morning or evening when I reach for a dopamine hit.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548615"><td></td></tr>
            <tr id="39548462"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548462" href="https://news.ycombinator.com/vote?id=39548462&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>Consider the 'HN hug of death' we have patience for when a site linked on the front page is down.<p>HN must be getting orders of magnitude higher traffic than that <i>constantly</i>.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39548146"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548146" href="https://news.ycombinator.com/vote?id=39548146&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I remember I read somewhere here that it is recommended to log off your session when you do not need to stay online to comment or post something.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548162"><td></td></tr>
                <tr id="39548250"><td></td></tr>
                <tr id="39548318"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39548318" href="https://news.ycombinator.com/vote?id=39548318&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>When the server is having issues, so the served front page is basically a cached static HTML file. The anti-bot limiter applies during normal operation. These are not the same thing.<p>---</p><p>On Feb 28, 2023:</p><p>&gt; Hi sph</p><p>&gt; Yes, you ran into HN's anti-bot software, which blocked your IP. Sorry! Our intention is definitely not to block legit users, but we have to be somewhat aggressive about detecting bots because we don't have much performance to spare.</p><p>&gt; I've unblocked your IP. <i>If you browse HN while logged in, that should immunize you against this happening again.</i> Also, if it ever does happen again, you can unban your IP as described at <a href="https://news.ycombinator.com/newsfaq.html">https://news.ycombinator.com/newsfaq.html</a>. But you have to do that from a different IP address, of course.</p><p>&gt; Let us know if you have any further trouble,</p><p>&gt; Daniel (dang)</p><p>Emphasis mine.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548592"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39548592" href="https://news.ycombinator.com/vote?id=39548592&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>That's all well and good, but in no way demonstrates that the OP you replied to was wrong about logging out having been suggested as a fix for slow site performance.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548363"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39548363" href="https://news.ycombinator.com/vote?id=39548363&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>User-accounts mean limits can be applied per-user instead of per-IP.  Especially when a lot of us are connecting from the same office/site, or the same corporate VPN.<p>But being logged out is more efficient for cached responses. The more load the site is under, the more this pays off.</p><p>It makes sense that they're both true - it's not a case of which is more recent, it's what problem they're solving.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39548428"><td></td></tr>
                  <tr id="39548308"><td></td></tr>
                              <tr id="39548245"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548245" href="https://news.ycombinator.com/vote?id=39548245&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>&gt; what happens, why do we get that message<p>This message is a HTTP 500 error page. 5xx are backend unreachability-related, so likely "the app" dies and has a long-ish boot time, or start is delayed by waiting for cron event.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39548227"><td></td></tr>
            <tr id="39548230"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548230" href="https://news.ycombinator.com/vote?id=39548230&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Backend upgrades I assume. The fact that this even exists, is free, is frequented, and has super valuable commentary is enough to make me wait. I get way more value out of HN than any other site I visit. It’s not my most frequented but it’s my most valued. Try not to compare it with a SaaS you pay for or that sells your information to pay for it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548157"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548157" href="https://news.ycombinator.com/vote?id=39548157&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>I'm getting the same but only when using VPN. Not sure if there's a connection or just a correlation with me using the VPN during the day.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548292"><td></td></tr>
                  <tr id="39548163"><td></td></tr>
                <tr id="39548181"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39548181" href="https://news.ycombinator.com/vote?id=39548181&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>also to remind you that one does not need to check HN when you have 5 minutes to kill. Go take a breath and have a walk.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39548144"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548144" href="https://news.ycombinator.com/vote?id=39548144&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Just guessing but I believe they run their own colocated infraestruture and don't have much or anything that autoscales, so if they're not overprovisioned enough and there's a lot of threads that have too many comments it happens. I also saw they are hiring for an infra engineer role so they might also be understaffed.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548273"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548273" href="https://news.ycombinator.com/vote?id=39548273&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>You might be clicking on a bunch of links at once (triggering some anti-ddos/spam measure?). Happened to me once or twice. I assumed it might have been because my dynamic ip had been "used by robots" prior.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548204"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548204" href="https://news.ycombinator.com/vote?id=39548204&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Is there any open metrics on HN hits / usage etc?  Curious on growth of this platform. For me is my #1 place I regularly go to each day. Other sites less important to hit frequently.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548182"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548182" href="https://news.ycombinator.com/vote?id=39548182&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><p><span>I was always under the impression it was a sort of shadowquasiban/shadowratelimit mechanic<p>it definitely shows up a lot more via vpn
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39548220"><td></td></tr>
            <tr id="39548153"><td></td></tr>
            <tr id="39548248"><td></td></tr>
            <tr id="39548311"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548311" href="https://news.ycombinator.com/vote?id=39548311&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Speculation – but Google moved HN up in search recently and I suspect that's resulted in a spike in traffic. I assume the downtime is capacity related.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548241"><td></td></tr>
                <tr id="39548288"><td></td></tr>
                  <tr id="39548221"><td></td></tr>
            <tr id="39548425"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548425" href="https://news.ycombinator.com/vote?id=39548425&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Used to happen whenever you criticized communist China so I assumed it wad an anti-naughty-posting feature. (Thankfully there’s been some relaxation on this, as evidenced by this post being visible.)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39548149"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39548149" href="https://news.ycombinator.com/vote?id=39548149&amp;how=up&amp;goto=item%3Fid%3D39548058"></a></center>    </td><td><br><div>
                  <p><span>Might be worth considering moving the arch of the site to a SaaS solution like netlify to really benefit from the scaling capabilities of serverless.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39548244"><td></td></tr>
            <tr id="39548367"><td></td></tr>
                  <tr id="39548365"><td></td></tr>
                <tr id="39548387"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon lobbyists to be barred from European parliament (112 pts)]]></title>
            <link>https://www.techradar.com/pro/amazon-lobbyists-to-be-barred-from-european-parliament</link>
            <guid>39547976</guid>
            <pubDate>Thu, 29 Feb 2024 10:33:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techradar.com/pro/amazon-lobbyists-to-be-barred-from-european-parliament">https://www.techradar.com/pro/amazon-lobbyists-to-be-barred-from-european-parliament</a>, See on <a href="https://news.ycombinator.com/item?id=39547976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Amazon warehouse logistics" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X.jpg"><source type="image/jpeg" alt="Amazon warehouse logistics" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X.jpg"><img src="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-320-80.jpg" alt="Amazon warehouse logistics" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/JyvJoDSEYtmPRghihFkR9X.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Shutterstock)</span>
</figcaption>
</div>

<div id="article-body">
<p>Lobbyists from <a data-analytics-id="inline-link" href="https://www.techradar.com/tag/amazon" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.techradar.com/tag/amazon">Amazon</a> are to banned from the European parliament after a number of MEPs called for action to be taken.</p><p>The MEPs stated that Amazon is not cooperating with the parliament on issues surrounding working conditions and the rights of its employees.</p><p>This comes at a time when Amazon and other tech giants such as <a data-analytics-id="inline-link" href="https://www.techradar.com/tag/microsoft" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.techradar.com/tag/microsoft">Microsoft</a> are receiving additional scrutiny by the EU on their business practices.</p><h2 id="x20ac-18-8-million-spent-on-lobbying-since-2013-3">€18.8 million spent on lobbying since 2013</h2><p>Amazon has faced increasing criticism on the working conditions in its European sites and its less than friendly approach to unionionization. Since 2021, the ecommerce giant has failed to attend three meetings with the employment and social affairs committee, with the most recent meeting being missed due to “short notice”, according to a letter from the committee to Robert Metsola, the EU parliament president.</p><p>“It is unreasonable for members to be lobbied by Amazon while at the same time being deprived of the right to represent the interests of European citizens and inquire about claims of breaches of fundamental rights enshrined in EU Treaties and EU labour laws,” the letter stated.</p><p>In response to the decision, Amazon said, “We are very disappointed with this decision, as we want to engage constructively with policymakers. As a company that has been active in the EU for more than 25 years and now has more than 150,000 permanent employees here, we take our engagement with policymakers in Brussels and across Europe extremely seriously.”</p><p>Since 2013, around €18.8 million has been spent by Amazon on lobbying campaigns in EU institutions, according to non-profit research group, the Corporate Europe Observatory. “Amazon’s anti-democratic behaviour won’t be tolerated,” said Oliver Roethig, regional secretary of European trade union group UNI Europa in response to the ban.</p><p><em>Via</em> <a data-analytics-id="inline-link" href="https://www.ft.com/content/11d20273-71e8-433d-bcac-c66d919a203a" target="_blank" data-url="https://www.ft.com/content/11d20273-71e8-433d-bcac-c66d919a203a">FT</a></p><h3 id="section-more-from-techradar-pro"><span>More from TechRadar Pro</span></h3><ul><li><a href="https://www.techradar.com/news/live/mwc-2024-all-the-top-b2b-news-from-this-years-mobile-world-congress" data-before-rewrite-localise="https://www.techradar.com/news/live/mwc-2024-all-the-top-b2b-news-from-this-years-mobile-world-congress">MWC 2024 day three — all the B2B news and announcements from Mobile World Congress</a></li><li>Take a look at our guide to the <a href="https://www.techradar.com/best/firewall" data-before-rewrite-localise="https://www.techradar.com/best/firewall">best firewalls</a></li><li><a href="https://www.techradar.com/pro/the-white-house-urgently-wants-memory-safe-programming-languages-to-be-used-by-developers" data-before-rewrite-localise="https://www.techradar.com/pro/the-white-house-urgently-wants-memory-safe-programming-languages-to-be-used-by-developers">The White House urgently wants memory-safe programming languages to be used by developers</a></li></ul>
</div>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-426zPpCJf44ibCqcuF9rJA"><section><p>Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed!</p></section></div>
<div id="slice-container-authorBio-426zPpCJf44ibCqcuF9rJA"><p>Benedict Collins is a Staff Writer at TechRadar Pro covering privacy and security. Before settling into journalism he worked as a Livestream Production Manager, covering games in the National Ice Hockey League for 5 years and contributing heavily to the advancement of livestreaming within the league. Benedict is mainly focused on security issues such as phishing, malware, and cyber criminal activity, but he also likes to draw on his knowledge of geopolitics and international relations to understand the motives and consequences of state-sponsored cyber attacks.</p>

<p>He has a MA in Security, Intelligence and Diplomacy, alongside a BA in Politics with Journalism, both from the University of Buckingham. His masters dissertation, titled 'Arms sales as a foreign policy tool,' argues that the export of weapon systems has been an integral part of the diplomatic toolkit used by the US, Russia and China since 1945. Benedict has also written about NATO's role in the era of hybrid warfare, the influence of interest groups on US foreign policy, and how reputational insecurity can contribute to the misuse of intelligence.</p>

<p>Outside of work Ben follows many sports; most notably ice hockey and rugby. When not running or climbing, Ben can most often be found deep in the shrubbery of a pub garden.</p></div>


</section>



<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>









</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hetzner switches to new billing model (277 pts)]]></title>
            <link>https://docs.hetzner.com/general/others/new-billing-model/</link>
            <guid>39547940</guid>
            <pubDate>Thu, 29 Feb 2024 10:18:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.hetzner.com/general/others/new-billing-model/">https://docs.hetzner.com/general/others/new-billing-model/</a>, See on <a href="https://news.ycombinator.com/item?id=39547940">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2 id="questions-about-billing-changes-between-march-and-may-2024"><a href="#questions-about-billing-changes-between-march-and-may-2024" aria-label="questions about billing changes between march and may 2024 permalink"></a>Questions about billing changes between March and May 2024</h2>
<h3 id="what-will-change-about-the-way-that-hetzner-calculates-the-invoice-for-march-2024-and-why"><a href="#what-will-change-about-the-way-that-hetzner-calculates-the-invoice-for-march-2024-and-why" aria-label="what will change about the way that hetzner calculates the invoice for march 2024 and why permalink"></a>What will change about the way that Hetzner calculates the invoice for March 2024 and why?</h3>
<p>We are in the process of changing our billing structure to make it more unified; by doing this, we hope to make our products more user friendly.</p>
<p>As part of this process, we will change the billing for many of our products from monthly to hourly. Some products will be based on consumption. This structure will be similar to our Cloud billing. It will take effect in March 2024.</p>
<p>If you use a product for the whole month, we will continue to invoice you for the same monthly amount as always.</p>
<p>During the transition period, which will start with the March 2024 invoice, you may see some unusual things on your invoice. Below, you can see an <a href="#example-invoices">example</a> of what these changes may look like during the transition period.</p>
<p>Just to make it clear, the montly price you will pay will NOT change, even if you see some short-term changes in monthly totals on your invoices during the transition period.</p>
<p>It is possible that you will see a smaller-than-normal total on your invoice for March. In April, we will retro-actively invoice you for March for any hourly-based products; the invoice will be pro rata (proportional to the amount of hours in March that you used those products.)</p>
<h3 id="why-will-my-march-invoice-be-different-from-my-earlier-invoices"><a href="#why-will-my-march-invoice-be-different-from-my-earlier-invoices" aria-label="why will my march invoice be different from my earlier invoices permalink"></a>Why will my March invoice be different from my earlier invoices?</h3>
<p>Starting in April, we will only invoice customers for the services that they have used <strong>AFTER</strong> the month that they use those services.</p>
<p>For that reason, the March invoice will NOT contain any products whose prices we already calculated in March under the old billing structure. That's why your invoice for March may have a smaller total that normal.</p>
<p>The affected products (the ones with hourly-based billing) for March will then appear retro-actively on the APRIL invoice, but with the new hourly based billing.</p>
<p>Please take a look at the <a href="#example-invoices">example invoices below</a>.</p>
<h3 id="why-will-my-april-invoice-be-different-from-my-earlier-invoices"><a href="#why-will-my-april-invoice-be-different-from-my-earlier-invoices" aria-label="why will my april invoice be different from my earlier invoices permalink"></a>Why will my April invoice be different from my earlier invoices?</h3>
<p>Your April 2024 invoice will be the first one that is based on hourly billing. It will cover your hourly usage for the month of March. The hourly billing will apply to most products, but not all. For example, it will not apply to one-time products (like setup fees) or to products like domains and SSL certificates, which will continue to have yearly payment periods.</p>
<p>For this one time, the invoice will retro-actively cover products that were NOT covered on March's invoice as part of the transition period.</p>
<p>After that (starting in April) all future invoices will have a service period for hourly-based products. The service period will start on the first day of the month and end on the last day of the month. If you use these products for a full month, you will see the normal monthly price.</p>
<p>For more details, please look at the section below <a href="#example-invoices">("Example invoices")</a>.</p>
<h3 id="what-will-be-new-in-the-may-invoice"><a href="#what-will-be-new-in-the-may-invoice" aria-label="what will be new in the may invoice permalink"></a>What will be new in the May invoice?</h3>
<p>By the time you get your May invoice, the transition period will be finished.</p>
<p>The May invoice will show you the products that you used in April. For hourly-based products, you will see how many hours you used each product for April. If you have used the product for the entire month of April, you will see the normal monthly price. If you use the product for less than a month, and the hourly calculation is less than the monthly total, we will charge you the smaller hourly-based amount.</p>
<p>For more details, please look at the section below <a href="#example-invoices">("Example invoices")</a>.</p>
<h3 id="why-didnt-i-get-an-invoice-yet-for-april"><a href="#why-didnt-i-get-an-invoice-yet-for-april" aria-label="why didnt i get an invoice yet for april permalink"></a>Why didn't I get an invoice yet for April?</h3>
<p>There may be a one-time delay in when we send you your April invoice. We apologize for that in advance and ask you for your understanding. Naturally, we will extend the time that you will have to pay your April invoice. In the months following April, we will send you invoices regularly and on time.</p>
<h3 id="why-am-i-now-receiving-my-invoice-on-a-different-day-of-the-month"><a href="#why-am-i-now-receiving-my-invoice-on-a-different-day-of-the-month" aria-label="why am i now receiving my invoice on a different day of the month permalink"></a>Why am I now receiving my invoice on a different day of the month?</h3>
<p>We want to provide you with better and quicker customer service in the future when you have billing questions. That's why we have decided to spread out the days of the month when we send out invoices to customers. You will always receive your invoice on the same day of the month. But this day will be different from customer to customer. This will allow our support team to answer billing questions more quickly.</p>
<p>We sent you an email informing you about this change; it had the subject line "Changes to the billing model".  We sent you this email between 29 February and 15 March. You can find a copy of this email <a href="#email-from-hetzner">below</a>. You can find your new billing day by going to <a href="https://accounts.hetzner.com/invoice" target="_blank" rel="nofollow noopener noreferrer">your account</a>.</p>
<h3 id="example-invoices"><a href="#example-invoices" aria-label="example invoices permalink"></a>Example invoices</h3>
<p>Example: You have two servers, Server A and Server B under the old billing model.</p>
<p>Server A had a service period of 21 February to 20 March.
Server B had a service period of 27 January to 26 February.</p>
<p>In <strong>February</strong> you received, as usual, an invoice for both servers with their two different service periods:
<span>
      <span></span>
  <img alt="alt text" title="alt text" src="https://docs.hetzner.com/static/89789ecba094922b409ea2f170148fc6/5a190/example-invoice-1-EN.png" srcset="https://docs.hetzner.com/static/89789ecba094922b409ea2f170148fc6/772e8/example-invoice-1-EN.png 200w,
https://docs.hetzner.com/static/89789ecba094922b409ea2f170148fc6/e17e5/example-invoice-1-EN.png 400w,
https://docs.hetzner.com/static/89789ecba094922b409ea2f170148fc6/5a190/example-invoice-1-EN.png 800w,
https://docs.hetzner.com/static/89789ecba094922b409ea2f170148fc6/77800/example-invoice-1-EN.png 855w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy" decoding="async">
    </span></p>
<p>In <strong>March</strong>, you will NOT see any products on the invoice that will have a service period that extends into April 2024.</p>
<p>To be specific in this example, only Server B would appear on March's invoice because its service period does not fall into April. It only goes from 27 February to 26 March.</p>
<p>Server A, on the other hand, has a service period that would extend into April. So it would NOT be calculated on the March 2024 invoice. That's why the invoice for this example for March would be smaller.</p>
<p><span>
      <span></span>
  <img alt="alt text" title="alt text" src="https://docs.hetzner.com/static/b5273ad5ad121d8faebe4cb32be22ee9/5a190/example-invoice-2-EN.png" srcset="https://docs.hetzner.com/static/b5273ad5ad121d8faebe4cb32be22ee9/772e8/example-invoice-2-EN.png 200w,
https://docs.hetzner.com/static/b5273ad5ad121d8faebe4cb32be22ee9/e17e5/example-invoice-2-EN.png 400w,
https://docs.hetzner.com/static/b5273ad5ad121d8faebe4cb32be22ee9/5a190/example-invoice-2-EN.png 800w,
https://docs.hetzner.com/static/b5273ad5ad121d8faebe4cb32be22ee9/3cd52/example-invoice-2-EN.png 857w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy" decoding="async">
    </span></p>
<p>Now let's imagine that you order another server, Server C, in March, and Hetzner gives you access to the server on 15 March.</p>
<p>The <strong>April</strong> invoice will be the first retro-active invoice. It will include the service period of March for any products that have not already been calculated in March's invoice:</p>
<p><span>
      <span></span>
  <img alt="alt text" title="alt text" src="https://docs.hetzner.com/static/d1c619b581d1ba278193c9350996ef44/5a190/example-invoice-3-EN.png" srcset="https://docs.hetzner.com/static/d1c619b581d1ba278193c9350996ef44/772e8/example-invoice-3-EN.png 200w,
https://docs.hetzner.com/static/d1c619b581d1ba278193c9350996ef44/e17e5/example-invoice-3-EN.png 400w,
https://docs.hetzner.com/static/d1c619b581d1ba278193c9350996ef44/5a190/example-invoice-3-EN.png 800w,
https://docs.hetzner.com/static/d1c619b581d1ba278193c9350996ef44/3cd52/example-invoice-3-EN.png 857w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy" decoding="async">
    </span></p>
<ul>
<li>Server A for 21-31 March (previous invoice calculated in February)</li>
<li>Server B for 27-31 March (previous invoice calculated in March)</li>
<li>Server C for 15-31 March (new product; first invoice)</li>
</ul>
<p>The calculation for these invoices is based on hourly usage.</p>
<p>Now let's imagine that you cancelled Server A and that cancellation takes effect on 31 March. To replace this server, you order a new one, Server D, which Hetzner gives you access to on 20 April.</p>
<p>The invoice for <strong>May</strong> will include the service period from the previous month, April. So you would see the full service period for April listed for each server. Since you used Server B and Server C for the whole month, you would see the full monthly price there. And since you only used Server D for part of the month of April, you would see the calculation there based on hourly usage.</p>
<p><span>
      <span></span>
  <img alt="alt text" title="alt text" src="https://docs.hetzner.com/static/d31a31bc0ad114919b14365313c9dd52/5a190/example-invoice-4-EN.png" srcset="https://docs.hetzner.com/static/d31a31bc0ad114919b14365313c9dd52/772e8/example-invoice-4-EN.png 200w,
https://docs.hetzner.com/static/d31a31bc0ad114919b14365313c9dd52/e17e5/example-invoice-4-EN.png 400w,
https://docs.hetzner.com/static/d31a31bc0ad114919b14365313c9dd52/5a190/example-invoice-4-EN.png 800w,
https://docs.hetzner.com/static/d31a31bc0ad114919b14365313c9dd52/3cd52/example-invoice-4-EN.png 857w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy" decoding="async">
    </span></p>
<h2 id="questions-about-your-invoices-and-payments"><a href="#questions-about-your-invoices-and-payments" aria-label="questions about your invoices and payments permalink"></a>Questions about your invoices and payments</h2>
<h3 id="can-i-change-the-date-that-hetzner-issues-my-invoice"><a href="#can-i-change-the-date-that-hetzner-issues-my-invoice" aria-label="can i change the date that hetzner issues my invoice permalink"></a>Can I change the date that Hetzner issues my invoice?</h3>
<p>Unfortunately, no. For the foreseeable future, it will not be possible to change the date that we issue your invoice to you. We're sorry about that.</p>
<h3 id="how-precisely-does-hetzner-calculate-the-hourly-billing"><a href="#how-precisely-does-hetzner-calculate-the-hourly-billing" aria-label="how precisely does hetzner calculate the hourly billing permalink"></a>How precisely does Hetzner calculate the hourly billing?</h3>
<p>The beginning of the hourly billing starts as soon as the product becomes available to you. We always round up when calculating the hourly use. If you only use the product for a few minutes, we will charge you a full hour. If you use the product for close to a month, and the montly price is cheaper, we will always charge you the cheaper monthly price rather than a higher hourly price.</p>
<h3 id="when-will-hetzner-charge-me-the-hourly-price"><a href="#when-will-hetzner-charge-me-the-hourly-price" aria-label="when will hetzner charge me the hourly price permalink"></a>When will Hetzner charge me the hourly price?</h3>
<p>We will always use the hourly price when it saves you money, meaning when you have used a product for less than a month, and the total hourly price is less than the monthly price.</p>
<h3 id="when-does-the-time-for-the-hourly-price-start"><a href="#when-does-the-time-for-the-hourly-price-start" aria-label="when does the time for the hourly price start permalink"></a>When does the time for the hourly price start?</h3>
<p>It starts when Hetzner makes the product you ordered available to you. This is true even for products that you use for just a short period of time.</p>
<h3 id="can-i-pay-in-yearly-payment-periods"><a href="#can-i-pay-in-yearly-payment-periods" aria-label="can i pay in yearly payment periods permalink"></a>Can I pay in yearly payment periods?</h3>
<p>Unfortunately not. In the new system, we only allow monthly payments. However, you can make automated payments with two different payment options to help make it easier to make your payments. You can do automated payments using SEPA bank transfers or credit cards.</p>
<p>Important note: It is not always possible to do automated payments. There may be some exceptions.</p>
<h3 id="email-from-hetzner"><a href="#email-from-hetzner" aria-label="email from hetzner permalink"></a>Email from Hetzner</h3>
<p>I don't have the email from Hetzner about the new billing structure at hand.
What is changing?
Starting in March 2024, almost all of our products will have consumption-based and hour-based billing, similar to our Cloud products.</p>
<p>What does this mean for you?</p>
<p>Consumption-based billing: The invoices for these products is based on the service we provide. This means you always receive an invoice for the previous month.</p>
<p>Hour-based billing: Billing is based on the actual usage time in hours. There are some exceptions: products with an annual fee (domains and SSL certificates) and licences. These products' invoices are based on the entire calendar month regardless of when during the month you order them. If you use the products for a whole month, you will be charged the monthly price as usual.</p>
<p>What is important during the changeover phase in March and April?</p>
<p>During the changeover phase, your products will be charged pro rata (based on the proportion of the month). This may result in different invoice amounts for March and April. The changeover will happen automatically. You do not need to take further action. Your monthly price will not change.</p>
<p>What is important after the changeover?</p>
<p>We want to be able to offer you even better customer service in the future. For that reason, we want to change the date of your invoice. This will make it easier for us to quickly answer questions about your invoices.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CT scans show how Heinz's new ketchup cap depends on shear-thinning principles (243 pts)]]></title>
            <link>https://www.lumafield.com/article/heinzs-sustainable-ketchup-cap</link>
            <guid>39547109</guid>
            <pubDate>Thu, 29 Feb 2024 07:23:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lumafield.com/article/heinzs-sustainable-ketchup-cap">https://www.lumafield.com/article/heinzs-sustainable-ketchup-cap</a>, See on <a href="https://news.ycombinator.com/item?id=39547109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Heinz has taken a major step forward for sustainable packaging with the introduction of its first fully recyclable ketchup cap, made possible through a pioneering collaboration with <a href="https://www.berryglobal.com/en/news/articles/kraft-heinz-introduces-first-fully-recyclable-ketchup-cap-with-help-from-berry-global">Berry Global</a>. Combining complex engineering with simple materials, Heinz’s achievement offers a model for manufacturers in the <a href="https://www.lumafield.com/industries/consumer-packaged-goods-cpg">consumer packaged goods (CPG)</a> space to strive for waste reduction by designing more environmentally-friendly products.</p><p>Industrial CT is the perfect tool for exploring the intricacies of Heinz's new cap design without damaging it, even while it’s fully assembled and closed. Let’s take a look.</p><h3>Mono-material construction</h3><p>The old cap featured a silicone valve, which posed recycling challenges. The new cap's uniform composition of polypropylene (PP) simplifies recycling and can be accepted by any facility that processes plastic #5. Currently only about 3% of PP products are being recycled in the United States, but it is becoming more widely accepted. The new cap appears as a uniform color in Voyager’s range map, indicating that it’s entirely made of the same material. Compare it to the old cap, whose silicone valve is denser than the surrounding plastic.</p><figure><p><img src="https://assets-global.website-files.com/63e15418201b6e2a5cabb911/65cbc42a80870f285b2d0c15_4fHOwfEnbmCcBVmnYkFB_8Yt0l5Nos-j_Zh6BBRvX5i688yB0SuadxUlj4lQI9ei4m1n0bYLt2qS3Oy8Hw3eVAXXIVp9mK4mla6hsoEeug2iWtnd0VDZpHm7v2u8iUhUm-fpP9SBhdSm-CWdLB2HqGY.png" alt=""></p><figcaption>The dense silicone ring (left) presents obstacles for recycling. The new mono-material cap (right) is of a uniform density.</figcaption></figure><h3>Innovative valve design</h3><p>The new design leverages ketchup's shear-thinning property to dispense the perfect amount. Ketchup requires a specific amount of pressure to flow. When the bottle is squeezed, it moves through the outer channels where the wall separating them from the inner channels plays a crucial role. The wall prevents the ketchup from flowing back and directs it toward the antechamber, building the necessary pressure for the ketchup to pass through the nozzle efficiently.</p><p>Once the squeezing stops, the ketchup's viscosity increases, preventing drips and mess. This design ensures a clean and controlled dispense of the product.</p><figure><p><img src="https://assets-global.website-files.com/63e15418201b6e2a5cabb911/65cbc42a7b0050f7e8c59d86_CuLl6RDCU0dCWfdZnp8_4ofr0EsloqxIcsUNWJfHyHov9INxT77P_Nc9CpKqyY9hgS0Q3HuCaABFJXu1rtT6U7c0S4m9v83eZMlqdEz8qHTYPg40ZHjyA0sFZnAJW-J-Jx7B1dK41isnpiKOLGjaTpk.png" alt=""></p><figcaption>Views from below (left) and above (right) of the Heinz ketchup cap's valve channels</figcaption></figure><h3>Industrial CT and sustainability</h3><p>Developing sustainable packaging can present a significant engineering challenge. Recyclable plastics often don’t perform as well as their non-recyclable counterparts, and reducing material usage can mean that safety factors are reduced as well. Effective, sustainable packaging requires careful design and lots of fine tuning.</p><p>Industrial CT plays a pivotal role in the development of sustainable packaging, offering a non-invasive method to analyze, refine, and perfect packaging solutions. By reducing the need for physical prototypes, CT scanning accelerates the development process, cuts down on waste, and helps avoid the costs associated with scrapped prototypes and recalled products. It embodies the convergence of innovation and sustainability, offering a blueprint for the packaging industry's next steps.</p><p>Heinz's recyclable cap is more than just an innovation; it's a statement of intent, reflecting a broader commitment to environmental sustainability. The cap's successful redesign, fueled by a $1.2 million investment and extensive testing, demonstrates the potential for significant waste reduction—up to 300 million plastic caps annually—and a future where packaging is fully recyclable, reusable, or compostable.</p><h3>Learn more</h3><p>Download our free white paper <strong>Removing Obstacles to Sustainable Packaging</strong> and discover how industrial x-ray CT can help packaging engineers create solutions that work.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SEC Investigating Whether OpenAI Investors Were Misled (123 pts)]]></title>
            <link>https://www.wsj.com/tech/sec-investigating-whether-openai-investors-were-misled-9d90b411</link>
            <guid>39546412</guid>
            <pubDate>Thu, 29 Feb 2024 04:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/sec-investigating-whether-openai-investors-were-misled-9d90b411">https://www.wsj.com/tech/sec-investigating-whether-openai-investors-were-misled-9d90b411</a>, See on <a href="https://news.ycombinator.com/item?id=39546412">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/sec-investigating-whether-openai-investors-were-misled-9d90b411: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[New jet engine enables efficiency at every speed for cheaper orbital launches (148 pts)]]></title>
            <link>https://twitter.com/k2pilot/status/1763007610993991722</link>
            <guid>39546333</guid>
            <pubDate>Thu, 29 Feb 2024 04:11:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/k2pilot/status/1763007610993991722">https://twitter.com/k2pilot/status/1763007610993991722</a>, See on <a href="https://news.ycombinator.com/item?id=39546333">Hacker News</a></p>
Couldn't get https://twitter.com/k2pilot/status/1763007610993991722: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[I keep making things out of checkboxes (2021) (178 pts)]]></title>
            <link>https://www.bryanbraun.com/2021/09/21/i-keep-making-things-out-of-checkboxes/</link>
            <guid>39546158</guid>
            <pubDate>Thu, 29 Feb 2024 03:34:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bryanbraun.com/2021/09/21/i-keep-making-things-out-of-checkboxes/">https://www.bryanbraun.com/2021/09/21/i-keep-making-things-out-of-checkboxes/</a>, See on <a href="https://news.ycombinator.com/item?id=39546158">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>Something happened earlier this year where I got on a run making checkbox animations and just couldn’t stop.</p>
<p>A bit of background: back in pre-pandemic 2020, I went to <a href="https://www.recurse.com/">the Recurse Center</a> for a week and built <a href="https://www.bryanbraun.com/checkboxland/">Checkboxland</a>, a JavaScript library that lets you display text and animations on a checkbox grid. It was a fun little project. I made some demos, <a href="https://www.bryanbraun.com/2020/06/06/checkboxland/">blogged about it</a>, and ultimately put it on the shelf where I didn’t touch it for about a year.</p>
<p>Eventually, I was feeling desperate for a fun coding diversion so I picked it back up again. I wanted to try making better and more complex animations so I started building a ripple effect, and got hooked.</p>
<h2 id="mathematical-animations">Mathematical Animations</h2>
<figure>
<img src="https://www.bryanbraun.com/assets/images/cbl-ripple.gif" loading="lazy" alt="A ripple animation made with html checkboxes.">
<figcaption>The ripple animation. See <a href="https://www.bryanbraun.com/2021/04/15/ripple-animation-in-javascript/">my write-up about ripples</a> for more details.</figcaption>
</figure>
<p>Building the ripple forced me to dig into some animation math. I soon realized that I could use similar techniques to build other animations, including these ones:</p>
<p>
<img src="https://www.bryanbraun.com/assets/images/cbl-spiral.gif" loading="lazy" alt="A spiral animation made with html checkboxes">
</p>
<p>
<img src="https://www.bryanbraun.com/assets/images/cbl-pinwheel.gif" loading="lazy" alt="A pinwheel animation made with html checkboxes">
</p>
<p>
<img src="https://www.bryanbraun.com/assets/images/cbl-circles.gif" loading="lazy" alt="A checkerboard animation made with html checkboxes">
</p>
<p>Whenever I’d show someone an animation like this, they’d often try to click the checkboxes to see what would happen. This never did anything—the animation would just override their clicks.</p>
<p>That was pretty disappointing, so I wanted to try making animations that responded to clicks.</p>
<h2 id="interactive-animations">Interactive Animations</h2>
<figure>
<img src="https://www.bryanbraun.com/assets/images/cbl-lasers.gif" loading="lazy" alt="A laser animation made with html checkboxes.">
<figcaption>A "laser" animation. <a href="https://www.bryanbraun.com/checkboxland/docs/demos/lasers/">Try it here</a>.</figcaption>
</figure>
<figure>
<img src="https://www.bryanbraun.com/assets/images/cbl-pulse.gif" loading="lazy" alt="A pulse animation made with html checkboxes.">
<figcaption>A "pulse" animation. <a href="https://www.bryanbraun.com/checkboxland/docs/demos/pulse/">Try it here</a>.</figcaption>
</figure>
<p>The more interactive demos I made, the more ideas I had. I could make games! <a href="https://www.bryanbraun.com/checkboxland/docs/demos/snake/">Snake</a>, Pong, Tetris!</p>
<p>But before I got too far down that path, another thought caught hold in my mind. If I could display any image, then I wouldn’t have to go through the laborious process of defining every checkbox manually or coming up with an algorithm for the scene I wanted.</p>
<h2 id="images">Images</h2>
<p>Converting images seemed tricky so I sat on the idea for while until I came across <a href="https://www.jonathan-petitcolas.com/2017/12/28/converting-image-to-ascii-art.html">this excellent article on converting images into ASCII text</a>. A short while later I was converting images:</p>
<p><img src="https://www.bryanbraun.com/assets/images/cbl-nike.png" alt="The Nike logo displayed side-by-side with an html checkbox version"></p>
<p><img src="https://www.bryanbraun.com/assets/images/cbl-apple.png" alt="The Apple logo displayed side-by-side with an html checkbox version"></p>
<p>I soon realized that converting images gets you 90% of the way to converting video so that became my next task.</p>
<h2 id="videos">Videos</h2>
<figure>
<img src="https://www.bryanbraun.com/assets/images/cbl-video.gif" loading="lazy" alt="A video animation displayed side-by-side with an html checkbox version.">
<figcaption>An mp4 video (left) powering a checkbox animation (right). <a href="https://www.bryanbraun.com/checkboxland/docs/demos/video-test/">Try other videos (or upload your own) here</a>.</figcaption>
</figure>
<p>Soon I had extended the Checkboxland API so I could load any video (like ones from <a href="https://giphy.com/">giphy</a>) and instantly generate a checkbox version. Now checkbox animations were trivial.</p>
<p>This also meant I could display webcam data, which got a lot of attention on Twitter when I shared it:</p>
<blockquote data-dnt="true">
— Bryan Braun (@BryanEBraun) <a href="https://twitter.com/BryanEBraun/status/1435955497358741506?ref_src=twsrc%5Etfw">September 9, 2021</a>
</blockquote>

<p>Finally, my co-worker Reed told me about a challenge where people try to play the animated video “Bad Apple” on various obscure computing environments (see <a href="https://www.youtube.com/playlist?list=PLajlU5EKJVdonUGTEc7B-0YqElDlz9Sf9">a bunch of examples here</a>). It sounded fun so I went ahead and put together a youtube video for that.</p>
<figure>
<iframe width="640" height="360" src="https://www.youtube.com/embed/ZGvXdYXami4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<figcaption><a href="https://www.bryanbraun.com/checkboxland/docs/demos/bad-apple/">Play the in-browser version here</a>.</figcaption>
</figure>
<hr>
<p>This whole process has been fun but I really ought to stop.</p>
<p>I got <a href="https://xkcd.com/356/">nerd sniped</a>, hard. Sure it’s harmless fun, but I’m starting to feel guilty spending months tinkering on these things when I’ve got the tools and skills to put actually useful stuff into the world. <a href="https://www.bryanbraun.com/2018/02/18/the-cure-for-boredom-is-superpowers/">I feel like Superman</a>, using his powers to fry an egg.</p>
<p>Plus, if I keep doing this then I’m going to end up known as “the checkbox guy.” That’s not exactly marketable but I guess it could be worse.</p>
<p>Fortunately, it feels like I’m starting to exhaust the interesting things I could build in this format. At some point it’s like “dude, we get it, you can make anything with checkboxes.” I still have a few lingering ideas though… maybe it’s like a controlled forest fire and I should just let myself keep making these things until it burns itself out.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starlink terminal revision 4: overview and tests (139 pts)]]></title>
            <link>https://olegkutkov.me/2024/02/12/starlink-terminal-revision-4-overview-and-tests/</link>
            <guid>39546120</guid>
            <pubDate>Thu, 29 Feb 2024 03:25:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olegkutkov.me/2024/02/12/starlink-terminal-revision-4-overview-and-tests/">https://olegkutkov.me/2024/02/12/starlink-terminal-revision-4-overview-and-tests/</a>, See on <a href="https://news.ycombinator.com/item?id=39546120">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-3256">

	<div>
			<p><img decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_test_thumb.jpg" alt="" width="150" height="113">Revision 4 is the new version of the Starlink user terminal. As of February 2024, the new version is only available in the US.<br>
I decided to test the new hardware and compare it to the well-known REV3 (a.k.a. Gen2/V2 or “Standard Actuated”).</p>


<h3>Revision 4</h3>
<p>If you don’t understand why this model is called REV4, I explain it in the unboxing video.<br>
Here is my unboxing and initial review of the new Starlink user terminal:</p>
<p><iframe title="Starlink REV4 (V3) unbox and quick review" width="850" height="478" src="https://www.youtube.com/embed/WESdXlQdXsw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3><strong>Revision 3 and Revision 4 specifications</strong></h3>
<p>This is a comparison of basic specifications from the Starlink website.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev3_rev4_basic_specs_site.jpg"><img fetchpriority="high" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev3_rev4_basic_specs_site-1024x719.jpg" alt="" width="850" height="597" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev3_rev4_basic_specs_site-1024x719.jpg 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rev3_rev4_basic_specs_site-400x281.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev3_rev4_basic_specs_site-768x539.jpg 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rev3_rev4_basic_specs_site.jpg 1502w" sizes="(max-width: 850px) 100vw, 850px"></a></p>
<h3>Breaking into</h3>
<p>The IP rating is higher because the new housing is not ultrasonically welded anymore. It has a complex construction and is glued with an automotive-class sealant.<br>
Unfortunately, this housing is quite hard to disassemble without partial destruction.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_teardown_collage.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_teardown_collage-1024x770.jpg" alt="" width="850" height="639" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_teardown_collage-1024x770.jpg 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_teardown_collage-400x300.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_teardown_collage-768x577.jpg 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_teardown_collage.jpg 1213w" sizes="(max-width: 850px) 100vw, 850px"></a></p>
<p>At this moment, I have no idea how to seal it back. I’ll share more details on the teardown process in future posts.</p>
<h3>Revision 4 PCB</h3>
<p>The new Starlink terminal has a resigned PCB with all-new antenna electronics.</p>
<p>The next-gen Shiraz digital beamformers support more RF channels. There are only six beamformer ICs (rev3 has 16 chips). FEM elements are connected in a daisy chain and combined by groups. I didn’t do detailed reverse-engineering yet.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_pcb_overview.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_pcb_overview-1024x749.jpg" alt="" width="850" height="622" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_pcb_overview-1024x749.jpg 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_pcb_overview-400x292.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_pcb_overview-768x562.jpg 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_pcb_overview-1536x1123.jpg 1536w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_pcb_overview.jpg 1853w" sizes="(max-width: 850px) 100vw, 850px"></a></p>
<p>SoC, RAM, and eMMC are the same as in REV3.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_soc_ram_flash.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_soc_ram_flash.jpg" alt="" width="800" height="533" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_soc_ram_flash.jpg 900w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_soc_ram_flash-400x267.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_soc_ram_flash-768x512.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a></p>
<p>The main difference is the PoE circuit. Now, it’s on a separate board. This PCB receives 48 PoE and steps it down to 12V and 3.3V. STM32 MCU controls PoE negotiation and board operation.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_poe_board.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_poe_board.jpg" alt="" width="784" height="453" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_poe_board.jpg 900w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_poe_board-400x231.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_poe_board-768x444.jpg 768w" sizes="(max-width: 784px) 100vw, 784px"></a></p>
<p>I will not focus on further reverse engineering in this article. It’s just an overview.</p>
<h3>REV4 vs REV3: basic tests</h3>
<p>Location: Kyiv, Ukraine<br>
Test date: 23 January 2024<br>
Time: 4 p.m.<br>
Starlinks firmware version: a8a61034-4207-4484-b8ea-4c4c01f07cde<br>
Standard user setup with routers. No bypass mode.<br>
Conditions: clear sky</p>
<p>Please watch my initial and basic tests below. I’m comparing startup time, power consumption, and network speed. Snow melt mode was disabled.</p>
<p><iframe loading="lazy" title="First tests of the Starlink REV4 (V3/Gen3) in Ukraine" width="850" height="478" src="https://www.youtube.com/embed/hWPMpJrjd1g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p>During these synthetic tests, the new REV4 performed better. The total power consumption of the REV4 terminal and the new REV3 router was under 100W. This meets the stated specifications. But without the snow melt mode. Please note this.</p>

<table id="tablepress-20">
<thead>
<tr>
	<th>Parameter</th><th>Starlink REV3</th><th>Starlink REV4</th>
</tr>
</thead>
<tbody>
<tr>
	<td>Download speed, Mbps</td><td>199</td><td>307</td>
</tr>
<tr>
	<td>Upload speed, Mbps</td><td>10</td><td>15</td>
</tr>
<tr>
	<td>Average ping, ms</td><td>93</td><td>88</td>
</tr>
<tr>
	<td>Jitter, ms</td><td>111.9</td><td>9.2</td>
</tr>
<tr>
	<td>Max power consumption, W</td><td>55</td><td>100</td>
</tr>
</tbody>
</table>
<!-- #tablepress-20 from cache -->
<p>I believe that most of the differences were caused by routers.</p>
<h3>REV4 vs REV3: advanced tests</h3>
<p>Location: Kyiv, Ukraine<br>
Test date: 4 February 2024<br>
Time: 3 p.m.<br>
REV3 firmware version: a8a61034-4207-4484-b8ea-4c4c01f07cde.uterm.release<br>
REV4 firmware version: c4718913-5c91-4cf2-b31a-45c187e4bca2.uterm_manifest.release<br>
No routers were used.<br>
Conditions: cloudy sky</p>
<p>During the second test, I used <a href="https://flent.org/">flent</a> to run <a href="https://www.bufferbloat.net/projects/codel/wiki/RRUL_test_suite/">rrul</a> to <code>netperf-eu.bufferbloat.net</code> and collected information about bandwidth and response fluctuations. Additionally, I ran a <a href="https://speed.cloudflare.com/">Cloudflare speed test</a>. All tests were run separately for both Dishys, except one test where I ran the Cloudflare test simultaneously on both devices.</p>
<p>The video of the tests is currently editing.</p>
<p>During the tests, I used two GEN1 PoE bricks and two laptops with direct Ethernet connections.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_rev3_second_test_layout.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_rev3_second_test_layout-1024x544.jpg" alt="" width="664" height="353" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_rev3_second_test_layout-1024x544.jpg 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_rev3_second_test_layout-400x213.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_rev3_second_test_layout-768x408.jpg 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_rev3_second_test_layout-1536x817.jpg 1536w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_rev3_second_test_layout.jpg 1614w" sizes="(max-width: 664px) 100vw, 664px"></a></p>
<p>Test command line: <code>flent -p all_scaled -l 60 -H netperf-eu.bufferbloat.net -t "rrul_"$DISHY_NAME -o rrul_$DISHY_NAME.png</code></p>
<p><strong>Results for REV3, single run:</strong></p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev3.png"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev3-1024x549.png" alt="" width="850" height="456" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev3-1024x549.png 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev3-400x215.png 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev3-768x412.png 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev3.png 1281w" sizes="(max-width: 850px) 100vw, 850px"></a></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/rrul-2024-02-04T145950.580729.rrul_rev3.flent">Download the Flent file.</a></p>
<p><strong>Results for REV4, single run:</strong></p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4.png"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4-1024x549.png" alt="" width="850" height="456" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4-1024x549.png 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4-400x215.png 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4-768x412.png 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4.png 1281w" sizes="(max-width: 850px) 100vw, 850px"></a></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/rrul-2024-02-04T151232.341139.rrul_rev4.flent">Download the Flent file.</a></p>
<p>As you can see, it’s pretty good! The ping plot fluctuates around 100ms without any crazy jumps.</p>
<p>Additionally,<strong> REV3 2 TCP Streams upload and download vs. ping.</strong><strong><br>
</strong></p>
<p>Test command for upload: <code>flent tcp_2up -p totals -l 60 -H netperf-eu.bufferbloat.net -t "rrul_"$DISHY_NAME -o rrul_$DISHY_NAME.png</code><br>
Test command for download: <code>flent tcp_2down -p totals -l 60 -H netperf-eu.bufferbloat.net -t "rrul_"$DISHY_NAME -o rrul_$DISHY_NAME.png</code></p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev3_netperf_2_streams_ud.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev3_netperf_2_streams_ud-1024x330.jpg" alt="" width="797" height="257" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev3_netperf_2_streams_ud-1024x330.jpg 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rev3_netperf_2_streams_ud-400x129.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev3_netperf_2_streams_ud-768x248.jpg 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rev3_netperf_2_streams_ud-1536x495.jpg 1536w, https://olegkutkov.me/wp-content/uploads/2024/02/rev3_netperf_2_streams_ud-2048x660.jpg 2048w" sizes="(max-width: 797px) 100vw, 797px"></a></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/tcp_2down-2024-02-04T150224.790786.tpc_2_download_rev3.flent">Download the Flent file for 2 streams down.</a><br>
<a href="https://olegkutkov.me/starlink_rev4_second_test/tcp_2up-2024-02-04T150457.081631.tpc_2_upload_rev3.flent">Download the Flent file for 2 streams up.</a></p>
<p><strong>REV4 2 TCP Streams upload and download vs. ping</strong></p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_netperf_2_streams_ud.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_netperf_2_streams_ud-1024x330.jpg" alt="" width="797" height="257" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_netperf_2_streams_ud-1024x330.jpg 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_netperf_2_streams_ud-400x129.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_netperf_2_streams_ud-768x248.jpg 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_netperf_2_streams_ud-1536x495.jpg 1536w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_netperf_2_streams_ud-2048x660.jpg 2048w" sizes="(max-width: 797px) 100vw, 797px"></a></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/tcp_2down-2024-02-04T151503.399911.tpc_2_download_rev4.flent">Download the Flent file for 2 streams down.</a><br>
<a href="https://olegkutkov.me/starlink_rev4_second_test/tcp_2up-2024-02-04T151733.796919.tpc_2_upload_rev4.flent">Download the Flent file for 2 streams up.</a></p>
<p>I noticed a slight packet loss on both devices. That looks okay. For some reason, REV4 had a higher loss rate.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/packet_loss_rev4_vs_rev3.png"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/packet_loss_rev4_vs_rev3.png" alt="" width="580" height="383" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/packet_loss_rev4_vs_rev3.png 791w, https://olegkutkov.me/wp-content/uploads/2024/02/packet_loss_rev4_vs_rev3-400x264.png 400w, https://olegkutkov.me/wp-content/uploads/2024/02/packet_loss_rev4_vs_rev3-768x507.png 768w" sizes="(max-width: 580px) 100vw, 580px"></a>No more problems were noticed with either device.</p>
<p><strong>REV4 power consumption</strong></p>
<p>I ran the new terminal with the Snowmelt mode ON and found this device very power-hungry. The consumption jumped way higher than I expected – 186W!<br>
Note this if you consider running this device with an autonomous power supply.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_power_consumption_snow_melt_mode_on_1.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_power_consumption_snow_melt_mode_on_1.jpg" alt="" width="432" height="281" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_power_consumption_snow_melt_mode_on_1.jpg 750w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_power_consumption_snow_melt_mode_on_1-400x260.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_power_consumption_snow_melt_mode_on_1-345x225.jpg 345w" sizes="(max-width: 432px) 100vw, 432px"></a></p>
<h3>Additional tests for REV4</h3>
<p>In a few days, I decided to run additional tests with the new terminal.<br>
It was 2 a.m., curfew. I wasn’t able to visit my previous test site. So, I put the terminal outside my window and tested it with many obstructions.</p>
<p>It started snowing during testing, so I measured the power consumption again.</p>
<p>Location: Kyiv, Ukraine<br>
Test date: 8-9 February 2024<br>
Time: 2 a.m.<br>
Firmware version: c4718913-5c91-4cf2-b31a-45c187e4bca2.uterm_manifest.release<br>
Two modes were tested: the Gen3 router and the Gen3 router in bypass mode.<br>
Conditions: cloudy sky, <strong>snow</strong></p>
<p>The initial synthetic speed test showed some fantastic results despite not ideal conditions. This is the speed record so far!</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_fantastic_speed_test.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_fantastic_speed_test.jpg" alt="" width="561" height="299" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_fantastic_speed_test.jpg 750w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_fantastic_speed_test-400x213.jpg 400w" sizes="(max-width: 561px) 100vw, 561px"></a></p>
<p>Power consumption during the test remained around <strong>85W</strong>. Activation of the Snowmelt mode caused a crazy jump to <strong>200W</strong>. It wasn’t a fluctuation, but stable consumption during the test time.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_crazy_power_consumption.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_crazy_power_consumption.jpg" alt="" width="455" height="491" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_crazy_power_consumption.jpg 550w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_crazy_power_consumption-278x300.jpg 278w" sizes="(max-width: 455px) 100vw, 455px"></a></p>
<p>This is even higher than the actual REV4 PSU advertised consumption (197W).</p>
<p>I ran <code>rrul</code> 5-minute tests in two modes: with the Gen3 router and the Gen3 router in bypass mode. There were interruptions during the tests.</p>
<p>Test command: <code>flent rrul -p all_scaled --socket-stats -s 0.5 -l 300 -H netperf-eu.bufferbloat.net -t "rrul_"$DISHY_NAME -o rrul_$DISHY_NAME.png</code></p>
<p><strong>Results for the first 5-minute run with the router in normal mode:</strong></p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_with_obstructions.png"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_with_obstructions-1024x549.png" alt="" width="850" height="456" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_with_obstructions-1024x549.png 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_with_obstructions-400x215.png 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_with_obstructions-768x412.png 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_with_obstructions.png 1281w" sizes="(max-width: 850px) 100vw, 850px"></a></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/rrul-2024-02-09T015217.788561.rrul_rev4_5min_with_obstructions.flent">Download the flent file.</a></p>
<p><strong>Results for the first 5-minute run with the router in bypass mode:</strong></p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_w_obstruct_router_bypass.png"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_w_obstruct_router_bypass-1024x549.png" alt="" width="850" height="456" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_w_obstruct_router_bypass-1024x549.png 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_w_obstruct_router_bypass-400x215.png 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_w_obstruct_router_bypass-768x412.png 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rrul_rev4_5min_w_obstruct_router_bypass.png 1281w" sizes="(max-width: 850px) 100vw, 850px"></a></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/rrul-2024-02-09T025405.192603.rrul_rev4_5min_w_obstruct_router_bypass.flent">Download the flent file.</a></p>
<h5>Update. February 18, 2024</h5>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release.png"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release-1024x549.png" alt="" width="762" height="409" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release-1024x549.png 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release-400x215.png 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release-768x412.png 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rrul_-_rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release.png 1281w" sizes="(max-width: 762px) 100vw, 762px"></a></p>
<p>The new firmware 5776ed0f-38b5-47bf-8ff4-d38f7d2c326b.<span>uterm_manifest.release performs slightly better in terms of latency and stability.</span></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/rrul-2024-02-18T203347.764414.rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release.flent.gz">Download the flent file, 300 seconds test.</a></p>
<p><a href="https://olegkutkov.me/starlink_rev4_second_test/rrul-2024-02-18T203033.230468.rev4_5776ed0f-38b5-47bf-8ff4-d38f7d2c326b_release.flent.gz">Download the flent file, 60 seconds test.</a></p>
<p>I haven’t reverse-engineered the new router yet. It looks like here we are dealing with the same software switch (Linux bridge) with all known problems.</p>
<p>On the other side. I noticed that the new antenna better picks up the signal in poor <strong>(snow and physical obstructions</strong>) conditions. This obviously makes it possible to achieve higher modulation rates.<br>
Please look at the obstruction map during the last test.</p>
<p><a href="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_last_test_obstruction_map.jpg"><img loading="lazy" decoding="async" src="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_last_test_obstruction_map-1024x529.jpg" alt="" width="670" height="346" srcset="https://olegkutkov.me/wp-content/uploads/2024/02/rev4_last_test_obstruction_map-1024x529.jpg 1024w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_last_test_obstruction_map-400x206.jpg 400w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_last_test_obstruction_map-768x396.jpg 768w, https://olegkutkov.me/wp-content/uploads/2024/02/rev4_last_test_obstruction_map.jpg 1170w" sizes="(max-width: 670px) 100vw, 670px"></a></p>
<p>I also noticed that the obstacle map was built quite quickly. But perhaps this is simply the result of a software update.</p>
<p>There will be more materials on the new terminal, so stay tuned.<br>
Thanks for reading.</p>
<p><span>Tagged <a href="https://olegkutkov.me/tag/rev3/" rel="tag">rev3</a>, <a href="https://olegkutkov.me/tag/rev4/" rel="tag">rev4</a>, <a href="https://olegkutkov.me/tag/starlink/" rel="tag">starlink</a>, <a href="https://olegkutkov.me/tag/test/" rel="tag">test</a></span>		</p></div>

</article></div>]]></description>
        </item>
    </channel>
</rss>