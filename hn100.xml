(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 24 Apr 2025 14:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I wrote to the address in the GPLv2 license notice (2022) (169 pts)]]></title>
            <link>https://code.mendhak.com/gpl-v2-address-letter/</link>
            <guid>43781888</guid>
            <pubDate>Thu, 24 Apr 2025 12:26:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://code.mendhak.com/gpl-v2-address-letter/">https://code.mendhak.com/gpl-v2-address-letter/</a>, See on <a href="https://news.ycombinator.com/item?id=43781888">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>Dealing with open source software, I regularly encounter many kinds of licenses — MIT, Apache, BSD, GPL being the most prominent — and I’ve taken time out to read them.  Of the many, the GNU General Public License (GPL) stands out the most.  It <a href="https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html">reads like a letter</a> to the reader rather than legalese, and feels quite in tune with the spirit of open source and software freedom.</p>
<p>Although GPLv3 is the most current version, I commonly encounter software that makes use of GPLv2.  I got curious about the last line in its license notice:</p>
<pre><code>You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
</code></pre>
<p>Why does this license notice have a physical address, and not a URL?  After all, even though the full license doesn’t often get included with software, it’s a simple matter to do a search and find the text of the GPLv2. Do people write to this address, and what happens if you do?</p>
<h2 id="asking-the-question-on-stack-exchange" tabindex="-1"><a href="#asking-the-question-on-stack-exchange">Asking the question on Stack Exchange</a></h2>
<p>I turned to the <a href="https://opensource.stackexchange.com/questions/12714/why-does-gplv2-include-a-mailing-address-51-franklin-street-in-the-license-not">Open Source Stack Exchange</a> and got a very helpful answer.  It’s because the GPLv2 was published in 1991, and most people were not online.  Most people would have acquired software through physical media (such as tape or floppies) rather than a download.</p>
<p>Considering the storage constraints back then, it wouldn’t be surprising if developers only included the license notice, and not the entire license.  It makes sense that the most common form of communication would have been through post.</p>
<p>The GPLv3, published in 2007, does contain a URL in the license notice since Internet usage was more widespread at the time.</p>
<h2 id="writing-to-them" tabindex="-1"><a href="#writing-to-them">Writing to them</a></h2>
<p>I decided to write to the address to see what would happen.  To do that, I would need some stamps and envelopes (I found one at my workplace) to send the request, and a self addressed enveloped with an <a href="https://en.wikipedia.org/wiki/International_reply_coupon">international reply coupon</a> to cover the cost of the reply.</p>
<p>I was disappointed to find out that the UK’s Royal Mail <a href="https://www.royalmail.com/reply-sender">discontinued international reply coupons in 2011</a>.  The only alternative that I could think of was to buy some US stamps.</p>
<h3 id="i-got-some-stamps" tabindex="-1"><a href="#i-got-some-stamps">I got some stamps</a></h3>
<p>The easiest place to look for US stamps was on Ebay.  I didn’t realize that I was stepping briefly into the world of philately; most stamp listings on Ebay were covered in phrases and terminology such as very fine grade, MNH (Mint Never Hinged), FDC (First Day Cover), NDC (No Die Cut), NDN (Nondenominated), and so on.  It’s pretty easy to glean that these are properties that collectors would be looking for.</p>
<p>I ordered what seemed to be a ‘global’ stamp, for the smallest but safest amount that I could (about £3.86).  The listing mentioned that it was ‘uncertified’ which was mildly unnerving, did that mean it was an invalid stamp? I decided to chance it, and quickly exited that world.</p>
<p>After a few weeks of waiting, I eventually received the ‘African Daisy global forever vert pair’ stamp which was round!  I should have noticed that the seller sent me the item using stamps at a much lower denomination that those I had ordered.  Oh well.</p>
<figure>
<a href="https://code.mendhak.com/assets/images/gpl-v2-address-letter/003a.jpg"><img src="https://code.mendhak.com/assets/images/gpl-v2-address-letter/003a.jpg" alt="" loading="lazy" title=""></a>
<a href="https://code.mendhak.com/assets/images/gpl-v2-address-letter/003b.jpg"><img src="https://code.mendhak.com/assets/images/gpl-v2-address-letter/003b.jpg" alt="" loading="lazy" title=""></a>
<figcaption>Ebay seller sent me some stamps</figcaption></figure>
<h3 id="i-prepared-the-request" tabindex="-1"><a href="#i-prepared-the-request">I prepared the request</a></h3>
<p>With the self addressed envelope ready, I wrote the request and addressed it to the GPLv2 address.  Luckily I did have some UK stamps available to send the letter with.</p>
<figure><a href="https://code.mendhak.com/assets/images/gpl-v2-address-letter/004a.jpg">
    <img src="https://code.mendhak.com/assets/images/gpl-v2-address-letter/004a.jpg" alt="" loading="lazy"></a>
    <figcaption>I wrote a letter</figcaption>
  </figure>
<p>Writing the address on the envelope was awkward, as I haven’t used a pen in several years; it took a few attempts and some wasted envelopes, printing the address would have taken less time.  But it was ready so I posted it in my nearest Royal Mail box.</p>
<h2 id="receiving-the-reply" tabindex="-1"><a href="#receiving-the-reply">Receiving the reply</a></h2>
<p>I had posted the letter in June 2022 and about five later weeks later, I received a reply.  The round stamps looked sufficiently stamped upon with wavy lines, known as <a href="https://en.wikipedia.org/wiki/Cancellation_(mail)">cancellation marks</a>, which are yet another thing that philatelists like to collect!</p>
<figure><a href="https://code.mendhak.com/assets/images/gpl-v2-address-letter/005a.jpg">
    <img src="https://code.mendhak.com/assets/images/gpl-v2-address-letter/005a.jpg" alt="" loading="lazy"></a>
    <figcaption>I received a reply</figcaption>
  </figure>
<p>Anyway the letter inside contained the full license text on 5 sheets of double-sided paper.</p>
<h3 id="the-paper-was-a-weird-size" tabindex="-1"><a href="#the-paper-was-a-weird-size">The paper was a weird size</a></h3>
<p>The first thing that came to attention, the paper that the text was printed on wasn’t an A4, it was smaller and not a size I was familiar with.  I measured it and found that it’s a US letter size paper at about 21.5cm x 27.9cm.  I completely forgot that the US, Canada, and a few other countries don’t follow the standard international paper sizes, even though I had <a href="https://code.mendhak.com/paper-sizes-standard/#some-paper-sizes-are-arbitrary">written about it</a> earlier.</p>
<h3 id="i-received-the-gpl-v3" tabindex="-1"><a href="#i-received-the-gpl-v3">I received the GPL v3</a></h3>
<p>There was a problem that I noticed right away, though: this text was from the GPL <em>v3</em>, not the GPL <em>v2</em>.  In my original request I had never mentioned the GPL version I was asking about.</p>
<figure>
<a href="https://code.mendhak.com/assets/images/gpl-v2-address-letter/006a.jpg"><img src="https://code.mendhak.com/assets/images/gpl-v2-address-letter/006a.jpg" alt="" loading="lazy" title=""></a>
<a href="https://code.mendhak.com/assets/images/gpl-v2-address-letter/006b.jpg"><img src="https://code.mendhak.com/assets/images/gpl-v2-address-letter/006b.jpg" alt="" loading="lazy" title=""></a>
<a href="https://code.mendhak.com/assets/images/gpl-v2-address-letter/006c.jpg"><img src="https://code.mendhak.com/assets/images/gpl-v2-address-letter/006c.jpg" alt="" loading="lazy" title=""></a>
<figcaption>GPL license</figcaption></figure>
<p>The original license notice makes no mention of GPL version either.  Should the fact that the license notice contained an address have been enough metadata or a clue, that I was actually requesting the GPL v2 license? Or should I have mentioned that I was seeking the GPLv2 license?</p>
<p>I could choose to pursue by writing again and requesting the right thing, but it would take too much effort to follow up on, and I’m overall satisfied with what I received.  As a postal introvert, I will now need a long period of rest to recoup.</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cars and Key Fobs: Attacks on Car Remotes (107 pts)]]></title>
            <link>https://web.stanford.edu/class/ee26n/Assignments/Assignment5.html</link>
            <guid>43780876</guid>
            <pubDate>Thu, 24 Apr 2025 09:53:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.stanford.edu/class/ee26n/Assignments/Assignment5.html">https://web.stanford.edu/class/ee26n/Assignments/Assignment5.html</a>, See on <a href="https://news.ycombinator.com/item?id=43780876">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="layout-content">


<h2>Overview</h2>
<p>Almost all cars currently come with a key fob, which allows you to open the doors, and start the car.  When you buy a car, the convenience is the compelling feature.  You can leave the key fob in your pocket, and never again worry about having a physical key. It sounds great.</p>
<p>The implicit assumption you make is that the key fob system is secure, and that some random person with $50 of hardware can't drive off with your car.  You have no real way to tell whether the car company did a reasonable job with their system, so you have to trust them.  Unfortunately, that trust is not always warranted.  And it isn't until people try to hack these systems that the problems come out.  Problems that less scrupulous people may have already been exploiting.</p>
<h2>Your Car's Key Fob</h2>
<p>There are lots of different key fob systems.  We'll start by looking at the key fob for my 2006 Prius. Key fobs use something called a Remote Keyless System (RKS).  In the U.S. these operate at 315 MHz, +/- 2.5 MHz.  My Prius key turned out to be at 312.590 MHz.The keyfobs are all listed in the FCC database.  Watching for new entries is one of the ways people can tell when new car models are coming out. These will appear long before the official announcement.</p>
<p>You can figure out what frequency your key fob transmits on using your SDR and use GQRX or SDR# to monitor the spectrum.  When you push a button on the fob, you should see a brief jump in the spectrum.  You may need to shift the frequency band up or down by a couple of MHz to find the signal, mine was almost 2.5 MHz low.</p>
<p>One word of caution.  Don't get too carried away pushing the button!  The RKS system uses a rolling pseudo-randomly generated code.  Both the key fob and the car keep in sync, so that the car recognizes the next code.  However, if the key fob gets too far ahead in the sequence (100s of button pushes) the car won't recognize it.  That makes the key (and the car) considerably less useful!</p>
<p>If we capture the signal the result is shown below</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/rks_sig.png" width="800"></p></div>
<p>The total width of the plot is 10 seconds, so you can see there is one key press shortly after 2 seconds, and another shortly after 5 seconds.</p>
<p>If we plot 100 ms starting at 2 seconds, we can see the digital signal we are looking for:</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/rks_zoom1.png" width="800"> </p></div>
<p>Zooming in to the first couple of bits, we get</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/rks_zoom2.png" width="800"> </p></div>
<p>The bits are easy to identify.  A decision threshold of 15 will give almost perfect detection. If we do this, and then plot first part of the digital data for the two key presses, we get this</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/rks_digital.png" width="800"> </p></div>
<p>Although the two start the same, they rapidly diverge.  This is fortunate, because if the signal was the same every time, you'd have enough information to steal my car now!</p>
<p>The data is again on-off keying (OOK).  It is also almost certainly split phase  (or Manchester) encoding. Instead of a “1” being high, and a “0” being low, the information is  encoding in the transition from high to low or low to high. That means that a “0” bit is a rising transition, and a “1” bit is a falling transition.  A good way to recognize split phase encoding is that you can only have one or two low or high segments in a row.  The nice thing about Manchester encoding is that every symbol has a transition, and these are easier to find then when the signal has been high or low for several intervals.</p>
<p>This example is OOK, which is the most common for car remotes.  Some use frequency-shift keying (FSK), where each bit is transmitted as a different frequency, and the envelope is constant.</p>
<h2>Attacks on Car Remotes</h2>
<p>There are lots of different attacks that can be used against car remotes, depending on how they work, and what sort of access you are looking for.  The simplest just let you open the car up.  More thorough attacks give you complete control by basically cloning the remote.</p>
<p>Most key fobs use a rolling key. This produces a new waveform that depends on the ID of the key fob, a random seed, and how many times the key has been pressed.  The car keeps track of the last code it received, and knows what the next several hundred codes might be.  If it detects one of the expected future codes it opens the car.  If it gets a previously used code, it stops responding to the key fob.  For the Prius you have to do the <a href="https://www.youtube.com/watch?v=xAuYVsokC5o">“Chicken Dance”</a> to get it to work again, provided you have another working key fob.  Otherwise, you have to have the dealer rekey the car, for many hundreds of dollars. I have had to do this a couple times, now (for other reasons).</p>
<p>There are several lines of attack.  One is simply recording the key fob output for a couple of button presses when it is away from the car, or the car is being jammed.  With recorded unused codes, you can open the car. </p>
<p>Another is to reverse engineer the RKS sequence.  In general this should be extremely hard.  However, there have been several situations where this is very easy. </p>
<p>Finally, there are cars that open when the owner gets close to the car.  This is based on a low power signal that can only be received when the key fob is very close.  This can be defeated by amplifying these small signals.</p>
<p>There are many more attacks, and these will continue to multiply as cars get more complex, and have more embedded computer systems to go after.  You can look at some of these for next week.</p>
<h3>Replay Attacks</h3>
<p>The oldest and simplest approach was to record the waveform that a key fob puts out (using your rtl-sdr), and then replay it.  This works well for older garage door openers, that used a single fixed key. There are still cars out there that have key fobs that work this way (some pre-2000 Mercedes for example).</p>
<p>For key fobs that use a rolling key, you can still use a replay attack. If you can get access to the key fob when it is away from the car and record several key presses, you can replay these to have the car open. </p>
<p>If you can't get access to the key fob, a second approach is to make a device that records the output of the key fob when it is used, and simultaneously jams the car.  A standard way to do this is to listen to the key fob transmission, and then start jamming when the error correction bits are transmitted at the end. That way you don't jam yourself.  The car won't recognize the packet, but you can recreate the error correction bits, and retransmit the waveform later.  </p>
<p>Finally, a jammer by itself will keep the remote from begin able to lock the car.  If the driver isn't attentive, they may walk away from the car leaving it open.</p>
<h3>Retransmission Devices</h3>
<p>All of this depends on your ability to both transmit and receive RF. Your rtl-sdr's are just receivers, and do a great job of acquiring signals. There are lots of options for transmitting.  There are a number of usb dongles that are based on the TI CC111X chips that are used in key fobs, like this one</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/CC1111_USB.png" width="600"> </p></div>
<p>Another recent device that has attracted a lot of attention is the Flipper Zero</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/Flipper_Zero.png" width="600"></p></div>
<p>This has the same chip as the previous device, but is much more accessiuble packaged.  This is the Swiss army knife of RF hacking.  It has generated a lot of controversy, as you can look into for this week's assignment.</p>
<p>An interesting, more flexible approach uses your Raspberry PI to generate RF by sending a carefully crafted data sequence to the GPIO port.  This is described in detail, with videos, and links to the code here:</p>
<p><a href="https://www.rtl-sdr.com/transmitting-fm-am-ssb-sstv-and-fsq-with-just-a-raspberry-pi">Raspberry PI transmitter</a></p>
<p>With this, you can generate pretty much any digital packet waveform you would like. Power levels are more than adequate for emulating a key fob.  The rtl-sdr's are also well supported on the Raspberry PI, so the two together give you a total key fob hacking system for $50 or so, as we will see shortly.</p>
<h3>Attacking Passive Keyless Entry and Start (PKES) Systems</h3>
<p>Many higher end cars use a passive system for opening the car when the driver approaches.  A low power signal is transmitted from the car as a challenge.  The key fob then responds with an authentication.  Because the power is so low, the car assumes the driver must be in close proximity if it receives a response.</p>
<p>These systems can be hacked by building a repeater that placed near the car.  It captures the car's signal and retransmits it at higher power.  The remote can be anywhere with in a couple hundred meters, and it will still hear the signal.  The remote responds, and that is again captured by the repeater, and retransmitted.  The car thinks the key fob is nearby and opens the car.</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/PKES.png" width="400"> </p></div>
<p>The nice thing about this approach is that you don't need to know anything about the key fob, except its frequency.  You don't need to reverse engineer the protocol it uses, you are actually just using the real key!</p>
<p>Here is a video of some care thieves stealing a Tesla with this approach</p>
<p><a href="https://www.theverge.com/2018/10/22/18008514/tesla-model-s-stolen-key-fob-hack-watch-video">Passive Remote Attack, Tesla Model 3</a></p>
<p>How can you reduce this risk?</p>
<h3>Attacking the Rolling Key System</h3>
<p>The next attacks go after the rolling key system itself.  The way this generally works is that the key fob sends an ID, along with a counter of how many times a key has been pressed.  This is encrypted, and transmitted to the car when you push the button.</p>
<div>
<p><img src="https://web.stanford.edu/class/ee26n/Assignments/graphics/RKS_Car.png" width="600"> </p></div>
<p>If the encryption is strong, it is extremely difficult to figure out what the userid and counter is.  There are several interesting cases.  One is for the 20 years of VW's (and Audi's, Porsche's, etc), that we'll look at here.  Another is for Subarus, that you can look at for your assignment this week.</p>
<p>A description of the VW RKS system is given here</p>
<p><a href="https://www.wired.com/2016/08/oh-good-new-hack-can-unlock-100-million-volkswagens/">VW Hack</a></p>
<p>This points to a Wired article (which unfortunately currently behind a paywall), and includes a technical paper that goes into great detail about how it works.  The authors of the technical paper looked at the VW RKS systems for the last 20 years. </p>
<p>For the most recent systems, the encryption was relatively strong, equivalent to a 90 bit key.  However, it turns out they used the <b>same key</b> in every car!  100 million of them!</p>
<p>The challenge then is to figure out what the key is, and what the encryption algorithm is.   The car itself helps you solve that one.  When button is pushed the car receives the signal, and then decodes it in the onboard computer (ECU).  The key and the algorithm are stored in the ECU firmware.  The authors bought some ECUs on EBay, downloaded the firmware, and reverse engineered the encryption (these are usually fairly simple bitwise operations that are easy to identify).  With this knowledge, after acquiring the signal from a single key press, the user ID and counter can be decoded, and the key fob cloned, giving complete control of the car.</p>
<p>There are a couple of interesting things here.  One is that every VW car decodes every key fob, so by monitoring the execution of your ECU, you can find the user ID and counter for all of the cars around you. There are reports of people using systems like this to steal other makes of cars, also.</p>
<p>The reason only your car responds to your remote is that your car has a “allow list” of 
key fob ID's it responds to.  That is what gets set when you rekey the car.</p>
<p>This all sounds pretty alarming.  But it gets worse, as we'll see next week.</p>
<div>
<h2>Assignment</h2>
<p>You have several options for your assignment this week. For each topic, generate about 5 slides to describe your thoughts or results. Sign up here</p>
<p><a href="https://docs.google.com/spreadsheets/d/1U9bNqlV4cXqNPDBIRoxuOmPMbRGMeoGzIOwI0_hZr1Y/edit?usp=share_link">Signup</a></p>
<p>and upload your slides here:</p>
<p><a href="https://drive.google.com/drive/folders/1QpThT_bgUZadzqQ98c9nEW_fpIYQueNq?usp=share_link">Week 5 Slides</a></p>
<p>1. This article concerns the Subaru RKS system.  Read it, watch the videos, and describe what you find.</p>
<p><a href="https://www.rtl-sdr.com/using-an-rtl-sdr-and-rpitx-to-defeat-the-rolling-code-scheme-used-on-some-subaru-cars/">Subaru RKS</a></p>
<p>2. The Flipper Zero has gotten lots of attention.  What controversies can you find? What can the device actually do?  Should it be banned?</p>
<p>3. Why steal a car when you can have a bulldozer!  Read this article, and watch the video, to see how this works.</p>
<p><a href="https://www.rtl-sdr.com/industrial-machines-like-cranes-excavators-can-easily-be-hacked-with-software-defined-radios/">Hacking Industrial Machines</a></p>
<p>4. There are lots of other car hacks out there.  See if you can find something interesting, and describe it.  Look for stories where you can figure out how it works. Entertainment systems are a common mode of access (check the Uconnect hack for Jeeps). Tesla and hackers have a long running cat-and-mouse game going.  There are lots of interesting examples here.  Two recent are <a href="https://techcrunch.com/2022/05/18/bluetooth-attack-unlock-tesla/">Teslas</a> and <a href="https://techcrunch.com/2022/07/12/honda-key-fob-flaw-hackers/">Hondas</a>.  </p>
<p>Finally, if you haven't already, please send me an email about how the class is going for you.  I appreciate hearing your thoughts. Thanks!</p>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[On loyalty to Your Employer (109 pts)]]></title>
            <link>https://www.talentstuff.com/blog/on-loyalty-to-your-employer</link>
            <guid>43780815</guid>
            <pubDate>Thu, 24 Apr 2025 09:43:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.talentstuff.com/blog/on-loyalty-to-your-employer">https://www.talentstuff.com/blog/on-loyalty-to-your-employer</a>, See on <a href="https://news.ycombinator.com/item?id=43780815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-6c9e46f520d21d455f2e">
  <p>I’ve just returned to London having spent the past two weeks back home in Cork where I spent an awful lot of time with my father, a man who set up his first ever email account less than a year ago and has spent the past 30 years working for the same employer. My Dad is the antithesis of the tech industry in every sense.</p><p>Considering the average ‘career’ with each employer in the tech industry is a touch under three years, the idea of spending 30 years working for the same employer is mind boggling. Despite this enormous disparity, I’m constantly witness to colleagues in the tech industry posting on LinkedIn about how great their employer is and why everyone should drop everything and come and work with them, only for them to announce a few short years later that they are moving on “to bigger and better things”.</p><p>I’m going to be the first to hold my hands up and admit to being extremely guilty of doing exactly that on a regular basis in the past. I work in recruitment. Employers pay me a lot of money to wax lyrical about how great they are. They pay me to convince you that the grass is not only greener, but their grass is more flexible and inclusive too. So how do I reconcile my apathy towards every employer claiming to be the best, and my ability to do a good job?</p><h3><strong>Transparency &amp; Honesty</strong></h3><p>My criteria for vetting an employer worth working with is very straightforward. Anything beyond these four criteria is a bonus (and extremely subjective) but the four criteria below are my absolute zero compromise criteria.</p><ol data-rte-list="default"><li><p><strong><em>Do you pay reasonable salaries?<br></em></strong>Fortunately, due to my line of work, asking for specifics around salaries is par for the course and not something an employer can easily lie about. To put it simply, if your salaries aren’t at least competitive then we’re wasting each other’s time. Pay fairly or pay well and we’re off to a good start.</p></li><li><p><strong><em>Do you treat your people well?<br></em></strong>Glassdoor is your friend. If there are a slew of negative comments, look for consistencies. Were they all posted around the same time? Are there consistent themes? Raise these points and ask for the employers perspective. A quality employer will be honest and highlight what steps they took to address those issues. Not every company has a helpful Glassdoor profile (a lot of startups have yet to be reviewed) so take to social media, and look up current and former employees to see if there are any red flags.</p></li><li><p><strong><em>Are you financially secure?<br></em></strong>This is startup 101 folks. Do your due diligence. Companies House, Crunchbase, etc are a good start. Enquire about their runway (how long they can survive if their current income and expenses stay constant). If they aren’t willing to be open and honest about their finances, walk away immediately.</p></li><li><p><strong><em>Are you open to trying new things?<br></em></strong>This criteria is quite specific to the work I do and may not be universally applicable. If you’re asking me to team up with you to improve your ability to hire people then you categorically need to be open and willing to try new things. No amount of money will be enough to convince me to join your company and follow your same old tired recipe just because it worked well a couple of times in the past.</p></li></ol><p>If you hit all of the above criteria then I can do the thing that enables me to convince great people to work for your company. I can be absolutely transparent and honest with people.</p><h3><strong>Delicious Kool-Aid</strong></h3>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1745486033847_3489">
  <ul data-rte-list="default"><li><p>Do not sacrifice your relationship with family and friends to appease your employer.</p></li></ul><ul data-rte-list="default"><li><p>Do not sacrifice your mental wellbeing to appease your employer.</p></li><li><p>Do not sacrifice your dignity, values, and ethics to appease your employer.</p></li><li><p>Do not buy into the bullshit hype of “hustle” to appease your employer.</p></li></ul><h3><strong>Mutual Respect</strong></h3><p>Get your head down and work hard. If your employer compensates you well, puts effort into ensuring you are healthy in every sense and invests in your personal and/or professional growth then by all means, tell the world how happy you are.</p><p>Focus on your own growth. Focus on helping the humans you work with. Focus on being efficient with your time and efforts so that you can spend even more time and effort on the things and people that truly matter.</p><p>I’ll leave you on the words of my father on the eve of his 30 year work anniversary:</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Careless People" the book that Meta tried to suppress (504 pts)]]></title>
            <link>https://pluralistic.net/2025/04/23/zuckerstreisand/#zdgaf</link>
            <guid>43780363</guid>
            <pubDate>Thu, 24 Apr 2025 08:17:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#zdgaf">https://pluralistic.net/2025/04/23/zuckerstreisand/#zdgaf</a>, See on <a href="https://news.ycombinator.com/item?id=43780363">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-10777">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
books, reviews, sarah wynne-williams, facebook, meta, streisand effect, joel kaplan, mark zuckerberg, gift guide, sheryl sandberg, myanmar, genocide, big tech, antitrust, trustbusting, monopolies, enshittification, ndas, gag orders, sexual abuse

Summary:
Sarah Wynn-Williams's 'Careless People'; Hey look at this; Upcoming appearances; Recent appearances; Latest books; Upcoming books

URL:
https://pluralistic.net/2025/04/23/zuckerstreisand/

Title:
Pluralistic: Sarah Wynn-Williams's 'Careless People' (23 Apr 2025) zuckerstreisand

Bullet:
🧃

Separator:
⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂ ⠂⠄⠄⠂⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂ ⠂⠄⠄⠂⠂⠄⠄⠂⠁⠁⠂⠄

Top Sources:
None

--><br>
<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/23Apr2025.jpg?w=840&amp;ssl=1"></a></p>
<h2>Today's links</h2>
<ul>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#zdgaf">Sarah Wynn-Williams's 'Careless People'</a>: "Too big to care."
</li>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#linkdump">Hey look at this</a>: Delights to delectate.
</li>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#retro">Object permanence</a>: 2005, 2010, 2015, 2020, 2024
</li>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#upcoming">Upcoming appearances</a>: Where to find me.
</li>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#recent">Recent appearances</a>: Where I've been.
</li>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#latest">Latest books</a>: You keep readin' em, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#upcoming-books">Upcoming books</a>: Like I said, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#bragsheet">Colophon</a>: All the rest.
</li>
</ul>

<hr>
<p><a name="zdgaf"></a><br>
<img data-recalc-dims="1" decoding="async" alt="The Crown Books cover for Sarah Wynn-Williams's 'Careless People.'" src="https://i0.wp.com/craphound.com/images/carelesspeople.jpg?w=840&amp;ssl=1"></p>
<h2>Sarah Wynn-Williams's 'Careless People' (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#zdgaf">permalink</a>)</h2>
<p>I never would have read <em>Careless People</em>, Sarah Wynn-Williams's tell-all memoir about her years running global policy for Facebook, but then Meta's lawyer tried to get the book suppressed and secured an injunction to prevent her from promoting it:</p>
<p><a href="https://www.npr.org/2025/03/14/nx-s1-5318854/former-meta-executive-barred-from-discussing-criticism-of-the-company">https://www.npr.org/2025/03/14/nx-s1-5318854/former-meta-executive-barred-from-discussing-criticism-of-the-company</a></p>
<p>So I've got something to thank Meta's lawyers for, because it's a great book! Not only is Wynn-Williams a skilled and lively writer who spills some of Facebook's most shameful secrets, but she's also a kick-ass narrator (I listened to the audiobook, which she voices):</p>
<p><a href="https://libro.fm/audiobooks/9781250403155-careless-people">https://libro.fm/audiobooks/9781250403155-careless-people</a></p>
<p>I went into <em>Careless People</em> with strong expectations about the kind of disgusting behavior it would chronicle. I have several friends who took senior jobs at Facebook, thinking they could make a difference (three of them actually appear in Wynn-Williams's memoir), and I've got a good sense of what a nightmare it is for a company.</p>
<p>But Wynn-Williams was a lot closer to three of the key personalities in Facebook's upper echelon than anyone in my orbit: Mark Zuckerberg, Sheryl Sandberg, and Joel Kaplan, who was elevated to VP of Global Policy after the Trump II election. I already harbor an atavistic loathing of these three based on their public statements and conduct, but the events Wynn-Williams reveals from their private lives make these three out to be beyond despicable. There's Zuck, whose underlings let him win at board-games like Settlers of Catan because he's a manbaby who can't lose (and who accuses Wynn-Williams of cheating when she fails to throw a game of Ticket to Ride while they're flying in his private jet). There's Sandberg, who demands the right to buy a kidney for her child from someone in Mexico, should that child ever need a kidney.</p>
<p>Then there's Kaplan, who is such an extraordinarily stupid and awful oaf that it's hard to pick out just one example, but I'll try. At one point, Wynn-Williams gets Zuck a chance to address the UN General Assembly. As is his wont, Zuck refuses to be briefed before he takes the dais (he's repeatedly described as unwilling to consider any briefing note longer than a single text message). When he gets to the mic, he spontaneously promises that Facebook will provide internet access to refugees all over the world. Various teams at Facebook then race around, trying to figure out whether this is something the company is actually doing, and once they realize Zuck was just bullshitting, set about trying to figure out how to do it. They get some way down this path when Kaplan intervenes to insist that giving away free internet to refugees is a bad idea, and that instead, they should <em>sell</em> internet access to refugees. Facebookers dutifully throw themselves into this absurd project, which dies when Kaplan fires off an email stating that he's just realized that refugees don't have any money. The project dies.</p>
<p>The path that brought Wynn-Williams's into the company of these careless people is a weird – and rather charming – one. As a young woman, Wynn-Williams was a minor functionary in the New Zealand diplomatic corps, and during her foreign service, she grew obsessed with the global political and social potential of Facebook. She threw herself into the project of getting hired to work on Facebook's global team, working on strategy for liaising with governments around the world. The biggest impediment to landing this job is that it doesn't exist: sure, FB was lobbying the US government, but it was monumentally disinterested in the rest of the world in general, and the governments of the world in particular.</p>
<p>But Wynn-Williams persists, pestering potentially relevant execs with requests, working friends-of-friends (Facebook itself is extraordinarily useful for this), and refusing to give up. Then comes the Christchurch earthquake. Wynn-Williams is in the US, about to board a flight, when her sister, a news presenter, calls her while trapped inside a collapsed building (the sister hadn't been able to get a call through to anyone in NZ). Wynn-Williams spends the flight wondering if her sister is dead or alive, and only learns that her sister is OK through a post on Facebook.</p>
<p>The role Facebook played in the Christchurch quake transforms Wynn-Williams's passion for Facebook into something like religious zealotry. She throws herself into the project of landing the job, and she <em>does</em>, and after some funny culture-clashes arising from her Kiwi heritage and her public service background, she settles in at Facebook.</p>
<p>Her early years there are sometimes comical, sometimes scary, and are characteristic of a company that is growing quickly and unevenly. She's dispatched to Myanmar amidst a nationwide block of Facebook ordered by the ruling military junta and at one point, it seems like she's about to get kidnapped and imprisoned by goons from the communications ministry. She arranges for a state visit by NZ Prime Minister John Key, who wants a photo-op with Zuckerberg, who – oblivious to the prime minister standing right there in front of him – berates Wynn-Williams for demanding that he meet with some jackass politician (they do the photo-op anyway).</p>
<p>One thing is clear: Facebook doesn't really care about countries other than America. Though Wynn-Williams chalks this up to plain old provincial chauvinism (which FB's top eschelon possess in copious quantities), there's something else at work. The USA is the only country in the world that a) is rich, b) is populous, and c) has no meaningful privacy protections. If you make money selling access to dossiers on rich people to advertisers, America is the most important market in the world.</p>
<p>But then Facebook conquers America. Not only does FB saturate the US market, it uses its free cash-flow and high share price to acquire potential rivals, like Whatsapp and Instagram, ensuring that American users who leave Facebook (the service) remain trapped by Facebook (the company).</p>
<p>At this point, Facebook – Zuckerberg – turns towards the rest of the world. Suddenly, acquiring non-US users becomes a matter of urgency, and overnight Wynn-Williams is transformed from the sole weirdo talking about global markets to the key asset in pursuit of the company's top priority.</p>
<p>Wynn-Williams's explanation for this shift lies in Zuckerberg's personality, his need to constantly dominate (which is also why his subordinates have learned to let him win at board games). This is doubtless true: not only has this aspect of Zuckerberg's personality been on display in public for decades, Wynn-Williams was able to observe it first-hand, behind closed doors.</p>
<p>But I think that in addition to this personality defect, there's a <em>material</em> pressure for Facebook to grow that Wynn-Williams doesn't mention. Companies that grow get extremely high price-to-earnings (P:E) ratios, meaning that investors are willing to spend many dollars on shares for every dollar the company takes in. Two similar companies with similar earnings can have vastly different valuations (the value of all the stock the company has ever issued), depending on whether one of them is still growing.</p>
<p>High P:E ratios reflect a bet on the part of investors that the company will continue to grow, and those bets only become more extravagant the more the company grows. This is a <em>huge</em> advantage to companies with "growth stocks." If your shares constantly increase in value, they are highly liquid – that is, you can always find someone who's willing to buy your shares from you for cash, which means that you can treat shares <em>like</em> cash. But growth stocks are <em>better</em> than cash, because money grows slowly, if at all (especially in periods of extremely low interest rates, like the past 15+ years). Growth stocks, on the other hand, <em>grow</em>.</p>
<p>Best of all, companies with growth stocks have no trouble finding more stock when they need it. They just type zeroes into a spreadsheet and more shares appear. Contrast this with money. Facebook may take in a lot of money, but the money only arrives when <em>someone else</em> spends it. Facebook's access to money is limited by exogenous factors – your willingness to send your money to Facebook. Facebook's access to shares is only limited by endogenous factors – the company's own willingness to issue new stock.</p>
<p>That means that when Facebook needs to buy something, there's a very good chance that the seller will accept Facebook's stock in lieu of US dollars. Whether Facebook is hiring a new employee or buying a company, it can outbid rivals who only have dollars to spend, because that bidder has to ask someone else for more dollars, whereas Facebook can make its own stock on demand. This is a <em>massive</em> competitive advantage.</p>
<p>But it is also a <em>massive</em> business risk. As Stein's Law has it, "anything that can't go on forever eventually stops." Facebook can't grow forever by signing up new users. Eventually, everyone who might conceivably have a Facebook account will get one. When that happens, Facebook will need to find some other way to make money. They could enshittify – that is, shift value from the company's users and customers to itself. They could invent something new (like metaverse, or AI). But if they can't make those things work, then the company's growth will have ended, and it will <em>instantaneously</em> become grossly overvalued. Its P:E ratio will have to shift from the high value enjoyed by growth stocks to the low value endured by "mature" companies.</p>
<p>When that happens, anyone who is slow to sell will lose a <em>ton</em> of money. So investors in growth stocks tend to keep one fist poised over the "sell" button and sleep with one eye open, watching for any hint that growth is slowing. It's not just that growth gives FB the power to outcompete rivals – it's <em>also</em> the case that growth makes the company vulnerable to massive, sudden devaluations. What's more, if these devaluations are persistent and/or frequent enough, the key FB employees who accepted stock in lieu of cash for some or all of their compensation will either demand <em>lots</em> more cash, or jump ship for a growing rival. These are the very same people that Facebook needs to pull itself out of its nosedives. For a growth stock, even small reductions in growth metrics (or worse, declines) can trigger cascades of compounding, mutually reinforcing collapse.</p>
<p>This is what happened in early 2022, when Meta posted slightly lower-than-anticipated US growth numbers, and the market all pounded on the "sell" button at once, lopping $250,000,000,000 of the company's valuation in 24 hours. At the time, it was the worst-ever single day losses for any company in human history:</p>
<p><a href="https://www.forbes.com/sites/sergeiklebnikov/2022/02/03/facebook-faces-an-existential-moment-after-230-billion-stock-crash/">https://www.forbes.com/sites/sergeiklebnikov/2022/02/03/facebook-faces-an-existential-moment-after-230-billion-stock-crash/</a></p>
<p>Facebook's conquest of the US market triggered an emphasis on foreign customers, but not just because Zuck is obsessed with conquest. For Facebook, a decline in US growth posed an existential risk, the possibility of mass stock selloffs and with them, the end of the years in which Facebook could acquire key corporate rivals and executives with "money" it could print on the premises, on demand.</p>
<p>So Facebook cast its eye upon the world, and Wynn-Williams's long insistence that the company should be paying attention to the political situation abroad suddenly starts landing with her bosses. But those bosses – Zuck, Sandberg, Kaplan and others – are "careless." Zuck screws up opportunity after opportunity because he refuses to be briefed, forgets what little information he's been given, and blows key meetings because he refuses to get out of bed before noon. Sandberg's visits to Davos are undermined by her relentless need to promote herself, her "Lean In" brand, and her petty gamesmanship. Kaplan is the living embodiment of Green Day's "American Idiot" and can barely fathom that foreigners exist.</p>
<p>Wynn-Williams's adventures during this period are very well told, and are, by turns, harrowing and hilarious. Time and again, Facebook's top brass snatch defeat from the jaws of victory, squandering incredible opportunities that Wynn-Williams secures for them because of their pettiness, short-sightedness, and arrogance (that is, their carelessness).</p>
<p>But Wynn-Williams's disillusionment with Facebook isn't rooted in these frustrations. Rather, she is both personally and professionally aghast at the company's disgusting, callous and cruel behavior. She describes how her boss, Joel Kaplan, relentlessly sexually harasses her, and everyone in a position to make this stop tells her to shut up and take it. When Wynn-Williams give birth to her second child, she hemorrhages, almost dies, and ends up in a coma. Afterwards, Kaplan gives her a negative performance review because she was "unresponsive" to his emails and texts while she was dying in an ICU. This is a significant escalation of the earlier behavior she describes, like pestering her with personal questions about breastfeeding, video-calling her from bed, and so on (Kaplan is Sandberg's ex-boyfriend, and Wynn-Williams describes another creepy event where Sandberg pressures her to sleep next to her in the bedroom on one of Facebook's jets, something Wynn-Williams says she routinely does with the young women who report to her).</p>
<p>Meanwhile, Zuck is relentlessly pursuing Facebook's largest conceivable growth market: China. The only problem: China doesn't want Facebook. Zuck repeatedly tries to engineer meetings with Xi Jinping so he can plead his case in person. Xi is monumentally hostile to this idea. Zuck learns Mandarin. He studies Xi's book, conspicuously displays a copy of it on his desk. Eventually, he manages to sit next to Xi at a dinner where he begs Xi to name his next child. Xi turns him down.</p>
<p>After years of persistent nagging, lobbying, and groveling, Facebook's China execs start to make progress with a state apparatchik who dangles the possibility of Facebook entering China. Facebook promises this factotum the world – all the surveillance and censorship the Chinese state wants and more. Then, Facebook's contact in China is jailed for corruption, and they have to start over.</p>
<p>At this point, Kaplan has punished Wynn-Williams – she blames it on her attempts to get others to force him to stop his sexual harassment – and cut her responsibilities in half. He tries to maneuver her into taking over the China operation, something he knows she absolutely disapproves of and has refused to work on – but she refuses. Instead, she is put in charge of hiring the new chief of China operations, giving her access to a voluminous paper-trail detailing the company's dealings with the Chinese government.</p>
<p>According to Wynn-Williams, Facebook actually built an extensive censorship and surveillance system for the Chinese state – spies, cops and military – to use against Chinese Facebook users, and FB users globally. They promise to set up caches of global FB content in China that the Chinese state can use to monitor all Facebook activity, everywhere, with the implication that they'll be able to spy on private communications, and censor content for non-Chinese users.</p>
<p>Despite all of this, Facebook is never given access to China. However, the Chinese state <em>is</em> able to use the tools Facebook built for it to attack independence movements, the free press and dissident uprisings in Hong Kong and Taiwan.</p>
<p>Meanwhile, in Myanmar, a genocide is brewing. NGOs and human rights activists keep reaching out to Facebook to get them to pay attention to the widespread use of the platform to whip up hatred against the country's Muslim minority group, the Rohinga. Despite having expended tremendous amounts of energy to roll out "Free Basics" in Myanmar (a program whereby Facebook bribes carriers to exclude its own services from data caps), with the result that in Myanmar, "the internet" is synonymous with "Facebook," the company has not expended <em>any</em> effort to manage its Burmese presence. The entire moderation staff consists of one (later two) Burmese speakers who are based in Dublin and do not work local hours (later, these two are revealed as likely stooges for the Myanmar military junta, who are behind the genocide plans).</p>
<p>The company has also failed to invest in Burmese language support for its systems – posts written in Burmese script are not stored as Unicode, meaning that none of the company's automated moderation systems can parse it. The company is so hostile to pleas to upgrade these systems that Wynn-Williams and some colleagues create secret, private Facebook groups where they can track the failures of the company and the rising tide of lethal violence in the country (this isn't the only secret dissident Facebook group that Wynn-Williams joins – she's also part of a group of women who have been sexually harassed by colleagues and bosses).</p>
<p>The genocide that follows is horrific beyond measure. And, as with the Trump election, the company's initial posture is that they couldn't possibly have played a significant role in a real-world event that shocked and horrified its rank-and-file employees.</p>
<p>The company, in other words, is "careless." Warned of imminent harms to its users, to democracy, to its own employees, the top executives simply do not care. They ignore the warnings and the consequences, or pay lip service to them. They don't care.</p>
<p>Take Kaplan: after figuring out that the company can't curry favor with the world's governments by selling drone-delivered wifi to refugees (the drones don't fly and the refugees are broke), he hits on another strategy. He remakes "government relations" as a <em>sales office</em>, selling political ads to politicians who are seeking to win over voters, or, in the case of autocracies, disenfranchised hostage-citizens. This is hugely successful, both as a system for securing government cooperation and as a way to transform Facebook's global policy shop from a cost-center to a profit-center.</p>
<p>But of course, it has a price. Kaplan's best customers are dictators and would-be dictators, formenters of hatred and genocide, authoritarians seeking opportunities to purge their opponents, through exile and/or murder.</p>
<p>Wynn-Williams makes a very good case that Facebook is run by awful people who are also very careless – in the sense of being <em>reckless</em>, incurious, indifferent.</p>
<p>But there's another meaning to "careless" that lurks just below the surface of this excellent memoir: "careless" in the sense of "arrogant" – in the sense of not caring about the consequences of their actions.</p>
<p>To me, this was the most important – but least-developed – lesson of <em>Careless People</em>. When Wynn-Williams lands at Facebook, she finds herself surrounded by oafs and sociopaths, cartoonishly selfish and shitty people, who, <em>nevertheless</em>, have built a service that she <em>loves</em> and values, along with hundreds of millions of other people.</p>
<p>She's not wrong to be excited about Facebook, or its potential. The company may be run by careless people, but they are still <em>prudent</em>, behaving as though the consequences of screwing up matter. They are "careless" in the sense of "being reckless," but they <em>care</em>, in the sense of having a healthy fear (and thus respect) for what might happen if they fully yield to their reckless impulses.</p>
<p>Wynn-Williams's firsthand account of the next decade is not a story of these people becoming more reckless, rather, its a story in which the possibility of consequences for that recklessness recedes, and with it, so does their care over those consequences.</p>
<p>Facebook buys its competitors, freeing it from market consequences for its bad acts. By buying the places where disaffected Facebook users are seeking refuge – Instagram and Whatsapp – Facebook is able to insulate itself from the discipline of competition – the fear that doing things that are adverse to its users will cause them to flee.</p>
<p>Facebook captures its regulators, freeing it from regulatory consequences for its bad acts. By playing a central role in the electoral campaigns of Obama and then other politicians around the world, Facebook transforms its watchdogs into supplicants who are more apt to beg it for favors than hold it to account.</p>
<p>Facebook tames its employees, freeing it from labor consequences for its bad acts. As engineering supply catches up with demand, Facebook's leadership come to realize that they don't have to worry about workforce uprisings, whether incited by impunity for sexually abusive bosses, or by the company's complicity in genocide and autocratic oppression.</p>
<p>First, Facebook becomes too big to fail.</p>
<p>Then, Facebook becomes too big to jail.</p>
<p>Finally, Facebook becomes too big to <em>care</em>.</p>
<p>This is the "carelessness" that ultimately changes Facebook for the worse, that turns it into the hellscape that Wynn-Williams is eventually fired from after she speaks out once too often. Facebook bosses aren't just "careless" because they refuse to read a briefing note that's longer than a tweet. They're "careless" in the sense that they arrive at a juncture where they don't have to care who they harm, whom they enrage, who they ruin.</p>
<p>There's a telling anaecdote near the end of <em>Careless People</em>. Back in 2017, leaks revealed that Facebook's sales-reps were promising advertisers the ability to market to teens who felt depressed and "worthless":</p>
<p><a href="https://arstechnica.com/information-technology/2017/05/facebook-helped-advertisers-target-teens-who-feel-worthless/">https://arstechnica.com/information-technology/2017/05/facebook-helped-advertisers-target-teens-who-feel-worthless/</a></p>
<p>Wynn-Williams is – rightly – aghast about this, and even more aghast when she sees the company's official response, in which they disclaim any knowledge that this capability was being developed and fire a random, low-level scapegoat. Wynn-Williams knows they're lying. She knows that this is a routine offering, one that the company routinely boasts about to advertisers.</p>
<p>But she doesn't mention the <em>other</em> lies that Facebook tells in this moment: for one thing, the company offers advertisers the power to target more teens than actually <em>exist</em>. The company proclaims the efficacy of its "sentiment analysis" tool that knows how to tell if teens are feeling depressed or "worthless," even though these tools are notoriously inaccurate, hardly better than a coin-toss, a kind of digital phrenology.</p>
<p>Facebook, in other words, isn't just lying to the public about what it offers to advertisers – it's lying to advertisers, too. Contra those who say, "if you're not paying for the product, you're the product," Facebook treats <em>anyone</em> it can get away with abusing as "the product" (just like every other tech monopolist):</p>
<p><a href="https://pluralistic.net/2022/11/14/luxury-surveillance/#liar-liar">https://pluralistic.net/2022/11/14/luxury-surveillance/#liar-liar</a></p>
<p>Wynn-Williams documents so many instances in which Facebook's top executives lie – to the courts, to Congress, to the UN, to the press. Facebook lies when it is beneficial to do so – but only when they can get away with it. By the time Facebook was lying to advertisers about its depressed teen targeting tools, it was already colluding with Google to rig the ad market with an illegal tool called "Jedi Blue":</p>
<p><a href="https://en.wikipedia.org/wiki/Jedi_Blue">https://en.wikipedia.org/wiki/Jedi_Blue</a></p>
<p>Facebook's story is the story of a company that set out to become <em>too big to care</em>, and achieved that goal. The company's abuses track precisely with its market dominance. It enshittified things for users once it had the users locked in. It screwed advertisers once it captured their market. It did the media-industry-destroying "pivot to video" fraud once it captured the media:</p>
<p><a href="https://en.wikipedia.org/wiki/Pivot_to_video">https://en.wikipedia.org/wiki/Pivot_to_video</a></p>
<p>The important thing about Facebook's carelessness is that it wasn't the result of the many grave personality defects in Facebook's top executives – it was the result of policy choices. Government decisions not to enforce antitrust law, to allow privacy law to wither on the vine, to expand IP law to give Facebook a weapon to shut down interoperable rivals – these all created the enshittogenic environment that allowed the careless people who run Facebook to stop caring.</p>
<p>The corollary: if we change the policy environment, we can make these careless people – and their successors, who run other businesses we rely upon – <em>care</em>. They may never care about <em>us</em>, but we can make them care about what we might do to <em>them</em> if they give in to their carelessness.</p>
<p>Meta is in global regulatory crosshairs, facing antitrust action in the USA:</p>
<p><a href="https://pluralistic.net/2025/04/18/chatty-zucky/#is-you-taking-notes-on-a-criminal-fucking-conspiracy">https://pluralistic.net/2025/04/18/chatty-zucky/#is-you-taking-notes-on-a-criminal-fucking-conspiracy</a></p>
<p>And muscular enforcement pledges in the EU:</p>
<p><a href="https://www.reuters.com/business/retail-consumer/eu-says-it-will-enforce-digital-rules-irrespective-ceo-location-2025-04-21/">https://www.reuters.com/business/retail-consumer/eu-says-it-will-enforce-digital-rules-irrespective-ceo-location-2025-04-21/</a></p>
<p>As Martin Luther King, Jr put it:</p>
<blockquote><p>
  The law cannot make a man love me, but it can stop him from lynching me, and I think that's pretty important.
</p></blockquote>
<hr>

<h2>Hey look at this (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#linkdump">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/heylookatthis2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>Corporate Lawlessness Comes Next <a href="https://www.hamiltonnolan.com/p/corporate-lawlessness-comes-next">https://www.hamiltonnolan.com/p/corporate-lawlessness-comes-next</a>
</li>
<li>
<p>Deconstructing Housing <a href="https://democracyjournal.org/magazine/76/deconstructing-housing/">https://democracyjournal.org/magazine/76/deconstructing-housing/</a></p>
</li>
<li>
<p>What Happens When Private Equity Owns Your Kid’s Day Care <a href="https://jacobin.com/2025/04/private-equity-day-care-childcare/">https://jacobin.com/2025/04/private-equity-day-care-childcare/</a></p>
</li>
</ul>
<hr>
<p><a name="retro"></a><br>
<img data-recalc-dims="1" height="416" width="796" decoding="async" alt="A Wayback Machine banner." src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1"></p>
<h2>Object permanence (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#retro">permalink</a>)</h2>
<p>#20yrsago Free Culture Movement turns one <a href="https://web.archive.org/web/20050426022041/http://www.lessig.org/blog/archives/002838.shtml">https://web.archive.org/web/20050426022041/http://www.lessig.org/blog/archives/002838.shtml</a></p>
<p>#15yrsago India’s copyright bill gets it right <a href="https://web.archive.org/web/20100425031519/https://www.michaelgeist.ca/content/view/4974/196/">https://web.archive.org/web/20100425031519/https://www.michaelgeist.ca/content/view/4974/196/</a></p>
<p>#15yrsago Hitler’s pissed off about fair use <a href="https://www.youtube.com/watch?v=kBO5dh9qrIQ">https://www.youtube.com/watch?v=kBO5dh9qrIQ</a></p>
<p>#10yrsago Fascinating, wide-ranging discussion with William Gibson <a href="https://www.youtube.com/watch?v=bmh29gwEy7Y">https://www.youtube.com/watch?v=bmh29gwEy7Y</a></p>
<p>#10yrsago Tory chairman accused of smearing party rivals’ Wikipedia entries <a href="https://www.theguardian.com/politics/2015/apr/21/grant-shapps-accused-of-editing-wikipedia-pages-of-tory-rivals">https://www.theguardian.com/politics/2015/apr/21/grant-shapps-accused-of-editing-wikipedia-pages-of-tory-rivals</a></p>
<p>#10yrsago John Oliver on patent trolls <a href="https://www.youtube.com/watch?v=3bxcc3SM_KA">https://www.youtube.com/watch?v=3bxcc3SM_KA</a></p>
<p>#5yrsago Disney heiress slams top execs' compensation <a href="https://pluralistic.net/2020/04/22/filternet/#castmembers">https://pluralistic.net/2020/04/22/filternet/#castmembers</a></p>
<p>#5yrsago Covid burns through Charter Cable employees <a href="https://pluralistic.net/2020/04/22/filternet/#thomas-rutledge-murderer">https://pluralistic.net/2020/04/22/filternet/#thomas-rutledge-murderer</a></p>
<p>#5yrsago Unmasking the registrants of the "reopen" websites <a href="https://pluralistic.net/2020/04/22/filternet/#krebs">https://pluralistic.net/2020/04/22/filternet/#krebs</a></p>
<p>#5yrsago Apartment buildings didn't cause the pandemic <a href="https://pluralistic.net/2020/04/22/filternet/#kate-wagner">https://pluralistic.net/2020/04/22/filternet/#kate-wagner</a></p>
<p>#5yrsago Web-wide copyright filters would be a disaster <a href="https://pluralistic.net/2020/04/22/filternet/#filternet">https://pluralistic.net/2020/04/22/filternet/#filternet</a></p>
<p>#1yrago Paying for it doesn't make it a market <a href="https://pluralistic.net/2024/04/22/kargo-kult-kaptialism/#dont-buy-it">https://pluralistic.net/2024/04/22/kargo-kult-kaptialism/#dont-buy-it</a></p>
<hr>

<h2>Upcoming appearances (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#upcoming">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" alt="A photo of me onstage, giving a speech, pounding the podium." src="https://i0.wp.com/craphound.com/images/appearances2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>Auckland: Unity Books, May 2, 6PM<br>
<a href="https://www.eventbrite.co.nz/e/an-evening-with-cory-doctorow-tickets-1320740102199">https://www.eventbrite.co.nz/e/an-evening-with-cory-doctorow-tickets-1320740102199</a>
</li>
<li>
<p>Wellingon: Unity Books, May 3, 3PM<br>
<a href="https://www.unitybooks.co.nz/news-and-events/author-talk-picks-and-shovels-by-cory-doctorow">https://www.unitybooks.co.nz/news-and-events/author-talk-picks-and-shovels-by-cory-doctorow</a></p>
</li>
<li>
<p>Pittsburgh: Picks and Shovels at White Whale Books, May 15<br>
<a href="https://whitewhalebookstore.com/events/20250515">https://whitewhalebookstore.com/events/20250515</a></p>
</li>
<li>
<p>Pittsburgh: PyCon, May 16<br>
<a href="https://us.pycon.org/2025/schedule/">https://us.pycon.org/2025/schedule/</a></p>
</li>
<li>
<p>Virtual: Writing to Resist (California Writers Club Berkeley):<br>
<a href="https://cwc-berkeley.org/writing-to-resist-5-18-25/">https://cwc-berkeley.org/writing-to-resist-5-18-25/</a></p>
</li>
<li>
<p>PDX: Teardown 2025, Jun 20-22<br>
<a href="https://www.crowdsupply.com/teardown/portland-2025">https://www.crowdsupply.com/teardown/portland-2025</a></p>
</li>
<li>
<p>PDX: Picks and Shovels with bunnie Huang at Barnes and Noble, Jun 20<br>
<a href="https://stores.barnesandnoble.com/event/9780062183697-0">https://stores.barnesandnoble.com/event/9780062183697-0</a></p>
</li>
<li>
<p>London: How To Academy with Riley Quinn, Jul 1<br>
<a href="https://howtoacademy.com/events/cory-doctorow-the-fight-against-the-big-tech-oligarchy/">https://howtoacademy.com/events/cory-doctorow-the-fight-against-the-big-tech-oligarchy/</a></p>
</li>
<li>
<p>Manchester: Picks and Shovels at Blackwell's Bookshop, Jul 2<br>
<a href="https://www.eventbrite.co.uk/e/an-evening-with-cory-doctorow-tickets-1308451968059">https://www.eventbrite.co.uk/e/an-evening-with-cory-doctorow-tickets-1308451968059</a></p>
</li>
<li>
<p>Manchester: Co-operatives UK Co-op Congress keynote, Jul 3<br>
<a href="https://www.uk.coop/events-and-training/events-calendar/co-op-congress-2025-book-your-place">https://www.uk.coop/events-and-training/events-calendar/co-op-congress-2025-book-your-place</a></p>
</li>
<li>
<p>New Orleans: DeepSouthCon63, Oct 10-12, 2025<br>
<a href="http://www.contraflowscifi.org/">http://www.contraflowscifi.org/</a></p>
</li>
</ul>
<hr>
<p><a name="recent"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A screenshot of me at my desk, doing a livecast." src="https://i0.wp.com/craphound.com/images/recentappearances2.jpg?w=840&amp;ssl=1"></p>
<h2>Recent appearances (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#recent">permalink</a>)</h2>
<ul>
<li>Can we use the Internet for Democracy?<br>
<a href="https://www.youtube.com/watch?v=Zh_HON6iql8">https://www.youtube.com/watch?v=Zh_HON6iql8</a>
</li>
<li>
<p>Fightback Against Trump's Tariff Attack (Avi Lewis)<br>
<a href="https://www.youtube.com/watch?v=P9sgIAc6z_o">https://www.youtube.com/watch?v=P9sgIAc6z_o</a></p>
</li>
<li>
<p>The Voice of Canadian Humanism<br>
<a href="https://open.spotify.com/episode/7uuwdZTIbWzKhBQ3mmMiRv">https://open.spotify.com/episode/7uuwdZTIbWzKhBQ3mmMiRv</a></p>
</li>
</ul>
<hr>
<p><a name="latest"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A grid of my books with Will Stahle covers.." src="https://i0.wp.com/craphound.com/images/recent.jpg?w=840&amp;ssl=1"></p>
<h2>Latest books (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#latest">permalink</a>)</h2>
<ul>
<li>
<ul>
<li>Picks and Shovels: a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (<a href="https://us.macmillan.com/books/9781250865908/picksandshovels">https://us.macmillan.com/books/9781250865908/picksandshovels</a>).</li>
</ul>
</li>
<li>The Bezzle: a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (<a href="http://the-bezzle.org/">the-bezzle.org</a>). Signed, personalized copies at Dark Delicacies (<a href="https://www.darkdel.com/store/p3062/Available_Feb_20th%3A_The_Bezzle_HB.html#/">https://www.darkdel.com/store/p3062/Available_Feb_20th%3A_The_Bezzle_HB.html#/</a>).
</li>
<li>
<p>"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (<a href="http://lost-cause.org/">http://lost-cause.org</a>). Signed, personalized copies at Dark Delicacies (<a href="https://www.darkdel.com/store/p3007/Pre-Order_Signed_Copies%3A_The_Lost_Cause_HB.html#/">https://www.darkdel.com/store/p3007/Pre-Order_Signed_Copies%3A_The_Lost_Cause_HB.html#/</a>)</p>
</li>
<li>
<p>"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (<a href="http://seizethemeansofcomputation.org/">http://seizethemeansofcomputation.org</a>). Signed copies at Book Soup (<a href="https://www.booksoup.com/book/9781804291245">https://www.booksoup.com/book/9781804291245</a>).</p>
</li>
<li>
<p>"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books <a href="http://redteamblues.com/">http://redteamblues.com</a>. Signed copies at Dark Delicacies (US): <a href="https://www.darkdel.com/store/p2873/Wed%2C_Apr_26th_6pm%3A_Red_Team_Blues%3A_A_Martin_Hench_Novel_HB.html#/"> and Forbidden Planet (UK): </a><a href="https://forbiddenplanet.com/385004-red-team-blues-signed-edition-hardcover/">https://forbiddenplanet.com/385004-red-team-blues-signed-edition-hardcover/</a>.</p>
</li>
<li>
<p>"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 <a href="https://chokepointcapitalism.com/">https://chokepointcapitalism.com</a></p>
</li>
<li>
<p>"Attack Surface": The third Little Brother novel, a standalone technothriller for adults. The <em>Washington Post</em> called it "a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance." Order signed, personalized copies from Dark Delicacies <a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html</a></p>
</li>
<li>
<p>"How to Destroy Surveillance Capitalism": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. <a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59?sk=f6cd10e54e20a07d4c6d0f3ac011af6b">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59?sk=f6cd10e54e20a07d4c6d0f3ac011af6b</a>) (signed copies: <a href="https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html">https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html</a>)</p>
</li>
<li>
<p>"Little Brother/Homeland": A reissue omnibus edition with a new introduction by Edward Snowden: <a href="https://us.macmillan.com/books/9781250774583">https://us.macmillan.com/books/9781250774583</a>; personalized/signed copies here: <a href="https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html">https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html</a></p>
</li>
<li>
<p>"Poesy the Monster Slayer" a picture book about monsters, bedtime, gender, and kicking ass. Order here: <a href="https://us.macmillan.com/books/9781626723627">https://us.macmillan.com/books/9781626723627</a>. Get a personalized, signed copy here: <a href="https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/">https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/</a>.</p>
</li>
</ul>
<hr>
<p><a name="upcoming-books"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A cardboard book box with the Macmillan logo." src="https://i0.wp.com/craphound.com/images/upcoming-books.jpg?w=840&amp;ssl=1"></p>
<h2>Upcoming books (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#upcoming-books">permalink</a>)</h2>
<ul>
<li>Enshittification: Why Everything Suddenly Got Worse and What to Do About It, Farrar, Straus, Giroux, October 7 2025<br>
<a href="https://us.macmillan.com/books/9780374619329/enshittification/">https://us.macmillan.com/books/9780374619329/enshittification/</a>
</li>
<li>
<p>Unauthorized Bread: a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026</p>
</li>
<li>
<p>Enshittification, Why Everything Suddenly Got Worse and What to Do About It (the graphic novel), Firstsecond, 2026</p>
</li>
<li>
<p>The Memex Method, Farrar, Straus, Giroux, 2026</p>
</li>
</ul>
<hr>
<p><a name="bragsheet"></a><br>
<img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/colophon2.jpg?w=840&amp;ssl=1"></p>
<h2>Colophon (<a href="https://pluralistic.net/2025/04/23/zuckerstreisand/#bragsheet">permalink</a>)</h2>
<p>Today's top sources:</p>
<p><b>Currently writing: </b></p>
<ul>
<li>Enshittification: a nonfiction book about platform decay for Farrar, Straus, Giroux. Status: second pass edit underway (readaloud)
</li>
<li>
<p>A Little Brother short story about DIY insulin PLANNING</p>
</li>
<li>
<p>Picks and Shovels, a Martin Hench noir thriller about the heroic era of the PC. FORTHCOMING TOR BOOKS FEB 2025</p>
</li>
</ul>
<p><b>Latest podcast:</b> Nimby and the D-Hoppers CONCLUSION <a href="https://craphound.com/stories/2025/04/13/nimby-and-the-d-hoppers-conclusion/">https://craphound.com/stories/2025/04/13/nimby-and-the-d-hoppers-conclusion/</a></p>
<hr>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/by.svg.png?w=840&amp;ssl=1"></p>
<p>This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>
<p><a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></p>
<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>
<hr>
<h2>How to get Pluralistic:</h2>
<p>Blog (no ads, tracking, or data-collection):</p>
<p><a href="http://pluralistic.net/">Pluralistic.net</a></p>
<p>Newsletter (no ads, tracking, or data-collection):</p>
<p><a href="https://pluralistic.net/plura-list">https://pluralistic.net/plura-list</a></p>
<p>Mastodon (no ads, tracking, or data-collection):</p>
<p><a href="https://mamot.fr/@pluralistic">https://mamot.fr/@pluralistic</a></p>
<p>Medium (no ads, paywalled):</p>
<p><a href="https://doctorow.medium.com/">https://doctorow.medium.com/</a></p>
<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://twitter.com/doctorow">https://twitter.com/doctorow</a></p>
<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://mostlysignssomeportents.tumblr.com/tagged/pluralistic">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>
<p>"<em>When life gives you SARS, you make sarsaparilla</em>" -Joey "Accordion Guy" DeVilla</p>
<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>
<p>ISSN: 3066-764X</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD Publishes Open-Source Driver for GPU Virtualization, Radeon "In the Roadmap" (115 pts)]]></title>
            <link>https://www.phoronix.com/news/AMD-GIM-Open-Source</link>
            <guid>43779953</guid>
            <pubDate>Thu, 24 Apr 2025 06:58:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/AMD-GIM-Open-Source">https://www.phoronix.com/news/AMD-GIM-Open-Source</a>, See on <a href="https://news.ycombinator.com/item?id=43779953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="AMD" src="https://www.phoronix.com/assets/categories/amd.webp" width="100" height="100"></p><p>
AMD has published as open-source their "GPU-IOV Module" used for virtualization with Instinct accelerators. It's also reported on their roadmap for bringing virtualization support to their client (Radeon) discrete GPUs.
</p><p>
The AMD GPU-IOV Module is for the Linux kernel and for providing SR-IOV based hardware virtualization in conjunction with the KVM hypervisor. GIM provides the GPU IOV virtualization, virtual function (VF) configuration and enablement, GPU scheduling for world switch, hang detection and FLR reset, and PF/VF handshake capabilities.
</p><p>
Initially the AMD GIM driver is for the Instinct MI300X hardware and tested atop Ubuntu 22.04 LTS with ROCm 6.4. Those interested can find the AMD GIM code currently via <a href="https://github.com/amd/MxGPU-Virtualization">GitHub</a>. It's not laid out in the repository or any other public communications I've seen what any upstreaming plans are for this GIM driver to get it into the mainline Linux kernel.
</p><p>
Of interest to many Phoronix readers will be that GIM / SR-IOV support could be coming to client discrete GPUs, which has been a long sought feature for the Radeon graphics cards. AMD engineer Anush Elangovan responded on <a href="https://x.com/AnushElangovan/status/1914667824230097144">X</a> that the client GPU support is reportedly "in the roadmap":
</p><p><img src="https://www.phoronix.net/image.php?id=2025&amp;image=radeon_sriov_roadmap" alt="roadmap tweet/X"></p>
<p>Hopefully this client GPU support pans out and comes sooner rather than later.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shortest-possible walking tour to 81,998 bars in South Korea (359 pts)]]></title>
            <link>https://www.math.uwaterloo.ca/tsp/korea/index.html</link>
            <guid>43778105</guid>
            <pubDate>Thu, 24 Apr 2025 00:20:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.math.uwaterloo.ca/tsp/korea/index.html">https://www.math.uwaterloo.ca/tsp/korea/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=43778105">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 

<p>
We have solved a traveling salesman problem (TSP) to walk to 81,998 bars in South Korea.
The problem was created using the <a href="https://project-osrm.org/">Open Source Routing Machine</a> (OSRM) to build a table of the 3,361,795,003 point-to-point travel times, one for each pair of bar locations.
Our computation produced a tour together with a proof that it is a shortest-possible route to visit all 81,998 stops when measured with the OSRM times.
</p>

<p>
It would be a very long pub crawl.
The total walking time for the round trip is 15,386,177 seconds, or 178 days, 1 hour, 56 minutes, and 17 seconds.
You will need to stop for plenty of drinks along the way (better stick with water, tea, or Diet Coke if you want to finish the route in only a few years), so it's  not likely you would count every second on such a journey.
But the level of precision makes the point that this not just a good route, it is an optimal solution to the 81,998-stop TSP.
It is not possible to rearrange the order of stops to save even a single second of the OSRM-estimated walking time.
</p>


<p>
This is the largest road-map instance of the TSP that has been solved to provable optimality, exceeding the <a href="https://www.math.uwaterloo.ca/tsp/nl/index.html">57,912-stop tour through the Netherlands</a> solved in February 2021.
The computations were carried out between December 2024 and March 2025 at <a href="https://ruc.dk/en">Roskilde University</a> and at the <a href="https://uwaterloo.ca/">University of Waterloo</a>.
Details of the computing work can be found on the <a href="https://www.math.uwaterloo.ca/tsp/korea/computation.html">Computation</a> page.
</p>


<p>
  <h2>Interactive map</h2>
</p>


<p>       
The figure below is a screen shot of an interactive map of the korea81998 tour.
The menu on the left-hand-side lets you select one of seven regions to view.
At the top right-hand-side you can choose to have either a colored street map or a grayscale map without street labels.
Just below this menu you can select whether or not to display the stop markers, or to display the tour edges, or to display both.
You can view the map by clicking on the image.
</p><figure>
  <a href="https://www.math.uwaterloo.ca/tsp/korea/korea81998_lite.html"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/korea_map.jpg" width="100%" alt="Screenshot of the interactive map"></a>
</figure>





<p>
  <h2>Snapshots of the Tour</h2>
</p>

<p>
If you have trouble viewing the interactive map, you can click on the drawings below to see high-resolution images of the tour.
For close-up views of city regions, please see the <a href="https://www.math.uwaterloo.ca/tsp/korea/cities.html">Cities</a> page.
</p>

<div>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap1.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap1_1000.jpg" alt="Tour snapshot 1"></a>
   </p>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap2.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap2_1000.jpg" alt="Tour snapshot 2"></a>
   </p>
</div> 

<div>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap3.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap3_1000.jpg" alt="Tour snapshot 3"></a>
   </p>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap4.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap4_1000.jpg" alt="Tour snapshot 4"></a>
   </p>
</div> 




<p>
  <h2>Optimality</h2>
</p>

<p>
Newspapers, popular journals, blogs, and scientific press releases regularly report that solving even tiny instances of the TSP is impossible with the current generation of computers.
A typical example is the following quote from the Washington Post.
</p>

<figure>
<blockquote>
<p>
"It would take a laptop computer 1,000 years to compute the most efficient route between 22 cities, for example."
</p>
</blockquote>
  
</figure>

<!--
<figure>
<blockquote class="blockquote">
<p>
"... used a special quantum chip to solve a 22-stop traveling salesman problem that would have taken a supercomputer more than a thousand years to solve."
</p>
</blockquote>
  <figcaption class="blockquote-footer">
     Alles auf Quantencomputer!: Warum es lohnt, auf die Schluesseltechnologie zu setzen, <cite title="Source Title">Der Tagesspiegel</cite>, November 25, 2021.
  </figcaption>
</figure>

<figure>
<blockquote class="blockquote">
<p>
"With 50 landmarks to put in order . . . . computing this problem on your home computer right now, you'd find the optimal route in about 9.64 x 10<sup>52</sup> years."
</p>
</blockquote>
  <figcaption class="blockquote-footer">
     The ultimate American road trip revealed: Data scientist uses algorithms to plot the best route across the United States, <cite title="Source Title">Daily Mail</cite>, March 14, 2015.
  </figcaption>
</figure>
-->


<p>
Statements such as this assume the only way to solve the TSP is to check each possible tour, one-by-one.
That clearly cannot work for any of the large instances of the TSP we have solved.
The number of tours in the korea81998 case is roughly <a href="http://www.wolframalpha.com/input/?i=81997!">2 followed by 367308 zeroes</a>.
</p>

<p>
This huge number of possible solutions is frightening, but it doesn't mean we can't solve this large example of the TSP.
Our approach combines the <a href="http://webhotel4.ruc.dk/~keld/research/LKH/">LKH</a> code for computing extremely good TSP solutions and the <a href="https://www.math.uwaterloo.ca/tsp/concorde.html">Concorde</a> code for applying what is known as the "cutting-plane method" for producing quality guarantees.
You can see a short discussion of how we apply these tools on the <a href="https://www.math.uwaterloo.ca/tsp/korea/computation.html">Computation</a> page.
</p>

<p>
For a quick glimpse of the cutting-plane method, here is how I describe the process in a <a href="http://www.scientificamerican.com/article/case-traveling-salesman-unsolvable-limits-computation/">short piece in Scientific American</a>
</p>
<figure>
<blockquote>
<p>
"The idea is to follow Yogi Berra's advice `When you come to a fork in the road, take it.' A tool called linear programming allows us to do just this, assigning fractions to roads joining pairs of cities, rather than deciding immediately whether to use a road or not. It is perfectly fine, in this model, to send half a salesman along both branches of the fork."
</p>

<p>
"The process begins with the requirement that, for every city, the fractions assigned to the arriving and departing roads each sum to one. Then, step-by-step, further restrictions are added, each involving sums of fractions assigned to roads. Linear programming eventually points us to the best decision for each road, and thus the shortest possible route."
</p>
</blockquote>
<!--
  <figcaption class="blockquote-footer text-bg-light p-1 border border-dark-subtle border-top-0">
    Traveling Salesman: A Seemingly Unsolvable Problem Offers a Glimpse of the Limits of Computation, <cite title="Source Title">Scientific America</cite>, June 2012.
  </figcaption>
-->
</figure>


<p>
If you have a few minutes, you can check out the video of the talk <a href="https://www.youtube.com/watch?v=tChnXG6ulyE">Optimal Tours</a> given at the <a href="https://momath.org/civicrm/?page=CiviCRM&amp;q=civicrm%2Fevent%2Finfo&amp;reset=1&amp;id=6601">National Museum of Mathematics</a>, where the method is described in detail. 
Or, keeping with the Korean theme, please have a look at video of the talk <a href="https://www.youtube.com/watch?v=W0XnU1uvIwo">Amazon Deliveries, Pub Walks, and Astro Tours</a>, given at <a href="https://www.kaist.ac.kr/en/">KAIST</a> in March 2024.

</p><div>
   <p><a href="https://www.youtube.com/watch?v=tChnXG6ulyE"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/momath_title.jpg" alt="Tour snapshot 1"></a>
   </p>
   <p><a href="https://www.youtube.com/watch?v=W0XnU1uvIwo"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/korea2024_title.jpg" alt="Tour snapshot 2"></a>
   </p>
</div> 




<p>
  <h2>P vs NP</h2>
</p>

<p>
A great discussion of the P and NP complexity classes, including connections to the TSP, can be found in Lance Fortnow's article <a href="https://dl.acm.org/doi/pdf/10.1145/3460351">Fifty Years of P vs. NP and the Possibility of the Impossible</a>.
</p>

<figure> 
  <img src="https://www.math.uwaterloo.ca/tsp/korea/img/optiland.jpg" width="50%" alt="Optiland">
  <figcaption>Credit: https://cacm.acm.org/research/fifty-years-of-p-vs-np-and-the-possibility-of-the-impossible/</figcaption>
</figure>


<p>
  <h2>The Big Picture</h2>
</p>

<p>
We use large examples of the traveling salesman problem as a means for developing and testing general-purpose optimization methods.
The world has limited resources and the aim of the applied mathematics fields of <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">mathematical optimization</a> and <a href="https://en.wikipedia.org/wiki/Operations_research">operations research</a> is to create tools to help us to use these resources as efficiently as possible.
</p>

<p>
For general information on mathematical modeling and its impact on industry, commerce, medicine, and the environment, we point you to a number of societies that support mathematics research and education:
<a href="http://www.ams.org/home/page">American Mathematical Society</a>,
<a href="http://www.maa.org/">Mathematical Association of America</a>,
<a href="http://www.mathopt.org/">Mathematical Optimization Society</a>,
<a href="https://www.informs.org/">INFORMS</a> (operations research), 
and <a href="http://www.siam.org/">SIAM</a> (applied mathematics).
</p>


<p>
  <h2>Research Team</h2>
</p>

<p>
  <a href="http://www.math.uwaterloo.ca/~bico/">William Cook</a>, Combinatorics and Optimization, University of Waterloo, Canada<br>
  <a href="https://scholar.google.com/citations?user=7KSvWuQAAAAJ&amp;hl=en">Daniel Espinoza</a>, Alicanto Labs, Chile<br> 
  <a href="http://mgoycool.uai.cl/">Marcos Goycoolea</a>, School of Business, Universidad Adolfo Ibanez, Chile<br>
  <a href="http://www.akira.ruc.dk/~keld/">Keld Helsgaun</a>, Computer Science, Roskilde University, Denmark
</p>


<p>
  <h2>Acknowledgements</h2>
</p>

<p>
The huge number of linear-programming models that arose in the computation were solved with the <a href="https://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">IBM CPLEX Optimizer</a>.
Many thanks to IBM for making their great software <a href="https://community.ibm.com/community/user/datascience/blogs/xavier-nodet1/2020/07/09/cplex-free-for-students">freely available for academic research</a>.
</p>

<p>
The map drawings of the tour were created with the <a href="https://leafletjs.com/">Leaflet</a> open-source JavaScript library for mobile-friendly interactive maps and make use of map tiles built by <a href="https://www.openstreetmap.org/">OpenStreetMap</a>, by <a href="https://carto.com/basemaps">Carto Basemaps</a> and by <a href="https://stadiamaps.com/products/map-tiles/">Stadia Maps</a>.
</p>

<p>
We thank <a href="https://dimag.ibs.re.kr/home/sangil/">Dr. Sang-il Oum</a>, Chief Investigator of the <a href="https://dimag.ibs.re.kr/">Discrete Mathematics Group</a> at the <a href="https://www.ibs.re.kr/eng.do">Institute for Basic Science (IBS)</a> for obtaining the locations of the bars in Korea.
The locations were downloaded from a <a href="https://www.bigdata-policing.kr/product/view?product_id=PRDT_360">database</a> maintained by the Korean National Police Agency.
</p>

<p>
The table of point-to-point walking times was created with the <a href="https://project-osrm.org/">Open Source Routing Machine</a> (OSRM).
</p>



<p>
  <h2>Other Road Trips</h2>
</p>

<div> 
  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/japan/index.html" data-ua-action="hp-news" title="Image of Japan tour"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/japan_270.jpg" alt="Konbini"></a></p><p>40,426 Japanese Konbini.</p>
  </div>

  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/uk/index.html" data-ua-action="hp-news" title="UK49687 Tour"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/uk49_270.png" alt="UK"></a></p><p>49,687 pubs in the UK.</p>
  </div>

  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/us/index.html" data-ua-action="hp-news" title="Screen shot of US50K"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/us50k_full_270.png" alt="US50K"></a></p><p>49,603 US historic places.</p>
  </div>

  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/nl/index.html" data-ua-action="hp-news" title="NL Tour"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/nl_270.jpg" alt="UK"></a></p><p>57,912 Dutch monuments.</p>
  </div>
</div>


<p>
  <h2>Further Reading</h2>
</p>

<div "=""> 
  <div>
    <p><a href="http://press.princeton.edu/titles/9531.html" data-ua-action="hp-news" title="In Pursuit of the Traveling Salesman"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/pursuit.jpg" alt="Pursuit"></a></p><p>An introduction to the TSP, including its history, applications, and solution techniques.</p>
  </div>

  <div>
    <p><a href="http://press.princeton.edu/titles/8451.html" title="Traveling Salesman Problem"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/tspcomp.jpg" alt="TSP"></a></p><p>Detailed computational study of the cutting-plane method for the TSP.</p>
  </div>

  <div>
    <p><a href="http://press.princeton.edu/titles/9937.html" data-ua-action="hp-news" title="The Golden Ticket"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/golden.jpg" alt="The Golden Ticket"></a></p><p>Gentle introduction to the P vs NP problem and its ramifications.</p>
  </div>

  <div>
    <p><a href="https://press.princeton.edu/books/hardcover/9780691164069/opt-art" data-ua-action="hp-news" title="Opt Art"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/optart.jpg" alt="Opt Art"></a></p><p>See how the TSP is used to create pretty images with a single line.</p>
  </div>

  <div>
    <p><a href="https://www.or.uni-bonn.de/tspbook/tsp_book.html" data-ua-action="hp-news" title="Approximation Algorithms for the TSP"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/approx.jpg" alt="Approximation Algorithms"></a></p><p>Latest research on the theory of approximation algorithms for the TSP.</p>
  </div>

  <div>
    <p><a href="https://link.springer.com/book/10.1007/3-540-48661-5" data-ua-action="hp-news" title="Computational Solutions for TSP Applications"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/reinelt.jpg" alt="Reinelt TSP"></a></p><p>Applications of the TSP are given in this 1994 book, now available as a free download.</p>
  </div>



<!--
  <div class="col col-md-2">
    <a href="https://www.alexbellos.com/numberland" class="su-link" data-ua-action="hp-news" title="Numberland"><img src="./img/bellos.jpg" class="img-fluid" alt="Alex Bellos"></a>
    <p>Fantastic math book! Not directly about the TSP, but reading get you in the mood for math research.</p>
  </div>

  <div class="col col-md-2">
    <a href="https://dimag.ibs.re.kr" class="su-link" data-ua-action="hp-news" title="AFSA"><img src="./img/ibs.jpg" class="img-fluid" alt="IBS"></a>
    <p>In Korea, there is one of the world's leading research groups focusing on discrete mathematics.
-->

</div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: My from-scratch OS kernel that runs DOOM (254 pts)]]></title>
            <link>https://github.com/UnmappedStack/TacOS</link>
            <guid>43778081</guid>
            <pubDate>Thu, 24 Apr 2025 00:15:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/UnmappedStack/TacOS">https://github.com/UnmappedStack/TacOS</a>, See on <a href="https://news.ycombinator.com/item?id=43778081">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">TacOS</h2><a id="user-content-tacos" aria-label="Permalink: TacOS" href="#tacos"></a></p>
<p dir="auto">My from-scratch OS with it's own kernel written in C and assembly</p>
<p dir="auto">TacOS is a UNIX-like kernel which is able to run DOOM, among various other smaller userspace programs. It has things like a VFS, scheduler, TempFS, devices, context switching, virtual memory management, physical page frame allocation, and a port of Doom. It runs both on real hardware (tested on my laptop) and in the Qemu emulator.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/UnmappedStack/TacOS/blob/main/screenshots/screenshot1.webp"><img src="https://github.com/UnmappedStack/TacOS/raw/main/screenshots/screenshot1.webp" alt="A screenshot of TacOS's shell"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/UnmappedStack/TacOS/blob/main/screenshots/screenshot2.webp"><img src="https://github.com/UnmappedStack/TacOS/raw/main/screenshots/screenshot2.webp" alt="A screenshot of TacOS running DOOM"></a></p>
<p dir="auto">Please note that TacOS is a hobby toy OS and is not complete enough for real usage. It has multiple known bugs.</p>
<p dir="auto">I have a Discord server for PotatOS where I will share most updates, and you can also get help with your own OSDev project or just have a chat. You can join <a href="https://discord.gg/hPg9S2F2nD" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">To build and run TacOS, simply run in your shell:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/UnmappedStack/TacOS
cd TacOS
git clone https://github.com/limine-bootloader/limine
cd limine
git checkout v9.x-binary
make"><pre><code>git clone https://github.com/UnmappedStack/TacOS
cd TacOS
git clone https://github.com/limine-bootloader/limine
cd limine
git checkout v9.x-binary
make
</code></pre></div>
<p dir="auto">You'll need to have Qemu, NASM, and Clang installed. It will automatically run in the Qemu emulator.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">TacOS is under the Mozilla Public License 2.0. See <code>LICENSE</code> for more information.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CubeCL: GPU Kernels in Rust for CUDA, ROCm, and WGPU (173 pts)]]></title>
            <link>https://github.com/tracel-ai/cubecl</link>
            <guid>43777731</guid>
            <pubDate>Wed, 23 Apr 2025 23:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tracel-ai/cubecl">https://github.com/tracel-ai/cubecl</a>, See on <a href="https://news.ycombinator.com/item?id=43777731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">TL;DR</h2><a id="user-content-tldr" aria-label="Permalink: TL;DR" href="#tldr"></a></p>
<p dir="auto">With CubeCL, you can program your GPU using Rust, taking advantage of zero-cost abstractions to develop maintainable, flexible, and efficient compute kernels.
CubeCL currently fully supports functions, generics, and structs, with partial support for traits, methods and type inference.
As the project evolves, we anticipate even broader support for Rust language primitives, all while maintaining optimal performance.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<p dir="auto">Simply annotate functions with the <code>cube</code> attribute to indicate that they should run on the GPU.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use cubecl::prelude::*;

#[cube(launch_unchecked)]
/// A [Line] represents a contiguous series of elements where SIMD operations may be available.
/// The runtime will automatically use SIMD instructions when possible for improved performance.
fn gelu_array<F: Float>(input: &amp;Array<Line<F>>, output: &amp;mut Array<Line<F>>) {
    if ABSOLUTE_POS < input.len() {
        output[ABSOLUTE_POS] = gelu_scalar(input[ABSOLUTE_POS]);
    }
}

#[cube]
fn gelu_scalar<F: Float>(x: Line<F>) -> Line<F> {
    // Execute the sqrt function at comptime.
    let sqrt2 = F::new(comptime!(2.0f32.sqrt()));
    let tmp = x / Line::new(sqrt2);

    x * (Line::erf(tmp) + 1.0) / 2.0
}"><pre><span>use</span> cubecl<span>::</span>prelude<span>::</span><span>*</span><span>;</span>

<span>#<span>[</span>cube<span>(</span>launch_unchecked<span>)</span><span>]</span></span>
<span>/// A [Line] represents a contiguous series of elements where SIMD operations may be available.</span>
<span></span><span>/// The runtime will automatically use SIMD instructions when possible for improved performance.</span>
<span></span><span>fn</span> <span>gelu_array</span><span>&lt;</span><span>F</span><span>:</span> <span>Float</span><span>&gt;</span><span>(</span><span>input</span><span>:</span> <span>&amp;</span><span>Array</span><span>&lt;</span><span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span><span>&gt;</span><span>,</span> <span>output</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Array</span><span>&lt;</span><span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>if</span> <span>ABSOLUTE_POS</span> &lt; input<span>.</span><span>len</span><span>(</span><span>)</span> <span>{</span>
        output<span>[</span><span>ABSOLUTE_POS</span><span>]</span> = <span>gelu_scalar</span><span>(</span>input<span>[</span><span>ABSOLUTE_POS</span><span>]</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span>

<span>#<span>[</span>cube<span>]</span></span>
<span>fn</span> <span>gelu_scalar</span><span>&lt;</span><span>F</span><span>:</span> <span>Float</span><span>&gt;</span><span>(</span><span>x</span><span>:</span> <span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span><span>)</span> -&gt; <span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span> <span>{</span>
    <span>// Execute the sqrt function at comptime.</span>
    <span>let</span> sqrt2 = <span>F</span><span>::</span><span>new</span><span>(</span><span>comptime</span><span>!</span><span>(</span><span>2.0f32</span><span>.</span>sqrt<span>(</span><span>)</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> tmp = x / <span>Line</span><span>::</span><span>new</span><span>(</span>sqrt2<span>)</span><span>;</span>

    x <span>*</span> <span>(</span><span>Line</span><span>::</span><span>erf</span><span>(</span>tmp<span>)</span> + <span>1.0</span><span>)</span> / <span>2.0</span>
<span>}</span></pre></div>
<p dir="auto">You can then launch the kernel using the autogenerated <code>gelu_array::launch_unchecked</code> function.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pub fn launch<R: Runtime>(device: &amp;R::Device) {
    let client = R::client(device);
    let input = &amp;[-1., 0., 1., 5.];
    let vectorization = 4;
    let output_handle = client.empty(input.len() * core::mem::size_of::<f32>());
    let input_handle = client.create(f32::as_bytes(input));

    unsafe {
        gelu_array::launch_unchecked::<f32, R>(
            &amp;client,
            CubeCount::Static(1, 1, 1),
            CubeDim::new(input.len() as u32 / vectorization, 1, 1),
            ArrayArg::from_raw_parts::<f32>(&amp;input_handle, input.len(), vectorization as u8),
            ArrayArg::from_raw_parts::<f32>(&amp;output_handle, input.len(), vectorization as u8),
        )
    };

    let bytes = client.read_one(output_handle.binding());
    let output = f32::from_bytes(&amp;bytes);

    // Should be [-0.1587,  0.0000,  0.8413,  5.0000]
    println!(&quot;Executed gelu with runtime {:?} => {output:?}&quot;, R::name());
}"><pre><span>pub</span> <span>fn</span> <span>launch</span><span>&lt;</span><span>R</span><span>:</span> <span>Runtime</span><span>&gt;</span><span>(</span><span>device</span><span>:</span> <span>&amp;</span><span>R</span><span>::</span><span>Device</span><span>)</span> <span>{</span>
    <span>let</span> client = <span>R</span><span>::</span><span>client</span><span>(</span>device<span>)</span><span>;</span>
    <span>let</span> input = <span>&amp;</span><span>[</span>-<span>1.</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>,</span> <span>5.</span><span>]</span><span>;</span>
    <span>let</span> vectorization = <span>4</span><span>;</span>
    <span>let</span> output_handle = client<span>.</span><span>empty</span><span>(</span>input<span>.</span><span>len</span><span>(</span><span>)</span> <span>*</span> core<span>::</span>mem<span>::</span><span>size_of</span><span>::</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> input_handle = client<span>.</span><span>create</span><span>(</span>f32<span>::</span><span>as_bytes</span><span>(</span>input<span>)</span><span>)</span><span>;</span>

    <span>unsafe</span> <span>{</span>
        gelu_array<span>::</span><span>launch_unchecked</span><span>::</span><span>&lt;</span><span>f32</span><span>,</span> <span>R</span><span>&gt;</span><span>(</span>
            <span>&amp;</span>client<span>,</span>
            <span>CubeCount</span><span>::</span><span>Static</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>,</span>
            <span>CubeDim</span><span>::</span><span>new</span><span>(</span>input<span>.</span><span>len</span><span>(</span><span>)</span> <span>as</span> <span>u32</span> / vectorization<span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>,</span>
            <span>ArrayArg</span><span>::</span><span>from_raw_parts</span><span>::</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>(</span><span>&amp;</span>input_handle<span>,</span> input<span>.</span><span>len</span><span>(</span><span>)</span><span>,</span> vectorization <span>as</span> <span>u8</span><span>)</span><span>,</span>
            <span>ArrayArg</span><span>::</span><span>from_raw_parts</span><span>::</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>(</span><span>&amp;</span>output_handle<span>,</span> input<span>.</span><span>len</span><span>(</span><span>)</span><span>,</span> vectorization <span>as</span> <span>u8</span><span>)</span><span>,</span>
        <span>)</span>
    <span>}</span><span>;</span>

    <span>let</span> bytes = client<span>.</span><span>read_one</span><span>(</span>output_handle<span>.</span><span>binding</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> output = f32<span>::</span><span>from_bytes</span><span>(</span><span>&amp;</span>bytes<span>)</span><span>;</span>

    <span>// Should be [-0.1587,  0.0000,  0.8413,  5.0000]</span>
    <span>println</span><span>!</span><span>(</span><span>"Executed gelu with runtime {:?} =&gt; {output:?}"</span><span>,</span> <span>R</span><span>::</span>name<span>(</span><span>)</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">To see it in action, run the working GELU example with the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run --example gelu --features cuda # cuda runtime
cargo run --example gelu --features wgpu # wgpu runtime"><pre>cargo run --example gelu --features cuda <span><span>#</span> cuda runtime</span>
cargo run --example gelu --features wgpu <span><span>#</span> wgpu runtime</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Runtime</h2><a id="user-content-runtime" aria-label="Permalink: Runtime" href="#runtime"></a></p>
<p dir="auto">We support the following GPU runtimes:</p>
<ul dir="auto">
<li><a href="https://github.com/gfx-rs/wgpu">WGPU</a> for cross-platform GPU support (Vulkan, Metal, DirectX, WebGPU)</li>
<li><a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow">CUDA</a> for NVIDIA GPU support</li>
<li><a href="https://www.amd.com/en/products/software/rocm.html" rel="nofollow">ROCm/HIP</a> for AMD GPU support (WIP)</li>
</ul>
<p dir="auto">We also plan to develop an optimized JIT CPU runtime with SIMD instructions, leveraging <a href="https://cranelift.dev/" rel="nofollow">Cranelift</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">The goal of CubeCL is to ease the pain of writing highly optimized compute kernels that are portable across hardware.
There is currently no adequate solution when you want optimal performance while still being multi-platform.
You either have to write custom kernels for different hardware, often with different languages such as CUDA, Metal, or ROCm.
To fix this, we created a Just-in-Time compiler with three core features: <strong>automatic vectorization</strong>, <strong>comptime</strong>, and <strong>autotune</strong>!</p>
<p dir="auto">These features are extremely useful for anyone writing high-performance kernels, even when portability is not a concern.
They improve code composability, reusability, testability, and maintainability, all while staying optimal.
CubeCL also ships with a memory management strategy optimized for throughput with heavy buffer reuse to avoid allocations.</p>
<p dir="auto">Our goal extends beyond providing an optimized compute language; we aim to develop an ecosystem of high-performance and scientific computing in Rust.
To achieve this, we're developing linear algebra components that you can integrate into your own kernels.
We currently have an highly optimized matrix multiplication module, leveraging Tensor Cores on NVIDIA hardware where available, while gracefully falling back to basic instructions on other platforms.
While there's room for improvement, particularly in using custom instructions from newer NVIDIA GPUs, our implementation already delivers impressive performance.</p>
<p dir="auto">This is just the beginning.
We plan to include more utilities such as convolutions, random number generation, fast Fourier transforms, and other essential algorithms.
We are a small team also building <a href="https://burn.dev/" rel="nofollow">Burn</a>, so don't hesitate to contribute and port algorithms; it can help more than you would imagine!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">CubeCL leverages Rust's proc macro system in a unique two-step process:</p>
<ol dir="auto">
<li>Parsing: The proc macro parses the GPU kernel code using the syn crate.</li>
<li>Expansion: Instead of immediately generating an Intermediate Representation (IR), the macro generates a new Rust function.</li>
</ol>
<p dir="auto">The generated function, semantically similar to the original, is responsible for creating the IR when called.
This approach differs from traditional compilers, which typically generate IR directly after parsing.
Our method enables several key features:</p>
<ul dir="auto">
<li><strong>Comptime</strong>: By not transforming the original code, it becomes remarkably easy to integrate compile-time optimizations.</li>
<li><strong>Automatic Vectorization</strong>: By simply vectorizing the inputs of a CubeCL function, we can determine the vectorization factor of each intermediate variable during the expansion.</li>
<li><strong>Rust Integration</strong>: The generated code remains valid Rust code, allowing it to be bundled without any dependency on the specific runtime.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design</h2><a id="user-content-design" aria-label="Permalink: Design" href="#design"></a></p>
<p dir="auto">CubeCL is designed around - you guessed it - Cubes! More specifically, it's based on cuboids, because not all axes are the same size.
Since all compute APIs need to map to the hardware, which are tiles that can be accessed using a 3D representation, our topology can easily be mapped to concepts from other APIs.</p>
<div dir="auto">
<p dir="auto"><h3 tabindex="-1" dir="auto">CubeCL - Topology</h3><a id="user-content-cubecl---topology" aria-label="Permalink: CubeCL - Topology" href="#cubecl---topology"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/tracel-ai/cubecl/blob/main/assets/cubecl.drawio.svg"><img src="https://github.com/tracel-ai/cubecl/raw/main/assets/cubecl.drawio.svg" width="100%"></a>
<br>
</p></div>

<p dir="auto"><em>A cube is composed of units, so a 3x3x3 cube has 27 units that can be accessed by their positions along the x, y, and z axes.
Similarly, a hyper-cube is composed of cubes, just as a cube is composed of units.
Each cube in the hyper-cube can be accessed by its position relative to the hyper-cube along the x, y, and z axes.
Hence, a hyper-cube of 3x3x3 will have 27 cubes.
In this example, the total number of working units would be 27 x 27 = 729.</em></p>
<details>
<summary>Topology Equivalence 👇</summary>

<p dir="auto">Since all topology variables are constant within the kernel entry point, we chose to use the Rust constant syntax with capital letters.
Often when creating kernels, we don't always care about the relative position of a unit within a cube along each axis, but often we only care about its position in general.
Therefore, each kind of variable also has its own axis-independent variable, which is often not present in other languages.</p>
<br>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>CubeCL</th>
<th>CUDA</th>
<th>WebGPU</th>
<th>Metal</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUBE_COUNT</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>CUBE_COUNT_X</td>
<td>gridDim.x</td>
<td>num_workgroups.x</td>
<td>threadgroups_per_grid.x</td>
</tr>
<tr>
<td>CUBE_COUNT_Y</td>
<td>gridDim.y</td>
<td>num_workgroups.y</td>
<td>threadgroups_per_grid.y</td>
</tr>
<tr>
<td>CUBE_COUNT_Z</td>
<td>gridDim.z</td>
<td>num_workgroups.z</td>
<td>threadgroups_per_grid.z</td>
</tr>
<tr>
<td>CUBE_POS</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>CUBE_POS_X</td>
<td>blockIdx.x</td>
<td>workgroup_id.x</td>
<td>threadgroup_position_in_grid.x</td>
</tr>
<tr>
<td>CUBE_POS_Y</td>
<td>blockIdx.y</td>
<td>workgroup_id.y</td>
<td>threadgroup_position_in_grid.y</td>
</tr>
<tr>
<td>CUBE_POS_Z</td>
<td>blockIdx.z</td>
<td>workgroup_id.z</td>
<td>threadgroup_position_in_grid.z</td>
</tr>
<tr>
<td>CUBE_DIM</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>CUBE_DIM_X</td>
<td>blockDim.x</td>
<td>workgroup_size.x</td>
<td>threads_per_threadgroup.x</td>
</tr>
<tr>
<td>CUBE_DIM_Y</td>
<td>blockDim.y</td>
<td>workgroup_size.y</td>
<td>threads_per_threadgroup.y</td>
</tr>
<tr>
<td>CUBE_DIM_Z</td>
<td>blockDim.z</td>
<td>workgroup_size.z</td>
<td>threads_per_threadgroup.z</td>
</tr>
<tr>
<td>UNIT_POS</td>
<td>N/A</td>
<td>local_invocation_index</td>
<td>thread_index_in_threadgroup</td>
</tr>
<tr>
<td>UNIT_POS_X</td>
<td>threadIdx.x</td>
<td>local_invocation_id.x</td>
<td>thread_position_in_threadgroup.x</td>
</tr>
<tr>
<td>UNIT_POS_Y</td>
<td>threadIdx.y</td>
<td>local_invocation_id.y</td>
<td>thread_position_in_threadgroup.y</td>
</tr>
<tr>
<td>UNIT_POS_Z</td>
<td>threadIdx.z</td>
<td>local_invocation_id.z</td>
<td>thread_position_in_threadgroup.z</td>
</tr>
<tr>
<td>PLANE_POS</td>
<td>N/A</td>
<td>subgroup_id</td>
<td>simdgroup_index_in_threadgroup</td>
</tr>
<tr>
<td>PLANE_DIM</td>
<td>warpSize</td>
<td>subgroup_size</td>
<td>threads_per_simdgroup</td>
</tr>
<tr>
<td>UNIT_POS_PLANE</td>
<td>N/A</td>
<td>subgroup_invocation_id</td>
<td>thread_index_in_simdgroup</td>
</tr>
<tr>
<td>ABSOLUTE_POS</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>ABSOLUTE_POS_X</td>
<td>N/A</td>
<td>global_id.x</td>
<td>thread_position_in_grid.x</td>
</tr>
<tr>
<td>ABSOLUTE_POS_Y</td>
<td>N/A</td>
<td>global_id.y</td>
<td>thread_position_in_grid.y</td>
</tr>
<tr>
<td>ABSOLUTE_POS_Z</td>
<td>N/A</td>
<td>global_id.z</td>
<td>thread_position_in_grid.z</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Special Features</h2><a id="user-content-special-features" aria-label="Permalink: Special Features" href="#special-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Automatic Vectorization</h3><a id="user-content-automatic-vectorization" aria-label="Permalink: Automatic Vectorization" href="#automatic-vectorization"></a></p>
<p dir="auto">High-performance kernels should rely on SIMD instructions whenever possible, but doing so can quickly get pretty complicated!
With CubeCL, you can specify the vectorization factor of each input variable when launching a kernel.
Inside the kernel code, you still use only one type, which is dynamically vectorized and supports automatic broadcasting.
The runtimes are able to compile kernels and have all the necessary information to use the best instruction!
However, since the algorithmic behavior may depend on the vectorization factor, CubeCL allows you to access it directly in the kernel when needed, without any performance loss, using the comptime system!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Comptime</h3><a id="user-content-comptime" aria-label="Permalink: Comptime" href="#comptime"></a></p>
<p dir="auto">CubeCL isn't just a new compute language: though it feels like you are writing GPU kernels, you are, in fact, writing compiler plugins that you can fully customize!
Comptime is a way to modify the compiler IR at runtime when compiling a kernel for the first time.</p>
<p dir="auto">This enables lots of optimizations and flexibility without having to write many separate variants of the same kernels to ensure maximal performance.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Instruction Specialization</strong></td>
<td>Not all instructions are available on all hardware, but when a specialized one exists, it should be enabled with a simple if statement.</td>
</tr>
<tr>
<td><strong>Automatic Vectorization</strong></td>
<td>When you can use SIMD instructions, you should! But since not all hardware supports the same vectorization factors, it can be injected at runtime!</td>
</tr>
<tr>
<td><strong>Loop Unrolling</strong></td>
<td>You may want multiple flavors of the same kernel, with loop unrolling for only a certain range of values. This can be configured easily with Comptime.</td>
</tr>
<tr>
<td><strong>Shape Specialization</strong></td>
<td>For deep learning kernels, it's often crucial to rely on different kernels for different input sizes; you can do it by passing the shape information as Comptime values.</td>
</tr>
<tr>
<td><strong>Compile Time Calculation</strong></td>
<td>In general, you can calculate a constant using Rust runtime properties and inject it into a kernel during its compilation, to avoid recalculating it during each execution.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Autotuning</h3><a id="user-content-autotuning" aria-label="Permalink: Autotuning" href="#autotuning"></a></p>
<p dir="auto">Autotuning drastically simplifies kernel selection by running small benchmarks at runtime to figure out the best kernels with the best configurations to run on the current hardware; an essential feature for portability.
This feature combines gracefully with comptime to test the effect of different comptime values on performance; sometimes it can be surprising!</p>
<p dir="auto">Even if the benchmarks may add some overhead when running the application for the first time, the information gets cached on the device and will be reused.
It is usually a no-brainer trade-off for throughput-oriented programs such as deep learning models.
You can even ship the autotune cache with your program, reducing cold start time when you have more control over the deployment target.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Resource</h2><a id="user-content-resource" aria-label="Permalink: Resource" href="#resource"></a></p>
<p dir="auto">For now we don't have a lot of resources to learn, but you can look at the <a href="https://github.com/tracel-ai/cubecl/blob/main/crates/cubecl-linalg/README.md">linear algebra library</a> to see how CubeCL can be used.
If you have any questions or want to contribute, don't hesitate to join the <a href="https://discord.gg/KSBSPhAUCc" rel="nofollow">Discord</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer &amp; History</h2><a id="user-content-disclaimer--history" aria-label="Permalink: Disclaimer &amp; History" href="#disclaimer--history"></a></p>
<p dir="auto">CubeCL is currently in <strong>alpha</strong>.</p>
<p dir="auto">While CubeCL is used in <a href="https://burn.dev/" rel="nofollow">Burn</a>, there are still a lot of rough edges; it isn't refined yet.
The project started as a WebGPU-only backend for Burn.
As we optimized it, we realized that we needed an intermediate representation (IR) that could be optimized then compiled to WGSL.
Having an IR made it easy to support another compilation target, so we made a CUDA runtime.
However, writing kernels directly in that IR wasn't easy, so we created a Rust frontend using the <a href="https://github.com/dtolnay/syn">syn</a> crate.
Navigating the differences between CUDA and WebGPU, while leveraging both platforms, forced us to come up with general concepts that worked everywhere.
Hence, CubeCL was born!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yagri: You are gonna read it (259 pts)]]></title>
            <link>https://www.scottantipa.com/yagri</link>
            <guid>43776967</guid>
            <pubDate>Wed, 23 Apr 2025 21:47:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scottantipa.com/yagri">https://www.scottantipa.com/yagri</a>, See on <a href="https://news.ycombinator.com/item?id=43776967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        
        <p><b>April, 2025</b></p>

        <p>
            YAGNI, or, <a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it">You aren't gonna need it</a>,
            is a standard piece of advice that warns against over engineering
            and building too many features too early. I think its great and saves you from wasting time, which
            can kill a project.
        </p>

        <p>
            However, there's an exception that I call YAGRI, or, "You are gonna read it". It means that you shouldn't just store
            the minimum
            data required to satisfy the current product spec. You should also store data that you'll highly likely use (read),
            such as timestamps and contextual metadata.
        </p>

        <p>
            This problem tends to happen when a UI design shows that you only need to display a few specific bits of data to the
            user,
            so you only store those exact fields in the database. You've satisfied the design and ship it. Then later you realize
            you're missing valuable information to help debug an issue, do internal analytics, etc.
        </p>

        <p>
            As an example, this commonly occurs when implementing a feature to let users delete something. The easy way
            is to just
            delete the row from the database, and maybe that's all that the current UI design call for.
            In this situation, regardless of the requested feature set, as engineers we should maintain good data standards
            and store:
        </p>
        <ul>
            <li>who deleted it</li>
            <li>how they deleted it (with what permission)</li>
            <li>when</li>
            <li>why (surrounding context, if possible)</li>
        </ul>

        <p>
            In general, these are some useful fields to store on almost any table:
        </p>
        <ul>
            <li>created_at</li>
            <li>updated_at</li>
            <li>deleted_at (soft deletes)</li>
            <li>created_by etc</li>
            <li>permission used during CRUD</li>
        </ul>

        <p>
            This practice will pay off with just a single instance of your boss popping into a meeting and going "wait
            do we know why that thing was deleted, the customer is worried...".
            
        </p>
        <p>
            However, not every one of these fields that you store will end up serving a purpose. But maybe just a single
            field on a single table will save you one day, and that makes up for the costs of implementing a dozen others.
            Most of the apps we build, at the end of the day, are about storing data to keep track of facts.            
            It's quite possibly your most important job as an engineer to steward and maintain this data.
        </p>

        <p>
            Of course you can go too far in the other direction. You shouldnt just log everything.
            But I've never heard someone complain about a table having too many timestamps.
        </p>
                
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google blocked Motorola use of Perplexity AI, witness says (196 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant</link>
            <guid>43776512</guid>
            <pubDate>Wed, 23 Apr 2025 20:52:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant">https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant</a>, See on <a href="https://news.ycombinator.com/item?id=43776512">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Doge Worker's Code Supports NLRB Whistleblower (909 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/04/doge-workers-code-supports-nlrb-whistleblower/</link>
            <guid>43776476</guid>
            <pubDate>Wed, 23 Apr 2025 20:48:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/04/doge-workers-code-supports-nlrb-whistleblower/">https://krebsonsecurity.com/2025/04/doge-workers-code-supports-nlrb-whistleblower/</a>, See on <a href="https://news.ycombinator.com/item?id=43776476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>A whistleblower at the <strong>National Labor Relations Board</strong> (NLRB) alleged last week that denizens of Elon Musk’s <strong>Department of Government Efficiency</strong> (DOGE) siphoned gigabytes of data from the agency’s sensitive case files in early March. The whistleblower said accounts created for DOGE at the NLRB downloaded three code repositories from <strong>GitHub</strong>. Further investigation into one of those code bundles shows it is remarkably similar to a program published in January 2025 by <strong>Marko Elez</strong>, a 25-year-old DOGE employee who has worked at a number of Musk’s companies.</p>
<div id="attachment_71090"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71090" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds.png" alt="" width="748" height="323" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds.png 1287w, https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds-768x331.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds-782x337.png 782w" sizes="(max-width: 748px) 100vw, 748px"></a></p><p id="caption-attachment-71090">A screenshot shared by NLRB whistleblower Daniel Berulis shows three downloads from GitHub.</p></div>
<p>According to <a href="https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/" target="_blank" rel="noopener">a whistleblower complaint</a> filed last week by&nbsp;<strong>Daniel J. Berulis</strong>, a 38-year-old security architect at the NLRB, officials from DOGE met with NLRB leaders on March 3 and demanded the creation of several&nbsp;all-powerful “tenant admin” accounts that were to be exempted from network logging activity that would otherwise keep a detailed record of all actions taken by those accounts.</p>
<p>Berulis said the new DOGE accounts had unrestricted permission to read, copy, and alter information contained in NLRB databases. The new accounts also could restrict log visibility, delay retention, route logs elsewhere, or even remove them entirely — top-tier user privileges that neither Berulis nor his boss possessed.</p>
<p>Berulis said he discovered one of the DOGE accounts had downloaded three external code libraries from <strong>GitHub</strong> that neither NLRB nor its contractors ever used. A “readme” file in one of the code bundles explained it was created to rotate connections through a large pool of cloud Internet addresses that serve “<em>as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing</em>.” Brute force attacks involve automated login attempts that try many credential combinations in rapid sequence.</p>
<p>A search on that description in Google brings up a code repository at GitHub for a user with the account name “<strong>Ge0rg3</strong>” who published a program roughly four years ago called “<a href="https://github.com/Ge0rg3/requests-ip-rotator" target="_blank" rel="noopener">requests-ip-rotator</a>,” described as a library that will allow the user “to bypass IP-based rate-limits for sites and services.”</p>
<div id="attachment_71091"><p><img aria-describedby="caption-attachment-71091" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh.png" alt="" width="749" height="543" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh.png 1171w, https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh-768x557.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh-782x568.png 782w" sizes="(max-width: 749px) 100vw, 749px"></p><p id="caption-attachment-71091">The README file from the GitHub user Ge0rg3’s page for requests-ip-rotator includes the exact wording of a program the whistleblower said was downloaded by one of the DOGE users. Marko Elez created an offshoot of this program in January 2025.</p></div>
<p>“A Python library to utilize AWS API Gateway’s large IP pool as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing,” the description reads.</p>
<p>Ge0rg3’s code is “open source,” in that anyone can copy it and reuse it non-commercially. As it happens, there is a newer version of this project that was derived or “forked” from Ge0rg3’s code — called “<a href="https://github.com/markoelez/async-ip-rotator/blob/master/README.md" target="_blank" rel="noopener">async-ip-rotator</a>” — and it was committed to GitHub in January 2025 by DOGE captain <a href="https://github.com/markoelez" target="_blank" rel="noopener">Marko Elez</a>.</p>
<div id="attachment_71085"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71085" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh.png" alt="" width="750" height="492" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh.png 1150w, https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh-768x504.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh-782x513.png 782w" sizes="(max-width: 750px) 100vw, 750px"></a></p><p id="caption-attachment-71085">The whistleblower stated that one of the GitHub files downloaded by the DOGE employees who transferred sensitive files from an NLRB case database was an archive whose README file read: “Python library to utilize AWS API Gateway’s large IP pool as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing.” Elez’s code pictured here was forked in January 2025 from a code library that shares the same description.</p></div>
<p>A key DOGE staff member who gained access to the Treasury Department’s central payments system, Elez has worked for a number of Musk companies, including <strong>X</strong>, <strong>SpaceX</strong>, and <strong>xAI</strong>. Elez was among the first DOGE employees to face public scrutiny, after <strong>The Wall Street Journal</strong> <a href="https://www.wsj.com/tech/doge-staffer-resigns-over-racist-posts-d9f11a93" target="_blank" rel="noopener">linked him to social media posts</a> that advocated racism and eugenics.</p>
<p>Elez resigned after that brief scandal, but was rehired after President Donald Trump and Vice President JD Vance expressed support for him. <strong>Politico</strong> <a href="https://www.politico.com/news/2025/03/29/doge-marco-elez-software-engineer-us-payroll-00259303" target="_blank" rel="noopener">reports</a> Elez is now a <strong>Labor Department</strong> aide detailed to multiple agencies, including the <strong>Department of Health and Human Services</strong>.</p>
<p>“During Elez’s initial stint at Treasury, he violated the agency’s information security policies by sending a spreadsheet containing names and payments information to officials at the General Services Administration,” Politico wrote, citing court filings.</p>
<p>KrebsOnSecurity sought comment from both the NLRB and DOGE, and will update this story if either responds.<span id="more-71075"></span></p>
<p>The NLRB has been effectively hobbled since <strong>President Trump</strong> fired three board members, leaving the agency without the quorum it needs to function. Both&nbsp;<strong>Amazon</strong>&nbsp;and Musk’s&nbsp;<strong>SpaceX</strong>&nbsp;have&nbsp;<a href="https://apnews.com/article/amazon-nlrb-unconstitutional-spacex-elon-musk-ab42977117d883e97110a7bf8e8b257f" target="_blank" rel="noopener">been suing</a>&nbsp;the NLRB over complaints the agency filed in disputes about workers’ rights and union organizing, arguing that the NLRB’s very existence is unconstitutional. On March 5, a U.S. appeals court&nbsp;<a href="https://www.reuters.com/legal/government/musks-spacex-loses-early-legal-challenge-us-labor-boards-powers-2025-03-05/" target="_blank" rel="noopener">unanimously rejected</a>&nbsp;Musk’s claim that the NLRB’s structure somehow violates the Constitution.</p>
<p>Berulis’s complaint alleges the DOGE accounts at NLRB downloaded more than 10 gigabytes of data from the agency’s case files, a database that includes reams of sensitive records including information about employees who want to form unions and proprietary business documents. Berulis said he went public after higher-ups at the agency told him not to report the matter to the US-CERT, as they’d previously agreed.</p>
<p>Berulis told KrebsOnSecurity he worried the unauthorized data transfer by DOGE could unfairly advantage defendants in a number of ongoing labor disputes before the agency.</p>
<p>“If any company got the case data that would be an unfair advantage,” Berulis said. “They could identify and fire employees and union organizers without saying why.”</p>
<div id="attachment_71106"><p><img aria-describedby="caption-attachment-71106" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/markoelez.png" alt="" width="444" height="515"></p><p id="caption-attachment-71106">Marko Elez, in a photo from a social media profile.</p></div>
<p>Berulis said the other two GitHub archives that DOGE employees downloaded to NLRB systems included <strong>Integuru</strong>, a software framework designed to reverse engineer application programming interfaces (APIs) that websites use to fetch data; and a “headless” browser called <strong>Browserless</strong>, which is made for automating web-based tasks that require a pool of browsers, such as web scraping and automated testing.</p>
<p>On February 6, someone <a href="https://github.com/markoelez/async-ip-rotator/issues/1" target="_blank" rel="noopener">posted a lengthy and detailed critique</a> of Elez’s code on the GitHub “issues” page for async-ip-rotator, calling it “insecure, unscalable and a fundamental engineering failure.”</p>
<p>“If this were a side project, it would just be bad code,” the reviewer wrote. “But if this is representative of how you build production systems, then there are much larger concerns. This implementation is fundamentally broken, and if anything similar to this is deployed in an environment handling sensitive data, it should be audited immediately.”</p>
<p>Further reading:&nbsp;<a href="https://whistlebloweraid.org/wp-content/uploads/2025/04/2025_0414_Berulis-Disclosure-with-Exhibits.s.pdf" target="_blank" rel="noopener">Berulis’s complaint</a>&nbsp;(PDF).</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Wouldn't Steal a Font (1163 pts)]]></title>
            <link>https://fedi.rib.gay/notes/a6xqityngfubsz0f</link>
            <guid>43775926</guid>
            <pubDate>Wed, 23 Apr 2025 19:42:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fedi.rib.gay/notes/a6xqityngfubsz0f">https://fedi.rib.gay/notes/a6xqityngfubsz0f</a>, See on <a href="https://news.ycombinator.com/item?id=43775926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="splash"><p><img id="splashIcon" src="https://fedi.rib.gay/static-assets/splash.png?1745440201643"><span id="splashText">Loading...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First Successful Lightning Triggering and Guiding Using a Drone (157 pts)]]></title>
            <link>https://group.ntt/en/newsrelease/2025/04/18/250418a.html</link>
            <guid>43775766</guid>
            <pubDate>Wed, 23 Apr 2025 19:24:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://group.ntt/en/newsrelease/2025/04/18/250418a.html">https://group.ntt/en/newsrelease/2025/04/18/250418a.html</a>, See on <a href="https://news.ycombinator.com/item?id=43775766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                
                <p>News Highlights:</p>
<!-- [/c-txt-2] -->

<div>
<ol>
    <li><span>◆</span>We have achieved the world's first successful lightning triggering and guiding using a drone by harnessing electric field fluctuations.</li>
    <li><span>◆</span>We developed and validated a lightning protection cage design that prevents malfunction or damage even when the drone is struck directly by lightning. This design can also be implemented on commercial drones.</li>
    <li><span>◆</span>In the future, we aim to protect cities and infrastructure with "lightning drones," working toward a society free from lightning-related damage.</li>
</ol>
</div>
<!-- [/c-txt-list-1] -->

<p><span>TOKYO - April 18, 2025 - </span>NTT Corporation (Headquarters: Chiyoda, Tokyo; President and CEO: Akira Shimada; hereinafter "NTT") has become the first in the world to successfully trigger and guide lightning using a drone. This experiment also demonstrated, under natural lightning conditions, the effectiveness of both the drone's lightning protection technology and the electric field-based lightning triggering method. These results are expected to contribute to further research on the still-mysterious mechanisms of lightning and to help reduce lightning-related damage to cities and people.</p>
<!-- [/c-box-1] -->

<h3>Background</h3>
<!-- [/c-ttl-2] -->

<p>Lightning strikes are one of the most destructive natural phenomena affecting human society. While the NTT Group has implemented various lightning protection measures for critical infrastructure—including telecommunications facilities—lightning-related damage remains a persistent issue. In Japan alone, the estimated annual cost of lightning damage ranges from 100 to 200 billion yen<sup>1</sup>. Building on its long-standing expertise in protecting communications equipment from lightning, NTT is now working to advance this technology further, with the aim of eliminating lightning strikes on infrastructure and urban areas altogether.<br>
　Traditionally, lightning protection has relied heavily on lightning rods. However, their protective range is limited, and in some cases—such as wind turbines or outdoor event venues—it may not be feasible to install them. At NTT, we are exploring the use of rapidly advancing drone technology to create a new approach: "drone-triggered lightning"<sup>2</sup>. This method involves flying drones into optimal positions beneath thunderclouds to actively trigger lightning strikes, and then guiding the discharge safely away from vulnerable areas.</p>
<!-- [/c-txt-1] -->

<h3>Overview and Key Findings of the Experiment</h3>
<!-- [/c-ttl-2] -->

<p>From December 2024 to January 2025, a lightning-triggering experiment using drones was conducted at an elevation of 900 meters in a mountainous area of Hamada City, Shimane Prefecture. In this experiment, a device called a field mill<sup>3</sup> was used to monitor the electric field at ground level. When the electric field strength increased due to the approach of a thundercloud, a drone equipped with a custom-designed lightning protection cage was launched to attempt lightning triggering (Figure 1).</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418aa.jpg" alt="Figure 1 Lightning Protection Drone">
    <span><span><span>Figure 1 </span><span>Lightning Protection Drone</span></span></span>
</p>
<!-- [/c-img-4] -->

<p>On December 13, 2024, during the approach of a thundercloud, the electric field strength observed by the field mill increased. At that moment, a drone equipped with a conductive wire was flown to an altitude of 300 meters. The drone was then electrically connected to the ground via a switch installed on the ground (Figure 2). As a result, a large current was observed flowing through the wire, accompanied by a significant change in the surrounding electric field strength (Figure 3).<br>
　Just before the lightning strike, it was confirmed that a voltage of over 2000 volts had developed between the wire and the ground. This rapid increase in local electric field strength triggered a lightning strike directed at the drone. This marks the first successful case in the world of triggering lightning using a drone.<br>
　At the moment of the strike, a loud cracking sound was heard, a flash was observed at the winch, and partial melting occurred in the drone's lightning protection cage (Figure 4). However, the drone equipped with the protective cage continued to fly stably even after the lightning strike.</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ab.jpg" alt="Figure 2 Experimental Setup for Drone-Based Lightning Triggering">
    <span><span><span>Figure 2 </span><span>Experimental Setup for Drone-Based Lightning Triggering</span></span></span>
</p>
<!-- [/c-img-4] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ac.jpg" alt="Figure 3 Observed Waveforms During Lightning Triggering">
    <span><span><span>Figure 3 </span><span>Observed Waveforms During Lightning Triggering</span></span></span>
</p>
<!-- [/c-img-4] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ad.jpg" alt="Figure 4 Flash Emission from the Winch During Lightning Triggering">
    <span><span><span>Figure 4 </span><span>Flash Emission from the Winch During Lightning Triggering</span></span></span>
</p>
<!-- [/c-img-4] -->

<h3>Technical Highlights</h3>
<!-- [/c-ttl-2] -->

<p>To successfully trigger lightning using a drone, the drone must remain operational even after being struck. Moreover, simply flying a drone under a thundercloud is not sufficient to attract lightning; an active triggering method is required. To address these challenges, we proposed and demonstrated the following two key technologies:</p>
<!-- [/c-txt-1] -->

<h4>(1) Lightning Protection Technology for Drones</h4>
<!-- [/c-ttl-3] -->

<p>We developed a lightning protection cage design that prevents malfunction or damage even if the drone is directly struck by lightning. This cage, which can be mounted on commercially available drones, is made of conductive metal and functions as a shield. It redirects the high current from the lightning strike away from the drone's internal components, preventing it from flowing through the drone itself. Additionally, the cage is designed to distribute the lightning current radially, which cancels out the strong magnetic fields generated by the current and minimizes electromagnetic interference with the drone (Figure 5).<br>
　Furthermore, we conducted artificial lightning tests on drones equipped with the lightning protection cage. The results showed that the system withstood artificial strikes of up to 150 kA—five times greater than the average natural lightning strike—without any malfunction or damage, covering over 98% of naturally occurring lightning conditions.</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ae.jpg" alt="Figure 5 Lightning Protection Design for High Current and Strong Magnetic Fields">
    <span><span><span>Figure 5 </span><span>Lightning Protection Design for High Current and Strong Magnetic Fields</span></span></span>
</p>
<!-- [/c-img-4] -->

<h4>(2) Electric Field–Based Lightning Triggering Technology</h4>
<!-- [/c-ttl-3] -->

<p>To actively trigger lightning, we devised a method in which a conductive wire connects the drone to the ground, with a high-voltage switch installed on the ground side. By operating this switch at the optimal moment, we can rapidly change the electric field around the drone. This sharp increase in local electric field strength encourages a lightning discharge to occur toward the drone (Figure 6).</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418af.jpg" alt="Figure 6 Principle of Electric Field–Based Lightning Triggering Technology">
    <span><span><span>Figure 6 </span><span>Principle of Electric Field–Based Lightning Triggering Technology</span></span></span>
</p>
<!-- [/c-img-4] -->

<h3>Outlook</h3>
<!-- [/c-ttl-2] -->

<p>NTT aims to protect cities and people from lightning damage by flying drones—designed to withstand direct lightning strikes—to accurately predict lightning-prone locations, actively trigger strikes, and safely guide them away. To improve the success rate of drone-based lightning triggering, we will continue to advance research and development in two key areas: high-precision lightning location prediction and a deeper understanding of lightning mechanisms. In addition, we aim to not only trigger and control lightning, but also to harness its energy. Future efforts will focus on developing technologies for capturing and storing lightning energy for potential use (Figure 7).</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ag.jpg" alt="Figure 7 NTT's Vision: Protecting Cities from Lightning and Harnessing Its Energy Using Drones">
    <span><span><span>Figure 7 </span><span>NTT's Vision: Protecting Cities from Lightning and Harnessing Its Energy Using Drones</span></span></span>
</p>
<!-- [/c-img-4] -->

<h3>[Glossary]</h3>
<!-- [/c-ttl-2] -->

<p><sup>1</sup><span>The Institute of Electrical Engineers of Japan, Technical Report No. 902, 2002.</span></p>
<!-- [/c-txt-9] -->

<p><sup>2</sup><span>Lightning triggering: The active process of "initiating" lightning and "guiding" it safely to a target location.</span></p>
<!-- [/c-txt-9] -->

<p><sup>3</sup><span>Field mill: A device used to measure atmospheric electric fields.</span></p>
<!-- [/c-txt-9] -->

<h3>About NTT</h3>
<!-- [/c-ttl-2] -->

<p>NTT contributes to a sustainable society through the power of innovation. We are a leading global technology company providing services to consumers and businesses as a mobile operator, infrastructure, networks, applications, and consulting provider. Our offerings include digital business consulting, managed application services, workplace and cloud solutions, data center and edge computing, all supported by our deep global industry expertise. We are over $92B in revenue and 330,000 employees, with $3.6B in annual R&amp;D investments. Our operations span across 80+ countries and regions, allowing us to serve clients in over 190 of them. We serve over 75% of Fortune Global 100 companies, thousands of other enterprise and government clients and millions of consumers.</p>
<!-- [/c-txt-2] -->

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The hidden cost of AI coding (186 pts)]]></title>
            <link>https://terriblesoftware.org/2025/04/23/the-hidden-cost-of-ai-coding/</link>
            <guid>43775358</guid>
            <pubDate>Wed, 23 Apr 2025 18:44:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terriblesoftware.org/2025/04/23/the-hidden-cost-of-ai-coding/">https://terriblesoftware.org/2025/04/23/the-hidden-cost-of-ai-coding/</a>, See on <a href="https://news.ycombinator.com/item?id=43775358">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<p><em>“The best moments in our lives are not the passive, receptive, relaxing times… The best moments usually occur if a person’s body or mind is stretched to its limits in a voluntary effort to accomplish something difficult and worthwhile.”</em> — Mihaly Csikszentmihalyi</p>
</blockquote>



<p>I know I’ve posted some upbeat content about AI before, <a href="https://terriblesoftware.org/2024/12/14/weve-been-here-before/">celebrating its potential</a> and <a href="https://terriblesoftware.org/2025/04/07/making-ai-actually-work-on-your-team/">encouraging teams to embrace these tools</a>. And honestly, I still believe in that future. But today I want to share something more personal, more nuanced — the one thing that currently worries me most about using AI for software development: <strong>lack of joy</strong>.</p>



<p>It’s easy to talk about productivity gains, competitive advantages, and how AI will reshape our industry. <a href="https://terriblesoftware.org/tag/ai/">We’ve had those conversations</a>. What’s harder to discuss is what might be lost along the way – something intangible but vital to many of us who chose this profession not just for the paycheck, but because we genuinely love the craft of programming.</p>



<hr>



<p>It’s 8:47 AM, fresh coffee steams on the table, and my headphones cocoon me in the perfect playlist. I go to Asana, where I know <em>exactly</em> what I need to do that day. I open Neovim and code starts <em>flowing</em> through me. I’ve lost the sense of time; I’m completely present in the moment.</p>



<p>That, my friends, is what I used to describe as a happy work day. I’m sure that some of you will resonate.</p>



<p>Those days I’d emerge tired but fulfilled. Something about the direct connection between thought and creation — where my fingers were simply the conduit for translating ideas into working software — felt almost transcendent. The struggle to solve problems, the small victories along the way, and the satisfaction of building something from nothing… these weren’t just aspects of the job; they were the reason I fell in love with programming in the first place.</p>



<p>This experience I’m describing is what psychologists call “flow” — a mental state where you’re fully immersed in an activity, energized by deep focus and complete involvement. First described by <a href="https://www.amazon.com/Flow-Psychology-Experience-Perennial-Classics/dp/0061339202/">Mihaly Csikszentmihalyi</a> (the psychologist I quoted at the beginning), flow is that sweet spot where challenge meets skill, where the task at hand is neither too easy (causing boredom) nor too difficult (causing anxiety). It’s a state strongly associated with creativity, productivity, and most importantly — happiness. For software developers, it’s that magical zone where problems become puzzles rather than obstacles, where hours pass like minutes, and where the boundary between you and your code seems to dissolve.</p>



<p>Fast forward to today, and that joy of coding is decreasing rapidly. Well, I’m a manager these days, so there’s that… But even when I do get technical, I usually just open Cursor and prompt my way out of 90% of it. It’s way more productive, but more passive as well.</p>



<p>Instead of that deep immersion where I’d craft each function, I’m now more like a <em>curator</em>? I describe what I want, evaluate what the AI gives me, tweak the prompts, and iterate. It’s efficient, yes. Revolutionary, even. But something essential feels missing — that state of flow where time vanishes and you’re completely absorbed in creation. If this becomes the dominant workflow across teams, do we risk an industry full of highly productive yet strangely detached developers?</p>



<hr>



<p>So that’s what I’m worried about, and honestly, I have no idea what to think of it. On one hand, it’s clear to me that people using AI tools <em>are</em> more productive. On the other hand, I worry about long-term happiness and joy in their craft when they’re simply hitting tab to generate code rather than writing it themselves.</p>



<p>When we outsource the parts of programming that used to demand our complete focus and creativity, do we also outsource the opportunity for satisfaction? Can we find the same fulfillment in prompt engineering that we once found in problem-solving through code?</p>



<p>Perhaps what we need is a new understanding of where happiness can exist in this AI-augmented world. Maybe the joy doesn’t have to disappear completely — it just shifts. Instead of finding delight in writing the perfect algorithm, perhaps we’ll discover satisfaction in the higher-level thinking about system design, in the creative process of describing exactly what we want to build, or in the human aspects of software development that AI can’t touch.</p>



<p>I don’t have all the answers. But maybe, just maybe, we need to be intentional about preserving (some) spaces in our work where flow can still happen — where we still code by hand sometimes, not because it’s efficient, but because it make us happy.</p>



<p>After all, if we lose the joy in our craft, what exactly are we optimizing for?</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sail-Trim Simulator (128 pts)]]></title>
            <link>https://simulator.atterwind.info/</link>
            <guid>43775283</guid>
            <pubDate>Wed, 23 Apr 2025 18:36:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simulator.atterwind.info/">https://simulator.atterwind.info/</a>, See on <a href="https://news.ycombinator.com/item?id=43775283">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Wind-Basics" target="_blank"><h2>Wind Basics</h2></a><p>
            Learn and get a better mental model about wind-gradient, apparent-wind, sail-twist at changing speeds and course
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Simulation" target="_blank"><h2>Simulator and Sail Trim</h2></a><p>
            Improve trimming through boat acceleration, especially in apparent wind high-performance sailing
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Real-world-comparison" target="_blank"><h2>Real world comparison</h2></a><p>
            Comparison with real-world A-Class foiling catamaran DNA F1x trim settings
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Usage" target="_blank"><h2>Simulator Usage</h2></a><p>
            Mouse, keyboard, touch and Weblink sharing
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki"><h2>More info</h2></a><p>
            Source code and documentation on <a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki" target="_blank">Github</a>
        </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teaching LLMs how to solid model (278 pts)]]></title>
            <link>https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html</link>
            <guid>43774990</guid>
            <pubDate>Wed, 23 Apr 2025 18:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html">https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html</a>, See on <a href="https://news.ycombinator.com/item?id=43774990">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>It turns out that LLMs can make CAD models for simple 3D mechanical parts. And, I think they’ll be extremely good at it soon.</p>

<h2 id="an-ai-mechanical-engineer">An AI Mechanical Engineer</h2>

<p>Code generation is the first breakthrough application for LLMs. What would an AI agent look like for mechanical engineering? Material selection, design for manufacturing, computer-aided manufacturing (CAM), and off-the-shelf part comparison would all be important features of an AI mechanical engineer. Perhaps, most importantly, an AI mechanical engineer would design and improve CAD models. Mechanical engineers typically design CAD using point-and-click software (e.g. Fusion 360, Solidworks, and Onshape). How could AI generate these solid models instead?</p>

<h2 id="code-generation-meets-cad">Code generation meets CAD</h2>

<p>One promising direction is training a generative model on millions of existing CAD files. This approach is being actively researched by <a href="https://damassets.autodesk.net/content/dam/autodesk/www/pdfs/brepgen.pdf">multiple</a> <a href="https://arxiv.org/pdf/2105.09492">teams</a> who are investigating both diffusion and transformer architectures. In particular, I like <a href="https://www.youtube.com/watch?v=5r1qQ5DOsUI">Autodesk Research</a>’s approach to encode the parametric primitives (points, curves, shapes, extrusions, etc) into a transformer architecture. However, as far as I understand, the models in these projects cannot yet take an arbitrary input command and generate a desired shape.</p>

<p>Then a few weeks ago, I was inspired by the <a href="https://github.com/ahujasid/blender-mcp">recent use of LLMs to drive Blender</a>, the open source modeling tool widely used for animation. Given that LLMs are incredibly good at generating code, perhaps programmatic interfaces for CAD modeling could be used to generate solid models in a similar way. I immediately thought of <a href="https://openscad.org/">OpenSCAD</a>, an open-source programmatic CAD tool that’s been developed for more than 15 years. Instead of using point-and-click software to create a solid model, the user writes a software script, which is then rendered into the solid CAD model.</p>

<h2 id="llms-rock-at-writing-openscad">LLMs rock at writing OpenSCAD</h2>

<p>To test it out, I created a simple project in Cursor, made a blank OpenSCAD script (Cursor.scad), and added some Cursor rules:</p>

<div><pre><code># Your rule content

- We're creating files to model things in open scad. 
- All the OpenScad files you create will be in Cursor.scad. I've set up this file such that if you edit it, it will automatically be read by OpenScad (it's the open file in the program). 
- If I want to save what you've done, I'll tell you and you should create a new file and put it in the Saved folder. 
- That's it! Overtime, if needed, we could create documentation about how to use OpenScad. 
- If I'm asking you to create a new design, you should delete the current contents of cursor.scad and add the new design into it.
- When I make requests you should always first develop a step by step plan. Then tell me the step by step plan. And then I'll tell you to start modeling. 
- When you're going through the step by step plans, only execute one step at a time. 
- When you've executed a step, ask the user if its right.
</code></pre></div>

<p>Then, I started using Cursor to create solid models.</p>

<p>Here’s an example:  “Create an iPhone case”.</p>

<p><img src="https://willpatrick.xyz/assets/images/blog/iphone.gif" alt="iPhone GIF"></p>

<p>It didn’t nail it on the first try, but with a couple of iterations (including giving it screenshots) we created a basic case.</p>

<p>You can also leverage OpenSCAD libraries (there are many public ones). Here, I use a library to make a thread for a flange.</p>

<p><img src="https://willpatrick.xyz/assets/images/blog/flange.gif" alt="Flange GIF"></p>

<p>One thing that’s pretty neat is that the LLM can use its general knowledge of mechanical engineering. For example, above, Cursor created holes in the pipe for M6 bolts and it correctly made the diameter slightly bigger than 6 mm, so the bolts could pass through.</p>

<pre><code>bolt_hole_d = 6.5; // Diameter for M6 bolts
</code></pre>

<p>Of course, one of the really nice things about this approach is that the files are editable and Cursor defaults to parameterizing all the key elements of the design. In the above example, I asked it to add holes for mounting bolts, which it did, and then I edited the number of holes manually to 3 from 4.</p>

<pre><code>// Flange parameter
flange_OD = 50; // Outer diameter of the flange in mm 
flange_thickness = 10; // Thickness of the flange in mm
pipe_size = 1/2; // NPT Pipe Size

// Bolt hole parameters
num_bolts = 3;
bolt_hold_d = 6.5; // Diameter for M6 bolts
bold_hole_circle = 35; // Diameter for the bolt circle
</code></pre>

<h2 id="building-an-eval-for-llm---openscad---stl">Building an eval for LLM -&gt; OpenSCAD -&gt; STL</h2>

<p>I was impressed by these initial results but I wanted to learn more. For example, did the model’s reasoning ability help it think through the steps of creating a part? So, I decided to develop an evaluation to test the performance of various LLMs at generating solid models via OpenSCAD.</p>

<p>One of the challenges with creating an eval for CAD design is that most tasks have many correct answers. For example, a task such as “make a m3 screw that’s 10mm long” could have many correct answers because the length, diameter, and style of the head are not defined in the task. To account for this, I decided to write the tasks in my eval such that there was only a single, correct interpretation of the geometry.</p>

<p>For example, here is one of the tasks in the eval:</p>

<blockquote>
  <p>This is a 3mm thickness rectangular plate with two holes.</p>

  <ol>
    <li>
      <p>The plate is 18mm x 32mm in dimension.</p>
    </li>
    <li>
      <p>When looking down at the plate, it has two holes that are drilled through it. In the bottom left of the plate, there’s a hole with a centerpoint that is 3mm from the short (18mm) side and 3 mm from the long (32mm) side. This hole has a diameter of 2mm.</p>
    </li>
    <li>
      <p>In roughly the top left corner of plate, there’s a hole of diameter 3mm. Its center point is 8mm from the short side (18mm side) and 6mm away from the long (32mm) side.</p>
    </li>
  </ol>
</blockquote>

<p>The benefit of this approach is that we can score each task as a Pass or Fail and we can do this in an automated way. I wrote 25 total CAD tasks which ranged in difficulty from a single operation (“A 50mm long pipe that has a 10mm outer diameter and 2mm wall thickness”) to 5 sequential operations. For each task, I designed a reference CAD model using Autodesk Fusion 360 and then exported a STL mesh file.</p>

<p>Then, I set about programming the automated eval pipeline (of course, <a href="https://willpatrick.xyz/software/2025/03/17/software-with-a-market-of-one.html">I didn’t actually write much code</a>).</p>

<p>Here is how the eval pipeline works:</p>

<ol>
  <li>For each task and model, the eval sends the text prompt (along with a system prompt) to the LLM via API.</li>
  <li>The LLM sends back the openSCAD code.</li>
  <li>The openSCAD code is rendered into a STL</li>
  <li>The generated STL is automatically checked against the reference STL</li>
  <li>The task “passes” if it passes a number of geometric checks.</li>
  <li>The results are then outputted in a dashboard.</li>
</ol>

<p>
graph LR
    A[Start Eval For each Task &amp; Model] --&gt; B{Send System + Task Prompt to LLM};
    B --&gt; C[LLM Returns OpenSCAD];
    C --&gt; D{Render OpenSCAD to STL};
    D --&gt; E{Compare Generated STL to Reference STL};
    E --&gt; I[Output Eval Results to Dashboard];
</p>

<p>[Note: The eval runs multiple replicates per task x model combo. And the eval is executed in parallel, because there can be 1000+ tasks when running the full evaluation.]</p>

<p>Here’s how the geometric check works:</p>

<ul>
  <li>The generated STL and reference STL are aligned using the iterative closest point (ICP) algorithm.</li>
  <li>The aligned meshes are then compared by:
    <ul>
      <li>Their volumes (pass = &lt;2% diff)</li>
      <li>Their bounding boxes (pass = &lt;1 mm)</li>
      <li>The average chamfer distance between the parts (pass = &lt;1 mm)</li>
      <li>The Hausdorff distance (95% percentile) (pass = &lt;1 mm)</li>
    </ul>
  </li>
  <li>To “pass” the eval, all of the geometric checks must be passed.</li>
</ul>

<p>There are a few areas where the eval pipeline could be improved. In particular, false negatives are common (est: ~5%). I’ve also noticed that occasionally, small features that are incorrect (like a small radius fillet) are not caught by the automated geometry check. Nevertheless, the eval pipeline is still good enough to see interesting results and compare the performance of the various LLMs.</p>

<p>If you’d like to learn more about the eval, use it, or check out the tasks, please check out the <a href="https://github.com/wgpatrick/cadeval">GitHub repo</a>.</p>

<p>Finally, there are a number of ways to improve the evaluation. Here are a few things that I’d like to do next:</p>

<ul>
  <li>More tasks with greater coverage</li>
  <li>Optimize system prompts, in particular by adding OpenSCAD documentation and code snippets</li>
  <li>Create an eval variation that uses sketches and drawings as input</li>
  <li>Add another variation that tests the ability of the LLM to add operations to existing OpenSCAD script and STL</li>
  <li>Evaluate the ability of the LLM to fix mistakes in an existing STL / OpenSCAD code</li>
</ul>

<h2 id="rapid-improvement-of-frontier-models">Rapid improvement of frontier models</h2>

<p>Here are the results from an eval run executed on April 22, 2025. In the eval run, 15 different models were tested on the 25 tasks with 2 replicates were task. All of the results and configuration details from the run are available <a href="https://willpatrick.xyz/cadevalresults_20250422_095709/">here</a>.</p>

<p>The results show that LLMs only became good at OpenSCAD solid modeling recently.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/overall_result2.png" alt="Results from CadEval">
  <figcaption>Results from CadEval. In this run, each model attempted to complete 25 tasks (2 replicates per task). "Success" means they passed a number of geometric checks that compared to a reference geometry.</figcaption>
</figure>

<p>The top 3 models were all launched while I was working on the project and the top 7 models are all reasoning models. These models offer large performance increases compared to their predecessor, non-reasoning counterparts. Sonnet 3.5 is the best non-reasoning model and Sonnet 3.7 is only slightly better performing in the eval (for Sonnet 3.7, thinking was used with a budget of 2500 tokens).</p>

<p>Digging into the results offers some interesting insights. First, the LLMs are quite good at generating OpenSCAD code that compiles correctly and can be rendered into a STL. In other words, only a small portion of the failures are coming from things like OpenSCAD syntax errors. Anthropic’s Sonnet models are the best at this.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/stl_render_success.png" alt="Rendering Success Rate">
  <figcaption>For the same eval run as above, the % of tasks for each model where a STL was rendered (and the geometry was checked).</figcaption>
</figure>

<p>Additionally, we can look at the success rate for tasks where a STL was rendered. The o3-mini is quite strong, with nearly the same sucess rate as the full-size o3 model, while Sonnet 3.7 appears to be a step behind the leading Gemini 2.5 Pro and o1, o3, o4-mini, and o3-mini models.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/success_rate_for_only_tasks_with_rendered_stl.png" alt="Success Rate if STL Rendered">
  <figcaption>Of tasks where a STL was generated, the % of tasks that successfully passed all geometric checks.</figcaption>
</figure>

<p>Finally, to be expected, Gemini 2.5 and o4-mini are substantially cheaper and slightly faster to run than the full o3 and o1 models.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/average_estimated_cost.png" alt="Average cost per task for various models">
  <figcaption>The estimated cost per task for each model.</figcaption>
</figure>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/average_estimated_time.png" alt="Average time per task for various models">
  <figcaption>The average total time per task to generate OpenSCAD and then render a STL. The time to make the API call and receive the OpenSCAD is much, much greater than the time to render the STL, which is  less than 1 second. </figcaption>
</figure>

<p>As expected, some tasks were easy and some tasks were hard to complete.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/task_success_rate.png" alt="Pass rate for each of the 25 tasks">
  <figcaption>Overall success rate task by task.</figcaption>
</figure>

<p>Generally, speaking tasks with more operations we’re more challenging.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/part_complexity.png" alt="Pass rate by part complexity">
  <figcaption>Each task required 1 to 5 operations to complete manually in Fusion360. Within the eval, there were 5 tasks that required a single operation, 5 required two, and so forth. </figcaption>
</figure>

<p>Tasks 2, Task 3, and Task 6 were the easiest tasks with over 80% correct across models. Here’s what these tasks looked like with example successes.</p>



<p>Only 2 tasks had 0% success, task 11 and task 15. Here are the prompts for those two tasks and representative failures.</p>



<p>These failures are both interesting and quite different. Task 11 is a good example of poor spatial reasoning. In the specific failure highlighted in the image, the model extrudes the shank of the eyebolt  orthogonally to the torus (instead of in the same plane). Task 15 is a different failure mode. It’s hard to see in the attached image, but if you zoom in closely, it’s clear that the generated shape is slightly larger than the reference shape (which makes sense, because the generated STL failed the volume check). From looking at the OpenSCAD code for this example, it appears that the failure is due to using OpenSCAD’s <a href="https://www.openscad.info/index.php/2020/10/18/hull/">hull operation</a>, which is not precisely the same as a loft operation. OpenSCAD does not have a loft operation built-in.</p>

<p>Tasks 20-24 all required 5 sequential operations and the average success rate for these tasks ranged from 3.3% to 30%. Here are the prompts for those 5 tasks with representative successes and failures.</p>

<p>The failures can be tricky to spot. The green areas of the failed images should have geometry in the generated STL, but do not (the reference point cloud is plotted in green). Likewise, the red areas have geometry in the generated STL, but they shouldn’t.</p>



<h2 id="start-ups">Start-ups</h2>

<p>In the past few months, two different start-ups launched text-to-CAD products, AdamCad and Zoo.dev. Zoo.dev offers an API to use their text-to-CAD model. Zoo’s demos of their API and text-to-CAD product are very cool and look quite similar to the Cursor -&gt; OpenSCAD demo I have above.</p>

<blockquote><div lang="en" dir="ltr"><p>We're excited to announce the launch of Zoo.dev, a text-to-CAD API that lets you generate 3D models from text descriptions.</p><p>We've been working on this for the past year, and we're finally ready to share it with the world.</p><p>Here's a thread on what we've built 🧵 <a href="https://t.co/Yd9Yd9Ixqm">pic.twitter.com/Yd9Yd9Ixqm</a></p></div>— Abhishek (@abhi1thakur) <a href="https://twitter.com/abhi1thakur/status/1881766438383337573?ref_src=twsrc%5Etfw">July 21, 2024</a></blockquote>


<p>I added Zoo into the eval pipeline to compare against LLM -&gt; OpenSCAD -&gt; STL. Instead of generating OpenSCAD, the Zoo.dev API shoots back a STL directly. Zoo says they use <a href="https://zoo.dev/machine-learning-api">a proprietary dataset and machine learning model</a>. To my surprise, Zoo’s API didn’t perform particularly well in comparison to LLMs generating STLs by creating OpenSCAD. Despite that, I’m excited to see the development of Zoo.dev and I will be eager to see how future model launches from Zoo.dev compare to LLMs creating OpenSCAD.</p>

<h2 id="whats-next">What’s next?</h2>

<p>I think these initial results are promising. Cursor (or another coding agent) + OpenSCAD offers a solution for producing solid models in an automated way.</p>

<p>However, I don’t think this approach is about to take off and spread rapidly through the CAD design ecosystem. The current set-up is seriously clunky and I think substantial product improvements are needed to make this work better. Similar to how Cursor, Windsurf, and other tools have developed specific UX and LLM workflows for code generation, I imagine there will be substantial work required to develop workflows and UX that make sense for CAD generation. Here are a few ideas that I think could be worth pursuing in this direction:</p>

<ul>
  <li>Tools that bring in console logs and viewport images to Cursor from OpenSCAD for iterative improvement and debugging.</li>
  <li>A UI to highlight (and measure) certain faces, lines, or aspects of a part, which are fed to the LLM for additional context.</li>
  <li>Drawing or sketch-input, so the user can quickly visually communicate their ideas.</li>
  <li>A UI with sliders to adjust parameters instead of editing the code.</li>
</ul>

<p>Additionally, I expect that further model advances will continue to unlock this application. In particular, improving spatial reasoning is an <a href="https://arxiv.org/pdf/2504.05786">active area of research</a>. I imagine that improved spatial reasoning could greatly improve models’ ability to design parts step by step.</p>

<p>So when does text-to-CAD become a commonly used tool for mechanical engineers? With start-ups actively building products and the rapid improvement of frontier models, my guess would be something like 6-24 months.</p>

<h2 id="where-does-this-go">Where does this go?</h2>

<p>In the medium to long term (2-10 years), I imagine that most parts will be created with a form of GenCAD. Allow me to speculate.</p>

<ul>
  <li>Initially, GenCAD will be used to create parts that fit within existing assemblies. For example, you might say: “I need a bracket that fits here.”  And, the GenCAD tool will create a bracket that perfectly joins with the existing assembly components. Want to analyze three variants with FEA? Ask for them. I expect mainstream CAD suites (Autodesk, Solidworks, Onshape) to add these capabilities directly into their product suite.</li>
  <li>Longer term, I imagine GenCAD will reach every aspect of a CAD suite: sketches, mates, assemblies, exploded views, CAM tool-pathing, rendering visualizations, and CAE. Imagine a design review where you highlight a subassembly and say “replace these rivets with M6 countersunk screws and regenerate the BOM.” The model, drawings, and purchasing spreadsheet all update in seconds.</li>
</ul>

<p>We’re watching CAD begin to exit the manual-input era. I, for one, am quite excited about that.</p>

<!-- Carousel CSS and JS -->





  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Graphics livecoding in Common Lisp (185 pts)]]></title>
            <link>https://kevingal.com/blog/cl-livecoding.html</link>
            <guid>43774726</guid>
            <pubDate>Wed, 23 Apr 2025 17:48:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kevingal.com/blog/cl-livecoding.html">https://kevingal.com/blog/cl-livecoding.html</a>, See on <a href="https://news.ycombinator.com/item?id=43774726">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <header>
        <p data-nosnippet="">
        <nav>
        <a href="https://kevingal.com/index.html">about</a>
        • <a href="https://kevingal.com/blog.html">blog</a>
        • <a href="https://kevingal.com/projects.html">projects</a>
        • <a href="https://kevingal.com/feed.xml">rss</a>
        </nav>
        </p>
    </header>


<h3>2025-04-23</h3>
<h3>Developing a Boids program from scratch without restarting it.</h3>
<p>Tags: <a href="https://kevingal.com/blog/tag/lisp.html">lisp</a> <a href="https://kevingal.com/blog/tag/programming.html">programming</a> <a href="https://kevingal.com/blog/tag/artsy.html">artsy</a> </p>
<a href="https://kevingal.com/blog/chess-detective.html">&lt;&lt; previous</a>
<hr>
<p>Some Lisps, like Common Lisp, have a powerful feature that tends to go underappreciated amidst all the talk about macros: the ability to recompile your program while it's running, without restarting it. For the purposes of this post, and because it sounds cool, let's call this ability <em>livecoding</em><sup id="fnref:livecod"><a href="#fn:livecod">1</a></sup>.</p>
<p>Entering this strange land where the programs never stop, we'll first take a brief tour of Common Lisp and one of its graphics frameworks, Sketch, before walking through a livecoded implementation of the <a href="https://en.wikipedia.org/wiki/Boids">Boids algorithm</a>.</p>
<figure>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/img/cl-livecoding/boids-sample.mp4" type="video/mp4">
</video> 
<figcaption>Boids!</figcaption>
</figure>

<h3 id="wait-what-exactly-is-this-livecoding-thing">"Wait, what exactly is this livecoding thing?"</h3>
<p>Consider the typical workflow needed to modify a running application, like a videogame.</p>
<ol>
<li>Stop the application.</li>
<li>Change the code.</li>
<li>(If a compiled language) Wait N time units for a full recompilation.</li>
<li>Start the application again.</li>
<li>Fiddle with the application to get it back to its previous state.</li>
<li>Carry on.</li>
</ol>
<p>In a livecoding environment, the application is never stopped, which eliminates steps 1, 4 and 5. Instead, small code changes (which can be as granular as recompiling a single function) are immediately reflected in the running program. Step 3 is often instantaneous because only the changed parts of the program must be recompiled. In theory, then, you can develop an entire application while it continuously runs in the background, without ever waiting for code to recompile. This makes the development process more fluid and interactive, with minimal downtime.</p>
<p>In Common Lisp, the workflow might look something like this:</p>
<ol>
<li>Make a small change to a single function.</li>
<li>Recompile the function (instantaneous).</li>
<li>Carry on.</li>
</ol>
<p>For an example of this workflow in action, check out Common Lisp and Emacs being used as an environment for <a href="https://www.youtube.com/watch?v=EkYUU0UoB_0">live musical performance</a>. You can hear about a Lisp program being debugged remotely while running in <a href="https://corecursive.com/lisp-in-space-with-ron-garret/">deep space</a>. Livecoding (or hot reloading, or whatever you like to call it) is also available in other languages, like Smalltalk and Erlang.</p>
<h3 id="a-rough-sketch-of-sketch">A rough sketch of Sketch</h3>
<p>Before jumping into Boids, let's take a brief look at <a href="https://github.com/vydd/sketch">Sketch</a>, our Common Lisp graphics framework of choice. We'll be more concerned with big ideas than with code minutiae, but if you're unfamiliar with Common Lisp and want to understand the code samples, then please take a detour through <a href="https://learnxinyminutes.com/common-lisp/">Learn Common Lisp in Y Minutes</a>.</p>
<p>So, Sketch. The Sketch API is heavily based on that of <a href="https://processing.org/">Processing</a>. Its primary entry point is the <code>defsketch</code> macro. The code below defines a "sketch" called <code>my-sketch</code>.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>my-sketch</span>
    <span>((</span><span>width</span> <span>200</span><span>)</span>
     <span>(</span><span>height</span> <span>200</span><span>)</span>
     <span>(</span><span>n</span> <span>5</span><span>))</span>
  <span>;; ...drawing code here...</span>
  <span>)</span>
</code></pre></div>

<p>After the name of the sketch comes a list of bindings that define its state and configuration. Here, the window properties <code>width</code> and <code>height</code> are set to <code>200</code>, while <code>n</code> is an attribute we've added for our own use.</p>
<p>Then comes the drawing code. This gets run in a loop while the sketch is running, once per frame. The following snippet draws 5 red circles on a black background, each of radius 10 and in random positions.</p>
<div><pre><span></span><code><span>(</span><span>background</span> <span>+black+</span><span>)</span>
<span>(</span><span>loop</span> <span>repeat</span> <span>n</span>
      <span>do</span> <span>(</span><span>with-pen</span> <span>(</span><span>make-pen</span> <span>:fill</span> <span>+red+</span><span>)</span>
           <span>(</span><span>circle</span> <span>(</span><span>random</span> <span>width</span><span>)</span> <span>(</span><span>random</span> <span>height</span><span>)</span> <span>10</span><span>)))</span>
</code></pre></div>

<p>After painting the background black, the all-powerful <code>loop</code> macro is used to draw <code>n</code> circles. The <code>with-pen</code> macro (defined by Sketch) configures drawing properties like fill colour, stroke width and stroke colour. It takes a "pen" object as an argument.</p>
<p>Here's all the code together:</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>my-sketch</span>
    <span>((</span><span>width</span> <span>200</span><span>)</span>
     <span>(</span><span>height</span> <span>200</span><span>)</span>
     <span>(</span><span>n</span> <span>5</span><span>))</span>
  <span>(</span><span>background</span> <span>+black+</span><span>)</span>
  <span>(</span><span>loop</span> <span>repeat</span> <span>n</span>
        <span>do</span> <span>(</span><span>with-pen</span> <span>(</span><span>make-pen</span> <span>:fill</span> <span>+red+</span><span>)</span>
             <span>(</span><span>circle</span> <span>(</span><span>random</span> <span>width</span><span>)</span> <span>(</span><span>random</span> <span>height</span><span>)</span> <span>10</span><span>))))</span>
</code></pre></div>

<p>Finally, to run the sketch, we compile our code and execute <code>(run-sketch 'my-sketch)</code> from the REPL, resulting in...</p>
<figure>
<img src="https://kevingal.com/static/img/cl-livecoding/sketch-sample.gif" alt="The result: red circles flashing on a black background.">
<figcaption>...art.</figcaption>
</figure>

<p>That's all we need to know about Sketch for now!</p>
<h3 id="livecoding-boids">Livecoding Boids</h3>
<p><a href="https://en.wikipedia.org/wiki/Boids">Boids</a> is an algorithm from 1986 for simulating flocks of birds. In its essence, it consists of applying 3 forces to the simulated birds. Quoting Wikipedia<sup id="fnref:boidsref"><a href="#fn:boidsref">2</a></sup>, these forces are:</p>
<blockquote>
<ul>
<li>separation: steer to avoid crowding local flockmates</li>
<li>cohesion: steer to move towards the average position (center of mass) of local flockmates</li>
<li>alignment: steer towards the average heading of local flockmates</li>
</ul>
</blockquote>
<p>How can we implement this ourselves? First, we need a canvas to draw on!</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>))</span>
  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
</code></pre></div>

<p>The only mysterious thing in this code is the <code>restart-on-change</code> parameter, which is available in my <a href="https://github.com/Kevinpgalligan/sketch">fork</a> of Sketch. When its value is <code>nil</code> (false), the sketch's state - like the boid positions - won't be reset when we recompile our code.</p>
<p>Compiling the defsketch form in Emacs (with the Ctrl-C Ctrl-C shortcut) and executing <code>(run-sketch 'boids)</code> at the REPL gives us... 🥁... a gray background. Wonderful.</p>
<figure>
<img src="https://kevingal.com/static/img/cl-livecoding/boids-1-canvas.png" alt="A light-gray background.">
</figure>

<p>(Note: all going well, this modest window will run continuously throughout the entire development lifecycle).</p>
<p>Now let's create some boids to populate our world. We add a <code>boid</code> class to store their position and velocity, as well as a convenience function <code>make-boid</code> to create a boid from x &amp; y co-ordinates. These rely on a hopefully self-explanatory implementation of 2d vectors, which are created using the <code>vec2</code> function.</p>
<div><pre><span></span><code><span>(</span><span>defclass</span> <span>boid</span> <span>()</span>
  <span>((</span><span>pos</span> <span>:initarg</span> <span>:pos</span> <span>:accessor</span> <span>pos</span><span>)</span>
   <span>(</span><span>velocity</span> <span>:initarg</span> <span>:velocity</span>
             <span>:initform</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)</span>
             <span>:accessor</span> <span>velocity</span><span>)))</span>

<span>(</span><span>defun</span> <span>make-boid</span> <span>(</span><span>x</span> <span>y</span><span>)</span>
  <span>(</span><span>make-instance</span> <span>'boid</span> <span>:pos</span> <span>(</span><span>vec2</span> <span>x</span> <span>y</span><span>)))</span>
</code></pre></div>

<p>To the sketch itself, we add 20 boids in random positions, and pass them to the <code>draw-boids</code> function in the drawing loop.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>)</span>
<span>     <span>(</span><span>boids</span> <span>(</span><span>loop</span> <span>repeat</span> <span>20</span>
</span><span>                  <span>collect</span> <span>(</span><span>make-boid</span> <span>(</span><span>random</span> <span>width</span><span>)</span> <span>(</span><span>random</span> <span>height</span><span>)))))</span>
</span>  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
<span>  <span>(</span><span>draw-boids</span> <span>boids</span><span>))</span>
</span></code></pre></div>

<p>If we then recompile defsketch (with Ctrl-C Ctrl-C)... </p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-2-missing-draw-compile.mp4" type="video/mp4">
</video>

<p>...we get an error! Woops. </p>
<figure>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-2-missing-draw.mp4" type="video/mp4">
</video> 
<figcaption>Before: gray canvas. After: red error screen.</figcaption>
</figure>

<p>But of course! We forgot to define <code>draw-boids</code>. The program doesn't crash, however, and we'll soon be able to recover from this setback.</p>
<p>Here's an implementation of <code>draw-boids</code>. We don't need to get into the weeds of how it works. For each boid, it does some unwieldy vector math to figure out which direction the boid is facing and draws a triangle pointing in that direction.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>draw-boids</span> <span>(</span><span>boids</span><span>)</span>
  <span>(</span><span>let</span> <span>((</span><span>boid-width</span> <span>10</span><span>)</span>
        <span>(</span><span>boid-length</span> <span>20</span><span>))</span>
    <span>(</span><span>loop</span> <span>for</span> <span>boid</span> <span>in</span> <span>boids</span>
          <span>do</span> <span>(</span><span>with-slots</span> <span>(</span><span>pos</span> <span>velocity</span><span>)</span> <span>boid</span>
               <span>(</span><span>with-pen</span> <span>(</span><span>:fill</span> <span>+black+</span><span>)</span>
                 <span>(</span><span>let*</span> <span>((</span><span>dir</span> <span>(</span><span>if</span> <span>(</span><span>zerop</span> <span>(</span><span>v-length</span> <span>velocity</span><span>))</span>
                                 <span>(</span><span>vec2</span> <span>0</span> <span>-1</span><span>)</span>
                                 <span>(</span><span>v-normalise</span> <span>velocity</span><span>)))</span>
                        <span>(</span><span>p1</span> <span>(</span><span>v+</span> <span>pos</span> <span>(</span><span>v-rescale</span> <span>(</span><span>/</span> <span>boid-length</span> <span>2</span><span>)</span> <span>dir</span><span>)))</span>
                        <span>(</span><span>p2</span> <span>(</span><span>v+</span> <span>pos</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>-</span> <span>(</span><span>/</span> <span>boid-length</span> <span>2</span><span>))</span> <span>dir</span><span>)</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>/</span> <span>boid-width</span> <span>2</span><span>)</span>
                                           <span>(</span><span>perpendicular-anticlockwise</span> <span>dir</span><span>))))</span>
                        <span>(</span><span>p3</span> <span>(</span><span>v+</span> <span>pos</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>-</span> <span>(</span><span>/</span> <span>boid-length</span> <span>2</span><span>))</span> <span>dir</span><span>)</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>/</span> <span>boid-width</span> <span>2</span><span>)</span>
                                           <span>(</span><span>perpendicular-clockwise</span> <span>dir</span><span>)))))</span>
                   <span>(</span><span>polygon</span> <span>(</span><span>vx</span> <span>p1</span><span>)</span> <span>(</span><span>vy</span> <span>p1</span><span>)</span>
                            <span>(</span><span>vx</span> <span>p2</span><span>)</span> <span>(</span><span>vy</span> <span>p2</span><span>)</span>
                            <span>(</span><span>vx</span> <span>p3</span><span>)</span> <span>(</span><span>vy</span> <span>p3</span><span>))))))))</span>
</code></pre></div>

<p>As soon as we compile <code>draw-boids</code>, the error screen disappears and our lovely boids are drawn into place. And we didn't have to restart the program to fix it!</p>
<figure>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-3-define-draw.mp4" type="video/mp4">
</video> 
<figcaption>Before: red error screen. After: boids are drawn.</figcaption>
</figure>

<p>There are two Common Lisp features that enable us to fix errors on-the-fly like we've done here:</p>
<ol>
<li>Newly compiled code, and recompiled code, is immediately loaded (sometimes called "hot reloading") into the running program. This opens up possibilities such as optimising a program as it runs, tweaking parameters like gravitational force and background colour, and iteratively developing a GUI.</li>
<li>The condition system! This is somewhat like exception handling in other languages, but more powerful. Not only can we signal exceptional situations ("conditions"), but we can also define "restarts" for recovering from those situations. When a running Common Lisp program encounters an unhandled condition, control passes to the debugger, and the user is presented with a selection of restarts. Perhaps they want to recompile the offending function and continue execution from the previous stack frame. Or perhaps the error was a division by zero, and the offending function provides a restart that swaps in a value of 1 for the divisor. Suddenly, there are a lot more possibilities than just crashing the program.</li>
</ol>
<p>Anyway, a worthy discussion of the condition system would take up a full blog post of its own. Back to Boids!</p>
<p>Now that our boids are drawn correctly, we want them to move around and do boid things. First, we implement an <code>update-positions</code> function, which basically adds the velocity of each boid to its position (so that the boid moves), and applies the 3 Boidian forces to update the boid's velocity. For now, the functions implementing these forces are stubbed out.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>update-positions</span> <span>(</span><span>boids</span><span>)</span>
  <span>(</span><span>let</span> <span>((</span><span>max-velocity</span> <span>10</span><span>))</span>
    <span>;; Update boid positions.</span>
    <span>(</span><span>map</span> <span>nil</span>
         <span>(</span><span>lambda</span> <span>(</span><span>boid</span><span>)</span>
           <span>(</span><span>setf</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>v+</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>velocity</span> <span>boid</span><span>))))</span>
         <span>boids</span><span>)</span>

    <span>;; Update boid velocities.</span>
    <span>(</span><span>loop</span> <span>for</span> <span>boid</span> <span>in</span> <span>boids</span>
          <span>do</span> <span>(</span><span>setf</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                   <span>(</span><span>v-clamp</span> <span>max-velocity</span>
                            <span>(</span><span>v+</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                                <span>(</span><span>rule1</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule2</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule3</span> <span>boid</span> <span>boids</span><span>)))))))</span>

<span>;; Stubs! (For now).</span>
<span>(</span><span>defun</span> <span>rule1</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
  <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>))</span>

<span>(</span><span>defun</span> <span>rule2</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
  <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>))</span>

<span>(</span><span>defun</span> <span>rule3</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
  <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>))</span>
</code></pre></div>

<p>We then have to modify the drawing loop to call <code>update-positions</code>.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>)</span>
     <span>(</span><span>boids</span> <span>(</span><span>loop</span> <span>repeat</span> <span>20</span>
                  <span>collect</span> <span>(</span><span>make-boid</span> <span>(</span><span>random</span> <span>width</span><span>)</span>
                                     <span>(</span><span>random</span> <span>height</span><span>)))))</span>
  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
  <span>(</span><span>draw-boids</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>update-positions</span> <span>boids</span><span>))</span>
</span></code></pre></div>

<p>So far, these changes haven't affected the boid behaviour, so let's circle back and implement <code>rule-1</code>, which can be summarised as "stay away from other boids". When a boid is less than 10 pixels from another boid, we push them away from each other to avoid crowding.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>rule1</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>let</span> <span>((</span><span>v-sum</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)))</span>
</span><span>   <span>(</span><span>loop</span> <span>for</span> <span>boid2</span> <span>in</span> <span>boids</span>
</span><span>         <span>for</span> <span>offset</span> <span>=</span> <span>(</span><span>v-</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>pos</span> <span>boid2</span><span>))</span>
</span><span>         <span>for</span> <span>dist</span> <span>=</span> <span>(</span><span>v-length</span> <span>offset</span><span>)</span>
</span><span>         <span>when</span> <span>(</span><span>and</span> <span>(</span><span>not</span> <span>(</span><span>eq</span> <span>boid</span> <span>boid2</span><span>))</span> <span>(</span><span>&lt;</span> <span>dist</span> <span>10</span><span>))</span>
</span><span>           <span>do</span> <span>(</span><span>v+!</span> <span>v-sum</span> <span>offset</span><span>))</span>
</span><span>   <span>v-sum</span><span>))</span>
</span></code></pre></div>

<p>(Note: the vector functions ending in <code>!</code>, like <code>v+!</code>, follow the convention of storing the result in the vector passed as the first argument).</p>
<p>When we recompile this function...</p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-4-first-rule.mp4" type="video/mp4">
</video>

<p>...a pair of boids that happen to be too close to each other are sent flying off into the void. There's no counterforce to bring them back, just yet.</p>
<p>Next, we implement <code>rule-2</code>: boids should fly towards the average position of other boids. Our implementation could be more efficient by summing the boid positions just once, rather than doing it for every single boid, but I can't be bothered.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>rule2</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>let</span> <span>((</span><span>center</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)))</span>
</span><span>    <span>(</span><span>map</span> <span>nil</span>
</span><span>         <span>(</span><span>lambda</span> <span>(</span><span>boid2</span><span>)</span>
</span><span>           <span>(</span><span>when</span> <span>(</span><span>not</span> <span>(</span><span>eq</span> <span>boid</span> <span>boid2</span><span>))</span>
</span><span>             <span>(</span><span>v+!</span> <span>center</span> <span>(</span><span>pos</span> <span>boid2</span><span>))))</span>
</span><span>         <span>boids</span><span>)</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>(</span><span>1-</span> <span>(</span><span>length</span> <span>boids</span><span>)))</span> <span>center</span><span>)</span>
</span><span>    <span>(</span><span>v-!</span> <span>center</span> <span>(</span><span>pos</span> <span>boid</span><span>))</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>200</span><span>)</span> <span>center</span><span>)</span>
</span><span>    <span>center</span><span>))</span>
</span></code></pre></div>

<p>Recompiling <code>rule-2</code>, we get...</p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-5-second-rule.mp4" type="video/mp4">
</video>

<p>Yes! This is starting to look vaguely like Boids. Let's add the final rule, <code>rule-3</code>: boids should match their velocity to all the other boids. Implementation note: we probably shouldn't update the velocities until all the new velocities have been calculated, but this doesn't seem to matter too much.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>rule3</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>let</span> <span>((</span><span>result</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)))</span>
</span><span>    <span>(</span><span>map</span> <span>nil</span>
</span><span>         <span>(</span><span>lambda</span> <span>(</span><span>boid2</span><span>)</span>
</span><span>           <span>(</span><span>when</span> <span>(</span><span>not</span> <span>(</span><span>eq</span> <span>boid</span> <span>boid2</span><span>))</span>
</span><span>             <span>(</span><span>v+!</span> <span>result</span> <span>(</span><span>velocity</span> <span>boid2</span><span>))))</span>
</span><span>         <span>boids</span><span>)</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>(</span><span>1-</span> <span>(</span><span>length</span> <span>boids</span><span>)))</span> <span>result</span><span>)</span>
</span><span>    <span>(</span><span>v-!</span> <span>result</span> <span>(</span><span>velocity</span> <span>boid</span><span>))</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>8</span><span>)</span> <span>result</span><span>)</span>
</span><span>    <span>result</span><span>))</span>
</span></code></pre></div>

<p>Recompiling, we see the Boids calm down a little bit.</p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-6-third-rule.mp4" type="video/mp4">
</video>

<p>Since it's not very bird-like to fly around in a vortex of death, we could also give the boids a purpose by making them follow the mouse position. The result of these changes can be seen at the top of the post.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>)</span>
     <span>(</span><span>boids</span> <span>(</span><span>loop</span> <span>repeat</span> <span>20</span>
                  <span>collect</span> <span>(</span><span>make-boid</span> <span>(</span><span>random</span> <span>width</span><span>)</span>
                                     <span>(</span><span>random</span> <span>height</span><span>))))</span>
<span>     <span>(</span><span>mouse-pos</span> <span>(</span><span>vec2</span> <span>200</span> <span>200</span><span>)))</span>
</span>  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
  <span>(</span><span>draw-boids</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>update-positions</span> <span>boids</span> <span>mouse-pos</span><span>))</span>
</span>
<span><span>(</span><span>defmethod</span> <span>on-hover</span> <span>((</span><span>instance</span> <span>boids</span><span>)</span> <span>x</span> <span>y</span><span>)</span>
</span><span>  <span>(</span><span>setf</span> <span>(</span><span>boids-mouse-pos</span> <span>instance</span><span>)</span> <span>(</span><span>vec2</span> <span>x</span> <span>y</span><span>)))</span>
</span>
<span>(</span><span>defun</span> <span>update-positions</span> <span>(</span><span>boids</span> <span>mouse-pos</span><span>)</span>
  <span>(</span><span>let</span> <span>((</span><span>max-velocity</span> <span>10</span><span>))</span>
    <span>(</span><span>map</span> <span>nil</span>
         <span>(</span><span>lambda</span> <span>(</span><span>boid</span><span>)</span>
           <span>(</span><span>setf</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>v+</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>velocity</span> <span>boid</span><span>))))</span>
         <span>boids</span><span>)</span>
    <span>(</span><span>loop</span> <span>for</span> <span>boid</span> <span>in</span> <span>boids</span>
          <span>do</span> <span>(</span><span>setf</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                   <span>(</span><span>v-clamp</span> <span>max-velocity</span>
                            <span>(</span><span>v+</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                                <span>(</span><span>rule1</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule2</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule3</span> <span>boid</span> <span>boids</span><span>)</span>
<span>                                <span>(</span><span>v-rescale</span> <span>0.1</span> <span>(</span><span>v-</span> <span>mouse-pos</span> <span>(</span><span>pos</span> <span>boid</span><span>)))))))))</span>
</span></code></pre></div>

<p>And with that, we have a complete implementation of Boids! At the risk of beating a dead horse, I'll re-emphasise that we did the whole thing without once restarting our program or waiting a perceivable amount of time for code to compile.</p>
<h3 id="closing-thoughts">Closing thoughts</h3>
<p>I hope, in this brief demonstration of livecoding, I've given you a taste of how useful and fun this feature can be, whether you're developing a graphics application or mundane accounting software. Like I've said, it's not unique to Common Lisp, as at least Smalltalk and Erlang have similar capabilities. It's also possible to bridge the gap in less interactive languages by making applications automatically restart themselves when a code change is detected, or by bolting on a scripting language. Just do me a favour and ask yourself, the next time you're waiting the requisite time units for your code to recompile: <em>How can I make this workflow more interactive? How can I make it more... like Common Lisp?</em></p>
<!-- Just in case, here's the ffmpeg command I used to trim the screen recordings:
ffmpeg -i input.mp4 -ss 2 -to 4 -async 1 cut.mp4 -->


<hr>
<a href="https://kevingal.com/blog/chess-detective.html">&lt;&lt; previous</a>
<ul>
<li><a href="https://kevingal.com/blog.html">Back to blog</a></li>
<li><a href="https://kevingal.com/feed.xml">RSS feed</a></li>
</ul>
<p>I'd be happy to hear from you at <i>galligankevinp@gmail.com</i>.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of MCPs (164 pts)]]></title>
            <link>https://iamcharliegraham.substack.com/publish/post/161906169</link>
            <guid>43774327</guid>
            <pubDate>Wed, 23 Apr 2025 17:12:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iamcharliegraham.substack.com/publish/post/161906169">https://iamcharliegraham.substack.com/publish/post/161906169</a>, See on <a href="https://news.ycombinator.com/item?id=43774327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3341558,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://iamcharliegraham.substack.com/i/161906169?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>This was originally posted at </span><a href="https://www.iamcharliegraham.com/mcps-gatekeepers-and-the-future-of-ai/" rel="nofollow ugc noopener">https://www.iamcharliegraham.com/mcps-gatekeepers-and-the-future-of-ai/</a></em><a href="https://www.iamcharliegraham.com/mcps-gatekeepers-and-the-future-of-ai/" rel="nofollow ugc noopener"><br></a><br><span>Lately, there’s been significant buzz and genuine excitement around MCPs—Model Context Protocols. If you've been following AI development circles, you've likely heard optimistic claims such as "this will change everything."</span></p><p>Curious about the possibilities, I went deep into MCPs, building two experimental MCP servers myself, and thoroughly exploring their potential and current limitations. Here's what I discovered.</p><p><em><strong>Note:</strong><span> This post is more technical and detailed than most of my previous posts.</span></em></p><p>Think of MCPs as standardized APIs—connectors between external data sources or applications and large language models (LLMs) like ChatGPT or Claude. They let the model contact a travel site to fetch real-time prices, read and manage your calendar, or even rename files on your computer.</p><p>While tools like Claude, Cursor, and OpenAI already use custom integrations under the hood, MCPs aim to offer a universal, standardized format for all such interactions.</p><p>MCPs have two main parts: clients (like ChatGPT) and servers (external services like a flight scheduling site). When used together, they give LLMs “superpowers”—letting them access real-time data, take action on the web, and act more like agents than static chatbots.</p><p>Today, two main types of MCP Servers are emerging. One set is developer-focused—tools like Cursor or Claude Code that integrate with your laptop to manage files, and/or run scripts. The other is web and action-oriented, built around real-world tasks like searching for products, registering domains, booking events, or sending emails.</p><p>To explore what’s actually possible, I built one of each MCP server. The first was a developer server called GPT Learner - a tool that lets you instruct Cursor to remember what went wrong and avoid repeating mistakes. If Claude or Cursor rewrote your code incorrectly, after you have it fixed you can say “record learnings,” and it will store what to do and not do in its rules for the future.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png" width="1129" height="608" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:608,&quot;width&quot;:1129,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The second project was more ambitious: a prediction market MCP that connects an LLM to</span><a href="https://betsee.xyz/?ref=iamcharliegraham.com" rel="nofollow ugc noopener"> betsee.xyz</a><span>, a site I built that aggregates live prediction markets. When you ask Claude something like, “Trump just paused tariffs—what are the second-order effects, and what are people betting on?” the MCP returns relevant markets from Polymarket or Kalshi, along with live odds.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png" width="1296" height="1604" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1604,&quot;width&quot;:1296,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Building these things made a few things clear. First, MCPs aren’t ready for broad adoption.</p><p>The user experience is rough. Most chat clients like ChatGPT don’t yet support MCP servers. The few that do require manual JSON editing to install them—not exactly user-friendly. Clients like Cursor and Claude currently prompt users for every request and often return incomplete info or raw JSON outputs. It's clunky and frustrating.</p><p>When I used Claude Desktop to query my prediction market MCP, it often didn’t send links or prices unless I explicitly asked. Sometimes it didn’t call the server at all. And every time it made a call to my MCP, it prompted me to approve - which quickly became annoying. Eventually, MCP installation will be seamless (e.g., “click to add from a catalog”), and responses will be meaningful. But we’re not there yet.</p><p>Security is another glaring issue. Because MCPs enable external actions and access to live systems, they introduce a wide new surface area for abuse. Prompt injection, malicious tool installs, unauthorized access, and Trojan-horse-style exploits are all very real risks today. There's no sandboxing, no validation layer, and no mature security ecosystem to handle these edge cases.</p><p>We’re clearly still in the experimental stage.</p><p>While building these servers, I had one more important learning: while MCP servers provide the data and actions, the clients control the future.</p><p>Whoever controls the LLM interface— Claude, ChatGPT, Cursor, etc...—controls what tools users see, which ones get triggered, and what responses actually get surfaced. You can build the world’s most useful MCP server, but the client may not call it, or only show half of its output. You may not even be allowed to install it</p><p>Given that MCP clients hold all the power, it’s easy to see how MCPs will end up governed by a framework resembling a combination of the two dominant monopolies of the last two decades: search and mobile app stores. Major LLM providers—OpenAI, Anthropic, and others—will emerge as the new monopoly gatekeepers, managing MCP selection and monetizing that control through preferred placements and curated inclusion.</p><p>Since its founding in the late 1990s, Google has controlled which products users see when they have purchase intent—building an incredibly lucrative business. Now, GPT chats (the MCP clients) are entering that space, replacing the "10 blue links" by curating responses to people’s requests: deciding what content is included, what’s excluded, and how it's formatted. MCP servers will become the new SEM/SEO layer—paying fees to reach users via these AI intermediaries.</p><p>Installation, meanwhile, will resemble the mobile app store model. Just as Apple and Google shaped the mobile ecosystem by determining which apps were featured, preinstalled, or approved at all, LLM clients will decide which MCP servers get surfaced, promoted, or even allowed. Companies will compete—and likely pay significant sums—for premium visibility in these ecosystems, turning MCP directories into high-stakes distribution platforms.</p><p>Users will be able to install MCPs—or “chat apps”—from large, curated directories. Tools like Gmail, HubSpot, Uber, and Kayak will add MCP endpoints, integrating directly into chat-based workflows. While installation is technically possible, most users won’t bother to choose their own tools. Instead, they’ll rely on the defaults provided by the client (like ChatGPT). These defaults won’t be arbitrary—they’ll be the result of lucrative partnerships. Large companies will pay to become the preselected option for categories like shopping, travel, domain name search, or services search . Being the default means embedding into the daily flow of millions of users—bringing massive exposure, data, and commercial value.</p><p>Some client-side MCP App Stores (MAS) will offer looser, more open directories, allowing broader experimentation and community-developed MCPs. Others will be tightly gated, favoring quality, security, and monetization with strict approval processes. In either case, the client sets the terms of participation—and the rules for success.</p><p>MCP clients like OpenAI and Claude will become the new iOS and Android. MCP servers will play the role of apps—modular tools delivering rich, structured, interactive responses tailored to the user’s needs. But instead of screens and taps, interaction happens through language. The app is invoked not by icon, but by intent.</p><p>Over time, we’ll also see specialized clients emerge, tailored to specific industries or domains. Imagine a Travel Planner Chat Client that integrates seamlessly with airlines, hotel chains, and tour operators, offering users a complete trip-planning experience inside a single conversational flow. Or an HR-focused MCP client that unifies access to legal data, employee records, and organizational tools—transforming how businesses manage people and policy.</p><p>And while most users will stick with mainstream clients backed by billion-dollar UX budgets, some open-source GPT interfaces will likely emerge as well. These will appeal to power users who want full control over the MCPs they install—without gatekeepers. But just like Linux on the desktop, these open clients will remain niche: influential, dedicated, and small in number compared to the dominant platforms.</p><p>If this world unfolds, here are some of the businesses and tools I expect to emerge—and why they matter:</p><p><strong>MCP Wrapper and Server Packs</strong><span> These will simplify setup by bundling multiple related MCPs into a single installable unit. Imagine installing a “Startup Stack” that includes MCPs for calendar, email, CRM, and file storage—ready to go, no configuration required. These packs will streamline onboarding and become especially useful in vertical clients and may include packaged tooling ("set a calendar and send an email").</span></p><p><strong>MCP Affiliate Shopping Engines</strong><span> Some MCP servers will act like AI-powered comparison engines, returning real-time prices and product listings across vendors. They’ll monetize through affiliate links—earning referral fees from purchases. This echoes the early days of SEO and affiliate marketing, now reimagined for AI agents.</span></p><p><strong>MCP-First Content Apps</strong><span> Instead of designing websites for humans, these services will optimize content delivery for LLMs via MCP servers. Think rich, structured data, semantic labeling, and pricing hooks—all returned via MCP calls. Revenue will come from subscriptions or embedded sponsorships and product placements, not page views.</span></p><p><strong>API-to-MCP Providers</strong><span> Many existing APIs will want to participate in this new ecosystem but won’t have the resources to rebuild everything. Middleware tools will emerge that automatically translate traditional REST APIs into compliant, discoverable MCP servers, making onboarding turnkey for SaaS platforms.</span></p><p><strong>Cloudflare for MCPs</strong><span> Security will become a major issue, and someone will step in to handle it. These tools will sit between clients and servers, sanitizing inputs, logging requests, blocking attacks, and monitoring for anomalies. Just as Cloudflare made the modern web safer, a similar role will exist for MCP ecosystems.</span></p><p><strong>Enterprise “Private” MCP Solutions</strong><span> Large companies will start to wire up their own internal services into private MCP servers—exposing data from HR systems, legal tools, analytics dashboards, and more. Paired with open-source LLM clients, these internal setups will unlock AI workflows behind the firewall, with enterprise-level control.</span></p><p><strong>Verticalized MCP Clients</strong><span> Generic chat interfaces will only get you so far. Some domains—like babysitting marketplaces, industrial procurement, or compliance workflows—require specific UIs and business logic. Vertically focused MCP clients will emerge to serve these needs with tailored actions, language, and layouts.</span></p><p>If you’re working on this space—building MCP clients, servers, or something even better —I’d love to hear from you: charlie@iamcharliegraham.com</p><p>We’re still early. MCPs today are messy, brittle, and mostly in the hands of developers. But the direction is clear.</p><p>These protocols have the potential to transform LLMs from chat-based search engines into powerful, agent-like tools that can take action on your behalf—securely, intelligently, and in real time.</p><p><span>But the real story isn’t just about what MCP servers </span><em>can</em><span> do. It’s about who gets to decide </span><em>what they’re allowed to do</em><span>. And in that story, it’s the clients-the ChatGPTs and Claudes of the world—that will write the rules, set the defaults, and shape the future.</span></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I won't be vibe coding anymore: a noob's perspective (132 pts)]]></title>
            <link>https://varunraghu.com/why-i-wont-be-vibe-coding-anymore/</link>
            <guid>43773977</guid>
            <pubDate>Wed, 23 Apr 2025 16:41:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://varunraghu.com/why-i-wont-be-vibe-coding-anymore/">https://varunraghu.com/why-i-wont-be-vibe-coding-anymore/</a>, See on <a href="https://news.ycombinator.com/item?id=43773977">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  <header>
    <a href="https://varunraghu.com/">
      <h2>
        Varun Raghu
      </h2>
    </a>
    <nav>
      <p><a href="https://varunraghu.com/blog/">Blog</a></p>

    </nav>
  </header>
  <main>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-04-22T19:40Z">
                    22 Apr, 2025
                </time>
            </i>
        </p>
    

    <p>i’m breaking up with vibe coding. here’s why.</p>
<p>when i first started learning to code, i built apps/websites that would be considered poor in the traditional sense. it also took me an embarassing amout of time to figure out basic stuff. it was frustratingly difficult. the ‘finished’ product wasn’t even polished.</p>
<p>but atleast i built it. i wasn’t begging an ai agent to fix my bugs. no matter how poor, the code had my blood, sweat and tears in it. no one could take that away from me.</p>
<p>as i was lying in bed on a sleepless night. i realized i hadn’t learnt a new concept in weeks. i had built a few useful apps with ai, but a nagging question kept me awake - what was the point of it all if i didn’t learn a thing?</p>
<p>that’s when it struck me. coding isn’t about the finished product. its a lot like writing. its about the process. its about how you approach a problem. its critical thinking.</p>
<p>and i don’t think i’m ready to let ai take these away from me. i’m going back to writing shitty code, slowly and deliberately.</p>


    

    
        

        
            


        
    


  </main>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Horseless Carriages (676 pts)]]></title>
            <link>https://koomen.dev/essays/horseless-carriages/</link>
            <guid>43773813</guid>
            <pubDate>Wed, 23 Apr 2025 16:19:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://koomen.dev/essays/horseless-carriages/">https://koomen.dev/essays/horseless-carriages/</a>, See on <a href="https://news.ycombinator.com/item?id=43773813">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[More Everything Forever (133 pts)]]></title>
            <link>https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html</link>
            <guid>43773746</guid>
            <pubDate>Wed, 23 Apr 2025 16:13:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html">https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html</a>, See on <a href="https://news.ycombinator.com/item?id=43773746">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[They made computers behave like annoying salesmen (287 pts)]]></title>
            <link>https://rakhim.exotext.com/they-made-computers-behave-like-annoying-salesmen</link>
            <guid>43773710</guid>
            <pubDate>Wed, 23 Apr 2025 16:10:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rakhim.exotext.com/they-made-computers-behave-like-annoying-salesmen">https://rakhim.exotext.com/they-made-computers-behave-like-annoying-salesmen</a>, See on <a href="https://news.ycombinator.com/item?id=43773710">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Computers are precise machines. You can give a computer a precise command using an inhumane language, and it should perfome the command. It's not a human, and there is no point of treating it as one. The goal of humanizing user experience isn't to create an illusion of human interaction - it's to make these mechanical commands more accessible while preserving their precise, deterministic nature. </p>
<p>UX designers and product managers of tech companies did a lot of damange to people's understanding of computers by making the software behave like a human; or to be more precise, behave like an annoying salesman. </p>
<p><img src="https://img.exotext.com/1/Mam8J5UIOOGzSAR80SsCi.png" alt=""></p>
<p><em>(Image from "<a href="https://blog.prototypr.io/not-now-a91c75ad35b6">Not Now. Not later either</a>" by Chris Oliver)</em></p>
<p>We're all familiar with this type. After receiving a clear "no thanks" they deploy increasingly manipulative tactics to meet their "always-be-closing" quotas: "Would this Wednesday work better?" "What would change your mind?" This behavior is frustrating enough from actual salespeople - it's even worse when programmed into our software.</p>
<p>(<a href="https://www.youtube.com/watch?v=GrhSLf0I-HM">Corporate LLM training session circa 2025</a>)</p>
<p>Personally, I can tolerate but deeply dislike software that pretends to have ulterior motives. Take YouTube, for instance. When I explicitly say "Not interested" to their damned shorts feature, I get this response:</p>
<p><img src="https://img.exotext.com/1/BRKRAYhSqywqHunBgXt0P.png" alt="youtube web page with a message saying 'shelf will be hidden for 30 days'"></p>
<p>I understand that it's not the "YouTube program" having its own agency and making this decision - it's the team behind it, driven by engagement metrics and growth targets. But does the average user understand this distinction?</p>
<p>The population (especially the younger generation, who never seen a different kind of technology at all) is being conditioned by the tech industry to accept that software should behave like an unreliable, manipulative human rather than a precise, predictable machine. They're learning that you can't simply tell a computer "I'm not interested" and expect it to respect that choice. Instead, you must engage in a perpetual dance of "not now, please" - only to face the same prompts again and again.</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Cua (YC X25) – Open-Source Docker Container for Computer-Use Agents (141 pts)]]></title>
            <link>https://github.com/trycua/cua</link>
            <guid>43773563</guid>
            <pubDate>Wed, 23 Apr 2025 15:55:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trycua/cua">https://github.com/trycua/cua</a>, See on <a href="https://news.ycombinator.com/item?id=43773563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><strong>TL;DR</strong>: <strong>c/ua</strong> (pronounced "koo-ah", short for Computer-Use Agent) is a framework that enables AI agents to control full operating systems within high-performance, lightweight virtual containers. It delivers up to 97% native speed on Apple Silicon and works with any vision language models.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is c/ua?</h2><a id="user-content-what-is-cua" aria-label="Permalink: What is c/ua?" href="#what-is-cua"></a></p>
<p dir="auto"><strong>c/ua</strong> offers two primary capabilities in a single integrated framework:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>High-Performance Virtualization</strong> - Create and run macOS/Linux virtual machines on Apple Silicon with near-native performance (up to 97% of native speed) using the <strong>Lume CLI</strong> with <code>Apple's Virtualization.Framework</code>.</p>
</li>
<li>
<p dir="auto"><strong>Computer-Use Interface &amp; Agent</strong> - A framework that allows AI systems to observe and control these virtual environments - interacting with applications, browsing the web, writing code, and performing complex workflows.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Use c/ua?</h2><a id="user-content-why-use-cua" aria-label="Permalink: Why Use c/ua?" href="#why-use-cua"></a></p>
<ul dir="auto">
<li><strong>Security &amp; Isolation</strong>: Run AI agents in fully isolated virtual environments instead of giving them access to your main system</li>
<li><strong>Performance</strong>: <a href="https://browser.geekbench.com/v6/cpu/compare/11283746?baseline=11102709" rel="nofollow">Near-native performance</a> on Apple Silicon</li>
<li><strong>Flexibility</strong>: Run macOS or Linux environments with the same framework</li>
<li><strong>Reproducibility</strong>: Create consistent, deterministic environments for AI agent workflows</li>
<li><strong>LLM Integration</strong>: Built-in support for connecting to various LLM providers</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">System Requirements</h2><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"></a></p>
<ul dir="auto">
<li>Mac with Apple Silicon (M1/M2/M3/M4 series)</li>
<li>macOS 15 (Sequoia) or newer</li>
<li>Python 3.10+ (required for the Computer, Agent, and MCP libraries). We recommend using Conda (or Anaconda) to create an ad hoc Python environment.</li>
<li>Disk space for VM images (30GB+ recommended)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Lume CLI Only (VM Management)</h3><a id="user-content-option-1-lume-cli-only-vm-management" aria-label="Permalink: Option 1: Lume CLI Only (VM Management)" href="#option-1-lume-cli-only-vm-management"></a></p>
<p dir="auto">If you only need the virtualization capabilities:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)&quot;"><pre>sudo /bin/bash -c <span><span>"</span><span><span>$(</span>curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh<span>)</span></span><span>"</span></span></pre></div>
<p dir="auto">For Lume usage instructions, refer to the <a href="https://github.com/trycua/cua/blob/main/libs/lume/README.md">Lume documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Full Computer-Use Agent Capabilities</h3><a id="user-content-option-2-full-computer-use-agent-capabilities" aria-label="Permalink: Option 2: Full Computer-Use Agent Capabilities" href="#option-2-full-computer-use-agent-capabilities"></a></p>
<p dir="auto">If you want to use AI agents with virtualized environments:</p>
<ol dir="auto">
<li>
<p dir="auto">Install the Lume CLI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)&quot;"><pre>sudo /bin/bash -c <span><span>"</span><span><span>$(</span>curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh<span>)</span></span><span>"</span></span></pre></div>
</li>
<li>
<p dir="auto">Pull the latest macOS CUA image:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lume pull macos-sequoia-cua:latest"><pre>lume pull macos-sequoia-cua:latest</pre></div>
</li>
<li>
<p dir="auto">Start Lume daemon service:</p>

</li>
<li>
<p dir="auto">Install the Python libraries:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install cua-computer cua-agent[all]"><pre>pip install cua-computer cua-agent[all]</pre></div>
</li>
<li>
<p dir="auto">Use the libraries in your Python code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from computer import Computer
from agent import ComputerAgent, LLM, AgentLoop, LLMProvider

async with Computer(verbosity=logging.DEBUG) as macos_computer:
  agent = ComputerAgent(
      computer=macos_computer,
      loop=AgentLoop.OPENAI, # or AgentLoop.ANTHROPIC, or AgentLoop.OMNI
      model=LLM(provider=LLMProvider.OPENAI) # or LLM(provider=LLMProvider.ANTHROPIC)
  )

  tasks = [
      &quot;Look for a repository named trycua/cua on GitHub.&quot;,
  ]

  for task in tasks:
    async for result in agent.run(task):
      print(result)"><pre><span>from</span> <span>computer</span> <span>import</span> <span>Computer</span>
<span>from</span> <span>agent</span> <span>import</span> <span>ComputerAgent</span>, <span>LLM</span>, <span>AgentLoop</span>, <span>LLMProvider</span>

<span>async</span> <span>with</span> <span>Computer</span>(<span>verbosity</span><span>=</span><span>logging</span>.<span>DEBUG</span>) <span>as</span> <span>macos_computer</span>:
  <span>agent</span> <span>=</span> <span>ComputerAgent</span>(
      <span>computer</span><span>=</span><span>macos_computer</span>,
      <span>loop</span><span>=</span><span>AgentLoop</span>.<span>OPENAI</span>, <span># or AgentLoop.ANTHROPIC, or AgentLoop.OMNI</span>
      <span>model</span><span>=</span><span>LLM</span>(<span>provider</span><span>=</span><span>LLMProvider</span>.<span>OPENAI</span>) <span># or LLM(provider=LLMProvider.ANTHROPIC)</span>
  )

  <span>tasks</span> <span>=</span> [
      <span>"Look for a repository named trycua/cua on GitHub."</span>,
  ]

  <span>for</span> <span>task</span> <span>in</span> <span>tasks</span>:
    <span>async</span> <span>for</span> <span>result</span> <span>in</span> <span>agent</span>.<span>run</span>(<span>task</span>):
      <span>print</span>(<span>result</span>)</pre></div>
<p dir="auto">Explore the <a href="https://github.com/trycua/cua/blob/main/notebooks">Agent Notebook</a> for a ready-to-run example.</p>
</li>
<li>
<p dir="auto">Optionally, you can use the Agent with a Gradio UI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from utils import load_dotenv_files
load_dotenv_files()
 
from agent.ui.gradio.app import create_gradio_ui

app = create_gradio_ui()
app.launch(share=False)"><pre><span>from</span> <span>utils</span> <span>import</span> <span>load_dotenv_files</span>
<span>load_dotenv_files</span>()
 
<span>from</span> <span>agent</span>.<span>ui</span>.<span>gradio</span>.<span>app</span> <span>import</span> <span>create_gradio_ui</span>

<span>app</span> <span>=</span> <span>create_gradio_ui</span>()
<span>app</span>.<span>launch</span>(<span>share</span><span>=</span><span>False</span>)</pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 3: Build from Source (Nightly)</h3><a id="user-content-option-3-build-from-source-nightly" aria-label="Permalink: Option 3: Build from Source (Nightly)" href="#option-3-build-from-source-nightly"></a></p>
<p dir="auto">If you want to contribute to the project or need the latest nightly features:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone https://github.com/trycua/cua.git
cd cua

# Open the project in VSCode
code ./vscode/py.code-workspace

# Build the project
./scripts/build.sh"><pre><span><span>#</span> Clone the repository</span>
git clone https://github.com/trycua/cua.git
<span>cd</span> cua

<span><span>#</span> Open the project in VSCode</span>
code ./vscode/py.code-workspace

<span><span>#</span> Build the project</span>
./scripts/build.sh</pre></div>
<p dir="auto">See our <a href="https://github.com/trycua/cua/blob/main/docs/Developer-Guide.md">Developer-Guide</a> for more information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Monorepo Libraries</h2><a id="user-content-monorepo-libraries" aria-label="Permalink: Monorepo Libraries" href="#monorepo-libraries"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Library</th>
<th>Description</th>
<th>Installation</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/lume/README.md"><strong>Lume</strong></a></td>
<td>CLI for running macOS/Linux VMs with near-native performance using Apple's <code>Virtualization.Framework</code>.</td>
<td><a href="https://github.com/trycua/cua/releases/latest/download/lume.pkg.tar.gz"><img src="https://camo.githubusercontent.com/bfc757e594c3881d25b9fe5be133b6f423c97d586a6be5a8981f598a3795644e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f776e6c6f61642d3333333333333f7374796c653d666f722d7468652d6261646765266c6f676f3d676974687562266c6f676f436f6c6f723d7768697465" alt="Download" data-canonical-src="https://img.shields.io/badge/Download-333333?style=for-the-badge&amp;logo=github&amp;logoColor=white"></a></td>
<td><a href="https://github.com/trycua/cua/releases"><img src="https://camo.githubusercontent.com/28582a8533a2f40c7c0012fa1f85d228b014c5e9f903e956953952ed05bc2575/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f7472796375612f6375613f636f6c6f723d333333333333" alt="GitHub release" data-canonical-src="https://img.shields.io/github/v/release/trycua/cua?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/computer/README.md"><strong>Computer</strong></a></td>
<td>Computer-Use Interface (CUI) framework for interacting with macOS/Linux sandboxes</td>
<td><code>pip install cua-computer</code></td>
<td><a href="https://pypi.org/project/cua-computer/" rel="nofollow"><img src="https://camo.githubusercontent.com/677fa2657fc6a5c02156848fb989e054d665eb63f96b173757fb0c643608ffb6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d636f6d70757465723f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-computer?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/agent/README.md"><strong>Agent</strong></a></td>
<td>Computer-Use Agent (CUA) framework for running agentic workflows in macOS/Linux dedicated sandboxes</td>
<td><code>pip install cua-agent</code></td>
<td><a href="https://pypi.org/project/cua-agent/" rel="nofollow"><img src="https://camo.githubusercontent.com/7544ebe8fe2cb215318bf3bb083a45506c1a9d11e8bfe36ffd0ac8a22e662081/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d6167656e743f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-agent?color=333333"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<p dir="auto">For the best onboarding experience with the packages in this monorepo, we recommend starting with the <a href="https://github.com/trycua/cua/blob/main/libs/computer/README.md">Computer</a> documentation to cover the core functionality of the Computer sandbox, then exploring the <a href="https://github.com/trycua/cua/blob/main/libs/agent/README.md">Agent</a> documentation to understand Cua's AI agent capabilities, and finally working through the Notebook examples.</p>
<ul dir="auto">
<li><a href="https://github.com/trycua/cua/blob/main/libs/lume/README.md">Lume</a></li>
<li><a href="https://github.com/trycua/cua/blob/main/libs/computer/README.md">Computer</a></li>
<li><a href="https://github.com/trycua/cua/blob/main/libs/agent/README.md">Agent</a></li>
<li><a href="https://github.com/trycua/cua/blob/main/notebooks">Notebooks</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demos</h2><a id="user-content-demos" aria-label="Permalink: Demos" href="#demos"></a></p>
<p dir="auto">Demos of the Computer-Use Agent in action. Share your most impressive demos in Cua's <a href="https://discord.com/invite/mVnXXpdE85" rel="nofollow">Discord community</a>!</p>
<details open="">
<summary><b>MCP Server: Work with Claude Desktop and Tableau </b></summary>

<p dir="auto">
    <details open="">
  <summary>
    
    <span aria-label="Video description mcp-claude-tableau.mp4">mcp-claude-tableau.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/195596869/432513160-9f573547-5149-493e-9a72-396f3cff29df.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDMyNTEzMTYwLTlmNTczNTQ3LTUxNDktNDkzZS05YTcyLTM5NmYzY2ZmMjlkZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YTg2OGQ1M2FjNjM3ZmQxZjk1NWE4Y2QzMGVkYTljMmY2NWYwOTk0YjczOTNkYjBmMjE1YmMzMWJkODE5MTFkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Dh-OsskAGXJ92uyHEfKr92XExG-IVZ86N6I5eH4I1wU" data-canonical-src="https://private-user-images.githubusercontent.com/195596869/432513160-9f573547-5149-493e-9a72-396f3cff29df.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDMyNTEzMTYwLTlmNTczNTQ3LTUxNDktNDkzZS05YTcyLTM5NmYzY2ZmMjlkZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YTg2OGQ1M2FjNjM3ZmQxZjk1NWE4Y2QzMGVkYTljMmY2NWYwOTk0YjczOTNkYjBmMjE1YmMzMWJkODE5MTFkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Dh-OsskAGXJ92uyHEfKr92XExG-IVZ86N6I5eH4I1wU" controls="controls" muted="muted">

  </video>
</details>

</p>
<details open="">
<summary><b>AI-Gradio: multi-app workflow requiring browser, VS Code and terminal access</b></summary>

<p dir="auto">
    <details open="">
  <summary>
    
    <span aria-label="Video description ai-gradio-clone.mp4">ai-gradio-clone.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/195596869/423690370-723a115d-1a07-4c8e-b517-88fbdf53ed0f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzNjkwMzcwLTcyM2ExMTVkLTFhMDctNGM4ZS1iNTE3LTg4ZmJkZjUzZWQwZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03ZjBmNzNkMDE0OTgyMDZmZGZjMGRjNDZkNGJlMzU2NmU2YjcyMGM4YTU2N2M5MTIxMjE4OTk2NjM1YjdjNDcyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.iiuC-O-Lrj2Y_e4SK75ZDJIifv7v5QlPzdo9T43CqP0" data-canonical-src="https://private-user-images.githubusercontent.com/195596869/423690370-723a115d-1a07-4c8e-b517-88fbdf53ed0f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzNjkwMzcwLTcyM2ExMTVkLTFhMDctNGM4ZS1iNTE3LTg4ZmJkZjUzZWQwZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03ZjBmNzNkMDE0OTgyMDZmZGZjMGRjNDZkNGJlMzU2NmU2YjcyMGM4YTU2N2M5MTIxMjE4OTk2NjM1YjdjNDcyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.iiuC-O-Lrj2Y_e4SK75ZDJIifv7v5QlPzdo9T43CqP0" controls="controls" muted="muted">

  </video>
</details>

</p>
</details>
<details open="">
<summary><b>Notebook: Fix GitHub issue in Cursor</b></summary>

<p dir="auto">
    <details open="">
  <summary>
    
    <span aria-label="Video description notebook-github-cursor.mp4">notebook-github-cursor.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/195596869/423227709-f67f0107-a1e1-46dc-aa9f-0146eb077077.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzMjI3NzA5LWY2N2YwMTA3LWExZTEtNDZkYy1hYTlmLTAxNDZlYjA3NzA3Ny5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NGIxNDZhZmM1YjIxN2ZlMzdjMjg3YjljZjdiOWIxNjE2NWRmZGVjY2NkZWJkNzgzODA4YWJjMGU0MjQwZGVmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.GyYBYPMvfGNKj3S0TXUOpcNTinf195RFQjMD110-XLM" data-canonical-src="https://private-user-images.githubusercontent.com/195596869/423227709-f67f0107-a1e1-46dc-aa9f-0146eb077077.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzMjI3NzA5LWY2N2YwMTA3LWExZTEtNDZkYy1hYTlmLTAxNDZlYjA3NzA3Ny5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NGIxNDZhZmM1YjIxN2ZlMzdjMjg3YjljZjdiOWIxNjE2NWRmZGVjY2NkZWJkNzgzODA4YWJjMGU0MjQwZGVmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.GyYBYPMvfGNKj3S0TXUOpcNTinf195RFQjMD110-XLM" controls="controls" muted="muted">

  </video>
</details>

</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Accessory Libraries</h2><a id="user-content-accessory-libraries" aria-label="Permalink: Accessory Libraries" href="#accessory-libraries"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Library</th>
<th>Description</th>
<th>Installation</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/core/README.md"><strong>Core</strong></a></td>
<td>Core functionality and utilities used by other Cua packages</td>
<td><code>pip install cua-core</code></td>
<td><a href="https://pypi.org/project/cua-core/" rel="nofollow"><img src="https://camo.githubusercontent.com/78e19e4d4807aff22db19c4a99319d0cf4173d57bd12aeabf4f8875d2ffa6e11/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d636f72653f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-core?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/pylume/README.md"><strong>PyLume</strong></a></td>
<td>Python bindings for Lume</td>
<td><code>pip install pylume</code></td>
<td><a href="https://pypi.org/project/pylume/" rel="nofollow"><img src="https://camo.githubusercontent.com/dc81f8cd99d66b602c71a01fa76382a22ca11ab56e576a8e3f46543306d1fea3/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f70796c756d653f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/pylume?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/computer-server/README.md"><strong>Computer Server</strong></a></td>
<td>Server component for the Computer-Use Interface (CUI) framework</td>
<td><code>pip install cua-computer-server</code></td>
<td><a href="https://pypi.org/project/cua-computer-server/" rel="nofollow"><img src="https://camo.githubusercontent.com/99568cb5aaf982926609b01d71d3fec021d82afebb220076e360fd2cec3fb08a/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d636f6d70757465722d7365727665723f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-computer-server?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/som/README.md"><strong>SOM</strong></a></td>
<td>Self-of-Mark library for Agent</td>
<td><code>pip install cua-som</code></td>
<td><a href="https://pypi.org/project/cua-som/" rel="nofollow"><img src="https://camo.githubusercontent.com/c49bae7797b2df0a453cf939a349436b9a8733afa3621322efa1a5eb56017e8c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d736f6d3f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-som?color=333333"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome and greatly appreciate contributions to Cua! Whether you're improving documentation, adding new features, fixing bugs, or adding new VM images, your efforts help make lume better for everyone. For detailed instructions on how to contribute, please refer to our <a href="https://github.com/trycua/cua/blob/main/CONTRIBUTING.md">Contributing Guidelines</a>.</p>
<p dir="auto">Join our <a href="https://discord.com/invite/mVnXXpdE85" rel="nofollow">Discord community</a> to discuss ideas or get assistance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Cua is open-sourced under the MIT License - see the <a href="https://github.com/trycua/cua/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto">Microsoft's OmniParser, which is used in this project, is licensed under the Creative Commons Attribution 4.0 International License (CC-BY-4.0) - see the <a href="https://github.com/microsoft/OmniParser/blob/master/LICENSE">OmniParser LICENSE</a> file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Trademarks</h2><a id="user-content-trademarks" aria-label="Permalink: Trademarks" href="#trademarks"></a></p>
<p dir="auto">Apple, macOS, and Apple Silicon are trademarks of Apple Inc. Ubuntu and Canonical are registered trademarks of Canonical Ltd. Microsoft is a registered trademark of Microsoft Corporation. This project is not affiliated with, endorsed by, or sponsored by Apple Inc., Canonical Ltd., or Microsoft Corporation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stargazers over time</h2><a id="user-content-stargazers-over-time" aria-label="Permalink: Stargazers over time" href="#stargazers-over-time"></a></p>
<p dir="auto"><a href="https://starchart.cc/trycua/cua" rel="nofollow"><img src="https://camo.githubusercontent.com/0803bde0e4d80af5fd0b5651fd66e8f3929f576b783654b91e338d2b4ffd3aa4/68747470733a2f2f7374617263686172742e63632f7472796375612f6375612e7376673f76617269616e743d6164617074697665" alt="Stargazers over time" data-canonical-src="https://starchart.cc/trycua/cua.svg?variant=adaptive"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>



<markdown-accessiblity-table><table>
  <tbody>
    <tr>
      <td><a href="https://github.com/f-trycua"><img src="https://avatars.githubusercontent.com/u/195596869?v=4?s=100" width="100px;" alt="f-trycua"><br><sub><b>f-trycua</b></sub></a><br><a href="#code-f-trycua" title="Code">💻</a></td>
      <td><a href="http://pepicrft.me/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/663605?v=4?s=100" width="100px;" alt="Pedro Piñera Buendía"><br><sub><b>Pedro Piñera Buendía</b></sub></a><br><a href="#code-pepicrft" title="Code">💻</a></td>
      <td><a href="https://iamit.in/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/5647941?v=4?s=100" width="100px;" alt="Amit Kumar"><br><sub><b>Amit Kumar</b></sub></a><br><a href="#code-aktech" title="Code">💻</a></td>
      <td><a href="https://productsway.com/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/870029?v=4?s=100" width="100px;" alt="Dung Duc Huynh (Kaka)"><br><sub><b>Dung Duc Huynh (Kaka)</b></sub></a><br><a href="#code-jellydn" title="Code">💻</a></td>
      <td><a href="http://zaydkrunz.com/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/70227235?v=4?s=100" width="100px;" alt="Zayd Krunz"><br><sub><b>Zayd Krunz</b></sub></a><br><a href="#code-ShrootBuck" title="Code">💻</a></td>
      <td><a href="https://github.com/PrashantRaj18198"><img src="https://avatars.githubusercontent.com/u/23168997?v=4?s=100" width="100px;" alt="Prashant Raj"><br><sub><b>Prashant Raj</b></sub></a><br><a href="#code-PrashantRaj18198" title="Code">💻</a></td>
      <td><a href="https://www.mobile.dev/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/847683?v=4?s=100" width="100px;" alt="Leland Takamine"><br><sub><b>Leland Takamine</b></sub></a><br><a href="#code-Leland-Takamine" title="Code">💻</a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/ddupont808"><img src="https://avatars.githubusercontent.com/u/3820588?v=4?s=100" width="100px;" alt="ddupont"><br><sub><b>ddupont</b></sub></a><br><a href="#code-ddupont808" title="Code">💻</a></td>
      <td><a href="https://github.com/Lizzard1123"><img src="https://avatars.githubusercontent.com/u/46036335?v=4?s=100" width="100px;" alt="Ethan Gutierrez"><br><sub><b>Ethan Gutierrez</b></sub></a><br><a href="#code-Lizzard1123" title="Code">💻</a></td>
      <td><a href="https://ricterz.me/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/5282759?v=4?s=100" width="100px;" alt="Ricter Zheng"><br><sub><b>Ricter Zheng</b></sub></a><br><a href="#code-RicterZ" title="Code">💻</a></td>
      <td><a href="https://www.trytruffle.ai/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/50844303?v=4?s=100" width="100px;" alt="Rahul Karajgikar"><br><sub><b>Rahul Karajgikar</b></sub></a><br><a href="#code-rahulkarajgikar" title="Code">💻</a></td>
      <td><a href="https://github.com/trospix"><img src="https://avatars.githubusercontent.com/u/81363696?v=4?s=100" width="100px;" alt="trospix"><br><sub><b>trospix</b></sub></a><br><a href="#code-trospix" title="Code">💻</a></td>
      <td><a href="https://wavee.world/invitation/b96d00e6-b802-4a1b-8a66-2e3854a01ffd" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/22633385?v=4?s=100" width="100px;" alt="Ikko Eltociear Ashimine"><br><sub><b>Ikko Eltociear Ashimine</b></sub></a><br><a href="#code-eltociear" title="Code">💻</a></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>



</details></article></div></div>]]></description>
        </item>
    </channel>
</rss>