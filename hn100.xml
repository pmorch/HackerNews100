<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 07 Jan 2025 02:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Triptych Proposals (129 pts)]]></title>
            <link>https://alexanderpetros.com/triptych/</link>
            <guid>42615646</guid>
            <pubDate>Mon, 06 Jan 2025 20:52:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexanderpetros.com/triptych/">https://alexanderpetros.com/triptych/</a>, See on <a href="https://news.ycombinator.com/item?id=42615646">Hacker News</a></p>
Couldn't get https://alexanderpetros.com/triptych/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Used Meta AI, now Instagram is using my face on ads targeted at me (264 pts)]]></title>
            <link>https://old.reddit.com/r/ABoringDystopia/comments/1ht7fft/used_meta_ai_to_edit_a_selfie_now_instagram_is/</link>
            <guid>42615538</guid>
            <pubDate>Mon, 06 Jan 2025 20:44:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/ABoringDystopia/comments/1ht7fft/used_meta_ai_to_edit_a_selfie_now_instagram_is/">https://old.reddit.com/r/ABoringDystopia/comments/1ht7fft/used_meta_ai_to_edit_a_selfie_now_instagram_is/</a>, See on <a href="https://news.ycombinator.com/item?id=42615538">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/ABoringDystopia/comments/1ht7fft/used_meta_ai_to_edit_a_selfie_now_instagram_is/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[An autumn bike adventure down the US portion of the Eastern Divide Trail (126 pts)]]></title>
            <link>https://www.crazyguyonabike.com/doc/?doc_id=26078</link>
            <guid>42613878</guid>
            <pubDate>Mon, 06 Jan 2025 18:50:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.crazyguyonabike.com/doc/?doc_id=26078">https://www.crazyguyonabike.com/doc/?doc_id=26078</a>, See on <a href="https://news.ycombinator.com/item?id=42613878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

   <div>

        

        <h3>An autumn adventure down the US portion of the Eastern Divide Trail</h3><p>

        Copyright ¬© 2024-2025 By
        <a href="https://www.crazyguyonabike.com/directory/?o=3d2&amp;user=zygomorph&amp;v=1" title="zygomorph joined September 21st 2024">zygomorph</a>&nbsp;&nbsp;<a href="https://www.crazyguyonabike.com/doc/guestbook/?o=3d2&amp;doc_id=26078&amp;v=j4" title="Contact"><i></i></a></p><p>
           <span>Completed Dec 2024</span> <br>

        

   3,877 miles (6,239 km) over
         77 days from October 1, 2024 to December 16, 2024 <br>

        <a href="https://www.crazyguyonabike.com/doc/latest/?o=3d2&amp;doc_id=26078&amp;v=j4">Updated</a>: Monday December 16, 2024 19:11 (US/Pacific) (edited Mon 16 Dec 2024 19:28 (US/Pacific))
        <br>
         
        <a href="https://www.crazyguyonabike.com/doc/thumbnails/?o=3d2&amp;doc_id=26078&amp;v=j4">342 pics</a>
           <br>
        12,540 hits since September 30, 2024 (hitcounts updated nightly) </p><p>

        <b>Topic</b>: 

   <a href="https://www.crazyguyonabike.com/doc/26078">Bicycle Touring</a>
      &nbsp;
   <br>
        <b>Categories</b>:
        <a href="https://www.crazyguyonabike.com/doc/categories/?o=3d2&amp;category_id=124&amp;doctype=journal">Tour diaries</a>, <a href="https://www.crazyguyonabike.com/doc/categories/?o=3d2&amp;category_id=1396&amp;doctype=journal">Bikepacking bikes</a>, <a href="https://www.crazyguyonabike.com/doc/categories/?o=3d2&amp;category_id=403&amp;doctype=journal">Camping</a>, <a href="https://www.crazyguyonabike.com/doc/categories/?o=3d2&amp;category_id=404&amp;doctype=journal">Motel</a>, <a href="https://www.crazyguyonabike.com/doc/categories/?o=3d2&amp;category_id=191&amp;doctype=journal">Offroad</a>, <a href="https://www.crazyguyonabike.com/doc/categories/?o=3d2&amp;category_id=405&amp;doctype=journal">Stealth camping</a>, <a href="https://www.crazyguyonabike.com/doc/categories/?o=3d2&amp;category_id=182&amp;doctype=journal">1-3 months</a><br>

        <b>Locales:</b> <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=7160709&amp;doctype=journal">North&nbsp;America</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=227&amp;doctype=journal">United&nbsp;States</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51172&amp;doctype=journal">Maine</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51182&amp;doctype=journal">New&nbsp;Hampshire</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51205&amp;doctype=journal">Vermont</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51185&amp;doctype=journal">New&nbsp;York</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51190&amp;doctype=journal">Pennsylvania</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51173&amp;doctype=journal">Maryland</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51209&amp;doctype=journal">West&nbsp;Virginia</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51207&amp;doctype=journal">Virginia</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51186&amp;doctype=journal">North&nbsp;Carolina</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51163&amp;doctype=journal">Georgia</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51153&amp;doctype=journal">Alabama</a>, <a href="https://www.crazyguyonabike.com/doc/locales/?o=3d2&amp;locale_id=51162&amp;doctype=journal">Florida</a><br>
        <b>Year:</b> <a href="https://www.crazyguyonabike.com/doc/years/?year=2024&amp;doctype=journal">2024</a><br>
           <b>Keywords</b>: Eastern Divide, bikepack, krampus <br>
        </p><p>

        <b>Permalink</b>: <a href="https://www.crazyguyonabike.com/doc/easterndivideq42024" title="Use this URL when linking to this journal">https://www.crazyguyonabike.com/doc/easterndivideq42024</a>
        <a href="#" title="Copy to clipboard" onclick="copyStringToClipboard('https://www.crazyguyonabike.com/doc/easterndivideq42024',true);return false;"><i></i></a>
        </p></div>

    

 <h3 id="toc">Table of Contents</h3>
      <dl>
      <dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=679670&amp;v=Mj" id="679670">Day 0</a>: A Long Expected Journey </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680093&amp;v=MX" id="680093">Day 1</a>: A Rough Start </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680102&amp;v=MA" id="680102">Day 2</a>: Bustin' Baxter </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680249&amp;v=M5" id="680249">Day 3</a>: Velogation Supreme </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680250&amp;v=Lv" id="680250">Day 4</a>: Wishes Come True </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680251&amp;v=LY" id="680251">Day 5</a>: Take Chances, Make Mistakes, and Get Messy </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680291&amp;v=Kv" id="680291">Day 6</a>: Emperor Nero </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680384&amp;v=Ks" id="680384">Day 7</a>: Zero's Paradox </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680439&amp;v=LJ" id="680439">Day 8</a>: A Grand Day Out </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680473&amp;v=KV" id="680473">Day 9</a>: The Man on the Silver Mountain </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680551&amp;v=KC" id="680551">Day 10</a>: Finite State Machine </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680553&amp;v=JW" id="680553">Day 11</a>: Splitting Headache </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680610&amp;v=Jd" id="680610">Day 12</a>: Chain of Fools </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680613&amp;v=JC" id="680613">Day 13</a>: By the Numbers </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680678&amp;v=Ik" id="680678">Day 14</a>: But It Pours </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680708&amp;v=J0" id="680708">Day 15</a>: Eugene Onagain </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680745&amp;v=I7" id="680745">Day 16</a>: Doorways in the Sand </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680842&amp;v=Hz" id="680842">Day 17</a>: When in Rome </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=680985&amp;v=HR" id="680985">Day 18</a>: Shore Leave </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681024&amp;v=He" id="681024">Day 19</a>: On the Straight and Narrow </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681087&amp;v=HD" id="681087">Day 20</a>: Canal Trail Strikes Back </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681116&amp;v=Gs" id="681116">Day 21</a>: Geographic Compression </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681162&amp;v=Ga" id="681162">Day 22</a>: Mixed Media </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681169&amp;v=Fr" id="681169">Day 23</a>: The Lord of the Rings </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681254&amp;v=Ff" id="681254">Day 24</a>: Happy Little Accidents </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681257&amp;v=FD" id="681257">Day 25</a>: State Pen </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681277&amp;v=Ej" id="681277">Day 26</a>: Cranksgiving </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681385&amp;v=Eh" id="681385">Day 27</a>: A Cold Day in Hellbender </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681386&amp;v=EC" id="681386">Day 28</a>: All's Well That Ends Well </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681388&amp;v=E5" id="681388">Day 29</a>: R&amp;R on the C&amp;O </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681410&amp;v=DM" id="681410">Day 30</a>: Country Roads </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681436&amp;v=Cu" id="681436">Day 31</a>: A Day in the Lonesome October </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681492&amp;v=CX" id="681492">Day 32</a>: Blackwater Park </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681493&amp;v=CX" id="681493">Day 33</a>: Robert Katz </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681507&amp;v=Bo" id="681507">Day 34</a>: Springs Into Action </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681564&amp;v=Bd" id="681564">Day 35</a>: An Abundance of Katherines </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681566&amp;v=B9" id="681566">Day 36</a>: Called on Account of Rain </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681587&amp;v=Al" id="681587">Day 37</a>: Logistical Nightmare </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681723&amp;v=Ar" id="681723">Day 45</a>: On the Road Again </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681807&amp;v=Ab" id="681807">Day 46</a>: Star Trek: Trans North Georgia </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681808&amp;v=AA" id="681808">Day 47</a>: Cirith Ungol </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681809&amp;v=AC" id="681809">Day 48</a>: Sweet Home Alabama </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681810&amp;v=9t" id="681810">Day 49</a>: Downhill From Here </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681843&amp;v=9N" id="681843">Day 50</a>: Ten Things I Hate About You </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681844&amp;v=96" id="681844">Day 51</a>: Judgement Call </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681912&amp;v=8x" id="681912">Day 52</a>: Tempting Fate </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681914&amp;v=8G" id="681914">Day 53</a>: Brooklyn 99 - 7 </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681915&amp;v=89" id="681915">Day 54</a>: Hope, the Greatest of All Treasures </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=681916&amp;v=7j" id="681916">Day 55</a>: Nice Ville Ya Got There </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682062&amp;v=7h" id="682062">Day 56</a>: Rattlesnake Lake, the Southern One </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682063&amp;v=76" id="682063">Day 57</a>: I'd Ride a Mile for a Camel Lake </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682064&amp;v=6w" id="682064">Day 58</a>: Your Two Tents </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682066&amp;v=6u" id="682066">Day 59</a>: Cycle of Thanks </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682071&amp;v=6E" id="682071">Day 60</a>: Tallahassle </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682155&amp;v=6Q" id="682155">Day 61</a>: Trails and Tribulations </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682173&amp;v=65" id="682173">Day 62</a>: Saint Marks the Spot </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682194&amp;v=5l" id="682194">Day 63</a>: Aucilla the Hun </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682222&amp;v=5N" id="682222">Day 64</a>: Skipping Ahead </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682244&amp;v=5F" id="682244">Day 65</a>: Many Are Cold, Few Are Frozen </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682269&amp;v=54" id="682269">Day 66</a>: Dream Cycle </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682352&amp;v=4m" id="682352">Day 67</a>: Bagels and Locks </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682354&amp;v=4Z" id="682354">Day 68</a>: Alex Springs Eternal </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682355&amp;v=4T" id="682355">Day 69</a>: What a Bear Does in the Woods </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682356&amp;v=3b" id="682356">Day 70</a>: Point A to Point B </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682397&amp;v=3f" id="682397">Day 71</a>: Insult to Injury </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682400&amp;v=36" id="682400">Day 72</a>: Merger and Acquisition </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682430&amp;v=2R" id="682430">Day 73</a>: Hell on Wheels </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682497&amp;v=29" id="682497">Day 74</a>: Pantera </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682498&amp;v=1l" id="682498">Day 75</a>: The Rainbow Connection </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682500&amp;v=1b" id="682500">Day 76</a>: Keystream </span></dd><dd>
         

   <span><a href="https://www.crazyguyonabike.com/doc/page/?o=3d2&amp;page_id=682510&amp;v=12" id="682510">Day 77</a>: You Just Gotta Ride, Clyde </span></dd></dl>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C: Simple Defer, Ready to Use (141 pts)]]></title>
            <link>https://gustedt.wordpress.com/2025/01/06/simple-defer-ready-to-use/</link>
            <guid>42613671</guid>
            <pubDate>Mon, 06 Jan 2025 18:36:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gustedt.wordpress.com/2025/01/06/simple-defer-ready-to-use/">https://gustedt.wordpress.com/2025/01/06/simple-defer-ready-to-use/</a>, See on <a href="https://news.ycombinator.com/item?id=42613671">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Software is eating the world, all right (2024) (170 pts)]]></title>
            <link>https://medium.com/@metapgmr/software-is-eating-the-world-all-right-faedbab6d623</link>
            <guid>42613550</guid>
            <pubDate>Mon, 06 Jan 2025 18:28:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@metapgmr/software-is-eating-the-world-all-right-faedbab6d623">https://medium.com/@metapgmr/software-is-eating-the-world-all-right-faedbab6d623</a>, See on <a href="https://news.ycombinator.com/item?id=42613550">Hacker News</a></p>
Couldn't get https://medium.com/@metapgmr/software-is-eating-the-world-all-right-faedbab6d623: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of Htmx (538 pts)]]></title>
            <link>https://htmx.org/essays/future/</link>
            <guid>42613221</guid>
            <pubDate>Mon, 06 Jan 2025 18:05:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://htmx.org/essays/future/">https://htmx.org/essays/future/</a>, See on <a href="https://news.ycombinator.com/item?id=42613221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

  
  
    <address>Carson Gross, Alex Petros</address>
    <p><time>January 01, 2025</time></p><h2 id="in-the-beginning"><a href="#in-the-beginning" aria-label="Anchor link for: in-the-beginning">In The Beginning‚Ä¶</a></h2>
<p>htmx began life as <a rel="noopener" target="_blank" href="https://intercoolerjs.org/">intercooler.js</a>, a library built around jQuery that added behavior based
on HTML attributes.</p>
<p>For developers who are not familiar with it, <a rel="noopener" target="_blank" href="https://jquery.com/">jQuery</a> is a venerable JavaScript
library that made writing cross-platform JavaScript a lot easier during a time when browser implementations were very
inconsistent, and JavaScript didn‚Äôt have many of the convenient APIs and features that it does now.</p>
<p>Today many web developers consider jQuery to be ‚Äúlegacy software.‚Äù With all due respect to this perspective, jQuery is
currently used on <a rel="noopener" target="_blank" href="https://w3techs.com/technologies/overview/javascript_library">75% of all public websites</a>, a number that dwarfs all other JavaScript tools.</p>
<p>Why has jQuery remained so ubiquitous?</p>
<p>Here are three technical reasons we believe contribute to its ongoing success:</p>
<ul>
<li>It is very easy to add to a project (just a single, dependency-free link)</li>
<li>It has maintained a very consistent API, remaining largely backwards compatible over its life (intercooler.js works
with jQuery v1, v2 and v3)</li>
<li>As a library, you can use as much or as little of it as you like: it stays out of the way otherwise and doesn‚Äôt
dictate the structure of your application</li>
</ul>
<h2 id="htmx-is-the-new-jquery"><a href="#htmx-is-the-new-jquery" aria-label="Anchor link for: htmx-is-the-new-jquery">htmx is the New jQuery</a></h2>
<p>Now, that‚Äôs a ridiculous (and arrogant) statement to make, of course, but it is an <em>ideal</em> that we on the htmx team are
striving for.</p>
<p>In particular, we want to emulate these technical characteristics of jQuery that make it such a low-cost, high-value
addition to the toolkits of web developers. Alex has
discussed <a rel="noopener" target="_blank" href="https://www.youtube.com/watch?v=lASLZ9TgXyc">‚ÄúBuilding The 100 Year Web Service‚Äù</a> and we want htmx to be a
useful tool for exactly that use case.</p>
<p>Websites that are built with jQuery stay online for a very long time, and websites built with htmx should be capable of
the same (or better).</p>
<p>Going forward, htmx will be developed with its <em>existing</em> users in mind.</p>
<p>If you are an existing user of htmx‚Äîor are thinking about becoming one‚Äîhere‚Äôs what that means.</p>
<h3 id="stability-as-a-feature"><a href="#stability-as-a-feature" aria-label="Anchor link for: stability-as-a-feature">Stability as a Feature</a></h3>
<p>We are going to work to ensure that htmx is extremely stable in both API &amp; implementation. This means accepting and
documenting the <a rel="noopener" target="_blank" href="https://htmx.org/quirks/">quirks</a> of the current implementation.</p>
<p>Someone upgrading htmx (even from 1.x to 2.x) should expect things to continue working as before.</p>
<p>Where appropriate, we may add better configuration options, but we won‚Äôt change defaults.</p>
<h3 id="no-new-features-as-a-feature"><a href="#no-new-features-as-a-feature" aria-label="Anchor link for: no-new-features-as-a-feature">No New Features as a Feature</a></h3>
<p>We are going to be increasingly inclined to not accept new proposed features in the library core.</p>
<p>People shouldn‚Äôt feel pressure to upgrade htmx over time unless there are specific bugs that they want fixed, and they
should feel comfortable that the htmx that they write in 2025 will look very similar to htmx they write in 2035 and
beyond.</p>
<p>We will consider new core features when new browser features become available, for example we
are <a rel="noopener" target="_blank" href="https://htmx.org/examples/move-before/">already using</a> the experimental <code>moveBefore()</code> API on supported browsers.</p>
<p>However, we expect most new functionality to be explored and delivered via the
htmx <a rel="noopener" target="_blank" href="https://htmx.org/extensions/">extensions API</a>, and will work to make the extensions API more capable where
appropriate.</p>
<h3 id="quarterly-releases"><a href="#quarterly-releases" aria-label="Anchor link for: quarterly-releases">Quarterly Releases</a></h3>
<p>Our release schedule is going to be roughly quarterly going forward.</p>
<p>There will be no death march upgrades associated with htmx, and there is no reason to monitor htmx releases for major
functionality changes, just like with jQuery. If htmx 1.x is working fine for you, there is no reason to feel like you
need to move to 2.x.</p>

<p>htmx does not aim to be a total solution for building web applications and services:
it <a rel="noopener" target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3648188.3675127">generalizes hypermedia controls</a>, and that‚Äôs roughly about it.</p>
<p>This means that a very important way to improve htmx ‚Äî and one with lots of work remaining ‚Äî is by helping improve the tools
and techniques that people use <em>in conjunction</em> with htmx.</p>
<p>Doing so makes htmx dramatically more useful <em>without</em> any changes to htmx itself.</p>

<p>While htmx gives you a few new tools in your HTML, it has no opinions about other important aspects of building your
websites. A flagship feature of htmx is that it does not dictate what backend or database you use.</p>
<p>htmx is <a rel="noopener" target="_blank" href="https://htmx.org/essays/hypermedia-on-whatever-youd-like/">compatible with lots of backends</a>, and we want to
help make hypermedia-driven development work better for all of them.</p>
<p>One part of the hypermedia ecosystem that htmx has already helped improve is template engines. When
we <a rel="noopener" target="_blank" href="https://htmx.org/essays/template-fragments/">first wrote</a> about how ‚Äútemplate fragments‚Äù make defining partial page
replacements much simpler, they were a relatively rare feature in template engines.</p>
<p>Not only are fragments much more common now, that essay
is <a rel="noopener" target="_blank" href="https://github.com/mitsuhiko/minijinja/issues/260">frequently</a> <a rel="noopener" target="_blank" href="https://github.com/sponsfreixes/jinja2-fragments">cited</a>
as an inspiration for building the feature.</p>
<p>There are many other ways that the experience of writing hypermedia-based applications can be improved, and we will
remain dedicated to identifying and promoting those efforts.</p>
<h3 id="writing-research-and-standardization"><a href="#writing-research-and-standardization" aria-label="Anchor link for: writing-research-and-standardization">Writing, Research, and Standardization</a></h3>
<p>Although htmx will not be changing dramatically going forward, we will continue energetically evangelizing the ideas of
hypermedia.</p>
<p>In particular, we are trying to push <a rel="noopener" target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3648188.3675127">the ideas</a> of htmx into the
HTML standard itself, via the <a rel="noopener" target="_blank" href="https://alexanderpetros.com/triptych/">Triptych project</a>. In an ideal world, htmx
functionality disappears into the web platform itself.</p>
<p>htmx code written <em>today</em> will continue working forever, of course, but in the very long run perhaps there will be no
need to include the library to achieve <a rel="noopener" target="_blank" href="https://htmx.org/examples">similar UI patterns</a> via hypermedia.</p>
<h2 id="intercooler-was-right"><a href="#intercooler-was-right" aria-label="Anchor link for: intercooler-was-right">Intercooler Was Right</a></h2>
<p>At the <a rel="noopener" target="_blank" href="https://intercoolerjs.org/docs#philosophy">end of the intercooler docs</a>, we said this:</p>
<blockquote>
<p>Many javascript projects are updated at a dizzying pace. Intercooler is not.</p>
<p>This is not because it is dead, but rather because it is (mostly) right: the basic idea is right, and the implementation
at least right enough.</p>
<p>This means there will not be constant activity and churn on the project, but rather
a <a rel="noopener" target="_blank" href="https://en.wikipedia.org/wiki/Stewardship_(theology)">stewardship</a> relationship: the main goal now is to not screw
it up. The documentation will be improved, tests will be added, small new declarative features will be added around the
edges, but there will be no massive rewrite or constant updating. This is in contrast with the software industry in
general and the front end world in particular, which has comical levels of churn.</p>
<p>Intercooler is a sturdy, reliable tool for web development.</p>
</blockquote>
<p>Leaving aside <a rel="noopener" target="_blank" href="https://www.youtube.com/watch?v=zGyAWH5btwY">the snark at the end of the third paragraph</a>, this thinking
is very much applicable to htmx. In fact, perhaps even more so since htmx is a standalone piece of software, benefiting
from the experiences (and mistakes) of intercooler.js.</p>
<p>We hope to see htmx, in its own small way, join the likes of giants like jQuery as a sturdy and reliable tool for
building your 100 year web services.</p>

  <p>
    &lt;/&gt;
  </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All clocks are 30 seconds late (204 pts)]]></title>
            <link>https://victorpoughon.fr/all-clocks-are-30-seconds-late/</link>
            <guid>42612842</guid>
            <pubDate>Mon, 06 Jan 2025 17:40:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://victorpoughon.fr/all-clocks-are-30-seconds-late/">https://victorpoughon.fr/all-clocks-are-30-seconds-late/</a>, See on <a href="https://news.ycombinator.com/item?id=42612842">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-01-06T10:00Z">
                    06 Jan, 2025
                </time>
            </i>
        </p>
    

    <p>OK, this is going to sound crazy: I believe all clocks are 30 seconds late.</p>
<p>Let's get a few things out of the way: this is neither about time zones, nor leap seconds.
It's not about synchronization of clocks, and it's not about relativity or any obscure corner of physics.
I'm talking about everyday clocks. The ones that you might have around in your house, like this one that sits on my desk:</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/victorpoughon/post2image1-2.webp" alt="post2image1"></p>
<p>Or this one that stands in London:</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/victorpoughon/572px-big_ben_elizabeth_tower_london_2023_01_detail.webp" alt="572px-Big_Ben_Elizabeth_Tower_London_2023_01_Detail"></p>
<p><em>(Photo from Wikipedia)</em></p>
<p>Or even the clock on your phone! Maybe they're all correctly set very precisely to a very accurate reference clock, but here I will argue that they are still exactly 30 seconds late. In other words:</p>
<blockquote>
<p>It would be more accurate if they were thirty seconds ahead.</p>
</blockquote>
<h2 id="what-are-you-on-about">What are you on about?</h2><p>All the above clocks have one thing in common: they don't show seconds. They truncate down to the nearest lower whole minute, right? So when it's actually <code>14:15:45</code>, they'll show <code>14:15</code>.
And when the actual time goes from <code>14:15:59</code> to <code>14:16:00</code>, then that's when your clock changes from <code>14:15</code> to <code>14:16</code>.</p>
<p>They apply the
<a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions">floor function</a>!</p>
<p>Ok great. Now hear me out! Let's compute the average error between a usual (truncating) clock, and the precise current time.</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>matplotlib.dates</span> <span>as</span> <span>mdates</span>

<span># A datetime array from 14:00:15pm for 300 seconds</span>
<span>true_time</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>datetime</span><span>.</span><span>datetime</span><span>(</span><span>2024</span><span>,</span> <span>12</span><span>,</span> <span>20</span><span>,</span> <span>14</span><span>,</span> <span>00</span><span>,</span> <span>15</span><span>)</span> <span>+</span> <span>datetime</span><span>.</span><span>timedelta</span><span>(</span><span>seconds</span><span>=</span><span>i</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>300</span><span>)])</span>

<span># The clock truncates seconds</span>
<span>shown_time</span> <span>=</span> <span>[</span><span>t</span><span>.</span><span>replace</span><span>(</span><span>second</span><span>=</span><span>0</span><span>)</span> <span>for</span> <span>t</span> <span>in</span> <span>true_time</span><span>]</span>

<span># The clock error is the shown time minus the true time</span>
<span>error</span> <span>=</span> <span>[</span><span>dt</span><span>.</span><span>total_seconds</span><span>()</span> <span>for</span> <span>dt</span> <span>in</span> <span>(</span><span>shown_time</span> <span>-</span> <span>true_time</span><span>)]</span>

<span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>figsize</span><span>=</span><span>(</span><span>10</span><span>,</span> <span>3.5</span><span>))</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>true_time</span><span>,</span> <span>error</span><span>,</span> <span>label</span><span>=</span><span>"clock error"</span><span>,</span> <span>color</span><span>=</span><span>"teal"</span><span>)</span>
<span>ax</span><span>.</span><span>hlines</span><span>(</span><span>np</span><span>.</span><span>mean</span><span>(</span><span>error</span><span>),</span> <span>xmin</span><span>=</span><span>true_time</span><span>[</span><span>0</span><span>],</span> <span>xmax</span><span>=</span><span>true_time</span><span>[</span><span>-</span><span>1</span><span>],</span> <span>label</span><span>=</span><span>"average"</span><span>,</span> <span>linestyle</span><span>=</span><span>"--"</span><span>,</span> <span>color</span><span>=</span><span>"orange"</span><span>)</span>
<span>ax</span><span>.</span><span>xaxis</span><span>.</span><span>set_major_formatter</span><span>(</span><span>mdates</span><span>.</span><span>DateFormatter</span><span>(</span><span>'%H:%M'</span><span>))</span>
<span>ax</span><span>.</span><span>set_ylim</span><span>([</span><span>-</span><span>60</span><span>,</span> <span>60</span><span>])</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span>"A normal clock"</span><span>)</span>
<span>ax</span><span>.</span><span>legend</span><span>()</span>
</pre></div>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/victorpoughon/post2plot1-1.webp" alt="post2plot1"></p>
<ul>
<li>Sometimes the error is 1 or 2 seconds, like when the clock shows <code>14:02</code> and it's actually <code>14:02:01</code></li>
<li>Sometimes the error is almost 60 seconds, like when the clock shows <code>14:02</code> and it's actually <code>14:02:57</code></li>
</ul>
<p>So, the average error of a truncating clock is 30 seconds. Let that sink in for a moment: <strong>the average error of a clock is 30 seconds</strong>. If clocks
<a href="https://en.wikipedia.org/wiki/Rounding">rounded</a>
to the nearest minute instead of truncating, the average error would be 0. Therefore all clocks are 30 seconds late!</p>
<p>Similarly of course, all clocks that show seconds but not milliseconds are half a second late.</p>
<div><pre><span></span><span># The rounding clock! aka +30s</span>
<span>shown_time</span> <span>=</span> <span>[(</span><span>t</span> <span>+</span> <span>datetime</span><span>.</span><span>timedelta</span><span>(</span><span>seconds</span><span>=</span><span>30</span><span>))</span><span>.</span><span>replace</span><span>(</span><span>second</span><span>=</span><span>0</span><span>)</span> <span>for</span> <span>t</span> <span>in</span> <span>true_time</span><span>]</span>

<span># The clock error is the shown time minus the true time</span>
<span>error</span> <span>=</span> <span>[</span><span>dt</span><span>.</span><span>total_seconds</span><span>()</span> <span>for</span> <span>dt</span> <span>in</span> <span>(</span><span>shown_time</span> <span>-</span> <span>true_time</span><span>)]</span>

<span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>figsize</span><span>=</span><span>(</span><span>10</span><span>,</span> <span>3.5</span><span>))</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>true_time</span><span>,</span> <span>error</span><span>,</span> <span>label</span><span>=</span><span>"clock error"</span><span>,</span> <span>color</span><span>=</span><span>"teal"</span><span>)</span>
<span>ax</span><span>.</span><span>hlines</span><span>(</span><span>np</span><span>.</span><span>mean</span><span>(</span><span>error</span><span>),</span> <span>xmin</span><span>=</span><span>true_time</span><span>[</span><span>0</span><span>],</span> <span>xmax</span><span>=</span><span>true_time</span><span>[</span><span>-</span><span>1</span><span>],</span> <span>label</span><span>=</span><span>"average"</span><span>,</span> <span>linestyle</span><span>=</span><span>"--"</span><span>,</span> <span>color</span><span>=</span><span>"orange"</span><span>)</span>
<span>ax</span><span>.</span><span>xaxis</span><span>.</span><span>set_major_formatter</span><span>(</span><span>mdates</span><span>.</span><span>DateFormatter</span><span>(</span><span>'%H:%M'</span><span>))</span>
<span>ax</span><span>.</span><span>set_ylim</span><span>([</span><span>-</span><span>60</span><span>,</span> <span>60</span><span>])</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span>"A rounding clock"</span><span>)</span>
<span>ax</span><span>.</span><span>legend</span><span>()</span>
</pre></div>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/victorpoughon/post2plot2-1.webp" alt="post2plot2"></p>
<h2 id="this-is-just-a-convention">This is just a convention</h2><blockquote>
<p>But this is just a convention! Truncating, rounding or even ceiling are all valid, as long as we pick one and stick to it. By your logic we should say that it's Tuesday as soon as it's one second past noon on Monday.</p>
</blockquote>
<p>Well... kind of.</p>
<p>It would be weird if we rounded for years, months and days, that's for sure. I think most people think of those scales as intervals. In other words, July is a period of time, with a start and an end. So are years, centuries, seasons. We are inside of it or outside.</p>
<p>Is it the same for the current minute of the current hour ? I'm not so sure.</p>
<p>Basically I'm arguing that rounding for clocks would be more useful than flooring.
This is especially apparent when you're trying to calculate "how much time until my next meeting?", and your next meeting is at noon. If it's 11:55, you would usually mentally subtract and conclude: the meeting is in 5 minutes. That's how I always do it myself anyway! But the most probable estimate given the available information is actually 4'30"!</p>
<p>If you had a rounding clock instead, 5 minutes would be the correct estimation.</p>
<p>In fact, as we go down the various scales of time all the way from years, months, days and we reach hours, that's when we start truncating! At hours! For example: if it's <code>10:43</code> and you are asked the time and (for some context appropriate reason) you reply with just hours, you would say it's 11! Personally, I would never say that it's 10 if the clock shows anything past <code>10:30</code>. I realize that's probably very different in other cultures, though! And I'd be interested to learn about how different cultures approximate time in language.</p>
<p>So, looking at the various scales of time and how I mentally view them:</p>
<ul>
<li><strong>Years</strong>: truncate. If the full date has <code>2019</code> in it, I'll say "the year is 2019" - all the way to the end. Saying "it's 2020" in September 2019 is super weird.</li>
<li><strong>Months</strong>: truncate. It's January all the way until it's February.</li>
<li><strong>Days</strong>: truncate. It gets a little weird if it's past midnight and I haven't slept yet. Is tomorrow today? Or is it the day after that? I think collectively we still haven't quite figured that one out yet. And that's ok. Kind of like how "next Friday" becomes ambiguous on Thursdays. Some cultures use times beyond 24:00, like 25:30 to indicate one hour and a half past midnight, and I think that's lovely!</li>
<li><strong>Hours</strong>: That's when mentally, I switch to rounding! At <code>15:48</code> I definitely feel like it's pretty much <code>16:00</code>.</li>
<li><strong>Minutes</strong>: At <code>15:48:57</code>, I definitely feel like it's <code>15:49</code>! But clocks switch back to flooring for for some reason! But mentally we round! This is why I feel like all clocks are 30 seconds late: because the truncating convention doesn't match my intuition at the minute scale.</li>
<li><strong>Seconds and below</strong>: definitely rounding.</li>
</ul>
<p>Please someone tell me I'm not crazy üôÉ</p>


    

    
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[3blue1brown YouTube Bitcoin video taken down as copyright violation (583 pts)]]></title>
            <link>https://twitter.com/3blue1brown/status/1876291319955398799</link>
            <guid>42612494</guid>
            <pubDate>Mon, 06 Jan 2025 17:10:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/3blue1brown/status/1876291319955398799">https://twitter.com/3blue1brown/status/1876291319955398799</a>, See on <a href="https://news.ycombinator.com/item?id=42612494">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[My little sister's use of ChatGPT for homework is heartbreaking (236 pts)]]></title>
            <link>https://old.reddit.com/r/ChatGPT/comments/1hun3e4/my_little_sisters_use_of_chatgpt_for_homework_is/</link>
            <guid>42611844</guid>
            <pubDate>Mon, 06 Jan 2025 16:19:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/ChatGPT/comments/1hun3e4/my_little_sisters_use_of_chatgpt_for_homework_is/">https://old.reddit.com/r/ChatGPT/comments/1hun3e4/my_little_sisters_use_of_chatgpt_for_homework_is/</a>, See on <a href="https://news.ycombinator.com/item?id=42611844">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/ChatGPT/comments/1hun3e4/my_little_sisters_use_of_chatgpt_for_homework_is/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Justin Trudeau resigns (387 pts)]]></title>
            <link>https://www.bbc.com/news/live/clyjmy7vl64t</link>
            <guid>42611730</guid>
            <pubDate>Mon, 06 Jan 2025 16:07:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/live/clyjmy7vl64t">https://www.bbc.com/news/live/clyjmy7vl64t</a>, See on <a href="https://news.ycombinator.com/item?id=42611730">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-testid="content-post" id="asset:d8d78812-2c27-40cc-839b-ba2651f3bc82"><header><span><img src="https://static.files.bbci.co.uk/core/website/assets/static/news/incident-types/analysis.77b314ef10b5742f931e.svg" alt="Analysis" draggable="false"><h3 type="normal"><span role="text"><span>Once the fresh face of his party, Trudeau became a drag on its fortunes</span><span><span data-testid="timestamp"><span data-testid="accessible-timestamp">published at 17:38 Greenwich Mean Time</span></span></span></span></h3></span></header><p><span><span><span></span></span></span><span><strong>Jessica Murphy</strong><br>BBC News, Toronto</span></p><figure><p><span><img alt="Trudeau in dark suit with beard, next to blurry reflection of himself" src="https://ichef.bbci.co.uk/ace/standard/640/cpsprodpb/vivo/live/images/2025/1/6/201ddc2d-ea59-4b5f-8281-58cbfb0e429c.jpg.webp" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/vivo/live/images/2025/1/6/201ddc2d-ea59-4b5f-8281-58cbfb0e429c.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/vivo/live/images/2025/1/6/201ddc2d-ea59-4b5f-8281-58cbfb0e429c.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/vivo/live/images/2025/1/6/201ddc2d-ea59-4b5f-8281-58cbfb0e429c.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/vivo/live/images/2025/1/6/201ddc2d-ea59-4b5f-8281-58cbfb0e429c.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/vivo/live/images/2025/1/6/201ddc2d-ea59-4b5f-8281-58cbfb0e429c.jpg.webp 800w" width="1024" height="668"></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>Trudeau in 2020</p></figcaption></figure><p>For months now ‚Äì in the face of a frustrated electorate, a political rival surging in the polls, and most importantly, a deepening dislike from voters - Prime Minister Justin Trudeau has faced variations of the same question: ‚ÄúWill you step down?‚Äù</p><p>He has always stood firm, vowing he would be the one to lead the party into the next election.</p><p>But the shock resignation of his key deputy, former Finance Minister Chrystia Freeland, in mid-December proved to be the toppling domino that led to todays‚Äô announcement. </p><p>Trudeau swept to power nearly a decade ago, heralded as the fresh face of progressive politics. In 2015, swayed by his youthful charisma and a hopeful political message, voters catapulted the Liberals from a third-place party into a majority - unprecedented in Canadian political history.</p><p>He remains the only leader left standing among peers when he came into office, from Barack Obama to Angela Merkel, Shinzo Abe and David Cameron, and is currently the longest-serving leader in the G7. </p><p>But in the years since, and over two general elections, Trudeau and his brand have become a drag on the party‚Äôs fortunes.</p><p>A series of early ethics scandals began to take the sheen off the new government. He was found to have violated federal conflict of interest rules in the handling of a corruption inquiry ‚Äì the SNC-Lavalin affair - and for luxury trips to the Bahamas.</p><p>In 2020, he faced scrutiny for picking a charity with ties to his family to manage a major government programme.</p><p>More recently, Trudeau faced headwinds over the cost of living and inflation, which have contributed to incumbent election upsets around the world.</p><p>And after more than nine years in power, he is among Canada‚Äôs longest serving prime ministers, and there is a general sense of fatigue and frustration with his government.</p><p>In the end, pressure from his own MPs, who over the holidays made it clear they no longer supported his leadership, made staying on near impossible.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spline Distance Fields (126 pts)]]></title>
            <link>https://zone.dog/braindump/spline_fields/</link>
            <guid>42611540</guid>
            <pubDate>Mon, 06 Jan 2025 15:49:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zone.dog/braindump/spline_fields/">https://zone.dog/braindump/spline_fields/</a>, See on <a href="https://news.ycombinator.com/item?id=42611540">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <p>
      December 31th, 2024
    </p>
    <h2 id="problem">Problem</h2>
    <p>
      Earlier this year I decided to put my main project Tangerine on hold
      indefinitely and began prototyping
      <a href="https://github.com/aeva/star-machine">a new renderer</a>
      in an <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)">unfamiliar language</a>
      using a <a href="https://github.com/libsdl-org/SDL/pull/9312">totally new graphics API</a>
      with the goal of overcoming all of Tangerine's technical shortcomings.
      The new renderer is an eccentric CPU ray tracer called Star Machine that
      boasts the ability to <em>effortlessly</em> push 4k frames at 120hz or
      better <em>irrespective of scene complexity</em>, a custom coordinate
      system that limits the play space to roughly <em>940.7 astronomical
      units</em> with a constant world resolution of 15 micrometers, and a
      <em>truly unique</em> visual style.  To prove out the underlying theories and
      help me prioritize what to work on, I am also developing a time trial
      racing game called
      <a href="https://mastodon.gamedev.place/@aeva/113104448301517076">Rainy Road</a>.
    </p>
    <p>
      At this time of writing, Rainy Road lacks a way to render terrain.  These
      are my requirements for its terrain rendering system:
    </p>
    <ol>
      <li>
        Some terrain features (roads specifically) must be defined as splines.
      </li>
      <li>
        Terrain features must be composable, allowing for map sections to be
        rapidly swapped out at runtime.
      </li>
      <li>
        The system must be useful for procedural object placement.
      </li>
      <li>
        Terrain data must be fast to process into rendering intermediaries.
      </li>
      <li>
        Terrain data must be very compact.  An implicit representation is
        preferred if possible.
      </li>
      <li>
        Iterating on designing level sections must be quick and easy.
      </li>
      <li>
        I'd like to use existing tools where possible.
      </li>
      <li>
        I'm not interested in using proprietary tools for this project.
      </li>
    </ol>
    <p>
      A quick survey of existing terrain editing tools revealed that virtually
      all general purpose terrain editors violate at least one of these
      constraints, and unsurprisingly I did not find any terrain tools
      available targeting my particular niche.
    </p>
    <p>
      The next most obvious course of action is to use low resolution
      heightmaps with a good noise function to give it the illusion of being
      continous.  I've seen games (which are now 20+ years old now) use this
      technique to great effect, so I consider this to be pretty low risk.
      Additionally, I figure I can use Blender to rapidly iterate on variations
      of this technique, and once I am satisfied it can function as the level
      editor.
    </p>
    <p>
      My experimentation in Blender (and lots of great feedback from internet
      people experienced on the subject) quickly revealed that reasoning about
      landscapes and roads in isolation from one another "adds skill" a bit
      more than I would like, and so I see this as a good opportunity to
      develop structured workflows and supporting tools to take me to the
      places I want to go.
    </p>
    <h2 id="solution">Solution</h2>
    <p>
      This particular conceptual brick in the washing machine has led me to
      deeply internalizing what I now know to be a fundamental law of design
      and composition that applies <em>universally</em>:
    </p>
    <p>
      <a href="https://en.wikipedia.org/wiki/Tobler%27s_first_law_of_geography">
        <strong><em>Everything Affects Everything</em></strong>
      </a>
    </p>
    <p>
      In the real world roads are built along whatever happens to be the most
      circumstantially optimal route through the world they are to exist
      within.  The landscape (among other things) affects the decision of
      where to put a road, and in turn the road changes the landscape.
    </p>
    <p>
      If we know where some things <em>must</em> be, then we can infer what
      surrounds those thing.  We can eschew the input height map entirely, and
      instead generate the terrain from only points and splines, possibly in
      real time.
    </p>
    <p>
      It turns out there's
      <a href="https://en.wikipedia.org/wiki/Spatial_analysis">a whole field of math about this stuff</a>
      already that I didn't even know existed until after developing the
      spline distance fields technique and posting about it on Mastodon, and
      at this time of writing, I have not yet explored it in any significant
      depth.
    </p>
    <p>
      According to my journal, on September 20th of 2024 I realized I could
      generate plausible terrain surfaces entirely from splines that describe
      the important terrain features (rivers, roads, rails, cliffs, etc).  In
      its simplest form each point in space has a corresponding closent point
      on the closest spline.  That closest-point-on-closest-spline (along with
      its corresponding binormal vector) defines a plane that determines the
      local elevation relative to your original arbitrary point in space.  This
      effectively is a method of extruding splines within a constraining
      volume of space that suspiciously resembles a voronoi diagram (because it
      secretly is one, but don't worry about that).
    </p>
    <p>
      Things get a bit dicey for sampling points that are close to the boundary
      of a spline field, but as I wrote in my journal, these inbetween spaces
      should simply be "interpolated somehow".  I call this the "liminality
      problem".  This can appear similar to subduction and obduction in real
      life, and so this quality may be reasonably considered a useful feature
      if it can be handled intentionally.  However, in most cases you will want
      your spline zones to flow together seamlessly, and so this article only
      describes a method that sweeps the problem under the rug.
    </p>
    <p>
      <a href="https://mastodon.gamedev.place/@aeva/113174121732654836">The next day</a>
      I put this idea to the test, and this is what I got:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/spline_field_a.png">
    </p>
    <p>
      Applying what I learned from making that first test, I produce this
      second attempt right away:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/spline_field_b.png">
    </p>
    <p>
      <a href="https://mastodon.gamedev.place/@aeva/113179963448228702">The following day</a>
      I pushed the technique further to experiment with procedural object
      placement and test out road generation.  This is what I came up with:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/spline_field_c.png">
    </p>
    <p>
      This is <em>exactly</em> the sort of thing I've been searching for.
    </p>
    <p>
      This technique is still an area of active experimentation and research
      for me:
    </p>
    <ul>
        <li>
          This technique can be modified to describe
          <a href="https://mastodon.gamedev.place/@aeva/113303633154607005">freeform 3D surfaces</a>
          instead of heightmaps.
        </li>
        <li>
          Exploring alternative
          <a href="https://mastodon.gamedev.place/@aeva/113320880275563952">interpolation strategies</a>.
        </li>
        <li>
          Whether or not
          <a href="https://mastodon.gamedev.place/@aeva/113344090802658027">sparse point clouds</a>
          are better than heightmaps as a rendering intermediary for Star Machine.
        </li>
        <li>
          Actually sitting down and implementing this in Star Machine.
        </li>
      </ul>
    
    <p>
      Unfortunately due to my yearly struggle with
      <a href="https://en.wikipedia.org/wiki/Seasonal_affective_disorder">Father Winter</a>
      and a very stressful ongoing dispute with my health insurance, I've
      stalled out on this research project for the time being.
    </p>
    <p>
      Until the rains of spring heal my soul and wash away the pain,
    </p>
    <h2 id="how_it_works">Here's How the Basic Version Works</h2>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/the_important_part.png">
    </p>
    <p>
      The above pseudo code outlines the entire technique.  If this tells you
      everything you need to know to implement it, great!  Be sure to at least
      take a quick look through the <a href="#appendix_b">pretty pictures</a>
      at the end of this post before you close the browser tab.
      Or don't!  Nobody is paying anyone to hold on to your attention.  You are
      free!  I don't even know if anyone is even reading this because I don't
      collect any analytics at all.
    </p>
    <p>
      Now, for everyone who wasn't born with perfect knowledge of everything,
      the next section of this post walks through how the <em>normal</em>,
      <em>tangent</em>, and <em>binormal</em> vectors work for splines in
      Blender; and the section after that steps through a real working
      implementation of this technique.  Example source files are also
      provided for you to use in any way you like.
    </p>

    <h2 id="relevant_spline_math">Relevant Spline Math</h2>
    <p>
      Blender's Geometry Nodes system provides a variety of useful high level
      functions for working with Blender's curve and point cloud primitives, so
      we're going to use those where possible.  This leaves a few bits of math
      to review  that are important to our implementation.  If you already know
      how to calculate a binormal vector, breeze on over to
      <a href="#generating_the_heightmap">the next section</a>.
    </p>
    <p>
      The first thing we need is the ability to define a plane for any given
      point on a spline.  For our purposes we'll use a point in space and the
      direction that is perpendicular to the plane (aka "the surface normal" of
      the plane).  In terms of spline parameters, these vectors are called the
      <em>position</em> and the <em>binormal</em>.  Blender does not provide
      the spline's <em>binormal</em>, but it is very easy to calculate it from
      the spline's <em>normal</em> and <em>tangent</em> vectors which Blender
      does provide.
    </p>
    <p>
      <strong><em>I cannot stress this enough</em></strong> the thing we want
      here is the thing you're probably used to calling "the surface normal",
      <strong>but</strong>‚Äîfor
      <a href="https://en.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas#Definitions">reasons</a>
      I am <em>not</em> responsible for‚Äîthe thing we want is instead called the
      "<strong>binormal</strong>" here and the thing that is called the "normal"
      is instead a different thing.  Why did the mathematicians do this to us?!
    </p>
    <p>
      Blender's splines always define a <em>tangent</em> and <em>normal</em>
      vector for all control points and all interpolated points.  These are
      "unit vectors", which means they always have a length of one, and they
      encode a direction.  The <em>binormal</em> is the cross product of these
      two vectors, which I'll illustrate in a little bit.
    </p>
    <h3 id="the_tangent_vector">The Tangent Vector</h3>
    <p>
      The <em>tangent</em> vector is a unit vector that grazes the point on the
      curve.  This vector rests on the surface of the plane we want to
      describe.  This is what it looks like:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/tangents.png">
    </p>
    <h3 id="the_normal_vector">The Normal Vector</h3>
    <p>
      The <em>normal</em> vector perpendicular to the <em>tangent</em> vector,
      and also rests on the surface of the plane we want to describe.  This is
      what it looks like:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/normals.png">
    </p>
    <h3 id="calculating_the_binormal">Calculating the Binormal</h3>
    <p>
      To calculate the <em>binormal</em>, take the cross product of the
      <em>normal</em> and <em>tangent</em>, like so:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/binormals.png">
    </p>

    <h2 id="generating_the_heightmap">Generating the Heightmap</h2>
    <p>
      With the spline's <em>binormal</em> in hand, now it is time to generate
      the height map.  Here's the eagle eye view:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/the_big_picture.png">
    </p>
    <p>
      I find it works best to keep the splines in their own collection.  This
      way the geometry node graph can read alll of the splines from it in one
      go, and you don't need to change any code to add more splines to your
      terrain.  Only one geometry nodes modifier is required to implement this
      technique, and that placed on an empty mesh.
    </p>
    <p>
      Let's examine the <strike>spaghetti</strike> program:
    </p>

    <h3 id="curves_to_surfels">Curves to Surfels</h3>
    <p>
      You may have already noticed this, but the curves are just a useful
      editing interface that is immediately discarded.
    </p>
    <p>
      What we're actually doing is using the curves to generate a set of
      primitives called surfels, and then using the surfels to extrapolate the
      surface of the terrain.  In this particular case, a surfel is defined as
      being a point in space with an associated <strike>normal</strike>
      <em>binormal</em> vector.  Maybe I should have named this technique
      "<em>surfel distance fields</em>".
    </p>
    <p>
      Since our heightmap starts as a flat subdivided plane, we'll get the best
      results if we project the surfels onto the XY plane before sampling them
      so that Blender's sampling functions behave the way we expect them to.
      We still need the original position, so we just capture that attribute to
      snapshot it before flattening.
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/overview_part_1.png">
    </p>

    <h3 id="surfel_sampling">Surfel Sampling</h3>
    <p>
      Next we create the geometry that will be deformed into our terrain.  For
      this we use the <em>Grid</em> node.  <strong>The density of the grid
      affects interpolation behavior</strong>.  The mesh generation method
      described in this page takes the "sweep the error under the rug"
      strategy.  <em>If your vertex density is too high, you will get abrupt
      changes in elevation between locations that belong to different
      curves.</em>  Likewise, if your vertex density is too low, your landscape
      will be soft and featureless.
    </p>
    <p>
      To sample the nearest surfel parameters, use the <em>Sample Nearest</em>
      node to find the index of the nearest surfel to a given vertex on the
      grid.  Then use the <em>Sample Index</em> node to translate that index
      into the parameters we want.  If you're not familiar with geometry
      nodes's
      <a href="https://docs.blender.org/manual/en/latest/modeling/geometry_nodes/fields.html">fields</a>
      concept, the following graph section will look confusing.
    </p>
    <p>
      The <em>Capture Attribute</em> at the end of this part of the program is
      not strictly necessary, but I've added it in hopes of making the data
      flow a little clearer.
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/overview_part_2.png">
    </p>

    <h3 id="generate_the_heightmap">Generate the Heightmap</h3>
    <p>
      I've mentioned a plane function many times now, and here it finally is!
      The graph section below starts by finding the distance of each point on
      the undeformed heightmap to the closest surfel.  The function for this is
      the <em>signed distance</em> from an arbitrary point in space to the
      nearest point on a plane.  The term "<em>signed distance</em>" means the
      distance can be a negative value, which usually indicates that the
      evaluated point was under the surface of the plane.
    </p>
    <p>
      However, that would imply that a negation would be needed in my code
      below, <em>which is curiously absent</em>.  The reason for this is I
      screwed up the math somewhere here in such a way that inverts the
      polarity of the result.  This elides the need for the negation.  The
      result appears to be correct though.  Please pretend that I am smart and
      meant to do this.  Someone smart once told me that every shipped game
      contains an even number of sign errors.
    </p>
    <p>
      Moving on, once you have the planar distance in hand, I find that bluring
      it a few iterations helps to smooth out any liminality problems, much
      like adjusting the vertex density.  This is not an exact science, but
      generally if you adjust the number of blur iterations or the number of
      verticies, you also have to adjust the other.
    </p>
    <p>
      Finally, we use the blurred distance field value as an position offset
      along the Z axis, and that gets us the deformed terrain mesh.
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/overview_part_3.png">
    </p>

    <h3 id="tada"><em>Tada!</em></h3>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/result.png">
    </p>

    <h2 id="appendix_a">Appendix A: Show Me the Source!</h2>
    <p>
      Here are the blend files for the examples shown above:
    </p>
    <ul>
      <li><a href="https://zone.dog/braindump/spline_fields/spline_vectors.blend">Spline Vector Illustrations</a></li>
      <li><a href="https://zone.dog/braindump/spline_fields/spline_distance_fields.blend">Full Spline Distance Field Implementation</a></li>
    </ul>
    <p>
      These example files are made available to you to use for whatever you
      like via your choice of
      <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a> or
      <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>.
    </p>
    <p>
      If you do choose to provide attribution for some reason, credit me as
      "Aeva Palecek" and link to this article if it is reasonable to do so.
    </p>

    <h2 id="appendix_b">Appendix B: Examples in the Wild</h2>
    <h2 id="promising_prototype">Promising Prototype Provokes Preproduction Perturbation</h2>
    <p>
      I put one of my early prototypes into the hands of my dear friend
      <a href="https://bsky.app/profile/bmprager.bsky.social">Bitmap</a> and 30
      minutes later she sent me this message:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/unlimited_power_a.png">
    </p>
    <p>
      And the next day she sent me this:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/unlimited_power_b.png"><br>
      <small><em>
        The stripes on the vertical surfaces here are isolines added by a
        shader to show changes in elevation.
      </em></small>
    </p>
    <p>
      This caused quite a stir for the game production she's part of, as they
      ended up completely throwing out the Godot terrain tool they were using
      in favor of switching to a new workflow built around the prototype I gave
      her.  I'm equal parts honored and deeply terrified by this development.
    </p>
    <p>
      Bitmap <strike>fucking <em>hates</em></strike> tends to bounce off of
      conventional digital sculpting tools like z-brush and Blender's sculpt
      mode.  Her artistic background is primarily as a 2D illustrator, and
      she's found that the way she reasons about form and space is generally
      incompatible with those kinds of tools.
    </p>
    <p>
      I'm very eager to see what things she will create now that she can simply
      <em>draw the terrain</em>.
    </p>
    <p>
      I asked Bitmap and The Director if there were any recent(ish) screenshots
      that would also be ok for me to share in this blog post, and they
      provided me with a treasure trove of gorgeous preproduction progress
      photographs which I've included all of below except for the one The Director
      asked me not to:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/bmp_a.png">
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/bmp_b.png">
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/bmp_c.png">
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/bmp_d.png">
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/bmp_e.png">
    </p>
    <p>
      You may be wondering where all of that nice multitexturing in these
      screenshots fits into this technique.  Bitmap provides a set of flat
      subdivided quads with UVs already prepared, and the tool I provided
      deforms them.  Weight painting is used to control how the textures are
      combined.
    </p>
    <h2 id="sculptor">Sculptor: Non-Destructive 3D Modeling in Godot</h2>
    <p>
      My colleague <a href="https://mastodon.gamedev.place/@dbat">Dbat</a> has
      been hard at working building a procedural modeling tool in Godot called
      <a href="https://codeberg.org/dbat/godot-sculptor">Sculptor</a>.
      Sculptor is a non-destructive 3D sculpting tool that works by deforming
      meshes that have been generated via
      <a href="https://en.wikipedia.org/wiki/Constructive_solid_geometry">CSG</a>.
    </p>
    <p>
      To do this, Dbat has developed an advanced version of the spline distance
      fields technique that enables you to create freeform meshes instead of
      height maps.  Their technique uses ray tracing to iteratively deform
      meshes towards the implicit surface described by the input curves.
      Sculptor exposes parameters that allow you to control the projected shape
      and influence of each curve on the mesh deformation process.  Way cool!
    </p>
    <p>
      Dbat's technique would pair very nicely with an adaptive tessellation
      system.
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/sculptor_a.png">
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/sculptor_b.png">
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/sculptor_c.png">
    </p>
    <h2 id="Inverse_distance_weighting">Inverse Distance Weighting Variant</h2>
    <p>
      Math wizard <a href="https://mathstodon.xyz/@Danpiker">Danpiker</a>
      <a href="https://mathstodon.xyz/@Danpiker/113191759673781705">wisely pointed out to me</a>
      that the spline distance fields technique is very compatible with
      <a href="https://en.wikipedia.org/wiki/Inverse_distance_weighting">Inverse Distance Weighting</a>.
      Shortly after, Danpiker put together
      <a href="https://mathstodon.xyz/@Danpiker/113192150280297469">this awesome animated demo</a>
      of exactly that.  Here's a still frame from the demo:
    </p>
    <p>
      <img src="https://zone.dog/braindump/spline_fields/danpiker_inverse_distance_weighting.png">
    </p>
    <p>
      Inverse Distance Weighting solves the liminality problem, and produces a
      <em>very</em> slick look.  You can very the degree of influence by
      adjusting the exponents in the equation.
    </p>
    <p>
      I've found inverse distance weighting to be a bit tricky to implement
      efficiently in geometry nodes, however the introduction of the
      <em>for-each</em> nodes in Blender 4.3 improves things a bit.
    </p>
    <p>
      Personally, I find the smoothing effect is maybe a bit too effective at
      smoothing things out, as it tends to erase the earthy look I'm going for.
      However, I suspect this is easily overcome with a good displacement map.
    </p>
    <h2 id="closing_thoughts">Closing Thoughts</h2>
    <p>
      I like splines!
    </p>
    <h2 id="future_work">Future Work</h2>
    <p>
      I do not know what the future holds.  Let us brave it together.
    </p>
    </div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stimulation Clicker (1616 pts)]]></title>
            <link>https://neal.fun/stimulation-clicker/</link>
            <guid>42611536</guid>
            <pubDate>Mon, 06 Jan 2025 15:48:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neal.fun/stimulation-clicker/">https://neal.fun/stimulation-clicker/</a>, See on <a href="https://news.ycombinator.com/item?id=42611536">Hacker News</a></p>
Couldn't get https://neal.fun/stimulation-clicker/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Mashups ‚Äì Resurrecting Yahoo Pipes, my side project (123 pts)]]></title>
            <link>https://www.mashups.io</link>
            <guid>42609819</guid>
            <pubDate>Mon, 06 Jan 2025 11:54:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mashups.io">https://www.mashups.io</a>, See on <a href="https://news.ycombinator.com/item?id=42609819">Hacker News</a></p>
Couldn't get https://www.mashups.io: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Dive into Time-Series Anomaly Detection: A Decade Review (333 pts)]]></title>
            <link>https://arxiv.org/abs/2412.20512</link>
            <guid>42609595</guid>
            <pubDate>Mon, 06 Jan 2025 11:10:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2412.20512">https://arxiv.org/abs/2412.20512</a>, See on <a href="https://news.ycombinator.com/item?id=42609595">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2412.20512">View PDF</a>
    <a href="https://arxiv.org/html/2412.20512v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Recent advances in data collection technology, accompanied by the ever-rising volume and velocity of streaming data, underscore the vital need for time series analytics. In this regard, time-series anomaly detection has been an important activity, entailing various applications in fields such as cyber security, financial markets, law enforcement, and health care. While traditional literature on anomaly detection is centered on statistical measures, the increasing number of machine learning algorithms in recent years call for a structured, general characterization of the research methods for time-series anomaly detection. This survey groups and summarizes anomaly detection existing solutions under a process-centric taxonomy in the time series context. In addition to giving an original categorization of anomaly detection methods, we also perform a meta-analysis of the literature and outline general trends in time-series anomaly detection research.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: John Paparrizos [<a href="https://arxiv.org/show-email/6830b0c2/2412.20512" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Sun, 29 Dec 2024 16:11:46 UTC (10,831 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The evolution of a structural code editor (161 pts)]]></title>
            <link>https://crowdhailer.me/2025-01-02/the-evolution-of-a-structural-code-editor/</link>
            <guid>42608923</guid>
            <pubDate>Mon, 06 Jan 2025 09:00:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crowdhailer.me/2025-01-02/the-evolution-of-a-structural-code-editor/">https://crowdhailer.me/2025-01-02/the-evolution-of-a-structural-code-editor/</a>, See on <a href="https://news.ycombinator.com/item?id=42608923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>The top image shows the structural editor, and shell, for the <a href="https://eyg.run/">eyg</a> programming language running on a phone.
Later on I‚Äôll show it running on a TV.
On both devices the structural editor is a better coding experience than a text editor would be.</p>

<p>This post outlines the evolution of the editor over several years, and highlights the major changes over time along with some design thoughts and implementation notes.
The web editor is built in <a href="https://gleam.run/">Gleam</a> and <a href="https://github.com/lustre-labs/lustre">Lustre</a>; originally it was <a href="https://gleam.run/">Gleam</a> and <a href="https://svelte.dev/">Svelte</a>. 
There also exists a terminal based structural <a href="https://vimeo.com/827006232">editor built in Go</a>.</p>

<p>Want to jump in and code with it? The latest version is at <a href="https://eyg.run/">eyg</a>.</p>

<h2 id="why-build-a-structural-editor">Why build a structural editor?</h2>

<p>Structural editors, also known as projectional editors, enhance writing, editing and understanding code. Unlike traditional text-based editors, these tools treat code as a structured tree rather than a flat sequence of characters.</p>

<p><em>This structured data may be the Abstract Syntax Tree(AST) of the represented program, however it can also be a different structure.
For this post I won‚Äôt quibble over the differences.</em></p>

<p>Some traditional editors have tools that understand the code structure, for example autocomplete.
However in most cases these tools work as suggestions and a traditional text editor will accept any input.</p>

<p>I define a structural editor as one that does not accept invalid or arbitrary input.
Changes to the program always proceed through well known states.</p>

<p>This clarification is important because the editors I talk about here render the program to the user as text, but it‚Äôs important to note that there is no way to enter arbitrary text.</p>

<p>The benefits of a structural editor are:</p>

<ol>
  <li>
    <p><strong>No syntax errors.</strong>
  Zero time is spent on missing quotes, semi-colons or other details.</p>
  </li>
  <li>
    <p><strong>Better type information.</strong>
Because the program is always in a valid state the type checker can always run and give meaningful feedback.</p>
  </li>
  <li>
    <p><strong>No keywords</strong>
Variables can be called <code>var</code> and functions called <code>fn</code>. Either can also be called üß™ or <code>!_//</code> though maybe they shouldn‚Äôt be.</p>
  </li>
  <li>
    <p><strong>Rich visualisations</strong>
A program can be shown as box and wires, or boolean logic operators. On a smaller scale a record of latitude and longitude can be shown on a map.</p>
  </li>
  <li>
    <p><strong>Reduced complexity</strong>
There is no lexer or parser so issues like <a href="https://gleam.run/news/fault-tolerant-gleam/">fault tolerant parsing</a> are entirely circumvented.</p>
  </li>
</ol>

<p>Several other structed editor projects exist. Jetbrains has <a href="https://www.jetbrains.com/mps/">MPS</a> which targets creating your own domain specific languges.
<a href="https://tylr.fun/">Tylr</a> is a beautiful example but currently only good for one line of code at a time.</p>

<h2 id="an-adhoc-first-attempt">An adhoc first attempt</h2>

<p>This is my first recording of the structural editor - admire the minimalistic and clean look.</p>

<p><iframe src="https://player.vimeo.com/video/664401317?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" title="Week 1"></iframe></p>

<p>The first generation editor worked by directly editing the AST with no effort to hide the details from the user.</p>

<p>Pressing <code>a</code> increased the selection by moving the current selection to the parent node, <code>j/k</code> moved to the previous/next node and
<code>i</code> entered insert mode on the current node. You might see the vim influence of these bindings.</p>

<p>This first version got a few things right.
The command pallet approach in particular is very nice.
It allows you to put a lot of help with certain actions. 
For example when creating a variable the pallet can show all the variables in scope at that position.</p>

<p>At the outset the AST design was driven by the development of the editor, one single enum represented all the expressions in the program.
This is the complete expression type from that time.</p>
<pre><code>pub type Node(m, g) {
  Binary(value: String)
  Tuple(elements: List(Expression(m, g)))
  Record(fields: List(#(String, Expression(m, g))))
  Access(value: Expression(m, g), key: String)
  Tagged(tag: String, value: Expression(m, g))
  Variable(label: String)
  Let(pattern: Pattern, value: Expression(m, g), then: Expression(m, g))
  Function(pattern: Pattern, body: Expression(m, g))
  Call(function: Expression(m, g), with: Expression(m, g))
  Case(
    value: Expression(m, g),
    branches: List(#(String, Pattern, Expression(m, g))),
  )
  Hole
  Provider(config: String, generator: Generator, generated: g)
}
</code></pre>

<p>The update function, called when you press a key in the editor,
was a huge case statement for each combination of key pressed and current position in the tree.
This approach although simple didn‚Äôt scale with complexity.
The AST was used by the editor, type checker and code generation so it was not possible to adapt it to the requirements of any particular use case.</p>

<p>In this first version too many concerns were rolled into one project.</p>

<p><em>The <code>Provider</code> node is my implementation of type providers and not part of this story.
But you can see other videos in my <a href="https://petersaxton.uk/log/">log</a> about them.</em></p>

<p>This first effort eventually ground to a halt under its complexity.</p>

<h2 id="a-simple-ast">A simple AST</h2>

<p>As a rich AST could not work for all usecases I focused on creating the simplest AST.
Complexity for type checking or editing would move to the appropriate modules.</p>

<pre><code>pub type Expression {
  Variable(label: String)
  Lambda(label: String, body: Expression)
  Apply(func: Expression, argument: Expression)
  Let(label: String, definition: Expression, body: Expression)
  Vacant(comment: String)
  Binary(value: BitArray)
  // .. other primitives for integer, string and builtins
  Empty
  Extend(label: String)
  Select(label: String)
  // .. other operators for lists, unions, effects and references
}
</code></pre>

<p>This AST was the result, it still looks almost <a href="https://github.com/CrowdHailer/eyg-lang/blob/8a2a5c0a82ea99a321cfe8e7a0f6cbecaac4f97a/eyg/src/eygir/expression.gleam#L22-L61">identical today</a></p>

<p>By making all features of the language first class, there is a minimal number of compound nodes in the tree. 
Only <code>Lambda</code>, <code>Apply</code> and <code>Let</code> contain child expressions.</p>

<p>To create the record literal <code>{name: "Eve"}</code> required the following expression</p>
<pre><code>Apply(Apply(Extend(label: "name"), String("Eve")), Empty)
</code></pre>

<p>This change makes interpretation and type checking much simpler, take my word for it.</p>

<p>It also simplifies several details of the editor for example:
Positions in the tree are denoted by a list of integers where each integer identifies the child node.
This path is followed from the root node until the required point in the tree.</p>

<p>This <code>step</code> function implements one step of following that path, it takes an expression and goes to n‚Äôth child.
Only the three nodes mentioned have to be taken into account by the <code>step</code> function.
It is known that asking for a child of any other kind of node is an error.
This means that variants can be added/removed to the <code>Expression</code> type without in any way modifying or moving around the tree.</p>

<pre><code>pub fn step(exp, n) {
  case exp, n {
    e.Lambda(param, body), 0 -&gt; Ok(#(body, e.Lambda(param, _)))
    e.Apply(func, arg), 0 -&gt; Ok(#(func, e.Apply(_, arg)))
    e.Apply(func, arg), 1 -&gt; Ok(#(arg, e.Apply(func, _)))
    e.Let(label, value, then), 0 -&gt; Ok(#(value, e.Let(label, _, then)))
    e.Let(label, value, then), 1 -&gt; Ok(#(then, e.Let(label, value, _)))
    _, _ -&gt; Error("invalid path")
  }
}
</code></pre>

<p>This change didn‚Äôt effect the external look of the editor but it did substantially clean up the implementation.</p>

<h2 id="text-editing-is-intuitive-familiar">Text editing is <del>intuitive</del> familiar</h2>

<p>Moving around the code was tricky in the previous editor. 
This was because the order of nodes in the tree might not match the order they were shown on screen.</p>

<p>For example selecting the field from a record.</p>

<pre><code>let x = user.name
</code></pre>
<p>If <code>user</code> is selected, to move to <code>name</code> required moving left and another move left would jump back to the <code>x</code> of the variable declaration.</p>

<p>This is because the <code>.</code> syntax is sugar for calling the select operator on the variable user. 
In all other cases arguments come after the function but, for select, reversing the order it‚Äôs projected to the user makes more sense.</p>

<pre><code>Apply(Select("name"), Variable("user"))
</code></pre>

<p>Making transformations directly on the AST felt powerful but there were too many occasions where an understanding of the AST was needed to know how to move.</p>

<p>The next version aimed to fix the navigation issue by keeping a cursor centric approach.
This means that one key press of left moves the cursor one position left and a key press of right moves the cursor one position right.</p>

<p>Even with moving back to a text based navigation I wanted a fully structural editor so that the program was always a valid structure.</p>

<p>Traditional editors have similar behaviour, for example: when typing <code>(</code> an automatic <code>)</code> is often placed.
In this way you don‚Äôt go through a state of having unmatched brackets. 
The main difference is in a text editor this bracket matching features are adhoc and many other ways exist to create a syntactically invalid program.</p>

<p>You can see this working here.</p>
<p><iframe src="https://player.vimeo.com/video/833330371?h=9aeaa64b46&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" title="05/06/2023, Features of the structured editor"></iframe></p>

<p>This editor was actually quite short lived.
I liked that it showed the type of holes in the program directly in the editor.</p>

<p>However the editor was unintutive in many cases.
Keeping the editor structural but pretending it wasn‚Äôt led to too many inconsistencies.
There were places that typing certain characters would do nothing because the character was invalid.</p>

<p>Implementing this editor got complicated quickly.
Intercepting all keyboard events meant dropping out of Gleam and understanding the <a href="https://javascript.info/selection-range">range and selection</a> API‚Äôs in the browser. This resulted in a lot of <a href="https://github.com/CrowdHailer/eyg-lang/blob/40d1606d50292724970d79a6b1f61926294bc10f/eyg/src/easel_ffi.js">foreign function interface code</a></p>

<p>A positive aside of this effort to go text based meant I wanted better Gleam bindings to the browser API‚Äôs and that need kicked off building <a href="https://github.com/crowdhailer/plinth">plinth</a> a library to do just that.</p>

<h2 id="adding-sugar-and-projections">Adding sugar and projections</h2>

<p>The two previous editors were at opposing ends of a spectrum.
For the first, movement was entirely based on the layout of the AST.
For the second, movement was entirely based on the layout of the text.</p>

<p>I wrote approximately 10k ‚Äúlines‚Äù of EYG code, including a JSON parser and type checker, using the simple AST editor.
Transforming the AST felt very powerful when it worked. However, where the visuals did not match the AST representation navigation was unintuitive.
I eventually mastered it but it was clearly a blocker for anyone else picking up the editor.</p>

<p>This generation of the editor tries to find a middle ground one the spectrum from text to AST.
Navigation is always by whole AST nodes. In addition directions are always consistent with how the program is laid out on screen.</p>

<p>This was achieved by creating a representation of the program specifically for manipulation in the editor. There is:</p>

<ol>
  <li><a href="https://github.com/CrowdHailer/eyg-lang/blob/441e5686c6721373d6b66636c4f1ce73301d60d7/eyg/src/morph/editable.gleam#L11-L30"><code>Editable</code></a> a type which deals with larger code units than the basic AST</li>
  <li><a href="https://github.com/CrowdHailer/eyg-lang/blob/441e5686c6721373d6b66636c4f1ce73301d60d7/eyg/src/morph/projection.gleam#L234-L299"><code>Projection</code></a> a zipper into the <code>Editable</code> type that makes navigation and transforms more efficient.</li>
  <li><a href="https://github.com/CrowdHailer/eyg-lang/blob/441e5686c6721373d6b66636c4f1ce73301d60d7/eyg/src/morph/lustre/frame.gleam#L9-L17"><code>Frame</code></a> an intermediate representation for rendering expressions that track if they are single or multiple lines.</li>
</ol>

<p>The basic AST is still used by the interpreter and type checker so the complexity of presenting code to the user is only in the modules which deal with showing code to a user.</p>

<p><iframe src="https://player.vimeo.com/video/984437518?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" title="7/15/2024, Structured editor in a code notebook."></iframe></p>

<h2 id="using-the-mouse">Using the mouse</h2>

<p>Working with a keyboard is efficient, but only if you know the key bindings to each action you need.
Which key to press to get a desired action is not discoverable from looking at the UI element.
After all the UI for keyboard actions is just a cursor somewhere in the page.</p>

<p>A user is required to consult a cheatsheet of keyboard actions and learn some before ever getting started.
This friction makes getting started very challenging.</p>

<p>Devices without keyboards have to show virtual keyboards to use keyboard shortcuts.
If the actions are being presented on screen they might as well be shown as something more relevant than the letter code corresponding to the short cut.</p>

<p>This latest iteration adds a menu and icon based UI for each transformation that is possible on the AST.
A question mark button at the top toggles showing text descriptions of each action but at the cost of less screen to work with.
The UI works with keyboard, mouse, touch or TV remote.</p>

<p><img src="https://crowdhailer.me/2025-01-02/the-evolution-of-a-structural-code-editor/tv.jpg" alt=""></p>

<p>It also works great with a keyboard and if you forget the key, seemlessly switch to the visual.</p>

<p>Implementing the visual UI was simple with Lustre and the state and event approach it has.
Lustre is an implementation of the Elm architecture.</p>

<p>The state of the program works by <a href="https://github.com/CrowdHailer/eyg-lang/blob/441e5686c6721373d6b66636c4f1ce73301d60d7/website/src/website/components/snippet.gleam#L302-L352">switching on key press events</a>.</p>

<pre><code>pub fn update(state, message) {
  let Snippet(status: status, ..,) = state
  case message, status {
    UserPressedCommandKey(key), Editing(Command(_)) -&gt; {
      let state = Snippet(..state, using_mouse: False)
      case key {
        "ArrowRight" -&gt; move_right(state)
        "ArrowLeft" -&gt; move_left(state)
        "ArrowUp" -&gt; move_up(state)
        "ArrowDown" -&gt; move_down(state)
        " " -&gt; search_vacant(state)
        // Needed for my examples while Gleam doesn't have file embedding
        "Q" -&gt; copy_escaped(state)
        "w" -&gt; call_with(state)
        "E" -&gt; assign_above(state)
        "e" -&gt; assign_to(state)
        "r" -&gt; insert_record(state)
        "t" -&gt; insert_tag(state)
        "y" -&gt; copy(state)
        "Y" -&gt; paste(state)
        // "u" -&gt;
        "i" -&gt; insert_mode(state)
        "o" -&gt; overwrite_record(state)
        "p" -&gt; insert_perform(state)
        "a" -&gt; increase(state)
        "s" -&gt; insert_string(state)
        "d" | "Delete" -&gt; delete(state)
        "f" -&gt; insert_function(state)
        "g" -&gt; select_field(state)
        "h" -&gt; insert_handle(state)
        "j" -&gt; insert_builtin(state)
        "k" -&gt; toggle_open(state)
        "l" -&gt; insert_list(state)
        "#" -&gt; insert_reference(state)
        "z" -&gt; undo(state)
        "Z" -&gt; redo(state)
        // "x" -&gt;
        "c" -&gt; call_function(state)
        "v" -&gt; insert_variable(state)
        "b" -&gt; insert_binary(state)
        "n" -&gt; insert_integer(state)
        "m" -&gt; insert_case(state)
        "M" -&gt; insert_open_case(state)
        "," -&gt; extend_before(state)
        "EXTEND AFTER" -&gt; extend_after(state)
        "." -&gt; spread_list(state)
        "TOGGLE SPREAD" -&gt; toggle_spread(state)
        "TOGGLE OTHERWISE" -&gt; toggle_otherwise(state)

        "?" -&gt; #(state, ToggleHelp)
        "Enter" -&gt; execute(state)
        _ -&gt; show_error(state, NoKeyBinding(key))
      }
    }
  }
}
</code></pre>

<p>The UI buttons make use of the same events and update logic.
Each button in the visual UI consists of;</p>

<ul>
  <li>the icon to show (I use the heroicon library and the outline style)</li>
  <li>a text description of the action (which is shown when ‚Äúshow help‚Äù is on)</li>
  <li>the keypress event to dispatch.</li>
</ul>

<pre><code>fn cmd(x) {
  ShellMessage(snippet.UserPressedCommandKey(x))
}

fn item_before() {
  #(outline.arrow_turn_left_down(), "item before", cmd(","))
}

fn item_after() {
  #(outline.arrow_turn_right_down(), "item after", cmd("EXTEND AFTER"))
}

fn undo() {
  #(outline.arrow_uturn_left(), "undo", cmd("z"))
}

fn redo() {
  #(outline.arrow_uturn_right(), "redo", cmd("Z"))
}
</code></pre>

<p><em>There are more actions than available keys so the <code>EXTEND AFTER</code> string value can be dispatched by clicking the correct button, but not by any keyboard binding.</em></p>

<p>Here is the final result, as of today.</p>

<p><iframe src="https://player.vimeo.com/video/1043702197?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" title="1/3/2025, Fibonacci sequence in visual editor"></iframe></p>


<h2 id="whats-next">What‚Äôs next</h2>

<p>There will be more iterations of the editor but this one is interesting.
I want to see what other people make of the structured editor experience.
You can <a href="https://eyg.run/">try it out now</a> and if you have any opinions please get in touch. <em><a href="https://bsky.app/profile/crowdhailer.bsky.social">Bluesky</a> the best right now</em>.</p>

<p>The EYG language is still developing. References to external packages and better error messages based on effects will be coming soon.
To keep up with that progress join the newsletter.</p>

  <hr>
  I'm building EYG an experiment in a building better languages and tools; for some measure of better. <br>
  All progress is reported in my irregular newsletter.
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lord of the Io_uring (2020) (159 pts)]]></title>
            <link>https://unixism.net/loti/index.html</link>
            <guid>42608436</guid>
            <pubDate>Mon, 06 Jan 2025 07:11:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unixism.net/loti/index.html">https://unixism.net/loti/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=42608436">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="welcome-to-lord-of-the-io-uring" role="main">

<p><code><span>io_uring</span></code> is a powerful new way to do asynchronous I/O programming under Linux. Doing away with various limitations of previous generation  I/O subsystems, <code><span>io_uring</span></code> holds immense promise. For more details on what <code><span>io_uring</span></code> brings to the table, please see the chapter <a href="https://unixism.net/loti/what_is_io_uring.html#what-is-io-uring"><span>What is io_uring?</span></a>.</p>
<div id="about">
<h2>About<a href="#about" title="Permalink to this headline">¬∂</a></h2>
<p>This <code><span>io_uring</span></code> guide was created by Shuveb Hussain, who is also the author of the Linux-focused blog, <a href="https://unixism.net/">unixism.net</a>. You can <a href="https://twitter.com/shuveb">follow me on Twitter</a> where my posts are mainly tech-related with a focus on Linux, performance, scalability and cloud.</p>
</div>
<div id="contributing">
<h2>Contributing<a href="#contributing" title="Permalink to this headline">¬∂</a></h2>
<p>The source code repository for this guide is <a href="https://github.com/shuveb/loti">here on Github</a>. Please send me pull requests should you want to contribute. If you find any bugs in either the documentation or the included source code examples, please raise an issue on GitHub. The repository for the example programs is maintained separately. Please see details below.</p>
</div>
<div id="source-code-for-examples">
<h2>Source code for examples<a href="#source-code-for-examples" title="Permalink to this headline">¬∂</a></h2>
<p>Source code for all example programs in this guide are available <a href="https://github.com/shuveb/loti-examples">on Github</a>. If you find bugs in the examples, please raise issues on Github. I want to keep these examples simple and to the point. I many not merge pull requests that add features for that reason. Pull requests that fix bugs are welcome.</p>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uncut Currency (201 pts)]]></title>
            <link>https://www.usmint.gov/paper-currency/uncut-currency/</link>
            <guid>42608155</guid>
            <pubDate>Mon, 06 Jan 2025 06:12:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usmint.gov/paper-currency/uncut-currency/">https://www.usmint.gov/paper-currency/uncut-currency/</a>, See on <a href="https://news.ycombinator.com/item?id=42608155">Hacker News</a></p>
Couldn't get https://www.usmint.gov/paper-currency/uncut-currency/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Doom, the Gallery Experience (522 pts)]]></title>
            <link>https://bobatealee.itch.io/doom-the-gallery-experience</link>
            <guid>42607794</guid>
            <pubDate>Mon, 06 Jan 2025 04:53:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bobatealee.itch.io/doom-the-gallery-experience">https://bobatealee.itch.io/doom-the-gallery-experience</a>, See on <a href="https://news.ycombinator.com/item?id=42607794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<p><em>DOOM: The Gallery Experience was created as an art piece designed to parody the wonderfully pretentious world of gallery openings.</em></p><p>

<em>In this experience, you will be able to walk around and appreciate some fine art while sipping some wine and enjoying the complimentary hors d‚Äôoeuvres in the beautifully renovated and re-imagined E1M1 of id Software's DOOM (1993).</em><br>
<img src="https://img.itch.zone/aW1nLzE2MDg3Mjk0LnBuZw==/original/p2%2BXgT.png" loading="lazy">
<strong><u>CONTROLS</u></strong><br>
WASD / Arrow Keys - Move<br>
Right Click / Space - Interact<br>
Left Click / Shift - Drink<br>
Number Keys - Select beverage<br>
P - Pause</p><p>
Mouse / WASD / Arrow Keys - Navigate menus<br>
Left Click / Space / Enter - Confirm<br>
Right Click - Back<br>
F / Escape - Enter / Exit fullscreen</p></div><p>Supports mobile devices, as well!</p>
<p><img src="https://img.itch.zone/aW1nLzE2MDg3Mjk1LnBuZw==/original/lUEGu%2F.png" loading="lazy">
<strong><u>CREDITS</u></strong><br>
Filippo Meozzi - Producer, Director<br>
Liam Stone - Programming, Misc. Art<br>
<a href="https://www.metmuseum.org/art/collection/search?showOnly=openAccess" target="_blank" rel="nofollow noopener" referrerpolicy="origin">The Met Open Access Collection</a><br>
<a href="https://www.spriters-resource.com/ms_dos/doomdoomii/" target="_blank" rel="nofollow noopener" referrerpolicy="origin">The Spriter's Resource</a><br>
<a href="https://pmmusic.pro/downloads/" target="_blank" rel="nofollow noopener" referrerpolicy="origin">PM Music</a></p><p>
DOOM is copyright ¬© 1993 id Software.</p><p>
Find a bug? Report it <a href="https://github.com/bobatealee/doom_tge/issues" target="_blank" rel="nofollow noopener" referrerpolicy="origin">here</a>!
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hitting OKRs vs. Doing Your Job (340 pts)]]></title>
            <link>https://jessitron.com/2025/01/05/hitting-okrs-vs-doing-your-job/</link>
            <guid>42607623</guid>
            <pubDate>Mon, 06 Jan 2025 04:19:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jessitron.com/2025/01/05/hitting-okrs-vs-doing-your-job/">https://jessitron.com/2025/01/05/hitting-okrs-vs-doing-your-job/</a>, See on <a href="https://news.ycombinator.com/item?id=42607623">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
			
<p>In Engineering, quarterly OKRs (Objectives &amp; Key Results) can feel like a duplication of product planning. Basically, they say ‚ÄúShip the Roadmap.‚Äù What new information are they <a href="https://jessitron.com/2024/12/22/okrs-for-evil-and-good/">communicating</a> in that case? And if the OKRs say anything else, they‚Äôre in conflict the roadmap!</p>



<p>An example (that I made up):</p>



<figure><img data-recalc-dims="1" decoding="async" width="840" height="317" src="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.15.png?resize=840%2C317&amp;ssl=1" alt="Objective: Deliver Frontend Observability
KR: all features in Phase 1 are delivered
KR: error rate less than 3%
KR: 1000 users/day interact with the new screen" srcset="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.15.png?resize=1024%2C386&amp;ssl=1 1024w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.15.png?resize=300%2C113&amp;ssl=1 300w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.15.png?resize=768%2C289&amp;ssl=1 768w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.15.png?resize=1200%2C452&amp;ssl=1 1200w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.15.png?w=1232&amp;ssl=1 1232w" sizes="(max-width: 840px) 100vw, 840px"></figure>



<p>In Marketing, quarterly OKRs express our intentions clearly. They work really well to describe the focus for this time period. Marketing doesn‚Äôt complain about having to make OKRs.</p>



<p>A marketing example (that I made up):</p>



<figure><img data-recalc-dims="1" decoding="async" width="840" height="251" src="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.24.png?resize=840%2C251&amp;ssl=1" alt="Objective: Launch of Frontend Observability drives pipeline
KR: 3 news outlets report the launch
KR: 2000 hits to our landing page
KR: 100 marketing-qualified leads from target accounts" srcset="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.24.png?resize=1024%2C306&amp;ssl=1 1024w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.24.png?resize=300%2C90&amp;ssl=1 300w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.24.png?resize=768%2C230&amp;ssl=1 768w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.24.png?resize=1200%2C359&amp;ssl=1 1200w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.55.24.png?w=1418&amp;ssl=1 1418w" sizes="(max-width: 840px) 100vw, 840px"></figure>



<p>Why are OKRs easier in Marketing?</p>



<p>Partly: Marketing is closer to project work, while Engineering (at places like Honeycomb) is product work. Projects like Marketing campaigns fit within a quarter or two, while product work is an ongoing rhythm of updates.</p>



<p>There‚Äôs an ongoing rhythm of work in Marketing, too! There are ads to run, webinars to run, emails to send, events to staff. OKRs express <em>which</em> ads and webinars and events ‚Äî who we‚Äôre targeting and with what message.</p>



<p>Does this duplicate the campaign briefs? ‚Ä¶ yes. Therefore, OKRs often mention only new campaigns, new audiences or channels. They say what we‚Äôre spending money and time on <em>this</em> quarter, that we don‚Äôt do <em>every</em> quarter.</p>



<h4>Regular ongoing work doesn‚Äôt show up in OKRs, usually. That‚Äôs what KPIs (Key Performance Indicators) are for.</h4>



<p>Marketing has KPIs for their core job: bringing in leads, which become sales opportunities. We count those. We monitor website traffic, ad performance, SEO ranking, webinar attendance, contacts made at events.</p>



<p>These KPI numbers only show up in OKRs when we‚Äôre trying to improve them or get them differently, like in a new audience or with a new message. OKRs express shifts in focus, changes in process, or conversations we need to have.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="840" height="441" src="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.38.png?resize=840%2C441&amp;ssl=1" alt="Objective: Expand awareness of Honeycomb in these 3 countries
Objective: Reduce cost per opportunity
KR: Improve MQL to SQL conversion rate from 7 to 10%
Objective: Find 2 use cases worth investing in" srcset="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.38.png?resize=1024%2C538&amp;ssl=1 1024w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.38.png?resize=300%2C158&amp;ssl=1 300w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.38.png?resize=768%2C404&amp;ssl=1 768w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.38.png?resize=1200%2C631&amp;ssl=1 1200w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.38.png?w=1210&amp;ssl=1 1210w" sizes="auto, (max-width: 840px) 100vw, 840px"></figure>



<p>Engineering has KPIs for our core job: running software and shipping updates. Service-Level Objectives (<a href="https://www.honeycomb.io/blog/honeycomb-internal-slos">SLOs</a>) and <a href="https://nicolefv.com/writing">Accelerate</a> metrics like Deployment Frequency tell us we‚Äôre working smoothly.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="242" height="300" src="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.54.18.png?resize=242%2C300&amp;ssl=1" alt="sticker: shipping is the heartbeat of your company" srcset="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.54.18.png?resize=242%2C300&amp;ssl=1 242w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-19.54.18.png?w=630&amp;ssl=1 630w" sizes="auto, (max-width: 242px) 100vw, 242px"></figure></div>


<p>Shipping features from the roadmap is a chunk of our core job. It shouldn‚Äôt usually be in our OKRs. OKRs say what is different this quarter, what we‚Äôre changing, and what we‚Äôre trying to figure out.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="840" height="466" src="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.46.png?resize=840%2C466&amp;ssl=1" alt="Objective: Smooth launch of Frontend Observability
Objective: Get 3 new team members in on-call rotation.
Objective: Adopt these 2 services from this other team
Objective: Improve responsiveness of Timeline View
KR: Distributed tracing shows latency contributions" srcset="https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.46.png?resize=1024%2C568&amp;ssl=1 1024w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.46.png?resize=300%2C166&amp;ssl=1 300w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.46.png?resize=768%2C426&amp;ssl=1 768w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.46.png?resize=1200%2C665&amp;ssl=1 1200w, https://i0.wp.com/jessitron.com/wp-content/uploads/2025/01/Screenshot-2025-01-05-at-20.02.46.png?w=1504&amp;ssl=1 1504w" sizes="auto, (max-width: 840px) 100vw, 840px"></figure>



<p>Wait a minute! One of these examples is ‚ÄúSmooth launch of Frontend Observability.‚Äù Doesn‚Äôt that say ‚Äòship the roadmap‚Äô?</p>



<p>Shipping the features is part of a smooth launch, but it doesn‚Äôt end there. Of all the features we‚Äôre shipping this quarter, that one is the most critical to the business. Its presence in the OKRs tells people that we‚Äôll push other work, we‚Äôll respond immediately to bug reports, we‚Äôll support this release with enthusiasm.</p>



<p>When a team‚Äôs OKRs duplicate the roadmap, I read that as ‚ÄúWe aren‚Äôt trying to improve. This is a quarter for trudging along.‚Äù Not a good sign.</p>



<p>OKRs are for ‚ÄúWhat is special about this quarter? What is new? How do we want to be different? What do we want to figure out?‚Äù</p>



<p>Let OKRs highlight a special focus. Don‚Äôt try to cram everything you do into them.</p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unemployed office workers are having a harder time finding new jobs (120 pts)]]></title>
            <link>https://www.wsj.com/economy/jobs/job-search-workers-unemployment-months-5a4cfcee</link>
            <guid>42607454</guid>
            <pubDate>Mon, 06 Jan 2025 03:46:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/economy/jobs/job-search-workers-unemployment-months-5a4cfcee">https://www.wsj.com/economy/jobs/job-search-workers-unemployment-months-5a4cfcee</a>, See on <a href="https://news.ycombinator.com/item?id=42607454">Hacker News</a></p>
Couldn't get https://www.wsj.com/economy/jobs/job-search-workers-unemployment-months-5a4cfcee: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Apple squandered the Holy Grail (292 pts)]]></title>
            <link>https://xeiaso.net/blog/2025/squandered-holy-grail/</link>
            <guid>42607151</guid>
            <pubDate>Mon, 06 Jan 2025 02:55:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xeiaso.net/blog/2025/squandered-holy-grail/">https://xeiaso.net/blog/2025/squandered-holy-grail/</a>, See on <a href="https://news.ycombinator.com/item?id=42607151">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article>
    
    
    <p>
        Published on <time datetime="2025-01-06">01/06/2025</time>, 5397 words, 20 minutes to read
    </p>

    
        <p>Why Apple Intelligence failed even though everything it's built upon is nearly perfect</p>
    

    
        
            
    

    

        
    

    
        <figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/hero/shaka-walls-fell.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/hero/shaka-walls-fell.webp"><img alt="An image of A crumbling ruin of a once-mighty building on a hill in Afganistan" loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/hero/shaka-walls-fell.jpg"></picture></figure>
        <small>A crumbling ruin of a once-mighty building on a hill in Afganistan - Photo by Suliman Sallehi, found on Pexels</small>
    

    <p>A while ago, I got really frustrated at my Samsung S7. It was failing to hold a battery charge, or having issues with the Wi-Fi, or DNS over LTE or something and I reached a breaking point where I bussed over to Bellevue Square and bought an iPhone 7. It was my first Apple product that I'd ever bought with my own money and my first non-Android phone since I used Windows Mobile 6 on a T-Mobile Dash in high school.</p>
<p>Needless to say, I loved it at first sight and all my phones since have been iPhones. The camera is good enough that I have to go out of my way to make my actual cameras different from what you can get on an iPhone. Hell, the iPhone is a fully capable cinema camera these days. It's easily been one of the best technology moves I've ever done for my creative career. The device enables me to do things and create memories of them to share with others.</p>
<h2>Bicycles for the mind</h2>
<p>Way back in 1981, Steve Jobs (one of the co-founders of Apple) described the vision of Apple computers like this:</p>
<blockquote><p>I read a study that measured the efficiency of locomotion for various species
on the planet. The condor used the least energy to move a kilometer. And,
humans came in with a rather unimpressive showing, about a third of the way
down the list. [...] But, then somebody at Scientific American had the insight
to test the efficiency of locomotion for a man on a bicycle. And [...] a human
on a bicycle, blew the condor away. [A computer is] the most remarkable tool
that we‚Äôve ever come up with, and it‚Äôs the equivalent of a bicycle for our
minds.</p></blockquote>
<p>-<a href="https://www.goodreads.com/quotes/9281634-i-think-one-of-the-things-that-really-separates-us">Steve Jobs</a></p>
<p>Apple computers aim to make it easier for people to be creative while spending less energy to do it. One of the big things that Apple made the Macintosh for was typography. With that, they made <a href="https://en.wikipedia.org/wiki/MacWrite">MacWrite</a>, one of the two programs that shipped with every Macintosh computer for free. If you were used to having to write documents out by hand or using a typewriter to make them, the leap to something like a word processor is so amazingly vast that it's difficult for anyone younger than me to comprehend it. We've had them all our lives.</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/macwrite.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/macwrite.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/macwrite.webp"><img alt="A screenshot of an emulated Macintosh running MacWrite with the first paragraph of The Bee Movie script in it." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/macwrite.jpg"></picture></a><figcaption>A screenshot of an emulated Macintosh running MacWrite with the first paragraph of The Bee Movie script in it.</figcaption></figure>
<p>Imagine not being able to reliably use the backspace key when you're writing something. Imagine a world where all you could do was just write more text. Sure, there were ways to "cover up" a mis-typed letter, but they were vastly more inconvenient than just ignoring it or re-typing the word and crossing the wrong one out by hand.</p>
<p>Word processors let you use the backspace key to delete text and then look at the screen to get a reasonable approximation of what the printed document would look like. Before you print it.</p>
<p>To say that this enables a vastly different kind of creative process is like saying that water makes things damp. Word processors like MacWrite absolutely transformed the ways that everyone used computers. They were bicycles for the mind and without them our world would be starkly different. I shudder to imagine that <a href="https://nanowrimo.org/">NaNoWriMo</a> would be a thing without word processors.</p>
<p>Many companies want to make computers that you can use to do computer things. Apple makes tools that you use as an extension of your body in order to do creative things. They don't just sell computers, they sell something that helps enable you to create things that just so happen to be computers.</p>
<p>This is the big vision difference that puts Apple in its own class. They sell bicycles for the mind.</p>
<h2>Intelligence as a faucet</h2>
<p>In June 2024, Apple announced <a href="https://www.apple.com/apple-intelligence/">Apple Intelligence</a>: a set of features aimed at making your smartphone smart. The biggest thing that stood out to me was this example of what Apple Intelligence was going to enable in Siri:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/podcast-other-day.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/podcast-other-day.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/podcast-other-day.webp"><img alt="An Apple Keynote slide saying 'Play that podcast my wife sent the other day'." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/podcast-other-day.jpg"></picture></a><figcaption>An Apple Keynote slide saying 'Play that podcast my wife sent the other day'.</figcaption></figure>
<p>If they could really just correlate relationships, categorize links, and make all of that context visible to Siri, that would be fundamentally transformative in ways that the word processor would be to people that didn't have it before. Everything else done with it would be added bonuses or party tricks on the side. The real benefit would be being able to search through all of your digital life across every app with simple queries and then have your phone do things for you.</p>
<p>Sure Craig's example was playing a podcast, but the basic idea holds for other types of media too. "Share those pics from San Francisco to Instagram." All this context that everything is building up would finally be useful to the users instead of just useful to the companies making all of the apps we use.</p>
<p>They wanted to make all Apple devices be able to tap into <em>intelligence</em> as a faucet in the same way that Spotify lets you tap into music as a faucet and that the AWS API lets you tap into compute as a faucet. This is massive and if it was pulled off right would be the new standard that companies like Samsung and Google would clone the same way they cloned the hardware and software design of the iPhone.</p>
<p>In that keynote, they spilled out the vision that computers should work <em>with</em> you in order for you to do what you want to do. They should enable you to be creative. They should be bicycles for the mind. The fact that they are computers should only be a footnote in an appendex titled "implementation details".</p>
<p>Then they casually dropped the holy grail of trusted compute, but in order to understand why it's so big we need to take a little detour into the modern Internet user's view of the Internet.</p>
<h2>Apps as thin as reception</h2>
<p>One of the biggest problems with modern applications is that they are thin shells around web services. When you open the Instagram or Bluesky apps, your phone makes a request to their servers and then shows you posts when it gets a response. You don't know or care how those responses are getting made, you just know that when you open the app, you get content and that makes you happy.</p>
<p>However, when you don't have signal, you don't have the app. Go on an airplane and once you run out of reception the app is worthless. You can't queue posts to be made when you get back into signal. You can't view posts that were available before you lost connection. You can't even view things that you just posted in some cases. The app breaks and you are slowly alienated from your data one photo at a time.</p>
<p>This is the way nearly every single app on my phone works with only two exceptions: Signal and everything Apple makes. If you want to read more about how the modern user's experience with the Internet is like, check out Ed Zitron's <a href="https://www.wheresyoured.at/never-forgive-them/">Never Forgive Them</a>.</p>
<blockquote><p>As every single platform we use is desperate to juice growth from every user,
everything we interact with is hyper-monetized through plugins, advertising,
microtransactions and other things that constantly gnaw at the user
experience. We load websites expecting them to be broken, especially on
mobile, because every single website has to have 15+ different ad trackers,
video ads that cover large chunks of the screen, all while demanding our email
or for us to let them send us notifications.</p></blockquote>
<p>-<a href="https://www.wheresyoured.at/never-forgive-them/">Ed Zitron</a></p>
<p>Not to mention, you don't know how the services that power your apps work. The market at large does not want to pay for chat programs or social media. Running chat programs and social media apps is mind-bogglingly expensive. Venture capital only lasts so long and the companies involved have to make money somehow. The big pile of user data starts to look like a really good thing to mine in order to make a profit.</p>
<h2>The holy grail of trusted compute</h2>
<p>This stands in stark contrast to the goal of something like Apple Intelligence. When possible, Apple Intelligence will run on your device. Apple <a href="https://arxiv.org/abs/2312.11514">went out of their way</a> to make it possible and easy to run large language models and other AI models on your device without having to make too many compromises in the process. If something is done on your device (or at least on hardware that you can look at, like a Mac mini in your office), then the computation is <em>infinitely</em> more private than anything involving making a request to the outside world.</p>
<p>In Apple's WWDC keynote they claimed that they had a system called Private Cloud Compute that would enable users to have the same privacy guarantees (or more) when making requests out over the network as they did for computations running on their local devices.</p>
<p>This seemed impossible to me. From what I know about how the web service sausage is made, it seems impossible to have all of these guarantees at the same time:</p>
<ul>
<li>User data is only used to fulfill requests and then erased.</li>
<li>The load balancing infrastructure doesn't know who is making a request and what server it is going to.</li>
<li>Researchers are able to inspect and verify the Private Cloud Compute system and simulate it on their laptops.</li>
<li>Apple site reliability staff does not have privileged access to Private Cloud Compute nodes and logging is minimized at the compiler level.</li>
<li>An attacker cannot reliably figure out which node is being used to make any request from any user.</li>
</ul>
<p>If you have any modicum of site reliability experience, this seems like an unsatisfiable set of constraints. It seems literally impossible, yet here they are claiming that they have done it.</p>
<p>The <a href="https://security.apple.com/documentation/private-cloud-compute">technical details</a> of how they pulled this off is well worth reading, if only because it is the first time I have ever seen any company's AI product team put together a cogent security model and release that security model to the public. TL;DR:</p>
<ul>
<li>They X-ray the hardware at every step of the assembly process and compare that to reference images in order to combat threats from factory workers adding unapproved hardware to the boards of the servers.</li>
<li>You can set up your own local copy of a Private Cloud Compute node and punish it with all the hellfire you want to see if you can break it and get root. Apple will pay you a lot of money if you can.</li>
<li>The hardware certification process involves a lot of unrelated people in unrelated departments of Apple.</li>
<li>Every Private Cloud Compute node is rigged to not only decertify itself when power is removed, they also rigged the main power for the board to the chassis intrusion switch. Open the server? Power gets cut and the node is de-certified.</li>
<li>Every time your devices make a request to Private Cloud Compute, they record the node ID that was used to fulfill it and you can go in and verify that all of the nodes your device used are still certified.</li>
<li>The production OS images are free for the public to download and not encrypted in any way.</li>
<li>Every package that makes up the important parts of the OS are split into two types: code and data. You cannot mix code into a data package or vice-versa.</li>
</ul>
<p>This is literal madness in comparison to how most other AI products are run. Most of the time, an AI product is run on some GPUs you got somewhere that run some firmware that you probably haven't tested or verified (even though everyone with access to the GPU can reflash the firmware from software), with bog-standard ngnix or something choosing to route your requests to a service running somewhere without any real guarantees that the service is not logging and storing literally everything you put into it. From a user privacy standpoint, it's basically the same as using Instagram. You assume that everything is being logged and used to make money somehow.</p>
<p>Apple is standing in stark opposition to this and saying "no, we ain't doing that" and then backing it all up with code as well as detailed documentation for how they pulled it all off. They also released the source code for the security-critical parts of Private Cloud Compute <a href="https://github.com/apple/security-pcc">openly on GitHub</a>.</p>
<p>This is the holy grail for remotely attested trusted compute. This OS is the kind of thing that Richard Stallman was warning about in <a href="https://www.gnu.org/philosophy/right-to-read.en.html">The Right to Read</a>. You don't get root there. You don't get a compiler. You don't get a debugger. You don't get anything but the ability to run software that was shipped with the OS image. If this OS were shipped to consumers, you would have a nearly unhackable system that would make it basically impossible to tinker with. There are many reasons why you would want such a thing in <a href="https://www.youtube.com/watch?v=dWzz3NeDz3E">the era of phone scamming the elderly</a>, but it would make it difficult for people like me to be developed with it.</p>
<p>However, for something like Private Cloud Compute, it's a perfect match. All the computer can do is known in advance and nothing else is allowed to happen. This makes it a lot easier to ensure that privacy guarantees are that: guarantees.</p>
<p>It's really frustrating that this foundation of trusted compute is being squandered. I wish I had an OS like Private Cloud Compute's as an option for building production systems.</p>
<h2>What we got</h2>
<p>We got the first batch of Apple Intelligence features at the end of October 2024. They've been advertised as if they are all out. With that we got Writing Tools to help you summarize and rewrite text; summaries for notifications, webpages, and emails; Clean Up in case you want to remove things from photos; the ability to search for photos based on their contents; Siri being able to search through the documentation for your device; and Math Notes to let you solve equations in the Notes app. Later we got Image Playground and email categorization. That mythical personal context is omnipresent in the advertising yet somehow, it's not launched yet.</p>
<p>I'm gonna break down my feelings about each of these features in their own little sections after having used them somewhat extensively.</p>
<h3>Math Notes</h3>
<p>I just want to start out by saying that out of all of these features the one that I love the most is Math Notes. Holy crap, Math Notes is incredible. It lets you type out things like this:</p>
<pre><code><span>Rent <span>=</span> <span>2300</span>
</span><span>FamilySize <span>=</span> <span>2</span>
</span><span>Rent / FamilySize <span>=</span>
</span></code></pre>
<p>And then the Notes app will just insert <code>1150</code> after that last equals sign. It's fantastic. I end up using this to do basic calculations with variables including terrible estimates for how much money I'm making vs spending. It's probably one of the best features ever made for any Apple device ever.</p>
<p>I have zero complaints about Math Notes.</p>
<h3>Writing Tools</h3>
<p>I'm not the target audience for Writing Tools. I've written a bunch of articles on my blog and frankly, I don't really need help from an AI model in order to write; I have a bigger problem not writing than I do writing. With that in mind, Writing Tools is basically useless for me. It's just a way to get a slightly worse version of what I already have the ability to make myself better.</p>
<p>Using Writing Tools makes me feel the worst side effects of existing AI tools and how they replace the creative process instead of adding to it. When I put text through Writing Tools I get an opaque answer. I don't get layers into the answer or steerability beyond "make this professional" or "turn this into a table", I just get a blob of text that can be painful to read.</p>
<p>For example, I asked Writing Tools to summarize that last paragraph and here's what I got:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/writing-tools-fail.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/writing-tools-fail.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/writing-tools-fail.webp"><img alt="a modal dialog over the previous paragraph in Apple Notes titled 'Writing Tools Unavailable: Certain capabilities are unavailable at this time. Try again later.'" loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/writing-tools-fail.jpg"></picture></a><figcaption>a modal dialog over the previous paragraph in Apple Notes titled 'Writing Tools Unavailable: Certain capabilities are unavailable at this time. Try again later.'</figcaption></figure>
<p>You can't make this up. I asked it to make it friendlier and I got this:</p>
<blockquote>
<p>Using Writing Tools has some serious drawbacks. It feels like it‚Äôs taking away the creative process instead of enhancing it. When I input text into Writing Tools, I get a generic response that lacks depth and customization options. It‚Äôs like getting a one-size-fits-all answer that‚Äôs hard to follow and doesn‚Äôt allow for much creativity.</p>
</blockquote>
<p>It can be useful for taking a bunch of ranting I do on stream and turning that into an outline that I can use for a starting point in writing, but it does a terrible job of doing the writing for me. I imagine that for other people that don't have extensive English experience that it'd be a lot more useful, but I don't know how useful it is for me.</p>
<h3>Notification, Message, and Email summaries</h3>
<p>This is the biggest feature that sounds like a good idea until you actually implement it. The core idea is that when you get a bunch of notifications from your apps, you have a stack of things that can be tedious to go through. A summary is easier to digest and gets the point across much easier.</p>
<p>This works great until it doesn't. Here's the summary of a scam text message I got as I was writing this post:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sms-scam-fail.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sms-scam-fail.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sms-scam-fail.webp"><img alt="A message summary: 'Package delivery delayed due to incomplete address information...'" loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sms-scam-fail.jpg"></picture></a><figcaption>A message summary: 'Package delivery delayed due to incomplete address information...'</figcaption></figure>
<p>This phrases a <em>literal scam message</em> in ways that make me think immediate action is required. You can see how this doesn't scale, right? It's gotten to the point where the news has reported on how notification summaries <a href="https://www.bbc.com/news/articles/cd0elzk24dno">made people think a suspect in custody killed themselves</a>.</p>
<p>Even more, if you have Apple Intelligence enabled for some of the other features but disable notification summaries because you find them worthless, you can get your notifications delayed up to <em>five seconds</em>. It's kind of depressing that telling your computer to do <em>less work</em> makes the result take longer than doing <em>more work</em>.</p>
<p>Additionally, none of the summarization features work on my iPhone and I can't be bothered to figure out why and fix it. I personally don't find them useful. I just leave them enabled on my MacBook so that notification delivery is not impacted.</p>
<div><p><img alt="Cadey is percussive-maintenance" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/percussive-maintenance/128"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>Even though it has decent "Apple polish", it just feels half-baked somehow.
It's almost like it's not done yet but they were made to just ship whatever
they had in order to meet some arbitrary deadline made up by someone that
doesn't understand the details. This feels like it's happening across the
industry though, especially as companies try to milk the money generator for
more money.</p></div></div>
<h3>Clean Up</h3>
<p>I don't like Clean Up from a philosophical standpoint. I'm a photographer. When I frame a shot and take it, I want the data coming off of the sensor to be the data that makes up the image. I want to avoid as much processing as possible and I want the photo to be a reflection of reality as it is, not reality as it should have been. Sure, sometimes I'll do some color correction or cropping in post, but that doesn't change the <em>content</em> of the image, only its presentation.</p>
<p>Clean Up is best explained by this famous photo editing example:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/stalin-photo.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/stalin-photo.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/stalin-photo.webp"><img alt="A picture of Joseph Stalin, former Prime Minister of the Soviet Union next to Nikolai Yezhov before and after being removed from Soviet history after being purged." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/stalin-photo.jpg"></picture></a><figcaption>A picture of Joseph Stalin, former Prime Minister of the Soviet Union next to Nikolai Yezhov before and after being removed from Soviet history after being purged.</figcaption></figure>
<p>This tool allows you to capture a moment in time as you wish it happened, not as it actually happened. I don't like this from a philosophical standpoint. I'd much rather capture things as they were. As such, I haven't used Clean Up and can't talk about it much more.</p>
<h3>Image Playground</h3>
<p>I have a lot of thoughts about Image Playground. I've used a lot of image generation models and I'm currently working on experiments with conveyance (images that convey feelings or moods that would take many words to explain) in generative AI. Here's one of my successful examples:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sakura-flower-field.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sakura-flower-field.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sakura-flower-field.webp"><img alt="A picture of a brown-haired anime woman smiling in a field of blooming pink flowers, heavy depth of field so only the woman and a couple of flowers are in focus. Made with Stable Diffusion 1.5 and ComfyUI." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/sakura-flower-field.jpg"></picture></a><figcaption>A picture of a brown-haired anime woman smiling in a field of blooming pink flowers, heavy depth of field so only the woman and a couple of flowers are in focus. Made with Stable Diffusion 1.5 and ComfyUI.</figcaption></figure>
<p>I made this using a stack of about 11 to 12 models in a complex diffusion flow using a Stable Diffusion 1.5 finetune from late 2022. Let's call this the upper bound of how good you can get outputs from techniques of the era. There's some glaring flaws (mostly involving the continuity of the fence, but that could be explained with fence construction methods).</p>
<p>In comparison, here's one of my Image Playground generations of the East Berlin TV tower at sunset:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/berlin-tv-tower.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/berlin-tv-tower.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/berlin-tv-tower.webp"><img alt="An AI-generated illustration of the East Berlin TV tower at sunset." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/berlin-tv-tower.jpg"></picture></a><figcaption>An AI-generated illustration of the East Berlin TV tower at sunset.</figcaption></figure>
<p>This is also pretty good, there's problems with how the sky is half mid-day and half sunset and the windows/decks have a lot of issues with many straight lines, but it'd be mostly passable at a casual glance. Especially on a phone screen. I'm able to see a lot more of the flaws due to my extensive experience with AI tools, but in a pinch you probably wouldn't blink too hard at this.</p>
<p>I hate to admit that this is heavily cherry-picked. Most of the time, you will get horrors beyond mortal comprehension like this:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/hoof-taco.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/hoof-taco.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/hoof-taco.webp"><img alt="An AI-generated illustration of a taco smoking beer at a party. The taco has hooves for feet and hands. It uses a placid corporate artstyle and communicates nothing." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/hoof-taco.jpg"></picture></a><figcaption>An AI-generated illustration of a taco smoking beer at a party. The taco has hooves for feet and hands. It uses a placid corporate artstyle and communicates nothing.</figcaption></figure>
<p>This is horrifying. I don't even know where to begin in talking about all of the things that are off or wrong with this image. I also don't think you would need special training or experience to understand what is wrong with this image.</p>
<p>Mind you, this both of those images were generated with plain text prompts. You can add people to these images. Using a photo of yourself is a great way to experience what dysmorphia feels like. Here's one of <a href="https://bsky.app/profile/quinnypig.com">Corey Quinn</a> doing his typical gremlin smile:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/oompa-loompa.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/oompa-loompa.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/oompa-loompa.webp"><img alt="An AI-generated illustration of a man smiling. The proportions are disturbing. The soulless eyes peer into you and make you contemplate where the effort into AI image generation has gone and what good for humanity could have been done with that money and effort. His pupils are square like his teeth." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/oompa-loompa.jpg"></picture></a><figcaption>An AI-generated illustration of a man smiling. The proportions are disturbing. The soulless eyes peer into you and make you contemplate where the effort into AI image generation has gone and what good for humanity could have been done with that money and effort. His pupils are square like his teeth.</figcaption></figure>
<p>I cannot believe that this is a shipped product from Apple. I genuinely am stunned. What the hell is going on over there?</p>
<p>This is from the company that refused to ship so many things that we'll never hear about. This is from the company that <em>defined</em> the idea of having a vision-based product. Of having a product vision so strong that they were willing to accuse people of <em>holding a device wrongly</em> rather than admit they messed up.</p>
<div><p><img alt="Cadey is coffee" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/coffee/128"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>I feel like Image Playground (and Genmoji, which isn't talked about here due
to the fact that it's difficult to extract emoji from chat messages without
losing quality) creates results that are just as soulless and empty as it is.
This is the complete opposite of the level of care and quality that I've come
to expect from Apple over the years. It's like they've been forced to just
ship something due to either investor pressure or not wanting to be behind on
the curve; and nobody at the product team was able to stop it from hitting the
market.</p></div></div>
<p>And now every company out there is going to copy this with open-weights models and make things that don't look like horrifying monsters. While you get the oompa-loompas of doom staring into your soul on iPhones, the rest of the industry is going to be able to make things like this:</p>
<figure><a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/flux-pro-berlin-tv-tower.jpg"><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/flux-pro-berlin-tv-tower.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/flux-pro-berlin-tv-tower.webp"><img alt="A cartoon illustration of the Berlin TV tower at sunset. The sky has many shades of gold and red as it fades to twilight." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/flux-pro-berlin-tv-tower.jpg"></picture></a><figcaption>A cartoon illustration of the Berlin TV tower at sunset. The sky has many shades of gold and red as it fades to twilight.</figcaption></figure>
<p>It's frustrating. It'd be better if there was an IntelligenceKit for developers to be creative with the models or something, but there isn't. It all just feels half-baked like they were forced to release it out of obligation to shareholders, not out of choice for meeting the product vision.</p>
<h2>Generative AI is not a product</h2>
<p>Back in September, I had a strange dream. If you know me well enough, you know that when I have a "strange dream", that usually means that something wild happened. In this dream, I had a conversation with Steve Jobs about product design, the philsophy of Apple enabling people to be creative, but the most salient point we discussed was this:</p>
<blockquote>
<p>The real way that technology can change lives is by acting as a bicycle for the mind, a way to take human's latent creativity and allow them to focus it and employ it into something that makes their lives better. Imagine picking up a guitar and creating a song by purely feeling out the notes and working it into a melody just from what feels "right". Based on what you've described, most generative AI is useless for that because it removes all the creative control when going from A to B.</p>
<p>If anything, the human cost seems like that it would outweigh any process gains from being able to draw a cat on the moon faster. Generative AI is completely useless as a product unto itself, but could be part of a larger product in some way. It should never be the selling point.</p>
</blockquote>
<p>-"Steve Jobs" in a dream, September 2024</p>
<p>Breaking this apart, what does being able to make a terrible illustration of <a href="https://cdn.xeiaso.net/file/christine-static/blog/2025/squandered-holy-grail/berlin-tv-tower.jpg">the Berlin TV Tower</a> in a second or two really net us in terms of enabling creativity? You get a single final output. You don't get the layers to edit things like the color grading of the sky. Sure it'd be useful for low-effort social media posts, but this is not a product. This is a tech demo, and not even a good one. It'd be amazing if this was released 3 years ago, but it is 2025, not 2022.</p>
<p>If generative AI is not a product, then what is it really useful for? I know how to use it in creative flows because I already have the training needed to be an artist. I know how to use it in research environments due to having years of experience throwing science at the wall to see what sticks. I understand these tools and what they are good and bad at (this is why all of my AI illustrations that I put effort into end up with an anime-inspired artstyle because recreating humans photorealistically gets you inhuman monsters 7 times out of 10).</p>
<p>I think that it's better to view generative AI as an implementation detail, not the critical identity of the product. One of the best ways to understand a product is to start taking things away. If you take color out of a word processor, you still have a word processor. If you take bold or italic formatting out of a word processor, you still have a word processor. If you take font selection out of a word processor, you still have a word processor.</p>
<p>If you take away the display output from a word processor, you have a typewriter instead of a word processor. Thus, the core of a word processor is being able to see on the screen what you would see on the page before you hit print.</p>
<p>The core of why ChatGPT works as a product isn't the AI. It's the experience of each word being typed one at a time by the AI and saving your conversations with the AI for later.</p>
<h3>Where should we use generative AI?</h3>
<p>In terms of where I think generative AI is actually useful, it's in places that are not as flashy or exciting. Think data analysis, <a href="https://www.simplypsychology.org/qualitative-data-coding.html">qualitative data coding</a>, data entry, reading data out of images, and things along that nature. I've been working with a fellow redditor on a study involving people's experiences of medtation and the difficult to describe sensations that come up. We want to use generative AI to try and categorize those sensations and see if we can get an effective result without as much drudgery involved as you'd get doing it by hand.</p>
<p>I'll have more news about this by June. It'll involve publishing a paper or two in actual journals.</p>
<h2>Conclusion</h2>
<p>I think that Apple Intelligence is a failure of a product from an implementation standpoint. This is frustrating because the foundation they are building on top of is nearly invincible. All data is processed on device as much as possible. Everything that can't be processed on your device is put into frontier-grade security practices to make sure it's as private and encrypted as possible.</p>
<p>The thing that sucks about it is that they made the holy grail of remotely attested trusted compute and then made the end result so much worse to use than manually making your own integrations with <a href="https://ollama.com/">Ollama</a> on the <em>same device</em>. Using Ollama lets you pick models that are so much better than what you get with Apple Intelligence. And it'd be just as private.</p>
<div><p><img alt="Cadey is coffee" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/coffee/128"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>I just can't help but imagine what it could have been. I know that the Apple
we have would never do that, but I just can't help but wonder. Apple spends
untold amounts of money trying to create things and they get beaten by a bunch
of people in caves with boxes of scraps and consumer GPUs.</p></div></div>
<div><p><img alt="Aoi is coffee" loading="lazy" src="https://cdn.xeiaso.net/sticker/aoi/coffee/128"></p><div><p>&lt;<a href="https://xeiaso.net/characters#aoi"><b>Aoi</b></a>&gt; </p><p>You know, maybe that's why the open-source community will always win here.
Apple has no real limits. The open-source community has to milk everything
they can get out of the hardware they have. Their withered hardware requires
them to use <a href="https://newsletter.bijanstephen.blog/lateral-thinking-with-withered-technology/">lateral
thinking</a>
to get what they want. And they'll pretty much always win because then they
can deploy their creations into production. With zero modifications.</p></div></div>
<p>Needless to say, they did not give us bicycles of the mind. They gave us marginal improvements that feel like tech demos. The potential was so infinite and it just all feels wasted.</p>
<p>Except for Math Notes. Holy crap. I love Math Notes so much. I wish other note-taking apps had it. It's easily the best feature they've ever come up with.</p>
<p>I have a lot of complicated and nuanced thoughts about all this, and probably still have another 5-10k words left in me. Wish me luck.</p>
<hr>
<p>I wrote this <a href="https://www.twitch.tv/videos/2343241685">live on Twitch</a>, catch me on Fridays at noon EST to see more tech streaming goodness!</p>

    <hr>

    

    

    <p>Facts and circumstances may have changed since publication. Please contact me before jumping to conclusions if something seems wrong or unclear.</p>

    <p>Tags: </p>
</article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Printf debugging is ok (115 pts)]]></title>
            <link>https://www.polymonster.co.uk/blog/printf-debugging-is-ok</link>
            <guid>42607087</guid>
            <pubDate>Mon, 06 Jan 2025 02:42:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.polymonster.co.uk/blog/printf-debugging-is-ok">https://www.polymonster.co.uk/blog/printf-debugging-is-ok</a>, See on <a href="https://news.ycombinator.com/item?id=42607087">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page" data-page-title="printf debugging is OK ‚Äì Alex Dixon" data-image="">

			

<div>

		<p>I stopped going on Twitter a while ago because it has the tendency to evoke rage, as it is designed to do. But every now and then I check back in - it can be useful sometimes for keeping up with graphics research, gamedev news and some people do post nice things, like sharing projects they are working on, so there is something to pull me back from time to time.</p>

<p>After checking the other day I saw this debate going around about not using an IDE or debugger, just using ‚Äònotepad‚Äô to write code. I looked in the comments, people arguing about who was right and all the usual toxic vibes, and it reminded me of some earlier occasions of people discussing the same topic.</p>

<p>It feels like the same old debate has been going on for a long time now, it‚Äôs packaged differently each time, but I don‚Äôt really know why people get so wound up about things. The main arguments are ‚Äúif you need to use a debugger you‚Äôre an idiot and you don‚Äôt understand the code you are writing‚Äù (that‚Äôs not an actual quote but there was a similar take along those lines). Then there is ‚ÄúIf you can‚Äôt use a debugger you‚Äôre an idiot‚Äù. The hating on the ‚Äòprintf‚Äô crew is omnipresent.</p>

<p>At the risk of poking a hornet‚Äôs nest, I just wanted to share some thoughts and ideas on this subject in a balanced way, because I don‚Äôt think there needs to be an ultimate solution here. We need to debug code and there are tools out there to help us, some are more useful than others in certain situations, but at the end of the day do whatever you need to do to fix those bugs.</p>

<h2 id="debuggers">Debuggers</h2>

<p>I use a debugger regularly, I will launch most work in C++ from Visual Studio or Xcode and preferably run in a debug build. I know for some people this is often a terrible UX because of the performance of debug builds, so a prerequisite here is fast debug builds. This is hard to retrofit but having a usable debug build is useful. Once running I can use the debugger break and step if I need to, and if I encounter a crash then there is a nice call stack I can look through in more detail.</p>

<p>I have noticed that it is extremely common for graduate and junior software engineers to have little to no debugging knowledge or experience. It‚Äôs not something that seems like it is taught at university and I have also been told stories of teachers imposing their usage of VIM and esoteric debugging strategies upon the students. For the record I am not a VIM user (another topic that ends up in polarising debates). I find using a mouse and 2 finger typing works for me.</p>

<p>The moment when you show someone how to use a hardware breakpoint or a watchpoint and find a bug immediately is like seeing the lightbulb appear on top of their head, a whole world of possibility opening in front of them, or the dismay of the wasted hours trying to catch some dodgy logic through layers and layers of object oriented spaghetti.</p>

<p>Some of those argue about using only ‚Äònotepad‚Äô and no debugger because they can dry run their code on paper and they ‚Äúdon‚Äôt write bugs‚Äù, but I find it difficult to understand how they work within a larger team project or codebase . A lot of bugs and issues I have ever had to fix were not in code I wrote myself, they were in legacy systems, colleague‚Äôs code, or in open source code (and some hard as nails bugs to track too!) that had been just lifted into a project. If you believe in the impending AI coding apocalypse then human engineers may merely be around to debug and fix issues with AI generated code. So yeah, being able to write perfect code yourself is one thing, but using a debugger to debug existing code in a large complex project shouldn‚Äôt be a thing of shame and we might need all the tools we can to help.</p>

<p>Along with debuggers we get all sorts of other tools, which also should be used as and when we need them. Address sanitizer can catch memory issues easily, where in a bygone era we would have this 1 in 1000 crash somewhere reading outside of an array bounds, we can enable ASan and catch this every time without the undefined behaviour lottery. Same for undefined behaviour sanitizer, now we can catch UB when it‚Äôs benign and not only when a noticeable side effect occurs.</p>

<p>I don‚Äôt know if these notepad-only coders are taking all of those tools off the table as well, but when you have something like ASan that can catch an issue for you I just don‚Äôt really know why you wouldn‚Äôt use it. I have seen a lot of comments that seem to suggest the debugger slows them down, but in this case I certainly think the debugger speeds you up.</p>

<p>So if you‚Äôre reading this and you don‚Äôt know about these tools I would say take a look and see, they can be useful and might be able to save you a lot of time. There are tons of things you can do and it‚Äôs hard to cover it all here. I learned a lot from working with other people and side by side debugging difficult problems. I think there should be more resources to teach these skills instead of it being handed down information.</p>

<h2 id="printf-debugging-is-ok">Printf debugging is OK</h2>

<p>So for the ‚Äòprintf‚Äô haters I would also say that whilst using a debugger most of the time, sometimes I revert to ‚Äòprintf‚Äô debugging. There are some situations where there is no other choice - in the past I have had to debug release builds where we were unable to reproduce the bug in debug. Even pulling in debug modules for the engine (for on screen debug info) changed the executable such that we couldn‚Äôt reproduce the issue. The last thing was to put a few print statements in using the raw ‚Äòprintf‚Äô and removing them and adding more as we narrowed down the issue and eventually extracted enough information to fix the problem.</p>

<p>I have also had the need to use ‚Äòprintf‚Äô when debugging certain kinds of behaviours in an application. In the case of something like touch event tracking for mobile devices, if you try to debug an issue with breakpoints you interrupt the hardware and it makes it difficult to reproduce issues in the same way they appear naturally. So here printing the state of touch down events, touch up events, and being able to see the logical flow can identify a problem. There are many more scenarios that benefit from this type of debugging. Just throw the prints in and make sure to remove them after so no one knew you were ever there, like a ninja.</p>



<p>Custom UI based debugging tools can go one step further than printf debugging, providing some similar traits but also allowing more flexibility and controllability, I assume the notepad wielders who don‚Äôt use a regular debugger must have some such custom tools and things to help them track down issues. I am a big fan of embedded debugging and profiling tools within an application. You know stuff like performance counters that I can just pop-up in a UI or tweakable values to help to refine behaviours or visual appearance. I find that since the explosion of ImGui the level of integrated ad-hoc debugging tools and info has exponentially increased.</p>

<p>But with these kinds of custom tools, I personally wouldn‚Äôt try and re-invent the wheel. I would aim to make stuff that complements the existing tools I can pull off the shelf. So for example I like to have a quick, at a glance profiler for all my key performance hotspots that I can check whenever I notice something. But for more in-depth profiling I would use a CPU or GPU profiler to dig deeper.</p>

<h2 id="just-doing-what-needs-to-be-done">Just doing what needs to be done</h2>

<p>At the end of the day, finding bugs is just something that we need to get done, whatever helps you find and fix the issue doesn‚Äôt bother me as long as we get the job done. On a closing note, I noticed some code in a pull request left in by accident by another person:</p>

<div><pre><code><span>if</span><span>(</span><span>some_condition</span><span>)</span> <span>{</span>
    <span>int</span> <span>x</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>I found this interesting. I do the same thing except I usually name my variable ‚Äòa‚Äô. This is to insert some code where a breakpoint can be put on the ‚Äòint x‚Äô line and then it kind of acts like a conditional breakpoint when some_condition is true. You could use a conditional breakpoint within the debugger, but they can be slow and for me historically unreliable, but this little snippet gives you your own conditional breakpoint that works without fail.</p>

<p>Just make sure to remove the code before the PR next time!</p>


	</div>

		</div></div>]]></description>
        </item>
    </channel>
</rss>