<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 11 Nov 2023 15:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Fourteen Years of Go (156 pts)]]></title>
            <link>https://go.dev/blog/14years</link>
            <guid>38229001</guid>
            <pubDate>Sat, 11 Nov 2023 10:20:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go.dev/blog/14years">https://go.dev/blog/14years</a>, See on <a href="https://news.ycombinator.com/item?id=38229001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-slug="/blog/14years">
    
    <h2><a href="https://go.dev/blog/">The Go Blog</a></h2>
    

    
      
      
      
      <p><img src="https://go.dev/doc/gopher/gopherdrink.png" height="219" width="223"></p><p>Today we celebrate the fourteenth birthday of the Go open source release!
Go has had a great year, with two feature-filled releases and other important milestones.</p>
<p>We released <a href="https://go.dev/blog/go1.20">Go 1.20 in February</a>
and <a href="https://go.dev/blog/go1.21">Go 1.21 in August</a>,
focusing more on implementation improvements
than new language changes.</p>
<p>Profile-guided optimization (PGO),
<a href="https://go.dev/blog/pgo-preview">previewed in Go 1.20</a>
and
<a href="https://go.dev/blog/pgo">released in Go 1.21</a>,
allows the Go compiler to read a profile of your program
and then spend more time optimizing the parts
of your program that run most often.
In Go 1.21, workloads typically get between
2% and 7% CPU usage improvements from enabling PGO.
See “<a href="https://go.dev/blog/pgo">Profile-guided optimization in Go 1.21</a>” for an overview
and the <a href="https://go.dev/doc/pgo" rel="noreferrer" target="_blank">profile-guided optimization user guide</a>
for complete documentation.</p>
<p>Go has provided support for gathering coverage profiles during <code>go test</code>
<a href="https://go.dev/blog/cover">since Go 1.2</a>.
Go 1.20 added support for gathering coverage profiles in binaries
built by <code>go build</code>,
allowing you to gather coverage during larger integration tests as well.
See “<a href="https://go.dev/blog/integration-test-coverage">Code coverage for Go integration tests</a>” for details.</p>
<p>Compatibility has been an important part of Go since
“<a href="https://go.dev/doc/go1compat">Go 1 and the Future of Go Programs</a>”.
Go 1.21 improved compatibility further
by expanding the conventions for use of GODEBUG
in situations where we need to make a change,
such as an important bug fix,
that must be permitted but may still break existing programs.
See the blog post
“<a href="https://go.dev/blog/compat">Backward Compatibility, Go 1.21, and Go 2</a>”
for an overview and
the documentation
“<a href="https://go.dev/doc/godebug">Go, Backwards Compatibility, and GODEBUG</a>” for details.</p>
<p>Go 1.21 also shipped support for built-in toolchain management,
allowing you to change which version of the
Go toolchain you use in a specific module
as easily as you change the versions of other dependencies.
See the blog post
“<a href="https://go.dev/blog/toolchain">Forward Compatibility and Toolchain Management in Go 1.21</a>”
for an overview and the documentation
“<a href="https://go.dev/doc/toolchain">Go Toolchains</a>”
for details.</p>
<p>Another important tooling achievement was the
integration of on-disk indexes into
gopls, the Go LSP server.
This cut gopls’s startup latency and memory usage by 3-5X
in typical use cases.
“<a href="https://go.dev/blog/gopls-scalability">Scaling gopls for the growing Go ecosystem</a>”
explains the technical details.
You can make sure you’re running the latest gopls by running:</p>
<pre><code>go install golang.org/x/tools/gopls@latest
</code></pre>
<p>Go 1.21 introduced new
<a href="https://go.dev/pkg/cmp/">cmp</a>,
<a href="https://go.dev/pkg/maps/">maps</a>,
and
<a href="https://go.dev/pkg/slices/">slices</a>
packages — Go’s first generic standard libraries —
as well as expanding the set of comparable types.
For details about that, see the blog post
“<a href="https://go.dev/blog/comparable">All your comparable types</a>”.</p>
<p>Overall, we continue to refine generics
and to write talks and blog posts explaining
important details.
Two notable posts this year were
“<a href="https://go.dev/blog/deconstructing-type-parameters">Deconstructing Type Parameters</a>”,
and
“<a href="https://go.dev/blog/type-inference">Everything You Always Wanted to Know About Type Inference – And a Little Bit More</a>”.</p>
<p>Another important new package in Go 1.21 is
<a href="https://go.dev/pkg/log/slog/">log/slog</a>,
which adds an official API for
structured logging to the standard library.
See “<a href="https://go.dev/blog/slog">Structured logging with slog</a>” for an overview.</p>
<p>For the WebAssembly (Wasm) port, Go 1.21 shipped support
for running on WebAssembly System Interface (WASI) preview 1.
WASI preview 1 is a new “operating system” interface for Wasm
that is supported by most server-side Wasm environments.
See “<a href="https://go.dev/blog/wasi">WASI support in Go</a>” for a walkthrough.</p>
<p>On the security side, we are continuing to make sure
Go leads the way in helping developers understand their
dependencies and vulnerabilities,
with <a href="https://go.dev/blog/govulncheck">Govulncheck 1.0 launching in July</a>.
If you use VS Code, you can run govulncheck directly in your
editor using the Go extension:
see <a href="https://go.dev/doc/tutorial/govulncheck-ide" rel="noreferrer" target="_blank">this tutorial</a> to get started.
And if you use GitHub, you can run govulncheck as part of
your CI/CD, with the
<a href="https://github.com/marketplace/actions/golang-govulncheck-action" rel="noreferrer" target="_blank">GitHub Action for govulncheck</a>.
For more about checking your dependencies for vulnerability problems,
see this year’s Google I/O talk,
“<a href="https://www.youtube.com/watch?v=HSt6FhsPT8c&amp;ab_channel=TheGoProgrammingLanguage" rel="noreferrer" target="_blank">Build more secure apps with Go and Google</a>”.)</p>
<p>Another important security milestone was
Go 1.21’s highly reproducible toolchain builds.
See “<a href="https://go.dev/blog/rebuild">Perfectly Reproducible, Verified Go Toolchains</a>” for details,
including a demonstration of reproducing an Ubuntu Linux Go toolchain
on a Mac without using any Linux tools at all.</p>
<p>It has been a busy year!</p>
<p>In Go’s 15th year, we’ll keep working to make Go the best environment
for software engineering at scale.
One change we’re particularly excited about is
redefining for loop <code>:=</code> semantics to remove the
potential for accidental aliasing bugs.
See “<a href="https://go.dev/blog/loopvar-preview">Fixing For Loops in Go 1.22</a>”
for details,
including instructions for previewing this change in Go 1.21.</p>
<h2 id="thank-you">Thank You!</h2>
<p>The Go project has always been far more than just us on the Go team at Google.
Thank you to all our contributors and everyone in the Go community for
making Go what it is today.
We wish you all the best in the year ahead.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: DataSheetGrid, an Airtable-like React component (126 pts)]]></title>
            <link>https://react-datasheet-grid.netlify.app/</link>
            <guid>38228788</guid>
            <pubDate>Sat, 11 Nov 2023 09:36:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://react-datasheet-grid.netlify.app/">https://react-datasheet-grid.netlify.app/</a>, See on <a href="https://news.ycombinator.com/item?id=38228788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="docusaurus_skipToContent_fallback"><header><div><p>A<span><span>|</span></span> <!-- -->React component to create beautiful spreadsheets</p><div><div><div><div><p>Active</p></div></div><div><p>1</p></div><div><p>2</p></div></div><div><!-- --><p>rows</p></div></div><div><p><a href="https://react-datasheet-grid.netlify.app/docs/getting-started">Getting started</a></p></div></div></header><section><figure><a href="https://tggl.io/"><svg style="vertical-align:bottom" width="100%" viewBox="0 0 68 42" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M15.76 30.5C14.2667 30.78 12.8 30.9 11.36 30.86C9.93336 30.8333 8.65336 30.5867 7.52002 30.12C6.40002 29.64 5.54669 28.8733 4.96002 27.82C4.42669 26.8333 4.14669 25.8333 4.12002 24.82C4.09336 23.7933 4.08002 22.6333 4.08002 21.34V2.89999H9.52002V21.02C9.52002 21.86 9.52669 22.62 9.54002 23.3C9.56669 23.9667 9.70669 24.5 9.96002 24.9C10.44 25.66 11.2067 26.0733 12.26 26.14C13.3134 26.2067 14.48 26.1533 15.76 25.98V30.5ZM0.400024 13.1V8.9H15.76V13.1H0.400024Z" fill="currentColor"></path><path d="M62.2656 30.5V1.10001H67.7056V30.5H62.2656Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M47.8847 40.7C46.658 40.7 45.4913 40.5 44.3847 40.1C43.278 39.7133 42.2847 39.1667 41.4047 38.46C40.538 37.7667 39.8313 36.9533 39.2847 36.02L44.3247 33.58C44.6713 34.22 45.1647 34.7067 45.8047 35.04C46.458 35.3733 47.1647 35.54 47.9247 35.54C48.738 35.54 49.5047 35.4 50.2247 35.12C50.9447 34.8533 51.518 34.4467 51.9447 33.9C52.3847 33.3667 52.5913 32.7 52.5647 31.9V29.5241C50.838 30.581 48.8075 31.1902 46.6348 31.1902C43.3785 31.1902 40.4418 29.8219 38.3683 27.6289V31.98C38.3683 32.5133 38.3416 33.0133 38.2883 33.48C38.2483 33.96 38.1683 34.4333 38.0483 34.9C37.7016 36.22 37.0549 37.3067 36.1083 38.16C35.1749 39.0133 34.0283 39.6467 32.6683 40.06C31.3083 40.4867 29.8349 40.7 28.2483 40.7C27.0216 40.7 25.8549 40.5 24.7483 40.1C23.6416 39.7133 22.6483 39.1667 21.7683 38.46C20.9016 37.7667 20.1949 36.9533 19.6483 36.02L24.6883 33.58C25.0349 34.22 25.5283 34.7067 26.1683 35.04C26.8216 35.3733 27.5283 35.54 28.2883 35.54C29.1016 35.54 29.8683 35.4 30.5883 35.12C31.3083 34.8533 31.8816 34.4467 32.3083 33.9C32.7483 33.3667 32.9549 32.7 32.9283 31.9V30.576C31.7693 30.9741 30.5257 31.1902 29.2316 31.1902C22.9495 31.1902 17.8568 26.0975 17.8568 19.8154C17.8568 13.5333 22.9495 8.44058 29.2316 8.44058C30.7826 8.44058 32.261 8.75099 33.6083 9.31307C35.2936 10.0162 36.7736 11.1132 37.9332 12.4891C38.0736 12.3225 38.2187 12.16 38.3683 12.0018C40.4418 9.80886 43.3785 8.44058 46.6348 8.44058C49.0998 8.44058 51.3817 9.22471 53.2447 10.5571C56.0443 12.5595 57.8977 15.8001 58.0047 19.4787C58.0079 19.5905 58.0096 19.7028 58.0096 19.8154C58.0096 19.928 58.0079 20.0402 58.0047 20.152V31.98C58.0047 32.5133 57.978 33.0133 57.9247 33.48C57.8847 33.96 57.8047 34.4333 57.6847 34.9C57.338 36.22 56.6913 37.3067 55.7447 38.16C54.8113 39.0133 53.6647 39.6467 52.3047 40.06C50.9447 40.4867 49.4713 40.7 47.8847 40.7ZM29.217 12.9608C25.3703 12.9608 22.2519 16.0792 22.2519 19.926C22.2519 23.7727 25.3703 26.8911 29.217 26.8911H46.4614C49.7618 26.8911 52.526 24.5957 53.2447 21.5142C53.3637 21.0041 53.4266 20.4724 53.4266 19.926C53.4266 19.3796 53.3637 18.8479 53.2447 18.3377C52.526 15.2562 49.7618 12.9608 46.4614 12.9608H38.3683H38.3099H37.5565H29.217Z" fill="currentColor"></path></svg></a></figure></section><hr><div><figure><div><pre tabindex="0"><code><span><span>const</span><span> </span><span>[</span><span>rows</span><span>,</span><span> setRows</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>[</span><span>]</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span></span><span>return</span><span> </span><span>(</span><span></span><br></span><span><span>  </span><span>&lt;</span><span>DataSheetGrid</span><span></span><br></span><span><span>    </span><span>value</span><span>=</span><span>{</span><span>rows</span><span>}</span><span></span><br></span><span><span>    </span><span>onChange</span><span>=</span><span>{</span><span>setRows</span><span>}</span><span></span><br></span><span><span>    </span><span>columns</span><span>=</span><span>{</span><span>columns</span><span>}</span><span></span><br></span><span><span>  </span><span>/&gt;</span><span></span><br></span><span><span></span><span>)</span><br></span></code></pre></div></figure></div><div><figure><div><div><div><p>Active</p></div></div><div><p>1</p></div><div><p>2</p></div><div><p>3</p></div><div><p>4</p></div><div><p>5</p></div><div><p>6</p></div></div></figure></div><div><figure><img src="https://react-datasheet-grid.netlify.app/img/custom-widgets.png"></figure></div><section><h2>Feature rich</h2><div><figure><img src="https://react-datasheet-grid.netlify.app/img/logos.png"></figure></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gnome Receives €1M from German Government (241 pts)]]></title>
            <link>https://www.omgubuntu.co.uk/2023/11/gnome-sovereign-tech-fund</link>
            <guid>38228649</guid>
            <pubDate>Sat, 11 Nov 2023 09:02:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.omgubuntu.co.uk/2023/11/gnome-sovereign-tech-fund">https://www.omgubuntu.co.uk/2023/11/gnome-sovereign-tech-fund</a>, See on <a href="https://news.ycombinator.com/item?id=38228649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                <article id="post-273677">
                                                            <div>
                        
<p><strong>Heard of the <a href="https://sovereigntechfund.de/en/" target="_blank" rel="noreferrer noopener">Sovereign Tech Fund</a>? I hadn’t, but the GNOME project has bagged itself a whopping €1 million investment from them.</strong></p>



<p><a href="https://foundation.gnome.org/2023/11/09/gnome-recognized-as-public-interest-infrastructure/">GNOME plans</a> to use the cash to <em>“modernize the platform, improve tooling and accessibility, and support features that are in the public interest”</em>, adding that the following projects and initiatives will benefit directly during 2024: </p>



<ul>
<li><strong>Improve the current state of accessibility</strong></li>



<li><strong>Design and prototype a new accessibility stack</strong></li>



<li><strong>Encrypt user home directories individually</strong></li>



<li><strong>Modernize secrets storage</strong></li>



<li><strong>Increase the range and quality of hardware support</strong></li>



<li><strong>Invest in Quality Assurance and Developer Experience</strong></li>



<li><strong>Expand and broaden freedesktop APIs</strong></li>



<li><strong>Consolidate and improve platform component</strong></li>
</ul>



<p>Whether you’ve been using Linux for a fresh minute or a veritable eon you’ll know GNOME is a core pillar in the FOSS movement.</p>



<p>GNOME is the default desktop environment in the most popular Linux distributions,&nbsp;its apps are used by millions of people worldwide,&nbsp;and GNOME-backed technologies underpin experiences across a dizzying array of devices, platforms, and industries.  </p>



<p>With the Sovereign Tech Fund’s aim of supporting the <em>“…development, improvement and maintenance of open digital infrastructure”</em>, its synergies with the GNOME project are clear.</p>






<div>
<figure><a href="https://149366088.v2.pressablecdn.com/wp-content/uploads/2023/11/STF_mission_en.webp"><img decoding="async" width="800" height="419" src="https://149366088.v2.pressablecdn.com/wp-content/uploads/2023/11/STF_mission_en.webp" alt="Sovereign tech fund mission statement" srcset="https://149366088.v2.pressablecdn.com/wp-content/uploads/2023/11/STF_mission_en.webp 800w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2023/11/STF_mission_en-300x157.webp 300w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2023/11/STF_mission_en-768x402.webp 768w " sizes="(max-width: 800px) 100vw, 800px"></a><figcaption>Image: sovereign tech fund</figcaption></figure></div>


<p>The Sovereign Tech Fund is a German government-funded initiative run by Adriana Groh and Fiona Krakenbürg,&nbsp;who have ‘many years of experience in promoting open-source technologies’ at national and international levels. </p>



<p>On its website, the Fund notes: <em>“…the open source ecosystem, while incredibly successful, is also increasingly fragile. Many more people are using the software than contributing to it. It is time to invest in digital commons, volunteer communities and [open source] to build the digital world we want to see.”</em></p>



<p>Previous recipients of investment from the fund include curl, Fortran, WireGuard, OpenSSH, the Yocto Project, and a collaboration with OpenJS Foundation to ‘<a href="https://sovereigntechfund.de/en/projects/verbesserung-der-infrastruktur-und-sicherheit-des-javascript-okosystems/" target="_blank" rel="noreferrer noopener">improve Javascript Ecosystem Infrastructure and Security</a>‘.</p>



<p>So while I might not have heard of it, I’m glad I have. The Sovereign Tech Fund supports open-source infrastructure in the most critical way: with money. </p>



<h3>Funding Our Futures</h3>



<p>This is a major win for the GNOME project, for open-source, and for all of us who use and rely on the technologies it oversees. </p>



<p>With this investment, GNOME will be able to further focus on the things it does well, develop new features, and make it easier for people to contribute to the project. </p>



<p>Great stuff!</p>
                                                                                                
                                                                    </div>
                </article>
                                
                
                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Suits ignored IT's warnings, so the tech team went for the neck (195 pts)]]></title>
            <link>https://www.theregister.com/2023/11/10/on_call/</link>
            <guid>38228592</guid>
            <pubDate>Sat, 11 Nov 2023 08:48:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/10/on_call/">https://www.theregister.com/2023/11/10/on_call/</a>, See on <a href="https://news.ycombinator.com/item?id=38228592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>On Call</span> Friday is here, and perhaps your temper is a little frayed. Which is why <em>The Register</em> always opens the last day of the working week with a fresh installment of On Call, our reader-contributed tales of exciting incidents on the front lines of tech support.</p>
<p>This week's tale comes from a reader we'll Regomize as "Bruce" because his story concerns his time working for an Australian bank's internet infrastructure team.</p>
<p>Bruce joined when internet banking was in its infancy, so his team was growing fast. So was their workload.</p>

    

<p>"We controlled/owned/looked after everything from ISDN link to the cable that was connected to the network team's internal switch," Bruce explained.</p>

        


        

<p>But Bruce and his colleagues still had time for planning. And one day he was assessing current user numbers vs demand vs link capacity, then the trends for future numbers, and realized it would not be long before that ISDN link was more than half saturated.</p>
<p>With internet banking taking off, the risks were obvious. So Bruce and his mates put together a position paper explaining why ordering another ISDN line was a good idea and gave it to the CIO for approval.</p>

        

<p>This was vastly sensible – in those days ordering an internet link could take months, so Bruce knew that getting this order in ASAP was essential.</p>
<p>The CIO forwarded the request to the bank's Executive Committee, which promptly rejected it because it was clearly wasteful to buy an extra link when the current one wasn't even half-used!</p>
<p>Bruce and his colleagues were scolded for their wasteful ways.</p>

        

<p>Once usage ticked past 50 percent, the IT team again made a pitch for an ISDN order. And were again rebuffed – with instructions not to ask again until utilization was nudging 100 percent.</p>
<p>Bruce knew what would happen at that point: the connection would max out, user experience would become dire, and IT would be blamed for the bank's failed entry into the world of internet banking.</p>
<p>He also imagined being dragged out while on call to fix the inevitable network errors. And then being reamed for the extra cost of having the ISDN link installed as a rush job.</p>
<ul>

<li><a href="https://www.theregister.com/2023/10/27/on_call/">Ask a builder to fix a server and out come the vastly inappropriate power tools</a></li>

<li><a href="https://www.theregister.com/2023/10/20/on_call/">Making the problem go away is not the same thing as fixing it</a></li>

<li><a href="https://www.theregister.com/2023/10/13/on_call/">Workload written by student made millions, ran on unsupported hardware, with zero maintenance</a></li>

<li><a href="https://www.theregister.com/2023/10/06/on_call/">Police ignored the laws of datacenter climate control</a></li>
</ul>
<p>The IT team hatched a cunning plan to make this the executives' problem.</p>
<p>"The suits and their associated hangers-on all resided on one floor of Head Office with their own subnet of IPs," Bruce explained. That network topography made it a simple task to throttle their connection.</p>
<p>"The first week, we throttled them down ten percent. Each successive week we withdrew another ten percent," Bruce confessed.</p>
<p>After a month of these shenanigans, the IT team again requested the additional ISDN line.</p>
<p>It was approved – along with the extra payment for expedited installation, and an explanation that if the suits could understand the frustration of slow connections, customers would also chafe.</p>
<p>Once the new line was connected, the IT team removed the throttle, "and left the suits to congratulate themselves on fixing the 'internet problem'."</p>
<p>Have you used the powers of IT to fool the non-technical? If so, <a target="_blank" href="mailto:oncall@theregister.com">click here to send us an email</a> and we'll share your secret to brighten up a future Friday. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[.NET 8 Standalone 50% Smaller On Linux (130 pts)]]></title>
            <link>https://learn.microsoft.com/en-us/dotnet/core/whats-new/dotnet-8</link>
            <guid>38228265</guid>
            <pubDate>Sat, 11 Nov 2023 07:25:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://learn.microsoft.com/en-us/dotnet/core/whats-new/dotnet-8">https://learn.microsoft.com/en-us/dotnet/core/whats-new/dotnet-8</a>, See on <a href="https://news.ycombinator.com/item?id=38228265">Hacker News</a></p>
<div id="readability-page-1" class="page">
	<div>
		<a href="#main" tabindex="1">Skip to main content</a>

		

		<div id="unsupported-browser" hidden="">
				<p>This browser is no longer supported.</p>
				<p>Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.</p>
				
			</div>
		<!-- liquid-tag banners global -->

		<!-- site header -->
		

		


			

		
	</div>

	<div data-bi-name="body">


					<div id="main-column">

						<main id="main" role="main" data-bi-name="content" lang="en-us" dir="ltr">
							<!-- article-header -->
							
							<!-- end article-header -->


							

							<!-- end mobile-contents button  -->

							<div>


								<h2 id="whats-new-in-net-8">What's new in .NET 8</h2>


									<div>
											<ul data-bi-name="page info" lang="en-us" dir="ltr">
													<li>
Article													</li>

													<li>
														<time data-article-date="" aria-label="Article review date" datetime="2023-10-05T08:00:00Z" data-article-date-source="calculated">10/05/2023</time>
													</li>
														<li>
															
														</li>
											</ul>
										</div>

									

										<nav id="center-doc-outline" data-bi-name="intopic toc" role="navigation" aria-label="In this article">
											<h2 id="ms--in-this-article">In this article</h2>
										</nav>

								<!-- <content> -->
									<p>.NET 8 is the successor to <a href="https://learn.microsoft.com/en-us/dotnet/core/whats-new/dotnet-7" data-linktype="relative-path">.NET 7</a>. It will be <a href="https://dotnet.microsoft.com/platform/support/policy/dotnet-core" data-linktype="external">supported for three years</a> as a long-term support (LTS) release. You can <a href="https://dotnet.microsoft.com/download/dotnet" data-linktype="external">download .NET 8 here</a>.</p>
<p>This article has been updated for .NET 8 release candidate (RC) 2.</p>
<div>
<p>Important</p>
<ul>
<li>This information relates to a pre-release product that may be substantially modified before it's commercially released. Microsoft makes no warranties, express or implied, with respect to the information provided here.</li>
<li>Much of the other .NET documentation on <a href="https://learn.microsoft.com/en-us/dotnet" data-linktype="absolute-path">https://learn.microsoft.com/dotnet</a> has not yet been updated for .NET 8.</li>
</ul>
</div>
<h2 id="aspnet-core">ASP.NET Core</h2>
<p>For information about what's new in ASP.NET Core, see <a href="https://learn.microsoft.com/en-us/aspnet/core/release-notes/aspnetcore-8.0" data-linktype="absolute-path">What's new in ASP.NET Core 8.0</a>.</p>
<h2 id="core-net-libraries">Core .NET libraries</h2>
<p>This section contains the following subtopics:</p>
<ul>
<li><a href="#serialization" data-linktype="self-bookmark">Serialization</a></li>
<li><a href="#time-abstraction" data-linktype="self-bookmark">Time abstraction</a></li>
<li><a href="#utf8-improvements" data-linktype="self-bookmark">UTF8 improvements</a></li>
<li><a href="#methods-for-working-with-randomness" data-linktype="self-bookmark">Methods for working with randomness</a></li>
<li><a href="#performance-focused-types" data-linktype="self-bookmark">Performance-focused types</a></li>
<li><a href="#systemnumerics-and-systemruntimeintrinsics" data-linktype="self-bookmark">System.Numerics and System.Runtime.Intrinsics</a></li>
<li><a href="#data-validation" data-linktype="self-bookmark">Data validation</a></li>
<li><a href="#metrics" data-linktype="self-bookmark">Metrics</a></li>
<li><a href="#cryptography" data-linktype="self-bookmark">Cryptography</a></li>
<li><a href="#networking" data-linktype="self-bookmark">Networking</a></li>
<li><a href="#stream-based-zipfile-methods" data-linktype="self-bookmark">Stream-based ZipFile methods</a></li>
</ul>
<h3 id="serialization">Serialization</h3>
<p>Many improvements have been made to <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json" data-linktype="absolute-path">System.Text.Json</a> serialization and deserialization functionality in .NET 8. For example, you can <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/missing-members" data-linktype="relative-path">customize handling of members that aren't in the JSON payload</a>.</p>
<p>The following sections describe other serialization improvements:</p>
<ul>
<li><a href="#built-in-support-for-additional-types" data-linktype="self-bookmark">Built-in support for additional types</a></li>
<li><a href="#source-generator" data-linktype="self-bookmark">Source generator</a></li>
<li><a href="#interface-hierarchies" data-linktype="self-bookmark">Interface hierarchies</a></li>
<li><a href="#naming-policies" data-linktype="self-bookmark">Naming policies</a></li>
<li><a href="#read-only-properties" data-linktype="self-bookmark">Read-only properties</a></li>
<li><a href="#disable-reflection-based-default" data-linktype="self-bookmark">Disable reflection-based default</a></li>
<li><a href="#new-jsonnode-api-methods" data-linktype="self-bookmark">New JsonNode API methods</a></li>
<li><a href="#non-public-members" data-linktype="self-bookmark">Non-public members</a></li>
<li><a href="#streaming-deserialization-apis" data-linktype="self-bookmark">Streaming deserialization APIs</a></li>
<li><a href="#withaddedmodifier-extension-method" data-linktype="self-bookmark">WithAddedModifier extension method</a></li>
<li><a href="#new-jsoncontentcreate-overloads" data-linktype="self-bookmark">New JsonContent.Create overloads</a></li>
<li><a href="#freeze-a-jsonserializeroptions-instance" data-linktype="self-bookmark">Freeze a JsonSerializerOptions instance</a></li>
</ul>
<p>For more information about JSON serialization in general, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/overview" data-linktype="relative-path">JSON serialization and deserialization in .NET</a>.</p>
<h4 id="built-in-support-for-additional-types">Built-in support for additional types</h4>
<p>The serializer has built-in support for the following additional types.</p>
<ul>
<li><p><a href="https://learn.microsoft.com/en-us/dotnet/api/system.half" data-linktype="absolute-path">Half</a>, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.int128" data-linktype="absolute-path">Int128</a>, and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.uint128" data-linktype="absolute-path">UInt128</a> numeric types.</p>
<pre><code>Console.WriteLine(JsonSerializer.Serialize(new object[] { Half.MaxValue, Int128.MaxValue, UInt128.MaxValue }));
// [65500,170141183460469231731687303715884105727,340282366920938463463374607431768211455]
</code></pre>
</li>
<li><p><a href="https://learn.microsoft.com/en-us/dotnet/api/system.memory-1" data-linktype="absolute-path">Memory&lt;T&gt;</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.readonlymemory-1" data-linktype="absolute-path">ReadOnlyMemory&lt;T&gt;</a> values. <code>byte</code> values are serialized to Base64 strings, and other types to JSON arrays.</p>
<pre><code>JsonSerializer.Serialize&lt;ReadOnlyMemory&lt;byte&gt;&gt;(new byte[] { 1, 2, 3 }); // "AQID"
JsonSerializer.Serialize&lt;Memory&lt;int&gt;&gt;(new int[] { 1, 2, 3 }); // [1,2,3]
</code></pre>
</li>
</ul>
<h4 id="source-generator">Source generator</h4>
<p>.NET 8 includes enhancements of the System.Text.Json <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/source-generation" data-linktype="relative-path">source generator</a> that are aimed at making the <a href="https://learn.microsoft.com/en-us/dotnet/standard/glossary#native-aot" data-linktype="relative-path">Native AOT</a> experience on par with the <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/reflection-vs-source-generation#reflection" data-linktype="relative-path">reflection-based serializer</a>. For example:</p>
<ul>
<li><p>The source generator now supports serializing types with <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/required-properties" data-linktype="relative-path"><code>required</code></a> and <a href="https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/init" data-linktype="relative-path"><code>init</code></a> properties. These were both already supported in reflection-based serialization.</p>
</li>
<li><p>Improved formatting of source-generated code.</p>
</li>
<li><p><a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.serialization.jsonsourcegenerationoptionsattribute" data-linktype="absolute-path">JsonSourceGenerationOptionsAttribute</a> feature parity with <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions" data-linktype="absolute-path">JsonSerializerOptions</a>. For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/source-generation#specify-options" data-linktype="relative-path">Specify options (source generation)</a>.</p>
</li>
<li><p>Additional diagnostics (such as <a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/syslib-diagnostics/syslib1034" data-linktype="relative-path">SYSLIB1034</a> and <a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/syslib-diagnostics/syslib1039" data-linktype="relative-path">SYSLIB1039</a>).</p>
</li>
<li><p>Don't include types of ignored or inaccessible properties.</p>
</li>
<li><p>Support for nesting <code>JsonSerializerContext</code> declarations within arbitrary type kinds.</p>
</li>
<li><p>Support for compiler-generated or <em>unspeakable</em> types in weakly typed source generation scenarios. Since compiler-generated types can't be explicitly specified by the source generator, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json" data-linktype="absolute-path">System.Text.Json</a> now performs nearest-ancestor resolution at run time. This resolution determines the most appropriate supertype with which to serialize the value.</p>
</li>
<li><p>New converter type <code>JsonStringEnumConverter&lt;TEnum&gt;</code>. The existing <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.serialization.jsonstringenumconverter" data-linktype="absolute-path">JsonStringEnumConverter</a> class isn't supported in Native AOT. You can annotate your enum types as follows:</p>
<pre><code>[JsonConverter(typeof(JsonStringEnumConverter&lt;MyEnum&gt;))]
public enum MyEnum { Value1, Value2, Value3 }

[JsonSerializable(typeof(MyEnum))]
public partial class MyContext : JsonSerializerContext { }
</code></pre>
<p>For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/source-generation#serialize-enum-fields-as-strings" data-linktype="relative-path">Serialize enum fields as strings</a>.</p>
</li>
<li><p>New <code>JsonConverter.Type</code> property lets you look up the type of a non-generic <code>JsonConverter</code> instance:</p>
<pre><code>Dictionary&lt;Type, JsonConverter&gt; CreateDictionary(IEnumerable&lt;JsonConverter&gt; converters)
  =&gt; converters.Where(converter =&gt; converter.Type != null).ToDictionary(converter =&gt; converter.Type!);
</code></pre>
<p>The property is nullable since it returns <code>null</code> for <code>JsonConverterFactory</code> instances and <code>typeof(T)</code> for <code>JsonConverter&lt;T&gt;</code> instances.</p>
</li>
</ul>
<h5 id="chain-source-generators">Chain source generators</h5>
<p>The <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions" data-linktype="absolute-path">JsonSerializerOptions</a> class includes a new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.typeinforesolverchain#system-text-json-jsonserializeroptions-typeinforesolverchain" data-linktype="absolute-path">TypeInfoResolverChain</a> property that complements the existing <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.typeinforesolver#system-text-json-jsonserializeroptions-typeinforesolver" data-linktype="absolute-path">TypeInfoResolver</a> property. These properties are used in contract customization for chaining source generators. The addition of the new property means that you don't have to specify all chained components at one call site—they can be added after the fact. <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.typeinforesolverchain#system-text-json-jsonserializeroptions-typeinforesolverchain" data-linktype="absolute-path">TypeInfoResolverChain</a> also lets you introspect the chain or remove components from it. For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/source-generation#combine-source-generators" data-linktype="relative-path">Combine source generators</a>.</p>
<p>In addition, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.addcontext#system-text-json-jsonserializeroptions-addcontext-1" data-linktype="absolute-path">JsonSerializerOptions.AddContext&lt;TContext&gt;()</a> is now obsolete. It's been superseded by the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.typeinforesolver#system-text-json-jsonserializeroptions-typeinforesolver" data-linktype="absolute-path">TypeInfoResolver</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.typeinforesolverchain#system-text-json-jsonserializeroptions-typeinforesolverchain" data-linktype="absolute-path">TypeInfoResolverChain</a> properties. For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/syslib-diagnostics/syslib0049" data-linktype="relative-path">SYSLIB0049</a>.</p>
<h4 id="interface-hierarchies">Interface hierarchies</h4>
<p>.NET 8 adds support for serializing properties from interface hierarchies.</p>
<p>The following code shows an example where the properties from both the immediately implemented interface and its base interface are serialized.</p>
<pre><code>IDerived value = new DerivedImplement { Base = 0, Derived = 1 };
JsonSerializer.Serialize(value); // {"Base":0,"Derived":1}

public interface IBase
{
    public int Base { get; set; }
}

public interface IDerived : IBase
{
    public int Derived { get; set; }
}

public class DerivedImplement : IDerived
{
    public int Base { get; set; }
    public int Derived { get; set; }
}
</code></pre>
<h4 id="naming-policies">Naming policies</h4>
<p><a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonnamingpolicy?view=net-8.0&amp;preserve-view=true#properties" data-linktype="absolute-path"><code>JsonNamingPolicy</code></a> includes new naming policies for <code>snake_case</code> (with an underscore) and <code>kebab-case</code> (with a hyphen) property name conversions. Use these policies similarly to the existing <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonnamingpolicy.camelcase#system-text-json-jsonnamingpolicy-camelcase" data-linktype="absolute-path">JsonNamingPolicy.CamelCase</a> policy:</p>
<pre><code>var options = new JsonSerializerOptions { PropertyNamingPolicy = JsonNamingPolicy.SnakeCaseLower };
JsonSerializer.Serialize(new { PropertyName = "value" }, options); // { "property_name" : "value" }
</code></pre>
<p>For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/customize-properties#use-a-built-in-naming-policy" data-linktype="relative-path">Use a built-in naming policy</a>.</p>
<h4 id="read-only-properties">Read-only properties</h4>
<p>You can now deserialize onto read-only fields or properties (that is, those that don't have a <code>set</code> accessor).</p>
<p>To opt into this support globally, set a new option, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.preferredobjectcreationhandling#system-text-json-jsonserializeroptions-preferredobjectcreationhandling" data-linktype="absolute-path">PreferredObjectCreationHandling</a>, to <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.serialization.jsonobjectcreationhandling#system-text-json-serialization-jsonobjectcreationhandling-populate" data-linktype="absolute-path">JsonObjectCreationHandling.Populate</a>. If compatibility is a concern, you can also enable the functionality more granularly by placing the <code>[JsonObjectCreationHandling(JsonObjectCreationHandling.Populate)]</code> attribute on specific types whose properties are to be populated, or on individual properties.</p>
<p>For example, consider the following code that deserializes into a <code>CustomerInfo</code> type that has two read-only properties.</p>
<pre><code>using System.Text.Json;

CustomerInfo customer =
    JsonSerializer.Deserialize&lt;CustomerInfo&gt;("""{"Names":["John Doe"],"Company":{"Name":"Contoso"}}""")!;

Console.WriteLine(JsonSerializer.Serialize(customer));

class CompanyInfo
{
    public required string Name { get; set; }
    public string? PhoneNumber { get; set; }
}

[JsonObjectCreationHandling(JsonObjectCreationHandling.Populate)]
class CustomerInfo
{
    // Both of these properties are read-only.
    public List&lt;string&gt; Names { get; } = new();
    public CompanyInfo Company { get; } = new() { Name = "N/A", PhoneNumber = "N/A" };
}
</code></pre>
<p>Prior to .NET 8, the input values were ignored and the <code>Names</code> and <code>Company</code> properties retained their default values.</p>
<pre><code>{"Names":[],"Company":{"Name":"N/A","PhoneNumber":"N/A"}}
</code></pre>
<p>Now, the input values are used to populate the read-only properties during deserialization.</p>
<pre><code>{"Names":["John Doe"],"Company":{"Name":"Contoso","PhoneNumber":null}}
</code></pre>
<p>For more information about the <em>populate</em> deserialization behavior, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/populate-properties" data-linktype="relative-path">Populate initialized properties</a>.</p>
<h4 id="disable-reflection-based-default">Disable reflection-based default</h4>
<p>You can now disable using the reflection-based serializer by default. This disablement is useful to avoid accidental rooting of reflection components that aren't even in use, especially in trimmed and Native AOT apps. To disable default reflection-based serialization by requiring that a <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions" data-linktype="absolute-path">JsonSerializerOptions</a> argument be passed to the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializer" data-linktype="absolute-path">JsonSerializer</a> serialization and deserialization methods, set the <code>JsonSerializerIsReflectionEnabledByDefault</code> MSBuild property to <code>false</code> in your project file.</p>
<p>Use the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializer.isreflectionenabledbydefault#system-text-json-jsonserializer-isreflectionenabledbydefault" data-linktype="absolute-path">IsReflectionEnabledByDefault</a> API to check the value of the feature switch. If you're a library author building on top of <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json" data-linktype="absolute-path">System.Text.Json</a>, you can rely on the property to configure your defaults without accidentally rooting reflection components.</p>
<p>For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/source-generation#disable-reflection-defaults" data-linktype="relative-path">Disable reflection defaults</a>.</p>
<h4 id="new-jsonnode-api-methods">New JsonNode API methods</h4>
<p>The <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.nodes.jsonnode" data-linktype="absolute-path">JsonNode</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.nodes.jsonarray" data-linktype="absolute-path">System.Text.Json.Nodes.JsonArray</a> types include the following new methods.</p>
<pre><code>public partial class JsonNode
{
    // Creates a deep clone of the current node and all its descendants.
    public JsonNode DeepClone();

    // Returns true if the two nodes are equivalent JSON representations.
    public static bool DeepEquals(JsonNode? node1, JsonNode? node2);

    // Determines the JsonValueKind of the current node.
    public JsonValueKind GetValueKind(JsonSerializerOptions options = null);

    // If node is the value of a property in the parent
    // object, returns its name.
    // Throws InvalidOperationException otherwise.
    public string GetPropertyName();

    // If node is the element of a parent JsonArray,
    // returns its index.
    // Throws InvalidOperationException otherwise.
    public int GetElementIndex();

    // Replaces this instance with a new value,
    // updating the parent object/array accordingly.
    public void ReplaceWith&lt;T&gt;(T value);

    // Asynchronously parses a stream as UTF-8 encoded data
    // representing a single JSON value into a JsonNode.
    public static Task&lt;JsonNode?&gt; ParseAsync(
        Stream utf8Json,
        JsonNodeOptions? nodeOptions = null,
        JsonDocumentOptions documentOptions = default,
        CancellationToken cancellationToken = default);
}

public partial class JsonArray
{
    // Returns an IEnumerable&lt;T&gt; view of the current array.
    public IEnumerable&lt;T&gt; GetValues&lt;T&gt;();
}
</code></pre>
<h4 id="non-public-members">Non-public members</h4>
<p>You can opt non-public members into the serialization contract for a given type using <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.serialization.jsonincludeattribute" data-linktype="absolute-path">JsonIncludeAttribute</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.serialization.jsonconstructorattribute" data-linktype="absolute-path">JsonConstructorAttribute</a> attribute annotations.</p>
<pre><code>string json = JsonSerializer.Serialize(new MyPoco(42)); // {"X":42}
JsonSerializer.Deserialize&lt;MyPoco&gt;(json);

public class MyPoco
{
    [JsonConstructor]
    internal MyPoco(int x) =&gt; X = x;

    [JsonInclude]
    internal int X { get; }
}
</code></pre>
<p>For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/immutability" data-linktype="relative-path">Use immutable types and non-public members and accessors</a>.</p>
<h4 id="streaming-deserialization-apis">Streaming deserialization APIs</h4>
<p>.NET 8 includes new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.collections.generic.iasyncenumerable-1" data-linktype="absolute-path">IAsyncEnumerable&lt;T&gt;</a> streaming deserialization extension methods, for example <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.http.json.httpclientjsonextensions.getfromjsonasasyncenumerable" data-linktype="absolute-path">GetFromJsonAsAsyncEnumerable</a>. Similar methods have existed that return <a href="https://learn.microsoft.com/en-us/dotnet/api/system.threading.tasks.task-1" data-linktype="absolute-path">Task&lt;TResult&gt;</a>, for example, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.http.json.httpclientjsonextensions.getfromjsonasync" data-linktype="absolute-path">HttpClientJsonExtensions.GetFromJsonAsync</a>. The new extension methods invoke streaming APIs and return <a href="https://learn.microsoft.com/en-us/dotnet/api/system.collections.generic.iasyncenumerable-1" data-linktype="absolute-path">IAsyncEnumerable&lt;T&gt;</a>.</p>
<p>The following code shows how you might use the new extension methods.</p>
<pre><code>const string RequestUri = "https://api.contoso.com/books";
using var client = new HttpClient();
IAsyncEnumerable&lt;Book&gt; books = client.GetFromJsonAsAsyncEnumerable&lt;Book&gt;(RequestUri);

await foreach (Book book in books)
{
    Console.WriteLine($"Read book '{book.title}'");
}

public record Book(int id, string title, string author, int publishedYear);
</code></pre>
<h4 id="withaddedmodifier-extension-method">WithAddedModifier extension method</h4>
<p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.serialization.metadata.jsontypeinforesolver.withaddedmodifier#system-text-json-serialization-metadata-jsontypeinforesolver-withaddedmodifier(system-text-json-serialization-metadata-ijsontypeinforesolver-system-action((system-text-json-serialization-metadata-jsontypeinfo)))" data-linktype="absolute-path">WithAddedModifier(IJsonTypeInfoResolver, Action&lt;JsonTypeInfo&gt;)</a> extension method lets you easily introduce modifications to the serialization contracts of arbitrary <code>IJsonTypeInfoResolver</code> instances.</p>
<pre><code>var options = new JsonSerializerOptions
{
    TypeInfoResolver = MyContext.Default
        .WithAddedModifier(static typeInfo =&gt;
        {
            foreach (JsonPropertyInfo prop in typeInfo.Properties)
                prop.Name = prop.Name.ToUpperInvariant();
        })
};
</code></pre>
<h4 id="new-jsoncontentcreate-overloads">New JsonContent.Create overloads</h4>
<p>You can now create <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.http.json.jsoncontent" data-linktype="absolute-path">JsonContent</a> instances using trim-safe or source-generated contracts. The new methods are:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.http.json.jsoncontent.create#system-net-http-json-jsoncontent-create(system-object-system-text-json-serialization-metadata-jsontypeinfo-system-net-http-headers-mediatypeheadervalue)" data-linktype="absolute-path">JsonContent.Create(Object, JsonTypeInfo, MediaTypeHeaderValue)</a></li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.http.json.jsoncontent.create#system-net-http-json-jsoncontent-create-1(-0-system-text-json-serialization-metadata-jsontypeinfo((-0))-system-net-http-headers-mediatypeheadervalue)" data-linktype="absolute-path">JsonContent.Create&lt;T&gt;(T, JsonTypeInfo&lt;T&gt;, MediaTypeHeaderValue)</a></li>
</ul>
<pre><code>var book = new Book(id: 42, "Title", "Author", publishedYear: 2023);
HttpContent content = JsonContent.Create(book, MyContext.Default.Book);

public record Book(int id, string title, string author, int publishedYear);

[JsonSerializable(typeof(Book))]
public partial class MyContext : JsonSerializerContext
{ }
</code></pre>
<h4 id="freeze-a-jsonserializeroptions-instance">Freeze a JsonSerializerOptions instance</h4>
<p>The following new methods let you control when a <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions" data-linktype="absolute-path">JsonSerializerOptions</a> instance is frozen:</p>
<ul>
<li><p><a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.makereadonly#system-text-json-jsonserializeroptions-makereadonly" data-linktype="absolute-path">JsonSerializerOptions.MakeReadOnly()</a></p>
<p>This overload is designed to be trim-safe and will therefore throw an exception in cases where the options instance hasn't been configured with a resolver.</p>
</li>
<li><p><a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.makereadonly#system-text-json-jsonserializeroptions-makereadonly(system-boolean)" data-linktype="absolute-path">JsonSerializerOptions.MakeReadOnly(Boolean)</a></p>
<p>If you pass <code>true</code> to this overload, it populates the options instance with the default reflection resolver if one is missing. This method is marked <code>RequiresUnreferenceCode</code>/<code>RequiresDynamicCode</code> and is therefore unsuitable for Native AOT applications.</p>
</li>
</ul>
<p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializeroptions.isreadonly#system-text-json-jsonserializeroptions-isreadonly" data-linktype="absolute-path">IsReadOnly</a> property lets you check if the options instance is frozen.</p>
<h3 id="time-abstraction">Time abstraction</h3>
<p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.timeprovider" data-linktype="absolute-path">TimeProvider</a> class and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.threading.itimer" data-linktype="absolute-path">ITimer</a> interface add <em>time abstraction</em> functionality, which allows you to mock time in test scenarios. In addition, you can use the time abstraction to mock <a href="https://learn.microsoft.com/en-us/dotnet/api/system.threading.tasks.task" data-linktype="absolute-path">Task</a> operations that rely on time progression using <a href="https://learn.microsoft.com/en-us/dotnet/api/system.threading.tasks.task.delay" data-linktype="absolute-path">Task.Delay</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.threading.tasks.task.waitasync" data-linktype="absolute-path">Task.WaitAsync</a>. The time abstraction supports the following essential time operations:</p>
<ul>
<li>Retrieve local and UTC time</li>
<li>Obtain a timestamp for measuring performance</li>
<li>Create a timer</li>
</ul>
<p>The following code snippet shows some usage examples.</p>
<pre><code>// Get system time.
DateTimeOffset utcNow = TimeProvider.System.GetUtcNow();
DateTimeOffset localNow = TimeProvider.System.GetLocalNow();

// Create a time provider that works with a
// time zone that's different than the local time zone.
private class ZonedTimeProvider : TimeProvider
{
    private TimeZoneInfo _zoneInfo;

    public ZonedTimeProvider(TimeZoneInfo zoneInfo) : base()
    {
        _zoneInfo = zoneInfo ?? TimeZoneInfo.Local;
    }

    public override TimeZoneInfo LocalTimeZone =&gt; _zoneInfo;

    public static TimeProvider FromLocalTimeZone(TimeZoneInfo zoneInfo) =&gt;
        new ZonedTimeProvider(zoneInfo);
}

// Create a timer using a time provider.
ITimer timer = timeProvider.CreateTimer(callBack, state, delay, Timeout.InfiniteTimeSpan);

// Measure a period using the system time provider.
long providerTimestamp1 = TimeProvider.System.GetTimestamp();
long providerTimestamp2 = TimeProvider.System.GetTimestamp();

var period = GetElapsedTime(providerTimestamp1, providerTimestamp2);
</code></pre>
<h3 id="utf8-improvements">UTF8 improvements</h3>
<p>If you want to enable writing out a string-like representation of your type to a destination span, implement the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.iutf8spanformattable" data-linktype="absolute-path">IUtf8SpanFormattable</a> interface on your type. This new interface is closely related to <a href="https://learn.microsoft.com/en-us/dotnet/api/system.ispanformattable" data-linktype="absolute-path">ISpanFormattable</a>, but targets UTF8 and <code>Span&lt;byte&gt;</code> instead of UTF16 and <code>Span&lt;char&gt;</code>.</p>
<p><a href="https://learn.microsoft.com/en-us/dotnet/api/system.iutf8spanformattable" data-linktype="absolute-path">IUtf8SpanFormattable</a> has been implemented on all of the primitive types (plus others), with the exact same shared logic whether targeting <code>string</code>, <code>Span&lt;char&gt;</code>, or <code>Span&lt;byte&gt;</code>. It has full support for all formats (including the new <a href="https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-numeric-format-strings#binary-format-specifier-b" data-linktype="relative-path">"B" binary specifier</a>) and all cultures. This means you can now format directly to UTF8 from <code>Byte</code>, <code>Complex</code>, <code>Char</code>, <code>DateOnly</code>, <code>DateTime</code>, <code>DateTimeOffset</code>, <code>Decimal</code>, <code>Double</code>, <code>Guid</code>, <code>Half</code>, <code>IPAddress</code>, <code>IPNetwork</code>, <code>Int16</code>, <code>Int32</code>, <code>Int64</code>, <code>Int128</code>, <code>IntPtr</code>, <code>NFloat</code>, <code>SByte</code>, <code>Single</code>, <code>Rune</code>, <code>TimeOnly</code>, <code>TimeSpan</code>, <code>UInt16</code>, <code>UInt32</code>, <code>UInt64</code>, <code>UInt128</code>, <code>UIntPtr</code>, and <code>Version</code>.</p>
<p>New <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.unicode.utf8.trywrite" data-linktype="absolute-path">Utf8.TryWrite</a> methods provide a UTF8-based counterpart to the existing <a href="https://learn.microsoft.com/en-us/dotnet/api/system.memoryextensions.trywrite" data-linktype="absolute-path">MemoryExtensions.TryWrite</a> methods, which are UTF16-based. You can use interpolated string syntax to format a complex expression directly into a span of UTF8 bytes, for example:</p>
<pre><code>static bool FormatHexVersion(
    short major,
    short minor,
    short build,
    short revision,
    Span&lt;byte&gt; utf8Bytes,
    out int bytesWritten) =&gt;
    Utf8.TryWrite(
        utf8Bytes,
        CultureInfo.InvariantCulture,
        $"{major:X4}.{minor:X4}.{build:X4}.{revision:X4}",
        out bytesWritten);
</code></pre>
<p>The implementation recognizes <a href="https://learn.microsoft.com/en-us/dotnet/api/system.iutf8spanformattable" data-linktype="absolute-path">IUtf8SpanFormattable</a> on the format values and uses their implementations to write their UTF8 representations directly to the destination span.</p>
<p>The implementation also utilizes the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.encoding.trygetbytes#system-text-encoding-trygetbytes(system-readonlyspan((system-char))-system-span((system-byte))-system-int32@)" data-linktype="absolute-path">Encoding.TryGetBytes(ReadOnlySpan&lt;Char&gt;, Span&lt;Byte&gt;, Int32)</a> method, which together with its <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.encoding.trygetchars#system-text-encoding-trygetchars(system-readonlyspan((system-byte))-system-span((system-char))-system-int32@)" data-linktype="absolute-path">Encoding.TryGetChars(ReadOnlySpan&lt;Byte&gt;, Span&lt;Char&gt;, Int32)</a> counterpart, supports encoding and decoding into a destination span. If the span isn't long enough to hold the resulting state, the methods return <code>false</code> rather than throwing an exception.</p>
<h3 id="methods-for-working-with-randomness">Methods for working with randomness</h3>
<p>The <a href="https://learn.microsoft.com/en-us/dotnet/api/system.random" data-linktype="absolute-path">System.Random</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.security.cryptography.randomnumbergenerator" data-linktype="absolute-path">System.Security.Cryptography.RandomNumberGenerator</a> types introduce two new methods for working with randomness.</p>
<h4 id="getitemst">GetItems&lt;T&gt;()</h4>
<p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.random.getitems" data-linktype="absolute-path">System.Random.GetItems</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.security.cryptography.randomnumbergenerator.getitems" data-linktype="absolute-path">System.Security.Cryptography.RandomNumberGenerator.GetItems</a> methods let you randomly choose a specified number of items from an input set. The following example shows how to use <code>System.Random.GetItems&lt;T&gt;()</code> (on the instance provided by the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.random.shared#system-random-shared" data-linktype="absolute-path">Random.Shared</a> property) to randomly insert 31 items into an array. This example could be used in a game of "Simon" where players must remember a sequence of colored buttons.</p>
<pre><code>private static ReadOnlySpan&lt;Button&gt; s_allButtons = new[]
{
    Button.Red,
    Button.Green,
    Button.Blue,
    Button.Yellow,
};

// ...

Button[] thisRound = Random.Shared.GetItems(s_allButtons, 31);
// Rest of game goes here ...
</code></pre>
<h4 id="shufflet">Shuffle&lt;T&gt;()</h4>
<p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.random.shuffle" data-linktype="absolute-path">Random.Shuffle</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.security.cryptography.randomnumbergenerator.shuffle#system-security-cryptography-randomnumbergenerator-shuffle-1(system-span((-0)))" data-linktype="absolute-path">RandomNumberGenerator.Shuffle&lt;T&gt;(Span&lt;T&gt;)</a> methods let you randomize the order of a span. These methods are useful for reducing training bias in machine learning (so the first thing isn't always training, and the last thing always test).</p>
<pre><code>YourType[] trainingData = LoadTrainingData();
Random.Shared.Shuffle(trainingData);

IDataView sourceData = mlContext.Data.LoadFromEnumerable(trainingData);

DataOperationsCatalog.TrainTestData split = mlContext.Data.TrainTestSplit(sourceData);
model = chain.Fit(split.TrainSet);

IDataView predictions = model.Transform(split.TestSet);
// ...
</code></pre>
<h3 id="performance-focused-types">Performance-focused types</h3>
<p>.NET 8 introduces several new types aimed at improving app performance.</p>
<ul>
<li><p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.collections.frozen" data-linktype="absolute-path">System.Collections.Frozen</a> namespace includes the collection types <a href="https://learn.microsoft.com/en-us/dotnet/api/system.collections.frozen.frozendictionary-2" data-linktype="absolute-path">FrozenDictionary&lt;TKey,TValue&gt;</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.collections.frozen.frozenset-1" data-linktype="absolute-path">FrozenSet&lt;T&gt;</a>. These types don't allow any changes to keys and values once a collection created. That requirement allows faster read operations (for example, <code>TryGetValue()</code>). These types are particularly useful for collections that are populated on first use and then persisted for the duration of a long-lived service, for example:</p>
<pre><code>private static readonly FrozenDictionary&lt;string, bool&gt; s_configurationData =
    LoadConfigurationData().ToFrozenDictionary(optimizeForReads: true);

// ...
if (s_configurationData.TryGetValue(key, out bool setting) &amp;&amp; setting)
{
    Process();
}
</code></pre>
</li>
<li><p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.buffers.searchvalues-1" data-linktype="absolute-path">System.Buffers.SearchValues&lt;T&gt;</a> type is designed to be passed to methods that look for the first occurrence of any value in the passed collection. For example, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.string.indexofany#system-string-indexofany(system-char())" data-linktype="absolute-path">String.IndexOfAny(Char[])</a> looks for the first occurrence of any character in the specified array in the <code>string</code> it's called on. NET 8 adds new overloads of methods like <a href="https://learn.microsoft.com/en-us/dotnet/api/system.string.indexofany" data-linktype="absolute-path">String.IndexOfAny</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.memoryextensions.indexofany" data-linktype="absolute-path">MemoryExtensions.IndexOfAny</a> that accept an instance of the new type. When you create an instance of <a href="https://learn.microsoft.com/en-us/dotnet/api/system.buffers.searchvalues-1" data-linktype="absolute-path">System.Buffers.SearchValues&lt;T&gt;</a>, all the data that's necessary to optimize subsequent searches is derived <em>at that time</em>, meaning the work is done up front.</p>
</li>
<li><p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.compositeformat" data-linktype="absolute-path">System.Text.CompositeFormat</a> type is useful for optimizing format strings that aren't known at compile time (for example, if the format string is loaded from a resource file). A little extra time is spent up front to do work such as parsing the string, but it saves the work from being done on each use.</p>
<pre><code>private static readonly CompositeFormat s_rangeMessage =
    CompositeFormat.Parse(LoadRangeMessageResource());

// ...
static string GetMessage(int min, int max) =&gt;
    string.Format(CultureInfo.InvariantCulture, s_rangeMessage, min, max);
</code></pre>
</li>
<li><p>New <a href="https://learn.microsoft.com/en-us/dotnet/api/system.io.hashing.xxhash3" data-linktype="absolute-path">System.IO.Hashing.XxHash3</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.io.hashing.xxhash128" data-linktype="absolute-path">System.IO.Hashing.XxHash128</a> types provide implementations of the fast XXH3 and XXH128 hash algorithms.</p>
</li>
</ul>
<h3 id="systemnumerics-and-systemruntimeintrinsics">System.Numerics and System.Runtime.Intrinsics</h3>
<p>This section covers improvements to the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.numerics" data-linktype="absolute-path">System.Numerics</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics" data-linktype="absolute-path">System.Runtime.Intrinsics</a> namespaces.</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector256-1" data-linktype="absolute-path">Vector256&lt;T&gt;</a>, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.numerics.matrix3x2" data-linktype="absolute-path">Matrix3x2</a>, and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.numerics.matrix4x4" data-linktype="absolute-path">Matrix4x4</a> have improved hardware acceleration on .NET 8. For example, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector256-1" data-linktype="absolute-path">Vector256&lt;T&gt;</a> was reimplemented to internally be <code>2x Vector128&lt;T&gt;</code> operations, where possible. This allows partial acceleration of some functions when <code>Vector128.IsHardwareAccelerated == true</code> but <code>Vector256.IsHardwareAccelerated == false</code>, such as on Arm64.</li>
<li>Hardware intrinsics are now annotated with the <code>ConstExpected</code> attribute. This ensures that users are aware when the underlying hardware expects a constant and therefore when a non-constant value may unexpectedly hurt performance.</li>
<li>The <a href="https://learn.microsoft.com/en-us/dotnet/api/system.numerics.ifloatingpointieee754-1.lerp#system-numerics-ifloatingpointieee754-1-lerp(-0-0-0)" data-linktype="absolute-path">Lerp(TSelf, TSelf, TSelf)</a> <code>Lerp</code> API has been added to <a href="https://learn.microsoft.com/en-us/dotnet/api/system.numerics.ifloatingpointieee754-1" data-linktype="absolute-path">IFloatingPointIeee754&lt;TSelf&gt;</a> and therefore to <code>float</code> (<a href="https://learn.microsoft.com/en-us/dotnet/api/system.single" data-linktype="absolute-path">Single</a>), <code>double</code> (<a href="https://learn.microsoft.com/en-us/dotnet/api/system.double" data-linktype="absolute-path">Double</a>), and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.half" data-linktype="absolute-path">Half</a>. This API allows a linear interpolation between two values to be performed efficiently and correctly.</li>
</ul>
<h4 id="vector512-and-avx-512">Vector512 and AVX-512</h4>
<p>.NET Core 3.0 expanded SIMD support to include the platform-specific hardware intrinsics APIs for x86/x64. .NET 5 added support for Arm64 and .NET 7 added the cross-platform hardware intrinsics. .NET 8 furthers SIMD support by introducing <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector512-1" data-linktype="absolute-path">Vector512&lt;T&gt;</a> and support for <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-avx-512-instructions.html" data-linktype="external">Intel Advanced Vector Extensions 512 (AVX-512)</a> instructions.</p>
<p>Specifically, .NET 8 includes support for the following key features of AVX-512:</p>
<ul>
<li>512-bit vector operations</li>
<li>Additional 16 SIMD registers</li>
<li>Additional instructions available for 128-bit, 256-bit, and 512-bit vectors</li>
</ul>
<p>If you have hardware that supports the functionality, then <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector512.ishardwareaccelerated#system-runtime-intrinsics-vector512-ishardwareaccelerated" data-linktype="absolute-path">Vector512.IsHardwareAccelerated</a> now reports <code>true</code>.</p>
<p>.NET 8 also adds several platform-specific classes under the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86" data-linktype="absolute-path">System.Runtime.Intrinsics.X86</a> namespace:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512f" data-linktype="absolute-path">Avx512F</a> (foundational)</li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512bw" data-linktype="absolute-path">Avx512BW</a> (byte and word)</li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512cd" data-linktype="absolute-path">Avx512CD</a> (conflict detection)</li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512dq" data-linktype="absolute-path">Avx512DQ</a> (doubleword and quadword)</li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512vbmi" data-linktype="absolute-path">Avx512Vbmi</a> (vector byte manipulation instructions)</li>
</ul>
<p>These classes follow the same general shape as other instruction set architectures (ISAs) in that they expose an <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512f.issupported#system-runtime-intrinsics-x86-avx512f-issupported" data-linktype="absolute-path">IsSupported</a> property and a nested <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512f.x64" data-linktype="absolute-path">Avx512F.X64</a> class for instructions available only to 64-bit processes. Additionally, each class has a nested <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx512f.vl" data-linktype="absolute-path">Avx512F.VL</a> class that exposes the <code>Avx512VL</code> (vector length) extensions for the corresponding instruction set.</p>
<p>Even if you don't explicitly use <code>Vector512</code>-specific or <code>Avx512F</code>-specific instructions in your code, you'll likely still benefit from the new AVX-512 support. The JIT can take advantage of the additional registers and instructions implicitly when using <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector128-1" data-linktype="absolute-path">Vector128&lt;T&gt;</a> or <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.vector256-1" data-linktype="absolute-path">Vector256&lt;T&gt;</a>. The base class library uses these hardware intrinsics internally in most operations exposed by <a href="https://learn.microsoft.com/en-us/dotnet/api/system.span-1" data-linktype="absolute-path">Span&lt;T&gt;</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.readonlyspan-1" data-linktype="absolute-path">ReadOnlySpan&lt;T&gt;</a> and in many of the math APIs exposed for the primitive types.</p>
<h3 id="data-validation">Data validation</h3>
<p>The <a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations" data-linktype="absolute-path">System.ComponentModel.DataAnnotations</a> namespace includes new data validation attributes intended for validation scenarios in cloud-native services. While the pre-existing <code>DataAnnotations</code> validators are geared towards typical UI data-entry validation, such as fields on a form, the new attributes are designed to validate non-user-entry data, such as <a href="https://learn.microsoft.com/en-us/dotnet/core/extensions/options#options-validation" data-linktype="relative-path">configuration options</a>. In addition to the new attributes, new properties were added to the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.rangeattribute" data-linktype="absolute-path">RangeAttribute</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.requiredattribute" data-linktype="absolute-path">RequiredAttribute</a> types.</p>
<table>
<thead>
<tr>
<th>New API</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.rangeattribute.minimumisexclusive#system-componentmodel-dataannotations-rangeattribute-minimumisexclusive" data-linktype="absolute-path">RangeAttribute.MinimumIsExclusive</a><br><a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.rangeattribute.maximumisexclusive#system-componentmodel-dataannotations-rangeattribute-maximumisexclusive" data-linktype="absolute-path">RangeAttribute.MaximumIsExclusive</a></td>
<td>Specifies whether bounds are included in the allowable range.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.lengthattribute" data-linktype="absolute-path">System.ComponentModel.DataAnnotations.LengthAttribute</a></td>
<td>Specifies both lower and upper bounds for strings or collections. For example, <code>[Length(10, 20)]</code> requires at least 10 elements and at most 20 elements in a collection.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.base64stringattribute" data-linktype="absolute-path">System.ComponentModel.DataAnnotations.Base64StringAttribute</a></td>
<td>Validates that a string is a valid Base64 representation.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.allowedvaluesattribute" data-linktype="absolute-path">System.ComponentModel.DataAnnotations.AllowedValuesAttribute</a><br><a href="https://learn.microsoft.com/en-us/dotnet/api/system.componentmodel.dataannotations.deniedvaluesattribute" data-linktype="absolute-path">System.ComponentModel.DataAnnotations.DeniedValuesAttribute</a></td>
<td>Specify allow lists and deny lists, respectively. For example, <code>[AllowedValues("apple", "banana", "mango")]</code>.</td>
</tr>
</tbody>
</table>
<h3 id="metrics">Metrics</h3>
<p>New APIs let you attach key-value pair tags to <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.meter" data-linktype="absolute-path">Meter</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.instrument" data-linktype="absolute-path">Instrument</a> objects when you create them. Aggregators of published metric measurements can use the tags to differentiate the aggregated values.</p>
<pre><code>MeterOptions options = new MeterOptions("name")
{
    Version = "version",
    // Attach these tags to the created meter
    Tags = new TagList() { { "MeterKey1", "MeterValue1" }, { "MeterKey2", "MeterValue2" } }
};

Meter meter = meterFactory.Create(options);

Instrument instrument = meter.CreateCounter&lt;int&gt;("counter", null, null, new TagList() { { "counterKey1", "counterValue1" } });
instrument.Add(1);
</code></pre>
<p>The new APIs include:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.meteroptions" data-linktype="absolute-path">MeterOptions</a></li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.meter.-ctor#system-diagnostics-metrics-meter-ctor(system-diagnostics-metrics-meteroptions)" data-linktype="absolute-path">Meter(MeterOptions)</a></li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.meter.createcounter#system-diagnostics-metrics-meter-createcounter-1(system-string-system-string-system-string-system-collections-generic-ienumerable((system-collections-generic-keyvaluepair((system-string-system-object)))))" data-linktype="absolute-path">CreateCounter&lt;T&gt;(String, String, String, IEnumerable&lt;KeyValuePair&lt;String,Object&gt;&gt;)</a></li>
</ul>
<h3 id="cryptography">Cryptography</h3>
<p>.NET 8 adds support for the SHA-3 hashing primitives. (SHA-3 is currently supported by Linux with OpenSSL 1.1.1 or later and Windows 11 Build 25324 or later.) APIs where SHA-2 is available now offer a SHA-3 compliment. This includes <code>SHA3_256</code>, <code>SHA3_384</code>, and <code>SHA3_512</code> for hashing; <code>HMACSHA3_256</code>, <code>HMACSHA3_384</code>, and <code>HMACSHA3_512</code> for HMAC; <code>HashAlgorithmName.SHA3_256</code>, <code>HashAlgorithmName.SHA3_384</code>, and <code>HashAlgorithmName.SHA3_512</code> for hashing where the algorithm is configurable; and <code>RSAEncryptionPadding.OaepSHA3_256</code>, <code>RSAEncryptionPadding.OaepSHA3_384</code>, and <code>RSAEncryptionPadding.OaepSHA3_512</code> for RSA OAEP encryption.</p>
<p>The following example shows how to use the APIs, including the <code>SHA3_256.IsSupported</code> property to determine if the platform supports SHA-3.</p>
<pre><code>// Hashing example
if (SHA3_256.IsSupported)
{
    byte[] hash = SHA3_256.HashData(dataToHash);
}
else
{
    // ...
}

// Signing example
if (SHA3_256.IsSupported)
{
     using ECDsa ec = ECDsa.Create(ECCurve.NamedCurves.nistP256);
     byte[] signature = ec.SignData(dataToBeSigned, HashAlgorithmName.SHA3_256);
}
else
{
    // ...
}
</code></pre>
<p>SHA-3 support is currently aimed at supporting cryptographic primitives. Higher-level constructions and protocols aren't expected to fully support SHA-3 initially. These protocols include X.509 certificates, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.security.cryptography.xml.signedxml" data-linktype="absolute-path">SignedXml</a>, and COSE.</p>
<h3 id="networking">Networking</h3>
<h4 id="support-for-https-proxy">Support for HTTPS proxy</h4>
<p>Until now, the proxy types that <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.http.httpclient" data-linktype="absolute-path">HttpClient</a> supported all allowed a "man-in-the-middle" to see which site the client is connecting to, even for HTTPS URIs. <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.http.httpclient" data-linktype="absolute-path">HttpClient</a> now supports <em>HTTPS proxy</em>, which creates an encrypted channel between the client and the proxy so all requests can be handled with full privacy.</p>
<p>To enable HTTPS proxy, set the <code>all_proxy</code> environment variable, or use the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.webproxy" data-linktype="absolute-path">WebProxy</a> class to control the proxy programmatically.</p>
<p>Unix: <code>export all_proxy=https://x.x.x.x:3218</code>
Windows: <code>set all_proxy=https://x.x.x.x:3218</code></p>
<p>You can also use the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.net.webproxy" data-linktype="absolute-path">WebProxy</a> class to control the proxy programmatically.</p>
<h3 id="stream-based-zipfile-methods">Stream-based ZipFile methods</h3>
<p>.NET 8 includes new overloads of <a href="https://learn.microsoft.com/en-us/dotnet/api/system.io.compression.zipfile.createfromdirectory" data-linktype="absolute-path">ZipFile.CreateFromDirectory</a> that allow you to collect all the files included in a directory and zip them, then store the resulting zip file into the provided stream. Similarly, new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.io.compression.zipfile.extracttodirectory" data-linktype="absolute-path">ZipFile.ExtractToDirectory</a> overloads let you provide a stream containing a zipped file and extract its contents into the filesystem. These are the new overloads:</p>
<pre><code>namespace System.IO.Compression;

public static partial class ZipFile
{
    public static void CreateFromDirectory(string sourceDirectoryName, Stream destination);
    public static void CreateFromDirectory(string sourceDirectoryName, Stream destination, CompressionLevel compressionLevel, bool includeBaseDirectory);
    public static void CreateFromDirectory(string sourceDirectoryName, Stream destination, CompressionLevel compressionLevel, bool includeBaseDirectory, Encoding? entryNameEncoding);

    public static void ExtractToDirectory(Stream source, string destinationDirectoryName) { }
    public static void ExtractToDirectory(Stream source, string destinationDirectoryName, bool overwriteFiles) { }
    public static void ExtractToDirectory(Stream source, string destinationDirectoryName, Encoding? entryNameEncoding) { }
    public static void ExtractToDirectory(Stream source, string destinationDirectoryName, Encoding? entryNameEncoding, bool overwriteFiles) { }
}
</code></pre>
<p>These new APIs can be useful when disk space is constrained, because they avoid having to use the disk as an intermediate step.</p>
<h2 id="extension-libraries">Extension libraries</h2>
<p>This section contains the following subtopics:</p>
<ul>
<li><a href="#options-validation" data-linktype="self-bookmark">Options validation</a></li>
<li><a href="#loggermessageattribute-constructors" data-linktype="self-bookmark">LoggerMessageAttribute constructors</a></li>
<li><a href="#extensions-metrics" data-linktype="self-bookmark">Extensions metrics</a></li>
<li><a href="#hosted-lifecycle-services" data-linktype="self-bookmark">Hosted lifecycle services</a></li>
<li><a href="#keyed-di-services" data-linktype="self-bookmark">Keyed DI services</a></li>
<li><a href="#systemnumericstensorstensorprimitives" data-linktype="self-bookmark">System.Numerics.Tensors.TensorPrimitives</a></li>
</ul>
<h3 id="keyed-di-services">Keyed DI services</h3>
<p>Keyed dependency injection (DI) services provides a means for registering and retrieving DI services using keys. By using keys, you can scope how your register and consume services. These are some of the new APIs:</p>
<ul>
<li>The <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.ikeyedserviceprovider" data-linktype="absolute-path">IKeyedServiceProvider</a> interface.</li>
<li>The <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.servicekeyattribute" data-linktype="absolute-path">ServiceKeyAttribute</a> attribute, which can be used to inject the key that was used for registration/resolution in the constructor.</li>
<li>The <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.fromkeyedservicesattribute" data-linktype="absolute-path">FromKeyedServicesAttribute</a> attribute, which can be used on service constructor parameters to specify which keyed service to use.</li>
<li>Various new extension methods for <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.iservicecollection" data-linktype="absolute-path">IServiceCollection</a> to support keyed services, for example, <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.servicecollectionserviceextensions.addkeyedscoped" data-linktype="absolute-path">ServiceCollectionServiceExtensions.AddKeyedScoped</a>.</li>
<li>The <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.serviceprovider" data-linktype="absolute-path">ServiceProvider</a> implementation of <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.ikeyedserviceprovider" data-linktype="absolute-path">IKeyedServiceProvider</a>.</li>
</ul>
<p>The following example shows you to use keyed DI services.</p>
<pre><code>using Microsoft.Extensions.Caching.Memory;
using Microsoft.Extensions.Options;

var builder = WebApplication.CreateBuilder(args);

builder.Services.AddSingleton&lt;BigCacheConsumer&gt;();
builder.Services.AddSingleton&lt;SmallCacheConsumer&gt;();

builder.Services.AddKeyedSingleton&lt;IMemoryCache, BigCache&gt;("big");
builder.Services.AddKeyedSingleton&lt;IMemoryCache, SmallCache&gt;("small");

var app = builder.Build();

app.MapGet("/big", (BigCacheConsumer data) =&gt; data.GetData());
app.MapGet("/small", (SmallCacheConsumer data) =&gt; data.GetData());

app.Run();

class BigCacheConsumer([FromKeyedServices("big")] IMemoryCache cache)
{
    public object? GetData() =&gt; cache.Get("data");
}

class SmallCacheConsumer(IKeyedServiceProvider keyedServiceProvider)
{
    public object? GetData() =&gt; keyedServiceProvider.GetRequiredKeyedService&lt;IMemoryCache&gt;("small");
}
</code></pre>
<p>For more information, see <a href="https://github.com/dotnet/runtime/issues/64427" data-linktype="external">dotnet/runtime#64427</a>.</p>
<h3 id="hosted-lifecycle-services">Hosted lifecycle services</h3>
<p>Hosted services now have more options for execution during the application lifecycle. <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedservice" data-linktype="absolute-path">IHostedService</a> provided <code>StartAsync</code> and <code>StopAsync</code>, and now <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedlifecycleservice" data-linktype="absolute-path">IHostedLifecycleService</a> provides these additional methods:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedlifecycleservice.startingasync#microsoft-extensions-hosting-ihostedlifecycleservice-startingasync(system-threading-cancellationtoken)" data-linktype="absolute-path">StartingAsync(CancellationToken)</a></li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedlifecycleservice.startedasync#microsoft-extensions-hosting-ihostedlifecycleservice-startedasync(system-threading-cancellationtoken)" data-linktype="absolute-path">StartedAsync(CancellationToken)</a></li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedlifecycleservice.stoppingasync#microsoft-extensions-hosting-ihostedlifecycleservice-stoppingasync(system-threading-cancellationtoken)" data-linktype="absolute-path">StoppingAsync(CancellationToken)</a></li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedlifecycleservice.stoppedasync#microsoft-extensions-hosting-ihostedlifecycleservice-stoppedasync(system-threading-cancellationtoken)" data-linktype="absolute-path">StoppedAsync(CancellationToken)</a></li>
</ul>
<p>These methods run before and after the existing points respectively.</p>
<p>The following example shows how to use the new APIs.</p>
<pre><code>using Microsoft.Extensions.Hosting;

IHostBuilder hostBuilder = new HostBuilder();
hostBuilder.ConfigureServices(services =&gt;
{
    services.AddHostedService&lt;MyService&gt;();
});

using (IHost host = hostBuilder.Build())
{
    await host.StartAsync();
}

public class MyService : IHostedLifecycleService
{
    public Task StartingAsync(CancellationToken cancellationToken) =&gt; /* add logic here */ Task.CompletedTask;
    public Task StartAsync(CancellationToken cancellationToken) =&gt; /* add logic here */ Task.CompletedTask;
    public Task StartedAsync(CancellationToken cancellationToken) =&gt; /* add logic here */ Task.CompletedTask;
    public Task StopAsync(CancellationToken cancellationToken) =&gt; /* add logic here */ Task.CompletedTask;
    public Task StoppedAsync(CancellationToken cancellationToken) =&gt; /* add logic here */ Task.CompletedTask;
    public Task StoppingAsync(CancellationToken cancellationToken) =&gt; /* add logic here */ Task.CompletedTask;
}
</code></pre>
<p>For more information, see <a href="https://github.com/dotnet/runtime/issues/86511" data-linktype="external">dotnet/runtime#86511</a>.</p>
<h3 id="options-validation">Options validation</h3>
<h4 id="source-generator-1">Source generator</h4>
<p>To reduce startup overhead and improve validation feature set, we've introduced a source code generator that implements the validation logic. The following code shows example models and validator classes.</p>
<pre><code>public class FirstModelNoNamespace
{
    [Required]
    [MinLength(5)]
    public string P1 { get; set; } = string.Empty;

    [Microsoft.Extensions.Options.ValidateObjectMembers(typeof(SecondValidatorNoNamespace))]
    public SecondModelNoNamespace? P2 { get; set; }
}

public class SecondModelNoNamespace
{
    [Required]
    [MinLength(5)]
    public string P4 { get; set; } = string. Empty;
}

[OptionsValidator]
public partial class FirstValidatorNoNamespace : IValidateOptions&lt;FirstModelNoNamespace&gt;
{
}

[OptionsValidator]
public partial class SecondValidatorNoNamespace : IValidateOptions&lt;SecondModelNoNamespace&gt;
{
}
</code></pre>
<p>If your app uses dependency injection, you can inject the validation as shown in the following example code.</p>
<pre><code>var builder = WebApplication.CreateBuilder(args);
builder.Services.AddControllersWithViews();
builder.Services.Configure&lt;FirstModelNoNamespace&gt;(builder.Configuration.GetSection(...));

builder.Services.AddSingleton&lt;IValidateOptions&lt;FirstModelNoNamespace&gt;, FirstValidatorNoNamespace&gt;();
builder.Services.AddSingleton&lt;IValidateOptions&lt;SecondModelNoNamespace&gt;, SecondValidatorNoNamespace&gt;();
</code></pre>
<h4 id="validateoptionsresultbuilder-type">ValidateOptionsResultBuilder type</h4>
<p>.NET 8 introduces the <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.options.validateoptionsresultbuilder" data-linktype="absolute-path">ValidateOptionsResultBuilder</a> type to facilitate the creation of a <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.options.validateoptionsresult" data-linktype="absolute-path">ValidateOptionsResult</a> object. Importantly, this builder allows for the accumulation of multiple errors. Previously, creating the <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.options.validateoptionsresult" data-linktype="absolute-path">ValidateOptionsResult</a> object that's required to implement <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.options.ivalidateoptions-1.validate#microsoft-extensions-options-ivalidateoptions-1-validate(system-string-0)" data-linktype="absolute-path">IValidateOptions&lt;TOptions&gt;.Validate(String, TOptions)</a> was difficult and sometimes resulted in layered validation errors. If there were multiple errors, the validation process often stopped at the first error.</p>
<p>The following code snippet shows an example usage of <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.options.validateoptionsresultbuilder" data-linktype="absolute-path">ValidateOptionsResultBuilder</a>.</p>
<pre><code>ValidateOptionsResultBuilder builder = new();
builder.AddError("Error: invalid operation code");
builder.AddResult(ValidateOptionsResult.Fail("Invalid request parameters"));
builder.AddError("Malformed link", "Url");

// Build ValidateOptionsResult object has accumulating multiple errors.
ValidateOptionsResult result = builder.Build();

// Reset the builder to allow using it in new validation operation.
builder.Clear();
</code></pre>
<h3 id="loggermessageattribute-constructors">LoggerMessageAttribute constructors</h3>
<p><a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.logging.loggermessageattribute" data-linktype="absolute-path">LoggerMessageAttribute</a> now offers additional constructor overloads. Previously, you had to choose either the parameterless constructor or the constructor that required all of the parameters (event ID, log level, and message). The new overloads offer greater flexibility in specifying the required parameters with reduced code. If you don't supply an event ID, the system generates one automatically.</p>
<pre><code>public LoggerMessageAttribute(LogLevel level, string message);
public LoggerMessageAttribute(LogLevel level);
public LoggerMessageAttribute(string message);
</code></pre>
<h3 id="extensions-metrics">Extensions metrics</h3>
<h4 id="imeterfactory-interface">IMeterFactory interface</h4>
<p>You can register the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.imeterfactory" data-linktype="absolute-path">IMeterFactory</a> interface in dependency injection (DI) containers and use it to create <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.meter" data-linktype="absolute-path">Meter</a> objects in an isolated manner.</p>
<p>Register the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.imeterfactory" data-linktype="absolute-path">IMeterFactory</a> to the DI container using the default meter factory implementation:</p>
<pre><code>// 'services' is the DI IServiceCollection.
services.AddMetrics();
</code></pre>
<p>Consumers can then obtain the meter factory and use it to create a new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.metrics.meter" data-linktype="absolute-path">Meter</a> object.</p>
<pre><code>IMeterFactory meterFactory = serviceProvider.GetRequiredService&lt;IMeterFactory&gt;();

MeterOptions options = new MeterOptions("MeterName")
{
    Version = "version",
};

Meter meter = meterFactory.Create(options);
</code></pre>
<h4 id="metriccollectort-class">MetricCollector&lt;T&gt; class</h4>
<p>The new <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.diagnostics.metrics.testing.metriccollector-1" data-linktype="absolute-path">MetricCollector&lt;T&gt;</a> class lets you record metric measurements along with timestamps. Additionally, the class offers the flexibility to use a time provider of your choice for accurate timestamp generation.</p>
<pre><code>const string CounterName = "MyCounter";

var now = DateTimeOffset.Now;

var timeProvider = new FakeTimeProvider(now);
using var meter = new Meter(Guid.NewGuid().ToString());
var counter = meter.CreateCounter&lt;long&gt;(CounterName);
using var collector = new MetricCollector&lt;long&gt;(counter, timeProvider);

Assert.Empty(collector.GetMeasurementSnapshot());
Assert.Null(collector.LastMeasurement);

counter. Add(3);

// Verify the update was recorded.
Assert.Equal(counter, collector.Instrument);
Assert.NotNull(collector.LastMeasurement);

Assert.Single(collector.GetMeasurementSnapshot());
Assert.Same(collector.GetMeasurementSnapshot().Last(), collector.LastMeasurement);
Assert.Equal(3, collector.LastMeasurement.Value);
Assert.Empty(collector.LastMeasurement.Tags);
Assert.Equal(now, collector.LastMeasurement.Timestamp);
</code></pre>
<h3 id="systemnumericstensorstensorprimitives">System.Numerics.Tensors.TensorPrimitives</h3>
<p>The updated <a href="https://www.nuget.org/packages/System.Numerics.Tensors" data-linktype="external">System.Numerics.Tensors</a> NuGet package includes APIs in the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.numerics.tensors.tensorprimitives" data-linktype="absolute-path">TensorPrimitives</a> namespace that add support for tensor operations. The tensor primitives optimize data-intensive workloads like those of AI and machine learning.</p>
<p>AI workloads like semantic search and retrieval-augmented generation (RAG) extend the natural language capabilities of large language models such as ChatGPT by augmenting prompts with relevant data. For these workloads, operations on vectors—like <em>cosine similarity</em> to find the most relevant data to answer a question—are crucial. The System.Numerics.Tensors.TensorPrimitives package provides APIs for vector operations, meaning you don't need to take an external dependency or write your own implementation.</p>
<p>This package replaces the <a href="https://www.nuget.org/packages/System.Numerics.Tensors" data-linktype="external">System.Numerics.Tensors package</a>.</p>
<p>For more information, see the <a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-rc2/" data-linktype="external">Announcing .NET 8 RC 2 blog post</a>.</p>
<h2 id="garbage-collection">Garbage collection</h2>
<p>.NET 8 adds a capability to adjust the memory limit on the fly. This is useful in cloud-service scenarios, where demand comes and goes. To be cost-effective, services should scale up and down on resource consumption as the demand fluctuates. When a service detects a decrease in demand, it can scale down resource consumption by reducing its memory limit. Previously, this would fail because the garbage collector (GC) was unaware of the change and might allocate more memory than the new limit. With this change, you can call the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.gc.refreshmemorylimit#system-gc-refreshmemorylimit" data-linktype="absolute-path">RefreshMemoryLimit()</a> API to update the GC with the new memory limit.</p>
<p>There are some limitations to be aware of:</p>
<ul>
<li>On 32-bit platforms (for example, Windows x86 and Linux ARM), .NET is unable to establish a new heap hard limit if there isn't already one.</li>
<li>The API might return a non-zero status code indicating the refresh failed. This can happen if the scale-down is too aggressive and leaves no room for the GC to maneuver. In this case, consider calling <code>GC.Collect(2, GCCollectionMode.Aggressive)</code> to shrink the current memory usage, and then try again.</li>
<li>If you scale up the memory limit beyond the size that the GC believes the process can handle during startup, the <code>RefreshMemoryLimit</code> call will succeed, but it won't be able to use more memory than what it perceives as the limit.</li>
</ul>
<p>The following code snippet shows how to call the API.</p>
<pre><code>GC.RefreshMemoryLimit();
</code></pre>
<p>You can also refresh some of the GC configuration settings related to the memory limit. The following code snippet sets the heap hard limit to 100 mebibytes (MiB):</p>
<pre><code>AppContext.SetData("GCHeapHardLimit", (ulong)100 * 1024 * 1024);
GC.RefreshMemoryLimit();
</code></pre>
<p>The API can throw an <a href="https://learn.microsoft.com/en-us/dotnet/api/system.invalidoperationexception" data-linktype="absolute-path">InvalidOperationException</a> if the hard limit is invalid, for example, in the case of negative heap hard limit percentages and if the hard limit is too low. This can happen if the heap hard limit that the refresh will set, either because of new AppData settings or implied by the container memory limit changes, is lower than what's already committed.</p>
<h2 id="configuration-binding-source-generator">Configuration-binding source generator</h2>
<p>.NET 8 introduces a source generator to provide AOT and trim-friendly <a href="https://learn.microsoft.com/en-us/aspnet/core/fundamentals/configuration/" data-linktype="absolute-path">configuration</a> in ASP.NET Core. The generator is an alternative to the pre-existing reflection-based implementation.</p>
<p>The source generator probes for <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.options.configureoptions-1.configure#microsoft-extensions-options-configureoptions-1-configure(-0)" data-linktype="absolute-path">Configure(TOptions)</a>, <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.configuration.configurationbinder.bind" data-linktype="absolute-path">Bind</a>, and <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.configuration.configurationbinder.get" data-linktype="absolute-path">Get</a> calls to retrieve type info from. When the generator is enabled in a project, the compiler implicitly chooses generated methods over the pre-existing reflection-based framework implementations.</p>
<p>No source code changes are needed to use the generator. It's enabled by default in AOT'd web apps. For other project types, the source generator is off by default, but you can opt in by setting the <code>EnableConfigurationBindingGenerator</code> property to <code>true</code> in your project file:</p>
<pre><code>&lt;PropertyGroup&gt;
    &lt;EnableConfigurationBindingGenerator&gt;true&lt;/EnableConfigurationBindingGenerator&gt;
&lt;/PropertyGroup&gt;
</code></pre>
<p>The following code shows an example of invoking the binder.</p>
<pre><code>using Microsoft.AspNetCore.Builder;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.DependencyInjection;

WebApplicationBuilder builder = WebApplication.CreateBuilder(args);
IConfigurationSection section = builder.Configuration.GetSection("MyOptions");

// !! Configure call - to be replaced with source-gen'd implementation
builder.Services.Configure&lt;MyOptions&gt;(section);

// !! Get call - to be replaced with source-gen'd implementation
MyOptions options0 = section.Get&lt;MyOptions&gt;();

// !! Bind call - to be replaced with source-gen'd implementation
MyOptions options1 = new MyOptions();
section.Bind(options1);

WebApplication app = builder.Build();
app.MapGet("/", () =&gt; "Hello World!");
app.Run();

public class MyOptions
{
    public int A { get; set; }
    public string S { get; set; }
    public byte[] Data { get; set; }
    public Dictionary&lt;string, string&gt; Values { get; set; }
    public List&lt;MyClass&gt; Values2 { get; set; }
}

public class MyClass
{
    public int SomethingElse { get; set; }
}
</code></pre>
<h2 id="reflection-improvements">Reflection improvements</h2>
<p><a href="https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/unsafe-code#function-pointers" data-linktype="relative-path">Function pointers</a> were introduced in .NET 5, however, the corresponding support for reflection wasn't added at that time. When using <code>typeof</code> or reflection on a function pointer, for example, <code>typeof(delegate*&lt;void&gt;())</code> or <code>FieldInfo.FieldType</code> respectively, an <a href="https://learn.microsoft.com/en-us/dotnet/api/system.intptr" data-linktype="absolute-path">IntPtr</a> was returned. Starting in .NET 8, a <a href="https://learn.microsoft.com/en-us/dotnet/api/system.type" data-linktype="absolute-path">System.Type</a> object is returned instead. This type provides access to function pointer metadata, including the calling conventions, return type, and parameters.</p>
<div>
<p>Note</p>
<p>A function pointer instance, which is a physical address to a function, continues to be represented as an <a href="https://learn.microsoft.com/en-us/dotnet/api/system.intptr" data-linktype="absolute-path">IntPtr</a>. Only the reflection type has changed.</p>
</div>
<p>The new functionality is currently implemented only in the CoreCLR runtime and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.reflection.metadataloadcontext" data-linktype="absolute-path">MetadataLoadContext</a>.</p>
<p>New APIs have been added to <a href="https://learn.microsoft.com/en-us/dotnet/api/system.type" data-linktype="absolute-path">System.Type</a>, such as <a href="https://learn.microsoft.com/en-us/dotnet/api/system.type.isfunctionpointer#system-type-isfunctionpointer" data-linktype="absolute-path">IsFunctionPointer</a>, and to <a href="https://learn.microsoft.com/en-us/dotnet/api/system.reflection.propertyinfo" data-linktype="absolute-path">System.Reflection.PropertyInfo</a>, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.reflection.fieldinfo" data-linktype="absolute-path">System.Reflection.FieldInfo</a>, and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.reflection.parameterinfo" data-linktype="absolute-path">System.Reflection.ParameterInfo</a>. The following code shows how to use some of the new APIs for reflection.</p>
<pre><code>// Sample class that contains a function pointer field.
public unsafe class UClass
{
    public delegate* unmanaged[Cdecl, SuppressGCTransition]&lt;in int, void&gt; _fp;
}

// ...

FieldInfo fieldInfo = typeof(UClass).GetField(nameof(UClass._fp));

// Obtain the function pointer type from a field.
Type fpType = fieldInfo.FieldType;

// New methods to determine if a type is a function pointer.
Console.WriteLine($"IsFunctionPointer: {fpType.IsFunctionPointer}");
Console.WriteLine($"IsUnmanagedFunctionPointer: {fpType.IsUnmanagedFunctionPointer}");

// New methods to obtain the return and parameter types.
Console.WriteLine($"Return type: {fpType.GetFunctionPointerReturnType()}");

foreach (Type parameterType in fpType.GetFunctionPointerParameterTypes())
{
    Console.WriteLine($"Parameter type: {parameterType}");
}

// Access to custom modifiers and calling conventions requires a "modified type".
Type modifiedType = fieldInfo.GetModifiedFieldType();

// A modified type forwards most members to its underlying type.
Type normalType = modifiedType.UnderlyingSystemType;

// New method to obtain the calling conventions.
foreach (Type callConv in modifiedType.GetFunctionPointerCallingConventions())
{
    Console.WriteLine($"Calling convention: {callConv}");
}

// New method to obtain the custom modifiers.
foreach (Type modreq in modifiedType.GetFunctionPointerParameterTypes()[0].GetRequiredCustomModifiers())
{
    Console.WriteLine($"Required modifier for first parameter: {modreq}");
}
</code></pre>
<p>The previous example produces the following output:</p>
<pre><code>IsFunctionPointer: True
IsUnmanagedFunctionPointer: True
Return type: System.Void
Parameter type: System.Int32&amp;
Calling convention: System.Runtime.CompilerServices.CallConvSuppressGCTransition
Calling convention: System.Runtime.CompilerServices.CallConvCdecl
Required modifier for first parameter: System.Runtime.InteropServices.InAttribute
</code></pre>
<h2 id="native-aot-support">Native AOT support</h2>
<p>The option to <a href="https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/" data-linktype="relative-path">publish as Native AOT</a> was first introduced in .NET 7. Publishing an app with Native AOT creates a fully self-contained version of your app that doesn't need a runtime—everything is included in a single file. .NET 8 brings the following improvements to Native AOT publishing:</p>
<ul>
<li><p>Adds support for the x64 and Arm64 architectures on <em>macOS</em>.</p>
</li>
<li><p>Reduces the sizes of Native AOT apps on Linux by up to 50%. The following table shows the size of a "Hello World" app published with Native AOT that includes the entire .NET runtime on .NET 7 vs. .NET 8:</p>
<table>
<thead>
<tr>
<th>Operating system</th>
<th>.NET 7</th>
<th>.NET 8</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux x64 (with <code>-p:StripSymbols=true</code>)</td>
<td>3.76 MB</td>
<td>1.84 MB</td>
</tr>
<tr>
<td>Windows x64</td>
<td>2.85 MB</td>
<td>1.77 MB</td>
</tr>
</tbody>
</table>
</li>
<li><p>Lets you specify an optimization preference: size or speed. By default, the compiler chooses to generate fast code while being mindful of the size of the application. However, you can use the <code>&lt;OptimizationPreference&gt;</code> MSBuild property to optimize specifically for one or the other. For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/optimizing" data-linktype="relative-path">Optimize AOT deployments</a>.</p>
</li>
</ul>
<h3 id="console-app-template">Console app template</h3>
<p>The default console app template now includes support for AOT out-of-the-box. To create a project that's configured for AOT compilation, just run <code>dotnet new console --aot</code>. The project configuration added by <code>--aot</code> has three effects:</p>
<ul>
<li>Generates a native self-contained executable with Native AOT when you publish the project, for example, with <code>dotnet publish</code> or Visual Studio.</li>
<li>Enables compatibility analyzers for trimming, AOT, and single file. These analyzers alert you to potentially problematic parts of your project (if there are any).</li>
<li>Enables debug-time emulation of AOT so that when you debug your project without AOT compilation, you get a similar experience to AOT. For example, if you use <a href="https://learn.microsoft.com/en-us/dotnet/api/system.reflection.emit" data-linktype="absolute-path">System.Reflection.Emit</a> in a NuGet package that wasn't annotated for AOT (and therefore was missed by the compatibility analyzer), the emulation means you won't have any surprises when you try to publish the project with AOT.</li>
</ul>
<h3 id="target-ios-like-platforms-with-native-aot">Target iOS-like platforms with Native AOT</h3>
<p>.NET 8 starts the work to enable Native AOT support for iOS-like platforms. You can now build and run .NET iOS and .NET MAUI applications with Native AOT on the following platforms:</p>
<ul>
<li><code>ios</code></li>
<li><code>iossimulator</code></li>
<li><code>maccatalyst</code></li>
<li><code>tvos</code></li>
<li><code>tvossimulator</code></li>
</ul>
<p>Preliminary testing shows that app size on disk decreases by about 35% for .NET iOS apps that use Native AOT instead of Mono. App size on disk for .NET MAUI iOS apps decreases up to 50%. Additionally, the startup time is also faster. .NET iOS apps have about 28% faster startup time, while .NET MAUI iOS apps have about 50% better startup performance compared to Mono. The .NET 8 support is experimental and only the first step for the feature as a whole. For more information, see the <a href="https://devblogs.microsoft.com/dotnet/dotnet-8-performance-improvements-in-dotnet-maui/" data-linktype="external">.NET 8 Performance Improvements in .NET MAUI blog post</a>.</p>
<p>Native AOT support is available as an opt-in feature intended for app deployment; Mono is still the default runtime for app development and deployment. To build and run a .NET MAUI application with Native AOT on an iOS device, use <code>dotnet workload install maui</code> to install the .NET MAUI workload and <code>dotnet new maui -n HelloMaui</code> to create the app. Then, set the MSBuild property <code>PublishAot</code> to <code>true</code> in the project file.</p>
<pre><code>&lt;PropertyGroup&gt;
  &lt;PublishAot&gt;true&lt;/PublishAot&gt;
&lt;/PropertyGroup&gt;
</code></pre>
<p>When you set the required property and run <code>dotnet publish</code> as shown in the following example, the app will be deployed by using Native AOT.</p>
<pre><code>dotnet publish -f net8.0-ios -c Release -r ios-arm64  /t:Run
</code></pre>
<h4 id="limitations">Limitations</h4>
<p>Not all iOS features are compatible with Native AOT. Similarly, not all libraries commonly used in iOS are compatible with NativeAOT. And in addition to the existing <a href="https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/#limitations-of-native-aot-deployment" data-linktype="relative-path">limitations of Native AOT deployment</a>, the following list shows some of the other limitations when targeting iOS-like platforms:</p>
<ul>
<li>Using Native AOT is only enabled during app deployment (<code>dotnet publish</code>).</li>
<li>Managed code debugging is only supported with Mono.</li>
<li>Compatibility with the .NET MAUI framework is limited.</li>
</ul>
<h2 id="performance-improvements">Performance improvements</h2>
<p>.NET 8 includes improvements to code generation and just-in time (JIT) compilation:</p>
<ul>
<li>Arm64 performance improvements</li>
<li>SIMD improvements</li>
<li>Support for AVX-512 ISA extensions (see <a href="#vector512-and-avx-512" data-linktype="self-bookmark">Vector512 and AVX-512</a>)</li>
<li>Cloud-native improvements</li>
<li>JIT throughput improvements</li>
<li>Loop and general optimizations</li>
<li>Optimized access for fields marked with <a href="https://learn.microsoft.com/en-us/dotnet/api/system.threadstaticattribute" data-linktype="absolute-path">ThreadStaticAttribute</a></li>
<li>Consecutive register allocation. Arm64 has two instructions for table vector lookup, which require that all entities in their tuple operands are present in consecutive registers.</li>
<li>JIT/NativeAOT can now unroll and auto-vectorize some memory operations with SIMD, such as comparison, copying, and zeroing, if it can determine their sizes at compile time.</li>
</ul>
<p>In addition, dynamic profile-guided optimization (PGO) has been improved and is now enabled by default. You no longer need to use a <a href="https://learn.microsoft.com/en-us/dotnet/core/runtime-config/compilation#profile-guided-optimization" data-linktype="relative-path">runtime configuration option</a> to enable it. Dynamic PGO works hand-in-hand with tiered compilation to further optimize code based on additional instrumentation that's put in place during tier 0.</p>
<p>On average, dynamic PGO increases performance by about 15%. In a benchmark suite of ~4600 tests, 23% saw performance improvements of 20% or more.</p>
<h3 id="codegen-struct-promotion">Codegen struct promotion</h3>
<p>.NET 8 includes a new physical promotion optimization pass for codegen that generalizes the JIT's ability to promote struct variables. This optimization (also called <em>scalar replacement of aggregates</em>) replaces the fields of struct variables by primitive variables that the JIT is then able to reason about and optimize more precisely.</p>
<p>The JIT already supported this optimization but with several large limitations including:</p>
<ul>
<li>It was only supported for structs with four or fewer fields.</li>
<li>It was only supported if each field was a primitive type, or a simple struct wrapping a primitive type.</li>
</ul>
<p>Physical promotion removes these limitations, which fixes a number of long-standing JIT issues.</p>
<h2 id="net-sdk">.NET SDK</h2>
<p>This section contains the following subtopics:</p>
<ul>
<li><a href="#cli-based-project-evaluation" data-linktype="self-bookmark">CLI-based project evaluation</a></li>
<li><a href="#terminal-build-output" data-linktype="self-bookmark">Terminal build output</a></li>
<li><a href="#simplified-output-paths" data-linktype="self-bookmark">Simplified output paths</a></li>
<li><a href="#dotnet-workload-clean-command" data-linktype="self-bookmark">'dotnet workload clean' command</a></li>
<li><a href="#dotnet-publish-and-dotnet-pack-assets" data-linktype="self-bookmark">'dotnet publish' and 'dotnet pack' assets</a></li>
<li><a href="#template-engine" data-linktype="self-bookmark">Template engine</a></li>
<li><a href="#source-link" data-linktype="self-bookmark">Source Link</a></li>
<li><a href="#source-build-sdk" data-linktype="self-bookmark">Source-build SDK</a></li>
</ul>
<h3 id="cli-based-project-evaluation">CLI-based project evaluation</h3>
<p>MSBuild includes a new feature that makes it easier to incorporate data from MSBuild into your scripts or tools. The following new flags are available for CLI commands such as <a href="https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-publish" data-linktype="relative-path">dotnet publish</a> to obtain data for use in CI pipelines and elsewhere.</p>
<table>
<thead>
<tr>
<th>Flag</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--getProperty:&lt;PROPERTYNAME&gt;</code></td>
<td>Retrieves the MSBuild property with the specified name.</td>
</tr>
<tr>
<td><code>--getItem:&lt;ITEMTYPE&gt;</code></td>
<td>Retrieves MSBuild items of the specified type.</td>
</tr>
<tr>
<td><code>--getTargetResults:&lt;TARGETNAME&gt;</code></td>
<td>Retrieves the outputs from running the specified target.</td>
</tr>
</tbody>
</table>
<p>Values are written to the standard output. Multiple or complex values are output as JSON, as shown in the following examples.</p>
<pre><code>&gt;dotnet publish --getProperty:OutputPath
bin\Release\net8.0\
</code></pre>
<pre><code>&gt; dotnet publish -p PublishProfile=DefaultContainer --getProperty:GeneratedContainerDigest --getProperty:GeneratedContainerConfiguration
{
  "Properties": {
    "GeneratedContainerDigest": "sha256:ef880a503bbabcb84bbb6a1aa9b41b36dc1ba08352e7cd91c0993646675174c4",
    "GeneratedContainerConfiguration": "{\u0022config\u0022:{\u0022ExposedPorts\u0022:{\u00228080/tcp\u0022:{}},\u0022Labels\u0022...}}"
  }
}
</code></pre>
<pre><code>&gt;dotnet publish -p PublishProfile=DefaultContainer --getItem:ContainerImageTags
{
  "Items": {
    "ContainerImageTags": [
      {
        "Identity": "latest",
        ...
    ]
  }
}
</code></pre>
<h3 id="terminal-build-output">Terminal build output</h3>
<p><code>dotnet build</code> has a new option to produce more modernized build output. This <em>terminal logger</em> output groups errors with the project they came from, better differentiates the different target frameworks for multi-targeted projects, and provides real-time information about what the build is doing. To opt into the new output, use the <code>--tl</code> option. For more information about this option, see <a href="https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-build#options" data-linktype="relative-path">dotnet build options</a>.</p>
<h3 id="simplified-output-paths">Simplified output paths</h3>
<p>.NET 8 introduces an option to simplify the output path and folder structure for build outputs. Previously, .NET apps produced a deep and complex set of output paths for different build artifacts. The new, simplified output path structure gathers all build outputs into a common location, which makes it easier for tooling to anticipate.</p>
<p>For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/core/sdk/artifacts-output" data-linktype="relative-path">Artifacts output layout</a>.</p>
<h3 id="dotnet-workload-clean-command"><code>dotnet workload clean</code> command</h3>
<p>.NET 8 introduces a new command to clean up workload packs that might be left over through several .NET SDK or Visual Studio updates. If you encounter issues when managing workloads, consider using <code>workload clean</code> to safely restore to a known state before trying again. The command has two modes:</p>
<ul>
<li><p><code>dotnet workload clean</code></p>
<p>Runs <a href="https://github.com/dotnet/designs/blob/main/accepted/2021/workloads/workload-installation.md#workload-pack-installation-records-and-garbage-collection" data-linktype="external">workload garbage collection</a> for file-based or MSI-based workloads, which cleans up orphaned packs. Orphaned packs are from uninstalled versions of the .NET SDK or packs where installation records for the pack no longer exist.</p>
<p>If Visual Studio is installed, the command also lists any workloads that you should clean up manually using Visual Studio.</p>
</li>
<li><p><code>dotnet workload clean --all</code></p>
<p>This mode is more aggressive and cleans every pack on the machine that's of the current SDK workload installation type (and that's not from Visual Studio). It also removes all workload installation records for the running .NET SDK feature band and below.</p>
</li>
</ul>
<h3 id="dotnet-publish-and-dotnet-pack-assets"><code>dotnet publish</code> and <code>dotnet pack</code> assets</h3>
<p>Since the <a href="https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-publish" data-linktype="relative-path"><code>dotnet publish</code></a> and <a href="https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-pack" data-linktype="relative-path"><code>dotnet pack</code></a> commands are intended to produce production assets, they now produce <code>Release</code> assets by default.</p>
<p>The following output shows the different behavior between <code>dotnet build</code> and <code>dotnet publish</code>, and how you can revert to publishing <code>Debug</code> assets by setting the <code>PublishRelease</code> property to <code>false</code>.</p>
<pre><code>/app# dotnet new console
/app# dotnet build
  app -&gt; /app/bin/Debug/net8.0/app.dll
/app# dotnet publish
  app -&gt; /app/bin/Release/net8.0/app.dll
  app -&gt; /app/bin/Release/net8.0/publish/
/app# dotnet publish -p:PublishRelease=false
  app -&gt; /app/bin/Debug/net8.0/app.dll
  app -&gt; /app/bin/Debug/net8.0/publish/
</code></pre>
<p>For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/core/compatibility/sdk/8.0/dotnet-pack-config" data-linktype="relative-path">'dotnet pack' uses Release config</a> and <a href="https://learn.microsoft.com/en-us/dotnet/core/compatibility/sdk/8.0/dotnet-publish-config" data-linktype="relative-path">'dotnet publish' uses Release config</a>.</p>
<h3 id="dotnet-restore-security-auditing"><code>dotnet restore</code> security auditing</h3>
<p>Starting in .NET 8, you can opt into security checks for known vulnerabilities when dependency packages are restored. This auditing produces a report of security vulnerabilities with the affected package name, the severity of the vulnerability, and a link to the advisory for more details. When you run <code>dotnet add</code> or <code>dotnet restore</code>, warnings NU1901-NU1904 will appear for any vulnerabilities that are found. For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/core/tools/dotnet-restore#audit-for-security-vulnerabilities" data-linktype="relative-path">Audit for security vulnerabilities</a>.</p>
<h3 id="template-engine">Template engine</h3>
<p>The <a href="https://github.com/dotnet/templating" data-linktype="external">template engine</a> provides a more secure experience in .NET 8 by integrating some of NuGet's security-related features. The improvements include:</p>
<ul>
<li><p>Prevent downloading packages from <code>http://</code> feeds by default. For example, the following command will fail to install the template package because the source URL doesn't use HTTPS.</p>
<p><code>dotnet new install console --add-source "http://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-public/nuget/v3/index.json"</code></p>
<p>You can override this limitation by using the <code>--force</code> flag.</p>
</li>
<li><p>For <code>dotnet new</code>, <code>dotnet new install</code>, and <code>dotnet new update</code>, check for known vulnerabilities in the template package. If vulnerabilities are found and you wish to proceed, you must use the <code>--force</code> flag.</p>
</li>
<li><p>For <code>dotnet new</code>, provide information about the template package owner. Ownership is verified by the NuGet portal and can be considered a trustworthy characteristic.</p>
</li>
<li><p>For <code>dotnet search</code> and <code>dotnet uninstall</code>, indicate whether a template is installed from a package that's "trusted"—that is, it uses a <a href="https://learn.microsoft.com/en-us/nuget/nuget-org/id-prefix-reservation" data-linktype="absolute-path">reserved prefix</a>.</p>
</li>
</ul>
<h3 id="source-link">Source Link</h3>
<p><a href="https://learn.microsoft.com/en-us/dotnet/standard/library-guidance/sourcelink" data-linktype="relative-path">Source Link</a> is now included in the .NET SDK. The goal is that by bundling Source Link into the SDK, instead of requiring a separate <code>&lt;PackageReference&gt;</code> for the package, more packages will include this information by default. That information will improve the IDE experience for developers.</p>
<h3 id="source-build-sdk">Source-build SDK</h3>
<p>The Linux distribution-built (source-build) SDK now has the capability to build self-contained applications using the source-build runtime packages. The distribution-specific runtime package is bundled with the source-build SDK. During self-contained deployment, this bundled runtime package will be referenced, thereby enabling the feature for users.</p>
<h2 id="globalization">Globalization</h2>
<h3 id="hybridglobalization-mode-on-iostvosmaccatalyst">HybridGlobalization mode on iOS/tvOS/MacCatalyst</h3>
<p>Mobile apps can now use a new <em>hybrid</em> globalization mode that uses a lighter ICU bundle. In hybrid mode, globalization data is partially pulled from the ICU bundle and partially from calls into Native API. It serves all the <a href="https://github.com/dotnet/icu/blob/dotnet/main/icu-filters/icudt_mobile.json" data-linktype="external">locales supported by mobile</a>.</p>
<p><code>HybridGlobalization</code> is most suitable for apps that can't work in <code>InvariantGlobalization</code> mode and that use cultures that were trimmed from ICU data on mobile. You can also use it when you want to load a smaller ICU data file. (The <em>icudt_hybrid.dat</em> file is 34.5 % smaller than the default ICU data file <em>icudt.dat</em>.)</p>
<p>To use <code>HybridGlobalization</code> mode, set the MSBuild property to true:</p>
<pre><code>&lt;PropertyGroup&gt;
  &lt;HybridGlobalization&gt;true&lt;/HybridGlobalization&gt;
&lt;/PropertyGroup&gt;
</code></pre>
<p>There are some limitations to be aware of:</p>
<ul>
<li>Due to limitations of Native API, not all globalization APIs are supported in hybrid mode.</li>
<li>Some of the supported APIs have different behavior.</li>
</ul>
<p>To make sure your application isn't affected, see <a href="https://github.com/dotnet/runtime/blob/main/docs/design/features/globalization-hybrid-mode.md#behavioral-differences" data-linktype="external">Behavioral differences</a>.</p>
<h2 id="containers">Containers</h2>
<ul>
<li><a href="#container-images" data-linktype="self-bookmark">Container images</a></li>
<li><a href="#container-publishing" data-linktype="self-bookmark">Container publishing</a></li>
</ul>
<h3 id="container-images">Container images</h3>
<p>The following changes have been made to .NET container images for .NET 8:</p>
<ul>
<li><a href="#generated-image-defaults" data-linktype="self-bookmark">Generated-image defaults</a></li>
<li><a href="#debian-12" data-linktype="self-bookmark">Debian 12</a></li>
<li><a href="#non-root-user" data-linktype="self-bookmark">Non-root user</a></li>
<li><a href="#preview-image-tags" data-linktype="self-bookmark">Preview image tags</a></li>
<li><a href="#chiseled-ubuntu-images" data-linktype="self-bookmark">Chiseled Ubuntu images</a></li>
<li><a href="#build-multi-platform-container-images" data-linktype="self-bookmark">Build multi-platform container images</a></li>
<li><a href="#aspnet-composite-images" data-linktype="self-bookmark">ASP.NET composite images</a></li>
</ul>
<h4 id="generated-image-defaults">Generated-image defaults</h4>
<p>The new <a href="#non-root-user" data-linktype="self-bookmark"><code>non-root</code> capability</a> of the Microsoft .NET containers is now the default, which helps your apps stay secure-by-default. Change this default at any time by setting your own <code>ContainerUser</code>.</p>
<p>The default container tag is now <code>latest</code>. This default is in line with other tooling in the containers space and makes containers easier to use in inner development loops.</p>
<h4 id="debian-12">Debian 12</h4>
<p>The container images now use <a href="https://wiki.debian.org/DebianBookworm" data-linktype="external">Debian 12 (Bookworm)</a>. Debian is the default Linux distro in the .NET container images.</p>
<h4 id="non-root-user">Non-root user</h4>
<p>Images include a <code>non-root</code> user. This user makes the images <code>non-root</code> capable. To run as <code>non-root</code>, add the following line at the end of your Dockerfile (or a similar instruction in your Kubernetes manifests):</p>
<pre><code>USER app
</code></pre>
<p>.NET 8 adds an environment variable for the UID for the <code>non-root</code> user, which is 64198. This environment variable is useful for the Kubernetes <code>runAsNonRoot</code> test, which requires that the container user be set via UID and not by name. This <a href="https://github.com/dotnet/dotnet-docker/blob/e5bc76bca49a1bbf9c11e74a590cf6a9fe9dbf2a/samples/aspnetapp/Dockerfile.alpine-non-root#L27" data-linktype="external">dockerfile</a> shows an example usage.</p>
<p>The default port also changed from port <code>80</code> to <code>8080</code>. To support this change, a new environment variable <code>ASPNETCORE_HTTP_PORTS</code> is available to make it easier to change ports. The variable accepts a list of ports, which is simpler than the format required by <code>ASPNETCORE_URLS</code>. If you change the port back to port <code>80</code> using one of these variables, you can't run as <code>non-root</code>.</p>
<h4 id="preview-image-tags">Preview image tags</h4>
<p>Container image tags for .NET 8 Previews 1 through 7 had a <code>-preview</code> suffix, for example, <code>8.0-preview</code> and <code>8.0-preview-&lt;OS&gt;</code>. Starting in RC 1, <code>preview</code> is removed from the tag name, and those tags are no longer maintained. The new tags, <code>8.0</code> and <code>8.0-&lt;OS&gt;</code>, are permanent, and will be maintained throughout the lifetime of .NET 8.</p>
<h4 id="chiseled-ubuntu-images">Chiseled Ubuntu images</h4>
<p><a href="https://hub.docker.com/r/ubuntu/dotnet-deps" data-linktype="external">Chiseled Ubuntu images</a> are available for .NET 8. Chiseled images have a reduced attacked surface because they're ultra-small, have no package manager or shell, and are <code>non-root</code>. This type of image is for developers who want the benefit of appliance-style computing. Chiseled images are published to the <a href="https://mcr.microsoft.com/product/dotnet/nightly/aspnet/tags" data-linktype="external">.NET nightly artifact registry</a>.</p>
<h4 id="build-multi-platform-container-images">Build multi-platform container images</h4>
<p>Docker supports using and building <a href="https://docs.docker.com/build/building/multi-platform/" data-linktype="external">multi-platform images</a> that work across multiple environments. .NET 8 introduces a new pattern that enables you to mix and match architectures with the .NET images you build. As an example, if you're using macOS and want to target an x64 cloud service in Azure, you can build the image by using the <code>--platform</code> switch as follows:</p>
<p><code>docker build --pull -t app --platform linux/amd64</code></p>
<p>The .NET SDK now supports <code>$TARGETARCH</code> values and the <code>-a</code> argument on restore. The following code snippet shows an example:</p>
<pre><code>RUN dotnet restore -a $TARGETARCH

# Copy everything else and build app.
COPY aspnetapp/. .
RUN dotnet publish -a $TARGETARCH --self-contained false --no-restore -o /app
</code></pre>
<p>For more information, see the <a href="https://devblogs.microsoft.com/dotnet/improving-multiplatform-container-support/" data-linktype="external">Improving multi-platform container support</a> blog post.</p>
<h4 id="aspnet-composite-images">ASP.NET composite images</h4>
<p>As part of an effort to improve containerization performance, new ASP.NET Docker images are available that have a composite version of the runtime. This composite is built by compiling multiple MSIL assemblies into a single ready-to-run (R2R) output binary. Because these assemblies are embedded into a single image, jitting takes less time, and the startup performance of apps improves. The other big advantage of the composite over the regular ASP.NET image is that the composite images have a smaller size on disk.</p>
<p>There is a caveat to be aware of. Since composites have multiple assemblies embedded into one, they have tighter version coupling. Apps can't use custom versions of framework or ASP.NET binaries.</p>
<p>Composite images are available for the Alpine Linux, Jammy Chiseled, and Mariner Distroless platforms from the <code>mcr.microsoft.com/dotnet/nightly/aspnet</code> repo. The tags are listed with the <code>-composite</code> suffix on the <a href="https://hub.docker.com/_/microsoft-dotnet-nightly-aspnet" data-linktype="external">ASP.NET Docker page</a>.</p>
<h3 id="container-publishing">Container publishing</h3>
<ul>
<li><a href="#performance-and-compatibility" data-linktype="self-bookmark">Performance and compatibility</a></li>
<li><a href="#authentication" data-linktype="self-bookmark">Authentication</a></li>
<li><a href="#publish-to-targz-archive" data-linktype="self-bookmark">Publish to tar.gz archive</a></li>
</ul>
<h4 id="performance-and-compatibility">Performance and compatibility</h4>
<p>.NET 8 has improved performance for pushing containers to remote registries, especially Azure registries. Speedup comes from pushing layers in one operation and, for registries that don't support atomic uploads, a more reliable chunking mechanism.</p>
<p>These improvements also mean that more registries are supported: Harbor, Artifactory, Quay.io, and Podman.</p>
<h4 id="authentication">Authentication</h4>
<p>.NET 8 adds support for OAuth token exchange authentication (Azure Managed Identity) when pushing containers to registries. This support means that you can now push to registries like Azure Container Registry without any authentication errors. The following commands show an example publishing flow:</p>
<pre><code>&gt; az acr login -n &lt;your registry name&gt;
&gt; dotnet publish -r linux-x64 -p PublishProfile=DefaultContainer
</code></pre>
<p>For more information containerizing .NET apps, see <a href="https://learn.microsoft.com/en-us/dotnet/core/docker/publish-as-container" data-linktype="relative-path">Containerize a .NET app with dotnet publish</a>.</p>
<h4 id="publish-to-targz-archive">Publish to tar.gz archive</h4>
<p>Starting in .NET 8, you can create a container directly as a <em>tar.gz</em> archive. This feature is useful if your workflow isn't straightforward and requires that you, for example, run a scanning tool over your images before pushing them. Once the archive is created, you can move it, scan it, or load it into a local Docker toolchain.</p>
<p>To publish to an archive, add the <code>ContainerArchiveOutputPath</code> property to your <code>dotnet publish</code> command, for example:</p>
<pre><code>dotnet publish \
  -p PublishProfile=DefaultContainer \
  -p ContainerArchiveOutputPath=./images/sdk-container-demo.tar.gz
</code></pre>
<p>You can specify either a folder name or a path with a specific file name.</p>

<p>.NET 8 includes a new source generator that supports interoperating with COM interfaces. You can use the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcominterfaceattribute" data-linktype="absolute-path">GeneratedComInterfaceAttribute</a> to mark an interface as a COM interface for the source generator. The source generator will then generate code to enable calling from C# code to unmanaged code. It also generates code to enable calling from unmanaged code into C#. This source generator integrates with <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.libraryimportattribute" data-linktype="absolute-path">LibraryImportAttribute</a>, and you can use types with the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcominterfaceattribute" data-linktype="absolute-path">GeneratedComInterfaceAttribute</a> as parameters and return types in <code>LibraryImport</code>-attributed methods.</p>
<pre><code>using System.Runtime.InteropServices;
using System.Runtime.InteropServices.Marshalling;

[GeneratedComInterface]
[Guid("5401c312-ab23-4dd3-aa40-3cb4b3a4683e")]
interface IComInterface
{
    void DoWork();
}

internal class MyNativeLib
{
    [LibraryImport(nameof(MyNativeLib))]
    public static partial void GetComInterface(out IComInterface comInterface);
}
</code></pre>
<p>The source generator also supports the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcomclassattribute" data-linktype="absolute-path">GeneratedComClassAttribute</a> attribute to enable you to pass types that implement interfaces with the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcominterfaceattribute" data-linktype="absolute-path">GeneratedComInterfaceAttribute</a> attribute to unmanaged code. The source generator will generate the code necessary to expose a COM object that implements the interfaces and forwards calls to the managed implementation.</p>
<p>Methods on interfaces with the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcominterfaceattribute" data-linktype="absolute-path">GeneratedComInterfaceAttribute</a> attribute support all the same types as <code>LibraryImportAttribute</code>, and <code>LibraryImportAttribute</code> now supports <code>GeneratedComInterface</code>-attributed types and <code>GeneratedComClass</code>-attributed types.</p>
<p>If your C# code only uses a <code>GeneratedComInterface</code>-attributed interface to either wrap a COM object from unmanaged code or wrap a managed object from C# to expose to unmanaged code, you can use the options in the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcominterfaceattribute.options#system-runtime-interopservices-marshalling-generatedcominterfaceattribute-options" data-linktype="absolute-path">Options</a> property to customize which code will be generated. These options mean you don't need to write marshallers for scenarios that you know won't be used.</p>
<p>The source generator uses the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.strategybasedcomwrappers" data-linktype="absolute-path">StrategyBasedComWrappers</a> type to create and manage the COM object wrappers and the managed object wrappers. This new type handles providing the expected .NET user experience for COM interop, while providing customization points for advanced users. If your application has its own mechanism for defining types from COM or if you need to support scenarios that source-generated COM doesn't currently support, consider using the new <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.strategybasedcomwrappers" data-linktype="absolute-path">StrategyBasedComWrappers</a> type to add the missing features for your scenario and get the same .NET user experience for your COM types.</p>
<p>If you're using Visual Studio, new analyzers and code fixes make it easy to convert your existing COM interop code to use source-generated interop. Next to each interface that has the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.comimportattribute" data-linktype="absolute-path">ComImportAttribute</a>, a lightbulb offers an option to convert to source-generated interop. The fix changes the interface to use the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcominterfaceattribute" data-linktype="absolute-path">GeneratedComInterfaceAttribute</a> attribute. And next to every class that implements an interface with <code>GeneratedComInterfaceAttribute</code>, a lightbulb offers an option to add the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshalling.generatedcomclassattribute" data-linktype="absolute-path">GeneratedComClassAttribute</a> attribute to the type. Once your types are converted, you can move your <code>DllImport</code> methods to use <code>LibraryImportAttribute</code>.</p>
<h3 id="limitations-1">Limitations</h3>
<p>The COM source generator doesn't support apartment affinity, using the <code>new</code> keyword to activate a COM CoClass, and the following APIs:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.unmanagedtype#system-runtime-interopservices-unmanagedtype-idispatch" data-linktype="absolute-path">IDispatch</a>-based interfaces.</li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.unmanagedtype#system-runtime-interopservices-unmanagedtype-iinspectable" data-linktype="absolute-path">IInspectable</a>-based interfaces.</li>
<li>COM properties and events.</li>
</ul>
<h2 id="net-on-linux">.NET on Linux</h2>
<h3 id="minimum-support-baselines-for-linux">Minimum support baselines for Linux</h3>
<p>The minimum support baselines for Linux have been updated for .NET 8. .NET is built targeting Ubuntu 16.04, for all architectures. That's primarily important for defining the minimum <code>glibc</code> version for .NET 8. .NET 8 will fail to start on distro versions that include an older glibc, such as Ubuntu 14.04 or Red Hat Enterprise Linux 7.</p>
<p>For more information, see <a href="https://github.com/dotnet/core/blob/main/linux-support.md#red-hat-enterprise-linux-family-support" data-linktype="external">Red Hat Enterprise Linux Family support</a>.</p>
<h3 id="build-your-own-net-on-linux">Build your own .NET on Linux</h3>
<p>In previous .NET versions, you could build .NET from source, but it required you to create a "source tarball" from the <a href="https://github.com/dotnet/installer" data-linktype="external">dotnet/installer</a> repo commit that corresponded to a release. In .NET 8, that's no longer necessary and you can build .NET on Linux directly from the <a href="https://github.com/dotnet/dotnet" data-linktype="external">dotnet/dotnet</a> repository. That repo uses <a href="https://github.com/dotnet/source-build" data-linktype="external">dotnet/source-build</a> to build .NET runtimes, tools, and SDKs. This is the same build that Red Hat and Canonical use to build .NET.</p>
<p>Building in a container is the easiest approach for most people, since the <code>dotnet-buildtools/prereqs</code> container images contain all the required dependencies. For more information, see the <a href="https://github.com/dotnet/dotnet#building" data-linktype="external">build instructions</a>.</p>
<h2 id="cross-built-windows-apps">Cross-built Windows apps</h2>
<p>When you build apps that target Windows on non-Windows platforms, the resulting executable is now updated with any specified Win32 resources—for example, application icon, manifest, version information.</p>
<p>Previously, applications had to be built on Windows in order to have such resources. Fixing this gap in cross-building support has been a popular request, as it was a significant pain point affecting both infrastructure complexity and resource usage.</p>
<h2 id="aot-compilation-for-android-apps">AOT compilation for Android apps</h2>
<p>To decrease app size, .NET and .NET MAUI apps that target Android use <em>profiled</em> ahead-of-time (AOT) compilation mode when they're built in Release mode. Profiled AOT compilation affects fewer methods than regular AOT compilation. .NET 8 introduces the <code>&lt;AndroidStripILAfterAOT&gt;</code> property that lets you opt-in to further AOT compilation for Android apps to decrease app size even more.</p>
<pre><code>&lt;PropertyGroup&gt;
  &lt;AndroidStripILAfterAOT&gt;true&lt;/AndroidStripILAfterAOT&gt;
&lt;/PropertyGroup&gt;
</code></pre>
<p>By default, setting <code>AndroidStripILAfterAOT</code> to <code>true</code> overrides the default <code>AndroidEnableProfiledAot</code> setting, allowing (nearly) all methods that were AOT-compiled to be trimmed. You can also use profiled AOT and IL stripping together by explicitly setting both properties to <code>true</code>:</p>
<pre><code>&lt;PropertyGroup&gt;
  &lt;AndroidStripILAfterAOT&gt;true&lt;/AndroidStripILAfterAOT&gt;
  &lt;AndroidEnableProfiledAot&gt;true&lt;/AndroidEnableProfiledAot&gt;
&lt;/PropertyGroup&gt;
</code></pre>
<h2 id="code-analysis">Code analysis</h2>
<p>.NET 8 includes several new code analyzers and fixers to help verify that you're using .NET library APIs correctly and efficiently. The following table summarizes the new analyzers.</p>
<table>
<thead>
<tr>
<th>Rule ID</th>
<th>Category</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>CA1856</td>
<td>Performance</td>
<td>Fires when the <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.codeanalysis.constantexpectedattribute" data-linktype="absolute-path">ConstantExpectedAttribute</a> attribute is not applied correctly on a parameter.</td>
</tr>
<tr>
<td>CA1857</td>
<td>Performance</td>
<td>Fires when a parameter is annotated with <a href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.codeanalysis.constantexpectedattribute" data-linktype="absolute-path">ConstantExpectedAttribute</a> but the provided argument isn't a constant.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/code-analysis/quality-rules/ca1858" data-linktype="relative-path">CA1858</a></td>
<td>Performance</td>
<td>To determine whether a string starts with a given prefix, it's better to call <a href="https://learn.microsoft.com/en-us/dotnet/api/system.string.startswith" data-linktype="absolute-path">String.StartsWith</a> than to call <a href="https://learn.microsoft.com/en-us/dotnet/api/system.string.indexof" data-linktype="absolute-path">String.IndexOf</a> and then compare the result with zero.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/code-analysis/quality-rules/ca1859" data-linktype="relative-path">CA1859</a></td>
<td>Performance</td>
<td>This rule recommends upgrading the type of specific local variables, fields, properties, method parameters, and method return types from interface or abstract types to concrete types when possible. Using concrete types leads to higher quality generated code.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/code-analysis/quality-rules/ca1860" data-linktype="relative-path">CA1860</a></td>
<td>Performance</td>
<td>To determine whether a collection type has any elements, it's better to use <code>Length</code>, <code>Count</code>, or <code>IsEmpty</code> than to call <a href="https://learn.microsoft.com/en-us/dotnet/api/system.linq.enumerable.any" data-linktype="absolute-path">Enumerable.Any</a>.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/code-analysis/quality-rules/ca1861" data-linktype="relative-path">CA1861</a></td>
<td>Performance</td>
<td>Constant arrays passed as arguments aren't reused when called repeatedly, which implies a new array is created each time. To improve performance, consider extracting the array to a static readonly field.</td>
</tr>
<tr>
<td><a href="https://learn.microsoft.com/en-us/dotnet/fundamentals/code-analysis/quality-rules/ca1865-ca1867" data-linktype="relative-path">CA1865-CA1867</a></td>
<td>Performance</td>
<td>The char overload is a better-performing overload for a string with a single char.</td>
</tr>
<tr>
<td>CA2021</td>
<td>Reliability</td>
<td><a href="https://learn.microsoft.com/en-us/dotnet/api/system.linq.enumerable.cast#system-linq-enumerable-cast-1(system-collections-ienumerable)" data-linktype="absolute-path">Enumerable.Cast&lt;TResult&gt;(IEnumerable)</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.linq.enumerable.oftype#system-linq-enumerable-oftype-1(system-collections-ienumerable)" data-linktype="absolute-path">Enumerable.OfType&lt;TResult&gt;(IEnumerable)</a> require compatible types to function correctly. Widening and user-defined conversions aren't supported with generic types.</td>
</tr>
<tr>
<td>CA1510-CA1513</td>
<td>Maintainability</td>
<td>Throw helpers are simpler and more efficient than an <code>if</code> block constructing a new exception instance. These four analyzers were created for the following exceptions: <a href="https://learn.microsoft.com/en-us/dotnet/api/system.argumentnullexception" data-linktype="absolute-path">ArgumentNullException</a>, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.argumentexception" data-linktype="absolute-path">ArgumentException</a>, <a href="https://learn.microsoft.com/en-us/dotnet/api/system.argumentoutofrangeexception" data-linktype="absolute-path">ArgumentOutOfRangeException</a> and <a href="https://learn.microsoft.com/en-us/dotnet/api/system.objectdisposedexception" data-linktype="absolute-path">ObjectDisposedException</a>.</td>
</tr>
</tbody>
</table>
<h2 id="windows-presentation-foundation">Windows Presentation Foundation</h2>
<ul>
<li><a href="#hardware-acceleration" data-linktype="self-bookmark">Hardware acceleration</a></li>
<li><a href="#openfolderdialog" data-linktype="self-bookmark">OpenFolderDialog</a></li>
</ul>
<h3 id="hardware-acceleration">Hardware acceleration</h3>
<p>Previously, all WPF applications that were accessed remotely had to use software rendering, even if the system had hardware rendering capabilities. .NET 8 adds an option that lets you opt into hardware acceleration for Remote Desktop Protocol (RDP).</p>
<p>Hardware acceleration refers to the use of a computer's graphics processing unit (GPU) to speed up the rendering of graphics and visual effects in an application. This can result in improved performance and more seamless, responsive graphics. In contrast, software rendering relies solely on the computer's central processing unit (CPU) to render graphics, which can be slower and less effective.</p>
<p>To opt in, set the <code>Switch.System.Windows.Media.EnableHardwareAccelerationInRdp</code> configuration property to <code>true</code> in a <em>runtimeconfig.json</em> file. For more information, see <a href="https://learn.microsoft.com/en-us/dotnet/core/runtime-config/wpf#hardware-acceleration-in-rdp" data-linktype="relative-path">Hardware acceleration in RDP</a>.</p>
<h3 id="openfolderdialog">OpenFolderDialog</h3>
<p>WPF includes a new dialog box control called <code>OpenFolderDialog</code>. This control lets app users browse and select folders. Previously, app developers relied on third-party software to achieve this functionality.</p>
<pre><code>var openFolderDialog = new OpenFolderDialog()
{
    Title = "Select folder to open ...",
    InitialDirectory = Environment.GetFolderPath(Environment.SpecialFolder.ProgramFiles),
};

string folderName = "";
if (openFolderDialog.ShowDialog())
{
    folderName = openFolderDialog.FolderName;
}
</code></pre>
<p>For more information, see <a href="https://devblogs.microsoft.com/dotnet/wpf-file-dialog-improvements-in-dotnet-8/" data-linktype="external">WPF File Dialog Improvements in .NET 8 (.NET blog)</a>.</p>
<h2 id="nuget">NuGet</h2>
<p>Starting in .NET 8, NuGet verifies signed packages on Linux by default. NuGet continues to verify signed packages on Windows as well.</p>
<p>Most users shouldn't notice the verification. However, if you have an existing root certificate bundle located at <em>/etc/pki/ca-trust/extracted/pem/objsign-ca-bundle.pem</em>, you may see trust failures accompanied by <a href="https://learn.microsoft.com/en-us/nuget/reference/errors-and-warnings/nu3042" data-linktype="absolute-path">warning NU3042</a>.</p>
<p>You can opt out of verification by setting the environment variable <code>DOTNET_NUGET_SIGNATURE_VERIFICATION</code> to <code>false</code>.</p>
<h2 id="diagnostics">Diagnostics</h2>
<h3 id="c-hot-reload-supports-modifying-generics">C# Hot Reload supports modifying generics</h3>
<p>Starting in .NET 8, C# Hot Reload <a href="https://devblogs.microsoft.com/dotnet/hot-reload-generics/" data-linktype="external">supports modifying generic types and generic methods</a>. When you debug console, desktop, mobile, or WebAssembly applications with Visual Studio, you can apply changes to generic classes and generic methods in C# code or Razor pages. For more information, see the <a href="https://github.com/dotnet/roslyn/blob/main/docs/wiki/EnC-Supported-Edits.md" data-linktype="external">full list of edits supported by Roslyn</a></p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/core/compatibility/8.0" data-linktype="relative-path">Breaking changes in .NET 8</a></li>
<li><a href="https://learn.microsoft.com/en-us/aspnet/core/release-notes/aspnetcore-8.0" data-linktype="absolute-path">What's new in ASP.NET Core 8.0</a></li>
</ul>
<h3 id="net-blog">.NET blog</h3>
<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-rc2/" data-linktype="external">Announcing .NET 8 RC 2</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-rc1/" data-linktype="external">Announcing .NET 8 RC 1</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-preview-7/" data-linktype="external">Announcing .NET 8 Preview 7</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-preview-6/" data-linktype="external">Announcing .NET 8 Preview 6</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-preview-5/" data-linktype="external">Announcing .NET 8 Preview 5</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-preview-4/" data-linktype="external">Announcing .NET 8 Preview 4</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-preview-3/" data-linktype="external">Announcing .NET 8 Preview 3</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-preview-2/" data-linktype="external">Announcing .NET 8 Preview 2</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-8-preview-1/" data-linktype="external">Announcing .NET 8 Preview 1</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-rc-2/" data-linktype="external">ASP.NET Core updates in .NET 8 RC 2</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-rc-1/" data-linktype="external">ASP.NET Core updates in .NET 8 RC 1</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-preview-7/" data-linktype="external">ASP.NET Core updates in .NET 8 Preview 7</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-preview-6/" data-linktype="external">ASP.NET Core updates in .NET 8 Preview 6</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-preview-5/" data-linktype="external">ASP.NET Core updates in .NET 8 Preview 5</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-preview-4/" data-linktype="external">ASP.NET Core updates in .NET 8 Preview 4</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-preview-3/" data-linktype="external">ASP.NET Core updates in .NET 8 Preview 3</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-preview-2/" data-linktype="external">ASP.NET Core updates in .NET 8 Preview 2</a></li>
<li><a href="https://devblogs.microsoft.com/dotnet/asp-net-core-updates-in-dotnet-8-preview-1/" data-linktype="external">ASP.NET Core updates in .NET 8 Preview 1</a></li>
</ul>

							</div>

							
							
							<!-- </content> -->

						</main>





						<!-- recommendations section -->
						<!-- end recommendations section -->

						<!-- feedback section -->
<div data-bi-name="open-source-feedback-section" data-open-source-feedback-section="" hidden="">
				<div>
					<span aria-hidden="true">
						<span></span>
					</span>
					<span>Collaborate with us on GitHub					</span>
				</div>
				<span>
					The source for this content can be found on GitHub, where you can also create and review issues and pull requests. For more information, see <a href="https://learn.microsoft.com/contribute/content/dotnet/dotnet-contribute">our contributor guide</a>.
				</span>
			</div>
<section data-bi-name="feedback-section">
    <h2 id="feedback">Feedback</h2>

    <div>
        <p id="send-feedback-about">Submit and view feedback for</p>

        
    </div>

    
</section>
						<!-- end feedback section -->

						<!-- feedback report section -->
						<!-- end feedback report section -->

							<div id="ms--additional-resources-mobile" role="complementary" aria-label="Additional resources">
								<hr hidden="">
								<h2 id="ms--additional-resources-mobile-heading" hidden="">Additional resources</h2>
								
								
								
								
							</div>

						

					</div>

						<div id="ms--additional-resources" data-bi-name="pageactions" role="complementary" aria-label="Additional resources">
								<h2 id="ms--additional-resources-heading" hidden="">Additional resources</h2>
								
								
								
								<nav id="side-doc-outline" data-bi-name="intopic toc" role="navigation" aria-label="In this article">
									<h3>In this article</h3>
								</nav>
								
							</div>

				</div>
	<!--end of .mainContainer -->

	

		
	


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg 6.1 released (104 pts)]]></title>
            <link>http://www.ffmpeg.org/index.html#pr6.1</link>
            <guid>38227565</guid>
            <pubDate>Sat, 11 Nov 2023 04:14:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.ffmpeg.org/index.html#pr6.1">http://www.ffmpeg.org/index.html#pr6.1</a>, See on <a href="https://news.ycombinator.com/item?id=38227565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="index">

  <div>
    <p>
      <h2>
        A complete, cross-platform solution to record, convert and stream audio and video.
      </h2>
    </p> <!-- col -->
     <!-- col -->
  </div> <!-- row -->

  <div>
    <h3>Converting <strong>video</strong> and <strong>audio</strong> has never been so easy.
    </h3>
    <pre>$ ffmpeg -i input.mp4 output.avi</pre>
    
  </div> <!-- well -->

  <h2 id="news">
    <span>
      <a href="http://www.ffmpeg.org/main.rss"><strong></strong></a> &nbsp;
      <a href="https://twitter.com/FFmpeg"><strong><i></i></strong></a> &nbsp;
      <a href="https://www.facebook.com/ffmpeg"><strong><i></i></strong></a>
    </span>
    News
  </h2>

  <h3 id="pr6.1">November 10th, 2023, FFmpeg 6.1 "Heaviside"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_6.1">FFmpeg 6.1 "Heaviside"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>libaribcaption decoder</li>
    <li>Playdate video decoder and demuxer</li>
    <li>Extend VAAPI support for libva-win32 on Windows</li>
    <li>afireqsrc audio source filter</li>
    <li>arls filter</li>
    <li>ffmpeg CLI new option: -readrate_initial_burst</li>
    <li>zoneplate video source filter</li>
    <li>command support in the setpts and asetpts filters</li>
    <li>Vulkan decode hwaccel, supporting H264, HEVC and AV1</li>
    <li>color_vulkan filter</li>
    <li>bwdif_vulkan filter</li>
    <li>nlmeans_vulkan filter</li>
    <li>RivaTuner video decoder</li>
    <li>xfade_vulkan filter</li>
    <li>vMix video decoder</li>
    <li>Essential Video Coding parser, muxer and demuxer</li>
    <li>Essential Video Coding frame merge bsf</li>
    <li>bwdif_cuda filter</li>
    <li>Microsoft RLE video encoder</li>
    <li>Raw AC-4 muxer and demuxer</li>
    <li>Raw VVC bitstream parser, muxer and demuxer</li>
    <li>Bitstream filter for editing metadata in VVC streams</li>
    <li>Bitstream filter for converting VVC from MP4 to Annex B</li>
    <li>scale_vt filter for videotoolbox</li>
    <li>transpose_vt filter for videotoolbox</li>
    <li>support for the P_SKIP hinting to speed up libx264 encoding</li>
    <li>Support HEVC,VP9,AV1 codec in enhanced flv format</li>
    <li>apsnr and asisdr audio filters</li>
    <li>OSQ demuxer and decoder</li>
    <li>Support HEVC,VP9,AV1 codec fourcclist in enhanced rtmp protocol</li>
    <li>CRI USM demuxer</li>
    <li>ffmpeg CLI '-top' option deprecated in favor of the setfield filter</li>
    <li>VAAPI AV1 encoder</li>
    <li>ffprobe XML output schema changed to account for multiple variable-fields elements within the same parent element</li>
    <li>ffprobe -output_format option added as an alias of -of</li>
  </ul>
  <p>
    This release had been overdue for at least half a year, but due to constant activity in the repository,
    had to be delayed, and we were finally able to branch off the release recently, before some of the large
    changes scheduled for 7.0 were merged.
  </p>
  <p>
    Internally, we have had a number of changes too. The FFT, MDCT, DCT and DST implementation used for codecs
    and filters has been fully replaced with the faster libavutil/tx (full article about it coming soon).<br>
    This also led to a reduction in the the size of the compiled binary, which can be noticeable in small builds.<br>
    There was a very large reduction in the total amount of allocations being done on each frame throughout video decoders,
    reducing overhead.<br>
    RISC-V optimizations for many parts of our DSP code have been merged, with mainly the large decoders being left.<br>
    There was an effort to improve the correctness of timestamps and frame durations of each packet, increasing the
    accurracy of variable frame rate video.
  </p>
  <p>
    Next major release will be version 7.0, scheduled to be released in February. We will attempt to better stick
    to the new release schedule we announced at the start of this year.
  </p>
  <p>
    We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.
  </p>

  <h3 id="vk2023">May 31st, 2023, Vulkan decoding</h3>
  <p>
    A few days ago, Vulkan-powered decoding hardware acceleration code was merged into the codebase.
    This is the first vendor-generic and platform-generic decode acceleration API, enabling the
    same code to be used on multiple platforms, with very minimal overhead.
    This is also the first multi-threaded hardware decoding API, and our code makes full use of this,
    saturating all available decode engines the hardware exposes.
  </p>
  <p>
    Those wishing to test the code can read our
    <a href="https://trac.ffmpeg.org/wiki/HWAccelIntro#Vulkan">documentation page</a>.
    For those who would like to integrate FFmpeg's Vulkan code to demux, parse, decode, and receive
    a VkImage to present or manipulate, documentation and examples are available in our source tree.
    Currently, using the latest available git checkout of our
    <a href="https://git.videolan.org/?p=ffmpeg.git;a=summary">repository</a> is required.
    The functionality will be included in stable branches with the release of version 6.1, due
    to be released soon.
  </p><p>
    As this is also the first practical implementation of the specifications, bugs may be present,
    particularly in drivers, and, although passing verification, the implementation itself.
    New codecs, and encoding support are also being worked on, by both the Khronos organization
    for standardizing, and us as implementing it, and giving feedback on improving.
  </p>

  <h3 id="pr6.0">February 28th, 2023, FFmpeg 6.0 "Von Neumann"</h3>
  <p>
    A new major release, <a href="http://www.ffmpeg.org/download.html#release_6.0">FFmpeg 6.0 "Von Neumann"</a>,
    is now available for download. This release has many new encoders and decoders, filters,
    ffmpeg CLI tool improvements, and also, changes the way releases are done. All major
    releases will now bump the version of the ABI. We plan to have a new major release each
    year. Another release-specific change is that deprecated APIs will be removed after 3
    releases, upon the next major bump.
    This means that releases will be done more often and will be more organized.
  </p>
  <p>
    New decoders featured are Bonk, RKA, Radiance, SC-4, APAC, VQC, WavArc and a few ADPCM formats.
    QSV and NVenc now support AV1 encoding. The FFmpeg CLI (we usually reffer to it as ffmpeg.c
    to avoid confusion) has speed-up improvements due to threading, as well as statistics options,
    and the ability to pass option values for filters from a file. There are quite a few new audio
    and video filters, such as adrc, showcwt, backgroundkey and ssim360, with a few hardware ones too.
    Finally, the release features many behind-the-scenes changes, including a new FFT and MDCT
    implementation used in codecs (expect a blog post about this soon), numerous bugfixes, better
    ICC profile handling and colorspace signalling improvement, introduction of a number of RISC-V
    vector and scalar assembly optimized routines, and a few new improved APIs, which can be viewed
    in the doc/APIchanges file in our tree.
    A few submitted features, such as the Vulkan improvements and more FFT optimizations will be in the
    next minor release, 6.1, which we plan to release soon, in line with our new release schedule.
    Some highlights are:
  </p>
  <ul>
    <li>Radiance HDR image support</li>
    <li>ddagrab (Desktop Duplication) video capture filter</li>
    <li>ffmpeg -shortest_buf_duration option</li>
    <li>ffmpeg now requires threading to be built</li>
    <li>ffmpeg now runs every muxer in a separate thread</li>
    <li>Add new mode to cropdetect filter to detect crop-area based on motion vectors and edges</li>
    <li>VAAPI decoding and encoding for 10/12bit 422, 10/12bit 444 HEVC and VP9</li>
    <li>WBMP (Wireless Application Protocol Bitmap) image format</li>
    <li>a3dscope filter</li>
    <li>bonk decoder and demuxer</li>
    <li>Micronas SC-4 audio decoder</li>
    <li>LAF demuxer</li>
    <li>APAC decoder and demuxer</li>
    <li>Media 100i decoders</li>
    <li>DTS to PTS reorder bsf</li>
    <li>ViewQuest VQC decoder</li>
    <li>backgroundkey filter</li>
    <li>nvenc AV1 encoding support</li>
    <li>MediaCodec decoder via NDKMediaCodec</li>
    <li>MediaCodec encoder</li>
    <li>oneVPL support for QSV</li>
    <li>QSV AV1 encoder</li>
    <li>QSV decoding and encoding for 10/12bit 422, 10/12bit 444 HEVC and VP9</li>
    <li>showcwt multimedia filter</li>
    <li>corr video filter</li>
    <li>adrc audio filter</li>
    <li>afdelaysrc audio filter</li>
    <li>WADY DPCM decoder and demuxer</li>
    <li>CBD2 DPCM decoder</li>
    <li>ssim360 video filter</li>
    <li>ffmpeg CLI new options: -stats_enc_pre[_fmt], -stats_enc_post[_fmt], -stats_mux_pre[_fmt]</li>
    <li>hstack_vaapi, vstack_vaapi and xstack_vaapi filters</li>
    <li>XMD ADPCM decoder and demuxer</li>
    <li>media100 to mjpegb bsf</li>
    <li>ffmpeg CLI new option: -fix_sub_duration_heartbeat</li>
    <li>WavArc decoder and demuxer</li>
    <li>CrystalHD decoders deprecated</li>
    <li>SDNS demuxer</li>
    <li>RKA decoder and demuxer</li>
    <li>filtergraph syntax in ffmpeg CLI now supports passing file contents as option values</li>
    <li>hstack_qsv, vstack_qsv and xstack_qsv filters</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr5.1">July 22nd, 2022, FFmpeg 5.1 "Riemann"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_5.1">FFmpeg 5.1 "Riemann"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>add ipfs/ipns protocol support</li>
    <li>dialogue enhance audio filter</li>
    <li>dropped obsolete XvMC hwaccel</li>
    <li>pcm-bluray encoder</li>
    <li>DFPWM audio encoder/decoder and raw muxer/demuxer</li>
    <li>SITI filter</li>
    <li>Vizrt Binary Image encoder/decoder</li>
    <li>avsynctest source filter</li>
    <li>feedback video filter</li>
    <li>pixelize video filter</li>
    <li>colormap video filter</li>
    <li>colorchart video source filter</li>
    <li>multiply video filter</li>
    <li>PGS subtitle frame merge bitstream filter</li>
    <li>blurdetect filter</li>
    <li>tiltshelf audio filter</li>
    <li>QOI image format support</li>
    <li>ffprobe -o option</li>
    <li>virtualbass audio filter</li>
    <li>VDPAU AV1 hwaccel</li>
    <li>PHM image format support</li>
    <li>remap_opencl filter</li>
    <li>added chromakey_cuda filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr5.0">January 17th, 2022, FFmpeg 5.0 "Lorentz"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_5.0">FFmpeg 5.0 "Lorentz"</a>, a new
    major release, is now available! For this long-overdue release, a major effort
    underwent to remove the old encode/decode APIs and replace them with an
    N:M-based API, the entire libavresample library was removed, libswscale
    has a new, easier to use AVframe-based API, the Vulkan code was much improved,
    many new filters were added, including libplacebo integration, and finally,
    DoVi support was added, including tonemapping and remuxing. The default
    AAC encoder settings were also changed to improve quality.
    Some of the changelog highlights:
  </p>
  <ul>
    <li>ADPCM IMA Westwood encoder</li>
    <li>Westwood AUD muxer</li>
    <li>ADPCM IMA Acorn Replay decoder</li>
    <li>Argonaut Games CVG demuxer</li>
    <li>Argonaut Games CVG muxer</li>
    <li>Concatf protocol</li>
    <li>afwtdn audio filter</li>
    <li>audio and video segment filters</li>
    <li>Apple Graphics (SMC) encoder</li>
    <li>hsvkey and hsvhold video filters</li>
    <li>adecorrelate audio filter</li>
    <li>atilt audio filter</li>
    <li>grayworld video filter</li>
    <li>AV1 Low overhead bitstream format muxer</li>
    <li>swscale slice threading</li>
    <li>MSN Siren decoder</li>
    <li>scharr video filter</li>
    <li>apsyclip audio filter</li>
    <li>morpho video filter</li>
    <li>amr parser</li>
    <li>(a)latency filters</li>
    <li>GEM Raster image decoder</li>
    <li>asdr audio filter</li>
    <li>speex decoder</li>
    <li>limitdiff video filter</li>
    <li>xcorrelate video filter</li>
    <li>varblur video filter</li>
    <li>huesaturation video filter</li>
    <li>colorspectrum source video filter</li>
    <li>RTP packetizer for uncompressed video (RFC 4175)</li>
    <li>bitpacked encoder</li>
    <li>VideoToolbox VP9 hwaccel</li>
    <li>VideoToolbox ProRes hwaccel</li>
    <li>support loongarch.</li>
    <li>aspectralstats audio filter</li>
    <li>adynamicsmooth audio filter</li>
    <li>libplacebo filter</li>
    <li>vflip_vulkan, hflip_vulkan and flip_vulkan filters</li>
    <li>adynamicequalizer audio filter</li>
    <li>yadif_videotoolbox filter</li>
    <li>VideoToolbox ProRes encoder</li>
    <li>anlmf audio filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="irc2021">June 19th, 2021, IRC</h3>
  <p>
    We have a new IRC home at Libera Chat
    now! Feel free to join us at #ffmpeg and #ffmpeg-devel. More info at <a href="https://ffmpeg.org/contact.html#IRCChannels">contact#IRCChannels</a>
  </p>

  <h3 id="pr4.4">April 8th, 2021, FFmpeg 4.4 "Rao"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_4.4">FFmpeg 4.4 "Rao"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>AudioToolbox output device</li>
    <li>MacCaption demuxer</li>
    <li>PGX decoder</li>
    <li>chromanr video filter</li>
    <li>VDPAU accelerated HEVC 10/12bit decoding</li>
    <li>ADPCM IMA Ubisoft APM encoder</li>
    <li>Rayman 2 APM muxer</li>
    <li>AV1 encoding support SVT-AV1</li>
    <li>Cineform HD encoder</li>
    <li>ADPCM Argonaut Games encoder</li>
    <li>Argonaut Games ASF muxer</li>
    <li>AV1 Low overhead bitstream format demuxer</li>
    <li>RPZA video encoder</li>
    <li>ADPCM IMA MOFLEX decoder</li>
    <li>MobiClip FastAudio decoder</li>
    <li>MobiClip video decoder</li>
    <li>MOFLEX demuxer</li>
    <li>MODS demuxer</li>
    <li>PhotoCD decoder</li>
    <li>MCA demuxer</li>
    <li>AV1 decoder (Hardware acceleration used only)</li>
    <li>SVS demuxer</li>
    <li>Argonaut Games BRP demuxer</li>
    <li>DAT demuxer</li>
    <li>aax demuxer</li>
    <li>IPU decoder, parser and demuxer</li>
    <li>Intel QSV-accelerated AV1 decoding</li>
    <li>Argonaut Games Video decoder</li>
    <li>libwavpack encoder removed</li>
    <li>ACE demuxer</li>
    <li>AVS3 demuxer</li>
    <li>AVS3 video decoder via libuavs3d</li>
    <li>Cintel RAW decoder</li>
    <li>VDPAU accelerated VP9 10/12bit decoding</li>
    <li>afreqshift and aphaseshift filters</li>
    <li>High Voltage Software ADPCM encoder</li>
    <li>LEGO Racers ALP (.tun &amp; .pcm) muxer</li>
    <li>AV1 VAAPI decoder</li>
    <li>adenorm filter</li>
    <li>ADPCM IMA AMV encoder</li>
    <li>AMV muxer</li>
    <li>NVDEC AV1 hwaccel</li>
    <li>DXVA2/D3D11VA hardware accelerated AV1 decoding</li>
    <li>speechnorm filter</li>
    <li>SpeedHQ encoder</li>
    <li>asupercut filter</li>
    <li>asubcut filter</li>
    <li>Microsoft Paint (MSP) version 2 decoder</li>
    <li>Microsoft Paint (MSP) demuxer</li>
    <li>AV1 monochrome encoding support via libaom &gt;= 2.0.1</li>
    <li>asuperpass and asuperstop filter</li>
    <li>shufflepixels filter</li>
    <li>tmidequalizer filter</li>
    <li>estdif filter</li>
    <li>epx filter</li>
    <li>Dolby E parser</li>
    <li>shear filter</li>
    <li>kirsch filter</li>
    <li>colortemperature filter</li>
    <li>colorcontrast filter</li>
    <li>PFM encoder</li>
    <li>colorcorrect filter</li>
    <li>binka demuxer</li>
    <li>XBM parser</li>
    <li>xbm_pipe demuxer</li>
    <li>colorize filter</li>
    <li>CRI parser</li>
    <li>aexciter audio filter</li>
    <li>exposure video filter</li>
    <li>monochrome video filter</li>
    <li>setts bitstream filter</li>
    <li>vif video filter</li>
    <li>OpenEXR image encoder</li>
    <li>Simbiosis IMX decoder</li>
    <li>Simbiosis IMX demuxer</li>
    <li>Digital Pictures SGA demuxer and decoders</li>
    <li>TTML subtitle encoder and muxer</li>
    <li>identity video filter</li>
    <li>msad video filter</li>
    <li>gophers protocol</li>
    <li>RIST protocol via librist</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr4.3">June 15th, 2020, FFmpeg 4.3 "4:3"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_4.3">FFmpeg 4.3 "4:3"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>v360 filter</li>
    <li>Intel QSV-accelerated MJPEG decoding</li>
    <li>Intel QSV-accelerated VP9 decoding</li>
    <li>Support for TrueHD in mp4</li>
    <li>Support AMD AMF encoder on Linux (via Vulkan)</li>
    <li>IMM5 video decoder</li>
    <li>ZeroMQ protocol</li>
    <li>support Sipro ACELP.KELVIN decoding</li>
    <li>streamhash muxer</li>
    <li>sierpinski video source</li>
    <li>scroll video filter</li>
    <li>photosensitivity filter</li>
    <li>anlms filter</li>
    <li>arnndn filter</li>
    <li>bilateral filter</li>
    <li>maskedmin and maskedmax filters</li>
    <li>VDPAU VP9 hwaccel</li>
    <li>median filter</li>
    <li>QSV-accelerated VP9 encoding</li>
    <li>AV1 encoding support via librav1e</li>
    <li>AV1 frame merge bitstream filter</li>
    <li>AV1 Annex B demuxer</li>
    <li>axcorrelate filter</li>
    <li>mvdv decoder</li>
    <li>mvha decoder</li>
    <li>MPEG-H 3D Audio support in mp4</li>
    <li>thistogram filter</li>
    <li>freezeframes filter</li>
    <li>Argonaut Games ADPCM decoder</li>
    <li>Argonaut Games ASF demuxer</li>
    <li>xfade video filter</li>
    <li>xfade_opencl filter</li>
    <li>afirsrc audio filter source</li>
    <li>pad_opencl filter</li>
    <li>Simon &amp; Schuster Interactive ADPCM decoder</li>
    <li>Real War KVAG demuxer</li>
    <li>CDToons video decoder</li>
    <li>siren audio decoder</li>
    <li>Rayman 2 ADPCM decoder</li>
    <li>Rayman 2 APM demuxer</li>
    <li>cas video filter</li>
    <li>High Voltage Software ADPCM decoder</li>
    <li>LEGO Racers ALP (.tun &amp; .pcm) demuxer</li>
    <li>AMQP 0-9-1 protocol (RabbitMQ)</li>
    <li>Vulkan support</li>
    <li>avgblur_vulkan, overlay_vulkan, scale_vulkan and chromaber_vulkan filters</li>
    <li>ADPCM IMA MTF decoder</li>
    <li>FWSE demuxer</li>
    <li>DERF DPCM decoder</li>
    <li>DERF demuxer</li>
    <li>CRI HCA decoder</li>
    <li>CRI HCA demuxer</li>
    <li>overlay_cuda filter</li>
    <li>switch from AvxSynth to AviSynth+ on Linux</li>
    <li>mv30 decoder</li>
    <li>Expanded styling support for 3GPP Timed Text Subtitles (movtext)</li>
    <li>WebP parser</li>
    <li>tmedian filter</li>
    <li>maskedthreshold filter</li>
    <li>Support for muxing pcm and pgs in m2ts</li>
    <li>Cunning Developments ADPCM decoder</li>
    <li>asubboost filter</li>
    <li>Pro Pinball Series Soundbank demuxer</li>
    <li>pcm_rechunk bitstream filter</li>
    <li>scdet filter</li>
    <li>NotchLC decoder</li>
    <li>gradients source video filter</li>
    <li>MediaFoundation encoder wrapper</li>
    <li>untile filter</li>
    <li>Simon &amp; Schuster Interactive ADPCM encoder</li>
    <li>PFM decoder</li>
    <li>dblur video filter</li>
    <li>Real War KVAG muxer</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="photosensitivity">October 5th, 2019, Bright Lights</h3>
  <p>
  FFmpeg has added a realtime bright flash removal filter to libavfilter.
  </p>
  <p>
  Note that this filter is not FDA approved, nor are we medical professionals.
  Nor has this filter been tested with anyone who has photosensitive epilepsy.
  FFmpeg and its photosensitivity filter are not making any medical claims.
  </p>
  <p>
  That said, this is a new video filter that may help photosensitive people
  watch tv, play video games or even be used with a VR headset to block
  out epiletic triggers such as filtered sunlight when they are outside.
  Or you could use it against those annoying white flashes on your tv screen.
  The filter fails on some input, such as the
  <a href="https://www.youtube.com/watch?v=8L_9hXnUzRk">Incredibles 2 Screen Slaver</a>
  scene. It is not perfect. If you have other clips that you want this filter to
  work better on, please report them to us on our <a href="http://trac.ffmpeg.org/">trac</a>.
  </p>
  <p>
  <a href="http://ffmpeg.org/~compn/output20p8.mp4">See for yourself</a>.
  Example was made with -vf photosensitivity=20:0.8
  </p>
  <p>
  We are not professionals. Please use this in your medical studies to
  advance epilepsy research. If you decide to use this in a medical
  setting, or make a hardware hdmi input output realtime tv filter,
  or find another use for this, <a href="mailto:compn@ffmpeg.org">please let me know</a>.
  This filter was a feature request of mine
  <a href="https://trac.ffmpeg.org/ticket/2104">since 2013</a>.
  </p>

  <h3 id="pr4.2">August 5th, 2019, FFmpeg 4.2 "Ada"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_4.2">FFmpeg 4.2 "Ada"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>tpad filter</li>
    <li>AV1 decoding support through libdav1d</li>
    <li>dedot filter</li>
    <li>chromashift and rgbashift filters</li>
    <li>freezedetect filter</li>
    <li>truehd_core bitstream filter</li>
    <li>dhav demuxer</li>
    <li>PCM-DVD encoder</li>
    <li>GIF parser</li>
    <li>vividas demuxer</li>
    <li>hymt decoder</li>
    <li>anlmdn filter</li>
    <li>maskfun filter</li>
    <li>hcom demuxer and decoder</li>
    <li>ARBC decoder</li>
    <li>libaribb24 based ARIB STD-B24 caption support (profiles A and C)</li>
    <li>Support decoding of HEVC 4:4:4 content in nvdec and cuviddec</li>
    <li>removed libndi-newtek</li>
    <li>agm decoder</li>
    <li>KUX demuxer</li>
    <li>AV1 frame split bitstream filter</li>
    <li>lscr decoder</li>
    <li>lagfun filter</li>
    <li>asoftclip filter</li>
    <li>Support decoding of HEVC 4:4:4 content in vdpau</li>
    <li>colorhold filter</li>
    <li>xmedian filter</li>
    <li>asr filter</li>
    <li>showspatial multimedia filter</li>
    <li>VP4 video decoder</li>
    <li>IFV demuxer</li>
    <li>derain filter</li>
    <li>deesser filter</li>
    <li>mov muxer writes tracks with unspecified language instead of English by default</li>
    <li>added support for using clang to compile CUDA kernels</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr4.1">November 6th, 2018, FFmpeg 4.1 "al-Khwarizmi"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_4.1">FFmpeg 4.1 "al-Khwarizmi"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>deblock filter</li>
    <li>tmix filter</li>
    <li>amplify filter</li>
    <li>fftdnoiz filter</li>
    <li>aderivative and aintegral audio filters</li>
    <li>pal75bars and pal100bars video filter sources</li>
    <li>mbedTLS based TLS support</li>
    <li>adeclick and adeclip filters</li>
    <li>libtensorflow backend for DNN based filters like srcnn</li>
    <li>VC1 decoder is now bit-exact</li>
    <li>ATRAC9 decoder</li>
    <li>lensfun wrapper filter</li>
    <li>colorconstancy filter</li>
    <li>AVS2 video decoder via libdavs2</li>
    <li>IMM4 video decoder</li>
    <li>Brooktree ProSumer video decoder</li>
    <li>MatchWare Screen Capture Codec decoder</li>
    <li>WinCam Motion Video decoder</li>
    <li>1D LUT filter (lut1d)</li>
    <li>RemotelyAnywhere Screen Capture decoder</li>
    <li>cue and acue filters</li>
    <li>Support for AV1 in MP4 and Matroska/WebM</li>
    <li>transpose_npp filter</li>
    <li>AVS2 video encoder via libxavs2</li>
    <li>amultiply filter</li>
    <li>Block-Matching 3d (bm3d) denoising filter</li>
    <li>acrossover filter</li>
    <li>ilbc decoder</li>
    <li>audio denoiser as afftdn filter</li>
    <li>AV1 parser</li>
    <li>sinc audio filter source</li>
    <li>chromahold filter</li>
    <li>setparams filter</li>
    <li>vibrance filter</li>
    <li>S12M timecode decoding in h264</li>
    <li>xstack filter</li>
    <li>(a)graphmonitor filter</li>
    <li>yadif_cuda filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr4.0">April 20th, 2018, FFmpeg 4.0 "Wu"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_4.0">FFmpeg 4.0 "Wu"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>Bitstream filters for editing metadata in H.264, HEVC and MPEG-2 streams</li>
    <li>Experimental MagicYUV encoder</li>
    <li>TiVo ty/ty+ demuxer</li>
    <li>Intel QSV-accelerated MJPEG encoding</li>
    <li>native aptX and aptX HD encoder and decoder</li>
    <li>NVIDIA NVDEC-accelerated H.264, HEVC, MJPEG, MPEG-1/2/4, VC1, VP8/9 hwaccel decoding</li>
    <li>Intel QSV-accelerated overlay filter</li>
    <li>mcompand audio filter</li>
    <li>acontrast audio filter</li>
    <li>OpenCL overlay filter</li>
    <li>video mix filter</li>
    <li>video normalize filter</li>
    <li>audio lv2 wrapper filter</li>
    <li>VAAPI MJPEG and VP8 decoding</li>
    <li>AMD AMF H.264 and HEVC encoders</li>
    <li>video fillborders filter</li>
    <li>video setrange filter</li>
    <li>support LibreSSL (via libtls)</li>
    <li>Dropped support for building for Windows XP. The minimum supported Windows version is Windows Vista.</li>
    <li>deconvolve video filter</li>
    <li>entropy video filter</li>
    <li>hilbert audio filter source</li>
    <li>aiir audio filter</li>
    <li>Removed the ffserver program</li>
    <li>Removed the ffmenc and ffmdec muxer and demuxer</li>
    <li>VideoToolbox HEVC encoder and hwaccel</li>
    <li>VAAPI-accelerated ProcAmp (color balance), denoise and sharpness filters</li>
    <li>Add android_camera indev</li>
    <li>codec2 en/decoding via libcodec2</li>
    <li>native SBC encoder and decoder</li>
    <li>drmeter audio filter</li>
    <li>hapqa_extract bitstream filter</li>
    <li>filter_units bitstream filter</li>
    <li>AV1 Support through libaom</li>
    <li>E-AC-3 dependent frames support</li>
    <li>bitstream filter for extracting E-AC-3 core</li>
    <li>Haivision SRT protocol via libsrt</li>
    <li>vfrdet filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr3.4">October 15th, 2017, FFmpeg 3.4 "Cantor"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_3.4">FFmpeg 3.4 "Cantor"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>deflicker video filter</li>
    <li>doubleweave video filter</li>
    <li>lumakey video filter</li>
    <li>pixscope video filter</li>
    <li>oscilloscope video filter</li>
    <li>update cuvid/nvenc headers to Video Codec SDK 8.0.14</li>
    <li>afir audio filter</li>
    <li>scale_cuda CUDA based video scale filter</li>
    <li>librsvg support for svg rasterization</li>
    <li>crossfeed audio filter</li>
    <li>spec compliant VP9 muxing support in MP4</li>
    <li>surround audio filter</li>
    <li>sofalizer filter switched to libmysofa</li>
    <li>Gremlin Digital Video demuxer and decoder</li>
    <li>headphone audio filter</li>
    <li>superequalizer audio filter</li>
    <li>roberts video filter</li>
    <li>additional frame format support for Interplay MVE movies</li>
    <li>support for decoding through D3D11VA in ffmpeg</li>
    <li>limiter video filter</li>
    <li>libvmaf video filter</li>
    <li>Dolby E decoder and SMPTE 337M demuxer</li>
    <li>unpremultiply video filter</li>
    <li>tlut2 video filter</li>
    <li>floodfill video filter</li>
    <li>pseudocolor video filter</li>
    <li>raw G.726 muxer and demuxer, left- and right-justified</li>
    <li>NewTek NDI input/output device</li>
    <li>FITS demuxer and decoder</li>
    <li>FITS muxer and encoder</li>
    <li>despill video filter</li>
    <li>haas audio filter</li>
    <li>SUP/PGS subtitle muxer</li>
    <li>convolve video filter</li>
    <li>VP9 tile threading support</li>
    <li>KMS screen grabber</li>
    <li>CUDA thumbnail filter</li>
    <li>V4L2 mem2mem HW assisted codecs</li>
    <li>Rockchip MPP hardware decoding</li>
    <li>vmafmotion video filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr3.3">April 13th, 2017, FFmpeg 3.3 "Hilbert"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_3.3">FFmpeg 3.3 "Hilbert"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>Apple Pixlet decoder</li>
    <li>NewTek SpeedHQ decoder</li>
    <li>QDMC audio decoder</li>
    <li>PSD (Photoshop Document) decoder</li>
    <li>FM Screen Capture decoder</li>
    <li>ScreenPressor decoder</li>
    <li>XPM decoder</li>
    <li>DNxHR decoder fixes for HQX and high resolution videos</li>
    <li>ClearVideo decoder (partial)</li>
    <li>16.8 and 24.0 floating point PCM decoder</li>
    <li>Intel QSV-accelerated VP8 video decoding</li>
    <li>native Opus encoder</li>
    <li>DNxHR 444 and HQX encoding</li>
    <li>Quality improvements for the (M)JPEG encoder</li>
    <li>VAAPI-accelerated MPEG-2 and VP8 encoding</li>
    <li>premultiply video filter</li>
    <li>abitscope multimedia filter</li>
    <li>readeia608 filter</li>
    <li>threshold filter</li>
    <li>midequalizer filter</li>
    <li>MPEG-7 Video Signature filter</li>
    <li>add internal ebur128 library, remove external libebur128 dependency</li>
    <li>Intel QSV video scaling and deinterlacing filters</li>
    <li>Sample Dump eXchange demuxer</li>
    <li>MIDI Sample Dump Standard demuxer</li>
    <li>Scenarist Closed Captions demuxer and muxer</li>
    <li>Support MOV with multiple sample description tables</li>
    <li>Pro-MPEG CoP #3-R2 FEC protocol</li>
    <li>Support for spherical videos</li>
    <li>CrystalHD decoder moved to new decode API</li>
    <li>configure now fails if autodetect-libraries are requested but not found</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="gsoc2016finalreport">October 30th, 2016, Results: Summer Of Code 2016.</h3>
  <p>
    This has been a long time coming but we wanted to give a proper closure to our participation in this run of the program and it takes time. Sometimes it's just to get the final report for each project trimmed down, others, is finalizing whatever was still in progress when the program finished: final patches need to be merged, TODO lists stabilized, future plans agreed; you name it.
  </p>
  <p>
    Without further ado, here's the silver-lining for each one of the projects we sought to complete during this Summer of Code season:
  </p>
  <h4>FFv1 (Mentor: Michael Niedermayer)</h4>
  <p>
    Stanislav Dolganov designed and implemented experimental support for motion estimation and compensation in the lossless FFV1 codec. The design and implementation is based on the snow video codec, which uses OBMC. Stanislav's work proved that significant compression gains can be achieved with inter frame compression. FFmpeg welcomes Stanislav to continue working beyond this proof of concept and bring its advances into the official FFV1 specification within the IETF.
  </p>
  <h4>Self test coverage (Mentor: Michael Niedermayer)</h4>
  <p>
    Petru Rares Sincraian added several self-tests to FFmpeg and successfully went through the in-some-cases tedious process of fine tuning tests parameters to avoid known and hard to avoid problems, like checksum mismatches due to rounding errors on the myriad of platforms we support. His work has improved the code coverage of our self tests considerably.
  </p>
  <h4>MPEG-4 ALS encoder implementation (Mentor: Thilo Borgmann)</h4>
  <p>
    Umair Khan updated and integrated the ALS encoder to fit in the current FFmpeg codebase. He also implemented a missing feature for the ALS decoder that enables floating-point sample decoding. FFmpeg support for MPEG-4 ALS has been improved significantly by Umair's work. We welcome him to keep maintaining his improvements and hope for great contributions to come.
  </p>
  <h4>Tee muxer improvements (Mentor: Marton Balint)</h4>
  <p>
    Ján Sebechlebský's generic goal was to improve the tee muxer so it tolerated blocking IO and allowed transparent error recovery. During the design phase it turned out that this functionality called for a separate muxer, so Ján spent his summer working on the so-called FIFO muxer, gradually fixing issues all over the codebase. He succeeded in his task, and the FIFO muxer is now part of the main repository, alongside several other improvements he made in the process.
  </p>
  <h4>TrueHD encoder (Mentor: Rostislav Pehlivanov)</h4>
  <p>
    Jai Luthra's objective was to update the out-of-tree and pretty much abandoned MLP (Meridian Lossless Packing) encoder for libavcodec and improve it to enable encoding to the TrueHD format. For the qualification period the encoder was updated such that it was usable and throughout the summer, successfully improved adding support for multi-channel audio and TrueHD encoding. Jai's code has been merged into the main repository now. While a few problems remain with respect to LFE channel and 32 bit sample handling, these are in the process of being fixed such that effort can be finally put in improving the encoder's speed and efficiency.
  </p>
  <h4>Motion interpolation filter (Mentor: Paul B Mahol)</h4>
  <p>
    Davinder Singh investigated existing motion estimation and interpolation approaches from the available literature and previous work by our own: Michael Niedermayer, and implemented filters based on this research. These filters allow motion interpolating frame rate conversion to be applied to a video, for example, to create a slow motion effect or change the frame rate while smoothly interpolating the video along the motion vectors. There's still work to be done to call these filters 'finished', which is rather hard all things considered, but we are looking optimistically at their future.
  </p>
  <p>
    And that's it. We are happy with the results of the program and immensely thankful for the opportunity of working with such an amazing set of students. We can be a tough crowd but our mentors did an amazing job at hand holding our interns through their journey. Thanks also to Google for this wonderful program and to everyone that made room in their busy lives to help making GSoC2016 a success. See you in 2017!
  </p>
  <h3 id="sdl1">September 24th, 2016, SDL1 support dropped.</h3>
  <p>
    Support for the SDL1 library has been dropped, due to it no longer being maintained (as of
    January, 2012) and it being superseded by the SDL2 library. As a result, the SDL1 output device
    has also been removed and replaced by an SDL2 implementation. Both the ffplay and opengl output
    devices have been updated to support SDL2.
  </p>
  <h3 id="pr3.1.2">August 9th, 2016, FFmpeg 3.1.2 "Laplace"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_3.1">FFmpeg 3.1.2</a>, a new point release from the 3.1 release branch, is now available!
    It fixes several bugs.
  </p>
  <p>
    We recommend users, distributors, and system integrators, to upgrade unless they use current git master.
  </p>
  <h3 id="ffserv">July 10th, 2016, ffserver program being dropped</h3>
  <p>
    After thorough deliberation, we're announcing that we're about to drop the ffserver program from the project starting with the next release.
    ffserver has been a problematic program to maintain due to its use of internal APIs, which complicated the recent cleanups to the libavformat
    library, and block further cleanups and improvements which are desired by API users and will be easier to maintain. Furthermore the program has
    been hard for users to deploy and run due to reliability issues, lack of knowledgable people to help and confusing configuration file syntax.
    Current users and members of the community are invited to write a replacement program to fill the same niche that ffserver did using the new APIs
    and to contact us so we may point users to test and contribute to its development.
  </p>
  <h3 id="pr3.1.1">July 1st, 2016, FFmpeg 3.1.1 "Laplace"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_3.1">FFmpeg 3.1.1</a>, a new point release from the 3.1 release branch, is now available!
    It mainly deals with a few ABI issues introduced in the previous release.
  </p>
  <p>
    We strongly recommend users, distributors, and system integrators, especially those who experienced issues upgrading from 3.0, to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr3.1">June 27th, 2016, FFmpeg 3.1 "Laplace"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_3.1">FFmpeg 3.1 "Laplace"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>DXVA2-accelerated HEVC Main10 decoding</li>
    <li>fieldhint filter</li>
    <li>loop video filter and aloop audio filter</li>
    <li>Bob Weaver deinterlacing filter</li>
    <li>firequalizer filter</li>
    <li>datascope filter</li>
    <li>bench and abench filters</li>
    <li>ciescope filter</li>
    <li>protocol blacklisting API</li>
    <li>MediaCodec H264 decoding</li>
    <li>VC-2 HQ RTP payload format (draft v1) depacketizer and packetizer</li>
    <li>VP9 RTP payload format (draft v2) packetizer</li>
    <li>AudioToolbox audio decoders</li>
    <li>AudioToolbox audio encoders</li>
    <li>coreimage filter (GPU based image filtering on OSX)</li>
    <li>libdcadec removed</li>
    <li>bitstream filter for extracting DTS core</li>
    <li>ADPCM IMA DAT4 decoder</li>
    <li>musx demuxer</li>
    <li>aix demuxer</li>
    <li>remap filter</li>
    <li>hash and framehash muxers</li>
    <li>colorspace filter</li>
    <li>hdcd filter</li>
    <li>readvitc filter</li>
    <li>VAAPI-accelerated format conversion and scaling</li>
    <li>libnpp/CUDA-accelerated format conversion and scaling</li>
    <li>Duck TrueMotion 2.0 Real Time decoder</li>
    <li>Wideband Single-bit Data (WSD) demuxer</li>
    <li>VAAPI-accelerated H.264/HEVC/MJPEG encoding</li>
    <li>DTS Express (LBR) decoder</li>
    <li>Generic OpenMAX IL encoder with support for Raspberry Pi</li>
    <li>IFF ANIM demuxer &amp; decoder</li>
    <li>Direct Stream Transfer (DST) decoder</li>
    <li>loudnorm filter</li>
    <li>MTAF demuxer and decoder</li>
    <li>MagicYUV decoder</li>
    <li>OpenExr improvements (tile data and B44/B44A support)</li>
    <li>BitJazz SheerVideo decoder</li>
    <li>CUDA CUVID H264/HEVC decoder</li>
    <li>10-bit depth support in native utvideo decoder</li>
    <li>libutvideo wrapper removed</li>
    <li>YUY2 Lossless Codec decoder</li>
    <li>VideoToolbox H.264 encoder</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="gsoc2016">March 16th, 2016, Google Summer of Code</h3>
  <p>
    FFmpeg has been accepted as a <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> open source organization. If you wish to
    participate as a student see our <a href="https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2016">project ideas page</a>.
    You can already get in contact with mentors and start working on qualification tasks as well as register at google and submit your project proposal draft.
    Good luck!
  </p>

  <h3 id="pr3.0">February 15th, 2016, FFmpeg 3.0 "Einstein"</h3>
  <p>
    <a href="http://www.ffmpeg.org/download.html#release_3.0">FFmpeg 3.0 "Einstein"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li><a href="#aac_encoder_stable">The native FFmpeg AAC encoder has seen extensive improvements and is no longer considered experimental</a></li>
    <li><a href="#removing_external_aac_encoders">Removed support for libvo-aacenc and libaacplus</a></li>
    <li>Over 30 new filters have been added</li>
    <li>Many ASM optimizations</li>
    <li>VP9 Hardware Acceleration (DXVA2 and VA-API)</li>
    <li>Cineform HD decoder</li>
    <li>New DCA decoder based on libdcadec with full support for DTS-HD extensions</li>
    <li>As with all major releases expect major backward incompatible API/ABI changes</li>
    <li>See the <a href="https://git.videolan.org/?p=ffmpeg.git;a=blob_plain;f=Changelog;hb=n3.0">Changelog</a> for a list of more updates</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="removing_external_aac_encoders">January 30, 2016, Removing support for two external AAC encoders</h3>
  <p>
    We have just removed support for VisualOn AAC encoder (libvo-aacenc) and
    libaacplus in FFmpeg master.
  </p>
  <p>
    Even before marking our internal AAC encoder as
    <a href="#aac_encoder_stable">stable</a>, it was known that libvo-aacenc
    was of an inferior quality compared to our native one for most samples.
    However, the VisualOn encoder was used extensively by the Android Open
    Source Project, and we would like to have a tested-and-true stable option
    in our code base.
  </p>
  <p>
    When first committed in 2011, libaacplus filled in the gap of encoding
    High Efficiency AAC formats (HE-AAC and HE-AACv2), which was not supported
    by any of the encoders in FFmpeg at that time.
  </p>
  <p>
    The circumstances for both have changed. After the work spearheaded by
    Rostislav Pehlivanov and Claudio Freire, the now-stable FFmpeg native AAC
    encoder is ready to compete with much more mature encoders. The Fraunhofer
    FDK AAC Codec Library for Android was added in 2012 as the fourth
    supported external AAC encoder, and the one with the best quality and the
    most features supported, including HE-AAC and HE-AACv2.
  </p>
  <p>
    Therefore, we have decided that it is time to remove libvo-aacenc and
    libaacplus. If you are currently using libvo-aacenc, prepare to transition
    to the native encoder (<code>aac</code>) when updating to the next version
    of FFmpeg. In most cases it is as simple as merely swapping the encoder
    name. If you are currently using libaacplus, start using FDK AAC
    (<code>libfdk_aac</code>) with an appropriate <code>profile</code> option
    to select the exact AAC profile that fits your needs. In both cases, you
    will enjoy an audible quality improvement and as well as fewer licensing
    headaches.
  </p>
  <p>
    Enjoy!
  </p>

  <h3 id="pr2.8.5">January 16, 2016, FFmpeg 2.8.5, 2.7.5, 2.6.7, 2.5.10</h3>
  <p>
    We have made several new point releases (<b><a href="http://www.ffmpeg.org/download.html#release_2.8">2.8.5</a>,
      <a href="http://www.ffmpeg.org/download.html#release_2.7">2.7.5</a>,
      <a href="http://www.ffmpeg.org/download.html#release_2.6">2.6.7</a>,
      <a href="http://www.ffmpeg.org/download.html#release_2.5">2.5.10</a></b>).
    They fix various bugs, as well as CVE-2016-1897 and CVE-2016-1898.
    Please see the changelog for each release for more details.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="aac_encoder_stable">December 5th, 2015, The native FFmpeg AAC encoder is now stable!</h3>
  <p>
    After seven years the native FFmpeg AAC encoder has had its experimental flag
    removed and declared as ready for general use. The encoder is transparent
    at 128kbps for most samples tested with artifacts only appearing in extreme
    cases. Subjective quality tests put the encoder to be of equal or greater
    quality than most of the other encoders available to the public.
  </p>
  <p>
    Licensing has always been an issue with encoding AAC audio as most of the
    encoders have had a license making FFmpeg unredistributable if compiled with
    support for them. The fact that there now exists a fully open and truly
    free AAC encoder integrated directly within the project means a lot to those
    who wish to use accepted and widespread standards.
  </p>
  <p>
    The majority of the work done to bring the encoder up to quality was started
    during this year's GSoC by developer Claudio Freire and Rostislav Pehlivanov.
    Both continued to work on the encoder with the latter joining as a developer
    and mainainer, working on other parts of the project as well. Also, thanks
    to <a href="http://d.hatena.ne.jp/kamedo2/">Kamedo2</a> who does comparisons
    and tests, the original authors and all past and current contributors to the
    encoder. Users are suggested and encouraged to use the encoder and provide
    feedback or breakage reports through our <a href="https://trac.ffmpeg.org/">bug tracker</a>.
  </p>

  
  <p>
    A big thank you note goes to our newest supporters: MediaHub and Telepoint.
    Both companies have donated a dedicated server with free of charge internet
    connectivity. Here is a little bit about them in their own words:
  </p>

  <ul>
    <li>
      <p>
        <a href="http://www.telepoint.bg/en/">Telepoint</a> is the biggest
        carrier-neutral data center in Bulgaria. Located in the heart of Sofia
        on a cross-road of many Bulgarian and International networks, the
        facility is a fully featured Tier 3 data center that provides flexible
        customer-oriented colocation solutions (ranging from a server to a
        private collocation hall) and a high level of security.
      </p>
    </li>

    <li>
      <p>
        MediaHub Ltd. is a Bulgarian IPTV platform and services provider which
        uses FFmpeg heavily since it started operating a year ago. <i>"Donating
        to help keep FFmpeg online is our way of giving back to the community"
        </i>.
      </p>
    </li>
  </ul>

  <p>
    Thanks Telepoint and MediaHub for their support!
  </p>

  <h3 id="gsoc2015_result">September 29th, 2015, GSoC 2015 results</h3>

  <p>
    FFmpeg participated to the latest edition of
    the <a href="http://www.google-melange.com/gsoc/homepage/google/gsoc2015">Google
    Summer of Code</a> Project. FFmpeg got a total of 8 assigned
    projects, and 7 of them were successful.
  </p>

  <p>We want to thank <a href="https://www.google.com/">Google</a>, the
    participating students, and especially the mentors who joined this
    effort. We're looking forward to participating in the next GSoC
    edition!
  </p>

  <p>
    Below you can find a brief description of the final outcome of
    each single project.
  </p>

  <h4>Basic servers for network protocols, mentee: Stephan Holljes, mentor: Nicolas George</h4>

  <p>
    Stephan Holljes's project for this session of Google Summer of Code was to
    implement basic HTTP server features for libavformat, to complement the
    already present HTTP client and RTMP and RTSP server code.
  </p>

  <p>
    The first part of the project was to make the HTTP code capable of accepting
    a single client; it was completed partly during the qualification period and
    partly during the first week of the summer. Thanks to this work, it is now
    possible to make a simple HTTP stream using the following commands:
  </p>

  <pre>    ffmpeg -i /dev/video0 -listen 1 -f matroska \
    -c:v libx264 -preset fast -tune zerolatency http://:8080
    ffplay http://localhost:8080/
  </pre>

  <p>
    The next part of the project was to extend the code to be able to accept
    several clients, simultaneously or consecutively. Since libavformat did not
    have an API for that kind of task, it was necessary to design one. This part
    was mostly completed before the midterm and applied shortly afterwards.
    Since the ffmpeg command-line tool is not ready to serve several clients,
    the test ground for that new API is an example program serving hard-coded
    content.
  </p>

  <p>
    The last and most ambitious part of the project was to update ffserver to
    make use of the new API. It would prove that the API is usable to implement
    real HTTP servers, and expose the points where more control was needed. By
    the end of the summer, a first working patch series was undergoing code
    review.
  </p>

  <h4>Browsing content on the server, mentee: Mariusz Szczepańczyk, mentor: Lukasz Marek</h4>

  <p>
    Mariusz finished an API prepared by the FFmpeg community and implemented
    Samba directory listing as qualification task.
  </p>

  <p>
    During the program he extended the API with the possibility to
    remove and rename files on remote servers. He completed the
    implementation of these features for file, Samba, SFTP, and FTP
    protocols.
  </p>

  <p>
    At the end of the program, Mariusz provided a sketch of an
    implementation for HTTP directory listening.
  </p>

  <h4>Directshow digital video capture, mentee: Mate Sebok, mentor: Roger Pack</h4>

  <p>
    Mate was working on directshow input from digital video sources. He
    got working input from ATSC input sources, with specifiable tuner.
  </p>

  <p>
    The code has not been committed, but a patch of it was sent to the
    ffmpeg-devel mailing list for future use.
  </p>

  <p>
    The mentor plans on cleaning it up and committing it, at least for the
    ATSC side of things. Mate and the mentor are still working trying to
    finally figure out how to get DVB working.
  </p>

  <h4>Implementing full support for 3GPP Timed Text Subtitles, mentee: Niklesh Lalwani, mentor: Philip Langdale</h4>

  <p>
    Niklesh's project was to expand our support for 3GPP Timed Text
    subtitles. This is the native subtitle format for mp4 containers, and
    is interesting because it's usually the only subtitle format supported
    by the stock playback applications on iOS and Android devices.
  </p>

  <p>
    ffmpeg already had basic support for these subtitles which ignored all
    formatting information - it just provided basic plain-text support.
  </p>

  <p>
    Niklesh did work to add support on both the encode and decode side for
    text formatting capabilities, such as font size/colour and effects like
    bold/italics, highlighting, etc.
  </p>

  <p>
    The main challenge here is that Timed Text handles formatting in a very
    different way from most common subtitle formats. It uses a binary
    encoding (based on mp4 boxes, naturally) and stores information
    separately from the text itself. This requires additional work to track
    which parts of the text formatting applies to, and explicitly dealing
    with overlapping formatting (which other formats support but Timed
    Text does not) so it requires breaking the overlapping sections into
    separate non-overlapping ones with different formatting.
  </p>

  <p>
    Finally, Niklesh had to be careful about not trusting any size
    information in the subtitles - and that's no joke: the now infamous
    Android stagefright bug was in code for parsing Timed Text subtitles.
  </p>

  <p>
    All of Niklesh's work is committed and was released in ffmpeg 2.8.
  </p>

<h4>libswscale refactoring, mentee: Pedro Arthur, mentors: Michael Niedermayer, Ramiro Polla</h4>

  <p>
    Pedro Arthur has modularized the vertical and horizontal scalers.
    To do this he designed and implemented a generic filter framework
    and moved the existing scaler code into it. These changes now allow
    easily adding removing, splitting or merging processing steps.
    The implementation was benchmarked and several alternatives were
    tried to avoid speed loss.
  </p>

  <p>
    He also added gamma corrected scaling support.
    An example to use gamma corrected scaling would be:
  </p>

  <pre>    ffmpeg -i input -vf scale=512:384:gamma=1 output
  </pre>

  <p>
    Pedro has done impressive work considering the short time available,
    and he is a FFmpeg committer now. He continues to contribute to
    FFmpeg, and has fixed some bugs in libswscale after GSoC has
    ended.
  </p>

  <h4>AAC Encoder Improvements, mentee: Rostislav Pehlivanov, mentor: Claudio Freire</h4>

  <p>
    Rostislav Pehlivanov has implemented PNS, TNS, I/S coding and main
    prediction on the native AAC encoder. Of all those extensions, only
    TNS was left in a less-than-usable state, but the implementation has
    been pushed (disabled) anyway since it's a good basis for further
    improvements.
  </p>

  <p>
    PNS replaces noisy bands with a single scalefactor representing the
    energy of that band, gaining in coding efficiency considerably, and
    the quality improvements on low bitrates are impressive for such a
    simple feature.
  </p>

  <p>
    TNS still needs some polishing, but has the potential to reduce coding
    artifacts by applying noise shaping in the temporal domain (something
    that is a source of annoying, notable distortion on low-entropy
    bands).
  </p>

  <p>
    Intensity Stereo coding (I/S) can double coding efficiency by
    exploiting strong correlation between stereo channels, most effective
    on pop-style tracks that employ panned mixing. The technique is not as
    effective on classic X-Y recordings though.
  </p>

  <p>
    Finally, main prediction improves coding efficiency by exploiting
    correlation among successive frames. While the gains have not been
    huge at this point, Rostislav has remained active even after the GSoC,
    and is polishing both TNS and main prediction, as well as looking for
    further improvements to make.
  </p>

  <p>
    In the process, the MIPS port of the encoder was broken a few times,
    something he's also working to fix.
  </p>

  <h4>Animated Portable Network Graphics (APNG), mentee: Donny Yang, mentor: Paul B Mahol</h4>

  <p>
    Donny Yang implemented basic keyframe only APNG encoder as the
    qualification task. Later he wrote interframe compression via
    various blend modes. The current implementation tries all blend
    modes and picks one which takes the smallest amount of memory.
  </p>

  <p>
    Special care was taken to make sure that the decoder plays
    correctly all files found in the wild and that the encoder
    produces files that can be played in browsers that support APNG.
  </p>

  <p>
    During his work he was tasked to fix any encountered bug in the
    decoder due to the fact that it doesn't match APNG
    specifications. Thanks to this work, a long standing bug in the
    PNG decoder has been fixed.
  </p>

  <p>
    For latter work he plans to continue working on the encoder,
    making it possible to select which blend modes will be used in the
    encoding process. This could speed up encoding of APNG files.
  </p>

  <h3 id="pr2.8">September 9th, 2015, FFmpeg 2.8</h3>
  <p>
    We published release <b><a href="http://www.ffmpeg.org/download.html#release_2.8">2.8</a></b> as new major version.
    It contains all features and bug fixes of the git master branch from September 8th. Please see
    the <b><a href="https://raw.githubusercontent.com/FFmpeg/FFmpeg/release/2.8/Changelog">changelog</a></b>
    for a list of the most important changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use current git master.
  </p>

  <h3 id="message">August 1st, 2015, A message from the FFmpeg project</h3>
  <p>
    Dear multimedia community,
  </p>
  <p>
    The resignation of Michael Niedermayer as leader of FFmpeg yesterday has
    come by surprise. He has worked tirelessly on the FFmpeg project for many
    years and we must thank him for the work that he has done. We hope that in
    the future he will continue to contribute to the project. In the coming
    weeks, the FFmpeg project will be managed by the active contributors.
  </p>
  <p>
    The last four years have not been easy for our multimedia community - both
    contributors and users. We should now look to the future, try to find
    solutions to these issues, and to have reconciliation between the forks,
    which have split the community for so long.
  </p>
  <p>
    Unfortunately, much of the disagreement has taken place in inappropriate
    venues so far, which has made finding common ground and solutions
    difficult. We aim to discuss this in our communities online over the coming
    weeks, and in person at the <a href="https://www.videolan.org/videolan/events/vdd15/">VideoLAN Developer
    Days</a> in Paris in September: a neutral venue for the entire open source
    multimedia community.
  </p>
  <p>
    The FFmpeg project.
  </p>

  <h3 id="needhost">July 4th, 2015, FFmpeg needs a new host</h3>
  <p><b>UPDATE:</b> We have received more than 7 offers for hosting and servers, thanks a lot to everyone!</p>
  <p>
    After graciously hosting our projects (<a href="http://www.ffmpeg.org/">FFmpeg</a>, <a href="http://www.mplayerhq.hu/">MPlayer</a>
    and <a href="http://rtmpdump.mplayerhq.hu/">rtmpdump</a>) for 4 years, Arpi (our hoster) has informed us that we have to secure a new host somewhere else immediately.
  </p>
  <p>
    If you want to host an open source project, please let us know, either on <a href="http://ffmpeg.org/mailman/listinfo/ffmpeg-devel">ffmpeg-devel</a>
    mailing list or irc.freenode.net #ffmpeg-devel.
  </p>
  <p>
    We use about 4TB of storage and at least 4TB of bandwidth / month for various mailing lists, <a href="http://trac.ffmpeg.org/">trac</a>, <a href="http://samples.ffmpeg.org/">samples repo</a>, svn, etc.
  </p>

  <h3 id="pr2.6.1">March 16, 2015, FFmpeg 2.6.1</h3>
  <p>
    We have made a new major release (<b><a href="http://www.ffmpeg.org/download.html#release_2.6">2.6</a></b>)
    and now one week afterward 2.6.1. It contains all features and bugfixes of the git master branch from the 6th March.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.6">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="gsoc2015">March 4, 2015, Google Summer of Code</h3>
  <p>
    FFmpeg has been accepted as a <a href="http://www.google-melange.com/gsoc/homepage/google/gsoc2015">Google Summer of Code</a> Project. If you wish to
    participate as a student see our <a href="https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2015">project ideas page</a>.
    You can already get in contact with mentors and start working on qualification tasks. Registration
    at Google for students will open March 16th. Good luck!
  </p>

  <h3 id="clt2015">March 1, 2015, Chemnitzer Linux-Tage</h3>
  <p>
    We happily announce that FFmpeg will be represented at Chemnitzer Linux-Tage
    (CLT) in Chemnitz, Germany. The event will take place on 21st and 22nd of March.
  </p>

  <p>
    More information can be found <a href="https://chemnitzer.linux-tage.de/2015/en/">here</a>
  </p>

  <p>
    We demonstrate usage of FFmpeg, answer your questions and listen to
    your problems and wishes. <strong>If you have media files that cannot be
    processed correctly with FFmpeg, be sure to have a sample with you
    so we can have a look!</strong>
  </p>
  <p>
    For the first time in our CLT history, there will be an <strong>FFmpeg workshop</strong>!
    You can read the details <a href="https://chemnitzer.linux-tage.de/2015/de/programm/beitrag/209">here</a>.
    The workshop is targeted at FFmpeg beginners. First the basics of
    multimedia will be covered. Thereafter you will learn how to use
    that knowledge and the FFmpeg CLI tools to analyse and process media
    files. The workshop is in German language only and prior registration
    is necessary. The workshop will be on Saturday starting at 10 o'clock.
  </p>
  <p>
    We are looking forward to meet you (again)!
  </p>

  <h3 id="pr2.5">December 5, 2014, FFmpeg 2.5</h3>
  <p>
    We have made a new major release (<b><a href="http://www.ffmpeg.org/download.html#release_2.5">2.5</a></b>)
    It contains all features and bugfixes of the git master branch from the 4th December.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.5">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="ffmpeg_back_in_sid">October 10, 2014, FFmpeg is in Debian unstable again</h3>
  <p>
    We wanted you to know there are
    <a href="https://packages.debian.org/search?keywords=ffmpeg&amp;searchon=sourcenames&amp;suite=unstable&amp;section=main">
    FFmpeg packages in Debian unstable</a> again. <strong>A big thank-you
    to Andreas Cadhalpun and all the people that made it possible.</strong> It has been anything but simple.
  </p>
  <p>
    Unfortunately that was already the easy part of this news. The bad news is the packages probably won't
    migrate to Debian testing to be in the upcoming release codenamed jessie.
    <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=763148">Read the argumentation over at Debian.</a>
  </p>
  <p>
    <strong>However things will come out in the end, we hope for your continued remarkable support!</strong>
  </p>

  <h3 id="opw03">October 8, 2014, FFmpeg secured a place in OPW!</h3>
  <p>
    Thanks to a generous 6K USD donation by Samsung (Open Source Group),
    FFmpeg will be welcoming at least 1 "Outreach Program for Women" intern
    to work with our community for an initial period starting December 2014
    (through March 2015).
  </p>

  <p>
    We all know FFmpeg is used by the industry, but even while there are
    countless products building on our code, it is not at all common for
    companies to step up and help us out when needed. So a big thank-you
    to Samsung and the OPW program committee!
  </p>

  <p>
    If you are thinking on participating in OPW as an intern, please take
    a look at our <a href="https://trac.ffmpeg.org/wiki/SponsoringPrograms/OPW/2014-12">OPW wiki page</a>
    for some initial guidelines. The page is still a work in progress, but
    there should be enough information there to get you started. If you, on
    the other hand, are thinking on sponsoring work on FFmpeg through the
    OPW program, please get in touch with us at opw@ffmpeg.org. With your
    help, we might be able to secure some extra intern spots for this round!
  </p>

  <h3 id="pr2.4">September 15, 2014, FFmpeg 2.4</h3>
  <p>
    We have made a new major release (<b><a href="http://www.ffmpeg.org/download.html#release_2.4">2.4</a></b>)
    It contains all features and bugfixes of the git master branch from the 14th September.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.4">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="pr2.3.3">August 20, 2014, FFmpeg 2.3.3, 2.2.7, 1.2.8</h3>
  <p>
    We have made several new point releases (<b><a href="http://www.ffmpeg.org/download.html#release_2.3">2.3.3</a>,
      <a href="http://www.ffmpeg.org/download.html#release_2.2">2.2.7</a>,
      <a href="http://www.ffmpeg.org/download.html#release_1.2">1.2.8</a></b>).
    They fix various bugs, as well as CVE-2014-5271 and CVE-2014-5272.
    Please see the changelog for more details.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="opw02">July 29, 2014, Help us out securing our spot in OPW</h3>
  <p>
    Following our previous post regarding our participation on this year's
    OPW (Outreach Program for Women), we are now reaching out to our users
    (both individuals and companies) to help us gather the needed money to
    secure our spot in the program.<br>
    We need to put together 6K USD as a minimum but securing more funds would
    help us towards getting more than one intern.<br>
    You can donate by credit card using
    <a href="https://co.clickandpledge.com/advanced/default.aspx?wid=56226">
    Click&amp;Pledge</a> and selecting the "OPW" option. If you would like to
    donate by money transfer or by check, please get in touch by
    <a href="mailto:opw@ffmpeg.org">e-mail</a> and we will get back to you
    with instructions.<br>Thanks!
  </p>

  <h3 id="newweb">July 20, 2014, New website</h3>
  <p>
    The FFmpeg project is proud to announce a brand new version of the website
    made by <a href="http://db0.fr/">db0</a>. While this was initially motivated
    by the need for a larger menu, the whole website ended up being redesigned,
    and most pages got reworked to ease navigation. We hope you'll enjoy
    browsing it.
  </p>

  <h3 id="pr2.3">July 17, 2014, FFmpeg 2.3</h3>
  <p>
    We have made a new major release (<b><a href="http://www.ffmpeg.org/download.html#release_2.3">2.3</a></b>)
    It contains all features and bugfixes of the git master branch from the 16th July.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=489d066">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="opw01">July 3, 2014, FFmpeg and the Outreach Program For Women</h3>
  <p>
    FFmpeg has started the process to become an OPW includer organization for the
    next round of the program, with internships starting December 9. The
    <a href="https://gnome.org/opw/">OPW</a> aims to "Help women (cis and trans)
    and genderqueer to get involved in free and open source software". Part of the
    process requires securing funds to support at least one internship (6K USD), so
    if you were holding on your donation to FFmpeg, this is a great chance for you
    to come forward, get in touch and help both the project and a great initiative!
  </p>
  <p>
    We have set up an <a href="mailto:opw@ffmpeg.org">email address</a> you can use
    to contact us about donations and general inquires regarding our participation
    in the program. Hope to hear from you soon!
  </p>

  <h3 id="pr2.2.4">June 29, 2014, FFmpeg 2.2.4, 2.1.5, 2.0.5, 1.2.7, 1.1.12, 0.10.14</h3>
  <p>
    We have made several new point releases (<b><a href="http://www.ffmpeg.org/download.html#release_2.2">2.2.4</a>,
      <a href="http://www.ffmpeg.org/download.html#release_2.1">2.1.5</a>,
      <a href="http://www.ffmpeg.org/download.html#release_2.0">2.0.5</a>,
      <a href="http://www.ffmpeg.org/download.html#release_1.2">1.2.7</a>,
      <a href="http://www.ffmpeg.org/download.html#release_1.1">1.1.12</a>,
      <a href="http://www.ffmpeg.org/download.html#release_0.10">0.10.14</a></b>).
    They fix a
    <a href="http://blog.securitymouse.com/2014/06/raising-lazarus-20-year-old-bug-that.html">security issue in the LZO implementation</a>,
    as well as several other bugs. See the git log for details.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>


  <h3 id="lt2014">May 1, 2014, LinuxTag</h3>
  <p>
    Once again FFmpeg will be represented at LinuxTag in Berlin, Germany. The event will
    take place from 8th to 10th of May. Please note that this year's LinuxTag is at a
    different location closer to the city center.
  </p>

  <p>
    We will have a shared booth with XBMC and VideoLAN.
    <b>
      If you have media files that cannot be processed correctly with
      FFmpeg, be sure to have a sample with you so we can have a look!
    </b>
  </p>

  <p>
    More information about LinuxTag can be found <a href="http://www.linuxtag.org/2014/">here</a>
  </p>

  <p>
    We are looking forward to see you in Berlin!
  </p>

  <h3 id="heartbleed">April 18, 2014, OpenSSL Heartbeat bug</h3>
  <p>
    Our server hosting the Trac issue tracker was vulnerable to the attack
    against OpenSSL known as "heartbleed". The OpenSSL software library
    was updated on 7th of April, shortly after the vulnerability was publicly
    disclosed. We have changed the private keys (and certificates) for all
    FFmpeg servers. The details were sent to the mailing lists by
    Alexander Strasser, who is part of the project server team. Here is a
    link to the user mailing list
    <a href="https://lists.ffmpeg.org/pipermail/ffmpeg-user/2014-April/020968.html">archive</a>
    .
  </p><p>
    We encourage you to read up on
    <a href="https://www.schneier.com/blog/archives/2014/04/heartbleed.html">"OpenSSL heartbleed"</a>.
    <b>It is possible that login data for the issue tracker was exposed to
      people exploiting this security hole. You might want to change your password
      in the tracker and everywhere else you used that same password.</b>
  </p>

  <h3 id="pr2.2.1">April 11, 2014, FFmpeg 2.2.1</h3>
  <p>
    We have made a new point releases (<b><a href="http://www.ffmpeg.org/download.html#release_2.2">2.2.1</a></b>).
    It contains bug fixes for Tickets #2893, #3432, #3469, #3486, #3495 and #3540 as well as
    several other fixes.
    See the git log for details.
  </p>

  <h3 id="pr2.2">March 24, 2014, FFmpeg 2.2</h3>
  <p>
    We have made a new major release (<b><a href="http://www.ffmpeg.org/download.html#release_2.2">2.2</a></b>)
    It contains all features and bugfixes of the git master branch from 1st March.
    A partial list of new stuff is below:
  </p>
  <pre>    - HNM version 4 demuxer and video decoder
    - Live HDS muxer
    - setsar/setdar filters now support variables in ratio expressions
    - elbg filter
    - string validation in ffprobe
    - support for decoding through VDPAU in ffmpeg (the -hwaccel option)
    - complete Voxware MetaSound decoder
    - remove mp3_header_compress bitstream filter
    - Windows resource files for shared libraries
    - aeval filter
    - stereoscopic 3d metadata handling
    - WebP encoding via libwebp
    - ATRAC3+ decoder
    - VP8 in Ogg demuxing
    - side &amp; metadata support in NUT
    - framepack filter
    - XYZ12 rawvideo support in NUT
    - Exif metadata support in WebP decoder
    - OpenGL device
    - Use metadata_header_padding to control padding in ID3 tags (currently used in
    MP3, AIFF, and OMA files), FLAC header, and the AVI "junk" block.
    - Mirillis FIC video decoder
    - Support DNx444
    - libx265 encoder
    - dejudder filter
    - Autodetect VDA like all other hardware accelerations
  </pre>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="clt2014">February 3, 2014, Chemnitzer Linux-Tage</h3>
  <p>
    We happily announce that FFmpeg will be represented at `Chemnitzer Linux-Tage'
    in Chemnitz, Germany. The event will take place on 15th and 16th of March.
  </p>

  <p>
    More information can be found <a href="http://chemnitzer.linux-tage.de/2014/en/info/">here</a>
  </p>

  <p>
    We invite you to visit us at our booth located in the Linux-Live area!
    There we will demonstrate usage of FFmpeg, answer your questions and listen to
    your problems and wishes.
  </p>
  <p>
    <b>
      If you have media files that cannot be processed correctly with
      FFmpeg, be sure to have a sample with you so we can have a look!
    </b>
  </p>
  <p>
    We are looking forward to meet you (again)!
  </p>


  <h3 id="trac_sec">February 9, 2014, trac.ffmpeg.org / trac.mplayerhq.hu Security Breach</h3>
  <p>
    The server on which FFmpeg and MPlayer Trac issue trackers were
    installed was compromised. The affected server was taken offline
    and has been replaced and all software reinstalled.
    FFmpeg Git, releases, FATE, web and mailinglists are on other servers
    and were not affected. We believe that the original compromise happened
    to a server, unrelated to FFmpeg and MPlayer, several months ago.
    That server was used as a source to clone the VM that we recently moved
    Trac to. It is not known if anyone used the backdoor that was found.
  </p>
  <p>
    We recommend all users to change their passwords.
    <b>Especially users who use a password on Trac that they also use
      elsewhere, should change that password at least elsewhere.</b>
  </p>


  <h3 id="ffmpeg_rfp">November 12, 2013, FFmpeg RFP in Debian</h3>
  <p>
    Since the splitting of Libav the Debian/Ubuntu maintainers have followed
    the Libav fork. Many people have requested the packaging of ffmpeg in
    Debian, as it is more feature-complete and in many cases less buggy.
  </p>
  <p>
    <a href="http://cynic.cc/blog/">Rogério Brito</a>, a Debian developer,
    has proposed a Request For Package (RFP) in the Debian bug tracking
    system.
  </p>
  <p>
    Please let the Debian and Ubuntu developers know that you support packaging
    of the real FFmpeg! See Debian <a href="http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=729203">ticket #729203</a>
    for more details.
  </p>

  <h3 id="pr2.1">October 28, 2013, FFmpeg 2.1</h3>
  <p>
    We have made a new major release (<b><a href="http://www.ffmpeg.org/download.html#release_2.1">2.1</a></b>)
    It contains all features and bugfixes of the git master branch from 28th October.
    A partial list of new stuff is below:
  </p>
  <pre>    - aecho filter
    - perspective filter ported from libmpcodecs
    - ffprobe -show_programs option
    - compand filter
    - RTMP seek support
    - when transcoding with ffmpeg (i.e. not streamcopying), -ss is now accurate
    even when used as an input option. Previous behavior can be restored with
    the -noaccurate_seek option.
    - ffmpeg -t option can now be used for inputs, to limit the duration of
    data read from an input file
    - incomplete Voxware MetaSound decoder
    - read EXIF metadata from JPEG
    - DVB teletext decoder
    - phase filter ported from libmpcodecs
    - w3fdif filter
    - Opus support in Matroska
    - FFV1 version 1.3 is stable and no longer experimental
    - FFV1: YUVA(444,422,420) 9, 10 and 16 bit support
    - changed DTS stream id in lavf mpeg ps muxer from 0x8a to 0x88, to be
    more consistent with other muxers.
    - adelay filter
    - pullup filter ported from libmpcodecs
    - ffprobe -read_intervals option
    - Lossless and alpha support for WebP decoder
    - Error Resilient AAC syntax (ER AAC LC) decoding
    - Low Delay AAC (ER AAC LD) decoding
    - mux chapters in ASF files
    - SFTP protocol (via libssh)
    - libx264: add ability to encode in YUVJ422P and YUVJ444P
    - Fraps: use BT.709 colorspace by default for yuv, as reference fraps decoder does
    - make decoding alpha optional for prores, ffv1 and vp6 by setting
    the skip_alpha flag.
    - ladspa wrapper filter
    - native VP9 decoder
    - dpx parser
    - max_error_rate parameter in ffmpeg
    - PulseAudio output device
    - ReplayGain scanner
    - Enhanced Low Delay AAC (ER AAC ELD) decoding (no LD SBR support)
    - Linux framebuffer output device
    - HEVC decoder, raw HEVC demuxer, HEVC demuxing in TS, Matroska and MP4
    - mergeplanes filter
  </pre>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starship’s second flight test (146 pts)]]></title>
            <link>https://www.spacex.com/launches/mission/?missionId=starship-flight-2</link>
            <guid>38227463</guid>
            <pubDate>Sat, 11 Nov 2023 03:47:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spacex.com/launches/mission/?missionId=starship-flight-2">https://www.spacex.com/launches/mission/?missionId=starship-flight-2</a>, See on <a href="https://news.ycombinator.com/item?id=38227463">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mission-page-to-the-iss">
          <div id="docking">
  <div>
    <div>
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 1136 1105">
          <g>
            <rect width="1136" height="1105"></rect>
            <g transform="translate(-11.26 -78.359)">
              <g transform="translate(-7962.74 -3575.641)">
                <path d="M8762.139,4223.85l5.894-9.063,4.9,9.635Z" fill="#fff"></path>
                <line x2="55.486" y2="77.52" transform="translate(8534.092 4299.693)" fill="none" stroke="#c3c5c6" stroke-miterlimit="10" stroke-width="1.562"></line>
                <path d="M8507.452,4016.6c104.567,0,189.376,84.941,189.376,189.682s-84.809,189.677-189.376,189.677-189.371-84.939-189.371-189.677,84.8-189.682,189.371-189.682Z" fill="#cfd1d2" fill-rule="evenodd"></path>
                <path d="M8507.452,4016.6c104.567,0,189.376,84.941,189.376,189.682s-84.809,189.677-189.376,189.677-189.371-84.939-189.371-189.677,84.8-189.682,189.371-189.682Z" fill="#cfd1d2" fill-rule="evenodd"></path>
                <path d="M8507.452,4016.6c104.567,0,189.376,84.941,189.376,189.682s-84.809,189.677-189.376,189.677-189.371-84.939-189.371-189.677,84.8-189.682,189.371-189.682Z" fill="#cfd1d2" fill-rule="evenodd"></path>
                <path d="M8507.452,4016.6c104.567,0,189.376,84.941,189.376,189.682s-84.809,189.677-189.376,189.677-189.371-84.939-189.371-189.677,84.8-189.682,189.371-189.682Z" fill="#fff" fill-rule="evenodd"></path>
                <g clip-path="url(#a)">
                  <path d="M8588.518,4182.3l2.134-1.837.355,5.276h2.489v1.422l3.854-1.956,1.423.06.652,2.193h1.956l4.09,7.766h-4.209l-.83-2.528-1.837,4.9-1.6-3.083-8.477,3.853-.3-.948,2.016-3.557-1.423-.889-.3-10.67Z"></path>
                  <path d="M8573.1,4194.567l7.292-.356v1.6l-4.387.83-2.905-1.215v-.859Z"></path>
                  <path d="M8526.749,4137.186l-1.363,3.023,2.193,2.43,6.105-2.727,4.683,4.446,9.188,2.075h3.2v-1.422l-5.75-3.794,2.727.059,4.8,2.253-.948-2.786.948-1.542-10.374-7.232.3-2.727,8.714,4.5-.533-2.786.593-2.312-.475-3.023-4.446-1.423-2.134-2.371h-7l1.008-3.734L8521,4107.487v-2.016l-5.157-.948-5.928,2.193-.355-.949h-2.727l-2.668,2.9v5.928l3.675,1.423-2.549,1.186,2.165,2.49,12.655.119-.356-2.016,9.781,6.046,3.854,4.149-2.075,4.624,2.134,3.319-6.7,1.245Z"></path>
                  <path d="M8525.979,4124.619l-1.245,2.846.89,1.837h.889l1.838-2.341-.771-1.482-1.6-.86Z"></path>
                  <path d="M8511.4,4136.3l-2.489,9.248h3.261v2.431l4.386-3.972,4.564,1.719.652-1.067L8519.4,4144l-4.061-4.979-2.4.237-.89-2.668-.652-.3Z"></path>
                  <path d="M8515.338,4149.1v2.371h1.63l2.786-3.082-.889-.415h-1.319l-2.208,1.126Z"></path>
                  <path d="M8524.2,4149.723l-1.363,1.215.682,1.719.682.534.533-1.363-.533-2.1Z"></path>
                  <path d="M8407.718,4150.7l1.6-.593.712,1.245-1.156,4.979-1.808-.948.651-4.683Z"></path>
                  <path d="M8405.524,4156.985l2.431,2.015-2.786,3.261v5.454l-1.423-1.364v-8.062l1.778-1.3Z"></path>
                  <path d="M8387.326,4061.013l11.855-6.284h2.905l-.415,1.779,2.667.889v1.6l3.023-.059v-1.66l-.533-1.719,1.066-.474,1.838-.356,2.253-2.964-2.193-1.3-2.846,1.66-.059-1.186,14.76-10.492,1.245-5.395L8441.8,4016.6l77.063-7.518,112.273,25.964,66.984,67.34,9.01,106.82-1.422,19.325-8.577-.948-5.295-10.883-1.659-29.545-1.423-5.572-.948-13.871-4.387-8.536-5.69-18.258-1.067.593-.118,2.964-1.067.119-.355-2.608-2.253-.355-6.758-9.722-2.608-1.9v-14.82l-6.994-5.928-2.371-.711-.593,2.49-2.253-1.186-.711-5.335-1.778-2.134-.119-3.082-4.031-3.32,3.676,12.093-1.423.237-2.253-5.928-.593,2.134-5.216-4.505v-2.727l-4.506-1.92v2.039l-8.772-2.845-1.66-2.608-.237-3.438,2.964-1.067,4.387,4.031,5.81.237,3.082.711,1.66-2.015-5.217-4.624-2.964-6.995-11.145-4.268-.829,2.371-4.031-.83-12.8-9.6-24.423-12.686-10.67-8.655-.593-8.417,1.659-1.067-2.134-1.778-4.979.83-1.66-1.3-.474-1.067-2.371-.355-2.608,1.423-.83-1.186.237-1.66-10.789-4.149.119,1.756,3.912,1.208,1.3,2.134-1.186,1.778-11.736.593-13.516-1.541.237-1.186,20.51-.237.475-1.186-7.943-4.537h-2.016l-7.232,2.973-1.333-1.756h-2.816l-2.489-1.217-10.962.743-1.724,2.23-9.959,1.208-3.675,2.371-9.959-.711-1.778-2.868-10.2,2.156-.593,1.3-6.283,1.3-4.861-1.3-.829,2.49-5.691,2.845,1.778,2.134-1.066.83-2.371-.948-11.145,5.572-3.083,5.1-6.283.593-3.319,6.165-3.083,1.423-.474,1.541,2.964-.118-3.2,6.046-10.433,10.433,1.066.474-4.149,5.216-1.778-1.126-3.557.652-.355-1.3,4.149-4.505.237-2.49-2.49-1.541-6.521,3.557-.711-5.691-2.964-1.541,2.134-2.845-.475-1.423,1.3-2.727-3.32-.237-1.066,1.541-7.351,1.423-1.838-2.134Z"></path>
                  <path d="M8634.1,4099.9v2.489l1.778,1.3v2.608l7.587,5.809-1.3-6.757-4.86-4.268-3.2-1.186Z"></path>
                  <path d="M8497.644,4032.085l-3.2,1.423,3.912,1.423,1.067-2.134-1.778-.711Z"></path>
                  <path d="M8501.082,4032.8l-1.66,2.134,1.66.83,1.9,1.541,2.134-.711.593-2.252-4.623-1.541Z"></path>
                  <path d="M8539.968,4048.09l.949,1.9,4.149,1.66v2.727h4.742l7.231-2.49-6.876-1.3,1.3-1.66-1.778-.83-3.437,2.016-3.913-2.016Z"></path>
                  <path d="M8594.979,4087.807v5.217l-2.016,1.778,2.174,3.557h2.568l-.859,1.542h2.638l.712-1.186,5.275-1.542-2.431-6.046-3.2-3.794-4.86.474Z"></path>
                  <path d="M8580.633,4101.441l4.742,8.536-2.607,3.794.771,4.386,3.022,3.32v4.979l5.454,6.4.948,3.438-2.727.711-4.979-3.438-1.66,3.438L8571.5,4129.3l-4.623-4.683h-3.32l-6.508-11.322,2.358-2.252-8.536-6.521-2.364,1.9-3.919-4.861-11.145-8.536-6.905,2.348-5.306-2.348v-3.2l-2.727-1.186.474-1.3,2.786-3.794v-1.423l-1.363-.474,1.363-7.469,4.091-3.083-1.127-4.031,4.684-2.727H8537l1.778-2.49,1.186,1.067,6.64,4.268,10.445,3.912v1.541l6.152.237,9.366,10.789,3.794-.119,4.387,3.794,1.541,4.742.237,6.758-1.9,2.608Z"></path>
                  <path d="M8661.311,4315.5l-8.654,9.366-8.832,6.758-3.32-.059.83-1.364-2.312-.237-.118-3.082-7.114,2.26-.771,1.237-8.3,4.742-3.675-.533-.178-1.245-3.913.415-3.556,1.66-.238-1.719-5.987.355-7.409,4.565-11.678,2.726-.415-1.3-6.7-.474-.059,1.541-5.039,3.083-.711-1.126,3.379-2.609-2.668-1.126-6.757,5.869-2.728.237-.712,1.363-3.318.178-2.075,4.446-4.979,4.149-2.9-1.422-7.232.177-8.951,2.964-7.112-4.268,1.3-12.092-6.817-1.9-15.057.889,2.371-2.49.355-4.683h1.014l1.714-6.046,1.926-1.927v-2.934h-9.277l-5.1,2.608v3.2l-4,4h-12.182l-4.091-1.689-8.417-12.211v-11.2h2.846l.415-2.312-1.364-5.038,3.972-2.964v-1.779h3.675l3.262-2.43h10.433l5.038,2.845,2.727-1.067,2.432.949v-4.8h12.211l2.727,2.253h1.72l2.607-1.956,5.513,3.734v4.861l3.438,3.616v2.608l2.608.83,1.719,1.719h2.134l1.482-6.343-6.7-12.863v-4.8l5.809-6.817h1.126l2.313-4.208,2.016-.06,1.778-3.26,6.462-3.912-3.024-8,2.55-6.283-2.431-3.735.771-1.126,2.311,2.015,1.9-4.446-.533-1.245,1.719-1.956,2.549-.83,3.616-4.742.963.963,1.7-1.437-.474-1.3-1.66-1.087.593-5.908,2.608-2.193,1.008-2.49,2.193-.119,2.9-3.675V4216.7l2.728-1.448,2.252-3.378,3.557.558-.77,2.643-3.5,1.067-1.3,3.734.3,1.364,2.37.829,2.905-5.369,7.232-5.36-1.838-1.778,2.549-1.3.475-2.787-1.66-.592-.889-2.668-1.008.178-.83,6.4-1.6,1.482-5.751.178-3.2-3.26V4203.9h-1.778l2.312-3.878-2.549-2.49-4.92,2.786-6.4,6.936,2.192-6.639,2.728-1.364,1.008-4.683,13.16-3.616,3.971-5.216.3-2.134,3.734-2.312,1.008-4.446-2.549-4.861-2.371-.355-.949,1.719-.711-2.016-1.956-.415.118-2.134h-4.623l-8.6-3.675,1.541-2.312-12.923-11.263v7.706l-2.253,2.786-6.461-4.683-1.186-5.157h-3.616l-6.224-4.5-1.245,1.245-5.276-.178-2.134.889,2.609,10.433-1.542,5.869,2.964.948,3.5,6.817-1.541,5.572-4.031,4.268,3.853,10.433.06,2.253-.711,1.719-1.779-1.245-.711,1.838-7.351-7.173v-8.832l-6.225-1.127-1.481.356-2.608-1.6-3.853-.652-8.121-6.7-5.276,1.008v-7.647l-3.409.326v-3.912l6.491-12.982,3.113-1.423v-1.245l-3.735-1.867h4.535l3.379-.889,2.489-4.268-4.979-3.2v-.949l4.979,2.727,1.784-3.2-.954-1.126,2.668-.593v-1.482l2.845,1.837,3.557-4.09-1.659-2.371.236-4.742-2.845-1.66H8511.1l-.533,1.245,1.362,2.371-3.733,6.58-2.075-3.26,1.335-2.194-2.229-3.141-1.536,4.031-1.067-5.039-2.786-.593,1.186-.889-3.676-7.469-2.845,2.43.474,4.8,3.082,1.837-.3,1.66-3.379,4.624.06,3.26-.771-.118-1.364-4.091-1.422-.829-1.719,1.185-5.395.119-3.143-1.008-2.726-5.394-3.438,1.482-.3,4.327-1.008.059-1.778-3.734-3.142,1.422-4.5-2.9,2.371-1.423-.415-1.719-8.417-7.825-.949,1.244v-2.666l-2.845.948v-3.557l-3.854.475,1.245-1.779h-6.047v-1.423h-2.667l-1.838.356-2.489-8.714-2.846-5.631-.594-.474.476-2.075-.178-3.142-3.438-2.845-3.32-.534-2.785,1.482-1.541-1.185-.534-1.067h-1.541l-5.869,9.484-.652-.178-1.066-2.489,1.659-.83-.354-1.008-3.557-1.482-1.364,2.43-1.6.3-.711,2.489.89,3.2,2.252.592-1.007.889-2.965,1.7-2.727-1.34v-1.6h-1.245l-5.394,1.422-4.446,5.691.652,2.49-3.438,3.082,1.067,2.846-.771,1.482,1.838,1.837-3.853,2.668-6.7-.652-2.193-1.66-1.481.059-.652-1.067-1.481-.059v1.54l7.588,4.506,9.425-.178,2.727-2.489,2.846.178,2.015-1.245,4.15.177-.356,1.482-3.972.119-2.134,2.312-1.541-.119,2.431,2.194h3.141l3.143-2.49,1.127.711v6.877l3.378,4.327,2.075-.534.83,1.482-2.965,1.719-.3,6.936.771,1.245-.415,1.3-.533-.178-1.66,7.173,1.008,1.482,2.075-.119-.712,7.054.771,2.312-.771,2.668-2.134.118.178,3.083,1.067,1.007-.948,5.4.355,4.09-2.786.356-.356,2.015,3.854,11.382-1.542.829.415,6.343-.711.652-.356,1.957-5.809,10.788-1.956,1.245-.3,6.106-2.548,3.971.178,8,1.838,3.774v3.517h-1.067l.771,1.778-.593,2.135,1.659,4.623-.3,3.616,7.766,9.425,2.727,15.769,3.853,4.5.416,4.92-3.2-1.956-.592,1.007,8.773,9.426.118,4.8,6.105,8.6,1.838-2.311-1.3-2.668-1.542-.059-2.726-9.722-3.2-4.683.177-3.675-4.149-6.7-.118-7.173,5.335,3.319.948,9.959,5.1,5.987.118,2.016,3.615,4.979-1.245,1.067.534,1.364,11.915,13.871,1.363,6.283-.711,1.541h-.83l.237,1.838,32.069,18.791h9.662l12.864,7.292,4.86.355,6.165,1.956,3.918-.533,1.535.533-.236,1.364,7.173,3.794v3.2h3.615l7.41,3.556,5.69-.474,2.193,1.245h3.379l.651-1.067-1.244-.711,1.6-1.957,2.43-1.067h1.424l1.777,1.779-.237.889,4.388,3.438v3.557l-2.728,3.794h-2.9v2.134l-1.956.415-2.728,1.126-2.549,3.734h-1.541v3.186h2.313l-1.758,1.756h-1.681v2.646l4.742.711,13.279,7.173,62.122-11.263,56.553-38.938,6.4-29.173-18.08,2.727Zm-139.362-92.652.829-1.66,7.231.712,4.031,4.5-.948,2.134-2.371-.474-2.846-3.121,1.186,3.6-1.186,2.608v3.438h-2.252l-.83-3.557-2.608,1.66-.948-1.185,1.778-2.347-1.186-3.344-2.134-2.015,2.253-.949Zm-5.929,5.1-2.37.593-.237,3.6,1.185,4.08-2.964,5.745-1.357.568-1.369-4.03,1.363-7.114-1.363-1.541,2.727-5.928,3.2-1.067,3.083,1.067-1.9,4.031Zm-7.943-17.665h4.031l2.253,4.387h2.607l.949,5.572-7.642.948-2.82-1.66-1.157-1.659-7,3.319-3.2-1.778,11.975-9.129Z"></path><path d="M8521.71,4319.822l2.49,1.3,7.231-3.895,2.608,1.287,12.212.661,4.86,1.947v2.49l12.33-3.192-1.541-1.195-19.918-3.675-1.541-1.186-10.907.711-7.825,4.742Z"></path>
                  <path d="M8569.845,4322.9l-6.4,2.49.711,1.067,9.366-1.778,2.253-1.778,5.572-2.371h3.319v-1.541l-7.469-1.761-10.078,2.472-.236,1.3,2.964,1.9Z"></path>
                  <path d="M8589.644,4317.232l.83,1.761,3.794-2.371-1.3-1.3-3.319,1.915Z"></path>
                  <path d="M8460.772,4102.389v4.979l8.773-3.557-3.558,5.81,3.558,3.2h-4.492l.816,3.32,2.608,2.667-.237,1.719,4.624,1.067,6.876-2.786,3.912,3.5h1.66l-.593-2.016h1.778l.83-2.252-3.083-4.15.119-8.773-2.371-.593-2.134,4.742-.119-4.742h-1.423l-1.066,2.964-3.307-4.505v-2.489l-3.807-5.121h-3.32l-.83,2.394-5.216,4.624Z"></path>
                  <path d="M8472.628,4090.534l2.134,2.015h3.913l-3.023,3.912,1.363,1.067h2.134l-1.423,1.186.949,1.186,8.654-1.542-.475-3.142-1.541-2.193-1.778.593.355,3.2-1.3-.475-2.608-4.031,1.541-3.083-1.541-.948h-3.438l-3.912,2.252Z"></path>
                  <path d="M8490.886,4104.049l-2.964,4.79,4.031,5.406,2.489-1.067,1.067-3.557-1.067-6.521-3.557.949Z"></path>
                  <path d="M8496.932,4100.611h-3.912l-3.319-3.319v-3.2l2.846,1.281,1.9-1.755,1.9,2.964.593,4.031Z"></path>
                  <path d="M8501.438,4102.389h13.9v-4.268l-7.883.593-6.018-4.15h-4.506l.949,1.541,3.912,3.319-.237,2.016"></path>
                  <path d="M8492.664,4085.673v1.66l2.846,3.912,1.422-2.016-2.134-4.624-2.134,1.067Z"></path>
                  <path d="M8501.082,4080.279l-1.66,3.735.83,3.32,3.912,3.083,1.971-1.541,1.32,2.371-1.75,3.32,1.75,2.015,8.92-1.209-1.037-2.348,1.512-3.438-1.512-4.505,3.172-2.608,1.244-8.417-4.416-.711-11.174,4.1-.711,2.833Z"></path>
                  <path d="M8497.406,4105.116l-.475,5.335,2.49.474,2.253-1.541,1.541-3.379-3.105-1.481-2.7.593Z"></path>
                </g>
                <path d="M8507.454,4016.6c104.57,0,189.373,84.939,189.373,189.68s-84.8,189.678-189.373,189.678-189.371-84.938-189.371-189.678,84.8-189.68,189.371-189.68Z" fill="none" stroke="#000" stroke-miterlimit="10" stroke-width="3.904" fill-rule="evenodd"></path>
                <path d="M8768.5,4206.086c0-163.639-132.655-296.295-296.294-296.295s-296.294,132.656-296.294,296.295,132.656,296.294,296.294,296.294" fill="none" stroke="#fff" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2.8" stroke-dasharray="0 8" opacity="0.75"></path>
                <path d="M8490.071,4501.85c149.485-8.889,269.135-128.608,277.914-278.125" fill="none" stroke="#fff" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2.8" stroke-dasharray="0 8" opacity="0.75"></path>
                <path d="M8527.556,3839.565c-195.539,7.822-351.662,168.815-351.662,366.272" fill="none" stroke="#fff" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2.8" stroke-dasharray="0 8" opacity="0.75"></path>
                <path d="M8542.613,3840.34c202.521,0,366.7,163.749,366.7,365.744" fill="none" stroke="#fff" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2.8" stroke-dasharray="0 8" opacity="0.75"></path>
                <path d="M8908.251,4225.5c-10.12,212.656-185.737,381.96-400.9,381.96C8285.69,4607.461,8106,4427.767,8106,4206.1s179.694-401.358,401.357-401.358a399.5,399.5,0,0,1,201.611,54.236" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="2.8"></path>
                <path d="M8908.711,4206.1a400.05,400.05,0,0,0-114.4-280.618" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="2.8"></path>
                <path d="M8533.657,4298.614c106.21,75.39,216.023,39.713,234.328-74.889" fill="none" stroke="#000" stroke-miterlimit="10" stroke-width="12"></path>
                <path d="M8908.528,4217.788c-6.18,196.941-167.775,354.7-366.217,354.7-202.355,0-366.4-164.043-366.4-366.4" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="2.8"></path>
                <path d="M8240.311,4198.341q.1-3.745.31-7.463c7.667-137.344,122.6-246.377,263.255-246.377,145.617,0,263.662,116.858,263.662,261.009" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="2.8"></path>
                <path d="M8767.911,4222.568a265.358,265.358,0,0,1-5.2,37.594c-25.406,119.636-131.4,209.374-258.3,209.374-145.855,0-264.095-118.548-264.095-264.783" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="2.8"></path>
                <path d="M8768.509,4206.084c0-163.64-132.657-296.3-296.3-296.3-159.8,0-290.055,126.5-296.08,284.832" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="2.8"></path>
                <path d="M8533.657,4298.614c106.21,75.39,216.023,39.713,234.328-74.889" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="2.8"></path>
                <rect width="57.364" height="2.839" transform="matrix(0.933, 0.36, -0.36, 0.933, 8729.285, 3875.936)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <path d="M8753.763,3885.372l6.066-15.735,4.568,1.761-6.066,15.735" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></path>
                <path d="M8757.31,3889.782l-5.521,14.319-4.568-1.761,5.521-14.319" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></path>
                <rect width="8.058" height="4.146" transform="matrix(0.933, 0.36, -0.36, 0.933, 8750.846, 3870.538)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="3.899" height="4.146" transform="matrix(0.933, 0.36, -0.36, 0.933, 8762.933, 3875.198)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8739.28, 3850.008)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8746.226, 3852.686)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8726.896, 3882.131)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8733.842, 3884.809)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8781.736, 3866.376)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8788.682, 3869.054)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8769.352, 3898.499)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="4.419" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8776.297, 3901.177)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="5.772" height="5.772" transform="matrix(0.933, 0.36, -0.36, 0.933, 8743.011, 3888.344)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="5.772" height="5.772" transform="matrix(0.933, 0.36, -0.36, 0.933, 8758.92, 3894.477)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="11.862" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8739.28, 3850.008)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="11.862" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8781.736, 3866.376)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="11.862" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8726.896, 3882.131)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <rect width="11.862" height="23.985" transform="matrix(0.933, 0.36, -0.36, 0.933, 8769.352, 3898.499)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <line x1="1.368" y2="3.547" transform="translate(8777.274 3890.89)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <line x1="1.368" y2="3.547" transform="translate(8774.886 3897.085)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <line x1="1.368" y2="3.547" transform="translate(8761.613 3891.968)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <line x1="1.368" y2="3.547" transform="translate(8745.703 3885.835)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <line x1="1.368" y2="3.547" transform="translate(8732.431 3880.718)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <line x1="1.368" y2="3.547" transform="translate(8734.819 3874.522)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <rect width="4.029" height="2.733" transform="matrix(0.933, 0.36, -0.36, 0.933, 8749.354, 3874.407)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></rect>
                <line x2="2.032" y2="0.784" transform="translate(8765.825 3878.535)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <circle cx="0.987" cy="0.987" r="0.987" transform="translate(8760.017 3872.409)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></circle>
                <circle cx="0.987" cy="0.987" r="0.987" transform="translate(8750.595 3896.848)" fill="#454545" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></circle>
                <line y1="0.772" x2="5.545" transform="translate(8754.642 3882.32)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <line x1="3.592" y1="4.294" transform="translate(8755.618 3880.559)" fill="none" stroke="#fff" stroke-miterlimit="10" stroke-width="0.586"></line>
                <circle cx="19" cy="19" r="19" transform="translate(8517.738 4280.299)" fill="#fff" stroke="#000" stroke-miterlimit="10" stroke-width="6.625"></circle>
                <circle cx="19" cy="19" r="19" transform="translate(8748.785 4188.953)" fill="#fff" stroke="#000" stroke-miterlimit="10" stroke-width="6"></circle>
                <circle cx="19" cy="19" r="19" transform="translate(8157.298 4188.953)" fill="#fff" stroke="#000" stroke-miterlimit="10" stroke-width="6"></circle>
                <circle cx="19" cy="19" r="19" transform="translate(8889.737 4188.953)" fill="#fff" stroke="#000" stroke-miterlimit="10" stroke-width="6"></circle>
                <text transform="translate(8567.396 4299.299)" font-size="40" font-family="D-DIN-Regular, D-DIN-Bold, D-DIN" font-weight="700">
                  <tspan x="0" y="0">01</tspan>
                </text>
              </g>
              <g transform="translate(-7962.74 -3575.641)">
                <line y2="163.92" transform="translate(8178.295 4238.803)" fill="none" stroke="#8c9091" stroke-miterlimit="10" stroke-width="4.033"></line>
                <line y1="163.917" transform="translate(8767.001 4014.57)" fill="none" stroke="#8c9091" stroke-miterlimit="10" stroke-width="4.033"></line>
                <line y1="163.917" transform="translate(8907.791 4017.57)" fill="none" stroke="#8c9091" stroke-miterlimit="10" stroke-width="4.033"></line>
                <text transform="translate(8167.648 4240.383) rotate(90)" fill="#fff" font-size="21.508" font-family="D-DIN-Regular, D-DIN-Bold, D-DIN" font-weight="700" letter-spacing="0.15em" opacity="0.75">
                  <tspan x="0" y="18">THRUSTER</tspan>
                  <tspan x="0" y="42.197">BURN</tspan>
                </text>
                <text transform="translate(8922.517 4171.915) rotate(-90)" fill="#fff" font-size="21.508" font-family="D-DIN-Regular, D-DIN-Bold, D-DIN" font-weight="700" letter-spacing="0.15em" opacity="0.75">
                  <tspan x="0" y="18">THRUSTER</tspan>
                  <tspan x="0" y="42.197">BURN</tspan>
                </text>
                <text transform="translate(8794.306 4246.816)" fill="#fff" font-size="40" font-family="D-DIN-Regular, D-DIN-Bold, D-DIN" font-weight="700">
                  <tspan x="0" y="0">02</tspan>
                </text>
                <text transform="translate(8937.897 4246.816)" fill="#fff" font-size="40" font-family="D-DIN-Regular, D-DIN-Bold, D-DIN" font-weight="700">
                  <tspan x="0" y="0">03</tspan>
                </text>
                <text transform="translate(8119.102 4187.081)" fill="#fff" font-size="40" font-family="D-DIN-Regular, D-DIN-Bold, D-DIN" font-weight="700">
                  <tspan x="0" y="0">03</tspan>
                </text>
              </g>
            </g>
          </g>
        </svg>
        <div>
            <p><span>01. <span>LIFTOFF</span></span>
            </p>
            <p><span>02. <span>ORBIT ACTIVATION</span></span>
            </p>
            <p><span>03. <span>PHASING BURNS</span></span>
            </p>
          </div>
      </div>
    <div>
        <p><img src="https://www.spacex.com/static/images/infographics/nosecone-mobile.jpg" alt=""></p><div>
            <p><span>04. <span>APPROACH INITIATION</span></span>
            </p>
            <p><span>05. <span>PROXIMITY OPERATION</span></span>
            </p>
            <p><span>06. <span>DOCKING &amp; PRESSURIZATION</span></span>
            </p>
          </div>
      </div>
  </div>
  <div>
      <h2>To The space station</h2>
      <p id="to-the-iss-dynamic-mobile-present-tense">
        On its flight to the International Space Station, Dragon executes a series of burns that position the vehicle
        progressively closer to the station before it performs final docking maneuvers, followed by pressurization of
        the vestibule, hatch opening, and crew ingress.
      </p>
      <p id="to-the-iss-dynamic-mobile-past-tense">
        On its flight to the International Space Station, Dragon executed a series of burns that positioned the vehicle
        progressively closer to the station before it performed final docking maneuvers, followed by pressurization of
        the vestibule, hatch opening, and crew ingress.
      </p>
    </div>
  
  
</div>


<div id="to-the-iss">
    <div>
      <h3>Mission</h3>
      <h2>To The space station</h2>
      <p id="to-the-iss-dynamic-desktop-present-tense">
        On its flight to the International Space Station, Dragon executes a series of burns that position the vehicle
        progressively closer to the station before it performs final docking maneuvers, followed by pressurization of
        the vestibule, hatch opening, and crew ingress.
      </p>
      <p id="to-the-iss-dynamic-desktop-past-tense">
        On its flight to the International Space Station, Dragon executed a series of burns that positioned the vehicle
        progressively closer to the station before it performed final docking maneuvers, followed by pressurization of
        the vestibule, hatch opening, and crew ingress.
      </p>
    </div>
    <div>
      <p>
        <svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 1745.1 828.91"><defs><clipPath id="clip-path"><circle cx="414.24" cy="488.01" r="147.44"></circle></clipPath></defs><rect width="1745.1" height="828.91"></rect><g id="EARTH-ILLUSTRATION-FULL"><g id="EARTH"><path d="M414.23,340.57c81.29,0,147.21,66,147.21,147.44S495.52,635.45,414.23,635.45,267,569.43,267,488,333,340.57,414.23,340.57Z"></path><path d="M414.23,340.57c81.29,0,147.21,66,147.21,147.44S495.52,635.45,414.23,635.45,267,569.43,267,488,333,340.57,414.23,340.57Z"></path><path d="M414.23,340.57c81.29,0,147.21,66,147.21,147.44S495.52,635.45,414.23,635.45,267,569.43,267,488,333,340.57,414.23,340.57Z"></path><path d="M414.23,340.57c81.29,0,147.21,66,147.21,147.44S495.52,635.45,414.23,635.45,267,569.43,267,488,333,340.57,414.23,340.57Z"></path><g><polygon points="477.25 469.37 478.9 467.94 479.18 472.04 481.12 472.04 481.12 473.14 484.11 471.62 485.22 471.67 485.73 473.37 487.25 473.37 490.43 479.41 487.15 479.41 486.51 477.44 485.08 481.25 483.83 478.86 477.25 481.85 477.02 481.12 478.58 478.35 477.48 477.66 477.25 469.37 477.25 469.37"></polygon><polygon points="465.27 478.9 470.93 478.63 470.93 479.87 467.52 480.52 465.27 479.57 465.27 478.9 465.27 478.9"></polygon><polygon points="429.23 434.3 428.17 436.65 429.88 438.54 434.62 436.42 438.26 439.88 445.41 441.49 447.89 441.49 447.89 440.38 443.43 437.43 445.55 437.48 449.28 439.23 448.54 437.06 449.28 435.87 441.21 430.25 441.44 428.13 448.22 431.63 447.8 429.46 448.26 427.67 447.89 425.31 444.44 424.21 442.78 422.37 437.34 422.37 438.13 419.46 424.76 411.21 424.76 409.65 420.75 408.91 416.15 410.62 415.87 409.88 413.75 409.88 411.68 412.14 411.68 416.74 414.53 417.85 412.55 418.77 414.24 420.71 424.07 420.8 423.8 419.23 431.4 423.93 434.39 427.16 432.78 430.75 434.44 433.33 429.23 434.3 429.23 434.3"></polygon><polygon points="428.63 424.53 427.67 426.74 428.36 428.17 429.05 428.17 430.48 426.35 429.88 425.2 428.63 424.53 428.63 424.53"></polygon><polygon points="417.3 433.61 415.36 440.8 417.9 440.8 417.9 442.69 421.31 439.6 424.86 440.94 425.36 440.11 423.52 439.6 420.36 435.73 418.5 435.91 417.81 433.84 417.3 433.61 417.3 433.61"></polygon><polygon points="420.36 443.56 420.36 445.4 421.63 445.4 423.8 443.01 423.11 442.69 422.08 442.69 420.36 443.56 420.36 443.56"></polygon><polygon points="427.25 444.05 426.19 444.99 426.72 446.33 427.25 446.74 427.67 445.68 427.25 444.05 427.25 444.05"></polygon><polygon points="336.71 444.81 337.95 444.35 338.51 445.31 337.61 449.18 336.2 448.45 336.71 444.81 336.71 444.81"></polygon><polygon points="335 449.69 336.89 451.26 334.73 453.79 334.73 458.03 333.62 456.97 333.62 450.7 335 449.69 335 449.69"></polygon><polygon points="320.86 375.09 330.07 370.21 332.33 370.21 332.01 371.59 334.08 372.28 334.08 373.52 336.43 373.48 336.43 372.19 336.02 370.85 336.85 370.48 338.28 370.21 340.03 367.9 338.32 366.89 336.11 368.18 336.06 367.26 347.54 359.1 348.5 354.91 363.2 340.57 423.11 334.73 510.38 354.91 562.44 407.25 569.45 490.29 568.34 505.31 561.68 504.57 557.56 496.11 556.27 473.14 555.16 468.81 554.43 458.03 551.02 451.39 546.59 437.2 545.76 437.66 545.67 439.97 544.84 440.06 544.57 438.03 542.82 437.76 537.56 430.2 535.53 428.73 535.53 417.2 530.1 412.6 528.25 412.04 527.79 413.98 526.04 413.06 525.49 408.91 524.11 407.25 524.01 404.86 520.88 402.28 523.74 411.68 522.63 411.86 520.88 407.25 520.42 408.91 516.37 405.41 516.37 403.29 512.87 401.8 512.87 403.38 506.05 401.17 504.75 399.14 504.57 396.47 506.87 395.64 510.28 398.77 514.8 398.96 517.2 399.51 518.49 397.94 514.43 394.35 512.13 388.91 503.46 385.6 502.82 387.44 499.69 386.79 489.73 379.33 470.75 369.47 462.45 362.74 462 356.2 463.29 355.37 461.63 353.99 457.75 354.63 456.46 353.62 456.1 352.79 454.25 352.51 452.23 353.62 451.58 352.7 451.76 351.41 443.38 348.18 443.47 349.55 446.51 350.48 447.53 352.14 446.61 353.53 437.48 353.99 426.98 352.79 427.16 351.87 443.1 351.68 443.47 350.76 437.3 347.23 435.73 347.23 430.11 349.55 429.07 348.18 426.88 348.18 424.95 347.23 416.43 347.81 415.09 349.55 407.35 350.48 404.49 352.33 396.75 351.77 395.37 349.55 387.44 351.22 386.98 352.24 382.1 353.25 378.32 352.24 377.67 354.17 373.25 356.38 374.63 358.04 373.8 358.69 371.96 357.95 363.3 362.28 360.9 366.24 356.02 366.7 353.44 371.5 351.04 372.6 350.67 373.8 352.97 373.71 350.49 378.41 342.38 386.52 343.21 386.89 339.98 390.94 338.6 390.06 335.83 390.57 335.56 389.56 338.78 386.06 338.97 384.12 337.03 382.92 331.96 385.69 331.41 381.26 329.11 380.07 330.76 377.86 330.4 376.75 331.41 374.63 328.83 374.44 328 375.64 322.29 376.75 320.86 375.09 320.86 375.09"></polygon><polygon points="512.68 405.32 512.68 407.25 514.06 408.27 514.06 410.29 519.96 414.81 518.95 409.56 515.17 406.24 512.68 405.32 512.68 405.32"></polygon><polygon points="406.61 352.6 404.12 353.71 407.16 354.82 407.99 353.16 406.61 352.6 406.61 352.6"></polygon><polygon points="409.28 353.16 407.99 354.82 409.28 355.46 410.76 356.66 412.42 356.11 412.88 354.36 409.28 353.16 409.28 353.16"></polygon><polygon points="439.51 365.05 440.25 366.52 443.47 367.81 443.47 369.93 447.16 369.93 452.78 367.99 447.43 366.98 448.45 365.69 447.06 365.05 444.39 366.61 441.35 365.05 439.51 365.05 439.51 365.05"></polygon><polygon points="482.27 395.92 482.27 399.97 480.7 401.35 482.39 404.12 484.39 404.12 483.72 405.32 485.77 405.32 486.32 404.39 490.43 403.2 488.54 398.5 486.05 395.55 482.27 395.92 482.27 395.92"></polygon><polygon points="471.12 406.51 474.8 413.15 472.78 416.1 473.38 419.51 475.73 422.09 475.73 425.96 479.96 430.94 480.7 433.61 478.58 434.16 474.71 431.49 473.42 434.16 464.02 428.17 460.43 424.53 457.85 424.53 452.79 415.73 454.62 413.98 447.99 408.91 446.15 410.39 443.1 406.61 434.44 399.97 429.07 401.8 424.95 399.97 424.95 397.48 422.83 396.56 423.2 395.55 425.36 392.6 425.36 391.49 424.3 391.13 425.36 385.32 428.54 382.92 427.67 379.79 431.31 377.67 437.2 377.67 438.59 375.74 439.51 376.56 444.67 379.88 452.79 382.92 452.79 384.12 457.57 384.31 464.85 392.69 467.8 392.6 471.21 395.55 472.41 399.24 472.59 404.49 471.12 406.51 471.12 406.51"></polygon><path d="M533.83,572.9l-6.73,7.28-6.86,5.26-2.58-.05.64-1.06-1.8-.18-.09-2.4-5.53,1.76-.6,1-6.45,3.68-2.85-.41-.14-1-3,.32L495,588.38l-.18-1.33-4.66.27-5.76,3.55L475.36,593l-.33-1-5.2-.37-.05,1.2-3.91,2.39-.56-.87,2.63-2-2.07-.87L460.61,596l-2.12.18-.55,1.06-2.58.14-1.61,3.46-3.87,3.22-2.26-1.11-5.62.14-7,2.31-5.53-3.32,1-9.4-5.3-1.48-11.7.7,1.84-1.94.28-3.64h.79l1.33-4.7,1.5-1.5v-2.28h-7.21l-4,2v2.49L405,585.46H395.5l-3.18-1.31-6.54-9.5v-8.71H388l.33-1.79-1.06-3.92,3.08-2.3v-1.39h2.86l2.53-1.88h8.11l3.92,2.21,2.12-.83,1.89.73V553h9.49l2.12,1.75h1.34l2-1.52,4.28,2.91V560l2.67,2.81v2l2,.65,1.34,1.33h1.66l1.15-4.93-5.21-10v-3.73l4.52-5.3h.87l1.8-3.27,1.57,0,1.38-2.54,5-3-2.35-6.22,2-4.88-1.89-2.91.6-.87,1.8,1.56,1.47-3.45-.41-1,1.33-1.52,2-.65,2.81-3.68.75.75,1.32-1.12-.37-1-1.29-.85.46-4.59,2-1.71.78-1.93,1.71-.09,2.26-2.86v-.81l2.11-1.13,1.76-2.62,2.76.43-.6,2.06-2.72.83-1,2.9.23,1.06,1.84.64,2.26-4.17,5.62-4.17-1.43-1.38,2-1,.36-2.17-1.29-.46-.69-2.07-.78.14-.65,5-1.24,1.15-4.47.14-2.49-2.53v-2.56H465l1.8-3-2-1.93L461,483.37l-5,5.39,1.71-5.16,2.12-1.06.78-3.64,10.23-2.81,3.09-4,.23-1.66,2.9-1.8.79-3.45-2-3.78-1.84-.28-.74,1.34-.55-1.57-1.52-.32.09-1.66h-3.59L461,456l1.19-1.79-10-8.76v6l-1.75,2.17-5-3.64-.92-4h-2.82l-4.83-3.5-1,1-4.1-.13-1.66.69,2,8.11-1.2,4.56,2.3.73,2.72,5.3-1.2,4.34-3.13,3.31,3,8.11.05,1.75-.55,1.34-1.38-1-.56,1.43-5.71-5.57v-6.87l-4.84-.88-1.15.28-2-1.24-3-.51L409.14,462l-4.1.79v-5.95l-2.65.26v-3L407.44,444l2.42-1.1v-1L407,440.43h3.53l2.63-.69,1.93-3.32-3.87-2.49v-.74l3.87,2.12,1.39-2.48-.74-.88,2.07-.46v-1.15l2.21,1.43,2.77-3.18-1.29-1.85.18-3.68-2.21-1.29h-2.35l-.42,1,1.06,1.85-2.9,5.11-1.61-2.53,1-1.71L412.5,423l-1.19,3.13-.83-3.91-2.17-.46.93-.69-2.86-5.81-2.21,1.89.37,3.73,2.39,1.43-.23,1.29-2.63,3.59.05,2.54-.6-.09-1.06-3.18-1.1-.65-1.34.92-4.19.1-2.45-.79-2.11-4.19L388.59,423l-.23,3.36-.78.05-1.38-2.9-2.45,1.1-3.5-2.25,1.85-1.11-.33-1.34-6.54-6.08-.74,1v-2.07l-2.21.73v-2.76l-3,.37,1-1.39h-4.7v-1.1h-2.07l-1.43.28-1.93-6.78-2.22-4.38-.46-.36.37-1.62-.14-2.44L355,391.08l-2.58-.42-2.16,1.16-1.2-.93-.42-.82h-1.19l-4.57,7.37-.5-.14-.83-1.94,1.29-.64-.28-.78-2.76-1.16-1.06,1.89-1.25.23-.55,1.94.69,2.49,1.75.46-.78.69-2.31,1.32-2.12-1v-1.25h-1l-4.2,1.11L325.56,405l.5,1.94-2.67,2.39.83,2.21-.6,1.16,1.43,1.42-3,2.08-5.21-.51-1.71-1.29-1.15.05-.5-.83-1.16-.05v1.2l5.9,3.5,7.33-.14,2.12-1.93,2.21.14,1.57-1,3.22.14-.27,1.15-3.09.09-1.66,1.8-1.2-.09,1.89,1.7h2.44l2.44-1.94.88.56v5.34l2.63,3.37,1.61-.42.64,1.15-2.3,1.34-.23,5.39.6,1-.32,1-.42-.14L337,442.41l.78,1.15,1.62-.09-.56,5.48.6,1.8-.6,2.07-1.65.1.13,2.39.83.78-.73,4.2.27,3.18-2.16.27-.28,1.57,3,8.85-1.2.64.32,4.93-.55.51-.28,1.52-4.51,8.39-1.53,1-.23,4.75-2,3.09.14,6.22,1.43,2.93v2.74h-.83l.6,1.38-.46,1.66,1.29,3.59-.23,2.81,6,7.33,2.12,12.25,3,3.51.32,3.82-2.49-1.52-.46.78,6.82,7.33.09,3.73,4.75,6.68,1.43-1.79-1-2.08-1.19,0-2.12-7.56-2.49-3.64.14-2.86L342,541l-.09-5.58L346,538l.73,7.74,4,4.66.09,1.56,2.81,3.87-1,.83.42,1.06,9.26,10.78,1.06,4.89-.55,1.2h-.65l.18,1.43,24.93,14.6h7.51l10,5.67,3.78.28,4.79,1.52,3.05-.42,1.19.42-.18,1.06,5.57,3v2.48h2.81l5.76,2.77L436,607l1.7,1h2.63l.5-.83-1-.56,1.24-1.52,1.89-.83h1.11l1.38,1.39-.19.69,3.41,2.67v2.77l-2.12,2.94h-2.25v1.66l-1.52.33-2.12.87-2,2.9h-1.2v2.48h1.79L438,624.3h-1.31v2.05l3.69.56,10.32,5.57L499,623.73l44-30.27,5-22.68-14,2.12Zm-108.33-72,.65-1.29,5.62.56,3.13,3.5-.74,1.66-1.84-.37-2.21-2.43.92,2.8-.92,2V510h-1.75l-.65-2.77-2,1.29-.74-.92,1.38-1.82-.92-2.6-1.66-1.57,1.75-.74Zm-4.61,4-1.84.46-.18,2.79.92,3.17-2.31,4.47-1.05.44-1.07-3.13,1.06-5.53-1.06-1.2,2.12-4.61,2.49-.83,2.4.83-1.48,3.14Zm-6.17-13.74h3.13l1.75,3.41h2l.74,4.34-5.94.73-2.19-1.29-.9-1.29-5.44,2.58-2.49-1.38,9.31-7.1Z"></path><polygon points="425.32 576.27 427.25 577.28 432.87 574.25 434.9 575.25 444.39 575.77 448.17 577.28 448.17 579.22 457.75 576.73 456.56 575.8 441.07 572.95 439.88 572.03 431.4 572.58 425.32 576.27 425.32 576.27"></polygon><polygon points="462.73 578.66 457.75 580.6 458.31 581.43 465.59 580.04 467.34 578.66 471.67 576.82 474.25 576.82 474.25 575.62 468.44 574.25 460.61 576.17 460.43 577.19 462.73 578.66 462.73 578.66"></polygon><polygon points="478.12 574.25 478.77 575.62 481.72 573.78 480.7 572.76 478.12 574.25 478.12 574.25"></polygon><polygon points="377.95 407.25 377.95 411.12 384.77 408.36 382 412.87 384.77 415.36 381.28 415.36 381.91 417.94 383.94 420.02 383.75 421.35 387.35 422.18 392.69 420.02 395.74 422.73 397.02 422.73 396.56 421.17 397.95 421.17 398.59 419.42 396.19 416.19 396.29 409.37 394.44 408.91 392.79 412.6 392.69 408.91 391.59 408.91 390.76 411.21 388.19 407.71 388.19 405.78 385.23 401.8 382.65 401.8 382 403.66 377.95 407.25 377.95 407.25"></polygon><polygon points="387.16 398.04 388.82 399.6 391.86 399.6 389.51 402.64 390.57 403.47 392.23 403.47 391.13 404.39 391.86 405.32 398.59 404.12 398.22 401.68 397.02 399.97 395.64 400.43 395.92 402.92 394.9 402.55 392.88 399.42 394.08 397.02 392.88 396.29 390.2 396.29 387.16 398.04 387.16 398.04"></polygon><polygon points="401.36 408.54 399.05 412.27 402.19 416.47 404.12 415.64 404.95 412.87 404.12 407.81 401.36 408.54 401.36 408.54"></polygon><polygon points="406.06 405.87 403.01 405.87 400.44 403.29 400.44 400.8 402.65 401.8 404.12 400.43 405.6 402.74 406.06 405.87 406.06 405.87"></polygon><polyline points="409.56 407.25 420.36 407.25 420.36 403.94 414.24 404.39 409.56 401.17 406.06 401.17 406.79 402.37 409.83 404.95 409.65 406.51"></polyline><polygon points="402.74 394.26 402.74 395.55 404.95 398.59 406.06 397.02 404.4 393.43 402.74 394.26 402.74 394.26"></polygon><polygon points="409.28 390.06 407.99 392.97 408.64 395.55 411.68 397.94 413.21 396.75 414.24 398.59 412.88 401.17 414.24 402.74 421.17 401.8 420.36 399.97 421.54 397.3 420.36 393.8 422.83 391.77 423.8 385.23 420.36 384.67 411.68 387.86 411.13 390.06 409.28 390.06 409.28 390.06"></polygon><polygon points="406.43 409.37 406.06 413.52 407.99 413.89 409.74 412.69 410.94 410.06 408.53 408.91 406.43 409.37 406.43 409.37"></polygon></g><path d="M414.23,340.57c81.29,0,147.21,66,147.21,147.44S495.52,635.45,414.23,635.45,267,569.43,267,488,333,340.57,414.23,340.57Z"></path></g><line x1="156.52" y1="487.86" x2="156.52" y2="589.14"></line><polygon points="151.29 587.61 156.52 596.68 161.76 587.61 151.29 587.61"></polygon><line x1="617.15" y1="487.86" x2="617.15" y2="386.57"></line><polygon points="622.39 388.11 617.15 379.04 611.91 388.11 622.39 388.11"></polygon><line x1="726.14" y1="487.86" x2="726.14" y2="386.57"></line><polygon points="731.37 388.11 726.14 379.04 720.9 388.11 731.37 388.11"></polygon><polyline points="617.16 487.86 654.3 518.37 680.31 518.37"></polyline><polyline points="156.53 487.86 93.15 431.12 53.46 431.12"></polyline><text transform="translate(653.89 511.29)">02</text><polyline points="726.14 487.86 763.29 518.37 789.29 518.37"></polyline><text transform="translate(136.18 488.91) rotate(90) scale(1.01 1)">THRUSTER<tspan x="0" y="16.06">BU</tspan><tspan x="21.59" y="16.06">R</tspan><tspan x="32.16" y="16.06">N</tspan></text><text transform="translate(747.86 481.5) rotate(-90) scale(1.01 1)">THRUSTER<tspan x="0" y="16.06">BU</tspan><tspan x="21.59" y="16.06">R</tspan><tspan x="32.16" y="16.06">N</tspan></text><polyline points="434.6 559.78 525.01 686.85 577.84 686.85"></polyline><g id="DRAGON-RETURN"><g><path d="M617.15,487.86c0-127.2-103.11-230.32-230.31-230.32S156.52,360.66,156.52,487.86c0,123.59,97.35,224.44,219.55,230.06"></path><polygon points="373.68 725.29 386.84 718.17 374.1 710.34 373.68 725.29"></polygon></g><path d="M400.72,717.76c116.2-6.91,209.21-100,216-216.19"></path><path d="M429.86,203c-144.53,5.78-261.35,119.21-272.48,262.3"></path><g><path d="M452.33,203.76C604.76,209.4,726.6,334.44,726.6,487.86"></path><polygon points="454.32 211.36 441.56 203.56 454.7 196.41 454.32 211.36"></polygon></g></g><g id="ISS-ORBIT"><path d="M725.5,508.05C715.09,671,579.68,799.85,414.16,799.85c-172.31,0-312-139.68-312-312s139.67-312,312-312a310.48,310.48,0,0,1,156.71,42.16"></path><path d="M726.14,487.87a311,311,0,0,0-88.93-218.13"></path></g><g id="DRAGON-APPROACH"><path d="M434.6,559.78c82.56,58.6,167.92,30.87,182.15-58.21"></path><path d="M434.6,559.78c82.56,58.6,167.92,30.87,182.15-58.21"></path><path d="M725.19,511.2C713.32,657.57,590.77,772.66,441.33,772.66c-157.29,0-284.81-127.51-284.81-284.8"></path><polygon points="720.02 512.24 725.68 504.04 729.96 513.04 720.02 512.24"></polygon><path d="M206.9,474.67c6.65-106.12,95.69-190.15,204.55-190.15,113.19,0,205,90.84,205,202.89"></path><polygon points="212.02 473.48 206.58 481.84 202.06 472.95 212.02 473.48"></polygon><path d="M616.69,500.67a206.33,206.33,0,0,1-4,29.22c-19.75,93-102.14,162.75-200.79,162.75-113.37,0-205.28-92.15-205.28-205.82"></path><path d="M617.16,487.86c0-127.2-103.12-230.32-230.32-230.32-119.17,0-217.21,90.51-229.1,206.55"></path><polygon points="152.97 462.17 157.12 471.24 162.9 463.12 152.97 462.17"></polygon></g><text transform="translate(53.46 425.55)">03</text><g id="DOT"><circle data-index="0" data-name="Ellipse 117" cx="434.6" cy="559.78" r="9.96"></circle></g><g id="DOT-2" data-name="DOT"><circle data-index="1" data-name="Ellipse 118" cx="617.16" cy="487.86" r="9.96"></circle></g><g id="DOT-3" data-name="DOT"><circle data-index="2" data-name="Ellipse 119" cx="726.14" cy="487.86" r="9.96"></circle></g><g id="DOT-4" data-name="DOT"><circle data-index="2" data-name="Ellipse 120" cx="156.53" cy="487.17" r="9.96"></circle></g><text transform="translate(550.41 680.23)">01</text><g id="ISS-SMALL"><rect x="584.78" y="239.17" width="44.59" height="2.21" transform="translate(1074.69 695.91) rotate(-157.34)"></rect><polyline points="608.4 242.03 603.35 254.12 599.84 252.66 604.89 240.56"></polyline><polyline points="605.74 238.53 610.34 227.52 613.85 228.98 609.25 239.99"></polyline><rect x="604.95" y="249.31" width="6.26" height="3.22" transform="translate(1072.53 716.77) rotate(-157.34)"></rect><rect x="598.77" y="246.05" width="3.03" height="3.22" transform="translate(1058.79 707.5) rotate(-157.34)"></rect><rect x="619.19" y="251.23" width="3.43" height="18.64" transform="matrix(-0.92, -0.39, 0.39, -0.92, 1093.47, 740.23)"></rect><rect x="613.85" y="249" width="3.43" height="18.64" transform="translate(1084.07 733.88) rotate(-157.34)"></rect><rect x="629.5" y="226.54" width="3.43" height="18.64" transform="translate(1122.82 696.72) rotate(-157.34)"></rect><rect x="624.16" y="224.31" width="3.43" height="18.64" transform="translate(1113.41 690.38) rotate(-157.34)"></rect><rect x="586.55" y="237.6" width="3.43" height="18.64" transform="translate(1035.97 701.45) rotate(-157.34)"></rect><rect x="581.21" y="235.37" width="3.43" height="18.64" transform="translate(1026.56 695.1) rotate(-157.34)"></rect><rect x="596.86" y="212.91" width="3.43" height="18.64" transform="translate(1065.31 657.94) rotate(-157.34)"></rect><rect x="591.52" y="210.68" width="3.43" height="18.64" transform="translate(1055.9 651.6) rotate(-157.34)"></rect><rect x="613.37" y="234.77" width="4.49" height="4.49" transform="translate(1092.37 692.93) rotate(-157.34)"></rect><rect x="601.14" y="229.66" width="4.49" height="4.49" transform="translate(1070.82 678.4) rotate(-157.34)"></rect><rect x="613.63" y="250.12" width="9.22" height="18.64" transform="translate(1088.77 737.06) rotate(-157.34)"></rect><rect x="580.99" y="236.49" width="9.22" height="18.64" transform="translate(1031.27 698.28) rotate(-157.34)"></rect><rect x="623.94" y="225.42" width="9.22" height="18.64" transform="translate(1118.11 693.55) rotate(-157.34)"></rect><rect x="591.3" y="211.79" width="9.22" height="18.64" transform="translate(1060.61 654.77) rotate(-157.34)"></rect><line x1="589.19" y1="237.21" x2="590.33" y2="234.48"></line><line x1="591.18" y1="232.44" x2="592.32" y2="229.72"></line><line x1="601.38" y1="236.7" x2="602.52" y2="233.98"></line><line x1="613.61" y1="241.81" x2="614.75" y2="239.08"></line><line x1="623.82" y1="246.07" x2="624.96" y2="243.35"></line><line x1="621.83" y1="250.84" x2="622.97" y2="248.11"></line><rect x="601.78" y="230.53" width="3.13" height="2.12" transform="translate(123.7 -201.53) rotate(21.08)"></rect><line x1="615.07" y1="233.25" x2="616.65" y2="233.86"></line><circle cx="611.32" cy="229.25" r="0.77"></circle><circle cx="604" cy="248.25" r="0.77"></circle><line x1="606.38" y1="236.79" x2="610.69" y2="236.19"></line><line x1="609.93" y1="238.16" x2="607.14" y2="234.82"></line></g><text transform="translate(763.47 511.81)">03</text></g><g id="AP-POINTER"><line x1="647.02" y1="249.14" x2="905.57" y2="216.14"></line><path d="M648.39,256.55a7.52,7.52,0,1,1,6.51-8.41A7.53,7.53,0,0,1,648.39,256.55Z"></path><path d="M648.52,257.54a8.52,8.52,0,1,0-9.53-7.37,8.52,8.52,0,0,0,9.53,7.37Zm-1.9-14.92a6.52,6.52,0,1,1-5.64,7.3,6.54,6.54,0,0,1,5.64-7.3Z"></path><polygon points="903.94 226.4 919.81 214.32 901.41 206.62 903.94 226.4"></polygon></g><g id="APPROACH-FULL"><text transform="translate(1314.91 758.35)">04</text><text transform="translate(1189.45 543.7)">05</text><text transform="translate(1037.76 399.62)">06</text><polyline id="MARKER-LINE" points="1116.68 367.44 1069.85 407.58 1038.03 407.58"></polyline><line id="MARKER-LINE-2" data-name="MARKER-LINE" x1="1328.6" y1="702.73" x2="1328.6" y2="738.92"></line><line id="MARKER-LINE-3" data-name="MARKER-LINE" x1="1148.12" y1="536.19" x2="1184.31" y2="536.19"></line><g><text transform="translate(1366.09 734.04)">F<tspan x="13.62" y="0">INAL C</tspan><tspan x="90.39" y="0">O</tspan><tspan x="105.43" y="0">ELLIPTIC</tspan></text></g><g id="TRAJECTORY-1"><line x1="1576.57" y1="702.73" x2="1363.01" y2="702.73"></line><polygon points="1364.46 697.74 1355.83 702.73 1364.46 707.71 1364.46 697.74"></polygon></g><g id="TRAJECTORY-2"><path d="M1328.6,702.73c-75.36,0-174.7-68.09-180.39-147.81"></path><polygon points="1153.31 556.16 1147.95 547.75 1143.34 556.6 1153.31 556.16"></polygon></g><g id="TRAJECTORY-3"><path d="M1148.12,536.19c-48-31.63-60.74-83.84-40.15-144.24"></path><polygon points="1112.29 394.98 1110.4 385.19 1102.87 391.73 1112.29 394.98"></polygon></g><text transform="matrix(0.93, -0.37, 0.37, 0.93, 1052.13, 64.66)">K</text><text transform="translate(1066.19 59.12) rotate(-18.47)">E</text><text transform="translate(1079.07 54.91) rotate(-15.23)">E</text><text transform="matrix(0.98, -0.21, 0.21, 0.98, 1092.15, 51.42)">P</text><text transform="matrix(0.99, -0.16, 0.16, 0.99, 1106.14, 48.62)"> </text><text transform="matrix(0.99, -0.12, 0.12, 0.99, 1113.54, 47.39)">O</text><text transform="translate(1128.33 45.75) rotate(-3.08)">U</text><text transform="translate(1143.46 44.98) rotate(0.93)">T</text><text transform="translate(1156.38 45.2) rotate(2.57)"> </text><text transform="translate(1163.85 45.53) rotate(5.09)">S</text><text transform="translate(1177.65 46.84) rotate(8.43)">P</text><text transform="translate(1191.71 48.99) rotate(11.92)">H</text><text transform="translate(1206.44 52.22) rotate(15.35)">E</text><text transform="translate(1219.48 55.86) rotate(18.76)">R</text><text transform="translate(1233.37 60.68) rotate(22.11)">E</text><circle id="KEEP-OUT" cx="1147.66" cy="286.5" r="224.28"></circle><g id="ISS"><rect x="1001.88" y="280.35" width="292.46" height="11.98" transform="translate(2116.38 966.51) rotate(-158.92)"></rect><path d="M1108.42,307.71h52.93a2.51,2.51,0,0,1,2.51,2.51v15.25a2.51,2.51,0,0,1-2.51,2.51h-52.93a0,0,0,0,1,0,0V307.71A0,0,0,0,1,1108.42,307.71Z" transform="translate(1841.4 -627.91) rotate(111.08)"></path><path d="M1131.79,239.87h63.52a0,0,0,0,1,0,0v20.27a0,0,0,0,1,0,0h-63.52a2.51,2.51,0,0,1-2.51-2.51V242.38a2.51,2.51,0,0,1,2.51-2.51Z" transform="translate(1813.67 -744.56) rotate(111.08)"></path><path d="M1182.17,336.06l3.56-9.22a1.56,1.56,0,0,0-.89-2l-16-6.17a1.56,1.56,0,0,0-2,.9l-3.56,9.22,1,2.14L1180,337Z"></path><path d="M1120.77,343.12l-1.65,4.28a.81.81,0,0,0,.47,1l8.28,3.19a.81.81,0,0,0,1.05-.46l1.64-4.28-.85-1.82-7.08-2.73Z"></path><polyline points="1174.49 356.6 1139.1 342.95 1138.15 340.81"></polyline><path d="M1144.24,325l2.15-.95,36.71,14.16h0a28.61,28.61,0,0,1-2.64,11.83q-.17.38-.36.75"></path><path d="M1100.62,319.69a2.27,2.27,0,1,1,1.64-4.24"></path><path d="M1125.34,317.7l-1-2.14L1106,308.49h0a48,48,0,0,0-7.29,18.91h0l18.34,7.07,2.15-1"></path><line x1="1244.41" y1="343.29" x2="1218.23" y2="333.2"></line><rect x="1174.94" y="379.43" width="94.26" height="11.53" transform="translate(423.06 1386.9) rotate(-68.92)"></rect><rect x="1159.53" y="373.49" width="94.26" height="11.53" transform="translate(418.73 1368.71) rotate(-68.92)"></rect><rect x="1182.88" y="426.1" width="28.05" height="2.8" transform="translate(2159.91 1256.95) rotate(-158.92)"></rect><rect x="1217.8" y="335.54" width="28.05" height="2.8" transform="translate(2259.99 1094.44) rotate(-158.92)"></rect><rect x="1232.46" y="326.24" width="3.24" height="9.72" transform="translate(2266.44 1083.96) rotate(-158.92)"></rect><line x1="1277.9" y1="356.21" x2="1251.73" y2="346.11"></line><rect x="1208.44" y="392.34" width="94.26" height="11.53" transform="translate(432.45 1426.42) rotate(-68.92)"></rect><rect x="1193.02" y="386.4" width="94.26" height="11.53" transform="translate(428.13 1408.23) rotate(-68.92)"></rect><rect x="1216.38" y="439.02" width="28.05" height="2.8" transform="translate(2220.01 1293.96) rotate(-158.92)"></rect><rect x="1251.29" y="348.45" width="28.05" height="2.8" transform="translate(2320.09 1131.45) rotate(-158.92)"></rect><rect x="1265.95" y="339.15" width="3.24" height="9.72" transform="translate(2326.54 1120.97) rotate(-158.92)"></rect><line x1="1031.19" y1="261.09" x2="1005.02" y2="251"></line><rect x="961.73" y="297.23" width="94.26" height="11.53" transform="translate(363.24 1135.32) rotate(-68.92)"></rect><rect x="946.31" y="291.28" width="94.26" height="11.53" transform="translate(358.91 1117.13) rotate(-68.92)"></rect><rect x="969.67" y="343.9" width="28.05" height="2.8" transform="translate(1777.32 1021.35) rotate(-158.92)"></rect><rect x="1004.58" y="253.34" width="28.05" height="2.8" transform="translate(1877.39 858.84) rotate(-158.92)"></rect><rect x="1019.24" y="244.04" width="3.24" height="9.72" transform="translate(1883.85 848.36) rotate(-158.92)"></rect><line x1="1064.68" y1="274" x2="1038.51" y2="263.91"></line><rect x="995.22" y="310.14" width="94.26" height="11.53" transform="translate(372.63 1174.84) rotate(-68.92)"></rect><rect x="979.81" y="304.2" width="94.26" height="11.53" transform="matrix(0.36, -0.93, 0.93, 0.36, 368.31, 1156.65)"></rect><rect x="1003.16" y="356.81" width="28.05" height="2.8" transform="translate(1837.42 1058.36) rotate(-158.92)"></rect><rect x="1038.08" y="266.25" width="28.05" height="2.8" transform="translate(1937.49 895.85) rotate(-158.92)"></rect><rect x="1052.73" y="256.95" width="3.24" height="9.72" transform="translate(1943.95 885.37) rotate(-158.92)"></rect><line x1="1051.82" y1="229.38" x2="1078" y2="239.47"></line><rect x="1027.03" y="181.71" width="94.26" height="11.53" transform="translate(512.83 1122.29) rotate(-68.92)"></rect><rect x="1042.44" y="187.65" width="94.26" height="11.53" transform="translate(517.16 1140.48) rotate(-68.92)"></rect><rect x="1085.3" y="143.76" width="28.05" height="2.8" transform="translate(125.81 -385.73) rotate(21.08)"></rect><rect x="1050.38" y="234.33" width="28.05" height="2.8" transform="translate(156.05 -367.11) rotate(21.08)"></rect><rect x="1060.54" y="236.71" width="3.24" height="9.72" transform="translate(158 -365.91) rotate(21.08)"></rect><line x1="1018.33" y1="216.46" x2="1044.5" y2="226.56"></line><rect x="993.53" y="168.8" width="94.26" height="11.53" transform="translate(503.44 1082.77) rotate(-68.92)"></rect><rect x="1008.95" y="174.74" width="94.26" height="11.53" transform="translate(507.76 1100.96) rotate(-68.92)"></rect><rect x="1051.8" y="130.85" width="28.05" height="2.8" transform="translate(118.92 -374.55) rotate(21.08)"></rect><rect x="1016.89" y="221.42" width="28.05" height="2.8" transform="translate(149.16 -355.93) rotate(21.08)"></rect><rect x="1027.04" y="223.8" width="3.24" height="9.72" transform="translate(151.11 -354.73) rotate(21.08)"></rect><line x1="1265.04" y1="311.58" x2="1291.22" y2="321.67"></line><rect x="1240.25" y="263.91" width="94.26" height="11.53" transform="translate(572.65 1373.87) rotate(-68.92)"></rect><rect x="1255.66" y="269.86" width="94.26" height="11.53" transform="translate(576.98 1392.05) rotate(-68.92)"></rect><rect x="1298.52" y="225.97" width="28.05" height="2.8" transform="translate(169.65 -456.93) rotate(21.08)"></rect><rect x="1263.6" y="316.53" width="28.05" height="2.8" transform="translate(199.89 -438.31) rotate(21.08)"></rect><rect x="1273.76" y="318.91" width="3.24" height="9.72" transform="translate(201.84 -437.11) rotate(21.08)"></rect><line x1="1231.55" y1="298.67" x2="1257.72" y2="308.76"></line><rect x="1206.75" y="251" width="94.26" height="11.53" transform="translate(563.25 1334.35) rotate(-68.92)"></rect><rect x="1222.17" y="256.94" width="94.26" height="11.53" transform="translate(567.58 1352.53) rotate(-68.92)"></rect><rect x="1265.02" y="213.05" width="28.05" height="2.8" transform="translate(162.77 -445.75) rotate(21.08)"></rect><rect x="1230.11" y="303.62" width="28.05" height="2.8" transform="translate(193.01 -427.13) rotate(21.08)"></rect><rect x="1240.26" y="306" width="3.24" height="9.72" transform="translate(194.96 -425.92) rotate(21.08)"></rect><rect x="1174.55" y="354.43" width="18.02" height="7.41" transform="translate(2159.06 1118.05) rotate(-158.92)"></rect><path d="M1184.78,354.63l1.74-13.94a.3.3,0,0,0-.57-.14l-3.22,8.36-1.54-.59"></path><rect x="1178.01" y="350.63" width="3.08" height="1.92" transform="translate(2153.67 1103.96) rotate(-158.92)"></rect><path d="M1192.7,359.47a2,2,0,0,1-1.46,3.81"></path><rect x="1101.41" y="325.31" width="16.95" height="2.7" rx="0.84" transform="translate(2027.95 1030.7) rotate(-158.92)"></rect><line x1="1119.35" y1="324.48" x2="1104.32" y2="318.68"></line><line x1="1152.19" y1="303.77" x2="1128.91" y2="308.44"></line><line x1="1133.5" y1="296.56" x2="1147.61" y2="315.65"></line><circle cx="1129.15" cy="335.54" r="3.53"></circle><circle cx="1161.74" cy="251" r="5.09"></circle><line x1="1163.07" y1="276.16" x2="1144.16" y2="268.87"></line><line x1="1178.52" y1="236.08" x2="1159.61" y2="228.79"></line><line x1="1172.58" y1="242.67" x2="1159.59" y2="237.67"></line><line x1="1178.91" y1="226.26" x2="1165.92" y2="221.26"></line><line x1="1171.34" y1="238.1" x2="1163.58" y2="235.11"></line><line x1="1172.18" y1="333.99" x2="1164.89" y2="352.9"></line><line x1="1153.08" y1="330.02" x2="1148.07" y2="343.01"></line><line x1="1168.18" y1="272.13" x2="1186.72" y2="224.04"></line><line x1="1169.97" y1="267.49" x2="1166.87" y2="266.3"></line><line x1="1184.96" y1="228.6" x2="1181.87" y2="227.41"></line><line x1="1161.62" y1="214.36" x2="1143.08" y2="262.46"></line><line x1="1159.83" y1="219" x2="1162.93" y2="220.19"></line><line x1="1144.84" y1="257.89" x2="1147.93" y2="259.09"></line><rect x="1194.71" y="282.88" width="8.52" height="6.88" transform="translate(2214.69 984.76) rotate(-158.92)"></rect><rect x="1198.23" y="273.75" width="8.52" height="6.88" transform="translate(2224.77 968.39) rotate(-158.92)"></rect><rect x="1201.74" y="264.63" width="8.52" height="6.88" transform="translate(2234.85 952.02) rotate(-158.92)"></rect><rect x="1205.26" y="255.51" width="8.52" height="6.88" transform="translate(2244.93 935.65) rotate(-158.92)"></rect><rect x="1184.65" y="279" width="8.52" height="6.88" transform="translate(2196.63 973.64) rotate(-158.92)"></rect><rect x="1188.17" y="269.87" width="8.52" height="6.88" transform="translate(2206.72 957.27) rotate(-158.92)"></rect><rect x="1191.68" y="260.75" width="8.52" height="6.88" transform="translate(2216.8 940.9) rotate(-158.92)"></rect><rect x="1195.2" y="251.63" width="8.52" height="6.88" transform="translate(2226.88 924.53) rotate(-158.92)"></rect><rect x="1174.6" y="275.12" width="8.52" height="6.88" transform="translate(2178.6 962.54) rotate(-158.92)"></rect><rect x="1178.12" y="266" width="8.52" height="6.88" transform="translate(2188.68 946.17) rotate(-158.92)"></rect><rect x="1181.63" y="256.88" width="8.52" height="6.88" transform="translate(2198.77 929.8) rotate(-158.92)"></rect><rect x="1185.15" y="247.75" width="8.52" height="6.88" transform="translate(2208.85 913.43) rotate(-158.92)"></rect><line x1="1200.22" y1="283.08" x2="1201.25" y2="280.4"></line><line x1="1203.72" y1="273.98" x2="1204.76" y2="271.3"></line><line x1="1207.24" y1="264.86" x2="1208.28" y2="262.18"></line><line x1="1190.16" y1="279.2" x2="1191.19" y2="276.52"></line><line x1="1193.66" y1="270.1" x2="1194.7" y2="267.42"></line><line x1="1197.18" y1="260.98" x2="1198.22" y2="258.3"></line><line x1="1180.17" y1="275.35" x2="1181.21" y2="272.67"></line><line x1="1183.68" y1="266.26" x2="1184.72" y2="263.57"></line><line x1="1187.2" y1="257.13" x2="1188.23" y2="254.45"></line><rect x="1184.46" y="285.34" width="3.24" height="8.89" transform="translate(183.64 -407.26) rotate(21.08)"></rect><rect x="1126.58" y="256.61" width="8.52" height="6.88" transform="translate(2092.45 909.48) rotate(-158.92)"></rect><rect x="1130.1" y="247.49" width="8.52" height="6.88" transform="translate(2102.53 893.11) rotate(-158.92)"></rect><rect x="1133.62" y="238.37" width="8.52" height="6.88" transform="translate(2112.61 876.74) rotate(-158.92)"></rect><rect x="1137.14" y="229.24" width="8.52" height="6.88" transform="translate(2122.69 860.37) rotate(-158.92)"></rect><rect x="1116.52" y="252.73" width="8.52" height="6.88" transform="translate(2074.39 898.37) rotate(-158.92)"></rect><rect x="1120.04" y="243.61" width="8.52" height="6.88" transform="translate(2084.47 881.99) rotate(-158.92)"></rect><rect x="1123.56" y="234.49" width="8.52" height="6.88" transform="translate(2094.55 865.62) rotate(-158.92)"></rect><rect x="1127.07" y="225.36" width="8.52" height="6.88" transform="translate(2104.64 849.25) rotate(-158.92)"></rect><rect x="1106.47" y="248.86" width="8.52" height="6.88" transform="translate(2056.36 887.26) rotate(-158.92)"></rect><rect x="1109.99" y="239.74" width="8.52" height="6.88" transform="translate(2066.44 870.89) rotate(-158.92)"></rect><rect x="1113.51" y="230.61" width="8.52" height="6.88" transform="matrix(-0.93, -0.36, 0.36, -0.93, 2076.52, 854.52)"></rect><rect x="1117.03" y="221.49" width="8.52" height="6.88" transform="translate(2086.6 838.15) rotate(-158.92)"></rect><line x1="1132.09" y1="256.82" x2="1133.13" y2="254.13"></line><line x1="1135.6" y1="247.72" x2="1136.63" y2="245.04"></line><line x1="1139.12" y1="238.6" x2="1140.15" y2="235.91"></line><line x1="1122.03" y1="252.94" x2="1123.07" y2="250.25"></line><line x1="1125.54" y1="243.84" x2="1126.57" y2="241.16"></line><line x1="1129.06" y1="234.72" x2="1130.09" y2="232.03"></line><line x1="1112.05" y1="249.09" x2="1113.08" y2="246.41"></line><line x1="1115.56" y1="239.99" x2="1116.59" y2="237.31"></line><line x1="1119.07" y1="230.87" x2="1120.11" y2="228.19"></line><rect x="1116.33" y="259.08" width="3.24" height="8.89" transform="translate(169.63 -384.51) rotate(21.08)"></rect><line x1="1211.07" y1="317.02" x2="1205.67" y2="331.01"></line><rect x="1199.01" y="324.82" width="7.82" height="4.95" transform="translate(2207.58 1065.4) rotate(-158.92)"></rect><rect x="1203.23" y="319.53" width="5.97" height="3.53" transform="translate(2216.12 1054.99) rotate(-158.92)"></rect><rect x="1207.79" y="323.4" width="3.91" height="4.95" transform="translate(2221.29 1065.11) rotate(-158.92)"></rect><line x1="1211.73" y1="304.44" x2="1217.12" y2="290.45"></line><rect x="1215.97" y="291.69" width="7.82" height="4.95" transform="translate(187.48 -419.13) rotate(21.08)"></rect><rect x="1213.59" y="298.4" width="5.97" height="3.53" transform="translate(189.42 -417.54) rotate(21.08)"></rect><rect x="1211.09" y="293.11" width="3.91" height="4.95" transform="translate(187.53 -416.58) rotate(21.08)"></rect><line x1="1085.46" y1="255.76" x2="1090.86" y2="241.77"></line><rect x="1089.71" y="243.01" width="7.82" height="4.95" transform="translate(161.52 -376.97) rotate(21.08)"></rect><rect x="1087.32" y="249.72" width="5.97" height="3.53" transform="translate(163.45 -375.38) rotate(21.08)"></rect><rect x="1084.83" y="244.43" width="3.91" height="4.95" transform="translate(161.57 -374.41) rotate(21.08)"></rect><line x1="1084.8" y1="268.34" x2="1079.41" y2="282.33"></line><rect x="1072.74" y="276.14" width="7.82" height="4.95" transform="translate(1981.01 925.88) rotate(-158.92)"></rect><rect x="1076.97" y="270.85" width="5.97" height="3.53" transform="translate(1989.55 915.47) rotate(-158.92)"></rect><rect x="1081.53" y="274.72" width="3.91" height="4.95" transform="translate(1994.72 925.59) rotate(-158.92)"></rect></g><g id="DOT-5" data-name="DOT"><circle data-index="4" data-name="Ellipse 131" cx="1148.17" cy="536.01" r="9.96"></circle></g><g id="DOT-6" data-name="DOT"><circle data-index="5" data-name="Ellipse 132" cx="1116.65" cy="368.49" r="9.96"></circle></g><g id="DOT-7" data-name="DOT"><circle data-index="3" data-name="Ellipse 133" cx="1328.5" cy="702.71" r="9.96"></circle></g><g id="STEP-3"><rect x="1645.65" y="677.61" width="44.13" height="47.85" transform="translate(966.18 2369.26) rotate(-90)"></rect><path d="M1664.73,673.25l-15.14,6.22h42.05v-8.4h-15.86A29.06,29.06,0,0,0,1664.73,673.25Z"></path><path d="M1664.73,729.82l-15.14-6.22h42.05V732h-15.86A29.06,29.06,0,0,1,1664.73,729.82Z"></path><ellipse cx="1674.02" cy="688.12" rx="5.08" ry="3.15"></ellipse><polygon points="1649.59 701.54 1656.61 706.31 1691.64 706.31 1691.64 696.76 1656.61 696.76 1649.59 701.54"></polygon><line x1="1649.59" y1="701.54" x2="1691.59" y2="701.54"></line><path d="M1645.11,678.31c-6.1,0-30.06,4.66-43,12.59v2.47a46.4,46.4,0,0,0,5.21,21.56c13.33,6.23,32.42,9.82,37.77,9.82Z"></path><path d="M1645.11,724.75V678.31a35.4,35.4,0,0,0-4.09.34v45.76A35.4,35.4,0,0,0,1645.11,724.75Z"></path><ellipse cx="1620.75" cy="715.61" rx="2.42" ry="3.81" transform="translate(565.84 2139.02) rotate(-77.28)"></ellipse><ellipse cx="1620.75" cy="687.44" rx="3.74" ry="2.37" transform="translate(-111.59 373.74) rotate(-12.72)"></ellipse><line x1="1629.6" y1="722.24" x2="1629.6" y2="680.79"></line><rect x="1630.23" y="698.35" width="10.46" height="6.36" rx="1.58" transform="translate(933.93 2336.99) rotate(-90)"></rect><polygon points="1626.78 695.75 1626.78 707.31 1614.98 707.04 1614.98 696.02 1626.78 695.75"></polygon><line x1="1629.6" y1="691.95" x2="1602.16" y2="695.02"></line><line x1="1629.6" y1="711.11" x2="1604.53" y2="708.31"></line><line x1="1608.88" y1="705.68" x2="1608.88" y2="697.39"></line><ellipse cx="1636.03" cy="718.85" rx="1.71" ry="1.74"></ellipse><ellipse cx="1636.03" cy="684.19" rx="1.71" ry="1.74"></ellipse><ellipse cx="1620.88" cy="701.53" rx="1.81" ry="1.85"></ellipse><path d="M1594.76,733.32l-1.76,1.75c5.78,1.4,10.73,1.25,13.57-1.59,3.7-3.7,2.82-11-.09-19.06a.08.08,0,0,0-.15,0A46.54,46.54,0,0,1,1594.76,733.32Z"></path><path d="M1600.38,692v19.14a48.17,48.17,0,0,0,7,3.78,44.89,44.89,0,0,1-5.21-21.45V690.9C1601.57,691.24,1600.9,691.66,1600.38,692Z"></path><path d="M1600.72,697.75a1.26,1.26,0,1,1,0,2.51h-1.34v-2.51Z"></path><path d="M1600.72,707.64a1.26,1.26,0,1,1,0,2.51h-1.34v-2.51Z"></path><rect x="1598.63" y="703.45" width="2.51" height="0.99" transform="translate(895.93 2303.83) rotate(-90)"></rect><rect x="1598.63" y="693.56" width="2.51" height="0.99" transform="translate(905.82 2293.94) rotate(-90)"></rect></g></g></svg>

      </p>
      <div>
        <div data-index="0">
          
          <p><span>01. <span>LIFTOFF</span></span></p><p>Falcon 9’s first stage lofts Dragon to orbit. Falcon 9’s first and second stage separate. Second stage accelerates Dragon to orbital velocity.</p>
        </div>
        <div data-index="1">
          
          <p><span>02. <span>ORBIT ACTIVATION</span></span></p><p>Dragon separates from Falcon 9’s second stage and performs initial orbit activation and checkouts of propulsion, life support, and thermal control systems.</p>
        </div>
        <div data-index="2">
          
          <p><span>03. <span>PHASING BURNS</span></span></p><p>Dragon performs delta-velocity orbit raising maneuvers to catch up with the International Space Station.</p>
        </div>
        <div data-index="3">
          
          <p><span>04. <span>APPROACH INITIATION</span></span></p><p>Dragon establishes a communication link with the International Space Station and performs its final orbit raising delta-velocity burn.</p>
        </div>
        <div data-index="4">
          
          <p><span>05. <span>PROXIMITY OPERATION</span></span></p><p>Dragon establishes relative navigation to the International Space Station and arrives along  the docking axis, initiating an autonomous approach.</p>
        </div>
        <div data-index="5">
          
          <p><span>06. <span>DOCKING &amp; PRESSURIZATION</span></span></p><p>Dragon performs final approach and docks with the International Space Station, followed by pressurization, hatch open, and crew ingress.</p>
        </div>
      </div>
    </div>
  </div>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Weird debugging tricks the browser doesn’t want you to know (446 pts)]]></title>
            <link>https://alan.norbauer.com/articles/browser-debugging-tricks</link>
            <guid>38226743</guid>
            <pubDate>Sat, 11 Nov 2023 01:35:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alan.norbauer.com/articles/browser-debugging-tricks">https://alan.norbauer.com/articles/browser-debugging-tricks</a>, See on <a href="https://news.ycombinator.com/item?id=38226743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><article><section><p>A list of useful, not-obvious hacks to get the most out of your browser’s<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup> debugger. Assumes an intermediate-level-or-higher understanding of the developer tools.</p>
<section><h2 id="advanced-conditional-breakpoints"><a href="#advanced-conditional-breakpoints">Advanced Conditional Breakpoints</a></h2><p>By using expressions that have side effects in places you wouldn’t expect, we can squeeze more functionality out of basic features like conditional breakpoints.</p><section><h3 id="logpoints--tracepoints"><a href="#logpoints--tracepoints">Logpoints / Tracepoints</a></h3><p>For example, we can <code>console.log</code> in breakpoints. Logpoints are breakpoints that log to the console without pausing execution. While Microsoft Edge has had logpoints built-in for a while and Chrome just added them in v73, Firefox does not. But, we can use conditional breakpoints to simulate them in any browser.</p><p><img alt="Conditional Breakpoint - console.log" loading="lazy" width="756" height="337" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-console-log.2d18d3e4.gif&amp;w=828&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-console-log.2d18d3e4.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-console-log.2d18d3e4.gif&amp;w=1920&amp;q=75"></p><p>Use <code>console.count</code> instead of <code>console.log</code> if you also want a running count of how many times the line is executed.</p><p>UPDATE (May 2020): All the major browsers now directly support logpoints/tracepoints (<a href="https://developers.google.com/web/updates/2019/01/devtools#logpoints" alt="Chrome Logpoints Documentation">Chrome Logpoints</a>, <a href="https://docs.microsoft.com/en-us/microsoft-edge/devtools-guide/debugger#breakpoints" alt="Edge Tracepoint Documentation">Edge Tracepoints</a>, <a href="https://developer.mozilla.org/en-US/docs/Tools/Debugger/Set_a_logpoint" alt="Firefox Logpoint Documentation">Firefox Logpoints</a>)</p><section><h4 id="watch-pane"><a href="#watch-pane">Watch Pane</a></h4><p>You can also use <code>console.log</code> in the watch pane. For example, to dump a snapshot of <code>localStorage</code> everytime your application pauses in the debugger, you can create a <code>console.table(localStorage)</code> watch:</p><p><img alt="console.table in watch pane" loading="lazy" width="431" height="131" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-table-in-watch.03919d55.png&amp;w=640&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-table-in-watch.03919d55.png&amp;w=1080&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-table-in-watch.03919d55.png&amp;w=1080&amp;q=75"></p><p>Or to execute an expression after DOM mutation, set a DOM mutation breakpoint (in the Element Inspector):
<img alt="DOM Mutation Breakpoint" loading="lazy" width="830" height="456" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-DOM-mutation-chrome.27f07619.png&amp;w=1080&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-DOM-mutation-chrome.27f07619.png&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-DOM-mutation-chrome.27f07619.png&amp;w=1920&amp;q=75"></p><p>And then add your watch expression, e.g. to record a snapshot of the DOM: <code>(window.doms = window.doms || []).push(document.documentElement.outerHTML)</code>. Now, after any DOM subtree modification, the debugger will pause execution and the new DOM snapshot will be at the end of the <code>window.doms</code> array. (There is no way to create a DOM mutation breakpoint that doesn’t pause execution.)</p></section><section><h4 id="tracing-callstacks"><a href="#tracing-callstacks">Tracing Callstacks</a></h4><p>Let’s say you have a function that shows a loading spinner and a function that hides it, but somewhere in your code you’re calling the show method without a matching hide call. How can you find the source of the unpaired show call? Use <code>console.trace</code> in a conditional breakpoint in the show method, run your code, find the last stack trace for the show method and click the caller to go to the code:</p><p><img alt="console.trace in conditional breakpoint" loading="lazy" width="622" height="639" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-trace-find-stack.d107e89c.gif&amp;w=640&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-trace-find-stack.d107e89c.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-trace-find-stack.d107e89c.gif&amp;w=1920&amp;q=75"></p></section></section><section><h3 id="changing-program-behavior"><a href="#changing-program-behavior">Changing Program Behavior</a></h3><p>By using expressions that have side effects on program behavior, we can change program behavior on the fly, right in the browser.</p><p>For example, you can override the param to the <code>getPerson</code> function, <code>id</code>. Since <code>id=1</code> evaluates to true, this conditional breakpoint would pause the debugger. To prevent that, append <code>, false</code> to the expression.</p><p><img alt="Conditional Breakpoint - parameter override" loading="lazy" width="756" height="337" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-parameter-override.375af5d5.gif&amp;w=828&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-parameter-override.375af5d5.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-parameter-override.375af5d5.gif&amp;w=1920&amp;q=75"></p></section><section><h3 id="quick-and-dirty-performance-profiling"><a href="#quick-and-dirty-performance-profiling">Quick and Dirty Performance Profiling</a></h3><p>You shouldn’t muddy your performance profiling with things like conditional breakpoint evaluation time, but if you want a quick and dirty measurement of how long something takes to run, you can use the console timing API in conditional breakpoints. In your starting point set a breakpoint with the condition <code>console.time('label')</code> and at the end point set a breakpoint with the condition <code>console.timeEnd('label')</code>. Everytime the thing you’re measuring runs, the browser will log to the console how long it takes.</p><p><img alt="Conditional Breakpoint - performance profile" loading="lazy" width="745" height="505" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-time-performance-profile.9b494665.gif&amp;w=750&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-time-performance-profile.9b494665.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconsole-time-performance-profile.9b494665.gif&amp;w=1920&amp;q=75"></p></section><section><h3 id="using-function-arity"><a href="#using-function-arity">Using Function Arity</a></h3><section><h4 id="break-on-number-of-arguments"><a href="#break-on-number-of-arguments">Break on Number of Arguments</a></h4><p>Only pause when the current function is called with 3 arguments: <code>arguments.callee.length === 3</code></p><p>Useful when you have an overloaded function that has optional parameters.</p><p><img alt="Conditional Breakpoint - argument length" loading="lazy" width="798" height="337" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-argument-length.eedb2e1c.gif&amp;w=828&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-argument-length.eedb2e1c.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-argument-length.eedb2e1c.gif&amp;w=1920&amp;q=75"></p></section><section><h4 id="break-on-function-arity-mismatch"><a href="#break-on-function-arity-mismatch">Break on Function Arity Mismatch</a></h4><p>Only pause when the current function is called with the wrong number of arguments: <code>(arguments.callee.length) != arguments.length</code></p><p><img alt="Conditional Breakpoint - arity check" loading="lazy" width="749" height="230" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-arity-check.70c0a60c.gif&amp;w=750&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-arity-check.70c0a60c.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-arity-check.70c0a60c.gif&amp;w=1920&amp;q=75"></p><p>Useful when finding bugs in function call sites.</p></section></section><section><h3 id="using-time"><a href="#using-time">Using Time</a></h3><section><h4 id="skip-page-load"><a href="#skip-page-load">Skip Page Load</a></h4><p>Don’t pause until 5 seconds after page load:
<code>performance.now() &gt; 5000</code></p><p>Useful when you want to set a breakpoint but you’re only interested in pausing execution after initial page load.</p></section><section><h4 id="skip-n-seconds"><a href="#skip-n-seconds">Skip N Seconds</a></h4><p>Don’t pause execution if the breakpoint is hit in the next 5 seconds, but pause anytime after: <code>window.baseline = window.baseline || Date.now(), (Date.now() - window.baseline) &gt; 5000</code></p><p>Reset the counter from the console anytime you’d like: <code>window.baseline = Date.now()</code></p></section></section><section><h3 id="using-css"><a href="#using-css">Using CSS</a></h3><p>Pause based on computed CSS values, e.g. only pause execution when the document body has a red background color: <code>window.getComputedStyle(document.body).backgroundColor === "rgb(255,0,0)"</code></p></section><section><h3 id="even-calls-only"><a href="#even-calls-only">Even Calls Only</a></h3><p>Only pause every other time the line is executed:
<code>window.counter = window.counter || 0, window.counter % 2 === 0</code></p></section><section><h3 id="break-on-sample"><a href="#break-on-sample">Break on Sample</a></h3><p>Only break on a random sample of executions of the line, e.g. only break 1 out of every 10 times the line is executed:
<code>Math.random() &lt; 0.1</code></p></section><section><h3 id="never-pause-here"><a href="#never-pause-here">Never Pause Here</a></h3><img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"><p>When you right-click the gutter and select “Never Pause Here,” Chrome creates a conditional breakpoint that is <code>false</code> and never passes. This makes it so that the debugger will never pause on this line.</p><p><img alt="Never Pause Here" loading="lazy" width="282" height="158" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnever-pause-here.a4010ee4.png&amp;w=384&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnever-pause-here.a4010ee4.png&amp;w=640&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnever-pause-here.a4010ee4.png&amp;w=640&amp;q=75">
<img alt="Never Pause Here Result" loading="lazy" width="324" height="86" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnever-pause-here-result.32dc71c3.png&amp;w=384&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnever-pause-here-result.32dc71c3.png&amp;w=750&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnever-pause-here-result.32dc71c3.png&amp;w=750&amp;q=75"></p><p>Useful when you want to exempt a line from XHR breakpoints, ignore an exception that is being thrown, etc.</p></section><section><h3 id="automatic-instance-ids"><a href="#automatic-instance-ids">Automatic Instance IDs</a></h3><p>Automatically assign a unique ID to every instance of a class by setting this conditional breakpoint in the constructor: <code>(window.instances = window.instances || []).push(this)</code></p><p>Then to retrieve the unique ID: <code>window.instances.indexOf(instance)</code> (e.g. <code>window.instances.indexOf(this)</code> when in a class method)</p></section><section><h3 id="programmatically-toggle"><a href="#programmatically-toggle">Programmatically Toggle</a></h3><p>Use a global boolean to gate one or more conditional breakpoints:</p><p><img alt="Boolean gate" loading="lazy" width="949" height="121" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-gated.d32764ce.png&amp;w=1080&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-gated.d32764ce.png&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-gated.d32764ce.png&amp;w=1920&amp;q=75"></p><p>Then programmatically toggle the boolean, e.g.</p><ul>
<li>manually, from the console<!-- -->
<div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>window.enableBreakpoints </span><span>= </span><span>true</span><span>;</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>window</span><span>.</span><span>enableBreakpoints </span><span>= </span><span>true</span><span>;</span><br></span></p></code></pre></div>
</li>
<li>from other breakpoints
<img alt="Boolean gate - enable from other breakpoint" loading="lazy" width="880" height="128" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-gated-enable-from-breakpoint.1c568b6e.png&amp;w=1080&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-gated-enable-from-breakpoint.1c568b6e.png&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fconditional-breakpoint-gated-enable-from-breakpoint.1c568b6e.png&amp;w=1920&amp;q=75"></li>
<li>from a timer on the console<!-- -->
<div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>setTimeout</span><span>(() </span><span>=&gt;</span><span> (window.enableBreakpoints </span><span>= </span><span>true</span><span>), </span><span>5000</span><span>);</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>setTimeout</span><span>(() </span><span>=&gt; </span><span>(</span><span>window</span><span>.</span><span>enableBreakpoints </span><span>= </span><span>true</span><span>)</span><span>, </span><span>5000</span><span>)</span><span>;</span><br></span></p></code></pre></div>
</li>
<li>etc</li>
</ul></section></section>
<section><h2 id="monitor-class-calls"><a href="#monitor-class-calls">monitor() class Calls</a></h2><img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"><p>You can use Chrome’s <code>monitor</code> command line method to easily trace all calls to class methods. E.g. given a class <code>Dog</code></p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>class </span><span>Dog</span><span> {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  bark</span><span>(</span><span>count</span><span>) {</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>    /* ... */</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>  }</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>}</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>class </span><span>Dog </span><span>{</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  bark</span><span>(</span><span>count</span><span>) {</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>    /* ... */</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>  }</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>}</span><br></span></p></code></pre></div><p>If we want to know all calls made to all instances of <code>Dog</code>, paste this into the command line:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>var</span><span> p </span><span>= </span><span>Dog</span><span>.prototype;</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>Object.</span><span>getOwnPropertyNames</span><span>(p).</span><span>forEach</span><span>((</span><span>k</span><span>) </span><span>=&gt; </span><span>monitor</span><span>(p[k]));</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>var </span><span>p </span><span>= </span><span>Dog</span><span>.</span><span>prototype;</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>Object</span><span>.</span><span>getOwnPropertyNames</span><span>(</span><span>p</span><span>).</span><span>forEach</span><span>((</span><span>k</span><span>) </span><span>=&gt; </span><span>monitor</span><span>(</span><span>p</span><span>[</span><span>k</span><span>]))</span><span>;</span><br></span></p></code></pre></div><p>and you’ll get output in the console:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span>&gt; function bark called with arguments: 2</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span>&gt; function bark called with arguments: 2</span><br></span></p></code></pre></div><p>You can use <code>debug</code> instead of <code>monitor</code> if you want to pause execution on any method calls (instead of just logging to the console).</p><section><h3 id="from-a-specific-instance"><a href="#from-a-specific-instance">From a Specific Instance</a></h3><img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"><p>If you don’t know the class but you have an instance:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>var</span><span> p </span><span>=</span><span> instance.constructor.prototype;</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>Object.</span><span>getOwnPropertyNames</span><span>(p).</span><span>forEach</span><span>((</span><span>k</span><span>) </span><span>=&gt; </span><span>monitor</span><span>(p[k]));</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>var </span><span>p </span><span>= </span><span>instance</span><span>.</span><span>constructor</span><span>.</span><span>prototype;</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>Object</span><span>.</span><span>getOwnPropertyNames</span><span>(</span><span>p</span><span>).</span><span>forEach</span><span>((</span><span>k</span><span>) </span><span>=&gt; </span><span>monitor</span><span>(</span><span>p</span><span>[</span><span>k</span><span>]))</span><span>;</span><br></span></p></code></pre></div><p>Useful when you’d like to write a function that does this for any instance of any class (instead of just <code>Dog</code>)</p></section></section>
<section><h2 id="call-and-debug-a-function"><a href="#call-and-debug-a-function">Call and Debug a Function</a></h2><p>Before calling the function you want to debug in the console, call <code>debugger</code>. E.g. given:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>function </span><span>fn</span><span>() {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  /* ... */</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>}</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>function </span><span>fn</span><span>() {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  /* ... */</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>}</span><br></span></p></code></pre></div><p>From your console:</p><p>And then “Step into next function call” to debug the implementation of <code>fn</code>.</p><p>Useful when you don’t feel like finding the definition of <code>fn</code> and adding a breakpoint manually or if <code>fn</code> is dynamically bound to a function and you don’t know where the source is.</p><p>In Chrome you can also optionally call <code>debug(fn)</code> on the command line and the debugger will pause execution inside <code>fn</code> every time it is called.</p></section>
<section><h2 id="pause-execution-on-url-change"><a href="#pause-execution-on-url-change">Pause Execution on URL Change</a></h2><p>To pause execution before a single-page application modifies the URL (i.e. some routing event happens):</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>const </span><span>dbg </span><span>=</span><span> () </span><span>=&gt;</span><span> {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  debugger</span><span>;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>};</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>history.pushState </span><span>=</span><span> dbg;</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>history.replaceState </span><span>=</span><span> dbg;</span><br></span></p><p><span><span data-bright-ln="6">6</span><span>window.onhashchange </span><span>=</span><span> dbg;</span><br></span></p><p><span><span data-bright-ln="7">7</span><span>window.onpopstate </span><span>=</span><span> dbg;</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>const </span><span>dbg </span><span>= () </span><span>=&gt; </span><span>{</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  debugger</span><span>;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>}</span><span>;</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>history</span><span>.</span><span>pushState </span><span>= </span><span>dbg</span><span>;</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>history</span><span>.</span><span>replaceState </span><span>= </span><span>dbg</span><span>;</span><br></span></p><p><span><span data-bright-ln="6">6</span><span>window</span><span>.</span><span>onhashchange </span><span>= </span><span>dbg</span><span>;</span><br></span></p><p><span><span data-bright-ln="7">7</span><span>window</span><span>.</span><span>onpopstate </span><span>= </span><span>dbg</span><span>;</span><br></span></p></code></pre></div><p>Creating a version of <code>dbg</code> that pauses execution without breaking navigation is an exercise left up to the reader.</p><p>Also, note that this doesn’t handle when code calls <code>window.location.replace/assign</code> directly because the page will immediately unload after the assignment, so there is nothing to debug. If you still want to see the source of these redirects (and debug your state at the time of redirect), in Chrome you can <code>debug</code> the relevant methods:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>debug</span><span>(window.location.replace);</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>debug</span><span>(window.location.assign);</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>debug</span><span>(</span><span>window</span><span>.</span><span>location</span><span>.</span><span>replace</span><span>)</span><span>;</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>debug</span><span>(</span><span>window</span><span>.</span><span>location</span><span>.</span><span>assign</span><span>)</span><span>;</span><br></span></p></code></pre></div></section>
<section><h2 id="debugging-property-reads"><a href="#debugging-property-reads">Debugging Property Reads</a></h2><p>If you have an oject and want to know whenever a property is read on it, use an object getter with a <code>debugger</code> call. For example, convert <code>{configOption: true}</code> to <code>{get configOption() { debugger; return true; }}</code> (either in the original source code or using a conditional breakpoint).</p><p>Useful when you’re passing in some configuration options to something and you’d like to see how they get used.</p></section>
<section><h2 id="use-copy"><a href="#use-copy">Use copy()</a></h2><img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"><img data-no-style="true" alt="Firefox" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/firefox.583d9a58.svg"><p>You can copy interest information out of the browser directly to your clipboard without any string truncation using the <code>copy()</code> console API. Some interesting things you might want to copy:</p><ul>
<li>Snapshot of the current DOM: <code>copy(document.documentElement.outerHTML)</code></li>
<li>Metadata about resources (e.g. images): <code>copy(performance.getEntriesByType("resource"))</code></li>
<li>A large JSON blob, formatted: <code>copy(JSON.parse(blob))</code></li>
<li>A dump of your localStorage: <code>copy(localStorage)</code></li>
<li>Etc.</li>
</ul></section>
<section><h2 id="debugging-htmlcss"><a href="#debugging-htmlcss">Debugging HTML/CSS</a></h2><p>The JS console can be helpful when diagnosing problems with your HTML/CSS.</p><section><h3 id="inspect-the-dom-with-js-disabled"><a href="#inspect-the-dom-with-js-disabled">Inspect the DOM with JS Disabled</a></h3><p>When in the DOM inspector press ctrl+\ (Chrome/Windows) to pause JS execution at any time. This allows you to inspect a snapshot of the DOM without worrying about JS mutating the DOM or events (e.g. mouseover) causing the DOM to change from underneath you.</p></section><section><h3 id="inspect-an-elusive-element"><a href="#inspect-an-elusive-element">Inspect an Elusive Element</a></h3><p>Let’s say you want to inspect a DOM element that only conditionally appears. Inspecting said element requires moving your mouse to it, but when you try to, it disappears:</p><p><img alt="Elusive element" loading="lazy" width="668" height="99" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felusive-element.495b0945.gif&amp;w=750&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felusive-element.495b0945.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felusive-element.495b0945.gif&amp;w=1920&amp;q=75"></p><p>To inspect the element you can paste this into your console: <code>setTimeout(function() { debugger; }, 5000);</code>. This gives you 5 seconds to trigger the UI, and then once the 5 second timer is up, JS execution will pause and nothing will make your element disappear. You are free to move your mouse to the dev tools without losing the element:</p><p><img alt="Elusive element - inspected" loading="lazy" width="815" height="717" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felusive-element-inspected.f5f036b4.gif&amp;w=828&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felusive-element-inspected.f5f036b4.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felusive-element-inspected.f5f036b4.gif&amp;w=1920&amp;q=75"></p><p>While JS execution is paused you can inspect the element, edit its CSS, execute commands in the JS console, etc.</p><p>Useful when inspecting DOM that is dependent on specific cursor position, focus, etc.</p></section><section><h3 id="record-snapshots-of-the-dom"><a href="#record-snapshots-of-the-dom">Record Snapshots of the DOM</a></h3><p>To grab a copy of the DOM in its current state:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>copy</span><span>(document.documentElement.outerHTML);</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>copy</span><span>(</span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>outerHTML</span><span>)</span><span>;</span><br></span></p></code></pre></div><p>To record a snapshot of the DOM every second:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>doms </span><span>=</span><span> [];</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>setInterval</span><span>(() </span><span>=&gt;</span><span> {</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  const</span><span> domStr </span><span>=</span><span> document.documentElement.outerHTML;</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>  doms.</span><span>push</span><span>(domStr);</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>}, </span><span>1000</span><span>);</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>doms </span><span>= []</span><span>;</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>setInterval</span><span>(() </span><span>=&gt; </span><span>{</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  const </span><span>domStr </span><span>= </span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>outerHTML</span><span>;</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>  doms</span><span>.</span><span>push</span><span>(</span><span>domStr</span><span>)</span><span>;</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>}</span><span>, </span><span>1000</span><span>)</span><span>;</span><br></span></p></code></pre></div><p>Or just dump it to the console:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>setInterval</span><span>(() </span><span>=&gt;</span><span> {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  const</span><span> domStr </span><span>=</span><span> document.documentElement.outerHTML;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>snapshotting DOM: </span><span>"</span><span>, domStr);</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>}, </span><span>1000</span><span>);</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>setInterval</span><span>(() </span><span>=&gt; </span><span>{</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  const </span><span>domStr </span><span>= </span><span>document</span><span>.</span><span>documentElement</span><span>.</span><span>outerHTML</span><span>;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  console</span><span>.</span><span>log</span><span>(</span><span>"snapshotting DOM: "</span><span>, </span><span>domStr</span><span>)</span><span>;</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>}</span><span>, </span><span>1000</span><span>)</span><span>;</span><br></span></p></code></pre></div></section><section><h3 id="monitor-focused-element"><a href="#monitor-focused-element">Monitor Focused Element</a></h3><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>(</span><span>function</span><span> () {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  let</span><span> last </span><span>=</span><span> document.activeElement;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  setInterval</span><span>(() </span><span>=&gt;</span><span> {</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>    if</span><span> (document.activeElement </span><span>!==</span><span> last) {</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>      last </span><span>=</span><span> document.activeElement;</span><br></span></p><p><span><span data-bright-ln="6">6</span><span>      console.</span><span>log</span><span>(</span><span>"</span><span>Focus changed to: </span><span>"</span><span>, last);</span><br></span></p><p><span><span data-bright-ln="7">7</span><span>    }</span><br></span></p><p><span><span data-bright-ln="8">8</span><span>  }, </span><span>100</span><span>);</span><br></span></p><p><span><span data-bright-ln="9">9</span><span>})();</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>(</span><span>function </span><span>() {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  let </span><span>last </span><span>= </span><span>document</span><span>.</span><span>activeElement</span><span>;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  setInterval</span><span>(() </span><span>=&gt; </span><span>{</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>    if </span><span>(</span><span>document</span><span>.</span><span>activeElement </span><span>!== </span><span>last</span><span>) {</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>      last </span><span>= </span><span>document</span><span>.</span><span>activeElement</span><span>;</span><br></span></p><p><span><span data-bright-ln="6">6</span><span>      console</span><span>.</span><span>log</span><span>(</span><span>"Focus changed to: "</span><span>, </span><span>last</span><span>)</span><span>;</span><br></span></p><p><span><span data-bright-ln="7">7</span><span>    }</span><br></span></p><p><span><span data-bright-ln="8">8</span><span>  }</span><span>, </span><span>100</span><span>)</span><span>;</span><br></span></p><p><span><span data-bright-ln="9">9</span><span>})()</span><span>;</span><br></span></p></code></pre></div><p><img alt="Monitor focused element" loading="lazy" width="891" height="443" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmonitor-focus.b9692b99.gif&amp;w=1080&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmonitor-focus.b9692b99.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmonitor-focus.b9692b99.gif&amp;w=1920&amp;q=75"></p></section><section><h3 id="find-bold-elements"><a href="#find-bold-elements">Find Bold Elements</a></h3><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>const </span><span>isBold </span><span>=</span><span> (</span><span>e</span><span>) </span><span>=&gt;</span><span> {</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  let</span><span> w </span><span>=</span><span> window.</span><span>getComputedStyle</span><span>(e).fontWeight;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  return</span><span> w </span><span>=== </span><span>"</span><span>bold</span><span>" </span><span>||</span><span> w </span><span>=== </span><span>"</span><span>700</span><span>"</span><span>;</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>};</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>Array.</span><span>from</span><span>(document.</span><span>querySelectorAll</span><span>(</span><span>"</span><span>*</span><span>"</span><span>)).</span><span>filter</span><span>(isBold);</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>const </span><span>isBold </span><span>= (</span><span>e</span><span>) </span><span>=&gt; </span><span>{</span><br></span></p><p><span><span data-bright-ln="2">2</span><span>  let </span><span>w </span><span>= </span><span>window</span><span>.</span><span>getComputedStyle</span><span>(</span><span>e</span><span>).</span><span>fontWeight</span><span>;</span><br></span></p><p><span><span data-bright-ln="3">3</span><span>  return </span><span>w </span><span>=== </span><span>"bold" </span><span>|| </span><span>w </span><span>=== </span><span>"700"</span><span>;</span><br></span></p><p><span><span data-bright-ln="4">4</span><span>}</span><span>;</span><br></span></p><p><span><span data-bright-ln="5">5</span><span>Array</span><span>.</span><span>from</span><span>(</span><span>document</span><span>.</span><span>querySelectorAll</span><span>(</span><span>"*"</span><span>)).</span><span>filter</span><span>(</span><span>isBold</span><span>)</span><span>;</span><br></span></p></code></pre></div><section><h4 id="just-descendants"><a href="#just-descendants">Just Descendants</a></h4><p>Or just descendants of the element currently selected in the inspector:</p><div data-bright-theme="dracula" data-bright-mode="dark"><pre><code><p><span><span data-bright-ln="1">1</span><span>Array.</span><span>from</span><span>($0.</span><span>querySelectorAll</span><span>(</span><span>"</span><span>*</span><span>"</span><span>)).</span><span>filter</span><span>(isBold);</span><br></span></p></code></pre></div><div data-bright-theme="Firefox Light" data-bright-mode="light"><pre><code><p><span><span data-bright-ln="1">1</span><span>Array</span><span>.</span><span>from</span><span>(</span><span>$0</span><span>.</span><span>querySelectorAll</span><span>(</span><span>"*"</span><span>)).</span><span>filter</span><span>(</span><span>isBold</span><span>)</span><span>;</span><br></span></p></code></pre></div></section></section><section><h3 id="reference-currently-selected-element"><a href="#reference-currently-selected-element">Reference Currently Selected Element</a></h3><p><code>$0</code> in the console is an automatic reference to the currently selected element in the element inspector.</p><section><h4 id="previous-elements"><a href="#previous-elements">Previous Elements</a></h4><img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"><img data-no-style="true" alt="Edge" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/edge.c22c90ce.svg"><p>In Chrome and Edge you can access the element you last inspected with <code>$1</code>, the element before that with <code>$2</code>, etc.</p></section><section><h4 id="get-event-listeners"><a href="#get-event-listeners">Get Event Listeners</a></h4><img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"><p>In Chrome you can inspect the event listeners of the currently selected element: <code>getEventListeners($0)</code>, e.g.</p><p><img alt="getEventListeners" loading="lazy" width="757" height="402" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FgetEventListeners.4ae6f43e.png&amp;w=828&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FgetEventListeners.4ae6f43e.png&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FgetEventListeners.4ae6f43e.png&amp;w=1920&amp;q=75"></p></section></section><section><h3 id="monitor-events-for-element"><a href="#monitor-events-for-element">Monitor Events for Element</a></h3><img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"><p>Debug all events for selected element: <code>monitorEvents($0)</code></p><p>Debug specific events for selected element: <code>monitorEvents($0, ["control", "key"])</code></p><p><img alt="monitorEvents" loading="lazy" width="891" height="569" decoding="async" data-nimg="1" srcset="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FmonitorEvents.a03f9e53.gif&amp;w=1080&amp;q=75 1x, https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FmonitorEvents.a03f9e53.gif&amp;w=1920&amp;q=75 2x" src="https://alan.norbauer.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FmonitorEvents.a03f9e53.gif&amp;w=1920&amp;q=75"></p></section></section>
<section data-footnotes="true">
<ol>
<li id="user-content-fn-1">
<p>Tips are supported in Chrome, Firefox, and Edge unless the browser logos say otherwise: <img data-no-style="true" alt="Chrome" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/chrome.2d2a19fd.svg"> <img data-no-style="true" alt="Firefox" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/firefox.583d9a58.svg"> <img data-no-style="true" alt="Edge" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://alan.norbauer.com/_next/static/media/edge.c22c90ce.svg"> <a href="#user-content-fnref-1" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></section></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trading bot that buys stocks bought by politicians is up 20% since May 2022 (322 pts)]]></title>
            <link>https://www.threads.net/@quiverquantitative/post/CzcB-Gsgqow</link>
            <guid>38226404</guid>
            <pubDate>Sat, 11 Nov 2023 00:38:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.threads.net/@quiverquantitative/post/CzcB-Gsgqow">https://www.threads.net/@quiverquantitative/post/CzcB-Gsgqow</a>, See on <a href="https://news.ycombinator.com/item?id=38226404">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Iceland declares state of emergency over volcanic eruption threat (200 pts)]]></title>
            <link>https://www.theguardian.com/world/2023/nov/10/iceland-declares-state-of-emergency-over-volcanic-eruption-threat</link>
            <guid>38225019</guid>
            <pubDate>Fri, 10 Nov 2023 21:51:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2023/nov/10/iceland-declares-state-of-emergency-over-volcanic-eruption-threat">https://www.theguardian.com/world/2023/nov/10/iceland-declares-state-of-emergency-over-volcanic-eruption-threat</a>, See on <a href="https://news.ycombinator.com/item?id=38225019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Icelandic authorities have declared a state of emergency after a series of powerful earthquakes rocked the country’s southwestern Reykjanes peninsula, signalling the increased likelihood of a volcanic eruption in the region.</p><p>“The National police chief … declares a state of emergency for civil defence due to the intense earthquake (activity) at Sundhnjukagigar, north of Grindavik,” the Department of Civil Protection and Emergency Management said in a statement.</p><p>“Earthquakes can become larger than those that have occurred and this series of events could lead to an eruption,” the administration warned.</p><figure id="e59158e7-f38f-4542-8692-f1fdc9bf59fc" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/world/2023/nov/09/iceland-blue-lagoon-geothermal-resort-closes-seismic-storm-volcanic-eruption-fears&quot;,&quot;text&quot;:&quot;Geothermal spa closes in Iceland as guests flee after series of earthquakes&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;e59158e7-f38f-4542-8692-f1fdc9bf59fc&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>The Icelandic Met Office (IMO) said an eruption could take place “in several days”.</p><p>The village of Grindavik, home to about 4,000 people, is located 1.86 miles (3km) south-west of the area where Friday’s earthquake swarm was registered. It has evacuation plans in place in case of an eruption.</p><p>At about 5.30pm GMT, two strong earthquakes were felt as far as the capital, Reykjavik, 40km away, and along much of the country’s southern coast, causing windows and household objects to shake.</p><p>The biggest tremor, north of Grindavik, had a magnitude of 5.2, according to preliminary IMO figures.</p><p>Police closed a road running north-south to Grindavik on Friday after it was damaged by the earthquakes.</p><p><a href="https://www.theguardian.com/world/2023/oct/27/iceland-earthquakes-next-volcanic-eruption" data-link-name="in body link">Since late October, 24,000 tremors have been registered on the peninsula</a>, according to the IMO, with “a dense swarm” of nearly 800 quakes registered between midnight and 2pm GMT on Friday.</p><p>The IMO noted an accumulation of magma underground at a depth of about 3.1 miles (5km). Should it start moving towards the surface it could lead to a volcanic eruption.</p><p>“The most likely scenario is that it will take several days rather than hours for magma to reach the surface,” it said. “If a fissure were to appear where the seismic activity is at its highest now, lava would flow to the south-east and to the west, but not towards Grindavik.”</p><p>Since 2021, three eruptions have taken place on the Reykjanes peninsula, in March 2021, August 2022 and July 2023. Those three were located far from any infrastructure or populated areas.</p><p>On Thursday, the Blue Lagoon, located near Grindavik and famed for its geothermal spas and luxury hotels, <a href="https://www.theguardian.com/world/2023/nov/09/iceland-blue-lagoon-geothermal-resort-closes-seismic-storm-volcanic-eruption-fears" data-link-name="in body link">closed as a precaution after another earthquake swarm</a>.</p><p>Also nearby is the Svartsengi geothermal plant, the main supplier of electricity and water to 30,000 residents on the Reykjanes peninsula. It has contingency plans in place to protect the plant and its workers in the event of an eruption.</p><p><a href="https://www.theguardian.com/world/iceland" data-link-name="in body link">Iceland</a> has 33 active volcanic systems, the highest number in Europe.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple discriminated against US citizens in hiring, DOJ says (335 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/11/apple-discriminated-against-us-citizens-in-hiring-doj-says/</link>
            <guid>38224950</guid>
            <pubDate>Fri, 10 Nov 2023 21:45:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/11/apple-discriminated-against-us-citizens-in-hiring-doj-says/">https://arstechnica.com/tech-policy/2023/11/apple-discriminated-against-us-citizens-in-hiring-doj-says/</a>, See on <a href="https://news.ycombinator.com/item?id=38224950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Hiring discrimination
    —
</h4>
            
            <h2 itemprop="description">Apple deterred US citizens from positions open to foreign workers, DOJ found.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/apple-store-logo-800x517.jpg" alt="An Apple corporate logo hangs above the front door of a company store">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/apple-store-logo.jpg" data-height="1617" data-width="2500">Enlarge</a> <span>/</span> Apple Store at Garden State Plaza mall on November 4, 2023, in Paramus, New Jersey.  </p><p>Getty Images | Gary Hershorn </p></figcaption>  </figure>

  




<!-- cache hit 127:single/related:757acc1f958c8af5276c06bb0dc05b7f --><!-- empty -->
<p>Apple illegally discriminated against US citizens and other US residents in its hiring and recruitment practices for certain types of positions that went to foreign workers, the US Department of Justice <a href="https://www.justice.gov/opa/pr/justice-department-secures-25-million-landmark-agreement-apple-resolve-employment">said yesterday</a>. Apple agreed to pay up to $25 million in back pay and civil penalties to settle the DOJ allegations.</p>
<p>Apple discriminated "against US citizens and certain non-US citizens whose permission to live in and work in the United States does not expire," the agency said. The $25 million payment was called the largest ever collected by the Justice Department under the anti-discrimination provision of the Immigration and Nationality Act (INA).</p>
<p>Apple is required to pay $6.75 million in civil penalties and create an $18.25 million fund to provide back pay to those harmed by its hiring practices. Apple did not admit guilt in the <a href="https://www.justice.gov/d9/2023-11/ier-apple_settlement_agreement_signed_2023-11-08_fully_executed.pdf">settlement</a>. But the company acknowledged in a statement that it had "unintentionally not been following the DOJ standard," <a href="https://www.reuters.com/technology/apple-agrees-25-million-settlement-with-us-over-hiring-immigrants-2023-11-09/">according to Reuters</a>.</p>
<p>"We have implemented a robust remediation plan to comply with the requirements of various government agencies as we continue to hire American workers and grow in the US," Apple said. We contacted Apple and will update this article if it provides any further statement.</p>
<p>As Reuters noted, "Foreign labor can often be cheaper than hiring US workers, and immigrants who rely on their employers for green card sponsorship are seen as less likely to leave for a different job."</p>                                            
                                                        
<h2>DOJ investigation</h2>
<p>The DOJ said it began investigating in February 2019 and determined "that Apple violated the INA's anti-discrimination requirements during Apple's recruitment for positions falling under the permanent labor certification program (PERM)." The agency said the discrimination began no later than January 1, 2018, and continued until at least December 31, 2019.</p>
<p><span>Under this program, a "permanent labor certification issued by the Department of Labor (DOL) allows an employer to hire a foreign worker to work permanently in the United States," the DOL </span><span><a href="https://www.dol.gov/agencies/eta/foreign-labor/programs/permanent"><span>says</span></a></span><span>. But the employer must also obtain a certification "that there are not sufficient US workers able, willing, qualified and available to accept the job opportunity in the area of intended employment and that employment of the foreign worker will not adversely affect the wages and working conditions of similarly employed US workers."</span></p>
<p>The DOJ said its investigation "found that Apple engaged in a pattern or practice of citizenship status discrimination in recruitment for positions it hired through PERM, and that the company's unlawful discrimination prejudiced US citizens, US nationals, lawful permanent residents, and those granted asylum or refugee status. These less effective recruitment practices deterred protected workers from applying to positions that Apple preferred to fill instead with PERM beneficiaries."</p>
<p>Apple did not advertise PERM positions on its external job website like it does with other positions, the DOJ said. "It also required all PERM position applicants to mail paper applications, even though the company permitted electronic applications for other positions," the DOJ said.</p>
<p>In some cases, "Apple did not consider certain applications for PERM positions from Apple employees if those applications were submitted electronically, as opposed to paper applications submitted through the mail," the agency said. "These less effective recruitment procedures nearly always resulted in few or no applications to PERM positions from applicants whose permission to work does not expire."</p>
<h2>Apple changes hiring practices</h2>
<p>The settlement requires Apple to make its PERM recruitment practices match its standard recruitment practices more closely. Apple will have to "conduct more expansive recruitment for all PERM positions, including posting PERM positions on its external job website, accepting electronic applications, and enabling applicants to PERM positions to be searchable in its applicant tracking system."</p>
<p>Apple has already implemented some of the changes and agreed to "train its employees on the INA's anti-discrimination requirements and be subject to departmental monitoring for the three-year period of the agreement," the DOJ said.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The hijacking of rare Japanese KitKats (224 pts)]]></title>
            <link>https://www.straitstimes.com/world/united-states/how-to-kidnap-339000-in-rare-japanese-kitkats</link>
            <guid>38224810</guid>
            <pubDate>Fri, 10 Nov 2023 21:30:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.straitstimes.com/world/united-states/how-to-kidnap-339000-in-rare-japanese-kitkats">https://www.straitstimes.com/world/united-states/how-to-kidnap-339000-in-rare-japanese-kitkats</a>, See on <a href="https://news.ycombinator.com/item?id=38224810">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-wrapper">
              <main id="content" role="main">
                <section>
                  <a id="main-content" tabindex="-1"></a>
                    


  <div>
      

    
            
  


<div>
            <div>
            <p>Updated</p>
  
                          <p>
      November 9, 2023 at 5:39 PM</p>
      
  
    </div>

      <div>
            <p>Published</p>
  
                          <p>
      November 9, 2023 at 3:15 PM</p>
      
  
    </div>


  </div>

<div>
      

<div>
<p>NEW YORK – Mr Danny Taing’s 55,000 Kit Kats began their long, twisted, and sometimes obscure journey in Japan.</p>
<p>Mr Taing is the founder of Bokksu, a New York company that sells Japanese snacks in subscription boxes, and he intended to make a tidy sum by flipping the sweets in the United States. </p>
<p>The KitKat shipment, which included sought-after flavours such as melon, matcha latte, and daifuku mochi, had cost US$110,000 (S$149,000), but Bokksu expected to make about US$250,000 in total revenue.</p>

<p>“You can fit a lot of KitKats into two containers,” Mr Taing said.</p>
<p>And they are a booming business. In Japan, enthusiasts clamour for the rarer flavours, with some sold for just a few weeks or only in a specific region. In the United States, obsessives fawn over the collectibles, comparing reviews on Japanese snack blogs and shelling out for limited editions.</p>
<p>These particular KitKats would become key players in an ultimately frustrating saga of shell e-mail accounts, phantom truckers, supply-chain fraud and one seriously bewildered cargo freight broker.</p>


<p>Interviews and e-mails shared with The New York Times tell the story of just one instance of “strategic theft”, a growing corner of the criminal world that the Federal Bureau of Investigation has said accounts for some US$30 billion in losses a year – with food being among the top targets.</p>

<p>The precious sweets landed safely enough in California, and were trucked about 48km across Los Angeles County to a temporary storage facility in South El Monte, run by a company called Japan Crate Acquisition.</p>
<p>After weeks of chugging across the Pacific Ocean, they just needed to make the remaining leg of their journey to Bokksu’s warehouse in Carlstadt, New Jersey, and then into the hands of avid candy fans.</p>
<p>That was where Mr Shane Black came in.</p>

<p>Mr Black, who runs a freight brokering company called Freight Rate Central in Sarasota, Florida, is part of an invisible army of professionals who coordinate and marshal the fleets of trucks that criss-cross the country, carrying everything from chickens to smartphones. For this job, Bokksu would pay him about US$13,000.</p>
<p>Mr Black got to it. He posted the job on a trucking board that is something like a Craigslist for freight. Someone named Tristan with HCH Trucking accepted the job (though he was using a Gmail account), and said he would have the shipment picked up shortly.</p>
<p>On Aug 9, Tristan wrote in an e-mail: “Hey man, The first one is loaded and rolling, the second one we’ll pick it up tomorrow first thing in the morning.”</p>
<p>“There was nothing out of the ordinary,” Mr Black said in an interview.</p>
<h2>Coming clean</h2>
</div>

    <div>
<p>When the shipments failed to reach New Jersey days after any cross-country trip should have been completed, Mr Black started to have visions of KitKats melting in the summer heat.</p>
<p>“Please tell me the freight is in good order and has been refrigerated this whole time?” he e-mailed Tristan.</p>
<p>Tristan replied that one of the trucks had broken down in Washington, Pennsylvania, a small city just south-west of Pittsburgh. Tristan reassured him that the Kit Kats were cool and intact, but “if it’s not fixed by today we will have to head back to the shipper and re-unload them there”.</p>
<p>That sent up all kinds of red flags for Mr Black. If the truck was in good enough shape to drive over 3,800km back to California, why could it not make it fewer than 650km to New Jersey? So Mr Black called HCH Trucking.</p>
<p>“That’s when everything kind of hit the fan,” he said.</p>
<p>When he reached the HCH headquarters in Jersey City, New Jersey, he heard chaos in the background, sounds of panic. The representative told him that their information appeared to have been compromised. They had never heard of any Tristan.</p>
<p>If Mr Black was not dealing with HCH Trucking, who was he dealing with? And most important, where were the six figures’ worth of KitKats?</p>
<p>Seemingly on cue, Tristan followed up. “Time for some coming clean,” he confessed. “I’m actually a scammer and the owner of HCH doesn’t have anything to do with this.”</p>
<p>“Why though?” Mr Black replied plaintively. “What would you stand to gain? Can I please get access to the loads so I can get them to New Jersey? We’re not a big company at all. It‘s just me... I’m the owner and everything else.”</p>
<p>Tristan wrote back: “We’re trying to make money sir, I told you we’re scammers, really sorry I didn’t know your story, and hopefully the loads get to New Jersey.”</p>
<p>Tristan included the addresses of two warehouses, both just east of Los Angeles, where he had dropped the loads.</p>
</div>

  
  <div>
<p>The strange thing was that Mr Black had never paid Tristan any money; the shipping fee was due on delivery. If this was a con, so far it did not seem to be a very profitable one. In any case, Mr Black couldn’t believe his luck.</p>
<p>“When I found out they were at a cold-storage facility, I mean, I was just so happy,” he said. “I thought, ‘OK, we got the freight.’”</p>
<h2>Out of service</h2>
<p>Mr Black spun back into action. According to Tristan, one load was at Inland Empire Cold Storage in Jurupa Valley, California. The other was nearby, at Anytime Crossdock in Ontario, California. Tristan then went silent, and did not respond to repeated e-mails from NYTimes seeking comment.</p>
<p>Anytime was eager to get the load out of its warehouse and to be paid for nearly two weeks of storage.</p>
<p>It turned out that the KitKats had never left California. They had simply been driven about 50km east, put on ice and left to rack up storage fees.</p>
<p>“We would like to know when you are going to get this picked up,” Anytime wrote, “as we anticipated this to be a short-term storage request.”</p>
</div>

    <div>
<p>The outstanding balance for the storage was US$3,830. Mr Black said he paid US$2,000 of that out of his own pocket to secure the release of the freight, with the promise to pay the rest later. Anytime did not respond to repeated requests for comment from NYTimes.</p>
<p>Daunted but determined, he started the process over, posting the job again on the freight board. This time he said he got a bite from ‘Manny’ from MVK Transport.</p>
<p>According to Mr Black, Manny had the KitKats picked up. At least this half of the shipment was on its way to New Jersey, Mr Black believed. After a few days, though, communications turned spotty.</p>
<p>“I’ve been writing you for days now,” Mr Black e-mailed a few days later. “I called yesterday and you hung up and now your phone says it’s out of service.”</p>
<p>The next morning, he followed up, now furious: “How do you make money on this??? Are you going to sell KitKats on the corner???”</p>
<p>He had been had again. This time, the KitKats had disappeared for good into the expanse of Southern California’s freewayland. Requests for comment sent to MVK went unanswered.</p>
<h2>‘We cannot release the freight’</h2>
</div>

    <div>
<p>Inland Cold Empire Storage, at least, still had the other half of the KitKats, and Mr Black, by now frantic to salvage what he could of the candy, was still on the case.</p>
<p>“This load was stolen from us, and placed in your storage facility,” he wrote to Inland on Aug 21. Inland replied that its contract was with a man named Harry Centa.</p>
<p>“There is no ‘Harry’,” Mr Black explained. Bokksu, cc’ed on the e-mail, was the rightful owner. “‘Harry’ is a fictitious name.”</p>
<p>Harry Centa, however, is not a fictitious name. Mr Harry Centa lives in Ohio, and works in shipping. But the entire KitKat affair was news to him. “This is totally fraudulent and not me,” Mr Centa said in an e-mail to the NYTimes. “Good luck and hope they find the KitKats LOL.”</p>
<p>Nevertheless, Inland was unmoved: “Without proof that you are the rightful owner and payment for storage we cannot release the freight.”</p>
<p>Mr Black said he reached out to the sheriff’s departments of Riverside and San Bernardino counties, but said he was told<strong> </strong>jurisdictional issues kept them from getting involved, and no reports were filed.</p>
<p>He also turned to the team at Bokksu. Did they have anything that he could use to prove their ownership?</p>
<p>But Bokksu had essentially fired Mr Black in the meantime, stopped payment on his fee, filed a report with the Los Angeles County Sheriff’s Department for insurance purposes, and decided to move on. The KitKats were dead to them.</p>
</div>

    <div>
<p>“I don’t know if I would be comfortable selling these to customers,” said Mr Taing, Bokksu’s founder. “What if something actually happens to customers that eat this, and we get sued?”</p>
<p>Meanwhile, the KitKats are still at Inland, according to the company’s chief executive officer Kevin Sacalas.</p>
<p>“We have no use for this product and would happily release it to anyone who would show proof of proper ownership and pay the storage fees,” Mr Sacalas wrote in an e-mail to NYTimes.</p>
</div>

  
  <div>
<h2>Chess v checkers</h2>
<p>The Bokksu KitKats are just one instance of an increasingly common computer-based form of fraud that some experts call “fictitious pickups” or “strategic theft”. It is part identity theft, part extortion. The freight, sometimes called a “hostage load”, can vanish if the extortion demands are not met.</p>
<p>“The more you unpeel the onion, the worse it gets,” said Mr Keith Lewis, vice-president of operations at CargoNet, which is part of the global data analytics and technology provider Verisk. He said that strategic cargo theft is up 700 per cent in 2023.</p>
<p>“The supply chain is moving at the speed of light,” he said, adding: “The bad guys are playing chess and we’re playing checkers. We’re two or three steps behind them.”</p>
<p>As for Bokksu, its insurance claim has been denied. So the blame is now flowing backward along that supply chain.</p>
<p>Bokksu holds Mr Black responsible. He fell for an obvious scam, they said, and the Gmail addresses should have been a red flag.</p>
<p>Mr Black said truckers do not always use company domains. Ultimately, he blames Japan Crate Acquisition, which originally released the KitKats to ‘Tristan’.</p>
<p>“Obviously it didn’t go to an HCH truck,” Mr Black said, and whoever loaded the shipment “should’ve been suspicious.”</p>
<p>In possibly the strangest twist on the KitKat trail, Bokksu announced in September that it had acquired Japan Crate. But NYTimes discovered that the acquisition had actually been completed back in June. So Bokksu, through a wholly owned subsidiary, had in effect overseen the loading of its own KitKats onto the original two fraudulent trucks.</p>
<p>“I’ve been doing this for over two decades now, and I’ve never come across anything like this, anything of this magnitude,” Mr Black said. “It’s beyond crazy, it really is. Because there’s no answers.”</p>
<p>“I do feel cheated,” he added. “I just don’t know who is doing the cheating.” NYTIMES</p>
</div>

  


</div>

            
      
    </div>



                </section>
              </main>
                                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft pulls OneDrive update that would quiz you before letting you quit (123 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/11/microsoft-pulls-onedrive-update-that-would-quiz-you-before-letting-you-quit/</link>
            <guid>38224435</guid>
            <pubDate>Fri, 10 Nov 2023 20:58:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/11/microsoft-pulls-onedrive-update-that-would-quiz-you-before-letting-you-quit/">https://arstechnica.com/gadgets/2023/11/microsoft-pulls-onedrive-update-that-would-quiz-you-before-letting-you-quit/</a>, See on <a href="https://news.ycombinator.com/item?id=38224435">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      wish i knew how to quit you    —
</h4>
            
            <h2 itemprop="description">Change affected a "small subset" of users and has (thankfully) been reverted.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/neowin-onedrive-800x450.jpg" alt="Microsoft briefly tested a drop-down survey that you would need to fill out before you could quit the OneDrive app.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/neowin-onedrive.jpg" data-height="720" data-width="1280">Enlarge</a> <span>/</span> Microsoft briefly tested a drop-down survey that you would need to fill out before you could quit the OneDrive app.</p></figcaption>  </figure>

  




<!-- cache hit 127:single/related:15fc7c8fc96caed1d16d965b9ba42d94 --><!-- empty -->
<p>Modern versions of Windows <a href="https://arstechnica.com/gadgets/2023/08/windows-11-has-made-the-clean-windows-install-an-oxymoron/">have become more annoying</a> as time has gone on, pushing additional Microsoft products and services on users who are just trying to turn on their computers and get something done. Often, as we've covered, these notifications and reminders ignore or actively push back against user intent—prompting you to sign up for Microsoft 365 if you already said no, or trying to make you use Edge or Bing after you've already installed Chrome.</p>

<p>Microsoft took another step down this path this week when it began testing a new addition to the Windows OneDrive app that would force users to explain themselves when quitting the app. <a href="https://www.neowin.net/news/microsoft-wont-let-you-close-onedrive-in-windows-without-you-explaining-it-first/">Initially spotted by NeoWin</a>, the survey took the form of a drop-down menu, not unlike the ones you sometimes see when you try to unsubscribe from marketing or fundraising mailing lists.</p>
<p>Until you chose an answer from the drop-down, the "quit" button would be grayed out, preventing you from actually closing OneDrive.</p>
<p>This was an escalation from the previous behavior, which would ask you if you were sure before allowing you to quit but allowing you to actually click the "quit" button without interacting with any other menus. The old prompt was an explanation; the newer one was an imposition.</p>                                            
                                                        
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/onedrive-old.jpeg" data-height="800" data-width="1280" alt="The former (and current) prompt was more informational and would allow you to click the quit button without further interaction."><img alt="The former (and current) prompt was more informational and would allow you to click the quit button without further interaction." src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/onedrive-old-980x613.jpeg" width="980" height="613"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/onedrive-old.jpeg" data-height="800" data-width="1280">Enlarge</a> <span>/</span> The former (and current) prompt was more informational and would allow you to click the quit button without further interaction.</p><p>Andrew Cunningham</p></figcaption></figure>
<p>For its part, Microsoft <a href="https://www.theverge.com/2023/11/8/23952878/microsoft-onedrive-windows-close-app-notification">told The Verge</a> that the new prompt was a test that was only rolled out to a subset of OneDrive users and that the change has been reverted as of a couple of days ago.</p>
<p>"Between Nov. 1 and 8, a small subset of consumer OneDrive users were presented with a dialog box when closing the OneDrive sync client, asking for feedback on the reason they chose to close the application," reads Microsoft's statement. "This type of user feedback helps inform our ongoing efforts to enhance the quality of our products."</p>
<p>Reverted or not, the OneDrive prompt is of a piece with other things Microsoft does to encourage the usage of Edge, Bing, OneDrive, Microsoft 365, Game Pass, and its other services in Windows. You can always choose to avoid this kind of thing by declining to sign in to OneDrive or by uninstalling the app entirely. But it's just one more annoying default you need to change to make sure that modern Windows stays out of your way.</p>

        <p><em>Listing image by Microsoft</em></p>
                                                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to boss without being bossy (302 pts)]]></title>
            <link>https://www.jeffwofford.com/?p=2089</link>
            <guid>38224245</guid>
            <pubDate>Fri, 10 Nov 2023 20:42:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffwofford.com/?p=2089">https://www.jeffwofford.com/?p=2089</a>, See on <a href="https://news.ycombinator.com/item?id=38224245">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2089">
		<!-- .entry-header -->

	
	<div>
		
<p>Leaders command people. That’s kind of what a leader is: someone with the authority to direct the actions of others. </p>



<p>But people don’t often appreciate being commanded. When you step into leadership you face this challenge: how do you direct the members of your team without offending them? How do you become a good boss, but not be “bossy”?</p>



<p>It’s worth starting this discussion with the reminder that most of what bosses do isn’t bossing at all. Although a leader <em>can</em> tell people what to do, we should be slow to do so. Most team discussions are dynamic and interactive. They should involve everyone without imposing much hierarchy. As a team we cultivate ideas. We imagine solutions. We consider potential tasks. We settle on a plan. The best work happens when the whole team is involved in understanding the problem, the chosen solution, and each person’s role in making it happen. Then each member has the knowledge and ownership to handle tasks skillfully and with passion. The leader’s primary job is to nurture this discussion, to make sure there is a divergence of options and then a convergence to a solid choice. Often this leadership involves no “bossing” at all.</p>



<p>But sometimes we should and must tell people what to do. Sometimes people need the clarity, the unambiguity of a direct instruction. Sometimes we do assign tasks. “You do this.”</p>



<p>We should rarely say it like that.</p>



<p>Usually there are better ways to give a command, ways that make our purpose clear while honoring and respecting the listener. It is possible to issue a command without it feeling like a command.</p>



<p>Even the word “command” can feel abrasive. But I’m going to use that term in this article. Technically, if you as a person in authority direct someone else to perform a task, you are commanding them.</p>



<p>The question we’ll answer today, then, is: how do you give a command in a way your team members will accept, won’t reject as “bossy,” and might even feel good about?</p>



<p>We’re going to focus on words. When you know you have to give a command (or directive or instruction or assignment), what words should you use?</p>



<p>Body language matters too. Tone of voice matters. The conversation that surrounds the command—what comes before and after—matters a lot.  But today let’s dive into the nitty-gritty. What are the <em>best words</em> to use?</p>



<p>Here’s a couple of examples.</p>



<p><em>“Get this done!”</em> That’s pretty harsh. Maybe sometimes this level of directness is necessary, but it’s no way to win friends or influence people.</p>



<p><em>“Do you think we could maybe see about possibly…”</em> That’s pretty cagey. You may come across sounding weak, and your directive may get lost.</p>



<p>The English language offers a wealth of options for how to give a command. Let’s look at them and consider which work best in this or that situation and which, if any, are never good for any situation. We’ll consider the example of telling someone to take out the trash—something most of us have been asked or told to do at some point. We’ll consider different ways you might command someone to take out the trash, see how it feels, and consider how <em>clear</em> the command is and how <em>harsh</em> it may feel.</p>


<div>
<figure><img fetchpriority="high" decoding="async" width="1024" height="587" src="https://www.jeffwofford.com/wp/wp-content/uploads/2023/11/Screenshot-2023-11-10-at-4.04.13%E2%80%AFPM-1024x587.png" alt="" srcset="https://www.jeffwofford.com/wp/wp-content/uploads/2023/11/Screenshot-2023-11-10-at-4.04.13 https://www.jeffwofford.com/PM-1024x587.png 1024w, https://www.jeffwofford.com/wp/wp-content/uploads/2023/11/Screenshot-2023-11-10-at-4.04.13 https://www.jeffwofford.com/PM-300x172.png 300w, https://www.jeffwofford.com/wp/wp-content/uploads/2023/11/Screenshot-2023-11-10-at-4.04.13 https://www.jeffwofford.com/PM-768x440.png 768w, https://www.jeffwofford.com/wp/wp-content/uploads/2023/11/Screenshot-2023-11-10-at-4.04.13 https://www.jeffwofford.com/PM-1536x881.png 1536w, https://www.jeffwofford.com/wp/wp-content/uploads/2023/11/Screenshot-2023-11-10-at-4.04.13 https://www.jeffwofford.com/PM-2048x1174.png 2048w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"><figcaption>Command forms plotted against clarity and harshness</figcaption></figure></div>


<p>From this menu of command forms you can build your own style of how, when the occasion warrants, you direct members of your team to do things.</p>



<h2>A Taxonomy of Commands</h2>



<p>“<strong>Take out the trash.”</strong> The simplest and most direct way to give a command is to use a straightforward imperative verb. “<em>Drive</em> me to the airport.” “<em>Send</em> me the report by the end of the day.” “<em>Turn in</em> your homework.” These are uncomplicated, bald directives that state the intended action plainly and make no bones about who’s the boss and who’s the bossed.</p>



<p>The benefit of using a direct imperative is that your intention is perfectly clear. The listener knows what you want done and who you want to do it. The downside is harshness. Although there are more abrasive ways to give a command (we’ll get to those), the imperative feels pretty in-your-face in most business cultures. Usually (but not always) there’s a better choice.</p>



<p>Clarity: ★★★★★</p>



<p>Harshness: ★★★★☆</p>



<hr>



<p>“<strong>Please take out the trash.”</strong> The word “please” has an interesting and hard-to-define role in English usage. “Please” breaks down hierarchy and puts you on the same footing as your listener. It reaffirms the listener’s choice in the matter. Between friends, family members, and other peers it’s a crucial word, converting a command into an appeal. </p>



<p>You must judge for yourself what its effect is on the lips of a leader in a business setting. The effect varies widely based on circumstances and persons. </p>



<p>In general it has the advantage of coming across as appealing and polite. It has the disadvantage of not quite making the command definite. “Please” gives the listener an option. Do they really have an option? If the command really is indefinite—if you’re willing for the listener to say “no”—then “please” is just the right word to add. But if the listener is really obligated to obey, “please” might either make everyone feel better by preserving the public honor of the listener—the <em>illusion</em> of choice—or make everyone feel worse by exposing the leader as manipulative.</p>



<p>On balance, when giving your listener a real choice, adding “please” makes your request both clearer and more polite.</p>



<p>And keep “please” in mind while considering the other forms of command in this list. “Please” can be sprinkled into almost statement with similar, polite-ifying effects as the ones we discovered here.</p>



<p>Clarity: ★★★★★</p>



<p>Harshness: ★★★☆☆</p>



<hr>



<p>“<strong>Maybe take out the trash?” </strong>With the addition of one little word—”maybe”—and perhaps an upturned note at the end of the sentence to make it a question, the straightforward imperative becomes a much gentler request. The benefit is that you sound less bossy. The downside is that the command has lost its teeth, and the person you’re speaking to may simply ignore you. Leaders who direct others with “maybe” generally appear weak. You might make it work for your leadership style. Probably not.</p>



<p>Clarity: ★★☆☆☆</p>



<p>Harshness: ★☆☆☆☆</p>



<hr>



<p><strong>“You’d better take out the trash.” </strong>Adding “you’d better” to the start of any imperative adds a note of menace, a threat. Whether you say it or not, the phrase “or else…” creeps onto the back of the command.</p>



<p>This is almost never a good move. Tossing a threat, however implied, toward someone you want or need to have a lasting relationship with is always counterproductive. The threat weakens the relationship. </p>



<p>There’s a further problem: the threat actually weakens the command itself. The fact that you have to invoke “you’d better” to get this person to do something shows that you don’t really have the innate authority to compel them to do it. The threat, not your own leadership, holds the power. With a command like this you might get someone to do something <em>once,</em> but your authority over this person—and anyone observing the exchange—now lives on borrowed time.</p>



<p>“You’d better” tends to be the weapon of choice of bullies and demagogues. You’d better avoid it.</p>



<p>Clarity: ★★★★☆</p>



<p>Harshness: ★★★★★</p>



<hr>



<p><strong>“You will take out the trash.”</strong> One of the English language’s favorite ways of softening an imperative is to turn it into the <em>future tense.</em></p>



<p>On the face of it the future tense looks as if it’s expecting us to predict what the listener will do. “I am Carmac the Magnificent and I foresee that you will…<em>take out the trash!”</em> But we know that in fact this is a directive rather than a prediction, yet a slightly softer directive than the bare imperative.</p>



<p>How does it come across to the listener? The answer varies. If you stress the word “will” (or, heaven forbid, transmogrify it to “shall”), the directive is quite harsh and even threatening. But good leaders can say, “You will…” in a calm and inoffensive tone and convey a sense of solidity rather than threat. “What you’re going to do is to get the kitchen cleaned up. After that you’ll take out the trash.” In effect they’re directing: “Get the kitchen cleaned up. After that, take out the trash.” But the future tense with the proper tone comes across a little more gently.</p>



<p>Clarity: ★★★★★</p>



<p>Harshness: ★★★★☆</p>



<hr>



<p><strong>“I want you to take out the trash.” </strong>To my ear this is slightly gentler than a stark, “Take out the trash,” but tone of voice can make all the difference.</p>



<p>Clarity: ★★★★★</p>



<p>Harshness: ★★★★☆</p>



<hr>



<p><strong>“I need you to take out the trash.” </strong>The differences between these various ways of asking someone to do something may strike you as overly subtle, but often a grain of change can make a heap of difference. The shift here from “want” to “need” makes this command much more forceful, yet without seeming particularly harsh. </p>



<p>“I need you to…” is a very popular way of commanding. Many leaders prefer it over any other form. I’ve even seen it taught in assertiveness training classes. </p>



<p>The reason it works so well is that it makes an appeal to the listener that is very forceful yet neither threatening nor invasive. In essence you’re asking for help: “I have this need, you see? Would you meet my need?” It’s not <em>you</em> that demands so loudly that this person obey your request, it’s your <em>need</em> that makes the demand. “I have this need, and you can help me meet my need by doing <em>this.” </em>The phrase “I need you to” gives the directive a softer, less “bossy” quality than some alternatives.</p>



<p>Yet it is forceful. A listener will find it very difficult to evade this form of command. To do so they must in essence respond with, “No, you don’t <em>need</em> that.” That kind of response takes brass. It means making a higher claim about your needs than you yourself are making. The listener must say, in effect, “You <em>say</em> that you need me to do that, but you’re wrong. What you <em>really</em> need is….” Only a very well-informed and knowledgable—or else stupid and insubordinate—listener will reply like this. Sometimes it <em>is</em> the right reply, and if you as a leader are telling people that you need them to do something, you’d better actually need it. This is a bluff that can be called.</p>



<p>In normal circumstances “I need you to…” is a tried-and-true way of issuing a command that carries great force without seeming excessively harsh, and is therefore quite common.</p>



<p>Clarity: ★★★★★</p>



<p>Harshness: ★★★☆☆ (and yet forceful)</p>



<hr>



<p><strong>“Would you mind taking out the trash?” </strong>Here is one of the most common—and grammatically vexing—of English request forms, but also among the most effective. The fact that the listener must answer with “no” in order to agree to your request never ceases to befuddle. </p>



<p>As with adding “please” to a request, “would you mind” softens by transforming a demand into a plea. It is virtually illegal, culturally speaking, to answer with “yes,” as if you minded (even if you would). Instead the listener is obligated to refuse the request in some more deliberate way: “Well, actually I’m tied up just now” or something similar. Consequently this is one of those magic request forms (like “I need you to…”) that applies more force with less harshness.</p>



<p>“Would you mind” gives a less clear command than the bare imperative in that the user may refuse. The “answer yes by saying no” twisteroo also adds a little mental complication.</p>



<p>Clarity: ★★★★☆</p>



<p>Harshness: ★★★☆☆</p>



<hr>



<p><strong>“I</strong>‘<strong>m going to get you to take out the trash.” </strong>By prefacing the imperative with several filler words, we dull the edge of the command while keeping the meaning fairly clear (though not as clear as the bare imperative). There’s not much mistaking what is supposed to be done or who is to do it, yet a little wiggle room has been left to the listener. Several of the phrases on this list use this technique: make the command longer to make it less harsh, but also less clear. </p>



<p>Personally I find this phraseology irritating. It can perhaps feel more gentle than a bare imperative but it also sounds more toadying and manipulative. For my own preference, a leader tempted to hedge with “I’m going to get you to…” would do better to skip the rigmarole and just say what they want.</p>



<p>Clarity: ★★★★☆</p>



<p>Harshness: ★★★☆☆</p>



<hr>



<p><strong>“I’ll let you take out the trash.” </strong>Another softening-by-lengthening technique, now with the added twist of implying that the listener <em>wants</em> to do the task. To me it sounds manipulative, but it has the further disadvantage of lost clarity. The listener may reply (mentally or aloud), “You’re <em>letting </em>me? So if I don’t want to, I don’t have to?” The task may not get done, and you as leader won’t have much of an excuse for why you didn’t make your requirement clearer.</p>



<p>Clarity: ★★★☆☆</p>



<p>Harshness: ★★☆☆☆</p>



<hr>



<p><strong>“I’d like for the trash to be taken out.” </strong>It’s remarkable how often you’ll hear phrases like this in meetings at every level of an organization. A leader knows what they want done and who they want to do it, but by omitting the subject of the command—<em>“you”</em>—they hope to make it less bossy. Indeed, they hope the listener will reply, “Okay, I’ll take out the trash.” Sometimes this works. More often, everyone sits on their hands, waits for the moment to pass, and the command is ambiguously lost as the meeting moves on.</p>



<p>There is a time for leaders to suggest a task and allow followers to volunteer to take it on. But it’s best to make that dance explicit. “Somebody needs to take the trash out. Who’ll do it?” Trying to hedge your command as an invitation for volunteerism is usually just weak and ineffective. If you know that you’re speaking to John, and everyone knows that you’re speaking to John, then speak to John. Don’t imply commands.</p>



<p>Clarity: ★★☆☆☆</p>



<p>Harshness: ★★☆☆☆</p>



<hr>



<p><strong>“Will you/Would you take out the trash?” </strong>On the face of it, it looks as if the English language, by offering this form of request, is inviting the listener to proclaim a prophetic oracle. A cheeky reply would be, “I don’t know whether I’ll take out the trash—am I supposed to be able to see the future?” In reality, of course, the future tense of the verb is a softer way to frame an imperative mood. Phrasing the command in the form of a question softens it further. The question implies—truly or falsely—that the listener has a choice.</p>



<p>This is a good and of course very common way of asking people to do things, quite clear and not terribly harsh. Your parents and teachers probably used it with you. Don’t be too shy about using it with your team.</p>



<p>Clarity: ★★★★☆</p>



<p>Harshness: ★★☆☆☆</p>



<hr>



<p><strong>“Could you/Can you take out the trash?”</strong> Likewise, “could you/can you” feels slightly quaint, almost archaic, and holds a note of appeal (as opposed to command) that might work well for your style of leadership. Or not. Something to experiment with?</p>



<p>Clarity: ★★★☆☆</p>



<p>Harshness: ★★☆☆☆</p>



<hr>



<p><strong>“Let’s take out the trash.”</strong> Another way of softening a command is to put it into the plural first person (“we/us”) instead of the second person (“you”). “Let’s…” is very commonly used by leaders and probably shouldn’t be. It tries to avoid harshness by sacrificing clarity, but usually loses more than it gains. The real subject of the command—<em>you</em>—is hidden, and unless the context has made the subject clear, the command will be lost. When you mean “you,” say “you.”</p>



<p>Still, “Let’s…” has its place in a leader’s toolbox, as for example when the person responsible for the task has already been made explicit and the leader’s significant choice is not <em>who</em> will do it but <em>what</em> they will do. In that case, “Let’s take out the trash” may not be a hedging way of saying “You take out the trash,” but rather, “You’ll take out the trash instead of taking out the recycling.”</p>



<p>Clarity: ★★☆☆☆</p>



<p>Harshness: ★★☆☆☆</p>



<hr>



<p>“<strong>Why don’t we take out the tras</strong><strong>h?”</strong> Again an overused hedge but not without its place. It is extremely soft but also extremely unclear. Are you actually asking someone to do something? In the middle of an exploratory discussion, asking “why don’t we” or “what if” questions is helpful in cultivating new options or narrowing toward a final choice. But as a final choice, “Why don’t we…” is too cautious and vague. Make a clear choice of who is to do what and then tell them clearly to do it.</p>



<p>Clarity: ★☆☆☆☆</p>



<p>Harshness: ★☆☆☆☆</p>



<hr>



<p>“<strong>Could we take out the trash?”</strong> Similar in form and effect to “Why don’t we…?” See the discussion there.</p>



<p>Clarity: ★☆☆☆☆</p>



<p>Harshness: ★☆☆☆☆</p>



<hr>



<p>“<strong>If you would just take out the trash…”</strong> Couches the command in the form of an “if” statement, usually with disastrous results. </p>



<p>Sometimes leaders let the ellipsis dangle, just like that: “If you would just take out the trash…”—followed by an uncomfortable silence in the room. This is bad.</p>



<p>Sometimes they fill the ellipsis with some convenient apodosis: “If you would just take out the trash, we could wash out the bin and maybe it wouldn’t smell so much.” This is equally bad. What little imperative force was implied by the initial “If you would…” becomes lost in the succeeding drivel.</p>



<p>“If you would…” simply fails as a means of commanding (or even asking) someone to do something. It stages a desperate ploy to sound less bossy, but still comes across as bossy, yet in an evasive and pandering manner. Avoid it.</p>



<p>A common variant has “could” in place of “would.” I don’t see a great difference.</p>



<p>Clarity: ★☆☆☆☆</p>



<p>Harshness: ★☆☆☆☆</p>



<hr>



<p>If you want to be a good boss without being seen as bossy, mull over this list. Watch how other leaders use phrases like these and what effect they have. Try out new ways of issuing commands, see how they feel to you, see how people respond. The key is to find a way of directing people that suits your personality, your team, and your organization’s culture. Once you settle on a comfortable style and make it consistent, then you’ll be seen as a leader who knows how to get people to do things without coming across as obnoxious.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon gives Apple 'massive preferential treatment' in secret deal report claims (200 pts)]]></title>
            <link>https://9to5mac.com/2023/11/10/amazon-apple-special-deal-online-storefront/</link>
            <guid>38224217</guid>
            <pubDate>Fri, 10 Nov 2023 20:39:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2023/11/10/amazon-apple-special-deal-online-storefront/">https://9to5mac.com/2023/11/10/amazon-apple-special-deal-online-storefront/</a>, See on <a href="https://news.ycombinator.com/item?id=38224217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?quality=82&amp;strip=all&amp;w=1600" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2022/11/apple-amazon-lawsuit.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1600" height="900" alt="apple amazon lawsuit" fetchpriority="high">
	
	</figure>

<p>Apple and Amazon are once again facing scrutiny for their 2018 agreement that saw Apple finally establish an <a href="https://amzn.to/3sm9MUy">official Amazon storefront</a>. A report <a href="https://www.businessinsider.com/amazon-gives-apple-special-treatment-while-others-suffer-junk-ads-2023-11">from <em>Insider</em> today</a> goes in-depth on the details of this agreement, with one source saying that Apple is getting “massive preferential treatment” from Amazon.</p>



<p>The deal between Apple and Amazon has <a href="https://9to5mac.com/2019/08/02/apple-amazon/">faced quite a bit</a> of regulatory pushback over the <a href="https://9to5mac.com/2020/10/29/apple-amazon-deal-germany/">past several years</a>. The two companies are also <a href="https://9to5mac.com/2022/11/09/apple-amazon-lawsuit-price-fixing/">battling a price-fixing lawsuit</a> that alleges they colluded to raise iPhone and iPad prices.</p>



<p>As detailed by today’s report, the agreement between Apple and Amazon includes a carveout that reduces the number of ads and recommendations that appear on product pages for Apple devices. While Amazon product pages are generally full of ads, sponsored results, and recommendations, Apple’s product pages show only one banner ad at the very bottom of the page.</p>



<p>In contrast, product pages for Apple competitors like Samsung are riddled with ads from competitors, recommendations, and other sponsored banners. <em>Insider</em> says that other companies, including Samsung, have complained about the preferential treatment given to Apple.</p>



<p>It’s unclear whether Amazon has made similar offers to companies like Samsung. <em>Insider</em> cites “least half a dozen salespeople on Amazon’s advertising team” who say that “they were not able to extend this Apple-style special treatment to their clients.”</p>



<p>Emails revealed as part of an FTC lawsuit against Amazon reveal that the company initially pushed back against Apple’s demands for special treatment before eventually caving in. In a statement today, Apple explained:</p>



<blockquote>
<p>Apple also told Insider that the 2018 agreement with Amazon “sought to address significant counterfeit and safety issues” on Amazon’s marketplace. Prior to the deal, Apple sent “hundreds of thousands of take-down notices” to Amazon to reduce counterfeits, and the company conducted test purchases on Amazon that “consistently returned high counterfeit rates,” Apple added.</p>



<p>By providing “accurate, relevant and qualitative content on Apple Product pages,” Apple has been able to address much of the counterfeit issues on Amazon, the iPhone maker said.</p>



<p>“The 2018 Agreements significantly reduced the sale of counterfeit and unsafe Apple products on Amazon’s marketplaces and have materially improved customer experience,” Apple also wrote in a statement to Insider.</p>
</blockquote>



<p>The <a href="https://www.businessinsider.com/amazon-gives-apple-special-treatment-while-others-suffer-junk-ads-2023-11">full report at <em>Insider</em></a> includes additional details on the early negotiations between Apple and Amazon. For instance, at one point, Amazon insisted that Apple “compensate Amazon for the lost ad revenue” from the deal. Still, it’s unclear if that was included in the final agreement.</p>



<p><strong>Follow Chance</strong>:&nbsp;<a href="https://www.threads.net/@ChanceHMiller">Threads</a>,&nbsp;<a href="https://twitter.com/chancehmiller">Twitter</a>,&nbsp;<a href="https://www.instagram.com/chancehmiller/">Instagram</a>, and&nbsp;<a href="https://mastodon.social/@ChanceHMiller">Mastodon</a>.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/3shtH6M"><img src="https://9to5mac.com/wp-content/uploads/sites/6/2023/10/integration_1.webp" alt="" width="750" height="150"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hashmaps in Factor are faster than in Zig (148 pts)]]></title>
            <link>https://re.factorcode.org/2023/11/factor-is-faster-than-zig.html</link>
            <guid>38224033</guid>
            <pubDate>Fri, 10 Nov 2023 20:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://re.factorcode.org/2023/11/factor-is-faster-than-zig.html">https://re.factorcode.org/2023/11/factor-is-faster-than-zig.html</a>, See on <a href="https://news.ycombinator.com/item?id=38224033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Recently, I was looking at the <a href="https://ziglang.org/">Zig programming language</a>.
As I often do, I started implementing a few typical things in new languages to learn them. Well, one of them was super slow and Zig is supposed to be super
fast, so I was trying to understand where the disconnect was and compare it to
<a href="https://factorcode.org/">Factor</a>!</p>
<p>I was able to reduce the issue to a small test case and it turns out that there
is a behavioral issue in their <a href="https://github.com/ziglang/zig/blob/master/lib/std/hash_map.zig">implementation of
HashMap</a> that
makes their <a href="https://github.com/ziglang/zig/issues/17851">HashMaps get slow over
time</a>. The test case performs
these steps:</p>
<ul>
<li>creates a <code>HashMap</code> of 2 million items</li>
<li>decrements the map values, removing an item every third loop</li>
<li>inserts a replacement new item to maintain 2 million items in the <code>HashMap</code></li>
<li>for a total of 250 million actions, then</li>
<li>deletes the remaining items from the <code>HashMap</code></li>
</ul>
<p>We record the total time each block of 1 million actions takes:</p>
<p>
<img src="https://re.factorcode.org/images/2023-11-09-zig-hashmap-bug.png" alt="" width="531" height="386">
</p>
<p>Something is very wrong!</p>
<h3 id="zig">Zig</h3>
<p>This is the simple test case implemented in Zig using the <code>std.HashMap</code>:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span><span>std</span><span> </span><span>=</span><span> </span><span>@import</span><span>(</span><span>"std"</span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span><span>main</span><span>()</span><span> </span><span>!</span><span>void</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span><span>map</span><span> </span><span>=</span><span> </span><span>std</span><span>.</span><span>AutoHashMap</span><span>(</span><span>u64</span><span>,</span><span> </span><span>u64</span><span>).</span><span>init</span><span>(</span><span>std</span><span>.</span><span>heap</span><span>.</span><span>page_allocator</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>defer</span><span> </span><span>map</span><span>.</span><span>deinit</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span><span>list</span><span> </span><span>=</span><span> </span><span>std</span><span>.</span><span>ArrayList</span><span>(</span><span>u64</span><span>).</span><span>init</span><span>(</span><span>std</span><span>.</span><span>heap</span><span>.</span><span>page_allocator</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>defer</span><span> </span><span>list</span><span>.</span><span>deinit</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span><span>prng</span><span> </span><span>=</span><span> </span><span>std</span><span>.</span><span>rand</span><span>.</span><span>DefaultPrng</span><span>.</span><span>init</span><span>(</span><span>0</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>random</span><span> </span><span>=</span><span> </span><span>prng</span><span>.</span><span>random</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span><span>start</span><span> </span><span>=</span><span> </span><span>std</span><span>.</span><span>time</span><span>.</span><span>milliTimestamp</span><span>();</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span><span>i</span><span>:</span><span> </span><span>u64</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span><span>(</span><span>i</span><span> </span><span>&lt;</span><span> </span><span>2_000_000</span><span>)</span><span> </span><span>:</span><span> </span><span>(</span><span>i</span><span> </span><span>+=</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>try</span><span> </span><span>map</span><span>.</span><span>put</span><span>(</span><span>i</span><span>,</span><span> </span><span>3</span><span>);</span><span>
</span></span></span><span><span><span>        </span><span>try</span><span> </span><span>list</span><span>.</span><span>append</span><span>(</span><span>i</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span><span>(</span><span>i</span><span> </span><span>&lt;</span><span> </span><span>250_000_000</span><span>)</span><span> </span><span>:</span><span> </span><span>(</span><span>i</span><span> </span><span>+=</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>var</span><span> </span><span>index</span><span> </span><span>=</span><span> </span><span>random</span><span>.</span><span>uintLessThan</span><span>(</span><span>usize</span><span>,</span><span> </span><span>list</span><span>.</span><span>items</span><span>.</span><span>len</span><span>);</span><span>
</span></span></span><span><span><span>        </span><span>var</span><span> </span><span>j</span><span> </span><span>=</span><span> </span><span>list</span><span>.</span><span>items</span><span>[</span><span>index</span><span>];</span><span>
</span></span></span><span><span><span>        </span><span>var</span><span> </span><span>k</span><span> </span><span>=</span><span> </span><span>map</span><span>.</span><span>get</span><span>(</span><span>j</span><span>).</span><span>?</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span><span>(</span><span>k</span><span> </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>_</span><span> </span><span>=</span><span> </span><span>map</span><span>.</span><span>remove</span><span>(</span><span>j</span><span>);</span><span>
</span></span></span><span><span><span>            </span><span>try</span><span> </span><span>map</span><span>.</span><span>put</span><span>(</span><span>i</span><span>,</span><span> </span><span>3</span><span>);</span><span>
</span></span></span><span><span><span>            </span><span>list</span><span>.</span><span>items</span><span>[</span><span>index</span><span>]</span><span> </span><span>=</span><span> </span><span>i</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>try</span><span> </span><span>map</span><span>.</span><span>put</span><span>(</span><span>j</span><span>,</span><span> </span><span>k</span><span> </span><span>-</span><span> </span><span>1</span><span>);</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span><span>(</span><span>i</span><span> </span><span>%</span><span> </span><span>1_000_000</span><span> </span><span>==</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>var</span><span> </span><span>end</span><span> </span><span>=</span><span> </span><span>std</span><span>.</span><span>time</span><span>.</span><span>milliTimestamp</span><span>();</span><span>
</span></span></span><span><span><span>            </span><span>std</span><span>.</span><span>debug</span><span>.</span><span>print</span><span>(</span><span>"{} block took {} ms</span><span>\n</span><span>"</span><span>,</span><span> </span><span>.{</span><span> </span><span>i</span><span>,</span><span> </span><span>end</span><span> </span><span>-</span><span> </span><span>start</span><span> </span><span>});</span><span>
</span></span></span><span><span><span>            </span><span>start</span><span> </span><span>=</span><span> </span><span>std</span><span>.</span><span>time</span><span>.</span><span>milliTimestamp</span><span>();</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span><span>(</span><span>list</span><span>.</span><span>items</span><span>.</span><span>len</span><span> </span><span>&gt;</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>var</span><span> </span><span>j</span><span> </span><span>=</span><span> </span><span>list</span><span>.</span><span>pop</span><span>();</span><span>
</span></span></span><span><span><span>        </span><span>_</span><span> </span><span>=</span><span> </span><span>map</span><span>.</span><span>remove</span><span>(</span><span>j</span><span>);</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>We can run it using <code>ReleaseFast</code> to get the best performance and see
that, over time, it gets super slow – so slow that it isn’t even able to
really finish the test case:</p>
<pre tabindex="0"><code>$ zig version
0.11.0

$ zig run -O ReleaseFast maptest.zig
2000000 block took 156 ms
3000000 block took 122 ms
4000000 block took 127 ms
5000000 block took 133 ms
6000000 block took 138 ms
7000000 block took 141 ms
8000000 block took 143 ms
9000000 block took 145 ms
10000000 block took 147 ms
11000000 block took 148 ms
12000000 block took 151 ms
13000000 block took 153 ms
14000000 block took 155 ms
15000000 block took 157 ms
16000000 block took 159 ms
17000000 block took 164 ms
18000000 block took 167 ms
19000000 block took 171 ms
20000000 block took 173 ms
21000000 block took 180 ms
22000000 block took 186 ms
23000000 block took 190 ms
24000000 block took 195 ms
25000000 block took 205 ms
26000000 block took 213 ms
27000000 block took 221 ms
28000000 block took 234 ms
29000000 block took 247 ms
30000000 block took 264 ms
31000000 block took 282 ms
32000000 block took 301 ms
33000000 block took 320 ms
34000000 block took 346 ms
35000000 block took 377 ms
36000000 block took 409 ms
37000000 block took 448 ms
38000000 block took 502 ms
39000000 block took 550 ms
40000000 block took 614 ms
41000000 block took 694 ms
42000000 block took 767 ms
43000000 block took 853 ms
44000000 block took 961 ms
45000000 block took 1088 ms
46000000 block took 1250 ms
47000000 block took 1420 ms
48000000 block took 1612 ms
49000000 block took 1826 ms
50000000 block took 2056 ms
51000000 block took 2320 ms
52000000 block took 2688 ms
53000000 block took 3015 ms
54000000 block took 3467 ms
55000000 block took 3971 ms
56000000 block took 4618 ms
57000000 block took 5377 ms
58000000 block took 6172 ms
59000000 block took 7094 ms
60000000 block took 8173 ms
61000000 block took 9469 ms
62000000 block took 11083 ms
63000000 block took 12737 ms
64000000 block took 14000 ms
65000000 block took 16243 ms
66000000 block took 17912 ms
67000000 block took 20452 ms
68000000 block took 24356 ms
...
</code></pre><p>We can switch the example above to use <code>std.ArrayHashMap</code> which does not have
this problem, although it is a bit slower with each block taking roughly 250
milliseconds.</p>
<h3 id="factor">Factor</h3>
<p>We can compare that to a simple implementation in Factor:</p>
<div><pre tabindex="0"><code data-lang="factor"><span><span><span>USING:</span> <span>assocs</span> <span>calendar</span> <span>formatting</span> <span>io</span> <span>kernel</span> <span>math</span> <span>random</span>
</span></span><span><span><span>sequences</span> <span>;
</span></span></span><span><span><span></span>
</span></span><span><span><span>::</span> <span>maptest</span> <span>( -- )
</span></span></span><span><span><span></span>    H{ } <span>clone </span>:&gt; m
</span></span><span><span>    V{ } <span>clone </span>:&gt; l
</span></span><span><span>
</span></span><span><span>    now :&gt; start!
</span></span><span><span>    <span>0 </span>  :&gt; i!
</span></span><span><span>
</span></span><span><span>    [ i <span>2,000,000 </span><span>&lt; </span>] [
</span></span><span><span>        <span>3 </span>i m <span>set-at
</span></span></span><span><span><span></span>        i l <span>push
</span></span></span><span><span><span></span>        i <span>1 </span><span>+ </span>i!
</span></span><span><span>    ] <span>while
</span></span></span><span><span><span></span>
</span></span><span><span>    [ i <span>250,000,000 </span><span>&lt; </span>] [
</span></span><span><span>        l <span>length </span>random :&gt; j
</span></span><span><span>        j l <span>nth </span>:&gt; k
</span></span><span><span>        k m <span>at </span><span>1 </span><span>- </span>[
</span></span><span><span>            k m <span>delete-at
</span></span></span><span><span><span></span>            <span>3 </span>i m <span>set-at
</span></span></span><span><span><span></span>            i j l <span>set-nth
</span></span></span><span><span><span></span>        ] [
</span></span><span><span>            k m <span>set-at
</span></span></span><span><span><span></span>        ] <span>if-zero
</span></span></span><span><span><span></span>
</span></span><span><span>        i <span>1,000,000 </span><span>mod zero? </span>[
</span></span><span><span>            i now <span>start </span>time- duration&gt;milliseconds
</span></span><span><span>            <span>"%d block took %d ms\n"</span> printf <span>flush
</span></span></span><span><span><span></span>            now start!
</span></span><span><span>        ] <span>when
</span></span></span><span><span><span></span>        i <span>1 </span><span>+ </span>i!
</span></span><span><span>    ] <span>while
</span></span></span><span><span><span></span>
</span></span><span><span>    [ l <span>empty? </span>] [
</span></span><span><span>        l <span>pop </span>m <span>delete-at
</span></span></span><span><span><span></span>    ] <span>until </span><span>;
</span></span></span></code></pre></div><p>We can run it in Factor and see how long it takes. There are notably some long
delays in the first few blocks which I’d like to understand better – possibly
due to excessive rehashing or some allocation pattern with the Factor garbage
collector – and then it quickly reaches a steady state where each block takes
about 250 milliseconds.</p>
<pre tabindex="0"><code>$ factor maptest.factor
2000000 block took 855 ms
3000000 block took 198 ms
4000000 block took 205 ms
5000000 block took 3579 ms
6000000 block took 4438 ms
7000000 block took 3624 ms
8000000 block took 2996 ms
9000000 block took 232 ms
10000000 block took 243 ms
11000000 block took 248 ms
12000000 block took 298 ms
13000000 block took 233 ms
14000000 block took 238 ms
15000000 block took 298 ms
16000000 block took 233 ms
17000000 block took 521 ms
18000000 block took 231 ms
19000000 block took 236 ms
20000000 block took 280 ms
21000000 block took 235 ms
22000000 block took 235 ms
23000000 block took 281 ms
24000000 block took 231 ms
25000000 block took 236 ms
26000000 block took 294 ms
27000000 block took 231 ms
28000000 block took 236 ms
29000000 block took 506 ms
30000000 block took 234 ms
31000000 block took 237 ms
32000000 block took 277 ms
33000000 block took 232 ms
34000000 block took 239 ms
35000000 block took 279 ms
36000000 block took 235 ms
37000000 block took 239 ms
38000000 block took 275 ms
39000000 block took 234 ms
40000000 block took 514 ms
41000000 block took 231 ms
42000000 block took 236 ms
43000000 block took 282 ms
44000000 block took 235 ms
45000000 block took 235 ms
46000000 block took 282 ms
47000000 block took 231 ms
48000000 block took 233 ms
49000000 block took 280 ms
50000000 block took 234 ms
51000000 block took 238 ms
52000000 block took 507 ms
53000000 block took 231 ms
54000000 block took 236 ms
55000000 block took 276 ms
56000000 block took 231 ms
57000000 block took 238 ms
58000000 block took 278 ms
59000000 block took 234 ms
60000000 block took 235 ms
61000000 block took 278 ms
62000000 block took 237 ms
63000000 block took 239 ms
64000000 block took 510 ms
65000000 block took 234 ms
66000000 block took 284 ms
...
</code></pre><p>Not bad!</p>
<h3 id="whats-the-bug">What’s the Bug?</h3>
<p>So, Zig <em>could</em> be super fast, but the default <code>std.HashMap</code> implementation
uses tombstone buckets to mark slots as being deleted, and over time these
tombstone buckets create fragmentation in the HashMap, which causes their
linear probing to trend towards the worst case examination of every bucket in
the HashMap when looking for a key.</p>
<p>We can implement a <code>rehash()</code> method on the HashMap that performs an in-place
rehashing of all the elements, without allocations. Ideally, this would be done
when the number of filled and deleted slots reaches some capacity threshold.
But, for now, we can just run <code>map.rehash()</code> once per block, and see how that
improves performance:</p>
<div><pre tabindex="0"><code data-lang="diff"><span><span><span>diff --git a/lib/std/hash_map.zig b/lib/std/hash_map.zig
</span></span></span><span><span><span>index 8a3d78283..7192ba733 100644
</span></span></span><span><span><span></span><span>--- a/lib/std/hash_map.zig
</span></span></span><span><span><span></span><span>+++ b/lib/std/hash_map.zig
</span></span></span><span><span><span></span><span>@@ -681,6 +681,11 @@ pub fn HashMap(
</span></span></span><span><span><span></span>             self.unmanaged = .{};
</span></span><span><span>             return result;
</span></span><span><span>         }
</span></span><span><span><span>+
</span></span></span><span><span><span>+         /// Rehash the map, in-place
</span></span></span><span><span><span>+         pub fn rehash(self: *Self) void {
</span></span></span><span><span><span>+             self.unmanaged.rehash(self.ctx);
</span></span></span><span><span><span>+         }
</span></span></span><span><span><span></span>     };
</span></span><span><span> }
</span></span><span><span> 
</span></span><span><span><span>@@ -1505,6 +1510,92 @@ pub fn HashMapUnmanaged(
</span></span></span><span><span><span></span>             return result;
</span></span><span><span>         }
</span></span><span><span> 
</span></span><span><span><span>+       /// Rehash the map, in-place
</span></span></span><span><span><span>+       pub fn rehash(self: *Self, ctx: anytype) void {
</span></span></span><span><span><span>+             const mask = self.capacity() - 1;
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+             var metadata = self.metadata.?;
</span></span></span><span><span><span>+             var keys_ptr = self.keys();
</span></span></span><span><span><span>+             var values_ptr = self.values();
</span></span></span><span><span><span>+             var curr: Size = 0;
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+             // While we are re-hashing every slot, we will use the
</span></span></span><span><span><span>+             // fingerprint to mark used buckets as being used and either free
</span></span></span><span><span><span>+             // (needing to be rehashed) or tombstone (already rehashed).
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+             while (curr &lt; self.capacity()) : (curr += 1) {
</span></span></span><span><span><span>+                 metadata[curr].fingerprint = Metadata.free;
</span></span></span><span><span><span>+             }
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+             // Now iterate over all the buckets, rehashing them
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+             curr = 0;
</span></span></span><span><span><span>+             while (curr &lt; self.capacity()) {
</span></span></span><span><span><span>+                 if (!metadata[curr].isUsed()) {
</span></span></span><span><span><span>+                     assert(metadata[curr].isFree());
</span></span></span><span><span><span>+                     curr += 1;
</span></span></span><span><span><span>+                     continue;
</span></span></span><span><span><span>+                 }
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                 var hash = ctx.hash(keys_ptr[curr]);
</span></span></span><span><span><span>+                 var fingerprint = Metadata.takeFingerprint(hash);
</span></span></span><span><span><span>+                 var idx = @as(usize, @truncate(hash &amp; mask));
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                 // For each bucket, rehash to an index:
</span></span></span><span><span><span>+                 // 1) before the cursor, probed into a free slot, or
</span></span></span><span><span><span>+                 // 2) equal to the cursor, no need to move, or
</span></span></span><span><span><span>+                 // 3) ahead of the cursor, probing over already rehashed
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                 while ((idx &lt; curr and metadata[idx].isUsed()) or
</span></span></span><span><span><span>+                     (idx &gt; curr and metadata[idx].fingerprint == Metadata.tombstone))
</span></span></span><span><span><span>+                 {
</span></span></span><span><span><span>+                     idx = (idx + 1) &amp; mask;
</span></span></span><span><span><span>+                 }
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                 if (idx &lt; curr) {
</span></span></span><span><span><span>+                     assert(metadata[idx].isFree());
</span></span></span><span><span><span>+                     metadata[idx].fingerprint = fingerprint;
</span></span></span><span><span><span>+                     metadata[idx].used = 1;
</span></span></span><span><span><span>+                     keys_ptr[idx] = keys_ptr[curr];
</span></span></span><span><span><span>+                     values_ptr[idx] = values_ptr[curr];
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                     metadata[curr].used = 0;
</span></span></span><span><span><span>+                     assert(metadata[curr].isFree());
</span></span></span><span><span><span>+                     keys_ptr[curr] = undefined;
</span></span></span><span><span><span>+                     values_ptr[curr] = undefined;
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                     curr += 1;
</span></span></span><span><span><span>+                 } else if (idx == curr) {
</span></span></span><span><span><span>+                     metadata[idx].fingerprint = fingerprint;
</span></span></span><span><span><span>+                     curr += 1;
</span></span></span><span><span><span>+                 } else {
</span></span></span><span><span><span>+                     assert(metadata[idx].fingerprint != Metadata.tombstone);
</span></span></span><span><span><span>+                     metadata[idx].fingerprint = Metadata.tombstone;
</span></span></span><span><span><span>+                     if (metadata[idx].isUsed()) {
</span></span></span><span><span><span>+                         var tmpkey = keys_ptr[idx];
</span></span></span><span><span><span>+                         var tmpvalue = values_ptr[idx];
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                         keys_ptr[idx] = keys_ptr[curr];
</span></span></span><span><span><span>+                         values_ptr[idx] = values_ptr[curr];
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                         keys_ptr[curr] = tmpkey;
</span></span></span><span><span><span>+                         values_ptr[curr] = tmpvalue;
</span></span></span><span><span><span>+                     } else {
</span></span></span><span><span><span>+                         metadata[idx].used = 1;
</span></span></span><span><span><span>+                         keys_ptr[idx] = keys_ptr[curr];
</span></span></span><span><span><span>+                         values_ptr[idx] = values_ptr[curr];
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                         metadata[curr].fingerprint = Metadata.free;
</span></span></span><span><span><span>+                         metadata[curr].used = 0;
</span></span></span><span><span><span>+                         keys_ptr[curr] = undefined;
</span></span></span><span><span><span>+                         values_ptr[curr] = undefined;
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+                         curr += 1;
</span></span></span><span><span><span>+                     }
</span></span></span><span><span><span>+                 }
</span></span></span><span><span><span>+             }
</span></span></span><span><span><span>+         }
</span></span></span><span><span><span>+
</span></span></span><span><span><span></span>oid {
</span></span><span><span>             @setCold(true);
</span></span><span><span>             const new_cap = @max(new_capacity, minimal_capacity);
</span></span><span><span><span>@@ -2218,3 +2309,35 @@ test "std.hash_map repeat fetchRemove" {
</span></span></span><span><span><span></span>     try testing.expect(map.get(2) != null);
</span></span><span><span>     try testing.expect(map.get(3) != null);
</span></span><span><span> }
</span></span><span><span><span>+
</span></span></span><span><span><span>+test "std.hash_map rehash" {
</span></span></span><span><span><span>+    var map = AutoHashMap(u32, u32).init(std.testing.allocator);
</span></span></span><span><span><span>+    defer map.deinit();
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+    var prng = std.rand.DefaultPrng.init(0);
</span></span></span><span><span><span>+    const random = prng.random();
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+    const count = 6 * random.intRangeLessThan(u32, 100_000, 500_000);
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+    var i: u32 = 0;
</span></span></span><span><span><span>+    while (i &lt; count) : (i += 1) {
</span></span></span><span><span><span>+        try map.put(i, i);
</span></span></span><span><span><span>+        if (i % 3 == 0) {
</span></span></span><span><span><span>+            try expectEqual(map.remove(i), true);
</span></span></span><span><span><span>+        }
</span></span></span><span><span><span>+    }
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+    map.rehash();
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+    try expectEqual(map.count(), count * 2 / 3);
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+    i = 0;
</span></span></span><span><span><span>+    while (i &lt; count) : (i += 1) {
</span></span></span><span><span><span>+        if (i % 3 == 0) {
</span></span></span><span><span><span>+            try expectEqual(map.get(i), null);
</span></span></span><span><span><span>+        } else {
</span></span></span><span><span><span>+            try expectEqual(map.get(i).?, i);
</span></span></span><span><span><span>+        }
</span></span></span><span><span><span>+    }
</span></span></span><span><span><span>+}
</span></span></span></code></pre></div><p>We can apply that diff to <code>lib/std/hash_map.zig</code> and try again, now taking
about 165 milliseconds per block including the time for <code>map.rehash()</code>:</p>
<pre tabindex="0"><code>$ zig run -O ReleaseFast maptest.zig --zig-lib-dir ~/Dev/zig/lib
2000000 block took 155 ms
3000000 block took 147 ms
4000000 block took 154 ms
5000000 block took 160 ms
6000000 block took 163 ms
7000000 block took 164 ms
8000000 block took 165 ms
9000000 block took 166 ms
10000000 block took 166 ms
11000000 block took 165 ms
12000000 block took 166 ms
13000000 block took 165 ms
14000000 block took 166 ms
15000000 block took 172 ms
16000000 block took 165 ms
17000000 block took 167 ms
18000000 block took 165 ms
19000000 block took 167 ms
20000000 block took 169 ms
21000000 block took 168 ms
22000000 block took 167 ms
23000000 block took 166 ms
24000000 block took 167 ms
25000000 block took 167 ms
26000000 block took 165 ms
27000000 block took 166 ms
28000000 block took 166 ms
29000000 block took 165 ms
30000000 block took 165 ms
31000000 block took 165 ms
32000000 block took 166 ms
33000000 block took 165 ms
34000000 block took 167 ms
35000000 block took 170 ms
36000000 block took 165 ms
37000000 block took 166 ms
38000000 block took 166 ms
39000000 block took 164 ms
40000000 block took 165 ms
41000000 block took 167 ms
42000000 block took 166 ms
43000000 block took 167 ms
44000000 block took 169 ms
45000000 block took 166 ms
46000000 block took 165 ms
47000000 block took 166 ms
48000000 block took 166 ms
49000000 block took 166 ms
50000000 block took 166 ms
51000000 block took 166 ms
52000000 block took 164 ms
53000000 block took 165 ms
54000000 block took 167 ms
55000000 block took 165 ms
56000000 block took 166 ms
57000000 block took 166 ms
58000000 block took 165 ms
59000000 block took 166 ms
60000000 block took 169 ms
61000000 block took 165 ms
62000000 block took 165 ms
63000000 block took 166 ms
64000000 block took 166 ms
65000000 block took 165 ms
66000000 block took 166 ms
67000000 block took 176 ms
68000000 block took 166 ms
...
</code></pre><p>Well now, Zig is fast and everything is right again with the world – and
Factor takes only about 50% more time than Zig’s <code>std.HashMap</code> with
<code>rehash()</code> and about the same as <code>std.ArrayHashMap</code>, which is pretty
good for a dynamic language.</p>
<p>I submitted a <a href="https://github.com/ziglang/zig/pull/17890">pull request adding a rehash() method to
HashMap</a> and hopefully it gets into
the upcoming Zig 0.12 release and maybe for Zig 0.13 they can adjust it to
automatically rehash when it gets sufficiently fragmented, consider using
quadratic probing instead of linear probing, or perhaps switch to using a
completely different HashMap algorithm like <a href="https://engineering.fb.com/2019/04/25/developer-tools/f14/">Facebook’s F14 hash
table</a>, which
doesn’t have this issue.</p>
<p>Maybe we should consider some of these improvements for Factor as well!</p>
<p>Open source is fun!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Real-time image editing using latent consistency models (197 pts)]]></title>
            <link>https://twitter.com/krea_ai/status/1723067313392320607</link>
            <guid>38223822</guid>
            <pubDate>Fri, 10 Nov 2023 20:06:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/krea_ai/status/1723067313392320607">https://twitter.com/krea_ai/status/1723067313392320607</a>, See on <a href="https://news.ycombinator.com/item?id=38223822">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rare egg-laying mammal (echidna) rediscovered in Indonesia (179 pts)]]></title>
            <link>https://www.cbc.ca/news/science/echidna-video-1.7024966</link>
            <guid>38223660</guid>
            <pubDate>Fri, 10 Nov 2023 19:53:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/news/science/echidna-video-1.7024966">https://www.cbc.ca/news/science/echidna-video-1.7024966</a>, See on <a href="https://news.ycombinator.com/item?id=38223660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Scientists have rediscovered a long-lost species of mammal described as having the spines of a hedgehog, the snout of an anteater and the feet of a mole, in Indonesia's Cyclops Mountains more than 60 years after it was last recorded.</p><p>Attenborough's long-beaked echidna, named after British naturalist David Attenborough, was photographed for the first time by a trail camera on the last day of a four-week expedition led by Oxford University scientists.</p><p>Having descended from the mountains at the end of the trip, biologist James Kempton found the images of the small creature walking through the forest undergrowth on the last memory card retrieved from more than 80 remote cameras.</p><p>"There was a great sense of euphoria, and also relief having spent so long in the field with no reward until the very final day," he said, describing the moment he first saw the footage with collaborators from Indonesian conservation group YAPPENDA.</p><p>"I shouted out to my colleagues that were still remainin g... and said 'we found it, we found it' —&nbsp;I ran in from my desk to the living room and hugged the guys."</p><p>Echidnas share their name with a half-woman, half-serpent Greek mythological creature, and were described by the team as shy, nocturnal burrow-dwellers who are notoriously difficult to find.</p><p>"The reason it appears so unlike other mammals is because it is a member of the monotremes —&nbsp;an egg-laying group that separated from the rest of the mammal tree-of-life about 200 million years ago," Kempton said.</p><h2>Species only recorded once before</h2><p>The species has only been scientifically recorded once before, by a Dutch botanist in 1961. A different echidna species is found throughout Australia and lowland New Guinea.</p><div><ul><li><a href="https://www.cbc.ca/news/science/chevrotain-rediscovered-1.5356202" text="Rare, fanged deer-like species rediscovered after 30 years" flag="" data-contentid=""><span>Rare, fanged deer-like species rediscovered after 30 years</span></a></li></ul><ul><li><a href="https://www.cbc.ca/news/science/mammal-believed-extinct-found-in-mossy-forest-1.758476" text="Mammal believed extinct found in mossy forest" flag="" data-contentid=""><span>Mammal believed extinct found in mossy forest</span></a></li></ul></div><p>Kempton's team survived an earthquake, malaria and even a leech attached to an eyeball during their trip. They worked with the local village Yongsu Sapari to navigate and explore the remote terrain of northeastern Papua.</p><p>The echidna is embedded in the local culture, including a tradition that states conflicts are resolved by sending one party to a disagreement into the forest to search for the mammal and another to the ocean to find a marlin, according to Yongsu Sapari elders cited by the university.</p><p>Both creatures were seen as so difficult to find that it would often take decades or a generation to locate them. But&nbsp;once found, the animals symbolized the end of the conflict and a return to harmonious relationships.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Unix timestamp will begin with 17 this Tuesday (291 pts)]]></title>
            <link>https://www.unixtimestamp.com/</link>
            <guid>38222909</guid>
            <pubDate>Fri, 10 Nov 2023 18:54:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.unixtimestamp.com/">https://www.unixtimestamp.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38222909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <h2>What is the unix time stamp?</h2>
    <p>The unix time stamp is a way to track time as a running total of seconds. This count starts at the Unix Epoch on January 1st, 1970 at UTC. Therefore, the unix time stamp is merely the number of seconds between a particular date and the Unix Epoch. It should also be pointed out (thanks to the comments from visitors to this site) that this point in time technically does not change no matter where you are located on the globe.  This is very useful to computer systems for tracking and sorting dated information in dynamic and distributed applications both online and client side.</p>

<table>
<thead>
<tr>
	<th>Human Readable Time</th>
	<th>Seconds</th>
</tr>
</thead>
<tbody>
<tr>
	<td>1 Hour</td>
	<td>3600 Seconds</td>
</tr>
<tr>
	<td>1 Day</td>
	<td>86400 Seconds</td>
</tr>
<tr>
	<td>1 Week</td>
	<td>604800 Seconds</td>
</tr>
<tr>
	<td>1 Month (30.44 days)</td>
	<td>2629743 Seconds</td>
</tr>
<tr>
	<td>1 Year (365.24 days)</td>
	<td>31556926 Seconds</td>
</tr>
</tbody>
</table>

  <h2>What happens on January 19, 2038?</h2>
    <p>On this date the Unix Time Stamp will cease to work due to a 32-bit overflow. Before this moment millions of applications will need to either adopt a new convention for time stamps or be migrated to 64-bit systems which will buy the time stamp a "bit" more time. </p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git cherry-pick and revert use 3-way merge (194 pts)]]></title>
            <link>https://jvns.ca/blog/2023/11/10/how-cherry-pick-and-revert-work/</link>
            <guid>38222596</guid>
            <pubDate>Fri, 10 Nov 2023 18:30:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/11/10/how-cherry-pick-and-revert-work/">https://jvns.ca/blog/2023/11/10/how-cherry-pick-and-revert-work/</a>, See on <a href="https://news.ycombinator.com/item?id=38222596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>Hello! I was trying to explain to someone how <code>git cherry-pick</code> works the other
day, and I found myself getting confused.</p>

<p>What went wrong was: I thought that <code>git cherry-pick</code> was basically applying a
patch, but when I tried to actually do it that way, it didn’t work!</p>

<p>Let’s talk about what I thought <code>cherry-pick</code> did (applying a patch), why
that’s not quite true, and what it actually does instead (a “3-way merge”).</p>

<p>This post is extremely in the weeds and you definitely don’t need to understand
this stuff to use git effectively. But if you (like me) are curious about git’s
internals, let’s talk about it!</p>

<h3 id="cherry-pick-isn-t-applying-a-patch">cherry-pick isn’t applying a patch</h3>

<p>The way I previously understood <code>git cherry-pick COMMIT_ID</code> is:</p>

<ul>
<li>calculate the diff for <code>COMMIT_ID</code>, like <code>git show COMMIT_ID --patch &gt; out.patch</code></li>
<li>Apply the patch to the current branch, like <code>git apply out.patch</code></li>
</ul>

<p>Before we get into this – I want to be clear that this model is mostly
right, and if that’s your mental model that’s fine. But it’s wrong in some
subtle ways and I think that’s kind of interesting, so let’s see how it works.</p>

<p>If I try to do the “calculate the diff and apply the patch” thing in a case
where there’s a merge conflict, here’s what happens:</p>

<pre><code>$ git show 10e96e46 --patch &gt; out.patch
$ git apply out.patch
error: patch failed: content/post/2023-07-28-why-is-dns-still-hard-to-learn-.markdown:17
error: content/post/2023-07-28-why-is-dns-still-hard-to-learn-.markdown: patch does not apply
</code></pre>

<p>This just fails – it doesn’t give me any way to resolve the conflict or figure
out how to solve the problem.</p>

<p>This is quite different from what actually happens when run <code>git cherry-pick</code>,
which is that I get a merge conflict:</p>

<pre><code>$ git cherry-pick 10e96e46
error: could not apply 10e96e46... wip
hint: After resolving the conflicts, mark them with
hint: "git add/rm &lt;pathspec&gt;", then run
hint: "git cherry-pick --continue".
</code></pre>

<p>So it seems like the “git is applying a patch” model isn’t quite right. But the
error message literally does say “could not <strong>apply</strong> 10e96e46”, so it’s not quite
<em>wrong</em> either. What’s going on?</p>

<h3 id="so-what-is-cherry-pick-doing">so what is cherry-pick doing?</h3>

<p>I went digging through git’s source code to see how <code>cherry-pick</code> works, and
ended up at <a href="https://github.com/git/git/blob/dadef801b365989099a9929e995589e455c51fed/sequencer.c#L2353-L2358">this line of code</a>:</p>

<pre><code>res = do_recursive_merge(r, base, next, base_label, next_label, &amp;head, &amp;msgbuf, opts);
</code></pre>

<p>So a cherry-pick is a… merge? What? How? What is it even merging? And how does merging even work in the first place?</p>

<p>I realized that I didn’t really know how git’s merge worked, so I googled it
and found out that git does a thing called “3-way merge”. What’s that?</p>

<h3 id="how-git-merges-files-the-3-way-merge">how git merges files: the 3-way merge</h3>

<p>Let’s say I want to merge these 2 files. We’ll call them <code>v1.py</code> and <code>v2.py</code>.</p>

<pre><code>def greet():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
</code></pre>

<pre><code>def say_hello():
    greeting = "hello"
    name = "aanya"
    return greeting + " " + name
</code></pre>

<p>There are two lines that differ: we have</p>

<ul>
<li><code>def greet()</code> and <code>def say_hello</code></li>
<li><code>name = "aanya"</code> and <code>name = "julia"</code></li>
</ul>

<p>How do we know what to pick? It seems impossible!</p>

<p>But what if I told you that the original function was this (<code>base.py</code>)?</p>

<pre><code>def say_hello():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
</code></pre>

<p>Suddenly it seems a lot clearer! <code>v1</code> changed the function’s name to <code>greet</code>
and <code>v2</code> set <code>name = "aanya"</code>. So to merge, we should make both those changes:</p>

<pre><code>def greet():
    greeting = "hello"
    name = "aanya"
    return greeting + " " + name
</code></pre>

<p>We can ask git to do this merge with <code>git merge-file</code>, and it gives us exactly
the result we expected: it picks <code>def greet()</code> and <code>name = "aanya"</code>.</p>

<pre><code>$ git merge-file v1.py base.py v2.py -p
def greet():
    greeting = "hello"
    name = "aanya"
    return greeting + " " + name⏎
</code></pre>

<p>This way of merging where you merge 2 files + their original version is called
a <strong>3-way merge</strong>.</p>

<p>If you want to try it out yourself in a browser, I made a little playground at
<a href="https://jvns.ca/3-way-merge/">jvns.ca/3-way-merge/</a>. I made it very quickly so it’s not mobile friendly.</p>

<h3 id="git-merges-changes-not-files">git merges changes, not files</h3>

<p>The way I think about the 3-way merge is – git merges <strong>changes</strong>, not files.
We have an original file and 2 possible changes to it, and git tries to combine
both of those changes in a reasonable way. Sometimes it can’t (for example if
both changes change the same line), and then you get a merge conflict.</p>

<p>Git can also merge more than 2 possible changes: you can have an original file
and 8 possible changes, and it can try to reconcile all of them. That’s called
an octopus merge but I don’t know much more than that, I’ve never done one.</p>

<h3 id="how-git-uses-3-way-merge-to-apply-a-patch">how git uses 3-way merge to apply a patch</h3>

<p>Now let’s get a little weird! When we talk about git “applying a patch” (as you
do in a <code>rebase</code> or <code>revert</code> or <code>cherry-pick</code>), it’s not actually creating a
patch file and applying it. Instead, it’s doing a 3-way merge.</p>

<p>Here’s how applying commit <code>X</code> as a patch to your current commit corresponds to
this <code>v1</code>, <code>v2</code>, and <code>base</code> setup from before:</p>

<ol>
<li>The version of the file <strong>in your current commit</strong> is <code>v1</code>.</li>
<li>The version of the file <strong>before commit X</strong> is <code>base</code></li>
<li>The version of the file <strong>in commit X</strong>. Call that <code>v2</code></li>
<li>Run <code>git merge-file v1 base v2</code> to combine them (technically git does not
actually run <code>git merge-file</code>, it runs a C function that does it)</li>
</ol>

<p>Together, you can think of <code>base</code> and <code>v2</code> as being the “patch”: the diff between
them is the change that you want to apply to <code>v1</code>.</p>

<h3 id="how-cherry-pick-works">how cherry-pick works</h3>

<p>Let’s say we have this commit graph, and we want to cherry-pick <code>Y</code> on to <code>main</code>:</p>

<pre><code>A - B (main)
 \
  \
   X - Y - Z
</code></pre>

<p>How do we turn that into a 3-way merge? Here’s how it translates into our <code>v1</code>, <code>v2</code> and <code>base</code> from earlier:</p>

<ul>
<li><code>B</code> is v1</li>
<li><code>X</code> is the base, <code>Y</code> is v2</li>
</ul>

<p>So together <code>X</code> and <code>Y</code> are the “patch”.</p>

<p>And <code>git rebase</code> is just like <code>git cherry-pick</code>, but repeated a bunch of times.</p>

<h3 id="how-revert-works">how revert works</h3>

<p>Now let’s say we want to run <code>git revert Y</code> on this commit graph</p>

<pre><code>X - Y - Z - A - B
</code></pre>

<ul>
<li><code>B</code> is v1</li>
<li><code>Y</code> is the base, <code>X</code> is v2</li>
</ul>

<p>This is exactly like a cherry-pick, but with <code>X</code> and <code>Y</code> reversed. We have to
flip them because we want to apply a “reverse patch”.</p>

<p>Revert and cherry-pick are so closely related in git that they’re actually
implemented in the same file:
<a href="https://github.com/git/git/blob/dadef801b365989099a9929e995589e455c51fed/builtin/revert.c">revert.c</a>.</p>

<h3 id="this-3-way-patch-is-a-really-cool-trick">this “3-way patch” is a really cool trick</h3>

<p>This trick of using a 3-way merge to apply a commit as a patch seems really
clever and cool and I’m surprised that I’d never heard of it before! I don’t
know of a name for it, but I kind of want to call it a “3-way patch”.</p>

<p>The idea is that with a 3-way patch, you specify the patch as 2 files: the file
before the patch and after (<code>base</code> and <code>v2</code> in our language in this post).</p>

<p>So there are 3 files involved: 1 for the original and 2 for the patch.</p>

<p>The point is that the 3-way patch is a much better way to patch than a normal
patch, because you have a lot more context for merging when you have
both full files.</p>

<p>Here’s more or less what a normal patch for our example looks like:</p>

<pre><code>@@ -1,1 +1,1 @@:
- def greet():
+ def say_hello():
    greeting = "hello"
</code></pre>

<p>and a 3-way patch. This “3-way patch” is not a real file format, it’s just
something I made up.</p>

<pre><code>BEFORE: (the full file)
def greet():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
AFTER: (the full file)
def say_hello():
    greeting = "hello"
    name = "julia"
    return greeting + " " + name
</code></pre>

<h3 id="building-git-talks-about-this">“Building Git” talks about this</h3>

<p>The book <a href="https://shop.jcoglan.com/building-git/">Building Git</a> by James Coglan
is the only place I could find other than the git source code explaining how
<code>git cherry-pick</code> actually uses 3-way merge under the hood (I thought Pro Git might
talk about it, but it didn’t seem to as far as I could tell).</p>

<p>I actually went to buy it and it turned out that I’d already bought it in 2019
so it was a good reference to have here :)</p>

<h3 id="merging-is-actually-much-more-complicated-than-this">merging is actually much more complicated than this</h3>

<p>There’s more to merging in git than the 3-way merge – there’s something
called a “recursive merge” that I don’t understand, and there are a bunch of
details about how to deal with handling file deletions and moves, and there are
also multiple merge algorithms.</p>

<p>My best idea for where to learn more about this stuff is Building Git, though I
haven’t read the whole thing.</p>

<h3 id="so-what-does-git-apply-do">so what does <code>git apply</code> do?</h3>

<p>I also went looking through git’s source to find out what <code>git apply</code> does, and it
seems to (unsurprisingly) be in <code>apply.c</code>. That code parses a patch file, and
then hunts through the target file to figure out where to apply it. The core logic
seems to be <a href="https://github.com/git/git/blob/dadef801b365989099a9929e995589e455c51fed/apply.c#L2684">around here</a>:
I think the idea is to start at the line number that the patch suggested and
then hunt forwards and backwards from there to try to find it:</p>

<pre><code>	/*
	 * There's probably some smart way to do this, but I'll leave
	 * that to the smart and beautiful people. I'm simple and stupid.
	 */
	backwards = current;
	backwards_lno = line;
	forwards = current;
	forwards_lno = line;
	current_lno = line;
  for (i = 0; ; i++) {
     ...
</code></pre>

<p>That all seems pretty intuitive and about what I’d naively expect.</p>

<h3 id="that-s-all">that’s all!</h3>

<p>I was pretty surprised to learn that I didn’t actually understand the core way
that git applies patches internally – it was really cool to learn about!</p>

<p>I have <a href="https://jvns.ca/blog/2023/11/01/confusing-git-terminology/">lots of issues</a> with git’s UI but I think this particular thing is not
one of them. The 3-way merge seems like a nice unified way to solve a bunch of
different problems, it’s pretty intuitive for people (the idea of “applying a
patch” is one that a lot of programmers are used to thinking about, and the
fact that it’s implemented as a 3-way merge under the hood is an implementation
detail that nobody actually ever needs to think about).</p>

<p><small>
Also a very quick plug: I’m working on writing a
<a href="https://wizardzines.com/">zine</a> about git, if you’re interested in getting an email when it comes out you can
sign up to my <a href="https://wizardzines.com/zine-announcements/">very infrequent announcements mailing list</a>.
</small></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prominent S.F. developers charged with bribery in widening corruption scandal (108 pts)]]></title>
            <link>https://www.sfchronicle.com/crime/article/sf-corruption-scandal-sia-tahbazof-18334456.php</link>
            <guid>38222490</guid>
            <pubDate>Fri, 10 Nov 2023 18:22:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfchronicle.com/crime/article/sf-corruption-scandal-sia-tahbazof-18334456.php">https://www.sfchronicle.com/crime/article/sf-corruption-scandal-sia-tahbazof-18334456.php</a>, See on <a href="https://news.ycombinator.com/item?id=38222490">Hacker News</a></p>
Couldn't get https://www.sfchronicle.com/crime/article/sf-corruption-scandal-sia-tahbazof-18334456.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Google Cloud TPU Multislice Training (103 pts)]]></title>
            <link>https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e</link>
            <guid>38222277</guid>
            <pubDate>Fri, 10 Nov 2023 18:08:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e">https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e</a>, See on <a href="https://news.ycombinator.com/item?id=38222277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h5>Rajesh Anantharaman</h5><p>Product Management Lead, Cloud TPU</p></div><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>With the boom in generative AI, the size of foundational large language models (LLMs) has grown exponentially, utilizing hundreds of billions of parameters and trillions of training tokens.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Screenshot_2023-11-07_at_10.21.41_PM.max-1200x1200.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/Screenshot_2023-11-07_at_10.21.41_PM.max-1200x1200.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Training these kinds of large LLMs require tens of exa-FLOPs (10^18 FLOPs) of AI supercomputing power, which is typically distributed across large clusters that contain tens of thousands of AI accelerator chips. But utilizing large-scale clusters for distributed machine learning (ML) training presents many common and key technical challenges.</p><ol><li><b>Orchestration:</b> The software stack that is used for distributed training needs to manage all of these chips and scale as high as possible to accelerate training times. This stack also needs to be reliable, fault tolerant, and resilient in order to ensure training progress.</li><li><b>Compilation</b>: As training progresses, the computation and communication that happen across the chips need to be managed effectively by a high-performance compiler.</li><li><b>End-to-end optimization</b>: Distributed training at large scale requires deep expertise throughout both the ML training stack and the end-to-end ML training workflow, from storage and compute to memory and networking.</li></ol><h3>Google Cloud TPU Multislice Training</h3><p>To address each of the above distributed training challenges across orchestration, compilation, and end-to-end optimization, today we announced the general availability of Cloud TPU Multislice Training. This full-stack training offering — supporting TPU v4 and v5e — is built from the ground up to be scalable, reliable, and easy-to-use for end-to-end optimization of ML training. With Multislice, you can leverage Google’s cost-efficient, versatile, and scalable Cloud TPUs for training ML models efficiently and at large scale.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/The_largest_LLM_distributed_training_job_i.max-2200x2200.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/The_largest_LLM_distributed_training_job_i.max-2200x2200.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Cloud TPU Multislice Training has the following key features:</p><ol><li><b>Robust orchestration and scalability:</b> Scale large model training across tens of thousands of TPU chips in a reliable and fault-tolerant way across the training workflow.</li><li><b>Performant compilation:</b>Maximize performance and efficiency using the XLA compiler to automatically manage compute and communication.</li><li><b>Flexible stack for end-to-end training:</b> Provide first-class support for popular ML frameworks such as JAX and PyTorch, easy-to-use reference implementations and libraries, and support for a wide range of model architectures including LLMs, diffusion models and DLRM.</li></ol><p>Here we highlight some of the key components in the overall Multislice Training stack, many of which we have open-sourced in order to continue contributing to the broader AI/ML community:</p><ol><li><a href="https://github.com/google/xpk" target="_blank">Accelerated Processing Kit (XPK)</a> is an ML cluster and job orchestration tool built to be used with Google Kubernetes Engine (GKE) to standardize the best practices for orchestrating ML jobs. XPK focuses on ML semantics for creating, managing, and running ML training jobs to make it easier for machine learning engineers (MLE) to use, manage, and debug. XPK decouples provisioning capacity from running jobs through separate APIs.</li><li><a href="https://github.com/google/maxtext" target="_blank">MaxText</a> is a performant, scalable, and adaptable JAX LLM implementation. This implementation is built on top of open-source JAX libraries such as <a href="https://github.com/google/flax" target="_blank">Flax</a>, <a href="https://github.com/google/orbax" target="_blank">Orbax</a>, and <a href="https://github.com/google-deepmind/optax" target="_blank">Optax</a>. MaxText is a decoder-only LLM implementation written in pure Python, making it much easier for MLEs to understand, adapt, and modify. MaxText also leverages the XLA compiler heavily, making it easy for MLEs to achieve high performance without needing to build custom kernels. XLA through <a href="https://github.com/openxla/xla" target="_blank">OpenXLA</a> is an open-source ML compiler for a variety of hardware accelerators, such as TPUs, GPUs, CPUs, and others.</li><li><a href="https://github.com/google/aqt" target="_blank">Accurate Quantized Training (AQT)</a> is a Google-built training library that uses reduced numerical precision of 8-bit integers (INT8) instead of 16-bit floats (BF16) for training. AQT takes advantage of the fact that ML accelerators have 2X the compute speed when using INT8 operations versus BF16 operations. Using AQT’s simple and flexible API, MLEs can attain both higher performance during training and also higher model quality in production.</li></ol><p><b>Google Cloud TPU ran the world’s largest distributed training job for LLMs across 50,000+ TPU v5e chips</b></p><p>We used Multislice Training to run what we believe to be the world’s largest publicly disclosed LLM distributed training job (in terms of the number of chips used for training) on a compute cluster of 50,944 Cloud TPU v5e chips (spanning 199 Cloud TPU v5e pods) that is capable of achieving 10 exa-FLOPs (16-bit), or 20 exa-OPs (8-bit), of total peak performance. To give a sense of scale, this cluster of Cloud TPU v5e chips has more AI accelerators than the <a href="https://www.ornl.gov/news/frontier-supercomputer-debuts-worlds-fastest-breaking-exascale-barrier" target="_blank">TOP1 Supercomputer Frontier at Oak Ridge National Laboratory</a>, which featured <a href="https://en.wikipedia.org/wiki/Frontier_(supercomputer)" target="_blank">37,888 AMD M1250X GPUs</a></p><h3>Setting up the LLM distributed training job on Cloud TPU v5e</h3><p>We performed our large-scale LLM distributed training job using Cloud TPU Multislice Training on <a href="https://cloud.google.com/blog/products/compute/announcing-cloud-tpu-v5e-and-a3-gpus-in-ga">Cloud TPU v5e</a>. A Cloud TPU v5e pod consists of 256 chips connected via high-speed inter-chip interconnect (ICI). These pods are connected and communicate using Google’s <a href="https://cloud.google.com/blog/topics/systems/the-evolution-of-googles-jupiter-data-center-network">Jupiter data center networking</a> (DCN). We set up this distributed training job on the JAX framework, utilizing XPK, GKE, MaxText, AQT, and other components of the JAX training stack. The rest of this blog focuses on the JAX training stack portion of Cloud TPU Multislice Training.</p><p>We trained multiple MaxText models in various sizes of 16B, 32B, 64B, and 128B parameters. For each model, we scaled the training using data parallelism (DP) across pods over DCN, where each pod stores its own replica of the model. Then, each replica of the model is sharded across chips within a pod over ICI using fully sharded data parallelism (FSDP) for the 16B, 32B, and 64B configurations, and a mix of FSDP and tensor parallelism (TP) for the 128B configuration.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/3_R3KR09l.max-1200x1200.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/3_R3KR09l.max-1200x1200.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>We managed TPU capacity with <a href="https://cloud.google.com/kubernetes-engine">Google Kubernetes Engine (GKE)</a> and utilized XPK on top of GKE to orchestrate ML jobs. XPK handles creating clusters, resizes them as necessary, submits jobs into the GKE <a href="https://github.com/kubernetes-sigs/kueue" target="_blank">Kueue</a> system as <a href="https://github.com/kubernetes-sigs/jobset" target="_blank">JobSets</a>, manages those Jobsets, and provides visibility into the state of the cluster.</p><p>To accelerate model training, we used the <a href="https://docs.google.com/document/d/1TyEdSSXlNcjgLuqd0w_bICFINMM-poYxzpkzqa2YB6o/edit?resourcekey=0-3n8xkMT1abcN3WcgoLARYQ" target="_blank">Accurate Quantized Training (AQT)</a> library to train in quantized INT8. As of October 2023, this approach enables a <a href="https://docs.google.com/document/d/1TyEdSSXlNcjgLuqd0w_bICFINMM-poYxzpkzqa2YB6o/edit?resourcekey=0-3n8xkMT1abcN3WcgoLARYQ" target="_blank">1.2X to 1.4X acceleration</a> in steps per second while producing a convergence gap smaller than that normally associated with quantizing a model trained in BF16 to INT8.</p><h3>How we scaled the largest distributed LLM training job</h3><p>As we scaled our TPU compute cluster, we began to push the limits of the stack.</p><p><b>Orchestration<br></b>Managing over 50,000 accelerator chips working on a single training job requires a well-designed orchestration solution that enables both different users to submit smaller jobs for experiments as well as supporting a full-scale job that runs on the entire cluster. This functionality is provided through GKE’s <a href="https://github.com/kubernetes-sigs/jobset" target="_blank">Jobset</a> and <a href="https://kueue.sigs.k8s.io/" target="_blank">Kueue</a> features. As we pushed the limits on the number of VMs that GKE could handle, we optimized managing internal IP addresses, precaching docker images, designed clusters for scale, and enabled high-throughput scheduling. We also optimized GKE to push VM scaling limits in areas such as pod IP exhaustion, Domain Name Service (DNS) scalability, and control-plane node limits. We packaged and <a href="https://github.com/google/xpk/blob/main/xpk-large-scale-guide.sh" target="_blank">documented these solutions</a> alongside <a href="https://github.com/google/maxtext/tree/main/xpk" target="_blank">XPK</a> to make this a repeatable process for customers training at this massive scale.</p><p><b>Performance<br></b>JAX is powered by XLA (Accelerated Linear Algebra), a compiler-based linear algebra execution engine that optimizes workloads for ML accelerators like TPUs and GPUs to deliver supercomputer-like performance. The key parallelism technique behind XLA is SPMD (single program, multiple data) where the same computation is run in parallel on different devices. XLA leverages <a href="https://arxiv.org/abs/2105.04663" target="_blank">GSPMD</a> which simplifies SPMD programming by allowing the user to program a single giant supercomputer and then automatically parallelizing the computation across devices based on a few user annotations. Running at large scale exposed the need for optimizations that only become necessary with a large number of slices. For example, each worker VM needs to communicate over DCN with the worker VMs of the same rank in other slices. Originally, this caused slowdowns due to excess device-to-host and host-to-device transfers that scaled linearly with the number of slices. By optimizing the XLA runtime, we were able to prevent these transfers from being the bottleneck.</p><p><b>Storage<br></b>Interacting with persistent storage is a crucial aspect of training. Our 199-pod cluster had 1 Tb/s to Google Cloud Storage (GCS), 1,270 Tb/s inter-slice DCN, and 73,400 Tb/s intra-slice ICI. When loading docker images, loading data, and reading/writing checkpoints, we optimized the interaction with persistent storage.</p><p>We found that at large scale, data loading from GCS began to affect performance, starting at 64 pods scale. We have since mitigated this limit with a <a href="https://github.com/google/maxtext/pull/187" target="_blank">distributed data loading strategy that alleviates pressure on GCS by having a subset of hosts load data.</a></p><p>We also found limits due to checkpointing. By default, checkpointing loads the full checkpoint into each data parallel replica from GCS. Consider checkpoint loading for a 128B model sharded with cross-pod data parallelism. For a traditional optimizer state of three numbers per parameter (4bytes/number), this means loading a checkpoint of size ~1.536 TB separately into each pod (in this case for 199 pods). This would require 199 pods * 1.536TB/pod, or approximately 300TB of bandwidth. For reasonable performance from persistent storage of 1 Tb/s, this would require approximately 2,400 seconds (40 minutes). However, we needed much lower start or restart time, so had to take a different approach.</p><p>To alleviate the problem, we added features that enabled a <a href="https://github.com/google/maxtext/pull/187" target="_blank">single pod to load the checkpoint and broadcast it</a> to the other replicas. As a result, a single pod can read the checkpoint and then broadcast the optimizer state to the other pods by leveraging the flexibility of JAX. In principle, this should take 1.536TB/1Tb/s = ~12 seconds to load the checkpoint and then (2*1.536TB/pod) / (64 VM/per pod * 100 Gb/s/VM) = ~4 seconds to gather the optimizer state across the cluster, for a total of 16 seconds and a 150x speedup. Similarly, optimizations are needed when writing checkpoint data and loading training data. At write-time, a single leader replica can then write the entire checkpoint to avoid excessive QPS to GCS.</p><h3>How did we measure training performance?</h3><p>Training performance is measured in terms of Model FLOPs Utilization (MFU) and Effective Model FLOPs Utilization (EMFU). For an N-parameter decoder-only model, each token seen requires 6N matmul FLOPs for the learnable weights and 12LHQT matmul FLOPs for attention where L, H, Q, and T are the number of layers, the number of heads, the head dimension, and the sequence length respectively (see Appendix B of the <a href="https://arxiv.org/pdf/2204.02311.pdf" target="_blank">PaLM paper</a> for more details). Knowing the TFLOPs required for each token, we can represent the throughput of a step as observed TFLOP/chip/s which is computed as the total TFLOPs required for all tokens seen in the step for each chip divided by the step time.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/4_4nUjPCf.max-700x700.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/4_4nUjPCf.max-700x700.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>We can then compute MFU by dividing the observed TFLOP/chip/s by the peak TFLOP/chip/s of the hardware (197 TFLOP/chip/s for TPU v5e).</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/5_ioizemy.max-700x700.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/5_ioizemy.max-700x700.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>EMFU broadens observed TFLOP/chip/s to observed TOP/chip/s (tera-operations/chip/s), which encapsulates both quantized operations and floating point operations. However, since the observed TOP/chip/s for quantized operations can be larger than the peak TFLOP/chip/s for floating point operations, it is possible to achieve greater than 100% EMFU.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/6_WVraLLx.max-700x700.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/6_WVraLLx.max-700x700.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3>Largest LLM distributed training job scalability results</h3><p>For each model size (16B, 32B, 64B, 128B), we ran a sweep of training jobs, scaling the number of TPU v5e pods from 1 to 160. We saw as high as 66.86% MFU with BF16 training on a single TPU v5e pod and strong scaling outcomes when expanding to 160 pods. We also ran jobs exercising the entire 199-pod cluster with both BF16 training and INT8 quantized training (using AQT), achieving an impressive observed 5.32 exa-OP/s with INT8 quantized training. This scaling study was done with limited software optimizations across the Multislice Training JAX stack, and we will continue improving our software stack.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/7_F1Qex4l.max-1900x1900.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/7_F1Qex4l.max-1900x1900.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3>Future work</h3><h2>Job start-up time</h2><p>Along with measuring training performance, we also measured the start-up time of our ML jobs on the cluster, which scaled near-linearly with the number of chips.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/8_UMWQU21.max-2000x2000.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/8_UMWQU21.max-2000x2000.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>The start times we observed were impressive, but we believe we can improve these even further. We are working on areas such as optimizing scheduling in GKE to increase throughput and enabling ahead-of-time compilation in MaxText to avoid just-in-time compilations on the full cluster.</p><h2>Scaling efficiency</h2><p>We achieved excellent scaling across 50,944 TPU v5e chips, but we believe we can improve this even further. We’ve identified and are currently working on changes in the compiler and MaxText to improve stability and performance at large scale. We are considering scalable solutions such as hierarchical DCN collectives and further optimizing compiler scheduling in multipod regimes.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Bn5EmqU.max-1600x1600.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Bn5EmqU.max-1600x1600.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Google Internal data for TPU v5e As of November, 2023: All numbers normalized per chip. seq-len=2048 for 32 billion parameter decoder only language model implemented using MaxText. *2</p></span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3>Conclusion</h3><p>Google Cloud TPU Multislice Training was built from the ground up to address the challenges of distributed ML training in orchestration, compilation, and end-to-end optimization. We demonstrated the benefits of Cloud TPU Multislice Training with what we believe is the largest publicly disclosed LLM distributed training job in the world (in terms of number of chips used for training) on a compute cluster of 50,944 Cloud TPU v5e chips on the JAX ML framework, utilizing both BF16 and INT8 quantized training.</p><p>As generative AI continues to trend towards bigger and bigger LLMs, we will continue to push the boundaries of innovation needed to further scale and improve our software stack. We have open-sourced all the code used in this project. Please check out our open-source repositories for <a href="https://github.com/google/maxtext" target="_blank">MaxText</a>, <a href="https://github.com/google/maxtext/tree/main/xpk" target="_blank">XPK</a>, <a href="https://github.com/google/aqt" target="_blank">AQT</a> and <a href="https://github.com/openxla/xla" target="_blank">XLA</a>. To learn more about Google Cloud TPU Multislice Training and how to use it with Cloud TPUs to accelerate your generative AI projects, please contact your <a href="https://cloud.google.com/contact">Google Cloud account representative</a>.</p><hr><p><i><sup>This work constituted a massive effort across Google Cloud as well as multiple teams within Google. Special thanks to Raymond Zou, Rafi Witten, Lukasz Lew, Victor Barr and Andi Gavrilescu for their immense contributions to developing all of the components that made this project a success.</sup></i></p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/compute" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/compute" track-metadata-module="tag list" track-metadata-module_headline="posted in">Compute</a></li><li><a href="https://cloud.google.com/blog/products/ai-machine-learning" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/ai-machine-learning" track-metadata-module="tag list" track-metadata-module_headline="posted in">AI &amp; Machine Learning</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Protégé: A free, open-source ontology editor for building intelligent systems (118 pts)]]></title>
            <link>https://protege.stanford.edu/</link>
            <guid>38221709</guid>
            <pubDate>Fri, 10 Nov 2023 17:29:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://protege.stanford.edu/">https://protege.stanford.edu/</a>, See on <a href="https://news.ycombinator.com/item?id=38221709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <h2>Why Protégé</h2>
      <h2>
        Protégé’s plug-in architecture can be adapted to build 
        both simple and complex ontology-based applications. 
        Developers can integrate the output of Protégé with rule 
        systems or other problem solvers to construct a wide range 
        of intelligent systems.  Most important, the Stanford team 
        and the vast Protégé community are here to help.
      </h2>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Build AI Products the Way Everyone Else Is Doing It (435 pts)]]></title>
            <link>https://www.builder.io/blog/build-ai</link>
            <guid>38221552</guid>
            <pubDate>Fri, 10 Nov 2023 17:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.builder.io/blog/build-ai">https://www.builder.io/blog/build-ai</a>, See on <a href="https://news.ycombinator.com/item?id=38221552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div builder-type="blocks" data-builder-component="blog-article" data-builder-content-id="525874563ff643cab87e1e24b64b631b" builder-content-id="525874563ff643cab87e1e24b64b631b" builder-model="blog-article" data-name="blog-article" data-source="Rendered by Builder.io"><p><span><p>If you want to build AI products that are unique, valuable, and fast, don't do what everybody else is doing. I'll show you what to do instead.</p></span></p><p builder-id="builder-981e3200fea5451e914944395327b5ae"><a href="#what-not-to-do" id="what-not-to-do"><span><h3>What not to do</h3></span></a></p><p><span><p>The vast majority of AI products being built right now are just wrappers over other models, such as those that essentially involve calling ChatGPT over an API.</p></span></p><div builder-id="builder-ee917abbd620463f8d65a32f297d7beb"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram of code that simply hits OpenAI and does nothing else" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fe58e86c4b119488c97f4fa1247db35d2?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>While that's incredibly easy — you send natural language in and get natural language out — and it can do some really cool things, there are some major problems with this approach that people are running into.</p><p>But, there's a solution for them that I'll show you.</p></span></p><p builder-id="builder-d6ed2738276a4f76b7633d2b18710a42"><a href="#issue-1-lack-of-differentiation" id="issue-1-lack-of-differentiation"><span><h3>Issue #1: lack of differentiation</h3></span></a></p><p><span><p>The first major issue is this is not differentiated technology.</p><p>If you've noticed that one person creates a chat with a PDF app, and then another dozen people do too, and then OpenAI builds that into ChatGPT directly, it's because nobody there actually built something differentiated.</p><p>They use a simple technique, with a pre-trained model, which anyone can copy in a very short period of time.</p><p>When building a product whose unique value proposition is some type of advanced AI technology, it's a very risky position to be so easy to copy.</p><p>Now, of course, there's a whole spectrum here.</p></span></p><div builder-id="builder-0863de009fc34a1286aaed4e81a28324"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?format=webp&amp;width=503 503w" type="image/webp"><img alt="Sliding scale with &quot;chatgpt did all the work&quot; on the right and &quot;chatgpt did a bit of work&quot; on the left" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fedcaf8d3b0764e11b8f47ef05f43e4d4?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>If you're on the right side of the spectrum, where all you made was a button that sends something to ChatGPT and gets a response back that you showed your end users — where ChatGPT basically did all the work —you're at the highest risk here.</p><p>On the other end, if you actually built some substantial technology and LLMs where OpenAI has only assisted with a small but crucial piece, then you may be in a better position, but you're still going to run into two other major issues.</p></span></p><p builder-id="builder-06838a9809ca4e5da934bb9e4af517a8"><a href="#issue-2-ll-ms-are-very-expensive" id="issue-2-ll-ms-are-very-expensive"><span><h3>Issue #2: LLMs are very expensive</h3></span></a></p><p><span><p>The first major issue you'll run into is cost. The best part of a large language model is their broad versatility, but they achieve this by being exceptionally large and complex, which makes them incredibly costly to run.</p><p>As an example, per the Wall Street Journal, recently GitHub Copilot was <a href="https://www.wsj.com/tech/ai/ais-costly-buildup-could-make-early-products-a-hard-sell-bdd29b9f" rel="noopener noreferrer" target="_blank">losing money per user</a>, charging $10, but on average cost $20, and some users cost GitHub up to $80 <span><span><em>per month</em></span></span>.</p><p>And the worst part is you probably don't need such a large model. Your use case probably doesn't need a model trained on the entirety of the Internet because 99.9% of that training covers topics that have nothing to do with your use case.</p><p>So, while the ease of this approach might be tempting, you could run into this common issue where what your users want to pay is less than what it costs to run your service on top of large language models.</p></span></p><p builder-id="builder-51387a2017d64e1ba34cee8b2d0577fd"><a href="#issue-3-ll-ms-are-painfully-slow" id="issue-3-ll-ms-are-painfully-slow"><span><h3>Issue #3: LLMs are painfully slow</h3></span></a></p><p><span><p>Even if you're the rare case where the cost economics might work out okay for you, you're still going to hit one more major issue: LLMs are painfully slow.</p><p>Now, this isn't a huge problem for all applications. For use cases such as ChatGPT, where reading one word at a time is the norm, this might be okay.</p></span></p><p><span><p><span>However, in applications where text isn't meant to be read word-for-word, and the entire response is expected before proceeding to the next step in the workflow, this can pose a significant issue.</span><br></p><p>As an example, when we started working on Builder's <a href="https://www.builder.io/blog/figma-to-code-visual-copilot" rel="noopener noreferrer" target="_blank">Visual Copilot</a>, where we wanted one button click to turn any design into high-quality code, one of the approaches we explored was using an LLM for the conversion.</p></span></p><p><span><p><span>One of the key issues we encountered was the significant time delay. When passing an entire design specification into an LLM and receiving a new representation token by token, generating a response would take several minutes, making it impractical.</span><br></p><p>And because the representation returned by the LLM is not what a human would perceive, the loading state was just a spinner — not ideal.</p></span></p><p builder-id="builder-8b2942d781514858b7c538ba5b6fa773"><a href="#issue-4-ll-ms-cannot-be-customized-strong-that-strong-much" id="issue-4-ll-ms-cannot-be-customized-strong-that-strong-much"><span><h3>Issue #4: LLMs cannot be customized <strong>that</strong> much</h3></span></a></p><p><span><p>If for some reason, performance still isn't an issue for you, and your users don't care about having a slow and expensive product that's easy for your competitors to copy, you're still likely to run into another major issue — LLMs can't be customized that much.</p><p>Yes, they all support fine-tuning, and fine-tuning can incrementally help the model get closer to what you need. But in our case, we tried using fine-tuning to provide Figma designs and get code out the other side.</p><p>But no matter how many examples we gave the model, it didn't improve. We were left with something slow, expensive, and inferior quality. And that's when we realized we had to take a different approach.</p></span></p><p builder-id="builder-88d0ae6c15e04a0280eafb3a98df99e3"><a href="#the-solution-create-your-own-toolchain" id="the-solution-create-your-own-toolchain"><span><h2>The solution: create your own toolchain</h2></span></a></p><p><span><p>What did we have to do instead? We had to create our own toolchain.</p></span></p><div builder-id="builder-7fb58077a7a74b12964f2b8986b186f0"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram showing our toolchain that involves a custom built AI, a fine-tuned LLM, and our Mitosis compiler" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Ffb84cccff2b74231b3b083909d211e7f?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>In this case, we combined a fine-tuned LLM, a <a href="https://github.com/builderio/mitosis" rel="noopener noreferrer" target="_blank">custom compiler</a> that we wrote, and a custom-trained model.</p><p>And it wasn't as hard as it might seem.These days, you don't have to be a data scientist or a Ph.D. in machine learning to train your own model.</p><p>Any moderately experienced developer can do it. This way, you can build something that is way faster, way more reliable, far cheaper, and far more differentiated. You won't have to worry about copycat products or open-source clones spawning overnight, either.</p><p>And this isn't just a theory. Most, if not all, advanced AI products are built like this.</p></span></p><p builder-id="builder-c13376088c4243629cdcfefa9386b37f"><a href="#a-common-misconception-about-ai-products" id="a-common-misconception-about-ai-products"><span><h3>A common misconception about AI products</h3></span></a></p><p><span><p>A lot of people have a major misconception about how AI products are built. I've noticed that they often think that all the core tech is handled by one super smart model,  trained with tons of inputs to give exactly the right output.</p></span></p><div builder-id="builder-0c51c5144a11487fb9a0bd52f209565c"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram with one big model that has just a single stream of inputs and outputs" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F170a6c5a267345aeb66ad39cfed34bbf?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>Take self-driving cars, for example. A lot of people have the impression that there's a giant model that takes in all these different inputs like cameras, sensors, GPS, and so on, and that it crunches it through the AI, and then out comes the action on the other side, such as a right turn.</p></span></p><div builder-id="builder-0653ffed833647328a5744a9758b8086"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram showing &quot;Autonomous Vehicle Model&quot; with several inputs and one output &quot;turn right&quot;" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa9eed12b226b4bc7aa087b6e9aff1e69?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>But this could not be farther from the truth.That car driving itself is not one big AI brain.</p><p>Instead of a whole toolchain of specialized models, all connected with normal code — such as models for computer vision to find and identify objects, predictive decision-making, anticipating the actions of others, or natural language processing for understanding voice commands — all of these specialized models are combined with tons of just normal code and logic that creates the end result — a car that can drive itself.</p></span></p><div builder-id="builder-db06450b64ef405ab655af9f87ccc976"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?format=webp&amp;width=503 503w" type="image/webp"><img alt="Diagram showing normal code connecting everal different types of models" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2Fa347b9402ff1486aade3a1a7fa579773?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p><span><p>Now, keep in mind, autonomous vehicles is a highly complex example that includes many more models than I've mentioned here.</p><p>For building your own product, you won't need something nearly this complex, especially when starting out.</p><p>Remember, self-driving cars didn't spawn overnight. My 2018 Prius is capable of parking itself, stopping automatically when too close to an object, and many other things using little to no AI.</p><p>Over time, more and more layers were added to cars to do more and more advanced things, like correcting lane departure, or eventually making entire decisions to drive from one place to another.</p><p>But like all software, these things are built in layers, one on top of the next.</p></span></p><p builder-id="builder-917d1c0b6c18458197f7f9cf234d9f5b"><a href="#where-to-start-building-real-ai" id="where-to-start-building-real-ai"><span><h3>Where to start building real AI</h3></span></a></p><p><span><p>I highly recommend you explore the approach we used for Visual Copilot for your own AI solutions. It's a straightforward but counterintuitive approach.</p><p>The most important thing is to not use AI at first.</p><p>Explore the problem space using normal programming practices to determine what areas need a specialized model in the first place.</p><p>Remember, making “supermodels” is generally not the right approach. We don't want to send tons of Figma data into a model and get finished code out the other side.</p><p>That would be an outrageously complex problem to solve with just one model. And when you factor in all the different frameworks we support, and styling options and customizations, it would be unfeasible to retrain this model with all this additional data.</p></span></p><p><span><p><span>It likely would have become so complex, slow, and expensive that our product might never have even shipped.</span><br></p><p>Instead, we considered the problem and said, well, how can we solve this without AI? How far can we get before it gets impossible without the types of specialized decision-making AI is best at?</p><p>So we broke the problem down and said, okay, we need to convert each of these nodes to things we can represent in code.</p><p>We needed to understand, in detail, working with elements such as images, backgrounds, and foregrounds. And most importantly, we needed to intricately understand how to make any input responsive.</p><p>After that, we started considering more complex examples and realized there are lots of cases where many, many layers would need to be turned into one image.</p></span></p><p builder-id="builder-10e3c9ac5da441f780cefc684e17f111"><a href="#hand-code-the-logic-first" id="hand-code-the-logic-first"><span><h3>Hand-code the logic first</h3></span></a></p><p><span><p>We started writing hand-coded logic to say if a set of items is in a vertical stack that should probably be a flex column, and items that are side by side should probably be a flex row.</p><p>We got as far as we could creating all these different types of sophisticated algorithms to automatically transform designs to responsive code before we started hitting limits.</p><p>In my experience, wherever you think the limit is, it's probably a lot further. But, at a certain point, you'll find some things are just near impossible to do with standard code.</p><p>For example, automatically detecting which layers should turn into one image, is something that human perception is really good at understanding, but this isn't necessarily normal imperative code. In our case, we wrote all this in JavaScript.</p></span></p><p builder-id="builder-b2d4b78316a844f1af12d8b6165daf71"><a href="#add-specialized-ai-to-fill-in-the-gaps" id="add-specialized-ai-to-fill-in-the-gaps"><span><h3>Add specialized AI to fill in the gaps</h3></span></a></p><p><span><p>Lucky for us, training your own object detection model to solve this need with AI is not that hard. For example, products like Google's Vertex AI has a range of common types of models that you can efficiently train yourself — one of which is object detection.</p><p>I can choose that with a GUI and then prepare data and just upload it as a file.</p></span></p><p><span><p><span>For a well-established type of model like this, all it comes down to is creating the data.</span><br></p><p>Now, where things get interesting is finding creative ways of generating the data you need.</p><p>One awesome, massive free resource for generating data is simply the Internet.</p><p>One way we explored approaching this was using puppeteer to automate opening websites in a web browser, taking a screenshot of the site, and  traversing the HTML to find the <code>img</code> tags.</p><p>We then used the location of the images as the output data and the screenshot of the webpage as the input data. And now we have exactly what we need — a source image and coordinates of where all the sub-images are to train this AI model.</p></span></p><div builder-id="builder-ccea16bced6347a0921eda0f9bfe2b27"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?format=webp&amp;width=503 503w" type="image/webp"><img alt="Builder.io website screenshot with drawings overlaying where each of the images are" loading="lazy" src="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=705" srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=705 705w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=548 548w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F683efd47fdd14c718626672964d94c8b?width=503 503w" sizes="(max-width: 638px) 86vw,  (max-width: 998px) 51vw, 51vw"></picture></div><p builder-id="builder-dbe51ff78bbb4f7684e5f7b6df0c2ddf"><a href="#combine-code-ai-models-for-a-finished-complete-solution" id="combine-code-ai-models-for-a-finished-complete-solution"><span><h3>Combine code + AI models for a finished complete solution</h3></span></a></p><p><span><p>Using these techniques where we fill in the unknowns with specialized AI models and combine them is how we're able to produce end results like this: I can just select my design, click <strong>Generate code</strong>, wait only about one second, and launch into Builder.io.</p><p>Then in Builder, we get a completely responsive website with high-quality code that you can customize completely. It supports a wide variety of frameworks and options, and it's all super fast because all of our models are specially built just for this purpose.</p><p>We offer this at an exceptionally low cost, providing a generous free tier, and it's tremendously valuable for our customers, helping them save lots of time.</p></span></p><p builder-id="builder-33a15ef7844947beb9ad328cce482100"><a href="#the-benefits-of-controlling-your-own-models" id="the-benefits-of-controlling-your-own-models"><span><h2>The benefits of controlling your own models</h2></span></a></p><p><span><p>The best part is that this is only the beginning.</p></span></p><p builder-id="builder-ffbd66a65c9c41e2ae54ea36a3e766b1"><a href="#benefit-1-you-control-your-own-destiny" id="benefit-1-you-control-your-own-destiny"><span><h3>Benefit #1: you control your own destiny</h3></span></a></p><p><span><p>One of the best parts of this approach is that we completely own the models so we can constantly improve them. We aren't just wrapping somebody else's model.</p><p>If you're fully dependent only on someone else's model, like OpenAI, there's no guarantee it's going to get smarter, faster, or cheaper for your use case in any guaranteed timeline. And your ability to control that with prompt engineering and fine-tuning is severely limited.</p><p>But since we own our own model, we're making significant improvements every day.</p><p>When new designs come in that don't import well — which still happens as it's in beta — we rely on user feedback to improve at a rapid cadence, shipping improvements every single day.</p></span></p><p builder-id="builder-cbae2fe07d9b4985942d8bcbba828ffe"><a href="#benefit-2-you-control-privacy" id="benefit-2-you-control-privacy"><span><h3>Benefit #2: you control privacy</h3></span></a></p><p><span><p>With this approach, we never have to worry about a lack of control. For instance, when we started talking to some large and privacy-focused companies as potential early beta customers, one of the most common pieces of feedback was that they were not able to use OpenAI or any products using OpenAI.</p><p>Their privacy requirements prioritize making sure their data never goes into systems that they don't allow.</p><p>In our case, because we control the entire technology, we can hold our models to an extremely high privacy bar. Thank goodness, because we would’ve lost out on some serious business had we been dependent on other companies (like many others are).</p><p>And for the LLM step, we can either turn it off (because it's purely nice to have) or companies can plug in their own LLM. Those LLMs might be an entirely in-house built model, a fork of <code>llama2</code>, their own enterprise instance of OpenAI, or something else entirely.</p></span></p><p builder-id="builder-6ac7cf62e70d4d348c50a07599a499d9"><a href="#conclusion" id="conclusion"><span><h3>Conclusion</h3></span></a></p><p><span><p>So, if you want to build AI products, I highly recommend taking a similar approach as Builder.</p><p>As strange as it sounds, avoid using AI for as long as possible in your project. Then, when you start finding particular problems that standard coding doesn't solve well — but well-established AI models can — start generating your own data and training your own models with a wide variety of tools you can find off-the-shelf.</p><p>Connect your model(s) to your code only where they're needed.</p><p>And I want to emphasize this: use AI for as <em>little</em> as possible. At the end of the day, “normal” code is the fastest, most reliable, most deterministic, most easy to debug, easy to fix, easy to manage, and easy to test code you will ever have.</p><p>But the magic will come from the small but critical areas you use AI models for.</p><p>Can’t wait to see the awesome things you build.</p></span></p><div data-name="symbol" data-source="Rendered by Builder.io" data-model="symbol" builder-id="builder-cd61df2407824553be2497e03d87073a" builder-type="blocks" data-builder-component="symbol" data-builder-content-id="02714711c4b647959d015e34679ca6ee" builder-content-id="02714711c4b647959d015e34679ca6ee" builder-model="symbol"><template data-template-variant-id="6d0b491a00e64dce9781e3c0a9839b71"><div class="builder-content" builder-content-id="6d0b491a00e64dce9781e3c0a9839b71" builder-model="symbol"><div data-builder-component="symbol" data-builder-content-id="de784470c6884829b5e7c7603f4c51ed"><div class="builder-blocks css-h47494" builder-type="blocks"><style data-emotion-css="kf99zz">.css-kf99zz.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-left:-130px;margin-right:-260px;margin-top:10px;z-index:11px;}@media only screen and (max-width:991px){.css-kf99zz.builder-block{margin-left:0;margin-right:0;}}</style><div class="builder-block builder-7c77e4f236f848b48c79a96f49072518 css-kf99zz" builder-id="builder-7c77e4f236f848b48c79a96f49072518"><style data-emotion-css="jgc6i5">.css-jgc6i5.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:50px;width:100%;min-height:20px;min-width:20px;overflow:hidden;mix-blend-mode:multiply;margin-left:auto;margin-right:auto;max-width:405px;}@media only screen and (max-width:991px){.css-jgc6i5.builder-block{margin-top:10px;}}</style><div class="builder-block builder-661f4bd90a3547fa85f50126d1418c87 dark-mode-invert css-jgc6i5" builder-id="builder-661f4bd90a3547fa85f50126d1418c87"><picture><source srcset="https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=100 100w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=200 200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=400 400w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=800 800w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=1200 1200w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=1600 1600w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=2000 2000w, https://cdn.builder.io/api/v1/image/assets%2FYJIGb4i01jvw0SRdL5Bt%2F83677fb912dd4a539a3f3bb5c0c82de1?format=webp&amp;width=405 405w" type="image/webp"></picture><style data-emotion-css="1sn22t4">.css-1sn22t4{width:100%;padding-top:35.4%;pointer-events:none;font-size:0;}</style><div class="builder-image-sizer css-1sn22t4"> </div></div><div class="builder-block builder-296e83c56835496a896d380e22d2fbd9 builder-has-component css-logohe" builder-id="builder-296e83c56835496a896d380e22d2fbd9"><style data-emotion-css="1fuo4gk">.css-1fuo4gk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}@media (max-width:991px){.css-1fuo4gk{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;}}</style><div class="builder-columns css-1fuo4gk"><style data-emotion-css="15p9q9i">.css-15p9q9i{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(58.333% - 15px);margin-left:0;}.css-15p9q9i > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}@media (max-width:991px){.css-15p9q9i{width:100%;margin-left:0;}}</style><div class="builder-column css-15p9q9i"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-296e83c56835496a896d380e22d2fbd9"><style data-emotion-css="8r3wet">.css-8r3wet.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;min-height:20px;min-width:20px;width:100%;border-radius:5px;overflow:hidden;margin-right:auto;}</style><div class="builder-block builder-50cefa294545480a96166693c05e207d css-8r3wet" builder-id="builder-50cefa294545480a96166693c05e207d"><div class="css-79elbk"><video autoplay="" muted="" loop="" class="builder-video css-cz4v3a"></video><style data-emotion-css="m5569v">.css-m5569v{width:100%;padding-top:58.41%;pointer-events:none;font-size:0;}</style><div class="css-m5569v"></div></div></div></div></div><style data-emotion-css="1xaxpyc">.css-1xaxpyc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(41.667% - 15px);margin-left:30px;}.css-1xaxpyc > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}@media (max-width:991px){.css-1xaxpyc{width:100%;margin-left:0;}}</style><div class="builder-column css-1xaxpyc"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-296e83c56835496a896d380e22d2fbd9"><style data-emotion-css="9f7tx5">.css-9f7tx5.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:auto;margin-bottom:auto;}</style><div class="builder-block builder-2487409df20c4d6ea916563459503bd5 css-9f7tx5" builder-id="builder-2487409df20c4d6ea916563459503bd5"><style data-emotion-css="1718vnj">.css-1718vnj.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;height:auto;font-size:24px;}@media only screen and (max-width:991px){.css-1718vnj.builder-block{margin-top:28px;}}</style><div class="builder-block builder-01c085f9d331407291e18ae00c2e705f builder-has-component css-1718vnj" builder-id="builder-01c085f9d331407291e18ae00c2e705f"><span class="builder-text css-1qggkls"><p style="">Visually build with your components</p></span></div><style data-emotion-css="1mbueh1">.css-1mbueh1.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:12px;height:auto;}@media only screen and (max-width:991px){.css-1mbueh1.builder-block{margin-top:13px;}}</style><div class="builder-block builder-522f74098b38447289e1bbe3e525c9d6 fix-line-height builder-has-component css-1mbueh1" builder-id="builder-522f74098b38447289e1bbe3e525c9d6"><span class="builder-text css-1qggkls"><p style=""><a href="https://www.builder.io/m/developers" rel="noopener noreferrer" target="_blank">Builder.io</a>&nbsp;is a visual editor that connects to any site or app and lets you&nbsp;<a href="https://www.builder.io/m/products" rel="noopener noreferrer" target="_blank">drag and drop</a>&nbsp;with&nbsp;<a href="https://www.builder.io/m/developers" rel="noopener noreferrer" target="_blank">your components</a>.<br></p>
</span></div><style data-emotion-css="etaca8">.css-etaca8.builder-block{position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;margin-right:auto;margin-top:22px;}@media only screen and (max-width:991px){.css-etaca8.builder-block{margin-top:16px;}}@media only screen and (max-width:640px){.css-etaca8.builder-block{margin-top:17px;}}</style><div class="builder-block builder-04ce70c139f74cba9ce6b77cd2b59966 builder-has-component css-etaca8" builder-id="builder-04ce70c139f74cba9ce6b77cd2b59966"><style data-emotion-css="k008qs">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><div class="builder-columns css-k008qs"><style data-emotion-css="1ki2g2t">.css-1ki2g2t{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(50% - 10px);margin-left:0;}.css-1ki2g2t > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="builder-column css-1ki2g2t"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-04ce70c139f74cba9ce6b77cd2b59966"><style data-emotion-css="e9su4y">.css-e9su4y.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;-webkit-appearance:none;-moz-appearance:none;appearance:none;padding-top:10px;padding-bottom:10px;padding-left:35px;padding-right:35px;background-color:rgba(0,0,0,1);color:white;border-radius:8px;text-align:center;cursor:pointer;width:auto;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;font-family:"Poppins",sans-serif;font-size:16px;line-height:26px;-webkit-letter-spacing:.5px;-moz-letter-spacing:.5px;-ms-letter-spacing:.5px;letter-spacing:.5px;margin-right:auto;white-space:nowrap;}@media only screen and (max-width:991px){.css-e9su4y.builder-block{font-size:16px;line-height:18px;padding-left:23px;padding-right:23px;margin-top:0px;padding-top:13px;padding-bottom:13px;}}</style><a role="button" href="https://builder.io/signup" target="_blank" class="builder-block builder-bbfd1a8be4e54fa0bc8f887da6d8a83c builder-has-component css-e9su4y" builder-id="builder-bbfd1a8be4e54fa0bc8f887da6d8a83c">Try it out</a></div></div><style data-emotion-css="1q570rn">.css-1q570rn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;line-height:normal;width:calc(50% - 10px);margin-left:20px;}.css-1q570rn > .builder-blocks{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="builder-column css-1q570rn"><div class="builder-blocks builder-blocks-child css-h47494" builder-type="blocks" builder-parent-id="builder-04ce70c139f74cba9ce6b77cd2b59966"><style data-emotion-css="1t30id">.css-1t30id.builder-block{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;box-sizing:border-box;margin-top:0px;-webkit-appearance:none;-moz-appearance:none;appearance:none;padding-top:10px;padding-bottom:10px;padding-left:0px;padding-right:0px;color:rgba(0,0,0,1);border-radius:8px;text-align:center;cursor:pointer;width:auto;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;font-family:"Poppins",sans-serif;font-size:16px;line-height:26px;-webkit-letter-spacing:.5px;-moz-letter-spacing:.5px;-ms-letter-spacing:.5px;letter-spacing:.5px;margin-right:auto;margin-left:15px;}@media only screen and (max-width:991px){.css-1t30id.builder-block{font-size:16px;line-height:18px;padding-left:0px;padding-right:18px;margin-top:auto;margin-left:2px;min-width:110px;margin-bottom:auto;}}</style><a role="button" href="/m/developers" target="_blank" class="builder-block builder-b73a1d9611ee46b180da86ffdd53fa77 builder-has-component css-1t30id" builder-id="builder-b73a1d9611ee46b180da86ffdd53fa77">Learn more</a></div></div></div></div><style data-emotion-css="nwuw40">.css-nwuw40.builder-block{margin-top:20px;padding-left:20px;border-radius:4px;padding-right:20px;background-color:rgba(40,44,52,1);box-shadow:0 2px 6px 0 rgba(0,0,0,0.27);}</style><div class="builder-block builder-dde61f974a184a338de6b5e43b675061 builder-has-component css-nwuw40" builder-id="builder-dde61f974a184a338de6b5e43b675061"><style data-emotion="css 1ijwl8d">.css-1ijwl8d{position:relative;border-radius:3px;}.css-1ijwl8d:hover .copy-to-clipboard{display:block!important;}.css-1ijwl8d code{font-size:14px;}</style><div class="code-block css-1ijwl8d"><style data-emotion="css 185ibg">.css-185ibg{position:absolute!important;top:0;right:0;display:none!important;z-index:10;}</style><button class="MuiButtonBase-root MuiIconButton-root copy-to-clipboard css-185ibg" tabindex="0" type="button" title="Copy code to clipboard"><span class="MuiIconButton-label"><style data-emotion="css joy3r2">.css-joy3r2{color:white;opacity:0.7;}</style><svg class="MuiSvgIcon-root css-joy3r2" focusable="false" viewBox="0 0 24 24" aria-hidden="true"><path d="M19 3h-4.18C14.4 1.84 13.3 1 12 1c-1.3 0-2.4.84-2.82 2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-7 0c.55 0 1 .45 1 1s-.45 1-1 1-1-.45-1-1 .45-1 1-1zm2 14H7v-2h7v2zm3-4H7v-2h10v2zm0-4H7V7h10v2z"></path></svg></span></button><div class=""><pre style="display:block;overflow-x:auto;padding:0.5em;color:#ddd;background:#282c34;font-family:Menlo, Monaco, &quot;Courier New&quot;, monospace;line-height:1em;font-size:1.2em"><code class="language-jsx">// Dynamically render your components
export function MyPage({ json }) {
  return &lt;BuilderComponent content={json} /&gt;
}

registerComponents([MyHero, MyProducts])</code></pre></div></div></div></div></div></div></div></div></div><style data-emotion-css="1mvsfya">.css-1mvsfya.builder-block{height:0;width:0;display:inline-block;opacity:0;overflow:hidden;pointer-events:none;}</style><img role="presentation" aria-hidden="true" src="https://cdn.builder.io/api/v1/pixel?apiKey=YJIGb4i01jvw0SRdL5Bt" class="builder-block builder-pixel-e86nycc5tdw css-1mvsfya" builder-id="builder-pixel-e86nycc5tdw"></div></div></div></template><div builder-id="builder-7fd4bfcb2f3540cca129a9e10d1254f5" builder-type="blocks" builder-parent-id="builder-fd60c008f44a4c46be618e21afe30be5" data-builder-component="symbol" data-builder-content-id="de784470c6884829b5e7c7603f4c51ed" builder-content-id="de784470c6884829b5e7c7603f4c51ed" builder-model="symbol"><p><span><div><p>Introducing Visual Copilot: a new AI model to convert Figma designs to high quality code in a click.</p><p>No setup needed. 100% free. Supports all popular frameworks.</p></div>
</span></p><p><a role="button" href="https://builder.io/signup" target="_blank" builder-id="builder-a85aff888e7849f98193f66bd662f27e">Try Visual Copilot</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Texture Healing for Monospace Fonts (226 pts)]]></title>
            <link>https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md</link>
            <guid>38221379</guid>
            <pubDate>Fri, 10 Nov 2023 17:07:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md">https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md</a>, See on <a href="https://news.ycombinator.com/item?id=38221379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:githubnext/monaspace" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="TPvN7MsNCXIuV6vVQV5rcQHaD_7Vp6kjJhj-jxdU2XW_d9K5Cg5poUOO_olxMkI27Ms_Ki6qU2_NnDxqVeUODw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="githubnext/monaspace" data-current-org="githubnext" data-current-owner="" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=githubnext%2Fmonaspace" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/githubnext/monaspace/blob/main/docs/Texture%20Healing.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="b5e9e72f7999e9104da59519413a9f6f6970d8cf0b3d3ecd52abd892b386905c" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Missing windows discovered on U.S.-bound plane after departing London (110 pts)]]></title>
            <link>https://www.npr.org/2023/11/10/1212144515/plane-missing-window-london-us</link>
            <guid>38221121</guid>
            <pubDate>Fri, 10 Nov 2023 16:49:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2023/11/10/1212144515/plane-missing-window-london-us">https://www.npr.org/2023/11/10/1212144515/plane-missing-window-london-us</a>, See on <a href="https://news.ycombinator.com/item?id=38221121">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="res1212155850">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s400-c85.webp 400w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s600-c85.webp 600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s800-c85.webp 800w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s900-c85.webp 900w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s400-c85.png 400w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s600-c85.png 600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s800-c85.png 800w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s900-c85.png 900w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1200-c85.png 1200w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1600-c85.png 1600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1800-c85.png 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/png">
            <img src="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1100-c50.png" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                A photo included in the U.K.'s Air Accidents Investigations Branch special bulletin shows the location of one damaged and two missing window panes on an Airbus A321.
                <b aria-label="Image credit">
                    
                    Air Accidents Investigation Branch
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Air Accidents Investigation Branch
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1200.png" type="image/png">
            <img data-original="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1200.png" alt="" src="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.20.25-am-b5659621ba3c9521a695896349fb036897b47af8-s1200.png">
        </picture>
    </div>
<div>
        <p>A photo included in the U.K.'s Air Accidents Investigations Branch special bulletin shows the location of one damaged and two missing window panes on an Airbus A321.</p>
        <p><span aria-label="Image credit">
            
            Air Accidents Investigation Branch
            
        </span>
    </p></div>
   </div>
   <p>A U.S.-bound plane took off from London last month with four damaged window panes, including two that were completely missing, according to U.K. air accident investigators. </p>   <p>No one was injured by the window malfunctions, which appear to have been caused by high-power lights used in a film shoot, <a href="https://assets.publishing.service.gov.uk/media/6544b3089e05fd0014be7c9b/S2-2023__Airbus_A321-253NX_G-OATW.pdf">the U.K.'s Air Accident Investigation Branch</a> reported in a special bulletin published Nov. 4. </p>   <p><strong>T</strong>he aircraft departed from London's Stansted Airport on the morning of Oct. 4 carrying 11 crew members and nine passengers, all of whom are employees of the "tour company or the aircraft's operating company," the report states, without elaborating on the tour company.</p>   
   
   
<!-- END ID="RES1212148214" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p><a href="https://aircraft.airbus.com/en/aircraft/a320-the-most-successful-aircraft-family-ever/a321ceo">The single-aisle aircraft</a>, an Airbus A321, can seat more than 170 passengers, but the small group of passengers were all seated in the middle of the cabin, just ahead of the overwing exits. </p>   <p>The missing windows weren't discovered until the plane was climbing at an altitude of 13,000 feet, according to the AAIB report.</p>   <p>"Several passengers recalled that after takeoff the aircraft cabin seemed noisier and colder than they were used to," investigators wrote. A crew member walked towards the back of the aircraft, where he spotted a window seal flapping on the left side of the aircraft. </p>   <p>"The windowpane appeared to have slipped down," the report reads. "He described the cabin noise as 'loud enough to damage your hearing.' " </p>   <p>As the plane approached 14,000 feet, the pilots reduced speed and stopped their ascent. An engineer and co-pilot went back to take a look at the window and agreed the aircraft should turn around immediately.</p>   
   
<!-- END ID="RES1212147672" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>The plane landed safely back at Stansted after 36 minutes of total flying time, during which the plane had remained "pressurized normally," investigators wrote. </p>   <p>After inspecting the plane from the ground, the crew discovered that a second window pane was also missing and a third was dislodged. A fourth window appeared to be protruding slightly from its frame. </p>   <p>One shattered window pane was later recovered from the runway during a routine inspection. </p>   <p>The windows may have been damaged by high-power flood lights used during filming the day before the flight, according to the AAIB's assessment. </p>   <div id="res1212158802">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s400-c85.webp 400w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s600-c85.webp 600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s800-c85.webp 800w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s900-c85.webp 900w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s400-c85.png 400w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s600-c85.png 600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s800-c85.png 800w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s900-c85.png 900w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1200-c85.png 1200w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1600-c85.png 1600w,
https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1800-c85.png 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/png">
            <img src="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1100-c50.png" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                A photo from the AAIB's special bulletin shows the flood lights used during a film shoot the day before the plane departed Stansted Airport in London.
                <b aria-label="Image credit">
                    
                    Air Accidents Investigations Branch
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Air Accidents Investigations Branch
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1200.png" type="image/png">
            <img data-original="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1200.png" alt="" src="https://media.npr.org/assets/img/2023/11/10/screen-shot-2023-11-10-at-10.23.22-am-3a4c3b9dabb1847f169d444a891eefb496fa2f8b-s1200.png">
        </picture>
    </div>
<div>
        <p>A photo from the AAIB's special bulletin shows the flood lights used during a film shoot the day before the plane departed Stansted Airport in London.</p>
        <p><span aria-label="Image credit">
            
            Air Accidents Investigations Branch
            
        </span>
    </p></div>
   </div>
   <p>The lights, which were intended to give the illusion of a sunrise, were placed about 20 to 30 feet from the aircraft, shining on first the right, then the left side of the craft for over nine hours in total. </p>   
   <p>A foam liner had melted away from at least one of the windows and several window panes appeared to have been warped by the thermal heat. </p>   <p>"A different level of damage by the same means might have resulted in more serious consequences, especially if window integrity was lost at higher differential pressure," the AAIB wrote. The agency had not returned a call from NPR by the time of publication. </p>   <p>In 2018, <a href="https://www.npr.org/sections/thetwo-way/2018/04/17/603212224/1-person-killed-as-southwest-jet-with-engine-trouble-makes-emergency-landing">Southwest passenger Jennifer Riordan</a> was fatally injured after being partially sucked out of a plane window that was smashed by shrapnel from an exploded engine. </p>   <p><a href="https://www.cbsnews.com/news/delta-air-lines-windshield-cracks/">Several</a> <a href="https://www.usatoday.com/story/travel/airline-news/2023/05/15/cracked-window-southwest-flight-hawaii/70219229007/">cracked</a> <a href="https://www.independent.co.uk/travel/news-and-advice/polish-airlines-plane-window-cracked-b2153232.html">airplane windows</a> have made headlines in the years since, but <a href="https://www.wired.co.uk/article/getting-sucked-out-of-plane-window-sichuan-airlines-accident">aviation experts maintain</a> that the risk of being injured or killed in <a href="https://www.usatoday.com/story/travel/columnist/cox/2019/08/08/ask-captain-how-dangerous-cracked-cockpit-windshield/1943362001/">such a scenario</a> is still rare.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dungeon KeeperFX 1.0.0 has been released (199 pts)]]></title>
            <link>https://keeperfx.net/news/11/2023-11-10/keeperfx-100-has-been-released</link>
            <guid>38220982</guid>
            <pubDate>Fri, 10 Nov 2023 16:39:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keeperfx.net/news/11/2023-11-10/keeperfx-100-has-been-released">https://keeperfx.net/news/11/2023-11-10/keeperfx-100-has-been-released</a>, See on <a href="https://news.ycombinator.com/item?id=38220982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Numerous volunteers have put in a lot of work to deliver a long list of features and fixes. Notably, with this release, there is a jump from version 0.x to version 1.x, coinciding with the removal of the link to the keeperfx.dll file. </p><p>This means that all original Dungeon Keeper code has been rewritten, establishing KeeperFX as a true open-source standalone game. Ownership of the original game is still and will always be required for copyright reasons. When installing KeeperFX 1.0, perform a fresh installation without overwriting any previous versions. Saved games cannot be migrated. There is a <a href="https://github.com/dkfans/keeperfx/wiki">wiki</a> that holds answers to most of the questions you may have, and we have a large and friendly <a href="https://discord.gg/hE4p7vy2Hb">discord community</a> where we welcome all friendly new members. </p><p><strong>What’s new in KeeperFX 1.0.0:</strong> </p><ul><li>All remaining legacy functionality from the Dungeon Keeper executable has been moved to KeeperFX. <ul><li>This means we are no longer limited by the original game in what we can change </li><li>There can now be more than 2048 things on the map at the same time</li></ul> </li><li>Maps are no longer limited to being 85x85, they can be larger or smaller </li><li>New units: Time Mage and Druid (are not used in old campaigns, but wait to see them in new maps) </li><li>Higher frame rates </li><li>Fixed crashes when playing in 4k resolution </li><li>Improved bridge building and digging for enemy computers </li><li>Stopped the best computer players from instantly dropping their entire army on you </li><li>Removed the lowest rated campaigns that were bundled, to give new users a positive first impression </li><li>Bundled campaigns got higher quality landview speeches </li><li>Added more translations for included maps and campaigns </li><li>Objects can have a direction (so face east for example) </li><li>More customization options for mapmakers and modders. <ul><li>Add new creatures </li><li>Level scripts can be larger, resulting in more complex scenarios </li><li>Add new shots </li><li>New script commands </li><li>Custom music and sounds </li><li>Fully configurable traps </li><li>New decorative objects</li></ul> </li><li>New map textures </li><li>Orcs got an eating animation and the Avatar a torture animation </li><li>Maps can have larger hero parties </li><li>Improved multiplayer stability </li><li>Multiplayer map numbers can go past 255 </li><li>Gems are now purple on the minimap to distinguish them from gold </li><li>Units visible on minimap no longer jump around</li></ul> <p>For the full change list see <a href="https://github.com/dkfans/keeperfx/compare/Release050...Release1.0.0">here</a>. </p><p>- KeeperFX Team</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York restaurants fight back against reservations by bots (155 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-10-25/new-york-restaurants-bars-fight-back-against-reservations-by-bots</link>
            <guid>38220892</guid>
            <pubDate>Fri, 10 Nov 2023 16:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-10-25/new-york-restaurants-bars-fight-back-against-reservations-by-bots">https://www.bloomberg.com/news/articles/2023-10-25/new-york-restaurants-bars-fight-back-against-reservations-by-bots</a>, See on <a href="https://news.ycombinator.com/item?id=38220892">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gigantic heat caverns in Mustikkamaa have now been filled with water (2021) (159 pts)]]></title>
            <link>https://www.helen.fi/en/news/2021/gigantic-heat-caverns-in-mustikkamaa-filled</link>
            <guid>38220288</guid>
            <pubDate>Fri, 10 Nov 2023 15:46:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.helen.fi/en/news/2021/gigantic-heat-caverns-in-mustikkamaa-filled">https://www.helen.fi/en/news/2021/gigantic-heat-caverns-in-mustikkamaa-filled</a>, See on <a href="https://news.ycombinator.com/item?id=38220288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
                    News / 11.5.2021
                </p>
                <h2>Gigantic heat caverns in Mustikkamaa have now been filled with water</h2>
                <div>
    <p>The filling of underground heat caverns in Mustikkamaa with water has been completed this week, and the use of the heat caverns for heating homes in Helsinki is a step closer.</p>
</div>
                
            </div><div>
<p>Helen started to fill the heat caverns with tap water in early December. The filling of the caverns took more than three months due to their enormous total volume of 320 million litres. The caverns have such a large capacity that filling them from an ordinary kitchen tap would have taken more than 50 years.</p>
<p>The current estimated temperature of the water storage facility is about +30 degrees. Slow heating of the bedrock has started, and actual heating of water in the heat cavern will start in April. The aim is to connect the heat caverns into the current district heating system of Helsinki in July.</p>
<p>The heat caverns balance the consumption peaks in the district heating network throughout the year. For example, waste heat from waste waters and properties can be stored in the heat cavern and released for use as and when required. In future, the temperature of the water in the heat cavern will vary between +45 and +100 degrees according to usage situation.</p>
<p>- Helen is proceeding fast towards a carbon-neutral future, and the underground heat caverns are an important step on this path. The use of old oil caverns as an energy storage facility is a good example of Finnish innovation that is unique even on a global scale. The emission-free energy system of the future is made up of many pieces, and storage is an important element in the system. The heat caverns support all heat production forms, says Helen’s Director Timo Aaltonen.</p>
<p>Carbon-neutral production is also currently built at Helen’s heating and cooling plant in Sörnäinen with the arrival of two new heat pumps. A seawater heat pump and a bioenergy heating plant are being built in Vuosaari. The construction of the geothermal heating plant in Ruskeasuo will start this spring. Helen is also investigating, for example, waste heat from the Kilpilahti industrial area and extensive utilisation of seawater heat pumps.</p>
<p><strong> Facts</strong></p>
<ul>
<li>The heat contained in the water in the Mustikkamaa cavern heat storage facility corresponds to the heating of 25,000 one-bedroom apartments all year round.</li>
<li>Heat will not escape from the heat caverns because the bedrock that is tens of metres deep acts as an excellent insulator.</li>
<li>The rock caverns will decrease Helen’s carbon dioxide emissions by 21,000 tonnes per year.</li>
</ul>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Svalbard fibre optic cable connection (158 pts)]]></title>
            <link>https://spacenorway.no/en/what-we-do/operational-infrastructure/the-svalbard-fibre-optic-cable-connection/</link>
            <guid>38219998</guid>
            <pubDate>Fri, 10 Nov 2023 15:26:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spacenorway.no/en/what-we-do/operational-infrastructure/the-svalbard-fibre-optic-cable-connection/">https://spacenorway.no/en/what-we-do/operational-infrastructure/the-svalbard-fibre-optic-cable-connection/</a>, See on <a href="https://news.ycombinator.com/item?id=38219998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Svalbard has an ideal geographical location for downloading data from satellites in polar orbits. SvalSat, the Svalbard satellite ground station at 78 degrees north, is the northernmost ground station in the world and started operation in 1997. However, development of the business depended on efficient transfer of large volumes of data to the mainland.</p>







<p>The station is located at Platåberget outside Longyearbyen. Satellite data were initially transmitted to customers via a geostationary satellite. However, small capacity for data transmission via satellite was a limiting factor. Around 2001, it became clear that SvalSat’s future development was entirely dependent on the efficient transfer of large volumes of data to the mainland.</p>







<figure><img src="https://spacenorway.no/wp-content/uploads/2021/09/DJI_0709_web-768x1024.jpg" alt="KSATs stasjon på Svalbard, SvalSat har i dag over 100 operative antenner.
Foto: KSAT" width="501" height="668"><figcaption><sup>SvalSat, KSAT’s station on Svalbard, currently has more than 100 operational antennas. Photo: KSAT</sup></figcaption></figure>



<p>At this time, SvalSat was part of Norsk Romsenter Eiendom AS (later renamed Space Norway AS), a company owned by Stiftelsen Norsk Romsenter (NRS). NRS was concerned that SvalSat would lose out on commercial opportunities because of the lack of fibre connection to mainland Norway. NRS believed that a subsea fibre connection would be essential to ensure the future development of SvalSat’s activities. The telecommunications operator at Svalbard saw no commercial basis for investing in an approximately 1,400-kilometre subsea fibre optic cable connection. In 2002, NRS initiated its own assessment and planning of a fibre connection from Longyearbyen to the mainland, with the objective of establishing such connection without any government financing.</p>







<p>With Space Norway as a tool, NRS succeeded in this project. Financing was secured through a combination of long-term contracts, debt, prepayments from key customers, and funding from Space Norway. Customers and partners included NASA, NOAA, KSAT, Andøya Rocket Range (today Andøya Space Center), Telenor and Uninett8. The construction was done in 2003 and the fibre connection became operational in January 2004.</p>







<figure><img src="https://spacenorway.no/wp-content/uploads/2021/12/18%E2%80%A2NH0160021-1024x683.jpg" alt="" width="840" height="560"><figcaption>Jens Olav Frorud and Dag H. Stølan in Space Norway. Foto: Nina Holtan</figcaption></figure>







<p>The fibre connection has been of important strategic value for the growth and development of KSAT. SvalSat is now the world’s largest ground station for downloading data from satellites in polar orbits. Today, both KSAT and Space Norway are two successful spin-off businesses from NRS (Norwegian Space Agency).</p>







<p>The fibre connection consists of two separate cables that connect Longyearbyen to mainland Norway. The distance of approx. 1,400 km corresponds roughly to the distance between Oslo and Paris. The cables are buried approximately 2 metres in selected areas to protect against destruction by fish trawling and anchoring of ships. The sea depth reaches as much as 1,670 metres just west of Svalbard. At the time of construction, it was the world’s deepest fibre-optic cable. Tyco Communications (now SubCom) was the contractor for the project. The anticipated technical service life of the cables is 25 years. It is now 17 years since the cables became operational. The operating track record of the Svalbard connection has been excellent with few incidents that have led to interruptions of the service. During the period 2018-20, Space Norway carried out significant security related upgrades to the fibre connection.</p>







<p>The primary motivation for establishing the fibre-optic cable in 2004 was to ensure the growth and development of the satellite business at SvalSat. Today, the fibre connection also represents a critical resource for the society at Svalbard and enables modern electronic communication services. These are services necessary to maintain and develop society as well as Norwegian presence on the archipelago. The fibre connection is considered part of the national critical infrastructure.</p>






<div>
<figure><img src="https://spacenorway.no/wp-content/uploads/2021/09/Fiberforbindelse_Longyearbyen_bakgrunn-768x1024.jpg" alt="" width="511" height="681"><figcaption><sup>Illustration of the fibre optic cable enabling efficient transfer of large volumes of data to the mainland.</sup></figcaption></figure></div>






<p>National and international companies and entities depend on a functioning fibre connection to Svalbard. Information downloaded at SvalSat and distributed via the fibre connection is important for a number of purposes such as weather forecasting services, surveillance of ship traffic, environmental monitoring, development of ice maps for the Arctic and communication services in the critical phases of rocket launches9. The connection is also important for KSAT’s contribution to Galileo, Europe’s satellite-based navigation system10. Space Norway offer transmission capacity at wholesale level to a small number of customers, who in turn provide communication services in the retail and commercial markets. End customers and users of the fibre connection include a wide spectre of businesses: the society in general, the coastal radio service, Helsenett, Avinor, the Governor of Svalbard, including police and SAR (Search And Rescue) resources, local government in Longyearbyen, the Norwegian Coastal Administration with services for maritime security, EUMETSAT11, NASA, NOAA, Galileo, Iridium, ESA, the Norwegian Mapping Authority as well as university and research units on the archipelago such as UNIS, the Nansen Environmental and Remote Sensing Center and the Norwegian Institute of Marine Research etc.</p>







<p><strong>Sources:</strong></p>



<p><sup>8 NASA is the National Aeronautics and Space Administration, and NOAA is the National Oceanic and Atmospheric Administration, a department under the United States Department of Trade. KSAT is Kongsberg Satellite Services.</sup></p>



<p><sup>9 LEOP, Launch and early operations phase.</sup></p>



<p><sup>10 Galileo is a satellite navigation system set up by the European Union and the European Space Agency. The system has been designed as an alternative to the military and American-controlled Global Positioning System (GPS) and the Russian GLONASS.</sup></p>



<p><sup>11 EUMETSAT is the European organisation for meteorological satellites.</sup></p>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jeff Geerling (189 pts)]]></title>
            <link>https://www.raspberrypi.com/news/meet-jeff-geerling/</link>
            <guid>38219926</guid>
            <pubDate>Fri, 10 Nov 2023 15:20:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raspberrypi.com/news/meet-jeff-geerling/">https://www.raspberrypi.com/news/meet-jeff-geerling/</a>, See on <a href="https://news.ycombinator.com/item?id=38219926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p><strong><em>Andrew Gregory of <a href="https://hackspace.raspberrypi.com/">HackSpace magazine</a> sat down with the one and only Jeff Geerling to chat about the wholesome corner of the internet he created. </em></strong></p>


<div>
<figure><img decoding="async" loading="lazy" width="965" height="643" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45.png" alt="jeff in a blue anti static jacket pointing at raspberry pi awards inside the sony factory" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45.png 965w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-300x200.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-768x512.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-800x533.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-450x300.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.45-900x600.png 900w" sizes="(max-width: 965px) 100vw, 965px"><figcaption>Jeff exploring the Sony factory where Raspberry Pis are baked</figcaption></figure></div>


<p>If you want to cut through the buzzwords and find out what tech actually does, you could do a lot worse than listen to Jeff Geerling. He’s built an utterly wholesome corner of the internet in which he explains, demonstrates, and demystifies the latest thing that everybody else pretends to know about. Linux, single-board computers, open source, developer tools, home automation – Jeff does the lot, and he wants to teach you how to do it, too. We thought we’d talk to him about what he’s been getting up to with his new Raspberry Pi 5. </p>



<h3><strong>HackSpace:&nbsp; Morning Jeff! You’ve done loads of Pi projects over the last couple of years. What do you still have running at the moment?</strong></h3>



<p><strong>Jeff Geerling</strong>:&nbsp; Things that are practical, really. I have Pis running all of my home network stuff, all the home lab-type things; I have a Pi running internet monitoring, so I can keep my ISP honest. I have a Pi running my VPN.&nbsp;</p>



<p>I have no cloud services for my light bulbs, or for my HVAC or anything. It’s all running through Pis. I don’t have any cloud account tie-in. If the internet goes down here, the only thing is I can’t access it remotely, but everything’s still running. I love the privacy aspects of it. And I love the ability to learn new things through it – industrial automations, and controls, and APIs with these different systems.&nbsp;</p>



<p>I think one of the things that fascinates me the most is all these different IOT devices. Before I knew much about Pis and microcontrollers, I always thought IoT was magic. And then you open one of these up, and you just see a little microcontroller inside. It might just be an ESP board, or a Pico, or something else. But I know that I could hack it, and that opens up a new world. You could build one of those on your own to just about the same quality; you can’t get injection-moulded plastic, but everything else you can do on your own, and 3D printing has made it so that enclosures can be so much nicer. It’s just cool to see. It’s like taking down the wall of magic that you thought existed between really cool products and your own abilities.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="571" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-1024x571.png" alt="jeff wearing a mask and soldering towards the camera" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-1024x571.png 1024w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-300x167.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-768x429.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-800x446.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-450x251.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33-900x502.png 900w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.33.png 1145w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Jeff describes himself as an electronics beginner; something tells us he’s being modest</figcaption></figure></div>


<p>The projects that I do are typically rehashes of what other people have done; I might make the documentation a little better or I might package it up a little nicer. But really, I would say that I’m beginner-level electronics and beginner-level microcontrollers. I just have the ability to relate what I’m doing a little better than a lot of people who are experts at it.</p>



<p>A year or two ago, I talked to [Linux YouTuber] NetworkChuck about recording a podcast episode. He does a lot of stuff with Raspberry Pis, too, with red hat hacking and black hat stuff. And, you know, fun things. So we recorded the podcast. And it never went up because one of the microphones was messed up, and it sounded terrible. I didn’t hear from him for a while, and then on 01 March this year, he’s just like, ‘Hey, Jeff, do you want to work with me on a Mr. Beast project? At like, 9 am, right now?’ I had no travel planned and no deadlines, so I said yes.&nbsp;</p>



<p>And that was terrible, but also awesome. So many people who make things, especially if you make it for production use, want to make sure it actually works. So there’s a deadline attached to it. There are problems; there are always challenges, things you didn’t even think about. And that’s what happened on the Mr. Beast project. But that’s also kind of the addiction that drives us forward. Because while I would say I don’t want to ever do that again, I also say that was a fun experience. And getting to meet all the people there. And all of us going through that at the same time, solving all the challenges. It’s a weird kind of addiction that we have, I think, building software, building hardware, and working on something so big as well.&nbsp;</p>



<p>Any time we solved a problem with a five-minute fix, the sheer number of computers we were using turned that into a multiple-hour fix.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="642" height="532" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02.png" alt="jeff in a red t shirt holding a bowling ball" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02.png 642w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02-300x249.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.02-450x373.png 450w" sizes="(max-width: 642px) 100vw, 642px"><figcaption>Testing hardware by dropping a bowling ball on to it. Always wear eye protection!</figcaption></figure></div>


<h3><strong>HS:&nbsp; Why Raspberry Pi? What’s so good about it?</strong></h3>



<p><strong>JG:&nbsp;</strong> Raspberry Pi devotes a lot of time to testing and to making sure manufacturing is better. And manufacturing in the UK is a pretty cool thing. How many computer companies manufacture things in their home country – there’s not many, and Raspberry Pi does on a huge scale. So there’s a lot of those things that some people don’t assign value to – not just the bits and the little circuits on the board and all that.&nbsp;</p>



<p>Open source is another balance that Raspberry Pi has to offer. There’s the Broadcom chip [which isn’t open-source] versus you’re building the operating system based on Debian, which is like one of the most open-source Linux distributions. And it’s a weird balance. In the hardware world, it seems like there’s a lot less open source, because if you put out an open-source design and someone else makes it, all of a sudden you have zero revenue. Versus software, there’s sales and support and services, and there’s a lot more revenue opportunities that can’t just be immediately consumed by another company. Although, recently we’ve seen Amazon doing that sometimes, and leading to licences like the BSL, which is not really open-source.</p>


<div>
<figure><img decoding="async" loading="lazy" width="968" height="642" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54.png" alt="jeff in a red shirt looking into the camera holding a pi cluster next to his face" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54.png 968w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-300x199.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-768x509.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-800x531.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-450x298.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.54-900x597.png 900w" sizes="(max-width: 968px) 100vw, 968px"><figcaption>Jeff’s fascinated by factories. And he loves open source software and hardware</figcaption></figure></div>


<h3><strong>HS:&nbsp; I’ve heard of the BSD licence, but not BSL.</strong></h3>



<p><strong>JG:&nbsp;</strong> Most open-source licences don’t care if you’re a government or a spy or a bad person or a good person – it’s free. It’s unencumbered. But the BSL imposes a restriction: if you’re a big business, you can’t use it. Philosophically I can understand that stance, but don’t call it </p>



<p>open source: call it ‘source available’ or, you know, ‘maker friendly’. But on the flip side, there’s so many companies that start as a maker, somebody who designs a little thing, that thing becomes popular, and all of a sudden you’re a big business and your licence is void, just because you hit a revenue number. And it doesn’t matter if it’s 50 bucks or $5 billion, it’s a restriction and it’s a philosophical thing that’s not compatible with my understanding of the term ‘open source’.&nbsp;</p>



<p>I think Raspberry Pi offers a little bit of a different take on it. Early on, a lot of the hardware was super locked down and there weren’t datasheets. And one by one, they start making things better at release. So, you know, my hope is that someday we could get more open firmware and stuff for the Broadcom chips. I don’t know if that’ll ever happen. But it would be cool. Unlike many companies, where they start out open source and then start closing things, Raspberry Pi has always gotten better, even if it’s not perfect.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="966" height="640" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24.png" alt="jeff crouched next to a table with a massive pi cluster on it" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24.png 966w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-300x199.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-768x509.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-800x530.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-450x298.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.24-900x596.png 900w" sizes="(max-width: 966px) 100vw, 966px"><figcaption>The Petabyte Pi: a Raspberry Pi with 1024 terabytes of storage</figcaption></figure></div>


<h3><strong>HS:&nbsp; Hopefully people will like the new power button.&nbsp;</strong></h3>



<p><strong>JG:</strong> For me, the power button on the Pi 5 is the most appreciated new feature. It’s just so handy. Like, if I’m running a Raspberry Pi headless, with no keyboard, I can just do a quick shut down. I mean, I put power buttons on GPIO before, but it’s cumbersome. This is nice to have it on the board.&nbsp;</p>



<h3><strong>HS:&nbsp; And have you looked into the dual camera possibilities?</strong>&nbsp;</h3>



<p><strong>JG:&nbsp;</strong> So machine vision has gotten really interesting in the past year, to the point where there are open-source tools to do so many things that used to require tons of expensive I/O. You can do stereo camera depth vision with all open-source tools, and [I’m] hoping to use Google Coral TPU to do some of this stuff.&nbsp;</p>



<p>Again, it breaks down that barrier between you and the magic. You pick up an iPhone 15 and it can do depth mapping with whatever that sensor is. And you’re like, man, I’ll never be able to do that.&nbsp;</p>



<p>And then you get a Pi 5 with Wi-Fi and two cameras, and you’re like, oh, I can plug these open-source libraries together. And we get this – it might not be as high resolution, and it might not be 60 frames per second, but you could do depth mapping and 3D stuff with a little board, and everything’s under 200 bucks, all in, including power supplies and everything. That’s a big difference.&nbsp;</p>



<p>When I was a kid, you could go to RadioShack and buy an electronics hobbyist kit. And that’s how I learned the basics of resistors and all that. You put them together with little spring contacts, and it was really fun. And you could make buzzers and radios and all kinds of stuff – they don’t really exist anymore. All those hobbies that were big when I was a kid, a lot of them are superseded just by how amazing the technology we have today is. But the Raspberry Pi brings that back.</p>


<div>
<figure><img decoding="async" loading="lazy" width="966" height="643" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51.png" alt="jeff geerling in a shirt in front of a regency period looking building" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51.png 966w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-300x200.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-768x511.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-800x533.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-450x300.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.14.51-900x599.png 900w" sizes="(max-width: 966px) 100vw, 966px"></figure></div>


<p>What’s funny is that the Raspberry Pi is actually better at IoT stuff than most IoT companies. Mostly because of the open source philosophy. If we all work together, all these individuals around the world can write plug-ins and do stuff where you can put home assistant at your house. And you can interact with any light bulb, any doorbell, any camera, any washing-machine controller. Whereas if you get Philips, you get the Philips stuff and if you get Sony, you get the Sony stuff.&nbsp;</p>



<p>It’s like the tool world: I use DEWALT mostly, because the first tool I bought was a DEWALT. So you gotta use the DEWALT battery, and then you’re like, well, I could buy this cheaper tool, it’s better. But then it won’t work with my battery. So now I have something like 25 DEWALT tools. I think that’s dumb. It’s ridiculous. And that’s how IoT people want to be: you have the smart hub from this company, and you buy all their stuff. But we’ve already seen companies fail, and then all of your smart stuff becomes dumb. And it’s worse than dumb because you can’t even turn on a light bulb, you know – their server goes down and your lights turn off.&nbsp;</p>



<p>This is an area where instead of just seeing behind the curtain how it’s done, you can do it better. That’s one thing that I love about the Raspberry Pi ecosystem and the open-source ecosystem together.</p>



<h3><strong>HS:&nbsp; A slightly less practical, though no less awesome build of yours is the Pi cluster. Just one question: why?&nbsp;</strong></h3>



<p><strong>JG:&nbsp;</strong> For me, it’s fun. You get something out of it when you’re doing all this work on a cluster. And the first time you see all the nodes come up together, that’s kind of magic. And then also seeing the fact that, like, you can actually program things to scale. It’s useful for a job, especially if you’re gonna build software for the web.&nbsp;</p>



<p>It was a springboard for learning. And for a lot of us, we love that. We love hacking with things, and a Pi cluster is just a fun thing to do it. It also has the side benefit of being able to develop skills that might be incredibly useful. There are still a lot of companies that will pay good money for Kubernetes developers, and a lot of people have learned Kubernetes on Raspberry Pi. The shortage really built into that. And a lot of people started using small PCs that they got on eBay, which is perfectly fine. I think that’s awesome. The hard thing was, like, the reason the Pi was great was because it’s a $35 computer –&nbsp;now a $60 computer – but you can still get the Pi 4, and hopefully there’ll be more available now that Pi 5 has been announced. But it was a quick way to get into that whole ecosystem of learning. And, you know, it’s not necessary at all for a home lab. But it’s fun.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="576" src="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-1024x576.png" alt="jeff kneeling on gravel in front of a massive folded out solar panel" srcset="https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-1024x576.png 1024w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-300x169.png 300w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-768x432.png 768w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-800x450.png 800w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-450x253.png 450w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13-900x506.png 900w, https://www.raspberrypi.com/app/uploads/2023/11/Screenshot-2023-11-10-at-13.15.13.png 1143w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>


<p>And it translated into me getting a better job and doing consulting, which also helped me with that opportunity that I got in the pandemic: I was consulting and making extra money from doing all the work I was doing on Pis, learning clustering, because the clustering skills got me a better-paying job. And it gave me the opportunity to save up some money over the next year. I went to full-time YouTube in 2021, so maybe the Pi cluster was the reason I got into it.&nbsp;</p>



<p>I did my first Pi cluster in 2016. And I had a cluster running from 2016 to 2020 24/7 at my house, and I think had something like two hours of downtime in that time period.&nbsp;</p>



<h3><strong>HS:&nbsp; You said that you’re not a hardware guy. Does that mean that you have a background in software?&nbsp;</strong></h3>



<p><strong>JG:&nbsp;</strong> I started off doing web design. The first ever project I did was helping a radio station. They just transitioned to computers instead of CDs for their music playback, and in their system it had a file that would write to with the current song. My dad had the idea of taking this data and putting the song name on the website, so people could be listening, go to the website, on their laptop, or in an office, back then people did not have smartphones. It was ahead of its time. So I built a little interface that had, like, a car radio with the song title in it in a little, I think it was in Courier font or something, because there were only ten or so fonts that you could use back then. It worked for five or six years, until they got a real website. But, that was my first-ever project.&nbsp;</p>



<p>I learned electronics from my dad, who’s a radio engineer. And I, you know, I soldered together an FM radio. I still have the voltmeter that I soldered together when I was, like, eight years old or something. It still works, and I keep using it, even though it’s not as accurate as it could be. And I’m excited to do more of that since the Pico came out. I’ve done some more projects: I built a garage door sensor thing, and I’m working on some software for the Pimoroni Galactic Unicorn to write some stuff on the wall. And now I have a new office that I’m gonna go into. So there’s a lot of opportunities to build stuff for that.</p>



<h3><strong>HS:&nbsp; That’s a majestic piece of kit.</strong></h3>



<p><strong>JG:&nbsp;</strong> Yeah. And they put in little things like a button. You know, it’s nice to have a button here – now you can do, like, modes for the display. And you can even make a little game on the LEDs matrix. That’s the other thing that I love about the Pi ecosystem: Raspberry Pi works directly with some of these companies to make things better for everyone. And these companies work back with them. It’s a relationship that has been built up over the course of the past decade. It’s bearing more fruit with the Pico, and I think the Pi 5 will drive some of that, too. I’m really excited to see what people come up with with HATs for the Pi 5 with PCI Express. If anybody comes out with a dual 2.5 gigabit network cat, I’m gonna buy that thing the second I see it.</p>



<h2>HackSpace magazine issue 72 out NOW!</h2>



<p>Each month,&nbsp;<a href="https://www.raspberrypi.com/news/tag/hackspace-magazine/">HackSpace magazine</a>&nbsp;brings you the best projects, tips, tricks and tutorials from the makersphere. You can get HackSpace from the&nbsp;<a href="https://store.rpipress.cc/collections/hackspace-magazine">Raspberry Pi Press online store</a>&nbsp;or your local newsagents.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="1024" src="https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-1024x1024.png" alt="Hackspace magazine 72 cover" srcset="https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-1024x1024.png 1024w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-300x300.png 300w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-150x150.png 150w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-768x768.png 768w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-800x800.png 800w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-100x100.png 100w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-450x450.png 450w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54-900x900.png 900w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-24-at-12.05.54.png 1236w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS to start charging for IPv4 usage, but critical services don't support IPv6 (190 pts)]]></title>
            <link>https://old.reddit.com/r/aws/comments/17rxig8/aws_wants_to_start_charging_for_all_allocated/</link>
            <guid>38219882</guid>
            <pubDate>Fri, 10 Nov 2023 15:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/aws/comments/17rxig8/aws_wants_to_start_charging_for_all_allocated/">https://old.reddit.com/r/aws/comments/17rxig8/aws_wants_to_start_charging_for_all_allocated/</a>, See on <a href="https://news.ycombinator.com/item?id=38219882">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>AWS wants to start charging for all allocated IPv4 usage, yet many of their critical services don't support native IPv6</p>

<p>Examples include:</p>

<p>- AWS Cloudformation (cannot signal success/failure)</p>

<p>- AWS systems manager (ssm sessions not possible)</p>

<p>The above cannot be used without an IPv4 address allocated or a NAT gateway. NAT gateways can become quite pricey.</p>

<p>I would love to become complete IPv6 native, but AWS needs to provide IPv6 endpoints for all their major services.</p>

<p>Making this post to raise visibility before IPv4 fees start next year.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>