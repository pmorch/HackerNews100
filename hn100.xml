<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 29 May 2024 08:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[What We Learned from a Year of Building with LLMs (109 pts)]]></title>
            <link>https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/</link>
            <guid>40508390</guid>
            <pubDate>Wed, 29 May 2024 04:14:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/">https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/</a>, See on <a href="https://news.ycombinator.com/item?id=40508390">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

              
              
              
              
              
              




<div itemscope="" itemtype="http://schema.org/Product" id="trial-cta">
  <p><a href="https://www.oreilly.com/online-learning/">
      <img itemprop="image" src="https://d3ansictanv2wj.cloudfront.net/safari-topic-cta-1f60e6f96856da19ba3cb25660472ca5.jpg">
    </a>
  </p>
  <p>
    <h2>
      Learn faster. Dig deeper. See farther.
    </h2>
  </p>
   
</div>



<p>It‚Äôs an exciting time to build with large language models (LLMs). Over the past year, LLMs have become ‚Äúgood enough‚Äù for real-world applications. The pace of improvements in LLMs, coupled with a parade of demos on social media, will fuel an estimated $200B investment in AI by 2025. LLMs are also broadly accessible, allowing everyone, not just ML engineers and scientists, to build intelligence into their products. While the barrier to entry for building AI products has been lowered, creating those effective beyond a demo remains a deceptively difficult endeavor.</p>



<p>We‚Äôve identified some crucial, yet often neglected, lessons and methodologies informed by machine learning that are essential for developing products based on LLMs. Awareness of these concepts can give you a competitive advantage against most others in the field without requiring ML expertise! Over the past year, the six of us have been building real-world applications on top of LLMs. We realized that there was a need to distill these lessons in one place for the benefit of the community.</p>



<p>We come from a variety of backgrounds and serve in different roles, but we‚Äôve all experienced firsthand the challenges that come with using this new technology. Two of us are independent consultants who‚Äôve helped numerous clients take LLM projects from initial concept to successful product, seeing the patterns determining success or failure. One of us is a researcher studying how ML/AI teams work and how to improve their workflows. Two of us are leaders on applied AI teams: one at a tech giant and one at a startup. Finally, one of us has taught deep learning to thousands and now works on making AI tooling and infrastructure easier to use. Despite our different experiences, we were struck by the consistent themes in the lessons we‚Äôve learned, and we‚Äôre surprised that these insights aren‚Äôt more widely discussed.</p>



<p>Our goal is to make this a practical guide to building successful products around LLMs, drawing from our own experiences and pointing to examples from around the industry. We‚Äôve spent the past year getting our hands dirty and gaining valuable lessons, often the hard way. While we don‚Äôt claim to speak for the entire industry, here we share some advice and lessons for anyone building products with LLMs.</p>



<p>This work is organized into three sections: tactical, operational, and strategic. This is the first of three pieces. It dives into the tactical nuts and bolts of working with LLMs. We share best practices and common pitfalls around prompting, setting up retrieval-augmented generation, applying flow engineering, and evaluation and monitoring. Whether you‚Äôre a practitioner building with LLMs or a hacker working on weekend projects, this section was written for you. Look out for the operational and strategic sections in the coming weeks.</p>



<p>Ready to <s>dive</s> delve in? Let‚Äôs go.</p>



<h2><strong>Tactical</strong></h2>



<p>In this section, we share best practices for the core components of the emerging LLM stack: prompting tips to improve quality and reliability, evaluation strategies to assess output, retrieval-augmented generation ideas to improve grounding, and more. We also explore how to design human-in-the-loop workflows. While the technology is still rapidly developing, we hope these lessons, the by-product of countless experiments we‚Äôve collectively run, will stand the test of time and help you build and ship robust LLM applications.</p>



<h3><strong>Prompting</strong></h3>



<p>We recommend starting with prompting when developing new applications. It‚Äôs easy to both underestimate <em>and</em> overestimate its importance. It‚Äôs underestimated because the right prompting techniques, when used correctly, can get us very far. It‚Äôs overestimated because even prompt-based applications require significant engineering around the prompt to work well.</p>



<h4><strong>Focus on getting the most out of fundamental prompting techniques</strong></h4>



<p>A few prompting techniques have consistently helped improve performance across various models and tasks: n-shot prompts + in-context learning, chain-of-thought, and providing relevant resources.</p>



<p>The idea of in-context learning via n-shot prompts is to provide the LLM with a few examples that demonstrate the task and align outputs to our expectations. A few tips: </p>



<ul><li>If n is too low, the model may over-anchor on those specific examples, hurting its ability to generalize. As a rule of thumb, aim for n ‚â• 5. Don‚Äôt be afraid to go as high as a few dozen.</li><li>Examples should be representative of the expected input distribution. If you‚Äôre building a movie summarizer, include samples from different genres in roughly the proportion you expect to see in practice.</li><li>You don‚Äôt necessarily need to provide the full input-output pairs. In many cases, examples of desired outputs are sufficient.</li><li>If you are using an LLM that supports tool use, your n-shot examples should also use the tools you want the agent to use.</li></ul>



<p>In chain-of-thought (CoT) prompting, we encourage the LLM to explain its thought process before returning the final answer. Think of it as providing the LLM with a sketchpad so it doesn‚Äôt have to do it all in memory. The original approach was to simply add the phrase ‚ÄúLet‚Äôs think step-by-step‚Äù as part of the instructions. However, we‚Äôve found it helpful to make the CoT more specific, where adding specificity via an extra sentence or two often reduces hallucination rates significantly. For example, when asking an LLM to summarize a meeting transcript, we can be explicit about the steps, such as:</p>



<ul><li>First, list the key decisions, follow-up items, and associated owners in a sketchpad.</li><li>Then, check that the details in the sketchpad are factually consistent with the transcript.</li><li>Finally, synthesize the key points into a concise summary.</li></ul>



<p>Recently, <a href="https://arxiv.org/abs/2405.04776" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">some doubt</a> has been cast on whether this technique is as powerful as believed. Additionally, there‚Äôs significant debate about exactly what happens during inference when chain-of-thought is used. Regardless, this technique is one to experiment with when possible.</p>



<p>Providing relevant resources is a powerful mechanism to expand the model‚Äôs knowledge base, reduce hallucinations, and increase the user‚Äôs trust. Often accomplished via retrieval augmented generation (RAG), providing the model with snippets of text that it can directly utilize in its response is an essential technique. When providing the relevant resources, it‚Äôs not enough to merely include them; don‚Äôt forget to tell the model to prioritize their use, refer to them directly, and sometimes to mention when none of the resources are sufficient. These help ‚Äúground‚Äù agent responses to a corpus of resources. </p>



<h4><strong>Structure your inputs and outputs</strong></h4>



<p>Structured input and output help models better understand the input as well as return output that can reliably integrate with downstream systems. Adding serialization formatting to your inputs can help provide more clues to the model as to the relationships between tokens in the context, additional metadata to specific tokens (like types), or relate the request to similar examples in the model‚Äôs training data. </p>



<p>As an example, many questions on the internet about writing SQL begin by specifying the SQL schema. Thus, you may expect that effective prompting for Text-to-SQL should include structured schema definitions; <a href="https://www.researchgate.net/publication/371223615_SQL-PaLM_Improved_Large_Language_ModelAdaptation_for_Text-to-SQL" target="_blank" rel="noreferrer noopener" aria-label="indeed (opens in a new tab)">indeed</a>.</p>



<p>Structured output serves a similar purpose, but it also simplifies integration into downstream components of your system. <a rel="noreferrer noopener" aria-label="Instructor (opens in a new tab)" href="https://github.com/jxnl/instructor" target="_blank">Instructor</a> and <a href="https://github.com/outlines-dev/outlines" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Outlines</a> work well for structured output. (If you‚Äôre importing an LLM API SDK, use Instructor; if you‚Äôre importing Huggingface for a self-hosted model, use Outlines.) Structured input expresses tasks clearly and resembles how the training data is formatted, increasing the probability of better output.</p>



<p>When using structured input, be aware that each LLM family has their own preferences. Claude prefers <code>xml</code> while GPT favors Markdown and JSON. With XML, you can even pre-fill Claude‚Äôs responses by providing a <code>response</code> tag like so.</p>



<pre>                                                     <code>&lt;/&gt; python
messages=[     
    {         
        "role": "user",         
        "content": """Extract the &lt;name&gt;, &lt;size&gt;, &lt;price&gt;, and &lt;color&gt; </code>
                   <code>from this product description into your &lt;response&gt;.   
                &lt;description&gt;The SmartHome Mini </code>
                   <code>is a compact smart home assistant </code>
                   <code>available in black or white for only $49.99. </code>
                   <code>At just 5 inches wide, it lets you control   </code>
                   <code>lights, thermostats, and other connected </code>
                   <code>devices via voice or app‚Äîno matter where you</code>
<code>                   place it in your home. This affordable little hub</code>
                  <code> brings convenient hands-free control to your</code>
                  <code> smart devices.             
                &lt;/description&gt;"""     
   },     
   {         
        "role": "assistant",         
        "content": "&lt;response&gt;&lt;name&gt;"     
   } 
]</code></pre>



<h4><strong>Have small prompts that do one thing, and only one thing, well</strong></h4>



<p>A common anti-pattern/code smell in software is the ‚Äú<a rel="noreferrer noopener" aria-label="God Object (opens in a new tab)" href="https://en.wikipedia.org/wiki/God_object" target="_blank">God Object</a>,‚Äù where we have a single class or function that does everything. The same applies to prompts too.</p>



<p>A prompt typically starts simple: A few sentences of instruction, a couple of examples, and we‚Äôre good to go. But as we try to improve performance and handle more edge cases, complexity creeps in. More instructions. Multi-step reasoning. Dozens of examples. Before we know it, our initially simple prompt is now a 2,000 token frankenstein. And to add injury to insult, it has worse performance on the more common and straightforward inputs! GoDaddy shared this challenge as their <a href="https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough" target="_blank" rel="noreferrer noopener" aria-label="No. 1 lesson from building with LLMs (opens in a new tab)">No. 1 lesson from building with LLMs</a>.</p>



<p>Just like how we strive (read: struggle) to keep our systems and code simple, so should we for our prompts. Instead of having a single, catch-all prompt for the meeting transcript summarizer, we can break it into steps to:</p>



<ul><li>Extract key decisions, action items, and owners into structured format</li><li>Check extracted details against the original transcription for consistency</li><li>Generate a concise summary from the structured details</li></ul>



<p>As a result, we‚Äôve split our single prompt into multiple prompts that are each simple, focused, and easy to understand. And by breaking them up, we can now iterate and eval each prompt individually.</p>



<h4><strong>Craft your context tokens</strong></h4>



<p>Rethink, and challenge your assumptions about how much context you actually need to send to the agent. Be like Michaelangelo, do not build up your context sculpture‚Äîchisel away the superfluous material until the sculpture is revealed. RAG is a popular way to collate all of the potentially relevant blocks of marble, but what are you doing to extract what‚Äôs necessary?</p>



<p>We‚Äôve found that taking the final prompt sent to the model‚Äîwith all of the context construction, and meta-prompting, and RAG results‚Äîputting it on a blank page and just reading it, really helps you rethink your context. We have found redundancy, self-contradictory language, and poor formatting using this method. </p>



<p>The other key optimization is the structure of your context. Your bag-of-docs representation isn‚Äôt helpful for humans, don‚Äôt assume it‚Äôs any good for agents. Think carefully about how you structure your context to underscore the relationships between parts of it, and make extraction as simple as possible.</p>



<h3><strong>Information Retrieval/RAG</strong></h3>



<p>Beyond prompting, another effective way to steer an LLM is by providing knowledge as part of the prompt. This grounds the LLM on the provided context which is then used for in-context learning. This is known as retrieval-augmented generation (RAG). Practitioners have found RAG effective at providing knowledge and improving output, while requiring far less effort and cost compared to finetuning.RAG is only as good as the retrieved documents‚Äô relevance, density, and detail</p>



<h4><strong>The quality of your RAG‚Äôs output is dependent on the quality of retrieved documents, which in turn can be considered along a few factors.</strong></h4>



<p>The first and most obvious metric is relevance. This is typically quantified via ranking metrics such as <a rel="noreferrer noopener" aria-label="Mean Reciprocal Rank (MRR) (opens in a new tab)" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank" target="_blank">Mean Reciprocal Rank (MRR)</a> or <a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain" target="_blank" rel="noreferrer noopener" aria-label="Normalized Discounted Cumulative Gain (NDCG) (opens in a new tab)">Normalized Discounted Cumulative Gain (NDCG)</a>. MRR evaluates how well a system places the first relevant result in a ranked list while NDCG considers the relevance of all the results and their positions. They measure how good the system is at ranking relevant documents higher and irrelevant documents lower. For example, if we‚Äôre retrieving user summaries to generate movie review summaries, we‚Äôll want to rank reviews for the specific movie higher while excluding reviews for other movies.</p>



<p>Like traditional recommendation systems, the rank of retrieved items will have a significant impact on how the LLM performs on downstream tasks. To measure the impact, run a RAG-based task but with the retrieved items shuffled‚Äîhow does the RAG output perform?</p>



<p>Second, we also want to consider information density. If two documents are equally relevant, we should prefer one that‚Äôs more concise and has lesser extraneous details. Returning to our movie example, we might consider the movie transcript and all user reviews to be relevant in a broad sense. Nonetheless, the top-rated reviews and editorial reviews will likely be more dense in information.</p>



<p>Finally, consider the level of detail provided in the document. Imagine we‚Äôre building a RAG system to generate SQL queries from natural language. We could simply provide table schemas with column names as context. But, what if we include column descriptions and some representative values? The additional detail could help the LLM better understand the semantics of the table and thus generate more correct SQL.</p>



<h4><strong>Don‚Äôt forget keyword search; use it as a baseline and in hybrid search.</strong></h4>



<p>Given how prevalent the embedding-based RAG demo is, it‚Äôs easy to forget or overlook the decades of research and solutions in information retrieval.</p>



<p>Nonetheless, while embeddings are undoubtedly a powerful tool, they are not the be all and end all. First, while they excel at capturing high-level semantic similarity, they may struggle with more specific, keyword-based queries, like when users search for names (e.g., Ilya), acronyms (e.g., RAG), or IDs (e.g., claude-3-sonnet). Keyword-based search, such as BM25, are explicitly designed for this. And after years of keyword-based search, users have likely taken it for granted and may get frustrated if the document they expect to retrieve isn‚Äôt being returned. </p>



<blockquote><p>Vector embeddings <em>do not</em> magically solve search. In fact, the heavy lifting is in the step before you re-rank with semantic similarity search. Making a genuine improvement over BM25 or full-text search is hard. </p><cite>‚Äî <a href="https://x.com/AravSrinivas/status/1737886080555446552" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Aravind Srinivas, CEO Perplexity.ai</a></cite></blockquote>



<blockquote><p>We‚Äôve been communicating this to our customers and partners for months now. Nearest Neighbor Search with naive embeddings yields very noisy results and you‚Äôre likely better off starting with a keyword-based approach.</p><cite>‚Äî <a href="https://twitter.com/beyang/status/1767330006999720318" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Beyang Liu, CTO Sourcegraph</a></cite></blockquote>



<p>Second, it‚Äôs more straightforward to understand why a document was retrieved with keyword search‚Äîwe can look at the keywords that match the query. In contrast, embedding-based retrieval is less interpretable. Finally, thanks to systems like Lucene and OpenSearch that have been optimized and battle-tested over decades, keyword search is usually more computationally efficient.</p>



<p>In most cases, a hybrid will work best: keyword matching for the obvious matches, and embeddings for synonyms, hypernyms, and spelling errors, as well as multimodality (e.g., images and text). <a href="https://www.shortwave.com/blog/deep-dive-into-worlds-smartest-email-ai/" target="_blank" rel="noreferrer noopener" aria-label="Shortwave shared how they built their RAG pipeline (opens in a new tab)">Shortwave shared how they built their RAG pipeline</a>, including query rewriting, keyword + embedding retrieval, and ranking.</p>



<h4><strong>Prefer RAG over fine-tuning for new knowledge</strong></h4>



<p>Both RAG and fine-tuning can be used to incorporate new information into LLMs and increase performance on specific tasks. Thus, which should we try first?</p>



<p>Recent research suggests that RAG may have an edge. <a rel="noreferrer noopener" aria-label="One study (opens in a new tab)" href="https://arxiv.org/abs/2312.05934" target="_blank">One study</a> compared RAG against unsupervised fine-tuning (a.k.a. continued pre-training), evaluating both on a subset of MMLU and current events. They found that RAG consistently outperformed fine-tuning for knowledge encountered during training as well as entirely new knowledge. In <a rel="noreferrer noopener" aria-label="another paper (opens in a new tab)" href="https://arxiv.org/abs/2401.08406" target="_blank">another paper</a>, they compared RAG against supervised fine-tuning on an agricultural dataset. Similarly, the performance boost from RAG was greater than fine-tuning, especially for GPT-4 (see Table 20 of the paper).</p>



<p>Beyond improved performance, RAG comes with several practical advantages too. First, compared to continuous pretraining or fine-tuning, it‚Äôs easier‚Äîand cheaper!‚Äîto keep retrieval indices up-to-date. Second, if our retrieval indices have problematic documents that contain toxic or biased content, we can easily drop or modify the offending documents.</p>



<p>In addition, the R in RAG provides finer grained control over how we retrieve documents. For example, if we‚Äôre hosting a RAG system for multiple organizations, by partitioning the retrieval indices, we can ensure that each organization can only retrieve documents from their own index. This ensures that we don‚Äôt inadvertently expose information from one organization to another.</p>



<h4><strong>Long-context models won‚Äôt make RAG obsolete</strong></h4>



<p>With Gemini 1.5 providing context windows of up to 10M tokens in size, some have begun to question the future of RAG. </p>



<blockquote><p>I tend to believe that Gemini 1.5 is significantly overhyped by Sora. A context window of 10M tokens effectively makes most of existing RAG frameworks unnecessary‚Äîyou simply put whatever your data into the context and talk to the model like usual. Imagine how it does to all the startups/agents/LangChain projects where most of the engineering efforts goes to RAG üòÖ Or in one sentence: the 10m context kills RAG. Nice work Gemini.</p><cite>‚Äî <a href="https://x.com/Francis_YAO_/status/1758935954189115714" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Yao Fu</a></cite></blockquote>



<p>While it‚Äôs true that long contexts will be a game-changer for use cases such as analyzing multiple documents or chatting with PDFs, the rumors of RAG‚Äôs demise are greatly exaggerated.</p>



<p>First, even with a context window of 10M tokens, we‚Äôd still need a way to select information to feed into the model. Second, beyond the narrow needle-in-a-haystack eval, we‚Äôve yet to see convincing data that models can effectively reason over such a large context. Thus, without good retrieval (and ranking), we risk overwhelming the model with distractors, or may even fill the context window with completely irrelevant information.</p>



<p>Finally, there‚Äôs cost. The Transformer‚Äôs inference cost scales quadratically (or linearly in both space and time) with context length. Just because there exists a model that could read your organization‚Äôs entire Google Drive contents before answering each question doesn‚Äôt mean that‚Äôs a good idea. Consider an analogy to how we use RAM: we still read and write from disk, even though there exist compute instances with <a href="https://aws.amazon.com/ec2/instance-types/high-memory/" target="_blank" rel="noreferrer noopener" aria-label="RAM running into the tens of terabytes (opens in a new tab)">RAM running into the tens of terabytes</a>.</p>



<p>So don‚Äôt throw your RAGs in the trash just yet. This pattern will remain useful even as context windows grow in size.</p>



<h3><strong>Tuning and optimizing workflows</strong></h3>



<p>Prompting an LLM is just the beginning. To get the most juice out of them, we need to think beyond a single prompt and embrace workflows. For example, how could we split a single complex task into multiple simpler tasks? When is finetuning or caching helpful with increasing performance and reducing latency/cost? In this section, we share proven strategies and real-world examples to help you optimize and build reliable LLM workflows.</p>



<h4><strong>Step-by-step, multi-turn ‚Äúflows‚Äù can give large boosts.</strong></h4>



<p>We already know that by decomposing a single big prompt into multiple smaller prompts, we can achieve better results. An example of this is <a href="https://arxiv.org/abs/2401.08500" target="_blank" rel="noreferrer noopener" aria-label="AlphaCodium (opens in a new tab)">AlphaCodium</a>: By switching from a single prompt to a multi-step workflow, they increased GPT-4 accuracy (pass@5) on CodeContests from 19% to 44%. The workflow includes:</p>



<ul><li>Reflecting on the problem</li><li>Reasoning on the public tests</li><li>Generating possible solutions</li><li>Ranking possible solutions</li><li>Generating synthetic tests</li><li>Iterating on the solutions on public and synthetic tests.</li></ul>



<p>Small tasks with clear objectives make for the best agent or flow prompts. It‚Äôs not required that every agent prompt requests structured output, but structured outputs help a lot to interface with whatever system is orchestrating the agent‚Äôs interactions with the environment.</p>



<p>Some things to try</p>



<ul><li>An explicit planning step, as tightly specified as possible. Consider having predefined plans to choose from (c.f. https://youtu.be/hGXhFa3gzBs?si=gNEGYzux6TuB1del).</li><li>Rewriting the original user prompts into agent prompts. Be careful, this process is lossy!</li><li>Agent behaviors as linear chains, DAGs, and State-Machines; different dependency and logic relationships can be more and less appropriate for different scales. Can you squeeze performance optimization out of different task architectures?</li><li>Planning validations; your planning can include instructions on how to evaluate the responses from other agents to make sure the final assembly works well together.</li><li>Prompt engineering with fixed upstream state‚Äîmake sure your agent prompts are evaluated against a collection of variants of what may happen before.</li></ul>



<h4><strong>Prioritize deterministic workflows for now</strong></h4>



<p>While AI agents can dynamically react to user requests and the environment, their non-deterministic nature makes them a challenge to deploy. Each step an agent takes has a chance of failing, and the chances of recovering from the error are poor. Thus, the likelihood that an agent completes a multi-step task successfully decreases exponentially as the number of steps increases. As a result, teams building agents find it difficult to deploy reliable agents.</p>



<p>A promising approach is to have agent systems that produce deterministic plans which are then executed in a structured, reproducible way. In the first step, given a high-level goal or prompt, the agent generates a plan. Then, the plan is executed deterministically. This allows each step to be more predictable and reliable. Benefits include:</p>



<ul><li>Generated plans can serve as few-shot samples to prompt or finetune an agent.</li><li>Deterministic execution makes the system more reliable, and thus easier to test and debug. Furthermore, failures can be traced to the specific steps in the plan.</li><li>Generated plans can be represented as directed acyclic graphs (DAGs) which are easier, relative to a static prompt, to understand and adapt to new situations.</li></ul>



<p>The most successful agent builders may be those with strong experience managing junior engineers because the process of generating plans is similar to how we instruct and manage juniors. We give juniors clear goals and concrete plans, instead of vague open-ended directions, and we should do the same for our agents too. </p>



<p>In the end, the key to reliable, working agents will likely be found in adopting more structured, deterministic approaches, as well as collecting data to refine prompts and finetune models. Without this, we‚Äôll build agents that may work exceptionally well some of the time, but on average, disappoint users which leads to poor retention.</p>



<h4><strong>Getting more diverse outputs beyond temperature</strong></h4>



<p>Suppose your task requires diversity in an LLM‚Äôs output. Maybe you‚Äôre writing an LLM pipeline to suggest products to buy from your catalog given a list of products the user bought previously. When running your prompt multiple times, you might notice that the resulting recommendations are too similar‚Äîso you might increase the temperature parameter in your LLM requests.</p>



<p>Briefly, increasing the temperature parameter makes LLM responses more varied. At sampling time, the probability distributions of the next token become flatter, meaning that tokens which are usually less likely get chosen more often. Still, when increasing temperature, you may notice some failure modes related to output diversity. For example,Some products from the catalog that could be a good fit may never be output by the LLM.The same handful of products might be overrepresented in outputs, if they are highly likely to follow the prompt based on what the LLM has learned at training time.If the temperature is too high, you may get outputs that reference nonexistent products (or gibberish!)</p>



<p>In other words, increasing temperature does not guarantee that the LLM will sample outputs from the probability distribution you expect (e.g., uniform random). Nonetheless, we have other tricks to increase output diversity. The simplest way is to adjust elements within the prompt. For example, if the prompt template includes a list of items, such as historical purchases, shuffling the order of these items each time they‚Äôre inserted into the prompt can make a significant difference. </p>



<p>Additionally, keeping a short list of recent outputs can help prevent redundancy. In our recommended products example, by instructing the LLM to avoid suggesting items from this recent list, or by rejecting and resampling outputs that are similar to recent suggestions, we can further diversify the responses. Another effective strategy is to vary the phrasing used in the prompts. For instance, incorporating phrases like ‚Äúpick an item that the user would love using regularly‚Äù or ‚Äúselect a product that the user would likely recommend to friends‚Äù can shift the focus and thereby influence the variety of recommended products.</p>



<h4><strong>Caching is underrated.</strong></h4>



<p>Caching saves cost and eliminates generation latency by removing the need to recompute responses for the same input. Furthermore, if a response has previously been guardrailed, we can serve these vetted responses and reduce the risk of serving harmful or inappropriate content.</p>



<p>One straightforward approach to caching is to use unique IDs for the items being processed, such as if we‚Äôre summarizing new articles or <a href="https://www.cnbc.com/2023/06/12/amazon-is-using-generative-ai-to-summarize-product-reviews.html" target="_blank" rel="noreferrer noopener" aria-label="product reviews (opens in a new tab)">product reviews</a>. When a request comes in, we can check to see if a summary already exists in the cache. If so, we can return it immediately; if not, we generate, guardrail, and serve it, and then store it in the cache for future requests.</p>



<p>For more open-ended queries, we can borrow techniques from the field of search, which also leverages caching for open-ended inputs. Features like autocomplete and spelling correction also help normalize user input and thus increase the cache hit rate.</p>



<h4><strong>When to fine-tune</strong></h4>



<p>We may have some tasks where even the most cleverly designed prompts fall short. For example, even after significant prompt engineering, our system may still be a ways from returning reliable, high-quality output. If so, then it may be necessary to finetune a model for your specific task. </p>



<p>Successful examples include:</p>



<ul><li><a rel="noreferrer noopener" aria-label="Honeycomb's Natural Language Query Assistant (opens in a new tab)" href="https://www.honeycomb.io/blog/introducing-query-assistant" target="_blank">Honeycomb‚Äôs Natural Language Query Assistant</a>: Initially, the ‚Äúprogramming manual‚Äù was provided in the prompt together with n-shot examples for in-context learning. While this worked decently, fine-tuning the model led to better output on the syntax and rules of the domain-specific language.</li><li><a href="https://www.youtube.com/watch?v=B_DMMlDuJB0" target="_blank" rel="noreferrer noopener" aria-label="ReChat's Lucy (opens in a new tab)">ReChat‚Äôs Lucy</a>: The LLM needed to generate responses in a very specific format that combined structured and unstructured data for the frontend to render correctly. Fine-tuning was essential to get it to work consistently.</li></ul>



<p>Nonetheless, while fine-tuning can be effective, it comes with significant costs. We have to annotate fine-tuning data, finetune and evaluate models, and eventually self-host them. Thus, consider if the higher upfront cost is worth it. If prompting gets you 90% of the way there, then fine-tuning may not be worth the investment. However, if we do decide to fine-tune, to reduce the cost of collecting human annotated data, we can <a rel="noreferrer noopener" aria-label="generate and finetune on synthetic data (opens in a new tab)" href="https://eugeneyan.com/writing/synthetic/" target="_blank">generate and finetune on synthetic data</a>, or <a rel="noreferrer noopener" aria-label="bootstrap on open-source data (opens in a new tab)" href="https://eugeneyan.com/writing/finetuning/" target="_blank">bootstrap on open-source data</a>.</p>



<h3><strong> Evaluation &amp; Monitoring</strong></h3>



<p>Evaluating LLMs can be a minefield. The inputs and the outputs of LLMs are arbitrary text, and the tasks we set them to are varied. Nonetheless, rigorous and thoughtful evals are critical‚Äîit‚Äôs no coincidence that technical leaders at OpenAI <a rel="noreferrer noopener" aria-label="work on evaluation and give feedback on individual evals (opens in a new tab)" href="https://twitter.com/eugeneyan/status/1701692908074873036" target="_blank">work on evaluation and give feedback on individual evals</a>. </p>



<p>Evaluating LLM applications invites a diversity of definitions and reductions: it‚Äôs simply unit testing, or it‚Äôs more like observability, or maybe it‚Äôs just data science. We have found all of these perspectives useful. In the following section, we provide some lessons we‚Äôve learned about what is important in building evals and monitoring pipelines.</p>



<h4><strong>Create a few assertion-based unit tests from real input/output samples</strong></h4>



<p>Create <a rel="noreferrer noopener" aria-label="unit tests (i.e., assertions) (opens in a new tab)" href="https://hamel.dev/blog/posts/evals/#level-1-unit-tests" target="_blank">unit tests (i.e., assertions)</a> consisting of samples of inputs and outputs from production, with expectations for outputs based on at least three criteria. While three criteria might seem arbitrary, it‚Äôs a practical number to start with; fewer might indicate that your task isn‚Äôt sufficiently defined or is too open-ended, like a general-purpose chatbot. These unit tests, or assertions, should be triggered by any changes to the pipeline, whether it‚Äôs editing a prompt, adding new context via RAG, or other modifications. This <a rel="noreferrer noopener" aria-label="write-up has an example (opens in a new tab)" href="https://hamel.dev/blog/posts/evals/#step-1-write-scoped-tests" target="_blank">write-up has an example</a> of an assertion-based test for an actual use case.</p>



<p>Consider beginning with assertions that specify phrases or ideas to either include or exclude in all responses. Also consider checks to ensure that word, item, or sentence counts lie within a range. For other kinds of generation, assertions can look different. <a rel="noreferrer noopener" aria-label="Execution-evaluation (opens in a new tab)" href="https://www.semanticscholar.org/paper/Execution-Based-Evaluation-for-Open-Domain-Code-Wang-Zhou/1bed34f2c23b97fd18de359cf62cd92b3ba612c3" target="_blank">Execution-evaluation</a> is a powerful method for evaluating code-generation, wherein you run the generated code and determine that the state of runtime is sufficient for the user-request. </p>



<p>As an example, if the user asks for a new function named foo; then after executing the agent‚Äôs generated code, foo should be callable! One challenge in execution-evaluation is that the agent code frequently leaves the runtime in slightly different form than the target code. It can be effective to ‚Äúrelax‚Äù assertions to the absolute most weak assumptions that any viable answer would satisfy.</p>



<p>Finally, using your product as intended for customers (i.e., ‚Äúdogfooding‚Äù) can provide insight into failure modes on real-world data. This approach not only helps identify potential weaknesses, but also provides a useful source of production samples that can be converted into evals.</p>



<h4><strong>LLM-as-Judge can work (somewhat), but it‚Äôs not a silver bullet</strong></h4>



<p>LLM-as-Judge, where we use a strong LLM to evaluate the output of other LLMs, has been met with skepticism by some. (Some of us were initially huge skeptics.) Nonetheless, when implemented well, LLM-as-Judge achieves decent correlation with human judgements, and can at least help build priors about how a new prompt or technique may perform. Specifically, when doing pairwise comparisons (e.g., control vs. treatment), LLM-as-Judge typically gets the direction right though the magnitude of the win/loss may be noisy.</p>



<p>Here are some suggestions to get the most out of LLM-as-Judge:</p>



<ul><li>Use pairwise comparisons: Instead of asking the LLM to score a single output on a <a rel="noreferrer noopener" aria-label="Likert (opens in a new tab)" href="https://en.wikipedia.org/wiki/Likert_scale" target="_blank">Likert</a> scale, present it with two options and ask it to select the better one. This tends to lead to more stable results.</li><li>Control for position bias: The order of options presented can bias the LLM‚Äôs decision. To mitigate this, do each pairwise comparison twice, swapping the order of pairs each time. Just be sure to attribute wins to the right option after swapping!</li><li>Allow for ties: In some cases, both options may be equally good. Thus, allow the LLM to declare a tie so it doesn‚Äôt have to arbitrarily pick a winner.</li><li>Use Chain-of-Thought: Asking the LLM to explain its decision before giving a final preference can increase eval reliability. As a bonus, this allows you to use a weaker but faster LLM and still achieve similar results. Because frequently this part of the pipeline is in batch mode, the extra latency from CoT isn‚Äôt a problem.</li><li>Control for response length: LLMs tend to bias toward longer responses. To mitigate this, ensure response pairs are similar in length.</li></ul>



<p>One particularly powerful application of LLM-as-Judge is checking a new prompting strategy against regression. If you have tracked a collection of production results, sometimes you can rerun those production examples with a new prompting strategy, and use LLM-as-Judge to quickly assess where the new strategy may suffer.</p>



<p>Here‚Äôs an example of a <a href="https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">simple but effective approach</a> to iterate on LLM-as-Judge, where we simply log the LLM response, judge‚Äôs critique (i.e., CoT), and final outcome. They are then reviewed with stakeholders to identify areas for improvement. Over three iterations, agreement with human and LLM improved from 68% to 94%!</p>



<figure><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2024/05/Picture1.png" alt="" width="800" height="229"></figure>



<p>LLM-as-Judge is not a silver bullet though. There are subtle aspects of language where even the strongest models fail to evaluate reliably. In addition, we‚Äôve found that <a rel="noreferrer noopener" aria-label="conventional classifiers (opens in a new tab)" href="https://eugeneyan.com/writing/finetuning/" target="_blank">conventional classifiers</a> and reward models can achieve higher accuracy than LLM-as-Judge, and with lower cost and latency. For code generation, LLM-as-Judge can be weaker than more direct evaluation strategies like execution-evaluation.</p>



<h4><strong>The ‚Äúintern test‚Äù for evaluating generations</strong></h4>



<p>We like to use the following ‚Äúintern test‚Äù when evaluating generations: If you took the exact input to the language model, including the context, and gave it to an average college student in the relevant major as a task, could they succeed? How long would it take?</p>



<p>If the answer is no because the LLM lacks the required knowledge, consider ways to enrich the context.</p>



<p>If the answer is no and we simply can‚Äôt improve the context to fix it, then we may have hit a task that‚Äôs too hard for contemporary LLMs.</p>



<p>If the answer is yes, but it would take a while, we can try to reduce the complexity of the task. Is it decomposable? Are there aspects of the task that can be made more templatized?</p>



<p>If the answer is yes, they would get it quickly, then it‚Äôs time to dig into the data. What‚Äôs the model doing wrong? Can we find a pattern of failures? Try asking the model to explain itself before or after it responds, to help you build a theory of mind. </p>



<h4><strong>Overemphasizing certain evals can hurt overall performance</strong></h4>



<blockquote><p>‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù </p><cite>‚Äî Goodhart‚Äôs Law</cite></blockquote>



<p>An example of this is the Needle-in-a-Haystack (NIAH) eval. The original eval helped quantify model recall as context sizes grew, as well as how recall is affected by needle position. However, it‚Äôs been so overemphasized that it‚Äôs featured as <a rel="noreferrer noopener" aria-label="Figure 1 for Gemini 1.5's report (opens in a new tab)" href="https://arxiv.org/abs/2403.05530" target="_blank">Figure 1 for Gemini 1.5‚Äôs report</a>. The eval involves inserting a specific phrase (‚ÄúThe special magic {city} number is: {number}‚Äù) into a long document which repeats the essays of Paul Graham, and then prompting the model to recall the magic number.</p>



<p>While some models achieve near-perfect recall, it‚Äôs questionable whether NIAH truly reflects the reasoning and recall abilities needed in real-world applications. Consider a more practical scenario: Given the transcript of an hour-long meeting, can the LLM summarize the key decisions and next steps, as well as correctly attribute each item to the relevant person? This task is more realistic, going beyond rote memorization and also considering the ability to parse complex discussions, identify relevant information, and synthesize summaries.</p>



<p>Here‚Äôs an example of a <a rel="noreferrer noopener" aria-label="practical NIAH eval (opens in a new tab)" href="https://observablehq.com/@shreyashankar/needle-in-the-real-world-experiments" target="_blank">practical NIAH eval</a>. Using <a rel="noreferrer noopener" aria-label="transcripts of doctor-patient video calls (opens in a new tab)" href="https://github.com/wyim/aci-bench/tree/main/data/challenge_data" target="_blank">transcripts of doctor-patient video calls</a>, the LLM is queried about the patient‚Äôs medication. It also includes a more challenging NIAH, inserting a phrase for random ingredients for pizza toppings, such as ‚Äú<em>The secret ingredients needed to build the perfect pizza are: Espresso-soaked dates, Lemon and Goat cheese.</em>‚Äù Recall was around 80% on the medication task and 30% on the pizza task.</p>



<figure><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2024/05/Picture2.png" alt=""></figure>



<p>Tangentially, an overemphasis on NIAH evals can lead to lower performance on extraction and summarization tasks. Because these LLMs are so finetuned to attend to every sentence, they may start to treat irrelevant details and distractors as important, thus including them in the final output (when they shouldn‚Äôt!)</p>



<p>This could also apply to other evals and use cases. For example, summarization. An emphasis on factual consistency could lead to summaries that are less specific (and thus less likely to be factually inconsistent) and possibly less relevant. Conversely, an emphasis on writing style and eloquence could lead to more flowery, marketing-type language that could introduce factual inconsistencies.</p>



<h4><strong>Simplify annotation to binary tasks or pairwise comparisons</strong></h4>



<p>Providing open-ended feedback or ratings for model output on a <a rel="noreferrer noopener" aria-label="Likert scale (opens in a new tab)" href="https://en.wikipedia.org/wiki/Likert_scale" target="_blank">Likert scale</a> is cognitively demanding. As a result, the data collected is more noisy‚Äîdue to variability among human raters‚Äîand thus less useful. A more effective approach is to simplify the task and reduce the cognitive burden on annotators. Two tasks that work well are binary classifications and pairwise comparisons.</p>



<p>In binary classifications, annotators are asked to make a simple yes-or-no judgment on the model‚Äôs output. They might be asked whether the generated summary is factually consistent with the source document, or whether the proposed response is relevant, or if it contains toxicity. Compared to the Likert scale, binary decisions are more precise, have higher consistency among raters, and lead to higher throughput. This was how <a rel="noreferrer noopener" aria-label="Doordash setup their labeling queues (opens in a new tab)" href="https://doordash.engineering/2020/08/28/overcome-the-cold-start-problem-in-menu-item-tagging/" target="_blank">Doordash setup their labeling queues</a> for tagging menu items though a tree of yes-no questions.</p>



<p>In pairwise comparisons, the annotator is presented with a pair of model responses and asked which is better. Because it‚Äôs easier for humans to say ‚ÄúA is better than B‚Äù than to assign an individual score to either A or B individually, this leads to faster and more reliable annotations (over Likert scales). At a <a rel="noreferrer noopener" aria-label="Llama2 meetup (opens in a new tab)" href="https://www.youtube.com/watch?v=CzR3OrOkM9w" target="_blank">Llama2 meetup</a>, Thomas Scialom, an author on the Llama2 paper, confirmed that pairwise-comparisons were faster and cheaper than collecting supervised finetuning data such as written responses. The former‚Äôs cost is $3.5 per unit while the latter‚Äôs cost is $25 per unit.</p>



<p>If you‚Äôre starting to write labeling guidelines, here are some <a rel="noreferrer noopener" aria-label="reference guidelines (opens in a new tab)" href="https://eugeneyan.com/writing/labeling-guidelines/" target="_blank">reference guidelines</a> from Google and Bing Search.</p>



<h4><strong>(Reference-free) evals and guardrails can be used interchangeably </strong></h4>



<p>Guardrails help to catch inappropriate or harmful content while evals help to measure the quality and accuracy of the model‚Äôs output. In the case of reference-free evals, they may be considered two sides of the same coin. Reference-free evals are evaluations that don‚Äôt rely on a ‚Äúgolden‚Äù reference, such as a human-written answer, and can assess the quality of output based solely on the input prompt and the model‚Äôs response.</p>



<p>Some examples of these are <a rel="noreferrer noopener" aria-label="summarization evals (opens in a new tab)" href="https://eugeneyan.com/writing/evals/#summarization-consistency-relevance-length" target="_blank">summarization evals</a>, where we only have to consider the input document to evaluate the summary on factual consistency and relevance. If the summary scores poorly on these metrics, we can choose not to display it to the user, effectively using the eval as a guardrail. Similarly, reference-free <a rel="noreferrer noopener" aria-label="translation evals (opens in a new tab)" href="https://eugeneyan.com/writing/evals/#translation-statistical--learned-evals-for-quality" target="_blank">translation evals</a> can assess the quality of a translation without needing a human-translated reference, again allowing us to use it as a guardrail.</p>



<h4><strong>LLMs will return output even when they shouldn‚Äôt</strong></h4>



<p>A key challenge when working with LLMs is that they‚Äôll often generate output even when they shouldn‚Äôt. This can lead to harmless but nonsensical responses, or more egregious defects like toxicity or dangerous content. For example, when asked to extract specific attributes or metadata from a document, an LLM may confidently return values even when those values don‚Äôt actually exist. Alternatively, the model may respond in a language other than English because we provided non-English documents in the context.</p>



<p>While we can try to prompt the LLM to return a ‚Äúnot applicable‚Äù or ‚Äúunknown‚Äù response, it‚Äôs not foolproof. Even when the log probabilities are available, they‚Äôre a poor indicator of output quality. While log probs indicate the likelihood of a token appearing in the output, they don‚Äôt necessarily reflect the correctness of the generated text. On the contrary, for instruction-tuned models that are trained to respond to queries and generate coherent response, log probabilities may not be well-calibrated. Thus, while a high log probability may indicate that the output is fluent and coherent, it doesn‚Äôt mean it‚Äôs accurate or relevant.</p>



<p>While careful prompt engineering can help to some extent, we should complement it with robust guardrails that detect and filter/regenerate undesired output. For example, OpenAI provides a <a rel="noreferrer noopener" aria-label="content moderation API (opens in a new tab)" href="https://platform.openai.com/docs/guides/moderation" target="_blank">content moderation API</a> that can identify unsafe responses such as hate speech, self-harm, or sexual output. Similarly, there are numerous packages for <a rel="noreferrer noopener" aria-label="detecting personally identifiable information (opens in a new tab)" href="https://github.com/topics/pii-detection" target="_blank">detecting personally identifiable information</a> (PII). One benefit is that guardrails are largely agnostic of the use case and can thus be applied broadly to all output in a given language. In addition, with precise retrieval, our system can deterministically respond ‚ÄúI don‚Äôt know‚Äù if there are no relevant documents.</p>



<p>A corollary here is that LLMs may fail to produce outputs when they are expected to. This can happen for various reasons, from straightforward issues like long tail latencies from API providers to more complex ones such as outputs being blocked by content moderation filters. As such, it‚Äôs important to consistently log inputs and (potentially a lack of) outputs for debugging and monitoring.</p>



<h4><strong>Hallucinations are a stubborn problem.</strong></h4>



<p>Unlike content safety or PII defects which have a lot of attention and thus seldom occur, factual inconsistencies are stubbornly persistent and more challenging to detect. They‚Äôre more common and occur at a baseline rate of 5 ‚Äì 10%, and from what we‚Äôve learned from LLM providers, it can be challenging to get it below 2%, even on simple tasks such as summarization.</p>



<p>To address this, we can combine prompt engineering (upstream of generation) and factual inconsistency guardrails (downstream of generation). For prompt engineering, techniques like CoT help reduce hallucination by getting the LLM to explain its reasoning before finally returning the output. Then, we can apply a <a rel="noreferrer noopener" aria-label="factual inconsistency guardrail (opens in a new tab)" href="https://eugeneyan.com/writing/finetuning/" target="_blank">factual inconsistency guardrail</a> to assess the factuality of summaries and filter or regenerate hallucinations. In some cases, hallucinations can be deterministically detected. When using resources from RAG retrieval, if the output is structured and identifies what the resources are, you should be able to manually verify they‚Äôre sourced from the input context.</p>



<h2><strong>About the authors</strong></h2>



<p><strong>Eugene Yan</strong> designs, builds, and operates machine learning systems that serve customers at scale. He‚Äôs currently a Senior Applied Scientist at Amazon where he builds RecSys serving millions of customers worldwide <a rel="noreferrer noopener" aria-label="RecSys 2022 keynote (opens in a new tab)" href="https://eugeneyan.com/speaking/recsys2022-keynote/" target="_blank">RecSys 2022 keynote</a> and applies LLMs to serve customers better <a rel="noreferrer noopener" aria-label="AI Eng Summit 2023 keynote (opens in a new tab)" href="https://eugeneyan.com/speaking/ai-eng-summit/" target="_blank">AI Eng Summit 2023 keynote</a>. Previously, he led machine learning at Lazada (acquired by Alibaba) and a Healthtech Series A. He writes &amp; speaks about ML, RecSys, LLMs, and engineering at <a rel="noreferrer noopener" aria-label="eugeneyan.com (opens in a new tab)" href="https://eugeneyan.com/" target="_blank">eugeneyan.com</a> and <a rel="noreferrer noopener" aria-label="ApplyingML.com (opens in a new tab)" href="https://applyingml.com/" target="_blank">ApplyingML.com</a>.</p>



<p><strong>Bryan Bischof</strong> is the Head of AI at Hex, where he leads the team of engineers building Magic‚Äîthe data science and analytics copilot. Bryan has worked all over the data stack leading teams in analytics, machine learning engineering, data platform engineering, and AI engineering. He started the data team at Blue Bottle Coffee, led several projects at Stitch Fix, and built the data teams at Weights and Biases. Bryan previously co-authored the book Building Production Recommendation Systems with O‚ÄôReilly, and teaches Data Science and Analytics in the graduate school at Rutgers. His Ph.D. is in pure mathematics. </p>



<p><strong>Charles Frye</strong> teaches people to build AI applications. After publishing research in <a rel="noreferrer noopener" aria-label="psychopharmacology (opens in a new tab)" href="https://pubmed.ncbi.nlm.nih.gov/24316346/" target="_blank">psychopharmacology</a> and <a rel="noreferrer noopener" aria-label="neurobiology (opens in a new tab)" href="https://journals.physiology.org/doi/full/10.1152/jn.00172.2016" target="_blank">neurobiology</a>, he got his Ph.D. at the University of California, Berkeley, for dissertation work on <a rel="noreferrer noopener" aria-label="neural network optimization (opens in a new tab)" href="https://arxiv.org/abs/2003.10397" target="_blank">neural network optimization</a>. He has taught thousands the entire stack of AI application development, from linear algebra fundamentals to GPU arcana and building defensible businesses, through educational and consulting work at Weights and Biases, <a rel="noreferrer noopener" aria-label="Full Stack Deep Learning (opens in a new tab)" href="https://fullstackdeeplearning.com/" target="_blank">Full Stack Deep Learning</a>, and Modal.</p>



<p><strong>Hamel Husain</strong> is a machine learning engineer with over 25 years of <a rel="noreferrer noopener" aria-label="experience (opens in a new tab)" href="https://www.linkedin.com/in/hamelhusain/" target="_blank">experience</a>. He has worked with innovative companies such as Airbnb and GitHub, which included <a rel="noreferrer noopener" aria-label="early LLM research used by OpenAI (opens in a new tab)" href="https://openai.com/index/introducing-text-and-code-embeddings#:~:text=models%20on%20the-,CodeSearchNet,),-evaluation%20suite%20where" target="_blank">early LLM research used by OpenAI</a> for code understanding. He has also led and contributed to numerous popular <a rel="noreferrer noopener" aria-label="open-source machine-learning tools (opens in a new tab)" href="https://hamel.dev/oss/opensource.html" target="_blank">open-source machine-learning tools</a>. Hamel is currently an <a rel="noreferrer noopener" aria-label="independent consultant (opens in a new tab)" href="https://hamel.dev/hire.html" target="_blank">independent consultant</a> helping companies operationalize Large Language Models (LLMs) to accelerate their AI product journey.</p>



<p><strong>Jason Liu</strong> is a distinguished machine learning <a rel="noreferrer noopener" aria-label="consultant (opens in a new tab)" href="https://jxnl.co/services/" target="_blank">consultant</a> known for leading teams to successfully ship AI products. Jason‚Äôs technical expertise covers personalization algorithms, search optimization, synthetic data generation, and MLOps systems. His experience includes companies like Stitchfix, where he created a recommendation framework and observability tools that handled 350 million daily requests. Additional roles have included Meta, NYU, and startups such as Limitless AI and Trunk Tools. </p>



<p><strong>Shreya Shankar</strong> is an ML engineer and PhD student in computer science at UC Berkeley. She was the first ML engineer at 2 startups, building AI-powered products from scratch that serve thousands of users daily. As a researcher, her work focuses on addressing data challenges in production ML systems through a human-centered approach. Her work has appeared in top data management and human-computer interaction venues like VLDB, SIGMOD, CIDR, and CSCW.</p>



<h2><strong>Contact Us</strong></h2>



<p>We would love to hear your thoughts on this post. You can contact us at <a rel="noreferrer noopener" aria-label="contact@applied-llms.org (opens in a new tab)" href="mailto:contact@applied-llms.org" target="_blank">contact@applied-llms.org</a>. Many of us are open to various forms of consulting and advisory. We will route you to the correct expert(s) upon contact with us if appropriate.</p>



<h2><strong>Acknowledgements</strong></h2>



<p>This series started as a conversation in a group chat, where Bryan quipped that he was inspired to write ‚ÄúA Year of AI Engineering.‚Äù Then, ‚ú®magic‚ú® happened in the group chat, and we were all inspired to chip in and share what we‚Äôve learned so far. </p>



<p>The authors would like to thank Eugene for leading the bulk of the document integration and overall structure in addition to a large proportion of the lessons. Additionally, for primary editing responsibilities and document direction. The authors would like to thank Bryan for the spark that led to this writeup, restructuring the write-up into tactical, operational, and strategic sections and their intros, and for pushing us to think bigger on how we could reach and help the community. The authors would like to thank Charles for his deep dives on cost and LLMOps, as well as weaving the lessons to make them more coherent and tighter‚Äîyou have him to thank for this being 30 instead of 40 pages! The authors appreciate Hamel and Jason for their insights from advising clients and being on the front lines, for their broad generalizable learnings from clients, and for deep knowledge of tools. And finally, thank you Shreya for reminding us of the importance of evals and rigorous production practices and for bringing her research and original results to this piece.</p>



<p>Finally, the authors would like to thank all the teams who so generously shared your challenges and lessons in your own write-ups which we‚Äôve referenced throughout this series, along with the AI communities for your vibrant participation and engagement with this group.</p>

                          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI headphones let you listen to a single person in crowd, by looking at them (274 pts)]]></title>
            <link>https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/</link>
            <guid>40508278</guid>
            <pubDate>Wed, 29 May 2024 03:52:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/">https://www.washington.edu/news/2024/05/23/ai-headphones-noise-cancelling-target-speech-hearing/</a>, See on <a href="https://news.ycombinator.com/item?id=40508278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main_content" tabindex="-1">

  			<p>
    <a href="http://www.washington.edu/news/category/engineering/" rel="category tag">Engineering</a>&nbsp; | &nbsp;<a href="http://www.washington.edu/news/category/news-releases/" rel="category tag">News releases</a>&nbsp; | &nbsp;<a href="http://www.washington.edu/news/category/research/" rel="category tag">Research</a>&nbsp; | &nbsp;<a href="http://www.washington.edu/news/category/technology/" rel="category tag">Technology</a>  </p>
  
<p>May 23, 2024</p>

  


  


<nav id="mobile-relative" aria-label="mobile menu"></nav>
<p><iframe title="AI headphones filter out noise so you hear one voice in a crowd" width="750" height="422" src="https://www.youtube.com/embed/ArGKgodEUSo?feature=oembed&amp;enablejsapi=1&amp;origin=https://www.washington.edu" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>Noise-canceling headphones have gotten very good at creating an auditory blank slate. But allowing certain sounds from a wearer‚Äôs environment through the erasure still challenges researchers. The latest edition of Apple‚Äôs AirPods Pro, for instance, <a href="https://www.cnbc.com/2023/09/18/airpods-pro-usb-c-hands-on-adaptive-audio-and-conversation-awareness.html">automatically adjusts sound levels</a> for wearers ‚Äî sensing when they‚Äôre in conversation, for instance ‚Äî but the user has little control over whom to listen to or when this happens.</p>
<p>A University of Washington team has developed an artificial intelligence system that lets a user wearing headphones look at a person speaking for three to five seconds to ‚Äúenroll‚Äù them. The system, called ‚ÄúTarget Speech Hearing,‚Äù then cancels all other sounds in the environment and plays just the enrolled speaker‚Äôs voice in real time even as the listener moves around in noisy places and no longer faces the speaker.</p>
<p>The team presented <a href="https://programs.sigchi.org/chi/2024/program/content/147319">its findings</a> May 14 in Honolulu at the ACM CHI Conference on Human Factors in Computing Systems. The <a href="https://github.com/vb000/LookOnceToHear">code for the proof-of-concept device</a> is available for others to build on. The system is not commercially available.</p>
<p>‚ÄúWe tend to think of AI now as web-based chatbots that answer questions,‚Äù said senior author <a href="https://homes.cs.washington.edu/~gshyam/">Shyam Gollakota</a>, a UW professor in the Paul G. Allen School of Computer Science &amp; Engineering. ‚ÄúBut in this project, we develop AI to modify the auditory perception of anyone wearing headphones, given their preferences. With our devices you can now hear a single speaker clearly even if you are in a noisy environment with lots of other people talking.‚Äù</p>
<p>To use the system, a person wearing off-the-shelf headphones fitted with microphones taps a button while directing their head at someone talking. The sound waves from that speaker‚Äôs voice then should reach the microphones on both sides of the headset simultaneously; there‚Äôs a 16-degree margin of error. The headphones send that signal to an on-board embedded<a href="https://en.wikipedia.org/wiki/Single-board_computer"> computer</a>, where the team‚Äôs machine learning software learns the desired speaker‚Äôs vocal patterns. The system latches onto that speaker‚Äôs voice and continues to play it back to the listener, even as the pair moves around. The system‚Äôs ability to focus on the enrolled voice improves as the speaker keeps talking, giving the system more training data.</p>
<div>
<p><strong>Related:</strong></p>
<ul>
<li>For more information, see <a href="https://tsh.cs.washington.edu/">the team‚Äôs website</a></li>
<li>Stories from <a href="https://www.technologyreview.com/2024/05/23/1092832/noise-canceling-headphones-use-ai-to-let-a-single-voice-through/">MIT Technology Review </a>and <a href="https://www.geekwire.com/2024/look-and-listen-ai-headphones-cancel-background-noise-and-focus-on-one-speaker-after-a-glance/">GeekWire</a></li>
</ul>
</div>
<p>The team tested its system on 21 subjects, who rated the clarity of the enrolled speaker‚Äôs voice nearly twice as high as the unfiltered audio on average.</p>
<p>This work builds on the <a href="https://www.washington.edu/news/2023/11/09/ai-noise-canceling-headphones/">team‚Äôs previous ‚Äúsemantic hearing‚Äù research</a>, which allowed users to select specific sound classes ‚Äî such as birds or voices ‚Äî that they wanted to hear and canceled other sounds in the environment.</p>
<p>Currently the TSH system can enroll only one speaker at a time, and it‚Äôs only able to enroll a speaker when there is not another loud voice coming from the same direction as the target speaker‚Äôs voice. If a user isn‚Äôt happy with the sound quality, they can run another enrollment on the speaker to improve the clarity.</p>
<p>The team is working to expand the system to earbuds and hearing aids in the future.</p>
<p>Additional co-authors on the paper were <a href="https://homes.cs.washington.edu/~bandhav/">Bandhav Veluri</a>, <a href="https://www.linkedin.com/in/malek-itani-9311ba197/?originalSubdomain=lb">Malek Itani</a> and <a href="https://staff.washington.edu/tuochao/">Tuochao Chen</a>, UW doctoral students in the Allen School, and <a href="https://www.linkedin.com/in/ty274/">Takuya Yoshioka</a>, director of research at AssemblyAI. This research was funded by a <a href="https://www.washington.edu/news/2021/10/04/uws-shyam-gollakota-named-2021-moore-inventor-fellow/">Moore Inventor Fellow</a> award, a <a href="https://www.cs.washington.edu/supportcse/faculty/wrf-cable_professorship">Thomas J. Cabel Endowed Professorship</a> and a <a href="https://comotion.uw.edu/funding-and-competitions/programs/comotion-innovation-gap-fund/">UW CoMotion Innovation Gap Fund</a>.</p>
<p><em>For more information, contact </em><a href="mailto:tsh@cs.washington.edu"><em>tsh@cs.washington.edu</em></a><em>.</em></p>


<p><small>Tag(s): <a href="https://www.washington.edu/news/tag/bandhav-veluri/" rel="tag">Bandhav Veluri</a> ‚Ä¢ <a href="https://www.washington.edu/news/tag/college-of-engineering/" rel="tag">College of Engineering</a> ‚Ä¢ <a href="https://www.washington.edu/news/tag/department-of-electrical-computer-engineering/" rel="tag">Department of Electrical &amp; Computer Engineering</a> ‚Ä¢ <a href="https://www.washington.edu/news/tag/malek-itani/" rel="tag">Malek Itani</a> ‚Ä¢ <a href="https://www.washington.edu/news/tag/paul-g-allen-school-of-computer-science-engineering/" rel="tag">Paul G. Allen School of Computer Science &amp; Engineering</a> ‚Ä¢ <a href="https://www.washington.edu/news/tag/shyam-gollakota/" rel="tag">Shyam Gollakota</a> ‚Ä¢ <a href="https://www.washington.edu/news/tag/tuochao-chen/" rel="tag">Tuochao Chen</a></small></p><hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ex-OpenAI board member reveals what led to Sam Altman's brief ousting (569 pts)]]></title>
            <link>https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5</link>
            <guid>40506582</guid>
            <pubDate>Tue, 28 May 2024 23:13:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5">https://www.businessinsider.com/openai-board-member-details-sam-altman-lied-allegation-ousted-2024-5</a>, See on <a href="https://news.ycombinator.com/item?id=40506582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>She said that Altman was "withholding information" and "misrepresenting things that were happening in the company" for years.</p><div><p>Toner ‚Äî one of the board members who voted to kick Altman out ‚Äî alleged Altman also lied to the board by keeping them in the dark about the company's ownership structure. </p><p>"Sam didn't inform the board that he owned the OpenAI startup fund, even though he constantly was claiming to be an independent board member with no financial interest in the company," she said.</p></div><section data-component-type="content-recommendations" data-component-location="" data-delay-third-party-scripts="true" data-provider="dad" data-excluded-verticals="bi-video" data-premium-state="" data-renderer="three-related-posts" data-size="3" data-container-name="content-recommendations-three-related-posts-in-content" data-theme-class="" data-recommendations-placement="" data-author="" data-root-margin="250px 0px" data-track-view="{&quot;event&quot;: &quot;module_in_view&quot;, &quot;eventCategory&quot;: &quot;in_content_recirc&quot;, &quot;eventAction&quot;: &quot;module_in_view&quot;, &quot;eventLabel&quot;: &quot;module_in_view&quot;, &quot;element_name&quot;: &quot;in_content_recirc&quot;, &quot;subscription_experience&quot;: &quot;bi_value_unassigned&quot;, &quot;product_field&quot;: &quot;bi_value_unassigned&quot;}">
                            <p>
                                Related stories
                              </p>
                        
                          
                        </section><p>Altman keeping that from the board "really damaged our ability to trust him" and that the board was "already talking pretty seriously about whether we needed to fire him" in October, she said.</p><p>OpenAI didn't immediately respond to a request for comment from Business Insider. </p><p>Toner ‚Äî currently a director of strategy at the Centre for Security and Emerging Technology at Georgetown ‚Äî alleges the OpenAI chief also gave board members "inaccurate information about the small number of formal safety processes" OpenAI had in place.  </p><p>She said that made it "basically impossible" for the board to understand if the safety measures were sufficient or if any changes were needed.</p><div><p>She said there were other individual examples, but ultimately, the board concluded that "we just couldn't believe things that Sam was telling us, and that's a completely unworkable place to be in as a board." </p><p>Toner added that it was "totally impossible" for the board to trust Altman's word. The board, she said, had a role to have independent oversight of OpenAI and "not just helping the CEO to raise more money."</p><p>But then, last October, the board had a number of conversations where two executives detailed their own experiences with Altman in which they used the phrase "psychological abuse," according to Toner. </p><p>She said the executives told the board they "didn't think he was the right person to lead the company to AGI, telling us they had no belief that he could or would change, no point in giving him feedback, no point in trying to work through these issues."&nbsp;</p><p>By the time the board realized Altman needed replacing, Toner says it was clear that Altman would "pull out all the stops" to block the board from going against him if he found out. She claims he "started lying to other board members in order to try and push me off the board."</p><p>She said, "We were very careful, very deliberate about who we told, which was essentially almost no one in advance, other than obviously our legal team and so that's kind of what took us to to November 17." </p></div><p>But Altman's ouster didn't last long.</p><p>As staff threatened to quit and speculation swirled that Microsoft may poach Altman's team from OpenAI and hire him directly, the company's board brought back Altman as CEO less than a week later.</p><div><p>Toner resigned from her role as an OpenAI board member less than two weeks after Altman returned as CEO. </p><p><em>Do you work for OpenAI? Do you have insights to share? Contact the reporter at </em><a target="_blank" href="mailto:jmann@businessinsider.com" data-analytics-product-module="body_link" rel=" nofollow"><em>jmann@businessinsider.com</em></a> <em>or reach out via Signal</em> <em>at</em> <em>jyotimann.11</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google won‚Äôt comment on a leak of its search algorithm documentation (145 pts)]]></title>
            <link>https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo</link>
            <guid>40505310</guid>
            <pubDate>Tue, 28 May 2024 20:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo">https://www.theverge.com/2024/5/28/24166177/google-search-ranking-algorithm-leak-documents-link-seo</a>, See on <a href="https://news.ycombinator.com/item?id=40505310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Google‚Äôs search algorithm is perhaps the most consequential system on the internet, dictating <a href="https://www.theverge.com/2024/5/2/24147152/google-search-seo-publishing-housefresh-product-reviews">what sites live and die</a> and <a href="https://www.theverge.com/c/23998379/google-search-seo-algorithm-webpage-optimization">what content on the web looks like</a>. But how exactly Google ranks websites has long been a mystery, pieced together by journalists, researchers, and people working in search engine optimization.</p><p>Now, an explosive leak that purports to show <a href="https://sparktoro.com/blog/an-anonymous-source-shared-thousands-of-leaked-google-search-api-documents-with-me-everyone-in-seo-should-see-them/">thousands of pages of internal documents</a> appears to offer an unprecedented look under the hood of how Search works ‚Äî and suggests that Google hasn‚Äôt been entirely truthful about it for years. So far, Google hasn‚Äôt responded to multiple requests for comment on the legitimacy of the documents.</p><p>Rand Fishkin, who worked in SEO for more than a decade, says a source shared 2,500 pages of documents with him with the hopes that reporting on the leak would counter the ‚Äúlies‚Äù that Google employees had shared about how the search algorithm works. The documents outline Google‚Äôs search API and break down what information is available to employees, according to Fishkin.</p><p>The details shared by Fishkin are dense and technical, likely more legible to developers and SEO experts than the layperson. The contents of the leak are also not necessarily proof that Google uses the specific data and signals it mentions for search rankings. Rather, the leak outlines what data Google collects from webpages, sites, and searchers and offers indirect hints to SEO experts about what Google seems to care about, as SEO expert Mike King <a href="https://ipullrank.com/google-algo-leak">wrote</a> in his overview of the documents.</p><p>The leaked documents touch on topics like what kind of data Google collects and uses, which sites Google elevates for sensitive topics like elections, how Google handles small websites, and more. Some information in the documents appears to be in conflict with public statements by Google representatives, according to Fishkin and King. </p><p>‚Äú‚ÄòLied‚Äô is harsh, but it‚Äôs the only accurate word to use here,‚Äù King writes. ‚ÄúWhile I don‚Äôt necessarily fault Google‚Äôs public representatives for protecting their proprietary information, I do take issue with their efforts to actively discredit people in the marketing, tech, and journalism worlds who have presented reproducible discoveries.‚Äù</p><p>Google has not responded to <em>The Verge‚Äô</em>s requests for comment<em> </em>regarding the documents, including a direct request to refute their legitimacy. Fishkin told <em>The Verge </em>in an email that the company has not disputed the veracity of the leak, but that an employee asked him to change some language in the post regarding how an event was characterized.</p><p>Google‚Äôs secretive search algorithm has <a href="https://www.theverge.com/features/23931789/seo-search-engine-optimization-experts-google-results">birthed an entire industry</a> of marketers who closely follow Google‚Äôs public guidance and execute it for millions of companies around the world. The pervasive, often annoying tactics have led to a general narrative that Google Search results are getting worse, crowded with junk that website operators <a href="https://www.theverge.com/23753963/google-seo-shopify-small-business-ai">feel required to produce</a> to have their sites seen. In response to <em>The Verge</em>‚Äôs past reporting on the SEO-driven tactics, Google representatives often fall back to a familiar defense: that‚Äôs not what the <a href="https://developers.google.com/search/docs/fundamentals/seo-starter-guide">Google guidelines</a> say. </p><p>But some details in the leaked documents call into question the accuracy of Google‚Äôs public statements regarding how Search works. </p><p>One example cited by Fishkin and King is whether Google Chrome data is used in ranking at all. Google representatives have <a href="https://www.seroundtable.com/google-chrome-search-usage-15618.html">repeatedly</a> <a href="https://iloveseo.com/seo/google-does-not-use-anything-from-google-chrome-for-ranking/">indicated</a> that it doesn‚Äôt use Chrome data to rank pages, but Chrome is <a href="https://hexdocs.pm/google_api_content_warehouse/0.4.0/GoogleApi.ContentWarehouse.V1.Model.QualitySitemapTargetGroup.html#module-attributes">specifically mentioned in sections</a> about how websites appear in Search. In the screenshot below, which I captured as an example, the links appearing below the main vogue.com URL may be created in part using Chrome data, according to the documents.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="A Google Search screenshot of the Vogue.com result, with sublinks below the main homepage. The links direct to sections like ‚ÄúMet Gala 2024‚Äù and ‚ÄúBeauty.‚Äù" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/376x308/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/384x315/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/415x340/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/480x393/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/540x442/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/640x524/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/750x614/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/828x678/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1080x885/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1200x983/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1440x1180/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/1920x1573/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/2048x1678/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/2400x1966/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1284x1052/2400x1966/filters:focal(642x526:643x527):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25467524/Screenshot_2024_05_28_at_9.33.43_AM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Chrome is mentioned in a section about how additional links are created.</em></figcaption> <p><cite>Image: Google</cite></p></div></div><div><p>Another question raised is what role, if any, E-E-A-T plays in ranking. E-E-A-T stands for experience, expertise, authoritativeness, and trustworthiness, <a href="https://developers.google.com/search/blog/2022/12/google-raters-guidelines-e-e-a-t">a Google metric used to evaluate the quality of results</a>. Google representatives have <a href="https://x.com/searchliaison/status/1755283334631231514">previously said E-E-A-T isn‚Äôt a ranking factor</a>. Fishkin notes that he hasn‚Äôt found much in the documents mentioning E-E-A-T by name.</p></div><p>King, however, detailed how Google appears to collect author data from a page and has a field for whether an entity on the page is the author. A portion of the documents shared by King reads that the field was ‚Äúmainly developed and tuned for news articles... but is also populated for other content (e.g., scientific articles).‚Äù Though this doesn‚Äôt confirm that bylines are an explicit ranking metric, it does show that Google is at least keeping track of this attribute. Google representatives have <a href="https://x.com/searchliaison/status/1744379351297081637">previously insisted</a> that author bylines are something website owners should do for readers, not Google, because it doesn‚Äôt impact rankings.</p><p>Though the documents aren‚Äôt exactly a smoking gun, they provide a deep, unfiltered look at a tightly guarded black box system. The <a href="https://www.theverge.com/23869483/us-v-google-search-antitrust-case-updates">US government‚Äôs antitrust case against Google</a> ‚Äî which revolves around Search ‚Äî has also led to internal documentation becoming public, offering further insights into how the company‚Äôs main product works. </p><p>Google‚Äôs general caginess on how Search works has led to <a href="https://www.theverge.com/c/23998379/google-search-seo-algorithm-webpage-optimization">websites looking the same</a> as SEO marketers try to outsmart Google based on hints the company offers. Fishkin also calls out the publications credulously propping up Google‚Äôs public claims as truth without much further analysis.</p><p>‚ÄúHistorically, some of the search industry‚Äôs loudest voices and most prolific publishers have been happy to uncritically repeat Google‚Äôs public statements. They write headlines like ‚ÄòGoogle says XYZ is true,‚Äô rather than ‚ÄòGoogle Claims XYZ; Evidence Suggests Otherwise,‚Äô‚Äù Fishkin writes. ‚ÄúPlease, do better. If this leak and the DOJ trial can create just one change, I hope this is it.‚Äù</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shadama: A particle simulation programming environment for everyone (105 pts)]]></title>
            <link>https://tinlizzie.org/~ohshima/shadama2/live2017/</link>
            <guid>40505213</guid>
            <pubDate>Tue, 28 May 2024 20:25:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tinlizzie.org/~ohshima/shadama2/live2017/">https://tinlizzie.org/~ohshima/shadama2/live2017/</a>, See on <a href="https://news.ycombinator.com/item?id=40505213">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      
      <p>Yoshiki Ohshima, Dan Amelang and Bert Freudenberg<br>
      HARC/Y Combinator Research</p>

      <section id="abstract">
        <p>
We present a prototype of a programming system called Shadama.
Shadama is designed for writing programs that create, control and visualize large numbers of objects.
The basic execution model follows the tradition of StarLogo and its "turtles and patches" abstraction.
<label for="sn-starlogo">
</label>

<span>
<a href="#starlogo">
<i>Turtles, Termites, and Traffic Jams: Explorations in Massively Parallel Microworlds</i>
<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/starlogo-book.jpg" width="50%" height="50%">
</a>
</span>
&nbsp; This abstraction has been proven to be effective and easy to use.
The primary goal of the language is to facilitate the writing of scientific simulations by students
at the high school level.
        </p>

        <p>
The Shadama environment supports <i>liveness</i>.
Once changes to the program are saved, the effect on the running simulation is immediate;
there is no need to restart the simulation.
        </p>
        <p>
Shadama programs are run on the GPU by means of code translation to the OpenGL Shading Language.
<label for="sn-glsl">
</label>

<span>
<a href="#glsl">The OpenGL Shading Language</a>
</span> &nbsp;
Program data resides entirely on the GPU, which enables high performance.
        </p>

        <p>
A prototype of Shadama can be found <a href="http://tinlizzie.org/~ohshima/shadama2">here</a>.
Be aware that Shadama requires WebGL 2 and is affected by the floating point precision provided
by your graphics card. Thus, it only works on certain computer systems.
From our experience, it seems to work better on computers with an AMD Radeon graphics
card and on Chrome or Firefox browsers.
</p>
      </section>
      <section>
        <h2>Introduction</h2>
        <p>
The computing power available to us today is astounding.  Achieving
one teraflop of performance was a milestone for a building-sized supercomputer in
the late '90s, but now we expect smart phones to reach this same milestone soon.
Computing performance will only continue to increase in the future.
        </p>
        <p>
But what are people using this power for?  Not to be critical, but
people are generally more interested in watching cat videos and
playing games than trying to invent self-piloting personal airplanes
or discover the graviton.

All joking aside, one of the big problems we face today is our
struggle to advance science literacy, even within a
technologically-advanced society.  We need the next
generation to embrace science more, not less.
        </p>
        <p>
We think now is a good time to redouble our efforts to provide
environments where students and even professional
programmers can more easily tap into the computing power that is available.
To this end, we have been working on a prototype of a
programming language intended for high school students to explore
scientific concepts.
        </p>
        <p>
  Science is about making the invisible visible.  One notable example
of an invisible yet important concept is molecules in a gas.  We would
like students to learn about this, not by rote memorization, but
through actual experiments and model-building.  With the help of
computers, students can make a dynamic model and understand it more
deeply.  This kind of environment will help students construct
knowledge by doing, in line with the constructivism philosophy of
education.
        </p>
</section>

<section>
        <h2 id="a-science-experiment">A Science Experiment</h2>
        <p>
Before introducing the Shadama programming environment, we first
give an example of a physics experiment that could also be modeled
and simulated on a computer.
</p>
<iframe width="640" height="360" src="https://www.youtube.com/embed/07D0nB3mgLA" frameborder="0" allowfullscreen=""></iframe>
<p>
This movie demonstrates a vacuum cannon.  The cannon is a six foot PVC
pipe connected to a vacuum pump.  We put a ping pong ball inside the pipe,
cover the ends with sturdy but breakable material (such as plastic plates),
and pump the air out.
        </p>
        <p>
The pump reduces the pressure inside the tube to about 20% of full atmospheric pressure.
        </p>
        <p>
When the end near the ping pong ball is broken open by a box cutter, the
air molecules that rush into the pipe move into the
low pressure space and the ping pong ball is pushed out the other end.
Our crude setup can accelerate the ball to a speed of over 200 meters per second
(about 60% of the speed of sound).  Others have built similar setups
that can achieve supersonic speed.
        </p>
        <p>
An interesting point to understand is that it is just movement of
molecules that is causing the ball to shoot out. It is not that the
vacuum is sucking molecules into the pipe.
</p>
<p>
The invisible molecules that cause the ball to shoot out can
be made ‚Äúvisible‚Äù in a sense not only through this physical experiment,
but also through a computer simulation that reproduces the same phenomenon.
Creating such simulations is the purpose of our programming environment.
          </p>
</section>

<section>
        <h2 id="language-goals">Language Goals</h2>

<p>
We had the following goals when designing Shadama:
</p><ul>
<li> Easy to learn</li>
<li> Openness</li>
<li> Support for large numbers of particles</li>
<li> Liveness</li>
</ul>


<p>
To make learning Shadama easy, we based our language on StarLogo,
whose turtles and patches approach has proved intuitive to young learners.
In addition, we expect students familiar with Scratch to
learn Shadama easily because of similarites in how object behavior
is programmed and how objects can sense values near them spatially.
</p>

<p>
To encourage openness, we designed Shadama to be capable of implementing
complex behavior in the language itself, with as few primitives as possible.
We think that a learning environment should be open
in the sense that a student should be able to see, change and understand
how the various parts of the system work.
Although many sophisticated scientific software packages and simulation environments
exist, they are presented as immutable black boxes,
which limits understanding and stifles curiousity.
When additional software support is required, it should be provided in the
end-user's programming language, and it should be capable of modification
within the end-user's environment.
</p>

<p>
To support large numbers of particles, we designed the language
to execute on graphics hardware. Graphics processors today
are capable of computing on massive amounts of data.
Unfortunately, this requires a trade-off between ease of use and
high performance because there are fundamental limitations in
the execution model of today's graphics hardware.
Although Shadama has some features to mitigate these limitations,
certain behaviors cannot be implemented.
</p>

<p>
To support liveness, we designed the Shadama environment to show
the effects of code changes immediately. Of course,
a running simulation should not be updated for each and every key stroke.
Instead, the user submits a batch of code changes for the environment
to apply.
</p>

</section>

<section>
        <h2 id="shadama-in-Action">Shadama in Action</h2>
        <p>
The following movie introduces our prototype programming environment through several examples.
For details on the language, see the appendix.
The script for the narration of the movie is included below.
You can pause the movie at any time to scroll through and read the script.
        </p>
  
  
  <hr>
</section>
<section>
        <h2 id="implementation">Implementation</h2>
</section>
<p>
Shadama is built on web technologies, including WebGL 2.0 and OpenGL
Shading Language version 3.0.
Our code translator is written in Ohm
<label for="sn-ohm">
</label>

<span>
<a href="#ohm">Ohm: A library and language for building parsers, interpreters, compilers, etc.</a>
</span>
and generates vertex shader, fragment shader and JavaScript code from the Shadama program.
All the values for a given breed and property are stored in a single OpenGL texture.
These textures are created with the OpenGL type "R32F", to match
their use as an array of floating-point scalar values.
The values for a given patch and property are similarly represented.
</p>
<p>
Shadama static functions are translated to Javascript code that
runs OpenGL shaders derived from the Shadama methods.
For each method, a vertex shader is generated to fetch property values
from textures and perform the computation required for that method.
A generated fragment shader stores the property values back
into textures, using the multiple render targets feature of OpenGL.
</p>

<section>
        
        <p>
Previously, one of the authors implemented a particle system called Kedama as an extension of Etoys.
<label for="sn-kedama">
</label>

<span>
<a href="#kedama">
Kedama: A GUI-Based Interactive Massively Parallel Particle Programming System.<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/kedama.png" width="50%" height="50%" alt="Kedama screenshot"></a><br>

</span> &nbsp;    Shadama can be considered an attempt to give the same idea new life.
Kedama's target audience was middle school children, while Shadama's target audience is high school students.
        </p>
        <p>
The biggest inspiration for Shadama (and Kedama) was Resnick's StarLogo.
As such, it provided the basis for the basic organization of objects in Shadama.
However, StarLogo has certain features that Shadama does not, as mentioned in the introduction.
        </p>
        <p>
Based on Extempore, Swift et al. created a live programming environment for physics.
<label for="sn-extempore-pic">
</label>

<span>
<a href="#extempore">Live Programming in Scientific Simulation<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/extempore-pic.png" width="50%" height="50%" alt="Extempore PIC demo screenshot"></a><br>
</span> &nbsp;
This environment brings dynamic code swapping and interactive data
inspection to a sophisticated and optimized particle-in-cell
simulation engine. The spirit of this work is much in line with ours,
although their environment uses a third-party engine that cannot be modified from this same environment.
This is a reflection of their focus on empowering scientific researchers.
Such users are already familiar with the concepts behind the simulation and
value the tight interaction offered by this approach.
While it is possible to rewrite parts of the third-party engine in Extempore,
this is beyond the ability of most users, especially our target audience.
</p>
<p>
Nicky Case's simulation construction environment represents an interesting point in the design space.
<label for="sn-emoji">
</label>

<span>
<a href="#emoji">Simulating the World (in Emoji)<br>
  <img src="https://tinlizzie.org/~ohshima/shadama2/live2017/emoji.png" width="50%" height="50%" alt="Simulation in Emoji screenshot"></a>
</span>  &nbsp;
The system features a user-friendly design for creating many types of open-ended models.
However, it is only designed to handle a few hundred particles and cells.
</p>
<p>
Programming the GPU from a high-level language is a hot topic.
<label for="sn-ikra">
</label>

<span>
<a href="#ikra">Object Support in an Array-based GPGPU Extension for Ruby</a>
</span>&nbsp;  Researchers in this area aim for better performance through
increasingly sophisticated compilation techniques and the use of the CUDA API to more directly access the GPU.
Ease of use is given little consideration.
The authors think that Shadama can occupy a unique position
by striking a better balance between performance and ease of use.
        </p>
        <p>
Some languages for programming massively parallel particle simulations
are based on visual programming blocks.
StarLogo Nova is a notable example.
<label for="sn-slnova">
</label>

<span>
<a href="#slnova">
StarLogo Nova: A Programming Environment For Students and Teachers to
Create 3D Games and Simulations for Understanding Complex Systems
</a>
</span>
Shadama is currently text-based because we feel that scientific simulations
can be naturally expressed with concise text.
However, we have not ruled out other possiblities for syntax,
including a visual representation of the program.
        </p>

        <p>
Although many simulation environments such as Liquid Fun
<label for="sn-liquidfun">
</label>

<span>
<a href="#liquidfun">LiquidFun: A 2D Rigid-body and Fluid Simulation C++ Library for Games Based Upon Box2D<br>
<img src="https://tinlizzie.org/~ohshima/shadama2/live2017/liquidfun.png" width="50%" height="50%" alt="LiquidFun screenshot"></a>
</span>
are available today, they do not provide an end-user language.
</p>

</section>

<section>
        <h2 id="conclusions-and-future-work">Conclusions and Future Work</h2>
        <p>
We have presented an early prototype of a language in
which users can make enlightening simulations and intricate visualizations.
The liveliness of the environment encourages an
exploratory style of programming that enables trying out different ideas quickly.
We have also discovered that such an interactive and graphical environment
can be motivating even as bugs appear because of the spectacular
unintentional visual effects that are produced.
        </p>
        <p>
We are considering various improvements to the system.  One major
addition would be to fully support simulations in 3D, not just 2D.
While computation in Shadama only uses scalar values and is agnostic to dimensionality,
the primitives and concepts the system currently provides only work well for 2D applications.
We will need new ideas to manage 3D spatial data.
        </p>
        <p>
We also plan to support more mathematical concepts, such as vectors and matrices.
While first-time users may not initially have use for such abstractions,
we would like them to eventually learn and use these powerful concepts.
Ideally, the environment would gradually introduce the user to new, more difficult approaches.
        </p>
        <p>
We would like to conclude this paper by stressing the importance of
education. Education raises our awareness and enables us to see our world from new perspectives.
In this way, we are empowered with new approaches to solve problems.
For the next generation to solve the challenges of the future, their science literacy
is imperative. Our aim with Shadama is to leverage the power and ubiquity of
computing devices to improve science literacy for high school students by providing an engaging, open
environment in which to explore scientific concepts.
        </p>
</section>

      <section>
        <h2>References</h2>
        <ol type="1">
          <li id="starlogo">
            Mitchel Resnick. <i>Turtles, Termites, and Traffic Jams: Explorations
            in Massively Parallel Microworlds</i>. MIT Press, Cambridge, MA, USA, 1994.
          </li>
          <li id="glsl">
            The OpenGL Shading Language
            (<a href="https://www.khronos.org/registry/OpenGL/index_gl.php">Khronos OpenGL Registry</a>)
          </li>
          <li id="ohm">
            Ohm: A library and language for building parsers, interpreters, compilers, etc.
            (<a href="https://ohmlang.github.io/">project page</a>)
          </li>
          <li id="kedama">
            Yoshiki Ohshima. Kedama: A GUI-based Interactive Massively Parallel Particle Programming System.
            In <i>2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC‚Äô05)</i>, pages 91‚Äì98, Sept 2005.
          </li>
          <li id="extempore">
            Ben Swift, Andrew Sorensen, Henry Gardner, Peter Davis, and Viktor K Decyk.
            Live Programming in Scientific Simulation. <i>Supercomputing Frontiers and Innovations</i>, 2(4):4‚Äì15, March 2015.
            (<a href="http://dx.doi.org/10.14529/jsfi150401">DOI</a>)
          </li>
          <li id="liquidfun">
            LiquidFun: A 2D Rigid-body and Fluid Simulation C++ Library for Games Based Upon Box2D
            (<a href="http://google.github.io/liquidfun/">project page</a>)
          </li>
          <li id="emoji">
            Nicky Case. Simulating the World (in Emoji)
            (<a href="http://ncase.me/simulating">project page</a>)
          </li>
          <li id="ikra">
            Matthias Springer and Hidehiko Masuhara. Object Support in an Array-based GPGPU Extension for Ruby.
            In <i>Proceedings of the 3rd ACM SIGPLAN International Workshop on
            Libraries, Languages, and Compilers for Array Programming</i>,
            ARRAY 2016, pages 25‚Äì31, New York, NY, USA, 2016.
          </li>
          <li id="slnova">
            StarLogo Nova: A Programming Environment For Students and Teachers to
            Create 3D Games and Simulations for Understanding Complex Systems
            (<a href="http://education.mit.edu/portfolio_page/starlogonova/">project page</a>)
          </li>
        </ol>
      </section>
<section>
        <h2 id="language">Appendix: A Primer for the Shadama Language</h2>

<p>
The Shadama language uses a turtles and patches abstraction, drawn from the tradition of StarLogo.
</p>

        <h3 id="breeds">Breeds</h3>
<p>
Turtles are organized into
"breeds".  Each breed has its own set of properties.
A breed is declared in a program with the "breed" statement.  For example:
</p>
<pre>breed MyBreed (x, y)
</pre>
<p>
The above creates a breed of turtle called <code>MyBreed</code>, and declares that each
turtle in the breed has individual properties <code>x</code> and <code>y</code>.
</p>
<p>
Currently, properties in Shadama can only be scalar floating-point numbers.
</p>
<p>
Methods provide turtle behavior. The <code>def</code> statement is used to define
methods, as follows:
</p>
<pre>def move() {
  this.x = this.x + 1;
  this.y = this.y + 1;
}
</pre>
<p>
As expected, when this method is invoked on a turtle, the
turtle's x and y properties are incremented by one.
</p>
<p>
Methods can only be invoked from static functions. Methods calls are made
by first specifying a breed, then the method name.
The method is applied to all turtles in the breed concurrently.
For example:
</p>
<pre>static step() {
  MyBreed.move();
}
</pre>
<p>
The <code>step</code> function above calls the <code>move</code> method on all turtles of the <code>MyBreed</code> breed.
</p>

<p>
Shadama provides many built-in features made available through primitive methods:
</p>
<ul>

<li> <pre>aBreed.setCount(count);</pre>
  <span>
  The <code>setCount</code> primitive sets the number of turtles in the breed.
For example:
</span>
<pre>static setup() {
  MyBreed.setCount(10000);
}
</pre>
<span>
Invoking this static function will set the number of <code>MyBreed</code> turtles to 10,000.
In the current implementation, the number of turtles in a breed is limited to
1024 √ó 1024, or about 1 million.
</span>
</li>

<li> <pre>aBreed.fillRandom(name, min, max);</pre>
<span>
  The <code>fillRandom</code> primitive sets the property specified by <code>name</code>
  to be a random number between <code>min</code>
  (inclusive) and <code>max</code> (exclusive) for each turtle in the breed.
  For example:
</span>
<pre>static setup() {
  MyBreed.setCount(10000);
  MyBreed.fillRandom("x", 0, 100);
}
</pre>
<span>
  The above will set each of the 10,000 turtles <code>x</code> property to be a
  random floating-point number between 0 and 100.
</span>
</li>

<li> <pre>aBreed.fillRandomDir(dxName, dyName);</pre>
<span>
  The <code>fillRandomDir</code> primitive generates random 2D unit vectors.
  This is done for each turtle, and the x and y components of the result are stored
  in the <code>dxName</code> and <code>dyName</code> properties of the turtles.
  For example:
</span>
<pre>static setup() {
  MyBreed.setCount(10000);
  MyBreed.fillRandomDir("dx", "dy");
}
</pre>
<span>
The above sets the <code>dx</code> and <code>dy</code> properties of the turtles with the x and y components of the randomly generated unit vectors.
</span>
</li>

<li> <pre>aBreed.fillSpace(xName, yName, xDim, yDim);</pre>
        <span>
The fillSpace primitive first sets the number of turtles in the breed
to be <code>xDim</code> √ó <code>yDim</code>.  Then, it places the turtles on integral 2D grid points
within the (0..<code>xDim</code>, 0..<code>yDim</code>) area, storing into the <code>xName</code> and <code>yName</code> turtle properties.
For example:
</span>
<pre>static setup() {
  MyBreed.fillSpace("x", "y", 100, 100);
}
</pre>
<span>
The above creates 10,000 turtles of the MyBreed breed, setting the turtle's <code>x</code> and <code>y</code> properties
to be the integral grid points spanning (0, 0) to (99, 99), inclusive.
</span>
</li>

<li> <pre>aBreed.fillImage(xName, yName, rName, gName, bName, aName, anImageData);</pre>
        <span>
  The fillImage primitive converts a 2D image into a breed of turtles.
  The <code>anImageData</code> argument is a Javascript ImageData object containing the data used
  to populate the breed. The turtle count is set to be <code>anImageData.width</code> √ó <code>anImageData.height</code>.
  Similar to <code>fillSpace</code>, the turtles are placed on the 2D grid points within the image extent.
  The turtle properties given by <code>rName</code>, <code>gName</code>, <code>bName</code>, and <code>aName</code> are populated with the RGBA
  color component values of the image. Note that while the color components in <code>anImageData</code> range
  from 0 and 255 (integral values), those values in Shadama will be normalized to range from 0.0 and 1.0,
  inclusive (floating-point).
  For example:
<pre>breed MyBreed (x, y, r, g, b, a)
static setup() {
  MyBreed.fillImage("x", "y", "r", "g", "b", "a", anImage);
}
</pre>
</span>
<span>
Static function variables, such as <code>anImage</code>, are described below.
</span>
</li></ul>

<h3 id="patches">Patches</h3>

<p>
A patch is a 2D set of cells that store values.
Patches are fixed size, 512 √ó 512 by default.
The following declares a patch:
</p><pre>patch Field (nx, ny)
</pre>

<p>
Each cell in this patch stores two values, <code>nx</code> and <code>ny</code>.
</p>

<p>
A patch can be manipulated by passing it as an argument to a method on a breed.
As the method is executed for each turtle, turtles can access the patch cell
nearest them. No other patch cells are available to them.
For example:
</p><pre>breed MyBreed (x, y, r, g, b, a)
patch Field (r, g, b, a)

def store(field) {
  field.r = this.r;
}

static setup() {
  MyBreed.fillImage("x", "y", "r", "g", "b", "a", anImage);
  MyBreed.store(Field);
}
</pre>

<p>
The above declares a patch called Field which is used as an argument to <code>store</code>.
When <code>store</code> is executed for each turtle in <code>MyBreed</code>, the turtle's <code>r</code> property
is stored in the <code>r</code> property of the nearest cell in Field.
</p>

<p>
A turtle can read values from patch cells as well.  For example:
</p><pre>def load(field) {
   this.r = field.r;
}
</pre>

<p>
When the above method is executed, each turtle reads the <code>r</code> property of the nearest patch cell
and stores the value into its own <code>r</code> property.
</p>
<p>
Methods can receive multiple patches as arguments.
For example:
</p><pre>patch Field1 (nx, ny, r, g, b, a)
patch Field2 (nx, ny, r, g, b, a)
def transfer(f1, f2) {
  f2.r = f1.r;
  f2.a = f1.a;
}
</pre>

<p>
The following code is also valid, and correctly swaps values between patches.
</p><pre>def swap(f1, f2) {
  f2.r = f1.r;
  f1.r = f2.r
}
</pre>


<h3 id="local-variables">Local Variables</h3>

<p>
The <code>var</code> statement declares a local variable within a method.
The scope of a local variables is the whole method,
regardless of where in the method it is declared.
In the same method, there can be no more than one declaration for a given variable name.
This is in contrast to variable declarations in JavaScript.
For example:
</p><pre>def average() {
  var avg = (this.x + this.y) / 2.0;
  this.x = avg;
  this.y = avg;
}
</pre>
<p>
The above code properly defines and uses a local variable called <code>avg</code>.
However, the following code would raise an error because the variable <code>diff</code> is declared in two places:
</p><pre>def gcd() {
  if (this.a &gt; this.b) {
    var diff = this.a - this.b;
    this.a = diff;
  } else {
    var diff = this.b - this.a;
    this.b = diff;
  }
</pre>

<p>
The variable declaration has to be manually hoisted, as follows:
</p><pre>def gcd() {
  var diff;
  if (this.a &gt; this.b) {
    diff = this.a - this.b;
    this.a = diff;
  } else {
    diff = this.b - this.a;
    this.b = diff;
  }
</pre>


<h3 id="static-function-variables">Static Function Variables</h3>

<p>
Static function variables are declared within static functions, also using the "var" statement.
Static function variables are not available to methods, but are visible to all static functions.
For example:
</p><pre>static setup() {
  var begin = 1;
}

static loop() {
  if (begin) {
    begin = 0;
  }
}
</pre>

<p>
The two static functions above refer to the same <code>begin</code> variable.
</p>

<p>
Shadama provides the following built-in static function variables:
</p><ul>
  <li>
    <code>mousemove</code>:
    An object whose <code>x</code> and <code>y</code> properties refer to the most recent mouse cursor location.
  </li>
  <li>
    <code>mousedown</code>:
    An object whose <code>x</code> and <code>y</code> properties refer to the most
    recent location where the user pressed the mouse button down.
  </li>
  <li>
    <code>mouseup</code>:
    An object whose <code>x</code> and <code>y</code> properties refer to the most
    recent location where the user lifted the mouse button up.
  </li>
  <li>
    <code>time</code>:
    The number of seconds elapsed since the last time the <code>setup</code> function was called (in floating-point).
  </li>
  <li>
    <code>width, height</code>:
    The width and height of the Shadama canvas.
  </li>
</ul>

<p>
Be aware that mouse event objects are JavaScript objects. Thus, they can't be passed to methods because
methods can only take scalar arguments.
</p>

<p>
There is one additional variable called <code>Display</code>
for invoking certain system primitives.

For example:
</p><pre>static loop() {
  Display.clear();
  MyPatch.draw();
}
</pre>
<p>
The above code clears the canvas and then draws <code>MyPatch</code> by calling the <code>draw</code> primitive.  <code>Display</code> has <code>loadProgram</code>, and <code>clear</code>.
</p>

<h3 id="parallelism-considerations">Parallelism Considerations</h3>
<p>
It's possible for two or more nearby turtles to write into the same patch cell.
Which value gets stored in the patch is non-deterministic.
</p>
<p>
Also, updates to turtle properties and patch properties are not visible until after the method is run.
Consider the following method:
</p><pre>def test() {
  if (this.r &gt; 0) {
     this.r = 0;
  } else {
     this.r = 1;
  }
  this.b = this.r;
}
</pre>

<p>
Even though the last line reads <code>this.b = this.r;</code>, the <code>r</code> property and <code>b</code> property will
not be equal after the invocation. This is because the update to the <code>r</code> property seen earlier does not take effect
until after the method call is finished. Thus, the <code>b</code> property will have the previous <code>r</code> value.
</p>

<p>
The properties <code>this.b</code> and <code>this.r</code> can have the same value
through the following use of a local variable:
</p><pre>def test() {
  var r = this.r;
  if (r &gt; 0) {
     r = 0;
  } else {
     r = 1;
  }
  this.r = r;
  this.b = r;
}
</pre>


<p>
A script can be started by calling <code>start</code> on it. Likewise, you can stop it <code>stop</code>, and execute it once with <code>step</code>.
</p>

<h3 id="control-structures">Control Structures</h3>
<p>
The <code>if</code> statement is the only control structure that Shadama supports.
Loops may be supported in a future version of Shadama because the OpenGL shader language version 3.0
does support variable-count loops.
</p>
<h3 id="primitive-functions">Primitive Functions</h3>
<p>

There are a number of primitive functions that can be called from methods.
Most of them actually result in a direct call to a GLSL built-in function.
For example:
</p><pre>def prims(x) {
  var c = cos(x);
  var s = step(0.5, x);
  var a = abs(x);
  var f = fract(x); // the fraction part of x

  this.r = c * s * a * f;
}
</pre>

<p>
The above code uses several primitive functions to compute a contrived value which
is then stored into the turtle's <code>r</code> property.
</p>

<h3 id="method-binding">Method Binding</h3>
<p>
Methods are not defined for any particular breed, but a given
method can only be applied to breeds that have the properties referenced
in the method.
For example:
</p><pre>breed A (x, r)
breed B (x, y, r, g)
breed C (r)

def set() {
  this.r = 1;
  this.x = 0;
}

static test() {
  A.set();
  B.set();
}
</pre>

<p>
The <code>set</code> method above can be called for both breed <code>A</code> and breed <code>B</code>.
This is the not the case for breed C because it does not have an <code>x</code> property, which is
referenced in <code>set</code>.
</p>

<h3 id="limitations">Limitations</h3>

<p>
The following are important limitations of the Shadama language.
</p>

<p>
Methods can not take breeds as arguments.
For example, the following code is invalid:
</p><pre>breed A (x, y)
breed B (x, y)

def hit(other) {
  var diff = other.x - this.x;
  ...
}

static step() {
  A.hit(B);
}
</pre>


<p>
The <code>step</code> function passes breed B as an argument to the <code>hit</code> method, which is not allowed.
Even if it were, it is not clear which turtle from breed <code>B</code> should
be bound to the argument <code>other</code>.
</p>

<p>
Another limitation is that a given method can either update the turtle's properties or
the patch's properties, but not both.
For example, the following code is invalid:
</p><pre>def test(field) {
  field.r = 1;
  this.r = 1;
}
</pre>


<p>
This limitation arises from limitations in WebGL itself. Future
versions of WebGL, and thus Shadama, may no longer have this restriction.
In the meantime, a workaround is to split the method into two methods ‚Äî one
for updating the patch and one for updating the turtle.
It is also possible that a future version of Shadama will automatically
perform this code transformation.
</p>

</section>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing an NVMe Driver in Rust [pdf] (133 pts)]]></title>
            <link>https://db.in.tum.de/~ellmann/theses/finished/24/pirhonen_writing_an_nvme_driver_in_rust.pdf</link>
            <guid>40505167</guid>
            <pubDate>Tue, 28 May 2024 20:21:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://db.in.tum.de/~ellmann/theses/finished/24/pirhonen_writing_an_nvme_driver_in_rust.pdf">https://db.in.tum.de/~ellmann/theses/finished/24/pirhonen_writing_an_nvme_driver_in_rust.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40505167">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3-V: Matching GPT4-V with a 100x smaller model and 500 dollars (366 pts)]]></title>
            <link>https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee</link>
            <guid>40505099</guid>
            <pubDate>Tue, 28 May 2024 20:16:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee">https://aksh-garg.medium.com/llama-3v-building-an-open-source-gpt-4v-competitor-in-under-500-7dd8f1f6c9ee</a>, See on <a href="https://news.ycombinator.com/item?id=40505099">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://aksh-garg.medium.com/?source=post_page-----7dd8f1f6c9ee--------------------------------"><div aria-hidden="false"><p><img alt="Aksh Garg" src="https://miro.medium.com/v2/resize:fill:88:88/1*OY2kCIbiKHX3y9S-JEZQJg.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><h2 id="216d"><strong>Overview</strong></h2><p id="14b9">Llama3 took the world by storm, outperforming GPT3.5 in almost all benchmarks and GPT4 on several. And then GPT4o came out, reclaiming the throne with its multimodal finesse. Today, we‚Äôre releasing something to change that: Llama3-V, the first-ever multimodal model built on top of Llama3. As a bonus, we train everything in under $500.</p><p id="9c85">How are the benchmarks you ask? We‚Äôll let the tables speak for themselves. We have a 10‚Äì20% boost over Llava, the current SOTA and most popular model for multimodal understanding. Additionally, we fair very comparably to the closed source models of 100x the size on all metrics except MMMU.</p><figure></figure><h2 id="b6f7"><strong>Check us out on:</strong></h2><p id="9871">‚Ä¢ ü§ó: <a href="https://huggingface.co/mustafaaljadery/llama3v/tree/main" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/mustafaaljadery/llama3v/</a></p><p id="9c17">‚Ä¢ Github: <a href="https://github.com/mustafaaljadery/llama3v" rel="noopener ugc nofollow" target="_blank">https://github.com/mustafaaljadery/llama3v</a></p><h2 id="7795">The rest of the article covers</h2><ul><li id="ce14">Model Architecture</li><li id="422f">Training Framework</li><li id="ca98">Systems Optimizations</li><li id="68e8">Summary</li></ul><h2 id="5f28"><strong>Model Architecture</strong></h2><p id="2a6d">The bulk of our engineering efforts go into making Llama3 understand visual information. To do so, we take an input image and embed it into a series of patch embeddings using the SigLIP model. These embeddings are then aligned with the textual tokens via a projection block, which applies two self-attention blocks to put the textual and visual embeddings in the same plane. Finally, the visual tokens from the projection block are prepended to the textual tokens and the joint representation is passed into Llama3, just as it normally would.</p><figure><figcaption>Llama3-V Architecture: We use SigLIP to embed our input image in patches. Then we train a projection block with two self-attention blocks to align our textual and visual tokens.</figcaption></figure><p id="93cc">The diagram above illustrates at a high-level how everything works. Now, let‚Äôs dive into each stage in detail.</p><p id="66fa"><strong>SigLIP</strong>: SigLIP (Sigmoid Loss for Language Image Pre-Training) is an image embedding model that is similar to CLIP as we see in the figure below. However, unlike CLIP which uses a contrastive loss with softmax normalization, SigLIP utilizes a pairwise sigmoid loss, which allows the model to operate independently on each image-text pair, without requiring a global view across all pairs in a batch. At a high-level, SigLIP‚Äôs vision encoder splits the image into a sequence of non-overlapping image patches and projects them into a lower-dimensional linear embedding space, producing a sequence of patch embeddings. These patch embeddings then go through a vision encoder, which applies self-attention to capture long-range dependencies and extract higher-level visual features. For our purposes, we directly use the original SigLIP model trained by Google DeepMind.</p><figure><figcaption>Illustration of how SigLIP embeddings work. We train an image and text decoder concurrently but in our case the text encoding module is kept fixed. Unlike CLIP, we minimize a sigmoid loss instead of a softmax loss but most other things stay the same. Image from <a href="https://x.com/mervenoyann/status/1745476609686089800/photo/1" rel="noopener ugc nofollow" target="_blank">twitter post </a>by Merve</figcaption></figure><p id="a1f8"><strong>Alignment with textual embeddings: </strong>To save computational resources, we keep SigLIP fixed. However, to align the output image embeddings with the textual embeddings used in Llama3, we use an extra projection module. Unlike Llava, which applies a single linear layer to the original image embeddings, we instead train two self-attention blocks to better capture patterns in the input embeddings, producing the final image embedding vector.</p><p id="fcd5"><strong>Prepending image tokens:</strong> For the textual inputs, we first tokenize the text using a Byte Pair Encoding (BPE) vocabulary, producing a sequence of textual tokens. We demarcate these tokens by enclosing them within special &lt;text&gt; and &lt;/text&gt; tags. As for the image embeddings from the projection block, we treat each vector as a separate ‚Äúvisual token‚Äù and demarcate them using &lt;image&gt; and &lt;/image&gt; tags. Finally, we prepend the sequence of visual tokens to the sequence of textual tokens, forming the joint input representation that is passed into Llama3 for processing.</p><h2 id="75f6">Inference Optimizations</h2><p id="a1bb">Training these models is expensive. To optimize for computation resources, we make two major optimizations. The first is a simple caching mechanism and the second is on the MPS/MLX front.</p><p id="a391"><strong>Caching: </strong>The SigLIP model is much smaller than Llama3. Therefore, if we run everything serially, we have very little GPU utilization when SigLIP is running. Moreover, we can‚Äôt push the utilization up by increasing the batch size up on SigLIP as then Llama runs into OOM errors. Instead we observed that our SigLIP model stays the same and instead pre-compute the image embeddings. Then, for both pre-training and SFT, we directly pass in these precomputed image embeddings instead of re-running the SigLIP module. Not only does this allow us to increase the batch size and maximally use our GPUs for running the SigLIP modules, it also saves us training/inference time as the two parts of the pipeline can occur separately.</p><p id="df3e"><strong>MPS/MLX Optimizations: </strong>Our second optimization was again driven by SigLIP‚Äôs smaller size relative to Llama. Specifically, since SigLIP fit on our Macbooks, we ran inference on an MPS optimized SigLIP model, which allowed us to attain a throughput of 32 images/second ‚Äî allowing our caching step happen relatively quickly.</p><h2 id="8756"><strong>How it was trained</strong></h2><p id="0e19"><strong>Precompute the embeddings from SigLIP: </strong>let‚Äôs now dive into the first step of our pre-training process: <em>precomputing the image embeddings via SigLIP</em>. In this step, our goal is to essentially pass in images into the SigLIP embedding model to obtain a vector representation or embedding of the image. One technical detail: due to higher resolutions, we follow the approach taken by LLaVA-UHD and perform image-splitting. The purpose of image-splitting is to divide the image into variable-sized patches or segments for more efficient encoding. These split images are processed concurrently in batches.</p><p id="b746">Now let‚Äôs dive into how exactly we use the SigLIP embedding. We first load the SigLIP model and processor/tokenizer. We then preprocess the provided input image using the processor. We then pass the preprocessed image to the model. Following this, the model outputs logits for the image-text pairs. We now proceed to apply the sigmoid activation function to the logits to get the probabilities. We now see that the image embedding is contained within these probabilities. So far this embedding captures the visual information in the image.</p><p id="7ba6">Following the computation of the image embedding via SigLIP, we now proceed to learn a projection matrix ‚Äî you can also think of this as the <em>projection layer</em>, which is typically a linear or feed-forward layer. As described above in the ingredients section, the projection layer maps the vision embedding from its original space into a joint multimodal embedding space. Specifically, the projection layer applies a learned weight matrix W_v to the vision embedding v to get the projected multimodal vision embedding W_v * v. So after this projection step, the vision and text embeddings are essentially aligned into a common multimodal embedding space, allowing their representations to interact and be combined for multimodal modeling tasks like visual question answering, image captioning, etc. More specifically, the result of the projection layer is the generated ‚Äúlatents.‚Äù</p><p id="07a9">Once the latents are computed, we then prepend them as image tokens before the text tokens. The reason for the prepending is that having the image before the text makes it easier for the model to learn during pretraining. Think of it as having tokens representing the actual image and then tokens representing the contents of the image in text: almost like a caption paired with an image. Our architecture is nearly identical to that of LLaVA-UHD (they choose CLIP-ViT while we use SigLIP and they work with Vicuna-13B) so we provide their illustration as reference below:</p><figure></figure><p id="8bdb">Now that we‚Äôve established the data needed for pretraining, we can dive into what that actually looks like. In pre-training, we then use 600,000 examples of prepended images to text. In this step we keep the main weights of the Llama-3 architecture frozen. The key is that we want to only update the gradients of the projection matrix. Crucially, we keep the rest of the weights frozen. And with that, we‚Äôve wrapped up our intuition and process for the pretraining step. The key here was aligning the embedded images (latents) with their text in a joint representation and then pretraining LLaMA-3 to focus on updating the projection matrix based on the examples encountered.</p><p id="7888"><strong>Supervised Finetuning</strong></p><p id="f3f5">Following pretraining, we perform supervised finetuning to enhance the performance of our model. In this step, we are freezing our computed embeddings (from the projection layer) and we keep everything except the vision and projection matrices frozen. In other words, if you look at the image below, the red components are unfrozen while the blue components are frozen. This is meant to serve as ‚Äúinstruction‚Äù finetuning ‚Äî in other words making the model stronger for a multimodal text output. In this stage, we use 1M examples (7M split images).</p><figure></figure><h2 id="f170"><strong>In Summary</strong></h2><ul><li id="4f32">We add a vision encoder to Llama3 8B</li><li id="0665">Our model offers 10‚Äì20% performance boosts over Llava the current open-source SOTA vision language model.</li><li id="6423">We offer comparable vision abilities of models close to 100x* larger in size like GPT4v, Gemini Ultra, and Claude Opus.</li><li id="792d">We describe an efficient pipeline to pretrain and instruction finetune the model in under $500.</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[API Shouldn't Redirect HTTP to HTTPS (462 pts)]]></title>
            <link>https://jviide.iki.fi/http-redirects</link>
            <guid>40504756</guid>
            <pubDate>Tue, 28 May 2024 19:42:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jviide.iki.fi/http-redirects">https://jviide.iki.fi/http-redirects</a>, See on <a href="https://news.ycombinator.com/item?id=40504756">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <h2>Background</h2>
      <p>
        When an user directs their web browser to an HTTP URL, it's a common practice for the service to redirect the
        request to a corresponding HTTPS page. This unencrypted part of the communication flow has its flaws. Third
        parties in shared networks, as well as network intermediaries, could
        <a href="https://en.wikipedia.org/wiki/Sniffing_attack" target="_blank" rel="noopener noreferrer">sniff</a>
        passwords and other secrets from the initial HTTP traffic
        or even impersonate the web server with a <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack" target="_blank" rel="noopener noreferrer">MITM</a> attack.
        Nevertheless, redirection has been an useful first step in the transition from the largely unencrypted early web
        to the <a href="https://transparencyreport.google.com/https/overview" target="_blank" rel="noopener noreferrer">largely encrypted</a> web of today.
      </p>
      <p>
        Later techniques tightened the security story further. Servers can now send <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security" target="_blank" rel="noopener noreferrer">HSTS</a> along with the initial HTTP-to-HTTPS redirection response, telling the
        user's browser to use only HTTPS for that domain from
        then on. This limits the window of opportunity for trivial sniffing and MITM attacks to the first request.
        Browsers then added <a href="https://hstspreload.org/" target="_blank" rel="noopener noreferrer">HSTS preload
          lists</a> and <a href="https://support.mozilla.org/en-US/kb/https-only-prefs" target="_blank" rel="noopener noreferrer">HTTPS-Only modes</a> that allow skipping the initial unencrypted request altogether.
      </p>
      <p>
        From the perspective of usability-security tradeoff it all makes sense for user-facing sites. But interestingly,
        the redirection approach also appears to be widely adopted for APIs. APIs are mostly consumed by other software
        so the same usability arguments don't apply there. Moreover, many programmatic API clients don't tend to keep
        browser-like state of things like HSTS headers they have seen.
      </p>
      <p>
        This post argues that, due to these factors, the common practice of redirecting API calls from HTTP to
        HTTPS should be reconsidered. While the post mostly refers to REST APIs, its points also apply to other styles
        of APIs that use HTTP(S) as a transport mechanism.
      </p>

      <h2>A Simple Typo Is Enugh</h2>
      <p>
        At <a href="https://badrap.io/" target="_blank" rel="noopener noreferrer">work</a>, we were building a new
        integration against a third-party API. The initial code commit contained a mistyped API base URL
        <code>"http://..."</code> instead of <code>"https://..."</code>. A pretty easy mistake to make.
      </p>
      <p>
        The error was essentially masked during runtime: The third-party API responded to every request with a 301
        redirect to their HTTPS side. Node.js's built-in <a href="https://nodejs.org/docs/latest/api/globals.html#fetch" target="_blank" rel="noopener noreferrer">fetch</a>
        happily and <em>quietly</em> followed those redirects to the HTTPS endpoint.
      </p>
      <p>
        <strong>Every single one of our API requests now sent the API keys over the network in plaintext</strong>,
        before then sending them again to the encrypted endpoint. The one letter omission could have exposed the used
        API keys to third parties without us realizing it. As the integration would have worked, there's a good
        chance that code would have leaked any secrets in the API calls for years. In the long run, the
        probabilities for malice tend to accumulate.
      </p>
      <p>
        Luckily we spotted the error during the code review before the error could propagate to production or even
        testing. We also realized that our <em>own</em> API also did similar HTTP-to-HTTPS redirects.
      </p>

      <h2>The Fail-fast Principle</h2>
      <p>
        When an API redirect HTTP requests to HTTPS - and the API client silently follows those redirects - it tends to
        hide mistyped URLs like in the case described above. A simple one-letter omission can easily be ignored, end up
        in production, and compromise the entire system's confidentiality.
      </p>
      <p>
        In most cases, it's better to adhere to the <a href="https://en.wikipedia.org/wiki/Fail-fast_system" target="_blank" rel="noopener noreferrer">fail-fast principle</a>: unencrypted API calls should fail in a
        spectacular and visible way so that the developer can easily spot and fix the typo as early as possible during
        the development process.
      </p>
      <p>
        A great solution for failing fast would be to disable the API server's HTTP interface altogether and not even
        answer to connections attempts to port 80. If the initial unencrypted connection is never established then the
        API keys aren't sent, mitigating sniffing attacks and limiting the window of opportunity for MITM attacks to an
        extremely small time window. This approach is viable for APIs hosted under their own domains like
        <code>api.example.com</code>.
      </p>
      <p>
        Our own API was served under the <code>/api</code> path from the same domain as our service's web UI. We
        didn't have the guts to disable the HTTP interface for that domain altogether, so we picked next best
        option: all unencrypted HTTP requests made under <code>/api</code> now return a descriptive error message along
        with the HTTP status code 403. Some initial plaintext requests might be made during development, but they're
        much easier for developers to notice.
      </p>

      <h2>Who Else?</h2>
      <p>
        That took care of our own API. We also pinged the third-party API provider and a couple of friends that they
        might want to check their APIs. And who knows, maybe there were some commonly used APIs that accept API keys (or
        other credentials) and also redirect from HTTP to HTTPS?
      </p>
      <p>
        I listed a bunch of well known APIs from the top of my head and did a little surveys. Several of them returned
        HTTP errors or declined to connections altogether. They're listed here with cURL spells for checking out their
        detailed responses:
      </p>

      <ol>
        <li>
          <strong>Stripe API</strong>: Responds with <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403" target="_blank" rel="nofollow noreferrer">403</a> ("Forbidden") and a descriptive error message.
          <br>
          <code>curl -i http://api.stripe.com</code>
        </li>
        <li>
          <strong>Google Cloud API</strong>: Responds with 403 and a descriptive error message.
          <br>
          <code>curl -i http://compute.googleapis.com/compute/v1/projects/project/regions/region/addresses</code>
        </li>
        <li>
          <strong>Shopify API</strong>: Responds with 403 and a descriptive error message.
          <br>
          <code>curl -i http://shop.myshopify.com/admin/api/2021-07/shop.json</code>
        </li>
        <li>
          <strong>NPM Registry API</strong>: Responds with <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/426" target="_blank" rel="nofollow noreferrer">426</a> ("Upgrade Required") and a descriptive error message.
          <br>
          <code>curl -i -X PUT -H 'content-type: application/json' -d '{}' 'http://registry.npmjs.org/-/user/org.couchdb.user:npm'</code>
        </li>
        <li>
          <a href="https://www.fastmail.com/for-developers/integrating-with-fastmail/" target="_blank" rel="nofollow noreferrer">Fastmail JMAP API</a>: The whole HTTP interface seems to be disabled.
          <br>
          <code>curl -i -H 'Authorization: Bearer foo' http://api.fastmail.com/jmap/session</code>
        </li>
        <li>
          <strong>Mailjet</strong>: The socket responds with completely empty payload.
          <br>
          <code>curl -i -X POST --user "user:pass" http://api.mailjet.com/v3.1/send -H 'Content-Type: application/json' -d '{}'</code>
        </li>
      </ol>

      <p>However, the following APIs <em>did</em> respond with HTTP-to-HTTPS redirects:</p>

      <ol>
        <li>
          <a href="https://developers.activecampaign.com/reference/list-all-accounts" target="_blank" rel="nofollow noreferrer">ActiveCampaign
            API</a>
          <br>
          <code>curl -i -H "Api-Token: 123abc-def-ghi" http://123456demo.api-us1.com/api/3/accounts</code>
        </li>
        <li>
          <a href="https://developer.atlassian.com/server/jira/platform/rest-apis/" target="_blank" rel="nofollow noreferrer">Atlassian Jira
            REST API</a>
          <br>
          <code>curl -i http://jira.atlassian.com/rest/api/latest/issue/JRA-9</code>
        </li>
        <li>
          <a href="https://docs.anthropic.com/en/api/messages" target="_blank" rel="nofollow noreferrer">Anthropic
            API</a>
          <br>
          <code>curl -i http://api.anthropic.com/v1/messages --header "x-api-key: 1" --header "anthropic-version: 2023-06-01" --header "content-type: application/json" --data '{}'</code>
        </li>
        <li>
          <a href="https://auth0.com/docs/api/management/v2/introduction" target="_blank" rel="nofollow noreferrer">Auth0</a>
          <br>
          <code>curl -i 'http://login.auth0.com/api/v2/organizations' -H 'Accept: application/json' -H 'Authorization: Bearer foo'</code>
        </li>
        <li>
          <a href="https://developers.cloudflare.com/api/operations/listAccountRulesets" target="_blank" rel="nofollow noreferrer">Cloudflare
            API</a>
          <br>
          <code>curl -i http://api.cloudflare.com/client/v4/accounts/abf9b32d38c5f572afde3336ec0ce302/rulesets</code>
        </li>
        <li>
          <a href="https://docs.datadoghq.com/api/latest/gcp-integration/" target="_blank" rel="nofollow noreferrer">Datadog</a>
          <br>
          <code>curl -i http://api.datadoghq.com/api/v2/integration/gcp/accounts</code>
        </li>
        <li>
          <a href="https://docs.deno.com/subhosting/api/" target="_blank" rel="nofollow noreferrer">Deno Subhosting
            API</a>
          <br>
          <code>curl -i http://api.deno.com/v1/organizations/11111111-2222-3333-4444-555555555555/projects</code>
        </li>
        <li>
          <a href="https://docs.digitalocean.com/reference/api/example-usage/" target="_blank" rel="nofollow noreferrer">DigitalOcean</a>
          <br>
          <code>curl -i -X GET "http://api.digitalocean.com/v2/actions" -H "Authorization: Bearer foo"</code>
        </li>
        <li>
          <a href="https://developers.facebook.com/docs/graph-api/overview/#me" target="_blank" rel="nofollow noreferrer">Facebook Graph API</a>

          <br>
          <code>curl -i 'http://graph.facebook.com/me?access_token=foo</code>
        </li>
        <li>
          <a href="https://www.fastly.com/documentation/reference/api/account/customer/" target="_blank" rel="nofollow noreferrer">Fastly
            API</a>
          <br>
          <code>curl -i -H "Fastly-Key: foo" "http://api.fastly.com/current_customer"</code>
        </li>
        <li>
          <a href="https://www.figma.com/developers/api#users" target="_blank" rel="nofollow noreferrer">Figma
            API</a>
          <br>
          <code>curl -i -H 'X-FIGMA-TOKEN: 123' 'http://api.figma.com/v1/me'</code>
        </li>
        <li>
          <a href="https://docs.github.com/en/rest/users/users?apiVersion=2022-11-28#get-the-authenticated-user" target="_blank" rel="nofollow noreferrer">GitHub
            API</a>
          <br>
          <code>curl -i http://api.github.com/user</code>
        </li>
        <li>
          <a href="https://docs.gitlab.com/ee/api/audit_events.html" target="_blank" rel="nofollow noreferrer">Gitlab
            API</a>
          <br>
          <code>curl -i http://gitlab.com/api/v4/audit_events</code>
        </li>
        <li>
          <a href="https://api.hackerone.com/customer-resources/#organizations-get-your-organizations" target="_blank" rel="nofollow noreferrer">HackerOne API</a>
          <br>
          <code>curl -i "http://api.hackerone.com/v1/me/organizations" -X GET -u "user:token" -H 'Accept: application/json'</code>
        </li>
        <li>
          <a href="https://docs.hetzner.cloud/#certificates-get-all-certificates" target="_blank" rel="nofollow noreferrer">Hetzner Cloud
            API</a>
          <br>
          <code>curl -i -H "Authorization: Bearer 123" "http://api.hetzner.cloud/v1/certificates"</code>
        </li>
        <li>
          <a href="https://developers.hubspot.com/docs/api/settings/account-activity-api" target="_blank" rel="nofollow noreferrer">Hubspot
            API</a>
          <br>
          <code>curl -i --request GET --url http://api.hubapi.com/account-info/v3/api-usage/daily/private-apps  --header 'authorization: Bearer YOUR_ACCESS_TOKEN'</code>
        </li>
        <li>
          <a href="https://cloud.ibm.com/apidocs/factsheets#authentication" target="_blank" rel="nofollow noreferrer">IBM Cloud API</a>
          <br>
          <code>curl -i "http://iam.cloud.ibm.com/identity/token" -d "apikey=YOUR_API_KEY_HERE&amp;grant_type=urn%3Aibm%3Aparams%3Aoauth%3Agrant-type%3Aapikey" -H "Content-Type: application/x-www-form-urlencoded" -H "Authorization: Basic Yng6Yng="</code>
        </li>
        <li>
          <a href="https://developers.facebook.com/docs/instagram-basic-display-api/getting-started" target="_blank" rel="nofollow noreferrer">Instagram Basic Display API</a>
          <br>
          <code>curl -i 'http://graph.instagram.com/me/media?fields=id,caption&amp;access_token=foo'</code>
        </li>
        <li>
          <a href="https://developers.linear.app/docs/graphql/working-with-the-graphql-api" target="_blank" rel="nofollow noreferrer">Linear
            API</a>
          <br>
          <code>curl -i -X POST -H "Content-Type: application/json" http://api.linear.app/graphql</code>
        </li>
        <li>
          <a href="https://docs.joinmastodon.org/api/" target="_blank" rel="nofollow noreferrer">Mastodon API</a> (on
          mastodon.social)
          <br>
          <code>curl -i http://mastodon.social/api/v1/timelines/home</code>
        </li>
        <li>
          <a href="https://learn.microsoft.com/en-us/graph/api/user-list-messages" target="_blank" rel="nofollow noreferrer">Microsoft Graph
            API</a>
          <br>
          <code>curl -i http://graph.microsoft.com/v1.0/me/messages</code>
        </li>
        <li>
          <a href="https://docs.netlify.com/api/get-started/" target="_blank" rel="nofollow noreferrer">Netlify
            API</a>
          <br>
          <code>curl -i -H "User-Agent: foo" -H "Authorization: Bearer foo" http://api.netlify.com/api/v1/sites</code>
        </li>
        <li>
          <a href="https://platform.openai.com/docs/api-reference/making-requests" target="_blank" rel="nofollow noreferrer">OpenAI API</a>
          <br>
          <code>curl -i -H "Content-Type: application/json" -H "Authorization: Bearer 123" -d '{}' http://api.openai.com/v1/chat/completions</code>
        </li>
        <li>
          <a href="https://api.us.ovhcloud.com/console/#/auth/details~GET" target="_blank" rel="nofollow noreferrer">OVHCloud API</a>
          <br>
          <code>curl -i http://api.us.ovhcloud.com/1.0/auth/details</code>
        </li>
        <li>
          <a href="https://resend.com/docs/api-reference/domains/list-domains" target="_blank" rel="nofollow noreferrer">Resend</a>
          <br>
          <code>curl -i -X GET 'http://api.resend.com/domains' -H 'Authorization: Bearer re_123456789' -H 'Content-Type: application/json'</code>
        </li>
        <li>
          <a href="https://developer.shodan.io/api" target="_blank" rel="nofollow noreferrer">Shodan API</a>
          <br>
          <code>curl -i 'http://api.shodan.io/org?key=12345'</code>
        </li>
        <li>
          <a href="https://api.slack.com/web#posting_json" target="_blank" rel="nofollow noreferrer">Slack API</a>
          <br>
          <code>curl -i -X POST -H "Content-Type: application/json" http://slack.com/api/conversations.create</code>
        </li>
        <li>
          <a href="https://github.com/tailscale/tailscale/blob/main/publicapi/readme.md">Tailscale API</a>
          <br>
          <code>curl -i -H "Authorization: Bearer tskey-api-xxxxx" http://api.tailscale.com/api/v2/user-invites/1</code>
        </li>
        <li>
          Twitter
          <br>
          <code>curl -i http://api.twitter.com/2/users/by/username/jack</code>
        </li>
        <li>
          <a href="https://developer.uber.com/docs/drivers/guides/authentication#step-3:-get-an-access-token" target="_blank" rel="nofollow noreferrer">Uber API</a>
          <br>
          <code>curl -F client_secret=1 -F client_id=1 -F grant_type=authorization_code -F redirect_uri=1 -F code=1 https://auth.uber.com/oauth/v2/token</code>
        </li>
        <li>
          <a href="https://developers.upcloud.com/1.3/3-accounts/#get-account-information" target="_blank" rel="nofollow noreferrer">UpCloud
            API</a>
          <br>
          <code>curl -i -H 'Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=' http://api.upcloud.com/1.3/account</code>
        </li>
        <li>
          <a href="https://vercel.com/docs/rest-api/endpoints/authentication#get-auth-token-metadata" target="_blank" rel="nofollow noreferrer">Vercel API</a>
          <br>
          <code>curl -i -H 'Authorization: Bearer foo' http://api.vercel.com/v5/user/tokens/5d9f2ebd38ddca62e5d51e9c1704c72530bdc8bfdd41e782a6687c48399e8391</code>
        </li>
        <li>
          <a href="https://www.vultr.com/api/#tag/account/operation/get-account" target="_blank" rel="nofollow noreferrer">Vultr API</a>
          <br>
          <code>curl -i "http://api.vultr.com/v2/account" -H "Authorization: Bearer 123"</code>
        </li>
      </ol>
      <p>
        I didn't report these findings separately to all of these API providers. There were some outliers not listed
        here that I did contact, with varying results. More on that later.
      </p>
      <p>
        Take each individual result with a grain of salt: I had to test some of these APIs without valid
        credentials, or with credentials used in documentation examples. But the overall pattern indicates that the
        habit of APIs redirecting HTTP requests to HTTPS is quite widespread. Why is that?
      </p>

      <h2>Best Practices Need Practice Too</h2>
      <p>
        When speaking with people about this topic, many have noted that HTTP-to-HTTPS redirects from APIs have obvious
        downsides - in hindsight.
      </p>
      <p>Redirects for user-facing applications are often mentioned in lists best practices and cheat sheets, <a href="https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Security_Cheat_Sheet.html#use-tls-for-all-pages" target="_blank" rel="nofollow noreferrer">like the ones published by OWASP (The Open Worldwide Application
          Security Project)</a>.
        Recommendations specifically aimed for APIs seem rare in contrast. I found just few mentions, for example an
        excellent PDF slideset called <a href="https://owasp.org/www-chapter-belgium/assets/2018/2018-10-23/OWASP_20181023_CommonAPISecurityPitfalls.pdf" target="_blank" rel="nofollow noreferrer">"Common API Security Pitfalls"</a> by <a href="https://infosec.exchange/@PhilippeDeRyck" target="_blank" rel="nofollow noreferrer">Philippe De
          Ryck</a>,
        buried deep within the OWASP website:
      </p>

      <figure>
        <img alt="Slide 8 of &quot;Common API Security Pitfalls&quot;: &quot;API-only endpoints should disable HTTP and only need to support HTTPS.&quot;" src="https://jviide.iki.fi/deryck-slide-8.png">
        <figcaption>
          <small>
            Slide 8 of "Common API Security Pitfalls". Emphasis added to highlight the relevant
            section.
          </small>
        </figcaption>
      </figure>

      <p>
        My Google-fu might just be bad. But maybe each best practice item recommending HTTP-to-HTTPS redirects
        for user-facing sites should have an explicit caveat attached, prominently advising against such redirects for
        APIs. Therefore I opened <a href="https://github.com/OWASP/CheatSheetSeries/issues/1407" target="_blank" rel="nofollow noreferrer">an issue</a> that suggests amending OWASP's Transport Layer Security Cheat Sheet
        accordingly.
      </p>

      <h2>Bonus Round: Popular APIs That Respond In Plaintext</h2>
      <p>
        While reviewing the list of APIs, I bumped into some popular ones that neither redirected nor failed
        unencrypted requests. They just responded to unencrypted HTTP requests with unencrypted HTTP responses, without
        enforcing HTTPS at any stage.
      </p>
      <p>
        Maybe they had their reasons, or maybe they had just accidentally misconfigured their reverse proxies.
        Regardless, seeing that they all handle potentially sensitive data, I contacted these API providers through
        their respective security channels and explained the problem. The providers are listed below in the order of
        reporting. I'll unredact their names and details when they've given a definite response, or otherwise after
        a reasonable amount of time has passed.
      </p>
      <ul>
        <li>
          <strong>Provider A</strong>: Reported on <time datetime="2024-05-17">2024-05-17</time> through their
          vulnerability reporting email address. Awaiting response.
        </li>
        <li>
          <strong>Provider B</strong>: Reported on <time datetime="2024-05-21">2024-05-21</time> through their HackerOne
          program. Got a prompt triage response, stating that attacks requiring MITM (or physical access to a user's
          device) are outside the scope of the program. Sent back a response explaining that MITM or physical access was
          not required for sniffing. Awaiting response.
        </li>
        <li>
          <strong>Provider C</strong>: Reported on <time datetime="2024-05-21">2024-05-21</time> through their security
          email address. Awaiting response.
        </li>
        <li id="virustotal">
          <a href="https://docs.virustotal.com/reference/overview" target="_blank" rel="noopener noreferrer">VirusTotal
            API</a>: Reported on <time datetime="2024-05-21">2024-05-21</time> through Google's <a href="https://bughunters.google.com/" target="_blank" rel="noopener noreferrer">Bug Hunters</a> site
          (VirusTotal is owned by a Google subsidiary that got merged into Google Cloud). The
          API responds in plaintext to requests like for example this (where <code>$API_KEY</code> is a valid API key):

          <p>
            <code>curl -i -H 'x-apikey: $API_KEY' http://www.virustotal.com/api/v3/ip_addresses/1.1.1.1</code>
          </p>

          <p>
            The report got promptly triaged. Received a response on <time datetime="2024-05-24">2024-05-24</time>, cited
            in part below:
          </p>

          
          
        </li>
      </ul>

      <h2>Conclusion</h2>
      <p>
        Redirecting HTTP to HTTPS for APIs can be more harmful than helpful due to the nature of APIs. Unlike
        user-facing web pages, APIs are primarily consumed by other software. API clients often follow redirects
        automatically and do not maintain state or support security headers like HSTS. This can lead to silent failures
        where sensitive data in each API request is initially transmitted in plaintext over the network, unencrypted.
      </p>
      <p>
        Let's adopt a fail-fast approach and disable the HTTP interface entirely or return clear
        error responses for unencrypted requests. This ensures that developers can quickly notice and fix accidental
        use <code>http://</code> URLs to <code>https://</code>.
      </p>
      <p>
        Several well-known and popular APIs also redirect HTTP requests to HTTPS. This behavior seems to be
        widespread. Maybe it's time we amend best practices to explicitly recommend that APIs flat our reject
        unencrypted requests.
      </p>
      <p>
        <em>Huge thanks to Juhani Eronen (<a href="https://www.kyberturvallisuuskeskus.fi/en/homepage" target="_blank" rel="noopener noreferrer">NCSC-FI</a>) and Marko Laakso (<a href="https://www.oulu.fi/en/research-groups/oulu-university-secure-programming-group-ouspg" target="_blank" rel="noopener noreferrer">OUSPG</a>) for their help and guidance during writing this
          post.</em>
      </p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Former FTX Executive Ryan Salame Sentenced to 90 Months in Prison (126 pts)]]></title>
            <link>https://www.justice.gov/usao-sdny/pr/former-ftx-executive-ryan-salame-sentenced-90-months-prison</link>
            <guid>40504228</guid>
            <pubDate>Tue, 28 May 2024 19:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.justice.gov/usao-sdny/pr/former-ftx-executive-ryan-salame-sentenced-90-months-prison">https://www.justice.gov/usao-sdny/pr/former-ftx-executive-ryan-salame-sentenced-90-months-prison</a>, See on <a href="https://news.ycombinator.com/item?id=40504228">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Damian Williams, the United States Attorney for the Southern District of New York, announced that RYAN SALAME was sentenced today to 90&nbsp;months in prison. &nbsp;SALAME previously pled guilty to conspiracy to make unlawful political contributions and defraud the Federal Election Commission and conspiracy to operate an unlicensed money transmitting business before U.S. District Judge Lewis A. Kaplan, who imposed today‚Äôs sentence.&nbsp;</p>

<blockquote>
<p>U.S. Attorney Damian Williams said: ‚ÄúRyan Salame agreed to advance the interests of FTX, Alameda Research, and his co-conspirators through an unlawful political influence campaign and through an unlicensed money transmitting business, which helped FTX grow faster and larger by operating outside of the law.&nbsp; Salame‚Äôs involvement in two serious federal crimes undermined public trust in American elections and the integrity of the financial system.&nbsp; Today‚Äôs sentence underscores the substantial consequences for such offenses.‚Äù&nbsp;</p>
</blockquote>

<p>According to the filings and statements made during court proceedings:</p>

<p>RYAN SALAME was a high-ranking official at Alameda Research, the quantitative cryptocurrency trading firm founded by Samuel Bankman-Fried, from 2019 to 2021.&nbsp; In or about October 2021, SALAME was named co-CEO of FTX‚Äôs Bahamian affiliate FTX Digital Markets Ltd.</p>

<p>While working at Alameda Research and FTX, SALAME conspired with Bankman-Fried and other employees of FTX and Alameda Research to operate an unlicensed money transmitting business, unlawfully using FTX, Alameda Research, and an entity called ‚ÄúNorth Dimension‚Äù to transmit FTX customer funds without a license.&nbsp; The conspirators and others at Alameda Research and FTX also made false statements to U.S. banks in order to maintain their unlawful businesses.</p>

<p>Additionally, beginning in or around 2020, SALAME conspired with Bankman-Fried and FTX executive Nishad Singh to donate campaign contributions in a manner that obscured Bankman-Fried‚Äôs association with certain of the contributions.&nbsp; These donations were made to improve Bankman-Fried‚Äôs personal standing in Washington, D.C., increase FTX‚Äôs profile, and curry favor with candidates that could help pass legislation favorable to FTX, Alameda, or Bankman-Fried‚Äôs personal agenda. &nbsp;In total, SALAME and his co-conspirators made over 300 political contributions, totaling tens of millions of dollars, that were unlawful because they were made in the name of a straw donor or paid for with corporate funds and caused false information to be reported by campaigns and political action committees to the Federal Election Commission.</p>

<p>* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*</p>

<p>In addition to the prison term, SALAME, 30, of Potomac, Maryland, was sentenced to three&nbsp;years of supervised release and ordered to pay more than $6 million in forfeiture and more than $5 million in restitution.</p>

<p>Mr. Williams praised the outstanding investigative work of the Federal Bureau of Investigation.&nbsp;</p>

<p>This case is being handled by the Office‚Äôs Securities and Commodities Fraud Task Force, with assistance from the Office‚Äôs Illicit Finance and Money Laundering and Complex Frauds and Cybercrime Units. &nbsp;Assistant U.S. Attorneys Danielle Kudla, Samuel Raymond, Thane Rehn, Nicolas Roos, and Danielle Sassoon are in charge of the prosecution.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tinygrad 0.9.0 (192 pts)]]></title>
            <link>https://github.com/tinygrad/tinygrad/releases/tag/v0.9.0</link>
            <guid>40504212</guid>
            <pubDate>Tue, 28 May 2024 18:58:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tinygrad/tinygrad/releases/tag/v0.9.0">https://github.com/tinygrad/tinygrad/releases/tag/v0.9.0</a>, See on <a href="https://news.ycombinator.com/item?id=40504212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p>Close to the new line limit of 8000 lines, sitting at 7958 lines.<br>
tinygrad is <em><strong>much</strong></em> more usable now.</p>
<p>Just over 1200 commits since <code>0.8.0</code>.</p>
<h2>Release Highlights</h2>
<ul>
<li>New documentation: <a href="https://docs.tinygrad.org/" rel="nofollow">https://docs.tinygrad.org</a></li>
<li><code>gpuctypes</code> has been brought in tree and is no longer an external dependency. [<a data-error-text="Failed to load title" data-id="2102609199" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3253" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3253/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3253">#3253</a>]</li>
<li><code>AMD=1</code> and <code>NV=1</code> experimental backends for not requiring any userspace runtime components like ROCm or CUDA.
<ul>
<li>These backends should reduce the amount of python time, and specifically with multi-gpu use cases.</li>
</ul>
</li>
<li><code>PTX=1</code> for rendering directly to ptx instead of cuda. [<a data-error-text="Failed to load title" data-id="2082842526" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3139" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3139/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3139">#3139</a>] [<a data-error-text="Failed to load title" data-id="2170097313" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3623" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3623/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3623">#3623</a>] [<a data-error-text="Failed to load title" data-id="2190196107" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3775" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3775/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3775">#3775</a>]</li>
<li>Nvidia tensor core support. [<a data-error-text="Failed to load title" data-id="2162090889" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3544" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3544/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3544">#3544</a>]</li>
<li><code>THREEFRY=1</code> for numpy-less random number generation using threefry2x32. [<a data-error-text="Failed to load title" data-id="2023226416" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/2601" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/2601/hovercard" href="https://github.com/tinygrad/tinygrad/pull/2601">#2601</a>] [<a data-error-text="Failed to load title" data-id="2190830121" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3785" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3785/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3785">#3785</a>]</li>
<li>More stabilized <a href="https://github.com/tinygrad/tinygrad/blob/v0.9.0/tinygrad/multi.py">multi-tensor API</a>.
<ul>
<li>With ring all-reduce: [<a data-error-text="Failed to load title" data-id="2064844412" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3000" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3000/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3000">#3000</a>] [<a data-error-text="Failed to load title" data-id="2199791227" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3852" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3852/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3852">#3852</a>]</li>
</ul>
</li>
<li>Core tinygrad has been refactored into 4 pieces, read more about it <a href="https://docs.tinygrad.org/developer/" rel="nofollow">here</a>.</li>
<li>Linearizer and codegen has support for generating kernels with multiple outputs.</li>
<li>Lots of progress towards greater kernel fusion in the scheduler.
<ul>
<li>Fusing of ReduceOps with their elementwise children. This trains mnist and gpt2 with ~20% less kernels and makes llama inference faster.</li>
<li>New LoadOps.ASSIGN allows fusing optimizer updates with grad.</li>
<li>Schedule kernels in BFS order. This improves resnet and llama speed.</li>
<li>W.I.P. for fusing multiple reduces: [<a data-error-text="Failed to load title" data-id="2257858300" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4259" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4259/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4259">#4259</a>] [<a data-error-text="Failed to load title" data-id="2250170563" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4208" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4208/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4208">#4208</a>]</li>
</ul>
</li>
<li>MLPerf <a href="https://github.com/tinygrad/tinygrad/blob/0b58203cbe9ac67de3ae598c8e6552c2935fcb1e/examples/mlperf/model_train.py#L14">ResNet</a> and <a href="https://github.com/tinygrad/tinygrad/blob/0b58203cbe9ac67de3ae598c8e6552c2935fcb1e/examples/mlperf/model_train.py#L392">BERT</a> with a W.I.P. <a href="https://github.com/tinygrad/tinygrad/pull/3470" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3470/hovercard">UNet3D</a></li>
<li>Llama 3 support with a new <a href="https://github.com/tinygrad/tinygrad/blob/v0.9.0/examples/llama3.py"><code>llama3.py</code></a> that provides an OpenAI compatible API. [<a data-error-text="Failed to load title" data-id="2294318726" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4576" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4576/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4576">#4576</a>]</li>
<li><a href="https://arxiv.org/pdf/2305.14314" rel="nofollow">NF4</a> quantization support in Llama examples. [<a data-error-text="Failed to load title" data-id="2291150932" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/4540" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/4540/hovercard" href="https://github.com/tinygrad/tinygrad/pull/4540">#4540</a>]</li>
<li><code>label_smoothing</code> has been added to <code>sparse_categorical_crossentropy</code>. [<a data-error-text="Failed to load title" data-id="2164382442" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/3568" data-hovercard-type="pull_request" data-hovercard-url="/tinygrad/tinygrad/pull/3568/hovercard" href="https://github.com/tinygrad/tinygrad/pull/3568">#3568</a>]</li>
</ul>
<h2>Known Issues</h2>
<ul>
<li>Using tinygrad in a conda env on macOS is known to cause problems with the <code>METAL</code> backend. See <a data-error-text="Failed to load title" data-id="1979764563" data-permission-text="Title is private" data-url="https://github.com/tinygrad/tinygrad/issues/2226" data-hovercard-type="issue" data-hovercard-url="/tinygrad/tinygrad/issues/2226/hovercard" href="https://github.com/tinygrad/tinygrad/issues/2226">#2226</a>.</li>
</ul>
<h3>See the full changelog: <a href="https://github.com/tinygrad/tinygrad/compare/v0.8.0...v0.9.0"><tt>v0.8.0...v0.9.0</tt></a></h3>
<h3>See the known issues: <a href="https://github.com/tinygrad/tinygrad/issues?q=is%3Aissue+is%3Aopen+label%3Abug+sort%3Aupdated-desc">https://github.com/tinygrad/tinygrad/issues?q=is%3Aissue+is%3Aopen+label%3Abug+sort%3Aupdated-desc</a></h3>
<h3>Join the <a href="https://discord.gg/beYbxwxVdx" rel="nofollow">Discord</a>!</h3></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Revealed: Israeli spy chief 'threatened' ICC prosecutor over war crimes inquiry (111 pts)]]></title>
            <link>https://www.theguardian.com/world/article/2024/may/28/israeli-spy-chief-icc-prosecutor-war-crimes-inquiry</link>
            <guid>40504006</guid>
            <pubDate>Tue, 28 May 2024 18:41:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/article/2024/may/28/israeli-spy-chief-icc-prosecutor-war-crimes-inquiry">https://www.theguardian.com/world/article/2024/may/28/israeli-spy-chief-icc-prosecutor-war-crimes-inquiry</a>, See on <a href="https://news.ycombinator.com/item?id=40504006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>The former head of the<strong> </strong>Mossad, Israel‚Äôs foreign intelligence agency, allegedly threatened a chief prosecutor of the international criminal court in a series of secret meetings in which he tried to pressure her into abandoning a war crimes investigation, the Guardian can reveal.</p><p>Yossi Cohen‚Äôs covert contacts with the ICC‚Äôs then prosecutor, Fatou Bensouda, took place in the years leading up to her decision to <a href="https://www.theguardian.com/law/2021/mar/03/icc-open-formal-investigation-war-crimes-palestine#:~:text=Bensouda%20has%20said%20her%20probe,war%20crimes%20against%20our%20people." data-link-name="in body link">open a formal investigation</a> into alleged war crimes and crimes against humanity in occupied Palestinian territories.</p><p>That investigation, launched in 2021, culminated last week when <a href="https://www.theguardian.com/law/2021/feb/12/karim-khan-international-criminal-court-prosecutor" data-link-name="in body link">Bensouda‚Äôs successor</a>, Karim Khan, announced that he was seeking an arrest warrant for the Israeli prime minister, Benjamin Netanyahu, over the country‚Äôs conduct in its war in Gaza.</p><p>The prosecutor‚Äôs decision to apply to the ICC‚Äôs pre-trial chamber <a href="https://www.theguardian.com/law/article/2024/may/20/icc-prosecutor-seeks-arrest-warrants-israeli-pm-netanyahu-hamas-officials-war-crimes" data-link-name="in body link">for arrest warrants</a> for Netanyahu and his defence minister, Yoav Gallant, alongside three Hamas leaders, is an outcome Israel‚Äôs military and political establishment has long feared.</p><figure id="76e585de-e601-4cc2-a7ee-c9738a064d7c" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Netanyahu and Cohen" src="https://i.guim.co.uk/img/media/628c02b4c6e6e4529989c4df22a2a15faca0899a/0_113_4368_2621/master/4368.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267.02037545787545" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Cohen (right) was appointed as director of the Mossad by Netanyahu in 2016 after working for several years as his national security adviser.</span> Photograph: Gali Tibbon/AFP/Getty Images</figcaption></figure><p>Cohen‚Äôs personal involvement in the operation against the ICC took place when he was the director of the Mossad. His activities were authorised at a high level and justified on the basis the court posed a threat of prosecutions against military personnel, according to a senior Israeli official.</p><p>Another Israeli source briefed on the operation against Bensouda said the Mossad‚Äôs objective was to compromise the prosecutor or enlist her as someone who would cooperate with Israel‚Äôs demands.</p><p>A third source familiar with the operation said Cohen was acting as Netanyahu‚Äôs ‚Äúunofficial messenger‚Äù.</p><p>Cohen, who was one of Netanyahu‚Äôs closest allies at the time and is emerging as a political force in his own right in Israel, personally led the Mossad‚Äôs involvement in an almost decade-long campaign by the country to undermine the court.</p><p>Four sources confirmed that Bensouda had briefed a small group of senior ICC officials about Cohen‚Äôs attempts to sway her, amid concerns about the increasingly persistent and threatening nature of his behaviour.</p><figure id="17cd9167-3bb2-4833-9378-83f3db1aae0b" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.YoutubeBlockElement"><gu-island name="YoutubeBlockComponent" priority="critical" deferuntil="visible" props="{&quot;format&quot;:{&quot;display&quot;:2,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;isMainMedia&quot;:false,&quot;id&quot;:&quot;6f1692ab-ea89-4b79-acfb-c6605a283771&quot;,&quot;assetId&quot;:&quot;jPWM4reuB6U&quot;,&quot;expired&quot;:false,&quot;posterImage&quot;:[{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/1000.jpg&quot;,&quot;width&quot;:1000},{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/500.jpg&quot;,&quot;width&quot;:500},{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/140.jpg&quot;,&quot;width&quot;:140},{&quot;url&quot;:&quot;https://media.guim.co.uk/ac438d069d051ac4b4112e332ecbefd3e9400665/0_0_1920_1080/1920.jpg&quot;,&quot;width&quot;:1920}],&quot;duration&quot;:317,&quot;mediaTitle&quot;:&quot;ICC prosecutor requests arrest warrants for Netanyahu, Gallant and three Hamas leaders ‚Äì video&quot;,&quot;origin&quot;:&quot;https://www.theguardian.com&quot;,&quot;stickyVideos&quot;:false,&quot;switches&quot;:{&quot;lightbox&quot;:true,&quot;prebidAppnexusUkRow&quot;:true,&quot;mastheadWithHighlights&quot;:false,&quot;abSignInGateMainVariant&quot;:true,&quot;commercialMetrics&quot;:true,&quot;prebidTrustx&quot;:true,&quot;scAdFreeBanner&quot;:false,&quot;adaptiveSite&quot;:true,&quot;prebidPermutiveAudience&quot;:true,&quot;compareVariantDecision&quot;:false,&quot;enableSentryReporting&quot;:true,&quot;lazyLoadContainers&quot;:true,&quot;ampArticleSwitch&quot;:true,&quot;remarketing&quot;:true,&quot;articleEndSlot&quot;:true,&quot;keyEventsCarousel&quot;:true,&quot;updateLogoAdPartner&quot;:true,&quot;registerWithPhone&quot;:false,&quot;darkModeWeb&quot;:true,&quot;targeting&quot;:true,&quot;remoteHeader&quot;:true,&quot;slotBodyEnd&quot;:true,&quot;prebidImproveDigitalSkins&quot;:true,&quot;ampPrebidOzone&quot;:true,&quot;extendedMostPopularFronts&quot;:true,&quot;emailInlineInFooter&quot;:true,&quot;showNewPrivacyWordingOnEmailSignupEmbeds&quot;:true,&quot;abDeeplyReadRightColumn&quot;:true,&quot;prebidAnalytics&quot;:true,&quot;extendedMostPopular&quot;:true,&quot;ampContentAbTesting&quot;:false,&quot;prebidCriteo&quot;:true,&quot;okta&quot;:true,&quot;imrWorldwide&quot;:true,&quot;acast&quot;:true,&quot;automaticFilters&quot;:true,&quot;twitterUwt&quot;:true,&quot;updatedHeaderDesign&quot;:true,&quot;prebidAppnexusInvcode&quot;:true,&quot;ampPrebidPubmatic&quot;:true,&quot;a9HeaderBidding&quot;:true,&quot;prebidAppnexus&quot;:true,&quot;enableDiscussionSwitch&quot;:true,&quot;prebidXaxis&quot;:true,&quot;stickyVideos&quot;:true,&quot;interactiveFullHeaderSwitch&quot;:true,&quot;discussionAllPageSize&quot;:true,&quot;prebidUserSync&quot;:true,&quot;audioOnwardJourneySwitch&quot;:true,&quot;brazeTaylorReport&quot;:false,&quot;externalVideoEmbeds&quot;:true,&quot;abSignInGateAlternativeWording&quot;:false,&quot;callouts&quot;:true,&quot;sentinelLogger&quot;:true,&quot;geoMostPopular&quot;:true,&quot;weAreHiring&quot;:false,&quot;relatedContent&quot;:true,&quot;thirdPartyEmbedTracking&quot;:true,&quot;prebidOzone&quot;:true,&quot;ampLiveblogSwitch&quot;:true,&quot;ampAmazon&quot;:true,&quot;prebidAdYouLike&quot;:true,&quot;mostViewedFronts&quot;:true,&quot;discussionInApps&quot;:false,&quot;optOutAdvertising&quot;:true,&quot;abSignInGateMainControl&quot;:true,&quot;googleSearch&quot;:true,&quot;brazeSwitch&quot;:true,&quot;darkModeInApps&quot;:true,&quot;prebidKargo&quot;:true,&quot;consentManagement&quot;:true,&quot;personaliseSignInGateAfterCheckout&quot;:true,&quot;redplanetForAus&quot;:true,&quot;prebidSonobi&quot;:true,&quot;idProfileNavigation&quot;:true,&quot;confiantAdVerification&quot;:true,&quot;discussionAllowAnonymousRecommendsSwitch&quot;:false,&quot;dcrTagPages&quot;:true,&quot;absoluteServerTimes&quot;:false,&quot;permutive&quot;:true,&quot;comscore&quot;:true,&quot;ampPrebidCriteo&quot;:true,&quot;tagLinkDesign&quot;:false,&quot;abMpuWhenNoEpic&quot;:false,&quot;newsletterOnwards&quot;:false,&quot;youtubeIma&quot;:true,&quot;webFonts&quot;:true,&quot;prebidImproveDigital&quot;:true,&quot;abAdBlockAsk&quot;:false,&quot;ophan&quot;:true,&quot;crosswordSvgThumbnails&quot;:true,&quot;prebidTriplelift&quot;:true,&quot;weather&quot;:true,&quot;prebidPubmatic&quot;:true,&quot;serverShareCounts&quot;:false,&quot;autoRefresh&quot;:true,&quot;enhanceTweets&quot;:true,&quot;prebidIndexExchange&quot;:true,&quot;prebidOpenx&quot;:true,&quot;prebidHeaderBidding&quot;:true,&quot;idCookieRefresh&quot;:true,&quot;discussionPageSize&quot;:true,&quot;smartAppBanner&quot;:false,&quot;boostGaUserTimingFidelity&quot;:false,&quot;historyTags&quot;:true,&quot;brazeContentCards&quot;:true,&quot;surveys&quot;:true,&quot;remoteBanner&quot;:true,&quot;emailSignupRecaptcha&quot;:true,&quot;prebidSmart&quot;:true,&quot;shouldLoadGoogletag&quot;:true,&quot;inizio&quot;:true}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"><div data-chromatic="ignore" data-component="youtube-atom"><figcaption><span><svg width="36" height="23" viewBox="0 0 36 23"><path d="M3.2 0l-3.2 3.3v16.4l3.3 3.3h18.7v-23h-18.8m30.4 1l-8.6 8v5l8.6 8h2.4v-21h-2.4"></path></svg></span><span>ICC prosecutor requests arrest warrants for Netanyahu, Gallant and three Hamas leaders ‚Äì video</span></figcaption></div></gu-island></figure><p>Three of those sources were familiar with Bensouda‚Äôs formal disclosures to the ICC about the matter. They said she revealed Cohen had put pressure on her on several occasions not to proceed with a criminal investigation in the ICC‚Äôs Palestine case.</p><p>According to accounts shared with ICC officials, he is alleged to have told her: ‚ÄúYou should help us and let us take care of you. You don‚Äôt want to be getting into things that could compromise your security or that of your family.‚Äù</p><p>One individual briefed on Cohen‚Äôs activities said he had used ‚Äúdespicable tactics‚Äù against Bensouda as part of an ultimately unsuccessful effort to intimidate and influence her. They likened his behaviour to ‚Äústalking‚Äù.</p><p>The Mossad also took a keen interest in Bensouda‚Äôs family members and obtained transcripts of secret recordings of her husband, according to two sources with direct knowledge of the situation. Israeli officials then attempted to use the material to discredit the prosecutor.</p><p>The revelations about Cohen‚Äôs operation form part of a forthcoming investigation by the Guardian, the Israeli-Palestinian publication +972 Magazine and the Hebrew-language outlet Local Call, revealing how multiple Israel intelligence agencies ran a covert ‚Äúwar‚Äù against the ICC for almost a decade.</p><p>Contacted by the Guardian, a spokesperson for Israel‚Äôs prime minister‚Äôs office said: ‚ÄúThe questions forwarded to us are replete with many false and unfounded allegations meant to hurt the state of Israel.‚Äù Cohen did not respond to a request for comment. Bensouda declined to comment.</p><figure id="c590efc5-ec49-4a9f-a008-a8059949407c" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Fatou Bensouda stands next to various national flags at a lectern that features the UN logo." src="https://i.guim.co.uk/img/media/d0713fe19645a6661f1146e1dfea05fb1c6c85c3/0_307_7940_4763/master/7940.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.9439546599496" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>The ICC case dates back to 2015, when Fatou Bensouda decided to open a preliminary examination into the situation in Palestine.</span> Photograph: Pacific Press Media Production Corp/Alamy</figcaption></figure><p>In the Mossad‚Äôs efforts to influence Bensouda, Israel received support from an unlikely ally: Joseph Kabila, the former president of the Democratic Republic of the Congo, who played a supporting role in the plot.</p><p>Revelations about the Mossad‚Äôs efforts to influence Bensouda come as the current chief prosecutor, Khan, warned in recent days that he would not hesitate to prosecute ‚Äúattempts to impede, intimidate or improperly influence‚Äù ICC officials.</p><p>According to legal experts and former ICC officials, efforts by the Mossad to threaten or put pressure on Bensouda could amount to offences against the administration of justice under article 70 of the Rome statute, the treaty that established the court.</p><p>A spokesperson for the ICC would not say whether Khan had reviewed his predecessor‚Äôs disclosures about her contacts with Cohen, but said Khan had never met or spoken to the head of the Mossad.</p><p>While the spokesperson declined to comment on specific allegations, they said Khan‚Äôs office had been subjected to ‚Äúseveral forms of threats and communications that could be viewed as attempts to unduly influence its activities‚Äù.</p><h2 id="bensouda-sparks-ire-of-israel">Bensouda sparks ire of Israel</h2><p>Khan‚Äôs decision to seek arrest warrants against Netanyahu and Gallant last week marked the first time the court had taken action against leaders of a country closely allied with the US and Europe. Their alleged crimes ‚Äì which include directing attacks on civilians and using starvation as a method of warfare ‚Äì relate to the eight-month war in Gaza.</p><p>The ICC case, however, dates back to 2015, when Bensouda decided <a href="https://www.theguardian.com/law/2015/jan/16/icc-possible-war-crimes-palestinian-territories" data-link-name="in body link">to open a preliminary examination</a> into the situation in Palestine. Short of a full investigation, her inquiry was tasked with making an initial assessment of allegations of crimes by individuals in Gaza, the West Bank and East Jerusalem.</p><p>Bensouda‚Äôs decision sparked the ire of Israel, which feared its citizens could be prosecuted for their involvement in operations in <a href="https://www.theguardian.com/world/palestinian-territories" data-link-name="in body link" data-component="auto-linked-tag">Palestinian territories</a>. Israel had long been open about its opposition to the ICC, refusing to recognise its authority. Israeli ministers intensified their attacks on the court and even vowed to try to dismantle it.</p><p>Soon after commencing the preliminary examination, Bensouda and her senior prosecutors began to receive warnings that Israeli intelligence was taking a close interest in their work.</p><figure id="701b7240-95b2-408b-938f-e7376eee1fce" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Differential focus image that centres Yossi Cohen among a crowd of suited men" src="https://i.guim.co.uk/img/media/ba7b0125f847238642bc08243d6d61c63166c76d/0_224_6720_4032/master/6720.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Yossi Cohen during a reception held at the Israeli foreign ministry in Jerusalem, in May 2018.</span> Photograph: Amir Cohen/Reuters</figcaption></figure><p>According to two sources, there were even suspicions among senior ICC officials that Israel had cultivated sources within the court‚Äôs prosecution division, known as the office of the prosecutor. Another later recalled that although the Mossad ‚Äúdidn‚Äôt leave its signature‚Äù, it was an assumption the agency was behind some of the activity officials had been made aware of.</p><p>Only a small group of senior figures at the ICC, however, were informed that the director of the Mossad had personally approached the chief prosecutor.</p><p>A career spy, Cohen enjoys a reputation in Israel‚Äôs intelligence community as an effective recruiter of foreign agents. He was a loyal and powerful ally of the prime minister at the time, having been appointed as director of the Mossad by Netanyahu in 2016 after working for several years at his side as his national security adviser.</p><p>As the head of the national security council between 2013 and 2016, Cohen oversaw the body that, according to multiple sources, began to coordinate a multiagency effort against the ICC once Bensouda opened the preliminary inquiry in 2015.</p><p>Cohen‚Äôs first interaction with Bensouda appears to have taken place at the Munich security conference in 2017, when the Mossad director introduced himself to the prosecutor in a brief exchange. After this encounter, Cohen subsequently ‚Äúambushed‚Äù Bensouda in a bizarre episode in a Manhattan hotel suite, according to multiple sources familiar with the incident.</p><figure id="eabefa5b-5c0e-453c-906e-007ca2300738" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-5"><picture><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Bensouda shaking hands with a bearded Joseph Kabila" src="https://i.guim.co.uk/img/media/31a3044ba4918b2f97002bf164fcb70dfc7710ff/0_21_640_384/master/640.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Bensouda with Joseph Kabila in New York. Sources claim the then DRC leader played an important supporting role in the Mossad‚Äôs plot against the ICC‚Äôs chief prosecutor.</span> Photograph: ICC</figcaption></figure><p>Bensouda was in New York in 2018 on an official visit, and was meeting Kabila, then the president of the DRC, at his hotel. The pair had met several times before in relation to the ICC‚Äôs ongoing investigation into alleged crimes committed in his country.</p><p>The meeting, however, appears to have been a setup. At a certain point, after Bensouda‚Äôs staff were asked to leave the room, Cohen entered, according to three sources familiar with the meeting. The surprise appearance, they said, caused alarm to Bensouda and a group of ICC officials travelling with her.</p><p>Why Kabila helped Cohen is unclear, but ties between the two men were revealed in 2022 by the Israeli publication TheMarker, which reported on a series of secretive trips the Mossad director made to the DRC throughout 2019.</p><gu-island name="InteractiveBlockComponent" priority="critical" deferuntil="idle" props="{&quot;url&quot;:&quot;https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Get%20in%20touch&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Aharry.davies%40theguardian.com%22%3Eharry.davies%40theguardian.com%3C%2Fa%3E%2C%20or%20(using%20a%20non-work%20phone)%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fsignal.me%2F%23p%2F%2B447721857348%22%3ESignal%3C%2Fa%3E%20or%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fapi.whatsapp.com%2Fsend%3Fphone%3D447721857348%22%3EWhatsApp%3C%2Fa%3E%20to%20message%20%2B44%207721%20857348.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false&quot;,&quot;scriptUrl&quot;:&quot;https://interactive.guim.co.uk/embed/iframe-wrapper/0.1/boot.js&quot;,&quot;alt&quot;:&quot;Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348.&quot;,&quot;format&quot;:{&quot;display&quot;:2,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;elementId&quot;:&quot;43e668f7-c6da-422b-b6a3-945ffad8a4c0&quot;,&quot;isMainMedia&quot;:false}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"><figure id="43e668f7-c6da-422b-b6a3-945ffad8a4c0" data-alt="Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348." data-testid="interactive-element-Do%20you%20have%20information%20about%20this%20story?%20Email%20harry.davies@theguardian.com,%20or%20(using%20a%20non-work%20phone)%20use%20Signal%20or%20WhatsApp%20to%20message%20+44%207721%20857348." data-spacefinder-role="inline"><a data-name="placeholder" href="https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Get%20in%20touch&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Aharry.davies%40theguardian.com%22%3Eharry.davies%40theguardian.com%3C%2Fa%3E%2C%20or%20(using%20a%20non-work%20phone)%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fsignal.me%2F%23p%2F%2B447721857348%22%3ESignal%3C%2Fa%3E%20or%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fapi.whatsapp.com%2Fsend%3Fphone%3D447721857348%22%3EWhatsApp%3C%2Fa%3E%20to%20message%20%2B44%207721%20857348.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false">Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348.</a></figure></gu-island><p>According to the publication, Cohen‚Äôs trips, during which he sought Kabila‚Äôs advice ‚Äúon an issue of interest to Israel‚Äù, and which were almost certainly approved by Netanyahu, were highly unusual and had astonished senior figures within the intelligence community.</p><p>Reporting on the DRC meetings in 2022, the Israeli broadcaster Kan 11 said Cohen‚Äôs trips related to an ‚Äúextremely controversial plan‚Äù and cited official sources who described it as ‚Äúone of Israel‚Äôs most sensitive secrets‚Äù.</p><p>Multiple sources have confirmed to the Guardian the trips were partly related to the ICC operation, and Kabila, who left office in January 2019, played an important supporting role in the Mossad‚Äôs plot against Bensouda. Kabila did not respond to a request for comment.</p><h2 id="threats-and-manipulation">‚ÄòThreats and manipulation‚Äô</h2><p>After the surprise meeting with Kabila and Bensouda in New York, Cohen repeatedly phoned the chief prosecutor and sought meetings with her, three sources recalled. According to two people familiar with the situation, at one stage Bensouda asked Cohen how he had obtained her phone number, to which he replied: ‚ÄúDid you forget what I do for a living?‚Äù</p><p>Initially, the sources explained, the intelligence chief ‚Äútried to build a relationship‚Äù with the prosecutor and played ‚Äúgood cop‚Äù in an attempt to charm her. The initial objective, they said, appeared to have been to enlist Bensouda into cooperating with Israel.</p><p>Over time, however, the tone of Cohen‚Äôs contact changed and he began to use a range of tactics, including ‚Äúthreats and manipulation‚Äù, an individual briefed on the meetings said. This prompted Bensouda to inform a small group of senior ICC officials about his behaviour.</p><p>In December 2019, <a href="https://www.theguardian.com/law/2019/dec/20/icc-to-investigate-alleged-israeli-and-palestinian-war-crimes" data-link-name="in body link">the prosecutor announced</a> that she had grounds to open a full criminal investigation into allegations of war crimes in Gaza, the West Bank and East Jerusalem. However, she held off launching it, deciding first to request a ruling from the ICC‚Äôs pre-trial chamber to confirm the court did indeed have jurisdiction over Palestine.</p><figure id="77bb2be5-5a34-4bfb-96e5-520fb0a3429f" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-6"><picture><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Demonstrators carry banners outside the ICC" src="https://i.guim.co.uk/img/media/5658e661b52f962fe43e896e2db47f61a69c4778/0_0_5472_3648/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Protesters gather outside the ICC to call for the court to prosecute Israel for war crimes.</span> Photograph: Peter Dejong/AP</figcaption></figure><p>Multiple sources said it was at this stage, as the judges considered the case, that Cohen escalated his attempts to persuade Bensouda not to pursue a full investigation in the event the judges gave her the green light.</p><p>Between late 2019 and early 2021, the sources said, there were at least three encounters between Cohen and Bensouda, all initiated by the spy chief. His behaviour is said to have become increasingly concerning to ICC officials.</p><p>A source familiar with Bensouda‚Äôs accounts of the final two meetings with Cohen said he had raised questions about her security, and that of her family, in a manner that led her to believe he was threatening her.</p><p>On one occasion, Cohen is said to have shown Bensouda copies of photographs of her husband, which were taken covertly when the couple were visiting London. On another, according to sources, Cohen suggested to the prosecutor that a decision to open a full investigation would be detrimental to her career.</p><p>Four sources familiar with the situation said it was around the same time that Bensouda and other ICC officials discovered that information was circulating among diplomatic channels relating to her husband, who worked as an international affairs consultant.</p><p>Between 2019 and 2020, the Mossad had been actively seeking compromising information on the prosecutor and took an interest in her family members.</p><figure id="06390ceb-982e-4fe7-83d2-31bea22196f0" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-7"><picture><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="The international criminal court in The Hague" src="https://i.guim.co.uk/img/media/b8515f60a8bb747a9f7fa17cf04d6beba47ef03d/0_0_5472_3283/master/5472.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.9837353801169" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>In February 2021, it was confirmed that the ICC had jurisdiction in occupied Palestinian territories.</span> Photograph: Peter Dejong/AP</figcaption></figure><p>The spy agency obtained a cache of material, including transcripts of an apparent sting operation against her husband.</p><p>It is unclear who conducted the operation, or precisely what he is alleged to have said in the recordings. One possibility is that he had been targeted by the intelligence agency or by private actors of another country that wanted leverage over the ICC. Another possibility is the information was fabricated.</p><div><p>Once in the possession of Israel, however, the material was used by its diplomats in an unsuccessful attempt to undermine the chief prosecutor. But according to multiple sources, Israel failed to convince its allies of the significance of the material.</p><p>
 Three sources briefed on the information shared by Israel at a diplomatic level described the efforts as part of an unsuccessful ‚Äúsmear campaign‚Äù against Bensouda. ‚ÄúThey went after Fatou,‚Äù one source said, but it had ‚Äúno impact‚Äù on the prosecutor‚Äôs work.</p></div><figure id="b252e0f2-65b5-4458-83d8-cab4d4b3992d" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-8"><picture><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Trump and Netanyahu shake hands" src="https://i.guim.co.uk/img/media/7973a9020306ba61a7e04d84e716e69db290cfb7/0_95_2465_1480/master/2465.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267.1805273833671" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Trump and Netanyahu. The Trump administration imposed visa restrictions and sanctions on Bensouda in 2019-20.</span> Photograph: Ronen Zvulun/Reuters</figcaption></figure><p>The diplomatic efforts were part of a coordinated effort by the governments of Netanyahu and <a href="https://www.theguardian.com/us-news/donaldtrump" data-link-name="in body link" data-component="auto-linked-tag">Donald Trump</a> in the US to place public and private pressure on the prosecutor and her staff.</p><p>Between 2019 and 2020, in an unprecedented decision, the Trump administration imposed visa restrictions and sanctions <a href="https://www.theguardian.com/law/2020/sep/02/us-sanctions-international-criminal-court-fatou-bensouda" data-link-name="in body link">on the chief prosecutor</a>. The move was in retaliation to Bensouda‚Äôs pursuit of a separate investigation into war crimes in Afghanistan, allegedly committed by the Taliban and both Afghan and US military personnel.</p><p>However, Mike Pompeo, then US secretary of state, linked the sanctions package to the Palestine case. ‚ÄúIt‚Äôs clear the ICC is only putting Israel in [its] crosshairs for nakedly political purposes,‚Äù he said.</p><p>Months later, he accused Bensouda, without citing any evidence, of having ‚Äúengaged in corrupt acts for her personal benefit‚Äù.</p><p>The <a href="https://www.theguardian.com/law/2021/apr/02/us-lifts-sanctions-icc-prosecutor-fatou-bensouda-pompeo-blinken" data-link-name="in body link">US sanctions were rescinded</a> after President Joe Biden entered the White House.</p><p>In February 2021, the ICC‚Äôs pre-trial chamber issued a ruling <a href="https://www.theguardian.com/law/2021/feb/05/icc-rules-it-can-investigate-war-crimes-in-palestine-despite-israeli-objections" data-link-name="in body link">confirming the ICC had jurisdiction</a> in occupied Palestinian territories. The following month, Bensouda <a href="https://www.theguardian.com/law/2021/mar/03/icc-open-formal-investigation-war-crimes-palestine" data-link-name="in body link">announced the opening</a> of the criminal investigation.</p><p>‚ÄúIn the end, our central concern must be for the victims of crimes, both Palestinian and Israeli, arising from the long cycle of violence and insecurity that has caused deep suffering and despair on all sides,‚Äù she said at the time.</p><p>Bensouda completed her nine-year term at the ICC three months later, leaving it to her successor, Khan, to take up the investigation. It was only after the Hamas attacks on Israel on 7 October and the ensuing war on Gaza that the ICC‚Äôs investigation gained renewed urgency, culminating in last week‚Äôs request for arrest warrants.</p><p>It was the conclusion Israel‚Äôs political, military and intelligence establishment had feared. ‚ÄúThe fact they chose the head of Mossad to be the prime minister‚Äôs unofficial messenger to [Bensouda] was to intimidate, by definition,‚Äù said a source briefed on Cohen‚Äôs operation. ‚ÄúIt failed.‚Äù</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers cracked an 11-year-old password to a $3M crypto wallet (204 pts)]]></title>
            <link>https://www.wired.com/story/roboform-password-3-million-dollar-crypto-wallet/</link>
            <guid>40503925</guid>
            <pubDate>Tue, 28 May 2024 18:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/roboform-password-3-million-dollar-crypto-wallet/">https://www.wired.com/story/roboform-password-3-million-dollar-crypto-wallet/</a>, See on <a href="https://news.ycombinator.com/item?id=40503925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>Two years ago</span> when ‚ÄúMichael,‚Äù an owner of <a href="https://www.wired.com/tag/cryptocurrency/">cryptocurrency</a>, contacted Joe Grand to help recover access to about $2 million worth of <a href="https://www.wired.com/tag/bitcoin/">bitcoin</a> he stored in encrypted format on his computer, Grand turned him down.</p><p>Michael, who is based in Europe and asked to remain anonymous, stored the cryptocurrency in a password-protected digital wallet. He generated a password using the RoboForm password manager and stored that password in a file encrypted with a tool called TrueCrypt. At some point, that file got corrupted and Michael lost access to the 20-character password he had generated to secure his 43.6 BTC (worth a total of about ‚Ç¨4,000, or $5,300, in 2013). Michael used the RoboForm password manager to generate the password but did not store it in his manager. He worried that someone would hack his computer and obtain the password.</p><p>‚ÄúAt [that] time, I was really paranoid with my security,‚Äù he laughs.</p><p>Grand is a famed hardware hacker who in 2022 helped another crypto wallet owner <a href="https://www.theverge.com/2022/1/24/22898712/crypto-hardware-wallet-hacking-lost-bitcoin-ethereum-nft">recover access to $2 million in cryptocurrency</a> he thought he‚Äôd lost forever after forgetting the PIN to his Trezor wallet. Since then, dozens of people have contacted Grand to help them recover their treasure. But Grand, known by the hacker handle ‚ÄúKingpin,‚Äù turns down most of them, for various reasons.</p><p>Grand is an <a data-offer-url="http://www.grandideastudio.com/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.grandideastudio.com/&quot;}" href="http://www.grandideastudio.com/" rel="nofollow noopener" target="_blank">electrical engineer</a> who began hacking computing hardware at age 10 and in 2008 cohosted the Discovery Channel‚Äôs <em>Prototype This</em> show. He now consults with companies that build complex digital systems to help them understand how hardware hackers like him might subvert their systems. He cracked the Trezor wallet in 2022 using complex hardware techniques that forced the USB-style wallet to reveal its password.</p><figure data-testid="IframeEmbed"><div data-testid="IframeEmbedContainer"><p><iframe height="300px" sandbox="allow-scripts allow-popups allow-same-origin" title="Embedded Frame" src="https://www.youtube-nocookie.com/embed/o5IySpAkThg" allow="autoplay *; encrypted-media *; clipboard-write; autoplay; fullscreen; picture-in-picture"></iframe></p></div></figure><p>But Michael stored his cryptocurrency in a software-based wallet, which meant none of Grand‚Äôs hardware skills were relevant this time. He considered brute-forcing Michael‚Äôs password‚Äîwriting a script to automatically guess millions of possible passwords to find the correct one‚Äîbut determined this wasn‚Äôt feasible. He briefly considered that the RoboForm password manager Michael used to generate his password might have a flaw in the way it generated passwords, which would allow him to guess the password more easily. Grand, however, doubted such a flaw existed.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Michael contacted multiple people who specialize in cracking cryptography; they all told him ‚Äúthere‚Äôs no chance‚Äù of retrieving his money. But last June he approached Grand again, hoping to convince him to help, and this time Grand agreed to give it a try, working with a friend named Bruno in Germany who also hacks digital wallets.</p><p>Grand and Bruno spent months reverse engineering the version of the RoboForm program that they thought Michael had used in 2013 and found that the pseudo-random number generator used to generate passwords in that version‚Äîand subsequent versions until 2015‚Äîdid indeed have a significant flaw that made the random number generator not so random. The RoboForm program unwisely tied the random passwords it generated to the date and time on the user‚Äôs computer‚Äîit determined the computer‚Äôs date and time, and then generated passwords that were predictable. If you knew the date and time and other parameters, you could compute any password that would have been generated on a certain date and time in the past.</p><p>If Michael knew the day or general time frame in 2013 when he generated it, as well as the parameters he used to generate the password (for example, the number of characters in the password, including lower- and upper-case letters, figures, and special characters), this would narrow the possible password guesses to a manageable number. Then they could hijack the RoboForm function responsible for checking the date and time on a computer and get it to travel back in time, believing the current date was a day in the 2013 time frame when Michael generated his password. RoboForm would then spit out the same passwords it generated on the days in 2013.</p><p>There was one problem: Michael couldn‚Äôt remember when he created the password.</p><p>According to the log on his software wallet, Michael moved bitcoin into his wallet for the first time on April 14, 2013. But he couldn‚Äôt remember if he generated the password the same day or some time before or after this. So, looking at the parameters of other passwords he generated using RoboForm, Grand and Bruno configured RoboForm to generate 20-character passwords with upper- and lower-case letters, numbers, and eight special characters from March 1 to April 20, 2013.</p><p>It failed to generate the right password. So Grand and Bruno lengthened the time frame from April 20 to June 1, 2013, using the same parameters. Still no luck.</p><p>Michael says they kept coming back to him, asking if he was sure about the parameters he‚Äôd used. He stuck to his first answer.</p><p>‚ÄúThey really annoyed me, because who knows what I did 10 years ago,‚Äù he recalls. He found other passwords he generated with RoboForm in 2013, and two of them did not use special characters, so Grand and Bruno adjusted. Last November, they reached out to Michael to set up a meeting in person. ‚ÄúI thought, ‚ÄòOh my God, they will ask me again for the settings.‚Äù</p><p>Instead, they revealed that they had finally found the correct password‚Äîno special characters. It was generated on May 15, 2013, at 4:10:40 pm GMT.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>‚ÄúWe ultimately got lucky that our parameters and time range was right. If either of those were wrong, we would have ‚Ä¶ continued to take guesses/shots in the dark,‚Äù Grand says in an email to WIRED. ‚ÄúIt would have taken significantly longer to precompute all the possible passwords.‚Äù</p><p>Grand and Bruno <a href="https://www.youtube.com/watch?v=o5IySpAkThg">created a video</a> to explain the technical details more thoroughly.</p><p>RoboForm, made by US-based Siber Systems, was one of the first password managers on the market, and <a data-offer-url="https://earthweb.com/roboform-users/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://earthweb.com/roboform-users/&quot;}" href="https://earthweb.com/roboform-users/" rel="nofollow noopener" target="_blank">currently has more than 6 million users</a> worldwide, according to a company report. In 2015, Siber seemed to fix the RoboForm password manager. In a cursory glance, Grand and Bruno couldn‚Äôt find any sign that the pseudo-random number generator in the 2015 version used the computer‚Äôs time, which makes them think they removed it to fix the flaw, though Grand says they would need to examine it more thoroughly to be certain.</p><p>Siber Systems confirmed to WIRED that it did fix the issue with version 7.9.14 of RoboForm, released June 10, 2015, but a spokesperson wouldn‚Äôt answer questions about how it did so. In a <a data-offer-url="https://www.roboform.com/news-windows" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.roboform.com/news-windows&quot;}" href="https://www.roboform.com/news-windows" rel="nofollow noopener" target="_blank">changelog</a> on the company‚Äôs website, it mentions only that Siber programmers made changes to&nbsp;‚Äúincrease randomness of generated passwords,‚Äù but it doesn‚Äôt say how they did this. Siber spokesman Simon Davis says that ‚ÄúRoboForm 7 was discontinued in 2017.‚Äù</p><p>Grand says that, without knowing how Siber fixed the issue, attackers may still be able to regenerate passwords generated by versions of RoboForm released before the fix in 2015. He‚Äôs also not sure if current versions contain the problem.</p><p>‚ÄúI'm still not sure I would trust it without knowing how they actually improved the password generation in more recent versions,‚Äù he says. ‚ÄúI'm not sure if RoboForm knew how bad this particular weakness was.‚Äù</p><p>Customers may also still be using passwords that were generated with the early versions of the program before the fix. It doesn‚Äôt appear that Siber ever notified customers when it released the fixed version 7.9.14 in 2015 that they should generate new passwords for critical accounts or data. The company didn‚Äôt respond to a question about this.</p><p>If Siber didn‚Äôt inform customers, this would mean that anyone like Michael who used RoboForm to generate passwords prior to 2015‚Äîand are still using those passwords‚Äîmay have vulnerable passwords that hackers can regenerate.</p><p>‚ÄúWe know that most people don't change passwords unless they're prompted to do so,‚Äù Grand says. ‚ÄúOut of 935 passwords in my password manager (not RoboForm), 220 of them are from 2015 and earlier, and most of them are [for] sites I still use.‚Äù</p><p>Depending on what the company did to fix the issue in 2015, newer passwords may also be vulnerable.</p><p>Last November, Grand and Bruno deducted a percentage of bitcoins from Michael‚Äôs account for the work they did, then gave him the password to access the rest. The bitcoin was worth $38,000 per coin at the time. Michael waited until it rose to $62,000 per coin and sold some of it. He now has 30 BTC, now worth $3 million, and is waiting for the value to rise to $100,000 per coin.</p><p>Michael says he was lucky that he lost the password years ago because, otherwise, he would have sold off the bitcoin when it was worth $40,000 a coin and missed out on a greater fortune.</p><p>‚ÄúThat I lost the password was financially a good thing.‚Äù</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A robot will soon try to remove melted nuclear fuel from Fukushima reactor (130 pts)]]></title>
            <link>https://apnews.com/article/japan-fukushima-nuclear-meltdown-debris-robot-238a5177ec3ac3c7608c3116fdf58a58</link>
            <guid>40503648</guid>
            <pubDate>Tue, 28 May 2024 18:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/japan-fukushima-nuclear-meltdown-debris-robot-238a5177ec3ac3c7608c3116fdf58a58">https://apnews.com/article/japan-fukushima-nuclear-meltdown-debris-robot-238a5177ec3ac3c7608c3116fdf58a58</a>, See on <a href="https://news.ycombinator.com/item?id=40503648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>TOKYO (AP) ‚Äî The operator of Japan‚Äôs destroyed Fukushima Daiichi nuclear power plant demonstrated Tuesday how a remote-controlled robot would retrieve tiny bits of melted fuel debris from one of three damaged reactors later this year for the first time since the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/japan-fukushima-quake-tsunami-anniversary-0089f053d670c78dafd9578c242e1fb3">2011 meltdown</a></span>.</p><p>Tokyo Electric Power Company Holdings plans to deploy a ‚Äútelesco-style‚Äù extendable pipe robot into Fukushima Daiichi No. 2 reactor to test the removal of debris from its primary containment vessel by October.</p><p>That work is more than two years behind schedule. The removal of melted fuel was supposed to begin in late 2021 but has been plagued with delays, underscoring the difficulty of recovering from the magnitude 9.0 quake and tsunami in 2011.</p><p>During the demonstration at the Mitsubishi Heavy Industries‚Äô shipyard in Kobe, western Japan, where the robot has been developed, a device equipped with tongs slowly descended from the telescopic pipe to a heap of gravel and picked up a granule.</p>
    

<p>TEPCO plans to remove less than 3 grams (0.1 ounce) of debris in the test at the Fukushima plant.</p><p>‚ÄúWe believe the upcoming test removal of fuel debris from Unit 2 is an extremely important step to steadily carry out future decommissioning work,‚Äù said Yusuke Nakagawa, a TEPCO group manager for the fuel debris retrieval program. ‚ÄúIt is important to proceed with the test removal safely and steadily.‚Äù</p>



<p>About 880 tons of highly radioactive melted nuclear fuel remain inside the three damaged reactors. Critics say the 30- to 40-year cleanup target set by the government and TEPCO for Fukushima Daiichi is overly optimistic. The damage in each reactor is different, and plans must accommodate their conditions.</p>
    
<p>Better understanding the melted fuel debris from inside the reactors is key to their decommissioning. TEPCO deployed four mini drones into the No. 1 reactor‚Äôs primary containment vessel earlier this year to capture images from the areas where robots had not reached.</p><h2>___</h2><p>AP video journalist Ayaka McGill contributed to this report.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California is about to side with PG&E ‚Äì again ‚Äì to kill community solar projects (144 pts)]]></title>
            <link>https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php</link>
            <guid>40503592</guid>
            <pubDate>Tue, 28 May 2024 18:03:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php">https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php</a>, See on <a href="https://news.ycombinator.com/item?id=40503592">Hacker News</a></p>
Couldn't get https://www.sfchronicle.com/opinion/editorials/article/california-pge-community-solar-19468490.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[TTE: Terminal Text Effects (1248 pts)]]></title>
            <link>https://chrisbuilds.github.io/terminaltexteffects/showroom/</link>
            <guid>40503202</guid>
            <pubDate>Tue, 28 May 2024 17:31:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrisbuilds.github.io/terminaltexteffects/showroom/">https://chrisbuilds.github.io/terminaltexteffects/showroom/</a>, See on <a href="https://news.ycombinator.com/item?id=40503202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
              <article>
                
                  

  
  



<p>The effects shown below represent the built-in library of effects and their default configuration.</p>
<h2 id="beams">Beams</h2>
<p>Creates beams which travel over the canvas illuminating the characters.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/beams_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/beams/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/beams/#terminaltexteffects.effects.effect_beams.BeamsConfig">Config</a></p>
<details>
<summary>Beams Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>--beam-row-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>                    Symbols to use for the beam effect when moving along a row. Strings will be used in sequence to create an animation. (default: ('‚ñÇ', '‚ñÅ', '_'))
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>--beam-column-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>                    Symbols to use for the beam effect when moving along a column. Strings will be used in sequence to create an animation. (default: ('‚ñå', '‚ñç', '‚ñé', '‚ñè'))
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>--beam-delay (int &gt; 0)
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>                    Number of frames to wait before adding the next group of beams. Beams are added in groups of size random(1, 5). (default: 10)
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>--beam-row-speed-range (hyphen separated int range e.g. '1-10')
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>                    Minimum speed of the beam when moving along a row. (default: (10, 40))
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>--beam-column-speed-range (hyphen separated int range e.g. '1-10')
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>                    Minimum speed of the beam when moving along a column. (default: (6, 10))
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>--beam-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>                    Space separated, unquoted, list of colors for the beam, a gradient will be created between the colors. (default: ('ffffff', '00D1FF', '8A008A'))
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>--beam-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>                    Space separated, unquoted, numbers for the of gradient steps to use. More steps will create a smoother and longer gradient animation. Steps are paired with the colors in final-gradient-
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>                    stops. (default: (2, 8))
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>--beam-gradient-frames (int &gt; 0)
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 2)
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>                    Space separated, unquoted, list of colors for the wipe gradient. (default: ('8A008A', '00D1FF', 'ffffff'))
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>                    Space separated, unquoted, numbers for the of gradient steps to use. More steps will create a smoother and longer gradient animation. Steps are paired with the colors in final-gradient-
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>                    stops. (default: (12,))
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>--final-wipe-speed (int &gt; 0)
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>                    Speed of the final wipe as measured in diagonal groups activated per frame. (default: 1)
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>Example: terminaltexteffects beams --beam-row-symbols ‚ñÇ ‚ñÅ _ --beam-column-symbols ‚ñå ‚ñç ‚ñé ‚ñè --beam-delay 10 --beam-row-speed-range 10-40 --beam-column-speed-range 6-10 --beam-gradient-stops ffffff 00D1FF 8A008A --beam-gradient-steps 2 8 --beam-gradient-frames 2 --final-gradient-stops 8A008A 00D1FF ffffff --final-gradient-steps 12 --final-gradient-frames 5 --final-gradient-direction vertical --final-wipe-speed 1
</span></code></pre></div>
</details>
<hr>
<h2 id="binarypath">Binarypath</h2>
<p>Decodes characters into their binary form. Characters travel from outside the canvas towards their input coordinate, moving at right angles.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/binarypath_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/binarypath/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/binarypath/#terminaltexteffects.effects.effect_binarypath.BinaryPathConfig">Config</a></p>
<details>
<summary>Binarypath Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>                    (default: ('00d500', '007500'))
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>                    Direction of the final gradient. (default: Direction.CENTER)
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>--binary-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>                    Space separated, unquoted, list of colors for the binary characters. Character color is randomly assigned from this list. (default: ('044E29', '157e38', '45bf55', '95ed87'))
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>                    Speed of the binary groups as they travel around the terminal. (default: 1.0)
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>--active-binary-groups (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>                    Maximum number of binary groups that are active at any given time. Lower this to improve performance. (default: 0.05)
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>Example: terminaltexteffects binarypath --final-gradient-stops 00d500 007500 --final-gradient-steps 12 --final-gradient-direction vertical --binary-colors 044E29 157e38 45bf55 95ed87 --movement-speed 1.0 --active-binary-groups 0.05
</span></code></pre></div>
</details>
<hr>
<h2 id="blackhole">Blackhole</h2>
<p>Creates a blackhole in a starfield, consumes the stars, explodes the input data back into position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/blackhole_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/blackhole/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/blackhole/#terminaltexteffects.effects.effect_blackhole.BlackholeConfig">Config</a></p>
<details>
<summary>Blackhole Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>--blackhole-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>                    Color for the stars that comprise the blackhole border. (default: ffffff)
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>--star-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>                    List of colors from which character colors will be chosen and applied after the explosion, but before the cooldown to final color. (default: ('ffcc0d', 'ff7326', 'ff194d', 'bf2669',
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>                    '702a8c', '049dbf'))
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>                    (default: ('8A008A', '00D1FF', 'ffffff'))
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>Example: terminaltexteffects blackhole --star-colors ffcc0d ff7326 ff194d bf2669 702a8c 049dbf --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --final-gradient-direction vertical
</span></code></pre></div>
</details>
<hr>
<h2 id="bouncyballs">BouncyBalls</h2>
<p>Characters fall from the top of the canvas as bouncy balls before settling into place.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/bouncyballs_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bouncyballs/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bouncyballs/#terminaltexteffects.effects.effect_bouncyballs.BouncyBallsConfig">Config</a></p>
<details>
<summary>Bouncyballs Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>--ball-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>                    Space separated list of colors from which ball colors will be randomly selected. If no colors are provided, the colors are random. (default: ('d1f4a5', '96e2a4', '5acda9'))
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>--ball-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>                    Space separated list of symbols to use for the balls. (default: ('*', 'o', 'O', '0', '.'))
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>                    (default: ('f8ffae', '43c6ac'))
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>--ball-delay (int &gt;= 0)
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>                    Number of frames between ball drops, increase to reduce ball drop rate. (default: 7)
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>--movement-speed (float &gt; 0)
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>                    Movement speed of the characters.  (default: 0.25)
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>--easing EASING       Easing function to use for character movement. (default: out_bounce)
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>Easing
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>------
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>Note: A prefix must be added to the function name.
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>All easing functions support the following prefixes:
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>    IN_  - Ease in
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>    OUT_ - Ease out
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-3-26"><a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>
</span><span id="__span-3-27"><a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>Easing Functions
</span><span id="__span-3-28"><a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>----------------
</span><span id="__span-3-29"><a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>SINE   - Sine easing
</span><span id="__span-3-30"><a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>QUAD   - Quadratic easing
</span><span id="__span-3-31"><a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>CUBIC  - Cubic easing
</span><span id="__span-3-32"><a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>QUART  - Quartic easing
</span><span id="__span-3-33"><a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>QUINT  - Quintic easing
</span><span id="__span-3-34"><a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>EXPO   - Exponential easing
</span><span id="__span-3-35"><a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>CIRC   - Circular easing
</span><span id="__span-3-36"><a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a>BACK   - Back easing
</span><span id="__span-3-37"><a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>ELASTIC - Elastic easing
</span><span id="__span-3-38"><a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a>BOUNCE - Bounce easing
</span><span id="__span-3-39"><a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>
</span><span id="__span-3-40"><a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-3-41"><a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>
</span><span id="__span-3-42"><a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a>Example: terminaltexteffects bouncyballs --ball-colors d1f4a5 96e2a4 5acda9 --ball-symbols o "*" O 0 . --final-gradient-stops f8ffae 43c6ac --final-gradient-steps 12 --final-gradient-direction diagonal --ball-delay 7 --movement-speed 0.25 --easing OUT_BOUNCE
</span></code></pre></div>
</details>
<hr>
<h2 id="bubbles">Bubbles</h2>
<p>Forms bubbles with the characters. Bubbles float down and pop.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/bubbles_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bubbles/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/bubbles/#terminaltexteffects.effects.effect_bubbles.BubblesConfig">Config</a></p>
<details>
<summary>Bubbles Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>--rainbow             If set, the bubbles will be colored with a rotating rainbow gradient. (default: False)
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>--bubble-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>                    Space separated, unquoted, list of colors for the bubbles. Ignored if --no-rainbow is left as default False. (default: ('d33aff', '7395c4', '43c2a7', '02ff7f'))
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>--pop-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>                    Color for the spray emitted when a bubble pops. (default: ffffff)
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>                    (default: ('d33aff', '02ff7f'))
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>--bubble-speed (float &gt; 0)
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>                    Speed of the floating bubbles.  (default: 0.1)
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>--bubble-delay (int &gt; 0)
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>                    Number of frames between bubbles. (default: 50)
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>--pop-condition {row,bottom,anywhere}
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>                    Condition for a bubble to pop. 'row' will pop the bubble when it reaches the the lowest row for which a character in the bubble originates. 'bottom' will pop the bubble at the bottom
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>                    row of the terminal. 'anywhere' will pop the bubble randomly, or at the bottom of the terminal. (default: row)
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>--easing (Easing Function)
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>                    Easing function to use for character movement after a bubble pops. (default: in_out_sine)
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>Easing
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>------
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>Note: A prefix must be added to the function name.
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>All easing functions support the following prefixes:
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>    IN_  - Ease in
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>    OUT_ - Ease out
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-4-31"><a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a>
</span><span id="__span-4-32"><a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>Easing Functions
</span><span id="__span-4-33"><a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a>----------------
</span><span id="__span-4-34"><a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a>SINE   - Sine easing
</span><span id="__span-4-35"><a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a>QUAD   - Quadratic easing
</span><span id="__span-4-36"><a id="__codelineno-4-36" name="__codelineno-4-36" href="#__codelineno-4-36"></a>CUBIC  - Cubic easing
</span><span id="__span-4-37"><a id="__codelineno-4-37" name="__codelineno-4-37" href="#__codelineno-4-37"></a>QUART  - Quartic easing
</span><span id="__span-4-38"><a id="__codelineno-4-38" name="__codelineno-4-38" href="#__codelineno-4-38"></a>QUINT  - Quintic easing
</span><span id="__span-4-39"><a id="__codelineno-4-39" name="__codelineno-4-39" href="#__codelineno-4-39"></a>EXPO   - Exponential easing
</span><span id="__span-4-40"><a id="__codelineno-4-40" name="__codelineno-4-40" href="#__codelineno-4-40"></a>CIRC   - Circular easing
</span><span id="__span-4-41"><a id="__codelineno-4-41" name="__codelineno-4-41" href="#__codelineno-4-41"></a>BACK   - Back easing
</span><span id="__span-4-42"><a id="__codelineno-4-42" name="__codelineno-4-42" href="#__codelineno-4-42"></a>ELASTIC - Elastic easing
</span><span id="__span-4-43"><a id="__codelineno-4-43" name="__codelineno-4-43" href="#__codelineno-4-43"></a>BOUNCE - Bounce easing
</span><span id="__span-4-44"><a id="__codelineno-4-44" name="__codelineno-4-44" href="#__codelineno-4-44"></a>
</span><span id="__span-4-45"><a id="__codelineno-4-45" name="__codelineno-4-45" href="#__codelineno-4-45"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-4-46"><a id="__codelineno-4-46" name="__codelineno-4-46" href="#__codelineno-4-46"></a>
</span><span id="__span-4-47"><a id="__codelineno-4-47" name="__codelineno-4-47" href="#__codelineno-4-47"></a>Example: terminaltexteffects bubbles --bubble-colors d33aff 7395c4 43c2a7 02ff7f --pop-color ffffff --final-gradient-stops d33aff 02ff7f --final-gradient-steps 12 --final-gradient-direction diagonal --bubble-speed 0.1 --bubble-delay 50 --pop-condition row --easing IN_OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="burn">Burn</h2>
<p>Characters are ignited and burn up the screen.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/burn_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/burn/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/burn/#terminaltexteffects.effects.effect_burn.BurnConfig">Config</a></p>
<details>
<summary>Burn Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>                    Color of the characters before they start to burn. (default: 837373)
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>--burn-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>                    Colors transitioned through as the characters burn. (default: ('ffffff', 'fff75d', 'fe650d', '8A003C', '510100'))
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>                    (default: ('00c3ff', 'ffff1c'))
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>Example: terminaltexteffects burn --starting-color 837373 --burn-colors ffffff fff75d fe650d 8a003c 510100 --final-gradient-stops 00c3ff ffff1c --final-gradient-steps 12
</span></code></pre></div>
</details>
<hr>
<h2 id="colorshift">ColorShift</h2>
<p>Display a gradient that shifts colors across the terminal.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/colorshift_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/colorshift/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/colorshift/#terminaltexteffects.effects.effect_colorshift.ColorShiftConfig">Config</a></p>
<details>
<summary>ColorShift Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>--gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>                    Space separated, unquoted, list of colors for the gradient. (default: (Color(e81416), Color(ffa500), Color(faeb36), Color(79c314), Color(487de7), Color(4b369d), Color(70369d)))
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>--gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>                    Number of gradient steps to use. More steps will create a smoother gradient animation. (default: 12)
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>--gradient-frames (int &gt; 0)
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>--travel              Display the gradient as a traveling wave (default: False)
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>--travel-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>                    Direction the gradient travels across the canvas. (default: Direction.HORIZONTAL)
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>--reverse-travel-direction
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>                    Reverse the gradient travel direction. (default: False)
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>--loop-gradient       Loop the gradient. This causes the final gradient color to transition back to the first gradient color. (default: False)
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>--cycles (int &gt; 0)    Number of times to cycle the gradient. (default: 3)
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>--skip-final-gradient
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>                    Skip the final gradient. (default: False)
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>                    (default: (Color(e81416), Color(ffa500), Color(faeb36), Color(79c314), Color(487de7), Color(4b369d), Color(70369d)))
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-6-22"><a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-6-23"><a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>
</span><span id="__span-6-24"><a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>Example: terminaltexteffects colorshift --gradient-stops 0000ff ffffff 0000ff --gradient-steps 12
</span><span id="__span-6-25"><a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a>        --gradient-frames 10 --cycles 3 --travel --travel-direction radial --loop --final-gradient-stops 00c3ff ffff1c --final-gradient-steps 12
</span></code></pre></div>
</details>
<hr>
<h2 id="crumble">Crumble</h2>
<p>Characters crumble into dust before being vacuumed up and reformed.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/crumble_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/crumble/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/crumble/#terminaltexteffects.effects.effect_crumble.CrumbleConfig">Config</a></p>
<details>
<summary>Crumble Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>                    (default: ('5CE1FF', 'FF8C00'))
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>Example: terminaltexteffects crumble --final-gradient-stops 5CE1FF FF8C00 --final-gradient-steps 12 --final-gradient-direction diagonal
</span></code></pre></div>
</details>
<hr>
<h2 id="decrypt">Decrypt</h2>
<p>Movie style text decryption effect.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/decrypt_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/decrypt/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/decrypt/#terminaltexteffects.effects.effect_decrypt.DecryptConfig">Config</a></p>
<details>
<summary>Decrypt Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>--typing-speed (int &gt; 0)
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>                    Number of characters typed per keystroke. (default: 1)
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>--ciphertext-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>                    Space separated, unquoted, list of colors for the ciphertext. Color will be randomly selected for each character. (default: ('008000', '00cb00', '00ff00'))
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>                    (default: ('eda000',))
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>Example: terminaltexteffects decrypt --typing-speed 2 --ciphertext-colors 008000 00cb00 00ff00 --final-gradient-stops eda000 --final-gradient-steps 12 --final-gradient-direction vertical
</span></code></pre></div>
</details>
<hr>
<h2 id="errorcorrect">ErrorCorrect</h2>
<p>Swaps characters from an incorrect initial position to the correct position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/errorcorrect_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/errorcorrect/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/errorcorrect/#terminaltexteffects.effects.effect_errorcorrect.ErrorCorrectConfig">Config</a></p>
<details>
<summary>ErrorCorrect Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>--error-pairs (int &gt; 0)
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>                        Percent of characters that are in the wrong position. This is a float between 0 and 1.0. 0.2 means 20 percent of the characters will be in the wrong position. (default: 0.1)
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>--swap-delay (int &gt; 0)
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>                        Number of frames between swaps. (default: 10)
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>--error-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>                        Color for the characters that are in the wrong position. (default: e74c3c)
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>--correct-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>                        Color for the characters once corrected, this is a gradient from error-color and fades to final-color. (default: 45bf55)
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>                        Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a>                        (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>                        Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>                        Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a>--movement-speed (float &gt; 0)
</span><span id="__span-9-17"><a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a>                        Speed of the characters while moving to the correct position. Valid values are n &gt; 0. Adjust speed and animation rate separately to fine tune the
</span><span id="__span-9-18"><a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a>                        effect. (default: 0.5)
</span><span id="__span-9-19"><a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>
</span><span id="__span-9-20"><a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a>    Easing
</span><span id="__span-9-21"><a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a>    ------
</span><span id="__span-9-22"><a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a>    Note: A prefix must be added to the function name.
</span><span id="__span-9-23"><a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>
</span><span id="__span-9-24"><a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a>    All easing functions support the following prefixes:
</span><span id="__span-9-25"><a id="__codelineno-9-25" name="__codelineno-9-25" href="#__codelineno-9-25"></a>        IN_  - Ease in
</span><span id="__span-9-26"><a id="__codelineno-9-26" name="__codelineno-9-26" href="#__codelineno-9-26"></a>        OUT_ - Ease out
</span><span id="__span-9-27"><a id="__codelineno-9-27" name="__codelineno-9-27" href="#__codelineno-9-27"></a>        IN_OUT_ - Ease in and out
</span><span id="__span-9-28"><a id="__codelineno-9-28" name="__codelineno-9-28" href="#__codelineno-9-28"></a>
</span><span id="__span-9-29"><a id="__codelineno-9-29" name="__codelineno-9-29" href="#__codelineno-9-29"></a>    Easing Functions
</span><span id="__span-9-30"><a id="__codelineno-9-30" name="__codelineno-9-30" href="#__codelineno-9-30"></a>    ----------------
</span><span id="__span-9-31"><a id="__codelineno-9-31" name="__codelineno-9-31" href="#__codelineno-9-31"></a>    SINE   - Sine easing
</span><span id="__span-9-32"><a id="__codelineno-9-32" name="__codelineno-9-32" href="#__codelineno-9-32"></a>    QUAD   - Quadratic easing
</span><span id="__span-9-33"><a id="__codelineno-9-33" name="__codelineno-9-33" href="#__codelineno-9-33"></a>    CUBIC  - Cubic easing
</span><span id="__span-9-34"><a id="__codelineno-9-34" name="__codelineno-9-34" href="#__codelineno-9-34"></a>    QUART  - Quartic easing
</span><span id="__span-9-35"><a id="__codelineno-9-35" name="__codelineno-9-35" href="#__codelineno-9-35"></a>    QUINT  - Quintic easing
</span><span id="__span-9-36"><a id="__codelineno-9-36" name="__codelineno-9-36" href="#__codelineno-9-36"></a>    EXPO   - Exponential easing
</span><span id="__span-9-37"><a id="__codelineno-9-37" name="__codelineno-9-37" href="#__codelineno-9-37"></a>    CIRC   - Circular easing
</span><span id="__span-9-38"><a id="__codelineno-9-38" name="__codelineno-9-38" href="#__codelineno-9-38"></a>    BACK   - Back easing
</span><span id="__span-9-39"><a id="__codelineno-9-39" name="__codelineno-9-39" href="#__codelineno-9-39"></a>    ELASTIC - Elastic easing
</span><span id="__span-9-40"><a id="__codelineno-9-40" name="__codelineno-9-40" href="#__codelineno-9-40"></a>    BOUNCE - Bounce easing
</span><span id="__span-9-41"><a id="__codelineno-9-41" name="__codelineno-9-41" href="#__codelineno-9-41"></a>
</span><span id="__span-9-42"><a id="__codelineno-9-42" name="__codelineno-9-42" href="#__codelineno-9-42"></a>    Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-9-43"><a id="__codelineno-9-43" name="__codelineno-9-43" href="#__codelineno-9-43"></a>
</span><span id="__span-9-44"><a id="__codelineno-9-44" name="__codelineno-9-44" href="#__codelineno-9-44"></a>
</span><span id="__span-9-45"><a id="__codelineno-9-45" name="__codelineno-9-45" href="#__codelineno-9-45"></a>Example: terminaltexteffects errorcorrect --error-pairs 0.1 --swap-delay 10 --error-color e74c3c --correct-color 45bf55 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --movement-speed 0.5
</span></code></pre></div>
</details>
<hr>
<h2 id="expand">Expand</h2>
<p>Characters expand from the center.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/expand_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/expand/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/expand/#terminaltexteffects.effects.effect_expand.ExpandConfig">Config</a></p>
<details>
<summary>Expand Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>                    Movement speed of the characters.  (default: 0.35)
</span><span id="__span-10-12"><a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a>--expand-easing EXPAND_EASING
</span><span id="__span-10-13"><a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a>                    Easing function to use for character movement. (default: in_out_quart)
</span><span id="__span-10-14"><a id="__codelineno-10-14" name="__codelineno-10-14" href="#__codelineno-10-14"></a>
</span><span id="__span-10-15"><a id="__codelineno-10-15" name="__codelineno-10-15" href="#__codelineno-10-15"></a>Easing
</span><span id="__span-10-16"><a id="__codelineno-10-16" name="__codelineno-10-16" href="#__codelineno-10-16"></a>------
</span><span id="__span-10-17"><a id="__codelineno-10-17" name="__codelineno-10-17" href="#__codelineno-10-17"></a>Note: A prefix must be added to the function name.
</span><span id="__span-10-18"><a id="__codelineno-10-18" name="__codelineno-10-18" href="#__codelineno-10-18"></a>
</span><span id="__span-10-19"><a id="__codelineno-10-19" name="__codelineno-10-19" href="#__codelineno-10-19"></a>All easing functions support the following prefixes:
</span><span id="__span-10-20"><a id="__codelineno-10-20" name="__codelineno-10-20" href="#__codelineno-10-20"></a>    IN_  - Ease in
</span><span id="__span-10-21"><a id="__codelineno-10-21" name="__codelineno-10-21" href="#__codelineno-10-21"></a>    OUT_ - Ease out
</span><span id="__span-10-22"><a id="__codelineno-10-22" name="__codelineno-10-22" href="#__codelineno-10-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-10-23"><a id="__codelineno-10-23" name="__codelineno-10-23" href="#__codelineno-10-23"></a>
</span><span id="__span-10-24"><a id="__codelineno-10-24" name="__codelineno-10-24" href="#__codelineno-10-24"></a>Easing Functions
</span><span id="__span-10-25"><a id="__codelineno-10-25" name="__codelineno-10-25" href="#__codelineno-10-25"></a>----------------
</span><span id="__span-10-26"><a id="__codelineno-10-26" name="__codelineno-10-26" href="#__codelineno-10-26"></a>SINE   - Sine easing
</span><span id="__span-10-27"><a id="__codelineno-10-27" name="__codelineno-10-27" href="#__codelineno-10-27"></a>QUAD   - Quadratic easing
</span><span id="__span-10-28"><a id="__codelineno-10-28" name="__codelineno-10-28" href="#__codelineno-10-28"></a>CUBIC  - Cubic easing
</span><span id="__span-10-29"><a id="__codelineno-10-29" name="__codelineno-10-29" href="#__codelineno-10-29"></a>QUART  - Quartic easing
</span><span id="__span-10-30"><a id="__codelineno-10-30" name="__codelineno-10-30" href="#__codelineno-10-30"></a>QUINT  - Quintic easing
</span><span id="__span-10-31"><a id="__codelineno-10-31" name="__codelineno-10-31" href="#__codelineno-10-31"></a>EXPO   - Exponential easing
</span><span id="__span-10-32"><a id="__codelineno-10-32" name="__codelineno-10-32" href="#__codelineno-10-32"></a>CIRC   - Circular easing
</span><span id="__span-10-33"><a id="__codelineno-10-33" name="__codelineno-10-33" href="#__codelineno-10-33"></a>BACK   - Back easing
</span><span id="__span-10-34"><a id="__codelineno-10-34" name="__codelineno-10-34" href="#__codelineno-10-34"></a>ELASTIC - Elastic easing
</span><span id="__span-10-35"><a id="__codelineno-10-35" name="__codelineno-10-35" href="#__codelineno-10-35"></a>BOUNCE - Bounce easing
</span><span id="__span-10-36"><a id="__codelineno-10-36" name="__codelineno-10-36" href="#__codelineno-10-36"></a>
</span><span id="__span-10-37"><a id="__codelineno-10-37" name="__codelineno-10-37" href="#__codelineno-10-37"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-10-38"><a id="__codelineno-10-38" name="__codelineno-10-38" href="#__codelineno-10-38"></a>
</span><span id="__span-10-39"><a id="__codelineno-10-39" name="__codelineno-10-39" href="#__codelineno-10-39"></a>
</span><span id="__span-10-40"><a id="__codelineno-10-40" name="__codelineno-10-40" href="#__codelineno-10-40"></a>Example: terminaltexteffects expand --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --final-gradient-frames 5 --movement-speed 0.35 --expand-easing IN_OUT_QUART
</span></code></pre></div>
</details>
<hr>
<h2 id="fireworks">Fireworks</h2>
<p>Launches characters up the screen where they explode like fireworks and fall into place.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/fireworks_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/fireworks/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/fireworks/#terminaltexteffects.effects.effect_fireworks.FireworksConfig">Config</a></p>
<details>
<summary>Fireworks Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>--explode-anywhere    If set, fireworks explode anywhere in the canvas. Otherwise, fireworks explode above highest settled row of text. (default: False)
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>--firework-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>                    Space separated list of colors from which firework colors will be randomly selected. (default: ('88F7E2', '44D492', 'F5EB67', 'FFA15C', 'FA233E'))
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>--firework-symbol (ASCII/UTF-8 character)
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>                    Symbol to use for the firework shell. (default: o)
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>--firework-volume (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>                    Percent of total characters in each firework shell. (default: 0.02)
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-11-14"><a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>                    Direction of the final gradient. (default: Direction.HORIZONTAL)
</span><span id="__span-11-15"><a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>--launch-delay (int &gt;= 0)
</span><span id="__span-11-16"><a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a>                    Number of frames to wait between launching each firework shell. +/- 0-50 percent randomness is applied to this value. (default: 60)
</span><span id="__span-11-17"><a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>--explode-distance (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-11-18"><a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a>                    Maximum distance from the firework shell origin to the explode waypoint as a percentage of the total canvas width. (default: 0.1)
</span><span id="__span-11-19"><a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a>
</span><span id="__span-11-20"><a id="__codelineno-11-20" name="__codelineno-11-20" href="#__codelineno-11-20"></a>Example: terminaltexteffects fireworks --firework-colors 88F7E2 44D492 F5EB67 FFA15C FA233E --firework-symbol o --firework-volume 0.02 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --launch-delay 60 --explode-distance 0.1 --explode-anywhere
</span></code></pre></div>
</details>
<hr>
<h2 id="middleout">MiddleOut</h2>
<p>Text expands in a single row or column in the middle of the canvas then out.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/middleout_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/middleout/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/middleout/#terminaltexteffects.effects.effect_middleout.MiddleOutConfig">Config</a></p>
<details>
<summary>MiddleOut Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>                    Color for the initial text in the center of the canvas. (default: ffffff)
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>--expand-direction {vertical,horizontal}
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>                    Direction the text will expand. (default: vertical)
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>--center-movement-speed (float &gt; 0)
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>                    Speed of the characters during the initial expansion of the center vertical/horiztonal line. Note: Speed effects the number of steps in the easing function. Adjust speed and animation
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>                    rate separately to fine tune the effect. (default: 0.35)
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>--full-movement-speed (float &gt; 0)
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>                    Speed of the characters during the final full expansion. Note: Speed effects the number of steps in the easing function. Adjust speed and animation rate separately to fine tune the
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>                    effect. (default: 0.35)
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>--center-easing CENTER_EASING
</span><span id="__span-12-19"><a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>                    Easing function to use for initial expansion. (default: in_out_sine)
</span><span id="__span-12-20"><a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>--full-easing FULL_EASING
</span><span id="__span-12-21"><a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>                    Easing function to use for full expansion. (default: in_out_sine)
</span><span id="__span-12-22"><a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>
</span><span id="__span-12-23"><a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>Easing
</span><span id="__span-12-24"><a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a>------
</span><span id="__span-12-25"><a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a>Note: A prefix must be added to the function name.
</span><span id="__span-12-26"><a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a>
</span><span id="__span-12-27"><a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a>All easing functions support the following prefixes:
</span><span id="__span-12-28"><a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a>    IN_  - Ease in
</span><span id="__span-12-29"><a id="__codelineno-12-29" name="__codelineno-12-29" href="#__codelineno-12-29"></a>    OUT_ - Ease out
</span><span id="__span-12-30"><a id="__codelineno-12-30" name="__codelineno-12-30" href="#__codelineno-12-30"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-12-31"><a id="__codelineno-12-31" name="__codelineno-12-31" href="#__codelineno-12-31"></a>
</span><span id="__span-12-32"><a id="__codelineno-12-32" name="__codelineno-12-32" href="#__codelineno-12-32"></a>Easing Functions
</span><span id="__span-12-33"><a id="__codelineno-12-33" name="__codelineno-12-33" href="#__codelineno-12-33"></a>----------------
</span><span id="__span-12-34"><a id="__codelineno-12-34" name="__codelineno-12-34" href="#__codelineno-12-34"></a>SINE   - Sine easing
</span><span id="__span-12-35"><a id="__codelineno-12-35" name="__codelineno-12-35" href="#__codelineno-12-35"></a>QUAD   - Quadratic easing
</span><span id="__span-12-36"><a id="__codelineno-12-36" name="__codelineno-12-36" href="#__codelineno-12-36"></a>CUBIC  - Cubic easing
</span><span id="__span-12-37"><a id="__codelineno-12-37" name="__codelineno-12-37" href="#__codelineno-12-37"></a>QUART  - Quartic easing
</span><span id="__span-12-38"><a id="__codelineno-12-38" name="__codelineno-12-38" href="#__codelineno-12-38"></a>QUINT  - Quintic easing
</span><span id="__span-12-39"><a id="__codelineno-12-39" name="__codelineno-12-39" href="#__codelineno-12-39"></a>EXPO   - Exponential easing
</span><span id="__span-12-40"><a id="__codelineno-12-40" name="__codelineno-12-40" href="#__codelineno-12-40"></a>CIRC   - Circular easing
</span><span id="__span-12-41"><a id="__codelineno-12-41" name="__codelineno-12-41" href="#__codelineno-12-41"></a>BACK   - Back easing
</span><span id="__span-12-42"><a id="__codelineno-12-42" name="__codelineno-12-42" href="#__codelineno-12-42"></a>ELASTIC - Elastic easing
</span><span id="__span-12-43"><a id="__codelineno-12-43" name="__codelineno-12-43" href="#__codelineno-12-43"></a>BOUNCE - Bounce easing
</span><span id="__span-12-44"><a id="__codelineno-12-44" name="__codelineno-12-44" href="#__codelineno-12-44"></a>
</span><span id="__span-12-45"><a id="__codelineno-12-45" name="__codelineno-12-45" href="#__codelineno-12-45"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-12-46"><a id="__codelineno-12-46" name="__codelineno-12-46" href="#__codelineno-12-46"></a>
</span><span id="__span-12-47"><a id="__codelineno-12-47" name="__codelineno-12-47" href="#__codelineno-12-47"></a>Example: terminaltexteffects middleout --starting-color 8A008A --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --expand-direction vertical --center-movement-speed 0.35 --full-movement-speed 0.35 --center-easing IN_OUT_SINE --full-easing IN_OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="orbittingvolley">OrbittingVolley</h2>
<p>Four launchers orbit the canvas firing volleys of characters inward to build the input text from the center out.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/orbittingvolley_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/orbittingvolley/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/orbittingvolley/#terminaltexteffects.effects.effect_orbittingvolley.OrbittingVolleyConfig">Config</a></p>
<details>
<summary>OrbittingVolley Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>--top-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>                    Symbol for the top launcher. (default: ‚ñà)
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>--right-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>                    Symbol for the right launcher. (default: ‚ñà)
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>--bottom-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>                    Symbol for the bottom launcher. (default: ‚ñà)
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>--left-launcher-symbol (ASCII/UTF-8 character)
</span><span id="__span-13-8"><a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>                    Symbol for the left launcher. (default: ‚ñà)
</span><span id="__span-13-9"><a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-13-10"><a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-13-11"><a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>                    (default: ('FFA15C', '44D492'))
</span><span id="__span-13-12"><a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-13-13"><a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-13-14"><a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-13-15"><a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a>                    Direction of the final gradient. (default: Direction.RADIAL)
</span><span id="__span-13-16"><a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a>--launcher-movement-speed (float &gt; 0)
</span><span id="__span-13-17"><a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a>                    Orbitting speed of the launchers. (default: 0.5)
</span><span id="__span-13-18"><a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a>--character-movement-speed (float &gt; 0)
</span><span id="__span-13-19"><a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a>                    Speed of the launched characters. (default: 1)
</span><span id="__span-13-20"><a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a>--volley-size (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-13-21"><a id="__codelineno-13-21" name="__codelineno-13-21" href="#__codelineno-13-21"></a>                    Percent of total input characters each launcher will fire per volley. Lower limit of one character. (default: 0.03)
</span><span id="__span-13-22"><a id="__codelineno-13-22" name="__codelineno-13-22" href="#__codelineno-13-22"></a>--launch-delay (int &gt;= 0)
</span><span id="__span-13-23"><a id="__codelineno-13-23" name="__codelineno-13-23" href="#__codelineno-13-23"></a>                    Number of animation ticks to wait between volleys of characters. (default: 50)
</span><span id="__span-13-24"><a id="__codelineno-13-24" name="__codelineno-13-24" href="#__codelineno-13-24"></a>--character-easing (Easing Function)
</span><span id="__span-13-25"><a id="__codelineno-13-25" name="__codelineno-13-25" href="#__codelineno-13-25"></a>                    Easing function to use for launched character movement. (default: out_sine)
</span><span id="__span-13-26"><a id="__codelineno-13-26" name="__codelineno-13-26" href="#__codelineno-13-26"></a>
</span><span id="__span-13-27"><a id="__codelineno-13-27" name="__codelineno-13-27" href="#__codelineno-13-27"></a>Easing
</span><span id="__span-13-28"><a id="__codelineno-13-28" name="__codelineno-13-28" href="#__codelineno-13-28"></a>------
</span><span id="__span-13-29"><a id="__codelineno-13-29" name="__codelineno-13-29" href="#__codelineno-13-29"></a>Note: A prefix must be added to the function name.
</span><span id="__span-13-30"><a id="__codelineno-13-30" name="__codelineno-13-30" href="#__codelineno-13-30"></a>
</span><span id="__span-13-31"><a id="__codelineno-13-31" name="__codelineno-13-31" href="#__codelineno-13-31"></a>All easing functions support the following prefixes:
</span><span id="__span-13-32"><a id="__codelineno-13-32" name="__codelineno-13-32" href="#__codelineno-13-32"></a>    IN_  - Ease in
</span><span id="__span-13-33"><a id="__codelineno-13-33" name="__codelineno-13-33" href="#__codelineno-13-33"></a>    OUT_ - Ease out
</span><span id="__span-13-34"><a id="__codelineno-13-34" name="__codelineno-13-34" href="#__codelineno-13-34"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-13-35"><a id="__codelineno-13-35" name="__codelineno-13-35" href="#__codelineno-13-35"></a>
</span><span id="__span-13-36"><a id="__codelineno-13-36" name="__codelineno-13-36" href="#__codelineno-13-36"></a>Easing Functions
</span><span id="__span-13-37"><a id="__codelineno-13-37" name="__codelineno-13-37" href="#__codelineno-13-37"></a>----------------
</span><span id="__span-13-38"><a id="__codelineno-13-38" name="__codelineno-13-38" href="#__codelineno-13-38"></a>SINE   - Sine easing
</span><span id="__span-13-39"><a id="__codelineno-13-39" name="__codelineno-13-39" href="#__codelineno-13-39"></a>QUAD   - Quadratic easing
</span><span id="__span-13-40"><a id="__codelineno-13-40" name="__codelineno-13-40" href="#__codelineno-13-40"></a>CUBIC  - Cubic easing
</span><span id="__span-13-41"><a id="__codelineno-13-41" name="__codelineno-13-41" href="#__codelineno-13-41"></a>QUART  - Quartic easing
</span><span id="__span-13-42"><a id="__codelineno-13-42" name="__codelineno-13-42" href="#__codelineno-13-42"></a>QUINT  - Quintic easing
</span><span id="__span-13-43"><a id="__codelineno-13-43" name="__codelineno-13-43" href="#__codelineno-13-43"></a>EXPO   - Exponential easing
</span><span id="__span-13-44"><a id="__codelineno-13-44" name="__codelineno-13-44" href="#__codelineno-13-44"></a>CIRC   - Circular easing
</span><span id="__span-13-45"><a id="__codelineno-13-45" name="__codelineno-13-45" href="#__codelineno-13-45"></a>BACK   - Back easing
</span><span id="__span-13-46"><a id="__codelineno-13-46" name="__codelineno-13-46" href="#__codelineno-13-46"></a>ELASTIC - Elastic easing
</span><span id="__span-13-47"><a id="__codelineno-13-47" name="__codelineno-13-47" href="#__codelineno-13-47"></a>BOUNCE - Bounce easing
</span><span id="__span-13-48"><a id="__codelineno-13-48" name="__codelineno-13-48" href="#__codelineno-13-48"></a>
</span><span id="__span-13-49"><a id="__codelineno-13-49" name="__codelineno-13-49" href="#__codelineno-13-49"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-13-50"><a id="__codelineno-13-50" name="__codelineno-13-50" href="#__codelineno-13-50"></a>
</span><span id="__span-13-51"><a id="__codelineno-13-51" name="__codelineno-13-51" href="#__codelineno-13-51"></a>
</span><span id="__span-13-52"><a id="__codelineno-13-52" name="__codelineno-13-52" href="#__codelineno-13-52"></a>Example: terminaltexteffects orbittingvolley --top-launcher-symbol ‚ñà --right-launcher-symbol ‚ñà --bottom-launcher-symbol ‚ñà --left-launcher-symbol ‚ñà --final-gradient-stops FFA15C 44D492 --final-gradient-steps 12 --launcher-movement-speed 0.5 --character-movement-speed 1 --volley-size 0.03 --launch-delay 50 --character-easing OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="overflow">Overflow</h2>
<p>Input text overflows ands scrolls the terminal in a random order until eventually appearing ordered.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/overflow_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/overflow/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/overflow/#terminaltexteffects.effects.effect_overflow.OverflowConfig">Config</a></p>
<details>
<summary>Overflow Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>--overflow-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>                    Space separated, unquoted, list of colors for the overflow gradient. (default: ('f2ebc0', '8dbfb3', 'f2ebc0'))
</span><span id="__span-14-10"><a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a>--overflow-cycles-range (hyphen separated int range e.g. '1-10')
</span><span id="__span-14-11"><a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a>                    Number of cycles to overflow the text. (default: (2, 4))
</span><span id="__span-14-12"><a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a>--overflow-speed (int &gt; 0)
</span><span id="__span-14-13"><a id="__codelineno-14-13" name="__codelineno-14-13" href="#__codelineno-14-13"></a>                    Speed of the overflow effect. (default: 3)
</span><span id="__span-14-14"><a id="__codelineno-14-14" name="__codelineno-14-14" href="#__codelineno-14-14"></a>
</span><span id="__span-14-15"><a id="__codelineno-14-15" name="__codelineno-14-15" href="#__codelineno-14-15"></a>Example: terminaltexteffects overflow --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --overflow-gradient-stops f2ebc0 8dbfb3 f2ebc0 --overflow-cycles-range 2-4 --overflow-speed 3
</span></code></pre></div>
</details>
<hr>
<h2 id="pour">Pour</h2>
<p>Pours the characters back and forth from the top, bottom, left, or right.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/pour_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/pour/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/pour/#terminaltexteffects.effects.effect_pour.PourConfig">Config</a></p>
<details>
<summary>Pour Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>--pour-direction {up,down,left,right}
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>                    Direction the text will pour. (default: down)
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>--pour-speed (int &gt; 0)
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>                    Number of characters poured in per tick. Increase to speed up the effect. (default: 1)
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>--movement-speed (float &gt; 0)
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>                    Movement speed of the characters.  (default: 0.2)
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>--gap (int &gt;= 0)      Number of frames to wait between each character in the pour effect. Increase to slow down effect and create a more defined back and forth motion. (default: 1)
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>                    Color of the characters before the gradient starts. (default: ffffff)
</span><span id="__span-15-10"><a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-15-11"><a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>                    Space separated, unquoted, list of colors for the character gradient. If only one color is provided, the characters will be displayed in that color. (default: ('8A008A', '00D1FF',
</span><span id="__span-15-12"><a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>                    'FFFFFF'))
</span><span id="__span-15-13"><a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>--final-gradient-steps (int &gt; 0)
</span><span id="__span-15-14"><a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-15-15"><a id="__codelineno-15-15" name="__codelineno-15-15" href="#__codelineno-15-15"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-15-16"><a id="__codelineno-15-16" name="__codelineno-15-16" href="#__codelineno-15-16"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 10)
</span><span id="__span-15-17"><a id="__codelineno-15-17" name="__codelineno-15-17" href="#__codelineno-15-17"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-15-18"><a id="__codelineno-15-18" name="__codelineno-15-18" href="#__codelineno-15-18"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-15-19"><a id="__codelineno-15-19" name="__codelineno-15-19" href="#__codelineno-15-19"></a>--easing EASING       Easing function to use for character movement. (default: in_quad)
</span><span id="__span-15-20"><a id="__codelineno-15-20" name="__codelineno-15-20" href="#__codelineno-15-20"></a>
</span><span id="__span-15-21"><a id="__codelineno-15-21" name="__codelineno-15-21" href="#__codelineno-15-21"></a>Easing
</span><span id="__span-15-22"><a id="__codelineno-15-22" name="__codelineno-15-22" href="#__codelineno-15-22"></a>------
</span><span id="__span-15-23"><a id="__codelineno-15-23" name="__codelineno-15-23" href="#__codelineno-15-23"></a>Note: A prefix must be added to the function name.
</span><span id="__span-15-24"><a id="__codelineno-15-24" name="__codelineno-15-24" href="#__codelineno-15-24"></a>
</span><span id="__span-15-25"><a id="__codelineno-15-25" name="__codelineno-15-25" href="#__codelineno-15-25"></a>All easing functions support the following prefixes:
</span><span id="__span-15-26"><a id="__codelineno-15-26" name="__codelineno-15-26" href="#__codelineno-15-26"></a>    IN_  - Ease in
</span><span id="__span-15-27"><a id="__codelineno-15-27" name="__codelineno-15-27" href="#__codelineno-15-27"></a>    OUT_ - Ease out
</span><span id="__span-15-28"><a id="__codelineno-15-28" name="__codelineno-15-28" href="#__codelineno-15-28"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-15-29"><a id="__codelineno-15-29" name="__codelineno-15-29" href="#__codelineno-15-29"></a>
</span><span id="__span-15-30"><a id="__codelineno-15-30" name="__codelineno-15-30" href="#__codelineno-15-30"></a>Easing Functions
</span><span id="__span-15-31"><a id="__codelineno-15-31" name="__codelineno-15-31" href="#__codelineno-15-31"></a>----------------
</span><span id="__span-15-32"><a id="__codelineno-15-32" name="__codelineno-15-32" href="#__codelineno-15-32"></a>SINE   - Sine easing
</span><span id="__span-15-33"><a id="__codelineno-15-33" name="__codelineno-15-33" href="#__codelineno-15-33"></a>QUAD   - Quadratic easing
</span><span id="__span-15-34"><a id="__codelineno-15-34" name="__codelineno-15-34" href="#__codelineno-15-34"></a>CUBIC  - Cubic easing
</span><span id="__span-15-35"><a id="__codelineno-15-35" name="__codelineno-15-35" href="#__codelineno-15-35"></a>QUART  - Quartic easing
</span><span id="__span-15-36"><a id="__codelineno-15-36" name="__codelineno-15-36" href="#__codelineno-15-36"></a>QUINT  - Quintic easing
</span><span id="__span-15-37"><a id="__codelineno-15-37" name="__codelineno-15-37" href="#__codelineno-15-37"></a>EXPO   - Exponential easing
</span><span id="__span-15-38"><a id="__codelineno-15-38" name="__codelineno-15-38" href="#__codelineno-15-38"></a>CIRC   - Circular easing
</span><span id="__span-15-39"><a id="__codelineno-15-39" name="__codelineno-15-39" href="#__codelineno-15-39"></a>BACK   - Back easing
</span><span id="__span-15-40"><a id="__codelineno-15-40" name="__codelineno-15-40" href="#__codelineno-15-40"></a>ELASTIC - Elastic easing
</span><span id="__span-15-41"><a id="__codelineno-15-41" name="__codelineno-15-41" href="#__codelineno-15-41"></a>BOUNCE - Bounce easing
</span><span id="__span-15-42"><a id="__codelineno-15-42" name="__codelineno-15-42" href="#__codelineno-15-42"></a>
</span><span id="__span-15-43"><a id="__codelineno-15-43" name="__codelineno-15-43" href="#__codelineno-15-43"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-15-44"><a id="__codelineno-15-44" name="__codelineno-15-44" href="#__codelineno-15-44"></a>
</span><span id="__span-15-45"><a id="__codelineno-15-45" name="__codelineno-15-45" href="#__codelineno-15-45"></a>Example: terminaltexteffects pour --pour-direction down --movement-speed 0.2 --gap 1 --starting-color FFFFFF --final-gradient-stops 8A008A 00D1FF FFFFFF --easing IN_QUAD
</span></code></pre></div>
</details>
<hr>
<h2 id="print">Print</h2>
<p>Prints the input data one line at at time with a carriage return and line feed.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/print_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/print/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/print/#terminaltexteffects.effects.effect_print.PrintConfig">Config</a></p>
<details>
<summary>Print Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>                    (default: ('02b8bd', 'c1f0e3', '00ffa0'))
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-16-6"><a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-16-7"><a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-16-8"><a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a>--print-head-return-speed (float &gt; 0)
</span><span id="__span-16-9"><a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a>                    Speed of the print head when performing a carriage return. (default: 1.25)
</span><span id="__span-16-10"><a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a>--print-speed (int &gt; 0)
</span><span id="__span-16-11"><a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a>                    Speed of the print head when printing characters. (default: 1)
</span><span id="__span-16-12"><a id="__codelineno-16-12" name="__codelineno-16-12" href="#__codelineno-16-12"></a>--print-head-easing PRINT_HEAD_EASING
</span><span id="__span-16-13"><a id="__codelineno-16-13" name="__codelineno-16-13" href="#__codelineno-16-13"></a>                    Easing function to use for print head movement. (default: in_out_quad)
</span><span id="__span-16-14"><a id="__codelineno-16-14" name="__codelineno-16-14" href="#__codelineno-16-14"></a>
</span><span id="__span-16-15"><a id="__codelineno-16-15" name="__codelineno-16-15" href="#__codelineno-16-15"></a>Easing
</span><span id="__span-16-16"><a id="__codelineno-16-16" name="__codelineno-16-16" href="#__codelineno-16-16"></a>------
</span><span id="__span-16-17"><a id="__codelineno-16-17" name="__codelineno-16-17" href="#__codelineno-16-17"></a>Note: A prefix must be added to the function name.
</span><span id="__span-16-18"><a id="__codelineno-16-18" name="__codelineno-16-18" href="#__codelineno-16-18"></a>
</span><span id="__span-16-19"><a id="__codelineno-16-19" name="__codelineno-16-19" href="#__codelineno-16-19"></a>All easing functions support the following prefixes:
</span><span id="__span-16-20"><a id="__codelineno-16-20" name="__codelineno-16-20" href="#__codelineno-16-20"></a>    IN_  - Ease in
</span><span id="__span-16-21"><a id="__codelineno-16-21" name="__codelineno-16-21" href="#__codelineno-16-21"></a>    OUT_ - Ease out
</span><span id="__span-16-22"><a id="__codelineno-16-22" name="__codelineno-16-22" href="#__codelineno-16-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-16-23"><a id="__codelineno-16-23" name="__codelineno-16-23" href="#__codelineno-16-23"></a>
</span><span id="__span-16-24"><a id="__codelineno-16-24" name="__codelineno-16-24" href="#__codelineno-16-24"></a>Easing Functions
</span><span id="__span-16-25"><a id="__codelineno-16-25" name="__codelineno-16-25" href="#__codelineno-16-25"></a>----------------
</span><span id="__span-16-26"><a id="__codelineno-16-26" name="__codelineno-16-26" href="#__codelineno-16-26"></a>SINE   - Sine easing
</span><span id="__span-16-27"><a id="__codelineno-16-27" name="__codelineno-16-27" href="#__codelineno-16-27"></a>QUAD   - Quadratic easing
</span><span id="__span-16-28"><a id="__codelineno-16-28" name="__codelineno-16-28" href="#__codelineno-16-28"></a>CUBIC  - Cubic easing
</span><span id="__span-16-29"><a id="__codelineno-16-29" name="__codelineno-16-29" href="#__codelineno-16-29"></a>QUART  - Quartic easing
</span><span id="__span-16-30"><a id="__codelineno-16-30" name="__codelineno-16-30" href="#__codelineno-16-30"></a>QUINT  - Quintic easing
</span><span id="__span-16-31"><a id="__codelineno-16-31" name="__codelineno-16-31" href="#__codelineno-16-31"></a>EXPO   - Exponential easing
</span><span id="__span-16-32"><a id="__codelineno-16-32" name="__codelineno-16-32" href="#__codelineno-16-32"></a>CIRC   - Circular easing
</span><span id="__span-16-33"><a id="__codelineno-16-33" name="__codelineno-16-33" href="#__codelineno-16-33"></a>BACK   - Back easing
</span><span id="__span-16-34"><a id="__codelineno-16-34" name="__codelineno-16-34" href="#__codelineno-16-34"></a>ELASTIC - Elastic easing
</span><span id="__span-16-35"><a id="__codelineno-16-35" name="__codelineno-16-35" href="#__codelineno-16-35"></a>BOUNCE - Bounce easing
</span><span id="__span-16-36"><a id="__codelineno-16-36" name="__codelineno-16-36" href="#__codelineno-16-36"></a>
</span><span id="__span-16-37"><a id="__codelineno-16-37" name="__codelineno-16-37" href="#__codelineno-16-37"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-16-38"><a id="__codelineno-16-38" name="__codelineno-16-38" href="#__codelineno-16-38"></a>
</span><span id="__span-16-39"><a id="__codelineno-16-39" name="__codelineno-16-39" href="#__codelineno-16-39"></a>
</span><span id="__span-16-40"><a id="__codelineno-16-40" name="__codelineno-16-40" href="#__codelineno-16-40"></a>Example: terminaltexteffects print --final-gradient-stops 02b8bd c1f0e3 00ffa0 --final-gradient-steps 12 --print-head-return-speed 1.25 --print-speed 1 --print-head-easing IN_OUT_QUAD
</span></code></pre></div>
</details>
<hr>
<h2 id="rain">Rain</h2>
<p>Rain characters from the top of the canvas.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/rain_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rain/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rain/#terminaltexteffects.effects.effect_rain.RainConfig">Config</a></p>
<details>
<summary>Rain Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>--rain-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>                    List of colors for the rain drops. Colors are randomly chosen from the list. (default: ('00315C', '004C8F', '0075DB', '3F91D9', '78B9F2', '9AC8F5', 'B8D8F8', 'E3EFFC'))
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>--movement-speed (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>                    Falling speed range of the rain drops. (default: (0.1, 0.2))
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>--rain-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>                    Space separated list of symbols to use for the rain drops. Symbols are randomly chosen from the list. (default: ('o', '.', ',', '*', '|'))
</span><span id="__span-17-7"><a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-17-8"><a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-17-9"><a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a>                    (default: ('488bff', 'b2e7de', '57eaf7'))
</span><span id="__span-17-10"><a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-17-11"><a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-17-12"><a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-17-13"><a id="__codelineno-17-13" name="__codelineno-17-13" href="#__codelineno-17-13"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-17-14"><a id="__codelineno-17-14" name="__codelineno-17-14" href="#__codelineno-17-14"></a>--easing (Easing Function)
</span><span id="__span-17-15"><a id="__codelineno-17-15" name="__codelineno-17-15" href="#__codelineno-17-15"></a>                    Easing function to use for character movement. (default: in_quart)
</span><span id="__span-17-16"><a id="__codelineno-17-16" name="__codelineno-17-16" href="#__codelineno-17-16"></a>
</span><span id="__span-17-17"><a id="__codelineno-17-17" name="__codelineno-17-17" href="#__codelineno-17-17"></a>Easing
</span><span id="__span-17-18"><a id="__codelineno-17-18" name="__codelineno-17-18" href="#__codelineno-17-18"></a>------
</span><span id="__span-17-19"><a id="__codelineno-17-19" name="__codelineno-17-19" href="#__codelineno-17-19"></a>Note: A prefix must be added to the function name.
</span><span id="__span-17-20"><a id="__codelineno-17-20" name="__codelineno-17-20" href="#__codelineno-17-20"></a>
</span><span id="__span-17-21"><a id="__codelineno-17-21" name="__codelineno-17-21" href="#__codelineno-17-21"></a>All easing functions support the following prefixes:
</span><span id="__span-17-22"><a id="__codelineno-17-22" name="__codelineno-17-22" href="#__codelineno-17-22"></a>    IN_  - Ease in
</span><span id="__span-17-23"><a id="__codelineno-17-23" name="__codelineno-17-23" href="#__codelineno-17-23"></a>    OUT_ - Ease out
</span><span id="__span-17-24"><a id="__codelineno-17-24" name="__codelineno-17-24" href="#__codelineno-17-24"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-17-25"><a id="__codelineno-17-25" name="__codelineno-17-25" href="#__codelineno-17-25"></a>
</span><span id="__span-17-26"><a id="__codelineno-17-26" name="__codelineno-17-26" href="#__codelineno-17-26"></a>Easing Functions
</span><span id="__span-17-27"><a id="__codelineno-17-27" name="__codelineno-17-27" href="#__codelineno-17-27"></a>----------------
</span><span id="__span-17-28"><a id="__codelineno-17-28" name="__codelineno-17-28" href="#__codelineno-17-28"></a>SINE   - Sine easing
</span><span id="__span-17-29"><a id="__codelineno-17-29" name="__codelineno-17-29" href="#__codelineno-17-29"></a>QUAD   - Quadratic easing
</span><span id="__span-17-30"><a id="__codelineno-17-30" name="__codelineno-17-30" href="#__codelineno-17-30"></a>CUBIC  - Cubic easing
</span><span id="__span-17-31"><a id="__codelineno-17-31" name="__codelineno-17-31" href="#__codelineno-17-31"></a>QUART  - Quartic easing
</span><span id="__span-17-32"><a id="__codelineno-17-32" name="__codelineno-17-32" href="#__codelineno-17-32"></a>QUINT  - Quintic easing
</span><span id="__span-17-33"><a id="__codelineno-17-33" name="__codelineno-17-33" href="#__codelineno-17-33"></a>EXPO   - Exponential easing
</span><span id="__span-17-34"><a id="__codelineno-17-34" name="__codelineno-17-34" href="#__codelineno-17-34"></a>CIRC   - Circular easing
</span><span id="__span-17-35"><a id="__codelineno-17-35" name="__codelineno-17-35" href="#__codelineno-17-35"></a>BACK   - Back easing
</span><span id="__span-17-36"><a id="__codelineno-17-36" name="__codelineno-17-36" href="#__codelineno-17-36"></a>ELASTIC - Elastic easing
</span><span id="__span-17-37"><a id="__codelineno-17-37" name="__codelineno-17-37" href="#__codelineno-17-37"></a>BOUNCE - Bounce easing
</span><span id="__span-17-38"><a id="__codelineno-17-38" name="__codelineno-17-38" href="#__codelineno-17-38"></a>
</span><span id="__span-17-39"><a id="__codelineno-17-39" name="__codelineno-17-39" href="#__codelineno-17-39"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-17-40"><a id="__codelineno-17-40" name="__codelineno-17-40" href="#__codelineno-17-40"></a>
</span><span id="__span-17-41"><a id="__codelineno-17-41" name="__codelineno-17-41" href="#__codelineno-17-41"></a>Example: terminaltexteffects rain --rain-symbols o . , "*" "|" --rain-colors 00315C 004C8F 0075DB 3F91D9 78B9F2 9AC8F5 B8D8F8 E3EFFC --final-gradient-stops 488bff b2e7de 57eaf7 --final-gradient-steps 12 --movement-speed 0.1-0.2 --easing IN_QUART
</span></code></pre></div>
</details>
<hr>
<h2 id="randomsequence">RandomSequence</h2>
<p>Prints the input data in a random sequence, one character at a time.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/randomsequence_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/randomsequence/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/randomsequence/#terminaltexteffects.effects.effect_random_sequence.RandomSequenceConfig">Config</a></p>
<details>
<summary>RandomSequence Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>--starting-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>                    Color of the characters at spawn. (default: 000000)
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-18-7"><a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-18-8"><a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-18-9"><a id="__codelineno-18-9" name="__codelineno-18-9" href="#__codelineno-18-9"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 12)
</span><span id="__span-18-10"><a id="__codelineno-18-10" name="__codelineno-18-10" href="#__codelineno-18-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-18-11"><a id="__codelineno-18-11" name="__codelineno-18-11" href="#__codelineno-18-11"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-18-12"><a id="__codelineno-18-12" name="__codelineno-18-12" href="#__codelineno-18-12"></a>--speed (float &gt; 0)   Speed of the animation as a percentage of the total number of characters. (default: 0.004)
</span><span id="__span-18-13"><a id="__codelineno-18-13" name="__codelineno-18-13" href="#__codelineno-18-13"></a>
</span><span id="__span-18-14"><a id="__codelineno-18-14" name="__codelineno-18-14" href="#__codelineno-18-14"></a>Example: terminaltexteffects randomsequence --starting-color 000000 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --final-gradient-frames 12 --speed 0.004
</span></code></pre></div>
</details>
<hr>
<h2 id="rings">Rings</h2>
<p>Characters are dispersed and form into spinning rings.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/rings_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rings/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/rings/#terminaltexteffects.effects.effect_rings.RingsConfig">Config</a></p>
<details>
<summary>Rings Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>--ring-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>                    Space separated, unquoted, list of colors for the rings. (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-19-5"><a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a>                    (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-19-6"><a id="__codelineno-19-6" name="__codelineno-19-6" href="#__codelineno-19-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-19-7"><a id="__codelineno-19-7" name="__codelineno-19-7" href="#__codelineno-19-7"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-19-8"><a id="__codelineno-19-8" name="__codelineno-19-8" href="#__codelineno-19-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-19-9"><a id="__codelineno-19-9" name="__codelineno-19-9" href="#__codelineno-19-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-19-10"><a id="__codelineno-19-10" name="__codelineno-19-10" href="#__codelineno-19-10"></a>--ring-gap RING_GAP   Distance between rings as a percent of the smallest canvas dimension. (default: 0.1)
</span><span id="__span-19-11"><a id="__codelineno-19-11" name="__codelineno-19-11" href="#__codelineno-19-11"></a>--spin-duration SPIN_DURATION
</span><span id="__span-19-12"><a id="__codelineno-19-12" name="__codelineno-19-12" href="#__codelineno-19-12"></a>                    Number of frames for each cycle of the spin phase. (default: 200)
</span><span id="__span-19-13"><a id="__codelineno-19-13" name="__codelineno-19-13" href="#__codelineno-19-13"></a>--spin-speed (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-19-14"><a id="__codelineno-19-14" name="__codelineno-19-14" href="#__codelineno-19-14"></a>                    Range of speeds for the rotation of the rings. The speed is randomly selected from this range for each ring. (default: (0.25, 1.0))
</span><span id="__span-19-15"><a id="__codelineno-19-15" name="__codelineno-19-15" href="#__codelineno-19-15"></a>--disperse-duration DISPERSE_DURATION
</span><span id="__span-19-16"><a id="__codelineno-19-16" name="__codelineno-19-16" href="#__codelineno-19-16"></a>                    Number of frames spent in the dispersed state between spinning cycles. (default: 200)
</span><span id="__span-19-17"><a id="__codelineno-19-17" name="__codelineno-19-17" href="#__codelineno-19-17"></a>--spin-disperse-cycles SPIN_DISPERSE_CYCLES
</span><span id="__span-19-18"><a id="__codelineno-19-18" name="__codelineno-19-18" href="#__codelineno-19-18"></a>                    Number of times the animation will cycles between spinning rings and dispersed characters. (default: 3)
</span><span id="__span-19-19"><a id="__codelineno-19-19" name="__codelineno-19-19" href="#__codelineno-19-19"></a>
</span><span id="__span-19-20"><a id="__codelineno-19-20" name="__codelineno-19-20" href="#__codelineno-19-20"></a>Example: terminaltexteffects rings --ring-colors ab48ff e7b2b2 fffebd --final-gradient-stops ab48ff e7b2b2 fffebd --final-gradient-steps 12 --ring-gap 0.1 --spin-duration 200 --spin-speed 0.25-1.0 --disperse-duration 200 --spin-disperse-cycles 3
</span></code></pre></div>
</details>
<hr>
<h2 id="scattered">Scattered</h2>
<p>Text is scattered across the canvas and moves into position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/scattered_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/scattered/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/scattered/#terminaltexteffects.effects.effect_scattered.ScatteredConfig">Config</a></p>
<details>
<summary>Scattered Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>                    Space separated, unquoted, list of colors for the character gradient. If only one color is provided, the characters will be displayed in that color. (default: ('ff9048', 'ab9dff',
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>                    'bdffea'))
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a>--final-gradient-steps (int &gt; 0)
</span><span id="__span-20-5"><a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-20-6"><a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-20-7"><a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 12)
</span><span id="__span-20-8"><a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-20-9"><a id="__codelineno-20-9" name="__codelineno-20-9" href="#__codelineno-20-9"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-20-10"><a id="__codelineno-20-10" name="__codelineno-20-10" href="#__codelineno-20-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-20-11"><a id="__codelineno-20-11" name="__codelineno-20-11" href="#__codelineno-20-11"></a>                    Movement speed of the characters.  (default: 0.5)
</span><span id="__span-20-12"><a id="__codelineno-20-12" name="__codelineno-20-12" href="#__codelineno-20-12"></a>--movement-easing MOVEMENT_EASING
</span><span id="__span-20-13"><a id="__codelineno-20-13" name="__codelineno-20-13" href="#__codelineno-20-13"></a>                    Easing function to use for character movement. (default: in_out_back)
</span><span id="__span-20-14"><a id="__codelineno-20-14" name="__codelineno-20-14" href="#__codelineno-20-14"></a>
</span><span id="__span-20-15"><a id="__codelineno-20-15" name="__codelineno-20-15" href="#__codelineno-20-15"></a>Easing
</span><span id="__span-20-16"><a id="__codelineno-20-16" name="__codelineno-20-16" href="#__codelineno-20-16"></a>------
</span><span id="__span-20-17"><a id="__codelineno-20-17" name="__codelineno-20-17" href="#__codelineno-20-17"></a>Note: A prefix must be added to the function name.
</span><span id="__span-20-18"><a id="__codelineno-20-18" name="__codelineno-20-18" href="#__codelineno-20-18"></a>
</span><span id="__span-20-19"><a id="__codelineno-20-19" name="__codelineno-20-19" href="#__codelineno-20-19"></a>All easing functions support the following prefixes:
</span><span id="__span-20-20"><a id="__codelineno-20-20" name="__codelineno-20-20" href="#__codelineno-20-20"></a>    IN_  - Ease in
</span><span id="__span-20-21"><a id="__codelineno-20-21" name="__codelineno-20-21" href="#__codelineno-20-21"></a>    OUT_ - Ease out
</span><span id="__span-20-22"><a id="__codelineno-20-22" name="__codelineno-20-22" href="#__codelineno-20-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-20-23"><a id="__codelineno-20-23" name="__codelineno-20-23" href="#__codelineno-20-23"></a>
</span><span id="__span-20-24"><a id="__codelineno-20-24" name="__codelineno-20-24" href="#__codelineno-20-24"></a>Easing Functions
</span><span id="__span-20-25"><a id="__codelineno-20-25" name="__codelineno-20-25" href="#__codelineno-20-25"></a>----------------
</span><span id="__span-20-26"><a id="__codelineno-20-26" name="__codelineno-20-26" href="#__codelineno-20-26"></a>SINE   - Sine easing
</span><span id="__span-20-27"><a id="__codelineno-20-27" name="__codelineno-20-27" href="#__codelineno-20-27"></a>QUAD   - Quadratic easing
</span><span id="__span-20-28"><a id="__codelineno-20-28" name="__codelineno-20-28" href="#__codelineno-20-28"></a>CUBIC  - Cubic easing
</span><span id="__span-20-29"><a id="__codelineno-20-29" name="__codelineno-20-29" href="#__codelineno-20-29"></a>QUART  - Quartic easing
</span><span id="__span-20-30"><a id="__codelineno-20-30" name="__codelineno-20-30" href="#__codelineno-20-30"></a>QUINT  - Quintic easing
</span><span id="__span-20-31"><a id="__codelineno-20-31" name="__codelineno-20-31" href="#__codelineno-20-31"></a>EXPO   - Exponential easing
</span><span id="__span-20-32"><a id="__codelineno-20-32" name="__codelineno-20-32" href="#__codelineno-20-32"></a>CIRC   - Circular easing
</span><span id="__span-20-33"><a id="__codelineno-20-33" name="__codelineno-20-33" href="#__codelineno-20-33"></a>BACK   - Back easing
</span><span id="__span-20-34"><a id="__codelineno-20-34" name="__codelineno-20-34" href="#__codelineno-20-34"></a>ELASTIC - Elastic easing
</span><span id="__span-20-35"><a id="__codelineno-20-35" name="__codelineno-20-35" href="#__codelineno-20-35"></a>BOUNCE - Bounce easing
</span><span id="__span-20-36"><a id="__codelineno-20-36" name="__codelineno-20-36" href="#__codelineno-20-36"></a>
</span><span id="__span-20-37"><a id="__codelineno-20-37" name="__codelineno-20-37" href="#__codelineno-20-37"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-20-38"><a id="__codelineno-20-38" name="__codelineno-20-38" href="#__codelineno-20-38"></a>
</span><span id="__span-20-39"><a id="__codelineno-20-39" name="__codelineno-20-39" href="#__codelineno-20-39"></a>Example: terminaltexteffects scattered --final-gradient-stops ff9048 ab9dff bdffea --final-gradient-steps 12 --final-gradient-frames 12 --movement-speed 0.5 --movement-easing IN_OUT_BACK
</span></code></pre></div>
</details>
<hr>
<h2 id="slice">Slice</h2>
<p>Slices the input in half and slides it into place from opposite directions.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/slice_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slice/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slice/#terminaltexteffects.effects.effect_slice.SliceConfig">Config</a></p>
<details>
<summary>Slice Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>                    (default: (Color(8A008A), Color(00D1FF), Color(FFFFFF)))
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-21-6"><a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-21-7"><a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-21-8"><a id="__codelineno-21-8" name="__codelineno-21-8" href="#__codelineno-21-8"></a>--slice-direction {vertical,horizontal,diagonal}
</span><span id="__span-21-9"><a id="__codelineno-21-9" name="__codelineno-21-9" href="#__codelineno-21-9"></a>                    Direction of the slice. (default: vertical)
</span><span id="__span-21-10"><a id="__codelineno-21-10" name="__codelineno-21-10" href="#__codelineno-21-10"></a>--movement-speed (float &gt; 0)
</span><span id="__span-21-11"><a id="__codelineno-21-11" name="__codelineno-21-11" href="#__codelineno-21-11"></a>                    Movement speed of the characters. (default: 0.15)
</span><span id="__span-21-12"><a id="__codelineno-21-12" name="__codelineno-21-12" href="#__codelineno-21-12"></a>--movement-easing MOVEMENT_EASING
</span><span id="__span-21-13"><a id="__codelineno-21-13" name="__codelineno-21-13" href="#__codelineno-21-13"></a>                    Easing function to use for character movement. (default: in_out_expo)
</span><span id="__span-21-14"><a id="__codelineno-21-14" name="__codelineno-21-14" href="#__codelineno-21-14"></a>
</span><span id="__span-21-15"><a id="__codelineno-21-15" name="__codelineno-21-15" href="#__codelineno-21-15"></a>Easing
</span><span id="__span-21-16"><a id="__codelineno-21-16" name="__codelineno-21-16" href="#__codelineno-21-16"></a>------
</span><span id="__span-21-17"><a id="__codelineno-21-17" name="__codelineno-21-17" href="#__codelineno-21-17"></a>Note: A prefix must be added to the function name (except LINEAR).
</span><span id="__span-21-18"><a id="__codelineno-21-18" name="__codelineno-21-18" href="#__codelineno-21-18"></a>
</span><span id="__span-21-19"><a id="__codelineno-21-19" name="__codelineno-21-19" href="#__codelineno-21-19"></a>All easing functions support the following prefixes:
</span><span id="__span-21-20"><a id="__codelineno-21-20" name="__codelineno-21-20" href="#__codelineno-21-20"></a>    IN_  - Ease in
</span><span id="__span-21-21"><a id="__codelineno-21-21" name="__codelineno-21-21" href="#__codelineno-21-21"></a>    OUT_ - Ease out
</span><span id="__span-21-22"><a id="__codelineno-21-22" name="__codelineno-21-22" href="#__codelineno-21-22"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-21-23"><a id="__codelineno-21-23" name="__codelineno-21-23" href="#__codelineno-21-23"></a>
</span><span id="__span-21-24"><a id="__codelineno-21-24" name="__codelineno-21-24" href="#__codelineno-21-24"></a>Easing Functions
</span><span id="__span-21-25"><a id="__codelineno-21-25" name="__codelineno-21-25" href="#__codelineno-21-25"></a>----------------
</span><span id="__span-21-26"><a id="__codelineno-21-26" name="__codelineno-21-26" href="#__codelineno-21-26"></a>LINEAR - Linear easing
</span><span id="__span-21-27"><a id="__codelineno-21-27" name="__codelineno-21-27" href="#__codelineno-21-27"></a>SINE   - Sine easing
</span><span id="__span-21-28"><a id="__codelineno-21-28" name="__codelineno-21-28" href="#__codelineno-21-28"></a>QUAD   - Quadratic easing
</span><span id="__span-21-29"><a id="__codelineno-21-29" name="__codelineno-21-29" href="#__codelineno-21-29"></a>CUBIC  - Cubic easing
</span><span id="__span-21-30"><a id="__codelineno-21-30" name="__codelineno-21-30" href="#__codelineno-21-30"></a>QUART  - Quartic easing
</span><span id="__span-21-31"><a id="__codelineno-21-31" name="__codelineno-21-31" href="#__codelineno-21-31"></a>QUINT  - Quintic easing
</span><span id="__span-21-32"><a id="__codelineno-21-32" name="__codelineno-21-32" href="#__codelineno-21-32"></a>EXPO   - Exponential easing
</span><span id="__span-21-33"><a id="__codelineno-21-33" name="__codelineno-21-33" href="#__codelineno-21-33"></a>CIRC   - Circular easing
</span><span id="__span-21-34"><a id="__codelineno-21-34" name="__codelineno-21-34" href="#__codelineno-21-34"></a>BACK   - Back easing
</span><span id="__span-21-35"><a id="__codelineno-21-35" name="__codelineno-21-35" href="#__codelineno-21-35"></a>ELASTIC - Elastic easing
</span><span id="__span-21-36"><a id="__codelineno-21-36" name="__codelineno-21-36" href="#__codelineno-21-36"></a>BOUNCE - Bounce easing
</span><span id="__span-21-37"><a id="__codelineno-21-37" name="__codelineno-21-37" href="#__codelineno-21-37"></a>
</span><span id="__span-21-38"><a id="__codelineno-21-38" name="__codelineno-21-38" href="#__codelineno-21-38"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-21-39"><a id="__codelineno-21-39" name="__codelineno-21-39" href="#__codelineno-21-39"></a>
</span><span id="__span-21-40"><a id="__codelineno-21-40" name="__codelineno-21-40" href="#__codelineno-21-40"></a>
</span><span id="__span-21-41"><a id="__codelineno-21-41" name="__codelineno-21-41" href="#__codelineno-21-41"></a>Example: terminaltexteffects slice --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12
</span><span id="__span-21-42"><a id="__codelineno-21-42" name="__codelineno-21-42" href="#__codelineno-21-42"></a>--slice-direction vertical--movement-speed 0.15 --movement-easing IN_OUT_EXPO
</span></code></pre></div>
</details>
<hr>
<h2 id="slide">Slide</h2>
<p>Slide characters into view from outside the terminal.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/slide_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slide/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/slide/#terminaltexteffects.effects.effect_slide.SlideConfig">Config</a></p>
<details>
<summary>Slide Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>--movement-speed (float &gt; 0)
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>                    Speed of the characters. (default: 0.5)
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a>--grouping {row,column,diagonal}
</span><span id="__span-22-4"><a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>                    Direction to group characters. (default: row)
</span><span id="__span-22-5"><a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-22-6"><a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a>                    Space separated, unquoted, list of colors for the character gradient. If only one color is provided, the characters will be displayed in that color. (default: ('833ab4', 'fd1d1d',
</span><span id="__span-22-7"><a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a>                    'fcb045'))
</span><span id="__span-22-8"><a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a>--final-gradient-steps (int &gt; 0)
</span><span id="__span-22-9"><a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-22-10"><a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-22-11"><a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 10)
</span><span id="__span-22-12"><a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a>--final-gradient-direction FINAL_GRADIENT_DIRECTION
</span><span id="__span-22-13"><a id="__codelineno-22-13" name="__codelineno-22-13" href="#__codelineno-22-13"></a>                    Direction of the gradient (vertical, horizontal, diagonal, center). (default: Direction.VERTICAL)
</span><span id="__span-22-14"><a id="__codelineno-22-14" name="__codelineno-22-14" href="#__codelineno-22-14"></a>--gap (int &gt;= 0)      Number of frames to wait before adding the next group of characters. Increasing this value creates a more staggered effect. (default: 3)
</span><span id="__span-22-15"><a id="__codelineno-22-15" name="__codelineno-22-15" href="#__codelineno-22-15"></a>--reverse-direction   Reverse the direction of the characters. (default: False)
</span><span id="__span-22-16"><a id="__codelineno-22-16" name="__codelineno-22-16" href="#__codelineno-22-16"></a>--merge               Merge the character groups originating from either side of the terminal. (--reverse-direction is ignored when merging) (default: False)
</span><span id="__span-22-17"><a id="__codelineno-22-17" name="__codelineno-22-17" href="#__codelineno-22-17"></a>--movement-easing (Easing Function)
</span><span id="__span-22-18"><a id="__codelineno-22-18" name="__codelineno-22-18" href="#__codelineno-22-18"></a>                    Easing function to use for character movement. (default: in_out_quad)
</span><span id="__span-22-19"><a id="__codelineno-22-19" name="__codelineno-22-19" href="#__codelineno-22-19"></a>
</span><span id="__span-22-20"><a id="__codelineno-22-20" name="__codelineno-22-20" href="#__codelineno-22-20"></a>Easing
</span><span id="__span-22-21"><a id="__codelineno-22-21" name="__codelineno-22-21" href="#__codelineno-22-21"></a>------
</span><span id="__span-22-22"><a id="__codelineno-22-22" name="__codelineno-22-22" href="#__codelineno-22-22"></a>Note: A prefix must be added to the function name.
</span><span id="__span-22-23"><a id="__codelineno-22-23" name="__codelineno-22-23" href="#__codelineno-22-23"></a>
</span><span id="__span-22-24"><a id="__codelineno-22-24" name="__codelineno-22-24" href="#__codelineno-22-24"></a>All easing functions support the following prefixes:
</span><span id="__span-22-25"><a id="__codelineno-22-25" name="__codelineno-22-25" href="#__codelineno-22-25"></a>    IN_  - Ease in
</span><span id="__span-22-26"><a id="__codelineno-22-26" name="__codelineno-22-26" href="#__codelineno-22-26"></a>    OUT_ - Ease out
</span><span id="__span-22-27"><a id="__codelineno-22-27" name="__codelineno-22-27" href="#__codelineno-22-27"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-22-28"><a id="__codelineno-22-28" name="__codelineno-22-28" href="#__codelineno-22-28"></a>
</span><span id="__span-22-29"><a id="__codelineno-22-29" name="__codelineno-22-29" href="#__codelineno-22-29"></a>Easing Functions
</span><span id="__span-22-30"><a id="__codelineno-22-30" name="__codelineno-22-30" href="#__codelineno-22-30"></a>----------------
</span><span id="__span-22-31"><a id="__codelineno-22-31" name="__codelineno-22-31" href="#__codelineno-22-31"></a>SINE   - Sine easing
</span><span id="__span-22-32"><a id="__codelineno-22-32" name="__codelineno-22-32" href="#__codelineno-22-32"></a>QUAD   - Quadratic easing
</span><span id="__span-22-33"><a id="__codelineno-22-33" name="__codelineno-22-33" href="#__codelineno-22-33"></a>CUBIC  - Cubic easing
</span><span id="__span-22-34"><a id="__codelineno-22-34" name="__codelineno-22-34" href="#__codelineno-22-34"></a>QUART  - Quartic easing
</span><span id="__span-22-35"><a id="__codelineno-22-35" name="__codelineno-22-35" href="#__codelineno-22-35"></a>QUINT  - Quintic easing
</span><span id="__span-22-36"><a id="__codelineno-22-36" name="__codelineno-22-36" href="#__codelineno-22-36"></a>EXPO   - Exponential easing
</span><span id="__span-22-37"><a id="__codelineno-22-37" name="__codelineno-22-37" href="#__codelineno-22-37"></a>CIRC   - Circular easing
</span><span id="__span-22-38"><a id="__codelineno-22-38" name="__codelineno-22-38" href="#__codelineno-22-38"></a>BACK   - Back easing
</span><span id="__span-22-39"><a id="__codelineno-22-39" name="__codelineno-22-39" href="#__codelineno-22-39"></a>ELASTIC - Elastic easing
</span><span id="__span-22-40"><a id="__codelineno-22-40" name="__codelineno-22-40" href="#__codelineno-22-40"></a>BOUNCE - Bounce easing
</span><span id="__span-22-41"><a id="__codelineno-22-41" name="__codelineno-22-41" href="#__codelineno-22-41"></a>
</span><span id="__span-22-42"><a id="__codelineno-22-42" name="__codelineno-22-42" href="#__codelineno-22-42"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-22-43"><a id="__codelineno-22-43" name="__codelineno-22-43" href="#__codelineno-22-43"></a>
</span><span id="__span-22-44"><a id="__codelineno-22-44" name="__codelineno-22-44" href="#__codelineno-22-44"></a>Example: terminaltexteffects slide --movement-speed 0.5 --grouping row --final-gradient-stops 833ab4 fd1d1d fcb045 --final-gradient-steps 12 --final-gradient-frames 10 --final-gradient-direction vertical --gap 3 --reverse-direction --merge --movement-easing OUT_QUAD
</span></code></pre></div>
</details>
<hr>
<h2 id="spotlights">Spotlights</h2>
<p>Spotlights search the text area, illuminating characters, before converging in the center and expanding.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/spotlights_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spotlights/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spotlights/#terminaltexteffects.effects.effect_spotlights.SpotlightsConfig">Config</a></p>
<details>
<summary>Spotlights Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>                    (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-23-7"><a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-23-8"><a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a>--beam-width-ratio (float &gt; 0)
</span><span id="__span-23-9"><a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a>                    Width of the beam of light as min(width, height) // n of the input text. (default: 2.0)
</span><span id="__span-23-10"><a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a>--beam-falloff (float &gt;= 0)
</span><span id="__span-23-11"><a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a>                    Distance from the edge of the beam where the brightness begins to fall off, as a percentage of total beam width. (default: 0.3)
</span><span id="__span-23-12"><a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a>--search-duration (int &gt; 0)
</span><span id="__span-23-13"><a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a>                    Duration of the search phase, in frames, before the spotlights converge in the center. (default: 750)
</span><span id="__span-23-14"><a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a>--search-speed-range (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-23-15"><a id="__codelineno-23-15" name="__codelineno-23-15" href="#__codelineno-23-15"></a>                    Range of speeds for the spotlights during the search phase. The speed is a random value between the two provided values. (default: (0.25, 0.5))
</span><span id="__span-23-16"><a id="__codelineno-23-16" name="__codelineno-23-16" href="#__codelineno-23-16"></a>--spotlight-count (int &gt; 0)
</span><span id="__span-23-17"><a id="__codelineno-23-17" name="__codelineno-23-17" href="#__codelineno-23-17"></a>                    Number of spotlights to use. (default: 3)
</span><span id="__span-23-18"><a id="__codelineno-23-18" name="__codelineno-23-18" href="#__codelineno-23-18"></a>
</span><span id="__span-23-19"><a id="__codelineno-23-19" name="__codelineno-23-19" href="#__codelineno-23-19"></a>Easing
</span><span id="__span-23-20"><a id="__codelineno-23-20" name="__codelineno-23-20" href="#__codelineno-23-20"></a>------
</span><span id="__span-23-21"><a id="__codelineno-23-21" name="__codelineno-23-21" href="#__codelineno-23-21"></a>Note: A prefix must be added to the function name.
</span><span id="__span-23-22"><a id="__codelineno-23-22" name="__codelineno-23-22" href="#__codelineno-23-22"></a>
</span><span id="__span-23-23"><a id="__codelineno-23-23" name="__codelineno-23-23" href="#__codelineno-23-23"></a>All easing functions support the following prefixes:
</span><span id="__span-23-24"><a id="__codelineno-23-24" name="__codelineno-23-24" href="#__codelineno-23-24"></a>    IN_  - Ease in
</span><span id="__span-23-25"><a id="__codelineno-23-25" name="__codelineno-23-25" href="#__codelineno-23-25"></a>    OUT_ - Ease out
</span><span id="__span-23-26"><a id="__codelineno-23-26" name="__codelineno-23-26" href="#__codelineno-23-26"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-23-27"><a id="__codelineno-23-27" name="__codelineno-23-27" href="#__codelineno-23-27"></a>
</span><span id="__span-23-28"><a id="__codelineno-23-28" name="__codelineno-23-28" href="#__codelineno-23-28"></a>Easing Functions
</span><span id="__span-23-29"><a id="__codelineno-23-29" name="__codelineno-23-29" href="#__codelineno-23-29"></a>----------------
</span><span id="__span-23-30"><a id="__codelineno-23-30" name="__codelineno-23-30" href="#__codelineno-23-30"></a>SINE   - Sine easing
</span><span id="__span-23-31"><a id="__codelineno-23-31" name="__codelineno-23-31" href="#__codelineno-23-31"></a>QUAD   - Quadratic easing
</span><span id="__span-23-32"><a id="__codelineno-23-32" name="__codelineno-23-32" href="#__codelineno-23-32"></a>CUBIC  - Cubic easing
</span><span id="__span-23-33"><a id="__codelineno-23-33" name="__codelineno-23-33" href="#__codelineno-23-33"></a>QUART  - Quartic easing
</span><span id="__span-23-34"><a id="__codelineno-23-34" name="__codelineno-23-34" href="#__codelineno-23-34"></a>QUINT  - Quintic easing
</span><span id="__span-23-35"><a id="__codelineno-23-35" name="__codelineno-23-35" href="#__codelineno-23-35"></a>EXPO   - Exponential easing
</span><span id="__span-23-36"><a id="__codelineno-23-36" name="__codelineno-23-36" href="#__codelineno-23-36"></a>CIRC   - Circular easing
</span><span id="__span-23-37"><a id="__codelineno-23-37" name="__codelineno-23-37" href="#__codelineno-23-37"></a>BACK   - Back easing
</span><span id="__span-23-38"><a id="__codelineno-23-38" name="__codelineno-23-38" href="#__codelineno-23-38"></a>ELASTIC - Elastic easing
</span><span id="__span-23-39"><a id="__codelineno-23-39" name="__codelineno-23-39" href="#__codelineno-23-39"></a>BOUNCE - Bounce easing
</span><span id="__span-23-40"><a id="__codelineno-23-40" name="__codelineno-23-40" href="#__codelineno-23-40"></a>
</span><span id="__span-23-41"><a id="__codelineno-23-41" name="__codelineno-23-41" href="#__codelineno-23-41"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-23-42"><a id="__codelineno-23-42" name="__codelineno-23-42" href="#__codelineno-23-42"></a>
</span><span id="__span-23-43"><a id="__codelineno-23-43" name="__codelineno-23-43" href="#__codelineno-23-43"></a>Example: terminaltexteffects spotlights --final-gradient-stops ab48ff e7b2b2 fffebd --final-gradient-steps 12 --beam-width-ratio 2.0 --beam-falloff 0.3 --search-duration 750 --search-speed-range 0.25-0.5 --spotlight-count 3
</span></code></pre></div>
</details>
<hr>
<h2 id="spray">Spray</h2>
<p>Sprays the characters from a single point.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/spray_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spray/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/spray/#terminaltexteffects.effects.effect_spray.SprayConfig">Config</a></p>
<details>
<summary>Spray Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>                    (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-24-8"><a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>--spray-position {n,ne,e,se,s,sw,w,nw,center}
</span><span id="__span-24-9"><a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>                    Position for the spray origin. (default: e)
</span><span id="__span-24-10"><a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>--spray-volume (float &gt; 0)
</span><span id="__span-24-11"><a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>                    Number of characters to spray per tick as a percent of the total number of characters. (default: 0.005)
</span><span id="__span-24-12"><a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a>--movement-speed (hyphen separated float range e.g. '0.25-0.5')
</span><span id="__span-24-13"><a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a>                    Movement speed of the characters. (default: (0.4, 1.0))
</span><span id="__span-24-14"><a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a>--movement-easing MOVEMENT_EASING
</span><span id="__span-24-15"><a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a>                    Easing function to use for character movement. (default: out_expo)
</span><span id="__span-24-16"><a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a>
</span><span id="__span-24-17"><a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a>Easing
</span><span id="__span-24-18"><a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a>------
</span><span id="__span-24-19"><a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a>Note: A prefix must be added to the function name.
</span><span id="__span-24-20"><a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a>
</span><span id="__span-24-21"><a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a>All easing functions support the following prefixes:
</span><span id="__span-24-22"><a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a>    IN_  - Ease in
</span><span id="__span-24-23"><a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a>    OUT_ - Ease out
</span><span id="__span-24-24"><a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-24-25"><a id="__codelineno-24-25" name="__codelineno-24-25" href="#__codelineno-24-25"></a>
</span><span id="__span-24-26"><a id="__codelineno-24-26" name="__codelineno-24-26" href="#__codelineno-24-26"></a>Easing Functions
</span><span id="__span-24-27"><a id="__codelineno-24-27" name="__codelineno-24-27" href="#__codelineno-24-27"></a>----------------
</span><span id="__span-24-28"><a id="__codelineno-24-28" name="__codelineno-24-28" href="#__codelineno-24-28"></a>SINE   - Sine easing
</span><span id="__span-24-29"><a id="__codelineno-24-29" name="__codelineno-24-29" href="#__codelineno-24-29"></a>QUAD   - Quadratic easing
</span><span id="__span-24-30"><a id="__codelineno-24-30" name="__codelineno-24-30" href="#__codelineno-24-30"></a>CUBIC  - Cubic easing
</span><span id="__span-24-31"><a id="__codelineno-24-31" name="__codelineno-24-31" href="#__codelineno-24-31"></a>QUART  - Quartic easing
</span><span id="__span-24-32"><a id="__codelineno-24-32" name="__codelineno-24-32" href="#__codelineno-24-32"></a>QUINT  - Quintic easing
</span><span id="__span-24-33"><a id="__codelineno-24-33" name="__codelineno-24-33" href="#__codelineno-24-33"></a>EXPO   - Exponential easing
</span><span id="__span-24-34"><a id="__codelineno-24-34" name="__codelineno-24-34" href="#__codelineno-24-34"></a>CIRC   - Circular easing
</span><span id="__span-24-35"><a id="__codelineno-24-35" name="__codelineno-24-35" href="#__codelineno-24-35"></a>BACK   - Back easing
</span><span id="__span-24-36"><a id="__codelineno-24-36" name="__codelineno-24-36" href="#__codelineno-24-36"></a>ELASTIC - Elastic easing
</span><span id="__span-24-37"><a id="__codelineno-24-37" name="__codelineno-24-37" href="#__codelineno-24-37"></a>BOUNCE - Bounce easing
</span><span id="__span-24-38"><a id="__codelineno-24-38" name="__codelineno-24-38" href="#__codelineno-24-38"></a>
</span><span id="__span-24-39"><a id="__codelineno-24-39" name="__codelineno-24-39" href="#__codelineno-24-39"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-24-40"><a id="__codelineno-24-40" name="__codelineno-24-40" href="#__codelineno-24-40"></a>
</span><span id="__span-24-41"><a id="__codelineno-24-41" name="__codelineno-24-41" href="#__codelineno-24-41"></a>Example: terminaltexteffects spray --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --spray-position e --spray-volume 0.005 --movement-speed 0.4-1.0 --movement-easing OUT_EXPO
</span></code></pre></div>
</details>
<hr>
<h2 id="swarm">Swarm</h2>
<p>Characters are grouped into swarms and move around the terminal before settling into position.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/swarm_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/swarm/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/swarm/#terminaltexteffects.effects.effect_swarm.SwarmConfig">Config</a></p>
<details>
<summary>Swarm Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>--base-color (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>                    Space separated, unquoted, list of colors for the swarms (default: ('31a0d4',))
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>--flash-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-25-4"><a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>                    Color for the character flash. Characters flash when moving. (default: f2ea79)
</span><span id="__span-25-5"><a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-25-6"><a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-25-7"><a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>                    (default: ('31b900', 'f0ff65'))
</span><span id="__span-25-8"><a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-25-9"><a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-25-10"><a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-25-11"><a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a>                    Direction of the final gradient. (default: Direction.HORIZONTAL)
</span><span id="__span-25-12"><a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a>--swarm-size (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-25-13"><a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a>                    Percent of total characters in each swarm. (default: 0.1)
</span><span id="__span-25-14"><a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a>--swarm-coordination (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-25-15"><a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a>                    Percent of characters in a swarm that move as a group. (default: 0.8)
</span><span id="__span-25-16"><a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a>--swarm-area-count (hyphen separated int range e.g. '1-10')
</span><span id="__span-25-17"><a id="__codelineno-25-17" name="__codelineno-25-17" href="#__codelineno-25-17"></a>                    Range of the number of areas where characters will swarm. (default: (2, 4))
</span><span id="__span-25-18"><a id="__codelineno-25-18" name="__codelineno-25-18" href="#__codelineno-25-18"></a>
</span><span id="__span-25-19"><a id="__codelineno-25-19" name="__codelineno-25-19" href="#__codelineno-25-19"></a>Example: terminaltexteffects swarm --base-color 31a0d4 --flash-color f2ea79 --final-gradient-stops 31b900 f0ff65 --final-gradient-steps 12 --swarm-size 0.1 --swarm-coordination 0.80 --swarm-area-count 2-4
</span></code></pre></div>
</details>
<hr>
<h2 id="synthgrid">SynthGrid</h2>
<p>Create a grid which fills with characters dissolving into the final text.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/synthgrid_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/synthgrid/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/synthgrid/#terminaltexteffects.effects.effect_synthgrid.SynthGridConfig">Config</a></p>
<details>
<summary>SynthGrid Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>--grid-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>                    Space separated, unquoted, list of colors for the grid gradient. (default: ('CC00CC', 'ffffff'))
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>--grid-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-26-4"><a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-26-5"><a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>--grid-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-26-6"><a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>                    Direction of the gradient for the grid color. (default: Direction.DIAGONAL)
</span><span id="__span-26-7"><a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a>--text-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-26-8"><a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a>                    Space separated, unquoted, list of colors for the text gradient. (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-26-9"><a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a>--text-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-26-10"><a id="__codelineno-26-10" name="__codelineno-26-10" href="#__codelineno-26-10"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-26-11"><a id="__codelineno-26-11" name="__codelineno-26-11" href="#__codelineno-26-11"></a>--text-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-26-12"><a id="__codelineno-26-12" name="__codelineno-26-12" href="#__codelineno-26-12"></a>                    Direction of the gradient for the text color. (default: Direction.VERTICAL)
</span><span id="__span-26-13"><a id="__codelineno-26-13" name="__codelineno-26-13" href="#__codelineno-26-13"></a>--grid-row-symbol (ASCII/UTF-8 character)
</span><span id="__span-26-14"><a id="__codelineno-26-14" name="__codelineno-26-14" href="#__codelineno-26-14"></a>                    Symbol to use for grid row lines. (default: ‚îÄ)
</span><span id="__span-26-15"><a id="__codelineno-26-15" name="__codelineno-26-15" href="#__codelineno-26-15"></a>--grid-column-symbol (ASCII/UTF-8 character)
</span><span id="__span-26-16"><a id="__codelineno-26-16" name="__codelineno-26-16" href="#__codelineno-26-16"></a>                    Symbol to use for grid column lines. (default: ‚îÇ)
</span><span id="__span-26-17"><a id="__codelineno-26-17" name="__codelineno-26-17" href="#__codelineno-26-17"></a>--text-generation-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-26-18"><a id="__codelineno-26-18" name="__codelineno-26-18" href="#__codelineno-26-18"></a>                    Space separated, unquoted, list of characters for the text generation animation. (default: ('‚ñë', '‚ñí', '‚ñì'))
</span><span id="__span-26-19"><a id="__codelineno-26-19" name="__codelineno-26-19" href="#__codelineno-26-19"></a>--max-active-blocks (float &gt; 0)
</span><span id="__span-26-20"><a id="__codelineno-26-20" name="__codelineno-26-20" href="#__codelineno-26-20"></a>                    Maximum percentage of blocks to have active at any given time. For example, if set to 0.1, 10 percent of the blocks will be active at any given time. (default: 0.1)
</span><span id="__span-26-21"><a id="__codelineno-26-21" name="__codelineno-26-21" href="#__codelineno-26-21"></a>
</span><span id="__span-26-22"><a id="__codelineno-26-22" name="__codelineno-26-22" href="#__codelineno-26-22"></a>Example: terminaltexteffects synthgrid --grid-gradient-stops CC00CC ffffff --grid-gradient-steps 12 --text-gradient-stops 8A008A 00D1FF FFFFFF --text-gradient-steps 12 --grid-row-symbol ‚îÄ --grid-column-symbol "‚îÇ" --text-generation-symbols ‚ñë ‚ñí ‚ñì --max-active-blocks 0.1
</span></code></pre></div>
</details>
<hr>
<h2 id="unstable">Unstable</h2>
<p>Spawns characters jumbled, explodes them to the edge of the canvas, then reassembles them.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/unstable_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/unstable/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/unstable/#terminaltexteffects.effects.effect_unstable.UnstableConfig">Config</a></p>
<details>
<summary>Unstable Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>--unstable-color (XTerm [0-255] OR RGB Hex [000000-ffffff])
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>                        Color transitioned to as the characters become unstable. (default: ff9200)
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-27-4"><a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>                        Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-27-5"><a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>                        (default: ('8A008A', '00D1FF', 'FFFFFF'))
</span><span id="__span-27-6"><a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-27-7"><a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>                        Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-27-8"><a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-27-9"><a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>                        Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-27-10"><a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a>--explosion-ease EXPLOSION_EASE
</span><span id="__span-27-11"><a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a>                        Easing function to use for character movement during the explosion. (default: out_expo)
</span><span id="__span-27-12"><a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a>--explosion-speed (float &gt; 0)
</span><span id="__span-27-13"><a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>                        Speed of characters during explosion. (default: 0.75)
</span><span id="__span-27-14"><a id="__codelineno-27-14" name="__codelineno-27-14" href="#__codelineno-27-14"></a>--reassembly-ease REASSEMBLY_EASE
</span><span id="__span-27-15"><a id="__codelineno-27-15" name="__codelineno-27-15" href="#__codelineno-27-15"></a>                        Easing function to use for character reassembly. (default: out_expo)
</span><span id="__span-27-16"><a id="__codelineno-27-16" name="__codelineno-27-16" href="#__codelineno-27-16"></a>--reassembly-speed (float &gt; 0)
</span><span id="__span-27-17"><a id="__codelineno-27-17" name="__codelineno-27-17" href="#__codelineno-27-17"></a>                        Speed of characters during reassembly. (default: 0.75)
</span><span id="__span-27-18"><a id="__codelineno-27-18" name="__codelineno-27-18" href="#__codelineno-27-18"></a>
</span><span id="__span-27-19"><a id="__codelineno-27-19" name="__codelineno-27-19" href="#__codelineno-27-19"></a>    Easing
</span><span id="__span-27-20"><a id="__codelineno-27-20" name="__codelineno-27-20" href="#__codelineno-27-20"></a>    ------
</span><span id="__span-27-21"><a id="__codelineno-27-21" name="__codelineno-27-21" href="#__codelineno-27-21"></a>    Note: A prefix must be added to the function name.
</span><span id="__span-27-22"><a id="__codelineno-27-22" name="__codelineno-27-22" href="#__codelineno-27-22"></a>
</span><span id="__span-27-23"><a id="__codelineno-27-23" name="__codelineno-27-23" href="#__codelineno-27-23"></a>    All easing functions support the following prefixes:
</span><span id="__span-27-24"><a id="__codelineno-27-24" name="__codelineno-27-24" href="#__codelineno-27-24"></a>        IN_  - Ease in
</span><span id="__span-27-25"><a id="__codelineno-27-25" name="__codelineno-27-25" href="#__codelineno-27-25"></a>        OUT_ - Ease out
</span><span id="__span-27-26"><a id="__codelineno-27-26" name="__codelineno-27-26" href="#__codelineno-27-26"></a>        IN_OUT_ - Ease in and out
</span><span id="__span-27-27"><a id="__codelineno-27-27" name="__codelineno-27-27" href="#__codelineno-27-27"></a>
</span><span id="__span-27-28"><a id="__codelineno-27-28" name="__codelineno-27-28" href="#__codelineno-27-28"></a>    Easing Functions
</span><span id="__span-27-29"><a id="__codelineno-27-29" name="__codelineno-27-29" href="#__codelineno-27-29"></a>    ----------------
</span><span id="__span-27-30"><a id="__codelineno-27-30" name="__codelineno-27-30" href="#__codelineno-27-30"></a>    SINE   - Sine easing
</span><span id="__span-27-31"><a id="__codelineno-27-31" name="__codelineno-27-31" href="#__codelineno-27-31"></a>    QUAD   - Quadratic easing
</span><span id="__span-27-32"><a id="__codelineno-27-32" name="__codelineno-27-32" href="#__codelineno-27-32"></a>    CUBIC  - Cubic easing
</span><span id="__span-27-33"><a id="__codelineno-27-33" name="__codelineno-27-33" href="#__codelineno-27-33"></a>    QUART  - Quartic easing
</span><span id="__span-27-34"><a id="__codelineno-27-34" name="__codelineno-27-34" href="#__codelineno-27-34"></a>    QUINT  - Quintic easing
</span><span id="__span-27-35"><a id="__codelineno-27-35" name="__codelineno-27-35" href="#__codelineno-27-35"></a>    EXPO   - Exponential easing
</span><span id="__span-27-36"><a id="__codelineno-27-36" name="__codelineno-27-36" href="#__codelineno-27-36"></a>    CIRC   - Circular easing
</span><span id="__span-27-37"><a id="__codelineno-27-37" name="__codelineno-27-37" href="#__codelineno-27-37"></a>    BACK   - Back easing
</span><span id="__span-27-38"><a id="__codelineno-27-38" name="__codelineno-27-38" href="#__codelineno-27-38"></a>    ELASTIC - Elastic easing
</span><span id="__span-27-39"><a id="__codelineno-27-39" name="__codelineno-27-39" href="#__codelineno-27-39"></a>    BOUNCE - Bounce easing
</span><span id="__span-27-40"><a id="__codelineno-27-40" name="__codelineno-27-40" href="#__codelineno-27-40"></a>
</span><span id="__span-27-41"><a id="__codelineno-27-41" name="__codelineno-27-41" href="#__codelineno-27-41"></a>    Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-27-42"><a id="__codelineno-27-42" name="__codelineno-27-42" href="#__codelineno-27-42"></a>
</span><span id="__span-27-43"><a id="__codelineno-27-43" name="__codelineno-27-43" href="#__codelineno-27-43"></a>
</span><span id="__span-27-44"><a id="__codelineno-27-44" name="__codelineno-27-44" href="#__codelineno-27-44"></a>    Example: terminaltexteffects unstable --unstable-color ff9200 --final-gradient-stops 8A008A 00D1FF FFFFFF --final-gradient-steps 12 --explosion-ease OUT_EXPO --explosion-speed 0.75 --reassembly-ease OUT_EXPO --reassembly-speed 0.75&lt;/details&gt;
</span></code></pre></div>
</details>
<hr>
<h2 id="vhstape">VHSTape</h2>
<p>Lines of characters glitch left and right and lose detail like an old VHS tape.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/vhstape_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/vhstape/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/vhstape/#terminaltexteffects.effects.effect_vhstape.VHSTapeConfig">Config</a></p>
<details>
<summary>VHSTape Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-28-3"><a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>                    (default: ('ab48ff', 'e7b2b2', 'fffebd'))
</span><span id="__span-28-4"><a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-28-5"><a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (12,))
</span><span id="__span-28-6"><a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-28-7"><a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-28-8"><a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>--glitch-line-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-9"><a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>                    Space separated, unquoted, list of colors for the characters when a single line is glitching. Colors are applied in order as an animation. (default: ('ffffff', 'ff0000', '00ff00',
</span><span id="__span-28-10"><a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a>                    '0000ff', 'ffffff'))
</span><span id="__span-28-11"><a id="__codelineno-28-11" name="__codelineno-28-11" href="#__codelineno-28-11"></a>--glitch-wave-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-12"><a id="__codelineno-28-12" name="__codelineno-28-12" href="#__codelineno-28-12"></a>                    Space separated, unquoted, list of colors for the characters in lines that are part of the glitch wave. Colors are applied in order as an animation. (default: ('ffffff', 'ff0000',
</span><span id="__span-28-13"><a id="__codelineno-28-13" name="__codelineno-28-13" href="#__codelineno-28-13"></a>                    '00ff00', '0000ff', 'ffffff'))
</span><span id="__span-28-14"><a id="__codelineno-28-14" name="__codelineno-28-14" href="#__codelineno-28-14"></a>--noise-colors (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-28-15"><a id="__codelineno-28-15" name="__codelineno-28-15" href="#__codelineno-28-15"></a>                    Space separated, unquoted, list of colors for the characters during the noise phase. (default: ('1e1e1f', '3c3b3d', '6d6c70', 'a2a1a6', 'cbc9cf', 'ffffff'))
</span><span id="__span-28-16"><a id="__codelineno-28-16" name="__codelineno-28-16" href="#__codelineno-28-16"></a>--glitch-line-chance (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-28-17"><a id="__codelineno-28-17" name="__codelineno-28-17" href="#__codelineno-28-17"></a>                    Chance that a line will glitch on any given frame. (default: 0.05)
</span><span id="__span-28-18"><a id="__codelineno-28-18" name="__codelineno-28-18" href="#__codelineno-28-18"></a>--noise-chance (0 &lt;= float(n) &lt;= 1)
</span><span id="__span-28-19"><a id="__codelineno-28-19" name="__codelineno-28-19" href="#__codelineno-28-19"></a>                    Chance that all characters will experience noise on any given frame. (default: 0.004)
</span><span id="__span-28-20"><a id="__codelineno-28-20" name="__codelineno-28-20" href="#__codelineno-28-20"></a>--total-glitch-time (int &gt; 0)
</span><span id="__span-28-21"><a id="__codelineno-28-21" name="__codelineno-28-21" href="#__codelineno-28-21"></a>                    Total time, frames, that the glitching phase will last. (default: 1000)
</span><span id="__span-28-22"><a id="__codelineno-28-22" name="__codelineno-28-22" href="#__codelineno-28-22"></a>
</span><span id="__span-28-23"><a id="__codelineno-28-23" name="__codelineno-28-23" href="#__codelineno-28-23"></a>Example: terminaltexteffects vhstape --final-gradient-stops ab48ff e7b2b2 fffebd --final-gradient-steps 12 --glitch-line-colors ffffff ff0000 00ff00 0000ff ffffff --glitch-wave-colors ffffff ff0000 00ff00 0000ff ffffff --noise-colors 1e1e1f 3c3b3d 6d6c70 a2a1a6 cbc9cf ffffff --glitch-line-chance 0.05 --noise-chance 0.004 --total-glitch-time 1000
</span></code></pre></div>
</details>
<hr>
<h2 id="waves">Waves</h2>
<p>Waves travel across the terminal leaving behind the characters.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/waves_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/waves/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/waves/#terminaltexteffects.effects.effect_waves.WavesConfig">Config</a></p>
<details>
<summary>Waves Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>--wave-symbols (ASCII/UTF-8 character) [(ASCII/UTF-8 character) ...]
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>                    Symbols to use for the wave animation. Multi-character strings will be used in sequence to create an animation. (default: ('‚ñÅ', '‚ñÇ', '‚ñÉ', '‚ñÑ', '‚ñÖ', '‚ñÜ', '‚ñá', '‚ñà', '‚ñá', '‚ñÜ', '‚ñÖ', '‚ñÑ',
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>                    '‚ñÉ', '‚ñÇ', '‚ñÅ'))
</span><span id="__span-29-4"><a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a>--wave-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-29-5"><a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-29-6"><a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a>                    (default: (Color(#f0ff65), Color(#ffb102), Color(#31a0d4), Color(#ffb102), Color(#f0ff65)))
</span><span id="__span-29-7"><a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a>--wave-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-29-8"><a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: (6,))
</span><span id="__span-29-9"><a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-29-10"><a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a>                    Space separated, unquoted, list of colors for the character gradient (applied from bottom to top). If only one color is provided, the characters will be displayed in that color.
</span><span id="__span-29-11"><a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a>                    (default: (Color(#ffb102), Color(#31a0d4), Color(#f0ff65)))
</span><span id="__span-29-12"><a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-29-13"><a id="__codelineno-29-13" name="__codelineno-29-13" href="#__codelineno-29-13"></a>                    Space separated, unquoted, list of the number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-29-14"><a id="__codelineno-29-14" name="__codelineno-29-14" href="#__codelineno-29-14"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-29-15"><a id="__codelineno-29-15" name="__codelineno-29-15" href="#__codelineno-29-15"></a>                    Direction of the final gradient. (default: Direction.DIAGONAL)
</span><span id="__span-29-16"><a id="__codelineno-29-16" name="__codelineno-29-16" href="#__codelineno-29-16"></a>--wave-count WAVE_COUNT
</span><span id="__span-29-17"><a id="__codelineno-29-17" name="__codelineno-29-17" href="#__codelineno-29-17"></a>                    Number of waves to generate. n &gt; 0. (default: 7)
</span><span id="__span-29-18"><a id="__codelineno-29-18" name="__codelineno-29-18" href="#__codelineno-29-18"></a>--wave-length (int &gt; 0)
</span><span id="__span-29-19"><a id="__codelineno-29-19" name="__codelineno-29-19" href="#__codelineno-29-19"></a>                    The number of frames for each step of the wave. Higher wave-lengths will create a slower wave. (default: 2)
</span><span id="__span-29-20"><a id="__codelineno-29-20" name="__codelineno-29-20" href="#__codelineno-29-20"></a>--wave-direction {column_left_to_right,column_right_to_left,row_top_to_bottom,row_bottom_to_top,center_to_outside,outside_to_center}
</span><span id="__span-29-21"><a id="__codelineno-29-21" name="__codelineno-29-21" href="#__codelineno-29-21"></a>                    Direction of the wave. (default: column_left_to_right)
</span><span id="__span-29-22"><a id="__codelineno-29-22" name="__codelineno-29-22" href="#__codelineno-29-22"></a>--wave-easing WAVE_EASING
</span><span id="__span-29-23"><a id="__codelineno-29-23" name="__codelineno-29-23" href="#__codelineno-29-23"></a>                    Easing function to use for wave travel. (default: in_out_sine)
</span><span id="__span-29-24"><a id="__codelineno-29-24" name="__codelineno-29-24" href="#__codelineno-29-24"></a>
</span><span id="__span-29-25"><a id="__codelineno-29-25" name="__codelineno-29-25" href="#__codelineno-29-25"></a>Easing
</span><span id="__span-29-26"><a id="__codelineno-29-26" name="__codelineno-29-26" href="#__codelineno-29-26"></a>------
</span><span id="__span-29-27"><a id="__codelineno-29-27" name="__codelineno-29-27" href="#__codelineno-29-27"></a>Note: A prefix must be added to the function name (except LINEAR).
</span><span id="__span-29-28"><a id="__codelineno-29-28" name="__codelineno-29-28" href="#__codelineno-29-28"></a>
</span><span id="__span-29-29"><a id="__codelineno-29-29" name="__codelineno-29-29" href="#__codelineno-29-29"></a>All easing functions support the following prefixes:
</span><span id="__span-29-30"><a id="__codelineno-29-30" name="__codelineno-29-30" href="#__codelineno-29-30"></a>    IN_  - Ease in
</span><span id="__span-29-31"><a id="__codelineno-29-31" name="__codelineno-29-31" href="#__codelineno-29-31"></a>    OUT_ - Ease out
</span><span id="__span-29-32"><a id="__codelineno-29-32" name="__codelineno-29-32" href="#__codelineno-29-32"></a>    IN_OUT_ - Ease in and out
</span><span id="__span-29-33"><a id="__codelineno-29-33" name="__codelineno-29-33" href="#__codelineno-29-33"></a>
</span><span id="__span-29-34"><a id="__codelineno-29-34" name="__codelineno-29-34" href="#__codelineno-29-34"></a>Easing Functions
</span><span id="__span-29-35"><a id="__codelineno-29-35" name="__codelineno-29-35" href="#__codelineno-29-35"></a>----------------
</span><span id="__span-29-36"><a id="__codelineno-29-36" name="__codelineno-29-36" href="#__codelineno-29-36"></a>LINEAR - Linear easing
</span><span id="__span-29-37"><a id="__codelineno-29-37" name="__codelineno-29-37" href="#__codelineno-29-37"></a>SINE   - Sine easing
</span><span id="__span-29-38"><a id="__codelineno-29-38" name="__codelineno-29-38" href="#__codelineno-29-38"></a>QUAD   - Quadratic easing
</span><span id="__span-29-39"><a id="__codelineno-29-39" name="__codelineno-29-39" href="#__codelineno-29-39"></a>CUBIC  - Cubic easing
</span><span id="__span-29-40"><a id="__codelineno-29-40" name="__codelineno-29-40" href="#__codelineno-29-40"></a>QUART  - Quartic easing
</span><span id="__span-29-41"><a id="__codelineno-29-41" name="__codelineno-29-41" href="#__codelineno-29-41"></a>QUINT  - Quintic easing
</span><span id="__span-29-42"><a id="__codelineno-29-42" name="__codelineno-29-42" href="#__codelineno-29-42"></a>EXPO   - Exponential easing
</span><span id="__span-29-43"><a id="__codelineno-29-43" name="__codelineno-29-43" href="#__codelineno-29-43"></a>CIRC   - Circular easing
</span><span id="__span-29-44"><a id="__codelineno-29-44" name="__codelineno-29-44" href="#__codelineno-29-44"></a>BACK   - Back easing
</span><span id="__span-29-45"><a id="__codelineno-29-45" name="__codelineno-29-45" href="#__codelineno-29-45"></a>ELASTIC - Elastic easing
</span><span id="__span-29-46"><a id="__codelineno-29-46" name="__codelineno-29-46" href="#__codelineno-29-46"></a>BOUNCE - Bounce easing
</span><span id="__span-29-47"><a id="__codelineno-29-47" name="__codelineno-29-47" href="#__codelineno-29-47"></a>
</span><span id="__span-29-48"><a id="__codelineno-29-48" name="__codelineno-29-48" href="#__codelineno-29-48"></a>Visit: https://easings.net/ for visualizations of the easing functions.
</span><span id="__span-29-49"><a id="__codelineno-29-49" name="__codelineno-29-49" href="#__codelineno-29-49"></a>
</span><span id="__span-29-50"><a id="__codelineno-29-50" name="__codelineno-29-50" href="#__codelineno-29-50"></a>Example: terminaltexteffects waves --wave-symbols ‚ñÅ ‚ñÇ ‚ñÉ ‚ñÑ ‚ñÖ ‚ñÜ ‚ñá ‚ñà ‚ñá ‚ñÜ ‚ñÖ ‚ñÑ ‚ñÉ ‚ñÇ ‚ñÅ --wave-gradient-stops f0ff65 ffb102 31a0d4 ffb102 f0ff65 --wave-gradient-steps 6 --final-gradient-stops ffb102 31a0d4 f0ff65 --final-gradient-steps 12 --wave-count 7 --wave-length 2 --wave-easing IN_OUT_SINE
</span></code></pre></div>
</details>
<hr>
<h2 id="wipe">Wipe</h2>
<p>Performs a wipe across the terminal to reveal characters.</p>
<p><img alt="Demo" src="https://chrisbuilds.github.io/terminaltexteffects/img/effects_demos/wipe_demo.gif"></p>
<p><a href="https://chrisbuilds.github.io/terminaltexteffects/effects/wipe/">Reference</a> <a href="https://chrisbuilds.github.io/terminaltexteffects/effects/wipe/#terminaltexteffects.effects.effect_wipe.WipeConfig">Config</a></p>
<details>
<summary>Wipe Command Line Arguments</summary>
<div><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>--wipe-direction {column_left_to_right,column_right_to_left,row_top_to_bottom,row_bottom_to_top,diagonal_top_left_to_bottom_right,diagonal_bottom_left_to_top_right,diagonal_top_right_to_bottom_left,diagonal_bottom_right_to_top_left,outside_to_center,center_to_outside}
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>                    Direction the text will wipe. (default: diagonal_bottom_left_to_top_right)
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a>--final-gradient-stops (XTerm [0-255] OR RGB Hex [000000-ffffff]) [(XTerm [0-255] OR RGB Hex [000000-ffffff]) ...]
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a>                    Space separated, unquoted, list of colors for the wipe gradient. (default: (Color(#833ab4), Color(#fd1d1d), Color(#fcb045)))
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a>--final-gradient-steps (int &gt; 0) [(int &gt; 0) ...]
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a>                    Number of gradient steps to use. More steps will create a smoother and longer gradient animation. (default: 12)
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a>--final-gradient-frames (int &gt; 0)
</span><span id="__span-30-8"><a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>                    Number of frames to display each gradient step. Increase to slow down the gradient animation. (default: 5)
</span><span id="__span-30-9"><a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a>--final-gradient-direction (diagonal, horizontal, vertical, radial)
</span><span id="__span-30-10"><a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a>                    Direction of the final gradient. (default: Direction.VERTICAL)
</span><span id="__span-30-11"><a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a>--wipe-delay (int &gt;= 0)
</span><span id="__span-30-12"><a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a>                    Number of frames to wait before adding the next character group. Increase, to slow down the effect. (default: 0)
</span><span id="__span-30-13"><a id="__codelineno-30-13" name="__codelineno-30-13" href="#__codelineno-30-13"></a>
</span><span id="__span-30-14"><a id="__codelineno-30-14" name="__codelineno-30-14" href="#__codelineno-30-14"></a>Example: terminaltexteffects wipe --wipe-direction diagonal_bottom_left_to_top_right --final-gradient-stops 833ab4 fd1d1d fcb045 --final-gradient-steps 12 --final-gradient-frames 5 --wipe-delay 0
</span></code></pre></div>
</details>












                
              </article>
            </div>
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Openkoda ‚Äì Open‚Äìsource, private, Salesforce alternative (257 pts)]]></title>
            <link>https://github.com/openkoda/openkoda</link>
            <guid>40502956</guid>
            <pubDate>Tue, 28 May 2024 17:11:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/openkoda/openkoda">https://github.com/openkoda/openkoda</a>, See on <a href="https://news.ycombinator.com/item?id=40502956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311209030-698c333f-4791-4c6b-95d4-aa6eff7dc6d3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDkwMzAtNjk4YzMzM2YtNDc5MS00YzZiLTk1ZDQtYWE2ZWZmN2RjNmQzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmNDdiM2UwNDIzN2M5OWU5YzRjNDRkYmJiOTgyODA3NjhmZWIzN2EyYzJkNzk2NzQxNjYxNjhhNWI4ZWRkMjImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.1u0a3wf6OoZqus-IQnw8RRkCdnrefFx85vsOL4kXJqg"><img alt="Openkoda Logo" src="https://private-user-images.githubusercontent.com/14223954/311209030-698c333f-4791-4c6b-95d4-aa6eff7dc6d3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDkwMzAtNjk4YzMzM2YtNDc5MS00YzZiLTk1ZDQtYWE2ZWZmN2RjNmQzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmNDdiM2UwNDIzN2M5OWU5YzRjNDRkYmJiOTgyODA3NjhmZWIzN2EyYzJkNzk2NzQxNjYxNjhhNWI4ZWRkMjImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.1u0a3wf6OoZqus-IQnw8RRkCdnrefFx85vsOL4kXJqg" width="70%"></a>
</p>
<div dir="auto">
  <p dir="auto"><h3 tabindex="-1" dir="auto">Ready-to-use development platform that accelerates the process of building business applications and internal tools.</h3><a id="user-content-ready-to-use-development-platform-that-accelerates-the-process-of-building-business-applications-and-internal-tools" aria-label="Permalink: Ready-to-use development platform that accelerates the process of building business applications and internal tools." href="#ready-to-use-development-platform-that-accelerates-the-process-of-building-business-applications-and-internal-tools"></a></p>
</div>
<p><a href="https://opensource.org/licenses/MIT" rel="nofollow"><img alt="License: MIT" src="https://camo.githubusercontent.com/efc2f3907feb90b733c9fa4fe158637fd40ee1cfe834cad6b46cf8e3e75de8c9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d3138423243362e737667" data-canonical-src="https://img.shields.io/badge/License-MIT-18B2C6.svg"></a>
    <a href="https://openkoda.com/product/" rel="nofollow"><img alt="Openkoda: 1.5.1" src="https://camo.githubusercontent.com/58bc75c5b47caa6bc4757689919f005f4ef9fef128b0196b74052809860b4057/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d4f70656e6b6f6461266d6573736167653d312e352e3126636f6c6f723d313842324336" data-canonical-src="https://img.shields.io/static/v1?label=Openkoda&amp;message=1.5.1&amp;color=18B2C6"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8729903294ca978fe85f10d43fe3dad9e7a0e015e14ba5b0705ee8f4e39dca48/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d4a617661266d6573736167653d31372e302e3226636f6c6f723d313842324336"><img alt="Java: 17.0.2" src="https://camo.githubusercontent.com/8729903294ca978fe85f10d43fe3dad9e7a0e015e14ba5b0705ee8f4e39dca48/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d4a617661266d6573736167653d31372e302e3226636f6c6f723d313842324336" data-canonical-src="https://img.shields.io/static/v1?label=Java&amp;message=17.0.2&amp;color=18B2C6"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9d06407a13551712cbd371caa6f26014b0bbf0fde10cba37b667b2759042aa15/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d537072696e67253230426f6f74266d6573736167653d332e302e3526636f6c6f723d313842324336"><img alt="Spring Boot: 3.0.5" src="https://camo.githubusercontent.com/9d06407a13551712cbd371caa6f26014b0bbf0fde10cba37b667b2759042aa15/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d537072696e67253230426f6f74266d6573736167653d332e302e3526636f6c6f723d313842324336" data-canonical-src="https://img.shields.io/static/v1?label=Spring%20Boot&amp;message=3.0.5&amp;color=18B2C6"></a>
</p>
<br>
<ul dir="auto">
<li><strong>Reduce development time and effort</strong>. Use pre-built functionalities and out-of-the-box features.</li>
<li><strong>Adopt a flexible and scalable approach</strong>. Build applications with dynamic entities. Choose from multiple multi-tenancy models.</li>
<li><strong>Use technology you already know</strong>: Java, Spring Boot, JavaScript, HTML, Hibernate, PostgreSQL</li>
<li><strong>Extend as you wish</strong>. Openkoda offers unlimited customization and integration options.</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312075569-9acded2e-a3e6-4480-805e-7ac38ebdafc0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzU1NjktOWFjZGVkMmUtYTNlNi00NDgwLTgwNWUtN2FjMzhlYmRhZmMwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFjMjY5NGU3NGI5OGU4MGZkYTA4M2E1YWZlZDRkYWQwNDljZGJlOWM3YjliMTAxODEzYTVkMjE5M2YwN2JmODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lVSNQM1OT2siE2xaSYaRyG44Xw4FxFaRXmyYAA8WE0c"><img src="https://private-user-images.githubusercontent.com/14223954/312075569-9acded2e-a3e6-4480-805e-7ac38ebdafc0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzU1NjktOWFjZGVkMmUtYTNlNi00NDgwLTgwNWUtN2FjMzhlYmRhZmMwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFjMjY5NGU3NGI5OGU4MGZkYTA4M2E1YWZlZDRkYWQwNDljZGJlOWM3YjliMTAxODEzYTVkMjE5M2YwN2JmODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lVSNQM1OT2siE2xaSYaRyG44Xw4FxFaRXmyYAA8WE0c" alt="openkoda admin"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">üìåContents</h3><a id="user-content-contents" aria-label="Permalink: üìåContents" href="#contents"></a></p>
<p dir="auto">üß© <a href="#-integrations">Integrations</a><br>
üöÄ <a href="#-getting-started">How to start</a><br>
‚úÖ <a href="#-out-of-the-box-features">Out-of-the-box features</a><br>
üë®‚Äçüíª <a href="#-tech-stack">Tech stack</a><br>
üí° <a href="#-sample-applications">Sample applications</a><br>
üí° <a href="#-application-screenshots">Application screenshots</a><br>
üíô <a href="#-contribution">Contribution</a><br>
üìú <a href="#%EF%B8%8F-release-notes">Release notes</a><br>
ü§ù <a href="#-partners">Partners</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">üß© Integrations</h3><a id="user-content--integrations" aria-label="Permalink: üß© Integrations" href="#-integrations"></a></p>
<p dir="auto">Enhance your application by adding integrations.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Open Source</h4><a id="user-content-open-source" aria-label="Permalink: Open Source" href="#open-source"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230132-bffafc23-6a72-4a8b-86cf-4a073cfe9c3b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxMzItYmZmYWZjMjMtNmE3Mi00YThiLTg2Y2YtNGEwNzNjZmU5YzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFkNWYyODViMzU0NzE3NWE5YTlkYjFkNWVmMmM3OWE4MzkyZDE5MDBjOThmNmY0ZGZkMjU5NmI2OWQ3ZTFkNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.gNYKJm2drHOk3UxIKrND4C42fWDv0iF3vyyM9F2Juq4"><img height="60" alt="logo-slack" src="https://private-user-images.githubusercontent.com/14223954/311230132-bffafc23-6a72-4a8b-86cf-4a073cfe9c3b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxMzItYmZmYWZjMjMtNmE3Mi00YThiLTg2Y2YtNGEwNzNjZmU5YzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFkNWYyODViMzU0NzE3NWE5YTlkYjFkNWVmMmM3OWE4MzkyZDE5MDBjOThmNmY0ZGZkMjU5NmI2OWQ3ZTFkNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.gNYKJm2drHOk3UxIKrND4C42fWDv0iF3vyyM9F2Juq4"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230162-f3b72e42-04c1-42c1-b268-76ef524a805c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxNjItZjNiNzJlNDItMDRjMS00MmMxLWIyNjgtNzZlZjUyNGE4MDVjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTIyOTBlNjU3OTE4MTQ0NWRhOWEyMjU4YTQ1YWEwMGI3MDZmOWM1OGY0OWMwY2VmZTVlMzlhZDZjMDFlZjk5ZTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.NjxSw5u4eQVKqIxAW94t1AeIMSyrM74DxoiElmF3tB8"><img height="60" alt="logo-discord" src="https://private-user-images.githubusercontent.com/14223954/311230162-f3b72e42-04c1-42c1-b268-76ef524a805c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAxNjItZjNiNzJlNDItMDRjMS00MmMxLWIyNjgtNzZlZjUyNGE4MDVjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTIyOTBlNjU3OTE4MTQ0NWRhOWEyMjU4YTQ1YWEwMGI3MDZmOWM1OGY0OWMwY2VmZTVlMzlhZDZjMDFlZjk5ZTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.NjxSw5u4eQVKqIxAW94t1AeIMSyrM74DxoiElmF3tB8"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230221-d26eccd9-39f2-4cc5-af86-e3e74bad95cf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMjEtZDI2ZWNjZDktMzlmMi00Y2M1LWFmODYtZTNlNzRiYWQ5NWNmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAwMDNmMTNlZWM3MTFlNjg0Y2JhMTFhYzBlNDUzYjVmY2I3NDk3MGVjNzA4NGE0NWNkOTdlNzQzNGIyYzE0YmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.WGoDLep9jJRSUF1ngHa4JsJRxRVtIWnhWtz1VJFreYM"><img height="60" alt="logo-basecamp" src="https://private-user-images.githubusercontent.com/14223954/311230221-d26eccd9-39f2-4cc5-af86-e3e74bad95cf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMjEtZDI2ZWNjZDktMzlmMi00Y2M1LWFmODYtZTNlNzRiYWQ5NWNmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAwMDNmMTNlZWM3MTFlNjg0Y2JhMTFhYzBlNDUzYjVmY2I3NDk3MGVjNzA4NGE0NWNkOTdlNzQzNGIyYzE0YmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.WGoDLep9jJRSUF1ngHa4JsJRxRVtIWnhWtz1VJFreYM"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230238-ba648de4-4cbf-4007-aff4-82c94942a65d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMzgtYmE2NDhkZTQtNGNiZi00MDA3LWFmZjQtODJjOTQ5NDJhNjVkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThlYTU5NmI3NTZhMzE5NmEwNmEyNGRhMjY2MTg0ZTAyMDliZmE0Zjk2YjEzOGJjNWI0NmU3NjliMGI5NTRjMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RiuoFjiAMFIkKKKdIhut7k8d9Dbm2Omngw5kiCYXGmw"><img height="60" alt="logo-github" src="https://private-user-images.githubusercontent.com/14223954/311230238-ba648de4-4cbf-4007-aff4-82c94942a65d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyMzgtYmE2NDhkZTQtNGNiZi00MDA3LWFmZjQtODJjOTQ5NDJhNjVkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThlYTU5NmI3NTZhMzE5NmEwNmEyNGRhMjY2MTg0ZTAyMDliZmE0Zjk2YjEzOGJjNWI0NmU3NjliMGI5NTRjMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RiuoFjiAMFIkKKKdIhut7k8d9Dbm2Omngw5kiCYXGmw"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230298-e45c0174-e07e-49dc-bdf5-2c1415538682.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyOTgtZTQ1YzAxNzQtZTA3ZS00OWRjLWJkZjUtMmMxNDE1NTM4NjgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdjZWNmYWU1YWY1NzEwYzI4MjI2YjgzZDMyMjg1M2EzNTc5YWZiNmI0NGI4NDE1NjVlMmUxZGYxZTRiZWFjY2MmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QZgrx7YzsleoANv6JiSaUfAyeOpIcGVsE1Rpyh8XbSA"><img height="40" alt="logo-jira" src="https://private-user-images.githubusercontent.com/14223954/311230298-e45c0174-e07e-49dc-bdf5-2c1415538682.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAyOTgtZTQ1YzAxNzQtZTA3ZS00OWRjLWJkZjUtMmMxNDE1NTM4NjgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdjZWNmYWU1YWY1NzEwYzI4MjI2YjgzZDMyMjg1M2EzNTc5YWZiNmI0NGI4NDE1NjVlMmUxZGYxZTRiZWFjY2MmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QZgrx7YzsleoANv6JiSaUfAyeOpIcGVsE1Rpyh8XbSA"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311230327-f18841b5-e6ad-4807-9b9c-f0d5622300f7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAzMjctZjE4ODQxYjUtZTZhZC00ODA3LTliOWMtZjBkNTYyMjMwMGY3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTMyYjc3MWUzOWViYjE5MmJhZDllYjgwMThlNjBmMGEzMTMxNmYyYzlmOGJlMjUzM2JlYWZjZDNkNzg2N2Q5YzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lBTlU1ibHGNoMY-1PDvzGTx0krrlL3E_ihv5rSTklss"><img height="60" alt="logo-trello" src="https://private-user-images.githubusercontent.com/14223954/311230327-f18841b5-e6ad-4807-9b9c-f0d5622300f7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzAzMjctZjE4ODQxYjUtZTZhZC00ODA3LTliOWMtZjBkNTYyMjMwMGY3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTMyYjc3MWUzOWViYjE5MmJhZDllYjgwMThlNjBmMGEzMTMxNmYyYzlmOGJlMjUzM2JlYWZjZDNkNzg2N2Q5YzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lBTlU1ibHGNoMY-1PDvzGTx0krrlL3E_ihv5rSTklss"></a>&nbsp;&nbsp;
</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Enterprise</h4><a id="user-content-enterprise" aria-label="Permalink: Enterprise" href="#enterprise"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231535-ae5cb4fd-4fb2-43ab-9a4a-3ca1deaf1aaf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1MzUtYWU1Y2I0ZmQtNGZiMi00M2FiLTlhNGEtM2NhMWRlYWYxYWFmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg2OTZhNmY3ZGIxOWE4NGZkNzdiN2YyYTMyOGZlMjNlZWZmY2UzZmJiMzA3OTUwMDVmMGE0Zjk5MWRkN2U3OTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.odOEvQrdxSRFkAeBdvWVcUJxDsYoSnGWcsrMXs9HFqg"><img height="60" alt="logo-google" src="https://private-user-images.githubusercontent.com/14223954/311231535-ae5cb4fd-4fb2-43ab-9a4a-3ca1deaf1aaf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1MzUtYWU1Y2I0ZmQtNGZiMi00M2FiLTlhNGEtM2NhMWRlYWYxYWFmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg2OTZhNmY3ZGIxOWE4NGZkNzdiN2YyYTMyOGZlMjNlZWZmY2UzZmJiMzA3OTUwMDVmMGE0Zjk5MWRkN2U3OTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.odOEvQrdxSRFkAeBdvWVcUJxDsYoSnGWcsrMXs9HFqg"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231552-42620407-eb57-4a04-a67e-6bc7bbbb4e7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1NTItNDI2MjA0MDctZWI1Ny00YTA0LWE2N2UtNmJjN2JiYmI0ZTdjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY4ZmM3Yjk3NmQ5OWViY2U4MDJjNjlmZTBiMzAyNmNhZmQ3NGUzYjNjZjJlZmY2NThmNDJkMDQ4M2NlNDcwOGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.nr1_y4ggB_QWAuvGxvPPabtayHTO5k_KLRsIaEInbHw"><img height="60" alt="logo-facebook" src="https://private-user-images.githubusercontent.com/14223954/311231552-42620407-eb57-4a04-a67e-6bc7bbbb4e7c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1NTItNDI2MjA0MDctZWI1Ny00YTA0LWE2N2UtNmJjN2JiYmI0ZTdjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY4ZmM3Yjk3NmQ5OWViY2U4MDJjNjlmZTBiMzAyNmNhZmQ3NGUzYjNjZjJlZmY2NThmNDJkMDQ4M2NlNDcwOGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.nr1_y4ggB_QWAuvGxvPPabtayHTO5k_KLRsIaEInbHw"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231593-33594d22-07f6-4a20-ad71-f18cbb428fc4.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1OTMtMzM1OTRkMjItMDdmNi00YTIwLWFkNzEtZjE4Y2JiNDI4ZmM0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYwNDA0YTViMmIxYzJmZTM4YzIxNWM3MWQ4NDM1YzAyYWEyMTkwNzhhOWJmNGYwMjYxYTNhY2M5NzEzYzdiNzMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.pgBfSqbDoaJKiqc2Cp5q6ICD48X9SAk3wrMSyrWcm_8"><img height="60" alt="logo-stripe" src="https://private-user-images.githubusercontent.com/14223954/311231593-33594d22-07f6-4a20-ad71-f18cbb428fc4.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE1OTMtMzM1OTRkMjItMDdmNi00YTIwLWFkNzEtZjE4Y2JiNDI4ZmM0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYwNDA0YTViMmIxYzJmZTM4YzIxNWM3MWQ4NDM1YzAyYWEyMTkwNzhhOWJmNGYwMjYxYTNhY2M5NzEzYzdiNzMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.pgBfSqbDoaJKiqc2Cp5q6ICD48X9SAk3wrMSyrWcm_8"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231611-61b60851-b821-4f94-8fe5-e7af910017ce.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE2MTEtNjFiNjA4NTEtYjgyMS00Zjk0LThmZTUtZTdhZjkxMDAxN2NlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ1MDA5MmNmMTM0ODNmY2UzNGQwMGI1YjRlZmE3MTExYWQ1NTU5NDhiOTIzOTNjZDhiOGUxNGIxMjllNDM0MjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.JZstw8nqQny7Up83Iq1bGMGBFhKnRo0D4gwuTbFn6No"><img height="60" alt="logo-ms-teams" src="https://private-user-images.githubusercontent.com/14223954/311231611-61b60851-b821-4f94-8fe5-e7af910017ce.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE2MTEtNjFiNjA4NTEtYjgyMS00Zjk0LThmZTUtZTdhZjkxMDAxN2NlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ1MDA5MmNmMTM0ODNmY2UzNGQwMGI1YjRlZmE3MTExYWQ1NTU5NDhiOTIzOTNjZDhiOGUxNGIxMjllNDM0MjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.JZstw8nqQny7Up83Iq1bGMGBFhKnRo0D4gwuTbFn6No"></a>&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311231859-47058144-3584-4059-9239-42d7192b475a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE4NTktNDcwNTgxNDQtMzU4NC00MDU5LTkyMzktNDJkNzE5MmI0NzVhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY5YjBlMjFkODYyZGY0YjZkMGI3OGE5OTgxZTBlZTQwMDQ4Yjg3YmY5ODkwNmU1OWUyOGZmODUwMGFlYTBjNjgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.heYud7QgsngADvYL8eBw5OCXoIDgMHvCaTpPruocdo4"><img height="60" alt="logo-ldap" src="https://private-user-images.githubusercontent.com/14223954/311231859-47058144-3584-4059-9239-42d7192b475a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzE4NTktNDcwNTgxNDQtMzU4NC00MDU5LTkyMzktNDJkNzE5MmI0NzVhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTY5YjBlMjFkODYyZGY0YjZkMGI3OGE5OTgxZTBlZTQwMDQ4Yjg3YmY5ODkwNmU1OWUyOGZmODUwMGFlYTBjNjgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.heYud7QgsngADvYL8eBw5OCXoIDgMHvCaTpPruocdo4"></a>&nbsp;&nbsp;
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">üë®‚Äçüíª Tech stack</h3><a id="user-content--tech-stack" aria-label="Permalink: üë®‚Äçüíª Tech stack" href="#-tech-stack"></a></p>
<ul dir="auto">
<li>Java (17+)</li>
<li>Spring Boot 3.x</li>
<li>Hibernate</li>
<li>PostgreSQL</li>
<li>GraalVM</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">üöÄ Getting started</h3><a id="user-content--getting-started" aria-label="Permalink: üöÄ Getting started" href="#-getting-started"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">There are two installation options to start application development with Openkoda:</p>
<ul dir="auto">
<li>Building from sources</li>
<li>Running as a Docker container</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option #1: Build from Source</h4><a id="user-content-option-1-build-from-source" aria-label="Permalink: Option #1: Build from Source" href="#option-1-build-from-source"></a></p>
<p dir="auto">Prerequisites:</p>
<p dir="auto">Git, Java 17+, Maven 3.8+, PostgreSQL 14+</p>
<ol dir="auto">
<li><a href="https://github.com/openkoda/openkoda.git">Create an empty database</a></li>
<li>Clone or download this Git repository</li>
<li>Build application with maven:</li>
</ol>
<div data-snippet-clipboard-copy-content="mvn -f openkoda/pom.xml clean install spring-boot:repackage -DskipTests"><pre><code>mvn -f openkoda/pom.xml clean install spring-boot:repackage -DskipTests
</code></pre></div>
<ol start="4" dir="auto">
<li>Initialize the database in a first run:</li>
</ol>
<div data-snippet-clipboard-copy-content="java -Dloader.path=/BOOT-INF/classes -Dspring.profiles.active=openkoda,drop_and_init_database -jar openkoda.jar --server.port=<http port>"><pre><code>java -Dloader.path=/BOOT-INF/classes -Dspring.profiles.active=openkoda,drop_and_init_database -jar openkoda.jar --server.port=&lt;http port&gt;
</code></pre></div>
<ol start="5" dir="auto">
<li>Run Openkoda</li>
</ol>
<div data-snippet-clipboard-copy-content="java -Dloader.path=/BOOT-INF/classes -Dsecure.cookie=false -jar openkoda.jar --spring.profiles.active=openkoda --server.port=<http port>"><pre><code>java -Dloader.path=/BOOT-INF/classes -Dsecure.cookie=false -jar openkoda.jar --spring.profiles.active=openkoda --server.port=&lt;http port&gt;
</code></pre></div>
<p dir="auto">Detailed instructions can be found in the <a href="https://github.com/openkoda/openkoda/blob/main/openkoda/doc/installation.md">Installation</a> manual.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option #2: Run as a Docker Container</h4><a id="user-content-option-2-run-as-a-docker-container" aria-label="Permalink: Option #2: Run as a Docker Container" href="#option-2-run-as-a-docker-container"></a></p>
<p dir="auto">Docker images are available at Docker Hub : <a href="https://hub.docker.com/r/openkoda/openkoda" rel="nofollow">https://hub.docker.com/r/openkoda/openkoda</a></p>
<p dir="auto">It can be launched via simple:</p>
<div data-snippet-clipboard-copy-content="docker pull openkoda/openkoda:latest"><pre><code>docker pull openkoda/openkoda:latest
</code></pre></div>
<p dir="auto">Please note that in that case Postgres needs to be already in place and <code>SPRING_DATASOURCE_URL</code>, <code>SPRING_DATASOURCE_USERNAME</code>, <code>SPRING_DATASOURCE_PASSWORD</code> env variables needs to be adjusted when running docker (<a href="https://hub.docker.com/r/openkoda/openkoda" rel="nofollow">see Docker Hub for detailed options</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Docker compose</h5><a id="user-content-docker-compose" aria-label="Permalink: Docker compose" href="#docker-compose"></a></p>
<p dir="auto">A simpler option may be to use the Docker Compose scripts located in the: <code>./docker/docker-compose.yaml</code> and <code>./docker/docker-compose-no-db.yaml</code> - depending on your preference, with or without Postgres as a part of the docker service. Here is a useful one-liner :</p>
<div data-snippet-clipboard-copy-content="curl https://raw.githubusercontent.com/openkoda/openkoda/main/docker/docker-compose.yaml | docker compose -f - up"><pre><code>curl https://raw.githubusercontent.com/openkoda/openkoda/main/docker/docker-compose.yaml | docker compose -f - up
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">‚úÖ Out-of-the-box features</h3><a id="user-content--out-of-the-box-features" aria-label="Permalink: ‚úÖ Out-of-the-box features" href="#-out-of-the-box-features"></a></p>
<p dir="auto">To significantly reduce development time and effort, Openkoda offers pre-built functionality and out-of-the-box features.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîÄ Dynamic entities:</h4><a id="user-content--dynamic-entities" aria-label="Permalink: üîÄ Dynamic entities:" href="#-dynamic-entities"></a></p>
<p dir="auto">Create database table, CRUD functionality, form, and overview with no need of re-compilation</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üõ†Ô∏è Application admin panel:</h4><a id="user-content-Ô∏è-application-admin-panel" aria-label="Permalink: üõ†Ô∏è Application admin panel:" href="#Ô∏è-application-admin-panel"></a></p>
<ul dir="auto">
<li><strong>App Configurations</strong>: Manage email settings, roles, privileges, and HTML templates.</li>
<li><strong>Audit Screen</strong>: Track changes to data for accountability.</li>
<li><strong>System Logs</strong>: Review logs for activity insights and troubleshooting.</li>
<li><strong>System Health</strong>: Get a quick overview of system performance and status.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üë§User Management</h4><a id="user-content-user-management" aria-label="Permalink: üë§User Management" href="#user-management"></a></p>
<ul dir="auto">
<li>Invite users to the organization</li>
<li>Set roles globally and within the organization context</li>
<li>Access user profile settings</li>
<li>Spoof user (available in admin mode)</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîë Roles and Privileges</h4><a id="user-content--roles-and-privileges" aria-label="Permalink: üîë Roles and Privileges" href="#-roles-and-privileges"></a></p>
<ul dir="auto">
<li>Create global or organization-specific roles</li>
<li>Assign privileges from a list to each role</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üè¢ Organization management</h4><a id="user-content--organization-management" aria-label="Permalink: üè¢ Organization management" href="#-organization-management"></a></p>
<ul dir="auto">
<li>Separate organization data</li>
<li>Implement security rules for data access</li>
<li>Customize your own dashboard</li>
<li>Assign organizational roles, such as member or admin, to users.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üìù CMS</h4><a id="user-content--cms" aria-label="Permalink: üìù CMS" href="#-cms"></a></p>
<ul dir="auto">
<li>Modify HTML templates</li>
<li>Edit draft versions of resources</li>
<li>Introduce new public resources</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üóÇÔ∏è Resource Management</h4><a id="user-content-Ô∏è-resource-management" aria-label="Permalink: üóÇÔ∏è Resource Management" href="#Ô∏è-resource-management"></a></p>
<ul dir="auto">
<li>Manage file overview</li>
<li>Resize images</li>
<li>Set files to public access</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîä Event Listeners:</h4><a id="user-content--event-listeners" aria-label="Permalink: üîä Event Listeners:" href="#-event-listeners"></a></p>
<p dir="auto">Respond to application events (e.g., user creation, login, application start) with built-in Openkoda handlers (e.g., messaging, push notifications).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üíæ Backups:</h4><a id="user-content--backups" aria-label="Permalink: üíæ Backups:" href="#-backups"></a></p>
<p dir="auto">Embedded database backup routines</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üì• Import and export:</h4><a id="user-content--import-and-export" aria-label="Permalink: üì• Import and export:" href="#-import-and-export"></a></p>
<p dir="auto">Export components from current app and easily import them into another Openkoda Core instance</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üóÑÔ∏è Multiple Multi-tenancy models:</h4><a id="user-content-Ô∏è-multiple-multi-tenancy-models" aria-label="Permalink: üóÑÔ∏è Multiple Multi-tenancy models:" href="#Ô∏è-multiple-multi-tenancy-models"></a></p>
<p dir="auto">Openkoda supports the following multi-tenancy setups:</p>
<ul dir="auto">
<li>Single Database / Single Schema</li>
<li>Single Database / Many Schemas</li>
<li>Multiple Databases / Many Schemas</li>
</ul>
<p dir="auto">See <a href="https://github.com/openkoda/openkoda/blob/main/openkoda/doc/installation.md#multitenancy-setup">multitenancy setup</a> for more details</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîÑ Job Requests</h4><a id="user-content--job-requests" aria-label="Permalink: üîÑ Job Requests" href="#-job-requests"></a></p>
<p dir="auto">Schedule jobs to be performed in time intervals
Process jobs with event listeners</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîî Notifications</h4><a id="user-content--notifications" aria-label="Permalink: üîî Notifications" href="#-notifications"></a></p>
<p dir="auto">Synchronize your application with notifications channels:
Email
Slack
Jira
GitHub
Trello
Basecamp</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">‚úâÔ∏è Email Sender</h4><a id="user-content-Ô∏è-email-sender" aria-label="Permalink: ‚úâÔ∏è Email Sender" href="#Ô∏è-email-sender"></a></p>
<p dir="auto">Customize email templates via CMS
Schedule emails</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">üí° Sample applications</h3><a id="user-content--sample-applications" aria-label="Permalink: üí° Sample applications" href="#-sample-applications"></a></p>
<p dir="auto">Openkoda Application Templates are sample applications built with Openkoda.</p>
<p dir="auto">They represent a standard set of functions for a traditional web application provided by Openkoda Core, as well as business functionalities created specifically for these examples.</p>
<p dir="auto">Application Templates can be easily extended, taking into account both the data storage schema and any custom functionality.</p>
<p dir="auto">Learn more in our <a href="https://github.com/openkoda/openkoda/blob/main/openkoda/doc/5-minute-guide.md">5-minute guide</a>.</p>
<p dir="auto"><strong>Timelog</strong></p>
<p dir="auto">Timelog is a time tracking solution for companies of all sizes. It allows employees to record hours spent on specific tasks, while managers generate monthly performance reports. <a href="https://openkoda.com/time-tracking-software/" rel="nofollow">Learn more</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076431-ecaf54d2-6112-4c45-a67f-15ac7b150452.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0MzEtZWNhZjU0ZDItNjExMi00YzQ1LWE2N2YtMTVhYzdiMTUwNDUyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTcxN2ZjNzk5ZmVjOGQ2MWQ5MWEzYzg0ODJkYTEyYmIxOWMzYjA0MjUzOWRiY2MyYzZkOTYzNWZkY2I0Zjc5YWMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.igno7rI81UjPz-rib7ISwiXYdJHnlswwrvRjNl3H4O8"><img src="https://private-user-images.githubusercontent.com/14223954/312076431-ecaf54d2-6112-4c45-a67f-15ac7b150452.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0MzEtZWNhZjU0ZDItNjExMi00YzQ1LWE2N2YtMTVhYzdiMTUwNDUyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTcxN2ZjNzk5ZmVjOGQ2MWQ5MWEzYzg0ODJkYTEyYmIxOWMzYjA0MjUzOWRiY2MyYzZkOTYzNWZkY2I0Zjc5YWMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.igno7rI81UjPz-rib7ISwiXYdJHnlswwrvRjNl3H4O8" alt="timelog user"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076469-e9669bef-5929-4fd6-92e8-8e35865a9261.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0NjktZTk2NjliZWYtNTkyOS00ZmQ2LTkyZTgtOGUzNTg2NWE5MjYxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmOGZmODBhZjg4ZWFlODAxMTIzMzgwNzJjMTA4YjFmZDlkMGIxOTJmYjQ5MzY1NTUzYzA4Y2IyZDA1NjRiZDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.0EPTOm1B4aHcoyuwOwyNvaaBUL9NM2ej5lJI55GbtXI"><img src="https://private-user-images.githubusercontent.com/14223954/312076469-e9669bef-5929-4fd6-92e8-8e35865a9261.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY0NjktZTk2NjliZWYtNTkyOS00ZmQ2LTkyZTgtOGUzNTg2NWE5MjYxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmOGZmODBhZjg4ZWFlODAxMTIzMzgwNzJjMTA4YjFmZDlkMGIxOTJmYjQ5MzY1NTUzYzA4Y2IyZDA1NjRiZDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.0EPTOm1B4aHcoyuwOwyNvaaBUL9NM2ej5lJI55GbtXI" alt="timelog admin"></a></p>
<p dir="auto"><strong>Insurance Policy Management</strong></p>
<p dir="auto">Insurance Policy Management is a dynamic policy data storage tool with a variety of embeddable widgets for personalized customer and policy dashboards.
Widgets include: message senders, email schedulers, attachment and task lists, notes, and detailed customer/policy information to improve operational efficiency and customer engagement. <a href="https://openkoda.com/insurance-policy-management-software/" rel="nofollow">Learn more</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076544-cb2f4065-59a4-42da-915d-4fd3d810fc19.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1NDQtY2IyZjQwNjUtNTlhNC00MmRhLTkxNWQtNGZkM2Q4MTBmYzE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhYmJlNTAzNjRlNGRhYTMyNGMzYzdjYjExODg5ZDViNWI5MWI5MmM2YzBjNTlmYWE2OWYxMjdhNDBjZTc2MmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.zNr0TBPgYiAro0GEsSp3LdqhWWSPmyHM-fgcPoPNUXQ"><img src="https://private-user-images.githubusercontent.com/14223954/312076544-cb2f4065-59a4-42da-915d-4fd3d810fc19.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1NDQtY2IyZjQwNjUtNTlhNC00MmRhLTkxNWQtNGZkM2Q4MTBmYzE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhYmJlNTAzNjRlNGRhYTMyNGMzYzdjYjExODg5ZDViNWI5MWI5MmM2YzBjNTlmYWE2OWYxMjdhNDBjZTc2MmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.zNr0TBPgYiAro0GEsSp3LdqhWWSPmyHM-fgcPoPNUXQ" alt="insurance user"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/312076583-ac47b4ba-246e-4772-b47c-69bbfe8512fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1ODMtYWM0N2I0YmEtMjQ2ZS00NzcyLWI0N2MtNjliYmZlODUxMmZlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE4NTlhNWE0NjY1NThmMzJkNTE1OTQ1N2JjMjNmMmMxZDM0ZDUyMjE3MDgxNzM3Nzk4MzcwNjQ4NzkyYTQ3NzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.M1rbI3qt_wiQx4bEtRl6CFd7sZUDcfu2wZUbogmt6Fo"><img src="https://private-user-images.githubusercontent.com/14223954/312076583-ac47b4ba-246e-4772-b47c-69bbfe8512fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTIwNzY1ODMtYWM0N2I0YmEtMjQ2ZS00NzcyLWI0N2MtNjliYmZlODUxMmZlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE4NTlhNWE0NjY1NThmMzJkNTE1OTQ1N2JjMjNmMmMxZDM0ZDUyMjE3MDgxNzM3Nzk4MzcwNjQ4NzkyYTQ3NzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.M1rbI3qt_wiQx4bEtRl6CFd7sZUDcfu2wZUbogmt6Fo" alt="insurance admin"></a></p>
<p dir="auto"><strong>Weather App</strong></p>
<p dir="auto">A sample application that provides weather forecast for selected vacation spots.</p>
<p dir="auto">Watch the short video to see the building process:
<a href="https://youtu.be/gob4j072Isg" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/10715247/316587497-19c670f1-281f-463c-b93c-0715ebef6402.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xMDcxNTI0Ny8zMTY1ODc0OTctMTljNjcwZjEtMjgxZi00NjNjLWI5M2MtMDcxNWViZWY2NDAyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmNzExNGM5N2NjM2E0Y2YzYzU0OTY2ZTkwMmRjOTg3M2FjNmExODIzYWQ3NDUxMWE4N2QyYzc4YjQxYTI1MmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ip79AyNEbKHF-Sz1W5e3D8KVZnFvTL4En0l87tNCpiQ" alt="How to build a weather app in less than 20 minutes?" secured-asset-link="" data-animated-image=""></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">üí° Application screenshots</h3><a id="user-content--application-screenshots" aria-label="Permalink: üí° Application screenshots" href="#-application-screenshots"></a></p>
<p dir="auto">CMS</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311207985-3e4e5563-53d3-4e7b-9ccf-8a69ea346bc1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDc5ODUtM2U0ZTU1NjMtNTNkMy00ZTdiLTljY2YtOGE2OWVhMzQ2YmMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBhNDNlNWZiNmIxOTY3YjI3MzExM2I4MWQzZTgzNmMxZDZmYzA1MGE3NzgxY2IyMTlmN2Q4N2FmMThlOWExMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5mTkTjOq5Yew2yQCCZPKCfEZaObfrKHk0b5JJFjVjyY"><img alt="openkoda-frontendresource-all" src="https://private-user-images.githubusercontent.com/14223954/311207985-3e4e5563-53d3-4e7b-9ccf-8a69ea346bc1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDc5ODUtM2U0ZTU1NjMtNTNkMy00ZTdiLTljY2YtOGE2OWVhMzQ2YmMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBhNDNlNWZiNmIxOTY3YjI3MzExM2I4MWQzZTgzNmMxZDZmYzA1MGE3NzgxY2IyMTlmN2Q4N2FmMThlOWExMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5mTkTjOq5Yew2yQCCZPKCfEZaObfrKHk0b5JJFjVjyY"></a>
<p dir="auto">Organization Settings</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311208029-275135d1-6c99-48fa-9224-008183d02085.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDgwMjktMjc1MTM1ZDEtNmM5OS00OGZhLTkyMjQtMDA4MTgzZDAyMDg1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MDE3YjhlOTU4MjkzNTM3ZTM4NGZmOThhNTc4NjAzYzMzOWIwMzZkZTUyNDE3ZjdkNmFlODA3YWFmZjJlNmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.kETK4acUfnKlUvWCMqNOIZWgAce9MjNfZBaQoulEj5c"><img alt="openkoda-organization-settings" src="https://private-user-images.githubusercontent.com/14223954/311208029-275135d1-6c99-48fa-9224-008183d02085.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMDgwMjktMjc1MTM1ZDEtNmM5OS00OGZhLTkyMjQtMDA4MTgzZDAyMDg1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MDE3YjhlOTU4MjkzNTM3ZTM4NGZmOThhNTc4NjAzYzMzOWIwMzZkZTUyNDE3ZjdkNmFlODA3YWFmZjJlNmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.kETK4acUfnKlUvWCMqNOIZWgAce9MjNfZBaQoulEj5c"></a>
<p dir="auto">Job Request</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311232624-2d26ddfd-3bee-4cc3-a4e0-be08d522bc96.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2MjQtMmQyNmRkZmQtM2JlZS00Y2MzLWE0ZTAtYmUwOGQ1MjJiYzk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM1OTliMjA5YzVlMjY3MmJiODJkMDUzYWIwNTE3Yjg0ZjNlZDE2ZDNiZDQwZDhjZGViYTk5YTFiMzJmNzRjMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.muDj1R_hne1QGz9sFK5HhhspMDHmdwma_OgN3f492lY"><img alt="openkoda-job-request" src="https://private-user-images.githubusercontent.com/14223954/311232624-2d26ddfd-3bee-4cc3-a4e0-be08d522bc96.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2MjQtMmQyNmRkZmQtM2JlZS00Y2MzLWE0ZTAtYmUwOGQ1MjJiYzk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWM1OTliMjA5YzVlMjY3MmJiODJkMDUzYWIwNTE3Yjg0ZjNlZDE2ZDNiZDQwZDhjZGViYTk5YTFiMzJmNzRjMmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.muDj1R_hne1QGz9sFK5HhhspMDHmdwma_OgN3f492lY"></a>
<p dir="auto">Event Litener</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311232682-ac5d52b5-5509-4f37-b5b2-b7a3d9aaa631.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2ODItYWM1ZDUyYjUtNTUwOS00ZjM3LWI1YjItYjdhM2Q5YWFhNjMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI0ZGFiZGYzZmM5MjVlODkyZTdkOGFkNzEzM2Y2OTkwYmYyYzFhZjdlYTNmODJlNzI3N2JjYTNkNDUxMzk1NGYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.bwjdE3L0nNuj-_CILjO89ZgrRAg4ec7KlQfW1jKqd7M"><img alt="openkoda-event-listener" src="https://private-user-images.githubusercontent.com/14223954/311232682-ac5d52b5-5509-4f37-b5b2-b7a3d9aaa631.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI2ODItYWM1ZDUyYjUtNTUwOS00ZjM3LWI1YjItYjdhM2Q5YWFhNjMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI0ZGFiZGYzZmM5MjVlODkyZTdkOGFkNzEzM2Y2OTkwYmYyYzFhZjdlYTNmODJlNzI3N2JjYTNkNDUxMzk1NGYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.bwjdE3L0nNuj-_CILjO89ZgrRAg4ec7KlQfW1jKqd7M"></a>
<p dir="auto">Forgot Password</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14223954/311232707-f4c78aca-dc1d-4f42-8ba2-903d641a4229.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI3MDctZjRjNzhhY2EtZGMxZC00ZjQyLThiYTItOTAzZDY0MWE0MjI5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE4MmRjNzYwN2NmZDkzZjUzYTg0NjRmOWVkODk2NjA5MDc3NWY2MmRjODFhODM1OGMyMGRiMzE0OTg1NDJjNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.V5i5nqZt1gL0qNpqcXj28UOzD5vnX8JLbBpZjn3CZnY"><img alt="openkoda-forgot-password" src="https://private-user-images.githubusercontent.com/14223954/311232707-f4c78aca-dc1d-4f42-8ba2-903d641a4229.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTY5MjEzMDMsIm5iZiI6MTcxNjkyMTAwMywicGF0aCI6Ii8xNDIyMzk1NC8zMTEyMzI3MDctZjRjNzhhY2EtZGMxZC00ZjQyLThiYTItOTAzZDY0MWE0MjI5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTI4VDE4MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE4MmRjNzYwN2NmZDkzZjUzYTg0NjRmOWVkODk2NjA5MDc3NWY2MmRjODFhODM1OGMyMGRiMzE0OTg1NDJjNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.V5i5nqZt1gL0qNpqcXj28UOzD5vnX8JLbBpZjn3CZnY"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto">üíô Contribution</h3><a id="user-content--contribution" aria-label="Permalink: üíô Contribution" href="#-contribution"></a></p>
<p dir="auto">Openkoda is an open source project under <a href="https://github.com/openkoda/openkoda/blob/main/LICENSE">MIT license</a>. It‚Äôs built by developers for developers.</p>
<p dir="auto">If you have ideas for improvement, contribute and let's innovate together.</p>
<p dir="auto">How to contribute:</p>
<ol dir="auto">
<li>Create a fork</li>
<li>Create a feature branch from main branch</li>
<li>Push</li>
<li>Create a Pull Request to an upstream main branch</li>
</ol>
<p dir="auto"><a href="https://github.com/openkoda/openkoda/blob/main/openkoda/CONTRIBUTING.md"><strong>Detailed contribution rules</strong></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">üì¢ Follow, learn, and spread the word</h3><a id="user-content--follow-learn-and-spread-the-word" aria-label="Permalink: üì¢ Follow, learn, and spread the word" href="#-follow-learn-and-spread-the-word"></a></p>
<p dir="auto"><a href="https://github.com/orgs/openkoda/repositories">Openkoda Community</a>: Become a part of Openkoda<br>
<a href="https://www.youtube.com/channel/UCN0LzuxOYIDdKDX9W0sGFlg" rel="nofollow">YouTube</a>: Learn how to use Openkoda<br>
<a href="https://www.linkedin.com/company/openkoda" rel="nofollow">LinkedIn</a>: Stay up to date<br>
<a href="https://openkoda.com/about-us/" rel="nofollow">About us</a>: Let us introduce ourselves</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">üóÉÔ∏è Release notes</h3><a id="user-content-Ô∏è-release-notes" aria-label="Permalink: üóÉÔ∏è Release notes" href="#Ô∏è-release-notes"></a></p>
<p dir="auto">Openkoda is constantly evolving. Check out the changelog:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Openkoda 1.5. üöÄ</h4><a id="user-content-openkoda-15-" aria-label="Permalink: Openkoda 1.5. üöÄ" href="#openkoda-15-"></a></p>
<ul dir="auto">
<li><strong>Dynamic Entities</strong>: Now create database tables, perform full CRUD operations and generate forms.</li>
<li><strong>New Dashboard UI</strong>: Enhanced for better readability and smoother navigation flow.</li>
<li><strong>Files Assignment</strong>: Support for dynamically registered entities.</li>
<li><strong>Organization-Level Email Configuration</strong>: Customize email settings at the organization level.</li>
<li><strong>Bug Fixes</strong>: Various fixes for improved app stability and performance.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Openkoda 1.4.3.</h4><a id="user-content-openkoda-143" aria-label="Permalink: Openkoda 1.4.3." href="#openkoda-143"></a></p>
<ul dir="auto">
<li><strong>Page Builder</strong>: Introducing a tool for creating custom dashboards.</li>
<li><strong>Web Forms Assistance</strong>: Streamlined web form creation based on your data model definitions.</li>
<li><strong>YAML Components Import/Export</strong>: Easily manage components such as web forms, endpoints, server code, event listeners, schedulers, and frontend resources.</li>
<li><strong>Dashboard UI</strong>: Upgrades for an improved dashboard interface.</li>
<li><strong>Updates &amp; Security</strong>: Minor adjustments and security fixes.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">ü§ù Partners</h3><a id="user-content--partners" aria-label="Permalink: ü§ù Partners" href="#-partners"></a></p>
<p dir="auto"><strong>Openkoda source code is completely free and is available under the <a href="https://github.com/openkoda/openkoda/blob/main/LICENSE">MIT license</a>.‚Äã</strong></p>
<p dir="auto">Join us as a partner in transforming the software development market by delivering maximum value to your clients using Openkoda. The goal is to simplify the process of building enterprise applications, allowing developers to focus on core business logic.</p>
<p dir="auto">Learn more about <a href="https://openkoda.com/partners/" rel="nofollow">Openkoda Partner Program</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">‚òÅÔ∏è Managed Cloud</h4><a id="user-content-Ô∏è-managed-cloud" aria-label="Permalink: ‚òÅÔ∏è Managed Cloud" href="#Ô∏è-managed-cloud"></a></p>
<p dir="auto">Our enterprise managed cloud allows for easy deployment and scaling of your Openkoda applications. <a href="https://openkoda.com/contact/" rel="nofollow">Contact us</a> for more information.</p>

<p><a href="https://www.facebook.com/Openkoda/" rel="nofollow"><img alt="Openkoda Facebook" src="https://github.com/openkoda/openkoda/raw/main/openkoda/src/main/resources/public/vendor/fontawesome-free/svgs/brands/facebook.svg" width="20px"></a>
    <a href="https://www.linkedin.com/company/openkoda" rel="nofollow"><img alt="Openkoda Facebook" src="https://github.com/openkoda/openkoda/raw/main/openkoda/src/main/resources/public/vendor/fontawesome-free/svgs/brands/linkedin.svg" width="20px"></a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steve Jurvetson's personal collection of Apollo Lunar Module parts (109 pts)]]></title>
            <link>https://www.flickr.com/photos/jurvetson/albums/72157623704246792/</link>
            <guid>40502877</guid>
            <pubDate>Tue, 28 May 2024 17:03:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.flickr.com/photos/jurvetson/albums/72157623704246792/">https://www.flickr.com/photos/jurvetson/albums/72157623704246792/</a>, See on <a href="https://news.ycombinator.com/item?id=40502877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-view-signature="album-header-view__UA_1__adConfig_1__albumId_72157623704246792__albumPhotoListLayoutStyle_story__baseURL_%2Fphotos%2Fjurvetson%2Falbums%2F72157623704246792%2F__id_72157623704246792__isMobile_false__isOwner_false__isTwitterbot_false__maxNumAttrName_totalCount__modelRegistryName_set-models__nsid_44124348109%40N01__nsidOrPathAlias_jurvetson__pageParams_1__photoListConfig_1__requiredToShowOnClient_true__requiredToShowOnServer_true">

	
	


	<div data-view-signature="album-title-desc-view__UA_1__adConfig_1__albumId_72157623704246792__albumPhotoListLayoutStyle_story__baseURL_%2Fphotos%2Fjurvetson%2Falbums%2F72157623704246792%2F__id_72157623704246792__isMobile_false__isOwner_false__isTwitterbot_false__maxNumAttrName_totalCount__modelRegistryName_set-models__nsid_44124348109%40N01__nsidOrPathAlias_jurvetson__pageParams_1__photoListConfig_1__requiredToShowOnClient_true__requiredToShowOnServer_true">
	<p>
		Space Collection üöÄ
	</p>


	<div><p>
			2021 Video Tour: <a href="https://youtu.be/4FOF0f70Hoc" rel="noreferrer nofollow">youtu.be/4FOF0f70Hoc</a> at Future Ventures' HQ ‚Äî with a focus on Apollo and flown spacecraft.  The museum includes a part of every Lunar Module that has been to the moon and some of the largest displays of Moon and Mars rock. </p><p>I try to be a good curator, gathering as much info as I can on the items which I have on display at the office.  If you have additional information on any of these, please add to the comments, or send me documents (steve at future dot ventures).</p></div>

	<p><span data-action="showMore">
			Show more
		</span>
	</p>

	</div>
	<div data-view-signature="album-stats-view__UA_1__adConfig_1__albumId_72157623704246792__albumPhotoListLayoutStyle_story__baseURL_%2Fphotos%2Fjurvetson%2Falbums%2F72157623704246792%2F__id_72157623704246792__isMobile_false__isOwner_false__isTwitterbot_false__maxNumAttrName_totalCount__modelRegistryName_set-models__nsid_44124348109%40N01__nsidOrPathAlias_jurvetson__pageParams_1__photoListConfig_1__requiredToShowOnClient_true__requiredToShowOnServer_true"><p><span>559 photos</span>
			<span>¬∑</span>
		<span>4 videos</span>
		<span>¬∑</span>
		<span>51,947 views</span>
</p>
</div>
	
	

	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reproduce GPT-2 in llm.c (472 pts)]]></title>
            <link>https://twitter.com/karpathy/status/1795484547267834137</link>
            <guid>40502090</guid>
            <pubDate>Tue, 28 May 2024 15:58:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karpathy/status/1795484547267834137">https://twitter.com/karpathy/status/1795484547267834137</a>, See on <a href="https://news.ycombinator.com/item?id=40502090">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Leaked OpenAI Docs Show Sam Altman Clearly Aware of Silencing Former Employees (156 pts)]]></title>
            <link>https://futurism.com/sam-altman-silencing-former-employees</link>
            <guid>40501739</guid>
            <pubDate>Tue, 28 May 2024 15:33:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://futurism.com/sam-altman-silencing-former-employees">https://futurism.com/sam-altman-silencing-former-employees</a>, See on <a href="https://news.ycombinator.com/item?id=40501739">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="incArticle"><p>OpenAI's credibility ‚Äî and the credibility of its CEO, Sam Altman ‚Äî is crumbling.</p><p>Last week, amid a surprise string of high-profile executive and safety team departures, <a href="https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release"><em>V</em><em>ox</em> revealed that</a> the ChatGPT creator had pressured employees into signing draconian non-disclosure and non-disparagement agreements by threatening to claw back exiting OpenAI employees' vested equity in the multibillion-dollar AI company.</p><p>Clawing back vested equity ‚Äî in short, the amount of company ownership that an employee has gained through their months or years of working there ‚Äî is a highly unusual practice to begin with. This is especially true in the startup-powered Silicon Valley, where tech workers often forgo high salaries in favor of equity agreements based on the hope that they'll get rich later when a successful startup like OpenAI eventually goes public. For OpenAI to play bizarre contractual take-backsies in exchange for narrative control over former employees would be an <a href="https://futurism.com/the-byte/openai-nda-criticism">awful look</a> for any company ‚Äî let alone a supposedly "open" venture claiming it's the best one to build the imagined all-knowing AI that OpenAI's leaders say will power humanity's future.</p><p>In response to the <em>Vox</em> report, Altman apologetically took to X-formerly-Twitter to admit that yes, "there was a provision about potential equity cancellation in our previous exit docs." But according to the CEO, though the clause was there, the company never <em>actually&nbsp;</em>clawed anything back. Most importantly, he further <a href="https://futurism.com/the-byte/sam-altman-nda-superintelligent">claimed</a> that he had no knowledge of the provision.</p><p>"This is on me and one of the few times I've been genuinely embarrassed running OpenAI," Altman continued in a tone that can only be described as sheepish, "I did not know this was happening and I should have."</p><p>But <a href="https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees">according to <em>Vox's</em> latest follow-up</a>, Altman wasn't in the dark about the equity clauses, as he claimed in his tail-between-legs tweet.</p><p>Documentation reviewed by <em>Vox</em> reveals that several company leaders ‚Äî including OpenAI chief strategy officer Jason Kwon, who reportedly told staffers following the initial <em>Vox </em>report that OpenAI leadership "caught" the provision "~month ago" ‚Äî signed documents that plainly outlined the stifling clawback provision. The list of executives includes Altman, whose signature, according to <em>Vox</em>'s reporting, is on "incorporation documents" for the holding company that manages OpenAI equity; these documents contain "multiple passages with language that gives the company near-arbitrary authority to claw back equity from former employees" or, if employees choose not to actually return the equity, "block them from selling it" altogether.</p><p>In other words, unless someone forged the CEO's signature, he gave express permission for these clauses to exist. Outside of forgery, there are only two plausible reasons for Altman's alleged lack of knowledge: either he didn't fully read the employment contracts he was signing or he was lying.</p><p>Complicating the denials further is the way employees were reportedly treated on their way out. According to the <em>Vox</em> report, the equity provisions were no secret to OpenAI representatives handling departures, who in some cases gave outgoing employees just seven days to make the incredibly complicated decision about their future ‚Äî all the while, in instances reviewed by <em>Vox</em>, emphasizing possible clawbacks.</p><p>"We want to make sure you understand that if you don't sign, it could impact your equity," one rep told an outgoing employee, according to <em>Vox</em>. "That's true for everyone, and we're just doing things by the book."</p><p>But again, as the report reiterates, this is <em>not </em>"by-the-book" behavior.</p><p>"For a company to threaten to claw back already-vested equity is egregious and unusual," Chambord Benton-Hayes, a California employment law attorney, told <em>Vox.</em></p><p>When <em>Vox</em> asked OpenAI to explain how the provisions could have possibly wound up in documents signed by Altman without Altman actually knowing about them, Kwon non-answered that "we are sorry for the distress this has caused great people who have worked hard for us."</p><p>"We have been working to fix this as quickly as possible," Kwon ‚Äî who, again, also signed papers delineating this provision ‚Äî continued in his statement. "We will work even harder to be better."</p><p>But that's getting harder and harder to believe. Last year, when Altman was briefly forced out of OpenAI in what was pretty much a corporate coup, those who voted to oust the CEO ‚Äî many of whom departed after losing said coup ‚Äî claimed that Altman had been "inconsistently candid" in his communications with the board. Altman and OpenAI are also caught up in a <a href="https://futurism.com/the-byte/law-experts-scarlett-johansson-strong-case-openai">brewing legal storm</a> with actress Scarlett Johansson, who claims that Altman copycatted her voice for OpenAI's new "Sky" AI assistant after she had explicitly turned Altman and OpenAI down. (Altman chalked Johansson's allegations up to <a href="https://www.businessinsider.com/openai-scarlett-johansson-voice-defense-sam-altman-washington-post-chatgpt-2024-5">simple miscommunication</a>.)</p><p>Meanwhile, <a href="https://futurism.com/openai-safety-worker-quit-confidence-agi">recent departures</a> have <a href="https://futurism.com/the-byte/openai-researcher-quits-criticism-superallignment">ground</a> OpenAI's "Superalignment" safety team ‚Äî the ones tasked with making sure a killer AI doesn't obliterate humankind ‚Äî <a href="https://www.cnbc.com/2024/05/17/openai-superalignment-sutskever-leike.html">into dust</a>. Great stuff.</p><p>On its website, OpenAI features a "<a href="https://openai.com/charter/">charter</a>" declaring that "OpenAI's mission is to ensure that artificial general intelligence (AGI) ‚Äî by which we mean highly autonomous systems that outperform humans at most economically valuable work ‚Äî benefits all of humanity."</p><p>"We will attempt to directly build safe and beneficial AGI," it continues, "but will also consider our mission fulfilled if our work aids others to achieve this outcome."</p><p>The document then lists a series of "principles," which the company claims it'll follow to achieve this mission. The word "transparency" is notably absent.</p><p><strong>More on OpenAI: </strong><a href="https://futurism.com/sam-altman-openai-scarlett-johansson"><em>Sam Altman Ignoring Scarlett Johansson's Lack of Consent Shows Us Exactly What Type of Person He Really Is</em></a></p><br></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mobifree ‚Äì An open-source mobile ecosystem (267 pts)]]></title>
            <link>https://f-droid.org/2024/05/24/mobifree.html</link>
            <guid>40501027</guid>
            <pubDate>Tue, 28 May 2024 14:24:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://f-droid.org/2024/05/24/mobifree.html">https://f-droid.org/2024/05/24/mobifree.html</a>, See on <a href="https://news.ycombinator.com/item?id=40501027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Have you ever wondered what it would be like to engage in a mobile ecosystem
outside of the watchful eye of the Big Tech giants and gatekeepers? A system
that includes everything from operating systems, to app stores, to cloud
services, messaging apps, email servers and more? A system that puts your
privacy first, believes in a democratic approach and healthy competition,
and a system that relies on open-source solutions to drive its software?
Welcome to <a href="https://mobifree.org/">Mobifree</a>, a human-centered, ethical
alternative, that champions privacy over profit and believes in
collaboration, sustainability and inclusiveness.</p>

<p>Everyone is locked into a mobile phone ecosystem where the terms are
dictated by a handful of Big Tech companies all located in a single
country.  From end users looking to download and use their favorite apps, to
developers who run into roadblocks when trying to get their solutions
published, to governments who are increasingly using apps as a way to
provide services to their citizens, we are all impacted by the gatekeeping,
data tracking, and railroading Big Tech is imposing on us in the current
mobile ecosystem. A new alternative is required to shape a better
future. And F-Droid is excited to be a part of creating that new mobile
ecosystem, together with our other partners in Mobifree.</p>

<p><img src="https://f-droid.org/assets/icon_dv5EXg0_UTcQ7wK2dYoloypQJfXvPPbhZ9IEg5nxYFw=.png" alt="NGI Mobifree logo"></p>

<p>For an average user, it is difficult to discern how you are being tracked,
where your private information is being saved, how it is being used and who
it is being sold to. As a long-standing champion of user and developer
rights, pushing for privacy over profit, F-Droid has always been committed
to upholding high open-source standards in the technology we create. For
more than 14 years, F-Droid has been developing solutions which act as
pieces of the alternative mobile ecosystem puzzle. So it was a natural fit
for F-Droid to become a contributing partner in the broader Mobifree
project.</p>

<p>Of particular emphasis is the impact this alternative mobile ecosystem will
have on the services governments provide their citizens. Governments at all
levels are providing services through mobile apps. And in many cases, mobile
apps are becoming the preferred way to access important services. These apps
are only available via the Apple App Store or Google Play. And installing
apps from those stores requires agreeing to their Terms of Services. Both
app stores were built on tracking users to sell their data, thereby giving
Apple and Google power over how citizens receive services from their own
governments. Even the governments themselves are beholden to the Big Tech
gatekeepers: citizens and government officials and employees must use apps
that are only published on Apple and Google.</p>

<p>Austria provides a few specific examples of how governments interact with
the current ecosystem at multiple levels. After COVID-19 countermeasures
forced schools to adopt online learning, many public schools required
education apps for their students, parents and teachers in order to stay
connected. Public health insurance providers require a specific app called
‚ÄúHandy Signatur‚Äù to be downloaded in order for citizens to access their
accounts online. People with the Handy Signatur app can sign petitions, and
download vaccination certificates, sometimes required for work or leisure
activities. Without this app, it is much more work and effort and is
borderline impossible in some cases to engage in certain activities.</p>

<p>Governments around the world are taking action to reign in the dominance of
Big Tech. South Africa and the
<a href="https://theplatformlaw.blog/2021/12/17/the-interim-report-of-the-cmas-market-study-on-mobile-ecosystems-a-great-piece-of-work/">UK</a>
have changed their competition policy to include user freedom in what they
<a href="https://www.theverge.com/2024/5/24/24164204/uk-dmcc-law-big-tech-regulation">regulate</a>.
Japan is working on new laws to <a href="https://content.clearygottlieb.com/antitrust/digital-markets-regulation-handbook/japan/index.html">open
up</a>
their mobile markets. And even the US government and many individual US
states have <a href="https://www.npr.org/2023/12/19/1220202154/google-to-pay-700-million-in-case-over-whether-its-app-store-is-an-illegal-monop">sued Big
Tech</a>
to stop monopolistic behaviors.</p>

<p>The EU is also taking a step towards creating distance between its citizens
and Big Tech gatekeepers. They passed a landmark law: the <a href="https://en.wikipedia.org/wiki/Digital_Markets_Act">Digital Markets
Act</a>, representing a
whole new approach to tackling gatekeeper companies that aim to keep all
sorts of competition out.  It builds upon the successes of the EU‚Äôs General
Data Protection Regulation (GDPR), taking an important step in a more
ethical, democratic and citizens-first direction.  All of these efforts are
helping to open up possibilities for mobile users. And thanks to the
Mobifree partnership, funded by an EU Horizon Europe grant, F-Droid can
share open-source, privacy-driven solutions with a larger audience.</p>

<p>In fact Europe is already seeing significant changes as a result of the
Digital Markets Act (DMA). Google has shut out other app stores by ensuring
that they have a third-class user experience. The DMA means that Google is
now legally forbidden from giving preference to their own app store over
alternatives like F-Droid.  Additionally, Apple has opened up to external
app stores for the first time ever.  And while these are great first steps
in the right direction, regulations and litigation do not build
software. With this in mind, Mobifree is poised to take action on the new
opportunities in the market, to build an unprecedented mobile experience for
users and developers. One that centers around ethical practices, digital
sovereignty, fairness, sustainability and inclusiveness.</p>

<p>F-Droid will play a major role in this project, tasked with creating a
decentralized distribution system for developers to deliver apps to Android
users. The impact will be an opening of the app market for Android,
improving honest competition around app development. And a foundational
guiding principle is to provide privacy controls to users, without locking
anyone out from participating. The app distribution system will focus on a
3-party interaction between app developers, app stores and app users where
every party will have freedom of choice at all points of interaction. The
system will have no terms of service or even user accounts to sign up
for. Developers can publish their own apps, via their own repositories. Any
app store can use those repositories to provide users with a method to
install those apps. And if the app is open source, it can be included in the
main F-Droid.org repository, where it will be reviewed using F-Droid‚Äôs
proven ethical review process. Users will be given true choice in terms of
their apps and app store preferences, additional privacy guardrails and
increased transparency into what is happening with their data.</p>

<p>F-Droid is one participating organization who has joined forces to help
create this new mobile ecosystem. However, additional input, expertise,
inspiration and work will be needed in order to break the traditional
framework established by Big Tech. From community outreach to legal support,
from developers, to researchers and end users, we welcome all forms of
support. If you are a curious citizen interested in taking part in the
Mobifree movement, we encourage you to reach out to us at f-droid.org and
see how you can take part in this exciting mobile alternative.</p>

<p>(<em>We will be tracking work under this
<a href="https://cordis.europa.eu/project/id/101135795">grant</a> using the
<a href="https://gitlab.com/groups/fdroid/-/issues/?sort=updated_desc&amp;state=all&amp;label_name%5B%5D=Mobifree">Mobifree</a>
label.</em>)</p>

  </div>

</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a free app to calibrate your turntable by simply playing a song (345 pts)]]></title>
            <link>https://grooved.okat.best/</link>
            <guid>40501021</guid>
            <pubDate>Tue, 28 May 2024 14:23:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grooved.okat.best/">https://grooved.okat.best/</a>, See on <a href="https://news.ycombinator.com/item?id=40501021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <header>
        
        <img src="data:image/svg+xml,%3c?xml%20version='1.0'%20encoding='utf-8'?%3e%3c!--%20Generator:%20Adobe%20Illustrator%2028.3.0,%20SVG%20Export%20Plug-In%20.%20SVG%20Version:%206.00%20Build%200)%20--%3e%3csvg%20version='1.1'%20id='Layer_1'%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20x='0px'%20y='0px'%20viewBox='0%200%2024.41%2012.21'%20style='enable-background:new%200%200%2024.41%2012.21;'%20xml:space='preserve'%3e%3cstyle%20type='text/css'%3e%20.st0{fill:%23FFFFFF;}%20%3c/style%3e%3cg%3e%3cpath%20class='st0'%20d='M24.41,0l-2.34,1.31c-4.39,2.46-7.85,6.29-9.87,10.9l0,0l0,0C10.19,7.6,6.73,3.77,2.34,1.31L0,0H24.41z'/%3e%3c/g%3e%3c/svg%3e" id="down">
      </header>
      <h2 id="tables">How the turntables.</h2>

      <div id="rant">
        <p>
          <strong>Do you ever think that copywriting has become too self-aware for
            its own good?
          </strong>
          It's like we collectively decided to drop the corporate facade of
          prestige in favor of the <em>"wink wink we're fun too!"</em> brand of
          language. From websites to ads to the back of shipping trucks, it
          feels like every company's identity has become a collection of short
          statements vaguely related to their industry, in pun form, devoid of
          any actual attempt at humor. It's akin to a child trying to formulate
          a joke: clearly understanding the structure and the components of
          comedy, yet missing what makes it funny. I'm not saying this is
          necessarily a good or a bad thing, it's just something that I have
          noticed. It makes sense to do something like that
          <a href="https://www.youtube.com/watch?v=Xx5YqFKjTCY" target="_blank">if you're writing posters for a animated movie</a>, but when it comes to companies valued higher than the GDP of some
          countries it loses all relatability. Let's be real, if this charade of
          a website was an actual startup, we'd probably wear t-shirts that say
          <em>"This isn't a revolution. It's 33<span id="third">‚Öì</span>
            of them."</em>
          while we'd get articles written about our fun company culture, the Bob
          Dylan quotes graffiti'd on the wall, the meeting rooms named after
          each of the Jackson 5, and the pink neon in the entrance that says
          <em>"Like a record, Baby."</em>. Oh, and while I'm at it what is it
          with the period after each of those taglines? Normally I am not one to
          complain about proper punctuation but at this point it seems more like
          a thinly veiled attempt at recapturing some of that seriousness
          combined with an unwillingness to commit to the bit. Because they
          really want you to know that to them, it's not a joke. it's a
          statement.
        </p>

        <p id="oh">
          On a slightly unrelated note, I made an app that helps you
          <span id="highlight">calibrate your turntable.</span>
        </p>
      </div>

      <h2 id="mj">As easy as 1-2-3.</h2>

      <p>
        Do you remember the early days of the iPhone, where every once in a
        while a new app would come out and it would do just one completely new
        thing, and nothing else? There was so much excitement around finding new
        use cases and it was all
        <em>"Oh yeah this is the app I use to pretend I'm shaving my face. And
          this is app I use to see where the ISS is"</em>. I can't remember the last time I genuinely got excited about some
        unitasker app like that and I think that's too bad. That's why Grooved
        tells you your turntable's speed <strong>in just one tap.</strong>
      </p>

      <!-- <h2>Not quite my tempo.</h2> -->

      <div id="steps">
        <div id="play">
          <p><img src="data:image/svg+xml,%3c?xml%20version='1.0'%20encoding='utf-8'?%3e%3c!--%20Generator:%20Adobe%20Illustrator%2028.3.0,%20SVG%20Export%20Plug-In%20.%20SVG%20Version:%206.00%20Build%200)%20--%3e%3csvg%20version='1.1'%20id='Layer_1'%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20x='0px'%20y='0px'%20viewBox='0%200%2080%2080'%20style='enable-background:new%200%200%2080%2080;'%20xml:space='preserve'%3e%3cstyle%20type='text/css'%3e%20.st0{fill:none;stroke:%23FFFFFF;stroke-miterlimit:10;}%20%3c/style%3e%3cpath%20class='st0'%20d='M70.11,34.54L27,9.64c-4.21-2.43-9.46,0.61-9.46,5.46v49.78c0,4.86,5.26,7.89,9.46,5.46l43.11-24.89%20C74.32,43.04,74.32,36.96,70.11,34.54z'/%3e%3c/svg%3e">
          </p>
          <h4>1.</h4>
          <h3>Play</h3>
          <p>Pick a good song, and play it loud.</p>
        </div>
        <div id="analysis">
          <p><img src="data:image/svg+xml,%3c?xml%20version='1.0'%20encoding='utf-8'?%3e%3c!--%20Generator:%20Adobe%20Illustrator%2028.3.0,%20SVG%20Export%20Plug-In%20.%20SVG%20Version:%206.00%20Build%200)%20--%3e%3csvg%20version='1.1'%20id='Layer_1'%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20x='0px'%20y='0px'%20viewBox='0%200%2080%2080'%20style='enable-background:new%200%200%2080%2080;'%20xml:space='preserve'%3e%3cstyle%20type='text/css'%3e%20.st0{fill:none;stroke:%23FFFFFF;stroke-miterlimit:10;}%20%3c/style%3e%3cg%20id='Regular-S'%20transform='matrix(1%200%200%201%201403.59%20696)'%3e%3cpath%20class='st0'%20d='M-1374.89-618.3c3.6,1.1,7.4,1.7,11.3,1.7c21.5,0,39.5-17.9,39.5-39.4c0-3.9-0.6-7.6-1.7-11.1l-20.6,7.3%20c0.3,1.2,0.4,2.5,0.4,3.8c0,9.8-7.9,17.6-17.6,17.6c-1.4,0-2.7-0.1-4.1-0.4L-1374.89-618.3z%20M-1327.09-670.4%20c-1.1-2.8-2.5-5.4-4.2-7.9l-17.3,13.4c0.4,0.6,0.7,1.2,0.9,1.8L-1327.09-670.4z%20M-1333.49-681.1c-4.1-4.9-9.3-8.8-15.2-11.3%20l-7.3,20.7c2,0.9,3.8,2.3,5.3,3.9L-1333.49-681.1z%20M-1352.09-693.6c-3.7-1.2-7.6-1.8-11.6-1.8c-21.5,0-39.4,17.9-39.4,39.4%20c0,4.1,0.6,8.1,1.9,11.8l20.6-7.3c-0.4-1.4-0.6-2.9-0.6-4.4c0-9.6,8-17.4,17.6-17.4c1.4,0,2.8,0.1,4.2,0.5L-1352.09-693.6z%20M-1399.89-640.9c1.1,2.7,2.6,5.3,4.3,7.7l17.2-13.3c-0.3-0.5-0.6-1.1-0.9-1.7L-1399.89-640.9z%20M-1393.39-630.4%20c4.1,4.7,9.3,8.5,15.1,10.9l7.2-20.5c-1.9-0.9-3.7-2.1-5.1-3.7L-1393.39-630.4z%20M-1363.59-642.6c7.3,0,13.2-6,13.2-13.3%20c0-7.2-6-13.1-13.2-13.1s-13.3,5.9-13.3,13C-1376.89-648.5-1370.89-642.6-1363.59-642.6z%20M-1365.99-655.9c0-1.3,1.1-2.4,2.4-2.4%20s2.4,1.1,2.4,2.4c0,1.3-1.1,2.4-2.4,2.4S-1365.99-654.6-1365.99-655.9z'/%3e%3c/g%3e%3c/svg%3e">
          </p>
          <h4>2.</h4>
          <h3>Analyze</h3>
          <p>Fire up <strong>Grooved</strong> and start the analysis.</p>
        </div>
        <div id="tweak">
          <p><img src="https://grooved.okat.best/assets/tweak-DEG7p12_.svg">
          </p>
          <h4>3.</h4>
          <h3>Tweak</h3>
          <p>Adjust your turntable. Reapply as needed.</p>
        </div>
      </div>

      <a id="privacy"><h2 id="hush">This is off the record, player.</h2></a>

      <p>
        Grooved does not collect any data, whatsoever. The audio stream is
        processed locally on your device and never recorded. I have no idea how
        you use the app, and to be honest I'm not sure what good knowing how
        well your record player runs would be for me anyways.
      </p>

      <p>
        Grooved does not use any third party library or API, just the built-in
        components provided by Apple.
      </p>

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An air quality model that is evolving with the times (124 pts)]]></title>
            <link>https://eos.org/science-updates/an-air-quality-model-that-is-evolving-with-the-times</link>
            <guid>40501015</guid>
            <pubDate>Tue, 28 May 2024 14:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eos.org/science-updates/an-air-quality-model-that-is-evolving-with-the-times">https://eos.org/science-updates/an-air-quality-model-that-is-evolving-with-the-times</a>, See on <a href="https://news.ycombinator.com/item?id=40501015">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-223570">
	<div>

		
		
<p>The quality of the air we breathe is among the biggest factors influencing human health and well-being worldwide. Air pollution‚Äîfrom fossil fuel combustion in the power, industrial, residential, and transportation sectors as well as from wildfires, agricultural practices, and many other sources‚Äî<a href="https://eos.org/articles/the-complex-relationship-between-hurricanes-air-pollution-and-climate" target="_blank" rel="noreferrer noopener">interacts with the climate</a>, <a href="https://eos.org/articles/wildfire-particulates-raise-cardiopulmonary-health-concerns" target="_blank" rel="noreferrer noopener">exacerbates</a> <a href="https://eos.org/articles/stroke-deaths-rise-life-expectancy-falls-with-polluted-air" target="_blank" rel="noreferrer noopener">countless</a> <a href="https://eos.org/articles/air-pollution-linked-to-adverse-mental-health-effects" target="_blank" rel="noreferrer noopener">medical</a> <a href="https://eos.org/research-spotlights/establishing-a-link-between-air-pollution-and-dementia" target="_blank" rel="noreferrer noopener">conditions</a>, and is estimated to cause <a href="https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health" target="_blank" rel="noreferrer noopener">millions of deaths annually</a>.</p>

<figure><blockquote><p>Safeguarding public health and combating climate change depend on robust impact assessments and eÔ¨Äective policymaking with respect to air quality.</p></blockquote></figure>

<p>Safeguarding public health and combating climate change depend on robust impact assessments and eÔ¨Äective policymaking with respect to air quality, which in turn require an accurate understanding of air composition and the processes that control how and why it changes.</p>

<p>For decades, scientists have applied multiscale modeling approaches informed by observations to help advance the understanding and predictability of air quality and its interactions with the climate. Such investigations are becoming more in-depth, more capable of revealing details of the processes at play, and more accessible to broader communities.</p>

<p>Key to the continued success of such approaches is that the models used keep up with advances in scientific knowledge, modeling techniques, and the capabilities of Earth-observing systems and that the valuable features of the models are well recognized by the scientists and decisionmakers who interpret their results.</p>

<p>Here we look back on the history of one such influential model, the pioneering Sulfur Transport and Deposition Model (STEM), and we look forward to how it can keep revealing more about air quality, climate, and other societally important issues.</p>

<h3><strong>Sulfur Model Shows the Way</strong></h3>

<figure><blockquote><p>Development of the Sulfur Transport and Deposition Model (STEM) started in 1976. At the time, fossil fuel consumption was setting records, and effective technologies for scrubbing sulfur species from emissions were not widely implemented.</p></blockquote></figure>

<p>Development of STEM started in 1976, much earlier than many other contemporary air quality and atmospheric chemistry models. At the time, fossil fuel consumption was setting records, and effective technologies for scrubbing sulfur species from emissions were not widely implemented. The resulting atmospheric <a href="https://eos.org/research-spotlights/effects-of-acid-rain-climate-change-on-freshwater-lakes" target="_blank" rel="noreferrer noopener">sulfur pollution and acid rain</a> caused increasingly negative impacts on humans, infrastructure, and ecosystems. These impacts also raised awareness that air pollution was not just a local problem: Emissions from one place could affect other places hundreds and even thousands of kilometers downwind. STEM was initially designed to help understand the transport, transformation, and removal processes of atmospheric sulfur and to inform emissions reduction strategies [<a href="https://doi.org/10.1016/0004-6981(84)90070-2" target="_blank" rel="noreferrer noopener"><em>Carmichael and Peters</em></a>, 1984].</p>


<p>Since its creation, STEM has evolved to cover a broader set of key air pollutants, such as ozone and particulate matter, which also cause regional and even intercontinental problems [<a href="https://doi.org/10.1016/0960-1686(91)90085-L" target="_blank" rel="noreferrer noopener"><em>Carmichael et al.</em></a>, 1991; <a href="https://doi.org/10.5194/acp-17-5721-2017" target="_blank" rel="noreferrer noopener"><em>Huang et al.</em></a>, 2017]. Coupled with widely used meteorological models, including multiple versions of the <a href="https://www.mmm.ucar.edu/models/wrf" target="_blank" rel="noreferrer noopener">Weather Research and Forecasting</a> and <a href="https://www2.mmm.ucar.edu/mm5/" target="_blank" rel="noreferrer noopener">MM5</a> models, STEM has been adopted to study air quality in the United States and regions in the Arctic, Asia, and South America, contributing to hundreds of peer-reviewed publications. These studies have highlighted the usefulness of such models for addressing a wide range of scientific questions related to the atmospheric distributions of chemicals, quantification of these chemicals‚Äô environmental impacts, and evaluation of environmental mitigation strategies.</p>

<p>By answering these science questions, STEM also has demonstrated the capability of models to support the design and deployment of airborne and ground-based Ô¨Åeld experiments, many of which have been <a href="https://doi.org/10.1029/2002JD003117" target="_blank" rel="noreferrer noopener">led by NASA</a> or other agencies. For example, during the 2001 NASA Transport and Chemical Evolution over the Pacific (<a href="https://www-air.larc.nasa.gov/missions/tracep/tracep.htm" target="_blank" rel="noreferrer noopener">TRACE-P</a>) experiment, based out of Hong Kong, STEM forecasts of pollution outflow regions over the Pacific Ocean were used daily to help plan locations for aircraft sampling of air pollutants (Figure 1). Applying STEM in the field by design also enabled its use in interpreting and providing context for collected observations, which in turn helped improve the model [<a href="https://doi.org/10.1029/2002JD003117" target="_blank" rel="noreferrer noopener"><em>Carmichael et al.</em></a>, 2003]. The use of air quality models in such forecast applications has since expanded dramatically, and today these models are used operationally at urban, national, and global scales.</p>

<figure><img decoding="async" width="780" height="298" src="https://i0.wp.com/eos.org/wp-content/uploads/2024/05/sulfur-atmosphere-modeling-trace-mission.png?resize=780%2C298&amp;ssl=1" alt="STEM-simulated and NASA P-3B aircraft observed sulfur dioxide (SO2) during a selected TRACE-P flight in March 2001" srcset="https://i0.wp.com/eos.org/wp-content/uploads/2024/05/sulfur-atmosphere-modeling-trace-mission.png?resize=1024%2C391&amp;ssl=1 1024w, https://i0.wp.com/eos.org/wp-content/uploads/2024/05/sulfur-atmosphere-modeling-trace-mission.png?resize=480%2C183&amp;ssl=1 480w, https://i0.wp.com/eos.org/wp-content/uploads/2024/05/sulfur-atmosphere-modeling-trace-mission.png?resize=768%2C293&amp;ssl=1 768w, https://i0.wp.com/eos.org/wp-content/uploads/2024/05/sulfur-atmosphere-modeling-trace-mission.png?resize=400%2C153&amp;ssl=1 400w, https://i0.wp.com/eos.org/wp-content/uploads/2024/05/sulfur-atmosphere-modeling-trace-mission.png?w=1200&amp;ssl=1 1200w, https://i0.wp.com/eos.org/wp-content/uploads/2024/05/sulfur-atmosphere-modeling-trace-mission-1024x391.png?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px" data-recalc-dims="1"><figcaption>Fig. 1. At left, the flight path of a NASA P-3B aircraft on 18 March 2001 during the Transport and Chemical Evolution over the Pacific (TRACE-P) mission is overlain atop sulfur dioxide (SO<sub>2</sub>) concentrations (in parts per billion by volume, ppbv) modeled by the Sulfur Transport and Deposition Model (STEM) in the vicinity of China, Japan, and the Korean Peninsula. At right, modeled SO<sub>2</sub> concentrations are compared with those measured during the flight. STEM forecasts used during field campaigns such as TRACE-P helped plan locations for aircraft sampling of air pollutants and provided context for the collected observations. Credit: <em><a href="https://doi.org/10.1029/2002JD003117" target="_blank" rel="noreferrer noopener">Carmichael et al.</a></em> [2003]</figcaption></figure>

<p>STEM has further served scientific communities by advancing satellite missions, such as <a href="https://aura.gsfc.nasa.gov/" target="_blank" rel="noreferrer noopener">Aura</a>. It has supported <a href="https://climate.nasa.gov/news/2346/background-ozone-a-major-issue-in-us-west/" target="_blank" rel="noreferrer noopener">novel applications</a> of the main data products from Aura‚Äôs onboard sensors [e.g., <a href="https://doi.org/10.1002/2014JD022993" target="_blank" rel="noreferrer noopener"><em>Huang et al.</em></a>, 2015], for example, and stimulated development and evaluation of <a href="https://asdc.larc.nasa.gov/project/TES/TL2OCSN_8" target="_blank" rel="noreferrer noopener">new retrieval products</a>. And it has contributed to international multimodel intercomparison experiments, including the <a href="https://www.acap.asia/en/research-main/mics-asia/" target="_blank" rel="noreferrer noopener">Model Inter-Comparison Study for Asia</a> [<a href="https://doi.org/10.1016/S1352-2310(01)00448-4" target="_blank" rel="noreferrer noopener"><em>Carmichael et al.</em></a>, 2002] and the <a href="https://doi.org/10.5194/acp-17-5721-2017" target="_blank" rel="noreferrer noopener">Task Force on Hemispheric Transport of Air Pollution</a> [<a href="https://doi.org/10.5194/acp-17-5721-2017" target="_blank" rel="noreferrer noopener"><em>Huang et al.</em></a>, 2017]. These experiments helped provide more robust estimates of air pollution source-receptor relationships and environmental impacts, and they helped scientists better understand the strengths and weaknesses of the various models compared.</p>

<h3><strong>Simplicity, Stability, and Flexibility</strong></h3>

<figure><blockquote><p>The long history and wide applications of STEM have helped shape its main technical strengths.</p></blockquote></figure>

<p>The long history and wide applications of STEM have helped shape its main technical strengths. These strengths include its structural simplicity, which allows users to make changes to it easily, and its stability, which is built upon decades of tuning with field and laboratory measurements and other information from past applications. In addition, it features Ô¨Çexible tools to generate chemical boundary conditions and other key inputs as well as advanced data assimilation capability. Of particular note is the development of the <a href="https://people.cs.vt.edu/~asandu/Software/Kpp/" target="_blank" rel="noreferrer noopener">Kinetic PreProcessor</a> software, which allowed for easily changing the chemical mechanisms used in STEM (and other models) and improved its ability to assimilate observational data [<a href="https://doi.org/10.1016/j.jcp.2004.10.011" target="_blank" rel="noreferrer noopener"><em>Sandu et al.</em></a>, 2005].</p>

<p>These features have enabled researchers using the model to make notable policy-relevant scientific contributions in both the air quality and climate communities and to train dozens of students and early-career scientists globally. Such contributions include using real-world observations to derive surface-atmosphere Ô¨Çuxes of short- and long-lived climate forcers and their precursors‚Äîsuch as nitrogen oxides, carbon dioxide (CO<sub>2</sub>), carbonyl sulfide (COS), and toxic airborne materials including mercury compounds‚Äîand to understand the factors controlling them [e.g., <a href="https://doi.org/10.1126/science.1164015" target="_blank" rel="noreferrer noopener"><em>Campbell et al.</em></a>, 2008].</p>

<p>STEM also has helped in attributing the effects of aerosols on air quality and climate to emissions from different source sectors (e.g., energy production, industrial processes, transportation, residential sources, and wildfires) and in identifying sources of air pollution as atmospheric circulation and emissions patterns shift under the changing climate [e.g., <a href="https://doi.org/10.1038/ngeo156" target="_blank" rel="noreferrer noopener"><em>Ramanathan and Carmichael</em></a>, 2008; <em>Huang et al.</em>, <a href="https://doi.org/10.1016/j.atmosenv.2012.01.021" target="_blank" rel="noreferrer noopener">2012</a>, <a href="https://doi.org/10.1002/2014JD022993" target="_blank" rel="noreferrer noopener">2015</a>, <a href="https://doi.org/10.5194/acp-17-5721-2017" target="_blank" rel="noreferrer noopener">2017</a>].</p>

<p>These studies based on the STEM model have inspired subsequent research and discussions about new applications. For example, they stimulated discussions on using COS as <a href="https://eos.org/features/assessing-a-new-clue-to-how-much-carbon-plants-take-up" target="_blank" rel="noreferrer noopener">a proxy for gross primary productivity</a> because of the link between plants‚Äô uptake of COS and CO<sub>2</sub>, which further led to developing and applying satellite-based data products to track COS.</p>

<p>Meanwhile, researchers are continuing to develop methods to reduce uncertainties in estimating how aerosol and greenhouse gas emissions from different regions and source sectors affect health and climate. In part, these efforts involve integrating Earth observations across multiple disciplines to improve process-level constraints used in making these estimates. Observation-driven analyses are also being advanced to improve estimates of background air pollution levels, information that is relevant for updating air quality standards as the climate changes.</p>

<h3><strong>Keeping Current to Stay Relevant</strong></h3>

<figure><blockquote><p>As productive as STEM has been through its history, updating it is necessary to ensure that it remains a robust option for air quality and climate scientists to study our environment and to inform policymaking.</p></blockquote></figure>

<p>Maintaining and enhancing the diversity of models available for air quality science and management are important because significant uncertainties remain in the predictions (and their implications) from individual models. In addition, as productive as STEM has been through its history, updating it (and similar models) is necessary to ensure that it remains a robust option for air quality and climate scientists to study our environment and to inform policymaking and the design of atmospheric observing systems.</p>

<p>Major updates to STEM are ongoing to improve how the model interfaces with up-to-date and next-generation meteorological and land surface modeling systems. These systems include, for example, the <a href="https://www.mmm.ucar.edu/models/mpas" target="_blank" rel="noreferrer noopener">Model for Prediction Across Scales</a>, which can be run at variable resolutions, and the <a href="https://ral.ucar.edu/model/noah-multiparameterization-land-surface-model-noah-mp-lsm" target="_blank" rel="noreferrer noopener">Noah-Multiparameterization land surface model</a>, which can simulate vegetation dynamics under many configurations. Such updates can facilitate improved representations of processes like atmospheric deposition. STEM also will be more closely integrated with regional and global climate models, and it will be applied at progressively finer, satellite-resolved scales of several kilometers or less.</p>

<p>We continue to collect community input on goals and updates for STEM, and suggestions are always welcome. Ideally, STEM (and other chemical transport models) should be adapted to perform on new generations of high-performance supercomputing systems, perhaps in combination with <a href="https://nap.nationalacademies.org/read/24938/chapter/7#177" target="_blank" rel="noreferrer noopener">commercial cloud computing</a>, artificial intelligence and machine learning, and other technologies.</p>

<p>Additional updates could include capabilities to provide detailed documentation of model elements, features, and steps to execute it, as well as polished postprocessing and visualization routines to help improve the interpretability and communication of model results. Further, models could be updated to support crowdsourced science projects, by integrating data from or feeding data to them, and the design and application of low-cost spaceborne and surface observing systems. User communities should be able to access and contribute easily to synthesized and modernized models and their associated documentation from centralized, open-access platforms.</p>

<p>These updates would allow models like STEM to be implemented over wider spatial and time scales than previously possible and to support studies of emerging topics, such as those <a href="https://eos.org/articles/some-communities-feel-the-effects-of-air-pollution-more-than-others" target="_blank" rel="noreferrer noopener">related to environmental justice</a>. Simulations of regional to local air quality as well as of its contributing factors, combined with socioeconomic data, could clarify the picture of <a href="https://eos.org/articles/indias-disadvantaged-groups-face-more-air-pollution" target="_blank" rel="noreferrer noopener">environmental inequity</a> across an area of interest and help evaluate potential solutions involving migration, relocation, or <a href="https://eos.org/science-updates/converging-on-solutions-to-plan-sustainable-cities" target="_blank" rel="noreferrer noopener">urban</a> or <a href="https://www.unep.org/news-and-stories/video/what-ecosystem-based-adaptation" target="_blank" rel="noreferrer noopener">ecosystem</a> adaptations.</p>

<p>For decades, the STEM model has proven its value by contributing insights into air quality, climate, and the environment to help shape scientific understanding, science-based policymaking, and software design. With the ongoing and envisioned updates, the model‚Äôs usefulness for these purposes will continue for many years to come, and its relevance for new applications will grow.</p>

<h3><strong>Acknowledgments</strong></h3>

<p>The authors acknowledge the following people (in alphabetical order) who also have contributed to the developments and applications of the STEM model: Maryam Abdi-Oskouei, Bhupesh Adhikary, Richard Arndt, Giuseppe Calori, Elliott Campbell, Tianfeng Chai, Young-Soo Chang, Yafang Cheng, Seog-Yeon Cho, Shin-Woo Chul, Kevin Crist, Dacian Daescu, Alessio D‚ÄôAllura, Valeriu Damian, Meng Gao, Sarath Guttikunda, Amir Hakami, Hiroshi Hayami, Shan He, Daven Henze, Min-Sun Hong, Aditsuda Jamroensan, Kuruvilla John, Toshihiro Kitada, Rao Kotamarthi, Sarika Kulkarni, Gakuji Kurata, Pallavi Marrapu, Marcelo Mena, Li Pan, Leonard Peters, Mahesh Phadnis, Florian Potra, Pablo Saide, Adrian Sandu, John Seinfeld, Shang-Gyoo Shim, Negin Sobhani, Chul Han Song, Scott Spak, David Streets, Young Sunwoo, Youhua Tang, Narisara Thongboonchoo, Itsushi Uno, Xuemei Wang, Zifa Wang, Chao Wei, Jung-Hun Woo, Hui Xiao, Yiwen Xu, and Yang Zhang.</p>

<h3><strong>References</strong></h3>

<p>Campbell, J. E., et al. (2008), Photosynthetic control of atmospheric carbonyl sulfide during the growing season, <em>Science</em>, <em>332</em>(5904), 1,085‚Äì1,088, <a href="https://doi.org/10.1126/science.1164015" target="_blank" rel="noreferrer noopener">https://doi.org/10.1126/science.1164015</a>.</p>

<p>Carmichael, G. R., and L. K. Peters (1984), An Eulerian transport/transformation/removal model for SO<sub>2</sub> and sulfate‚ÄîI. Model development, <em>Atmos. Environ.</em>, <em>18</em>(5), 937‚Äì951, <a href="https://doi.org/10.1016/0004-6981(84)90070-2" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/0004-6981(84)90070-2</a>.</p>

<p>Carmichael, G. R., et al. (1991), The STEM-II regional scale acid deposition and photochemical oxidant model‚ÄîI. An overview of model development and applications, <em>Atmos. Environ.</em>, <em>25</em>(10), 2,077‚Äì2,090, <a href="https://doi.org/10.1016/0960-1686(91)90085-L" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/0960-1686(91)90085-L</a>.</p>

<p>Carmichael, G. R., et al. (2002), The MICS-Asia study: Model intercomparison of long-range transport and sulfur deposition in East Asia, <em>Atmos. Environ.</em>, <em>36</em>(2), 175‚Äì199, <a href="https://doi.org/10.1016/S1352-2310(01)00448-4" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/S1352-2310(01)00448-4</a>.</p>

<p>Carmichael, G. R., et al. (2003), Regional-scale chemical transport modeling in support of the analysis of observations obtained during the TRACE-P experiment, <em>J. Geophys. Res.</em>, <em>108</em>(D21), 8823, <a href="https://doi.org/10.1029/2002JD003117" target="_blank" rel="noreferrer noopener">https://doi.org/10.1029/2002JD003117</a>.</p>

<p>Huang, M., et al. (2012), Sectoral and geographical contributions to summertime continental United States (CONUS) black carbon spatial distributions, <em>Atmos. Environ.</em>, <em>51</em>, 165‚Äì174, <a href="https://doi.org/10.1016/j.atmosenv.2012.01.021" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/j.atmosenv.2012.01.021</a>.</p>

<p>Huang, M., et al. (2015), Improved western U.S. background ozone estimates via constraining nonlocal and local source contributions using Aura TES and OMI observations, <em>J. Geophys. Res. Atmos.</em>, <em>120</em>(8), 3,572‚Äì3,592, <a href="https://doi.org/10.1002/2014JD022993" target="_blank" rel="noreferrer noopener">https://doi.org/10.1002/2014JD022993</a>.</p>

<p>Huang, M., et al. (2017), Impact of intercontinental pollution transport on North American ozone air pollution: An HTAP phase 2 multi-model study, <em>Atmos. Chem. Phys.</em>, <em>17</em>(9), 5,721‚Äì5,750, <a href="https://doi.org/10.5194/acp-17-5721-2017" target="_blank" rel="noreferrer noopener">https://doi.org/10.5194/acp-17-5721-2017</a>.</p>

<p>Ramanathan, V., and G. Carmichael (2008), Global and regional climate changes due to black carbon, <em>Nat. Geosci.</em>, <em>1</em>, 221‚Äì227, <a href="https://doi.org/10.1038/ngeo156" target="_blank" rel="noreferrer noopener">https://doi.org/10.1038/ngeo156</a>.</p>

<p>Sandu, A., et al. (2005), Adjoint sensitivity analysis of regional air quality models, <em>J. Comput. Phys.</em>, <em>204</em>(1), 222‚Äì252, <a href="https://doi.org/10.1016/j.jcp.2004.10.011" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/j.jcp.2004.10.011</a>.</p>

<h3>Author Information</h3>

<p>Min Huang (<a href="mailto:mhuang8585@gmail.com" target="_blank" rel="noreferrer noopener">mhuang8585@gmail.com</a>), University of Maryland, College Park; also at NASA Ames Research Center, Mountain View, Calif.; Gregory Carmichael, University of Iowa, Iowa City; and Kevin Bowman, Jet Propulsion Laboratory, California Institute of Technology, Pasadena</p>

<h5><strong>Citation:</strong>&nbsp;Huang, M., G. Carmichael, and K. Bowman (2024), An air quality model that is evolving with the times,&nbsp;<em>Eos, 105, </em><a href="https://doi.org/10.1029/2024EO240228" target="_blank" rel="noreferrer noopener">https://doi.org/10.1029/2024EO240228</a>. Published on 28 May 2024.</h5>

<h6><strong>Text ¬© 2024. AGU.&nbsp;<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/" target="_blank" rel="noreferrer noopener">CC BY-NC-ND 3.0</a></strong><br><strong>Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited.</strong></h6>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What would you spend your time working on if you didn't need money? (108 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40500429</link>
            <guid>40500429</guid>
            <pubDate>Tue, 28 May 2024 13:13:22 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40500429">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="40500429">
      <td><span></span></td>      <td><center><a id="up_40500429" href="https://news.ycombinator.com/vote?id=40500429&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=40500429">Ask HN: What would you spend your time working on if you didn't need money?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_40500429">103 points</span> by <a href="https://news.ycombinator.com/user?id=gooob">gooob</a> <span title="2024-05-28T13:13:22"><a href="https://news.ycombinator.com/item?id=40500429">13 hours ago</a></span> <span id="unv_40500429"></span> | <a href="https://news.ycombinator.com/hide?id=40500429&amp;goto=item%3Fid%3D40500429">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20What%20would%20you%20spend%20your%20time%20working%20on%20if%20you%20didn%27t%20need%20money%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=40500429&amp;auth=d536dc8a5ff2a5224e240d3429fecc7765be50d8">favorite</a> | <a href="https://news.ycombinator.com/item?id=40500429">174&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><p>basically what would your ideal job be, in an ideal world? would you contribute towards making society more rational, healthy, and well-coordinated? or do you have better ideas? sorry if this is a silly question just a random thought.</p></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table><table>
            <tbody><tr id="40502914"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40502914" href="https://news.ycombinator.com/vote?id=40502914&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I would devote my time to building high quality, durable, and energy efficient 3bd 2ba homes in the rural areas surrounding major metropolitan areas, which I would then sell at material cost.</p><p>Buying my first home (mobile/manufactured) has been a combination of the best and worst thing I've ever done. The house cost nearly 3 times what my grandparents paid about ~30 years ago in the same neighborhood (on the same street!) while the construction and finish quality are sub-par at best, with a nearly endless list of things that are constantly in need of repair, multiple water intrusion issues, etc. To make matters worse, the housing market in the area I live has reached unreasonable levels, with my current home being 'valued' at 1.4x what I bought it for roughly 3 years ago.</p><p>Additionally, I keep seeing homes built that are on monolithic slabs and nearly everyone I know personally who is a homeowner is having issues with their home's foundation due to the high movement soil (clay) even in recently built homes. I would build homes that use pier and beam foundations with piles deep enough to resist soil movement, ensure site drainage was appropriate for each home, and generally put all the necessary care and work into ensuring that each home built would last for multiple generations.</p><p>I want to build homes that last and allow others to flourish without the litany of concerns I currently have to struggle with on-top of my day job.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505932"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40505932" href="https://news.ycombinator.com/vote?id=40505932&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Good answer! It's a massive societal failure that so few people are able to own a good house these days. It's 2024, we can build microchips virtually atom-by-atom, we can have plain English conversations with our computers about almost any topic, the number of billionaires has grown 20-fold since the 1980's, but the basic human need for shelter is a problem that is getting <i>less</i> solved by the day. It's perverse.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504642"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40504642" href="https://news.ycombinator.com/vote?id=40504642&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I've gotten into a habit of watching homebuilders on YouTube/reading about construction methods (especially with ICF forms), and it's been quite fun. Lots of advancements happening these days.</p><p>As for foundation issues, I live in a Gulf Coast state 2 miles from the Gulf as the crow flies, and my crawlspace is so humid that I had to get it encapsulated. I have 2 dehumidifiers, and now that summer is here 1 of them runs 24/7. On the flip side, the deterioration has stopped, but now the joists and subloor are drying and warping (I was warned this would happen, though).</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40504937"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40504937" href="https://news.ycombinator.com/vote?id=40504937&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>This probably edges into the industrial-control level of automation, but have you thought about hooking up your dehumidifiers to humidity sensors to maintain humidity at a specific level rather than an all-or-nothing approach?</p><p>It's my understanding that wood rot occurs mainly due to frequent changes in moisture, the expansion and contraction causing breakdown of the wood fibers, while warping occurs when wood transitions between 'wet' and 'dry' too slowly/quickly/unevenly.</p><p>Allowing the moisture to increase back to previous levels *may* reverse some or most of the warping that has occurred, followed with a gradual decrease in humidity with an adjustment period between changes using the aforementioned control system may allow you to find a happy medium and ease the wood into a more stable moisture content without having to deal with squeaky subfloors and uneven joists.</p><p>¬Ø\_(„ÉÑ)_/¬Ø</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507381"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40507381" href="https://news.ycombinator.com/vote?id=40507381&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>&gt;have you thought about hooking up your dehumidifiers to humidity sensors to maintain humidity at a specific level rather than an all-or-nothing approach?</p><p>They have a knob on them that sets it to a specific humidity level, which I believe is 55 or 60 percent.</p><p>&gt;Allowing the moisture to increase back to previous levels <i>may</i> reverse some or most of the warping that has occurred</p><p>Warping has already occurred on the joists due to the ridiculous levels of humidity in the crawl space, this is just more warping occurring. I'm talking like 90% or more humidity down there, and the moisture content of the joists were at 21% and mold was growing all over. At this point, I'm willing to take warping over the other path, which is having my joists rot out. Encapsulation is part 1, and part 2 will happen next year in the winter where I'll get beams and jacks installed.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40503567"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40503567" href="https://news.ycombinator.com/vote?id=40503567&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>On nicer homes builders will sometimes put cylinders of concrete down from the slab towards bedrock.  Then they pour the slab over top of them.  I assume this helps prevent the movement.  Not sure how this compares to p&amp;b in cost.  Just another option.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40503799"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40503799" href="https://news.ycombinator.com/vote?id=40503799&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Well most slab foundations will have various types of footings that transfer the majority of the load to deeper soil that can support significantly higher PSF.</p><p>The slab part of the foundation generally is meant only to transfer the load of the house onto these footings rather than support the weight itself, sort of like a desk transfers the weight of it's contents onto the legs.</p><p>While this can help resist movement, it all depends on the drainage and expansion qualities of the soil where the bottom of the footer rests. If the area sees periods of extreme drought in highly expansive soil and the drought 'reaches' the bottom of the footer then you'll end up with significant movement as the weight of the foundation and home settles down into the void created by the now dry soil, while the opposite is true during periods of extremely heavy rainfall.</p><p>When you combine periods of extreme drought and heavy rainfall in close succession of each other on highly expansive soils, pretty much any slab that is not supported by bedrock in some way will be at risk of cracking due to the frequent seasonal movement of the surrounding soil.</p><p>This can be mitigated somewhat during periods of drought by 'watering' the areas surrounding the foundation, and during periods of heavy rainfall by having a properly graded home site that routes water away from the home in every direction. Unfortunately these are mitigations that require monitoring by homeowners who may not be aware of these issues at all.</p><p>Ideally prior to building any permanent foundation a core sample would be obtained from the site and analyzed to determine the footer depth necessary to compensate for the 'worst case' rainfall and temperature fluctuation in that region, additionally accounting for local movement due to topography.</p><p>Except most folks building out in my area are just trying to make as much money with as little investment as possible, and thus do just enough to not be liable if any of the above scenarios conspire to create problems for their long-since-forgotten customers.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40503348"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503348" href="https://news.ycombinator.com/vote?id=40503348&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>This is me. Fortunate to be able to retire at 55, programming my whole life, I love my career even when particular jobs had their issues. So now I work on projects I want to work on, no commute, no 20-person meetings.</p><p>I'm currently working with a team that's recreating the Prodigy online service servers in Elixir. Having a blast, and I have my next project already in mind, also in Elixir or some other BEAM language.</p><p>On top of that I'm reading programming-adjacent books and papers, for example on Category Theory and lambda calculus. I'm going through my backlog of interesting papers I've printed off over the last 30 years.</p><p>So no, not saving the world but keeping my mind engaged and loving it.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40503565"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40503565" href="https://news.ycombinator.com/vote?id=40503565&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Thanks for sharing. I really look up to people like you as I'd like to semi-retire around 55 too (13 years from now on).</p><p>I have a question for you: How do you assess your learning ability at 55? Let me explain -- I'd like to pursue studies in some Physics topics when I semi-retire (I can't do that now due to lack of time), but I'm not sure whether my brain is up to the job then. I know you are not studying Physics, but category theory is definitely non-trivial. How do you assess your ability to grapple with difficult theories?</p><p>A side question: do you exercise routinely, and if so do you think it contributes significantly to your health?</p><p>Thanks for any insight.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40503738"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40503738" href="https://news.ycombinator.com/vote?id=40503738&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>My wife and I are 57 years old, so I think I can address this. We finally got the younger child through to grad school and paid off all our debt, and now we can devote our time to what we want to do. Mostly, anyway - I'd like to be doing coding for pay, but instead I do technical translation.</p><p>But in terms of <i>study</i> - academic work - we're free. She's got a PhD in theoretical physics and has finally had the time to start publishing, including picking up quantum chromodynamics.</p><p>I've picked up my original doctoral work, too, which was on hold for thirty years while I supported the family. I've had no problems whatsoever tackling difficult topics - in fact, I've had less difficulty. I'm calmer, partly because I have to be in order to keep my blood pressure under control. I think I can do less in any given day, but I'm not even sure about that, because when I look back at items checked off over a week or a month, it's about what I wanted to get done.</p><p>So putting off study until you're 55 is not a bad plan. Keep reading about things in the meantime, of course. Take good notes. Keep things where you can find them in ten or twenty years. Write down your daily thoughts. You'll thank yourself later, trust me on this.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40504181"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40504181" href="https://news.ycombinator.com/vote?id=40504181&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Thanks a lot. I really appreciate your sharings. I'm glad that both of you manage to work on things you are interested in.</p><p>Did your wife get the PHD recently or when she was young? Reading through the lines I feel it was when she was young but I could definitely be wrong.</p><p>I also feel I don't have much to write down every day. Most of the time is spent on work chores or family chores. There are a few happy moments but that's it. May I ask what type of information do you retain?</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504086"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40504086" href="https://news.ycombinator.com/vote?id=40504086&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>&gt; Write down your daily thoughts.</p><p>Can you elaborate on this? What sorts of daily thoughts did you write down and how did it help you?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40504659"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40504659" href="https://news.ycombinator.com/vote?id=40504659&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I keep a notebook of ideas I want to pursue later. A lot of times if you don't write them down they'll be forgotten over the years, unless they're of major importance.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40504637"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40504637" href="https://news.ycombinator.com/vote?id=40504637&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>For the most part I'm staying near my field of study, programming, programming languages, theory about programming etc. In that way, just about everything I see I can relate to something I've learned before, I'm in true "I've seen it all before" mode at my age. For example the pattern matching and recursion-based "looping" navigation is just like when I went through my Haskell/Ocaml/Common Lisp/Scheme phase in the mid 2000's, so it was easy to pick up. The only new part of it is the actor-based concurrency model.</p><p>My foray into Category Theory so far has been reading "The Joy of Abstraction", which is a layman's book to CT. So far what's she's written makes perfect sense and would be mostly obvious to anyone who hangs out on HN. Moving up and down various levels of abstraction, the idea of "functions", as I read this I'm basically thinking it's what I've been doing for the past 40 years, not a big deal. We'll see as I continue in it.</p><p>Circling back to the original question, it's hard to assess my learning ability since I'm not venturing out into totally new territory for me.</p><p>When you have a job it's hard to fit in as much exercise etc. as you want, it's easier when you're retired. But also when you're retired it's easy to fill the time with other things, errands, as you get older medical appointments, and motivation is a little harder since you don't have deadlines on your projects. Work comes in spurts interlaced with reading, which is important but doesn't move the projects forward.</p><p>I do exercise regularly, especially after the heart attack. "Make these changes or you'll die" makes a great motivator.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505050"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40505050" href="https://news.ycombinator.com/vote?id=40505050&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Thanks a lot. I do agree that staying in familiar ground requires less brain work.</p><p>I do agree with the "more time without a job" observation. That's part of the motivation to pick up serious stuffs when I go semi-retire.</p><p>I hope you get well (the heart attack thing), but I'm happy that you make those changes when still young (relatively).</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40506633"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40506633" href="https://news.ycombinator.com/vote?id=40506633&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I‚Äôll chime in on this - my wife and I were just talking about it yesterday.</p><p>I‚Äôm mid 50‚Äôs.  I had perfect 20/20 eye sight until about age 50, and now I can‚Äôt read almost anything without reading glasses - it came on quickly, but doesn‚Äôt seem to be worsening.  I‚Äôve always been a perfect speller (for the vocabulary that I use), but I‚Äôm finding I misspell 1-3% of what I type now (not typos).  I‚Äôm also starting to misread headlines which I never did before (inserting words, misreading a single critical word, etc).  It does feel like a tiny bit of haze is setting in, and I feel like this is probably normal.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40505712"><td></td></tr>
                  <tr id="40507638"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40507638" href="https://news.ycombinator.com/vote?id=40507638&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Currently working toward this at 38, but my goal is to start building a team of individuals to create a research / design firm that studies symbiotic relationships in nature in order to discover and pair natural additive processes (think spider producing webs as one of these additive process) starting with bespoke pieces such as a spider woven glove.</p><p>This would help create buzz and intrigue with the objective to attract top talent and essentially the seed money to self funded a hybrid medusa that is studying "organic 3D printers" with the objective of being the "Manhattan project" size of integrating nature into the manufacturing process.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40507291"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40507291" href="https://news.ycombinator.com/vote?id=40507291&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>&gt; basically what would your ideal job be</p><p>Easy. A nonexistent one. If you didn't need money, why would you be seeking a job?</p><p>&gt; would you contribute towards making society more rational, healthy, and well-coordinated?</p><p>How does a job contribute to 'society'? Who works to contribute to society? What company exists to 'contribute to society'?</p><p>Has 'hacker' news become so cynical to believe one's existence is about finding a job?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507385"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40507385" href="https://news.ycombinator.com/vote?id=40507385&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Oh get off it, the dude is asking what you‚Äôd work in if you had all the money in the world.</p><p>It‚Äôs not hard to understand the spirit of his question.</p><p>If your answer is none, that‚Äôs great, I think the follow up sermon was unnecessary.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507449"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40507449" href="https://news.ycombinator.com/vote?id=40507449&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>&gt; It‚Äôs not hard to understand the spirit of his question.</p><p>Agreed. That's why I answered as I did.</p><p>&gt; If your answer is none, that‚Äôs great, I think the follow up sermon was unnecessary.</p><p>You proved it was necessary. Might want to look into why you are getting so defensive. Seems like I touched a nerve.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40507642"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40507642" href="https://news.ycombinator.com/vote?id=40507642&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I would help WikiHouse (<a href="https://www.wikihouse.cc/" rel="nofollow">https://www.wikihouse.cc/</a>) project. It is a DIY-able CNC-machined plywood- or OSB-based house. I would like to make it more parametric and smart.</p><p>My pet project these days is "nothing to WikiHouse": DIY a minimally viable 3D printer, print a bigger 3D printer on it (e.g. Voron), print a CNC machine (LowRider CNC V3), and use it to cut the house sheets.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40505540"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40505540" href="https://news.ycombinator.com/vote?id=40505540&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I guess I'll find out on Friday, which is my last day. Poking around on computers has been good enough to me that I can call it quits at 60. What comes after this? First, a summer of being a bum (if I last that long). After that, more volunteering at the animal shelter, more volunteering with the local running club, and I half-jokingly say I'm going to be a professional trail runner (where I'll be paid in socks and cheap medals from my age group wins).</p><p>I'll buckle down on my mandolin playing, and it's time to pick up the fiddle and give it a good effort.</p><p>Read more.</p><p>Let's not let all that coding experience go to waste: I'll go hunt down an open source project that I could make some good contributions to, and then devote a good chunk of time to that. Or write something new that the world could use.</p><p>But beware: "if you didn't need money" is a pretty loaded phrase. As I stare down the firehose of money and realize it will soon produce only a trickle, if that, I still ask if we have enough even though we're probably better off than the majority of retirees (if various sources are to be believed). Because there's "don't <i>need</i> an income" and then there's "won the startup lottery, and my <i>kids</i> won't need an income", and we are firmly in the former category. :-)</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506623"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506623" href="https://news.ycombinator.com/vote?id=40506623&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I am quite surprized how few people are proposing to make art or music. Is this why artists/musicians can't make money, because so few people enjoy it? I always thought it was the digitization and easy access that allowed us to enjoy these things from our homes (instead of going out to clubs), but maybe not.</p><p>Anyway, for the record, I would be recording my lifetime backlog songs I've written.  And probably re-recording in different styles.  And perfecting every one, no more of this 'good-enough' demo stuff. I'd get all the needed gear and software, and have no more excuses.  I've actually already started to do this, at the detriment of my actual career...sigh.</p><p>EDIT: now that I read the OP's question more closely, I guess the answers are skewed towards practical things that would make the world better...but impractical things like creative music and abstract art also make the world better, so I'm sticking with my plan!</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507390"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40507390" href="https://news.ycombinator.com/vote?id=40507390&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>i didn't intend for the answers to be skewed a certain way. that's just what i had in mind. and i do think that music makes the world a better place anyway. but if you wanted to just go around and drink beer at various bars that'd be fine too. (btw i just came back to this post after forgetting about after posting it this morning and wow didn't expect this many responses!)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506650"><td></td></tr>
            <tr id="40506695"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40506695" href="https://news.ycombinator.com/vote?id=40506695&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>&gt; impractical things like creative music and abstract art also make the world better</p><p>If you expand your definition of practical, it becomes quite practical!</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506659"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40506659" href="https://news.ycombinator.com/vote?id=40506659&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Because doing it is hard to master, harder to execute, and way harder to be economically succesful at it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40506329"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506329" href="https://news.ycombinator.com/vote?id=40506329&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>General infrastructure that benefits humanity in a goal agnostic way, e.g., related to energy or compute seems like a meaningful thing to get behind. This could be novel technology or logistics and efficiency improvements, but these are things that can augment everyone's ability to do the things they want.</p><p>Socially, there are a lot of things that seem "silly" (euphemistically), and it's a blight on civilization that they are tolerated. That people in my country (USA, but can apply to many countries in the world) are homeless or starving is silly; if you were running a country, ensuring the citizenry have food and shelter might be an obvious top priority. The world can seem really complex at times and our systems become so convoluted that people rationalize why the things that seem obviously silly are too difficult to solve or worthwhile tradeoffs. I think it's generally a good heuristic to avoid doing things that seem obviously silly and fix the things that are (that is, it's often better to be naive about it!).</p><p>This portion of the comment is not a direct answer to the question but a related thought others may have further insights about. Practically, a situation in which you don't need money rarely materializes instantaneously; it usually arises from circumstances that have constituted a great deal of your life and identity. As a consequence of this, I think ego can become a real challenge that prevents people from pursuing possible "ideals". If you've been in a certain kind of position for a long time, there can be psychological barriers to pursuing something in a way in which, e.g., you are a true beginner or have less control. This tends to be something that can dissipate with age but can be especially difficult for people who've achieved financial success well before standard retirement age.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40506635"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40506635" href="https://news.ycombinator.com/vote?id=40506635&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I don't think the US's strategic goal is to solve homelessness. In that between maintaining world dominance and solving homelessness, homelessness is way less important. Nations choose their sacrifices based on their priorities same as individuals.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40507274"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40507274" href="https://news.ycombinator.com/vote?id=40507274&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I don‚Äôt have enough to retire on, but spent my last decade working on what I wanted.   I worked on Formal Proof, until I realized the problem wasn‚Äôt the tech but the math-proof business model.   (Academic mathematicians aren‚Äôt incentivized to write formal proofs.).  I got an Econ degree.   I‚Äôve studied housing in Austin and advocated to loosen restrictive regulation that causes high rents.  And I designed version 3 of Parchive.   (You may know the previous version by its file extension ‚Äú.par2‚Äù)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504694"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504694" href="https://news.ycombinator.com/vote?id=40504694&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>In an ideal world I would go back to chemistry.</p><p>Since the option in the world we have is working 60 hours sub minimum wage trying to get through a PhD followed by bouncing round on 2 year short term contracts as a postdoc (still barely on minimum wage) while University administrators make your life hell I took the only rational route.</p><p>I switched to software and make people's lives and the climate worse for a paycheck that still isn't enough to live where I want to live.</p><p>But ideally I'd use my brain to research some of the fundamental challenges we face, battery chemistry, plastic recycling, industrial catalysts, etc, etc.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507444"><td></td></tr>
                  <tr id="40503588"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503588" href="https://news.ycombinator.com/vote?id=40503588&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Family first, of course. I already dedicate a ton of my time to them - everything from just basic "hanging out" with my wife and kids, to all the basic maintenance of life - budgeting, housework, driving people around, scheduling appointments, and so on.</p><p>With my day job gone, I have a huge stack of side projects and hobbies that I'd love to put more time into. I think the hardest part, in a world where I've regained the time I spend on my job, would be deciding which of those things I actually want to dedicate my time to (there isn't enough time in my life for all of them, sadly).</p><p>I'd definitely spend more time on fitness, reading, and playing and listening to music. I have plenty of programming related projects I'd like to work on too. I like making videos and writing blog posts, and I'd continue doing that - probably at about the same rate that I currently do, creating a writeup or a video when I find something cool to share.</p><p>Honestly, I'd spend my time about the same way I do now - just "more so." I guess I'm fortunate to be able to say that!</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40505131"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40505131" href="https://news.ycombinator.com/vote?id=40505131&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I stopped work at 55 after 40 years in tech, from being a developer right up to CTO. I do very little coding, mainly because there are so many other things I want to do. Having this time really makes you ask yourself what it is you really want to do and for me that means running, particularly in mountains. Like another poster I also watch a ton of stuff on YouTube about DIY and I‚Äôm learning how to do stuff on my own house and doing a van conversion (to take to the mountains). I see a lot more of family than I did and I consciously try to spend more time with and in particular give my time to help others. I‚Äôm helping my daughter a lot to break into software engineering. Like another poster I have so many things I want to do and just not enough time so I‚Äôm journaling a lot and making a lot of notes about ideas I have and these are starting to lead to some ideas about software that would be useful to me and so I expect others. I‚Äôm constantly learning what I like to do and I have so many non technical projects on the go.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501813"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501813" href="https://news.ycombinator.com/vote?id=40501813&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Maybe a better question for me would be what I would stop spending time working on. I'd continue doing what I currently do, but I'd cut out some of the things that come with the job that no sane person would do other than for the pay. For instance, I would still be doing research, which I view as very important, but I'd do more research and wouldn't mess around with the peer review process. I'd be writing open source software that would help others do their research too. I'd write textbooks and give them away for free. I wouldn't be doing administrative work of any kind, and I wouldn't waste time on a lot of the stuff I do at home.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501799"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501799" href="https://news.ycombinator.com/vote?id=40501799&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I'd spend my days painting miniatures and reading.  Don't really care enough about the rest of the world, to be honest; I'd turn inward.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506670"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506670" href="https://news.ycombinator.com/vote?id=40506670&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I spent 15 amazing years as a firefighter, but the cost of living along with other factors forced me to switch gears and become a software developer. I've learned a lot, but every day I miss the fire service more than anything.</p><p>Working on legal software as an underpaid, overworked, and abused (not joking) dev has been a real drag and it's taken a toll on me mentally and physically.</p><p>I've also realized that firefighting is my true calling. So I've been trying to turn things around; Working out, finding classes to re-up my certs, and giving myself a lot of mental space.</p><p>I'd love to go back, my local station is mostly volunteer so I'd never make much money. But maybe I can use my new tech skills to create tools that help firefighters help people as a little side gig.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507634"><td></td></tr>
                  <tr id="40505105"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40505105" href="https://news.ycombinator.com/vote?id=40505105&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I‚Äôd do absolutely nothing. I‚Äôd sit on a beach or in a pool/hot tub drinking beer and wine while reading or watching tv. I‚Äôd walk enough so that I don‚Äôt look like the future people from Wall-E. I‚Äôd make sure to do absolutely nothing productive though.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501838"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501838" href="https://news.ycombinator.com/vote?id=40501838&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I‚Äôd love to help universal basic education become true.</p><p>There are some people who are extremely qualified and specialized in their fields, but many more would really benefit from additional formal education. Even tech literacy is taken for granted sometimes, even though it shouldn‚Äôt. It‚Äôs the kind of thing that makes an actual difference in the lives of people.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507545"><td></td></tr>
                  <tr id="40503800"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503800" href="https://news.ycombinator.com/vote?id=40503800&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I would just create software. I love coding little programs that make life easier. It gives me joy of creation. In fact that's what I have been doing, in last few months I have created (1)a video GPS viewer, (2)Windows based authenticator and an (3)online clipboard. After my day job and on weekends, this is how I like to spend my time. I have stopped trying to create the next killer app. I am just going to create whatever I feel like creating.
Links to my latest creations
(1) <a href="https://yash.info/camgeoplayer/" rel="nofollow">https://yash.info/camgeoplayer/</a>
(2) <a href="https://authwin.com/" rel="nofollow">https://authwin.com/</a>
(3) <a href="https://klipit.in/" rel="nofollow">https://klipit.in/</a></p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40507701"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40507701" href="https://news.ycombinator.com/vote?id=40507701&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>that's the way to do it man. i have a handful a small little personal softwares that i've made for myself</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40500506"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40500506" href="https://news.ycombinator.com/vote?id=40500506&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Check out the book From Strength To Strength by Arthur Brooks. It‚Äôs a bit of a mid-life crisis book that addresses this. In short: develop hobbies, invest in friends/community, explore spiritually.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40507672"><td></td></tr>
            <tr id="40500905"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40500905" href="https://news.ycombinator.com/vote?id=40500905&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Fortunately, I have reached that stage.</p><p>OTOH, still figuring out what to do next.</p><p>I keep reminding myself of what PG had to say: By compressing the dull but necessary task of making a living into the smallest possible time, you show respect for life, and there is something grand about that.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501573"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501573" href="https://news.ycombinator.com/vote?id=40501573&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I feel like my answer should be something reliable like "educating the next generation", but instead I think what I'd actually do is some kind of "shoot for the moon" / "hail mary" ultra ambitious project (hopefully with a bunch of similarly motivated and smart people).</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501556"><td></td></tr>
                <tr id="40501753"><td></td></tr>
                  <tr id="40507133"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40507133" href="https://news.ycombinator.com/vote?id=40507133&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>If money wasn't a concern, I would strive to fill my time with pursuits that challenge me, help me grow, allow me to contribute something of value, and bring me a deep sense of purpose and fulfillment.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506553"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506553" href="https://news.ycombinator.com/vote?id=40506553&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>You ask one thing in the title and something else in your text. I'm answering only the question in the title.</p><p>As of now, I'd split my time between a couple of things:</p><p>(1) In  winter and autumn, become a part-time psychologist to help reduce some of the mental pain that people go through.</p><p>(2) In spring and summers, go for weeks-long hikes in nature, become a part-time hiking guide in the mountains.  Help maintain the trails, mountain-hut infrastructure, and take people on hikes. Simply, be more in nature.</p><p>Luckily, today I can still enjoy some of these: study cognitive science as a hobby, and hike in nature in my free time.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40506681"><td></td></tr>
                  <tr id="40501732"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501732" href="https://news.ycombinator.com/vote?id=40501732&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I‚Äôd build handcrafted furniture, millwork, etc. give it away.  Help others in the community / area with projects. Sail, grow more food, spend more time reflecting, staring at clouds, watching the ecosystem in the grass etc.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501613"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501613" href="https://news.ycombinator.com/vote?id=40501613&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Not a silly question, worth revisiting periodically.</p><p>I'd spend part of the time doing some sort of weight-lifting or low-stress cardio, part of the time working on independent B2B/B2C software ventures, and part of the time training as a musician.</p><p>Eventually I'd like to add some component of service to others there, but I haven't really felt a pull to that yet.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501658"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501658" href="https://news.ycombinator.com/vote?id=40501658&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I would have a nut tree orchard and nursery.  I love gardening and being outside.  If I didn't need to work to support my family I would risk starting a nursery.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506739"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506739" href="https://news.ycombinator.com/vote?id=40506739&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>As many have noted there are two different scenarios.</p><p>In the lottery jackpot/UBI scenario where money is no concern at all I'd camp, fish, read books, and drink whisky.</p><p>In the need a job, but every job will pay my asking salary scenario, I'd make software like I do now, but probably for a smaller, less bureaucratic company.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506990"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506990" href="https://news.ycombinator.com/vote?id=40506990&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Researching new ways to apply spaced repetition and LLMs to second language acquisition. Reach out to me via my blog, LinkedIn, Reddit, GitHub etc.. if you feel the same way.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501716"><td></td></tr>
            <tr id="40504520"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504520" href="https://news.ycombinator.com/vote?id=40504520&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Health. I'm in lower 40ties and in two and a half years had two surgeries to fix a herniated disc. After the first surgery a part of my recovery were exercises on pilates reformer and it worked wonders. Unfortunately I needed a second surgery and now I'm slowly getting back on the reformer.</p><p>My original plan was just to get back to normal and continue living as normal. This recently changed, and I don't want to get back to normal. I want to be healthier than I ever was. I want to be stronger and much more flexible. You don't know what you have until you lose it.</p><p>So without much money I'll work on myself by doing pilates and other resistance training, and if I had more money I would probably open up pilates studio so I could share the joy which I'm having.</p><p>When you're not healthy, the only thing you want above all is health. If I were asked the same question 3 years ago I would say: riding bikes all day long. This still might be the answer, but long and toned muscles come first.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40505695"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40505695" href="https://news.ycombinator.com/vote?id=40505695&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>&gt; basically what would your ideal job be, in an ideal world?</p><p>But that's a completely different question from the one in the title. My ideal job and what I'd do if I didn't need money are two very different things.</p><p>If I didn't need money, I'd have more time to do the things I already do when I'm not "on the clock", so I'd do more of them.</p><p>&gt; would you contribute towards making society more rational, healthy, and well-coordinated?</p><p>Yes, absolutely. I already do. But I'd also be able to spend more time expanding my knowledge and skillset, having fun, and other such stuff with no direct connection with improving the world.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506355"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506355" href="https://news.ycombinator.com/vote?id=40506355&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I am 46 and hope to retire at 50.</p><p>Been active most of my life and plan to do more of it - mountain-biking, racquet sports, skiing, etc.</p><p>My kids will be in their teens, and I hope to focus more on them and prepare them for life.</p><p>Get involved in the local community, and help less fortunate people. I do this mainly by contributing money but I hope to give time.</p><p>Travel - Not as a tourist which I've done for most of my life, but as a true explorer of cultures.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501622"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501622" href="https://news.ycombinator.com/vote?id=40501622&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I used to be a data scientist, I'm now a grad student researching personality development. There are easier ways to make a lot more money, but I feel like I'm doing the deepest possible work, given my interests and skillset.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506345"><td></td></tr>
            <tr id="40504500"><td></td></tr>
            <tr id="40501537"><td></td></tr>
                <tr id="40504318"><td></td></tr>
                  <tr id="40502660"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40502660" href="https://news.ycombinator.com/vote?id=40502660&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>A few days back "Where are the builders?" was asked and I was going to chime in there but then today this comes up which correlates, good timing. I too was a Nintendo and Lego kid that took it to extremes, I still play with Legos today as they are great for mock ideas and concepts.</p><p>My lifestyle and past choices now afford me all my time as I made great sacrifices for many years saving prolifically while others accrued more and more debt chasing the Jones. Apparently this is called FIRE now but I was doing it long before the acronym.</p><p>I have been a problem solver my entire life and have both reverse engineered many things but more importantly I have built a vast variety of personal and professional solutions using mechanics, electronics, technology, automation, and more. I am now building and patenting an energy storage device of my own design given the problem that I personally have which one can likely deduce. I am in absolutely no hurry as all my time is mine to invest where I see fit and as such I am my own boss with ONLY the goal of solving my problem.</p><p>For those with the entrepreneurial mindset, exactly like my own, I‚Äôll answer your implicit question from the above reading: "Yes". Once I have my device functioning and it performs as I designed it to the satisfaction of my requirements then a business opportunity unfolds. Given my past choices I am referred to professionally as a serial entrepreneur so I may as well apply my time to my interests and keep solving problems. The difference now however is that I have zero anxiety in my pursuit of my problem since the goal is the objective, not money.</p><p>Stay Healthy!</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501024"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501024" href="https://news.ycombinator.com/vote?id=40501024&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I'm not sure, and that slightly concerning to me. I'm on the path to be financially independent within the decade, but I'm not really sure what I'd do in that case. I'd probably keep writing software (since that's my first love) and just have the complete freedom to quit a job or take time off if I want.</p><p>I'd like to get into some more hobbies, since I really went 100% in on software once I started working full time and I'd really hate to burn out on this. Working a shorter week or with more half days would be great too. We'll see. Life changes.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40501827"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40501827" href="https://news.ycombinator.com/vote?id=40501827&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I'm on a similar path, and still haven't figured it out. My main recommendation would be to increase the time you spend on hobbies, travelling, volunteering, etc. Use the next few years to figure out what you enjoy, and what you are retiring to. Slowly let it expand to fill your available time.</p><p>And if you decide not to stop working, there is something truly freeing about knowing that you don't need the job. In some cases I'd argue that it actually makes you a better employee (since you aren't willing to put up with bs, play politics, etc).</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501688"><td></td></tr>
                  <tr id="40504946"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504946" href="https://news.ycombinator.com/vote?id=40504946&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>At this point I‚Äôm kind of bored of programming and I‚Äôd probably leave if it didn‚Äôt pay so well.</p><p>If I had enough money I‚Äôd probably take up sewing full time and make furry cosplay stuff. Seems much more rewarding than building corporate tech junk.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505724"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40505724" href="https://news.ycombinator.com/vote?id=40505724&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I'm bored too. I got into programming young so I'm only about 15 years into my career and it's been my hobby for 25 years.</p><p>Not only will I never learn everything about software, but I hit the point of negative returns a while ago. Every hour I spend on the computer is an hour I'm not spending on myself or my friends or on making new friends</p><p>I just want to travel, exercise, practice non-monogamy, do stuff like that I didn't do as a teenager because I was busy programming. The computer will be there when I'm done.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40501615"><td></td></tr>
            <tr id="40505402"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40505402" href="https://news.ycombinator.com/vote?id=40505402&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>In the tech realm: I'd spend my time doing optimization work for open-source projects. It's fun, and you get to show some objective results. I'd probably do that until I had some sort of concrete idea for a cool project or some kind of project that might benefit the world somehow.</p><p>Or maybe I'd just leave tech behind entirely and do volunteer work.</p><p>But I feel like that's a one-way street. If I walked away from tech for a few years, and decided I wanted to go back... it feels like it would be very difficult.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501768"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501768" href="https://news.ycombinator.com/vote?id=40501768&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>That's easy. Writing books and researching curiosities.</p><p>I have dozens of book ideas, from novels to reference volumes. My research would at least partially focus on energy/power generation/storage, and partially on current scientific mysteries in our reality.</p><p>Ideally, such work could help enrich humanity. Make the world better in some way. Sadly, unless I win a lottery tomorrow or a wealthy person issues me a grant, some of this work won't get done.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40506772"><td></td></tr>
                  <tr id="40500593"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40500593" href="https://news.ycombinator.com/vote?id=40500593&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>If cash wasn't a thing, I'd be all in on creating a system that lets you transfer your memories and brainpower into another body or a robot.</p><p>I'll let you laugh at this like others, but I'm serious.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505615"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40505615" href="https://news.ycombinator.com/vote?id=40505615&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Curious how one starts doing this. Don't we need several generations of Neuralink to even start?</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40502131"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40502131" href="https://news.ycombinator.com/vote?id=40502131&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>When this becomes possible, prisons will become very compact: a micro SD card to trap one's consciousness.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40502907"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40502907" href="https://news.ycombinator.com/vote?id=40502907&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>As you might expect, there's a Black Mirror episode not far from that (IIRC "White Christmas"). And several other works of literature.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40501740"><td></td></tr>
            <tr id="40501774"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501774" href="https://news.ycombinator.com/vote?id=40501774&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I already love what I'm doing for a living as a CTO for a small start-up, and probably wouldn't quit, but if money absolutely wasn't an object and my current mission were fullfilled, then I'd probably spend more hours on gardening, and more hours on "technoetic" art/research projects: exploring consciousness through technological means.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506377"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506377" href="https://news.ycombinator.com/vote?id=40506377&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>&gt; What would you spend your time working on if you didn't need money?</p><p>What an interesting question; thank you for asking it!</p><p>What I would spend my time working on...I guess I would continue with what I have been doing the past 15 years.</p><pre><code>  - continue working on improving my character
  - fixing my past mistakes and learn from them
  - enrich my knowledge with topics I may find interesting at any time
  - learn to forgive and put myself in others' shoes to see their own POV
  - embrace life
  - appreciate little things; such as a smile, a hug, a kiss

</code></pre><p>
This whole process I have aforementioned can impact anyone's job towards the best, because people will notice (eventually) that something is different with you and how you approach things in your life, let alone in your job, and they will appreciate it; well, at least I hope!</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501767"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501767" href="https://news.ycombinator.com/vote?id=40501767&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I'd work on whatever my current hobby is. The actual hobby changes over time.
Currently, my hobby is maintaining/repairing cars. If I had more time (and space), I'd restore old cars and/or build a track car (and of course use it on track).</p><p>Unfortunately the time and space limits means I don't even have the time to finish my very long TODO list on my own car.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40500634"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40500634" href="https://news.ycombinator.com/vote?id=40500634&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Some voluntary work and care giving to others who need help. I would do some social projects supporting the teens finding orientation. That's what I would do.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501780"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501780" href="https://news.ycombinator.com/vote?id=40501780&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I think I would want to work on an open source video game engine or a CPU.</p><p>In a world where nobody had to worry about money, I think we‚Äôd have trouble getting enough people together to work on a very good CPU. And I don‚Äôt know enough to do it on my own. But I think I‚Äôd enjoy tinkering with it, even if I got a very poor result.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504612"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504612" href="https://news.ycombinator.com/vote?id=40504612&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I have almost always done what I want and that is writing software. I like writing development tools, formal theories and low level stuff (databases, OS, editors).</p><p>And, since about two years, I am working with some friends on Common Lisp software again; far more enjoyable than anything else imho. I regret going for some of the new fads in the 90s while I could‚Äôve been working with CL all that time. But he, regrets are useless and I did learn a lot.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40504701"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40504701" href="https://news.ycombinator.com/vote?id=40504701&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>What do you consider fads of the 90's? We had object-orientation, of course, Java, it was the beginning of XML.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40504931"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40504931" href="https://news.ycombinator.com/vote?id=40504931&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>All of them and more‚Ä¶ We did CL, and Perl before Java and then immediately went to the 0.1 of Java when it was available. JSP didn‚Äôt exist yet, or servlets even, but we were hooked.</p><p>I went into 2000s doing enterprise java beans (and Corba code generators in xml) and stupid over architected Java stuff with everything XML (and XSLT). We wrote our own db which stored XML (but was mostly in memory), our own frontend language in XML. All with Java under it.</p><p>Our own fairly comprehensive application server with all kinds of ready made components; we sold a lot of licenses and in the end the company for a lot to a big vendor who immediately threw it all away.</p><p>But yes, we drank all the koolaid and it was good timing of course, just all very stodgy, especially as the system and the clients grew; we did the same large sized applications as we (other ‚Äòwe‚Äô but still me) do now, but with far more people and far worse processes. The first years we had zip file version control (until moving to csv and then svn), tests, what are those? And more like that.</p><p>In hindsight, I would‚Äôve skipped Java until Clojure, or skipped it altogether. I was very good at Common Lisp and c/c++ and liked all those things better. But I was convinced somehow that all that was going to die because of Java.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505229"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40505229" href="https://news.ycombinator.com/vote?id=40505229&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>It all did die because of Java, or at least went into hibernation.</p><p>Common Lisp, true or not, was known as an AI language and died because it was attached to the AI winter.</p><p>C++ was killed by Java for a lot of business software, including at my company. It won what I call the 80/20 battle, meaning it gave you 80% of what the old technology gave you for 20% of the hassle. You still had OO, but didn‚Äôt have to worry about pass by reference vs. pass by value, interfaces got you out of the multiple inheritance diamond problem, and garbage collection of course.
Do you think if your application server was in Common Lisp or Perl that it would have sold for a lot?</p><p>Other losers of the 80/20 battles, Java over C++, XML over SGML, JSON over XML.</p><p>Cobra‚Ä¶shudder. Oh and COM, don‚Äôt forget COM. My greatest accomplishments in my career were avoiding going into management and avoiding COM.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40504973"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504973" href="https://news.ycombinator.com/vote?id=40504973&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>1. Science
2. Philosophy
3. Art</p><p>I am currently factually volunteering to a project in CERN that needs full-time attention, but unfortunately I need to feed myself and my family so I work at daytime as a full-time Software(Data) Engineer. I spent whatever time I find (mostly nights) doing science. I do hope I will manage to deliver new NN method I experiment now. This has a lifelong meaning for me.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40504995"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40504995" href="https://news.ycombinator.com/vote?id=40504995&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>How do you "work on" philosophy?</p><p>Asking because my web developer wife, who happened to have majored in art and philosophy, is currently unemployed and kinda bummed about it.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505045"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40505045" href="https://news.ycombinator.com/vote?id=40505045&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>YouTube video essays?</p><p>Only sort of joking; I have no idea what the economics of a small YouTube/Nebula channel look like and I suspect it's one of those things with a tiny minority of people whose work ends up being net positive and a long tail of others who break even or lose money.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40506064"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40506064" href="https://news.ycombinator.com/vote?id=40506064&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>It seems like there isn't any hobbyist philosophy right? Either your in academia or reposting stoic quotes on Instagram it feels like lol</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40501078"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501078" href="https://news.ycombinator.com/vote?id=40501078&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I'd probably jump between service based positions gear towards helping others/community even if they resemble a job.</p><p>Cobbler, Librarian, Prepare food in a school, stage crew, idc just something relatively physical and with an end product/objective and for the support of others/something. It would probably change every 3 - 6 months or so.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504813"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504813" href="https://news.ycombinator.com/vote?id=40504813&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Go back to uni, get that degree in Mathematics, earn that PhD, go back to uni, get that degree in Physics, earn the PhD, die?</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504873"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504873" href="https://news.ycombinator.com/vote?id=40504873&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Working on myself, my relationships, and my family. Exercising more, but doing more of the types of exercise I'd prefer (hiking and mountain biking) than I can really handle right now with work and young children. Gardening, canning and preserving food. Reading and writing. I'd spend more time with my parents and brother, who live very far away.</p><p>I'd work on house projects, too. I'd redo our flooring right out of the gate if I had more time. I did it in my previous home and enjoyed both the process and the outcome.</p><p>I still love programming, I started when I was single digits and am now in my 40s. I've been doing it professionally for just about 20 years now. But I'm frankly tired of digital everything at this point in my life. I have been filling my personal life with offline and analog hobbies and with every passing year I wish I could spend even less time in front of a computer.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501652"><td></td></tr>
            <tr id="40501995"><td></td></tr>
            <tr id="40501856"><td></td></tr>
            <tr id="40501567"><td></td></tr>
                <tr id="40501744"><td></td></tr>
                  <tr id="40506256"><td></td></tr>
            <tr id="40501692"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501692" href="https://news.ycombinator.com/vote?id=40501692&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>A depressing reality to this question is to just look at the current crop of billionaires. None of them need money, yet many of them spend their time pursuing more.</p><p>I know all of us have these quaint answers about all the noble or fulfilling things we would do, but the data doesn't seem to support that.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40501847"><td></td></tr>
            <tr id="40501817"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40501817" href="https://news.ycombinator.com/vote?id=40501817&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I've met people who were born into enough money they never needed to work, and a lot of them are just pretty normal people sans jobs.  I think the interesting question here would be how would you live if you had enough without working, but little enough that you still had to think about how to stretch it over a lifetime.  E.g. are you flying first class to spend a few days skiing in the Alps this weekend?  Probably not, but you can make sandwiches and go for a hike instead of clocking in to work.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40503764"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40503764" href="https://news.ycombinator.com/vote?id=40503764&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>The specifics do matter. You can have a very comfortable month-long international trip for certainly low five figures. (Obviously can do less but a few $K/week for a couple is a reasonable baseline.) You can also quickly add to the tab by picking the luxury hotels, first class flights, limos, etc. that may or may not add a lot to the experience considering.</p><p>I've traveled a lot and sometimes the splurge is really worth it. Often, it's not unless the money involved is just pocket lint to the person.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40504393"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40504393" href="https://news.ycombinator.com/vote?id=40504393&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I agree - I've travelled enough on my own dime and the corporate one to know that you definitely don't want to get the cheapest room on Expedia, but satisfaction doesn't scale linearly with the amount you spend.  Filet mignon doesn't automatically beat a nice warm rock to sit on.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40501707"><td></td></tr>
            <tr id="40501757"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40501757" href="https://news.ycombinator.com/vote?id=40501757&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>There's a bit less than 3000 billionaires, are you sure you're not just hearing about a very vocal minority?</p><p>Not to mention survivorship bias, the ones that reach that kind of wealth like money more than (other people's) life itself, often quite literally.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503219"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40503219" href="https://news.ycombinator.com/vote?id=40503219&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I mean, I think it is a different scenario. The kind of person who makes a billion dollars has something going on in their brain that makes them want to keep going. Think about it: by the point where they've made a billion dollars, they've long since passed on the opportunity to retire comfortably. They already had all the money they needed, and, faced with the chance to stop, they decided to stay in. They flew past $10MM, past $50MM, even $100MM‚Äîfar more than anyone could ever spend unless they really tried‚Äîall while saying "no, I'm not done yet". I would not expect someone with this mentality to suddenly stop at $1 billion. They are in it for something other than reaching the point of not having to work anymore. I'm not saying I admire them, in fact it sounds like a terrifying inner life to me.</p><p>On the other hand, the rest of us, the 98.7% of people who are only working for the paycheck that allows us to do the other things we actually want to do instead of our jobs. The extent to which we work is the extent to which we must pay for those needs. Remove the need to work, and we wouldn't be working anymore‚Äînot at those jobs, anyway.</p><p>What I'm saying is, I believe non-generational billionaires are weird outliers, and we can ignore them for the purposes of this question.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505687"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40505687" href="https://news.ycombinator.com/vote?id=40505687&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Our CEO is obsessed with "engagement." He has a problem where older employees are not engaged and are retiring in droves, and the incoming employees couldn't give two shits less about the company. They keep begging retirees to return.</p><p>I think this is microcosim of our wider economy. If it is, output is going to fall off a cliff, soon.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40502003"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40502003" href="https://news.ycombinator.com/vote?id=40502003&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Because the work they do is satisfying and interesting. Take that away and they‚Äôre less of a person. They can‚Äôt stop because the person they are is tied up with what they do.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40506251"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506251" href="https://news.ycombinator.com/vote?id=40506251&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Working on building my yacht and working on open source for fun (probably Debian developer)</p><p>Maybe doing something with biogas, CO2 capture</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501725"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501725" href="https://news.ycombinator.com/vote?id=40501725&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I'd probably just own some kind of cycling adjacent coffee/bicycle shop where I barely do anything but nod towards my workers and talk with everyone who visits.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40502281"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40502281" href="https://news.ycombinator.com/vote?id=40502281&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Have you read, ‚ÄòA Psalm For The Wild Built‚Äô by Becky Chambers?  The protagonist is a monk that cycles around on a bicycle-camper making tea for people, and ends up making friends with wild robots.  Touching...I've thought of serving coffee and tea at the nearby parks via bicycle often.  A physical location such as yours would be nice too.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40501540"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501540" href="https://news.ycombinator.com/vote?id=40501540&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>There's two different ways of answering this question: What would I do if I didn't need money for myself, and what would I do if I didn't need money for myself but had money for others.</p><p>In the first, I would keep working and enjoy life. In the latter, I would use it to help others. Specifically investing in technologies, companies, and public policy that helps people with disabilities and make their lives easier; better jobs, housing, everyday life, etc.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503964"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503964" href="https://news.ycombinator.com/vote?id=40503964&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I‚Äôd love to teach math/science to kids. I think I would be very good at it and enjoy it. But the pay really sucks.</p><p>At home id setup a shop with a 3d printer, laser cutter, cnc machine, power tools, etc. And I‚Äôd spend my free time just making all sorts of fun stuff.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503303"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503303" href="https://news.ycombinator.com/vote?id=40503303&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I am very slowly working on a non-profit community management / RSVP collection platform.  Think of this as an alternative of the websites you tend to think of if you want to collect RSVPs for a social club or meetup group, but run and maintained by a Wikimedia Foundation-style non-profit.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501754"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501754" href="https://news.ycombinator.com/vote?id=40501754&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I've been making scented candles.  Its easy enough to get started but there's enough complexity to it to keep things interesting.  If I didn't need money I'd just do that all the time and build it into a small business (that didn't need to make money, since I'm sure it wouldn't haha)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501617"><td></td></tr>
                <tr id="40505632"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40505632" href="https://news.ycombinator.com/vote?id=40505632&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Since you're on a throwaway account, I'm assuming you've already started this machiavellian endevour. ;-)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40506404"><td></td></tr>
                  <tr id="40501801"><td></td></tr>
            <tr id="40501949"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40501949" href="https://news.ycombinator.com/vote?id=40501949&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Adding counter spin:
And you had the unquestioned backing of world leaders ala the wall watchers in The Three Body Problem.</p><p>What would you do if you didn‚Äôt have to worry about money, or opposition, and the sky itself wasn‚Äôt even the limit.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40503780"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40503780" href="https://news.ycombinator.com/vote?id=40503780&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I will create a global society that is mostly a dictate of scientists and engineers. My point: It's better to be dictated by scientists and engineers than lawyers and accountants, if we have to be dictated.</p><p>- It is MANDATORY to receive STEM education up to undergraduate level AND pass several tests unless you are proved to be unfit by more than one independent medical institutions;</p><p>- A commission consists of global scientific and engineering elites dictate what scientific humans should pursue in the next X years. So for example it could be Space exploration, etc;</p><p>- All basic needs are free. Food, housing, clothing, transportation, entertainment etc are free. But any extravagant material (e.g. a family of 3 wants a 3,000 s.f. detached house with a 2-acre land? That's extravagant) is expensive and may require extraordinary contribution to Science or Engineering;</p><p>- All other resources are poured into research and development of above mentioned scientific pursuits;</p><p>- We don't really need a monetary system because most of the basic needs are free. Instead we have a "contribution point" system. Detail to be revealed;</p><p>I could probably go on and on but that's the basic ideas.</p></div></td></tr>
        </tbody></table></td></tr>
                                  <tr id="40505147"><td></td></tr>
            <tr id="40501667"><td></td></tr>
            <tr id="40503820"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503820" href="https://news.ycombinator.com/vote?id=40503820&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I'd create open-source software for hosting. Something like CapRover. Or take a big sum of money and do algorithmic trading. Or build something in crypto.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504462"><td></td></tr>
            <tr id="40501601"><td></td></tr>
            <tr id="40501855"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501855" href="https://news.ycombinator.com/vote?id=40501855&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Mostly just do whatever I find fun. Maybe contribute to the communities of those hobbies a bit while I still enjoy them. Thinking I'd do anything grander than that would be lying to myself.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503805"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503805" href="https://news.ycombinator.com/vote?id=40503805&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I would work on a Computer Algebra System. Maybe one day, who is to say.</p><p>That being said I'm pretty close to my dream job</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40505854"><td></td></tr>
                  <tr id="40503647"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503647" href="https://news.ycombinator.com/vote?id=40503647&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>My life goal is to make enough money in tech to semi-retire around 40 and teach CS to underprivileged kids.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503179"><td></td></tr>
            <tr id="40501531"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501531" href="https://news.ycombinator.com/vote?id=40501531&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I don't think I would work. I would pour myself full time into a few creative pursuits like woodworking. I would also travel a lot.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504728"><td></td></tr>
            <tr id="40500616"><td></td></tr>
            <tr id="40506236"><td></td></tr>
            <tr id="40506154"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506154" href="https://news.ycombinator.com/vote?id=40506154&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I wouldn‚Äôt work towards anything.</p><p>I‚Äôd shitpost online, read books, go to the coffeeshop, watch movies, go on walks, etc.</p><p>Took 3 years off in my 20s to do exactly that and it was incredible. Best years of my life. Would drop everything and do it again in heartbeat if I could swing it financially.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503695"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503695" href="https://news.ycombinator.com/vote?id=40503695&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>There‚Äôs brutal war two countries over, and if one falls, the war is coming here. I can‚Äôt stop taking care of my family, but not a day passes without me wondering if bread on the table today is more important than preparing to stop Russia tomorrow.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40503774"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40503774" href="https://news.ycombinator.com/vote?id=40503774&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>You can calm down, there is absolutely no way the Russians are coming for you.  Turn off the TV and enjoy time with your family.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40501606"><td></td></tr>
            <tr id="40501572"><td></td></tr>
            <tr id="40501758"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501758" href="https://news.ycombinator.com/vote?id=40501758&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>I'd open a bakery and make fresh sourdough bread, pizzas, focaccia and pasta every single day, and give it away for cost.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40502351"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40502351" href="https://news.ycombinator.com/vote?id=40502351&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Would you still start at 4am in the morning?  I was contemplating "retiring" to work at a local cooperative bakery that makes similar things, but their shifts were at horrible times that felt like it would ruin my health.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40501645"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501645" href="https://news.ycombinator.com/vote?id=40501645&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Stopping climate change, and helping homeless would be at the top of my list, and if those are not up your alley space exploration and AGI seem fun.</p><p>For bonus points, you could work on not making us poor folk feel bad for having to work a 9-5! ;)</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504764"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504764" href="https://news.ycombinator.com/vote?id=40504764&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Making even more money, of course.</p><p>Just look to your VC darlings, how many of them "don't need money"? By definition, all of them, and yet, what are they spending their time on? Making even more money, of course.</p><p>HN really is a cesspit of financial pillaging apologists...</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503892"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503892" href="https://news.ycombinator.com/vote?id=40503892&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I have a real passion for the "Long Now". Understanding how to preserve knowledge for the 10,000 year timeframe. Inspired by everything from Anatheum by Neal Stephenson and subsequently finding the Long Now Foundation and even stupid games like Horizon: Zero Dawn.</p><p>I would probably do more on that front than I currently am on the side. It's some balance of actually persisting knowledge in super-durable formats, and persisted knowledge in computer systems (Internet Archive, Arctic Code Vault, LibGen/Anna's Archive)</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503305"><td></td></tr>
            <tr id="40501691"><td></td></tr>
            <tr id="40501671"><td></td></tr>
                <tr id="40501874"><td></td></tr>
                  <tr id="40506296"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506296" href="https://news.ycombinator.com/vote?id=40506296&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Let's say by "didn't need money" you mean I have an income that is enough to fully support my family and keep my home in good repair and even make home improvements (we need some big repairs to gutters and fascia, deck, HVAC, etc.) That's not a small number especially factoring in health care... but let's assume it's taken care of and all our needs are taken care of, and I even have a little disposable income for IT, music stuff, books, etc. I could continue with the things I've done in my limited free time for decades:</p><p>- writing non-fiction and fiction
- making original music and podcasts
- developing educational hardware/software projects
- developing my own programming languages
- continuing to refine and catalog our large home library
- gardening and transitioning towards growing more of our own food.</p><p>I'd spend much more time involved with my kids since my wife and I already homeschool, but I can't put very much time into it now.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503561"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503561" href="https://news.ycombinator.com/vote?id=40503561&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I won‚Äôt tell the whole story but the other day a 1st grader who came over to hang out with my kids punched me in the stomach with ‚Äúwow you have so much food.‚Äù</p><p>The breakfast program at school is largely funded by Canada‚Äôs largest,  exceptionally profitable grocery chain. But this year they‚Äôre radio silence on renewing the funding.</p><p>So I‚Äôd probably be working on making sure children are fed.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40504473"><td></td></tr>
            <tr id="40506166"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40506166" href="https://news.ycombinator.com/vote?id=40506166&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I'll work on these:</p><p>(1) Convince car manufacturers to add a battery port in the trunk. They can make smaller cars with 100 mile range which covers &gt;98%[2] of the trips and anyone who needs more can rent extra batteries from their nearest retailers. Fast chargers don't work, queueing theory explains why: What happens when you add a new teller? [0]. Fast chargers won't work because we have to solve for the peak case, which is a third of US population driving during Thanksgiving, Christmas, New Year, Spring break, etc. Cars with smaller batteries will be cheaper, lighter and far more importantly we can make 3X the cars from the same battery materials. There will be a lone commenter who will complain that EV doesn't work for him, because he commutes every week from Miami to Seattle, but EVs work for most people's driving habits.</p><p>(2) Convince retailers to build battery banks, they can charge for free (or get paid for charging when electricity prices go negative!) and (a) rent fully charge batteries (b) participate in virtual power plants replacing natural gas, they can make bank[1]. This also increases their foot traffic, most of the big retail chains operate gas stations anyways as loss leaders. Batteries for rent will be extremely profitable, in addition to adding foot traffic.</p><p>(3) Change residential building codes to require 240V outlets in the garage, heat pump water heater, heat pump furnace, induction stove, solar panels, or better yet solar shingles. Solar shingles are coming up, may not be cost effective today, but probably soon? Also make the main panel and circuitry future proof -- home can be powered by vehicle (V2H - no need to generator for emergencies) and also V2G so everyone can participate in VPP.[2] I've already started working on this.</p><p>(4) Change commercial (anything non-residential) building code to require conduit before paving parking lot. Doesn't need to add EV chargers, but that makes the parking lot future proof, can make 10%, 20% or 100% of it EV ready whenever.</p><p>With (3) and (4) all new construction is energy efficient, future proof. People who buy these homes can have zero energy bills as well as make money from VPP.</p><p>(5) Everyone complains about high home prices. We see spirited discussions on HN once or twice a week. Convince builders to build homes to standards (#3 above) that make the old homes entirely undesirable to most people. There can be a huge building boom (builders benefit from this), very low sales of old homes, stopping the growth of home prices. Convince people to stop buying old homes.</p><p>(6) Work with cities on providing free charging at schools, parks, libraries and all city owned infrastructure.</p><p>(7) Work with HOAs/communities to build chargers in HOA managed parks, these are 10 - 100x more than city parks.</p><p>(8) Put shareholder resolutions to make companies either offer (a) fully remote (b) free charging.</p><p>(9) Put shareholder resolutions at Restaurants and Retailers to offer free charging. This is a win-win, they get high quality foot traffic, traffic that stays at least 30 mins.</p><p>I'm in my 40s, I think these are important and solvable problems, nothing more I'd love than working on these. Better yet, teach the younger generation on how to work on these. We can't change the world by thinking about fossil fuel led COP summits, Govts, but we can change by making decisions on where we live, work and shop. Gradually, then suddenly, everything will change for the better.</p><p>[0] <a href="https://www.johndcook.com/blog/2008/10/21/what-happens-when-you-add-a-new-teller/" rel="nofollow">https://www.johndcook.com/blog/2008/10/21/what-happens-when-...</a>
[1] <a href="https://electrek.co/2023/07/05/tesla-electric-customers-report-making-150-day/" rel="nofollow">https://electrek.co/2023/07/05/tesla-electric-customers-repo...</a>
[2] 98 percent of all single-trip journeys were under 50 miles in length: <a href="https://www.greencarcongress.com/2022/03/more-than-half-of-all-daily-trips-in-us-were-less-than-three-miles-in-2021.html" rel="nofollow">https://www.greencarcongress.com/2022/03/more-than-half-of-a...</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40505423"><td></td></tr>
            <tr id="40501596"><td></td></tr>
            <tr id="40502644"><td></td></tr>
            <tr id="40505768"><td></td></tr>
            <tr id="40505665"><td></td></tr>
            <tr id="40501805"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501805" href="https://news.ycombinator.com/vote?id=40501805&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I don't think there is really one answer to this. I'd be surprised if people's hobbies and interests are really this stable across a lifetime. If you'd have asked me five years ago, all my hobbies were very close to my actual job and I'd have been building compute labs and writing infrastructure orchestration software for fun. Ten years ago, I was more into amateur data analytics and I'd have at least wanted to try setting up my own BCS computer ranking for NCAA football. 20 years ago, it would have been photography and travel writing. Right now, I'd be all-in on personal athletics, trying to continue lifting and rehab my old fledgling habits of climbing and swimming, but mostly doubling down on running since it's what I'm best at and it consumes a lot of time anyway. I'd also love to get involved in big cat rescue, but with the success pumas are already having in the Americas, the need is probably mostly in Eurasia and Africa and I don't think I'd want to leave the only continent I've ever called home. Family still matters. I'd move closer to them, not farther.</p><p>Given all this history, I'm definitely not going to pretend I have any idea what I'm going to want to do when I actually retire. I'm also not alone. What I really end up doing is contingent on not disupting whatever my wife wants to do.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501008"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40501008" href="https://news.ycombinator.com/vote?id=40501008&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I'd focus on becoming more spiritual, spending more time in nature, reducing my waste footprint and disconnecting from the world.</p><p>I don't believe that "making society more rational, healthy, and well-coordinated" is a contribution; this sounds like those who have private jets and go to global conventions to about saving the environment. It sounds to me like you are a narcissist as well, to think that you are more rational than others or know better just because you have money.</p><p>The world is pretty rational, if they aren't healthy, it's because people are building the Coke's and Kraft Heinz around the world, companies that are predatory and exploit weaknesses of others.</p><p>Try to live a life that you no longer need to exploit others, or animals, or the environment you live in, and of course, document it so others can do it as well.</p><p>There are way too many rich folks already trying to change the world and making it worse because they are only looking at the bright side, not the side-effects of what they do, much less on how they live.</p><p>Rich people don't try to do this because they know it's really hard. Living sustainably is harder than having a job or making money.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40501591"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40501591" href="https://news.ycombinator.com/vote?id=40501591&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>This is the most realistic answer provided in this post thus far, and I feel the downvotes are just proving the point. _Not needing money doesn't make you an expert on the world_, please repeat that to yourself and everyone else on that path.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40505028"><td></td></tr>
            <tr id="40504319"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40504319" href="https://news.ycombinator.com/vote?id=40504319&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>I am in this situation and I focus on friends, family, hobbies.</p><p>I think that most problems in "society" stem from people losing track of these things.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40503583"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40503583" href="https://news.ycombinator.com/vote?id=40503583&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div>
                  <p>Probably Christian apologetics.  It is clear to me that science is incompatible with atheism and supports the Christian worldview, but this does not seem to be widely understood.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501568"><td></td></tr>
            <tr id="40507415"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40507415" href="https://news.ycombinator.com/vote?id=40507415&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>An ideal job is different than if you didn‚Äôt need money. I have a bit more of a lived experience with this than most. I‚Äôm planning to fatFIRE when I have kids going to college.</p><p>Currently, I‚Äôve been on a sabbatical for two years. In that time, I‚Äôve spent a good amount traveling and living in other areas. I‚Äôm living in NYC mostly rather than SF.</p><p>I‚Äôm interested in having a family and have been single for a few years. So, that‚Äôs why I moved to NYC. I simply couldn‚Äôt meet enough single women back in SF. The ratio is really bad in SF. In NYC it‚Äôs tolerable. (Check out census data - table b12002)</p><p>That‚Äôs what I would do because it‚Äôs what I‚Äôve done. I‚Äôd spend all my free time looksmaxxing and looking for a partner. It‚Äôs not a trivial task. I offered my closest friends in SF over $500k if they introduced me to my future wife but no one could even think of a single woman they knew who was single. I wasn‚Äôt being facetious - I was 100% willing to offer that matchmaker fee but they knew there was no one. Thus, I had to move and here I am.</p><p>It‚Äôs better but hard to find someone who is marriage material here. Also, the standards women have here are outlandish given what they bring to the table. I‚Äôve met several women who don‚Äôt even make $100k who demand a millionaire husband - lol. That level of delusion is just commonplace.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40505959"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40505959" href="https://news.ycombinator.com/vote?id=40505959&amp;how=up&amp;goto=item%3Fid%3D40500429"></a></center>    </td><td><br><div><p>Gardening and Dog training. You can get pretty deep into gardening, it's quite a rabbit hole, when you go into hydroponics and scientific approach.</p><p>For dog training, most people have no idea how to treat their animals (lots of shitty "folk wisdom" and pseudoscience in that area), so I would be doing both them and their owners a service.</p><p>Would probably run a dog-retreat and charge enough for some beer money, but that's it.</p><p>&gt; would you contribute towards making society more rational, healthy, and well-coordinated?</p><p>Can't really do that, unless society is willing to do so themselves. It's hard enough to change 1 person's mind on an issue, and nearly impossible to help someone who doesn't want the help.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40501612"><td></td></tr>
            </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wasmi v0.32: WebAssembly interpreter is now faster than ever (134 pts)]]></title>
            <link>https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/</link>
            <guid>40499130</guid>
            <pubDate>Tue, 28 May 2024 10:06:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/">https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/</a>, See on <a href="https://news.ycombinator.com/item?id=40499130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>After many months of research, development and QA, Wasmi‚Äôs most significant update ever is finally ready for production use.</p><p><a href="https://github.com/wasmi-labs/wasmi">Wasmi</a> is an efficient and versatile <a href="https://webassembly.org/">WebAssembly</a> (Wasm) interpreter with a focus on embedded environments. It is an excellent choice for plugin systems, cloud hosts and as smart contract execution engine.</p><p>Wasmi intentionally mirrors the Wasmtime API on a best-effort basis, making it an ideal drop-in replacement or prototyping runtime.</p><blockquote><p>Install <a href="https://crates.io/crates/wasmi_cli">Wasmi‚Äôs CLI tool</a> via <code>cargo install wasmi_cli</code> or use it as library via the <a href="https://crates.io/crates/wasmi"><code>wasmi</code> crate</a>.</p></blockquote><p>Wasmi v0.32 comes with a new execution engine that utilizes register-based bytecode enhancing its execution performance by a factor of up to 5.
Additionally, its startup performance has been improved by several orders of magnitudes thanks to lazy compilation and other new techniques.</p><p>The <a href="https://github.com/wasmi-labs/wasmi/releases/tag/v0.32.0">changelog for v0.32</a> is huge and the following sections will present the most significant changes.</p><h2 id="startup-performance">Startup Performance</h2><p>Wasmi is a <em>rewriting interpreter</em>, meaning that it rewrites the incoming WebAssembly bytecode into Wasmi‚Äôs own internal bytecode that is geared towards efficient execution performance.</p><p>This re-writing is what we call <em>compilation</em> or <em>translation</em> in an interpreter. This is not to be confused with compiling the Wasmi interpreter itself.</p><h3 id="why-is-translation-speed-important-for-wasmi">Why is translation speed important for Wasmi?</h3><p>Fast translation enables a fast startup time which is the time spent until the first instruction is executed.</p><p>As an interpreter, Wasmi is naturally optimized for fast startup times, making it well-suited for translation-intensive workloads where the time required to translate a Wasm binary exceeds the time needed to execute it.<br>Conversely, compute-intensive workloads, where execution time surpasses translation time, are better handled by JIT-based Wasm runtimes such as <a href="https://github.com/bytecodealliance/wasmtime">Wasmtime</a>, <a href="https://github.com/bytecodealliance/wasm-micro-runtime">WAMR</a>, or <a href="https://github.com/wasmerio/wasmer">Wasmer</a>. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><h3 id="lazy-translation">Lazy Translation</h3><p>Translation can be costly, especially with the new register-based bytecode. To address this, lazy translation has been implemented, translating only the parts of the Wasm binary necessary for execution.</p><p>Wasmi supports 3 different modes of translation:</p><ul><li><code>Eager</code>: Code is eagerly validated and eagerly translated ahead of time.<ul><li><strong>Note:</strong> This is the default mode for Wasmi v0.32.</li></ul></li><li><code>Lazy</code>: Code is lazily translated and lazily validated.<ul><li><strong>Note:</strong> One downside is that this allows for partially validated Wasm modules which are controversial within the wider Wasm community. <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></li></ul></li><li><code>LazyTranslation</code>: Code is lazily translated but eagerly validated.<ul><li><strong>Note:</strong> While slower than <code>Lazy</code> this fixes the problem with partially validated Wasm modules.</li></ul></li></ul><h4 id="usage-as-library">Usage as Library</h4><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span> <span>mut</span> c <span>=</span> wasmi::Config::default();
</span></span><span><span>c.compilation_mode(wasmi::CompilationMode::Lazy);
</span></span></code></pre></div><h4 id="usage-in-wasmis-cli">Usage in Wasmi‚Äôs CLI</h4><p>Wasmi CLI now supports the command-line option <code>--compilation-mode=&lt;mode&gt;</code> where <code>&lt;mode&gt;</code> is one of <code>eager</code>, <code>lazy</code>, or <code>lazy-translation</code>.</p><h3 id="unchecked-translation">Unchecked Translation</h3><p>Wasmi validates the Wasm binary which accounts for roughly 20-40% of the total time spent during the startup phase.
However, some users might want to skip Wasm validation altogether since they know ahead of time that used Wasm binaries are pre-validated. This is now possible via the <code>unsafe fn Module::new_unchecked</code> API.</p><h3 id="non-streaming-translation">Non-streaming Translation</h3><p>Wasmi v0.31 and earlier always used streaming translation to process their Wasm input. However, in practice most users never even made use of this, so in v0.32 Wasmi uses non-streaming translation by default which gives it yet another nice performance win.</p><blockquote><p>Users who actually want to use streaming translation simply can use the new <code>Module::new_streaming</code> API for their needs.</p></blockquote><h3 id="linker-caching">Linker Caching</h3><p>The Wasmi <code>Linker</code> is used to define the set of host functions that a Wasm binary can use to communicate with the host. Oftentimes, dozens of host functions are defined, which can quickly become costly.</p><p>To address this, Wasmi now offers a <code>LinkerBuilder</code>, which allows to efficiently instantiate new <code>Linker</code>s after the initial setup. <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup></p><p>Benchmarks with 50 defined host functions have demonstrated a 120x speedup using this approach.</p><h2 id="benchmarks">Benchmarks</h2><p>By combining all of the techniques above it is possible to speed up the startup time of Wasmi by several orders of magnitudes compared to the previous Wasmi v0.31.</p><p>The newest versions of all Wasm runtimes have been used at the time of writing this article. <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.</p><blockquote><p>Currently, Winch only supports <code>x86_64</code> platforms and therefore was only tested on those systems.</p></blockquote><h3 id="erc-20---7kb">ERC-20 - 7KB</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/erc20.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/erc20.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/erc20.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/erc20.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/erc20.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/erc20.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/erc20.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/erc20.svg" alt=""></a></td></tr></tbody></table><h3 id="argon2---61kb">Argon2 - 61KB</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/argon2.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/argon2.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/argon2.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/argon2.svg" alt=""></a></td></tr></tbody></table><h3 id="bz---147kb">BZ - 147KB</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/bz2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/bz2.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/bz2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/bz2.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/bz2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/bz2.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/bz2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/bz2.svg" alt=""></a></td></tr></tbody></table><h3 id="pulldown-cmark---16mb">Pulldown-Cmark - 1.6MB</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/pulldown-cmark.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/pulldown-cmark.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/pulldown-cmark.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/pulldown-cmark.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/pulldown-cmark.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/pulldown-cmark.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/pulldown-cmark.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/pulldown-cmark.svg" alt=""></a></td></tr></tbody></table><h3 id="spidermonkey---42mb">Spidermonkey - 4.2MB</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/spidermonkey.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/spidermonkey.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/spidermonkey.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/spidermonkey.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/spidermonkey.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/spidermonkey.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/spidermonkey.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/spidermonkey.svg" alt=""></a></td></tr></tbody></table><h3 id="ffmpeg---193mb">FFMPEG - 19.3MB</h3><blockquote><p><strong>Note:</strong> Wasmtime (Cranelift) timed out and
Stitch failed to compile <code>ffmpeg.wasm</code>.</p></blockquote><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/ffmpeg.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/compile/ffmpeg.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/ffmpeg.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/compile/ffmpeg.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/ffmpeg.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/compile/ffmpeg.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/ffmpeg.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/compile/ffmpeg.svg" alt=""></a></td></tr></tbody></table><h3 id="translation-benchmarks-conclusion">Translation Benchmarks: Conclusion</h3><p>Wasmi and Wasm3 perform best by far due to their lazy compilation capabilities. As expected, optimizing JIT-based Wasm runtimes like Wasmtime and Wasmer perform worse in this context. Single-pass JITs, which are designed for fast startup, such as <a href="https://crates.io/crates/wasmtime-winch">Winch</a> and <a href="https://crates.io/crates/wasmer-compiler-singlepass">Wasmer Singlepass</a>, are also significantly slower. Despite also using lazy translation, <a href="https://github.com/makepad/stitch">Stitch</a>‚Äôs translation performance is not ideal. However, it is important to note that both Winch and Stitch are still in an experimental phase of their development and improvements are to be expected.</p><h2 id="execution-speed">Execution Speed</h2><p>For an execution engine, the speed of computation is naturally of paramount importance. Unfortunately, the old Wasmi v0.31 left much to be desired in this regard.</p><h2 id="register-based-bytecode">Register-Based Bytecode</h2><p>The old Wasmi v0.31 internally uses a stack-based intermediate representation (IR) to drive execution. This IR is similar to WebAssembly bytecode and thus allows for fast translation times.</p><p>Stack-based IRs generally use more instructions to represent the same problem as register-based IRs. <sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> However, the performance of interpreters is mostly dictated by the dispatch of instructions. Hence, it is usually a good tradeoff to execute fewer instructions even if every executed instruction is more complex. <sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup></p><p>This is why starting with version 0.32 Wasmi now uses a register-based IR to drive its execution.</p><h2 id="memory-consumption">Memory Consumption</h2><p>The new register-based IR was carefully designed to enhance execution performance and to minimize memory usage. As the vast majority of a Wasm binary is comprised of encoded instructions, this substantially decreases memory usage and enhances cache efficiency when executing Wasm through Wasmi. <sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup></p><h2 id="benchmarks-1">Benchmarks</h2><p>The newest versions of all Wasm runtimes have been used at the time of writing this article. <sup id="fnref1:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.</p><h3 id="fibonacci-iterative---compute-intense">Fibonacci (Iterative) - Compute Intense</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/fib.iterative.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/fib.iterative.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/fib.iterative.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/fib.iterative.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/fib.iterative.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/fib.iterative.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/fib.iterative.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/fib.iterative.svg" alt=""></a></td></tr></tbody></table><h3 id="fibonacci-recursive---call-intense">Fibonacci (Recursive) - Call Intense</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/fib.recursive.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/fib.recursive.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/fib.recursive.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/fib.recursive.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/fib.recursive.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/fib.recursive.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/fib.recursive.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/fib.recursive.svg" alt=""></a></td></tr></tbody></table><p>Wasmi v0.32 has not significantly improved over v0.31 in this test case. This is partly because Wasmi v0.31 was already comparatively fast and that the new register-based bytecode favors compute-intense workloads over call-intense ones. This usually is a good tradeoff since most Wasm producers (such as LLVM) produce compute intense workloads due to aggressive inlining.</p><h3 id="primes---balanced">Primes - Balanced</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/primes.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/primes.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/primes.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/primes.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/primes.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/primes.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/primes.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/primes.svg" alt=""></a></td></tr></tbody></table><h3 id="matrix-multiplication---memory-intense">Matrix Multiplication - Memory Intense</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/matmul.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/matmul.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/matmul.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/matmul.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/matmul.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/matmul.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/matmul.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/matmul.svg" alt=""></a></td></tr></tbody></table><p>Interestingly, Wasmer (Singlepass) seems to have some trouble on Apple silicon being even slower than some of the interpreters.</p><h3 id="argon---compute-hash">Argon - Compute Hash</h3><blockquote><p><strong>Note:</strong> Stitch and Winch could not execute the <code>argon2.wasm</code> test case.</p></blockquote><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-epyc-7763/execute/argon2.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/linux-amd-threadripper-3990x/execute/argon2.svg" alt=""></a></td></tr><tr><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/macos-m2/execute/argon2.svg" alt=""></a></td><td><a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/argon2.svg"><img loading="lazy" src="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/benches/windows-intel-i7-14700k/execute/argon2.svg" alt=""></a></td></tr></tbody></table><p>The following table shows Coremark scores for the Wasm interpreters by CPU. <sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup></p><table><thead><tr><th></th><th>AMD Epyc 7763</th><th>AMD Threadripper 3990x</th><th>Apple M2 Pro</th><th>Intel i7 14700K</th></tr></thead><tbody><tr><td>Wasmi v0.31</td><td>657</td><td>944</td><td>884</td><td>1759</td></tr><tr><td>Wasmi v0.32</td><td><strong>1457</strong></td><td>1779</td><td>1577</td><td>2979</td></tr><tr><td>Tinywasm</td><td>235</td><td>339</td><td>592</td><td>772</td></tr><tr><td>Wasm3</td><td>1309</td><td>1999</td><td>2931</td><td>3831</td></tr><tr><td>Stitch</td><td>1390</td><td><strong>2187</strong></td><td><strong>3056</strong></td><td><strong>4892</strong></td></tr></tbody></table><h3 id="execution-benchmarks-conclusion">Execution Benchmarks: Conclusion</h3><p>Wasmi is especially strong on AMD server chips and lacks behind on Apple silicon. An explanation for this could be the difference in the technique for instruction dispatch being used. <sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup></p><p>The Stitch interpreter performs really well. The reason likely is that Stitch encourages the LLVM optimizer to produce tail calls for its instruction dispatch, despite Rust not supporting them. Due to various downsides this design decision was discussed and dismissed during the development of Wasmi v0.32. <sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup> <sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup> Given Stitch‚Äôs impressive execution performance especially on Apple silicon and Windows platforms those decisions should be reevaluated again.</p><p>Confusingly the great results for Wasmi on the test cases for the Intel i7 14700K are not reflected by its Coremark score. This probably is because every test case, including Coremark, is biased towards some kinds of workloads to some degree.</p><h2 id="benchmark-suite">Benchmark Suite</h2><p>The benchmarks and plots above have been gathered and generated using the <a href="https://github.com/wasmi-labs/wasmi-benchmarks"><code>wasmi-benchmarks</code></a> repository.
The reader is encouraged to run the benchmarks and plot the results on their own computer to confirm or disprove the claims. Usage instructions can be found in the <a href="https://github.com/wasmi-labs/wasmi-benchmarks?tab=readme-ov-file#plotting"><code>wasmi-benchmarks</code>‚Äôs <code>README.md</code></a>.</p><p>Contributions adding more Wasm runtimes, improving the plots or to add new test cases are welcome!</p><h2 id="summary--outlook">Summary &amp; Outlook</h2><p>This article displayed the highlights of the new Wasmi version 0.32 and demonstrated the significant improvements in both startup and execution performance through various test cases.</p><p>With this new major update Wasmi now has a solid foundation for future development.
Many <a href="https://github.com/WebAssembly/proposals">WebAssembly proposals</a> such as the <code>multi-memory</code>, <code>simd</code> and <code>gc</code> proposals that have been put on hold for the development of Wasmi v0.32 are awaiting their implementation.</p><p>The promising results especially on the AMD server chips are a decent indicator that
Wasmi has great potential.
The performance of Wasmi on Apple silicon will be improved in future releases.</p><p>Plans are underway to implement the <a href="https://github.com/WebAssembly/wasm-c-api">Wasm C-API</a>, enabling various ecosystems that can interface with C to use Wasmi as a library.</p><p>Wasmi will continue to solidify its position as an efficient and versatile Wasm interpreter
with a fantastic startup performance and low memory consumption especially suited for embedded environments.</p><h2 id="special-thanks">Special Thanks</h2><ul><li>First and foremost, I want to thank <a href="https://www.parity.io/">Parity Technologies</a> for financing and supporting the development of Wasmi for such a long time and for allowing Wasmi to become an independent project.</li></ul><ul><li>I want to commend the members of the <a href="https://bytecodealliance.org/">Bytecode Alliance</a> for their outstanding efforts in shaping the WebAssembly specification and ecosystem. Their contributions, among others, include runtimes such as <a href="https://github.com/bytecodealliance/wasmtime">Wasmtime</a> and <a href="https://github.com/bytecodealliance/wasm-micro-runtime">WAMR</a> as well as <a href="https://github.com/bytecodealliance/wasm-tools">advanced WebAssembly tooling</a>.</li></ul><ul><li>Additionally, I want to extend my gratitude to <a href="https://github.com/OLUWAMUYIWA">OLUWAMUYIWA</a>, who dedicated their time and effort to implement WASI preview1 support for Wasmi ‚Äî which was absolutely amazing!</li></ul><ul><li>Furthermore, I want to thank <a href="https://github.com/yamt">yamt</a>, who inspired me with their Wasm runtime benchmarking platform. I highly recommend checking out their <a href="https://github.com/yamt/toywasm">toywasm</a> Wasm interpreter!</li></ul><ul><li>Finally, I would like to acknowledge <a href="https://github.com/Neopallium">Neopallium</a> for the thought-provoking discussions and experiments we shared about efficient interpreter dispatching techniques in Rust. I highly recommend checking out one of his Wasm experiments, <a href="https://github.com/Neopallium/s1vm">s1vm</a>.</li></ul></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What You Shouldn't Know About Quantum Computers (122 pts)]]></title>
            <link>https://arxiv.org/abs/2405.15838</link>
            <guid>40498933</guid>
            <pubDate>Tue, 28 May 2024 09:23:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2405.15838">https://arxiv.org/abs/2405.15838</a>, See on <a href="https://news.ycombinator.com/item?id=40498933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>
      <h2>Physics &gt; Physics and Society</h2>
    </p>

    <p><strong>arXiv:2405.15838</strong> (physics)
    </p>

<div id="content-inner">
    <p>
  [Submitted on 24 May 2024]</p>
    
                
    <p><a href="https://arxiv.org/pdf/2405.15838">View PDF</a></p><blockquote>
            <span>Abstract:</span>Whether you're a CEO strategizing the future of your company, a tech enthusiast debating your next career move, a high school teacher eager to enlighten your students, or simply tired of the relentless quantum hype, this is crafted just for you. Cutting through the complex jargon to deliver the straight facts on quantum computing, peeling away the layers of mystique to reveal the true potential and limitations of this groundbreaking technology. Prepare to have your misconceptions challenged, and your understanding deepened in this clear-eyed view of the quantum future, written to inform and inspire readers across the spectrum of curiosity and need.
    </blockquote>

    <!--CONTEXT-->
    <div>
      <table summary="Additional metadata">        <tbody><tr>
          <td>Comments:</td>
          <td>With a foreword by Scott Aaronson</td>
        </tr>
<tr>
          <td>Subjects:</td>
          <td>
            <span>Physics and Society (physics.soc-ph)</span>; Popular Physics (physics.pop-ph); Quantum Physics (quant-ph)</td>
        </tr><tr>
          <td>Cite as:</td>
          <td><span><a href="https://arxiv.org/abs/2405.15838">arXiv:2405.15838</a> [physics.soc-ph]</span></td>
        </tr>
        <tr>
          <td>&nbsp;</td>
          <td>(or <span>
              <a href="https://arxiv.org/abs/2405.15838v1">arXiv:2405.15838v1</a> [physics.soc-ph]</span> for this version)
          </td>
        </tr></tbody></table>
    </div>
  </div>
    <div>
      <h2>Submission history</h2><p> From: Christopher Ferrie [<a href="https://arxiv.org/show-email/acee1c09/2405.15838">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 24 May 2024 12:44:12 UTC (833 KB)<br>
</p></div>
  </div><div id="labstabs"><p>
    <label for="tabone">Bibliographic Tools</label></p><div>
      <h2>Bibliographic and Citation Tools</h2>
      <div>
          <p><label>
              
              <span></span>
              <span>Bibliographic Explorer Toggle</span>
            </label>
          </p>
          
        </div>
        
        
        
    </div>


    <p>
    <label for="tabtwo">Code, Data, Media</label></p><div>
      <h2>Code, Data and Media Associated with this Article</h2>
      

      
      
      
      
      
      
    </div>


      <p>
      <label for="labstabs-demos-input" id="labstabs-demos-label">Demos</label></p><div>
        <h2>Demos</h2>
        
        
        
        
      </div>
      <p>
      <label for="tabfour">Related Papers</label></p><div>
        <h2>Recommenders and Search Tools</h2>
        
        
        
        
        
        
      </div>

      <p>
      <label for="tabfive">
        About arXivLabs
      </label></p><div>
            <h2>arXivLabs: experimental projects with community collaborators</h2>
            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>
            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>
            <p>Have an idea for a project that will add value for arXiv's community? <a href="https://info.arxiv.org/labs/index.html"><strong>Learn more about arXivLabs</strong></a>.</p>
          </div>

    </div></div>]]></description>
        </item>
    </channel>
</rss>