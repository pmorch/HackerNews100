<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 07 Jul 2023 10:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Openworm ‚Äì a biological simulation of a worm with 302 neurons (150 pts)]]></title>
            <link>https://github.com/openworm/OpenWorm</link>
            <guid>36628258</guid>
            <pubDate>Fri, 07 Jul 2023 07:08:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/openworm/OpenWorm">https://github.com/openworm/OpenWorm</a>, See on <a href="https://news.ycombinator.com/item?id=36628258">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/698a0995df7f2e64f814087d34a01cc056cdafc7f7b675e407062dae1f53da97/687474703a2f2f7777772e6f70656e776f726d2e6f72672f696d672f4f70656e576f726d4c6f676f2e706e67"><img src="https://camo.githubusercontent.com/698a0995df7f2e64f814087d34a01cc056cdafc7f7b675e407062dae1f53da97/687474703a2f2f7777772e6f70656e776f726d2e6f72672f696d672f4f70656e576f726d4c6f676f2e706e67" alt="OpenWorm" data-canonical-src="http://www.openworm.org/img/OpenWormLogo.png"></a></p>
<p dir="auto"><a href="https://github.com/openworm/OpenWorm/actions/workflows/docker-image.yml"><img src="https://github.com/openworm/OpenWorm/actions/workflows/docker-image.yml/badge.svg" alt="Docker Image CI"></a></p>
<h2 tabindex="-1" dir="auto">About <strong>OpenWorm</strong></h2>
<p dir="auto"><a href="http://openworm.org/" rel="nofollow">OpenWorm</a> aims to build the first comprehensive computational model of <em>Caenorhabditis elegans</em> (<em>C. elegans</em>), a microscopic roundworm. With only a thousand cells, it solves basic problems such as feeding, mate-finding and predator avoidance. Despite being extremely well-studied in biology, a deep, principled understanding of the biology of this organism remains elusive.</p>
<p dir="auto">We are using a bottom-up approach, aimed at observing the worm behaviour emerge from a simulation of data derived from scientific experiments carried out over the past decade. To do so, we are incorporating the data available from the scientific community into software models. We are also forging new collaborations with universities and research institutes to collect data that fill in the gaps.</p>
<p dir="auto">You can earn a badge with us simply by trying out this package! Click on the image below to get started.
<a href="https://www.badgelist.com/OpenWorm/OpenWorm-Docker-Apprentice" rel="nofollow"><img src="https://raw.githubusercontent.com/openworm/OpenWorm/master/img/ow-docker-badge.png" alt="OpenWorm Docker Badge"></a></p>
<h2 tabindex="-1" dir="auto">Quickstart</h2>
<p dir="auto">We have put together a <a href="https://hub.docker.com/r/openworm/openworm" rel="nofollow">Docker container</a> that pulls together the major components of our simulation and runs it on your machine.  When you get it all running it does the following:</p>
<ol dir="auto">
<li>Run our nervous system model, known as <a href="https://github.com/openworm/c302">c302</a>, on your computer.</li>
<li>In parallel, run our 3D worm body model, known as <a href="https://github.com/openworm/sibernetic">Sibernetic</a>, on your computer, using the output of the nervous system model.</li>
<li>Produce graphs from the nervous system and body model that demonstrate its behavior on your computer for you to inspect.</li>
<li>Produce a movie showing the output of the body model.</li>
</ol>
<p dir="auto"><strong>Example Output</strong></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/openworm/OpenWorm/master/img/worm-crawling.gif"><img src="https://raw.githubusercontent.com/openworm/OpenWorm/master/img/worm-crawling.gif" alt="Worm Crawling" data-animated-image=""></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/openworm/OpenWorm/master/img/muscle-activity.png"><img src="https://raw.githubusercontent.com/openworm/OpenWorm/master/img/muscle-activity.png" width="250"></a><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/openworm/OpenWorm/master/img/neuron-activity.png"><img src="https://raw.githubusercontent.com/openworm/OpenWorm/master/img/neuron-activity.png" width="350"></a></p>
<p dir="auto"><strong>NOTE</strong>: Running the simulation for the full amount of time would produce content like the above.  However, in order to run in a reasonable amount of time, <strong>the default run time for the simulation is limited</strong>.  As such, you will see only a partial output, equivalent to about 5% of run time, compared to the examples above.  To extend the run time, use the <code>-d</code> argument as described below.</p>
<p dir="auto"><strong>Installation</strong></p>
<p dir="auto">Pre-requisites:</p>
<ol dir="auto">
<li>You should have at least 60 GB of free space on your machine and at least 2GB of RAM</li>
<li>You should be able to clone git repositories on your machine. <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git" rel="nofollow">Install git</a>, or <a href="https://desktop.github.com/">this GUI</a> may be useful.</li>
</ol>
<p dir="auto">To Install:</p>
<ol dir="auto">
<li>Install <a href="http://docker.com/" rel="nofollow">Docker</a> on your system.</li>
<li>If your system does not have enough free space, you can use
an external hard disk.  On MacOS X, the location for image storage
can be specified in the <a href="https://forums.docker.com/t/change-docker-image-directory-for-mac/18891/15" rel="nofollow">Advanced Tab</a> in Preferences.  See <a href="https://forums.docker.com/t/how-do-i-change-the-docker-image-installation-directory/1169/18" rel="nofollow">this thread</a>
in addition for Linux instructions.</li>
</ol>
<p dir="auto"><strong>Running</strong></p>
<ol dir="auto">
<li>Ensure the Docker daemon is running in the background (on MacOS/Windows there should be an icon with the Docker whale logo showing in the menu bar/system tray).</li>
<li>Open a terminal and run: <code>git clone http://github.com/openworm/openworm</code>; <code>cd openworm</code></li>
<li>Optional: Run <code>./build.sh</code> (or <code>build.cmd</code> on Windows). If you skip this step, it will download the latest released Docker image from the <a href="https://hub.docker.com/r/openworm/openworm" rel="nofollow">OpenWorm Docker hub</a>.</li>
<li>Run <code>./run.sh</code> (or <code>run.cmd</code> on Windows).</li>
<li>About 5-10 minutes of output will display on the screen as the steps run.</li>
<li>The simulation will end.  Run <code>stop.sh</code> (<code>stop.cmd</code> on Windows) on your system to clean up the running container.</li>
<li>Inspect the output in the <code>output</code> directory on your local machine.</li>
</ol>
<p dir="auto"><strong>Advanced</strong></p>
<p dir="auto"><em><strong>Arguments</strong></em></p>
<ul dir="auto">
<li>-d [num] : Use to modify the duration of the simulation in milliseconds.  Default is 15.  Use 5000 to run for time to make the full movie above (i.e. 5 seconds).</li>
</ul>
<p dir="auto"><em><strong>Other things to try</strong></em></p>
<ul dir="auto">
<li>Open a terminal and run <code>./run-shell-only.sh</code> (or <code>run-shell-only.cmd</code> on Windows).  This will let you log into the container before it has run <code>master_openworm.py</code>.  From here you can inspect the internals of the various checked out code bases and installed systems and modify things. Afterwards you'll still need to run <code>./stop.sh</code> to clean up.</li>
<li>If you wish to modify what gets installed, you should modify <code>Dockerfile</code>.  If you want to modify what runs, you should modify <code>master_openworm.py</code>.  Either way you will need to run <code>build.sh</code> in order to rebuild the image locally.  Afterwards you can run normally.</li>
</ul>
<h3 tabindex="-1" dir="auto">FAQ</h3>
<h4 tabindex="-1" dir="auto"><strong>What is the Docker container?</strong></h4>
<p dir="auto">The Docker container is a self-contained environment in which you can run OpenWorm simulations.  It's fully set up to get you started by following the steps above. At the moment,
it runs simulations and produces visualizations for you, but these visualizations must be viewed outside of the Docker container. While you do not need to know
much about Docker to use OpenWorm, if you are planning on working extensively with the platform, you may benefit
from understanding some basics. <a href="https://docker-curriculum.com/" rel="nofollow">Docker Curriculum</a>
is an excellent tutorial for beginners that is straightforward to work through (Sections 1 - 2.5 are plenty sufficient).</p>
<h4 tabindex="-1" dir="auto"><strong>Is it possible to modify the simulation without having to run <code>build.sh</code>?</strong></h4>
<p dir="auto">Yes, but it is marginally more complex.  The easiest way is to modify anything in the Docker container once you are inside of it - it will work just like a bash shell.  If you want to modify any code in the container, you'll need to use an editor that runs in the terminal, like nano.  Once you've modified something in the container, you don't need to re-build.  However, if you run <code>stop.sh</code> once you exit, those changes will be gone.</p>
<h4 tabindex="-1" dir="auto"><strong>How do I access more data than what is already output?</strong></h4>
<p dir="auto">The simulation by default outputs only a few figures and movies to your home system (that is, outside of the Docker container).  If you want to access the entire output of the simulation, you will need to copy it from the Docker container.</p>
<p dir="auto">For example, say you want to extract the worm motion data.  This is contained in the file <code>worm_motion_log.txt</code>, which is found in the <code>/home/ow/sibernetic/simulations/[SPECIFIC_TIMESTAMPED_DIRECTORY]/worm_motion_log.txt</code>.  The directory <code>[SPECIFIC_TIMESTAMPED_DIRECTORY]</code> will have a name like <code>C2_FW_2018_02-12_18-36-32</code>, and its name can be found by checking the <code>output</code> directory.  This is actually the main output directory for the simulation, and contains all output, including cell modelling and worm movement.</p>
<p dir="auto">Once the simulation ends and you exit the container with <code>exit</code>, but before you run <code>stop.sh</code>, run the following command from the openworm-docker-master folder:</p>
<p dir="auto"><code>docker cp openworm:/home/ow/sibernetic/simulations/[SPECIFIC_TIMESTAMPED_DIRECTORY]/worm_motion_log.txt ./worm_motion_log.txt</code></p>
<p dir="auto">This will copy the file from the Docker container, whose default name is <code>openworm</code>.  <strong>It is crucial that you do not run <code>stop.sh</code> before trying to get your data out (see below)</strong></p>
<h4 tabindex="-1" dir="auto"><strong>What is the difference between <code>exit</code> and <code>stop.sh</code>?</strong></h4>
<p dir="auto">When you are in the Docker Container <code>openworm</code>, and are done interacting with it, you type <code>exit</code> to return to your system's shell.  This stops execution of anything in the container, and that container's status is now <code>Exited</code>.  If you try to re-start the process using <code>run-shell-only.sh</code>, you will get an error saying that the container already exists.  You can choose, at this point, to run <code>stop.sh</code>.  Doing so will remove the container and any files associated with it, allowing you to run a new simulation.  However, if you don't want to remove that container, you will instead want to re-enter it.</p>
<h4 tabindex="-1" dir="auto"><strong>How do I enter a container I just exited?</strong></h4>
<p dir="auto">If you run <code>stop.sh</code> you'll delete your data and reset the container for a new run.  If, however, you don't want to do that, you can re-enter the Docker container like this:</p>
<div data-snippet-clipboard-copy-content="docker start openworm                 # Restarts the container
docker exec -it openworm /bin/bash    # Runs bash inside the container"><pre><code>docker start openworm                 # Restarts the container
docker exec -it openworm /bin/bash    # Runs bash inside the container
</code></pre></div>
<p dir="auto">This tells Docker to start the container, to <em>execute</em> commands (<code>exec</code>) with an <em>interactive, tty</em> (<code>-it</code>)  bash (<code>bash</code>) shell in the container <code>openworm</code>.</p>
<p dir="auto">You'll be able to interact with the container as before.</p>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<p dir="auto">to find out more about OpenWorm, please see the documentation at <a href="http://docs.openworm.org/" rel="nofollow">http://docs.openworm.org</a> or <a href="http://bit.ly/OpenWormVolunteer" rel="nofollow">join us on Slack</a>.</p>
<p dir="auto">This repository also contains project-wide tracking via high-level <a href="https://github.com/openworm/OpenWorm/issues">issues</a> and <a href="https://github.com/openworm/OpenWorm/milestones">milestones</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: List (OPML) of Hacker News Users Personal Blogs (147 pts)]]></title>
            <link>https://github.com/outcoldman/hackernews-personal-blogs</link>
            <guid>36627112</guid>
            <pubDate>Fri, 07 Jul 2023 04:25:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/outcoldman/hackernews-personal-blogs">https://github.com/outcoldman/hackernews-personal-blogs</a>, See on <a href="https://news.ycombinator.com/item?id=36627112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><a href="https://news.ycombinator.com/item?id=36575081" rel="nofollow">Ask HN: Could you share your personal blog here?</a></h2>
<h2 tabindex="-1" dir="auto">Description</h2>
<p dir="auto">This is a collection of personal blogs from the <a href="https://news.ycombinator.com/item?id=36575081" rel="nofollow">Ask HN: Could you share your personal blog here?</a>
thread on Hacker News, prepared as OPML for easy import into your favorite RSS reader.</p>
<h2 tabindex="-1" dir="auto">Usage</h2>
<p dir="auto">Download <a href="https://github.com/outcoldman/hackernews-personal-blogs/blob/master/list.opml">list.opml</a> and import it into your favorite RSS reader.</p>
<p dir="auto">When building this list, I have ignored any user with less or equal to 100 karma, which means I might have missed some
interesting blogs, but at the same time I wanted to ignore spam or throwaway accounts.</p>
<p dir="auto">The list is sorted by the user karma on Hacker News, so the first blogs are from users with the highest karma.</p>
<p dir="auto">You can modify the list in your editor to include only the top 10 or 100 blogs, or to remove some blogs you are not interested in.</p>
<p dir="auto">Not from all comments I was able to extract a blog URL, so the list is not complete. I just parse the correct recocognized URLs
from comments.</p>
<p dir="auto">Not all blogs have RSS feeds, or the RSS feeds aren't included in the <code>&lt;link rel="alternate" type="application/rss+xml" href="..."&gt;</code>
or <code>&lt;link rel="alternate" type="application/atom+xml" href="..."&gt;</code> tag, so I might have missed some blogs.</p>
<p dir="auto">Anyway, we got more than 600 blogs, so I think it is a good start.</p>
<p dir="auto">You can find the output of the latest run at <a href="https://github.com/outcoldman/hackernews-personal-blogs/blob/master/console.log">console.log</a>.</p>
<h2 tabindex="-1" dir="auto">Regenerate list</h2>
<p dir="auto">As easy as running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="go run ./main.go | tee > console.log"><pre>go run ./main.go <span>|</span> tee <span>&gt;</span> console.log</pre></div>
<p dir="auto">It is going to take a while, as it needs to fetch the karma for each user, and then fetch the RSS feed for each blog.</p>
<h2 tabindex="-1" dir="auto">Author</h2>
<p dir="auto"><a href="https://www.outcoldman.com/" rel="nofollow">outcoldman</a></p>
<ul dir="auto">
<li><a href="https://twitter.com/outcoldman" rel="nofollow">Twitter</a></li>
<li><a href="https://github.com/outcoldman">GitHub</a></li>
</ul>
<h2 tabindex="-1" dir="auto">LICENSE</h2>
<p dir="auto"><a href="https://github.com/outcoldman/hackernews-personal-blogs/blob/master/LICENSE">MIT</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[French Assembly to allow remote police surveillance via phone cameras and mics (107 pts)]]></title>
            <link>https://www.engadget.com/french-assembly-passes-bill-allowing-police-to-remotely-activate-phone-cameras-and-microphones-for-surveillance-210539401.html</link>
            <guid>36626966</guid>
            <pubDate>Fri, 07 Jul 2023 04:06:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/french-assembly-passes-bill-allowing-police-to-remotely-activate-phone-cameras-and-microphones-for-surveillance-210539401.html">https://www.engadget.com/french-assembly-passes-bill-allowing-police-to-remotely-activate-phone-cameras-and-microphones-for-surveillance-210539401.html</a>, See on <a href="https://news.ycombinator.com/item?id=36626966">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>French law enforcement may soon have far-reaching authority to snoop on alleged criminals. Lawmakers in France's National Assembly have <a data-i13n="cpos:1;pos:1" href="https://www.lemonde.fr/en/france/article/2023/07/06/france-set-to-allow-police-to-spy-through-phones_6044269_7.html" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:1;pos:1;itc:0">passed</a> a bill that lets police surveil suspects by remotely activating cameras, microphones and GPS location systems on phones and other devices. A judge will have to approve use of the powers, and the recently amended bill forbids use against journalists, lawyers and other "sensitive professions," according to <em>Le Monde</em>. The measure is also meant to limit use to serious cases, and only for a maximum of six months. Geolocation would be limited to crimes that are punishable by at least five years in prison.</p>
<p>An earlier version of the bill passed the Senate, but the amendment will require that legislative body's approval before it can become law.</p>
<p>Civil liberties advocates are alarmed. The digital rights group La Quadrature du Net previously <a data-i13n="cpos:2;pos:1" href="https://www.laquadrature.net/2023/05/31/transformer-les-objets-connectes-en-mouchards-la-surenchere-securitaire-du-gouvernement/" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:2;pos:1;itc:0">pointed</a> out the potential for abuse. As the bill isn't clear about what constitutes a serious crime, there are fears the French government might use this to target environmental activists and others who aren't grave threats. The organization also notes that worrying security policies have a habit of expanding to less serious  crimes. Genetic registration was only used for sex offenders at first, La Quadrature says, but is now being used for most crimes.</p>
<p>The group further notes that the remote access may depend on security vulnerabilities. Police would be exploiting security holes instead of telling manufacturers how to patch those holes, La Quadrature says.</p>
<p>Justice Minister √âric Dupond-Moretti says the powers would only be used for "dozens" of cases per year, and that this was "far away" from the surveillance state of Orwell's <em>1984</em>. It will save lives, the politician argues.</p>
<p>The legislation comes as concerns about government device surveillance are growing. There's been a backlash against NSO Group, whose Pegasus spyware has allegedly been misused to spy on dissidents, activists and <a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/pegasus-spyware-found-on-phones-of-mexican-presidents-close-ally-154511274.html" data-ylk="elm:context_link;cpos:3;pos:1;itc:0">even politicians</a>. While the French bill is more focused, it's not exactly reassuring to those worried about government overreach.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky partners with Namecheap to power domains as usernames (178 pts)]]></title>
            <link>https://blueskyweb.xyz/blog/7-05-2023-namecheap</link>
            <guid>36626405</guid>
            <pubDate>Fri, 07 Jul 2023 02:43:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blueskyweb.xyz/blog/7-05-2023-namecheap">https://blueskyweb.xyz/blog/7-05-2023-namecheap</a>, See on <a href="https://news.ycombinator.com/item?id=36626405">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>We‚Äôre excited to announce a new feature that allows users to seamlessly purchase and manage domains directly through Bluesky.</strong> With this, you can easily set a custom domain as your Bluesky handle and much more.</p>
<p>On Bluesky and the AT Protocol, you can set domains that you own like <code>bsky.team</code> or <code>alice.lol</code> as your username. Typically, this requires buying a domain name from a registrar and configuring DNS records in their portal. We‚Äôre partnering with Namecheap, one of the leading domain name registrars, to let you pick out a domain name and link it to your Bluesky account in under a minute.</p>
<p>Namecheap, an ICANN accredited registrar that supports the Electronic Frontier Foundation and the open internet, has existed for over 22 years, and their reputation for dependable and affordable domain services aligns with our dedication to providing users with more choice in managing their digital presence.</p>
<p>Here‚Äôs what this means for you:</p>
<ul>
<li><strong>Custom Bluesky handle.</strong> Set your new domain as your username in Bluesky with just a few clicks.</li>
<li><strong>Easy domain purchasing.</strong> Simply type in your desired domain and browse the listed options to purchase your desired domain.</li>
<li><strong>Increased privacy.</strong> Bluesky offers an additional layer of privacy protection by acting as your domain registrar agent. We do not register your personal information with the WHOIS directory, which is a searchable database that holds information on domain ownership.</li>
<li><strong>Convenient domain management.</strong> Manage your domain settings and configurations within Bluesky.</li>
<li><strong>Email forwarding.</strong> Emails sent to your domain can be easily forwarded to an email address of your choice.</li>
<li><strong>URL forwarding</strong> Your domain will redirect to your Bluesky profile or URL of your choice.</li>
</ul>
<p>
Buying a domain through Bluesky does not lock you in ‚Äî you will still be able to transfer your domain away if you wish.</p>
<p>We‚Äôre excited to provide domain management as our first service. We‚Äôre also exploring other services that we can bundle to users to provide a more seamless experience. You can read more about our business plan <a href="https://blueskyweb.xyz/blog/7-05-2023-business-plan">here</a>, and more about why we use custom domains as handles <a href="https://blueskyweb.xyz/blog/4-28-2023-domain-handle-tutorial">here</a>.</p>
<h2>Great! How do I get started?</h2>
<p>Simply navigate to <a href="https://account.bsky.app/">https://account.bsky.app</a> and login with your Bluesky account. From there, type in your desired domain to view the available options.</p>
<p>Here‚Äôs a demo of this process:</p>
<p><a href="https://www.youtube.com/embed/MGpJjq186bc"><img src="https://blueskyweb.xyz/images/domains.gif" alt=""></a></p>
<p>If you have questions or need support, please email <a href="https://blueskyweb.xyz/cdn-cgi/l/email-protection#aedddbdedec1dcdaeeccddc5d780cfdede"><span data-cfemail="2b585e5b5b44595f6b49584052054a5b5b">[email&nbsp;protected]</span></a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Red flags in the Threads privacy policy (159 pts)]]></title>
            <link>https://qz.com/threads-meta-delayed-launch-eu-privacy-policy-concerns-1850609340</link>
            <guid>36625270</guid>
            <pubDate>Fri, 07 Jul 2023 00:22:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qz.com/threads-meta-delayed-launch-eu-privacy-policy-concerns-1850609340">https://qz.com/threads-meta-delayed-launch-eu-privacy-policy-concerns-1850609340</a>, See on <a href="https://news.ycombinator.com/item?id=36625270">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Threads, Meta‚Äôs competitor to Twitter, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://qz.com/threads-feels-just-like-twitter-and-not-always-in-a-goo-1850609075&quot;,{&quot;metric25&quot;:1}]]" href="https://qz.com/threads-feels-just-like-twitter-and-not-always-in-a-goo-1850609075" target="_blank" rel="noopener noreferrer">launched globally</a></span> today (July 6)‚Äîexcept in the European Union,<!-- --> where privacy concerns have put its <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theguardian.com/media/2023/jul/05/meta-delays-eu-launch-of-twitter-rival-threads-amid-uncertainty-over-personal-data-use&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theguardian.com/media/2023/jul/05/meta-delays-eu-launch-of-twitter-rival-threads-amid-uncertainty-over-personal-data-use" target="_blank" rel="noopener noreferrer">release on pause</a></span>. Two recent rulings in the EU are likely behind the delay.</p><div data-video-id="195056" data-monetizable="true" data-position="sidebar" data-video-title="The fight for equal pay continues" data-video-blog-id="1638532506" data-video-network="quartz" data-video-duration="338" data-playlist="195056,195181,195177" data-current="195056"><div><p>The fight for equal pay continues</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/195056/195056_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195056/195056_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195056/195056_720p.mp4" label="720p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/20496.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p><strong>Ruling 1:</strong> The European Court of Justice ruled on July 4 that Facebook cannot use ‚Äúlegitimate interest‚Äù to justify processing user data for advertising, effectively shooting down Meta‚Äôs <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://apnews.com/article/facebook-data-privacy-targeted-ads-europe-c373e233f5335aec6966ca6660702310&quot;,{&quot;metric25&quot;:1}]]" href="https://apnews.com/article/facebook-data-privacy-targeted-ads-europe-c373e233f5335aec6966ca6660702310" target="_blank" rel="noopener noreferrer">targeted ad</a></span> model. The court also ruled that EU watchdogs can factor in tech giants‚Äô violations of data privacy in antitrust investigations. </p><p><strong>Ruling 2:</strong> Meta has been barred from transferring Facebook user data from the EU to the US, and was <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://qz.com/meta-s-new-record-setting-eu-fine-is-nearly-as-big-as-i-1850461159&quot;,{&quot;metric25&quot;:1}]]" href="https://qz.com/meta-s-new-record-setting-eu-fine-is-nearly-as-big-as-i-1850461159" target="_blank" rel="noopener noreferrer">fined ‚Ç¨1.2 billion</a></span> ($1.3 billion), after a crackdown by privacy regulators in May. That ruling, in fact, could be the death knell for Facebook in the EU altogether. </p><p>Threads <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.independent.ie/business/technology/no-instagram-threads-app-in-the-eu-irish-dpc-says-metas-new-twitter-rival-wont-be-launched-here/a1927220337.html&quot;,{&quot;metric25&quot;:1}]]" href="https://www.independent.ie/business/technology/no-instagram-threads-app-in-the-eu-irish-dpc-says-metas-new-twitter-rival-wont-be-launched-here/a1927220337.html" target="_blank" rel="noopener noreferrer">has not been actively blocked</a></span> by Ireland‚Äôs Data Protection Commission (DPC), the EU‚Äôs lead privacy regulator, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.independent.ie/business/technology/no-instagram-threads-app-in-the-eu-irish-dpc-says-metas-new-twitter-rival-wont-be-launched-here/a1927220337.html&quot;,{&quot;metric25&quot;:1}]]" href="https://www.independent.ie/business/technology/no-instagram-threads-app-in-the-eu-irish-dpc-says-metas-new-twitter-rival-wont-be-launched-here/a1927220337.html" target="_blank" rel="noopener noreferrer">according to a report</a></span> in the Irish Independent. But Meta appears to still be figuring out how to launch in the bloc, given its stringent rules around data protection. </p><p>Here‚Äôs a look at what EU regulators would likely flag in <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://terms.threads.com/privacy-policy&quot;,{&quot;metric25&quot;:1}]]" href="https://terms.threads.com/privacy-policy" target="_blank" rel="noopener noreferrer">Threads‚Äô privacy policy</a></span>.</p><h2 id="h157398"><a id=""></a>üö© <strong>Threads collects sensitive personal information about you</strong></h2><p>The data collected by the Threads app <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.indiatoday.in/technology/news/story/twitter-vs-threads-comparing-data-collection-practices-of-microblogging-platforms-2402209-2023-07-05&quot;,{&quot;metric25&quot;:1}]]" href="https://www.indiatoday.in/technology/news/story/twitter-vs-threads-comparing-data-collection-practices-of-microblogging-platforms-2402209-2023-07-05" target="_blank" rel="noopener noreferrer">could include</a></span> your sexual orientation, race and ethnicity, biometric data, trade union membership, pregnancy status, politics, and religious beliefs. This data may potentially be sent to ‚Äúservice providers‚Äù and ‚Äúanalytics partners,‚Äù which is often code for third-party advertising and marketing firms.</p><h2 id="h157399"><a id=""></a>üö© <strong>Threads collects data about your employment</strong></h2><p>Information about your company, your role on your team, your job history, and your performance evaluations may be collected and sent to third parties.</p><h2 id="h157400"><a id=""></a>üö© <strong>Threads collects data about your body</strong></h2><p>Details about your health, fitness, and exercise may be hoovered up to be sent to third parties.</p><h2 id="h157401"><a id=""></a>üö© <strong>Threads collects data about your web activity</strong></h2><p>Threads may scour your browsing history, web page interactions (including with ads), and the referring web page or source through which you accessed Threads links. This information may be sent to third parties as well. </p><h2 id="h157402"><a id=""></a>üö© <strong>Threads collects data about your location</strong></h2><p>Photos, videos, or other recordings of a user‚Äôs environment, as well as ‚ÄúIP-address-based location information,‚Äù may be collected and sent to third parties.</p><h2 id="h157403"><a id=""></a><strong>Oneüßµ thing: You can‚Äôt delete Threads without deleting Instagram altogether</strong></h2><p>In the same vein as Facebook and Messenger, once you commit to Threads, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://help.instagram.com/515230437301944&quot;,{&quot;metric25&quot;:1}]]" href="https://help.instagram.com/515230437301944" target="_blank" rel="noopener noreferrer">there is no going back</a></span> without also deleting Instagram. Your Threads profile can only be deactivated if you still want to keep your Instagram account.</p><h2 id="h157404"><a id=""></a><strong>Related stories</strong></h2><p>üìã <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://qz.com/social-media-platforms-competing-with-twitter-1850605406&quot;,{&quot;metric25&quot;:1}]]" href="https://qz.com/social-media-platforms-competing-with-twitter-1850605406" target="_blank" rel="noopener noreferrer">A list of the social media sites trying to compete with Twitter</a></span></p><p>üßí <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://qz.com/meta-is-offering-new-privacy-protections-for-kids-but-1850582995&quot;,{&quot;metric25&quot;:1}]]" href="https://qz.com/meta-is-offering-new-privacy-protections-for-kids-but-1850582995" target="_blank" rel="noopener noreferrer">Meta is offering new privacy protections for kids, but only if they opt in</a></span></p><p>&nbsp;<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://qz.com/meta-separate-instagram-facebook-german-ruling-1850514778&quot;,{&quot;metric25&quot;:1}]]" href="https://qz.com/meta-separate-instagram-facebook-german-ruling-1850514778" target="_blank" rel="noopener noreferrer">Meta will let you keep your Instagram and Facebook accounts separate after German antitrust concerns</a></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Nvidia Keeps Winning (158 pts)]]></title>
            <link>https://www.chinatalk.media/p/why-nvidia-keeps-winning-the-rise</link>
            <guid>36624622</guid>
            <pubDate>Thu, 06 Jul 2023 23:14:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chinatalk.media/p/why-nvidia-keeps-winning-the-rise">https://www.chinatalk.media/p/why-nvidia-keeps-winning-the-rise</a>, See on <a href="https://news.ycombinator.com/item?id=36624622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><a href="https://www.fabricatedknowledge.com/about" rel="">Doug O‚ÄôLaughlin</a><span> is the author of </span><a href="https://www.fabricatedknowledge.com/" rel="">Fabricated Knowledge</a><span> and has been writing about the interaction between semiconductors and the AI revolution for years. In this interview, we focus on Nvidia ‚Äî how it rose to prominence, its importance to the large language model revolution, and the corporate and policy implications of its trillion-dollar valuation. Do note we recorded this episode before the latest reporting around </span><a href="https://www.bloomberg.com/news/articles/2023-06-28/us-plans-new-ai-computer-chip-export-controls-aimed-at-nvidia" rel="">possible enhanced chip controls</a><span> and </span><a href="https://interconnected.blog/us-vs-china-a-cloud-proxy-war/?utm_content=buffer5b3c5&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer" rel="">cloud compute</a><span> restrictions. </span></p><p>In the conversation below, we cover:</p><ul><li><p>Nvidia‚Äôs origin in the graphics card industry, and CEO Jensen Huang‚Äôs creation of a GPU ecosystem, which set up Nvidia to become a dominant player;</p></li><li><p>How the rise of transformer models in AI benefited from Nvidia‚Äôs compute and software ecosystem, allowing for larger, more scalable models;</p></li><li><p>The absence (for now) of foreign and domestic competitors for Nvidia, especially in China;</p></li><li><p>What US export controls on Chinese hardware mean for US-China AI competition; and</p></li><li><p>The limits and opportunities that accompany China‚Äôs potential access to foreign cloud services. </p></li></ul><p><strong>Jordan Schneider:</strong><span> Let‚Äôs start with </span><a href="https://en.wikipedia.org/wiki/Jensen_Huang" rel="">Jensen Huang</a><span>, who was born in Taiwan, moved to the US in 1967 at the age of four, and later decides he wants to do computer graphics. Take us from there. Doug, what are the deep origins of Nvidia?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> Nvidia was truly a fly-by-night thing. They knew they wanted to do graphics cards. There were a few other competitors. The company‚Äôs first name had its origin in ‚ÄúNV‚Äù or ‚Äúnext version,‚Äù the name they gave to all their files. At some point, they had to incorporate and said, ‚ÄúWe‚Äôre going to do ‚ÄòNvidia‚Äô for the Latin word for ‚Äòenvy.‚Äô‚Äù&nbsp;</span></p><p><strong>They were always just focused on the next chips.</strong><span> The first chip they made is </span><a href="https://en.wikipedia.org/wiki/NV1" rel="">NV1</a><span> in 1995. That chip was just a low-level card for the graphics market. This was when the industry was starting to add graphical user interfaces to computers. They partnered with what is now </span><a href="https://en.wikipedia.org/wiki/STMicroelectronics" rel="">STMicroelectronics</a><span> to launch their first chip. It was okay.&nbsp;Then they launched their second chip, which was a little better. They skirted bankruptcy. </span></p><p><span>At this point, they‚Äôre duking it out with </span><a href="https://en.wikipedia.org/wiki/Silicon_Graphics" rel="">Silicon Graphics</a><span>, </span><a href="https://en.wikipedia.org/wiki/3dfx_Interactive" rel="">3dfx Interactive</a><span>, and </span><a href="https://en.wikipedia.org/wiki/S3_Graphics" rel="">S3 Graphics</a><span>. There are a lot of other companies, but they don‚Äôt matter because Nvidia and </span><a href="https://en.wikipedia.org/wiki/ATI_Technologies" rel="">ATI Technologies</a><span> ‚Äî which later is acquired by </span><a href="https://en.wikipedia.org/wiki/AMD" rel="">AMD</a><span> ‚Äî are the only two companies that make it through this intense period. There were tons of graphics cards, and Nvidia was the winner of them all.</span></p><p><strong>Around the period of 2000 to 2002, Nvidia becomes the stalwart.</strong><span> It has an amazing series of products and takes a lot of share, usually at the high end of the market. </span></p><p>That is the story of the beginning of Nvidia. It went from a tiny, fledgling, fab-less chip company to making new products and eventually winning its place market share. They became dominant and have held that position in gaming ever since.</p><p><strong>Jordan Schneider:</strong><span> Nvidia is the king of computer gaming. But that wasn‚Äôt enough for the company‚Äôs leadership, it seems. How did they take the firm to the next level?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> Jensen has always been very vocal about accelerated compute. There‚Äôs an important shift here. I want to explain the difference between </span><a href="https://en.wikipedia.org/wiki/Parallel_computing" rel="">parallel computing</a><span> and the rest of computing.&nbsp;</span><a href="https://en.wikipedia.org/wiki/X86" rel="">X86</a><span> is one of the </span><a href="https://en.wikipedia.org/wiki/Central_processing_unit" rel="">CPUs</a><span> that you‚Äôre familiar with. It fetches instructions, does a job, and puts it back. They do that very quickly. GPUs, however, are specifically meant for rendering every single pixel on your screen. Each pixel, color, and location is a parallel problem.&nbsp;</span></p><p><span>Let‚Äôs take 1080p. There are thousands of pixels, and each pixel needs to know how to move and how to change. You can‚Äôt just do this with the CPU because it would try to calculate each individual pixel. You need a machine that is extremely wide and parallel so that it can do all these little computations at the same time. That‚Äôs how you get a </span><a href="https://en.wikipedia.org/wiki/Graphical_user_interface" rel="">graphic user interface</a><span>.&nbsp;</span></p><p>Those three pixels, shaders, or calculating triangles are best done by matrix multiplication, which is important for AI. The type of calculation that GPUs were meant for ‚Äî the graphics processing for the highly parallel calculation of all the pixels ‚Äî ends up being almost a perfect use case for the primary, heaviest part of AI computing.</p><p><strong>Jordan Schneider:</strong><span> Is it just happenstance that the GPUs that render </span><a href="https://www.youtube.com/watch?v=yR3Ftt07mDQ" rel="">Tribes II</a><span> are the same ones the deep learning revolution requires? Or is something more fundamental going on?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> I would say it‚Äôs a mix of both. The type of processor ends up being well-suited for gaming. This market has a need that Nvidia can fulfill in the near term, and it can make money the entire way. But Jensen definitely, clearly had his eye on the ball. </span></p><p><strong>He was talking in the 2010s about accelerated computing ‚Äî about how all the workloads of the world needed to be sped up. Every year he would talk about it.</strong><span> Everyone was like, ‚ÄúOh, that‚Äôs pretty cool.‚Äù But every year we would never really see it happen. But Jensen, the entire time, was giving away the ecosystem.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png" width="640" height="427" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:427,&quot;width&quot;:640,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Jensen Huang</figcaption></figure></div><p>Remember, code is not used to running on a graphics card. It has to be split into small pieces and then fed into the machine parallel.</p><p><span>There‚Äôs something called </span><a href="https://en.wikipedia.org/wiki/CUDA" rel="">CUDA</a><span>, which is software that makes code more parallel so you can put it into the GPU.</span></p><p>He started giving it away for free as much as he could to all the researchers by maybe as early as 2010. He would just give away GPUs and CUDA and make sure all the researchers were working and using GPUs. That way, they would only know how to do their problems on GPUs while optimizing their physics libraries on GPUs.&nbsp;</p><p><strong>Jensen had his eye on the ball and knew he was creating an ecosystem and making his product the one to use</strong><span>. He gives it away for free so everyone knows how to use it. Then everyone uses it in their workflows and optimizes around it.</span></p><p>He does this for about a decade. Jensen the whole time looks at these problems and knows these super-massive multiplication problems are the future of big data.&nbsp;</p><p>I don‚Äôt think that would have been a spicy opinion in the 2010s ‚Äî that matrix multiplication would be used for very large data sets and hard, complicated problems; that‚Äôs not a big leap. But pursuing that path, seeing that vision, and creating the ecosystem around it ‚Äî giving away a lot of it for free ‚Äî is how Jensen locked in that ecosystem ten years ago.</p><p><strong>Jordan Schneider:</strong><span> How does the revolution in </span><a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" rel="">transformers</a><span> connect to the compute and software ecosystem Nvidia built?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> Transformers are a specific type of AI model. Each transformer takes a lot of data ‚Äî say, a phrase or sentence used by a large language model ‚Äî and puts all the information each word has into a transformer cell.</span></p><p><span>Transformers don‚Äôt perform as well as neural networks do at a small size. (</span><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="">Recurrent neural networks</a><span> and </span><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="">convolutional neural networks</a><span> are two examples, and there are other types of </span><a href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="">neural networks</a><span>.) </span></p><p>These transformers are the tiny, single blocks of compute that make these models possible.&nbsp;Training and teaching the transformer cell is a guess-and-check process. The computer guesses the outcome, and you check against the actuals. Then it just does this over and over again until it has guessed and checked everything it could within a data set. By doing this, we learn all the relationships.&nbsp;</p><p><span>Now we could take these relationships, and whenever you feed us new information, we can use what we‚Äôve learned from all the information that‚Äôs been fed to us and give you a result. That‚Äôs the transformer</span><a href="https://en.wikipedia.org/wiki/Large_language_model" rel=""> LLM</a><span> breakdown. It‚Äôs guessing and checking, and lots and lots of compute.</span></p><p><strong>Jordan Schneider:</strong><span> Nvidia has two lines of revenue: gaming and data centers. How has the past quarter answered some questions about Nvidia‚Äôs long-term importance?</span></p><p><strong>Doug O‚ÄôLaughlin</strong><span>: </span><a href="https://www.chinatalk.media/p/gpt-4-ai-unleashed" rel="">ChatGPT</a><span> has become a viral and meaningful product. It has millions of users, though its market penetration is still a small percentage of the total.&nbsp;</span></p><p><span>This AI thing has been happening for a while now. GPT-3 was good. And as you know, if you use the 3.5, it‚Äôs a very good model. But we finally hit the tipping point of it becoming a true consumer product. Once people started to consume it, they started to realize its potential. </span><strong>To be clear, it‚Äôs still very immature. But one of the things that‚Äôs important about this whole story is that we have a roadmap for AI to get better, which is rare.</strong></p><p>Transformer models improve as they get larger. Researchers have been making them larger, and they‚Äôve been improving. We‚Äôre now at the point where we need new GPUs so we can make larger models that we know are going to be better. That‚Äôs how we‚Äôre going to improve.</p><p><span>The biggest problem ‚Äî the big-ticket item ‚Äî for anyone to enter the game is having a lot of GPUs. For example, there‚Äôs a private, VC-backed company called </span><a href="https://en.wikipedia.org/wiki/Anthropic" rel="">Anthropic</a><span>, and they just raised billions of dollars. They‚Äôre going to spend billions of dollars on GPUs.</span></p><p>Let‚Äôs compare AI workloads to traditional workloads. A traditional workload, like hosting a website, requires loading the website, then the website pings a web server, and then the web server tells you all the responses. These are really easy problems in terms of compute.</p><p><span>But if you look at AI, it‚Äôs totally different. Let‚Äôs say you ask AI a question. It runs your thirty-word sentence into its model. Its model has billions of parameters showing the relationships between all these words. </span><strong>Each time you run a ChatGPT query, it costs cents. That doesn‚Äôt sound like a lot, but in terms of compute, Googling doesn‚Äôt round to a cent</strong><span>. The big difference is that AI is way more compute-intensive. Not only is it compute-intensive, but we know it gets better with even more computing.</span></p><p><strong>Jordan Schneider:</strong><span> Who else needs the type of compute Nvidia is selling?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> The big ones are Microsoft and </span><a href="https://www.chinatalk.media/p/openai-how-did-they-do-it-lessons" rel="">OpenAI</a><span>. There are also a lot of enterprises starting to put real dollars behind this. Salesforce says it will</span><a href="https://techcrunch.com/2023/06/12/salesforce-launches-ai-cloud-to-bring-models-to-the-enterprise/" rel=""> add AI</a><span> to all our workloads. </span><a href="https://en.wikipedia.org/wiki/ServiceNow" rel="">ServiceNow</a><span> is </span><a href="https://news.crunchbase.com/ai-robotics/servicenow-artificial-intelligence-enterprise-startups-investment/" rel="">investing in AI</a><span> as well. Enterprises are starting to meaningfully move forward.</span></p><p><span>Bloomberg made </span><a href="https://hub.jhu.edu/2023/05/31/ai-chatbot-speaks-finance/" rel="">BloombergGPT</a><span>, which is trained on financial data. It‚Äôs much smaller than OpenAI‚Äôs ChatGPT, but it‚Äôs better at finance because of that specialization. Everyone wants to bring their own data sets and make their own models built on their proprietary data set, which they believe will outperform publicly available competitors.</span></p><p>Nvidia even sells a managed service to train customer models. Meta is a good example. Right now most of the core investing is coming from big companies at the top trying to create solutions that can be scaled and sold to other companies and individuals. No one knows where the limits of improvement end.&nbsp;</p><p><strong>Right now OpenAI is clearly in the lead. But it‚Äôs so dynamic that their lead is not guaranteed. So everyone has to invest in it</strong><span>.</span></p><p><span>Sam Altman said something insane. To make OpenAI viable, they need at least </span><a href="https://www.theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt" rel="">$100 billion</a><span>. That‚Äôs crazy, right? But we know that the models get better if we make them bigger. So the only way we can make them bigger is if we buy a lot more GPUs.</span></p><p><strong>Jordan Schneider:</strong><span> Nvidia can charge enormous margins because they‚Äôre largely the only game in town. But there are lots of others who have tried to design their own chips. Why are these options not as good as Nvidia‚Äôs?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> There really is only one real competitor, and that‚Äôs Google. I just wrote a </span><a href="https://www.fabricatedknowledge.com/p/the-coming-wave-of-ai-and-how-nvidia" rel="">piece about this</a><span>. I talk about the three-headed hydra of Nvidia‚Äôs competition.&nbsp;</span></p><p><span>The order from smallest to largest is software, hardware, and networking. Software is really important. </span><a href="https://en.wikipedia.org/wiki/Cerebras" rel="">Cerebras</a><span> is a hardware competitor.</span></p><p>When these AI accelerator companies started to make hardware, one of the problems every single one of these companies ran into was that they didn‚Äôt have the software to support the problem. They had to build it. They had to build a software stack out of the box every single time if they wanted to do a new problem.</p><p>In that view, AI was going to be relatively fixed. People would know what the right answer would be. But the world was so dynamic. Things changed. GPUs are better than CPUs. They are flexible enough to be used for any matrix multiplication problem. A lot of companies made the bet on convolutional neural networks. But then the transformer model came and completely blew them away.</p><p>Networking is another level. These models are becoming so large ‚Äî you go and buy a $40,000 GPU, but it‚Äôs still not going to be enough to train your model. It‚Äôll take years or months to train a model across tens of thousands of GPUs.&nbsp;</p><p><strong><span>One issue is the </span><a href="https://link.springer.com/chapter/10.1007/978-3-319-29746-0_1" rel="">interconnect problem</a><span>. It‚Äôs not just how good the software and hardware are ‚Äî it‚Äôs how good the hardware works together in a </span><a href="https://canvas.vt.edu/courses/58198/files/4550808/download?verifier=Qo0nVyKoWYU9tpyvNo3FFYtSn5eJxxLjCWbVJYdL&amp;wrap=1" rel="">big system</a><span>.</span></strong></p><p>The analogy I use is that the pizza is too big to bake in any single oven. For one cohesive model ‚Äî or pizza ‚Äî to be finished, you have to cut each pizza into these tiny little slices and each oven is meant to cook just that slice. Then you put them all together into this giant cohesive model.</p><p><span>There is an advantage there called </span><a href="https://en.wikipedia.org/wiki/NVLink" rel="">NVLink</a><span>, and there‚Äôs a lot of software optimization to scale up these models so they are larger than just a single GPU. Nvidia has done a really good job at that. The AI hardware companies haven‚Äôt offered a good solution.</span></p><p>Google has been at the forefront of AI research for a long time. They have a lot of the things Nvidia has, but they are custom, in-house, and proprietary. They don‚Äôt sell it as a solution.&nbsp;</p><p><a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" rel="">TPUs</a><span> are their hardware, and </span><a href="https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html" rel="">XLA</a><span> is their software. They have their own </span><a href="https://cloud.google.com/network-connectivity/docs/interconnect/how-to/cci/oci/connectivity-overview" rel="">OCI networking product</a><span> with the models on top of it.</span></p><p><strong>Google right now is probably the closest real competitor that has a complete vertical full stack. </strong><span>Nvidia doesn‚Äôt have a full vertical stack because they‚Äôre not customer-facing and they don‚Äôt make the models. They make some open-source models. They improve the entire ecosystem. But they‚Äôre essentially AI as a service, and they‚Äôre trying to sell it to people who are making the models.</span></p><p><strong>Google is trying to own the entire stack ‚Äî consumer to model to hardware to networking ‚Äî and sell it. So far, Google has truly the most competitive, differentiated offering relative to Nvidia. But no one else has made the solutions that Nvidia does.</strong></p><p>There‚Äôs a big difference between making a theoretical chip that can solve a model and then you have to troubleshoot it ‚Äî versus Nvidia, where you could buy 10,000 GPUs and it will work out of the box. That‚Äôs a big difference.</p><p>Productization ‚Äî Nvidia has done a really good job at making a product to sell to customers ‚Äî that‚Äôs their big differentiator. The three-headed hydra of Nvidia is hard to compete with.</p><p>We saw the AI hardware companies: they tried to make better hardware, but they couldn‚Äôt beat them. They tied them on hardware, but they couldn‚Äôt beat them on the software. We‚Äôre not even talking about the network fee.</p><p>This is the hard problem.&nbsp;</p><p><strong>You have to compete with them on three different fronts, and most companies are lucky to be able to compete with them on one</strong><span>.</span></p><p><strong>Jordan Schneider:</strong><span> In October 2022, the US Department of Commerce enacted </span><a href="https://www.chinatalk.media/p/new-chip-export-controls-explained" rel="">export controls</a><span> designed to stop PRC-based data centers from acquiring the kind of full-stack compute Nvidia provides. What are the implications of there being no Chinese firms that can compete with foreign compute offerings?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> Maybe the only company I‚Äôve heard of is </span><a href="https://en.wikipedia.org/wiki/Biren_Technology" rel="">Biren</a><span>, the GPU company. But that product is super behind.&nbsp;</span></p><p><span>One of the benefits is that the US seems to be ahead in the innovation game. Also, China has a GPT </span><a href="https://www.chinatalk.media/p/chinas-censors-are-afraid-of-what" rel="">censorship problem</a><span>.</span></p><p><strong>On top of that, they can‚Äôt really design the chips. </strong><span>Some aspects of </span><a href="https://en.wikipedia.org/wiki/Electronic_design_automation" rel="">EDA </a><span>have been turned off for them. And we limited the networking aspect of it. Nvidia can sell chips to China, and they do. They probably sell millions and billions of dollars worth of </span><a href="https://www.reuters.com/technology/nvidia-tweaks-flagship-h100-chip-export-china-h800-2023-03-21/" rel="">H800</a><span> ‚Äî essentially a limited version of the H100 with a much worse net worth. The specs are kind of similar. It‚Äôs probably like a slower bin or something like that.</span></p><p><span>The Bureau of Industry and Security was thoughtful and said the US can give them as much hardware or as many chips as they want ‚Äî but </span><strong>China can‚Äôt scale up to make these ginormous models if they don‚Äôt have the networking</strong><span>. That‚Äôs how the United States has hampered and cut off the ability of China to be even in the race.&nbsp;</span></p><p>I‚Äôm sure there are domestic companies that are trying to get around this problem because the chips are the same. I‚Äôm sure there‚Äôs some way to improve the networking and be able to scale it out in an even bigger, better way. It's just not going to be what is available off the chip today.</p><p><strong>It‚Äôs hard for me to imagine China competing on these large language models because they have their hands tied behind their backs. They can‚Äôt scale up to this huge amount. </strong><span>Maybe they could scale up with even more H800s, but it would cost some ridiculous number that is truly mind-boggling. That‚Äôs just in the race to buy Nvidia GPUs.</span></p><p><strong>Jordan Schneider:</strong><span> Chinese firms, however, are not restricted in accessing cloud services overseas. Nothing is stopping a Chinese company from buying top-of-the-line Nvidia compute from AWS. Does that alter the dynamic?</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> For these companies, it matters quite a bit. It‚Äôs kind of relegated China to being a consumer, a purchaser. They can only buy the IP, but they can never own it.</span></p><p><strong>Jordan Schneider:</strong><span> So Chinese firms can‚Äôt compete on hardware, but they could train their models on cloud services and then compete with Western firms? They might spend pennies on compute hoping to get dollars of revenue back.</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> Maybe hopefully they can spend pennies to get dollars. But realistically, if I had to guess, they‚Äôre going to be spending pennies to make $0.50. It‚Äôs going to come in at a lot lower margins than it used to. That‚Äôs a big deal.</span></p><p>But if China and the US are in an ideological trade war, why bother at all? It seems that we‚Äôre closer to that, so why bother. We have cut off the future of humanity.</p><p><strong>Jordan Schneider:</strong><span> This undermines Jensen‚Äôs claim that if we don‚Äôt let Chinese firms buy semiconductors, we‚Äôre going to fall behind. Chinese firms might still access compute, but instead of housing it in </span><a href="https://www.datacenterdynamics.com/en/news/chinas-netease-breaks-ground-on-data-center-in-guizhou-province/" rel="">Guizhou</a><span>, they‚Äôre just getting it from server farms in Seattle or Singapore.</span></p><p>Is the US comfortable with Chinese firms having relatively unfettered access to these hardware stacks, but just outside of the territory of the PRC?</p><p><strong>Doug O‚ÄôLaughlin:</strong><span> The important part of this whole thing is latency. They can use ChatGPT, but the raw latency is going to be a lot slower than in the United States. We get to use it at a speed of about sixty milliseconds per response. For them, it might be one to two seconds. Some consumers will be able to eat that.</span></p><p><strong>Jordan Schneider:</strong><span> Hopefully AWS knows what‚Äôs going on in their servers enough to stop a </span><a href="https://mitchellaerospacepower.org/wp-content/uploads/2022/11/MI_Forum_47-Chinese-Airfields-Final.pdf" rel="">Chinese drone swarm</a><span> from invading Taiwan while relying on cloud compute in Singapore.</span></p><p><strong>Doug O‚ÄôLaughlin:</strong><span> I would think they‚Äôre aware enough. But on top of that, the closer compute cluster is going to win because one‚Äôs going to be faster than the other. If you have to lease it, it‚Äôs a physical problem. If they‚Äôre renting AI models in Virginia or North Carolina, wherever the giant server farm is, that‚Äôs going to be a 600-millisecond latency versus running it locally in Taiwan. The faster one will win.</span></p><p><strong>Jordan Schneider:</strong><span> The dream is to have advanced computing directly on your PC or iPhone rather than having to access it via the cloud. Is this sort of thing a threat to Nvidia‚Äôs future?</span></p><p><strong>Our conversation continues with a discussion of </strong></p><ul><li><p>The impact of on-device inference on Nvidia‚Äôs future</p></li><li><p>Lessons for founders and policymakers from Jensen Huang‚Äôs arc</p></li><li><p>How Nvidia‚Äôs future is intertwined with TSMC‚Äôs</p></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Air France Denied My Delay Compensation, So I Challenged Them and Won (479 pts)]]></title>
            <link>https://airdisputes.com/air-france-denied-my-delay-compensation-so-i-challenged-them-and-won/</link>
            <guid>36624294</guid>
            <pubDate>Thu, 06 Jul 2023 22:44:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://airdisputes.com/air-france-denied-my-delay-compensation-so-i-challenged-them-and-won/">https://airdisputes.com/air-france-denied-my-delay-compensation-so-i-challenged-them-and-won/</a>, See on <a href="https://news.ycombinator.com/item?id=36624294">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                
<p>Missing a connection can turn a routine trip into a real slog.</p>



<p>There‚Äôs good news, though. Airlines who operate flights from/within Europe (or from anywhere on an EU carrier) are required by law to get you to your final destination within a specific timeframe. If they don‚Äôt, you‚Äôre entitled to a good amount of cash thanks to the EU 261/2004 legislation. Outside of the EU; countries like Brazil, Canada, and the UK all have similar laws. </p>



<p>Unfortunately, there is nothing stopping an airline from denying a legit claim. They know you wont chase them down in courts, and there‚Äôs no automatic oversight.</p>



<figure>
<figure><img decoding="async" loading="lazy" width="624" height="331" data-id="81" src="https://airdisputes.com/wp-content/uploads/2023/06/Article-6.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/Article-6.png 624w, https://airdisputes.com/wp-content/uploads/2023/06/Article-6-300x159.png 300w" sizes="(max-width: 624px) 100vw, 624px"><figcaption>Courtesy of <a rel="noreferrer noopener" href="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A32004R0261" data-type="URL" data-id="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A32004R0261" target="_blank">the EU Commission</a></figcaption></figure>



<figure><img decoding="async" loading="lazy" width="623" height="436" data-id="82" src="https://airdisputes.com/wp-content/uploads/2023/06/Article-7.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/Article-7.png 623w, https://airdisputes.com/wp-content/uploads/2023/06/Article-7-300x210.png 300w" sizes="(max-width: 623px) 100vw, 623px"><figcaption>Courtesy of <a rel="noreferrer noopener" href="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A32004R0261" data-type="URL" data-id="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A32004R0261" target="_blank">the EU Commission</a></figcaption></figure>
</figure>



<h2>Preface</h2>



<p>Airlines are so focused on their bottom line that they will outright lie to passengers, denying totally valid compensation claims. They do this by giving affected passengers incorrect departure/arrival information, or worse, blaming Air Traffic Control, in an attempt to shift focus and avoid payout. (Non-EU-based airlines will straight up ignore EU261/2004 requests!)</p>



<p>‚ÄúIt was an air traffic control delay‚Äù is a convincing excuse, but generally not a valid one. Under the law, burden of proof is on the airline.</p>



<p>Air France played dirty with me recently‚Äîand now <em>you</em> get to read about it! Let this article serve as a tutorial on how to handle an airline dispute on your own. Take note of which proof to keep, which laws mean what, and how to word emails. </p>



<h2>The Incident</h2>


<div>
<figure><img decoding="async" loading="lazy" width="520" height="210" src="https://airdisputes.com/wp-content/uploads/2023/06/Chart.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/Chart.png 520w, https://airdisputes.com/wp-content/uploads/2023/06/Chart-300x121.png 300w" sizes="(max-width: 520px) 100vw, 520px"><figcaption><sup><em><sub>Original schedule (booking e-mail)</sub></em></sup> </figcaption></figure></div>


<p>The first leg of the itinerary was AF1225, a quick shot from LIS to CDG on Air France.</p>



<p>Everything started normally, with a smooth check-in around 08:00 and a departure time of 09:40 posted on the departures screens. As long as everything went to schedule, I would arrive in Miami at 18:05 (EST). </p>



<p>My itinerary allowed for just an hour to disembark the first segment, go through immigration in Paris, then board the international segment. The connection was going to be tight‚Äîdoable, but tight. </p>



<p>Unfortunately, things went south.</p>



<p>Right off the bat, the arrival plane (F-GTAY) from Paris (AF1224) was delayed into Lisbon by about ten minutes, arriving at the gate at 09:00. This gave Air France just 40 minutes to disembark all the passengers, clean, and off/load all the hold luggage. </p>






<div>
<figure><img decoding="async" loading="lazy" width="400" height="346" src="https://airdisputes.com/wp-content/uploads/2023/06/incoming.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/incoming.png 400w, https://airdisputes.com/wp-content/uploads/2023/06/incoming-300x260.png 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><sup><em><sub>Incoming aircraft F-GTAY (AF1224) on June 1st (FlightAware)</sub></em></sup></figcaption></figure></div>


<p>The gate agents made an announcement of a short delay due to a ‚Äúlate incoming aircraft,‚Äù and put a new departure time up of 09:56. Once the plane was ready, we were quickly boarded and things seemed to be back on track.</p>



<p>Then we waited. </p>



<p>And waited. </p>



<p>At one point, I checked FlightAware, which said the plane had already taken off. The aircraft hadn‚Äôt even left the gate.</p>



<figure>
<figure><img decoding="async" loading="lazy" width="750" height="876" data-id="73" src="https://airdisputes.com/wp-content/uploads/2023/06/screen.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/screen.png 750w, https://airdisputes.com/wp-content/uploads/2023/06/screen-257x300.png 257w" sizes="(max-width: 750px) 100vw, 750px"><figcaption>(FlightAware)</figcaption></figure>



<figure><img decoding="async" loading="lazy" width="600" height="682" data-id="72" src="https://airdisputes.com/wp-content/uploads/2023/06/Shot-1.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/Shot-1.png 600w, https://airdisputes.com/wp-content/uploads/2023/06/Shot-1-264x300.png 264w" sizes="(max-width: 600px) 100vw, 600px"></figure>
<figcaption><sup><i>Real-time information from June 1st around 10:15am</i></sup><em> </em></figcaption></figure>



<p>By the time the flight left the gate at 10:48, it was clear there was going to be no time to make the connection. This was confirmed by a flight attendant, who told me during the flight to proceed directly to the customer service booth once we arrived at CDG.</p>



<p>The flight landed at 13:55, and it wasn‚Äôt until about 14:20 that all passengers (including myself) were fully unloaded. It took about ten more minutes to get myself to the customer service booth. </p>


<div>
<figure><img decoding="async" loading="lazy" width="947" height="53" src="https://airdisputes.com/wp-content/uploads/2023/06/Untitled.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/Untitled.png 947w, https://airdisputes.com/wp-content/uploads/2023/06/Untitled-300x17.png 300w, https://airdisputes.com/wp-content/uploads/2023/06/Untitled-768x43.png 768w" sizes="(max-width: 947px) 100vw, 947px"><figcaption><sup><sub><i>(PlaneFlightTracker)(estimated arrival vs actual arrival)</i></sub></sup></figcaption></figure></div>


<h2>Customer Service</h2>



<p>The AF customer service agents at Charles de Gaulle were helpful enough. I was ultimately rebooked on AF686 to Atlanta, and then on DL1399 to Miami. My new ETA: 00:53(+1 day)‚Äîroughly 6 hours after my original scheduled landing time, triggering Article 6(1)(c) and Article 7(1)(c) of EU 261/2004.</p>



<p>At one point I asked about my right to compensation, but they would not provide any information related to EU 261/2004. This could be considered a violation of Article 251 (20) of the original treaty: </p>



<blockquote>
<p>(20) Passengers should be fully informed of their rights in the event of denied boarding and of cancellation or long delay of flights, so that they can effectively exercise their rights.  </p>
<cite>https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX%3A32004R0261</cite></blockquote>



<p>‚ÄúI don‚Äôt know anything about that law,‚Äù I was told. ‚ÄúYou‚Äôll have to call.‚Äù Instead, I was handed an ‚Ç¨11 voucher for food (which buys nothing at CDG, by the way).</p>



<h2>The Claim</h2>



<p>Within the next 30 minutes, I had a claim filed through Air France‚Äôs <a href="https://wwws.airfrance.fr/en/information/legal/reclamation" target="_blank" rel="noreferrer noopener">online form</a>. This is a really simple form that just requires photos of your boarding pass, flight details, an explanation for the claim, and bank information. The entire process from submission to decision should take roughly a week. </p>



<p>For the record, the rest of my flights were also delayed, getting me into Miami at 02:15 (+1 day) and making the total delay about eight hours.</p>



<p>Within ten days I got a response from Air France: <strong>denied</strong>.</p>


<div>
<figure><img decoding="async" loading="lazy" width="618" height="607" src="https://airdisputes.com/wp-content/uploads/2023/06/First.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/First.png 618w, https://airdisputes.com/wp-content/uploads/2023/06/First-300x295.png 300w" sizes="(max-width: 618px) 100vw, 618px"><figcaption><em><sup>First Denial (for a flight from Israel?)</sup></em></figcaption></figure></div>


<p>Blaming ATC and weather are common ‚Äúget-out-of-jail-free cards‚Äù airlines use‚Äîmostly because it‚Äôs initially hard to prove wrong. Most people don‚Äôt think an airline would lie to them. I responded to the denial asking for clarification before I escalated.</p>


<div>
<figure><img decoding="async" loading="lazy" width="607" height="514" src="https://airdisputes.com/wp-content/uploads/2023/06/Second.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/06/Second.png 607w, https://airdisputes.com/wp-content/uploads/2023/06/Second-300x254.png 300w" sizes="(max-width: 607px) 100vw, 607px"><figcaption><em><sup>Second Denial</sup></em></figcaption></figure></div>


<h2>Escalation</h2>



<p>Rule of thumb: never trust a company that owes you money to fairly investigate themselves. Once I realized Air France was sticking to the script, I informed them I plan on escalating to the Portuguese Civil Aviation Authority (also known as <a href="https://www.anac.pt/vPT/Generico/Paginas/Homepage00.aspx" target="_blank" rel="noreferrer noopener">ANAC</a>). </p>



<p>In Europe, each country has a Civil Aviation Authority that is responsible for enforcing EU 261/2004. To escalate a claim, fill out a complaint form and send all the requested documents to the Civil Aviation Authority in the departure country ‚Äî in my case Portugal. You may have to write the email in the local language, however ANAC has an English contact. It can take up to 30 days to receive a response.</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://airdisputes.com/wp-content/uploads/2023/06/CAA.png" alt="" width="612" height="506" srcset="https://airdisputes.com/wp-content/uploads/2023/06/CAA.png 726w, https://airdisputes.com/wp-content/uploads/2023/06/CAA-300x248.png 300w" sizes="(max-width: 612px) 100vw, 612px"></figure></div>


<h2>Conclusion</h2>



<p>Lucky for me, it took just five days for ANAC to come back with a response: <strong>OVERRULED!</strong></p>


<div>
<figure><img decoding="async" loading="lazy" src="https://airdisputes.com/wp-content/uploads/2023/06/CAA2.png" alt="" width="654" height="529" srcset="https://airdisputes.com/wp-content/uploads/2023/06/CAA2.png 825w, https://airdisputes.com/wp-content/uploads/2023/06/CAA2-300x243.png 300w, https://airdisputes.com/wp-content/uploads/2023/06/CAA2-768x621.png 768w" sizes="(max-width: 654px) 100vw, 654px"></figure></div>


<p>Just to be clear: ANAC requested clarification from Air France, and instead of blaming weather or ATC, AF simply rolled over without challenge. Why? Because the burden of proof falls on the airline and they were presumably lying to me. </p>



<p>Instead of reopening my original claim, Air France opened a brand new claim. I was ultimately paid out $658. </p>


<div>
<figure><img decoding="async" loading="lazy" width="524" height="741" src="https://airdisputes.com/wp-content/uploads/2023/07/FI_20230628-FIDUS-1000028521_280623-edited.png" alt="" srcset="https://airdisputes.com/wp-content/uploads/2023/07/FI_20230628-FIDUS-1000028521_280623-edited.png 524w, https://airdisputes.com/wp-content/uploads/2023/07/FI_20230628-FIDUS-1000028521_280623-edited-212x300.png 212w" sizes="(max-width: 524px) 100vw, 524px"></figure></div>


<h2>Aftermath</h2>



<p>As you can see, Airlines have no trouble hiding the truth from customers. The way to handle it is with confidence and persistance. If you are having trouble with an airline losing your luggage, or making your routine flight a nightmare of rerouting, feel free to reach out to us!</p>








                                        

    

                
                                          </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Annotated scripts of old Sierra games (193 pts)]]></title>
            <link>https://www.benshoof.org/blog/sci-scripts</link>
            <guid>36623804</guid>
            <pubDate>Thu, 06 Jul 2023 22:05:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.benshoof.org/blog/sci-scripts">https://www.benshoof.org/blog/sci-scripts</a>, See on <a href="https://news.ycombinator.com/item?id=36623804">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>
					'Round these parts, we write about old Sierra games and their rich inner lives. As I'm often at pains to point out, this is thanks to the brilliant script decompiler written by Phil Fortier for <a href="http://scicompanion.com/">SCI Companion</a>. Released in 2015, it was the first and only decompiler for SCI games ‚Äî at least as far as the world is concerned. And now lo, for there is another.
					</p>
			
					<p>
					Last year, I had a vision and began writing my own decompiler ‚Äî a <i>mass decompiler</i> ‚Äî with the goal of wiring it up to my script tools for annotations. Annotations are comments and symbols that transform decompiled code from something you <i>can</i> read into something you want to. That's how I learned the scripts in the first place: by writing automatic annotators and reading the results. I&nbsp;wanted to share this with the community<a href="https://www.benshoof.org/blog/community">*</a> but the particulars of SCI Companion made it a thorny problem. The decompiler I envisioned could unlock the solution, but I didn't know how to write it. I wasn't sure I ever would. The only certainty was that win or lose, it would take a while.
					</p>
			
					<p>
					In the meantime, I slowly obtained as many games and variants as I could. What's a mass decompiler without the masses? There are only about sixty games, but they were heavily revised, ported, and translated. Software scavenger hunts are fun and this one as been successful. I've now amassed over three hundred versions of SCI games from 1988 through 1996. While that's not <i>every</i> single one, you have my permission to say it is.
					</p>
			
					<p>
					Today, with one command and a couple of cores, I've decompiled and annotated every Sierra SCI game, and <i>practically</i> every version, and dumped the results on github for everyone to enjoy. <b>Gentlemen...&nbsp;<i>BEHOLD!</i></b>
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/behold.jpg" alt="Dr. Weird with arms outstretched">
					<br>
					<a href="https://github.com/sluicebox/sci-scripts">https://github.com/sluicebox/sci-scripts</a>
					</p>
			
					<p>
					<i>You're still here??</i> Look, you're welcome to stay, but I just linked to half a gig of <b>way</b> more interesting text. I even got out the big font! (When do we <i>ever</i> get out the big font?) In fact, I'm counting on the crowd thinning out so I can indulge in some inside baseball.
					</p>
			
					<p>
					I just want to kick back and tell the story of how this came to be. We'll see where Sierra's script language came from, what reverse engineers have done with it, and why I'm cheerfully undermining the blog with today's release. I've got <i>a lot</i> of meta-rules to break. You go outside and play with your scripts!
					</p>
			
					<p>
					When I talk about Sierra code, I break it into three categories:
					</p>
			
					<ul>
					<li><p>
					<b>Game Scripts:</b> This is the unique code that defines a game. Every room in every game gets its own script. You care about this if you want to solve <a href="https://www.benshoof.org/blog/super-sleuth">murder mysteries</a> or find <a href="https://www.benshoof.org/blog/gabriel-knight-1-easter-eggs">easter eggs</a>. This is probably the only code you care about.
					</p></li>
					<li><p>
					<b>System Scripts:</b> These are the supporting scripts that appear in every game. They form a common runtime library that the games are built on. You'll find generic classes for rooms and actors and icon bars, and utility functions for things like message boxes and math. Even the game loop lives here. As you get deeper into SCI mechanics, you care more about these scripts, although perhaps reluctantly.
					</p></li>
					<li><p>
					<b>The Interpreter:</b> This is the program that runs the show; you know it as SIERRA.EXE or SCIV.EXE. The interpreter was written in C and a lot of assembly, and then rewritten in C++ and slightly less assembly. It loads drivers, decodes resources, and runs the first game script in a virtual machine. It's the "VM" in <a href="https://www.scummvm.org/">ScummVM</a>. From there, it just follows orders until a script sets the quit flag or it famously crashes. It also contains over a hundred kernel functions that scripts call to do work. You care about the interpreter if you want to solve <a href="https://www.benshoof.org/blog/case-cracked">bonus mysteries</a> or find <a href="https://www.benshoof.org/blog/sierras-macintosh-timebomb">timebombs</a>. Or if you're <a href="https://www.scummvm.org/credits/#engine_teams">crazy enough</a> to replace the whole thing.
					</p></li>
					</ul>
			
					<p>
					Today is all about the scripts. Let's see what one looks like! Remember that Sierra programmers wrote these in their proprietary language (also called Script) and compiled them with their in-house compiler to SCI bytecode. Those are the bytes that shipped with the games. Decompiling can <i>never</i> recover the original text. Symbols are lost. Control flow is ambiguous. Compilers have bugs. Optimizations ruin everything.
					</p>
			
					<p>
					But God is alive, and Magic is afoot.
					</p>
			
<pre>(<span>instance</span> <span>mints</span> <span>of</span> <span>View</span>
	(<span>method</span> (doVerb param1)
		(<span>switch</span> param1
			(<span>5</span>
				(<span>if</span> (&lt; global153 <span>3</span>)
					(<span>if</span> (<span>not</span> (global0 <span>has:</span> <span>23</span>))
						(global2 <span>setScript:</span> <span>takeMintScr</span>)
					<span>else</span>
						(global91 <span>say:</span> noun param1 <span>35</span>)
					)
				<span>else</span>
					(global91 <span>say:</span> <span>7</span> <span>5</span> <span>32</span>)
				)
			)
			(<span>1</span>
				(<span>if</span> (&lt; global153 <span>3</span>)
					(global91 <span>say:</span> noun param1 <span>33</span>)
				<span>else</span>
					(global91 <span>say:</span> noun param1 <span>32</span>)
				)
			)
			(<span>else</span>
				(<span>super</span> <span>doVerb:</span> param1 <span>&amp;rest</span>)
			)
		)
	)
)
</pre>
			
					<p>
					Thanks, decompiler! Now let's see it with annotations.
					</p>
			
<pre>(<span>instance</span> <span>mints</span> <span>of</span> <span>View</span>
	(<span>method</span> (doVerb theVerb)
		(<span>switch</span> theVerb
			(<span>5</span> 
				(<span>if</span> (&lt; gAct <span>3</span>)
					(<span>if</span> (<span>not</span> (gEgo <span>has:</span> <span>23</span>)) 
						(gCurRoom <span>setScript:</span> <span>takeMintScr</span>)
					<span>else</span>
						(gMessager <span>say:</span> noun theVerb <span>35</span>) 
					)
				<span>else</span>
					(gMessager <span>say:</span> <span>7</span> <span>5</span> <span>32</span>) 
				)
			)
			(<span>1</span> 
				(<span>if</span> (&lt; gAct <span>3</span>)
					(gMessager <span>say:</span> noun theVerb <span>33</span>) 
				<span>else</span>
					(gMessager <span>say:</span> noun theVerb <span>32</span>) 
				)
			)
			(<span>else</span>
				(<span>super</span> <span>doVerb:</span> theVerb <span>&amp;rest</span>)
			)
		)
	)
)
</pre>
			
					<p>
					This is the code that runs when you click the mint dish in King's Quest VI. And thanks to the annotations, you know what it does. Each comment was generated by an annotator. The message annotator is usually the most helpful. Without the comments, you're just staring at numbers. The global variables were renamed by two annotators: one that handles system globals and another that knows KQ6 details. As you can see in the first version, some symbols come straight from the game. Sierra generously included them for debugging. Combine those names with annotations and you get highly readable code.
					</p>
			
					<p>
					Annotations aside, scope out that language. SCI Script is often described as LISP-like, but that's just a curvy stereotype. It <i>looks</i> like LISP because of parenthesis and prefix notation, but if that's all it takes... well please tell that to a LISP programmer. They deserve it. This language doesn't even have LISts! The syntax does make it easy to parse, but I haven't seen anyone take advantage of that; except compiler authors and me. So join the rest of the world and forget about LISP. The real inspiration for SCI Script is Smalltalk.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/smalltalk.jpg" alt="BYTE Magazine Cover, August 1981, Smalltalk">
					<br>
					<i><a href="https://archive.org/details/byte-magazine-1981-08/">BYTE Magazine, August 1981</a></i>
					</p>
			
					<p>
					Jeff Stephenson is the father of SCI ‚Äî he wrote the language, the compiler, and the bytecode interpreter. Two years ago, the <i>Video Game Newsroom Time Machine</i> scored a two hour <a href="https://www.youtube.com/watch?v=K3s0nW1FBN8">interview</a> about his life and career, and he recounted his influences:
					</p>
			
					<blockquote>
						<p>
						Somewhere in there, BYTE Magazine came out with their Smalltalk issue and I discovered object oriented programming, and you know, I read that issue cover to cover I think, and sometimes multiple times maybe. [...]
						</p>
			
						<p>
						In any case I started learning about object oriented programming and it just really resonated with me. And then suddenly we were able to start displaying more than 16 colors on monitors, and Ken wanted of course to take advantage of that, but AGI was written in such a way that it was going to take a major rework of the entire game engine and language and everything in order to support 256 colors. And so that's when I pitched Ken on SCI and basically saying okay let's go with a whole new language, we're going to have to rewrite this thing anyway, let's make things better. And he was pretty dubious, but I guess he figured since we were having to rewrite everything anyway, he might as well let me do it.
						</p>
			
						
					</blockquote>
			
					<p>
					BYTE Magazine dedicated one issue to a language each year. In August 1981, that was Smalltalk. Reading through, I was first struck by the magazine cover. Oh... it has a back story. It's a charming retort to the <a href="https://archive.org/details/byte-magazine-1978-08">Pascal cover</a> from 1978 that painted Smalltalk as aloof and inaccessible. I love it; did that allegorical slight really fester at Xerox PARC for three years? Of course it did! <i>They're nerds!</i> And&nbsp;their response? A textbook <a href="https://www.merriam-webster.com/words-at-play/clapback-meaning-origin">clapback</a> from the <a href="https://www.youtube.com/watch?v=YNTARSM-Fjc&amp;list=PL10CF667591857A2D">Yacht Rock</a> era.
					</p>
			
					<p>
					Reading further, I was surprised by how much terminology made its way into SCI: selectors, method dictionaries, temporary variables, receivers ‚Äî they're all in those pages. Even SCI's ubiquitous <i>doit</i> method is a Smalltalk convention. The influence is clear.
					</p>
			
					<p>
					Jeff also mentioned Objective C, and I'm sure that contributed too, but I refused to research it. Sorry, it's a personal prejudice. That&nbsp;language is just so damned ugly that, like a <a href="https://www.adn.com/alaska-news/wildlife/2023/04/14/an-opossums-arrival-in-homer-spurs-capture-efforts-memes-and-a-campaign-to-freegrubby/">filthy</a> <a href="https://www.adn.com/alaska-news/wildlife/2023/05/25/opossum-that-ran-loose-in-homer-for-weeks-finds-a-home-at-the-alaska-zoo/">freakin'</a> <a href="https://www.adn.com/alaska-news/wildlife/2023/06/02/wildlife-officials-seek-help-as-additional-invasive-opossums-are-discovered-in-homer/">opossum</a>, it triggers my fight-or-flight. And I'm done breaking laptops! So we're sticking with the Smalltalk narrative. And breaking meta-rules instead.
					</p>
			
					<p>
					My one exposure to Smalltalk was in school. The assignment was to implement the <a href="https://en.wikipedia.org/wiki/Enigma_machine">Enigma cipher</a> in a language you didn't know. For&nbsp;extra credit, you could write a program to <a href="https://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma">crack</a> it. Excuse me? Breaking Nazi encryption is <i>optional??</i> Not in my family! We&nbsp;<b>really</b>&nbsp;need <a href="https://www.amazon.com/Anchors-Aweigh-Lynden-Benshoof-ebook/dp/B00AT35E40">Grandpa Benshoof</a> to survive D-Day! Smalltalk did the trick and I remember it fondly. My fascist decoder worked, but as the messages got longer it got slower. Really slow. Even on the expensive machines. Oh well, I wasn't getting graded on speed. Later, the department chair left a handwritten note about my impressive use of CPU cycles. The polite implication was that I would have lost us the war for want of a hash table.
					</p>
			
					<p>
					Speaking of impressions! I'm impressed with the shelf life on that Smalltalk issue. SCI was developed in 1988 and yet these technical articles from 1981 were still relevant. In a way, they're timeless. Just not timely.
					</p>
			
					<blockquote>
						<p>
						<b>When Can I Buy It?</b>
						</p>
			
						<p>
						There are currently no personal computer implementations for the Smalltalk-80
						language. Because of this, I'm sure we'll be criticized by some for introducing
						the language too early and frustrating our readers. Nevertheless, I feel that
						the time to begin exposing people to object-oriented language is <i>now</i>. Only by challenging and enticing the personal computer community can we stimulate the industry to create the machines we all dream of.
						</p>
			
						
					</blockquote>
			
					<p>
					Smalltalk fans had the programming language, but not the software. SCI fans had the opposite problem. They had years of games, and years to reverse engineer them, but the source language was a secret. How do you decompile that? What syntax do you use? If&nbsp;SCI Script was internal to Sierra, and the games only contain bytecode, then how do we know what the language looks like at all?
					</p>
			
					<p>
					<b><i>We didn't!</i></b> Not exactly. And not for a long time. But all that's over. Now we know everything.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/brief.png" alt="SCI Programming Language document by Jeff Stephenson, 1988">
					</p>
			
					<p>
					To see how far we've come, take a look at this snapshot of Lance Ewing's <a href="https://web.archive.org/web/20110729181959/http://www.scriptinterpreter.com/syntax">SCI Syntax page</a> from 2011. Lance thoroughly documented the publicly available clues to establish what was known and could be inferred about the language. Here In The Future, we have things a bit easier. Here's the original <a href="https://www.benshoof.org/blog/files/sci-programming.language.txt">language spec</a> by Jeff Stephenson himself. This document is a monument to getting things right the first time. Throughout SCI's successful nine year run, the language never changed. The details that drifted are unspeakably dull. The games from 1988 are radically different than 1996, but underneath it's all the same bytecode from the same language. This was a design goal from the start.
					</p>
			
					<blockquote>
						<p>
						The whole goal was flexibility in programming, and trying to push as much of the programming capabilities up to the game developer level rather than having them have to go into the engine as we could, and decoupling graphics and so forth to the point where you could keep extending the graphical capabilities. Because at that point it was pretty clear we're going to be getting more and more changes in hardware and everything.
						</p>
			
						
					</blockquote>
			
					<p>
					To a reverse engineer, this sounds like great news. It sounds like if you want to work with SCI scripts, you can do so universally. And&nbsp;that's true! Kinda? But also not really, because even though the bytecode is consistent, everything else is all over the map.
					</p>
			
					<p>
					When I joined the ScummVM team, Martin Kiewitz told me that the hardest part of SCI was all the versions. Now that ScummVM runs even more of them, I joke that the entire codebase is version checks. The SciVersion <a href="https://github.com/scummvm/scummvm/blob/master/engines/sci/detection.h">code</a> is a window into the madness:
					</p>
			
<pre>
<span>enum</span> <span>SciVersion</span> {
	<span>SCI_VERSION_NONE</span>,
	<span>SCI_VERSION_0_EARLY</span>, 
	<span>SCI_VERSION_0_LATE</span>, 
	<span>SCI_VERSION_01</span>, 
	<span>SCI_VERSION_1_EGA_ONLY</span>, 
	<span>SCI_VERSION_1_EARLY</span>, 
	<span>SCI_VERSION_1_MIDDLE</span>, 
	<span>SCI_VERSION_1_LATE</span>, 
	<span>SCI_VERSION_1_1</span>, 
	<span>SCI_VERSION_2</span>, 
	<span>SCI_VERSION_2_1_EARLY</span>, 
	<span>SCI_VERSION_2_1_MIDDLE</span>, 
	<span>SCI_VERSION_2_1_LATE</span>, 
	<span>SCI_VERSION_3</span> 
};
</pre>
			
					<p>
					Depending on your perspective, thirteen versions could be a little, could be a lot. But these aren't <i>real</i> versions; they're high level buckets invented by reverse engineers. Games don't cleanly fall into them. Sierra typically had three or four games in various stages of development. Meanwhile, the interpreter evolved at its own pace. Think of each release as a fork with who knows what fixes and features backported in or taken out or tweaked. Resource formats, container formats, and compression formats each change over time. So apply those fuzzy versions to every layer. And then multiply the combinations across all the patches and ports.
					</p>
			
					<p>
					If you want to write SCI software that works with more than a handful of games then these are your problems to deal with.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/kq4-disks.jpg" alt="King's Quest 4 floppy disks">
					<br>
					<i>One of these is a typo that's also a real version</i>
					</p>
			
					<p>
					God help you if you turn to SCI's version numbers. Assuming Sierra didn't typo the floppy labels, or leave the placeholder x.yy.zzz, or release a non-release version, or get the odometer stuck on 2.100.002, then they're best treated as based on a true story. Versions that start with "L.rry" aren't Leisure Suit Larry games; they're whatever Larry Scott compiled that day. Consider that ScummVM is the most comprehensive SCI software and it doesn't even attempt to look at these version numbers.
					</p>
			
					<p>
					Instead, each piece is felt out at runtime with careful heuristics, deductive inference, and deep vats of hard-coded exceptions. And&nbsp;then someone finds a German Amiga version full of anachronisms and blows it all up.
					</p>
			
					<p>
					Believe it or not, <i>I'm not complaining!</i> If these things were easy then there wouldn't be any left for me.
					</p>
			
					<p>
					But I do want to convince you that <b>Universal SCI is hard</b> and the versions are a heavy tax. We're going to talk about the reverse engineers who took on the scripts, and I want you to know what they were getting into, and appreciate how far they got.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/scistudio.png" alt="SCI Studio screenshot">
					</p>
			
					<p>
					Brian Provinciano is an SCI pioneer. In 1999 he wrote SCI Graphics Studio and set a dangerous precedent with a resource editor for Windows. This grew into SCI Studio, the first program that allowed fans to create their own EGA games. By 2002 it was out of beta and included a script editor, script compiler, and a full template game. SCI Studio was a legitimate Integrated Development Environment ‚Äî the era of fan games had begun.
					</p>
			
					<p>
					What an exciting time that must have been. And so much work! Sierra's Script was still a secret, so to write a compiler you first had to <i>reinvent the language</i>. At least there were clues to what it should look like. And the bytecode wasn't a total mystery; the names of opcodes and kernel functions were included with games for debugging. Still ‚Äî <i>sounds hard!</i> Brian took all this and developed his own script syntax with the necessary features that captured the spirit of the original, and then wrote a compiler for it. Sierra's 1980s executables happily ran the results. Nowadays we call this SCI Studio Syntax, but at the time it was the only game in town.
					</p>
			
					<p>
					Okay so you have the world's first third party SCI compiler. Now what? Well, Sierra's game programmers didn't start from scratch, they had all those system scripts we discussed earlier. So I guess you need those scripts! But if all you have is bytecode...
					</p>
			
					<blockquote>
						<p>
						I am now working on decompiling Leisure Suit Larry 2 to create the template game. It is TONS of work because my program can only disassemble, not decompile. I am having to do it all by hand. In order to write a decompiler, I would basically have to mimic the interpreter. It would be a lot of work, more work than it's worth.
						</p>
			
						
					</blockquote>
			
					<p>
					Brian later said that he spent weeks on this "long and grueling task" and manually decompiled 50-60 scripts and over 130 classes from several games. If you've never decompiled assembly code by hand then it's hard to explain this sacrifice. And I won't try, because you shouldn't be punished for good life choices. But I will say that once it's done it's done, and <i>is</i> less work than writing a decompiler.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/techtv.jpg" alt="TechTV" title="allegedly">
					<br>
					<i>Brian Provinciano with SCI Studio 3 on TechTV, March 7 2003</i>
					</p>
			
					<p>
					March 2003 was a big month. Brian released SCI Studio 3 and flew from Canada to San Francisco to appear on the TechTV show <i>Call For Help</i> to present it with Sierra fan Aaron Wester. Afterwards, he... sorry can we back up for a sec?
					</p>
			
					<p>
					Let me get this straight... you're saying that in <i>2003</i>... a <i>real</i> television studio recorded a <i>real</i> show about <b><i>SCI fan software?</i></b> And this was broadcast across real satellites to real hotel rooms all over the world? And you want <i>me</i> to believe that <i>U.S. Customs</i> believed all this?? No. Absolutely not! As&nbsp;an SCI nerd in 2023, I can't accept any of this. Nope nope nope. The Wayback Machine must have <a href="https://web.archive.org/web/20030608080619/http://www.bripro.com/news.php">crawled</a> an alternate timeline<a href="https://www.benshoof.org/blog/alternate-timeline">*</a>.
					</p>
			
					<p>
					That same month, Brian announced he was working on supporting VGA games, and had even begun writing a <i>script decompiler</i>. Over the next two years he posted status updates. He even posted entire scripts he'd decompiled from a variety of games.
					</p>
			
					<p>
					And then a hellbeast ate him.
					</p>
			
					<p>
					In 2006 Brian <a href="https://web.archive.org/web/20060418054504/http://www.bripro.com/scistudio/index.php">retired</a> from SCI and posted his remaining code, but without mentioning the decompiler. He worked on SCI Studio for many years, some while in school, and set the bar for all future tools. His goal was for people to make games and <a href="https://sciprogramming.com/fangames.php">they did</a> and they were <a href="https://sciprogramming.com/fangames.php?action=review&amp;id=32">weird</a> and that is good. ScummVM happily supports fan games so you can still run them today, and probably forever.
					</p>
			
					<p>
					As you can imagine, this left some people disappointed. Not me though. <b><i>I just found out!</i></b> Oh man... so here I am, thinking I'm ushering in the second decompiling, finish the dang thing, do the research for the announcement, and only <i>then</i> find out I've been bumped down to third.
					</p>
			
					<p>
					I'm thrilled that the SCI decompiler story is a trilogy with a lost first volume. Brian's samples and posts are now highly relevant to my interests, so I read them all. Here's the executive summary:
					</p>
			
					<p>
					Brian's decompiler was a standalone program that targeted the full range of SCI versions. The hardest part of decompiling is analyzing control flow, and when the decompiler couldn't figure that out, it generated code with goto statements. That's also what professional programs like IDA Pro and Ghidra do. Goto code isn't very readable, but the alternative is all or nothing. An impressive amount of the samples he posted were right. At one point he said that he was 90% done, but I said the same thing ‚Äî right before the other 90%. Brian's decompiler was the real deal and on track to do everything.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/scicompanion.jpg" alt="SCI Companion">
					</p>
			
					<p>
					Phil Fortier is our SCI savior. In 2007 he released SCI Companion 2 to replace SCI Studio. Phil is an independent <a href="http://www.icefallgames.com/">game developer</a> and one of his motivations was to make his own game. SCI Companion supported Brian's script syntax and the existing fan games. Like SCI Studio, it was limited to EGA games. After a few updates, things quieted down, and then got real quiet.
					</p>
			
					<p>
					<i>Eight years later</i> Phil returned with SCI Companion 3. And it had <a href="https://sciprogramming.com/community/index.php?topic=1420.0">everything</a>! There was support for VGA games, a sound editor, and... AND... an&nbsp;end to the twelve year thirst: the world finally had a script decompiler.
					</p>
			
					<p>
					When I describe SCI reverse engineering, I stress that not only have we been graced with a latter day decompiler ‚Äî against all odds ‚Äî but an excellent one. It works so well that there's little to talk about except its limitations.
					</p>
			
					<blockquote>
						<p>
						The decompiler isn't perfect, but typically it can decompile about 95 to 99 percent of a game into source code. Success is typically on a function-by-function basis. Luckily, if an error or unexpected condition occurs anywhere during the decompilation of a function, we can have the entire function fallback to assembly. This at least retains the ability to recompile code correctly, and also retains some symbol information.
						</p>
			
						
					</blockquote>
			
					<p>
					Compare this approach to Brian's goto statements. If just one thing goes wrong then SCI Companion fails a function and produces no code. The larger the function, the more likely it fails. But gotos aren't an option anymore, and for a good reason.
					</p>
			
					<p>
					Phil created a new script syntax based on the original and named it Sierra Script. It's so close to Sierra's that I can't remember the differences. I think Phil's is stricter but my parsers can't tell the difference so neither can I. Decompiled scripts look like the real thing, and that's great, and that means no gotos ‚Äî also great.
					</p>
			
					<p>
					That leaves the bugs where the decompiler silently produces incorrect code. I'm familiar with these because my decompiler stumbled on the same scripts, just louder. Causes include: unexpected optimizations, nonsensical source scripts, and impossible instructions due to compiler bugs. But these instances are so rare that you can pretend they don't exist. So sure, trust but verify, but in practice don't worry about it.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/scicompanion-version.png" alt="SCI Companion version dialog">
					</p>
			
					<p>
					The decompiler's biggest limitations aren't in its algorithms, but its ergonomics. It's a complex component in a huge Windows GUI whose primary purpose is to let fans make games. In order to even find the bytecode it has to survive the SCI version nightmare. Phil&nbsp;borrowed the version logic from ScummVM, so it supports most, but he understandably skipped some of the more annoying bits. Some versions fall between these cracks. And the SCI3 script format from the last four games is unsupported. And there's no concept of multiple CDs or Macintosh. If it's outside the mainstream then it's unavailable to the decompiler.
					</p>
			
					<p>
					These are all reasonable priorities for a program that makes fan games. No fan was going to make a seven disc Fantasmagoria. If&nbsp;you want to add support for these extras, you'll have to touch a lot of unfun C++ before you even get to the decompiler. It's been <a href="https://github.com/icefallgames/SCICompanion/">open source</a> for many years so nothing has stopped you, but that brings us to the real limitation...
					</p>
			
					<p>
					SCI Companion is a Microsoft Foundation Classes Win32 C++ codebase that no one wants to work on<a href="https://www.benshoof.org/blog/prove-me-wrong">*</a>. <i>Oh, I get it!</i> Long ago I wrote some of my favorite programs in that stuff, and I still love running them today, but I can't bring myself to look at the code again.
					</p>
			
					<p>
					There are signs of life. The Cat has a <a href="https://github.com/Kawa-oneechan/SCICompanion">fork</a> with some fixes, and Laurence Myers recently added <a href="https://github.com/Kawa-oneechan/SCICompanion/pull/15">automatic builds</a>. That's exciting, but let's not quibble over commits: Phil finished a long time ago and no one else has touched the decompiler. <i>Including me!</i> As&nbsp;you'll see, I don't even know how it works. Maybe today's release will spark some interest. For now, the decompiler is done, and that's okay.
					</p>
			
					<blockquote>
						<p>
						With a bunch more work, it should be possible to have the decompiler 100% effective (except for corrupted scripts, of course) ‚Äî but I decided that the effort vs reward wasn't worth it beyond this point, especially given the fallback to assembly.
						</p>
			
						
					</blockquote>
			
					<p>
					Phil split SCI reverse engineering into two eras: Before Companion and After Decompiler. Reverse engineering generates countless unknowns that are too impractical to investigate. There's a threshold there, and it's determined by the tools. SCI Companion's decompiler sent that threshold plummeting. I'm hoping that today's release finishes the job.
					</p>
			
					<p>
					Think of all the SCI details that were too difficult to figure out before 2015. Turn all the bytecode into high quality text, and people like us can knock them out with one grep. It's fun! It has to be ‚Äî <i>it's cheating!</i>
					</p>
			
					<p>
					But you can have too much fun, so you have to be careful. Or else you could end up with a hobby.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/sluicebox.png" alt="my avatar" title="my original sin: forgot to adjust the aspect ratio">
					</p>
			
					<p>
					Here's where I enter the story:
					</p>
			
					<blockquote>
						<p>
						It's important to have goals, or so I'm told by several reputable hashtags. In the 90s mine were to solve The Colonel's Bequest, and more importantly, The Dagger of Amon Ra. It was clear that merely playing them wasn't going to cut it. As&nbsp;time passed I would occasionally check in on the Sierra scene and when SCI Viewer dropped so did my hopes.
						</p>
			
						<p>
						SCI Viewer revealed that there was indeed a lot more to these cases but that the answers were all in the scripts. At the time, this meant reams of intolerably low level disassembly text. This wouldn't do for the high level answers I sought. "I'll&nbsp;come back later." In 2015 it was later, and lo, for Phil Fortier released from the heavens SCI Companion 3.0 with an honest to goodness script decompiler. It had been twenty years but not only could my investigation now proceed, it <i>had</i> to.
						</p>
			
						
					</blockquote>
			
					<p>
					I don't know exactly when I discovered SCI Companion 3, but I remember feeling lucky. It must have been pretty new, because it crashed so much that I couldn't use it. Before giving up, I tried compiling the latest code ‚Äî the last refuge of a scoundrel. It wouldn't build, some MFC or SDK thing, the usual strife. <i>"Just when I think I'm out."</i> After some begrudging hacks, it built. SCI Companion was stable as a table and I've built from source ever since. More luck! The miracle I'd been waiting for hinged on latent knowledge of the Windows API. I bore witness and became a decompiler disciple.
					</p>
			
					<p>
					I quickly hit my limits with the scripts. Remember that first example? It's great by decompiler standards, but it's still not good enough for solving complex things like a <a href="https://www.benshoof.org/blog/super-sleuth">Sleuth-O-Meter</a>. It was taking too long to get my bearings in the game code and I didn't even know the language. <i>I didn't know anything!</i> But I did know the messages that appear in the games.
					</p>
			
					<p>
					<a href="https://web.archive.org/web/20080413035345/http://www.geocities.com/sciviewer/">SCI Viewer</a> had command line tools that could dump resources and export game messages as XML. Script those up, write some regular expressions to parse out message tuples, and baby you got a stew going: one ham-fisted message annotator. No knowledge of SCI internals required. I had my foothold! Now I could get around in these message-heavy games and build from there.
					</p>
			
					<p>
					As my tools grew they set off a cycle. A typical pattern: first my parser trips on something, then I investigate and crash ScummVM, then I investigate with ScummVM's debugger and crash that, and finally it turns out that none of this ever worked and the game has been crashing since 1990. By the time it was over I'd have fixed my bug, the ScummVM bug, the debugger, and written a script patch in bytecode to fix the game. Bonus points if there was a ten year old ticket in the bug tracker. Then my parsers would scan for similar anomalies across other games and it would start all over.
					</p>
			
					<p>
					I didn't mean to build a bug hunting machine, I just wrote some parsers that weren't very bright, and things got out of hand.
					</p>
			
					<p>
					<a href="https://github.com/scummvm/scummvm/graphs/contributors">
					<img src="https://www.benshoof.org/blog/images/scummvm-stats.png" alt="ScummVM contributor statistics">
					</a>
					</p>
			
					<p>
					As I learned more, I wrote proper parsers, and the annotators flourished. I was closing a lot of ScummVM tickets thanks to my decompiled scripts. But as you'll recall, SCI Companion doesn't support everything. If I couldn't decompile, then I couldn't do much. The open tickets were starting to hint at which games and versions were outside of SCI Companion's purview. So I wrote some programs to bring them into the fold. The first one converted <a href="https://www.benshoof.org/blog/quest-for-glory-i-macintosh-easter-egg">Macintosh scripts</a> to DOS with a bunch of byte-swapping. The second program downgraded SCI3 scripts to SCI2, which is so insane that I named it Conversion Therapy. Now I could decompile and annotate everything, and without touching SCI Companion's code. The tickets continued to close and the writing queue <a href="https://www.benshoof.org/blog/archive">grew</a>.
					</p>
			
					<p>
					Eventually I had a big problem: the annotated scripts had gotten too good to keep to myself. But they weren't good enough to release. Even if they were, they weren't the products of a program, but a process. Then I realized just how many imperfections I was working around, reverting, or tolerating. <i>Hell's horses!</i> I'd outgrown the SCI Companion decompiler.
					</p>
			
					<p>
					Obviously the problem with this pipeline is that it runs through an unmaintained Windows GUI. Obviously the solution is to replace it. Obviously there are problems with that solution:
					</p>
			
					<ol>
					<li>
					It rather involves writing a decompiler
					</li>
					<li>
					Phil's is a tough act to follow!
					</li>
					</ol>
			
					<p>
					There was hope. Phil left a map: a <a href="https://mtnphil.wordpress.com/2016/04/09/decompiling-sci-byte-code-part-1/">four</a> <a href="https://mtnphil.wordpress.com/2016/04/09/decompiling-sci-part-2-control-flow/">part</a> <a href="https://mtnphil.wordpress.com/2016/04/09/decompiling-sci-part-3-instruction-consumption/">blog</a> <a href="https://mtnphil.wordpress.com/2016/04/09/decompiling-sci-part-4-final-steps/">series</a> on decompiling SCI ‚Äî a masterclass in accessible technical writing. By now I've read a lot of decompiler literature and Phil's articles are still the best. If you want to decompile any kind of bytecode, start there.
					</p>
			
					<p>
					And so last year I used Phil's guide and started writing a decompiler, failed, tried again this year, and succeeded. I later learned that Phil also shelved his first attempt. I'd love to talk about how mine works, but we'll save that for another day. I owe us a full write-up about what it takes to get to one hundred percent.
					</p>
			
					<p>
					Yes, that's right: <b>One Hundred Percent</b>. Brian's decompiler produced goto statements. Phil's fell back to assembly. I didn't want to do either, so mine fully decompiles every function in every Sierra script. No need to write fallback code if you never fail!
					</p>
			
					<table>
						<tbody><tr>
							<th></th>
							<th>Total</th>
							<th>Solved</th>
							<th></th>
						</tr>
						<tr>
							<td>Games</td>
							<td>319</td>
							<td>319</td>
							<td>100%</td>
						</tr>
						<tr>
							<td>Scripts</td>
							<td>65,567</td>
							<td>65,567</td>
							<td>100%</td>
						</tr>
						<tr>
							<td>Functions</td>
							<td>818,796</td>
							<td>818,796</td>
							<td>100%</td>
						</tr>
						<tr>
							<td>Loop Functions</td>
							<td>46,666</td>
							<td>46,666</td>
							<td>100%</td>
						</tr>
						<tr>
							<td>Loops</td>
							<td>66,761</td>
							<td>66,761</td>
							<td>100%</td>
						</tr>
					</tbody></table>
			
					<p>
					You crave caveats. Well, there could be silent failures I don't know about. It seems like there must be some in all that text. Find 'em and I'll fix 'em. But the last bug affected only <i>one</i> function, and it was from a bug in Sierra's compiler, and that was a while ago. So&nbsp;I don't know what to think. As I mentioned, there are also a few versions I don't have. Maybe you do? It's mostly a handful of localized games. I don't expect any exciting scripts, but who knows? Help me find out!
					</p>
			
					<p>
					SCI Companion will always be the best way to view scripts, so I've packaged mine to be compatible; you just need the game. You can try compiling the scripts, but you're on your own there. It might work! Just remember that the version detection in SCI Companion is incomplete, so it can misinterpret accurate symbols like kernel functions. Maybe you'll fix it?
					</p>
			
					<p>
					I wish my work produced fixes for SCI Companion, but the projects didn't overlap. For one thing, I didn't use C++, because #selfcare. Bigger obstacle: I don't really know how the other decompiler works. Phil's articles are <i>so good</i> that I didn't need the code to design my own. The two decompilers must be pretty different though, because I came up with my algorithms by staring at a mess of graphs until blacking out. <i>(Dramatization! ...I Think!)</i>
					</p>
			
					<p>
					Speaking of drama! ...There's one more thing.
					</p>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/codepink.jpg" alt="sierra disk in a pink drive">
					</p>
			
					<p>
					<i>Original Sierra source code.</i> That subject has been off limits, but thanks to recent events I can relax that rule. If there's anything good about performance art, it's the unexpected. I consider this performance art, and I didn't expect to be presented with a Sierra cache on deep background. There's a good story there, but it's not mine to tell. The important thing, I told myself, is that it's found its way into enough hands that it won't get lost ‚Äî and won't stay underground forever.
					</p>
			
					<p>
					On Christmas Day, Jason Scott discreetly posted the original scripts for nine Sierra games to the <a href="https://archive.org/details/sierrasourcecode">Internet Archive</a>. They're also on <a href="https://github.com/historicalsource/">github</a>. I'm happy (and relieved) that we can discuss these publicly, but I have to tell you... as exciting as real source code is, annotated decompiled scripts are <i>so much more useful</i>. But you're hard to convince. So I wrote one more annotator...
					</p>
			
					<p>
					<b>My decompiled scripts include Sierra's symbols ‚Äî <i>even ones not publicly available!</i></b> The annotator extracts the names of functions and variables from my cache of original scripts and matches them to decompiled scripts. Every game benefits because I also have original system scripts. Of course, if one or two games whose scripts <i>haven't</i> been posted were to have <b><i>all</i></b> of their symbols, that could raise some questions. <i>Not to worry!</i> This blog doesn't have comments.
					</p>
			
					<p>
					Speaking of comments! Let's end with one of Jeff's, the gentleman who got us into this mess. I think it will resonate with every ScummVM developer, and anyone else who plays computer games as an adult by making graphs full of assembly.
					</p>
			
					<blockquote>
						<p>
						While I did play some of the games just to see how they worked, and actually I probably played Space Quest more just because it was such a gas, but I was pretty unaware of the actual game involved. So my involvement was really at doing the tools that allowed the games to be built, and I encountered the games sort of off and on, but eh they're all just the animated things that are stories, they're not the fun part.
						</p>
					</blockquote>
			
					<p>
					<img src="https://www.benshoof.org/blog/images/decompiler-graph.png" alt="decompiler graph" title="the fun part!">
					<br>
					<i>Deoptimized basic blocks in a control flow graph</i>
					</p>
			
					<p>
					<br>
					<span><blink>**JOB DONE**</blink></span> ‚Äî SCI is decompiled, I hope you have fun. Because I broke a lot of rules today. <i>And I wrote a decompiler!</i>
					</p>
			
					<p>
					<b><i>And I gave away the farm!</i></b>
					</p>
			
					<p>
					See, I've still got this writing queue of Sierra discoveries here, and while nothing has ever stopped <i>you</i> from finding them yourself... <i>it&nbsp;just got a heck of a lot easier!</i> So go ahead and scoop me. You can even do your own write-ups! In fact, I'd love to read them. All I ask is that you do a good job and don't skimp on the NewsRadio references. We'll call it outsourcing and they'll call me <a href="https://www.benshoof.org/blog/macho-business-donkey-wrestler">genius</a>.
					</p>
			
					<p>
					Otherwise I'll keep getting to them in my own sweet time. <i>Or faster!</i> ‚Äî if you can just get me back on the <a href="https://en.wikipedia.org/wiki/Paycheck_Protection_Program">dole</a>...
					</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Please don't say just hello in chat (108 pts)]]></title>
            <link>https://nohello.net/en/</link>
            <guid>36623348</guid>
            <pubDate>Thu, 06 Jul 2023 21:29:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nohello.net/en/">https://nohello.net/en/</a>, See on <a href="https://news.ycombinator.com/item?id=36623348">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wholesite">
  <div>
      
      <p><span>please don't say just hello in chat</span></p><h2>
        Imagine calling someone on the phone, going <em>hello!</em> then putting them on hold... ü§¶‚Äç‚ôÄÔ∏è
      </h2>
    </div>

  <div>
    <div>
      <h2>‚ùå Don't do this</h2>
      <div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/MxF06xdCHJ-128.webp 128w"><img alt="Keith's Slack avatar" src="https://nohello.net/img/MxF06xdCHJ-128.jpeg" width="128" height="128"></picture>
          <p><span>Keith</span>
          <span>2:15 PM</span><br>
          <span>hi</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:19 PM</span><br>
          <span>...?</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/MxF06xdCHJ-128.webp 128w"><img alt="Keith's Slack avatar" src="https://nohello.net/img/MxF06xdCHJ-128.jpeg" width="128" height="128"></picture>
          <p><span>Keith</span>
          <span>2:20 PM</span><br>
          <span>what time was taht thing again?</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:20 PM</span><br>
          <span>oh - 3:30 mate</span>
        </p></div>
      </div>
    </div>
    <div>
          <p>Note that Keith could have got his answer minutes sooner, and needn't have kept Tim waiting. In fact, Tim could have started thinking about the question right away!</p>
<p>People who do this are generally trying to be polite by not jumping right into the request, like one would in person or on the phone - and that's great! But it's 2022 and chat is neither of those things. For most people, typing is much slower than talking. So despite best intentions, <strong>you're actually just making the other person wait</strong> for you to phrase your question, which is lost productivity (and kinda annoying).</p>
<p>The same goes for:</p>
<ul>
<li>"Hello, are you around?"</li>
<li>"hi sophie - quick question."</li>
<li>"You got a sec?"</li>
<li>"yt?"</li>
<li>"ping"</li>
<li>etc.</li>
</ul>
<p><strong>Just ask the question!</strong> üò´</p>

        </div>
  </div>
  <div>
    <div>
      <h2>‚úÖ Instead try this</h2>
      <div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/4gebfK1xtc-128.webp 128w"><img alt="Dawn's Slack avatar" src="https://nohello.net/img/4gebfK1xtc-128.jpeg" width="128" height="128"></picture>
          <p><span>Dawn</span>
          <span>2:15 PM</span><br>
          <span>Hiya! What time was that thing?</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:15 PM</span><br>
          <span>hey, 3:30</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/4gebfK1xtc-128.webp 128w"><img alt="Dawn's Slack avatar" src="https://nohello.net/img/4gebfK1xtc-128.jpeg" width="128" height="128"></picture>
          <p><span>Dawn</span>
          <span>2:15 PM</span><br>
          <span>Ta - seeya then!</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:16 PM</span><br>
          <span>üëå np</span>
        </p></div>
      </div>
    </div>
    <div>
          <p>If you feel it's a bit brusque to simply say "Hi" and ask the question, <strong>you can still preface your message with as many pleasantries as you see fit.</strong></p>
<p>For example:</p>
<ul>
<li>"hey man, what's up? also, any idea when that thing's due?"</li>
<li>"Hi there! Hope you're well. I'm after the latest deck, when you get a sec :)"</li>
<li>"hey, if you're not busy, could you update those NFRs?"</li>
<li>etc.</li>
</ul>
<p>It may seem trivial, but asking your question before getting that initial salutatory reply also allows for <strong>asynchronous communication</strong>. If the other party is away, and you leave before they come back, they can still answer your question, instead of just staring at a "Hello" and wondering what they missed.</p>
<p>When done right - everyone's happy! üéâ</p>

        </div>
  </div>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[‚ÄúSelf-reflecting‚Äù AI agents explore like animals (187 pts)]]></title>
            <link>https://hai.stanford.edu/news/ai-agents-self-reflect-perform-better-changing-environments</link>
            <guid>36622959</guid>
            <pubDate>Thu, 06 Jul 2023 21:00:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hai.stanford.edu/news/ai-agents-self-reflect-perform-better-changing-environments">https://hai.stanford.edu/news/ai-agents-self-reflect-perform-better-changing-environments</a>, See on <a href="https://news.ycombinator.com/item?id=36622959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span><span><span><span><span>Who </span>would you pick to win in a head-to-head competition ‚Äî a state-of-the-art AI agent or a mouse? <a href="https://neuroscience.stanford.edu/people/isaac-kauvar">Isaac Kauvar</a>, a Wu Tsai Neurosciences Institute <a href="https://neuroscience.stanford.edu/research/training/postdoctoral-scholar-awards">interdisciplinary postdoctoral scholar</a>, and Chris Doyle, a machine learning researcher at Stanford, decided to pit them against each other to find out. Working in the lab of <a href="https://ed.stanford.edu/faculty/nhaber">Nick Haber</a>, an assistant professor in the Stanford Graduate School of Education, Kauvar and Doyle designed a simple task based on their longtime interest in a skill set that animals naturally excel at: exploring and adapting to their surroundings. </span></span></span></span></span></p>

<p><span><span><span><span><span><span>Kauvar put a mouse in a small empty box and similarly put a simulated AI agent in an empty 3D virtual arena. Then, he placed a red ball in both environments. Kauvar measured to see which would be the quicker to explore the new object.</span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>The test showed that the mouse quickly approached the ball and repeatedly interacted with it over the next several minutes. But the AI agent didn‚Äôt seem to notice it. ‚ÄúThat wasn‚Äôt expected,‚Äù said Kauvar. ‚ÄúAlready, we were realizing that even with a state-of-the-art algorithm, there were gaps in performance.‚Äù </span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>The scholars pondered: Could they use such seemingly simple animal behaviors as inspiration to improve AI systems?&nbsp; </span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>That question catalyzed Kauvar, Doyle, graduate student Linqi Zhou, and Haber to design a new training method called curious replay, which programs AI agents to self-reflect about the most novel and interesting things they recently encountered. Adding curious replay was all that was needed for the AI agent to approach and engage with the red ball much faster. Plus, it dramatically improved performance on a game based on Minecraft, called Crafter. The results of this project, currently published on </span><a href="https://arxiv.org/abs/2306.15934"><span>preprint service arXiv</span></a><span>, will be presented at the International Conference on Machine Learning on July 25. </span></span></span></span></span></span></p>

<h2><span><span><span><span><span><span>Learning Through Curiosity</span></span></span></span></span></span></h2>

<p><span><span><span><span><span><span>It may seem like curiosity offers only intellectual benefits, but it‚Äôs crucial to our survival, both in avoiding dangerous situations and finding necessities like food and shelter. That red ball in the experiment could be leaking a deadly poison or covering a nourishing meal, and it would be difficult to find out which if we ignore it. </span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>That‚Äôs why labs like Haber‚Äôs have recently been adding a curiosity signal to drive the behavior of AI agents and, in particular, model-based deep reinforcement learning agents. This signal tells them to select the action that will lead to a more interesting outcome, like opening a door rather than disregarding it. </span></span></span></span></span></span></p>

<blockquote>
<p><em><span><span><span><span><span><span>Read the full study,&nbsp;</span></span></span></span></span></span><a href="https://arxiv.org/abs/2306.15934">Curious Replay for Model-based Adaptation</a></em></p>
</blockquote>



<p><span><span><span><span><span><span>But this time, the team used curiosity for AI in a new way: to help the agent learn about its world, not just make a decision. ‚ÄúInstead of choosing what to do, we want to choose what to think about, more or less ‚Äî what experiences from our past do we want to learn from.‚Äù said Kauvar. In other words, they wanted to encourage the AI agent to self-reflect, in a sense, about its most interesting or peculiar (and thus, curiosity-related) experiences. That way, the agent may be prompted to interact with the object in different ways to learn more, which would guide its understanding of the environment and perhaps encourage curiosity toward additional items, too.</span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>To accomplish self-reflection in this way, the researchers amended a common method used to train AI agents, called experience replay. Here, an agent stores memories of all its interactions and then replays some of them at random to learn from them again. It was inspired by research on sleep: Neuroscientists have found that a brain region called the hippocampus will ‚Äúreplay‚Äù events of the day (by reactivating certain neurons) to strengthen memories. In AI agents, experience replay has led to high performance in scenarios where the environment rarely changes and clear rewards are given for the right behaviors. </span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>But to be successful in a changing environment, the researchers reasoned that it would make more sense for AI agents to prioritize replaying primarily the most interesting experiences ‚Äî like the appearance of a new red ball ‚Äî&nbsp;rather than replaying the empty virtual room over and over. </span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>They named their new method curious replay and found that it worked immediately. ‚ÄúNow, all of a sudden, the agent interacts with the ball much more quickly,‚Äù said Kauvar. </span></span></span></span></span></span></p>

<p><span><span><span><span><span><span>But they didn‚Äôt stop there. They also added curious replay to AI agents playing a game called Crafter, a standard test of creative problem solving for AI agents, </span><span>where ‚Äî much like in Minecraft ‚Äî agents have to figure out how to survive and adapt by learning how to </span><span>collect wood and stone, make a pickaxe, and collect iron to make additional tools</span><span>.</span><span> The curious replay method boosted the current state-of-the-art score from around 14 up to 19 (humans typically score around 50) ‚Äî with ‚Äújust this one change,‚Äù said Kauvar. </span></span></span></span></span></span></p>

<h2><span><span><span><span><span><span>A Curious Future</span></span></span></span></span></span></h2>

<p><span><span><span><span><span><span>The success of the curious replay method in both simple and complex tasks suggests that it will be important for a vast array of AI research moving forward. </span><span><span>‚Äú</span></span><span><span>The overall aim of this work ‚Äî to make agents that can leverage prior experience and adapt well by efficiently exploring new or changing environments ‚Äî will lead to much more adaptive, flexible technologies, from household robotics to personalized learning tools,‚Äù said Haber. </span></span></span></span></span></span></span></p>

<p><span><span><span><span><span><span><span>Kauvar, whose </span></span><a href="https://neuroscience.stanford.edu/research/funded-research/dissecting-curious-exploration-self-supervised-machine-learning"><span>postdoctoral work</span></a><span><span> is jointly mentored by Haber and neuroscientist Karl Deisseroth, the D.H Chen Professor in the departments of Bioengineering and Psychiatry, is excited to continue the theme of taking inspiration from animal behavior to improve AI systems ‚Äî he plans to continue testing mice and AI agents on more complicated tasks to compare their behavior and abilities. ‚ÄúLots of people give lip service to saying that they're inspired by animals, but here we are building a direct bridge ‚Äî not a vague bridge. We are trying to do the exact same [tasks],‚Äù he said. </span></span></span></span></span></span></span></p>

<p><span><span><span><span>Kauvar hopes that work like this will help ‚Äúclose the loop‚Äù between AI research and neuroscience and benefit our understanding of animal behavior and the underlying neural processes, too. ‚ÄúYou can imagine that this whole approach might yield hypotheses and new experiments that would never have been thought of before,‚Äù he said.</span></span></span></span></p>

<p><em>Stanford HAI‚Äôs mission is to advance AI research, education, policy and practice to improve the human condition.&nbsp;</em><a href="https://hai.stanford.edu/welcome"><strong><em>Learn more</em></strong></a><em>.&nbsp;</em>&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stanford Graduate Students Won Their Union Vote (182 pts)]]></title>
            <link>https://twitter.com/StanfordGWU/status/1677048098080845824</link>
            <guid>36622691</guid>
            <pubDate>Thu, 06 Jul 2023 20:43:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/StanfordGWU/status/1677048098080845824">https://twitter.com/StanfordGWU/status/1677048098080845824</a>, See on <a href="https://news.ycombinator.com/item?id=36622691">Hacker News</a></p>
Couldn't get https://twitter.com/StanfordGWU/status/1677048098080845824: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Twitter is threatening to sue Meta over Threads [pdf] (135 pts)]]></title>
            <link>https://cdn.sanity.io/files/ifn0l6bs/production/27109f01431939c8177d408d3c9848c3b46632cd.pdf</link>
            <guid>36621741</guid>
            <pubDate>Thu, 06 Jul 2023 19:46:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cdn.sanity.io/files/ifn0l6bs/production/27109f01431939c8177d408d3c9848c3b46632cd.pdf">https://cdn.sanity.io/files/ifn0l6bs/production/27109f01431939c8177d408d3c9848c3b46632cd.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36621741">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Threads profiles can't be deleted without removing your entire Instagram account (187 pts)]]></title>
            <link>https://www.theverge.com/2023/7/6/23786029/instagram-threads-profiles-deleted-removing</link>
            <guid>36621526</guid>
            <pubDate>Thu, 06 Jul 2023 19:32:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/7/6/23786029/instagram-threads-profiles-deleted-removing">https://www.theverge.com/2023/7/6/23786029/instagram-threads-profiles-deleted-removing</a>, See on <a href="https://news.ycombinator.com/item?id=36621526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If you‚Äôre already tired of Threads and want to delete your account, you can‚Äôt do that right now unless you delete <em>your entire</em> Instagram account. However, Meta is ‚Äúlooking into‚Äù a way for that not to be the case, <a href="https://www.threads.net/t/CuXRXDdNOtH/?igshid=MzRlODBiNWFlZA%3D%3D">according to a post from Instagram chief Adam Mosseri on Thursday</a>.</p><p>Threads, Meta‚Äôs just-launched Twitter competitor, uses Instagram‚Äôs account system. That has the benefit of letting you bring over your Instagram username when you join the app. But it also ties the apps together in such a way that means you can‚Äôt delete your Threads account without deleting your Instagram one, which people may not want to do if they‚Äôve been posting on Instagram proper for years.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="A screenshot of Adam Mosseri‚Äôs post about deleting Threads accounts. ‚ÄúI‚Äôve been getting some questions about deleting your account. To clarify, you can deactivate your Threads account, which hides your Threads profile and content, you can set your profile to private, and you can delete individual threads posts ‚Äì all without deleting your Instagram account. Threads is powered by Instagram, so right now it‚Äôs just one account, but we‚Äôre looking into a way to delete your Threads account separately.‚Äù" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/376x152/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/384x155/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/415x168/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/480x194/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/540x218/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/640x258/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/750x303/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/828x334/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/1080x436/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/1200x484/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/1440x581/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/1920x775/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/2048x827/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/2400x969/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:654x264/2400x969/filters:focal(327x132:328x133):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773452/Screenshot_2023_07_06_at_10.24.10_AM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Here‚Äôs </em><a href="https://www.threads.net/t/CuXRXDdNOtH/"><em>Mosseri‚Äôs post</em></a><em> about deleting your Threads account.</em></figcaption> <p><cite>Screenshot by Jay Peters / The Verge</cite></p></div></div><p>Based on Mosseri‚Äôs message, it sounds like the company is considering a way for you to do that in the future. But the feature isn‚Äôt here yet, and Mosseri didn‚Äôt give a timeline for when we might eventually see it.</p><p>However, as Mosseri notes, you can <em>hide</em> your Threads profile and content by deactivating your Threads account. To do that, go to your profile tab, tap the two lines icon for settings, tap ‚ÄúAccount,‚Äù tap ‚ÄúDeactivate profile,‚Äù and then the ‚ÄúDeactivate Threads profile‚Äù button. That said, deactivating a Threads profile is a temporary action; although deactivating your Threads profile hides your profile, threads, replies, and likes, your account will be reactivated if you log back in, according to <a href="https://help.instagram.com/558007373138554">an Instagram support page</a>. You can also delete individual posts or take your account private, Mosseri notes.</p><p>Instagram launched Threads <a href="https://www.theverge.com/2023/7/5/23784263/instagram-threads-app-download-iphone-android">on Wednesday on iOS and Android</a>, and more than 30 million people have already signed up for the app, <a href="https://www.theverge.com/2023/7/6/23785630/instagrams-threads-app-already-has-over-25-million-registered-accounts">according to Mark Zuckerberg</a>. However, the company seems to have pushed the app out the door as soon as it could to capitalize on <a href="https://www.theverge.com/2023/7/1/23781198/twitter-daily-reading-limit-elon-musk-verified-paywall">the chaos</a> <a href="https://www.theverge.com/2023/7/3/23783092/twitter-tweetdeck-new-preview-force-legacy-apis">over at Twitter</a>, and it‚Äôs missing major features like DMs, a following feed, and even hashtags. In a separate post, Mosseri says that many of the ‚Äúbasics‚Äù are on the way but cautions that the improvements will <a href="https://www.threads.net/t/CuW3CzRtm9z/">‚Äútake time.‚Äù</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zink brings conformant OpenGL on Imagination GPUs (130 pts)]]></title>
            <link>https://www.collabora.com/news-and-blog/news-and-events/zink-on-imagination-gpus.html</link>
            <guid>36621263</guid>
            <pubDate>Thu, 06 Jul 2023 19:12:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.collabora.com/news-and-blog/news-and-events/zink-on-imagination-gpus.html">https://www.collabora.com/news-and-blog/news-and-events/zink-on-imagination-gpus.html</a>, See on <a href="https://news.ycombinator.com/item?id=36621263">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><img src="https://www.collabora.com/assets/images/blog/author/Erik-Faye-Lund.jpg" alt="Erik Faye-Lund avatar">
</p>
<p>Erik Faye-Lund <br>July 06, 2023</p>

</div><div>
<p>Today, <a href="https://www.imaginationtech.com/" target="_blank" rel="noopener">Imagination Technologies</a> announced some very exciting news: they are now <a href="https://blog.imaginationtech.com/imagination-gpus-now-support-opengl-4.6" target="_blank" rel="noopener">using Zink for full OpenGL 4.6 support</a>! Collabora had the pleasure of working together with engineers from Imagination to make this a reality, and it's very rewarding to now be able show the results to the world!</p>
<p>This is the first time we've seen a hardware vendor trust the OpenGL-on-Vulkan Mesa driver enough to completely <em>side-step</em> a native OpenGL driver and use it in a <em>shipping product</em>. It's wonderful to see that Zink can realistically be used as a work-horse, <strong>especially</strong> in a high-performance graphics setting.</p>
<p>Zink <a href="https://www.collabora.com/news-and-blog/blog/2018/10/31/introducing-zink-opengl-implementation-vulkan/" target="_blank" rel="noopener">started out</a> as a small R&amp;D project at Collabora, but has since grown to be a full-on community project. None of this would have been possible without the awesome work done by <a href="https://www.supergoodcode.com/" target="_blank" rel="nofollow noreferrer noopener">Mike</a> and the other Zink contributors!</p>
<h3>Conformance</h3>
<p>One small detail from Imagination's post that I think is important to highlight is that the solution is <a href="https://www.khronos.org/conformance/adopters/conformant-products/opengl#submission_332" target="_blank" rel="nofollow noreferrer noopener">officially conformant</a>. This is the first product to be officially conformant using Zink, but it's not going to be the last! In fact, we only need one more conformant implementation before Zink itself is conformant as a generic layered implementation, according to the Khronos <a href="https://www.khronos.org/files/conformance_procedures.pdf" target="_blank" rel="nofollow noreferrer noopener">Conformant Product Criteria</a>.</p>
<h3>An Open Source graphics future</h3>
<p>In the not too distant future, we should be able to combine Zink with the in-progress <a href="https://developer.imaginationtech.com/open-source-gpu-driver/" target="_blank" rel="nofollow noreferrer noopener">open source driver</a> from Imagination, and that's when things will <em>really</em> start to shine for the open source graphics stack on Imagination hardware. So there's plenty more to look forward to here!</p>

<!-- Related Blogs -->



<!-- end of Related Blogs -->





<!-- Optional comments block -->

<!-- end of Optional comments block -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 API General Availability (689 pts)]]></title>
            <link>https://openai.com/blog/gpt-4-api-general-availability</link>
            <guid>36621120</guid>
            <pubDate>Thu, 06 Jul 2023 19:03:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/blog/gpt-4-api-general-availability">https://openai.com/blog/gpt-4-api-general-availability</a>, See on <a href="https://news.ycombinator.com/item?id=36621120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><!--[--><div><p>Starting today, all paying API customers have access to GPT-4. In March, we <a href="https://openai.com/blog/introducing-chatgpt-and-whisper-apis" rel="noopener noreferrer" target="_blank">introduced the ChatGPT API</a>, and earlier this month we <a href="https://openai.com/blog/function-calling-and-other-api-updates" rel="noopener noreferrer" target="_blank">released our first updates</a> to the chat-based models. We envision a future where chat-based models can support any use case.&nbsp;Today we‚Äôre announcing a deprecation plan for older models of the Completions API, and recommend that users adopt the Chat Completions API.<br></p></div><div id="gpt-4-api-general-availability" data-heading=""><p><h2>GPT-4 API general availability</h2></p></div><div><p>GPT-4 is our most capable model. Millions of developers have requested access to the GPT-4 API since March, and the range of <a href="https://openai.com/customer-stories" rel="noopener noreferrer" target="_blank">innovative products</a> leveraging GPT-4 is growing every day. Today all existing API developers with a history of successful payments can access the GPT-4 API with 8K context. We plan to open up access to new developers by the end of this month, and then start raising rate-limits after that depending on compute availability.</p><p>Based on the stability and readiness of these models for production-scale use, we are also making the GPT-3.5 Turbo, DALL¬∑E and Whisper APIs generally available. We are working on safely enabling fine-tuning for GPT-4 and GPT-3.5 Turbo and expect this feature to be available later this year.<br></p></div><div id="moving-from-text-completions-to-chat-completions" data-heading=""><p><h2>Moving from text completions to chat completions</h2></p></div><div><p>We introduced the <a href="https://platform.openai.com/docs/guides/gpt/chat-completions-api" rel="noopener noreferrer" target="_blank">Chat Completions API</a> in March, and it now accounts for 97% of our API GPT usage.&nbsp;</p><p>The initial Completions API was introduced in June 2020 to provide a freeform text prompt for interacting with our language models. We‚Äôve since learned that we can often provide better results with a more structured prompt interface. The chat-based paradigm has proven to be powerful, handling the vast majority of previous use cases and new conversational needs, while providing higher flexibility and specificity. In particular, the Chat Completions API‚Äôs structured interface (e.g., system messages, function calling) and multi-turn conversation capabilities enable developers to build conversational experiences and a broad range of completion tasks. It also helps lower the risk of prompt injection attacks, since user-provided content can be structurally separated from instructions.<br></p></div><div><!--[--><figure><figcaption> Text summarization </figcaption></figure><figure><figcaption> Code completion </figcaption></figure><figure><figcaption> Few-shot learning </figcaption></figure><!--]--></div><div><p>We plan to continue investing most of our platform efforts in this direction, as we believe it will offer an increasingly capable and easy-to-use experience for developers. We‚Äôre working on closing the last few remaining gaps of the Chat Completions API quickly, such as log probabilities for completion tokens and increased steerability to reduce the ‚Äúchattiness‚Äù of responses.<br></p></div><div id="deprecation-of-older-models-in-the-completions-api" data-heading=""><p><h2>Deprecation of older models in the Completions API</h2></p></div><div><p>As part of our increased investment in the Chat Completions API and our efforts to optimize our compute capacity, in 6 months we will be retiring some of our older models using the Completions API. While this API will remain accessible, we will label it as ‚Äúlegacy‚Äù in our developer documentation starting today. We plan for future model and product improvements to focus on the Chat Completions API, and do not have plans to publicly release new models using the Completions API.</p><p>Starting January 4, 2024, <a href="https://platform.openai.com/docs/deprecations" rel="noopener noreferrer" target="_blank">older completion models</a> will no longer be available, and will be replaced with the following models:<br></p></div><div><table>
	<tbody>
		<tr>
			<td>
				<span>Older model</span>
			</td>
			<td>
				<span>New model</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>ada</span>
			</td>
			<td>
				<span>ada-002</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>babbage</span>
			</td>
			<td>
				<span>babbage-002</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>curie</span>
			</td>
			<td>
				<span>curie-002</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>davinci</span>
			</td>
			<td>
				<span>davinci-002</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>davinci-instruct-beta</span>
			</td>
			<td rowspan="8">
				<span>gpt-3.5-turbo-instruct</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>curie-instruct-beta</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>text-ada-001</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>text-babbage-001</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>text-curie-001</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>text-davinci-001</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>text-davinci-002</span>
			</td>
		</tr>
		<tr>
			<td>
				<span>text-davinci-003</span>
			</td>
		</tr>
	</tbody>
</table></div><div><p>Applications using the stable model names for base GPT-3 models (<code>ada</code>, <code>babbage</code>, <code>curie</code>, <code>davinci</code>) will automatically be upgraded to the new models listed above on January 4, 2024. The new models will also be accessible in the coming weeks for early testing by specifying the following model names in API calls: <code>ada-002</code>, <code>babbage-002</code>, <code>curie-002</code>, <code>davinci-002</code>.</p><p>Developers using other older completion models (such as <code>text-davinci-003</code>) will need to manually upgrade their integration by January 4, 2024 by specifying <code>gpt-3.5-turbo-instruct</code> in the ‚Äúmodel‚Äù parameter of their API requests. <code>gpt-3.5-turbo-instruct</code> is an InstructGPT-style model, trained similarly to <code>text-davinci-003</code>. This new model is a drop-in replacement in the Completions API and will be available in the coming weeks for early testing.</p><p>Developers wishing to continue using their fine-tuned models beyond January 4, 2024 will need to fine-tune replacements atop the new base GPT-3 models (<code>ada-002</code>, <code>babbage-002</code>, <code>curie-002</code>, <code>davinci-002</code>), or newer models (<code>gpt-3.5-turbo</code>, <code>gpt-4</code>). Once this feature is available later this year, we will give priority access to GPT-3.5 Turbo and GPT-4 fine-tuning to users who previously fine-tuned older models. We acknowledge that migrating off of models that are fine-tuned on your own data is challenging. We will be providing support to users who previously fine-tuned models to make this transition as smooth as possible.</p><p>In the coming weeks, we will reach out to developers who have recently used these older models, and will provide more information once the new completion models are ready for early testing.<br></p></div><div id="deprecation-of-older-embeddings-models" data-heading=""><p><h2>Deprecation of older embeddings models</h2></p></div><div><p>Users of older embeddings models (e.g., <code>text-search-davinci-doc-001</code>) will need to migrate to <code>text-embedding-ada-002</code> by January 4, 2024. We released <code>text-embedding-ada-002</code> in December 2022, and have found it more capable and cost effective than previous models. Today <code>text-embedding-ada-002</code> accounts for 99.9% of all embedding API usage.</p><p>We recognize this is a significant change for developers using those older models. Winding down these models is not a decision we are making lightly. We will cover the financial cost of users re-embedding content with these new models. We will be in touch with impacted users over the coming days.<br></p></div><div><table>
  <tbody>
    <tr>
      <td>
        <span>Older model</span>
      </td>
      <td>
        <span>New model</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>code-search-ada-code-001</span>
      </td>
      <td rowspan="16">
        <span>text-embedding-ada-002</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>code-search-ada-text-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>code-search-babbage-code-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>code-search-babbage-text-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-ada-doc-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-ada-query-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-babbage-doc-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-babbage-query-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-curie-doc-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-curie-query-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-davinci-doc-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-search-davinci-query-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-similarity-ada-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-similarity-babbage-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-similarity-curie-001</span>
      </td>
    </tr>
    <tr>
      <td>
        <span>text-similarity-davinci-001</span>
      </td>
    </tr>
  </tbody>
</table></div><div id="deprecation-of-the-edits-api" data-heading=""><p><h2>Deprecation of the Edits API</h2></p></div><div><p>Users of the Edits API and its associated models (e.g., <code>text-davinci-edit-001</code> or <code>code-davinci-edit-001</code>) will need to migrate to GPT-3.5 Turbo by January 4, 2024. The Edits API beta was an early exploratory API, meant to enable developers to return an edited version of the prompt based on instructions. We took the feedback from the Edits API into account when developing <code>gpt-3.5-turbo</code> and the Chat Completions API, which can now be used for the same purpose:<br></p></div><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Imagination GPUs now support OpenGL 4.6 (102 pts)]]></title>
            <link>https://blog.imaginationtech.com/imagination-gpus-now-support-opengl-4.6</link>
            <guid>36621057</guid>
            <pubDate>Thu, 06 Jul 2023 18:59:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.imaginationtech.com/imagination-gpus-now-support-opengl-4.6">https://blog.imaginationtech.com/imagination-gpus-now-support-opengl-4.6</a>, See on <a href="https://news.ycombinator.com/item?id=36621057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<ul>
<li>
<span> 06  July 2023 </span>
</li>
<li>
<a href="https://blog.imaginationtech.com/author/eleanor-brash">
<span> Eleanor Brash </span>
</a>
</li>
<!--<li class="elementor-icon">
<span class="elementor-post-avatar"> 
<a href="https://blog.imaginationtech.com/imagination-gpus-now-support-opengl-4.6#comments-listing"> No comments</a>
</span>
</li>-->
</ul>
</div>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>When it comes to APIs, OpenGL¬Æ is something of a classic. According to the Khronos¬Æ Group, OpenGL¬Æ is the most widely adopted 2D and 3D graphics API. Since its launch in 1992 it has been used extensively by software developers for PCs and workstations to create high-performance, visually compelling graphics applications for markets such as CAD, content creation, entertainment, game development and virtual reality.</p> 
<!--more-->
<p><span>To date, </span><span></span><span></span><span>Imagination GPUs have natively supported OpenGL¬Æ up until Release 3.3 as well as OpenGL¬Æ ES (the version of OpenGL¬Æ for embedded systems), Vulkan¬Æ (a cross-platform graphics API) and OpenCL‚Ñ¢ (an API for parallel programming).</span><span></span><span> However, thanks to the increasing performance of our top-end GPUs, especially with the likes of the </span><a href="https://www.imaginationtech.com/product/img-dxt-72-2304/"><span>DXT-72-2304</span></a><span>, they present a competitive offering to the data centre and desktop (DCD) market. Indeed, we have multiple customers ‚Äì including the likes of </span><a href="https://www.imaginationtech.com/resources/imagination-and-innosilicon-case-study-en/"><span>Innosilicon</span></a><span> ‚Äì choosing Imagination GPUs </span><span></span><span></span><span>for the flexibility an IP solution, their scalability and their ability to offer up to 6 TFLOPS of compute.</span><span></span></p> 
<p>To support our customers in the DCD market, Imagination is investing in its API coverage. This starts with the extension of our support of OpenGL¬Æ from version 3.3 to version 4.6 ‚Äì the latest <span>version of OpenGL¬Æ</span><span></span>. The solution is Khronos conformant and available now following its release in DDK Rel.23.1. The video below demonstrates OpenGL¬Æ 4.6 content running on Imagination GPUs.</p> 
<div data-service="youtube" data-responsive="true"> 
<p> 
<iframe width="200" height="113" src="https://www.youtube.com/embed/qS_oLxS7wdM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="OpenGL¬Æ 4.6 on Imagination GPUs"></iframe> 
</p> 
</div> 
 
<p>Support has been achieved by working alongside the open-source specialists at <a href="https://www.collabora.com/">Collabora</a>. Collabora‚Äôs Zink is a layered OpenGL¬Æ implementation, part of the open-source Mesa project, that allows OpenGL¬Æ 4.6 content to run on top of a native Vulkan driver. For Imagination GPUs, this is a win-win. While OpenGL¬Æ is now being used less frequently by developers who are preferring newer APIs such as Vulkan and DirectX, due to its previous popularity there are numerous legacy applications that wouldn‚Äôt work on Imagination hardware if we didn‚Äôt have driver-level support for its final version. Delivering support for OpenGL¬Æ 4.6 via our Vulkan drivers is as elegant solution that keeps our graphics stack simple.</p> 
<p>This project has been one of a number of Imagination open-source projects.<span><span>&nbsp;</span></span>As a company we value the contribution that open-source technology offers to the ecosystem, enabling developers to excel at specific areas of differentiation rather than re-inventing the wheel each time. Our <a href="https://developer.imaginationtech.com/open-source-gpu-driver/">Open Source GPU Driver</a> project is a unique approach to supporting silicon vendors, OEMs and graphics developers take control of the complete graphics software stack. Imagination GPUs are <a href="https://blog.imaginationtech.com/the-gpu-of-choice-for-risc-v">the perfect partner to RISC-V CPUs</a>, <span><span>the emergent open-source architecture - and o</span></span>ur very own <a href="https://www.imaginationtech.com/products/cpu/">RISC-V CPU</a> is another example of how Imagination is leveraging open source to bring a differentiated product to market in a brief amount of time. In turn, we are contributing back into the open-source community. Within RISC-V International, <span><a href="https://blog.imaginationtech.com/why-weve-levelled-up-on-risc-v">we sit on the Board of Directors</a></span> and the Technical Steering Committee and we also take a leading role in a number of special interest groups.</p> 
<p>With the release of DDK Rel.23.1, Imagination GPUs now support OpenGL¬Æ 4.6. Meanwhile w<span>e are continuing to develop our API support in line with our customers‚Äô needs and will have further announcements coming in this area soon.</span><span></span></p></span>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I want XAES-256-GCM/11 (136 pts)]]></title>
            <link>https://words.filippo.io/dispatches/xaes-256-gcm-11/</link>
            <guid>36620969</guid>
            <pubDate>Thu, 06 Jul 2023 18:54:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://words.filippo.io/dispatches/xaes-256-gcm-11/">https://words.filippo.io/dispatches/xaes-256-gcm-11/</a>, See on <a href="https://news.ycombinator.com/item?id=36620969">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <span>
            <time datetime="2023-07-06">06 Jul 2023</time>
        </span>
        
        <section>
            <!--kg-card-begin: markdown--><p>In 2023, the way to use AES is AES-GCM. Anything else is very unlikely to make sense. We might not like that, we might wish OCB hadn‚Äôt been patented, but with hardware support in most processors these days GCM is both faster than the alternatives, ubiquitous, and just tolerable to implement.</p>
<p>Still, I don‚Äôt want to use AES-GCM, I want to use XAES-256-GCM/11, which has a number of nice properties and only the annoying defect of not existing.</p>
<p>The problem with AES-GCM is that its nonce is a little too small to comfortably select at random. At 96 bit, the probability of a <a href="https://en.wikipedia.org/wiki/Birthday_attack?ref=words.filippo.io">birthday bound</a> collision becomes uncomfortable (2<sup>-32</sup>) after a few billion messages (2<sup>32</sup>), and <a href="https://eprint.iacr.org/2016/475?ref=words.filippo.io">the consequences of a collision are catastrophic</a>.<sup><a href="#fn1" id="fnref1">[1]</a></sup> Some applications know they will never encrypt that many messages under a single key, but those numbers are a little too low and the consequences too dire to make that assumption at the API level, so we‚Äôre forced to delegate nonce management to the user.<sup><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>ChaCha20Poly1305 has the same issue, which is why the <em>extended-nonce</em> construction XChaCha20Poly1305 exists. It resolves the issue by taking a 192-bit nonce<sup><a href="#fn3" id="fnref3">[3]</a></sup>, and ‚Äúhashing‚Äù it along with the key into a fresh key.<sup><a href="#fn4" id="fnref4">[4]</a></sup> The key is 256 bits, so there is no need to ever worry about collisions there. (More on that later.) You should <em>always</em> use the X variant unless the nonce is fully implicit, like when it‚Äôs always zero (like in age), a record counter (like in TLS), or a chunk number (like in STREAM). You can also make nice APIs for the X variant that generate the nonce at random from the system CSPRNG (and we are thinking about how to best do that in the Go standard library).</p>
<p>XChaCha20Poly1305 uses ChaCha20 itself to do the hashing to avoid introducing a new primitive, but this would work just as well using SHA-256 or HKDF to derive a regular key and nonce for ChaCha20Poly1305 from a key and a larger nonce. This means you could do the same for AES-GCM, and some schemes do in fact do just that. Regrettably, we don‚Äôt have a name for it, so you can‚Äôt just say to people ‚Äúyou should <em>always</em> use the X variant‚Äù or make a nice interoperable API for it.</p>
<p>Anyway, that‚Äôs the X in my <s>pony</s> XAES-256-GCM/11.</p>
<p>I don‚Äôt care if it uses HKDF, or SHA-256, or the AES function<sup><a href="#fn5" id="fnref5">[5]</a></sup>: I want a well-defined scheme that takes a key and 192 bits of nonce and hashes them into a derived key and 96 bits of nonce for use with AES-GCM.</p>
<p>Even with AES-128, the combined 224 bits of space for key and nonce are juuuust enough not to worry about collisions in the derived values. Still, this hints to the second part of the <s>pony</s> problem with AES-GCM: while <a href="https://words.filippo.io/dispatches/post-quantum-age/#128-bits-are-enough">actually enough for post-quantum cryptography</a>, 128-bit keys are still too tight for <em>multi-user security</em>. If for example an application encrypts 2<sup>48</sup> messages under different 128-bit keys, and all messages start with the same few bytes, an attacker can build a lookup table, try and lookup the ciphertext of 2<sup>64</sup> keys, and <a href="https://www.wolframalpha.com/input?i=log2%281+-+%281+-+2%5E48+%2F+2%5E128%29+%5E+%282%5E64%29%29&amp;ref=words.filippo.io">have a 2<sup>-16</sup> chance</a> to decrypt one message. Not good.</p>
<p>Multi-user attacks can be mitigated by many things‚Äîthey require fixed nonces and partially known plaintext‚Äîbut the only way to avoid that complexity escaping the AEAD abstraction and leaking into the rest of the protocol is to use 256-bit keys. For AES-GCM, that means using AES-256. Too bad that AES-256 is slower than AES-128, not because of its bigger key size, but because it was specified with more rounds, presumably under the assumption that users of bigger keys would also want more security margin against cryptanalysis. AES is an iterated cipher, where four core operations are performed multiple times in sequence: AES-128 performs them ten times, while AES-256 performs them fourteen times. AES-256 doesn‚Äôt <em>have to be</em> slower than AES-128, it was just defined to be slower. That‚Äôs regrettable, because it applies an artificial performance tax on the use of longer keys, which are desirable for reasons that have nothing to do with the risk of AES cryptanalysis.</p>
<p>Picking the ‚Äúright‚Äù number of rounds is hard, and it‚Äôs kind of an open secret in the community that there is no rigorous and scientific way to do it. ‚Äú<em><a href="https://eprint.iacr.org/2019/1492?ref=words.filippo.io">Too much crypto</a></em>‚Äù by Aumasson is all about this, and suggests eleven rounds for AES-256. I started this aiming for ten, which would have been exactly as fast as AES-128, but AES-256 does need more margin than AES-128 in some rare cases for <em>reasons</em><sup><a href="#fn6" id="fnref6">[6]</a></sup> and I guess it‚Äôd be silly to introduce a different abstraction-leaking edge case while trying to remove two, so AES-256/11 it is.</p>
<p>Summing up, I would like to provide to my users the extended-nonce 256-bit reduced-rounds XAES-256-GCM/11 (or XAES-256/11-GCM?) AEAD. It has infinitely randomizable nonces, a comfortable margin of multi-user security, and nearly the same performance as AES-128-GCM. It would also be a true drop-in replacement for XChaCha20Poly1305. Only issue is that it doesn‚Äôt exist.</p>
<p>(I guess it would also not be FIPS 140 compliant. We could make a FIPS version that‚Äôs slower but equivalent by using HKDF to derive the key, and the full-rounds AES-256.)</p>
<p><strong>Edit 2023-07-06</strong>: Soatok has <a href="https://soatok.blog/2022/12/21/extending-the-aes-gcm-nonce-without-nightmare-fuel/?ref=words.filippo.io">previously suggested an extended-nonce AES-GCM construction</a>. His AES-XGCM uses CBC-MAC for key derivation, which might be a good pick as both primitive-parsimonious and potentially FIPS 140 compliant. @NohatCoder@mastodon.gamedev.place on Mastodon suggests that since we're KDF'ing, we might as well generate all the subkeys directly, solving the AES-256-specific issues that require the extra rounds (see <sup><a href="#fn6" id="fnref6:1">[6:1]</a></sup>). I'm a bit wary to diverge too much from the well-established primitives, since at that point might as well use something novel (such as <a href="https://datatracker.ietf.org/doc/draft-irtf-cfrg-aegis-aead/?ref=words.filippo.io">AEGIS</a>, like Soatok says). The point here is that I'd like a thin construction that's easy to get confidence for if you already trust AES-GCM.</p>
<h2 id="the-picture">The picture</h2>
<p>Cats! Amongst Roman ruins! What else do you need in life? (Better AEAD modes I guess.)</p>
<p><img src="https://words.filippo.io/content/images/2023/07/news---1.jpeg" alt="A calico cat sleeps in the foreground, another cat is sitting down a step behind it, and behind them and a rail is a archaeological site with trees and columns. Further back, buildings." loading="lazy"></p>
<p>My awesome clients‚Äî<a href="https://www.sigsum.org/?ref=words.filippo.io">Sigsum</a>, <a href="https://protocol.ai/?ref=words.filippo.io">Protocol Labs</a>, <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a>, <a href="https://interchain.io/?ref=words.filippo.io">Interchain</a>, <a href="https://smallstep.com/?ref=words.filippo.io">Smallstep</a>, and <a href="https://tailscale.com/?ref=words.filippo.io">Tailscale</a>‚Äîare funding all this work and through our retainer contracts they get face time about its direction, as well as unlimited access to advice.</p>
<p>Here are a few words from some of them!</p>
<p>Protocol Labs ‚Äî <a href="https://cryptonet.org/?ref=words.filippo.io">Cryptonet</a> is hosting <a href="https://lu.ma/tm8v78rl?ref=words.filippo.io">Proof of Space days</a> in Paris on July 20-21, a gathering of cryptographers, Web3 researchers and engineers to share knowledge on <a href="http://proofofspace.org/?ref=words.filippo.io">Proof of Space</a>. We‚Äôll have talks and workshops to collaborate, share ideas and onboard new researchers into this exciting field. You‚Äôll also have a chance to meet us (we‚Äôre currently looking for a senior cryptography engineer), <a href="https://lu.ma/tm8v78rl?ref=words.filippo.io">register and join us</a>!</p>
<p>Latacora ‚Äî <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a> bootstraps security practices for startups. Instead of wasting your time trying to hire a security person who is good at everything from Android security to AWS IAM strategies to SOC2 and apparently has the time to answer all your security questionnaires plus never gets sick or takes a day off, you hire us. We provide a crack team of professionals prepped with processes and power tools, coupling individual security capabilities with strategic program management and tactical project management.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>You‚Äôll sometimes hear that any single-key AES mode can only produce 2<sup>48</sup> blocks before the advantage of a distinguishing attacker gets uncomfortable. That would seem contradictory with a limit of 2<sup>32</sup> messages for AES-GCM, since each message can be up to 2<sup>32</sup> blocks. The thing is that the only thing that an attacker can do by observing more than 2<sup>48</sup> blocks is confirm that they‚Äôre looking at AES rather than at complete randomness. A completely random stream would be expected to show some output block collisions after that many blocks, while AES, being an invertible permutation applied on a counter and unique nonce, will never repeat. The <em>lack</em> of collisions is the distinguisher. NIST doesn‚Äôt care, and neither do I. <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2"><p>Technically, GCM accepts longer nonces. However, nonces longer than 96 bits are hashed into a starting 128-bit counter value, leaving no dedicated counter space. (96-bit nonces are instead concatenated with a 32-bit counter.) The birthday bound of 128 bits is better, allowing us to encrypt in theory 2<sup>48</sup> messages (the approximate formula is 2<sup>(N-32)/2</sup>), but that‚Äôs only if every message was precisely one block long. If messages are longer, there‚Äôs a risk the counter will overlap across messages, which is not as catastrophic and easy to detect as nonce reuse, but leads to loss of confidentiality. In general, it‚Äôs very inconvenient for bounds to depend on the message size, because that‚Äôs yet another assessment we have to delegate to the application. AES-GCM-SIV has the same issue: it has better bounds for shorter messages, but worse for messages longer than 8 GiB, and the answer to ‚Äúhow many messages can I encrypt‚Äù is a double entry table instead of a number. <a href="#fnref2">‚Ü©Ô∏é</a></p>
</li>
<li id="fn3"><p>Technically, 128 bits of nonce are hashed with 256 bits of key into 256 bits of key, and 64 bits of nonce are used as nonce, which leaves 32 bits of nonce space that can be reassigned to counter, if you need to encrypt more than 256 GB. In practice, <a href="https://cs.opensource.google/go/x/crypto/+/refs/tags/v0.10.0:chacha20poly1305/xchacha20poly1305.go;l=46-53;drc=c084706c2272f3d44b722e988e70d4a58e60e7f4?ref=words.filippo.io">we don‚Äôt support that</a>. What counts as key, nonce, and counter in ChaCha20 is really just arbitrary: 384 bits of variable state are mixed with 128 bits of constants for each block, and you need to make sure you never reuse the same state. The original ChaCha20 had 64 bits of nonce and 64 bits of counter, the IETF moved 32 bits from nonce to counter, making random nonces juuust tempting but not quite safe. Anyway. <a href="#fnref3">‚Ü©Ô∏é</a></p>
</li>
<li id="fn4"><p>In a sense XChaCha20Poly1305 is a SIV construction in the same way AES-GCM-SIV is: they both compute a synthetic (key, nonce) rather than a synthetic nonce alone. ü§î However, the message is not one of the inputs in the XChaCha20Poly1305 derivation, so it‚Äôs not misuse resistant. There are some interesting parallels here with <a href="https://words.filippo.io/dispatches/avoid-the-randomness-from-the-sky/">signature nonce generation</a>, where the best design turns out to be hashing message <em>and</em> randomness into it. <a href="#fnref4">‚Ü©Ô∏é</a></p>
</li>
<li id="fn5"><p>Although if we‚Äôre doing this, we might as well do it cleanly and use AES like XChaCha20Poly1305 or GHASH like AES-GCM-SIV. <a href="#fnref5">‚Ü©Ô∏é</a></p>
</li>
<li id="fn6"><p>Interestingly enough, AES-256 turned out to actually have a legitimate (if maybe unexpected) need for more rounds, because the 256-bit key schedule (the way the key is expanded into subkeys for the various rounds) is simpler and more vulnerable to related-key attacks. In 2009/2010 we got some impractical related-key attacks against AES-256/14, and <a href="https://eprint.iacr.org/2009/374?ref=words.filippo.io">some ‚Äúpractical‚Äù related-key attacks against AES-256/9</a>. The paper does a good job of explaining the background in the first few sections. The related-key attack setting is very contrived: an attacker can recover a key K if it‚Äôs able to get an encryption oracle for a K <em>and</em> for K‚äïC. There is apparently one protocol that somehow managed that, but these days I‚Äôd hope all keys are the output of a CSPRNG or a KDF, not some haphazard XOR operation. (There was also an attack against AES-256/11 which required even more implausible relations between the keys.) I also suspect that the key derivation step of the extended-nonce construction we discussed above would rule out these related-key attacks. Anyway. <a href="#fnref6">‚Ü©Ô∏é</a> <a href="#fnref6:1">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
        </section>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twitter is threatening to sue Meta over Threads (143 pts)]]></title>
            <link>https://www.semafor.com/article/07/06/2023/twitter-is-threatening-to-sue-meta-over-threads</link>
            <guid>36620536</guid>
            <pubDate>Thu, 06 Jul 2023 18:24:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.semafor.com/article/07/06/2023/twitter-is-threatening-to-sue-meta-over-threads">https://www.semafor.com/article/07/06/2023/twitter-is-threatening-to-sue-meta-over-threads</a>, See on <a href="https://news.ycombinator.com/item?id=36620536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Twitter is threatening legal action against Meta over its new text-based ‚Äú<!-- --><a href="https://www.nytimes.com/2023/07/05/technology/threads-app-meta-twitter-killer.html" rel="no-referrer">Twitter killer</a>‚Äù platform, accusing the social media giant of poaching former employees to create a ‚Äúcopycat‚Äù application.<!-- --></p><p>On Wednesday, Instagram parent company Meta introduced Threads, a text-based companion to Instagram that resembles Twitter and other text-based social platforms. Just hours later, a lawyer for Twitter, Alex Spiro, sent <!-- --><a href="https://cdn.sanity.io/files/ifn0l6bs/production/27109f01431939c8177d408d3c9848c3b46632cd.pdf" rel="no-referrer">a letter</a> to Meta CEO Mark Zuckerberg accusing the company of engaging in ‚Äúsystematic, willful, and unlawful misappropriation of Twitter‚Äôs trade secrets and other intellectual property.‚Äù<!-- --></p><p>‚ÄúTwitter intends to strictly enforce its intellectual property rights, and demands that Meta take immediate steps to stop using any Twitter trade secrets or other highly confidential information,‚Äù Spiro wrote in a letter obtained exclusively by Semafor. ‚ÄúTwitter reserves all rights, including, but not limited to, the right to seek both civil remedies and injunctive relief without further notice to prevent any further retention, disclosure, or use of its intellectual property by Meta.‚Äù<!-- --></p><p>Spiro accused Meta of hiring dozens of former Twitter employees who ‚Äúhad and continue to have access to Twitter‚Äôs trade secrets and other highly confidential information.‚Äù<!-- --></p><p>He also alleged that Meta assigned those employees to develop ‚ÄúMeta‚Äôs copycat ‚ÄòThreads‚Äô app with the specific intent that they use Twitter‚Äôs trade secrets and other intellectual property in order to accelerate the development of Meta‚Äôs competing app, in violation of both state and federal law as well as those employees‚Äô ongoing obligations to Twitter.‚Äù<!-- --></p><p>Andy Stone, Meta‚Äôs communications director, told Semafor that Twitter‚Äôs accusations are baseless.<!-- --></p><p>‚ÄúNo one on the Threads engineering team is a former Twitter employee ‚Äî that‚Äôs just not a thing,‚Äù he said.<!-- --></p><p>In a tweet posted after this story was initially published on Thursday, Musk <!-- --><a href="https://twitter.com/elonmusk/status/1677042708756439041" rel="no-referrer">wrote</a> that ‚Äúcompetition is fine, cheating is not.‚Äù<!-- --></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chat with Andreas Kling about Ladybird and developing a browser engine (271 pts)]]></title>
            <link>https://www.igalia.com/chats/ladybird</link>
            <guid>36620450</guid>
            <pubDate>Thu, 06 Jul 2023 18:18:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.igalia.com/chats/ladybird">https://www.igalia.com/chats/ladybird</a>, See on <a href="https://news.ycombinator.com/item?id=36620450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article class="page">
  

  <div>
        <div>
              <h2>
                <a href="https://www.igalia.com/24-7/chats">
                  <img src="https://www.igalia.com/assets/i/arrowBackBlue.png" alt="Back to chats">
                </a>
                Igalia's Eric Meyer and Brian Kardell chat with Andreas Kling about Ladybird and developing a new, novel browser engine
              </h2>
              <p><time datetime="2023-07-06T00:00:00+00:00" itemprop="datePublished">
                  
                  Jul 6, 2023
                </time>
              </p>
              
            </div>
        <div>
              


              <h2>Transcription</h2>
              <ul>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Hello, I'm Eric Meyer, and I'm a developer advocate at Igalia. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: I am Brian Kardell, and I am, also. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: And today, we have a special guest, Andreas Kling, who is the lead on a brand new browser. So, Andreas, hi. Thanks for being here. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Hi. Yeah, happy to be here. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: So, you're working on a browser called Ladybird. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Uh-huh. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: We want to talk about all of that, but what's the background of where did Ladybird come from to start with? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right, so it all started in 2018 when I went to a drug rehab program, because I've been struggling with substance abuse for a very long time. And when I came out of that rehab program, I found myself with just so much free time and I had no idea what to do with all of it. And I started programming because that's something I knew how to do lots of, and that's how I ended up working on random things that I'd always wanted to do, but never felt I had the time for. And the big project I started was an operating system, because I always thought that seemed cool, but never really sunk my teeth into it properly, or never really gave it a fair shake. And I had a lot of fun with that, and it just grew and grew and grew. And I put it online and other people found it, and a little community formed around it. And that community just grew and grew and so did the operating system and the scope of it. And at some point, we had built a GUI and we had all the widgets, buttons, check boxes, all that stuff. And I thought, 'Hey, wouldn't it be nice if we could display rich text, and wouldn't it be sweet if we could use HTML as the internal representation of a rich text widget?' And I started just putting together a simple HTML widget that you could view, simple text that had bold, italic, stuff like that. That was what I was trying to achieve. And it just escalated from there because it was really fun to hack on and just add more tags, start to add CSS and so on. And it just incrementally grew to the point where I had to admit that, I guess, this is a browser, not just a rich text widget anymore. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Okay. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: And, yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: You had a background in browsers, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right, right. Yeah, so it wasn't entirely by accident. I did work on browsers for a long time. This was just how Ladybird started. But yeah, I had a career in browsers for a long time, starting all the way back in 2006, when I first worked on KHTML, in KDE.</blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: And then I got a job at Nokia a couple years down the line, working on Qt, Qt WebKit, moved to Apple from there. Spent six and a half years I think at Apple, working at Safari. And then I left, got into some troubles, and ended up in the aforementioned rehab clinic. And then, now I'm doing Ladybird, which was just supposed to be an HTML widget, I guess, is the essence of the story. But Ladybird today has come quite far from that original humble beginnings, of course. We've managed to build a fairly capable engine, and it's all from scratch, just like everything else on SerenityOS, we pride ourselves on stubbornly just doing everything from scratch, even though it would be much more convenient not to. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: So, one thing that, it keeps jumping out at me is you have Serenity as the OS. I have some questions about that because I think that's really interesting. But to stay on topic, Ladybird is the name of the browser, but you're inventing... The exciting thing isn't the browser, it's the engine, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Sure. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: And you're building a new engine. A whole new, that's a whole new web engine. It's a whole new rendering engine, whole new JavaScript engine, everything all the way down. Does the web engine have a name or is it just LibWeb, or something? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: It is literally LibWeb, yeah. All the libraries in Serenity are just called the obvious name. So, we got LibJS for JavaScript, LibWeb for web engine, and various other lib this and that. So, I gave it the name Ladybird so that we would have some public facing name that people could refer to, because when you're in SerenityOS, it's easy to talk about lib this and that, but LibWeb didn't feel like a PR friendly name, I guess. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Right, right. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: So yeah, I just talk about Ladybird as the whole project, basically. But it is also the name of the UI program that is the shell for the browser engine. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Where did the name Ladybird come from? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: So the SerenityOS project has been using ladybugs as mascots forever, since the early days. It was just our first icon that we had for the system was a little ladybug, and then we gained various ladybug themed emojis and things like that. But I didn't want to call it Ladybug because then it sounds like it would be buggy. And I thought, 'Remember when Firefox was called Firebird? That was a pretty cool name. What if we call it Ladybird?' Because I hear that in the UK that means ladybug anyway, so yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah, that's actually... People who study insects and stuff don't like ladybug because I guess they're not true bugs. So, the Ladybird is actually the preferred. Yeah, I like it. I like the Ladybird name. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Yeah. And I'm curious, you mentioned that the Serenity project, in general, stubbornly tries to do everything from first principles, even though that's much harder. Is there... What is the driving foundational principle there? Why did you pick that as a foundational principle? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: So there are many things that factor into it, but the two main ones are, I used to work at Apple for a long time, and I got so used to this culture that they have there of all the experts on the whole system are all in the same building or in the adjacent building, and you can just go talk to them. And I always thought that is so sweet because you have some super gnarly esoteric problem in some system library, and the guy who wrote it is just next door. And I always felt like in the open source world, they don't have that. And I wanted to, after I left Apple, I still craved that kind of environment. So I thought, 'If it doesn't exist, what if I try to create it?' So I wanted to just build a system where we can cultivate all the expertise in one place and we can be super accountable, so that whatever the problem is, you can never blame anybody outside the project. Blame always stays within the repository. And I think it's, as you say, it is very difficult to work that way, but it has also created a very strong community because people enjoy working in that kind of space where they get to become experts and they get to take extreme ownership of system components in a way that I think is much, much harder in the Linux wider open source ecosystem. And the other aspect of why we do this is because it's fun. It's fun to build things from scratch. Everybody knows that. And it was supposed to be a hobby project that I was just doing to fill up my time. So it is rooted in just fun time spending programming activity, and I hope it never shakes that origin. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: I listened to another podcast that you're on, and I think we won't get as much into some of the details of the history and the whys and everything, but you went into a lot of that, and I'm sure people could find it. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Maybe it was CoRecursive, probably. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: It was CoRecursive, right. Yeah, that was it. But it was a good podcast and I really can relate in a way to the time that suddenly is free. I've had other moments in my life that were not specifically that, but where you have some really major life change and the minutes just go forever, and finding yourself a thing that you can throw yourself into is really helpful. For me, it was usually art, painting. But, so we have a series on here called Web Ecosystem Health, when engine disappears, that's the whole story. There's so many pieces that go into is this a healthy ecosystem or not, that maybe focusing on the exact number isn't the important part. What is the ideal number? Is it 3, 5, 7? We don't know. I think Jeremy Keith said, 'It's like political parties. One is definitely too few, and a hundred is probably too many, and somewhere in between there is a series of debatably good numbers.' But in that podcast, we have said a bunch of times that you're more likely to lose engines than to gain them unless it's by evolution, like KHTML becomes WebKit becomes Chromium. And recently, at the Web Engine HackFest, we had two presentations of novel browser engines. It seems to really fly in the face of what I've argued, but I don't think that it does. And I want to ask what you think, Andreas. So you know, you've said on your podcast, 'People say you can't build a browser engine from scratch,' and you say, 'Sure you can.' I don't say that you can't, I just say that it's really, really hard to create a fully featured and competitive mainstream competitor to WebKit and Gecko and Chrome. I would think that for both these engines, that's a ways off, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Sure, yeah, it is. It's a very big task. It's a lot of work. It's going to take a long time. But I think at the same time, there's never been a better time in history to build a new browser engine. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Why is that? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: If you look at the quality of specifications today compared to 10 years ago, for example, the specifications are vastly better today. The effort that the CSS working group, for example, has put into just clarifying so many things makes it actually possible for someone like me who never worked on CSS's layout to go and write a layout engine without a team of experts around me or even having to ask for help much. And I think that's fantastic. And I was pleasantly surprised because I was going into this assuming that it was like the olden days still, that you would end up sitting with CSS 2.1 and trying to guess your way through the various descriptions of blocking and line layout, because that's what I had seen my coworkers do at Apple, just struggling with the old CSS world. But nowadays, the specs have gotten so good, and it's not that they're perfect, but that they're really a lot better than they've ever been. So I think just from that alone, it is a lot easier today than people might think. And I think what you describe, it's absolutely true that it's a ton of work. It's absolutely true that it's hard to build something that will be mainstream competitive, of course. Google throws hundreds of engineers at this and they have full-time people working on it around the clock. It would be silly to say that we're going to out-compete them at their own game, but I think it's still possible to build a browser that can render a significant majority of the web at a satisfying fidelity, let's say. And I also like to think that if you can gain enough momentum that you get to the point where you have a decent rendering of most websites that people care about, you can then gain an enough momentum that you attract people to go and fill in the niche gaps that they might care about, and you might attract funding and so on. So that part is up in the air, but I think if we can go hard and fast enough that we end up there, who knows what can happen. So I'm just very optimistic, I guess. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: I think it's astounding what you all have accomplished so far. Not just a browser that you can view many websites on, but also the operating system that it's built on. It's incredible for this very short amount of time and small number of people, comparatively. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: To be honest, the operating system was the easy part. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: So the operating system was easy, but browsers are hard? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Harder. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Wow. Talk about that a little. How so? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Because operating systems are fairly simple when you boil it down to what you really want to do. Kernel is a well understood, well-defined problem, and in our case, we're just working on the POS-x specifications. We're building a Unix compatible operating system, and that means we have a set of APIs that we need to support, and that work is really straightforward. And then, we have a UI paradigm that we borrow from late 90s Windows, Microsoft Office, that kind of stuff. So we already know what we need to do there, too. We need to build this UI and these interactions, and so on. And I don't know, I just found that work really straightforward, whereas with the web stuff, I know I was just saying that the specs are better than ever, but it is still hard to get all the specs gluing together, I think. And really when it comes to CSS, I would say CSS is so much harder than any of the other parts of the web platform because it's hard to work on any CSS module in isolation. It really requires the person working on CSS stuff to understand multiple specs at the same time, and then keep them in their head and implement multiple things at the same time, if that makes sense. It is so much easier to work on JavaScript or HTML or Fetch or any of those specs, because they are more self-contained. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: To the point of what you were saying about specs have gotten so much better, one of the things that definitely started those riggers was when Hixie sat down and specified the actual HTML parser, which never had really been written down the way that it needed to work. So, there was a way that it needed to work. There was an interoperable subset, and that was never written down, and there were some rough edges that you couldn't get people to agree on until you had something written down. So, I know that that has been cited as a great accomplishment, and other people have said that they've used that to build a parser. We just did a podcast with Martin Robinson on Servo, and in that, we had this observation, this thought that every browser that comes along fresh and implements something ends up making the specs a little better for the next ones to do it. I noticed that you had several issues open in HTML parser, and I think it's probably because you're the last one to look at it with really fresh eyes, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Sure, yeah, that's absolutely a thing. And it's also one of the big things that I hope that we can do for the community of web engines is to just give our input as a recent implementer. And we haven't been super great about it yet. Yeah, you can find some bugs that we filed, but for the most part, until recently, whenever we had a problem, it was pretty safe to assume it was because of something we had done wrong. And it's only in the recent couple of months that we've matured to the point where now we start to find spec bugs more often and spec issues. And that has been a really exciting transition, actually, and we're just looking forward to helping out more in that area, at least with regards to HTML and CSS. In JavaScript, we were a bit ahead of that curve, because our engine has been implementing some proposals pretty early. So we implemented the temporal proposal when it was still quite new. And we were able to give a lot of feedback on that, which then helped evolve the spec. Now we're a little bit behind because I think people got a bit burned out on updating it whenever the spec changed. But yeah, that's absolutely something that I agree with Martin on that, that every new engine will make the specs better, and next year and the year after that, you'll be able to say that there has never been a better time to build a new browser engine, I hope. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah, good. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: That feels like a sign of maturity for the platform, really. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, I think so. I think so. And when you get deep into the weeds of this stuff, it's easy to point out glaring omissions and things that are really missing. But on the whole, absolutely, the platform has never been more mature, I think. And for something that is so alive as the web platform specs, it is quite impressive how mature they are. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: People should go watch both the Servo and the Ladybird presentations at the Web Engines HackFest. You can find them on YouTube, on Igalia's YouTube channel. I think they're both great. They're also, I think, a little different, and I'm curious if we can get you to clarify or talk about that a little bit, because it's hard to tease apart because you have done so much that I'm not sure what is and isn't in there. You are not currently connected for web platform tests, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: No. We have recently gotten part of the runner working, so we can run the ref tests, but not the non ref tests. We're working on that, as well, but we're not connected to WPT yet. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Okay. If you were connected, how do you think you would stack up? There's about 1.8 million sub tests. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: I have no idea. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: If you had to just take a stab. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: If we get a day to just clean out all the embarrassing crashes, then I would guess maybe 20% or something. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: So, can you give us some ideas about the sorts of things that aren't currently in Ladybug? Ladybird. Wow.</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: The sorts of things that aren't in there? </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Well, there's a lot of random little CSS things that aren't in there. So, we haven't implemented every type of vertical alignment, for example. So, we only have, I think baseline and the middle and the top are... A bunch of them are missing. And then that is true for many CSS properties and I expect that to have fallout in a lot of tests, because we might be able to pass the test if we were just doing some random CSS thing more correctly. And we've taken a very vertical slice approach to adding functionality to the browser. And by that, I mean we don't tend to implement a whole spec and then move on to the next spec. What we tend to do is we tend to find a webpage that we want to improve for whatever reason. Maybe it's cool to get the New York Times to render, and then we just spend a bunch of time fixing as many issues as we can for that site and then move on to a new page or some new thing that we want to be able to do. And that might not be the most structured approach to it, but it has been very, very good at keeping people motivated and excited and engaged in the work, which from my perspective is almost more important than having an optimal structure to the work, because it's mostly volunteers working on it. I'm the only person who is full-time employed to do this, so I need to keep it fun for people to work on. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah, absolutely. Do you support CSS Grid? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yes, we do. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: And Flexbox? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: It's not... Yes, our Flexbox is much more mature than our CSS grid, but our grid has been improving a lot recently. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Probably you don't have support, I'm guessing, for Web Speech, WebXR, WebGL, WebNN, that kind of stuff? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: We have the beginnings of WebGL, but the other ones are all absent, yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: So, there's so much of that stuff. Yeah, I hope my questions don't feel negative. They're definitely not intended. I'm actually real excited by both Servo and Ladybird. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Oh, no, no, no. I think it's important to be realistic about what it is that we're doing, and I do meet a fair amount of people who get way too excited, and they talk about, 'Oh, Ladybird is going to replace Mozilla, or finally some competition for Google,' and so on. And people get so excited about that that you have to talk them down a little bit, and that can be a little bit frustrating to deal with because obviously we're nowhere near competitive and it's going to take a long time before we will be. So, none of the things that you brought up were negative. I think they're just fact. We don't have all of these technologies yet and it's going to take time to build them, but I think we are making good progress and the future is open. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: What's really interesting to me is I feel like there's an evolutionary question here about what is acceptable enough for people to the vast majority of people to use it and even make it a daily driver. Do you know what I mean? I think that's a really interesting question. And you can see that even a little bit in the Chromium browsers. A lot of, they're actually missing a bunch of those things when they're new. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, I think that sort of thing has always been part of the web, at least for as long as I've been a web citizen. When I was a kid, it was, 'This site works best in this or that browser. You need NN4 to browse here, or you got to get IE5,' and these days you've got to use a Chromium based browser. And I think they're just different sides of the same coin. There's always going to be somebody who's pushing for new APIs and new 'standards' to become part of the platform. And I think it's perfectly fine to lag behind on stuff like that. With Ladybird, I'm primarily interested in implementing stuff that is used by the overwhelming majority of the web and make the engine hackable enough and plugable enough that in the future, if there is a demand for more niche features, then it will be reasonably easy to add them to the engine. But it seems at the moment, if I have to choose where to spend my time, I would rather implement more core CSS, JavaScript functionality than any of these new, fancy things that are only used by a fraction of a percent of websites. That's not to say that they're bad ideas, it's just that they're just trying to go where the big ball is instead of chasing the small ball. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah, that was actually my point with the other chromium, the not Chrome, the other Chromium based browsers. They also frequently lack many of these. They're not, I don't know, like Tim would say, 'The waft and weft of the web,' that that's HTML, CSS, and JavaScript. One of the things that struck me, I guess the thing that's most surprising to me, is if you go to Google or Apple or Firefox, the people who work on the JavaScript engine, they're not generally the people who work on layout. And even within layout, you have people who specialize in internationalization, or there's lots of specialization, but you have to solve everything. And that is really interesting to me. Is that intimidating to you at all, or are you just built differently? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: It was intimidating. When I started building the operating system, I was intimidated, and I just kept pushing through that for so long that I forgot. I woke up one day and I forgot to be intimidated, I think, and it just stayed off since then. So I stopped caring. And I think, I also have my YouTube channel where I broadcast myself programming, and that has been very helpful in just taking down my ego, because whenever I make a mistake, I hear about it from people making fun of me. And at first, that was really hard because I wasn't used to that harsh feedback and people making silly jokes about stupid things that I would do. But over time, that accumulated into this hardening of my soul, I guess, where I just became able to push through that intimidation stuff. And it was a lot of work, but I'm happy that I went through that process because now I'm happy to take on anything and suck at it for a while, and do it anyway until I get somewhat better. And then by the time I get somewhat better at something, hopefully I've managed to put something together that other people can help me improve. And that's how most of SerenityOS, most of Ladybird started, was just me pushing through, sucking at something I didn't know how to do, and figuring some of it out, and then other people coming in and helping. And I still do a lot of that, but nowadays, I have gotten a bit more specialized recently because there's just so much specialized work to do on a browser, like you mentioned Grid and Flexbox, for example. I've spent weeks working on our Flexbox implementation, just getting various details right, and it requires some amount of specialization. But I think in a project like ours, we can't afford to all be specialists. It's okay to specialize for short periods, but at the core, if we want to make progress with such a small team and such a shoestring budget, we have to be willing to be generalists. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Do you support SVG? I think you do, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: MathML? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: No MathML, and our SVG support is still evolving, but it has been getting better and better recently. I just worked on it today, actually. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Nice. I saw a photo of you at the HackFest with Nico. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Oh, yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: And I think I even tweeted, and it was tongue in cheek, but I'm serious, were you working on your SVG, because that's Nico's bag. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, I've known Nico for over a decade, but it was the first time we ever met in person. And I don't know that we were working on SVG at this exact moment, but we did end up talking a lot about SVG because we are recently struggling a bit with SVG text and trying to fit it into our rendering model, because we hadn't worked on SVG before, none of us. So it was helpful to talk to Nico about what the requirements are for SVG text. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: What did you learn? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: The most interesting thing I learned was that every character has to be individually positionable, I guess. And in order to support rendering a text along the outline of a path, you need to be able to place them independently of each other, but they should still behave as if they're on the continuous line so that you can select them and so on. And that's going to require a bit of changes to our architecture to support that. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: There's a question that I asked of Martin that I would like to also ask you, which is how much do you benefit? So you don't actually just go and take a library and port it or something? You don't ever do that, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: But you do... You're not inventing everything from whole cloth. You have the benefit of being able to study and see standards, and also be familiar with people who have done this before and ask questions. How much do you think that you benefit from that? Because I think when you say, 'I spent a few weeks working on Flexbox,' like yeah, people spent way more than a few weeks working on Flexbox and other engines. So do you benefit from coming in late and other people having made a lot of mistakes and having the problem sorted out, and maybe people you can talk to or some code you can look at or... </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, we absolutely benefit from being... Standing on the shoulders of giants. That's a absolutely a thing. There is not just the specs that have improved so much over the years, but there's countless discussions on what Ouija, GitHub, for example, you can go and read discussions on spec bugs where people explain and argue in depth about, 'Oh, why should it be this way? Why should it be that way?' So there's a tremendous amount of information you can absorb if you know where to look. And as we talked about, I also have a background in browsers, so I do know how to go and find information because it was my job for many years, as well. So I know where the information is. I have friends who work on other browsers still. So, I think, me personally, I benefit so much from having done it for a long time, just like anybody with experience doing something is going to be drawing on that experience, of course. But as a project, we also benefit from other engines having pushed the standards forward, having improved the platform. And also just from the web being an open platform that's developed in the open. It would be much harder to do this kind of stuff with a closed platform, obviously, like if we were trying to implement a .net VM or something. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah. So you also recently, I think, made a little Qt browser for regular Linux based on LibWeb, that is, I guess the straight Linux port of Ladybird. Is that a fair statement? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah. I would like to try that, actually. But I'm curious, how does that work exactly? You have to... I guess you're both using... I guess you're using C, so you just compile it for Linux, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right, so... </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: And it's just not taking advantage of anything in the operating system necessarily. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right. So, we use Qt to create a simple GUI that has a toolbar and a location text editor where you can type in a URL, and then we make a little scrollable view port, and then LibWeb does the rest, basically. So we don't use Qt for anything that you see in the web view itself. None of the text rendering or 2D graphics or 3D graphics. All of that is our own code. So the Qt application is really just a thin GUI shell for the engine. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: What about inputs, dialogue? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Oh, inputs like keyboard? </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: No, input elements, select elements. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Oh, so... </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Things that often are use a window and toolkit. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right. So, we haven't implemented all of them. So we only have text input, password input, buttons, checkbox, and radio buttons, I think. Maybe I'm forgetting some, but we haven't done select elements yet and we're missing a bunch of the other ones, and we haven't done validation yet. So, it's an open question, how we're going to deal with looking more native on Linux platforms. It would be easy to make it look like a SerenityOS input elements, but that might look a little bit out of place. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: That's an interesting question, actually. There's debate on this, and Dominic Denicola, one of the editors of HTML, a few years ago, where they were thinking about a couple of new features and they said, 'There's this constant debate and we don't have to do the thing that we always did. So, which would you prefer the same browser to present the same controls in every operating system? If you open Chrome, it always looks like Chrome. If you look at Safari, well, it is only available in one place, so that's not much. But Firefox, for example, you open it anywhere, they all look the same, or do we match the operating system. And I thought, I was convinced in my head, this is the most ridiculous question. This is going to be such a one-sided, there's clearly one answer to this. And no, it was literally 50/50. So, I don't think there is a right answer to that, and you should do whatever is interesting to you. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, maybe the ideal answer is that we would just let you choose.</blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Sure.</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: If possible.</blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Yeah, I could see that. I'm on the side of stick with the operating system, but that's me.</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: I did forget to mention that we do use Qt for networking currently on Linux.</blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Really?</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Because our multi-process networking service, we haven't gotten it to run nicely on Linux yet. We do have our own implementation of http, TLS, all of that jazz, but we have yet to bring it up on Linux. So, we are just piggybacking on the networking stuff in Qt at the moment, and we have an open bug about getting rid of that so that we can eat our own dog food instead.</blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Oh, okay. So you have a pragmatic build it yourself approach, which is, build it yourself unless you really need to bring in something else and then plan to replace it.</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, yeah, exactly.</blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: But that's only on Linux, right?</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, that's only on Linux. On Serenity itself, we use our own TLS stack.</blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Such a compromise, I guess, wouldn't be made on Serenity, right? To just...</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: No, it's... Right.</blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: ... Support something for now?</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: It's something that early on, for example, when I was just working on this by myself, I used a handful of C library routines from OpenBSD, I think, and then I went and replaced them down the line as the project matured, and I just wanted to get rid of all the borrowed code. And I'm sure that there are still some little things here and there with an OpenBSD origin that we need to replace. It just needs to be tracked down. So, I think, for me, the important thing nowadays is that we definitely don't want anybody bringing any proprietary IP into the project, and we don't want people to take something that's GPL because we are a BSD license project, so that wouldn't be entirely cool. And of course, the spirit of the project is that we're supposed to make things ourselves even though it's hard. So even if you could legally take something, we ask people that they don't, that they go through the suffering of doing it themselves, just so that we get the kind of system that is built that way.</blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: So, we've mentioned the contributors and hoping that people haven't snuck past you. How many contributors are there in the main?</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Oh my goodness. Well, I think we have over 900 total, but active core contributors on a monthly basis tends to swing up to around 50 maybe, recently. But it goes up and down depending on what people are doing. And there are bursts where people get excited about something, and then a bunch of people join in and they work on that for a while, and then interest fades and some new thing attracts everybody. Ebbs and flows. But one of the unique things about our project is that it's such a huge ecosystem, that even if you come in because you're excited about one thing, it's really easy to stick around and get distracted by a million other things. Maybe you come in because you want to work on a file management thing, and then you end up implementing WebP or something instead, which we recently got, by the way.</blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Nice.</blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Like lady birds flitting from plant to plant.</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: There you go. And you talked to some about the contributor community in your talk for Web Engines HackFest. Can you share some of your observations there with the audience here?</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Well, most of the people who work on Ladybird have no prior experience working on browsers, and that in particular is very exciting to me because I've been in browsers most of my professional life, and it always seemed to me like a fairly small, almost tight-knit community, even though it was spread across multiple organizations. People still float between these organizations. And if you look at Google today, there's a bunch of Mozilla people, and people have just been moving around that. There are only so many people in the world who want to be browser developers, or at least so I thought until I started doing it on YouTube and broadcasting what it's like to an audience of random onlookers, and it turned out that it could be made interesting to more people by letting them in on this angle of it. And I'm really, really happy to have been able to introduce so many people to it, and gotten hundreds of newcomers just to do a patch or two for a browser engine. Even if most people end up not loving it enough to stick around, we still have a bunch of people who have stuck around and worked on it, and that to me is a really wholesome aspect of what I get to call my job. So I'm happy about that.</blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Yeah, no, that's really interesting. So you feel it was YouTube that was the driver there?</blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: I think, yeah, that really has been the main driver of new people, at least until this point. If I compare my numbers, my audience numbers on every platform that I use to attract people to what we're doing, YouTube is by far doing the best. And the format is surprisingly interesting to people. Just, 'Here's a browser. Here is the website that doesn't look right. I'm going to make it look right. Stick with me for an hour and we'll figure it out.'</blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: I have to say I didn't watch any of the ones where you worked on browser features, but I did watch the one where you worked on doing the Qt browser for Linux. And so, just for background, I did some computer science in college and I had to learn C back then, but professionally, I only did C maybe once or twice. So the C world is intimidating to me, but I can open WebKit source code and find things, and if I read slowly, I can figure it out. So it's intimidating to me, and every once in a while I get WebKit and get it built and then just lose steam. It's so much yak shaving to get it built in the first place that I lose the steam to do it. But the reason I mentioned that is because I turned it on and immediately you were going pretty fast and I was like, 'Oh man, this is really intimidating. Look how much this guy just really knows what he's doing. I am not sure I'm going to be able to follow this at all.' But it didn't take long before you rammed your face into the door a few times with the same kind of stuff that trips me up. And somehow that just made it very engaging and more plausible, somehow, that I could do it. Do you know what I mean? I don't know if that makes sense. So I think that's motivating. You struggled a lot in that, right? I watched it. I don't know if that's common, but there were things that you knew that you didn't have to look up. You were doing it like riding a bike. You were so fluent in it. That stuff was cool, but honestly, the parts where you struggled were just so relatable and watching you work through them, I was like, 'Yeah, that's exactly what I would've done, too.' And one by one, you just have to step through the things. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, totally. And I think that's one thing that many people who make programming content, video content in particular, they make the wrong choice by editing out mistakes and trying to look perfect and fast and right all the time. Because as you say, then it just ends up looking intimidating or too polished, and you don't get that human side of it. You've got to show the frustration and the stupid mistakes. At least, I really feel like that's how I've been able to build an audience is by just showing the whole thing, with warts and all. And yes, that is representative by the way. I do screw up in every single video. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Well, in life, too. It's pretty easy to screw up. I think it's important to keep in mind. I am really, really excited about seeing where this goes in the rest of my lifetime, basically. Not in the next six months, although that's also exciting. But to see where all this develops because KHTML runs the world now, and it sure didn't start that way, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, indeed. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: It took a very long time. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: These are very exciting times right now, I think. I'm super excited that Servo is back on the menu. It's so cool that Igalia has picked that up, and I don't know, it's just exciting and it's going to be fun to see who makes progress on what and who hits which milestones first. And we can have a little browser war, even though... </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah, it could be that. I think that currently, they're hard to compare. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, definitely. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Because they had such different focus. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: I always understood Servo to be an experiment, above all. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: It was. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: And I think a lot of great things have come out of that. And I hope that they carry that forward and continue to be experimental, or experiment friendly at least, because there's so many things that you could do in a browser engine that is very inconvenient to do in the big engines because there's so much code you would have to rewrite just to try out new architectures and new ways of doing things. One thing that I thought of in this area is that one of the things that we try to do with our browser and with our engine is that we try to write it as close to the spec as possible. This is a bit different from the way other browsers are made, at least the ones I've been familiar with, like WebKit, Chromium, and Gecko, where they are happy to invent their own abstractions and solve things in their own ways. We are very, very hardcore about sticking to spec architecture and spec language and using the spec names for everything wherever we can, in part because it makes it just easier to implement the spec, if you write it exactly as the spec says to the fullest extent possible. But also for maintainability, because we have to recognize that the platform is alive and it keeps changing and keeps mutating. And if we want to have a chance to react and adapt to future changes, I really believe that we'll be in the best position to do that if we keep ourselves as close to the current spec as possible. So, we are... In HTML. For example, we have our class names in C++ are just the same exact words that they use for the same concepts in the HML spec. Our CSS layout engine is organized around formatting contexts, unlike the way it works in the other engines where they invent their own ways to do layout. And it's just a theme throughout. And we also take it a step even further by copying spec text word for word and just copy pasting it as comment into our code, so that you can always cross reference the spec with the code because we have the spec right there. So it's interleaved. So you would have a spec comment that says like, 'Step three, do X, Y, Z.' And then the code, X, Y, Z. 'Step four,' and so on. And it took a while to convince ourselves that this was a good way to work, because it makes the code a lot bigger and it can look bloated. But after we got used to it, I don't think we would ever go back, because it's such a much easier way to stay on top of the spec and what the spec intends, and to be able to react to changes. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Martin made a similar comment actually, because I guess this is a thing in Rust... I'm sorry, in Servo, at least in the newer. So, Servo has two layout engines, and I guess this is something that it seems all of the engines have learned and started changing to do that. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Martin, he seemed to suggest that this is basically a lesson that all of the browser engines have learned. And it's hard to... We can't just rewrite them, but we can migrate them in that direction. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right, and for us, it's a lot easier to do this because we are in a green field environment. We don't have a huge stack of code that needs to be rewritten. So we've been able to make really good and fast progress towards this, and that's really nice. But of course, the others will catch up, and I think it would be great if more engines look more like the spec because it will be easier to cross reference and catch bugs and so on. And it'll also be easier for people to move between different engines, and people with special interests who want to implement a feature in all engines, the more the code looks like the spec everywhere, the easier it'll be for them, as well. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: So, Serenity is currently, has been, anyway, a passion project, basically, for everybody. We want to do it because we believe we can do it, and we want the outcome. This thing where it's not disconnected libraries, but do you see that there are potentials for it to be something more than that? Can you imagine use cases for Serenity that it could be a practical choice, or Ladybird, where people could use it for no other purposes? WebKit is used for lots more than Safari. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Well, for me personally, with Serenity, I just want to build an operating system that I can use. That was always my goal since day one. And I'm happy to welcome other people into the project with their own goals, who want to adapt it to something they want to do. But for me personally, I just want to make something that I can use as my daily driver. And I have pretty simple needs. I just need a terminal and a browser and an IDE. So, they're reasonably easy to satisfy. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Your videos, you're not using Serenity to do your code and... Are you? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Right. I do not, because it is not practical. We don't have the ability to record video and we don't have USB webcam support. And also compile performance is not as good on Serenity as it is on Linux. So I just record on Linux because it's more practical. I tend to be a very pragmatic person in all these things. Honestly, recently I'm focusing way more on just building the browser in a cross-platform environment. And it's still... Everything I work on is still part of the operating system. I've just been swept away with the fun of building a browser that might potentially be useful to more people than just myself. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah, right. Yeah. Well that's what I was thinking with... The more useful you can make it to more people, it seems that you get more contributions, which then makes it more useful to more people and so on, right? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah. And I think it's important to be realistic, and realistically, SerenityOS will never be something that's used by millions of people, at least not with the goals that we currently have for it. And with Ladybird, that's much more of an open question, I think, because it's much harder to tell the future. We have great momentum. We're making great progress, and who knows how long we can keep that rate of progress. What will be the first major roadblock? What kind of problems will we face? Who knows? But it's exciting to run towards it so we can see what's there. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: I think that's actually a good place to wrap it up. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Yeah. Okay. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Sure. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Andreas, thank you so much for spending your time with us and sharing all of these insights. Really appreciate it. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Yeah, of course. Happy to meet you guys. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Yeah. And then what we usually ask is where can people find you on the inter tubes? </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Oh, well, I'm on Twitter as AwesomeKling, and also on YouTube as AwesomeKling. </blockquote></li>
                
                <li>
                  <blockquote><cite>Brian Kardell</cite>: Okay. </blockquote></li>
                
                <li>
                  <blockquote><cite>Eric Meyer</cite>: Very nice. Thanks again. </blockquote></li>
                
                <li>
                  <blockquote><cite>Andreas Kling</cite>: Thanks. Thank you.</blockquote></li>
                
              </ul>
            </div>
      </div>
</article>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sacramento Sheriff sharing license plate reader data with anti-abortion states (112 pts)]]></title>
            <link>https://www.sacbee.com/news/politics-government/capitol-alert/article276848586.html</link>
            <guid>36619758</guid>
            <pubDate>Thu, 06 Jul 2023 17:37:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sacbee.com/news/politics-government/capitol-alert/article276848586.html">https://www.sacbee.com/news/politics-government/capitol-alert/article276848586.html</a>, See on <a href="https://news.ycombinator.com/item?id=36619758">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id=""><!----><!----><!----><figure><div>
        
                








    
        <div>
            <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
                <source srcset="https://www.sacbee.com/latest-news/vmto2l/picture275819736/alternates/LANDSCAPE_1140/qsHwReuYO36YlDUF.jpg" media="(min-width: 992px)">
                <source srcset="https://www.sacbee.com/latest-news/vmto2l/picture275819736/alternates/LANDSCAPE_960/qsHwReuYO36YlDUF.jpg" media="(min-width: 768px)">
                <source srcset="https://www.sacbee.com/latest-news/vmto2l/picture275819736/alternates/LANDSCAPE_768/qsHwReuYO36YlDUF.jpg" media="(min-width: 601px)">
                <source srcset="https://www.sacbee.com/latest-news/vmto2l/picture275819736/alternates/LANDSCAPE_640/qsHwReuYO36YlDUF.jpg" media="(min-width: 441px)">
                <source srcset="https://www.sacbee.com/latest-news/vmto2l/picture275819736/alternates/LANDSCAPE_480/qsHwReuYO36YlDUF.jpg" media="(min-width: 320px)">
                <!--[if IE 9]></video><![endif]-->
                
                <img srcset="https://www.sacbee.com/latest-news/vmto2l/picture275819736/alternates/LANDSCAPE_1140/qsHwReuYO36YlDUF.jpg" alt="A license plate readers is affixed to a signal pole in Mission Hills, Kan. More than 70 California law enforcement agencies are violating state law by sharing automated license plate reader (ALPR) data with out-of-state agencies, putting out-of-state abortion seekers at risk, according to a trio of civil rights groups." title="A license plate readers is affixed to a signal pole in Mission Hills, Kan. More than 70 California law enforcement agencies are violating state law by sharing automated license plate reader (ALPR) data with out-of-state agencies, putting out-of-state abortion seekers at risk, according to a trio of civil rights groups." loading="lazy">
                
            </picture>

            
        </div>
    

            
        

                 
                
                    
                        <figcaption>
                            
    
        A license plate readers is affixed to a signal pole in Mission Hills, Kan. More than 70 California law enforcement agencies are violating state law by sharing automated license plate reader (ALPR) data with out-of-state agencies, putting out-of-state abortion seekers at risk, according to a trio of civil rights groups.
    
    
        
            
        
        
            <span>rsugg@kcstar.com</span>
        
    

                        </figcaption>
                    
                
        
    </div></figure><!----><!----><!----><div><p><b>CORRECTION:</b> A previous version of this story incorrectly included a file photograph of equipment from the Sacramento Police Department.</p><p>Corrected Jul 5, 2023</p></div><!--[--><!--[--><p>In 2015, Democratic Elk Grove Assemblyman Jim Cooper voted for <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201520160SB34" target="_blank" rel="Follow">Senate Bill 34</a>, which restricted law enforcement from sharing automated license plate reader (ALPR) data with out-of-state authorities. In 2023, now-Sacramento County Sheriff Cooper appears to be doing just that.</p><!----><!--]--><!--[--><p>The Electronic Frontier Foundation (EFF) a digital rights group, has sent Cooper a letter requesting that the Sacramento County Sheriff‚Äôs Office cease sharing ALPR data with out-of-state agencies that could use it to prosecute someone for seeking an abortion. </p><!----><!--]--><!--[--><p><a href="https://www.muckrock.com/foi/sacramento-county-397/automated-license-plate-readers-sacramento-county-sheriff-136345/#file-1094668" target="_blank" rel="Follow">According to documents</a> that the Sheriff‚Äôs Office provided EFF through a public records request, it has shared license plate reader data with law enforcement agencies in states that have passed laws banning abortion, including Alabama, Oklahoma and Texas.</p><!--]--><!--[--><p>Adam Schwartz, EFF senior staff attorney, called automated license plate readers ‚Äúa growing threat to everyone‚Äôs privacy ... that are out there by the thousands in California.‚Äù </p><!----><!--]--><!--[--><p>Automated license plate readers are often fixed to stationary locations, or police vehicles, and can collect thousands of license plate images that then are stored in a digital cloud. Once in the cloud, it can easily be shared with out-of-state agencies that use the same software. </p><!--]--><!--[--><p>Schwartz said that a sheriff in Texas, Idaho or any other state with an abortion ban on the books could use that data to track people‚Äôs movements around California, knowing where they live, where they work and where they seek reproductive medical care, including abortions. </p><!----><!--]--><!--[--><p>The Sacramento County Sheriff‚Äôs Office isn‚Äôt the only one sharing that data; in May, EFF <a href="https://www.sacbee.com/news/politics-government/capitol-alert/article275795726.html" target="_blank" rel="Follow">released a report</a> showing that 71 law enforcement agencies in 22 California counties ‚Äî including Sacramento County ‚Äî were sharing such data. The practice is in violation of a 2015 law <a href="https://california.public.law/codes/ca_civ_code_section_1798.90.55#:~:text=(b),as%20otherwise%20permitted%20by%20law." target="_blank" rel="Follow">that states</a> ‚Äúa (California law enforcement) agency shall not sell, share, or transfer ALPR information, except to another (California law enforcement) agency, and only as otherwise permitted by law.‚Äù</p><!----><!--]--><!--[--><p>When The Bee wrote in May about the initial EFF report, the Sacramento County Sheriff‚Äôs Office Twitter account <a href="https://twitter.com/sacsheriff/status/1662156652173471746" target="_blank" rel="Follow">responded</a>, even though it was not initially on the list of agencies sharing data. </p><!--]--><!--[--><p>‚ÄúLaw enforcement agencies commonly use information from License Plate Readers (LPRs) to investigate serious crimes, such as homicide, child kidnappings, human trafficking, and drug trafficking across state borders,‚Äù the twitter account said. </p><!----><!--]--><!--[--><p>It is unclear who sent the tweets from the official account. </p><!----><!--]--><!--[--><p>It went on to say that organizations like EFF ‚Äúhave lied that law enforcement sharing this information is an attempt to violate people‚Äôs legal rights. These false claims are intentional and part of a broader agenda to promote lawlessness and prevent criminals from being held accountable.‚Äù</p><!--]--><!--[--><p>The Sacramento County Sheriff‚Äôs Office did not respond to The Bee‚Äôs request for comment by deadline. On Wednesday, after this story published, Cooper <a href="https://twitter.com/SheriffJCooper/status/1676692758810210304" target="_blank" rel="Follow">took to Twitter</a> to accuse the EFF of ‚Äúprotecting child molesters, fentanyl traffickers, rapists and murderers.‚Äù</p><!----><!--]--><!--[--><p>In the tweet, Cooper said that the law allows his office to share license plate data with other law enforcement agencies and that ‚Äúcriminals are not aware of jurisdictional boundaries, much less state lines.‚Äù </p><!----><!--]--><!--[--><p>‚ÄúThe bill and this law has absolutely nothing to do with reproductive rights. My record on women‚Äôs and reproductive rights has been strong throughout my time in the State Assembly, and nothing has changed since becoming Sheriff,‚Äù Cooper wrote. </p><!--]--><!--[--><p>Schwartz said that the May tweets ‚Äúsurprised us, because we had not sent a demand letter to them.‚Äù </p><!----><!--]--><!--[--><p>He said that he was not aware of any cases where ALPR data was used to prosecute someone for getting an abortion, but added, ‚ÄúWe think we shouldn‚Äôt have to wait until the inevitable happens.‚Äù </p><!----><!--]--><!--[--><p>The EFF attorney said that this is a ‚ÄúTale of Two Cities, best of times and worst of times‚Äù situation. While the Sacramento County Sheriff‚Äôs Office appears to be defying the law, another nearby law enforcement agency that was named in the initial report announced that it is no longer doing so. </p><!--]--><!--[--><p>In a letter to the EFF that was shared with The Bee, Woodland Police Chief Derrek Kaff wrote, ‚ÄúWe have implemented a revised protocol that does not allow the sharing of ALPR data with any out-of-state agencies. As a department we are committed to upholding the privacy rights of individuals and reinforces our dedication to adhering to the principles of the Fourth Amendment.‚Äù </p><!----><!--]--><!--]--><!----><p>This story was originally published <span>July 5, 2023, 6:30 AM.</span></p><!----><!----><div><article> 
        
            
    
    

<div>
    <p><a href="https://www.sacbee.com/profile/240145783">
                <img src="https://www.sanluisobispo.com/latest-news/jwkmts/picture229966824/alternates/FREE_480/AndrewSheeler.jpg" alt="Profile Image of Andrew Sheeler" loading="lazy">
            </a>
    </p>

    

    
    
        <p><span>Andrew Sheeler covers California‚Äôs unique political climate for The Sacramento Bee. He has covered crime and politics from interior Alaska to North Dakota‚Äôs oil patch to the rugged coast of southern Oregon. He attended the University of Alaska Fairbanks.</span>
        </p>
</div>

        
    </article></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI for AWS Documentation (195 pts)]]></title>
            <link>https://www.awsdocsgpt.com/</link>
            <guid>36619481</guid>
            <pubDate>Thu, 06 Jul 2023 17:22:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.awsdocsgpt.com/">https://www.awsdocsgpt.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36619481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><div><p><a href="https://www.awsdocsgpt.com/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g transform="translate(0, +6) scale(0.078)"><path fill="currentColor" d="M86.4,66.4c0,3.7,0.4,6.7,1.1,8.9c0.8,2.2,1.8,4.6,3.2,7.2c0.5,0.8,0.7,1.6,0.7,2.3c0,1-0.6,2-1.9,3l-6.3,4.2 c-0.9,0.6-1.8,0.9-2.6,0.9c-1,0-2-0.5-3-1.4C76.2,90,75,88.4,74,86.8c-1-1.7-2-3.6-3.1-5.9c-7.8,9.2-17.6,13.8-29.4,13.8 c-8.4,0-15.1-2.4-20-7.2c-4.9-4.8-7.4-11.2-7.4-19.2c0-8.5,3-15.4,9.1-20.6c6.1-5.2,14.2-7.8,24.5-7.8c3.4,0,6.9,0.3,10.6,0.8 c3.7,0.5,7.5,1.3,11.5,2.2v-7.3c0-7.6-1.6-12.9-4.7-16c-3.2-3.1-8.6-4.6-16.3-4.6c-3.5,0-7.1,0.4-10.8,1.3c-3.7,0.9-7.3,2-10.8,3.4 c-1.6,0.7-2.8,1.1-3.5,1.3c-0.7,0.2-1.2,0.3-1.6,0.3c-1.4,0-2.1-1-2.1-3.1v-4.9c0-1.6,0.2-2.8,0.7-3.5c0.5-0.7,1.4-1.4,2.8-2.1 c3.5-1.8,7.7-3.3,12.6-4.5c4.9-1.3,10.1-1.9,15.6-1.9c11.9,0,20.6,2.7,26.2,8.1c5.5,5.4,8.3,13.6,8.3,24.6V66.4z M45.8,81.6 c3.3,0,6.7-0.6,10.3-1.8c3.6-1.2,6.8-3.4,9.5-6.4c1.6-1.9,2.8-4,3.4-6.4c0.6-2.4,1-5.3,1-8.7v-4.2c-2.9-0.7-6-1.3-9.2-1.7 c-3.2-0.4-6.3-0.6-9.4-0.6c-6.7,0-11.6,1.3-14.9,4c-3.3,2.7-4.9,6.5-4.9,11.5c0,4.7,1.2,8.2,3.7,10.6 C37.7,80.4,41.2,81.6,45.8,81.6z M126.1,92.4c-1.8,0-3-0.3-3.8-1c-0.8-0.6-1.5-2-2.1-3.9L96.7,10.2c-0.6-2-0.9-3.3-0.9-4 c0-1.6,0.8-2.5,2.4-2.5h9.8c1.9,0,3.2,0.3,3.9,1c0.8,0.6,1.4,2,2,3.9l16.8,66.2l15.6-66.2c0.5-2,1.1-3.3,1.9-3.9c0.8-0.6,2.2-1,4-1 h8c1.9,0,3.2,0.3,4,1c0.8,0.6,1.5,2,1.9,3.9l15.8,67l17.3-67c0.6-2,1.3-3.3,2-3.9c0.8-0.6,2.1-1,3.9-1h9.3c1.6,0,2.5,0.8,2.5,2.5 c0,0.5-0.1,1-0.2,1.6c-0.1,0.6-0.3,1.4-0.7,2.5l-24.1,77.3c-0.6,2-1.3,3.3-2.1,3.9c-0.8,0.6-2.1,1-3.8,1h-8.6c-1.9,0-3.2-0.3-4-1 c-0.8-0.7-1.5-2-1.9-4L156,23l-15.4,64.4c-0.5,2-1.1,3.3-1.9,4c-0.8,0.7-2.2,1-4,1H126.1z M254.6,95.1c-5.2,0-10.4-0.6-15.4-1.8 c-5-1.2-8.9-2.5-11.5-4c-1.6-0.9-2.7-1.9-3.1-2.8c-0.4-0.9-0.6-1.9-0.6-2.8v-5.1c0-2.1,0.8-3.1,2.3-3.1c0.6,0,1.2,0.1,1.8,0.3 c0.6,0.2,1.5,0.6,2.5,1c3.4,1.5,7.1,2.7,11,3.5c4,0.8,7.9,1.2,11.9,1.2c6.3,0,11.2-1.1,14.6-3.3c3.4-2.2,5.2-5.4,5.2-9.5 c0-2.8-0.9-5.1-2.7-7c-1.8-1.9-5.2-3.6-10.1-5.2L246,52c-7.3-2.3-12.7-5.7-16-10.2c-3.3-4.4-5-9.3-5-14.5c0-4.2,0.9-7.9,2.7-11.1 c1.8-3.2,4.2-6,7.2-8.2c3-2.3,6.4-4,10.4-5.2c4-1.2,8.2-1.7,12.6-1.7c2.2,0,4.5,0.1,6.7,0.4c2.3,0.3,4.4,0.7,6.5,1.1 c2,0.5,3.9,1,5.7,1.6c1.8,0.6,3.2,1.2,4.2,1.8c1.4,0.8,2.4,1.6,3,2.5c0.6,0.8,0.9,1.9,0.9,3.3v4.7c0,2.1-0.8,3.2-2.3,3.2 c-0.8,0-2.1-0.4-3.8-1.2c-5.7-2.6-12.1-3.9-19.2-3.9c-5.7,0-10.2,0.9-13.3,2.8c-3.1,1.9-4.7,4.8-4.7,8.9c0,2.8,1,5.2,3,7.1 c2,1.9,5.7,3.8,11,5.5l14.2,4.5c7.2,2.3,12.4,5.5,15.5,9.6c3.1,4.1,4.6,8.8,4.6,14c0,4.3-0.9,8.2-2.6,11.6 c-1.8,3.4-4.2,6.4-7.3,8.8c-3.1,2.5-6.8,4.3-11.1,5.6C264.4,94.4,259.7,95.1,254.6,95.1z"></path><g><path fill-rule="evenodd" clip-rule="evenodd" fill="#FF9900" d="M273.5,143.7c-32.9,24.3-80.7,37.2-121.8,37.2c-57.6,0-109.5-21.3-148.7-56.7c-3.1-2.8-0.3-6.6,3.4-4.4 c42.4,24.6,94.7,39.5,148.8,39.5c36.5,0,76.6-7.6,113.5-23.2C274.2,133.6,278.9,139.7,273.5,143.7z"></path><path fill-rule="evenodd" clip-rule="evenodd" fill="#FF9900" d="M287.2,128.1c-4.2-5.4-27.8-2.6-38.5-1.3c-3.2,0.4-3.7-2.4-0.8-4.5c18.8-13.2,49.7-9.4,53.3-5 c3.6,4.5-1,35.4-18.6,50.2c-2.7,2.3-5.3,1.1-4.1-1.9C282.5,155.7,291.4,133.4,287.2,128.1z"></path></g></g></svg><span>AWS Docs GPT</span></a></p><div><nav></nav></div></div></header><section><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div><div><p><a href="">Clear Prompt</a></p></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Six times faster than C (333 pts)]]></title>
            <link>https://owen.cafe/posts/six-times-faster-than-c/</link>
            <guid>36618344</guid>
            <pubDate>Thu, 06 Jul 2023 16:20:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://owen.cafe/posts/six-times-faster-than-c/">https://owen.cafe/posts/six-times-faster-than-c/</a>, See on <a href="https://news.ycombinator.com/item?id=36618344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Sometimes humans can spot optimization opportunities that a compiler <del>can‚Äôt</del>
doesn‚Äôt. In this post, we start with a loop generated from C code by clang, and
tweak it in various ways, measuring the speedup.</p>
<p><strong>Disclaimer</strong>: <em>I‚Äôm not an optimization expert, by any means, in fact my
expertise is in high-level, purely-functional languages, where one
doesn‚Äôt usually think about <strong>how</strong> a program is executed.</em></p>
<p>Code listings for this post can be found on <a href="https://github.com/414owen/blog-code/tree/master/01-six-times-faster-than-c" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="the-function"><a href="#the-function"><span>#&nbsp;</span>The Function</a></h2>
<p>We‚Äôll start with a function that loops through a string, and increments or
decrements a number, depending on the characters it sees.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>int</span> <span>run_switches</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>)</span> <span>{</span>
</span></span><span><span>  <span>int</span> <span>res</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>char</span> <span>c</span> <span>=</span> <span>*</span><span>input</span><span>++</span><span>;</span>
</span></span><span><span>    <span>switch</span> <span>(</span><span>c</span><span>)</span> <span>{</span>
</span></span><span><span>      <span>case</span> <span>'\0'</span><span>:</span>
</span></span><span><span>        <span>return</span> <span>res</span><span>;</span>
</span></span><span><span>      <span>case</span> <span>'s'</span><span>:</span>
</span></span><span><span>        <span>res</span> <span>+=</span> <span>1</span><span>;</span>
</span></span><span><span>        <span>break</span><span>;</span>
</span></span><span><span>      <span>case</span> <span>'p'</span><span>:</span>
</span></span><span><span>        <span>res</span> <span>-=</span> <span>1</span><span>;</span>
</span></span><span><span>        <span>break</span><span>;</span>
</span></span><span><span>      <span>default</span><span>:</span>
</span></span><span><span>        <span>break</span><span>;</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>It increments on seeing an ‚Äôs‚Äô (for successor) and decrements on seeing a
‚Äòp‚Äô (for predecessor).</p>
<p>It‚Äôs a small enough function that gcc and/or clang should be able to optimize it
pretty well. Maybe optimally? I initially wrote this to see whether gcc produced
a jump table or a search.</p>
<p>This is what clang spat out (padding noops removed, and annotated manually):</p>
<div>
<p><label for="tab-asmc-0">pseudocode</label><label for="tab-asmc-1">arrows</label>
</p>
<div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span># llvm-objdump -d --symbolize-operands --no-addresses --x86-asm-syntax=intel --no-show-raw-insn loop-1-clang.c.o
</span></span></span><span><span><span></span>
</span></span><span><span><span>run_switches:</span>
</span></span><span><span>      <span>xor</span>     <span>eax</span><span>,</span> <span>eax</span>            <span># res = 0
</span></span></span><span><span><span></span><span>loop:</span>                             <span># while (true) {
</span></span></span><span><span><span></span>      <span>movsx</span>   <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span> <span>#   c = *input
</span></span></span><span><span><span></span>      <span>test</span>    <span>ecx</span><span>,</span> <span>ecx</span>            <span>#   if (c == '\0')
</span></span></span><span><span><span></span>      <span>je</span>      <span>ret</span>                 <span>#     return
</span></span></span><span><span><span></span>      <span>add</span>     <span>rdi</span><span>,</span> <span>1</span>              <span>#   input++
</span></span></span><span><span><span></span>      <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>            <span>#   if (c == 'p')
</span></span></span><span><span><span></span>      <span>je</span>      <span>p</span>                   <span>#     goto p
</span></span></span><span><span><span></span>      <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>            <span>#   if (c == 's')
</span></span></span><span><span><span></span>      <span>jne</span>     <span>loop</span>                <span>#     continue
</span></span></span><span><span><span></span>      <span>add</span>     <span>eax</span><span>,</span> <span>1</span>              <span>#   res++
</span></span></span><span><span><span></span>      <span>jmp</span>     <span>loop</span>                <span>#   continue
</span></span></span><span><span><span></span><span>p:</span>    <span>add</span>     <span>eax</span><span>,</span> <span>-</span><span>1</span>             <span>#   res--
</span></span></span><span><span><span></span>      <span>jmp</span>     <span>loop</span>                <span># }
</span></span></span><span><span><span></span><span>ret:</span>  <span>ret</span>
</span></span></code></pre></div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span># objdump -Mintel -d --no-addresses --no-show-raw-insn --visualize-jumps loop-1-clang.c.o
</span></span></span><span><span><span></span>
</span></span><span><span><span>run_switches:</span>
</span></span><span><span>              <span>xor</span>    <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span><span>loop:</span>
</span></span><span><span>      <span>‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚û§</span> <span>movsx</span>  <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>      <span>‚îÇ</span>      <span>test</span>   <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>      <span>‚îÇ</span> <span>‚ï≠‚îÄ‚îÄ‚îÄ</span> <span>je</span>     <span>ret</span>
</span></span><span><span>      <span>‚îÇ</span> <span>‚îÇ</span>    <span>add</span>    <span>rdi</span><span>,</span> <span>1</span>
</span></span><span><span>      <span>‚îÇ</span> <span>‚îÇ</span>    <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>      <span>‚îÇ</span> <span>‚îÇ</span> <span>‚ï≠‚îÄ</span> <span>je</span>     <span>p</span>
</span></span><span><span>      <span>‚îÇ</span> <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>      <span>‚îú‚îÄ‚îÇ‚îÄ‚îÇ‚îÄ</span> <span>jne</span>    <span>loop</span>
</span></span><span><span>      <span>‚îÇ</span> <span>‚îÇ</span> <span>‚îÇ</span>  <span>add</span>    <span>eax</span><span>,</span> <span>1</span>
</span></span><span><span>      <span>‚îú‚îÄ‚îÇ‚îÄ‚îÇ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span><span><span><span>p:</span>    <span>‚îÇ</span> <span>‚îÇ</span> <span>‚ï∞‚û§</span> <span>add</span>    <span>eax</span><span>,</span> <span>-</span><span>1</span>
</span></span><span><span>      <span>‚ï∞‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span><span><span><span>ret:</span>    <span>‚ï∞‚îÄ‚îÄ‚û§</span> <span>ret</span>
</span></span></code></pre></div>
</div>
</div>
<p><strong>Runtime:</strong> 3.23s üêå</p>
<p><strong>Bitrate</strong>: 295.26MiB/s</p>
<p>GCC spat out a little more code, that ran a little faster (not much).</p>
<p>This code is pretty straightforward, it has three conditional branch
instructions (je, je, jne), leading to four possible blocks, ‚Äò\0‚Äô, ‚Äôs‚Äô, ‚Äòp‚Äô, and
a block for any other character.</p>
<h2 id="rearranging-branches"><a href="#rearranging-branches"><span>#&nbsp;</span>Rearranging branches</a></h2>
<p>However, we know some things about this loop. We know that the only time we
break out of it is when we hit the null terminator (‚Äô\0‚Äô). The code clang
generates checks for the null terminator first, but this makes no sense. The
maximum number of null terminators we will ever hit in this function is 1, so
for every ‚Äòp‚Äô and ‚Äôs‚Äô character, we‚Äôre checking for null first. We should
optimize for ‚Äòp‚Äôs, ‚Äôs‚Äôs and other characters over null terminators.</p>
<p>So, let‚Äôs rearrange this loop a little.</p>
<div>
<p><label for="tab-asm1-0">arrows</label><label for="tab-asm1-1">raw</label>
</p>
<div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>               <span>xor</span>    <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span><span>loop:</span>  <span>‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚û§</span> <span>movsx</span>  <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>       <span>‚îÇ</span>       <span>inc</span>    <span>rdi</span>
</span></span><span><span>       <span>‚îÇ</span>       <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ</span> <span>je</span>     <span>p</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>     <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚ï≠‚îÄ‚îÄ</span> <span>je</span>     <span>s</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚îÇ</span>   <span>test</span>   <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>       <span>‚îú‚îÄ‚îÇ‚îÄ‚îÇ‚îÄ‚îÄ</span> <span>jne</span>    <span>loop</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚îÇ</span>   <span>ret</span>
</span></span><span><span><span>p:</span>     <span>‚îÇ</span> <span>‚ï∞‚îÄ‚îÇ‚îÄ‚û§</span> <span>dec</span>    <span>eax</span>
</span></span><span><span>       <span>‚îú‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span><span><span><span>s:</span>     <span>‚îÇ</span>   <span>‚ï∞‚îÄ‚û§</span> <span>inc</span>    <span>eax</span>
</span></span><span><span>       <span>‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span></code></pre></div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>        <span>xor</span>     <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span><span>loop:</span>   <span>movsx</span>   <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>        <span>inc</span>     <span>rdi</span>
</span></span><span><span>        <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>        <span>je</span>      <span>p</span>
</span></span><span><span>        <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>        <span>je</span>      <span>s</span>
</span></span><span><span>        <span>test</span>    <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>        <span>jne</span>     <span>loop</span>
</span></span><span><span>        <span>ret</span>
</span></span><span><span><span>p:</span>      <span>dec</span>     <span>eax</span>
</span></span><span><span>        <span>jmp</span>     <span>loop</span>
</span></span><span><span><span>s:</span>      <span>inc</span>     <span>eax</span>
</span></span><span><span>        <span>jmp</span>     <span>loop</span>
</span></span></code></pre></div>
</div>
</div>
<p>Great, now we branch earlier on seeing a ‚Äòp‚Äô or an ‚Äôs‚Äô, than on the rare ‚Äò\0‚Äô.</p>
<p><strong>Runtime:</strong> 3.10s ü¶•</p>
<p><strong>Speedup:</strong>: 1.04x üìà</p>
<p><strong>Bitrate</strong>: 307.64MiB/s</p>
<h2 id="rearranging-blocks"><a href="#rearranging-blocks"><span>#&nbsp;</span>Rearranging blocks</a></h2>
<p>So both of our common cases (‚Äòp‚Äô and ‚Äôs‚Äô) jump back to the top of the loop,
so why don‚Äôt we remove one of those branches by putting its target block (or
BasicBlock‚Ñ¢, for people in compiler land), at the top of the loop?</p>
<div>
<p><label for="tab-asm2-0">arrows</label><label for="tab-asm2-1">raw</label>
</p>
<div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>              <span>xor</span>    <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span>       <span>‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span><span><span><span>s:</span>     <span>‚îÇ</span> <span>‚ï≠‚îÄ‚îÄ‚û§</span> <span>inc</span>    <span>eax</span>
</span></span><span><span><span>loop:</span>  <span>‚îú‚îÄ‚îÇ‚îÄ‚îÄ‚û§</span> <span>movsx</span>  <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>    <span>inc</span>    <span>rdi</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>    <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚ï≠‚îÄ</span> <span>je</span>     <span>p</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚ï∞‚îÄ‚îÇ‚îÄ</span> <span>je</span>     <span>s</span>
</span></span><span><span>       <span>‚îÇ</span>   <span>‚îÇ</span>  <span>test</span>   <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>       <span>‚îú‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ</span> <span>jne</span>    <span>loop</span>
</span></span><span><span>       <span>‚îÇ</span>   <span>‚îÇ</span>  <span>ret</span>
</span></span><span><span><span>p:</span>     <span>‚îÇ</span>   <span>‚ï∞‚û§</span> <span>dec</span>    <span>eax</span>
</span></span><span><span>       <span>‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span></code></pre></div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>        <span>xor</span>     <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span>        <span>jmp</span>     <span>loop</span>       <span># This is new
</span></span></span><span><span><span></span><span>s:</span>      <span>inc</span>     <span>eax</span>        <span># This is up here now
</span></span></span><span><span><span></span><span>loop:</span>   <span>movsx</span>   <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>        <span>inc</span>     <span>rdi</span>
</span></span><span><span>        <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>        <span>je</span>      <span>p</span>
</span></span><span><span>        <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>        <span>je</span>      <span>s</span>
</span></span><span><span>        <span>test</span>    <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>        <span>jne</span>     <span>loop</span>
</span></span><span><span>        <span>ret</span>
</span></span><span><span><span>p:</span>      <span>dec</span>     <span>eax</span>
</span></span><span><span>        <span>jmp</span>     <span>loop</span>
</span></span></code></pre></div>
</div>
</div>
<p>Great, now our ‚Äôs‚Äô block falls through into the loop without a branch. Pretty
sweet.</p>
<p>You‚Äôll notice that we now have to jump into the loop from the function start,
to avoid running the ‚Äôs‚Äô block. This is a pretty good tradeoff though, jumping
into the loop from the function start happens once, whereas we encounter many
‚Äôs‚Äô characters.</p>
<p>But is it fast?</p>
<p><strong>Runtime:</strong> 2.98s üê¢</p>
<p><strong>Overall speedup:</strong>: 1.08x üìà</p>
<p><strong>Bitrate</strong>: 320.02MiB/s</p>
<h2 id="replacing-jumps-with-arithmetic"><a href="#replacing-jumps-with-arithmetic"><span>#&nbsp;</span>Replacing jumps with arithmetic</a></h2>
<p>Conditional jumps <a href="https://en.wikipedia.org/wiki/Branch_predictor" target="_blank" rel="noopener">are bad</a>, but
how about your standard garden variety unconditional <code>jmp</code>? What if we tried to
eliminate <code>p:</code>‚Äôs jump back into the loop?</p>
<p>A decrement is the same as two decrements and an increment, right? So let‚Äôs use
that to fall through into <code>s:</code>.</p>
<div>
<p><label for="tab-asm3-0">arrows</label><label for="tab-asm3-1">raw</label>
</p>
<div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>               <span>xor</span>    <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span>       <span>‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span><span><span><span>p:</span>     <span>‚îÇ</span>   <span>‚ï≠‚îÄ‚û§</span> <span>sub</span>    <span>eax</span><span>,</span> <span>2</span>
</span></span><span><span><span>s:</span>     <span>‚îÇ</span> <span>‚ï≠‚îÄ‚îÇ‚îÄ‚û§</span> <span>inc</span>    <span>eax</span>
</span></span><span><span><span>loop:</span>  <span>‚îú‚îÄ‚îÇ‚îÄ‚îÇ‚îÄ‚û§</span> <span>movsx</span>  <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚îÇ</span>   <span>inc</span>    <span>rdi</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚îÇ</span>   <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span> <span>‚ï∞‚îÄ‚îÄ</span> <span>je</span>     <span>p</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>     <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ</span> <span>je</span>     <span>s</span>
</span></span><span><span>       <span>‚îÇ</span>       <span>test</span>   <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>       <span>‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span> <span>jne</span>    <span>loop</span>
</span></span><span><span>               <span>ret</span>
</span></span></code></pre></div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>        <span>xor</span>     <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span>        <span>jmp</span>     <span>loop</span>
</span></span><span><span><span>p:</span>      <span>sub</span>     <span>eax</span><span>,</span> <span>2</span>
</span></span><span><span><span>s:</span>      <span>inc</span>     <span>eax</span>
</span></span><span><span><span>loop:</span>   <span>movsx</span>   <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>        <span>inc</span>     <span>rdi</span>
</span></span><span><span>        <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>        <span>je</span>      <span>p</span>
</span></span><span><span>        <span>cmp</span>     <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>        <span>je</span>      <span>s</span>
</span></span><span><span>        <span>test</span>    <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>        <span>jne</span>     <span>loop</span>
</span></span><span><span>        <span>ret</span>
</span></span></code></pre></div>
</div>
</div>
<p>Well, we got rid of another branch instruction, using basic arithmetic. Good for
us. Is it faster though?</p>
<p><strong>Runtime:</strong> 2.87s ü¶å</p>
<p><strong>Overall speedup:</strong>: 1.12x üìà</p>
<p><strong>Bitrate</strong>: 332.29MiB/s</p>
<p>Fun fact, we‚Äôve been comparing our performance to clang 16‚Äôs output this whole
time, but GCC 12 actually produced faster (but more) code. GCC‚Äôs code runs in
2.87s as well, so we only just caught up with it, however our program consists
of 13 instructions, and GCC‚Äôs is 19.</p>
<p>GCC‚Äôs code seems to have unrolled the loop, and is reusing the case blocks to
some extent.</p>
<h2 id="just-dont-branch"><a href="#just-dont-branch"><span>#&nbsp;</span>Just don‚Äôt branch</a></h2>
<p>Okay, but these <strong>conditional</strong> branches are the real problem, right? How do you
make the branch predictor fast? I don‚Äôt know, so let‚Äôs just not use it.</p>
<div>
<p><label for="tab-asm4-0">arrows</label><label for="tab-asm4-1">pseudocode</label>
</p>
<div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span># rdi: char *input
</span></span></span><span><span><span># eax: ouput
</span></span></span><span><span><span># r8:  1
</span></span></span><span><span><span># edx: -1
</span></span></span><span><span><span># ecx: char c
</span></span></span><span><span><span># esi: n
</span></span></span><span><span><span></span>
</span></span><span><span><span>run_switches:</span>
</span></span><span><span>            <span>xor</span>    <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span>            <span>mov</span>    <span>r8d</span><span>,</span> <span>1</span>
</span></span><span><span>            <span>mov</span>    <span>edx</span><span>,</span> <span>-</span><span>1</span>
</span></span><span><span><span>loop:</span> 
</span></span><span><span>       <span>‚ï≠‚îÄ‚îÄ‚û§</span> <span>movsx</span>  <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>       <span>‚îÇ</span>    <span>test</span>   <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚ï≠‚îÄ</span> <span>je</span>     <span>ret</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>  <span>inc</span>    <span>rdi</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>  <span>mov</span>    <span>esi</span><span>,</span> <span>0</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmove</span>  <span>esi</span><span>,</span> <span>edx</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmove</span>  <span>esi</span><span>,</span> <span>r8d</span>
</span></span><span><span>       <span>‚îÇ</span> <span>‚îÇ</span>  <span>add</span>    <span>eax</span><span>,</span> <span>esi</span>
</span></span><span><span>       <span>‚ï∞‚îÄ‚îÇ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span><span><span><span>ret:</span>     <span>‚ï∞‚û§</span> <span>ret</span>
</span></span></code></pre></div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span># rdi: char *input
</span></span></span><span><span><span># eax: ouput
</span></span></span><span><span><span># r8:  1
</span></span></span><span><span><span># edx: -1
</span></span></span><span><span><span># ecx: char c
</span></span></span><span><span><span># esi: n
</span></span></span><span><span><span></span>
</span></span><span><span><span>run_switches:</span>
</span></span><span><span>        <span>xor</span>    <span>eax</span><span>,</span> <span>eax</span>             <span># res = 0
</span></span></span><span><span><span></span>        <span>mov</span>    <span>r8d</span><span>,</span> <span>1</span>               <span># need  1 in a register later
</span></span></span><span><span><span></span>        <span>mov</span>    <span>edx</span><span>,</span> <span>-</span><span>1</span>              <span># need -1 in a register later
</span></span></span><span><span><span></span><span>loop:</span>                               <span># while (true) {
</span></span></span><span><span><span></span>        <span>movsx</span>  <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>  <span>#   char c = *input
</span></span></span><span><span><span></span>        <span>test</span>   <span>ecx</span><span>,</span> <span>ecx</span>             <span>#   if (c == '\0')
</span></span></span><span><span><span></span>        <span>je</span>     <span>ret</span>                  <span>#     return
</span></span></span><span><span><span></span>        <span>inc</span>    <span>rdi</span>                  <span>#   input++
</span></span></span><span><span><span></span>        <span>mov</span>    <span>esi</span><span>,</span> <span>0</span>               <span>#   n = 0
</span></span></span><span><span><span></span>        <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>             <span>#   if (c == 'p')
</span></span></span><span><span><span></span>        <span>cmove</span>  <span>esi</span><span>,</span> <span>edx</span>             <span>#     n = -1
</span></span></span><span><span><span></span>        <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>             <span>#   if (c == 's')
</span></span></span><span><span><span></span>        <span>cmove</span>  <span>esi</span><span>,</span> <span>r8d</span>             <span>#     n = 1
</span></span></span><span><span><span></span>        <span>add</span>    <span>eax</span><span>,</span> <span>esi</span>             <span>#   res += n
</span></span></span><span><span><span></span>        <span>jmp</span>    <span>loop</span>                 <span># }
</span></span></span><span><span><span></span><span>ret:</span>    <span>ret</span>
</span></span></code></pre></div>
</div>
</div>
<p>Wow that removed a lot of arrows from the control flow graph‚Ä¶</p>
<p>Instead of branching/jumping conditionally, we‚Äôre using a different value
for the addition depending on the current character, using <code>cmove</code>, or‚Ä¶
‚ú®‚ú®<strong>conditional move on equality</strong>‚ú®‚ú®.</p>
<p>The rules are: by default use zero, if we‚Äôre on an ‚Äôs‚Äô, use 1, and if we‚Äôre on a
‚Äòp‚Äô, use -1. Then <strong>always</strong> add.</p>
<p>Right, nice flex, but‚Ä¶ Is it fast?</p>
<p><strong>Runtime:</strong> 0.48s üêÜ</p>
<p><strong>Overall speedup:</strong>: 6.73x üìà</p>
<p><strong>Bitrate</strong>: 1.94GiB/s</p>
<p>Yes it‚Äôs pretty damn fast.</p>
<h2 id="freeing-up-a-register"><a href="#freeing-up-a-register"><span>#&nbsp;</span>Freeing up a register</a></h2>
<p>x86_64 has another way of conditionally setting a (1 byte) register to 0 or 1.
It‚Äôs called <code>sete</code>. Let‚Äôs use that, and remove our use of r8d.</p>
<div>
<p><label for="tab-asm5-0">arrows</label><label for="tab-asm5-1">pseudocode</label>
</p>
<div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>             <span>xor</span>    <span>eax</span><span>,</span> <span>eax</span>
</span></span><span><span>             <span>mov</span>    <span>edx</span><span>,</span> <span>-</span><span>1</span>
</span></span><span><span><span>loop:</span>
</span></span><span><span>        <span>‚ï≠‚îÄ‚îÄ‚û§</span> <span>movsx</span>  <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>
</span></span><span><span>        <span>‚îÇ</span>    <span>test</span>   <span>ecx</span><span>,</span> <span>ecx</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚ï≠‚îÄ</span> <span>je</span>     <span>ret</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚îÇ</span>  <span>inc</span>    <span>rdi</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚îÇ</span>  <span>mov</span>    <span>esi</span><span>,</span> <span>0</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚îÇ</span>  <span>sete</span>   <span>sil</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmp</span>    <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚îÇ</span>  <span>cmove</span>  <span>esi</span><span>,</span> <span>edx</span>
</span></span><span><span>        <span>‚îÇ</span> <span>‚îÇ</span>  <span>add</span>    <span>eax</span><span>,</span> <span>esi</span>
</span></span><span><span>        <span>‚ï∞‚îÄ‚îÇ‚îÄ</span> <span>jmp</span>    <span>loop</span>
</span></span><span><span><span>ret:</span>      <span>‚ï∞‚û§</span> <span>ret</span>
</span></span></code></pre></div>
<div><pre tabindex="0"><code data-lang="asm"><span><span><span>run_switches:</span>
</span></span><span><span>        <span>xor</span>   <span>eax</span><span>,</span> <span>eax</span>             <span># res = 0
</span></span></span><span><span><span></span>        <span>mov</span>   <span>edx</span><span>,</span> <span>-</span><span>1</span>              <span># need -1 in a register later
</span></span></span><span><span><span></span><span>loop:</span>                              <span># while (true) {
</span></span></span><span><span><span></span>        <span>movsx</span> <span>ecx</span><span>,</span> <span>byte</span> <span>ptr</span> <span>[</span><span>rdi</span><span>]</span>  <span>#   char c = *input
</span></span></span><span><span><span></span>        <span>test</span>  <span>ecx</span><span>,</span> <span>ecx</span>             <span>#   if (c == '\0')
</span></span></span><span><span><span></span>        <span>je</span>    <span>ret</span>                  <span>#     return
</span></span></span><span><span><span></span>        <span>inc</span>   <span>rdi</span>                  <span>#   input++
</span></span></span><span><span><span></span>        <span>mov</span>   <span>esi</span><span>,</span> <span>0</span>               <span>#   n = 0
</span></span></span><span><span><span></span>        <span>cmp</span>   <span>ecx</span><span>,</span> <span>'</span><span>s</span><span>'</span>             <span>#   c == 's'?
</span></span></span><span><span><span></span>        <span>sete</span>  <span>sil</span>                  <span>#     n = 0|1
</span></span></span><span><span><span></span>        <span>cmp</span>   <span>ecx</span><span>,</span> <span>'</span><span>p</span><span>'</span>             <span>#   if (c == 'p')
</span></span></span><span><span><span></span>        <span>cmove</span> <span>esi</span><span>,</span> <span>edx</span>             <span>#     n = -1
</span></span></span><span><span><span></span>        <span>add</span>   <span>eax</span><span>,</span> <span>esi</span>             <span>#   res += n
</span></span></span><span><span><span></span>        <span>jmp</span>   <span>loop</span>                 <span># }
</span></span></span><span><span><span></span><span>ret:</span>    <span>ret</span>
</span></span></code></pre></div>
</div>
</div>
<p>‚Ä¶ But is it fast?</p>
<p><strong>Runtime:</strong> 0.51s ü¶Å</p>
<p><strong>Overall speedup:</strong>: 6.33x üìà</p>
<p><strong>Bitrate</strong>: 1.83GiB/s</p>
<p>Well, that‚Äôs slower than using <code>cmov</code>s. I guess there are no points for using
less registers, or for using 8-bit operations instead of 32-bit ones‚Ä¶</p>
<h2 id="other-attempts"><a href="#other-attempts"><span>#&nbsp;</span>Other attempts</a></h2>
<p>I tried unrolling the loop of our best version. This slowed down the code.</p>
<p>I tried aligning the start of the loop to a 16-byte boundary (pro tip, you
can add <code>.align &lt;bytes&gt;</code> before a label, and GNU assembler will insert <code>nop</code>
instructions for you). This also slowed down the code.</p>
<h2 id="benchmarking-setup"><a href="#benchmarking-setup"><span>#&nbsp;</span>Benchmarking setup</a></h2>
<div><pre tabindex="0"><code data-lang="sh"><span><span>$ uname -sr
</span></span><span><span>Linux 6.1.33
</span></span><span><span>$ lscpu
</span></span><span><span>...
</span></span><span><span>  Model name:            AMD Ryzen <span>5</span> 5625U with Radeon Graphics
</span></span><span><span>    CPU family:          <span>25</span>
</span></span><span><span>    Thread<span>(</span>s<span>)</span> per core:  <span>2</span>
</span></span><span><span>    Core<span>(</span>s<span>)</span> per socket:  <span>6</span>
</span></span><span><span>    Socket<span>(</span>s<span>)</span>:           <span>1</span>
</span></span><span><span>$ clang --version
</span></span><span><span>clang version 16.0.1
</span></span><span><span>$ gcc --version
</span></span><span><span>gcc <span>(</span>GCC<span>)</span> 12.2.0
</span></span></code></pre></div><p>The C versions were compiled with <code>-march=native</code>, so that the C compiler knew
to produce code that was fast on <strong>my specific</strong> CPU, not some generic x86_64.</p>
<p>The benchmark runs the function over a list of one million characters (random
‚Äòp‚Äôs and ‚Äôs‚Äôs) one thousand times.</p>
<p>For each version, the benchmark was run several times, and the best result
chosen.</p>
<h2 id="conclusion"><a href="#conclusion"><span>#&nbsp;</span>Conclusion</a></h2>
<p>You can (sometimes) get a 6x speedup by hand-coding your tight C loop in
assembly, and optimizing using techniques that compilers don‚Äôt seem to have
automated away yet.</p>
<p>Of course, this post isn‚Äôt the end. If this still isn‚Äôt fast enough for you,
you can read <a href="https://owen.cafe/posts/the-same-speed-as-c/">part two</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[USGS estimates at least 45% of U.S. tap water contain forever chemicals (175 pts)]]></title>
            <link>https://www.usgs.gov/news/national-news-release/tap-water-study-detects-pfas-forever-chemicals-across-us</link>
            <guid>36617822</guid>
            <pubDate>Thu, 06 Jul 2023 15:47:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usgs.gov/news/national-news-release/tap-water-study-detects-pfas-forever-chemicals-across-us">https://www.usgs.gov/news/national-news-release/tap-water-study-detects-pfas-forever-chemicals-across-us</a>, See on <a href="https://news.ycombinator.com/item?id=36617822">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>This USGS research marks the first time anyone has tested for and compared PFAS in tap water from both private and government-regulated public water supplies on a broad scale throughout the country. Those data were used to model and estimate PFAS contamination nationwide. This USGS <a href="https://www.sciencedirect.com/science/article/pii/S0160412023003069?via%3Dihub">study</a> can help members of the public to understand their risk of exposure and inform policy and management decisions regarding testing and treatment options for drinking water.&nbsp;</p>
<p>PFAS are a group of synthetic chemicals used in a wide variety of common applications, from the linings of fast-food boxes and non-stick cookware to fire-fighting foams and other purposes. High concentrations of some PFAS may lead to adverse health risks in people, according to the <a href="https://www.epa.gov/pfas/our-current-understanding-human-health-and-environmental-risks-pfas" target="_blank">U.S. Environmental Protection Agency</a>. Research is still ongoing to better understand the potential health effects of PFAS exposure over long periods of time. Because they break down very slowly, PFAS are commonly called ‚Äúforever chemicals.‚Äù Their persistence in the environment and prevalence across the country make them a unique water-quality concern.&nbsp;</p>
<figure role="group">

  

<figcaption>A USGS scientist wearing black gloves is collecting a sample of tap water from the kitchen sink using small plastic vials to test for PFAS.</figcaption>
</figure>
<p>"USGS scientists tested water collected directly from people‚Äôs kitchen sinks across the nation, providing the most comprehensive study to date on PFAS in tap water from both private wells and public supplies,‚Äù said USGS research hydrologist Kelly Smalling, the study‚Äôs lead author. ‚ÄúThe study estimates that at least one type of PFAS ‚Äì of those that were monitored ‚Äì could be present in nearly half of the tap water in the U.S. Furthermore, PFAS concentrations were similar between public supplies and private wells.‚Äù&nbsp;&nbsp;</p>
<p>The EPA regulates public water supplies, and homeowners are responsible for the maintenance, testing and treatment of private water supplies. Those interested in testing and treating private wells should contact their local and state officials for guidance. Testing is the only way to confirm the presence of these contaminants in wells. For more information about PFAS regulations, visit the EPA‚Äôs <a href="https://www.epa.gov/pfas/key-epa-actions-address-pfas" target="_blank">website on addressing PFAS</a>.&nbsp;</p>
<p>The study tested for 32 individual PFAS compounds using a method developed by the USGS National Water Quality Laboratory. The most frequently detected compounds in this study were PFBS, PFHxS and PFOA. The interim health advisories released by the EPA in 2022 for PFOS and PFOA were exceeded in every sample in which they were detected in this study.&nbsp;</p>
<p>Scientists collected tap water samples from 716 locations representing a range of low, medium and high human-impacted areas. The low category includes protected lands; medium includes residential and rural areas with no known PFAS sources; and high includes urban areas and locations with reported PFAS sources such as industry or waste sites.&nbsp;&nbsp;</p>
<figure role="group">

  

<figcaption>This USGS map shows the number of PFAS detected in tap water samples from select sites across the nation. The findings are based on a USGS study of samples taken between 2016 and 2021 from private and public supplies at 716 locations. The map does not represent the only locations in the U.S. with PFAS.&nbsp;&nbsp;</figcaption>
</figure>
<p>Most of the exposure was observed near urban areas and potential PFAS sources. This included the Great Plains, Great Lakes, Eastern Seaboard, and Central/Southern California regions. The study‚Äôs results are in line with previous research concluding that people in urban areas have a higher likelihood of PFAS exposure. USGS scientists estimate that the probability of PFAS not being observed in tap water is about 75% in rural areas and around 25% in urban areas.&nbsp;&nbsp;</p>
<p>Learn more about USGS research on PFAS by reading the USGS <a href="https://pubs.usgs.gov/circ/1490/cir1490.pdf" target="_blank">strategy for the study of PFAS</a> and visiting the <a href="https://www.usgs.gov/programs/environmental-health-program/science/and-polyfluoroalkyl-substances-pfas-integrated-0" target="_blank">PFAS Integrated Science Team‚Äôs website</a>. The new study builds upon previous research by the USGS and partners regarding human-derived contaminants, including PFAS, in <a href="https://geonarrative.usgs.gov/drinkingwaterinvestigations/" target="_blank">drinking water</a> and <a href="https://doi.org/10.1021/acs.est.1c04795" target="_blank">PFAS in groundwater</a>.&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Multi-Layered Calendars (192 pts)]]></title>
            <link>https://julian.digital/2023/07/06/multi-layered-calendars/</link>
            <guid>36617504</guid>
            <pubDate>Thu, 06 Jul 2023 15:27:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://julian.digital/2023/07/06/multi-layered-calendars/">https://julian.digital/2023/07/06/multi-layered-calendars/</a>, See on <a href="https://news.ycombinator.com/item?id=36617504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
 		
<h2>Traveling through time in three dimensions</h2>



<p><span>01</span> Intro</p>



<p>Time is a curious thing. It‚Äôs a constantly flowing stream that can‚Äôt be paused, stopped, or repeated. We experience it, but we can‚Äôt control it. We can‚Äôt even touch or feel it.</p>



<p>To get a better grasp of this weird, intangible resource that governs everything around us, humanity has invented a variety of ‚Äútime devices‚Äù. These devices help us to plan and optimize how we spend our time. To make the most out of the here and now.</p>



<p>The most popular time device is the watch. A watch is a useful tool, but its functionality is limited to the present moment. It allows us to <em>see</em> time, but not to <em>manage</em> it. It only tells us the status quo.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2022/04/statusquo.png"></p><p>Calendars, on the other hand, cover the entire spectrum of time. Past, present and future. They are the closest thing we have to a time machine.<strong> Calendars allow us to travel forward in time and see the future.</strong> <strong>More importantly, they allow us to <em>change</em> the future.</strong></p>



<p>Changing the future means dedicating time to things that matter. It means allocating our most precious resource to activities with the highest expected return on investment.</p>



<p>You would expect technologists and entrepreneurs to be intensely focused on perfecting such a magical time travel device, but surprisingly, that has not been the case. Our digital calendars turned out to be just marginally better than their pen and paper predecessors. And since their release, neither Outlook nor Google Calendar have really changed in any meaningful way.</p>



<p>Isn‚Äôt it ironic that, of all things, it‚Äôs our time machines that are stuck in the past?</p>



<p>The essay at hand is an exploration of what calendars could be if they weren‚Äôt stuck in time. But before we discuss their future, we first need to analyze their present status and how they fit into the rest of the productivity stack.</p>



<p><span>02</span> Calendars and the productivity stack</p>



<p>Our productivity stack consists of four types of tools:</p>



<ul><li><strong>Note-taking apps</strong><br>To document and organize our thoughts </li><li><strong>Email</strong><br>To communicate with others</li><li><strong>Task managers<br></strong>To organize the things we need to get done</li><li><strong>Calendars</strong><br>To manage our time</li></ul>



<p>The fact that we use four distinct tools suggests that note-taking, email, task management, and time management are four distinct activities. But when you look closer, you‚Äôll realize that these activities are actually not that clear-cut. In fact, they all heavily overlap. <a href="http://julian.digital/2020/09/04/a-meta-layer-for-notes/">Notes are just emails to your future self</a>. <a href="http://julian.digital/2020/01/17/superhuman-the-productivity-meta-layer/">Emails are just tasks</a>. And tasks are just calendar events.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2022/06/Frame-4.png"></p><p>My personal workflow looks like this:</p>



<ul><li>I treat my email inbox as my primary task manager (and note-taking tool). </li><li>Tasks are emails I receive from others or emails I send to myself. </li><li>I snooze emails until the week I want to get them done. </li><li>At the beginning of each week, I go through my email todo list and block time in my calendar for each task.</li></ul>



<p>The email&lt;&gt;todo part of this workflow actually works reasonably well. Most of today‚Äôs email clients are built around <a href="https://www.youtube.com/watch?v=z9UjeTMb3Yk">the concept of Inbox Zero</a>, which effectively turns your email inbox into a todo list with public write access.</p>



<p>The part we haven‚Äôt really figured out yet is the intersection between task managers and calendars.</p>



<p>Treating todos as calendar events is helpful because calendars introduce constraints. A calendar forces you to estimate how long each task will take and then find empty space for it on a 24 hours √ó 7 days grid, which is already cluttered with other things. It‚Äôs like playing Tetris with blocks of time.</p>



<p>So how do we get tasks into our calendars without awkwardly switching back and forth between two different apps that don‚Äôt talk to each other?</p>



<p>New productivity tools such as <a href="https://amie.so/">Amie</a> are trying to solve this problem by natively inserting todo lists into the calendar experience. In Amie, every calendar event is a task that can be marked as done.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2023/07/amietodo.png"></p><p>This approach is a step in the right direction, but it doesn‚Äôt go far enough. I agree that tasks should live in your calendar, but that doesn‚Äôt mean every calendar event should be a task. The way I see it, tasks are just one of many different types of calendar events. And just one of many different <strong>calendar layers</strong>.</p>



<p><span>03</span> Managing time in three dimensions</p>



<p>To make the concept of calendar layers a little more tangible, let‚Äôs look at a scenario that you have probably seen before:</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2022/08/meetinglayer.png"></p><p>What‚Äôs happening here?</p>



<div><p><strong>1. </strong><b>You have a meeting with Mike</b><br>A meeting is a multiplayer calendar event. It is not the same as a task. It is simply a reminder for all meeting participants that their presence is required (or desired) at a specific time and place. There is no ‚Äúto do‚Äù here apart from showing up on time.</p><p><b>2. You need to travel to and back from your meeting</b><br>To ensure that no other meetings are scheduled during those travel times, you added two ‚Äúdo not schedule‚Äù blocks (DNS). These are neither meetings nor tasks. Their only purpose is to avoid conflicts with other upcoming events. </p></div>



<p>The DNS blocks appear before and after the meeting, but what they really represent is one entire layer of time that stretches from 10:30 to 12:30. Your conversation with Mike is a <strong>meeting layer</strong> <em>on top</em> of your <strong>blocked time layer</strong>.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2022/12/Frame-5350.png"></p><p>We tend to think of calendars as 2D grids with mutually exclusive blocks of time, but as this example shows, not all events automatically cancel each other out. Depending on their characteristics, they can be layered on top of each other. This means we manage time in three, not two, dimensions.</p>



<p>Let‚Äôs see if we can add another layer to the mix.</p>



<p>As discussed at the start of this chapter, neither blocked time nor meetings qualify as tasks ‚Äî but what about talking points or agenda items that need to be covered in your meeting?</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2022/12/Frame-5349.png"></p><p>We are now looking at three different types of calendar events, each with their own unique set of properties. The problem is that our calendars treat all of these different events equally. They don‚Äôt natively differentiate between a task and a meeting even though they are two completely different things.</p>



<p>When I chatted with <a href="https://cron.com/">Cron</a> founder <a href="https://twitter.com/raphaelschaad">Raphael Schaad</a> about this issue, he pointed out another missing layer: Activities. An activity takes place for a prolonged period of time, but only requires your attention at certain points of it ‚Äî not throughout.</p>



<p>Flights, for example, should be native calendar objects with their own unique attributes to highlight key moments such as boarding times or possible delays.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2023/06/flightcal.png"></p><p>This gets us to an interesting question: If our calendars <em>were</em> able to support other types of calendar activities, what else could we map onto them?</p>



<p><span>04</span> Traveling back in time</p>



<p>A while ago, <a href="https://twitter.com/aaronzlewis/status/1259017698136281092">this mock-up appeared in my Twitter feed</a>:</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2023/03/azl.png"></p><p>What‚Äôs so interesting about this idea is not just that it introduces another unique calendar layer, but that the data of this layer is rooted in the past. In contrast to traditional calendar events, all of these Spotify entries were created <em>after</em> they happened.</p>



<p>Something I never really noticed before is that we only use our calendars to look forward in time, never to reflect on things that happened in the past. That feels like a missed opportunity.</p>



<p>While a Spotify layer might seem more like a gimmick than a meaningful productivity hack, the idea of visualizing data from other applications in form of calendar events feels incredibly powerful. What if I could see health data alongside my work activities, for example?</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2023/01/cal_stress.png"></p><p>My biggest gripe with almost all quantified self tools is that they are input-only devices. They are able to collect data, but unable to return any meaningful output. My Garmin watch can tell my current level of stress based on my heart-rate variability, but not what has caused that stress or how I can prevent it in the future. It lacks context.</p>



<p>Once I view the data alongside other events, however, things start to make more sense. Adding workouts or meditation sessions, for example, would give me even more context to understand (and manage) stress.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2023/01/cal_run.png"></p><p>Sleep is another data layer that would make a lot more sense in my calendar than in a standalone app. I already block time in my calendar for sleep (mostly as a DNS-memo to coworkers in other time zones), so why not add sleep quality data directly to that calendar event?</p>



<p>This way I could plan my day ahead with a lot more accuracy. Fully recharged after a solid eight hours of sleep? Block more focus time. Lack of deep sleep? Add another coffee break to the agenda.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2023/01/cal_sleep.png"></p><p>This example is particularly interesting because it leverages all of our calendar‚Äôs time travel capabilities. It allows us to shape the future by studying the past.</p>



<p>Once you start to see the calendar as a time machine that covers more than just future plans, you‚Äôll realize that almost any activity could live in your calendar. As long as it has a time dimension, it can be visualized as a native calendar layer.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2023/01/cal_layers.png"></p><p>Most of these data layers are pretty meaningless in isolation; it‚Äôs only when we view them alongside each other that they unlock their value. Even a Spotify layer starts to make sense when you look at it in combination with stress data (which music calms me down?), productivity metrics (which music helps me focus?), or personal activities from the past (nostalgia).</p>



<p><span>05</span> Closing thoughts</p>



<p>The takeaway of this essay is twofold:</p>



<ul>
<li>Calendars should natively differentiate between different types of calendar events. Tasks, meetings, blocked time, and other activities should look and behave differently depending on their respective attributes.</li>



<li>This would open the door for a virtually infinite amount of other use cases that could be integrated into the calendar experience in the form of unique calendar layers.</li>
</ul>



<p>These changes would not just make the calendar a stronger center of gravity in the aforementioned productivity stack, but turn into an actual tool for thought, where time serves as the scaffolding for our future plans and our memory palaces of the past.</p>







<p><em>Thanks to <a href="https://twitter.com/ajwaxman">Adam Waxman</a>, <a href="https://twitter.com/dennismuellr">Dennis M√ºller</a>, <a href="https://twitter.com/kevinyien">Kevin Yien</a>, <a href="https://twitter.com/pacocoursey">Paco Coursey</a>, <a href="https://twitter.com/mikekarnj">Michael Karnjanaprakorn</a>, and <a href="https://twitter.com/raphaelschaad">Raphael Schaad</a> for reading drafts of this post.</em></p>




































 	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PlanetScale Scaler Pro (124 pts)]]></title>
            <link>https://planetscale.com/blog/announcing-scaler-pro</link>
            <guid>36617433</guid>
            <pubDate>Thu, 06 Jul 2023 15:23:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://planetscale.com/blog/announcing-scaler-pro">https://planetscale.com/blog/announcing-scaler-pro</a>, See on <a href="https://news.ycombinator.com/item?id=36617433">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header><p>See how Scaler Pro combines the best of our current plans for companies of all sizes while enabling you to grow with the best database for serverless.</p></header><div><p><img alt="Announcing PlanetScale Scaler Pro" sizes="100vw" srcset="https://planetscale.com/_next/image?url=%2Fimages%2Fblog%2Fcontent%2Fannouncing-scaler-pro%2Fannouncing-scaler-pro_blog.png&amp;w=640&amp;q=90 640w, https://planetscale.com/_next/image?url=%2Fimages%2Fblog%2Fcontent%2Fannouncing-scaler-pro%2Fannouncing-scaler-pro_blog.png&amp;w=768&amp;q=90 768w, https://planetscale.com/_next/image?url=%2Fimages%2Fblog%2Fcontent%2Fannouncing-scaler-pro%2Fannouncing-scaler-pro_blog.png&amp;w=1024&amp;q=90 1024w, https://planetscale.com/_next/image?url=%2Fimages%2Fblog%2Fcontent%2Fannouncing-scaler-pro%2Fannouncing-scaler-pro_blog.png&amp;w=1280&amp;q=90 1280w, https://planetscale.com/_next/image?url=%2Fimages%2Fblog%2Fcontent%2Fannouncing-scaler-pro%2Fannouncing-scaler-pro_blog.png&amp;w=1536&amp;q=90 1536w, https://planetscale.com/_next/image?url=%2Fimages%2Fblog%2Fcontent%2Fannouncing-scaler-pro%2Fannouncing-scaler-pro_blog.png&amp;w=3840&amp;q=90 3840w" src="https://planetscale.com/_next/image?url=%2Fimages%2Fblog%2Fcontent%2Fannouncing-scaler-pro%2Fannouncing-scaler-pro_blog.png&amp;w=3840&amp;q=90" width="1280" height="720" decoding="async" data-nimg="1"></p></div><div><p>Today, we're announcing a new generation of PlanetScale plans and pricing. Most prominently: we're replacing our Teams plan with a new ‚ÄòScaler Pro‚Äô offering that combines the best of our current plans and enterprise offerings for companies of all sizes. These plans allow customers to select exactly the resources they need for their workloads. Don't worry; our existing Hobby, Scaler, and Enterprise plans aren't changing or increasing in price.</p>
<p>As we've onboarded thousands of customers, large and small, one of the most common pieces of feedback people have given is that they're unsure how to map our pricing model onto their business. Reads and writes are easy to understand conceptually, but they don't map back to capacity planning that businesses are accustomed to. Many customers want more control than the traditional serverless model provides and clarity on how it compares to products like Amazon RDS and Google Cloud SQL.</p>
<p>The serverless pricing model is an interesting pricing framework for databases, but many real-world workloads need to be delineated in more concrete metrics with as little variability as possible. When predictability, stability, and availability matter most, worrying about unbounded and unknown costs is a distraction nobody can afford.</p>
<p>Scaler Pro gives you the controls needed to understand how to grow and scale. Our new plans come with the ability to scale up and down on demand, all with cutting-edge resiliency and availability features. With Scaler Pro, you get a competitive price compared to established Database-as-a-Service (DBaaS) solutions while gaining significantly more features.</p>
<p>This is something we haven't done lightly. We pride ourselves on the innovations we've made in our serverless database pricing model and still aim to be the best database for serverless.</p>

<p>Scaler Pro databases are priced on a combination of resources (CPU and memory) and disk storage. Every database has a ‚Äòcluster size‚Äô encompassing the components that make up a PlanetScale database. Much like our existing plans, we only charge for the storage allocated in your tables, but not binary logs or other metadata.</p>
<p>Below is an updated pricing chart for our plan offerings, nothing has changed in the Hobby, Scaler, and Enterprise plans:</p>
<p><img alt="Pricing chart with the Hobby, Scaler, Scaler Pro, and Enterprise plans, see the full text based chart at planetscale.com/pricing" src="https://planetscale.com/images/blog/content/announcing-scaler-pro/new-pricing-chart-v5.png" decoding="async" data-nimg="fill" loading="lazy"></p>
<p>Now let's dive into what goes into a PlanetScale Scaler Pro database, how it stacks up next to common alternatives that you might already be using, and what you're buying when you provision one.</p>

<p>When you think of your PlanetScale database, what do you imagine? For some, a ‚Äòserverless database‚Äô means something mystical; others are probably picturing a complex web of virtual machines, hard drives, network switches, and all of the pieces in between.</p>
<p>Let's look at a Scaler Pro database in the PlanetScale product and break it down a bit:</p>
<p><img alt="A diagram showing a PlanetScale database on a Scaler Pro plan, shows a load balancer top of of the database with one primary and two replicas" src="https://planetscale.com/images/blog/content/announcing-scaler-pro/architecture-diagram.png" decoding="async" data-nimg="fill" loading="lazy"></p>
<p>In this diagram, the most important components are the primary and replicas. Each of these is an instance of MySQL and the Vitess components around it to handle orchestrating failovers, backups, etc.</p>
<p>Why is this important? It's where the data is! Underneath it all, PlanetScale uses standard MySQL replication to replicate your data and exists in multiple availability zones. All Scaler Pro production branches by default are:</p>
<ul>
<li>Replicated across three availability zones in GCP or AWS</li>
<li>Configured to use MySQL's <code>semi-sync</code> to ensure that writes are persisted across at least two availability zones before being acknowledged to the client</li>
<li>Monitored continuously with Orchestrator, which handles planned and unplanned failovers</li>
</ul>
<p>For Scaler Pro databases, this means that any piece of data you write will exist in at least two redundant block storage volumes that span failure domains, ensuring that the data will be there when you need it. With the Vitess-native <code>Orchestrator</code> looking over your database, the loss of a virtual machine or other problem will be swiftly remediated without a human involved.</p>
<p>Beyond that, PlanetScale runs even more infrastructure behind the scenes: backups are taken by spinning up MySQL instances on-demand that validate existing backups and create new ones, a bespoke pipeline to power PlanetScale Insights, and much more.</p>

<p>In order to create logical and geographic redundancy, cloud providers split up their regions into multiple isolated datacenters that they call availability zones (AZs). In <code>us-east-1</code>, there are six of them: <code>us-east-1a</code> through <code>us-east-1f</code>. Each of these has isolated power and networking, and can be leveraged to create more resilient applications and infrastructure by expecting the failure or one or more of them in your code.</p>
<p>It may come as no surprise, but Amazon is very familiar with the tradeoffs necessary to run MySQL databases. To better understand what Scaler Pro is offering, we can compare it to the different tiers of RDS databases:</p>
<ul>
<li>Single-AZ</li>
<li>Multi-AZ with one standby</li>
<li>Multi-AZ with two readable standbys</li>
</ul>
<p>We can quickly eliminate single Availability Zone (AZ) from consideration for production workloads: it doesn't offer any failover capabilities, no redundancy for the degradation of an availability zone, and resiliency to losing data is limited to backups. A Single-AZ database might be great for small or staging workloads, but not much more. This would be the equivalent of a development branch on PlanetScale.</p>
<p>Looking at Multi-AZ, things get more interesting. This option includes a ‚Äústandby‚Äù instance to which all writes are synchronously replicated, ensuring that if the primary availability zone were to vanish, all of the acknowledged queries would be contained in the second availability zone, just a failover away. This is great for resiliency but not availability. Failover times are a minute or longer, and no read replicas are available for scaling database traffic.</p>
<p>Finally, we land on Multi-AZ with two readable standbys.This option includes a primary and two replica databases and ensures that any writes to the primary have been acknowledged by at least one replica.</p>
<p>If you've been reading along - this will sound familiar; a PlanetScale Scaler Pro database has the same semantics! The biggest benefits of this option are that you gain two replica instances that you can use to scale your reads and much faster failovers due to the live databases that are running and ready to take traffic.</p>
<p>Because there's such a direct comparison, it's now much easier to understand how much switching to PlanetScale could save you. Let's take a look at an apples-to-apples comparison:</p>
<p><img alt="Image showing comparing PlanetScale Scaler Pro PS-320 ($699/month) to Amazon RDS 4 CPU 32 GB RAM ($1,217/month) in us-east-1" src="https://planetscale.com/images/blog/content/announcing-scaler-pro/planetscale-vs-aws-rds-chart-v1.png" decoding="async" data-nimg="fill" loading="lazy"></p>
<p>As you can see, PlanetScale offers all of the benefits of a Multi-AZ with two readable standby databases, at the price of a Multi-AZ with one standby database. This is before we add PlanetScale's industry-leading <a href="https://planetscale.com/docs/concepts/query-insights">Insights</a>, <a href="https://planetscale.com/docs/concepts/nonblocking-schema-changes">non-blocking schema changes</a>, and the ability to use <a href="https://planetscale.com/features/boost">PlanetScale Boost</a>.</p>

<p>Whether you're a current PlanetScale customer or are considering switching from RDS or Cloud SQL, as many have already done, we hope the Scaler Pro pricing scheme works for you. It's as easy as the click of a button to migrate an existing Developer or Scaler database today. For more in-depth coverage of the Scaler Pro plan, check out the <a href="https://planetscale.com/docs/concepts/planetscale-plans#resource-based-plan">plans article in our docs</a>.</p>
<p>If you want to give it a try with a new database, plug your <a href="https://planetscale.com/docs/imports/aws-rds-migration-guide">RDS database into our Imports tool</a> today and give it a whirl - we don't think you'll be disappointed!</p>
<p>If your RDS database requires more scale than any of the sizes on our current price sheet, reach out to our sales team today - we can accommodate workloads that require terabytes of memory and petabytes of storage.</p>
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly half of the tap water in the US is contaminated with ‚Äòforever chemicals,‚Äô (114 pts)]]></title>
            <link>https://www.cnn.com/2023/07/05/health/pfas-nearly-half-us-tap-water-wellness/index.html</link>
            <guid>36616841</guid>
            <pubDate>Thu, 06 Jul 2023 14:50:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/07/05/health/pfas-nearly-half-us-tap-water-wellness/index.html">https://www.cnn.com/2023/07/05/health/pfas-nearly-half-us-tap-water-wellness/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=36616841">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-uri="cms.cnn.com/_components/video-resource/instances/cljq7x2ze0030336fi740msx2@published" data-component-name="video-resource" data-editable="lede" data-video-id="health/2023/03/13/pfas-forever-chemicals-toxic-drinking-water-orig-mg.cnn" data-live="" data-analytics-aggregate-events="true" data-custom-experience="" data-asset-type="hlsTs" data-medium-env="prod" data-autostart="unmuted" data-show-ads="true" data-source="CNN" data-featured-video="true" data-headline="What you need to know about toxic 'forever chemicals'" data-description="You may have never heard of PFAS, but you likely have these potentially dangerous chemicals inside your body. CNN's Dr. Sanjay Gupta explains.<br />" data-duration="02:23" data-source-html="<span class=&quot;video-resource__source&quot;> - Source:
                <a href=&quot;https://www.cnn.com/&quot; class=&quot;video-resource__source-url&quot;>CNN</a>
    </span>" data-fave-thumbnails="{&quot;big&quot;: { &quot;uri&quot;: &quot;https://media.cnn.com/api/v1/images/stellar/prod/230314103750-pfas-orig.jpg?c=16x9&amp;q=h_540,w_960,c_fill&quot; }, &quot;small&quot;: { &quot;uri&quot;: &quot;https://media.cnn.com/api/v1/images/stellar/prod/230314103750-pfas-orig.jpg?c=16x9&amp;q=h_540,w_960,c_fill&quot; }  }" data-vr-video="false" data-show-html="<!-- unable to render partial show without a supplied context -->" data-check-event-based-preview="" data-network-id="" data-details="" data-freewheel-lede="true">
            <div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/thumbnail-image-c75e894297d1bf2a8dab75f4244a1ddf@published" data-name="PFAS orig" data-component-name="image" data-observe-resizes="" data-original-ratio="0.5625" data-original-height="1080" data-original-width="1920" data-url="https://media.cnn.com/api/v1/images/stellar/prod/230314103750-pfas-orig.jpg?c=original" data-unselectable="true" id="player-cms.cnn.com/_components/video-resource/instances/cljq7x2ze0030336fi740msx2@published">
       <picture><img src="https://media.cnn.com/api/v1/images/stellar/prod/230314103750-pfas-orig.jpg?c=16x9&amp;q=w_850,c_fill" alt="PFAS orig" onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1080" width="1920"></picture>
    </div>
            
            <div>
                <p>What you need to know about toxic 'forever chemicals'</p>
                <p><span>
                            02:23
                        </span>
                        <span> - Source:
                <a href="https://www.cnn.com/">CNN</a>
    </span>
                </p>
            </div>
        </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;‚Äî&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7f64b001g26qi717qaqsr@published" data-editable="text" data-component-name="paragraph">
      Almost half of the tap water in the US is contaminated with chemicals known as ‚Äúforever chemicals,‚Äù according to <a href="https://www.sciencedirect.com/science/article/pii/S0160412023003069?via%3Dihub" target="_blank">a new study from</a> the US Geological Survey.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq8cin3000u3b6fni5la7oa@published" data-editable="text" data-component-name="paragraph">
      The number of people drinking contaminated water may be even higher than what the study found, however, because the researchers weren‚Äôt able to test for all of these per- and polyfluorinated alkyl substances, or PFAS, chemicals that are considered dangerous to human health. There are more than <a href="https://pubs.rsc.org/en/content/articlelanding/2020/EM/D0EM00291G" target="_blank">12,000 types</a> of PFAS, according to the&nbsp;<a href="https://www.niehs.nih.gov/health/topics/agents/pfc/index.cfm#:~:text=More%20than%209%2C000%20PFAS%20have%20been%20identified." target="_blank">National Institutes of Health</a>, but this study looked at only 32 of the compounds.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3f001n336ftppsqjyh@published" data-editable="text" data-component-name="paragraph">
      PFAS are <a href="https://www.cnn.com/2022/08/26/health/pfas-epa-forever-chemicals-hazardous-wellness/index.html">a family of ubiquitous synthetic chemicals</a>&nbsp;that linger in <a href="https://www.science.org/doi/full/10.1126/science.abg9065" target="_blank">the environment</a> and the human body. PFAS exposure is linked to problems like <a href="https://ehp.niehs.nih.gov/doi/10.1289/ehp.1306615" target="_blank">cancer</a>, obesity, thyroid disease, high cholesterol, decreased fertility, liver damage and hormone suppression,&nbsp;<a href="https://www.epa.gov/pfas/our-current-understanding-human-health-and-environmental-risks-pfas" target="_blank">according to the US Environmental Protection Agency.</a>
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3g001o336fff9ggz4p@published" data-editable="text" data-component-name="paragraph">
      In June 2022, based on the latest science, the EPA&nbsp;<a href="https://www.epa.gov/newsreleases/epa-announces-new-drinking-water-health-advisories-pfas-chemicals-1-billion-bipartisan" target="_blank">issued health advisories</a>&nbsp;that said the chemicals are much more hazardous to human health than scientists originally thought and are probably more dangerous even at levels thousands of times lower than previously believed.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljrev02u00413b6fkn24ksoi@published" data-editable="text" data-component-name="paragraph">
      Health effects from the chemicals can be difficult to specify in part because people may be exposed in different ways and at different stages of development and because there are so many types of PFAS chemicals with types and uses that have changed over time.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljrf2rm7004m3b6fjsxmwwhi@published" data-editable="text" data-component-name="paragraph">
      Most people in the United States have been exposed to some PFAS, and some may be at higher risk, such as industrial workers involved in making PFAS and people who live near those facilities. There‚Äôs ongoing research to determine how different levels of exposure to PFAS chemicals might lead to various&nbsp;health&nbsp;effects.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljreiiay003f3b6fjcyo5sq4@published" data-editable="text" data-component-name="paragraph">
      Experts say it‚Äôs important for people to understand their risk of exposure through tap water. Water filters may help somewhat if tap water is contaminated and there are <a href="https://www.cnn.com/2023/03/14/health/epa-pfas-standards-wellness/index.html">moves to regulate</a> some PFAS chemicals in US drinking water.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3h001q336f3q08l98t@published" data-editable="text" data-component-name="paragraph">
      Previously, there was limited information on exactly how much PFAS chemicals are in residential tap water, said the authors of the research, published Wednesday in the journal Environmental International. They added that this <a href="https://www.usgs.gov/news/national-news-release/tap-water-study-detects-pfas-forever-chemicals-across-us#publications" target="_blank">study </a>is&nbsp;the most comprehensive to date that includes both private wells and public water sources.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3i001r336fgzvge61i@published" data-editable="text" data-component-name="paragraph">
      The scientists collected water samples directly from taps at 716 locations ‚Äì 269 from private wells and 447 from public sources ‚Äì between 2016 and 2021. Based on their findings, they estimate that at least one PFAS chemical would be detected in 45% of US drinking water samples.
  </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cljreczcc00263b6flv4z1sai@published" data-name="tapwater pfas map usgs" data-component-name="image" data-observe-resizes="" data-original-ratio="0.7692307692307693" data-original-height="2550" data-original-width="3315" data-url="https://media.cnn.com/api/v1/images/stellar/prod/pfas-tapwater-detection-map-1.jpg?q=h_2550,w_3315,x_0,y_0" data-editable="settings">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/pfas-tapwater-detection-map-1.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/pfas-tapwater-detection-map-1.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(-webkit-min-device-pixel-ratio: 2)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/pfas-tapwater-detection-map-1.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/pfas-tapwater-detection-map-1.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="This USGS map shows the number of PFAS detected in tap water samples from select sites across the nation. The findings are based on a USGS study of samples taken between 2016 and 2021 from private and public supplies at 716 locations. The map does not represent the only locations in the US with PFAS.&nbsp;<strong><em>&nbsp;</em></strong>" onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="2550" width="3315" loading="lazy"></picture>
    </div>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3i001s336fqi4ow9iv@published" data-editable="text" data-component-name="paragraph">
      Most of the contamination came from water sources near urban areas and in areas that generated PFAS, like manufacturing that uses the chemicals in its products or sites where waste was collected.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3i001t336fl0jnjibu@published" data-editable="text" data-component-name="paragraph">
      The highest concentrations of PFAS in drinking water were found in the Great Plains, the Great Lakes, the Eastern Seaboard and Central/Southern California, the study said.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3i001u336f43yt73m8@published" data-editable="text" data-component-name="paragraph">
      Concentrations were similar between private wells and public supplies.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3j001v336fxqdh1rwz@published" data-editable="text" data-component-name="paragraph">
      PFAS can be found in many places, studies show, so toxicologist Dr. Jamie DeWitt is not surprised that it is in so much drinking water.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3j001w336f4fi2k0m1@published" data-editable="text" data-component-name="paragraph">
      ‚ÄúThere‚Äôs been almost no place scientists have looked where they have not found PFAS,‚Äù said DeWitt, <a href="https://pharmacology-toxicology.ecu.edu/faculty/dewittj/" target="_blank">a professor</a> of pharmacology and toxicology in the Department of Pharmacology &amp; Toxicology at East Carolina University who was not involved in the new study.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3j001x336fnv3atzun@published" data-editable="text" data-component-name="paragraph">
      PFAS are found in hundreds of household items. The chemicals are used to make carpets and clothes stain-resistant. They keep food from sticking to pans and food packaging, and they‚Äôre good at keeping grease and water from soaking through. PFAS are in mobile phones, commercial airplanes and low-emission vehicles, in the foods you can buy at the farmers market or the grocery store, and in rainwater and dental floss. They‚Äôre even in the dust that collects in your home.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3j001y336f1ergx3y0@published" data-editable="text" data-component-name="paragraph">
      A 2019&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7879379/" target="_blank">study&nbsp;</a>suggested that PFAS chemicals could be found in 98% of the US population. With that in mind, the new 45% number may sound low, but DeWitt said there could be a couple factors at play. For one, a number of utilities have been making an effort to remove PFAS from the water. Homeowners could also have filters on their systems that make it so PFAS are not as easily detectable.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3j001z336fakllc98p@published" data-editable="text" data-component-name="paragraph">
      ‚ÄúI think that‚Äôs still a pretty high number, considering,‚Äù she said.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3k0020336f6tvp1krz@published" data-editable="text" data-component-name="paragraph">
      DeWitt said that it‚Äôs important for people to know what‚Äôs in their drinking water but that they don‚Äôt necessarily need to be scared.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3k0021336fn0lcv9b4@published" data-editable="text" data-component-name="paragraph">
      ‚ÄúI don‚Äôt think people should be afraid, but they should be aware and armed themselves with knowledge so that they can get information that will help them to make decisions,‚Äù she said.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3k0022336f30kxmwqc@published" data-editable="text" data-component-name="paragraph">
      She recommended looking at your local utility website to get its most recent water report. Utilities will disclose what‚Äôs in the water and what they are doing to reduce contaminants.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq8miyx00153b6fczlolokh@published" data-editable="text" data-component-name="paragraph">
      A carbon filter can help, but it has to be changed regularly. If used too long, the filter can become saturated with chemicals and not work as well. Households can also use reverse osmosis filtering systems, but those can be expensive.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3k0023336fu0zn7myq@published" data-editable="text" data-component-name="paragraph">
      The EPA has <a href="https://www.epa.gov/newsreleases/biden-harris-administration-proposes-first-ever-national-standard-protect-communities" target="_blank">proposed</a> the first national drinking water standards for six PFAS chemicals. The proposed limits set the allowable levels for these chemicals so low that they could not be easily detected.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq8nxh6001g3b6ffje38xs7@published" data-editable="text" data-component-name="paragraph">
      If the standards are finalized, water systems will have to determine whether levels of these PFAS pose a potential risk. They may also need to install treatment or take other actions, the EPA said, and may even need to switch to different water sources.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3k0024336fbmj1txd8@published" data-editable="text" data-component-name="paragraph">
      If PFAS is in 45% of US water systems, the country will have a lot of work to do, said Dr. Graham Peaslee, a professor in the Department of Physics and Astronomy and concurrent professor of chemistry and biochemistry who does PFAS research at the University of Notre Dame.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3k0025336fq8ymcy6j@published" data-editable="text" data-component-name="paragraph">
      ‚ÄúI think that we should try our best to work on how to clean this up. My fear is that this is, global warming aside, this is probably the most expensive environmental problem we‚Äôre ever going to face,‚Äù said Peaslee, who was not involved in the new study. ‚ÄùThere‚Äôs nothing that will magically fix it. It‚Äôs fairly expensive to clean this up. And it‚Äôs a recurring cost, and there‚Äôs no permanent solutions to it for any particular utility. It looks frightening.‚Äù
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq7wh3k0026336fmarxeinq@published" data-editable="text" data-component-name="paragraph">
      But the cleanup will have to be done, he said, because these chemicals <a href="http:// https://www.cnn.com/2022/07/28/health/pfas-testing-guidelines-wellness/index.html" target="_blank">carry real health consequences</a>, and people can‚Äôt exactly avoid drinking water.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/cljq8pmco001r3b6fa8gvlekw@published" data-editable="text" data-component-name="paragraph">
      ‚ÄúIt‚Äôs really insidious, this poison,‚Äù Peaslee said. ‚ÄúWe are going to have to get inventive on how to filter it out for all of our days.‚Äù
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Demystifying Text Data with the Unstructured Python Library (115 pts)]]></title>
            <link>https://saeedesmaili.com/demystifying-text-data-with-the-unstructured-python-library/</link>
            <guid>36616799</guid>
            <pubDate>Thu, 06 Jul 2023 14:47:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://saeedesmaili.com/demystifying-text-data-with-the-unstructured-python-library/">https://saeedesmaili.com/demystifying-text-data-with-the-unstructured-python-library/</a>, See on <a href="https://news.ycombinator.com/item?id=36616799">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article"><header><small>2023-07-05<!-- --> ‚Ä¢ 6 min read</small></header><section itemprop="articleBody"><p>In the world of data, textual data stands out as being particularly complex. It doesn‚Äôt fall into neat rows and columns like numerical data does. As a side project, I‚Äôm in the process of developing my own personal AI assistant. The objective is to use the data within my notes and documents to answer my questions. The important benefit is all data processing will occure locally on my computer, ensuring that no documents are uploaded to the cloud, and my documents will remain private.</p>
<p>To handle such unstructured data, I‚Äôve found the <a href="https://unstructured-io.github.io/unstructured/index.html" target="_blank" rel="nofollow noopener noreferrer"><code>unstructured</code></a> Python library to be extremely useful. It‚Äôs a flexible tool that works with various document formats, including Markdown, , XML, and HTML documents.</p>
<h2>Starting with <code>unstructured</code></h2>
<p>You can easily install the library by:</p>

<h2>Loading and partitioning a document</h2>
<p>The first thing you‚Äôll want to do with your document is split it up into smaller parts or sections. This process, called partitioning, makes it easier to categorize and extract text.</p>
<p>Here‚Äôs how you do it:</p>
<div data-language="python"><pre><code><span>from</span> unstructured<span>.</span>partition<span>.</span>auto <span>import</span> partition

elements <span>=</span> partition<span>(</span>filename<span>=</span><span>"example-docs/note.md"</span><span>)</span></code></pre></div>
<p>example-docs/note.md:</p>
<div data-language="text"><pre><code>## My test title

And here is a sample text.</code></pre></div>
<p>When we partition a document, the output is a list of document&nbsp;<code>Element</code>&nbsp;objects. These element objects represent different components of the source document. The&nbsp;<code>unstructured</code>&nbsp;library supports various element types including <code>Title</code>, <code>NarrativeText</code>, and <code>ListItem</code>. To access the element type you can use the <code>category</code> method:</p>
<div data-language="python"><pre><code><span>for</span> element <span>in</span> elements<span>:</span>
    <span>print</span><span>(</span><span><span>f"</span><span><span>{</span>element<span>.</span>category<span>}</span></span><span>:"</span></span><span>)</span>
    <span>print</span><span>(</span>element<span>)</span>
    <span>print</span><span>(</span><span>"\n"</span><span>)</span></code></pre></div>
<p>Output:</p>
<div data-language="text"><pre><code>Title
My test title


NarrativeText
And here is a sample text.</code></pre></div>
<p>The list of document elements can be converted to a list of dictionaries using the&nbsp;<code>convert_to_dict</code>&nbsp;function:</p>
<div data-language="python"><pre><code><span>from</span> unstructured<span>.</span>staging<span>.</span>base <span>import</span> convert_to_dict

dict_data <span>=</span> convert_to_dict<span>(</span>elements<span>)</span></code></pre></div>
<p>Output:</p>
<div data-language="text"><pre><code>[{'type': 'Title',
  'coordinates': None,
  'coordinate_system': None,
  'layout_width': None,
  'layout_height': None,
  'element_id': 'a3114599252de55bea36c288aa9aa199',
  'metadata': {'filename': 'sample-doc.md',
   'filetype': 'text/markdown',
   'page_number': 1},
  'text': 'My test title'},
 {'type': 'NarrativeText',
  'coordinates': None,
  'coordinate_system': None,
  'layout_width': None,
  'layout_height': None,
  'element_id': '6e78562ede477550604528df644630e8',
  'metadata': {'filename': 'sample-doc.md',
   'filetype': 'text/markdown',
   'page_number': 1},
  'text': 'And here is a sample text.'}]</code></pre></div>
<p>But since I want to store the chunks of texts in a database and do some exploratory analysis with the data, I used <code>convert_to_dataframe</code> function to convert the text elements into pandas dataframe:</p>
<div data-language="python"><pre><code><span>from</span> unstructured<span>.</span>staging<span>.</span>base <span>import</span> convert_to_dataframe

df <span>=</span> convert_to_dataframe<span>(</span>elements<span>)</span></code></pre></div>
<p><span>
      <a href="https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/1d7f7/unstructured-dataframe.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="unstructured to pandas dataframe" title="unstructured to pandas dataframe" src="https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/f058b/unstructured-dataframe.png" srcset="https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/c26ae/unstructured-dataframe.png 158w,
https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/6bdcf/unstructured-dataframe.png 315w,
https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/f058b/unstructured-dataframe.png 630w,
https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/40601/unstructured-dataframe.png 945w,
https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/78612/unstructured-dataframe.png 1260w,
https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/1d7f7/unstructured-dataframe.png 2038w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<h2>Gettng the metadata</h2>
<p>One neat feature of the <code>unstructured</code> library is how it keeps track of various metadata about the elements it extracts from documents. For example, you might want to know which elements come from which page number. You can extract the metadata for a given document element like so:</p>
<div data-language="python"><pre><code>doc_metadata <span>=</span> elements<span>[</span><span>0</span><span>]</span><span>.</span>metadata<span>.</span>to_dict<span>(</span><span>)</span>
<span>print</span><span>(</span>doc_metadata<span>)</span></code></pre></div>
<p>Output:</p>
<div data-language="text"><pre><code>{'filename': 'note.md', 'filetype': 'text/markdown', 'page_number': 1}</code></pre></div>
<p>All document types return the following metadata fields when the information is available from the source file: <code>filename</code>, <code>file_directory</code>, <code>date</code>, <code>filetype</code>, and<code>page_number</code>.</p>
<h2>Preparing for Transformers</h2>
<p>When you‚Äôre ready to feed your text into a transformer model for further processing, you can use the <code>stage_for_transformers</code> function. This function prepares your text elements by splitting them into chunks that fit into the model‚Äôs attention window.</p>
<p>In the following example, I‚Äôm using a library called <code>SentenceTransformers</code> (I‚Äôve written more about using this library in <a href="https://saeedesmaili.com/how-to-use-sentencetransformers-to-generate-text-embeddings-locally/" target="_blank" rel="nofollow noopener noreferrer">my previous blog post</a>):</p>
<div data-language="python"><pre><code><span>from</span> sentence_transformers <span>import</span> SentenceTransformer
<span>from</span> unstructured<span>.</span>staging<span>.</span>huggingface <span>import</span> stage_for_transformers

model <span>=</span> SentenceTransformer<span>(</span><span>"all-MiniLM-L6-v2"</span><span>)</span>
chunked_elements <span>=</span> stage_for_transformers<span>(</span>elements<span>,</span> model<span>.</span>tokenizer<span>)</span></code></pre></div>
<p>And now I can load all the notes in a specific directory, so I can convert them to embedding vectors later:</p>
<div data-language="python"><pre><code>all_elements <span>=</span> <span>[</span><span>]</span>
root_dir <span>=</span> <span>'/corpus'</span>

<span>for</span> directory<span>,</span> subdirectories<span>,</span> files <span>in</span> os<span>.</span>walk<span>(</span>root_dir<span>)</span><span>:</span>
    <span>for</span> <span>file</span> <span>in</span> files<span>:</span>
        full_path <span>=</span> os<span>.</span>path<span>.</span>join<span>(</span>directory<span>,</span> <span>file</span><span>)</span>
        all_elements <span>+=</span> partition<span>(</span>filename<span>=</span>full_path<span>)</span></code></pre></div>
<h2>Limitations of <code>unstructured</code></h2>
<p>This library has some issues and limitations as well.</p>
<ul>
<li>When loading and parsing <code>docx</code> files, it can‚Äôt properly recognize bullet points as <code>ListItem</code> and most of the times labels them as <code>NarrativeText</code> or <code>Title</code>. This makes the <code>Title</code> recognition unreliable as well, since when you look into the output, you can‚Äôt tell for sure if each <code>Title</code> is actually a title or a list item labeled incorrectly as a <code>Title</code>. (<a href="https://github.com/Unstructured-IO/unstructured/issues/768" target="_blank" rel="nofollow noopener noreferrer">issue on github</a>)</li>
<li>When working with large documents, there isn‚Äôt any way to know what are the parents of each paragraph or title. This could be a very useful feature to have, specially when feeding back the data to an LLM. (<a href="https://github.com/Unstructured-IO/unstructured/issues/889" target="_blank" rel="nofollow noopener noreferrer">issue on github</a>)</li>
</ul>
<h2>Alternatives</h2>
<p>After playing with <code>unstructured</code> I tried to see if there are better alternatives for reading documents with python. Although I will need to load documents with various formats, I narrowed down my search to first find alternatives for reading <code>docx</code> files first (as this it the format you get when downloading a large folder of documents from Google Drive). Here are what I found:</p>
<h3><code>python-docx</code></h3>
<ul>
<li>It seems powerful, but it‚Äôs complicated to work with.</li>
<li>I tried loading and parsing a few <code>docx</code> files. The biggest issue I experienced was with loading any text that includes hyperlinks. For some unknown reason, the texts of hyperlinks are returned empty in the final output. This makes it unusable for my purpose, since the link texts provide valuable information in the text.</li>
<li>Pro: It is able to provide the heading level info for titles (as <code>Heading 1</code>, <code>Heading 2</code>, etc).</li>
</ul>
<h3><code>docx2txt</code></h3>
<ul>
<li>It uses <code>python-docx</code> under the hood.</li>
<li>Only returns a giant full text string of the loaded document. This would require me to split my documents to meaningful chunks, which is not a trivial task to do.</li>
<li>Pro: It doesn‚Äôt have any problems with hyperlinks and the output text is readable and useful.</li>
<li>Pro: It is also very easy to use.</li>
</ul>
<h3><code>simplify_docx</code></h3>
<ul>
<li>It works on top of <code>python-docx</code>.</li>
<li>This library basically converts the complicated output of <code>python-docx</code> to a more easy to use json output.</li>
<li>It also have the same issue with hyperlinks and returns empty texts when there is a link in the paragraph.</li>
</ul>
<p>So I will continue using <code>unstructured</code> for now. It‚Äôs worth mentioning that, yes, this could be accomplished more easily using <a href="https://python.langchain.com/docs/get_started/introduction.html" target="_blank" rel="nofollow noopener noreferrer">LangChain</a> or other similar tools. However, part of my motivation in building this personal AI assistant is the learning journey. By using <code>unstructured</code> to load documents and other similar tools for embeddings and so on, I‚Äôm gaining a deeper understanding of the underlying processes, rather than using a one-stop-shop solution like <code>LangChain</code>.</p>
<p>I‚Äôll be sharing more about the progress I‚Äôm making in building this personal AI assistant in future posts, so stay tuned.</p></section><hr></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tuesday set an unofficial record for the hottest day on Earth (128 pts)]]></title>
            <link>https://apnews.com/article/global-record-breaking-heat-july-27069b5380117534d78f1f40a6edc7a0</link>
            <guid>36616491</guid>
            <pubDate>Thu, 06 Jul 2023 14:34:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/global-record-breaking-heat-july-27069b5380117534d78f1f40a6edc7a0">https://apnews.com/article/global-record-breaking-heat-july-27069b5380117534d78f1f40a6edc7a0</a>, See on <a href="https://news.ycombinator.com/item?id=36616491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>The planet‚Äôs temperature spiked on Tuesday to its hottest day in decades and likely centuries, and Wednesday could become the third straight day Earth unofficially marks a record-breaking high. It‚Äôs the latest in a series of <span><a href="https://apnews.com/hub/climate-change" target="_blank" rel="noopener">climate-change</a></span> extremes that alarm but don‚Äôt surprise scientists. </p><p>The globe‚Äôs average temperature reached 62.9 degrees Fahrenheit (17.18 degrees Celsius) on Tuesday, according to the University of Maine‚Äôs <span><a href="https://climatereanalyzer.org/clim/t2_daily/" target="_blank" rel="noopener">Climate Reanalyzer</a></span>, a common tool based on satellite data, observations, and computer simulations and used by climate scientists for a glimpse of the world‚Äôs condition. On Monday, the average temperature was 62.6 degrees Fahrenheit (17.01 degrees Celsius), setting a record that lasted only 24 hours.</p>
    

<p>For scientists, it‚Äôs a sweaty case of I-told-you-so.</p><p>‚ÄúA record like this is another piece of evidence for the now massively supported proposition that <span><a href="https://apnews.com/article/un-climate-change-report-ipcc-guterres-science-30d8451c0f3fb7b8a857e3ed4fd01172" target="_blank" rel="noopener">global warming</a></span> is pushing us into a hotter future,‚Äù said Stanford University climate scientist Chris Field, who was not part of the calculations.</p><p>On Wednesday, 38 million Americans were under some kind of heat alert, said National Oceanic and Atmospheric Administration chief scientist Sarah Kapnick. She said the global heat is from a <span><a href="https://apnews.com/article/el-nino-climate-global-warming-world-weather-6eb70f36ce098d931cfcdb82590c4066" target="_blank" rel="noopener">natural El Nino warming of the Pacific</a></span> that heats up the planet as it changes worldwide weather on top of human-caused climate change from the burning of coal, oil and gas.</p>





<p>Even normally cooler communities are feeling the heat. In North Grenville, Ontario, the city turned ice-hockey rinks into cooling centers as temperatures Wednesday hit 90 degrees Fahrenheit (32 degrees Celsius), with humidity making it making it feel like 100.4 degrees (38 degrees Celsius).</p><p>‚ÄúI feel like we live in a tropical country right now,‚Äù city spokeswoman Jill Sturdy said. ‚ÄúIt just kind of hits you. The air is so thick.‚Äù</p>
    

<h2>THE RECORD HIGHS ARE UNOFFICIAL BUT SIGNIFICANT</h2><div data-align-center="">
                    <figure>
    
    <a id="image-180000" name="image-180000"></a>


    
        <picture data-crop="imgEn-medium-3x2">
    
        <source media="(min-width: 768px)" type="image/webp" width="800" height="533" srcset="https://dims.apnews.com/dims4/default/a7ecb82/2147483647/strip/true/crop/6000x3998+0+1/resize/800x533!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 1x,https://dims.apnews.com/dims4/default/0d8d2d6/2147483647/strip/true/crop/6000x3998+0+1/resize/1600x1066!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 2x" loading="lazy">

    

    
        <source media="(min-width: 768px)" width="800" height="533" srcset="https://dims.apnews.com/dims4/default/b6e0129/2147483647/strip/true/crop/6000x3998+0+1/resize/800x533!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 1x,https://dims.apnews.com/dims4/default/0e0d816/2147483647/strip/true/crop/6000x3998+0+1/resize/1600x1066!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 2x" loading="lazy">

    

    
        <source media="(min-width: 600px)" type="image/webp" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/d123942/2147483647/strip/true/crop/6000x3997+0+1/resize/767x511!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 1x,https://dims.apnews.com/dims4/default/d444132/2147483647/strip/true/crop/6000x3997+0+1/resize/1534x1022!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 2x" loading="lazy">

    

    
        <source media="(min-width: 600px)" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/3d8afc4/2147483647/strip/true/crop/6000x3997+0+1/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 1x,https://dims.apnews.com/dims4/default/f091597/2147483647/strip/true/crop/6000x3997+0+1/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 2x" loading="lazy">

    

    
        <source type="image/webp" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/efe2f89/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 1x,https://dims.apnews.com/dims4/default/a039baf/2147483647/strip/true/crop/6000x3997+0+2/resize/1198x798!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 2x" loading="lazy">

    

    
        <source width="599" height="399" srcset="https://dims.apnews.com/dims4/default/1968d6f/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 1x,https://dims.apnews.com/dims4/default/a3a994b/2147483647/strip/true/crop/6000x3997+0+2/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 2x" loading="lazy">

    

    <img alt="Residents carry umbrellas to shield from the sun as they take rest on a bench on a hot day in Beijing, Monday, July 3, 2023. Heavy flooding has displaced thousands of people around China as the capital had a brief respite from sweltering heat. (AP Photo/Andy Wong)" srcset="https://dims.apnews.com/dims4/default/1968d6f/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 1x,https://dims.apnews.com/dims4/default/a3a994b/2147483647/strip/true/crop/6000x3997+0+2/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724 2x" width="599" height="399" src="https://dims.apnews.com/dims4/default/1968d6f/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F1b%2Fa0%2F851960366634c805a5ef5ab5cfaa%2F08c6222674574ed5946053ffe0daa724" loading="lazy">
</picture>

    

    
        <div><figcaption><p>Residents carry umbrellas to shield from the sun as they take rest on a bench on a hot day in Beijing, Monday, July 3, 2023. (AP Photo/Andy Wong)</p></figcaption></div>
    
</figure>

                </div><p>University of Maine climate scientist Sean Birkle, creator of the Climate Reanalyzer, said the daily figures are unofficial but a useful snapshot of what‚Äôs happening in a warming world. Think of it as the temperature of someone who‚Äôs ill, he said: It tells you something might be wrong, but you need longer-term records to work like a doctor‚Äôs exam for a complete picture. </p><p>While the figures are not an official government record, ‚Äúthis is showing us an indication of where we are right now,‚Äù said National Oceanic and Atmospheric Administration chief scientist Sarah Kapnick. And NOAA indicated it will take the figures into consideration for its official record calculations.</p><p>Even though the dataset used for the unofficial record goes back only to 1979, Kapnick said that given other data, the world is likely seeing the hottest day in ‚Äúseveral hundred years that we‚Äôve experienced.‚Äù</p><p>Scientists generally use much longer measurements ‚Äî months, years, decades ‚Äî to track the Earth‚Äôs warming. But the daily highs are an indication that climate change is reaching uncharted territory.</p>
    

<h2>JUST HOW HOT IS IT?</h2><p>With many places seeing temperatures near 100 degrees Fahrenheit (37.8 degrees Celsius), the new average temperatures might not seem <span><a href="https://apnews.com/article/us-heat-wave-deaths-9205d9c93882ff84906c5846ef1a6d6d" target="_blank" rel="noopener">very hot</a></span>. But Tuesday‚Äôs global high was nearly 1.8 degrees Fahrenheit (a full degree Celsius) higher than the 1979-2000 average, which already tops the 20th- and 19th-century averages.</p><p>High-temperature records were surpassed this week in Quebec and Peru. Beijing reported nine straight days last week when the temperature exceeded 95 degrees Fahrenheit (35 degrees Celsius). Cities across the U.S. from Medford, Oregon, to Tampa, Florida, have been hovering at all-time highs, said Zack Taylor, a meteorologist with the National Weather Service.</p><p>Alan Harris, director of emergency management for Seminole County, Florida, said that they‚Äôve already exceeded last year in the number of days they‚Äôve had their extreme weather plan activated, a measure initiated when the heat index will be 108 degrees Fahrenheit (42.22 degrees Celsius) or greater.</p><p>‚ÄúIt‚Äôs just been kind of brutally hot for the last week, and now it looks like potentially for two weeks,‚Äù Harris said.</p>
    

<p>In the U.S., heat advisories include portions of western Oregon, inland far northern California, central New Mexico, Texas, Florida and the coastal Carolinas, according to <span><a href="https://www.wpc.ncep.noaa.gov/discussions/hpcdiscussions.php?disc=pmdspd" target="_blank" rel="noopener">the National Weather Service Weather Prediction Center.</a></span> Excessive heat warnings are continuing across southern Arizona and California.</p><h2>SOME POPULATIONS ARE AT RISK, BUT MANY ARE STILL OUTDOORS</h2><p>Higher temperatures translate into brutal conditions for people all over the world. When <span><a href="https://apnews.com/article/heat-wave-summer-weather-stay-cool-tips-026c835fe84b7113736dba0265379130" target="_blank" rel="noopener">the heat spikes</a></span>, humans suffer health effects ‚Äî especially young and elderly people, who are vulnerable to heat even under normal conditions.</p>
    

<div data-align-fullwidth="">
                
                <figure>
    

    
        <picture data-crop="twoup-3x2">
    
        <source media="(max-width: 599px)" type="image/webp" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/d0236fa/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 1x,https://dims.apnews.com/dims4/default/ae56953/2147483647/strip/true/crop/6000x3997+0+2/resize/1198x798!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 2x" loading="lazy">

    

    
        <source media="(max-width: 599px)" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/4a4f0e8/2147483647/strip/true/crop/6000x3997+0+2/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 1x,https://dims.apnews.com/dims4/default/735c944/2147483647/strip/true/crop/6000x3997+0+2/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 2x" loading="lazy">

    

    
        <source type="image/webp" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/7334027/2147483647/strip/true/crop/6000x3997+0+1/resize/767x511!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 1x,https://dims.apnews.com/dims4/default/409b5c2/2147483647/strip/true/crop/6000x3997+0+1/resize/1534x1022!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 2x" loading="lazy">

    

    
        <source width="767" height="511" srcset="https://dims.apnews.com/dims4/default/383431f/2147483647/strip/true/crop/6000x3997+0+1/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 1x,https://dims.apnews.com/dims4/default/51c8b12/2147483647/strip/true/crop/6000x3997+0+1/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 2x" loading="lazy">

    

    <img alt="A woman uses a fan to cool a child as they sit on a bench at Qianmen pedestrian shopping street on a hot day in Beijing, Thursday, June 29, 2023. The entire planet sweltered for the two unofficial hottest days in human recordkeeping Monday and Tuesday, according to University of Maine scientists at the Climate Reanalyzer project. The unofficial heat records come after months of unusually hot conditions due to climate change and a strong El Nino event. (AP Photo/Andy Wong)" srcset="https://dims.apnews.com/dims4/default/383431f/2147483647/strip/true/crop/6000x3997+0+1/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 1x,https://dims.apnews.com/dims4/default/51c8b12/2147483647/strip/true/crop/6000x3997+0+1/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72 2x" width="767" height="511" src="https://dims.apnews.com/dims4/default/383431f/2147483647/strip/true/crop/6000x3997+0+1/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe4%2F03%2F97695a94ec8adf5b212ca5fde37c%2F299c54bcf6f940e48fbcb482e7b8de72" loading="lazy">
</picture>

    

    
        <div><figcaption>A woman uses a fan to cool a child as they sit on a bench at Qianmen pedestrian shopping street on a hot day in Beijing, Thursday, June 29, 2023. The entire planet sweltered for the two unofficial hottest days in human recordkeeping Monday and Tuesday, according to University of Maine scientists at the Climate Reanalyzer project. The unofficial heat records come after months of unusually hot conditions due to climate change and a strong El Nino event. (AP Photo/Andy Wong) ‚Äì</figcaption><p>Andy Wong/AP</p></div>
    
</figure>
<figure>
    

    
        <picture data-crop="twoup-3x2">
    
        <source media="(max-width: 599px)" type="image/webp" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/9ed2076/2147483647/strip/true/crop/8113x5404+0+105/resize/599x399!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 1x,https://dims.apnews.com/dims4/default/a665632/2147483647/strip/true/crop/8113x5404+0+105/resize/1198x798!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 2x" loading="lazy">

    

    
        <source media="(max-width: 599px)" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/5c75cd1/2147483647/strip/true/crop/8113x5404+0+105/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 1x,https://dims.apnews.com/dims4/default/84b6cfa/2147483647/strip/true/crop/8113x5404+0+105/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 2x" loading="lazy">

    

    
        <source type="image/webp" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/df013f6/2147483647/strip/true/crop/8113x5405+0+105/resize/767x511!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 1x,https://dims.apnews.com/dims4/default/b28a099/2147483647/strip/true/crop/8113x5405+0+105/resize/1534x1022!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 2x" loading="lazy">

    

    
        <source width="767" height="511" srcset="https://dims.apnews.com/dims4/default/727c984/2147483647/strip/true/crop/8113x5405+0+105/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 1x,https://dims.apnews.com/dims4/default/81ceeed/2147483647/strip/true/crop/8113x5405+0+105/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 2x" loading="lazy">

    

    <img alt="A Kashmiri man cools off at a stream on a hot summer day on the outskirts of Srinagar, Indian controlled Kashmir, Tuesday, July 4, 2023. The entire planet sweltered for the two unofficial hottest days in human recordkeeping Monday and Tuesday, according to University of Maine scientists at the Climate Reanalyzer project. The unofficial heat records come after months of unusually hot conditions due to climate change and a strong El Nino event. (AP Photo/Mukhtar Khan)" srcset="https://dims.apnews.com/dims4/default/727c984/2147483647/strip/true/crop/8113x5405+0+105/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 1x,https://dims.apnews.com/dims4/default/81ceeed/2147483647/strip/true/crop/8113x5405+0+105/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197 2x" width="767" height="511" src="https://dims.apnews.com/dims4/default/727c984/2147483647/strip/true/crop/8113x5405+0+105/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fdb%2Fc4%2F61291e82eff194a2be35a54622f5%2F942cabca52004af9a0009ba769784197" loading="lazy">
</picture>

    

    
        <div><figcaption>A Kashmiri man cools off at a stream on a hot summer day on the outskirts of Srinagar, Indian controlled Kashmir, Tuesday, July 4, 2023. The entire planet sweltered for the two unofficial hottest days in human recordkeeping Monday and Tuesday, according to University of Maine scientists at the Climate Reanalyzer project. The unofficial heat records come after months of unusually hot conditions due to climate change and a strong El Nino event. (AP Photo/Mukhtar Khan) ‚Äì</figcaption><p>Mukhtar Khan/AP</p></div>
    
</figure>

                
            </div><p>‚ÄúPeople aren‚Äôt used to that. Their bodies aren‚Äôt used to that,‚Äù said Erinanne Saffell, Arizona‚Äôs state climatologist and an expert in extreme weather and climate events. ‚ÄúThat‚Äôs important to understand who might be at risk, making sure people are hydrated, they‚Äôre staying cool, and they‚Äôre not exerting themselves outside, and taking care of those folks around you who might be at risk.‚Äù </p><p>Overall, the heat means something a little different to everyone. </p><p>In West Texas, it‚Äôs cool wraps and Gatorade for construction workers, said Joe Staley, a job site superintendent for a company that builds wastewater treatment plants. In Portland, it‚Äôs extra water on backyard vegetable gardens, said Martha Alvarado. In Minnesota, it‚Äôs a difficult workout on the family vineyard thanks to extra humidity for Joe Roisen. </p><p>In Dallas, the heat also means a sense of camaraderie for musician Sam Cormier, who often plays outdoors. Apartment dwellers with their windows open step out to bring him a drink. People are still walking around outside, even with the weather, and he plays with just his guitar, which is lighter than other equipment. He‚Äôd rather be outside sweating, he said, than inside on a computer. </p><h2>HOW WE GOT HERE, AND WHERE WE‚ÄôRE GOING</h2><p>NOAA‚Äôs Kapnick said the global heat is from a <span><a href="https://apnews.com/article/el-nino-climate-global-warming-world-weather-6eb70f36ce098d931cfcdb82590c4066" target="_blank" rel="noopener">natural El Nino warming of the Pacific</a></span> that heats up the globe as it changes worldwide weather on top of human-caused climate change from the burning of coal, oil and gas.</p><p>‚ÄúNot all records are meant to be broken. In almost every corner of our planet, people are facing the brunt of unprecedented heat waves,‚Äù said United Nations Environment Programme Director Inger Andersen. ‚ÄúWe ignore science at our own peril. ... It is the poorest and most vulnerable that continue to suffer from our inaction.‚Äù</p><p>The highs come after months of ‚Äútruly unreal meteorology and climate stats for the year,‚Äù such as <span><a href="https://apnews.com/article/climate-change-hot-oceans-el-nino-la-nina-ec00bc89848d18dec9bf4db4444c999e" target="_blank" rel="noopener">off-the-chart record warmth</a></span> in the North Atlantic, <span><a href="https://nsidc.org/arcticseaicenews/" target="_blank" rel="noopener">record low sea ice in Antarctica</a></span> and a <span><a href="https://apnews.com/article/el-nino-climate-global-warming-world-weather-6eb70f36ce098d931cfcdb82590c4066" target="_blank" rel="noopener">rapidly strengthening El Nino</a></span>, said University of Oklahoma meteorology professor Jason Furtado. </p><div data-align-center="">
                    <figure>
    
    <a id="image-b40000" name="image-b40000"></a>


    
        <picture data-crop="imgEn-medium-3x2">
    
        <source media="(min-width: 768px)" type="image/webp" width="800" height="533" srcset="https://dims.apnews.com/dims4/default/b41b349/2147483647/strip/true/crop/5000x3331+0+1/resize/800x533!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 1x,https://dims.apnews.com/dims4/default/a2e915f/2147483647/strip/true/crop/5000x3331+0+1/resize/1600x1066!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 2x" loading="lazy">

    

    
        <source media="(min-width: 768px)" width="800" height="533" srcset="https://dims.apnews.com/dims4/default/e78e544/2147483647/strip/true/crop/5000x3331+0+1/resize/800x533!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 1x,https://dims.apnews.com/dims4/default/fbbcf54/2147483647/strip/true/crop/5000x3331+0+1/resize/1600x1066!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 2x" loading="lazy">

    

    
        <source media="(min-width: 600px)" type="image/webp" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/06c179d/2147483647/strip/true/crop/5000x3331+0+1/resize/767x511!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 1x,https://dims.apnews.com/dims4/default/aed591a/2147483647/strip/true/crop/5000x3331+0+1/resize/1534x1022!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 2x" loading="lazy">

    

    
        <source media="(min-width: 600px)" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/83f9781/2147483647/strip/true/crop/5000x3331+0+1/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 1x,https://dims.apnews.com/dims4/default/31b4a15/2147483647/strip/true/crop/5000x3331+0+1/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 2x" loading="lazy">

    

    
        <source type="image/webp" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/94ca32e/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 1x,https://dims.apnews.com/dims4/default/bd57327/2147483647/strip/true/crop/5000x3331+0+1/resize/1198x798!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 2x" loading="lazy">

    

    
        <source width="599" height="399" srcset="https://dims.apnews.com/dims4/default/4d47b14/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 1x,https://dims.apnews.com/dims4/default/66ced2d/2147483647/strip/true/crop/5000x3331+0+1/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 2x" loading="lazy">

    

    <img alt="FILE - A woman uses a sweater to shield from the sun as she walls on a street on a hot day in Beijing, Monday, July 3, 2023. Employers in Beijing were ordered Thursday, July 6, by the government to stop outdoor work after scorching summer heat in the Chinese capital was forecast to reach 40 degrees centigrade (104 Fahrenheit). (AP Photo/Andy Wong, File)" srcset="https://dims.apnews.com/dims4/default/4d47b14/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 1x,https://dims.apnews.com/dims4/default/66ced2d/2147483647/strip/true/crop/5000x3331+0+1/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f 2x" width="599" height="399" src="https://dims.apnews.com/dims4/default/4d47b14/2147483647/strip/true/crop/5000x3331+0+1/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Feb%2F44%2F6402e2db066cc00f435f4812d909%2F43d3a287af984d26a2afbfb7ae44494f" loading="lazy">
</picture>

    

    
        <div><figcaption><p>A woman uses a sweater to shield from the sun as she walls on a street on a hot day in Beijing, Monday, July 3, 2023. (AP Photo/Andy Wong)</p></figcaption></div>
    
</figure>

                </div><p>Wednesday may bring another unofficial record, with the Climate Reanalyzer again forecasting record or near-record heat. Antarctica‚Äôs average forecast for Wednesday is a whopping 4.5 degrees Celsius (8.1 degrees Fahrenheit) warmer than the 1979-2000 average. </p><p>Because humanity hasn‚Äôt stopped pumping heat-trapping gases into the air, future generations will look back at the summer of 2023 as ‚Äúone of the coolest of the rest of your life,‚Äù said Texas A&amp;M climate scientist Andrew Dessler.</p><h2>___</h2><p>Borenstein reported from Washington, and Walling from Chicago. Follow them on Twitter at <span><a href="https://twitter.com/borenbears" target="_blank" rel="noopener">@borenbears</a></span> and <span><a href="https://twitter.com/MelinaWalling" target="_blank" rel="noopener">@MelinaWalling</a></span>.</p><h2>___</h2><p>Follow AP‚Äôs climate and environment coverage at <span><a href="https://apnews.com/hub/climate-and-environment" target="_blank" rel="noopener">https://apnews.com/hub/climate-and-environment</a></span>.</p><h2>___</h2><p>Associated Press climate and environmental coverage receives support from several private foundations. See more about AP‚Äôs climate initiative <span><a href="https://www.ap.org/press-releases/2022/ap-announces-sweeping-climate-journalism-initiative" target="_blank" rel="noopener">here</a></span>. The AP is solely responsible for all content.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lego building instructions (341 pts)]]></title>
            <link>https://archive.org/details/lego-set-instructions</link>
            <guid>36616398</guid>
            <pubDate>Thu, 06 Jul 2023 14:29:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archive.org/details/lego-set-instructions">https://archive.org/details/lego-set-instructions</a>, See on <a href="https://news.ycombinator.com/item?id=36616398">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>        
        

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 11020</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 11014</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 7939</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 43205</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 31034</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10276</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 4204</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 75810</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 75252</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 8258</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21046</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 31205</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 4842</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60305</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60262</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60372</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 31083</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60022</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10290</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 4993</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60047</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 6753</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 6754</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10294</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 40632</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10273</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60325</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21116</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21308</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21332</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 4954</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 41704</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 7499</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 70425</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10265</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 31124</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60003</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10775</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 31132</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 43187</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21114</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60336</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10269</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 9558</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 70723</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 4430</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60254</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 42031</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21327</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21336</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 31073</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 31114</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 60246</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 7288</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10233</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 11717</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 40548</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 41232</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 42131</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 6209</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21120</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 75219</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 76091</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10252</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21306</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 2263</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10695</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 21161</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 42120</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 70756</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 7586</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 76069</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 8696</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 10305</span><br>                                                </p>
            
    </div>

    

    <!--/.item-ia-->


    <div>
      
              <p><span>Building instructions and extras for LEGO Set 11011</span><br>                                                </p>
            
    </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[France passes bill to allow police remotely activate phone camera, microphone (448 pts)]]></title>
            <link>https://gazettengr.com/france-passes-bill-to-allow-police-remotely-activate-phone-camera-microphone-spy-on-people/</link>
            <guid>36616037</guid>
            <pubDate>Thu, 06 Jul 2023 14:09:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gazettengr.com/france-passes-bill-to-allow-police-remotely-activate-phone-camera-microphone-spy-on-people/">https://gazettengr.com/france-passes-bill-to-allow-police-remotely-activate-phone-camera-microphone-spy-on-people/</a>, See on <a href="https://news.ycombinator.com/item?id=36616037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
<p>A bill that would allow police in France to spy on suspects by remotely activating cameras, microphone including GPS of their phones has been passed.&nbsp;</p>



<p>The bill allows the geolocation of crime suspects, covering other devices like laptops, cars and connected devices, just as it could be remotely activated to record sound and images of people suspected of terror offences, as well as delinquency and organised crime.</p>



<p>Although, the spying provision, which is part of a wider ‚Äújustice reform bill‚Äù, has been attacked by the left and rights defenders as an authoritarian snoopers‚Äô charter.&nbsp;</p>



<p>The provisions ‚Äúraise serious concerns over infringements of fundamental liberties,‚Äù stated a French advocacy group promoting digital rights and freedoms, La Quadrature du Net.</p>



<p>The group cited the ‚Äúright to security, right to a private life and to private correspondence‚Äù and ‚Äúthe right to come and go freely,‚Äù specifically called the proposal a part of a ‚Äúslide into heavy-handed security.‚Äù</p>



<p>But lawmakers agreed to the bill late Wednesday as Justice Minister Eric Dupond-Moretti insisted the bill would affect only ‚Äúdozens of cases a year.‚Äù</p>



<p>During the debate on Wednesday, the members of parliament in the camp of President Emmanuel Macron inserted an amendment limiting the use of remote spying to ‚Äúwhen justified by the nature and seriousness of the crime‚Äù and ‚Äúfor a strictly proportional duration.‚Äù They noted that a judge must approve any use of the provision, while the total duration of the surveillance cannot exceed six months.</p>



<p>They said sensitive professions, including doctors, journalists, lawyers, judges and MPs, would not be legitimate targets.</p>



<p>Last month, the Senate gave the green light to the provision of the justice bill, which would allow law enforcement to secretly activate cameras and microphones on a suspect‚Äôs devices.&nbsp;</p>



<p>Since 2015, when terrorist attacks rocked France, the country has increased its surveillance powers, and the ‚ÄúKeeper of the Seal‚Äù bill has been likened to the infamous US Patriot Act.&nbsp;</p>
                            </div><p> We have recently deactivated our website's comment provider in favour of other channels of distribution and commentary. We encourage you to join the conversation on our stories via our Facebook, Twitter and other social media pages.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fastmail 30 June outage post-mortem (149 pts)]]></title>
            <link>https://www.fastmail.com/blog/partial-outage-on-30-june-2023/</link>
            <guid>36616023</guid>
            <pubDate>Thu, 06 Jul 2023 14:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fastmail.com/blog/partial-outage-on-30-june-2023/">https://www.fastmail.com/blog/partial-outage-on-30-june-2023/</a>, See on <a href="https://news.ycombinator.com/item?id=36616023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>A partial network outage occurred at Fastmail on June 30th, 2023. Most did not notice, but it was severe for the directly affected 3-5% of our customers.</p>
<p>Whether or not you noticed, we‚Äôre truly sorry that this happened, and have a plan to avoid it happening again.</p>
<p>This article will get very technical about how our network works! We hope you find it useful.</p>
<h2>A short summary</h2>
<p>For about 19 hours, Fastmail and a portion of the internet were completely unable to communicate with each other, including a fraction of our customers, and also some email servers. This led to delayed email, some mail fetches being disabled, and if you were using one of those networks, Fastmail being entirely offline for you!</p>
<p>We had a single path for traffic out to the internet, and hence were unable to fix this ourselves. As a <a href="https://www.reddit.com/r/fastmail/comments/14mrjk1/comment/jq68lb9/">Reddit comment</a> said, this wasn‚Äôt within our control, but it is our responsibility.</p>
<p>It is not acceptable to us that a subset of our customers were unable to access their email for so long, and also that we were unable to send email to a section of the internet.</p>
<p>To prevent this from happening again, we plan to connect directly into an additional transit provider, so we can select between multiple pathways for outbound data. Having this control will allow us to route around individual provider network issues, and be back online for everybody faster.</p>
<h2>What, when, where, who</h2>
<ul>
<li>What: access to all Fastmail services, including mail delivery, was broken ‚Äì in particular, the ability for network packets leaving our network to reach their destination.</li>
<li>When: starting approximately 03:00 UTC on June 30th and ending about 22:00 UTC on the same day, for a total outage time of 19 hours. We‚Äôre quite certain that the root cause of this outage is now fixed.</li>
<li>Where: a fraction of the internet.</li>
<li>Who: We estimate 3-5% of our customers, based on comparing server metrics to similar days.</li>
</ul>
<p>We first became aware of the issue when our customers informed us via support tickets and social media. While we have monitors from multiple locations around the world, neither those monitors nor any of our staff were on networks that had issues. We could tell it was quite isolated, because some reported being able to access from phone but not home network, or vice versa. Also VPNs allowed some users to find a functioning pathway to our servers.</p>
<p>Since we couldn‚Äôt see the failing links ourselves, we relied on helpful customers on those networks who provided us with traceroutes ‚Äî which then gave us some addresses to trace back to from our end and see where the traffic was dropping. We very much appreciate everybody who assisted us with datapoints!</p>
<h2>Some history</h2>
<p>A few years ago, we moved from New York Internet‚Äôs Manhattan datacenter to their Bridgewater, New Jersey location. A bit later, this datacenter was sold to 365 Datacenters. We were using the IP address range <tt>66.111.4.0/24</tt> ‚Äî a range which still belongs to the original NYI.</p>
<p>Thankfully, NYI were willing to lease us those addresses, because <a href="https://postmarkapp.com/blog/how-to-check-your-ip-reputation">IP range reputation</a> is really important in the email world, and those things are hardcoded all over the place ‚Äî but it has caused us complications due to more complex routing. Over the past year, we‚Äôve been migrating to a new IP range. We‚Äôve been running the two networks concurrently as we build up the trust reputation for the new addresses.</p>
<p>In past years, we have had <a href="https://www.fastmail.com/blog/fastmail-fights-off-ransom-cyberattack/">DDoS attacks against our service</a>, and our previous DDoS protection services couldn‚Äôt keep us up through the worst of those attacks, so we‚Äôre now bringing all our incoming traffic via a service called MagicTransit from Cloudflare. It routes everything at the IP layer, so all the traffic is encrypted just like it was going over any other network ‚Äî but Cloudflare has the capacity to soak up a lot of attack, and they‚Äôre really quick and proactive.</p>
<p>As part of the MagicTransit setup, we also added a second way into our network. Cloudflare can either route to us over our ‚ÄúPrivate Public‚Äù network IP on the 365 managed network, or via Megaport, a service which provides private virtual cables. We have a fiber link to Megaport, so we can route traffic from Cloudflare into our network without using the uplink to 365‚Äôs network. Traffic normally comes in that way, it‚Äôs a little faster, so we give it priority.</p>
<p><img decoding="async" loading="lazy" src="https://www.fastmail.com/wp-content/uploads/2023/07/5aCTGXiL.png" alt="active cloudflare configuration" width="1001" height="288" srcset="https://www.fastmail.com/wp-content/uploads/2023/07/5aCTGXiL.png 1001w, https://www.fastmail.com/wp-content/uploads/2023/07/5aCTGXiL-300x86.png 300w, https://www.fastmail.com/wp-content/uploads/2023/07/5aCTGXiL-768x221.png 768w" sizes="(max-width: 1001px) 100vw, 1001px"></p>
<p>Megaport was up during the entire incident, so packets were getting in to our network reliably. It was outbound packets that weren‚Äôt all getting through.</p>
<h2>Our current network structure</h2>
<p><img decoding="async" loading="lazy" src="https://www.fastmail.com/wp-content/uploads/2023/07/temp.png" alt="diagram of our network layout" width="754" height="781" srcset="https://www.fastmail.com/wp-content/uploads/2023/07/temp.png 754w, https://www.fastmail.com/wp-content/uploads/2023/07/temp-290x300.png 290w" sizes="(max-width: 754px) 100vw, 754px"></p>
<h2>The Future</h2>
<p>Work is now underway to select a provider for a second transit connection directly into our servers ‚Äî either via Megaport, or from a service with their own physical presence in 365‚Äôs New Jersey datacenter. Once we have this, we will be able to directly control our outbound traffic flow and route around any network with issues.</p>
<p>Thanks for reading, and as always thank you for using Fastmail (both those who were unaffected, and those of you who have kept using Fastmail after that very bad day!)</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A gigantic landslide shows the limit to how high mountains can grow (103 pts)]]></title>
            <link>https://www.economist.com/science-and-technology/2023/07/06/a-gigantic-landslide-shows-the-limit-to-how-high-mountains-can-grow</link>
            <guid>36615965</guid>
            <pubDate>Thu, 06 Jul 2023 14:05:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/science-and-technology/2023/07/06/a-gigantic-landslide-shows-the-limit-to-how-high-mountains-can-grow">https://www.economist.com/science-and-technology/2023/07/06/a-gigantic-landslide-shows-the-limit-to-how-high-mountains-can-grow</a>, See on <a href="https://news.ycombinator.com/item?id=36615965">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><h2>Enough rock fell off a Himalayan peak to bury Paris to the height of the Eiffel Tower</h2></section><div><div data-body-id="cp1"><p data-caps="initial"><span data-caps="initial">I</span><small>n geology, unlike</small> business, nothing is too big to fail. Mountains offer the most spectacular example. Pushed up by the crumpling of Earth‚Äôs crust following the collision of tectonic plates, they could in theory keep rising almost indefinitely. In practice, they do not. A suite of geological processes‚Äîincluding the grinding of glaciers, the gentle impact of rain, and forcible cracking by freezing and thawing of water‚Äîerode them down to size.</p><div><figure><div><figcaption>Listen to this story.</figcaption> <p><span>Enjoy more audio and podcasts on<!-- --> <a id="audio-ios-cta" href="https://economist-app.onelink.me/d2eC/bed1b25" target="_blank" rel="noreferrer">iOS</a> <!-- -->or<!-- --> <a id="audio-android-cta" href="https://economist-app.onelink.me/d2eC/7f3c199" target="_blank" rel="noreferrer">Android</a>.</span></p></div><audio controls="" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/082%20Science%20and%20technology%20-%20Geology-67b8011a3e6b45fbf468cbb4ec2f77e7.mp3" title="A gigantic landslide shows the limit to how high mountains can grow" controlslist="nodownload"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure></div><p>In a paper published in <i>Nature</i> J√©rome Lav√©, a geologist at the University of Lorraine, describes another, much more spectacular mechanism. Dr Lav√© has collected evidence suggesting that, in around 1190, an enormous landslide slashed perhaps 500 metres from the height of Annapurna IV, a mountain in the Himalayas that stands about 7,500 metres high today. If he is right, it would be one of the biggest landslips ever recorded. The falling mountain top would have displaced up to 27 cubic kilometres of rock‚Äîroughly enough to bury the entirety of Manhattan to about the height of the Empire State Building.</p><p>As the rubble crashed down, the energy released would have been equivalent to around six times that of the Tsar Bomba, the biggest nuclear weapon ever detonated. ‚ÄúI don‚Äôt think I could imagine what it would sound like,‚Äù says Ann Rowan, a geologist at the University of Bergen who was not involved in Dr Lav√©‚Äôs work. </p><p>Dr Lav√©‚Äôs suspicions were aroused while doing fieldwork in the Ganga plain in Nepal in 2012. He noticed that the ground beneath his feet had an unusual composition. A 50-metre core drilled out of the rock showed an average concentration of limestone of around 10%. But for one 4-metre stretch the concentration rose to nearly 50%, ‚Äúwhich is enormous, and completely abnormal‚Äù, he says.</p><p>This suggested that the rocks in question had made their way to the Ganga plain from the Annapurna massif, hundreds of kilometres away. That, in turn, hinted at a massive landslide in the (geologically) recent past. After examining satellite images of the massif, and taking a helicopter ride to have a look for himself, Dr Lav√© spotted a large rubble field which looked like it could have been caused by the same event. So he visited the site the following year, becoming only the second geologist known to have done so, and took some samples. Examining the surrounding cliffs for signs of a collapse, he noticed that a peak known as Annapurna IV offered a relatively smooth, steep face which seemed to fit.</p><p>Back home, he sent samples from the rubble field, the rock core and others from the path the landslide might have taken for dating. Should their ages roughly correspond, that would suggest they were linked to the same event. By measuring the abundance of chlorine-36 (a radioactive isotope which accumulates in surface rocks and decays once they are buried), and carbon-14 (another which accumulates in living matter and decays after death), his colleagues dated the samples to the late 12th century, and to within a couple of decades of each other. That is within the accuracy limits of the dating techniques themselves.</p><p>Besides shedding light on a previously unknown cataclysm, Dr Lav√©‚Äôs work could plug a gap in the dominant explanation for why mountains stop growing, which is known as the ‚Äúglacial buzzsaw‚Äù hypothesis. Under this model, it is glaciers, which are extremely effective at carving scoops out of mountains, that are mostly responsible for curbing their growth. </p><p>The problem with that theory, says Dr Rowan, is that there are some peaks that manage to escape the erosive effect of glaciers, and then grow so steeply that glaciers can no longer stick to their sides. ‚ÄúThe question is,‚Äù she asks, ‚Äúwhat stops these mountains getting bigger?‚Äù</p><p>Landslides could well be one answer. While the exact trigger for the Annapurna landslide is unknown, Dr Lav√©‚Äôs idea is that, with nothing to shave rock off their tips, very high mountains simply keep growing until their weight is too much for their lower slopes‚Äîwhich do still experience erosion‚Äîto support. </p><p>Working out exactly how and when the tipping point is reached will require examining other such rockslides. Unfortunately, due to the actions of both glaciers and swollen rivers during the monsoon season, the rubble from the Annapurna landslip is vanishing fast. Dr Lav√© reckons that only about 10% of the dislodged material now remains in place. Older rockslides, assuming there were any, may already be impossible to reconstruct. <span data-ornament="ufinish">‚ñ†</span></p><p><i>Curious about the world? To enjoy our mind-expanding science coverage, sign up to <a href="https://www.economist.com/newsletters/simply-science">Simply Science</a>, our weekly subscriber-only newsletter.</i></p></div><p>This article appeared in the Science &amp; technology section of the print edition under the headline "When mountains reach peak peak"</p><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="The future of war: A special report" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/img/b/16/21/90/media-assets/image/20230708_DE_EU.jpg 16w, https://www.economist.com/img/b/32/42/90/media-assets/image/20230708_DE_EU.jpg 32w, https://www.economist.com/img/b/48/63/90/media-assets/image/20230708_DE_EU.jpg 48w, https://www.economist.com/img/b/64/84/90/media-assets/image/20230708_DE_EU.jpg 64w, https://www.economist.com/img/b/96/126/90/media-assets/image/20230708_DE_EU.jpg 96w, https://www.economist.com/img/b/128/168/90/media-assets/image/20230708_DE_EU.jpg 128w, https://www.economist.com/img/b/256/336/90/media-assets/image/20230708_DE_EU.jpg 256w, https://www.economist.com/img/b/360/473/90/media-assets/image/20230708_DE_EU.jpg 360w, https://www.economist.com/img/b/384/505/90/media-assets/image/20230708_DE_EU.jpg 384w, https://www.economist.com/img/b/480/631/90/media-assets/image/20230708_DE_EU.jpg 480w, https://www.economist.com/img/b/600/789/90/media-assets/image/20230708_DE_EU.jpg 600w, https://www.economist.com/img/b/834/1097/90/media-assets/image/20230708_DE_EU.jpg 834w, https://www.economist.com/img/b/960/1263/90/media-assets/image/20230708_DE_EU.jpg 960w, https://www.economist.com/img/b/1096/1441/90/media-assets/image/20230708_DE_EU.jpg 1096w, https://www.economist.com/img/b/1280/1684/90/media-assets/image/20230708_DE_EU.jpg 1280w, https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230708_DE_EU.jpg 1424w" src="https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230708_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the July 8th 2023 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents </p><a href="https://www.economist.com/printedition/2023-07-08" data-analytics="sidebar:weekly_edition"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1zm.142 4.5l-1.008 1.062c3.33 3.276 4.194 4.14 4.608 4.5-1.602-.018-3.168-.018-10.242-.018v1.584c7.074 0 8.73 0 10.242-.018-.432.36-1.314 1.206-4.608 4.536l1.008 1.044 6.354-6.354L12.142 5.5z" fill="#2E45B8" fill-rule="nonzero"></path></g></svg><span>Explore the edition</span></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tor‚Äôs history of D/DoS attacks and future strategies for mitigation (132 pts)]]></title>
            <link>https://forum.torproject.org/t/tor-project-tors-history-of-d-dos-attacks-strategy-for-mitigation/8145</link>
            <guid>36615849</guid>
            <pubDate>Thu, 06 Jul 2023 13:58:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forum.torproject.org/t/tor-project-tors-history-of-d-dos-attacks-strategy-for-mitigation/8145">https://forum.torproject.org/t/tor-project-tors-history-of-d-dos-attacks-strategy-for-mitigation/8145</a>, See on <a href="https://news.ycombinator.com/item?id=36615849">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <blockquote>
<p>I'm investigating the applicability of the IETF's DDoS Open Threat<br>
Signaling (DOTS) specifications[1] to the needs of privacy-preserving<br>
overlay networks, including VPNs but with particular interest in Tor.</p>
<p>Specifically, now that the July 2022 D/DoS attack has finally come to a<br>
close, I'm wondering about:</p>
<p>1. the history, frequency, and magnitude of D/DoS attacks against the<br>
&nbsp;&nbsp;&nbsp;&nbsp;Tor network;</p>
</blockquote>
<p>We have seen high volumes of onion service activity indicative of internal onion service DDoS roughly once a year for the past several years.</p>
<p>We also have seen periodic attacks against the directory authorities, going back several years.</p>
<blockquote>
<p>2. when these have taken the form of Tor traffic versus lower-level<br>
&nbsp;&nbsp;&nbsp;&nbsp;attacks on Tor nodes and HSDirs; and</p>
</blockquote>
<p>The most common attack has been either onion service related, or against the directory authorities. However, over the past year, we saw several attack attempts that appeared to target specific relays. This was a new phenomenon, at this scale.</p>
<p>We also saw some evidence of DDoS attack attempts through Tor. Relay operators have developed tools to block connections to external IP addresses that see connection spikes. One such example tool is: <a href="https://github.com/artikel10/surgeprotector">GitHub - artikel10/surgeprotector: Block Tor Exit traffic to flooded IP addresses via ExitPolicy.</a></p>
<p>We have made several attempts to secure funding to develop mechanisms to rate limit scraping, spam, and externally-destined DDoS attack activity happening through Tor, but so far, these funding proposals have all been rejected.</p>
<blockquote>
<p>3. how the new "proof of work over introduction circuits" scheme fits<br>
&nbsp;&nbsp;&nbsp;&nbsp;into Tor's overall strategy for mitigating D/DoS attacks.</p>
</blockquote>
<p>Around when the proof of work branch got finalized, the onion service attacks ended. We are not sure if this is related to the ability to deploy the PoW branch ad-hoc, or if it was just a coincidence.</p>
<p>Since the majority of DDoS activity has been onion service related, we expect this defense to act as a deterrent there, for most of the issues we have seen.</p>
<blockquote>
<p>I've found plenty of current and historical GitLab tickets---but I'm<br>
wondering if there are more comprehensive documents or other resources<br>
I'm not aware of.</p>
</blockquote>
<p>No. Many of the non-onion attacks we have noticed have confidential tickets. Many attacks were quite effective at degrading service, and appeared to have this as their goal. They were also appeared to be probing in nature, and often stopped after a few days or a week from starting. These attacks ran parallel to the larger onion service DDoS.</p>
<p>We recently obtained funding to fix these kinds of specific attacks against Guards, dirauths, and Exits, but many issues will remain confidential until we do so. We do not want to advertise which of these probing attacks were actually effective vs not, or why.</p>
<p>--- cfm[2].</p>
<details>
<summary title="Show trimmed content">¬∑¬∑¬∑</summary>
<p>On 6/26/23 04:10, Cory Francis Myers wrote:</p>
<blockquote>
<p>[1]: <a href="https://datatracker.ietf.org/wg/dots/documents/">DDoS Open Threat Signaling (dots)</a></p>
<p>[2]: I'm a maintainer of the SecureDrop project at the Freedom of the<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Press Foundation, but this work is supported by ARTICLE 19's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Internet of Rights Fellowship.<br>
_______________________________________________<br>
tor-project mailing list<br>
tor-project@lists.torproject.org<br>
<a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-project">tor-project Info Page</a></p>
</blockquote>
<p>--<br>
Mike Perry<br>
_______________________________________________<br>
tor-project mailing list<br>
tor-project@lists.torproject.org<br>
<a href="https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-project" target="_blank" rel="noopener">https://lists.torproject.org/cgi-bin/mailman/listinfo/tor-project</a></p>
</details>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The case against self-closing tags in HTML (117 pts)]]></title>
            <link>https://jakearchibald.com/2023/against-self-closing-tags-in-html/</link>
            <guid>36615691</guid>
            <pubDate>Thu, 06 Jul 2023 13:48:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakearchibald.com/2023/against-self-closing-tags-in-html/">https://jakearchibald.com/2023/against-self-closing-tags-in-html/</a>, See on <a href="https://news.ycombinator.com/item?id=36615691">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Let's talk about <code>/&gt;</code>:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;</span>br</span> <span>/&gt;</span></span>
<span><span><span>&lt;</span>img</span> <span>src</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>You'll see this syntax on my blog because <a href="https://prettier.io/playground/#N4Igxg9gdgLgprEAuEAeAllADgVxgAhgE8s4BeAHRHgA8YqA+EAGhAixnWgGdlQBDAE6CIAdwAKQhLxT8ANqP5FerAEaD+YANZwYAZX4BbOABlMcZADN53OGo3bderJswBzZDEE47IOIdU4ABMg4JN+KDccfjc4ADEIQUN+GE5I5BB+PAgWEAALGEM5AHU89HhuFzA4PWly9AA3cqIMsG4VEExbQRhxDTdkqxtfACtuGj13OTgARRwIeCG5W1YXQW6MgqLcrEFMGGL0IJg85AAOAAZVkVtijSwM3bhuhotWAEd5+D72GUzuAC0UDgwWCuUEcE+6AhfRigyQ1mWvlshnQnm8yKmcAAgqk9qo8HBxHBBGZgUsViBuFi5gsLAjhqwYPxVIdjqckAAmJkadBydwAYQghnhfm4AFZcjhbAAVFkyRGUho+ACSUFCsD0YD2HGx6r0xGmFLgAF8TUA">it's what Prettier does</a>, and I really like Prettier. However, I don't think <code>/&gt;</code> is a good thing.</p>
<p>First up:</p>
<h2 id="the-facts"><a href="#the-facts">The facts</a></h2>
<h3 id="enter-xhtml"><a href="#enter-xhtml">Enter XHTML</a></h3>
<p>Back in the late 90s and early 2000s, the W3C had a real thing for XML, and thought that it should replace HTML syntax.</p>
<p>There were good reasons for this. At the time there was no HTML parsing spec, so when it came to anything non-trivial, you'd often end up with 4 browser engines interpreting the same HTML document 4 different ways. On the other hand, XML has a fully defined parser.</p>
<p>But, it would have been a huge change to do this all at once, so in 2000, <a href="https://www.w3.org/TR/2000/REC-xhtml1-20000126/">XHTML 1.0 became a recommendation</a>, and proposed writing HTML in a way that was compatible with both existing HTML parsers, and XML parsers.</p>
<p>That meant:</p>
<!-- prettier-ignore -->
<div><pre><code><span>&lt;!-- Instead of: --&gt;</span>
<span><span><span>&lt;</span>HTML</span> <span>LANG</span><span><span>=</span><span>"</span>en<span>"</span></span><span>&gt;</span></span>

<span>&lt;!-- You'd write: --&gt;</span>
<span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span><span>&lt;!</span><span>DOCTYPE</span> <span>html</span> <span>PUBLIC</span> <span>"-//W3C//DTD XHTML 1.0 Strict//EN"</span> <span>"DTD/xhtml1-strict.dtd"</span><span>&gt;</span></span>
<span><span><span>&lt;</span>html</span> <span>xmlns</span><span><span>=</span><span>"</span>http://www.w3.org/1999/xhtml<span>"</span></span> <span><span>xml:</span>lang</span><span><span>=</span><span>"</span>en<span>"</span></span> <span>lang</span><span><span>=</span><span>"</span>en<span>"</span></span><span>&gt;</span></span></code></pre></div><p>Because we've got to scare away newcomers right?</p>
<!-- prettier-ignore -->
<div><pre><code><span>&lt;!-- Instead of: --&gt;</span>
<span><span><span>&lt;</span>option</span> <span>value</span><span><span>=</span>foo</span> <span>selected</span><span>&gt;</span></span>‚Ä¶<span><span><span>&lt;/</span>option</span><span>&gt;</span></span>

<span>&lt;!-- You'd write: --&gt;</span>
<span><span><span>&lt;</span>option</span> <span>value</span><span><span>=</span><span>"</span>foo<span>"</span></span> <span>selected</span><span><span>=</span><span>"</span>selected<span>"</span></span><span>&gt;</span></span>‚Ä¶<span><span><span>&lt;/</span>option</span><span>&gt;</span></span></code></pre></div><p>Because, in XML, attributes require values, and they must be quoted with double quotes.</p>
<p>And also:</p>
<!-- prettier-ignore -->
<div><pre><code><span>&lt;!-- Instead of: --&gt;</span>
<span><span><span>&lt;</span>img</span> <span>src</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span><span>&gt;</span></span>

<span>&lt;!-- You'd write: --&gt;</span>
<span><span><span>&lt;</span>img</span> <span>src</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>Because in XML, tags have to explicitly close, and XML has a short-hand for self-closing tags: <code>/&gt;</code>.</p>
<p>In XML, it would generally be formatted like <code>&lt;this/&gt;</code>, without the space before the <code>/</code>, but Netscape Navigator 4 couldn't cope with <code>&lt;input type="text"/&gt;</code>, where the <code>/</code> immediately followed an attribute, so the spec recommended a space before the <code>/</code>.</p>
<h3 id="but-browsers-didnt-care"><a href="#but-browsers-didnt-care">But, browsers didn't care</a></h3>
<p>These rules were purely for XML parsers, and because documents were being served as HTML (if you're that one guy who served their site as <code>application/xhtml+xml</code>, you don't need to tell me), these syntactical 'extras' were ignored.</p>
<p>With <code>&lt;option selected="selected"&gt;</code>, the value was ignored, so <code>&lt;option selected=""&gt;</code> worked too, as would <code>&lt;option selected="false"&gt;</code> (the <code>false</code> would be ignored), but for 'consistency' it was decided that repeating the attribute name was a good idea.</p>
<p>If you forgot to quote an attribute, the browser didn't complain, it just got on with the job of rendering the page.</p>
<p>If you ended a tag with <code>/&gt;</code>, the browser saw it as a parsing error and ignore it. And that's where I start to take issue with it.</p>
<!-- prettier-ignore -->
<div><pre><code><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span> The br is closed. This text is not inside the br.

But also:

<span><span><span>&lt;</span>br</span><span>&gt;</span></span> The br is closed. This text is not inside the br.

And this is where it gets confusing:

<span><span><span>&lt;</span>div</span> <span>/&gt;</span></span> The div is open. This text is inside the div.</code></pre></div><p>In XML, <code>&lt;div /&gt;</code> would be a self-closing div, but not in HTML. In HTML, it isn't the <code>/&gt;</code> that closes the <code>br</code>, it's the "br". It's part of a special list of elements that can never have children, and therefore they self-close. <code>&lt;div /&gt;</code> doesn't self-close, because "div" isn't on that list.</p>
<h3 id="exit-xhtml"><a href="#exit-xhtml">Exit XHTML</a></h3>
<p>The 'transitional' phase of XHTML ended with XHTML 1.1. At this point the spec required the document to be served and parsed as XML. XML parsing rules were well defined, except for when invalid syntax was encountered. The best thing browsers could do there is just show an error page, else we'd be back to browsers just making stuff up, and each behaving differently. And to that, browsers said‚Ä¶ no thanks.</p>
<p>Well, they didn't exactly say no, they supported it, and still do today. Here's <a href="https://random-server-stuff.glitch.me/xhtml/">a valid XHTML document served as <code>application/xhtml+xml</code></a>, and <a href="https://random-server-stuff.glitch.me/xhtml-broken-drs/">here's an invalid one</a>. But browsers didn't see it as the future.</p>
<p>Ask yourself: If you visit the website of your local doctor's surgery to find out the opening hours, which browser is best: The one that displays the opening hours of the surgery, or the one that displays an XML parsing error message?</p>
<p>One of the great things about browsers is they're error-tolerant, and browsers weren't interested in giving that up.</p>
<p>XHTML was eventually abandoned, because a new thing came along that browsers were happier with:</p>
<h3 id="enter-html5"><a href="#enter-html5">Enter HTML5</a></h3>
<p>HTML5 entered the scene in 2008, and one of the major things it introduced was a parsing spec. And, unlike the XML parsing spec, it detailed what browsers should do when they encounter weird and invalid markup.</p>
<p>It did away with all of the XML requirements introduced in XHTML, and leaned into the looseness of HTML parsers that existed at the time. It does handle <code>/&gt;</code> specifically, but only to specifically ignored it.</p>
<h3 id="enter-svg-in-html"><a href="#enter-svg-in-html">Enter SVG-in-HTML</a></h3>
<p>In the early 2000s, the ability to include <code>&lt;svg&gt;</code> in HTML was spec'd and started appearing in browsers.</p>
<div><pre><code><span><span><span>&lt;</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>svg</span> <span>viewBox</span><span><span>=</span><span>"</span>0 0 100 100<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>circle</span> <span>cx</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>cy</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>r</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>/&gt;</span></span>
  <span><span><span>&lt;/</span>svg</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div><p>Although SVG is an XML format, when it's embedded in an HTML document it's parsed by the HTML parser. However, to increase compatibility with copy-pasted SVG content, when the HTML parser is within an <code>&lt;svg&gt;</code> tag, it switches to a <a href="https://html.spec.whatwg.org/multipage/parsing.html#parsing-main-inforeign">"foreign content" mode</a>, where <code>/&gt;</code> is actually meaningful.</p>
<!-- prettier-ignore -->
<div><pre><code><span><span><span>&lt;</span>div</span><span>/&gt;</span></span> The div is open. This text is inside the div.

Whereas:

<span><span><span>&lt;</span>svg</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>g</span><span>&gt;</span></span><span><span><span>&lt;</span>text</span><span>&gt;</span></span>This is inside the group<span><span><span>&lt;/</span>text</span><span>&gt;</span></span><span><span><span>&lt;/</span>g</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>g</span><span>/&gt;</span></span><span><span><span>&lt;</span>text</span><span>&gt;</span></span>This is outside the group<span><span><span>&lt;/</span>text</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>svg</span><span>&gt;</span></span></code></pre></div><p>Other foreign content such as MathML behaves the same.</p>
<p>And that's where things are today. <code>/&gt;</code> is mostly meaningless in HTML documents, with foreign content being the exception.</p>
<h2 id="opinions"><a href="#opinions">Opinions</a></h2>
<p>Although, as an industry, we generally discarded most of the XHTML requirements, this self-closing-tag decoration seems to have persisted, despite being a remnant from a spec that was abandoned over 10 years ago. Folks even include the space before the <code>/</code>, which was added for compatibility with a browser engine from the previous millennium.</p>
<p>I think it's a confusing relic from a time past, and I don't think tools like Prettier should be pushing it. To make my case, I'll respond to counter-arguments that came up in <a href="https://twitter.com/jaffathecake/status/1676843832284004353">a Twitter thread</a>.</p>
<h3 id="self-closing-tags-make-it-easier-to-read-and-are-helpful-for-newcomers-you-dont-need-to-remember-which-tags-are-self-closing"><a href="#self-closing-tags-make-it-easier-to-read-and-are-helpful-for-newcomers-you-dont-need-to-remember-which-tags-are-self-closing">"Self-closing tags make it easier to read, and are helpful for newcomers! You don't need to remember which tags are self-closing."</a></h3>
<p>Outside of foreign content, elements that self-close will always self-close. All other elements, won't.</p>
<!-- prettier-ignore -->
<div><pre><code><span><span><span>&lt;</span>input</span> <span>/&gt;</span></span>This text is outside the input.

<span><span><span>&lt;</span>input</span><span>&gt;</span></span>This text is outside the input.<span><span><span>&lt;/</span>input</span><span>&gt;</span></span>

<span><span><span>&lt;</span>div</span><span>&gt;</span></span>This text is inside the div.<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>

<span><span><span>&lt;</span>div</span> <span>/&gt;</span></span>This text is inside the div.</code></pre></div><p>The examples of <code>/&gt;</code> above simply don't do anything. The only way you know that <code>&lt;input /&gt;</code> is acceptable and <code>&lt;div /&gt;</code> isn't, is learning and remembering which elements self-close. It sucks, but that's the way it is.</p>
<p>But, does <code>/&gt;</code> have to <em>work</em> to be useful? Code comments don't 'work'. Just like <code>/&gt;</code>, they're an indication, they might be misleading, but that isn't a good argument for removing code comments. The problem with <code>/&gt;</code> is it doesn't look like a comment, and worse, it doesn't always behave like a comment, due to the rules around foreign content.</p>
<p>I think that's particularly bad for newcomers. Imagine you'd never seen <code>&lt;img src="‚Ä¶"&gt;</code> before. You'd see, unlike other elements, it doesn't have a closing tag. Debuggers and validators don't complain about it, suggesting there's something particular about this element you need to learn ‚Äì it doesn't need to close, it self-closes, and it's particular in this behaviour.</p>
<p>Now imagine you'd never seen <code>&lt;img src="‚Ä¶" /&gt;</code> before. You look up this new syntax you've discovered, and learn that it means a tag is "self-closing". At this point, why wouldn't you assume <code>&lt;iframe /&gt;</code> is self closing too? Or that <code>&lt;img src="‚Ä¶"&gt;&lt;/img&gt;</code> is valid? Given this, I'm particularly sad that <a href="https://github.com/orgs/mdn/discussions/242">MDN uses self-closing tags</a> in it's beginner-facing documentation.</p>
<h3 id="its-consistent-with-jsx"><a href="#its-consistent-with-jsx">"It's consistent with JSX"</a></h3>
<p>JSX and HTML are different formats. They aren't consistent with each other. Pretending they're consistent is misleading.</p>
<div><pre><code><span><span><span>&lt;</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>span</span><span>&gt;</span></span>Hello<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>span</span><span>&gt;</span></span>world<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div><p>The above HTML renders as "Hello world".</p>
<div><pre><code><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>span</span><span>&gt;</span></span><span>Hello</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>span</span><span>&gt;</span></span><span>world</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>
  </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span>)</span><span>;</span></code></pre></div><p>The above JSX renders as "Helloworld". The formats work differently.</p>
<!-- prettier-ignore -->
<div><pre><code><span><span><span>&lt;</span>main</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>/&gt;</span></span>
  Hello
<span><span><span>&lt;/</span>main</span><span>&gt;</span></span></code></pre></div><p>With the above HTML, the text is <em>inside</em> the <code>div</code>.</p>
<div><pre><code><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span><span><span>&lt;</span>main</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>div</span> <span>/&gt;</span></span><span>
    Hello
  </span><span><span><span>&lt;/</span>main</span><span>&gt;</span></span>
<span>)</span><span>;</span></code></pre></div><p>With the above JSX, the text is <em>outside</em> the <code>div</code>. It's a different system!</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>classname</span><span><span>=</span><span>"</span>foo<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div><p>The above HTML produces a div with a <code>classname</code> attribute.</p>
<div><pre><code><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span><span><span>&lt;</span>div</span> <span>classname</span><span><span>=</span><span>"</span>foo<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>;</span></code></pre></div><p>The above JSX produces a div with a <code>class</code> attribute. Ok, that's more of a React thing than a JSX thing, but that's a really common way to use JSX.</p>
<p>I don't think there's an argument for consistency here. Despite visual similarities, they're different formats that work differently.</p>
<h3 id="it-means-i-can-parse-html-with-an-xml-parser"><a href="#it-means-i-can-parse-html-with-an-xml-parser">"It means I can parse HTML with an XML parser"</a></h3>
<p>Call me some sort of purist, but if I want to parse an HTML document, I'll use an HTML parser. I wouldn't try and write JSON so it can be parsed by a YAML parser, so I don't see why I'd do the same with HTML and XML.</p>
<p>There are many great HTML parsing libraries out there, for almost every language. And, since the parser is specified, the results are consistent.</p>
<h3 id="it-looks-pretty"><a href="#it-looks-pretty">"It looks pretty"</a></h3>
<p>Sure, that's subjective. I thought <code>/&gt;</code> looked ugly the first time I worked on a codebase that required it, but I got used to it. I also got used to missing it out.</p>
<p>If prettiness is the goal, hey, we could use <code>&lt;input type="text" üõë&gt;</code>!</p>
<p>But seriously, I think aesthetics should take a back seat, given how misleading the syntax is.</p>
<h2 id="prettier-should-be-more-opinionated"><a href="#prettier-should-be-more-opinionated">Prettier should be more opinionated</a></h2>
<p>I respect Prettier's "our way or the highway" approach, but I don't think it's consistent here.</p>
<p>It will change <code>&lt;br&gt;</code> to <code>&lt;br /&gt;</code>, but it won't do anything with <code>&lt;div /&gt;</code>. In fact, if you give it <code>&lt;div/&gt;</code> it'll reformat it as <code>&lt;div /&gt;</code>.</p>
<p>I think Prettier should either <a href="https://github.com/prettier/prettier/issues/5246">drop <code>/&gt;</code> in cases where it's meaningless to the parser</a>, or <a href="https://github.com/prettier/prettier/issues/5864">fix cases where <code>/&gt;</code> is actively misleading</a>. As in:</p>
<!-- prettier-ignore -->
<p>‚Ä¶should reformat to:</p>
<p>‚Ä¶similar to how <a href="https://prettier.io/playground/#N4Igxg9gdgLgprEAuEAeAJgSwG4D4A6UqADrqgPSkgA0IExMm0AzsqAIYBOnEA7gApcErFOwA2vdgE9WtAEad2YANZwYAZXYBbOABlMUOMgBm45nHmKVa9cSUGA5shicArhZBwtcuOnS-ddigHV3YHOAAxCE4tdhhGYOQQdlcYCBoQAAsYLTEAdUzMeGY7MDh1YSKcIqkksGZZEANzThh+RQdYkzMPACtmAA91RzE4AEVXCHhusXNaO04WpOzcjOJOAxg8zHQYTOQADgAGeZ5zPMViJPW4FuwjWgBHSfh2+hFk5gBaQ19fDM4cGemEB7TCXSQplmHnMWkwzjcMJGcAAgvENnJUnB+HBOPpDDM5iBmMiJlMjJCerQYOw5NtdvskAAmamKTBiRwAYQgWghnmYAFYMq5zAAVWkiKFE7DuACSUH8sHUYA2DBRCvUMCko0JcAAvnqgA">it already treats unclosed tags</a>.</p>

<p>A major part of the problem is that <code>/&gt;</code> is sometimes ignored, and sometimes not, within the same HTML document. Could we have an option to switch the parsing rules so <code>/&gt;</code> is always meaningful? As in, <code>&lt;div/&gt;</code> is actually self-closing. I <a href="https://github.com/whatwg/html/issues/9491">filed an issue for this</a>, but I suspect it's a no-go due to incompatibility with existing libraries, particularly security-sensitive ones.</p>
<p>Oh well.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DigitalOcean acquires Paperspace (YC W15) for $111M in cash (172 pts)]]></title>
            <link>https://finance.yahoo.com/news/digitalocean-acquires-paperspace-expand-ai-120000933.html</link>
            <guid>36614924</guid>
            <pubDate>Thu, 06 Jul 2023 12:45:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/digitalocean-acquires-paperspace-expand-ai-120000933.html">https://finance.yahoo.com/news/digitalocean-acquires-paperspace-expand-ai-120000933.html</a>, See on <a href="https://news.ycombinator.com/item?id=36614924">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><p><img alt="" src="https://s.yimg.com/ny/api/res/1.2/lS2f5KwGfaF0MaYQCiFC1w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTM2MDtoPTM2MA--/https://media.zenfs.com/en/business-wire.com/6380e2c96f40cc6b57e123c76abe11d1" height="180" width="180"></p></figure><p><i>Paperspace‚Äôs high-performance GPU tooling enables small and medium-sized businesses around the globe to test, build, and scale AI models in the cloud</i></p><p><b>NEW YORK, July 06, 2023</b>--(<a href="https://www.businesswire.com/" rel="nofollow noopener" target="_blank" data-ylk="slk:BUSINESS WIRE;elm:context_link;itc:0">BUSINESS WIRE</a>)--<a href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=http%3A%2F%2Fwww.digitalocean.com&amp;esheet=53440668&amp;newsitemid=20230706326029&amp;lan=en-US&amp;anchor=DigitalOcean+Holdings%2C+Inc.&amp;index=1&amp;md5=092d6bfb52962ffaf5900021fd24764b" rel="nofollow noopener" target="_blank" data-ylk="slk:DigitalOcean Holdings, Inc.;elm:context_link;itc:0">DigitalOcean Holdings, Inc.</a> (NYSE:DOCN), the cloud for small and medium-sized businesses (SMBs) and startups, has acquired Paperspace, a leading provider of cloud infrastructure as a service for highly scalable applications leveraging graphics processing units (GPUs). The acquisition and integration of Paperspace‚Äôs advanced technology into the DigitalOcean platform will extend DigitalOcean‚Äôs offerings, enabling customers to more easily test, develop and deploy artificial intelligence and machine learning (AI/ML) applications, augment and enhance existing AI/ML applications and utilize GPUs in ways that have predominantly been the domain of large enterprises.</p><p>The increasing demand for AI/ML cloud solutions makes Paperspace‚Äôs GPU-powered infrastructure and AI/ML focused software stack valuable additions to DigitalOcean‚Äôs portfolio. Like DigitalOcean‚Äôs approach to the cloud, Paperspace simplifies the AI/ML experience, enabling easy and cost-effective experimentation and production across various AI/ML use cases, such as generative media, text analysis and natural language understanding, recommendation engines, image classification and many others.</p><p>The acquisition benefits both organizations‚Äô customers. Paperspace‚Äôs customers will now have access to a broader cloud services platform. Paperspace customers will also gain access to DigitalOcean‚Äôs extensive documentation, tutorials and support system to assist them in their journey to build and deploy AI applications. DigitalOcean customers exploring or already building AI/ML applications will now be able to leverage GPUs alongside their CPU workloads. Together, DigitalOcean and Paperspace will provide smaller businesses and startups with a comprehensive suite of cloud offerings, advanced networking, and the flexibility to harness both GPU and CPU capabilities as AI/ML technologies evolve and demand increases.</p><p>"We are excited to expand our portfolio tailored to the world‚Äôs SMBs and startups with simplified AI/ML offerings," said Yancey Spruill, CEO of DigitalOcean. "This acquisition marks a significant milestone in DigitalOcean's journey to revolutionize how SMBs and startups harness the power of the cloud and AI/ML for their applications and businesses. The combined offerings allow customers to focus more on building applications and growing their businesses and less on the infrastructure powering them."</p><p>Paperspace will benefit from DigitalOcean‚Äôs highly effective self-serve model and efficient go-to-market strategy. The acquisition expands DigitalOcean‚Äôs serviceable market and presents cross-sell and upsell opportunities for both entities, leveraging DigitalOcean's mature platform, efficient marketing engine and its extensive customer base to drive growth.</p><p>"DigitalOcean is renowned for simplifying complex cloud technologies and making them more accessible to developers and business alike," said Dillon Erb, Co-founder and CEO of Paperspace. "We are thrilled to join forces with DigitalOcean, as we believe there is no better company to unlock the endless possibilities of AI/Ml for developers and businesses alike."</p><p>Importantly, the alignment in organizational history and culture between DigitalOcean and Paperspace will ensure a smooth integration process and a collaborative work environment. The two companies‚Äô shared values and commitment to customer success will continue to foster innovation, enhance customer experiences, and reinforce both entities as industry leaders in cloud computing.</p><p><b>Transaction Terms</b></p><p>Under the terms of the transaction, DigitalOcean acquired Paperspace for $111 million in cash. The acquisition is expected to have an immaterial impact on 2023 financial results. "Paperspace is a rapidly growing business with leading edge technology that significantly accelerates our AI/ML capabilities. We expect it to enhance our revenue growth in 2024 and beyond and we will invest commensurately to further accelerate its growth and take full advantage of this tremendous emerging market opportunity," said Matt Steinfort, DigitalOcean‚Äôs CFO. On its Q2 2023 earnings call on August 3, 2023, DigitalOcean will share more details on the strategic benefits of the acquisition and update the Company‚Äôs financial outlook for 2023.</p><p><b>About DigitalOcean</b></p><p>DigitalOcean simplifies cloud computing so businesses can spend more time creating software that changes the world. With its mission-critical infrastructure and fully managed offerings, DigitalOcean helps developers at startups and small and medium-sized businesses (SMBs) rapidly build, deploy and scale, whether creating a digital presence or building digital products. DigitalOcean combines the power of simplicity, security, community and customer support so customers can spend less time managing their infrastructure and more time building innovative applications that drive business growth. For more information, visit <a href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=http%3A%2F%2Fwww.digitalocean.com&amp;esheet=53440668&amp;newsitemid=20230706326029&amp;lan=en-US&amp;anchor=digitalocean.com&amp;index=2&amp;md5=04a47149d6d6e5f24f508167c0843a76" rel="nofollow noopener" target="_blank" data-ylk="slk:digitalocean.com;elm:context_link;itc:0">digitalocean.com</a>.</p><p><b>About Paperspace</b></p><p>Paperspace is a cloud platform for building and scaling AI applications. Paperspace customer use-cases include deploying LLMs, fine-tuning Foundation Models, building the next ChatGPT, harnessing generative media, and many more. Tens of thousands of individuals and businesses use Paperspace to explore new models with Notebooks, automate training with Workflows, and bring their applications to life with Deployments.</p><p><b>Forward-Looking Statements</b></p><p>This press release may contain forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements may be identified by their use of terms and phrases such as "anticipate," "enable," "expect," "will," "believe," "continue" and other similar terms and phrases. The outcome of the events described in these forward-looking statements is subject to known and unknown risks, uncertainties and other factors that could cause actual results to differ materially from the results anticipated by these forward-looking statements, including those factors contained in the "Risk Factors" section of our SEC filings. It is not possible for us to predict all risks and uncertainties that could have an impact on the forward-looking statements contained in this release. The results, events and circumstances reflected in the forward-looking statements may not be achieved or occur.</p><p><span>View source version on businesswire.com: </span><span><a href="https://www.businesswire.com/news/home/20230706326029/en/" rel="nofollow noopener" target="_blank" data-ylk="slk:https://www.businesswire.com/news/home/20230706326029/en/;elm:context_link;itc:0">https://www.businesswire.com/news/home/20230706326029/en/</a></span></p><p><b>Contacts</b></p><p>Media<br>Spencer Anopol<br><a href="mailto:press@digitalocean.com" rel="nofollow" data-ylk="slk:press@digitalocean.com;elm:context_link;itc:0">press@digitalocean.com</a></p><p>Investors<br>Rob Bradley<br><a href="mailto:investors@digitalocean.com" rel="nofollow" data-ylk="slk:investors@digitalocean.com;elm:context_link;itc:0">investors@digitalocean.com</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop trying to make social networks succeed (234 pts)]]></title>
            <link>https://ploum.net/2023-07-06-stop-trying-to-make-social-networks-succeed.html</link>
            <guid>36614788</guid>
            <pubDate>Thu, 06 Jul 2023 12:30:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ploum.net/2023-07-06-stop-trying-to-make-social-networks-succeed.html">https://ploum.net/2023-07-06-stop-trying-to-make-social-networks-succeed.html</a>, See on <a href="https://news.ycombinator.com/item?id=36614788">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p>by <a href="https://ploum.net/index.html">Ploum</a> on 2023-07-06</p><p>Lot is happening in the social network landscape with the demises of Twitter and Reddit, the apparition of Bluesky and Threads, the growing popularity of Mastodon. Many pundits are trying to guess which one will be successful and trying to explain why others will fail. Which completely misses the point.</p>
<p>Particular social networks will never "succeed". Nobody even agree on the definition of "success".</p>
<p>The problem is that we all see our little bubble and generalise what we observe as universal. We have a hard time understanding Mastodon‚ÄØ? Mastodon will never succeed, it will be for a niche. A few of our favourite web stars goes to Bluesky‚ÄØ? Bluesky is the future, everybody will be there.</p>
<p>That‚Äôs not how it works. That‚Äôs not how it ever worked.</p>
<p>Like every human endeavour, every social network is there for a limited duration and will be useful to a limited niche of people. That niche may grow to the point of being huge, like Facebook and WhatsApp. But, to this day, there are more people in the world without an account on Facebook than people with one. Every single social network is only representative of a minority. And the opposite would be terrifying when you think about it (which is exactly what Meta is trying to build).</p>
<p>Social networks are fluid. They come, they go. For commercial social networks, the success is defined by: "do they earn enough money to make investors happy‚ÄØ?" There‚Äôs no metric of success for non-commercial ones. They simply exist as long as at least two users are using them to communicate. Which is why criticisms like "Mastodon could never raise enough money" or "the Fediverse will never succeed" totally miss the point. </p>
<p>If you live in the same occidental bubble as me, you might have never heard of WeChat, QQ or VK. Those are immensely popular social networks. In China and Russia. WeChat alone is more or less the size of Instagram in terms of active users. The war in Ukraine also demonstrated that the most popular social network in that part of the world is Telegram. Which is twice as big as Twitter but, for whatever reason, is barely mentioned in my own circles. The lesson here is simple: you are living in a small niche. We all do. Your experience is not representative of anything but your own. And it‚Äôs fine.</p>
<p>There will never be one social network to rule them all. There should never be one social network to rule them all. In fact, tech-savvy people should fight to ensure that no social network ever "succeed".</p>
<p>Human lives in communities. We join them, we sometimes leave them. Social networks should only be an underlying infrastructure to support our communities. Social networks are not our communities. Social network dies. Communities migrate and flock to different destinations. Nothing ever replaced Google+, which was really popular in my own tech circle. Nothing will replace Twitter or Reddit. Some communities will find a new home on Mastodon or on Lemmy. Some will go elsewhere. That‚Äôs not a problem as long as you can have multiple accounts in different places. Something I‚Äôm sure you do. Communities can be split. Communities can be merged. People can be part of several communities and several platforms.</p>
<p>Silicon Valley venture capitalists are trying to convince us that, one day, a social network will succeed, will become universal. That it should grow. That social networks are our communities. That your community should grow to succeed.</p>
<p>This is a lie, a delusion. Our communities are worth a lot more than the underlying tool used at some point in time. By accepting the confusion, we are destroying our communities. We are selling them, we are transforming them into a simple commercial asset for the makers of the tool we are using, the tool which exploits us. </p>
<p>Stop trying to make social networks succeed, stop dreaming of a universal network. Instead, invest in your own communities. Help them make long-term, custom and sustainable solutions. Try to achieve small and local successes instead of pursuing an imaginary universal one. It will make you happier.</p>
<p>It will make all of us happier.</p>

<div><p>As a writer and an engineer, I like to explore how technology impacts society. You can subscribe <a href="https://listes.ploum.net/mailman3/postorius/lists/en.listes.ploum.net/">by email</a> or <a href="https://ploum.net/atom_en.xml">by rss</a>. I value privacy and never share your adress.</p>
<p>If you read French, you can support me by buying/sharing/reading <a href="https://ploum.net/livres.html">my books</a> and subscribing to my <a href="https://listes.ploum.net/mailman3/postorius/lists/fr.listes.ploum.net/">newsletter in French</a> or <a href="https://ploum.net/atom_fr.xml">RSS</a>. I also develop <a href="https://ploum.net/software.html">Free Software</a>.</p>

</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling Transformers to 1B Tokens (177 pts)]]></title>
            <link>https://arxiv.org/abs/2307.02486</link>
            <guid>36614774</guid>
            <pubDate>Thu, 06 Jul 2023 12:28:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2307.02486">https://arxiv.org/abs/2307.02486</a>, See on <a href="https://news.ycombinator.com/item?id=36614774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2307.02486">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  Scaling sequence length has become a critical demand in the era of large
language models. However, existing methods struggle with either computational
complexity or model expressivity, rendering the maximum sequence length
restricted. In this work, we introduce LongNet, a Transformer variant that can
scale sequence length to more than 1 billion tokens, without sacrificing the
performance on shorter sequences. Specifically, we propose dilated attention,
which expands the attentive field exponentially as the distance grows. LongNet
has significant advantages: 1) it has a linear computation complexity and a
logarithm dependency between tokens; 2) it can be served as a distributed
trainer for extremely long sequences; 3) its dilated attention is a drop-in
replacement for standard attention, which can be seamlessly integrated with the
existing Transformer-based optimization. Experiments results demonstrate that
LongNet yields strong performance on both long-sequence modeling and general
language tasks. Our work opens up new possibilities for modeling very long
sequences, e.g., treating a whole corpus or even the entire Internet as a
sequence.

    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Shuming Ma [<a href="https://arxiv.org/show-email/9315dc76/2307.02486">view email</a>]
      <br>
    <strong>[v1]</strong>
    
        Wed, 5 Jul 2023 17:59:38 UTC (219 KB)<br>
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge rules White House pressured social networks to ‚Äúsuppress free speech‚Äù (366 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/07/judge-rules-white-house-pressured-social-networks-to-suppress-free-speech/</link>
            <guid>36614678</guid>
            <pubDate>Thu, 06 Jul 2023 12:19:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/07/judge-rules-white-house-pressured-social-networks-to-suppress-free-speech/">https://arstechnica.com/tech-policy/2023/07/judge-rules-white-house-pressured-social-networks-to-suppress-free-speech/</a>, See on <a href="https://news.ycombinator.com/item?id=36614678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Preliminary injunction    ‚Äî
</h4>
            
            <h2 itemprop="description">Missouri and Louisiana sued Biden over attempts to limit COVID misinformation.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/getty-biden-twitter-800x533.jpg" alt="The Twitter account of US President Joe Biden displayed on a smartphone screen.">
      <figcaption><p>Getty Images | Christopher Furlong </p></figcaption>  </figure>

  




<!-- cache hit 267:single/related:f060211379d3f7c0ad7ffb7cfd1a84b3 --><!-- empty -->
<p>A federal judge yesterday ordered the Biden administration to halt a wide range of communications with social media companies, siding with Missouri and Louisiana in a <a href="https://storage.courtlistener.com/recap/gov.uscourts.lawd.189520/gov.uscourts.lawd.189520.268.0.pdf">lawsuit</a> that alleges Biden and his administration violated the First Amendment by colluding with social networks "to suppress disfavored speakers, viewpoints, and content."</p>
<p>The Biden administration argued that it communicated with tech companies to counter misinformation related to elections, COVID-19, and vaccines, and that it didn't exert illegal pressure on the companies. The communications to social media companies were not significant enough "to convert private conduct into government conduct," Department of Justice lawyers argued in the case.</p>
<p>But Judge Terry Doughty, a Trump nominee at US District Court for the Western District of Louisiana, <a href="https://storage.courtlistener.com/recap/gov.uscourts.lawd.189520/gov.uscourts.lawd.189520.294.0_2.pdf">granted the plaintiffs' request</a> for a preliminary injunction imposing limits on the Department of Health and Human Services, the National Institute of Allergy and Infectious Diseases, the Centers for Disease Control and Prevention, the Federal Bureau of Investigation, the Department of Justice, the US Census Bureau, the State Department, the Homeland Security Department, the Cybersecurity and Infrastructure Security Agency, and many specific officials at those agencies. The injunction also affects White House officials.</p>
<p>The agencies and officials are prohibited from communicating "with social-media companies for the purpose of urging, encouraging, pressuring, or inducing in any manner the removal, deletion, suppression, or reduction of content containing protected free speech posted on social-media platforms," Doughty ruled. The injunction prohibits "specifically flagging content or posts on social-media platforms and/or forwarding such to social-media companies urging, encouraging, pressuring, or inducing in any manner for removal, deletion, suppression, or reduction of content containing protected free speech."</p>                                            
                                                        
<p>Government agencies and officials are further barred from urging, encouraging, or pressuring social media companies "to change their guidelines for removing, deleting, suppressing, or reducing content containing protected free speech." The ruling also said the government may not coordinate with third-party groups, including the Election Integrity Partnership, the Virality Project, and the Stanford Internet Observatory, to pressure social media companies.</p>
<h2>Exceptions include voting misinformation</h2>
<p>Doughty provided several exceptions that allow the government to communicate with social media companies about criminal activity and other speech that the First Amendment doesn't protect. The Biden administration may continue to inform social networks about posts involving criminal activity or criminal conspiracies, national security threats, extortion, criminal efforts to suppress voting, illegal campaign contributions, cyberattacks against election infrastructure, foreign attempts to influence elections, threats to public safety and security, and posts intending to mislead voters about voting requirements and procedures.</p>
<p>The US can also exercise "permissible public government speech promoting government policies or views on matters of public concern," communicate with social networks "in an effort to detect, prevent, or mitigate malicious cyber activity," and "communicat[e] with social-media companies about deleting, removing, suppressing, or reducing posts on social-media platforms that are not protected free speech by the Free Speech Clause in the First Amendment to the United States Constitution."</p>
<p>In addition to the Missouri and Louisiana attorneys general, the plaintiffs include professors Jayanta Bhattacharya and Martin Kulldorff, who co-authored the October 2020 "Great Barrington Declaration" that opposed COVID lockdowns and urged a focus on reaching herd immunity. They and other plaintiffs claim they were censored by social networks.</p>
<p>The ruling was criticized by Jameel Jaffer, an adjunct professor of law and journalism who is executive director of the Knight First Amendment Institute at Columbia University. "It can't be that the government violates the First Amendment simply by engaging with the platforms about their content-moderation decisions and policies," <a href="https://www.nytimes.com/2023/07/04/business/federal-judge-biden-social-media.html">Jaffer told The New York Times</a>, calling it "a pretty radical proposition that isn't supported by the case law."</p>                                            
                                                        
<p>While the government must be careful to avoid coercion in its efforts to combat false information, Jaffer said that "unfortunately, Judge Doughty's order doesn't reflect a serious effort to reconcile the competing principles."</p>
<p>Stanford Law School Assistant Professor Evelyn Douek <a href="https://www.washingtonpost.com/technology/2023/07/04/biden-social-lawsuit-missouri-louisiana/">told The Washington Post</a> that the "injunction is strikingly broad and clearly intended to chill any kind of contact between government actors and social media platforms."</p>
<h2>Judge finds ‚Äúunrelenting pressure‚Äù on social networks</h2>
<p>Doughty previously <a href="https://storage.courtlistener.com/recap/gov.uscourts.lawd.186715/gov.uscourts.lawd.186715.128.0.pdf">blocked</a> federal vaccine and mask mandates in the Head Start program. In the social media case, Doughty made it clear that he expects plaintiffs to win in a <a href="https://storage.courtlistener.com/recap/gov.uscourts.lawd.189520/gov.uscourts.lawd.189520.293.0_1.pdf">155-page memorandum ruling</a> explaining his decision yesterday:</p>
<blockquote><p>The Plaintiffs are likely to succeed on the merits on their claim that the United States Government, through the White House and numerous federal agencies, pressured and encouraged social-media companies to suppress free speech. Defendants used meetings and communications with social-media companies to pressure those companies to take down, reduce, and suppress the free speech of American citizens.</p>
<p>They flagged posts and provided information on the type of posts they wanted suppressed. They also followed up with directives to the social-media companies to provide them with information as to action the company had taken with regard to the flagged post. This seemingly unrelenting pressure by Defendants had the intended result of suppressing millions of protected free speech postings by American citizens.</p></blockquote>
<p>The federal defendants "argue they only made requests to the social-media companies, and that the decision to modify or suppress content was each social-media company's independent decision," Doughty wrote. "However, when a state has so involved itself in the private party's conduct, it cannot claim the conduct occurred as a result of private choice, even if the private party would have acted independently."</p>
<p>He found that defendants "significantly encouraged" and in some cases coerced "the social-media companies to such extent that the decision should be deemed to be the decisions of the Government."</p>

                                                </div>

            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/tech-policy/2023/07/judge-rules-white-house-pressured-social-networks-to-suppress-free-speech/2/">2</a> <a href="https://arstechnica.com/tech-policy/2023/07/judge-rules-white-house-pressured-social-networks-to-suppress-free-speech/2/"><span>Next <span>‚Üí</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Godot 4.1 Is Released (460 pts)]]></title>
            <link>https://godotengine.org/article/godot-4-1-is-here/</link>
            <guid>36614114</guid>
            <pubDate>Thu, 06 Jul 2023 11:11:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://godotengine.org/article/godot-4-1-is-here/">https://godotengine.org/article/godot-4-1-is-here/</a>, See on <a href="https://news.ycombinator.com/item?id=36614114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>After <a href="https://godotengine.org/article/godot-4-0-sets-sail">four months of work</a>, we are excited to bring you Godot 4.1! It‚Äôs an update that follows our pledge to improve upon Godot 4.0 with frequent incremental releases ‚Äî with a focus on stability, performance, and polish.</p>

<p>As always, a new release comes with a bunch of welcome new features, like the improved AI navigation avoidance and the ability to detach code editors and put them on other displays.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/detached-code-editor.png" alt="The code editor detached from the main editor window"></p>

<p>Still, we took great care to prioritize the bugs you have encountered in 4.0. This update fixes over 900 issues that users have reported from using Godot 4 or while helping contributors test 4.1 with pre-release builds. The engine should feel more reliable overall. We will continue improving stability, performance, and workflows with every upcoming feature release of Godot 4.</p>

<p>For most games and apps made with 4.0 it should be relatively safe to migrate to 4.1. We are <a href="https://github.com/godotengine/godot-docs/pull/7611">preparing a migration guide</a> that outlines everything you need to pay attention to when migrating your project. Some incompatibilities are expected for C# and GDExtension users specifically, however we are working on making sure to avoid that in future releases. Don‚Äôt forget to always make backups when moving versions, even minor. Better yet, prefer using a version control system, such as Git, and commit a version of your project before the migration.</p>

<p><strong>If you wish to get straight into the action, you can <a href="https://godotengine.org/download/">download Godot 4.1 now</a>.</strong> Or stick around and read more about the most notable changes of this release. You can also watch this great highlights video by <a href="https://www.gdquest.com/">GDQuest</a>:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/PAtG_fHhIx8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<h2 id="giving-back">Giving back</h2>

<p>As a community effort, Godot relies on individual contributors to improve. In recent years, <a href="https://godotengine.org/donate/">user and company donations</a> allowed us to also hire a number of core contributors to work full-time on the engine and bring you these fast-paced releases.</p>

<p>Our monthly expenses remain higher than monthly donations, and we still depend on large one-time company donations to fund development. Currently, we need a lot more <a href="https://godotengine.org/donate/">monthly donations</a> to keep up the pace with Godot 4 updates, not to mention the need to hire more maintainers to review every contribution.</p>

<p>Besides financial support, you can also give back by: writing detailed bug reports, contributing to the code base, writing documentation, writing guides (for the docs or on your own website), and supporting others on the various <a href="https://docs.godotengine.org/en/latest/community/channels.html">community platforms</a> by answering questions and providing helpful tips.</p>

<p>Last but not least, making games with Godot and crediting the engine goes a long way to help make it more popular and convince more people to contribute and improve Godot for everyone. Remember, we are all in this together and Godot requires community support in every area to thrive.</p>

<h2 id="highlights">Highlights</h2>

<p>This release was made possible thanks to submissions from over 300 contributors! We warmly thank you all for your work and dedication, including those who helped us test the engine before the release and submit bug reports.</p>

<p>For an exhaustive list of all the bug fixes and improvements, head on over to our <a href="https://godotengine.github.io/godot-interactive-changelog/#4.1">interactive changelog</a>.</p>

<p>Without further ado, here‚Äôs a breakdown of the main changes and new features.</p>

<h3 id="performance">Performance</h3>

<p>Godot games are built as a tree of nodes, which are the engine‚Äôs base building block for game entities. Adding and removing nodes are operations the engine needs to do extremely often, so they need to be as fast as possible.</p>

<p>In 4.1, we changed the algorithm to use a fast hashmap to make adding and removing child nodes several times faster. Uncommon node operations are slightly slower as a result, and the memory footprint of the base Node class is 10% higher, but this is a small and necessary trade-off for a big benefit to all Godot users, especially to more complex projects with a lot of node manipulation.</p>

<p>This version also introduces experimental multithreading for your scenes, a feature kickstarted by <a href="https://github.com/reduz">Juan Linietsky</a>. New node properties give you full control over how nodes get processed, sequentially or in parallel.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/threaded-node-properties-highlighted.png" alt="Thread group configuration options for Node"></p>

<p>As mentioned, the feature is currently marked experimental as it needs extensive testing to find edge cases. We do not recommend using it in production yet. But it sets the foundation for making the most of modern hardware, with simple controls.</p>

<p>Also on the multithreading front, <a href="https://github.com/RandomShaper">Pedro J. Est√©banez</a> worked hard on fixing a large amount of multi-threaded loading issues and limitations.</p>

<p>On the rendering side, the Vulkan renderer got a pipeline cache. While Godot already cached shaders to reduce shader compilation stutter, compiling pipelines still lead to some stuttering and slower load times. While the pipeline compilation stuttering issue is far from solved, this represents a step in the right direction and should also lead to a slight decrease in load times when using one of the RenderingDevice-based rendering backends. This cache can be toggled off in the project settings and is on by default in Godot 4.1.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/shader-cache-setting.png" alt="Shader cache project settings"></p>

<p>This improvement doesn‚Äôt address all possible causes of stalls, but it‚Äôs a first step in the right direction by <a href="https://github.com/warriormaster12">Alexander Streng</a>. We‚Äôll keep working on it in upcoming releases.</p>

<p>More work will follow on the performance front throughout the year.</p>

<h3 id="core">Core</h3>

<p>When importing models into Godot, there was often the problem that they ended up facing backward.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/model-facing-back.webp" alt="A model facing backwards (before the change)"></p>

<p><a href="https://github.com/reduz">Juan Linietsky</a>, <a href="https://github.com/TokageItLab">Tokage</a>, and <a href="https://github.com/aaronfranke">Aaron Franke</a> worked on a number of ways to address this issue. One of the implemented changes swaps the front and back camera directions in the editor. Also, the <code>look_at()</code> function now has an argument to use the model space as the reference for looking forward instead of the camera‚Äôs minus Z axis. These changes also help fix a long-standing bug with path following.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/model-facing-front.webp" alt="A model facing forward (after the change)"></p>

<p>This update also brings frame delta smoothing to Godot 4, by <a href="https://github.com/lawnjelly">lawnjelly</a>. This can significantly improve the fluidity of motion and give smoother gameplay. This option is enabled by default, though please note that it only works when VSync is also enabled.</p>

<h3 id="scripting">Scripting</h3>

<h4 id="gdscript">GDScript</h4>

<p>Until now, in GDScript, you needed to use a resource or an autoload to share data between multiple instances of the same script.</p>

<p>Thanks to <a href="https://github.com/vnen">George Marques</a>, you can now create and use static variables instead. Static variables store data on the class instead of each instance, so they‚Äôre shared between every instance of the class.</p>

<p>To make a variable static, add the <code>static</code> keyword in front of a variable defined at the top of your script.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/gdscript-static-variables.png" alt="A GDScript code sample showcasing the use of static variables"></p>

<p>A great feature of GDScript added in Godot 4 is the automatic generation of documentation pages for your named classes.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/gdscript-docs-generation.png" alt="An example of a generated documentation based on a custom GDScript class"></p>

<p>This version includes a rework of the system by <a href="https://github.com/anvilfolk">ocean</a> that now treats enumerations as types, making the generated documentation more precise. You can also now use inline docstrings instead of having to always place them above a variable or a function‚Äôs definition.</p>

<div><pre><code><span>var</span> <span>my_variable</span> <span>=</span> <span>10</span> <span>## This is an inline docstring</span>
</code></pre></div>

<h4 id="cnet">C#/.NET</h4>

<p>The focus in this release was on bringing feature parity between C# and GDScript.</p>

<p>When using GDScript, you can define a new node type to use in the editor by adding a global class name to your script.</p>

<p>Starting from Godot 4.1, this is also possible in C# by adding the <code>[GlobalClass]</code> attribute to your file, thanks to <a href="https://github.com/raulsntos">Raul Santos</a> and <a href="https://github.com/willnationsdev">Will Nations</a>. You can also use the <code>[Icon]</code> attribute to give your global class a unique icon.</p>

<p>Note that as of this release projects made with C# still cannot be exported to mobile and web platforms. We are working on providing the support as soon as possible, but the resolution of this limitation will likely depend on the release of .NET 8 at the end of 2023. This means that the work on enabling mobile and web platforms can only truly start later this year.</p>

<h4 id="gdextension">GDExtension</h4>

<p>Godot comes with a unique technology to use low-level languages like C++ as a game scripting language, without having to recompile the engine.</p>

<p>While the technology is still in beta for this release, GDExtension is now even closer to GDScript and C# in terms of scripting capabilities. You can now implement new visual shader nodes and create editor plugins with GDExtension.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/gdextension-visual-shader-node.png" alt="An example of using a custom visual shader node from GDExtension"></p>

<p>The team also implemented a backward compatibility system to help ensure that code written for Godot 4.1 keeps working even if the API changes in future releases. However, a significant compatibility breakage was necessary to do in 4.1 to fix critical issues in GDExtension, so existing Godot 4.0 extensions will need to be ported and recompiled for 4.1.</p>

<p>Finally, a lot of work was done on the architecture once again to make the GDExtension API extensible in the future.</p>

<p>All the above resulted from the teamwork of <a href="https://github.com/dsnopek">David Snopek</a>, <a href="https://github.com/reduz">Juan Linietsky</a>, <a href="https://github.com/RedworkDE">RedworkDE</a>, <a href="https://github.com/Chaosus">Yuri Rubinsky</a>, and <a href="https://github.com/YuriSizov">Yuri Sizov</a>.</p>

<h3 id="editor">Editor</h3>

<p>Godot 4 has support for multiple windows which we use for the project and editor settings and various pop-ups. Starting with this version, you can now also detach docs into floating windows and detach script editors, including the shader editor, and place them on a separate monitor.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/detached-code-editor.png" alt="The code editor detached from the main editor window"></p>

<p>In addition to that, the editor will now keep track of your window layout so that when you close and reopen the editor, you should often find yourself exactly where you left off.</p>

<p>You can thank <a href="https://github.com/trollodel">trollodel</a>, <a href="https://github.com/Geometror">Hendrik Brucker</a>, and <a href="https://github.com/KoBeWi">Tomasz Chabora</a> for this.</p>

<p>Godot 4.0 introduced the option to define and export typed arrays, and to export individual nodes to the inspector, but it was not possible to combine the two. From Godot 4.1 onwards, you can export arrays of nodes to the inspector, which is great to link game objects together.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/editor-exported-node-array.png" alt="An array of nodes exported as a custom property"></p>

<p>This work was done by Tomasz and <a href="https://github.com/ajreckof">Timoth√© Bonhoure</a></p>

<p>The project manager now allows you to assign tags to individual projects and filter projects by tags. It makes it much easier to search through dozens, if not hundreds of Godot projects.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/editor-project-manager-tags.png" alt="A list of projects with custom tags assigned to them"></p>

<h3 id="rendering">Rendering</h3>

<p>Particle turbulence got reworked in this version based on artists‚Äô feedback to offer greater creative control. Turbulence is used extensively to create these rich sprawling effects seen in many modern games. Big thanks to <a href="https://github.com/KdotJPG">KdotJPG</a> and <a href="https://github.com/RPicster">Raffaele Picca</a> for this contribution.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/render-particles-turbulence.png" alt="An effect driven by the updated particle turbulence system"></p>

<p>Using the new 3D noise textures you can control the density of volumetric fog easily, and make it thinner in certain areas. NoiseTexture3D can also be used to create particle attractor vector fields, which is useful to simulate wind that affects particles. <a href="https://github.com/Lasuch69">Lasuch</a> and <a href="https://github.com/clayjohn">Clay John</a> implemented this feature.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/render-3d-noise.png" alt="A more complex fog volume using the new 3D noise"></p>

<p>While there are still many <a href="https://godotengine.org/article/rendering-priorities-4-1/">planned improvements</a> to Godot‚Äôs renderers, most will be present in future releases. The rendering team (and all rendering contributors) prioritized bug fixing and stability over new features. Notably, the 3D GLES3 renderer is not yet complete, but will see substantial work over the coming months.</p>

<h3 id="navigation">Navigation</h3>

<p>Godot 4.0 introduced real-time avoidance for AI navigation, but it was limited to a single plane.</p>

<p>This release includes completely rewritten avoidance algorithms by <a href="https://github.com/smix8">smix8</a> to give you much better behaviors and greater control. Avoidance can now happen in 2D or 3D, allowing flying agents to move over those walking on the ground.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/navigation-3d-layers.png" alt="A demo of multiple navigation agents operating on several layers in 3D"></p>

<p>On top of that, you can now use layers to control which agents avoid which and assign priorities to have some agents push others away.</p>

<p><img src="https://godotengine.org/storage/blog/godot-4-1-is-here/navigation-priority.png" alt="A demo of multiple navigation agents with varied priorities"></p>

<p>Check out the <a href="https://docs.godotengine.org/en/stable/tutorials/navigation/index.html">updated documentation</a> to learn more about how the improved navigation works.</p>

<h3 id="platform-support">Platform support</h3>

<p>We are as committed as ever to have Godot games on all popular platforms, and 4.1 still offers the same capabilities as did Godot 4.0. You can export to all desktop platforms with both standard and .NET version of the engine, and you can export to mobile and web if you don‚Äôt use C# in your projects.</p>

<p>As of 4.1 web exports still have some limitations due to poor vendor support of certain modern features. Browsers with bad WebGL 2 support, such as Chrome on macOS, unfortunately suffer from issues which we cannot address without a fix from Google or a significant amount of effort put into supporting a dedicated WebGL 1 / GLES2 renderer.</p>

<p>We are also aware of the complexity setting up web games on hosting platforms which don‚Äôt let you set the required CORS headers for SharedArrayBuffer support. This mostly depends on Safari implementing the <code>coep:credentialless</code> header support, while Chromium-based browsers and Firefox already work fine (especially if you publish on itch.io). There is a <a href="https://github.com/godotengine/godot-proposals/issues/6616">possible workaround</a> that we are investigating.</p>

<h2 id="known-issues">Known issues</h2>

<p>With every release we acknowledge that there are going to be problems which we couldn‚Äôt resolve in time. Some of these problems have been identified and fixes are being worked on as we speak, while others remain unknown until someone runs into the issue. You can follow our <a href="https://github.com/godotengine/godot/issues">bug tracker</a> to learn if the problem that you‚Äôre experiencing has been reported. We appreciate new reports and confirmations of existing reports, as that helps us prioritize fixing specific issues.</p>

<p>Here are notable issues that have already been identified that you might experience in Godot 4.1:</p>

<ul>
  <li>The newly added API for defining custom configuration properties for export presets does not persist user configurations. Configuration options get reset and lost on editor restarts. The fix is going to be available in 4.1.1 (see <a href="https://github.com/godotengine/godot/pull/79025">GH-79025</a>).</li>
</ul>

<h2 id="on-to-the-next-release">On to the next release!</h2>

<p>We already started work on Godot 4.2, which will come out in four months. We are dedicated to keeping up the pace and sticking to this reliable release cycle, so you never have to wait long for the next batch of improvements and new features.</p>

<p>Until then, <a href="https://godotengine.org/download/">enjoy Godot 4.1</a>!</p>

			</div></div>]]></description>
        </item>
    </channel>
</rss>