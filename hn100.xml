<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 09 Apr 2024 20:00:11 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cow Magnets (114 pts)]]></title>
            <link>https://www.stanfordmagnets.com/cow-magnets.html</link>
            <guid>39982024</guid>
            <pubDate>Tue, 09 Apr 2024 17:45:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.stanfordmagnets.com/cow-magnets.html">https://www.stanfordmagnets.com/cow-magnets.html</a>, See on <a href="https://news.ycombinator.com/item?id=39982024">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                    <h2><strong>Cow Magnets</strong></h2>
<p><span lang="en">What is a <strong>cow magnet</strong>？Have you ever heard of this <strong><a href="https://www.stanfordmagnets.com/what-are-the-four-types-of-magnets.html">type of magnet</a></strong>? Actually, <strong>c</strong></span><strong>ow magnets</strong> are very popular with farmers, ranchers, and veterinarians since they are a well-known method of&nbsp;preventing hardware disease in cattle. So what’s&nbsp;hardware disease?</p>
<figure id="attachment_35470"><img src="https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets.jpg" alt="Cow Magnets" width="725" height="453" srcset="https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets.jpg 725w, https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets-300x187.jpg 300w, https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets-600x375.jpg 600w" sizes="(max-width: 725px) 100vw, 725px"><figcaption>Cow Magnets</figcaption></figure>
<h2><strong>About Hardware Disease</strong></h2>
<p>Hardware disease is a common term for bovine traumatic reticulopericarditis. It is usually caused by the ingestion of a sharp, metallic object. These pieces of metal settle in the reticulum and can irritate or penetrate the lining. It is most common in dairy cattle but is occasionally seen in beef cattle. It is very rarely reported in any other ruminants. It can be difficult to conclusively diagnose but can be prevented by the oral administration of a magnet around the time that the animal reaches the age of one year.</p>
<h2><strong>Causes of </strong><strong>Hardware Disease</strong></h2>
<p>Cattle commonly swallow foreign objects, because they do not use their lips to discriminate between materials and they do not completely chew their feed before swallowing.&nbsp;<span lang="en">Sharp metal objects (such as nails or iron wires) are a common cause of hardware diseases.&nbsp;The object travels into the rumen and is then pushed into the reticulum along with the rest of the feed.&nbsp; In some cases, contractions of the reticulum can push the object through part of the reticulum wall into the peritoneal cavity, where it causes severe inflammation.&nbsp;In rare cases, the metal object penetrates the entire wall of the reticulum and can pierce the heart sac, causing pericarditis. Compression by the uterus in late pregnancy, straining during parturition, and mounting during estrus can increase the likelihood of the object penetrating the abdominal wall or the heart sac.</span></p>
<h2><strong>How to prevent the hardware disease?</strong></h2>
<p><span lang="en">A <strong>cow magnet</strong> is a kind of veterinary medical equipment used to treat or prevent hardware diseases of cattle.&nbsp;Traditionally, the cow magnets are strong <strong><a href="https://www.stanfordmagnets.com/alnico-magnets.html">Alnico magnets</a></strong>, in the shape of a smooth rod, about 1 cm by 8 cm (0.4 by 3.1 inches). However, today they are more commonly several ring-shaped <strong><a href="https://www.stanfordmagnets.com/ceramic-ferrite-magnets.html">ferrite magnets</a></strong> attached to a stainless-steel or plastic core, in the same shape as the single-piece original.&nbsp;</span></p>
<p><span lang="en">Newer designs to help increase effectiveness include a cage design, in which the magnet holds metal objects inside a protective plastic framework. Even newer designs include a stronger array of <strong><a href="https://www.stanfordmagnets.com/are-rare-earth-magnets-really-rare.html">rare-earth magnets</a></strong> inside a stainless steel body that resembles the original Alnico design.</span></p>
<p>A rancher or dairy farmer feeds a magnet to each calf at branding time; the magnet settles in the rumen or reticulum and remains there for the life of the animal.&nbsp;The magnet is administered after fasting the cow for 18–24 hours. This is most effective if done to the entire herd before the age of one.</p>
<p>The cow magnet attracts such objects and prevents them from becoming lodged in the animal’s tissue. While the resultant mass of iron remains in the cow’s rumen as a pseudobezoar (an intentionally introduced bezoar), it does not cause the severe problems of hardware disease. Cow magnets cannot be passed through a cow’s 4th bonivial meta-colon.</p>
<p>Cow magnets are widely available from veterinary, feed supply, and scientific supply sources.</p>
<h2><strong>Conclusion&nbsp;</strong></h2>
<p>Thank you for reading our article and we hope it can help you to have a better understanding of the cow magnets. If you want to learn more about magnets, we would like to advise you to visit <strong><a href="https://www.stanfordmagnets.com/">Stanford Magnets</a></strong> for more information.</p>
<p>As a&nbsp;<a href="https://www.stanfordmagnets.com/magnet-manufacturer-and-supplier.html"><strong>leading&nbsp;magnet supplier&nbsp;</strong></a>across the world,&nbsp;<strong>Stanford Magnets</strong>&nbsp;has been involved in R&amp;D, manufacturing, and sales of&nbsp;<span lang="en">magnets</span>&nbsp;since the 1990s. It provides customers with high-quality permanent magnets like&nbsp;<strong><a href="https://www.stanfordmagnets.com/smco-magnets.html">SmCo magnets</a>,</strong>&nbsp;<strong><a href="https://www.samaterials.com/neodymium/1087-neodymium-metal-powder.html">neodymium</a>&nbsp;magnets</strong>,&nbsp;<strong>AlNiCo magnets</strong>, and&nbsp;<strong>ferrite magnets</strong>&nbsp;(ceramic magnets) at a very competitive price.</p>
<p><span></span>
			<span>Post Views: </span>
			<span>35,279</span>
			</p>                                    <p><span>Tags: <a href="https://www.stanfordmagnets.com/tag/alnico-magnets/" rel="tag">Alnico magnets</a>, <a href="https://www.stanfordmagnets.com/4-things-you-should-know-about-ceramic-magnets.html" rel="tag">Ceramic Magnets</a>, <a href="https://www.stanfordmagnets.com/tag/cow-magnet/" rel="tag">Cow Magnet</a>, <a href="https://www.stanfordmagnets.com/where-to-use-neodymium-countersunk-magnets.html-4" rel="tag">ferrite magnets</a>, <a href="https://www.stanfordmagnets.com/tag/hardware-disease/" rel="tag">Hardware Disease</a>, <a href="https://www.stanfordmagnets.com/how-to-choose-a-neodymium-magnet.html-9" rel="tag">leading&nbsp;magnet supplier</a>, <a href="https://www.stanfordmagnets.com/tag/neodymium-magnets/" rel="tag">Neodymium Magnets</a>, <a href="https://www.stanfordmagnets.com/tag/rare-earth-magnets/" rel="tag">rare earth magnets</a>, <a href="https://www.stanfordmagnets.com/everything-you-need-to-know-about-samarium-cobalt-magnets.html" rel="tag">SmCo Magnets</a>, <a href="https://www.stanfordmagnets.com/everything-you-need-to-know-about-rare-earth-magnets.html" rel="tag">Stanford Magnets</a>, <a href="https://www.stanfordmagnets.com/how-to-choose-a-neodymium-magnet.html-5" rel="tag">types of magnet</a></span></p>
                                                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zed Decoded: Async Rust (102 pts)]]></title>
            <link>https://zed.dev/blog/zed-decoded-async-rust</link>
            <guid>39981945</guid>
            <pubDate>Tue, 09 Apr 2024 17:38:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/zed-decoded-async-rust">https://zed.dev/blog/zed-decoded-async-rust</a>, See on <a href="https://news.ycombinator.com/item?id=39981945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p><h2><span data-br=":R3brrrqbf9la:" data-brr="1">Zed Decoded: Async Rust</span></h2></p><header></header><p>Welcome to the first article in a new series called <strong>Zed Decoded</strong>. In Zed Decoded I'm going to take a close look at Zed — how it's built, which data structures it uses, which technologies and techniques, what features it has, which bugs we ran into. The best part? I won't do this alone, but get to interview and ask my colleagues here at Zed about everything I want to know.</p>
<div><div><p><b>Companion Video</b>: <!-- -->Async Rust</p><p>This post comes with a 1hr companion video, in which Thorsten and Antonio explore how Zed uses async Rust —&nbsp;in Zed. It's a loose conversation that focuses on the code and dives a bit deeper into some topics that didn't fit into the post.</p><p>Watch the video here:<!-- --> <a href="https://youtu.be/gkU4NGSe21I">https://youtu.be/gkU4NGSe21I</a></p></div><p><img src="https://zed.dev/img/post/zed-decoded-async-rust/thumbnail.jpg" width="230" height="150"></p></div>
<p>The first topic that was on my list: async Rust and how it's used in Zed. Over the past few months I've become quite fascinated with async Rust — Zed's the first codebase I've worked in that uses it — so I decided to sit down and ask Antonio, one of Zed's co-founders, about how we use async Rust in Zed.</p>
<p>We won't get into the details of async Rust itself (familiarity with that is to be expected if you want to understand the nitty-gritty of the code we'll see), but instead focus on how Zed uses async Rust to build a high-performance, native application: what async code looks like on the application level, which runtime it uses, why it uses that runtime.</p>
<h2 id="writing-async-rust-with-gpui"><span data-br=":R4nbrrrqbf9la:" data-brr="1">Writing async Rust with GPUI</span></h2>
<p>Let's jump right into the deep end. Here is a snippet of code that's representative of async code in the Zed codebase:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>fn</span><span> show_cursor_names</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>cx</span><span>: &amp;</span><span>mut</span><span> ViewContext</span><span>&lt;</span><span>Self</span><span>&gt;) {</span></span>
<span data-line=""><span>    self</span><span>.show_cursor_names = </span><span>true</span><span>;</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>notify</span><span>();</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>spawn</span><span>(|</span><span>this</span><span>, </span><span>mut</span><span> cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>        cx</span><span>.</span><span>background_executor</span><span>().</span><span>timer</span><span>(CURSORS_VISIBLE_FOR).</span><span>await</span><span>;</span></span>
<span data-line=""><span>        this</span><span>.</span><span>update</span><span>(&amp;</span><span>mut</span><span> cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>            this</span><span>.show_cursor_names = </span><span>false</span><span>;</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>notify</span><span>()</span></span>
<span data-line=""><span>        })</span></span>
<span data-line=""><span>        .</span><span>ok</span><span>()</span></span>
<span data-line=""><span>    })</span></span>
<span data-line=""><span>    .</span><span>detach</span><span>();</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>It's <a href="https://github.com/zed-industries/zed/blob/98ddefc8884d0957ab766b3aea09265c8423684e/crates/editor/src/editor.rs#L3935-L3947">a function from our <code>Editor</code></a>. When it's called, Zed shows the names of the owners of each cursor: your name or the names of the people you're collaborating with. It's called, for example, when the editor is re-focused, so you can quickly see who's doing what and where.</p>
<p>What <code>show_cursor_names</code> does is the following:</p>
<ul>
<li>Toggle on <code>Editor.show_cursor_names</code> and trigger a re-render of the editor. When <code>Editor.show_cursor_names</code> is true, cursor names will be rendered.</li>
<li>Spawn a task that sleeps for <code>CURSOR_VISIBLE_FOR</code>, turn the cursors off, and trigger another re-render.</li>
</ul>
<p>If you've ever written async Rust before, you can spot some familiar elements in the code: there's a <code>.spawn</code>, there's an <code>async move</code>, there's an <code>await</code>. And if you've ever used the <code>async_task</code> crate before, this might remind you of code <a href="https://docs.rs/async-task/4.7.0/async_task/struct.Task.html#method.detach">like this</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>let</span><span> ex</span><span> = </span><span>Executor</span><span>::</span><span>new</span><span>();</span></span>
<span data-line=""><span>ex</span><span>.</span><span>spawn</span><span>(</span><span>async</span><span> {</span></span>
<span data-line=""><span>    loop</span><span> {</span></span>
<span data-line=""><span>        Timer</span><span>::</span><span>after</span><span>(</span><span>Duration</span><span>::</span><span>from_secs</span><span>(</span><span>1</span><span>)).</span><span>await</span><span>;</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>})</span></span>
<span data-line=""><span>.</span><span>detach</span><span>();</span></span></code></pre></div></figure>
<p>That's because Zed uses <code>async_task</code> for its <code>Task</code> type. But in this example there's an <code>Executor</code> — where is that in the Zed code? And what does <code>cx.background_executor()</code> do? Good questions, let's find answers.</p>
<h2 id="macos-as-our-async-runtime"><span data-br=":Rdnbrrrqbf9la:" data-brr="1">macOS as our async runtime</span></h2>
<p>One remarkable thing about async Rust is that it allows you to choose your own runtime. That's different from a lot of other languages (such as JavaScript) in which you can also write asynchronous code. Runtime isn't a term with very sharp definition, but for our purposes here, we can say that a runtime is the thing that runs your asynchronous code and provides you with utilities such as <code>.spawn</code> and something like an <code>Executor</code>.</p>
<p>The most popular of these runtimes is probably <a href="https://github.com/tokio-rs/tokio">tokio</a>. But there's also <a href="https://github.com/smol-rs/smol">smol</a>, <a href="https://github.com/embassy-rs/embassy">embassy</a> and others. Choosing and switching runtimes comes with tradeoffs, they <a href="https://corrode.dev/blog/async/">are only interchangable to a degree</a>, but it is possible.</p>
<p>In Zed for macOS, as it turns out, we don't use any one of these. We also don't use <code>async_task</code>'s <code>Executor</code>. But there has to be something to execute the asynchronous code, right? Otherwise I wouldn't be typing these lines in Zed.</p>
<p>So what then does <code>cx.spawn</code> do and what is the <code>cx.background_executor()</code>? Let's take a look. Here are <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/gpui/src/app.rs#L818-L836">three relevant methods from GPUI's <code>AppContext</code></a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/app.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> AppContext</span><span> {</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> background_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;</span><span>BackgroundExecutor</span><span> {</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>.background_executor</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    pub</span><span> fn</span><span> foreground_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;</span><span>ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>.foreground_executor</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Spawns the future returned by the given function on the thread pool. The closure will be invoked</span></span>
<span data-line=""><span>    /// with [AsyncAppContext], which allows the application state to be accessed across await points.</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> spawn</span><span>&lt;</span><span>Fut</span><span>, </span><span>R</span><span>&gt;(&amp;</span><span>self</span><span>, </span><span>f</span><span>: </span><span>impl</span><span> FnOnce</span><span>(</span><span>AsyncAppContext</span><span>) -&gt; </span><span>Fut</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt;</span></span>
<span data-line=""><span>    where</span></span>
<span data-line=""><span>        Fut</span><span>: </span><span>Future</span><span>&lt;</span><span>Output</span><span> = </span><span>R</span><span>&gt; + '</span><span>static</span><span>,</span></span>
<span data-line=""><span>        R</span><span>: '</span><span>static</span><span>,</span></span>
<span data-line=""><span>    {</span></span>
<span data-line=""><span>        self</span><span>.foreground_executor.</span><span>spawn</span><span>(</span><span>f</span><span>(</span><span>self</span><span>.</span><span>to_async</span><span>()))</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>Alright, two executors, <code>foreground_executor</code> and <code>background_executor</code>, and both have <code>.spawn</code> methods. We already saw <code>background_executor</code>'s <code>.spawn</code> above in <code>show_cursor_names</code> and here, in <code>AppContext.spawn</code>, we see the <code>foreground_executor</code> counterpart.</p>
<p>One level deeper, we can see what <code>foreground_executor.spawn</code> does:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/executor.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>    /// Enqueues the given Task to run on the main thread at some point in the future.</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> spawn</span><span>&lt;</span><span>R</span><span>&gt;(&amp;</span><span>self</span><span>, </span><span>future</span><span>: </span><span>impl</span><span> Future</span><span>&lt;</span><span>Output</span><span> = </span><span>R</span><span>&gt; + '</span><span>static</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt;</span></span>
<span data-line=""><span>    where</span></span>
<span data-line=""><span>        R</span><span>: '</span><span>static</span><span>,</span></span>
<span data-line=""><span>    {</span></span>
<span data-line=""><span>        let</span><span> dispatcher</span><span> = </span><span>self</span><span>.dispatcher.</span><span>clone</span><span>();</span></span>
<span data-line=""><span>        fn</span><span> inner</span><span>&lt;</span><span>R</span><span>: '</span><span>static</span><span>&gt;(</span></span>
<span data-line=""><span>            dispatcher</span><span>: </span><span>Arc</span><span>&lt;</span><span>dyn</span><span> PlatformDispatcher</span><span>&gt;,</span></span>
<span data-line=""><span>            future</span><span>: </span><span>AnyLocalFuture</span><span>&lt;</span><span>R</span><span>&gt;,</span></span>
<span data-line=""><span>        ) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt; {</span></span>
<span data-line=""><span>            let</span><span> (</span><span>runnable</span><span>, </span><span>task</span><span>) = </span><span>async_task</span><span>::</span><span>spawn_local</span><span>(</span><span>future</span><span>, </span><span>move</span><span> |</span><span>runnable</span><span>| {</span></span>
<span data-line=""><span>                dispatcher</span><span>.</span><span>dispatch_on_main_thread</span><span>(</span><span>runnable</span><span>)</span></span>
<span data-line=""><span>            });</span></span>
<span data-line=""><span>            runnable</span><span>.</span><span>schedule</span><span>();</span></span>
<span data-line=""><span>            Task</span><span>::</span><span>Spawned</span><span>(</span><span>task</span><span>)</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>        inner</span><span>::&lt;</span><span>R</span><span>&gt;(</span><span>dispatcher</span><span>, </span><span>Box</span><span>::</span><span>pin</span><span>(</span><span>future</span><span>))</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>There's a lot going on here, a lot of syntax, but what happens can be boiled down to this: the <code>.spawn</code> method takes in a <code>future</code>, turns it into a <a href="https://docs.rs/async-task/latest/async_task/struct.Runnable.html"><code>Runnable</code></a> and a <code>Task</code>, and asks the <code>dispatcher</code> to run it on the main thread.</p>
<p>The <code>dispatcher</code> here is a <code>PlatformDispatcher</code>. That's the GPUI equivalent of <code>async_task</code>'s <code>Executor</code> from above. It has <code>Platform</code> in its name because it has different implementations for macOS, Linux, and Windows. But in this post, we're only going to look at macOS, since that's our best-supported platform at the moment and Linux/Windows implementations are still work-in-progress.</p>
<p>So what does <code>dispatch_on_main_thread</code> do? Does <em>this</em> now call an async runtime? No, no runtime <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/gpui/src/platform/mac/dispatcher.rs#L66-L75">there either</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/mac/dispatcher.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> PlatformDispatcher</span><span> for</span><span> MacDispatcher</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> dispatch_on_main_thread</span><span>(&amp;</span><span>self</span><span>, </span><span>runnable</span><span>: </span><span>Runnable</span><span>) {</span></span>
<span data-line=""><span>        unsafe</span><span> {</span></span>
<span data-line=""><span>            dispatch_async_f</span><span>(</span></span>
<span data-line=""><span>                dispatch_get_main_queue</span><span>(),</span></span>
<span data-line=""><span>                runnable</span><span>.</span><span>into_raw</span><span>().</span><span>as_ptr</span><span>() </span><span>as</span><span> *</span><span>mut</span><span> c_void</span><span>,</span></span>
<span data-line=""><span>                Some</span><span>(</span><span>trampoline</span><span>),</span></span>
<span data-line=""><span>            );</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>extern</span><span> "C"</span><span> fn</span><span> trampoline</span><span>(</span><span>runnable</span><span>: *</span><span>mut</span><span> c_void</span><span>) {</span></span>
<span data-line=""><span>    let</span><span> task</span><span> = </span><span>unsafe</span><span> { </span><span>Runnable</span><span>::&lt;()&gt;::</span><span>from_raw</span><span>(</span><span>NonNull</span><span>::</span><span>new_unchecked</span><span>(</span><span>runnable</span><span> as</span><span> *</span><span>mut</span><span> ())) };</span></span>
<span data-line=""><span>    task</span><span>.</span><span>run</span><span>();</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p><code>dispatch_async_f</code> is where the call leaves the Zed codebase, because <code>dispatch_async_f</code> is actually a compile-time generated binding to the <a href="https://developer.apple.com/documentation/dispatch/1452834-dispatch_async_f"><code>dispatch_async_f</code></a> function in <a href="https://developer.apple.com/documentation/DISPATCH">macOS' Grand Central Dispatch's (GCD)</a>. <code>dispatch_get_main_queue()</code>, too, is such a binding.</p>
<p>That's right: Zed, as a macOS application, uses macOS' GCD to schedule and execute work.</p>
<p>What happens in the snippet above is that Zed turns the <code>Runnable</code> — think of it as a handle to a <code>Task</code> — into a raw pointer and passes it to <code>dispatch_async_f</code> along with a <code>trampoline</code>, which puts it on its <code>main_queue</code>.</p>
<p>When GCD then decides it's time to run the next item on the <code>main_queue</code>, it pops it off the queue, and calls <code>trampoline</code>, which takes the raw pointer, turns it back into a <code>Runnable</code> and, to poll the <code>Future</code> behind its <code>Task</code>, calls <code>.run()</code> on it.</p>
<p>And, as I learned to my big surprise: that's it. That's essentially all the code necessary to use GCD as a "runtime" for async Rust. Where other applications use tokio or smol, Zed uses thin wrappers around GCD and crates such as <code>async_task</code>.</p>
<p>Wait, but what about the <code>BackgroundExecutor</code>? It's very, very similar to the <code>ForegroundExecutor</code>, with the main difference being that the <code>BackgroundExecutor</code> calls this method on <code>PlatformDispatcher</code>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>impl</span><span> PlatformDispatcher</span><span> for</span><span> MacDispatcher</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> dispatch</span><span>(&amp;</span><span>self</span><span>, </span><span>runnable</span><span>: </span><span>Runnable</span><span>, </span><span>_</span><span>: </span><span>Option</span><span>&lt;</span><span>TaskLabel</span><span>&gt;) {</span></span>
<span data-line=""><span>        unsafe</span><span> {</span></span>
<span data-line=""><span>            dispatch_async_f</span><span>(</span></span>
<span data-line=""><span>                dispatch_get_global_queue</span><span>(DISPATCH_QUEUE_PRIORITY_HIGH.</span><span>try_into</span><span>().</span><span>unwrap</span><span>(), </span><span>0</span><span>),</span></span>
<span data-line=""><span>                runnable</span><span>.</span><span>into_raw</span><span>().</span><span>as_ptr</span><span>() </span><span>as</span><span> *</span><span>mut</span><span> c_void</span><span>,</span></span>
<span data-line=""><span>                Some</span><span>(</span><span>trampoline</span><span>),</span></span>
<span data-line=""><span>            );</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>The only difference between this <code>dispatch</code> method and <code>dispatch_async_f</code> from above is the queue. The <code>BackgroundExecutor</code> doesn't use the <code>main_queue</code>, but <a href="https://developer.apple.com/documentation/dispatch/1452927-dispatch_get_global_queue?language=objc">a global queue</a>.</p>
<p>Like I did when I first read through this code, you now might wonder: why?</p>
<p>Why use GCD? Why have a <code>ForegroundExecutor</code> and a <code>BackgroundExecutor</code>? What's so special about the <code>main_queue</code>?</p>
<h2 id="never-block-the-main-thread"><span data-br=":R14nbrrrqbf9la:" data-brr="1">Never block the main thread</span></h2>
<p>In a native UI application, the main thread is important. No, the main thread is <em>holy</em>. The main thread is where the rendering happens, where user input is handled, where the operating system communicates with the application. The main thread should never, ever block. On the main thread, the responsiveness of your app lives or dies.</p>
<p>That's true for <a href="https://en.wikipedia.org/wiki/Cocoa_(API)">Cocoa</a> applications on macOS too. Rendering, receiving user input, communication with macOS, and other platform concerns have to happen on the main thread. And since Zed wants perfect cooperation with macOS to ensure high-performance and responsiveness, it does two things.</p>
<p>First, it uses GCD to schedule its work — on and off the main thread — so that macOS can maintain high responsiveness and overall system efficiency.</p>
<p>Second, the importance of the main thread is baked into GPUI, the UI framework, by explicitly making the distinction between the <code>ForegroundExecutor</code> and the <code>BackgroundExecutor</code>, both of which we saw above.</p>
<p>As a writer of application-level Zed code, you should always be mindful of what happens on the main thread and never put too much blocking work on it. If you were to put, say, a blocking <code>sleep(10ms)</code> on the main thread, rendering the UI now has to wait for that <code>sleep()</code> to finish, which means that rendering the next frame would take longer than 8ms — the maximum frame time available if you want to achieve <a href="https://zed.dev/blog/120fps">120 FPS</a>. You'd "drop a frame", as they say.</p>
<p>Knowing that, let's take a look at another small snippet of code. This time it's from the built-in terminal in Zed, a function that <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/terminal/src/terminal.rs#L1346-L1358">searches through the contents of the terminal buffer</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/terminal/src/terminal.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>pub</span><span> struct</span><span> Terminal</span><span> {</span></span>
<span data-line=""><span>    term</span><span>: </span><span>Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>alacritty_terminal</span><span>::</span><span>Term</span><span>&lt;</span><span>ZedListener</span><span>&gt;&gt;&gt;,</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [... other fields ...]</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>pub</span><span> fn</span><span> find_matches</span><span>(</span></span>
<span data-line=""><span>    &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>    mut</span><span> searcher</span><span>: </span><span>RegexSearch</span><span>,</span></span>
<span data-line=""><span>    cx</span><span>: &amp;</span><span>mut</span><span> ModelContext</span><span>&lt;</span><span>Self</span><span>&gt;,</span></span>
<span data-line=""><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>RangeInclusive</span><span>&lt;</span><span>AlacPoint</span><span>&gt;&gt;&gt; {</span></span>
<span data-line=""><span>    let</span><span> term</span><span> = </span><span>self</span><span>.term.</span><span>clone</span><span>();</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>background_executor</span><span>().</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>        let</span><span> term</span><span> = </span><span>term</span><span>.</span><span>lock</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>        all_search_matches</span><span>(&amp;</span><span>term</span><span>, &amp;</span><span>mut</span><span> searcher</span><span>).</span><span>collect</span><span>()</span></span>
<span data-line=""><span>    })</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>The first line in <code>find_matches</code>, the <code>self.term.clone()</code>, happens on the main thread and is quick: <code>self.term</code> is an <code>Arc&lt;Mutex&lt;...&gt;&gt;</code>, so cloning only bumps the reference count on the <code>Arc</code>. The call to <code>.lock()</code> then only happens in the background, since <code>.lock()</code> might block. It's unlikely that there will be contention for this lock in this particular code path, but if there was contention, it wouldn't freeze the UI, only a single background thread. That's the pattern: if it's quick, you can do it on the main thread, but if it might take a while or even block, put it on a background thread by using <code>cx.background_executor()</code>.</p>
<p>Here's another example, the project-wide search in Zed (<code>⌘-shift-f</code>). It pushes as much heavy work as possible onto background threads to ensure Zed stays responsive while searching through tens of thousands of files in your project. Here's a simplified and heavily-commented <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/project/src/project.rs#L6485-L6498">excerpt from <code>Project.search_local</code></a> that shows the main part of the search:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/project/src/project.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>// Spawn a Task on the background executor. The Task finds all files on disk</span></span>
<span data-line=""><span>// that contain &gt;1 matches for the given `query` and sends them back over</span></span>
<span data-line=""><span>// the `matching_paths_tx` channel.</span></span>
<span data-line=""><span>let</span><span> (</span><span>matching_paths_tx</span><span>, </span><span>matching_paths_rx</span><span>) = </span><span>smol</span><span>::</span><span>channel</span><span>::</span><span>bounded</span><span>(</span><span>1024</span><span>);</span></span>
<span data-line=""><span>cx</span><span>.</span><span>background_executor</span><span>()</span></span>
<span data-line=""><span>    .</span><span>spawn</span><span>(</span><span>Self</span><span>::</span><span>background_search</span><span>(</span></span>
<span data-line=""><span>        // [... other arguments ... ]</span></span>
<span data-line=""><span>        query</span><span>.</span><span>clone</span><span>(),</span></span>
<span data-line=""><span>        matching_paths_tx</span><span>,</span></span>
<span data-line=""><span>    ))</span></span>
<span data-line=""><span>    .</span><span>detach</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>// Setup a channel on which we stream results to the UI.</span></span>
<span data-line=""><span>let</span><span> (</span><span>result_tx</span><span>, </span><span>result_rx</span><span>) = </span><span>smol</span><span>::</span><span>channel</span><span>::</span><span>bounded</span><span>(</span><span>1024</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>// On the main thread, spawn a Task that first...</span></span>
<span data-line=""><span>cx</span><span>.</span><span>spawn</span><span>(|</span><span>this</span><span>, </span><span>mut</span><span> cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>    // ... waits for the background thread to return the filepaths of</span></span>
<span data-line=""><span>    // the maximum number of files that we want to search...</span></span>
<span data-line=""><span>    let</span><span> mut</span><span> matching_paths</span><span> = </span><span>matching_paths_rx</span></span>
<span data-line=""><span>        .</span><span>take</span><span>(MAX_SEARCH_RESULT_FILES + </span><span>1</span><span>)</span></span>
<span data-line=""><span>        .</span><span>collect</span><span>::&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;()</span></span>
<span data-line=""><span>        .</span><span>await</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // ... then loops over the filepaths in chunks of 64...</span></span>
<span data-line=""><span>    for</span><span> matching_paths_chunk</span><span> in</span><span> matching_paths</span><span>.</span><span>chunks</span><span>(</span><span>64</span><span>) {</span></span>
<span data-line=""><span>        let</span><span> mut</span><span> chunk_results</span><span> = </span><span>Vec</span><span>::</span><span>new</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>        for</span><span> matching_path</span><span> in</span><span> matching_paths_chunk</span><span> {</span></span>
<span data-line=""><span>            // .... opens each file....</span></span>
<span data-line=""><span>            let</span><span> buffer</span><span> = </span><span>this</span><span>.</span><span>update</span><span>(&amp;</span><span>mut</span><span> cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>                this</span><span>.</span><span>open_buffer</span><span>((*</span><span>worktree_id</span><span>, </span><span>path</span><span>.</span><span>clone</span><span>()), </span><span>cx</span><span>)</span></span>
<span data-line=""><span>            })?;</span></span>
<span data-line=""> </span>
<span data-line=""><span>            // ... and pushes into `chunk_results` a Task that</span></span>
<span data-line=""><span>            // runs on the main thread and ...</span></span>
<span data-line=""><span>            chunk_results</span><span>.</span><span>push</span><span>(</span><span>cx</span><span>.</span><span>spawn</span><span>(|</span><span>cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>                // ... waits for the file to be opened ...</span></span>
<span data-line=""><span>                let</span><span> buffer</span><span> = </span><span>buffer</span><span>.</span><span>await</span><span>?;</span></span>
<span data-line=""><span>                // ... creates a snapshot of its contents ...</span></span>
<span data-line=""><span>                let</span><span> snapshot</span><span> = </span><span>buffer</span><span>.</span><span>read_with</span><span>(&amp;</span><span>cx</span><span>, |</span><span>buffer</span><span>, </span><span>_</span><span>| </span><span>buffer</span><span>.</span><span>snapshot</span><span>())?;</span></span>
<span data-line=""><span>                // ... and again starts a Task on the background executor,</span></span>
<span data-line=""><span>                // which searches through the snapshot for all results.</span></span>
<span data-line=""><span>                let</span><span> ranges</span><span> = </span><span>cx</span></span>
<span data-line=""><span>                    .</span><span>background_executor</span><span>()</span></span>
<span data-line=""><span>                    .</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>                        query</span></span>
<span data-line=""><span>                            .</span><span>search</span><span>(&amp;</span><span>snapshot</span><span>, </span><span>None</span><span>)</span></span>
<span data-line=""><span>                            .</span><span>await</span></span>
<span data-line=""><span>                            .</span><span>iter</span><span>()</span></span>
<span data-line=""><span>                            .</span><span>collect</span><span>::&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;()</span></span>
<span data-line=""><span>                    })</span></span>
<span data-line=""><span>                    .</span><span>await</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>                Ok</span><span>((</span><span>buffer</span><span>, </span><span>ranges</span><span>))</span></span>
<span data-line=""><span>            }));</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""> </span>
<span data-line=""><span>        // On the main thread, non-blocking, wait for all buffers to be searched...</span></span>
<span data-line=""><span>        let</span><span> chunk_results</span><span> = </span><span>futures</span><span>::</span><span>future</span><span>::</span><span>join_all</span><span>(</span><span>chunk_results</span><span>).</span><span>await</span><span>;</span></span>
<span data-line=""><span>        for</span><span> result</span><span> in</span><span> chunk_results</span><span> {</span></span>
<span data-line=""><span>            if</span><span> let</span><span> Some</span><span>((</span><span>buffer</span><span>, </span><span>ranges</span><span>)) = </span><span>result</span><span>.</span><span>log_err</span><span>() {</span></span>
<span data-line=""><span>                // send the results over the results channel</span></span>
<span data-line=""><span>                result_tx</span></span>
<span data-line=""><span>                    .</span><span>send</span><span>(</span><span>SearchResult</span><span>::</span><span>Buffer</span><span> { </span><span>buffer</span><span>, </span><span>ranges</span><span> })</span></span>
<span data-line=""><span>                    .</span><span>await</span><span>?;</span></span>
<span data-line=""><span>            }</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>})</span></span>
<span data-line=""><span>.</span><span>detach</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>result_rx</span></span></code></pre></div></figure>
<p>It's a lot of code — sorry! — but there's not a lot more going on than the concepts we already talked about. What's noteworthy here and why I wanted to show it is the ping-pong between the main thread and background threads:</p>
<ul>
<li><strong>main thread</strong>: kicks off the search and hands the <code>query</code> over to background thread</li>
<li><strong>background thread</strong>: finds files in project with &gt;1 occurrences of <code>query</code> in them, sends results back over channel as they come in</li>
<li><strong>main thread</strong>: waits until background thread has found <code>MAX+1</code> results, then drops channel, which causes background thread to exit</li>
<li><strong>main thread</strong>: spawns multiple other main-thread tasks to open each file &amp; create a snapshot.</li>
<li><strong>background threads</strong>: search through buffer snapshot to find all results in a buffer, sends results back over channel</li>
<li><strong>main thread</strong>: waits for background thread to find results in all buffers, then sends them back to the caller of the outer <code>search_local</code> method</li>
</ul>
<p>Even though this method can be optimized and the search made a lot faster (we haven't gotten around to that yet), it can already search thousands of files without blocking the main thread, while still using multiple CPU cores.</p>
<h2 id="async-friendly-data-structures-testing-executors-and-more"><span data-br=":R1inbrrrqbf9la:" data-brr="1">Async-Friendly Data Structures, Testing Executors, and More</span></h2>
<p>I'm pretty sure that the previous code excerpt raised a lot of questions that I haven't answered yet: how exactly is it possible to send a buffer snapshot to a background thread? How efficient is it do that? What if I want to modify such a snapshot on another thread? How do you test all this?</p>
<p>And I'm sorry to say that I couldn't fit all of the answers into this post. But there is a <a href="https://youtu.be/gkU4NGSe21I">companion video</a> in which Antonio and I did dive into a lot of these areas and talked about async-friendly data structures, copy-on-write buffer snapshots, and other things. Antonio also gave <a href="https://www.youtube.com/watch?v=ms8zKpS_dZE">a fantastic talk about how we do property-testing of async Rust code</a> in the Zed code base that I highly recommend. I also promise that in the future there will be a post about the data structures underlying the Zed editor.</p>
<p>Until next time!</p><hr></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fairbuds: In-ear with replaceable batteries (155 pts)]]></title>
            <link>https://shop.fairphone.com/fairbuds</link>
            <guid>39981550</guid>
            <pubDate>Tue, 09 Apr 2024 17:09:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shop.fairphone.com/fairbuds">https://shop.fairphone.com/fairbuds</a>, See on <a href="https://news.ycombinator.com/item?id=39981550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrap">
            
            <div data-snippet="s_fp_fairbuds_001" data-name="Fairbuds 001">
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/circle_blue.svg" loading="eager">
                    <img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/square_blue_2.svg" loading="eager"></p><h4>FAIRBUDS</h4>
                    <h2>Premium Sound. Designed to last.</h2>
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/330.webp" loading="lazy" data-bs-original-title="" title="" aria-describedby="tooltip343461">
                    </p>
                    <p>Meet the world's most repairable premium earbuds.</p>
                    <p><span data-fp-product-id="502">0.00</span>
                        <span>plus shipping costs from € 3.95</span>
                    </p>
                    <p><a href="https://shop.fairphone.com/shop/aufear-ww1-fairphone-true-wireless-earbuds-406#attr=119" data-bs-original-title="" title="" aria-describedby="popover696845">buy now</a>
                </p></div>
            <div id="section1" data-snippet="s_fp_fairbuds_002" data-name="Fairbuds 002">
                    <h2>Keep what you love for longer</h2>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/304.webp" loading="lazy">
                        <i data-fp-youtube-popup="fp_js_youtube_popup_16" data-fp-youtube-id="NkTYn8n_W64"></i></p>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_003" data-name="Fairbuds 003">
                        <p><i></i>
                            <span>Long-lasting with a three-year warranty</span>
                        </p>
                        <p><i></i>
                            <span>14-day trial period with 100% full refund</span>
                        </p>
                        <p><i></i>
                            <span>Replaceable batteries inside buds and charging case</span>
                        </p>
                    </div>
            <div>
                <h2>Iconic design. Available in two colors.</h2>
                
            </div>
            <div id="section2" data-snippet="s_fp_fairbuds_005" data-name="Fairbuds 005">
                    <h2>Premium sound</h2>
                    
                    <div>
                        <h4>FINE-TUNED FOR PERFECTION</h4>
                        <div>
                            <div>
                                    <h5>Active Noise Canceling</h5>
                                    <p>Immerse yourself in your music. Or stay connected to the world around you. It's up to you.</p>
                                </div>
                            <div>
                                    <h5>TITANIUM DRIVERS</h5>
                                    <p>The titanium-coated 11mm premium drivers deliver a one-of-a-kind listening experience, with rich, well-balanced sound profiles.
                                    </p>
                                </div>
                            <div>
                                    <h5>Seamless dual point connectivity</h5>
                                    <p>Stay connected to multiple devices simultaneously and switch between them hassle-free.</p>
                                </div>
                            <div>
                                    <h5>Dedicated app For iOS and Android
                                    </h5>
                                    <p>Pick your favorite presets, customize EQ settings just how you like it, and get all the latest software updates.</p>
                                </div>
                        </div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_006" data-name="Fairbuds 006">
                        <p>Up to 6 hours of listening in a single charge and 20 additional hours with charging case.</p>
                        </div>
            <div data-snippet="s_fp_fairbuds_007" data-name="Fairbuds 007">
                    <h2>Designed to last.</h2>
                    
                    <div>
                        <h4>Built for living worry-free</h4>
                        <div>
                            <div>
                                    <h5>3 year Warranty</h5>
                                    <p>Your Fairbuds come standard with a two year warranty.We're extending that by another year. Because we've got your
                                        back.
                                    </p>
                                </div>
                            <div>
                                    <h5>Easily Repairable</h5>
                                    <p>It was about time the True Wireless Earbuds category got the signature Fairphone treatment: Built to last and
                                        fully repairable.
                                    </p>
                                </div>
                            <div>
                                    <h5>Replaceable Batteries</h5>
                                    <p>Old batteries should never be the end of your earbuds. That's why we designed the Fairbuds with replaceable
                                        batteries - in the charging case and both buds!
                                    </p>
                                </div>
                            <div>
                                    <h5>IP54 Sweat and Water Resistance</h5>
                                    <p>It always rains in Amsterdam - so of course these had to be weatherproof. That also makes them great for working
                                        out.
                                    </p>
                                </div>
                        </div>
                    </div>
                </div>
            <section data-snippet="s_fp_fairbuds_008" data-name="Fairbuds 008">
                <div>
                    <h2>Small size. Big impact.</h2>
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/326.webp" loading="lazy">
                    </p>
                    <div>
                        <h2>Small size. Big impact.</h2>
                        <div>
                            <ul>
                                <li>Made with fair and recycled materials</li>
                                <li>Made in fair factories</li>
                                <li>Climate conscious and electronic waste neutral</li>
                            </ul>
                            <p><span data-fp-light-box="light_box_16">
                                <i></i>
                                <span>More about our fair approach</span>
                            </span>
                        </p></div>
                    </div>
                </div>
                <div id="light_box_16">
                            <h2>Small size. Big impact.</h2>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/326.webp" loading="lazy">
                                </p>
                                <h3>Made with fair and recycled materials</h3>
                                <p>We integrate Fairtrade Gold into the Fairbuds’ supply chain and invest in Fairmined Gold Credits, Fairtrade Silver Credits and Cobalt Credits to account for the Fairbuds’ gold, silver and cobalt footprint. They also contain recycled materials such as rare earth elements and post-consumer recycled plastic.
                                </p>
                            </div>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/112.png" loading="lazy">
                                </p>
                                <h3>Made in fair factories</h3>
                                <p>The people who help to assemble the Fairbuds are paid a living wage bonus that helps to bridge the gap between minimum wage and a decent salary. Plus they get an active voice in improving working conditions with factory management.
                                </p>
                            </div>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/327.webp" loading="lazy">
                                </p>
                                <h3>Electronic waste neutral</h3>
                                <p>The Fairbuds are electronic waste neutral. What does this mean? The Fairbuds weigh 78 grams with the charging case. So, for every
                                    Fairbuds we put out into the world, we make it a point to responsibly collect and recycle 78 grams of electronic waste.
                                </p>
                            </div>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/328.webp" loading="lazy">
                                </p>
                                <h3>Climate conscious</h3>
                                <p>Like all our products, the Fairbuds were designed to be climate conscious. The Fairbuds are designed to last really long, thanks to its modular approach. The longer it lasts, the less impact on climate it has. It uses recycled materials in the production process, reducing carbon emissions. For the remaining emissions, we invest in Gold Standard-certified carbon reduction projects.
                                </p>
                            </div>
                        </div>
            </section>
            <div data-snippet="s_fp_fairbuds_009" data-name="Fairbuds 009">
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/square_linear_gradient_3.svg" loading="lazy">
                    <img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/circle_blue.svg" loading="lazy"></p><h2>Your sound. Uninterrupted.</h2>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/322.webp" loading="lazy">
                            <i></i>
                        </p>
                        <div>
                            <h3>Active Noise Cancelling for the win</h3>
                            <p>For pristine sound in less than perfect conditions, switch on ANC with advanced wind noise reduction.</p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/323.webp" loading="lazy">
                            <i></i>
                        </p>
                        <div>
                            <h3>Crystal Clear Calls Always</h3>
                            <p>Say hello to clearer phone calls and voice recordings, thanks to Environmental Noise Canceling (ENC), powered by a six-microphone array
                                that vastly reduces background noise.
                            </p>
                        </div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_010" data-name="Fairbuds 010">
                    <h2>Easy to use. Easy to control.</h2>
                    
                    <div>
                        <h3>A dedicated mobile app to customise your Fairbuds</h3>
                        <div>
                            <div>
                                    <h5>CUSTOMIZE YOUR EQ SETTINGS</h5>
                                    <p>It’s time to own your sound. Get maximum control over how your Fairbuds sound with the fully customizable eight-band equalizer.
                                        Or take it easy with one of our presets.
                                    </p>
                                </div>
                            <div>
                                    <h5>KEEP YOUR BUDS UPDATED</h5>
                                    <p>You can also use the app to download and install the latest firmware updates for your Fairbuds.</p>
                                </div>
                        </div>
                        
                    </div>
                </div>
            
            <div data-snippet="s_fp_fairbuds_012" data-name="Fairbuds 012">
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/331.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Get the perfect fit</h3>
                            <p>Because one size shouldn’t fit all. Choose from three different ear tip options and find the one that fits the best.</p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/334.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Connect to more devices</h3>
                            <p>Connect to multiple devices and let the Fairbuds do the work for you. The Fairbuds will know where the music is playing, so you can sit
                                back and enjoy.
                            </p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/332.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Auto play and pause</h3>
                            <p>The Fairbuds know when they're in your ear. Take them out and your song will pause, put them back in and you won't miss a beat.</p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/333.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Dual audio controls</h3>
                            <p>Control your favorite playlist straight from your Fairbuds. Adjusting the volume and playback is right at your fingertips.</p>
                        </div>
                    </div>
                </div>
            
            <div id="section3" data-snippet="s_fp_fairbuds_014" data-name="Fairbuds 014">
                    <h2>The specs at a glance</h2>
                    <p>The Fairbuds are made for all your listening and wireless needs.</p>
                    <div>
                        <section data-name="Item row">
                            <p>
                                <h5>Controls</h5>
                            </p>
                            <div>
                                <ul>
                                    <li>Capacitive Touch Controls (Both Earbuds)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Bluetooth &amp; wireless</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Bluetooth: v5.3 (Profiles A2DP V1.2, AVRCP V1.5, HFP V1.8, HSP V1.2;)</li>
                                    <li>Multipoint Connection (Dual)</li>
                                    <li>Codec: SBC &amp; AAC</li>
                                    <li>Wireless Range: up to 10M (line of sight)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <p>
                                <h5>Connectors &amp; charging</h5>
                            </p>
                            <div>
                                <ul>
                                    <li>USB Type-C</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Battery</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Battery capacity: 45mAh (earbuds) 500mAh (charging case)</li>
                                    <li>Number of cycles: &gt;500 cycles</li>
                                    <li>Charging time: ~2 hours (case + earbuds), 10 min for 1.5h playback</li>
                                    <li>Total playtime (with case): Up to 26 hours</li>
                                    <li>Calling / Music time: Up to 5 hours (ANC on)/ Up to 6 hours (ANC off)</li>
                                    <li>Wireless charging: No</li>
                                    <li>Replaceable battery: Yes (both earbuds and case)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>SOUND</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Driver Diameter: 11mm</li>
                                    <li>Driver type: Titanium coated, dynamic driver</li>
                                    <li>Sensitivity: 104±1dB at 1KHZ</li>
                                    <li>Frequency Response Range: 20Hz -20KHz</li>
                                    <li>Driver impedance: 16Ω ±15%</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Microphone</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Total of 6 mics: 3 left, 3 right</li>
                                    <li>Smart assistants: Google Assistant, Apple Siri</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <p>
                                <h5>Weather resistant</h5>
                            </p>
                            <div>
                                <ul>
                                    <li>IP54 rating (light rain and sweat)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Product dimensions</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Earbud: 28.7mm*24.6mm*21mm</li>
                                    <li>Case: 65mm*65mm*27mm</li>
                                    <li>Weight: 78g including case; earbuds ~5g</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Compatibility</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Compatible with Fairphone 3, 3+, 4 and 5</li>
                                    <li>Compatible with any device with Bluetooth</li>
                                </ul>
                            </div>
                        </section>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_015" data-name="Fairbuds 015">
                    <h2>Included in the box</h2>
                    <p>Everything you need to get started. No more. No less.</p>
                    <div>
                        <div>
                            <p><span>1</span></p><div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/335.webp" loading="lazy">
                                </p>
                                <p><span>Fairbuds and charging case</span>
                            </p></div>
                        </div>
                        <div>
                            <p><span>2</span></p><div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/336.webp" loading="lazy">
                                </p>
                                <p><span>Three ear tips</span>
                            </p></div>
                        </div>
                        <div>
                            <p><span>3</span></p><div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/337.webp" loading="lazy">
                                </p>
                                <p><span>Quick-start guide</span>
                            </p></div>
                        </div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_016" data-name="Fairbuds 016">
                    <h3>Some things are not in the box, and here’s why:</h3>
                    <p>We do not include a <a data-bs-original-title="" title="" href="https://shop.fairphone.com/shop/usb-c-3-2-long-life-cable-5?category=5#attr=" target="_blank">USB Cable</a> or <a data-bs-original-title="" title="" href="https://shop.fairphone.com/shop/dual-port-30-w-charger-eu-6?category=5#attr=" target="_blank">charger</a> in this box because we believe that it’s better to
                        save the environment through the reduction of plastic waste. Of course, it’s possible to buy one of these products if you need it.
                    </p>
                </div>
            <div data-snippet="s_fp_fairbuds_017" data-name="Fairbuds 017">
                    <h2>Get your Fairbuds today</h2>
                    <div>
                        <div>
                            
                            
                            <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/338.webp" loading="lazy">
                                <img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/339.webp" loading="lazy">
                            </p>
                        </div>
                        <div>
                            <h5>FAIRBUDS</h5>
                            <ul>
                                <li>Titanium coated 11mm drivers</li>
                                <li>Active Noise Cancellation with advanced wind reduction</li>
                                <li>Modular and easy to repair with replaceable buds and batteries</li>
                            </ul>
                            <div>
                                <p><span data-fp-product-id="502">£129.00</span>
                                    <span data-fp-product-id="502">£129.00</span>
                                </p>
                                <p>plus shipping costs from € 3.95</p>
                            </div>
                            <p><a href="https://shop.fairphone.com/shop/aufear-ww1-fairphone-true-wireless-earbuds-406#attr=119" data-bs-original-title="" title="">buy now</a>
                        </p></div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_003" data-name="Fairbuds 003">
                        <p><i></i>
                            <span>Long-lasting with a three-year warranty</span>
                        </p>
                        <p><i></i>
                            <span>14-day trial period with 100% full refund</span>
                        </p>
                        <p><i></i>
                            <span>Replaceable batteries inside buds and charging case</span>
                        </p>
                    </div>
            <div data-snippet="s_fp_wwwww_024" data-name="wwwww 024">
                    <h2>Frequently asked questions</h2>
                    <div>
                        <section>
                            <h5>Why have you launched the Fairbuds?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_1"></i>
                            <p>Our mission at Fairphone is to establish a viable market for sustainable consumer electronics. Many of the problems that we see with smartphones, especially around e-waste and issues in the supply chain, also apply to audio products. In 2021, the Fairphone TWS earbuds were our first step into this new product category. They incorporated longer battery life and Fairtrade gold in the supply chain, but were, otherwise, an off-the-shelf design that was not repairable. Our plan was therefore always to improve on the design later on. The Fairbuds are the result of these efforts.
                                </p>
                        </section>
                        <section>
                            <h5>What warranty do you offer on the Fairbuds?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_2"></i>
                            <p>There is a standard 2-year warranty on the earbuds, plus a one-year extended warranty if users register their Fairbuds online. That said, due to the modular design and the repairability, we expect the Fairbuds to last a lot longer than three years.
                                </p>
                        </section>
                        <section>
                            <h5>Which parts of the Fairbuds can be repaired or exchanged by the user?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_3"></i>
                            <div id="faq_collapse_tab_3">
                                <p>Earbud (Left and/or Right)</p><p>Earbud Battery and Silicon Ring</p><p>Earbud Tips</p><p>Charging Case Outer Shell</p><p>Charging Case Core</p><p>Charging Case Battery</p></div>
                        </section>
                        <section>
                            <h5>Are the Fairbuds water-resistant/waterproof?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_4"></i>
                            <p>The Fairbuds have IP54 certification, meaning they are sweat and weather resistant, but not completely waterproof.
                                </p>
                        </section>
                        <section>
                            <h5>What is the Fairbuds app used for?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_5"></i>
                            <p>The Fairbuds app offers users more control over their earbuds, allowing you to change equalizer presets and tune your Fairbuds to your personal preferences. You can use the app to access the latest Fairbuds updates as well, ensuring better longevity of your device, with potentially new features, and the occasional bug-fix.  The app also offers users a quick start guide, tutorials, support articles and a customer service touchpoint. Learn more about the different components that make up your Fairbuds, and order replacement parts through the app if your Fairbuds are in need of repairs.</p>
                        </section>
                        
                        
                        
                        
                        
                    </div>
                </div>
            <div data-snippet="s_fp_home_010" data-name="Home 010">
                        <p>
                            <h2>Best in green electronics</h2>
                            
                        </p>
                        <div>
                            <h5>OUR IMPACT</h5>
                            <p>There are more phones than people. And behind every device is a complex supply chain. With suppliers, local communities and the wider industry, we work for fairer materials and more responsible practices. Showing the electronics industry that we can do better.
                            </p>
                            <p>Together we’re disrupting the industry’s short-term thinking that the world can no longer afford. And changing what it means to be “best.”</p>
                        </div>
                    </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peter Higgs, physicist who discovered Higgs boson, has died (449 pts)]]></title>
            <link>https://www.theguardian.com/science/2024/apr/09/peter-higgs-physicist-who-discovered-higgs-boson-dies-aged-94</link>
            <guid>39981034</guid>
            <pubDate>Tue, 09 Apr 2024 16:21:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/science/2024/apr/09/peter-higgs-physicist-who-discovered-higgs-boson-dies-aged-94">https://www.theguardian.com/science/2024/apr/09/peter-higgs-physicist-who-discovered-higgs-boson-dies-aged-94</a>, See on <a href="https://news.ycombinator.com/item?id=39981034">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Peter Higgs, the Nobel prize-winning physicist who discovered a new particle known as the <a href="https://www.theguardian.com/science/higgs-boson" data-link-name="in body link" data-component="auto-linked-tag">Higgs boson</a>, has died.</p><p>Higgs, 94, who was awarded the Nobel prize for physics in 2013 for his work in 1964 showing how the boson helped bind the universe together by giving particles their mass, died at home in <a href="https://www.theguardian.com/uk/edinburgh" data-link-name="in body link" data-component="auto-linked-tag">Edinburgh</a> on Monday.</p><p>After a series of experiments, which began in earnest in 2008, his theory was proven by physicists working at the Large Hadron Collider at Cern in Switzerland in 2012; the Nobel prize was shared with François Englert, a Belgian theoretical physicist whose work in 1964 also contributed directly to the discovery.</p><figure id="103dd219-b7ee-484e-a783-720a5d0d08b1" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Peter Higgs interview: ‘I have this kind of underlying incompetence’&quot;,&quot;elementId&quot;:&quot;103dd219-b7ee-484e-a783-720a5d0d08b1&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/science/2013/dec/06/peter-higgs-interview-underlying-incompetence&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>A member of the Royal Society and a Companion of Honour, Higgs spent the bulk of his professional life at Edinburgh University, which set up the Higgs centre for theoretical physics in his honour in 2012.</p><p>Prof Peter Mathieson, the university’s principal, said: “Peter Higgs was a remarkable individual – a truly gifted scientist whose vision and imagination have enriched our knowledge of the world that surrounds us.</p><p>“His pioneering work has motivated thousands of scientists, and his legacy will continue to inspire many more for generations to come.”</p><p>Prof Fabiola Gianotti, the director general at Cern and former leader of the Atlas experiment, which helped discover the Higgs particle in 2012, said: “Besides his outstanding contributions to particle physics, Peter was a very special person, a man of rare modesty, a great teacher and someone who explained physics in a very simple and profound way.</p><p>“An important piece of Cern’s history and accomplishments is linked to him. I am very saddened, and I will miss him sorely.”</p><p>The evening before the discovery of the particle was announced, Peter was invited to a small celebration at the home of John Ellis, the former head of theory at Cern. “A giant of particle physics has left us,” Ellis told the Guardian. “Without his theory, atoms could not exist and radioactivity would be a force as strong as electricity and magnetism.</p><p>“His prediction of the existence of the particle that bears his name was a deep insight, and its discovery at Cern in 2012 was a crowning moment that confirmed his understanding of the way the Universe works.”</p><p>Jon Butterworth, a member of the Atlas collaboration, said Higgs was “a hero to the particle physics community”.</p><p>“Even though he didn’t much enjoy it, he felt a responsibility to use the public profile his achievements brought him for the good of science, and he did so many times. The particle that carries his name is perhaps the single most stunning example of how seemingly abstract mathematical ideas can make predictions which turn out to have huge physical consequences.”</p><p>The Royal Swedish Academy of Sciences, which awards the Nobel, said at the time the standard model of physics which underpins the scientific understanding of the universe “rests on the existence of a special kind of particle: the Higgs particle. This particle originates from an invisible field that fills up all space.</p><p>“Even when the universe seems empty this field is there. Without it, we would not exist, because it is from contact with the field that particles acquire mass. The theory proposed by Englert and Higgs describes this process.”</p><p>An immensely shy man who disliked the fuss, Higgs had left home for a quiet lunch of soup and trout in Leith on the day of the announcement, to be stopped by a former neighbour who gave him the news on his way home.</p><p>Born in Newcastle upon Tyne, Higgs leaves two sons, Chris and Jonny, his daughter-in-law Suzanne and two grandchildren. His wife, Jody, a linguistics lecturer from whom he was separated, died in 2008.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel Gaudi 3 AI Accelerator (198 pts)]]></title>
            <link>https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html</link>
            <guid>39981032</guid>
            <pubDate>Tue, 09 Apr 2024 16:21:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html">https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html</a>, See on <a href="https://news.ycombinator.com/item?id=39981032">Hacker News</a></p>
<div id="readability-page-1" class="page">


















    
    
    
        















    
    
        
        
        
        
        
        
        
    




    
    
        
    




    
    
    
    
        
    


    
    
        
    


    
    
        
    


    
        
    
    






























    


    

































    
        <div data-component="global-nav-redesign" data-component-id="1">
            <header role="banner">
                <nav role="navigation" aria-label="main navigation" data-igm="">
                    <!-- Brand and toggle get grouped for better mobile display -->
                    <div>

                        <div>
                            <a href="https://www.intel.com/content/www/us/en/homepage.html" alt="Intel homepage">
                                    
                                <img src="https://www.intel.com/content/dam/logos/intel-header-logo.svg" height="300" width="118" alt="Intel logo - Return to the home page">
                            </a>
                        </div>

                        

                        <!-- START MOBLE TOGGLE buttons -->
                        <div>


                            <!-- START: NON-signed in panel -->
                            <span id="not-logged-in-scenario">

    
        </span>


                            


















































<span id="logged-in-scenario">






</span>

                            
















    




<div id="panel-language-selector" aria-expanded="false" aria-selected="false">
                <h2>
                    
                        
                            Select Your Language
                        
                        
                    
                </h2>
            </div>


                            <!-- END: NON-sign in panel -->
                            

























    

    



    








    











    
    
    
        
    


    
    <div aria-live="off" id="simplify-search" data-component="wa_skip_track" data-igm-search-content="" document-height="true">
                             
                                 
                            
                            <!-- Search Result Typeahead -->
                            <div id="igm-search-result" data-igm-search-results="">
                                    
                                        Sign In to access restricted content
                                </div>
                            <!-- Recent Searches: 1) display default search info if no search terms is available  -->
                            <!-- Recent Searches: 2) display recenter terms when available and hide default search info  -->
                            <div data-igm-search-related="">
                                <div>
                                    <!-- default search info -->
                                    <div>
                                        <h3>Using Intel.com Search</h3>
                                        <p>You can easily search the entire Intel.com site in several ways.</p>
                                        <ul>
                                            <li>
                                                Brand Name:
                                                <strong>
                                                    Core i9
                                                </strong>
                                            </li>
                                            <li>
                                                Document Number:
                                                <strong>
                                                    123456
                                                </strong>
                                            </li>
                                            <li>
                                                Code Name:
                                                <strong>
                                                    Emerald Rapids
                                                </strong>
                                            </li>
                                            <li>
                                                Special Operators:
                                                <strong>
                                                    “Ice Lake”, Ice AND Lake, Ice OR Lake, Ice*
                                                </strong>
                                            </li>
                                        </ul>
                                    </div>
                                    <!-- quick links is always visible on the recents overlay -->
                                    <div>
                                        <h3>Quick Links</h3>
                                        <p>You can also try the quick links below to see results for most popular searches.</p>
                                        <ul>
                                            <!--<li>
                                                <a class="quick-link" rel="noopener noreferrer"
                                                   href=https://ark.intel.com?wapkw=quicklink:product-specifications>
                                                    Product Specifications
                                                </a>
                                            </li>-->
                                            <li>
                                                <a rel="noopener noreferrer" href="https://www.intel.com/content/www/us/en/products/overview.html?wapkw=quicklink:products">
                                                    Product Information
                                                </a>
                                            </li>
                                            <li><a rel="noopener noreferrer" href="https://www.intel.com/content/www/us/en/support.html?wapkw=quicklink:support">
                                                Support
                                            </a>
                                            </li>
                                            <li>
                                                <a rel="noopener noreferrer" href="https://downloadcenter.intel.com/?wapkw=quicklink:download-center">
                                                    Drivers &amp; Software
                                                </a>
                                            </li>
                                        </ul>
                                    </div>
                                    <!-- recent search terms -->
                                    <div data-component="wa_skip_track" data-component-id="1">
                                            <h3>Recent Searches</h3>
                                        </div>
                                </div>
                                <div>
                                    
                                        Sign In to access restricted content
                                </div>
                            </div>
                            
                                 <div data-igm-advanced-search="">
											<div data-component="wa_skip_track" data-component-id="1">
													<h3>Advanced Search</h3>
													<div>
															<h3>Only search in</h3>
															<div aria-label="Only Search In">
																<label for="search_title">
																	
																	Title</label>

																	<label for="search_description">
																	
																Description</label>

																	<label for="search_id">
																	Content ID</label>
															</div>

															
														</div>
												</div>
											<div>
												Sign in to access
												restricted content.
											</div>
										</div>
                                    
                        </div>


                        </div>
                        <!-- END MOBILE TOGGLE buttons -->
                    </div>
                </nav>
            </header>
        </div>

    
    


<div id="alertMsg" data-scroll-track="false">
                        <p>The browser version you are using is not recommended for this site.<br>Please consider upgrading to the latest version of your browser by clicking one of the following links.</p>
                        <div>
                            <ul>
                                
                                    <li><a href="https://support.apple.com/downloads/safari">Safari</a></li>
                                
                                    <li><a href="https://support.google.com/chrome/answer/95346?hl=en">Chrome</a></li>
                                
                                    <li><a href="https://www.microsoft.com/en-us/edge">Edge</a></li>
                                
                                    <li><a href="https://www.mozilla.org/en-US/firefox/new/">Firefox</a></li>
                                
                            </ul>
                        </div>
                    </div>


<main id="primary-content">


























    
        
        
        <main id="primary-content-main">
            

            <div id="articleHero-1" data-component="articleHero" data-component-id="1">
                                                
                                                
                                                    
                                                        <h2>Intel Breaks Down Proprietary Walls to Bring Choice to Enterprise GenAI Market</h2>
                                                    
                                                    
                                                
                                                <div>
                                                    
                                                        <p>Intel Gaudi 3 AI accelerator brings global enterprises choice for generative AI, building on the performance and scalability of its Gaudi 2 predecessor.</p>

                                                    
                                                </div>
                                                
                                            </div>
            <article data-component-id="1" data-component="articletemplate">
                <div>
                            <div>

                                

                                <!-- duplicated from articlehero for vertical layout -->
                                
                                    
                                    
                                        
                                    
                                

                                
                                <!-- BUILT IN - ARTICLE INTRO COMPONENT -->
                                <!-- duplicated from right column for mobile layout -->
                                
                                <!-- END IN - ARTICLE INTRO COMPONENT -->

                                <!-- BUILT IN - ARTICLE TAKEAWAY COMPONENT -->

                                <div data-component="articleTakeaway" id="articleTakeaway-1" data-component-id="1">
                        <h2>News</h2>
                        <ul>
                            
                                
                                    <li><p>April 9, 2024</p>
                                    </li>
                                
                            
                                
                                    <li><p><a href="https://www.intel.com/content/www/us/en/newsroom/contact-public-relations-team.html">Contact Intel PR</a></p>
                                    </li>
                                
                            
                                
                                    <li><h4><strong>Follow Intel Newsroom on social:</strong></h4>

                                    </li>
                                
                            
                        </ul>
                    </div>

                                

                                <!-- only display this for authored pages and not salesforce pages-->
                                <div>
                                        
                                        <img src="" alt="author-image">
                                    </div>

                            </div>

                            <div>


<div id="articleparagraph-2" data-component="articleparagraph" data-component-id="2">
                                
                                
                                    
                                    
                                        <p><strong>What’s New:</strong>&nbsp; At Intel Vision, Intel introduces the Intel® Gaudi® 3 AI accelerator, which delivers 4x AI compute for BF16,&nbsp; 1.5x increase in memory bandwidth, and 2x networking bandwidth for massive system scale out compared to its predecessor – a significant leap in performance and productivity for AI training and inference on popular large language models (LLMs) and multimodal models. Building on the proven performance and efficiency of the Intel® Gaudi® 2 AI accelerator – the <a href="https://www.intel.com/content/www/us/en/newsroom/news/new-gaudi-2-xeon-performance-ai-inference.html" rel="noreferrer noopener" target="_blank">only MLPerf-benchmarked alternative</a> for LLMs on the market – Intel gives customers a choice with open community-based software and industry-standard Ethernet networking to scale their systems more flexibly.&nbsp;</p>

                                    
                                
                            </div>
<div id="articleparagraph-3" data-component="articleparagraph" data-component-id="3">
                                <blockquote>
                                    <p>“In the ever-evolving landscape of the AI market, a significant gap persists in the current offerings. Feedback from our customers and the broader market underscores a desire for increased choice. Enterprises weigh considerations such as availability, scalability, performance, cost, and energy efficiency. Intel Gaudi 3 stands out as the GenAI alternative presenting a compelling combination of price performance, system scalability, and time-to-value advantage.” </p>
                                    
                                    
                                        
                                    
                                </blockquote>
                            </div>
<div id="articleparagraph-4" data-component="articleparagraph" data-component-id="4">
                                
                                
                                    
                                    
                                        <p><strong>Why It Matters: </strong>Today, enterprises across critical sectors such as finance, manufacturing and healthcare are rapidly seeking to broaden accessibility to AI and transitioning generative AI (GenAI) projects from experimental phases to full-scale implementation. To manage this transition, fuel innovation and realize revenue growth goals, businesses require open, cost-effective and more energy-efficient solutions and products that meet return-on-investment (ROI) and operational efficiency needs.&nbsp;</p>

<p>The Intel Gaudi 3 accelerator will meet these requirements and offer versatility through open community-based software and open industry-standard Ethernet, helping businesses flexibly scale their AI systems and applications.&nbsp;&nbsp;</p>

<p><strong>How Custom Architecture Delivers GenAI Performance and Efficiency:</strong>&nbsp;The Intel Gaudi 3 accelerator, architected for efficient large-scale AI compute, is manufactured on a 5 nanometer (nm) process and offers significant advancements over its predecessor.&nbsp; It is designed to allow activation of all engines in parallel — with the Matrix Multiplication Engine (MME), Tensor Processor Cores (TPCs) and Networking Interface Cards (NICs) — enabling the acceleration needed for fast, efficient deep learning computation and scale. Key features include:&nbsp;<br>
&nbsp;</p>

<ul role="list">
	<li aria-setsize="-1" role="listitem">
	<p><strong>AI-Dedicated Compute Engine:</strong> The Intel Gaudi 3 accelerator was purpose-built for high-performance, high-efficiency GenAI compute.&nbsp; Each accelerator uniquely features a heterogenous compute engine comprised of 64 AI-custom and programmable TPCs and eight&nbsp; MMEs. Each Intel Gaudi 3 MME is capable of performing an impressive 64,000 parallel operations, allowing a high degree of computational efficiency, making them adept at handling complex matrix operations, a type of computation that is fundamental to deep learning algorithms. This unique design accelerates speed and efficiency of parallel AI operations and supports multiple data types, including FP8 and BF16.&nbsp;&nbsp;</p>
	</li>
	<li aria-setsize="-1" role="listitem">
	<p><strong>Memory Boost for LLM Capacity Requirements: </strong>128 gigabytes (GB) of HBMe2 memory capacity, 3.7 terabytes (TB) of memory bandwidth and 96 megabytes (MB) of on-board static random access memory (SRAM) provide ample memory for processing large GenAI datasets on fewer Intel Gaudi 3s, particularly useful in serving large language and multimodal models, resulting in increased workload performance and data center cost efficiency.&nbsp;&nbsp;</p>
	</li>
	<li aria-setsize="-1" role="listitem">
	<p><strong>Efficient System Scaling for Enterprise GenAI: </strong>Twenty-four 200 gigabit (Gb) Ethernet ports are integrated into every Intel Gaudi 3 accelerator, providing flexible and open-standard networking. They enable efficient scaling to support large compute clusters and eliminate vendor lock-in from proprietary networking fabrics. The Intel Gaudi 3 accelerator is designed to scale up and scale out efficiently from a single node to thousands to meet the expansive requirements of GenAI models.&nbsp;</p>
	</li>
	<li aria-setsize="-1" role="listitem">
	<p><strong>Open Industry Software for Developer Productivity:</strong> Intel Gaudi software integrates the PyTorch framework and provides optimized Hugging Face community-based models – the most-common AI framework for GenAI developers today. This allows GenAI developers to operate at a high abstraction level for ease of use and productivity and ease of model porting across hardware types.&nbsp;</p>
	</li>
</ul>

<ul role="list">
	<li aria-setsize="-1" role="listitem">
	<p><strong>Gaudi 3 PCIe:</strong> New to the product line is the Gaudi 3 peripheral component interconnect express (PCIe) add-in card. Tailored to bring high efficiency with lower power, this new form factor is ideal for workloads such as fine-tuning, inference and retrieval-augmented generation (RAG). It is equipped as a full-height form factor at 600 watts, with a memory capacity of 128GB and a bandwidth of 3.7TB per second.&nbsp;&nbsp;<br>
	&nbsp;</p>
	</li>
</ul>

<p>Intel Gaudi 3 accelerator will deliver significant performance improvements for training and inference tasks on leading GenAI models. Specifically, the Intel Gaudi 3 accelerator is projected to deliver on average versus Nvidia H100:</p>



<ul>
	<li><strong>50% faster time-to-train</strong><sup>1</sup> across Llama2 7B and 13B parameters, and GPT-3 175B parameter models. &nbsp;</li>
	<li><strong>50% faster inference throughput</strong><sup>2</sup> and <strong>40% greater inference power-efficiency</strong><sup>3</sup> across Llama 7B and 70B parameters, and Falcon 180B parameter models. An even greater inference performance advantage on longer input and output sequences.</li>
	<li><strong>30% faster inferencing</strong><sup>4</sup> on Llama 7B and 70B parameters, and Falcon 180B parameter models against Nvidia H200. &nbsp;</li>
</ul>



<p><strong>About Market Adoption and Availability:</strong>&nbsp;The Intel Gaudi 3 accelerator will be available to original equipment manufacturers (OEMs) in the second quarter of 2024 in industry-standard configurations of Universal Baseboard and open accelerator module (OAM). Among the notable OEM adopters that will bring Gaudi 3 to market are Dell Technologies, HPE, Lenovo and Supermicro. General availability of Intel Gaudi 3 accelerators is anticipated for the third quarter of 2024, and the Intel Gaudi 3 PCIe add-in card is anticipated to be available in the last quarter of 2024.&nbsp;&nbsp;</p>

<p>The Intel Gaudi 3 accelerator will also power several cost-effective cloud LLM infrastructures for training and inference, offering price-performance advantages and choices to organizations that now include NAVER.&nbsp;&nbsp;&nbsp;</p>

<p>Developers can get started today with access to Intel <a href="https://developer.habana.ai/intel-developer-cloud/getting-started-on-the-intel-developer-cloud/?utm_term=&amp;utm_campaign=PMax-+Google&amp;utm_source=adwords&amp;utm_medium=ppc&amp;hsa_acc=1034914560&amp;hsa_cam=21089989807&amp;hsa_grp=&amp;hsa_ad=&amp;hsa_src=x&amp;hsa_tgt=&amp;hsa_kw=&amp;hsa_mt=&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gad_source=1&amp;gclid=Cj0KCQjw2PSvBhDjARIsAKc2cgNPd48lg6eFDhBo6dvmlXhZT20O25FioJwE17vlbrN6C86x51H4vhYaAl2LEALw_wcB" rel="noreferrer noopener" target="_blank">Gaudi 2-based instances</a> on the developer cloud to learn, prototype, test, and run applications and workloads</p>

<p><strong>What’s Next:</strong> Intel Gaudi 3 accelerators' momentum will be foundational for Falcon Shores, Intel’s next-generation graphics processing unit (GPU) for AI and high-performance computing (HPC). Falcon Shores will integrate the Intel Gaudi and Intel® Xe intellectual property (IP) with a single GPU programming interface built on the Intel® oneAPI specification.&nbsp;</p>

<p><strong>More Context:</strong>&nbsp;<a href="https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-enterprise-ai-gaudi-3-open-systems-strategy.html">Intel Unleashes Enterprise AI with Gaudi 3, AI Open Systems Strategy and New Customer Wins</a>&nbsp;(News) | <a href="https://www.intel.com/content/www/us/en/products/details/processors/ai-accelerators/gaudi3.html">Intel Gaudi 3 AI Accelerator</a> (Product Page) | <a href="https://www.intel.com/content/www/us/en/content-details/817486/content-details.html">Intel Gaudi 3 AI Accelerator</a> (White Paper) |&nbsp;&nbsp;<a href="https://www.intel.com/content/www/us/en/newsroom/news/new-gaudi-2-xeon-performance-ai-inference.html">Intel Gaudi 2 Remains Only Benchmarked Alternative to NV H100 for GenAI Performance</a> (News)</p>

                                    
                                
                            </div>
<div id="articleparagraph-5" data-component="articleparagraph" data-component-id="5">
                                
                                
                                    
                                    
                                        <p><sub><strong>The Small Print:&nbsp;</strong></sub></p>

<p><sub>Intel does not control or audit third-party data.  You should consult other sources to evaluate accuracy.&nbsp;</sub></p>

<p><sup>1 </sup><sub>NV H100 comparison based on: <a href="https://developer.nvidia.com/deep-learning-performance-training-inference/training" rel="noreferrer noopener" target="_blank">https://developer.nvidia.com/deep-learning-performance-training-inference/training</a>, Mar 28th 2024  à “Large Language Model” tab Vs Intel® Gaudi® 3&nbsp; projections for LLAMA2-7B, LLAMA2-13B &amp; GPT3-175B as of 3/28/2024. Results may vary&nbsp;</sub></p>

<p><sup>2 </sup><sub>NV H100 comparison based on <a href="https://nvidia.github.io/TensorRT-LLM/performance.html" rel="noreferrer noopener" target="_blank">https://nvidia.github.io/TensorRT-LLM/performance.html#h100-gpus-fp8</a> , Mar 28th, 2024. Reported numbers are per GPU. Vs Intel® Gaudi® 3 projections for LLAMA2-7B, LLAMA2-70B &amp; Falcon 180B projections. Results may vary.&nbsp;</sub></p>

<p><sup>3 </sup><sub>NV comparison based on <a href="https://nvidia.github.io/TensorRT-LLM/performance.html" rel="noreferrer noopener" target="_blank">https://nvidia.github.io/TensorRT-LLM/performance.html#h100-gpus-fp8</a> , Mar 28th, 2024. Reported numbers are per GPU. Vs Intel® Gaudi® 3 projections for LLAMA2-7B, LLAMA2-70B &amp; Falcon 180B Power efficiency for both Nvidia and Gaudi 3 based on internal estimates. Results may vary.&nbsp;&nbsp;</sub></p>

<p><sup>4 </sup><sub>NV H200 comparison based on <a href="https://nvidia.github.io/TensorRT-LLM/performance.html" rel="noreferrer noopener" target="_blank">https://nvidia.github.io/TensorRT-LLM/performance.html#h100-gpus-fp8</a> , Mar 28th, 2024. Reported numbers are per GPU.Vs Intel® Gaudi® 3 projections for LLAMA2-7B, LLAMA2-70B &amp; Falcon 180B projections. Results may vary.&nbsp;</sub></p>

                                    
                                
                            </div>
</div>
                        </div>

                

                
                <div data-component="reference" data-component-id="1" id="reference">
                                
                                
                                    <p><b>About Intel</b></p>
<p>Intel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to <a href="https://newsroom.intel.com/">newsroom.intel.com</a> and <a href="https://www.intel.com/">intel.com</a>.</p>
<p>© Intel Corporation. Intel, the Intel logo and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.</p>
 
                                
                            </div>
                
                    











                
                

            </article>
        </main>
    
    





    




    


</main>












































    







</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beeper acquired by Automattic (WordPress) (346 pts)]]></title>
            <link>https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/</link>
            <guid>39980268</guid>
            <pubDate>Tue, 09 Apr 2024 15:09:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/">https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/</a>, See on <a href="https://news.ycombinator.com/item?id=39980268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<figure><img data-attachment-id="142603683" data-permalink="https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/beeper-only/" data-orig-file="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png" data-orig-size="2608,1471" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="beeper-only" data-image-description="" data-image-caption="" data-medium-file="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=300" data-large-file="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=1024" width="1024" height="577" src="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=1024" alt="" srcset="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=1024 1024w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=2046 2046w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=150 150w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=300 300w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I’m excited to announce that Beeper has been acquired by Automattic. This acquisition marks the beginning of an exciting new chapter as we continue our mission to create the best chat app on earth.</p>







<blockquote>
<p>If you haven’t heard of <a href="https://beeper.com/">Beeper</a> before, welcome! We make a universal chat app – one app to send and receive messages on 14 different chat networks. You might have also heard about Beeper Mini, our briefly available iMessage-on-Android app.</p>
</blockquote>



<p>In many ways, our journey has only just begun. Beeper has just over 115,000 users and was, <a href="https://blog.beeper.com/2024/04/09/beeper-is-now-available/">until today</a>, in beta. Given the state of the messaging landscape today, we believe there is a huge opportunity for us to push boundaries and create new experiences in chat. The majority of other chat apps have stagnated, entrenched in their positions, with <a href="https://twitter.com/ericmigi/status/1761916874227622299">no significant new players</a> emerging since Discord’s launch in 2015. Given the state of the messaging world, we’ve long felt the need for a strong ally with the resources to support us on our quest. Automattic has a long history of putting user control and privacy first with open source, and great bilateral relationships with Meta, Apple, Microsoft, Google, Matrix and others that we hope can usher in a new era of collaboration.</p>



<p>It’s a fantastic match. Automattic is best known for supporting WordPress and WooCommerce – two open source software projects that underpin huge portions of the internet’s publishing and ecommerce infrastructure. Together, we’ll develop software for a third fundamental pillar of the internet: chat.</p>



<p>Matt, Automattic’s CEO, and I have known each other for years. He was an early user, supporter and investor in Beeper. We’re very well aligned on our goal (build the best chat app on earth), approach (open source where possible), and independence (Beeper will operate independently as part of Automattic’s Other Bets division).</p>



<p>This is a big bet. Automattic is doubling down on chat after their acquisition last year of <a href="http://texts.com/">Texts.com</a>, a messaging app with a similar mission. Our teams and products will merge, and I will take on the role leading the team as Head of Messaging. It will take a bit of time for us to integrate and combine forces under the Beeper brand. We’ve got big plans! I’m really excited about the future of chat 📟</p>



<p><strong>Eric Migicovsky</strong></p>



<p>Beeper CEO → Automattic Head of Messaging<br></p>



<hr>



<h3>For Beeper users…</h3>



<ul>
<li>The Beeper app you know and love is only going to get better with the support of Automattic! In fact, today we’re making Beeper available to everyone – no more waitlist. <a href="https://blog.beeper.com/2024/04/09/beeper-is-now-available/">Learn more</a>.</li>



<li>Our privacy policy and terms of service remain the same, though they may change in the future.</li>



<li>As always, Beeper (and now Automattic Inc.) cannot view any of your historical chat history. All messages are encrypted with a key that only you have before being stored. Read more about <a href="https://beeper.com/faq#security-and-privacy">our security and privacy</a> commitments.</li>



<li>Our business model is unchanged. We build a fantastic free chat app, then charge for additional premium features.</li>



<li>If you no longer would like to use Beeper, visit <a href="https://account.beeper.com/">account.beeper.com</a> to delete your account.</li>
</ul>



<h3>For <a href="http://texts.com/">Texts.com</a> users…</h3>



<ul>
<li>Nothing is changing today. Texts is the same product today as it was yesterday.</li>



<li>Beeper and Texts share a common goal of building the best chat app on earth. Texts’ commitment to local data processing will be preserved.</li>



<li>Over time, we will work to integrate the teams and products. More news to come in the future!</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Grafana Loki UI: No LogQL Required (176 pts)]]></title>
            <link>https://grafana.com/blog/2024/04/09/find-your-logs-data-with-explore-logs-no-logql-required/</link>
            <guid>39979750</guid>
            <pubDate>Tue, 09 Apr 2024 14:23:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grafana.com/blog/2024/04/09/find-your-logs-data-with-explore-logs-no-logql-required/">https://grafana.com/blog/2024/04/09/find-your-logs-data-with-explore-logs-no-logql-required/</a>, See on <a href="https://news.ycombinator.com/item?id=39979750">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We are thrilled to announce the preview of Explore Logs, a new way to browse your logs without writing LogQL. In this post, we’ll cover why we built Explore Logs and we’ll dive deeper into some of its features, including at-a-glance breakdowns by label, detected fields, and our new pattern detection. At the end, we’ll tell you how you can try Explore Logs for yourself today.</p><p>But let’s start from the beginning — with good old LogQL.</p><h2 id="we-love-logql">We love LogQL</h2><p>Grafana Loki, Grafana Labs’ <a href="https://github.com/grafana/loki" target="_blank" rel="noopener noreferrer">open source log aggregation project</a>, provides a powerful query language called <a href="https://grafana.com/blog/2022/05/12/10-things-you-didnt-know-about-logql/">LogQL</a>. Site reliability engineers (SREs) and other Loki experts love to use it to filter logs for specific keywords, reduce noise by selecting specific labels, and perform other operations to get answers to understand their systems.</p><p>Metrics can be created from logs, which are put into dashboards to visualize key insights. Alerts can be set up and wired into <a href="https://grafana.com/products/cloud/irm/">Grafana Incident Response &amp; Management</a> (IRM), which includes <a href="https://grafana.com/products/cloud/oncall/">Grafana OnCall</a> and <a href="https://grafana.com/products/cloud/incident/">Grafana Incident,</a> so you can make sure you get early warnings when things go wrong.</p><p>Those same queries can be used to power <a href="https://grafana.com/docs/grafana/latest/panels-visualizations/visualizations/">Grafana dashboard visualizations</a> so you can make sense of your logs. LogQL is really powerful! There’s just one catch …</p><h2 id="but-i-dont-know-logql">‘But I don’t know LogQL!’</h2><p>If you aren’t digging into your logs every day, you might not have had a reason to learn LogQL. Perhaps you dive in now and again, or maybe only during an incident. And even in those moments, having to remember the details of a query language can slow down response times.&nbsp;</p><p>The point is, you come to your logs platform not because you love logs, but because you <em>need</em> logs to do your job. Whether you need them to see a deployment go smoothly, to investigate a latency issue, or to deal with a 4 a.m. page, the last thing you want to do is wrestle with yet another query language.&nbsp;</p><p>If only you could take advantage of all the great benefits Loki + Grafana provides, without needing to learn LogQL. Well, you guessed it: Now you can!</p><h2 id="introducing-explore-logs-a-new-oss-application">Introducing Explore Logs, a new OSS application</h2><p>Explore Logs is our new OSS application that lets you browse your logs as if they were already neatly organized for you in advance. You can find <a href="https://github.com/grafana/explore-logs" target="_blank" rel="noopener noreferrer">the source code on GitHub</a>, but before you head there to try it, allow us to give you a quick tour.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/explore-logs.gif" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/explore-logs.gif" alt="A GIF showing how to use Explore Logs in Grafana"></a></figure><p>When you come into Explore Logs (in the navigation, head over to <strong>Explore</strong> &gt; <strong>Logs</strong>), you are presented with a list of detected services or apps. Engineers no longer have to fight with teams across the organization to standardize on one convention. Instead, we embrace the chaos.</p><p>Services are presented along with their log volumes and a preview of recent log lines, so you can see, at a glance, which services are the most chatty and what kinds of logs they are emitting.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/recent-log-lines.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/recent-log-lines.png" alt="Service log volumes and a preview of recent log lines" data-src="/media/blog/explore-logs/recent-log-lines.png"></a></figure><p>Don’t see the service you are looking for? Simply search for it with the search bar (plain text search, not LogQL).</p><p>As if automatic service detection wasn’t enough, things start to get really interesting when you select a service.</p><h2 id="how-to-breakdown-logs-in-a-service">How to breakdown logs in a service&nbsp;</h2><p>Explore Logs provides tools to further visualize and breakdown a service’s logs by labels, detected fields, and patterns, all while making sure the log lines themselves are always just a click away.</p><ul><li><strong>Labels</strong> are key-value pairs that can be attached to log lines, for example: <code>level=error</code>, <code>environment=prod</code>, <code>app=nginx</code>, <code>team=loki</code></li><li><strong>Detected fields</strong> contain structured key-value pairs extracted automatically from a log line at query time.</li><li><strong>Patterns</strong> are templates automatically derived from the log stream, used to match lines of the same type. New innovations here have led to some powerful capabilities described below.</li></ul><p>Let’s explore (get it?) each of these in turn, and see how Explore Logs makes it easier than ever to make use of these features.</p><h3 id="labels">Labels</h3><p>In Loki, <a href="https://grafana.com/docs/loki/latest/get-started/labels/">labels</a> are key-value pairs that are used to organize and identify log streams. Labels are attached to log streams to help users query, filter, and aggregate logs efficiently. They are similar to tags or metadata in other logging systems.</p><p>Explore Logs creates a log volume chart for each label, allowing you to easily see which are the most active.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/labels.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/labels.png" alt="Log volume charts for each label in Loki" data-src="/media/blog/explore-logs/labels.png"></a></figure><p>Selecting a label shows you a breakdown of the logs per value. For example, log level is broken down into debug, info, warning, error, and critical.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/logs-per-value.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/logs-per-value.png" alt="Logs-per-value panels in Loki" data-src="/media/blog/explore-logs/logs-per-value.png"></a></figure><p>Selecting a value applies the filter (by writing LogQL for you in the background) and immediately jumps to a curated view showing the relevant log lines.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/curated-view.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/curated-view.png" alt="A curated view of log lines" data-src="/media/blog/explore-logs/curated-view.png"></a></figure><h3 id="detected-fields">Detected fields</h3><p>Detected fields in Loki refer to fields that are automatically extracted from log messages when they’re ingested. Loki doesn’t index the content of log lines, but it can parse and extract fields from logs at query time. This feature allows users to query logs more efficiently by using these fields without the need to label every possible attribute as labels, which could be costly and inefficient.</p><p>Explore Logs offers a seamless experience when dealing with detected metadata. A selection of the fields is automatically broken out into a grid view, and you can filter the logs down from there.</p><p>To the end user, the mechanics work nearly identically when working with labels and detected fields, reducing the cognitive overhead of having to remember which is which (and the query syntax associated with each one).</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/detected-fields.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/detected-fields.png" alt="Detected field panels in Loki" data-src="/media/blog/explore-logs/detected-fields.png"></a></figure><h3 id="pattern-matching">Pattern matching</h3><p>Loki extracts log patterns, which helps you understand the different types of log lines produced by your services. Pattern extraction occurs after filtering. For best results, we recommend that you first filter by known values (such as labels, detected fields, and time range) to narrow down the search space and make patterns more useful.</p><p>You can use pattern matching to:</p><ol><li>Understand the kinds of log lines produced by your systems</li><li>Hide noisy or irrelevant lines to quickly narrow down on what’s important</li><li>Focus on specific trends or anomalies by filtering for log lines matching one or more of the patterns</li></ol><p>Explore Logs lets you easily add multiple patterns to your filters, which will include log lines matching any of the selected patterns. You can also exclude a pattern to hide that kind of log line.</p><h4 id="example-use-case-for-pattern-matching">Example use case for pattern matching&nbsp;</h4><p>Say you’re looking for errors among a lot of HTTP traffic logs. It can be tough to spot the individual lines you’re looking for. With patterns, you can simply mute the offending lines by excluding lines of that type at the click of a button.</p><p>Consider the example log lines below. You can clearly see two distinct patterns:</p><div><pre data-expanded="false"><code>code=200 method=get path=/page1 trace_id=123
code=500 method=post path=/page2 trace_id=124
err: code=500 msg=”db connection error” trace_id=124
code=201 method=post path=/page2 trace_id=125
code=200 method=get path=/page1 trace_id=126
code=500 method=post path=/page2 trace_id=127
err: code=500 msg=”db connection error” trace_id=127
code=200 method=get path=/page2 trace_id=128
code=200 method=get path=/page2 trace_id=129
code=500 method=post path=/page2 trace_id=130
err: code=500 msg=”db connection error” trace_id=130</code></pre></div><p>The first pattern describes the HTTP requests:</p><div><pre data-expanded="false"><code>code=&lt;_&gt; method=&lt;_&gt; path=/&lt;_&gt; trace_id=&lt;_&gt;</code></pre></div><p>And the second pattern describes the error lines:</p><div><pre data-expanded="false"><code>err: code=&lt;_&gt; msg=”&lt;_&gt;” trace_id=&lt;_&gt;</code></pre></div><p>The values are stripped away, leaving only string constants and LogQL placeholders that make up the template, or pattern.</p><blockquote><p><strong>Did you know?</strong> In <a href="https://github.com/grafana/loki" target="_blank" rel="noopener noreferrer">Loki 3.0</a>, you can use <a href="https://grafana.com/docs/loki/latest/query/#pattern-match-filter-operators">pattern filters</a> in place of RegExp for a faster query time.</p></blockquote><h2 id="what-else-can-you-do-with-explore-logs">What else can you do with Explore Logs?</h2><p>In addition to everything we’ve already covered, there are a few other notable Explore Logs features to call out:</p><h3 id="search">Search</h3><p>Maybe LogQL is hard, but text search is not. Plain text, case-sensitive search of your rendered log lines can come in handy when you’ve narrowed your search far enough.</p><h3 id="copy-url">Copy URL</h3><p>Easily share your current Explore Logs context with a teammate, to help troubleshoot in a team environment.</p><h3 id="open-in-explore">Open in Explore&nbsp;</h3><p>Is there a feature in Explore that you really like that doesn’t exist in Explore Logs yet? Would LogQL be really helpful for you at this point? Easily jump into <a href="https://grafana.com/docs/grafana/latest/explore/">Explore</a> — our UI for data exploration of hundreds of data sources, including Loki — while preserving your current context.</p><h2 id="how-explore-logs-works">How Explore Logs works</h2><p>We can probably agree this looks really cool, and it’s a pretty different experience from Explore. But, how can it actually help developers?&nbsp;</p><p>Well, how does solving observability problems faster sound? Faster to close that P1, faster to know what hotfix to push to prod, faster back to bed. Let’s show you how.</p><p>Suppose you need to identify a misbehaving pod in one of your services. You can certainly get that information using LogQL and Explore — construct a LogQL metrics query that counts errors by service, and see which one pops up. But is it the <em>easiest</em> way?</p><p>Not anymore! Now you can:</p><ul><li>Start by selecting your service</li><li>Select the <code>level</code> label selector, then add <code>level=error</code> to your filter criteria</li><li>Select the <code>pod</code> label selector, then see all impacted pods and their error rates</li><li>With just one more click, see the log lines associated with these pods</li></ul><p>Just a handful of clicks, with visual cues at each step of the way and —&nbsp;once more with feeling — <em>without writing LogQL</em>.</p><h2 id="special-thanks">Special thanks</h2><p>Explore Logs was the result of shared empathy, creativity, and hard work. We’d like to recognize all the contributors to Explore Logs so far:</p><ul><li><a href="https://github.com/cyriltovena" target="_blank" rel="noopener noreferrer">cyriltovena</a></li><li><a href="https://github.com/gtk-grafana" target="_blank" rel="noopener noreferrer">gtk-grafana</a></li><li><a href="https://github.com/ivanahuckova" target="_blank" rel="noopener noreferrer">ivanahuckova</a></li><li><a href="https://github.com/L2D2grafana" target="_blank" rel="noopener noreferrer">L2D2grafana</a></li><li><a href="https://github.com/matryer" target="_blank" rel="noopener noreferrer">matryer</a></li><li><a href="https://github.com/matyax" target="_blank" rel="noopener noreferrer">matyax</a></li><li><a href="https://github.com/sandeepsukhani" target="_blank" rel="noopener noreferrer">sandeepsukhani</a></li><li><a href="https://github.com/shantanualsi" target="_blank" rel="noopener noreferrer">shantanualsi</a></li><li><a href="https://github.com/svennergr" target="_blank" rel="noopener noreferrer">svennergr</a></li><li><a href="https://github.com/trevorwhitney" target="_blank" rel="noopener noreferrer">trevorwhitney</a></li><li><a href="https://github.com/zizzpudding" target="_blank" rel="noopener noreferrer">zizzpudding</a></li></ul><h2 id="try-it-for-yourself">Try it for yourself!</h2><p>Explore Logs is available to preview today. You can learn more in the <a href="https://github.com/grafana/explore-logs" target="_blank" rel="noopener noreferrer">Explore Logs GitHub repository</a>. You can also try it out by installing from the repo and using Explore Logs with <a href="https://grafana.com/blog/2024/04/09/grafana-11-release-all-the-new-features/">Grafana 11</a> and <a href="https://grafana.com/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features/">Loki 3.0</a>, both of which were <a href="https://grafana.com/blog/2024/04/09/grafanacon-2024-a-guide-to-all-the-announcements-from-grafana-labs/">announced at GrafanaCON 2024</a>.</p><p>Or you can also take Explore Logs for a spin in the <a href="https://play.grafana.org/a/grafana-lokiexplore-app/explore?mode=start&amp;patterns=&amp;var-patterns=&amp;logId=&amp;var-filters=" target="_blank" rel="noopener noreferrer">Grafana Play environment</a>.&nbsp;</p><p>Please let us know what you would like to see improved or added with the <strong>Give Feedback</strong> button in Explore Logs, or you can engage more deeply in the repo itself!</p><p>We are excited to partner with our community and to build the easiest Loki + Grafana experience together!</p><p><em>Learn all about the <a href="https://grafana.com/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features">latest features in Loki 3.0</a>, our open source log aggregation tool.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Penpot 2.0 Released (105 pts)]]></title>
            <link>https://community.penpot.app/t/penpot-2-0-a-major-milestone-in-our-journey-is-now-yours-to-explore-and-enjoy/4906</link>
            <guid>39978781</guid>
            <pubDate>Tue, 09 Apr 2024 12:40:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.penpot.app/t/penpot-2-0-a-major-milestone-in-our-journey-is-now-yours-to-explore-and-enjoy/4906">https://community.penpot.app/t/penpot-2-0-a-major-milestone-in-our-journey-is-now-yours-to-explore-and-enjoy/4906</a>, See on <a href="https://news.ycombinator.com/item?id=39978781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p>As it’s often the case with major releases, they feel both like the end of a journey and the beginning of a new one.</p>

<p><em>Short clip showing all</em></p>
<p>Let me first cover why <a href="https://penpot.app/penpot-2.0">Penpot 2.0</a> is such an impactful release.</p>
<p>Once again, we delivered on our promise to bring developers and designers closer together. <strong>Our bold movement to build CSS Grid Layout</strong> and enable designers to create responsive interfaces matching coding constructs was unexpected. The design tool space has changed forever.</p>
<p><strong>Component Libraries have been revamped</strong> with a new data structure to help designers and large teams build extensive design systems more modularly. The addition of component swapping as well as more flexible categorisation options provide a significant boost in productivity.</p>
<p>We rebuilt the entire <strong>Penpot’s UI to be sleeker, faster and more beautiful</strong>. This will be obvious to everyone that used Penpot in the past but equally mesmerising to newcomers. Streamlining user experience means allowing for more time spent creating and collaborating at scale, which sits at the core of Penpot’s mission.</p>
<div><a href="https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/fd253723f560cacf66fde53bcc0977e47979431b.jpeg" data-download-href="/uploads/short-url/A7qx5hXOxO7zz8v99OaCECgw2Ar.jpeg?dl=1" title="screenshot-interaction"><img src="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/fd253723f560cacf66fde53bcc0977e47979431b_2_690x386.jpeg" alt="screenshot-interaction" data-base62-sha1="A7qx5hXOxO7zz8v99OaCECgw2Ar" width="690" height="386" srcset="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/fd253723f560cacf66fde53bcc0977e47979431b_2_690x386.jpeg, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/fd253723f560cacf66fde53bcc0977e47979431b_2_1035x579.jpeg 1.5x, https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/fd253723f560cacf66fde53bcc0977e47979431b.jpeg 2x" data-dominant-color="23252B"></a></div>
<p><em>Penpot 2.0 showing an interactive prototype</em></p>
<p>Each of these features, on its own, would have deserved a major release and yet we have another three major updates.</p>
<ul>
<li>You can now use images as a fill property.</li>
<li>We added HTML generation on top of CSS and SVG.</li>
<li>UI theming is now a reality, starting with Light &amp; Dark.</li>
</ul>
<div><a href="https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362.png" data-download-href="/uploads/short-url/h3e2rZ2gL5R9DkU3OH9NvmLrzdo.png?dl=1" title="workspace-light-dark"><img src="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_690x456.png" alt="workspace-light-dark" data-base62-sha1="h3e2rZ2gL5R9DkU3OH9NvmLrzdo" width="690" height="456" srcset="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_690x456.png, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_1035x684.png 1.5x, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_1380x912.png 2x" data-dominant-color="8EA3A9"></a></div>
<p><em>Dark or Light themes, we love both!</em></p>
<p>If you want to know all the details of what comes packed with 2.0, including performance improvements and 40+ changes not covered here, head to our <a href="https://penpot.app/dev-diaries">Dev Diaries</a> page.</p>
<p>It took the team 9 months to build and ship this amazing release. We didn’t want to cut corners, we wanted to be proud of our work so you could team up and collaborate around design and code projects with no limitations or compromises.</p>
<p>We are building our own path where concepts such as <a href="https://www.c11n.quest/does-declarative-design-foster-superior-collaboration-with-developers/">declarative design</a>, future-proof ownership of your work and a no-handoff mindset meet long-standing pragmatic design and coding practices.</p>
<p>Our SaaS service at <a href="https://design.penpot.app/">design.penpot.app</a> was the first to roll-out 2.0 a couple of days ago and <a href="https://penpot.app/self-host">self-host images</a> will follow very soon. We will always make sure that, no matter your choice, Penpot delivers the same experience.</p>
<div><a href="https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803.jpeg" data-download-href="/uploads/short-url/yHC4KQ8cxVrBFKaFLBOpF2LH8fF.jpeg?dl=1" title="screenshot-code"><img src="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803_2_690x386.jpeg" alt="screenshot-code" data-base62-sha1="yHC4KQ8cxVrBFKaFLBOpF2LH8fF" width="690" height="386" srcset="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803_2_690x386.jpeg, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803_2_1035x579.jpeg 1.5x, https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803.jpeg 2x" data-dominant-color="585858"></a></div>
<p><em>Design-as-code is a reality with Penpot</em></p>
<h2><a name="whats-next-1" href="#whats-next-1"></a>What’s next?</h2>
<p>Delivering Penpot 2.0 required the product team to act almost as a sole entity so interdependencies between new features would not create bottlenecks.</p>
<p>Post 2.0 we are shifting to an “initiatives” approach where smaller autonomous teams can ship upgrades independently. “Design tokens”, “Plugin architecture”, “AI” or “E2E testing framework” are some of them.</p>
<p>Do you want to know everything about Penpot 2.0 and what we’re cooking up next? Do you want to learn from amazing designers and developers that are shaping the industry by driving collaboration forward? Do you want to enjoy our very own PenpotFest in Barcelona, 5-7th June? Make sure to <a href="https://penpotfest.org/">get your early bird tickets</a> while they’re still available!</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Eclipse via Satellite (161 pts)]]></title>
            <link>https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/</link>
            <guid>39978723</guid>
            <pubDate>Tue, 09 Apr 2024 12:33:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/">https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/</a>, See on <a href="https://news.ycombinator.com/item?id=39978723">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
          <article>
    
    

    
    

    
    <div>
      <p>Yesterday’s eclipse as seen by the <a href="https://www.star.nesdis.noaa.gov/GOES/">GOES-East</a> weather satellite. I just grabbed the full-disk geocolor JPGs with <code>wget</code> and stitched them together with <code>ffmpeg</code>.</p>
<video autoplay="" loop="" muted="" playsinline="" controls="true" width="100%">
    <source src="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/eclipse_sm.mp4" type="video/mp4">
    <source src="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/eclipse_sm.mov" type="video/mov">
    <source src="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/eclipse_sm.webm" type="video/webm">
</video>

    </div>

    

    

    
  </article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google CodeGemma: Open Code Models Based on Gemma [pdf] (128 pts)]]></title>
            <link>https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf</link>
            <guid>39978717</guid>
            <pubDate>Tue, 09 Apr 2024 12:32:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf">https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39978717">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Google Axion Processors – Arm-based CPUs designed for the data center (164 pts)]]></title>
            <link>https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu/</link>
            <guid>39978577</guid>
            <pubDate>Tue, 09 Apr 2024 12:12:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu/">https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu/</a>, See on <a href="https://news.ycombinator.com/item?id=39978577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>At Google, we constantly push the boundaries of computing, exploring what is possible for grand challenges ranging from information retrieval, global video distribution, and of course generative AI. Doing so requires rethinking systems design in deep collaboration with service developers. This rethinking has resulted in our significant investment in custom silicon. Today, we are thrilled to announce the latest incarnation of this work: Google Axion Processors, our first custom Arm®</span><span>-based CPUs designed for the data center. Axion delivers industry-leading performance and energy efficiency and will be available to Google Cloud customers later this year.</span></p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_Ab4940U.max-2000x2000.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_Ab4940U.max-2000x2000.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Run general-purpose workloads on C4A for exceptional performance, energy-efficiency and advanced capabilities.</p></span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>Axion is but the latest in a long line of custom Google silicon. Since 2015 we’ve released five generations of Tensor Processing Units (TPU); in 2018 we released our first Video Coding Unit (VCU), achieving up to </span><a href="https://dl.acm.org/doi/abs/10.1145/3445814.3446723" rel="noopener" target="_blank"><span>33x</span></a><span> more efficiency for video transcoding; </span><span>in 2021, we </span><a href="https://cloud.google.com/blog/topics/systems/the-past-present-and-future-of-custom-compute-at-google?e=48754805"><span>doubled-down</span></a><span> on custom compute by investing in “system on a chip” (SoC) designs, and released the </span><a href="https://blog.google/products/pixel/introducing-google-tensor/" rel="noopener" target="_blank"><span>first of three generations</span></a><span> of Tensor chips for mobile devices.&nbsp;</span></p>
<p><span>While our investments in compute accelerators have transformed our customers’ capabilities, general-purpose compute is and will remain a critical portion of our customers’ workloads. Analytics, information retrieval, and ML training and serving all require a huge amount of compute power. Customers and users who wish to maximize performance, reduce infrastructure costs, and meet sustainability goals have found that the rate of CPU improvements has slowed recently. Amdahl’s Law suggests that as accelerators continue to improve, general purpose compute will dominate the cost and limit the capability of our infrastructure unless we make commensurate investments to keep up.</span></p>
<p><span>Axion processors combine Google’s silicon expertise with Arm’s highest performing CPU cores to deliver instances with up to </span><span>30% better performance than the fastest general-purpose Arm-based instances available in the cloud today, up to 50% better performance and up to 60% better energy-efficiency than comparable current-generation x86-based instances<sup>1</sup>.</span><span> </span><span>That’s why we’ve already started deploying Google services like BigTable, Spanner, BigQuery, Blobstore, Pub/Sub, Google Earth Engine, and the YouTube Ads platform on current generation Arm-based servers and plan to deploy and scale these services and more on Axion soon.</span></p>
<h3><strong>Unrivaled performance and efficiency, underpinned by Titanium</strong></h3>
<p><span>Built using the Arm Neoverse</span><span><span>™</span></span><span> V2 CPU, Axion processors deliver giant leaps in performance </span><span>for general-purpose workloads like web and app servers, containerized microservices, open-source databases, in-memory caches, data analytics engines, media processing, CPU-based AI training and inferencing, and more.&nbsp;</span></p>
<p><span>Axion is underpinned b</span><span>y </span><a href="https://cloud.google.com/titanium?e=48754805"><span>Titanium</span></a><span>, a system of</span><span> purpose-built custom silicon microcontrollers and tiered scale-out offloads</span><span>. Titanium offloads take care of platform operations like networking and security, so Axion processors have more capacity and improved performance for customer workloads. Titanium also offloads storage I/O processing to </span><a href="https://cloud.google.com/compute/docs/disks/hyperdisks"><span>Hyperdisk</span></a><span>, our new block storage service that decouples performance from instance size and that can be dynamically provisioned in real time.&nbsp;</span></p>
<p><em>“Google’s announcement of the new Axion CPU marks a significant milestone in delivering custom silicon that is optimized for Google’s infrastructure, and built on our high-performance Arm Neoverse V2 platform. Decades of ecosystem investment, combined with Google’s ongoing innovation and open-source software contributions ensure the best experience for the workloads that matter most to customers running on Arm everywhere."</em> - Rene Haas, CEO, Arm</p>
<p><span>Beyond performance, customers want to operate more efficiently and meet their sustainability goals. </span><span>Google Cloud data centers are already 1.5X more efficient than the industry average and deliver 3X more computing power with the same amount of electrical power compared with five years ago<sup>2</sup>.</span><span> </span><span>We’ve set ambitious </span><a href="https://sustainability.google/operating-sustainably/" rel="noopener" target="_blank"><span>goals</span></a><span> to </span><span>operate our offices, campuses, and data centers on carbon-free energy, 24/7</span><span>, and offer </span><a href="https://cloud.google.com/carbon-footprint"><span>tools</span></a><span> to help you report on carbon emissions. With Axion processors, customers can optimize for even more energy-efficiency.&nbsp;</span></p>
<h3><strong>Axion - out-of-the-box application compatibility and interoperability</strong></h3>
<p><span>Google also has a rich history of contributions to the Arm ecosystem. We built and open sourced Android, Kubernetes, Tensorflow and the Go language, and worked closely with Arm and industry partners to optimize them for the Arm architecture.&nbsp;</span></p>
<p><span>Axion is built on the standard Armv9 architecture and instruction set. Most recently, we contributed to SystemReady Virtual Environment (VE), Arm’s hardware and firmware interoperability standard that ensures common operating systems and software packages can seamlessly run on Arm-based servers and VMs, making it easier for customers to deploy Arm workloads on Google Cloud with limited-if-any code rewrites. Through this collaboration, we’re accessing an ecosystem of tens of thousands of cloud customers already deploying workloads and leveraging Arm-native software from hundreds of ISVs and open-source projects.&nbsp;</span></p>
<p><span>Customers will be able to use Axion in many Google Cloud services including Google Compute Engine, Google Kubernetes Engine, Dataproc, Dataflow, Cloud Batch, and more.&nbsp; Arm-compatible software and solutions are now available on the </span><a href="https://cloud.google.com/marketplace?hl=en"><span>Google Cloud Marketplace</span></a><span>, and we've recently launched preview support for Arm-based instances migration in the </span><a href="https://cloud.google.com/migrate/virtual-machines"><span>Migrate to Virtual Machines</span></a><span> service.</span></p>
<h3><strong>What our customers and partners are saying</strong></h3>
<p><span>"</span><span>We're thrilled to add application packages built on the new Axion Arm-based CPU for Google Cloud to the Bitnami by VMware Tanzu library. This will deliver significantly improved performance, attractive price-performance, and better sustainability for our users. We're excited to get our hands on the new Google Axion instances and do even more to help our customers streamline deployments and reduce their environmental footprint."</span><span> - Mike Wookey, Senior Director R&amp;D, Tanzu Division, Broadcom</span></p>
<p><span>"Organizations all over the world rely on CrowdStrike and our single platform, single agent architecture to stop cloud breaches. CrowdStrike delivers the industry’s best protection while being the fastest to deploy, so we’re excited about testing Google's new processor to discover power and efficiency gains." </span><span>– Daniel Bernard, Chief Business Officer, CrowdStrike</span></p>
<p><span>“Our customers demand uncompromising cybersecurity protection that our systems provide. We're intrigued by the power and efficiency gains possible with the new Google Cloud's custom Arm-based CPU and plan to validate its capabilities as a way to provide even better threat detection and response capabilities to our customers.” - </span><span>Tzach Segal, VP Business Development, Cybereason</span></p>
<p><span>“Datadog has been a trusted partner for customers adopting Arm-based virtual machines and an early adopter of Arm for our own operations. We’re excited about Google Cloud's announcement of the Axion processor and plan to evaluate it on our workloads as we help customers measure the cost and performance benefits of using Datadog on Google Cloud Arm instances.”</span><span> - </span><span>Yrieix Garnier, VP of Product Management</span><span>, Datadog</span></p>
<p><span>“Elastic is committed to helping customers unlock the potential of all their structured and unstructured data efficiently at any scale. We look forward to testing Google Cloud's new custom Arm-based CPU and expect it to help us provide an even better Elastic customer experience on the Google Cloud Platform.” </span><span>- Steve Kearns, VP of Product, Elastic</span><span>&nbsp;</span></p>
<p><span>“We’ve built a strong partnership with Google Cloud over many years and have seen the benefits of building on GCP Arm-based VMs. We can’t wait to see the remarkable improvements coming with the new generation Arm-based Axion processor.” </span><span>- Joel Meyer, SVP, Engineering, OpenX </span><span>&nbsp;</span></p>
<p><span>"Snap empowers everyone to express themselves, live in the moment, learn about the world, and have fun together. We're constantly optimizing our infrastructure for performance and efficiency. Google's new Axion Arm-based CPU promises major leaps forward in both. The potential to serve our community with these gains while leading on our sustainability goals is incredibly exciting. We look forward to seeing the benefits of Axion-based virtual machines when they become available." - </span><span>Korwin Smith, Sr Director of Engineering, Cloud Infrastructure, Snap</span></p>
<p><span>“WP Engine powers websites for more than 1.5 million customers across 150 countries. They rely on WP Engine to deliver on our core promises of performance, reliability, and security and we take that responsibility to heart. Our commitment to innovation and a customer-inspired mindset means we’re always looking for ways to further enhance our customers’ performance and confidence online. We’re excited to test Google’s new custom Arm-based processor and its anticipated performance and sustainability gains, and explore how they can empower our customers to create even more compelling websites and applications.”</span><span> - Ramadass Prabhakar, SVP and CTO, WP Engine</span></p>
<h3><strong>Learn more</strong></h3>
<p><span>Virtual machines based on Axion processors will be available in preview in the coming months. </span><a href="https://docs.google.com/forms/d/e/1FAIpQLSdmFDDBNffCScti1FLlum71Q2V9kBANNKIy_2fd85iSgMcj9Q/viewform" rel="noopener" target="_blank"><span>Register your interest today</span></a><span>! And if you’re here at Next ‘24, come learn more about Axion and other compute announcements in these related sessions:</span></p>
<ul>
<li>
<p><strong>SPTL205</strong><span> - </span><a href="https://cloud.withgoogle.com/next/session-library?filters=session-type-spotlight&amp;session=SPTL205#all" rel="noopener" target="_blank"><span>Workload-optimized and AI-powered Infrastructure</span></a></p>
</li>
<li>
<p><strong>ARC225 </strong><span>- </span><a href="https://cloud.withgoogle.com/next/session-library?filters=session-type-spotlight&amp;session=ARC225#all" rel="noopener" target="_blank"><span>Transform your cloud operations and design capability with Gemini for Google Cloud</span></a></p>
</li>
<li>
<p><strong>ARC229 </strong><span>- </span><a href="https://cloud.withgoogle.com/next/session-library?filters=session-type-spotlight,track-infrastructure-architects-admins&amp;session=ARC229#all" rel="noopener" target="_blank"><span>Best practices to manage and automate on Compute Engine</span></a></p>
</li>
</ul>
<hr>
<p><sup><em><span><span>1. Google Cloud Internal Data, 31 March 2024<br>2. <a href="https://www.gstatic.com/gumdrop/sustainability/google-2023-environmental-report.pdf" rel="noopener" target="_blank"><span>Google Environmental Report</span></a><span>, 2023, page 10.</span></span></span></em></sup></p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/compute" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/compute" track-metadata-module="tag list" track-metadata-module_headline="posted in">Compute</a></li><li><a href="https://cloud.google.com/blog/topics/google-cloud-next" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/google-cloud-next" track-metadata-module="tag list" track-metadata-module_headline="posted in">Google Cloud Next</a></li><li><a href="https://cloud.google.com/blog/products/ai-machine-learning" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/ai-machine-learning" track-metadata-module="tag list" track-metadata-module_headline="posted in">AI &amp; Machine Learning</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SSSL – Hackless SSL bypass for the Wii U (193 pts)]]></title>
            <link>https://github.com/PretendoNetwork/SSSL</link>
            <guid>39977862</guid>
            <pubDate>Tue, 09 Apr 2024 10:03:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PretendoNetwork/SSSL">https://github.com/PretendoNetwork/SSSL</a>, See on <a href="https://news.ycombinator.com/item?id=39977862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">SSSL - Hackless SSL bypass for the Wii U</h2><a id="user-content-sssl---hackless-ssl-bypass-for-the-wii-u" aria-label="Permalink: SSSL - Hackless SSL bypass for the Wii U" href="#sssl---hackless-ssl-bypass-for-the-wii-u"></a></p>
<div dir="auto">
	<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/PretendoNetwork/SSSL/blob/master/shutter.png"><img src="https://github.com/PretendoNetwork/SSSL/raw/master/shutter.png"></a></p></div>
<p dir="auto">On March 1, 2021 Nintendo released Wii U firmware version <a href="https://wiiubrew.org/wiki/5.5.5" rel="nofollow">5.5.5</a>. This update updated the Wii U's SSL verification and recompiled all RPLs (though no code changes were made). The exact purpose for this update is unknown, as nothing of significance was changed, and no other changes were made in this update. With the changes to SSL verification, Nintendo introduced a bug which allows for the forging of SSL certificates. These forged certificates will be seen as "Nintendo Signed" and, due to an existing bug with how the Wii U handles CA common names, will be accepted by all domains.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The bugs</h2><a id="user-content-the-bugs" aria-label="Permalink: The bugs" href="#the-bugs"></a></p>
<p dir="auto">There are 2 bugs at play:</p>
<ol dir="auto">
<li>Normally a CA common name does not accept a single wildcard (*) value. They must contain a hostname, and optionally one or many wildcards for subdomains. The Wii U will accept a single * wildcard in place of a hostname, which allows the CA to be accepted as any domain. This bug has existed since before 5.5.5, but was not useful until now.</li>
<li>As of 5.5.5, CA's crafted in a specific way may take a newly introduced alternate path for verification. This allows for a CA's signature to not be verified correctly. Instead, the Wii U simply checks if the CA matches one already known by the system, but not the signature or contents of the CA. We have no idea why this change was made, as it does not benefit Nintendo at all. It almost feels intentional.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Exploiting</h2><a id="user-content-exploiting" aria-label="Permalink: Exploiting" href="#exploiting"></a></p>
<p dir="auto">Not any CA will work. There are 3 conditions for a CA which still need to be met even for a forged CA to be accepted:</p>
<ol dir="auto">
<li>The CA needs to be one which the Wii U would already accept. The signature is not validated in this case, so modifying an existing CA works.</li>
<li>The Wii U does not allow a Root CA in the cert chain. It will ignore any certs that have a matching subject and authority key.</li>
<li>The title must not roll it's own SSL. WebKit titles such as the eShop, Miiverse, TVii, etc, as well as any game which uses it's own SSL library, will not work with these certificates.</li>
</ol>
<p dir="auto">The easiest way to exploit this bug is to use the Nintendo CA - G3 CA, and is what this script opts to do. This can be dumped from a Wii U's SSL certificates title at <code>/storage_mlc/sys/title/0005001b/10054000/content/scerts/CACERT_NINTENDO_CA_G3.der</code>. Changing the public key to a user-controlled key and changing the authority key identifier to anything else is all that is required. The resulting user-controlled private key and patched CA can be used to bypass SSL verification without any homebrew or CFW at all.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The script</h2><a id="user-content-the-script" aria-label="Permalink: The script" href="#the-script"></a></p>
<p dir="auto">This script takes in a PEM encoded copy of Nintendo CA - G3 and does the above patches and exports the patched CA and private key.</p>
<ul dir="auto">
<li>Install <a href="https://nodejs.org/" rel="nofollow">NodeJS</a></li>
<li><code>git clone https://github.com/PretendoNetwork/SSSL</code></li>
<li><code>cd SSSL</code></li>
<li><code>npm i</code> to install the dependencies</li>
<li><code>node patch</code> to run the patching wizard</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Shutterbug for actually finding the new verification bug</li>
<li>Jemma and Quarky for decompiling the updated SSL functions</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sqlime: Online SQLite Playground (129 pts)]]></title>
            <link>https://github.com/nalgeon/sqlime</link>
            <guid>39977231</guid>
            <pubDate>Tue, 09 Apr 2024 08:24:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nalgeon/sqlime">https://github.com/nalgeon/sqlime</a>, See on <a href="https://news.ycombinator.com/item?id=39977231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sqlime</h2><a id="user-content-sqlime" aria-label="Permalink: Sqlime" href="#sqlime"></a></p>
<p dir="auto"><strong><a href="http://sqlime.org/" rel="nofollow">Sqlime</a></strong> is an online SQLite playground for debugging and sharing SQL snippets. Kinda like JSFiddle, but for SQL instead of JavaScript.</p>
<p dir="auto">🌟 <strong>New!</strong> Turn static SQL code in your articles into <a href="https://codapi.org/sqlite/" rel="nofollow">interactive examples</a>.</p>
<a href="https://sqlime.org/" rel="nofollow">
    <img src="https://github.com/nalgeon/sqlime/raw/main/img/sqlime.jpg" alt="Sqlime" width="600">
</a>
<p dir="auto">Here are some notable features:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔋 Full-blown database in the browser</h3><a id="user-content--full-blown-database-in-the-browser" aria-label="Permalink: 🔋 Full-blown database in the browser" href="#-full-blown-database-in-the-browser"></a></p>
<p dir="auto">Sqlime is backed by the latest version of SQLite via the <a href="https://github.com/nalgeon/sqlean.js">sqlean.js</a> project. It provides a full-featured SQL implementation, including indexes, triggers, views, transactions, CTEs, window functions and execution plans.</p>
<p dir="auto">It also includes essential SQLite extensions, from math statistics and regular expressions to hash functions and dynamic SQL.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔌 Connect any data source</h3><a id="user-content--connect-any-data-source" aria-label="Permalink: 🔌 Connect any data source" href="#-connect-any-data-source"></a></p>
<p dir="auto">Connect any local or remote SQLite database. Both files and URLs are supported. For example, try loading the <a href="http://sqlime.org/#https://raw.githubusercontent.com/nalgeon/sqliter/main/employees.en.db" rel="nofollow">Employees&nbsp;database</a> from the GitHub repo.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔗 Save and share with others</h3></p>
<p dir="auto">Sqlime saves both the database and the queries to GitHub so that you can revisit them later or share them with a colleague. The database is stored as a plain text SQL dump, so it's easy to read the code or import data into PostgreSQL, MySQL, or other databases.</p>
<p dir="auto">For example, here is the <a href="https://gist.github.com/nalgeon/e012594111ce51f91590c4737e41a046">gist</a> for the Employees database, and here is the <a href="https://sqlime.org/#gist:e012594111ce51f91590c4737e41a046" rel="nofollow">sharing&nbsp;link</a> for it.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🤖 Ask AI</h3><a id="user-content--ask-ai" aria-label="Permalink: 🤖 Ask AI" href="#-ask-ai"></a></p>
<p dir="auto">Connect an OpenAI account to get help with your queries from the state-of-the-art ChatGPT assistant. AI can explain, teach, and troubleshoot your SQL.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nalgeon/sqlime/blob/main/img/sqlime-ai.jpg"><img src="https://github.com/nalgeon/sqlime/raw/main/img/sqlime-ai.jpg" alt="Ask AI" width="600"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">📱 Mobile friendly</h3><a id="user-content--mobile-friendly" aria-label="Permalink: 📱 Mobile friendly" href="#-mobile-friendly"></a></p>
<p dir="auto">Most playgrounds are not meant for small screens. Sqlime was specifically designed and tested on mobile devices. No need to zoom or aim at tiny buttons — everything looks and works just fine.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔒 Secure and private</h3><a id="user-content--secure-and-private" aria-label="Permalink: 🔒 Secure and private" href="#-secure-and-private"></a></p>
<p dir="auto">There is no server. Sqlime works completely in the browser. GitHub and OpenAI credentials are also stored locally. Queries are saved as private GitHub gists within your account. Your data is yours only.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⌨️ Dead simple</h3><a id="user-content-️-dead-simple" aria-label="Permalink: ⌨️ Dead simple" href="#️-dead-simple"></a></p>
<p dir="auto">Sqlime has zero third-party dependencies other than SQLite. Good old HTML, CSS, and vanilla JS — that's all. No frameworks, no heavy editors, no obsolete and vulnerable libraries. Just some modular open-source code, which is easy to grasp and extend.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Last but not least</h2><a id="user-content-last-but-not-least" aria-label="Permalink: Last but not least" href="#last-but-not-least"></a></p>
<p dir="auto"><strong>⭐️ Star the project</strong> if you like it</p>
<p dir="auto">🚀 <a href="https://antonz.org/subscribe/" rel="nofollow"><strong>Subscribe</strong></a> to stay on top of new features</p>
<p dir="auto">🍋 <a href="https://sqlime.org/" rel="nofollow"><strong>Use Sqlime</strong></a> to debug and share SQL snippets</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The U.S. government may finally mandate safer table saws (102 pts)]]></title>
            <link>https://www.npr.org/2024/04/02/1241148577/table-saw-injuries-safety-sawstop-cpsc</link>
            <guid>39977058</guid>
            <pubDate>Tue, 09 Apr 2024 07:48:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/04/02/1241148577/table-saw-injuries-safety-sawstop-cpsc">https://www.npr.org/2024/04/02/1241148577/table-saw-injuries-safety-sawstop-cpsc</a>, See on <a href="https://news.ycombinator.com/item?id=39977058">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="res1241402462">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Tom Noffsinger stands in his garage workshop, where he uses a SawStop table saw for woodworking at his home in Raleigh, North Carolina. About 20 years ago, Noffsinger had a table saw accident and almost lost his thumb.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Tom Noffsinger stands in his garage workshop, where he uses a SawStop table saw for woodworking at his home in Raleigh, North Carolina. About 20 years ago, Noffsinger had a table saw accident and almost lost his thumb.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>One day about 20 years ago, Tom Noffsinger experienced every woodworker's worst nightmare: One final cut on his table saw before knocking off for the day turned into a trip to the emergency room. It was afternoon, and he'd been in his shop since morning.</p>   <p>"I was a little tired. I should've quit," Noffsinger says. "I ran my hand right into the blade and nearly cut my thumb off."</p>   <p>Table saws are widely considered the <a href="https://www.npr.org/2010/07/05/127780027/sharp-edge-one-mans-quest-to-improve-saw-safety">most dangerous power tool</a>, and approximately <a href="https://www.federalregister.gov/documents/2017/05/12/2017-09098/safety-standard-addressing-blade-contact-injuries-on-table-saws#:~:text=In%202015%2C%20there%20were%20an,contact%20with%20the%20saw%20blade.">30,000</a> blade-contact injuries<strong> </strong>require medical treatment each year in the United States. About 4,000 result in amputations that can be career-ending for some professional carpenters and contractors. The Consumer Product Safety Commission says that when a person is hospitalized, the societal cost per table saw injury exceeds $500,000 when you also factor in loss of income and pain and suffering.</p>   
   
   
<!-- END ID="RES1241667138" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Noffsinger was lucky by comparison. Although he needed 14 stitches, doctors at a hospital near his home in Raleigh, N.C., were able to save his thumb. Reconstructive surgery followed. Even so, all these years later, he says he still has recurring pain.</p>   <div id="res1241402767">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Noffsinger opens a wooden box that he made using a SawStop table saw, which uses technology to prevent serious injury.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Noffsinger opens a wooden box that he made using a SawStop table saw, which uses technology to prevent serious injury.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>Woodworking has been a nearly lifelong passion for Noffsinger, and he was no stranger to power tools. Back before his accident, he'd seen a demonstration of a new and much safer type of table saw at a local woodworking store. Marketed under the name SawStop, it was designed to <a href="https://www.youtube.com/watch?v=SYLAi4jwXcs">stop and retract the spinning blade</a> within a few milliseconds of making contact with flesh — fast enough to turn a potentially life-changing injury into little more than a scratch. Noffsinger's table saw wasn't equipped with the high-tech safety feature because manufacturers aren't required to include it.</p>   
<div id="res1241667654">
    <p>
        <iframe src="https://www.youtube.com/embed/fq3o0VGUh50?rel=0" width="100%" height="100%" frameborder="0" allowfullscreen=""></iframe>
    </p>
        <p><b>
                    
                    <b>YouTube</b>
                </b>
        </p>
</div>   <p>But that may be about to change. The federal Consumer Product Safety Commission (CPSC) appears poised to mandate a SawStop-type safety brake on all new table saws sold in the United States. The move would follow years of failed efforts and false starts by the agency to impose such a standard.</p>   <p>Manufacturers have consistently fought a new rule, saying it would raise the price of table saws for consumers. Safety advocates liken it to air bags in cars and argue that the benefits outweigh the costs.</p>   
   <p>Over the years, Republicans on the commission have sided with the power tool industry in opposing further regulations. But with new Biden administration appointees, proponents on the commission appear to have a majority. In October, the CPSC <a href="https://www.federalregister.gov/documents/2023/12/11/2023-27133/safety-standard-addressing-blade-contact-injuries-on-table-saws-notice-of-extension-of-comment#:~:text=On%20October%2018%2C%202023%2C%20the,closes%20on%20January%202%2C%202024.">voted</a> to move forward on the mandate, which is expected to get approval later this year.</p>   <p>"We've got a [proposed] rule that is designed to prevent tens of thousands of medically treated table saw injuries per year," says CPSC Commissioner Richard Trumka Jr. "That's something that I very much support."</p>   <h3>Proponents say a new standard is long overdue</h3>   <p>Former acting CPSC Chairman Robert Adler says a standard requiring a blade brake "is long, long overdue." An average of more than 10 people per day in the U.S. suffer amputations on these types of saws, and "that is staggering when you think about it," he says. "I'm so thrilled to see it's very likely to occur now."</p>   <p>Adler, who was appointed by President Barack Obama in 2009 and served on the commission for 12 years, is a veteran of the fight for a new table saw safety standard. He calls the failure to require this type of feature on saws "the greatest single frustration I felt" while on the commission. He says that's because table saws are far and away the most dangerous tool that most Americans ever buy.</p>   <p>SawStop's competitors are represented by the <a href="https://www.powertoolinstitute.com/">Power Tool Institute</a>, the trade group that includes big power-tool makers such as Bosch, DeWalt and Milwaukee, as well as lesser-known brands. The group maintains that the new safety rule would be an overreach.</p>   <p>"Small manufacturers may go out of business," Susan Orenga, the Power Tool Institute's executive manager, said at a public hearing on the new rule in February. Requiring the safety brake would raise the cost of table saws too much, she said. "Sales of table saws will decrease, resulting in unemployment, and the government could be creating a monopoly."</p>   
   <p>The industry has long maintained that since SawStop owns patents surrounding the safety technology, the company would unduly benefit from such a government-imposed standard. But at the same hearing where Orenga spoke, SawStop pledged to allow manufacturers to produce safer saws regardless of those patents.</p>   <h3>Table saw safety comes at a price</h3>   <p>Exactly how much the safety brake would add to the price of a saw is unclear. An entry-level SawStop retails for $899. A comparable saw without the safety technology goes for several hundred dollars less.</p>   <p>But with the economies of scale enjoyed by larger competitors, the price difference could be narrower down the road.</p>   <div id="res1241403640">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                SawStops retail for hundreds of dollars more than the competition, depending on the manufacturer and the type of table saw. Unlike less expensive brands sold in big-box stores, SawStops are at the premium end of the market.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.jpg">
        </picture>
    </div>
<div>
        <p>SawStops retail for hundreds of dollars more than the competition, depending on the manufacturer and the type of table saw. Unlike less expensive brands sold in big-box stores, SawStops are at the premium end of the market.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>Since <a href="https://www.sawstop.com/company/#:~:text=The%20technology%20was%20invented%20by,SawStop%20Table%20Saw%20was%20sold.">SawStop came onto the market in 2004</a>, tens of thousands of the company's table saws have been sold in the U.S., and the company estimates that this has saved tens of thousands of professional and hobbyist woodworkers from injury.</p>   <p>The key to the SawStop is its <a href="https://www.sawstop.com/service-tips/active-injury-mitigation-aim-system-and-brake-cartridge-replacement-for-the-compact-table-saw-cts/">active injury mitigation</a> (AIM) system, which sends a small electrical charge through the saw blade, and because skin is conductive, the system senses whether the blade is touched. Basically, wood doesn't conduct electricity, but people do. When a hand comes in contact with the blade on a SawStop, this triggers a brake to stop the blade from spinning. This occurs so quickly that there's not enough time for a serious injury.</p>   <p>Sally Greenberg, executive director of the National Consumers League, has been interested in table saw safety since first hearing about the SawStop technology on <a href="https://www.npr.org/2004/12/07/4182602/table-saw-technology-aims-to-save-fingers">NPR</a> in 2004. Like Adler, she has been frustrated by the slow progress on a new safety standard.</p>   <p>"This is a category of product that could be made in this case 100% safe, but because of industry foot-dragging and resistance and lobbying power in Congress and with agencies, you have a situation of two steps forward, one step back," she says.</p>   
   <p>Until recently, SawStop competitors were largely prevented from developing AIM-type technology by a web of patents now owned by German-based TTS Tooltechnic Systems, which bought SawStop in 2017. But 20 years after the first SawStop was sold, most of those patents have now expired.</p>   <h3>SawStop vows to free up a key patent for rivals</h3>   <p>However, one key patent — the "840" patent — is not set to expire until 2033. To stave off potential competitors, it describes the AIM technology very broadly. In a surprise move at February's CPSC hearing, TTS Tooltechnic Systems North America CEO Matt Howard announced that the company would "dedicate the 840 patent to the public" if a new safety standard were adopted. Howard says that this would free up rivals to pursue their own safety devices or simply copy SawStop's. At the hearing, he challenged them "to get in the game."</p>   
   
<!-- END ID="RES1242019064" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Howard's concession follows years of bad blood between SawStop and the larger power tool companies. Before starting SawStop, the inventor of its technology, <a href="https://www.npr.org/2011/05/25/136617222/advocates-urge-lawmakers-to-make-table-saws-safer">Steve Gass</a> — himself a patent attorney — tried to interest manufacturers in licensing his idea. He got no takers. And years later, when Bosch Power Tools began selling a saw with its own version of an injury-mitigation system, SawStop <a href="https://www.sawstop.com/news/sawstop-sues-bosch-to-protect-inventions/">won a patent-infringement suit </a>against the company. TTS subsequently agreed to let Bosch sell the saw, but Bosch never reintroduced it to the U.S. market.</p>   <p>That lawsuit, however, has been cited by the industry to buttress its claim that any move to develop similar safety features would be aggressively met by SawStop and TTS.</p>   <p>There are other industry objections as well. Orenga notes that manufacturers already comply with a voluntary standard requiring blade guards and anti-kickback features designed to prevent a blade from catching a piece of wood and throwing it violently back at the operator.</p>   <h3>"Flimsy, poorly functioning guards" don't help</h3>   <p>But according to the CPSC, it's common for table saw users to "<a href="https://www.federalregister.gov/documents/2023/11/01/2023-23898/safety-standard-addressing-blade-contact-injuries-on-table-saws">remove modular blade guards</a>," often for reasons of "improved visibility" — in other words, because they can't easily see the cut they are trying to make.</p>   
   <p>As a result, the CPSC says, it has seen no discernible change in the number of blade-contact injuries since the industry adopted a voluntary requirement for improved blade guards and other safety features in 2010. In short, the voluntary standard "doesn't adequately reduce the risk of injury," Trumka says, which is why the commission is pursuing a mandatory standard.</p>   <p>Jim Hamilton, who hosts a popular <a href="https://www.youtube.com/@StumpyNubs">woodworking channel on YouTube</a>, says most table saw injuries could be prevented if woodworkers consistently used a blade guard. "Sadly, a culture has developed around many power tools, including table saws, that suggests safety devices are unnecessary or obstructive," he says, noting that even "veteran workers, including those who have worked at the highest levels of their trade, are seriously injured every day."</p>   <p>The situation is made worse, Hamilton says, by manufacturers including "flimsy, poorly functioning guards" that actually encourage users to remove them.</p>   <h3>Table saws cause a "vaporizing" type of injury</h3>   <p>Richard Bodor, a San Diego-based plastic surgeon, is all too familiar with the kind of catastrophic hand injuries that saw blades can cause.</p>   <p>The one he remembers most vividly occurred about 25 years ago, before SawStops were on the market. While he was operating one night to replant an amputated finger, the emergency room called about another "four-finger replant" being referred from Bodor's colleague — a senior surgeon and mentor. At first, Bodor thought his colleague was simply inquiring about another patient. He soon realized it was the surgeon himself who was injured.</p>   <p>That surgeon had been operating a table saw when his glove caught the saw blade and pulled in his hand. Bodor says the injured surgeon was surprisingly calm during pre-op, as the two discussed the complicated procedure to reconstruct the man's mangled hand.</p>   
   
<!-- END ID="RES1242011842" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Referring to each of his shredded fingers, the injured surgeon applied his own expertise to the reconstruction. "'I think this finger is going to make it. Now, I'm a little worried about this guy. However, I think this small one might be toast,'" Bodor said, recalling their conversation.</p>   <p>After a long recovery, Bodor said, the man eventually was able to resume surgeries. But these types of saw injuries are especially challenging and difficult to repair, he says. Unlike a clean amputation from a sharp cooking knife, he explains, a table saw blade actually obliterates the tissue. "It's a vaporizing type of injury," he says, adding that replantation typically requires hours of meticulous microsurgery.</p>   
   <p>But not everyone is convinced that a new safety standard alone will prevent such devastating injuries. Dale Juntunen owns a contracting firm in Deer River, Minn., that has been building homes for more than 40 years. "In all the years I've been in business, we've never had anybody get hurt" on a table saw, he says.</p>   <p>"If it's mandated, you're going to have people hanging on to their old saws forever," Juntunen says. "And, you know, that's when I'd say there will be more injuries on an old saw."</p>   <div id="res1241403994">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Noffsinger purchased a SawStop when he returned from the hospital after his table saw injury, and he has been using it ever since.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Noffsinger purchased a SawStop when he returned from the hospital after his table saw injury, and he has been using it ever since.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>Noffsinger, the North Carolina hobbyist woodworker, says even though he was injured, he's not sure mandating new safety technology on all saws is the best idea.</p>   <p>Still, when he returned home from the emergency room after nearly severing his thumb on a saw blade, he was met by his wife, "hands on her hips," he says. "She said, 'You will buy that SawStop thing.' So that's what I did."</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interview with Yanis Varoufakis on Technofeudalism (162 pts)]]></title>
            <link>https://www.wired.com/story/yanis-varoufakis-technofeudalism-interview/</link>
            <guid>39977002</guid>
            <pubDate>Tue, 09 Apr 2024 07:38:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/yanis-varoufakis-technofeudalism-interview/">https://www.wired.com/story/yanis-varoufakis-technofeudalism-interview/</a>, See on <a href="https://news.ycombinator.com/item?id=39977002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The tech giants have overthrown capitalism. That’s the argument of former Greek finance minister Yanis Varoufakis, who became famous trying to defend debt-laden Greece from its German creditors. Varoufakis has never quite regained the notoriety of 2015. But he has remained a prominent left-wing voice. After a failed campaign for a seat in the European Parliament in 2019, he plans to run again this June. This time, his adversary isn’t Berlin or the banks. It’s the tech companies he accuses of warping the economy while turning people against one other.</p><div data-testid="GenericCallout"><figure><p><span>Courtesy of Penguin Random House</span></p></figure></div><p>Varoufakis is also a prolific author; his 17th book, written as a letter to his techno-curious father, chronicles the evolution of capitalism from the 1960s advertising boom, through Wall Street in the 1980s, to the 2008 financial crisis and the pandemic. In its most compelling stretches, <a data-offer-url="https://www.amazon.com/Technofeudalism-Killed-Capitalism-Yanis-Varoufakis/dp/1685891241" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Technofeudalism-Killed-Capitalism-Yanis-Varoufakis/dp/1685891241&quot;}" href="https://www.amazon.com/Technofeudalism-Killed-Capitalism-Yanis-Varoufakis/dp/1685891241" rel="noopener" target="_blank"><em>Technofeudalism</em></a> argues that Apple, Facebook, and Amazon have changed the economy so much that it now resembles Europe’s medieval feudal system. The tech giants are the lords, while everyone else is a peasant, working their land for not much in return.</p><p>To Varoufakis, every time you post on X, formerly Twitter, you’re essentially toiling Elon Musk’s estate like a medieval serf. Musk doesn't pay you. But your free labor pays him, in a sense, by increasing the value of his company. On X, the more active users there are, the more people can be shown advertising or sold subscriptions. On Google Maps, he argues, users improve the product—alerting the system to traffic jams on their route.</p><p>The feudal comparison isn’t novel. But <em>Technofeudalism</em> attempts to introduce the idea to a wider audience. Its US release, launched the month before regulators in the <a href="https://www.wired.com/story/doj-sues-apple-antitrust/">US</a> and <a href="https://www.wired.com/story/apple-meta-alphabet-eu-digital-markets-act/">European Union</a> simultaneously initiated antitrust actions against Apple, also had impeccable timing.</p><p>Over Zoom, I spoke to Varoufakis, from his home near Athens, about how the tech giants have changed the economy—and why we should care about it.</p><p><em>This interview has been edited for length and clarity.</em></p><p><strong>WIRED: That word, <em>technofeudalism</em>, what does it mean? How is the feudal system relevant here?</strong></p><p><strong>Yanis Varoufakis:</strong> Profit drives capitalism, rent drove feudalism. Now we have moved [from one system to the other] because of this new form of super-duper, all-singing, all-dancing capital: cloud capital, algorithmic capital. If I'm right, that is creating new digital fiefdoms like Amazon.com, like Airbnb, where the main mode of wealth extraction comes in the form not of profit but of rent.</p><p>Take the Apple Store. You are producing an app, Apple can withhold 30 percent of your profits [through a commission fee]. That's a rent. That's like a ground rent. It's a bit like the Apple Store is a fiefdom. It's a cloud fiefdom, and Apple extracts a rent exactly as in feudalism. So my argument is not that we went back from capitalism to feudalism. My argument is that we have progressed forward to a new system, which has many of the characteristics of feudalism, but it is one step ahead of capitalism. To signal that, I added the word <em>techno</em>.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>When you're talking about these digital fiefdoms, the idea is easier to understand in terms of platforms that take a cut of the sales, like the Apple App Store or Amazon. But can you also accuse other platforms of operating these digital fiefs, like Facebook?</strong></p><p>Facebook is a classic cloud fief. It creates cloud capital which is attractive to you, to me, to other people who want to communicate with each other—to find friends, or post their views, or news about their dog or their cat. So you're drawn into this fiefdom, and then the next step for Zuckerberg was to draw into the same fiefdom publishers and advertisers in order to sell them the attention of users. And then immediately after that, as Cory Doctorow so beautifully describes through his concept of <a href="https://www.wired.com/story/tiktok-platforms-cory-doctorow/">enshittification</a>, you're a publisher, you feel great because your sales go up through Facebook, and then suddenly, you find that you've been downgraded. And then you have to pay a higher cloud rent in order to be re-upgraded [paying for ads, for example, for customers to find your product]. That’s typical cloud capitalism, producing technofeudalism.</p><p><strong>I understand technofeudalism as affecting three groups of people. Can we boil down who is affected into these groups?</strong></p><p>Yes, and I've given them names. The company that produces the electric bicycles sold on Alibaba or Amazon.com, this is a vassal capitalist. Most of the profit margin for that company is skimmed off by Jeff Bezos [Amazon’s founder and executive chairman] in the form of cloud rent.</p><p>Second is cloud proles, or cloud proletarians. Look at the workers in Amazon warehouses who are monitored by algorithms.</p><p>And the third one is you and me. I call us cloud serfs. Because the parallel with the serfs is that we <em>volunteer</em> free labor. It doesn't matter whether we're enjoying it or not. Every time you upload a video on Tiktok, on Facebook, on Instagram, you're adding to the capital stock of these companies. We are adding to it directly through our labor or our movement or our existence. In that way we're serfs, but we are more than serfs, we’re cloud serfs producing capital. And that has never happened in the history of the world.</p><p><strong>A company like Apple might argue that instead of being a fiefdom, maybe the Apple App Store is more like a mall where companies have to rent their stores from whomever owns the building. How is technofeudalism different from the mall dynamic?</strong></p><p>Well, hugely. Say you and I were going into partnership together with a fashion brand. We go to the shopping mall and we hire a shop, the rent is fixed. It is not proportional to our sales. The more money we make, the higher our price-to-rent margin. With the Apple Store, they get 30 percent of all sales. That’s not at all the same thing. That is the equivalent of the ground rent that the feudal lord used to extract from vassal capitalists.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>What makes cloud capitalism a worse economic system than capitalism?</strong></p><p>The first thing is from a macroeconomic perspective. When you have such a large sum of money extracted in the form of cloud rent, that money disappears from a circular flow of income. According to my calculations, between 35 and 40 percent of GDP is being siphoned off the circular flow of income by cloud rent, and that means there is less money in the economy. Investment is low, and that means less good, quality jobs in the rest of the economy.</p><p>The second reason is that this cloud capital is designed to reproduce itself through our attention and through our free labor. And platforms discovered that we spend more time doing this, producing free cloud capital for the owners of cloud capital, if we're angry. So algorithms are primed to poison our conversations. That is highly detrimental to our democracies because consensus is really bad for cloud capital. It doesn't want it. It wants you and me to be angry and shouting at each other.</p><p>Now, as a professor, I have noticed the effect on kids in universities in Britain, in Australia, here in Greece, in America. I find that students today are too scared of having a face-to-face conversation. They want a safe space. They do not want any challenging ideas to be presented to them in class. They protest, they will have you thrown out of university if you say something that upsets them, about anything. But give them a phone and they become toxic and ballistic. Now, that is no way of running a democracy or a civilized society for that matter.</p><p><strong>People have already expressed dissatisfaction with capitalism in various protest movements across Europe. Why should they care that there's been a shift to a slightly different system that's dominated by a slightly different kind of company?</strong></p><p>Ordinary people need to know the reasons behind the discontent. The discontented always ask: Why is this happening? Giving them an answer, in a way that makes sense to them, is hugely empowering. This is the foundation of any possibility of democracy. Because to have democracy, it's not enough to be able to vote every four or five years. You need people who understand what is going on, who are informed about the causes of their discontent. Because if they don't understand the causes of their discontent, then it's easy for them to fall prey to xenophobia, to misogyny, to racism. Then they can say, it’s the Jew. It's the Muslim. It's the foreigner. It's the Brit. It's the German, whatever. Then people latch on to simple solutions, which is the beginning of fascism.</p><p><strong>Are we at the beginning of fascism? And if so, is that really technofeudalism’s fault?</strong></p><p>I think that fascism is already on the rise. In France almost <a href="https://www.france24.com/en/france/20220425-victory-in-defeat-le-pen-raises-far-right-s-glass-ceiling-fails-to-crack-it">45 percent</a> of the population are supporting a neofascist [Marine Le Pen]. In Italy, we have a neofascist prime minister, Giorgia Meloni. That was not the doing of technofeudalism, because technofeudalism came later. What happened is, the rise of cloud capital and the siphoning off of money from the circular flow of income increases the discontent within people. At the same time you have the algorithms which make money and accumulate cloud capital to the extent that we hate one another. Hate is the fuel of facism. So if you blend discontent, the fact that most people can’t make ends meet, and you throw in there the hatred that is reinforced by the algorithms, that's fascism.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>So if we have this new system that is fueling a new fascism, then what should we do about it?</strong></p><p>Well, many things. But to begin with, let's understand where we are, so we don't blame the foreigners. We don't blame women. We don't blame trans people. A little bit of knowledge goes a long way towards recreating the circumstances for a decent conversation between us.</p><p>In economic terms, we need to introduce a cloud tax immediately. Tax Amazon 5 percent for every transaction that takes place on its platform. Then, introduce a capacity for you and me to own a digital identity so we don't need Google or Facebook to vouch for who we are on the internet. Having a state-issued digital identity will go a long way towards restoring or handing you property rights over your data, because at the moment you do not own your data.</p><p>You can introduce interoperability. I am on X. I can't go to Bluesky. Let's say that Elon Musk decides to block me because I said something he didn't like. He has blocked me before for a couple of weeks. Now, I have more than a million followers on X. I cannot leave without losing them. If I go to Bluesky, I have 10 followers. Interoperability would mean that if I go to another platform, to Bluesky, when I post something on Bluesky, then my 1 million followers on X can hear it.</p><p><strong>It’s interesting you mention interoperability, because that’s one of the proposals in the EU's Digital Markets Act, which feels like it’s at least trying to get at some of the problems you've outlined. Do you think it goes far enough?</strong></p><p>No, it certainly doesn't go far enough. There are some interesting ideas in there, like interoperability. But nobody in government is actually working on this. This is my problem. Not that it is a hard task, but there is nobody working on it, because they don't care. They are all in the pockets of the big technofeudal lords, as I call them.</p><p><strong>So if you believe no one in government is doing anything, how do you move forward from that?</strong></p><p>That's a very good question. I have no idea. But this is why—against my spirit, against my preferences and my desires—I'm still in politics, because there is no alternative to politics.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a discrete logic network card (334 pts)]]></title>
            <link>https://qdiv.dev/posts/eth2/</link>
            <guid>39976640</guid>
            <pubDate>Tue, 09 Apr 2024 06:24:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qdiv.dev/posts/eth2/">https://qdiv.dev/posts/eth2/</a>, See on <a href="https://news.ycombinator.com/item?id=39976640">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h5>April 9, 2024</h5><p>This post is a continuation of my journey to build a complete computer system using discrete logic components. At this point I have made a computer capable of running network applications like an HTTP server or a LAN game.</p><p>Last year I built <a href="https://qdiv.dev/posts/eth-to-spi">a physical level adapter</a> which converts a 10BASE-T Ethernet signal to SPI and back. Back then I used an STM32 microcontroller to test its operation, now I’m implementing a MAC layer module to connect it to my <a href="https://qdiv.dev/posts/ccpu">homebrew computer</a>.</p><p>Both adapters are full-duplex and have independent transmitter and receiver parts.</p><p><img src="https://qdiv.dev/eth2/overview-eth.jpg" alt="Discrete logic computer">
<em>Complete computer. The new module is bottom-right.</em></p><p><img src="https://qdiv.dev/eth2/eth.jpg" alt="ETH MAC adapter">
<em>The new module with PHY shield removed. Bodge wires fix swapped SCK and MOSI.</em></p><h2 id="receiver">Receiver
<a href="#receiver">#</a></h2><p>Summary of receiver operation:</p><ul><li>SPI serial data is converted to bytewise parallel data, byte clock is extracted;</li><li>First 6 bytes are checked against destination MAC address criteria, unmatched frames are rejected;</li><li>Bytes are written into a static RAM buffer;</li><li>When a frame ends, receiver is disabled and further frames are rejected until user re-arms the receiver. Byte counter is stopped, its value is made accessible to the user.</li></ul><p><a href="https://en.wikipedia.org/wiki/Frame_check_sequence">FCS</a> is not checked in hardware.</p><h3 id="data-collection">Data collection
<a href="#data-collection">#</a></h3><p>Firstly, serial SPI data needs to be converted into a stream of bytes.</p><p><img src="https://qdiv.dev/eth2/receiver.png" alt="Receiver"></p><p>Serial data is shifted into a shift register (<code>U32</code>). <code>U30</code> and <code>U31</code> count bits and bytes respectively. Static RAM write signal <code>recv_buf_we</code> is formed using a D flip-flop <code>U29B</code>. This signal briefly becomes low after each 8 bits of input data:</p><p><img src="https://qdiv.dev/eth2/recv_buf_we.svg" alt="recv_buf_we"></p><p>Received bytes are written into a 2 kB static RAM buffer 6116 (<code>U20</code>).</p><p><img src="https://qdiv.dev/eth2/recv-buffer.png" alt="receiver buffer"></p><p><code>U13</code>, <code>U16</code> and <code>U18</code> form an address multiplexer: it chooses either byte counter or system address bus as an address input for the SRAM (<code>U20</code>). A tri-state buffer <code>U21</code> forwards the received byte into the RAM.</p><p>To access the received data and its length, RAM and byte counter are connected to the system data bus with tri-state buffers:</p><p><img src="https://qdiv.dev/eth2/recv-output.png" alt="receiver output"></p><p><code>U25</code> connects the receiver RAM with the system data bus. After a frame is complete, the byte counter is not reset and its value is kept on the <code>recv_byte_cnt</code> bus. This bus is connected with the system data bus using <code>U26</code> and <code>U27</code>. They are activated when CPU makes a read request to specific addresses. The other half of <code>U27</code> makes a two-bit read-only status register which is used to query receiver and transmitter status.</p><h3 id="mac-address-filtering">MAC address filtering
<a href="#mac-address-filtering">#</a></h3><p>When analyzing the Ethernet traffic I noticed that frames usually come in small groups (3-4 frames together separated by a short delay). Frames in one group usually have different destination MAC addresses. This made me think that my computer won’t be able to filter received frames by MAC and re-arm the receiver fast enough to catch the frames meant for itself. I needed a hardware MAC address filtering.</p><p>Storing a custom MAC address somewhere and then comparing first 6 received bytes against it is a no-go: too complex. I could also make it a repetition of a single byte (e.g. FE:FE:FE:FE:FE:FE), but that’s boring. To bring some variation to my MAC, I made it a function of the byte index:</p><ul><li>Bit 0 is fixed to 0;</li><li>Bit 1 is fixed to 1;</li><li>Bits 2-4 are an inversion of the byte index;</li><li>Bits 5-7 are fixed to 1.</li></ul><p>Using this rule, the MAC address comes out to be <code>FE:FA:F6:F2:EE:EA</code>. We also need to accept the broadcast MAC <code>FF:FF:FF:FF:FF:FF</code> to work with ARP.</p><p><img src="https://qdiv.dev/eth2/mac-filter.png" alt="MAC filter"></p><p>On this schematics, bus <code>a[0..3]</code> is the lower 4 bits of the byte counter. Bus <code>d[0..7]</code> is the received byte. <code>U33</code> compares data bits 0 and 2-4 with their desired values, the output of <code>U34A</code> will be high when those bits match. <code>U35A</code> implements the broadcast MAC check: its output will be high when bits 0 and 2-4 are all ones. Those two signals are combined with a logical OR (implemented with diodes <code>D7</code> and resistor <code>R6</code>). The remaining bits are checked for being all ones with <code>U35B</code>.</p><p>This block only checks the validity of a single byte. To check all six of them, the result is accumulated in <code>U10A</code>. When no frame is being received, <code>ss</code> (the incoming SPI slave select signal) is low and <code>U10A</code> is set to 1. During frame reception this value is updated for each received byte. If destination MAC address matches the criteria, the value of <code>U10A</code> stays high. When byte address reaches 5, the final value is latched into <code>U36B</code>. Its output is used to inhibit frame reception if destination address is unmatched.</p><h2 id="transmitter">Transmitter
<a href="#transmitter">#</a></h2><p>Similarly to the receiver, the transmitter doesn’t implement FCS generation, it is done in software. To simplify the transmitter even further, I decided to only support frames of a fixed length. This way no complex digital comparator is necessary, the frame transmission logic only depends on a single bit of the byte counter. I selected the frame length to be 1024 bytes, this is close to the usual MTU of 1500 bytes. The frame preamble (the sequence of several 0x55 ending with a 0xD5 required by 10BASE-T) is also included in those 1024 bytes and needs to be loaded there in software.</p><p>Fixing the frame length doesn’t have any effect on higher-level protocols because they encode the packet size in their headers and do not rely on the actual Ethernet frame length.</p><p>Summary of transmitter operation:</p><ul><li>Data is stored in a static RAM;</li><li>20 MHz clock is fed to a 4-bit counter, its overflow output is used as a byte clock;</li><li>To transmit a frame, user writes to a specific write-only memory location which enables the counter;</li><li>Parallel byte data is serialized using a shift register.</li></ul><h3 id="counters">Counters
<a href="#counters">#</a></h3><p><img src="https://qdiv.dev/eth2/tx-counters.png" alt="tx counters"></p><p>Same as in the receiver, two counters are used to count bits (<code>U12</code>) and bytes (<code>U14</code>). First counter is fed by a 20 MHz clock from an integrated oscillator. 20 MHz is not used directly, but only divided at least by 2. This way the duty cycle of the oscillator doesn’t affect the output signal.</p><h3 id="data-flow">Data flow
<a href="#data-flow">#</a></h3><p><img src="https://qdiv.dev/eth2/tx-dataflow.png" alt="tx data flow"></p><p>Same as in the receiver three 74HC157 multiplexors (not shown here) are used to select address input for the RAM (<code>U22</code>). <code>U23</code> is used to load data into the RAM. <code>U24</code> acts as an intermediate storage for the byte currently being transmitted. The idea here is similar to my <a href="https://qdiv.dev/posts/vga/#image-generation">VGA pipeline</a>: byte counter 74HC4040 is a ripple counter and is slow to stabilize, <code>U24</code> provides a stable output while RAM output is still invalid. This data is fed to the shift register <code>U28</code> and shifted bit-by-bit.</p><p><em>After I’d built the thing I noticed that I’d messed up the order of bits coming from the RAM to the shift register. I had to shuffle bits in software to workaround this hardware bug. This was something I couldn’t test in Verilog beforehand.</em></p><p>To form a nice 10BASE-T signal (see <a href="https://qdiv.dev/posts/eth-to-spi/#transmitter">my previous post</a>) <code>MOSI</code> and <code>SCK</code> should be precisely synchronized. <code>U11A</code> and <code>U8B</code> achieve that. <code>tx_cnt0</code> (bit 0 of the bit counter, 20 MHz divided by 2) is used as a clock. <code>U11A</code> changes its output in sync with this signal. <code>U8B</code> delays the clock to match the delay introduced by <code>U11A</code>. Because a D-latch is more complex than a simple AND gate and has a slightly larger (by 5 ns) delay, a faster 74LV74A is used here. Its propagation delay is the same as of 74HC08. This is the only chip of a “fast” family on this board.</p><h2 id="cpu-interface">CPU interface
<a href="#cpu-interface">#</a></h2><p>From the programmer’s point of view, my Ethernet adapter has following interface:</p><ul><li>Both frame buffers are mapped at <code>0xF000</code>.</li><li>There are two read-only registers:<ul><li>8-bit status register at <code>0xFB00</code> has two flags:<ul><li><code>RX_FULL</code> - a frame is received,</li><li><code>TX_BUSY</code> - a frame is being transmitted;</li></ul></li><li>16-bit received data length register at <code>0xFB02</code>.</li></ul></li><li>Writing any value at <code>0xFB00</code> re-arms the receiver.</li><li>Writing any value at <code>0xFB01</code> starts a transmission.</li></ul><p>There are no interrupts since my CPU doesn’t support them.</p><p><img src="https://qdiv.dev/eth2/addr-select.png" alt="address selector"></p><p>Any relevant address starts with an <code>F</code> (upper 4 bits are all ones). This condition is checked by <code>U2A</code>.</p><p>Bit 11 should be 0 for a buffer address. <code>U1D</code>, <code>D2</code>, <code>R2</code> and <code>U1E</code> check that. Then the buffer select signal is combined with either write- or output-enable signals to select writing to the TX buffer or reading from the RX buffer.</p><p>Second hex digit being <code>B</code> (1011) for registers is checked by <code>U1B</code> and <code>U2B</code>. Then another diode logic block (<code>D1</code>, <code>R1</code>, <code>U1C</code>) combines it with the first digit check. Decoders <code>U4A</code> and <code>U4B</code> are used to select the individual function.</p><p>Two LEDs indicate buffer or register access.</p><h2 id="programming">Programming
<a href="#programming">#</a></h2><p>I wanted a network support for my computer, but didn’t want to implement a TCP/IP stack myself. Also I wanted a decent C compiler because my first compiler sucked and programming in assembly is annoying. So I made a <a href="https://github.com/imihajlow/ccpu-cc">C compiler</a>. It is mature enough to compile uIP 1.0 (a tiny TCP/IP library). Despite my CPU having awfully low code density, uIP is small enough to fit into RAM and have some place left for an actual application.</p><p>Network performance is very low, but I’m still very happy with it considering that no commercial CPUs or special chips are involved here:</p><ul><li>Ping round trip average 85 ms;</li><li>HTTP server download speed 2.6 kB/s (serving static files from the SD card).</li></ul><h2 id="project-repository">Project repository
<a href="#project-repository">#</a></h2><p>Models, schematic files and PCB drawings are located <a href="https://github.com/imihajlow/ccpu">on github</a>.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I Tripped Over the Debian Weak Keys Vulnerability (301 pts)]]></title>
            <link>https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html</link>
            <guid>39976225</guid>
            <pubDate>Tue, 09 Apr 2024 04:36:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html">https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html</a>, See on <a href="https://news.ycombinator.com/item?id=39976225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">

				
				<p>
					Posted: Tue,  9 April 2024
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html">permalink</a>
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html#comments">
						
							No comments
						
					</a>
				</p>
<p><em>Those of you who haven’t been in IT for far, far too long might not know that next month will be the 16th(!) anniversary of the <a href="https://security-tracker.debian.org/tracker/DSA-1571-1">disclosure</a> of what was, at the time, a fairly earth-shattering revelation: that for about 18 months, the Debian OpenSSL package was <a href="https://security-tracker.debian.org/tracker/CVE-2008-0166">generating entirely predictable private keys</a>.</em></p>

<p>The recent <a href="https://en.wikipedia.org/wiki/XZ_Utils_backdoor">xz-stential threat</a> (thanks to <a href="https://infosec.exchange/@nixCraft@mastodon.social">@nixCraft</a> for <a href="https://mastodon.social/@nixCraft/112219225728684695">making me aware of that one</a>), has got me thinking about my own serendipitous interaction with a major vulnerability.
Given that the statute of limitations has (probably) run out, I thought I’d share it as a tale of how “huh, that’s weird” can be a powerful threat-hunting tool – but only if you’ve got the time to keep pulling at the thread.</p>

<h2 id="prelude-to-an-adventure">Prelude to an Adventure</h2>

<p>Our story begins back in March 2008.
I was working at Engine Yard (EY), a now largely-forgotten Rails-focused hosting company, which pioneered several advances in Rails application deployment.
Probably EY’s greatest claim to lasting fame is that they helped launch a little code hosting platform you might have heard of, by providing them free infrastructure when they were little more than a glimmer in the Internet’s eye.</p>

<p>I am, of course, talking about everyone’s favourite Microsoft product: GitHub.</p>

<p>Since GitHub was in the right place, at the right time, with a compelling product offering, they quickly started to gain traction, and grow their userbase.
With growth comes challenges, amongst them the one we’re focusing on today: SSH login times.
Then, as now, GitHub provided SSH access to the git repos they hosted, by SSHing to <code>git@github.com</code> with publickey authentication.
They were using the standard way that everyone manages SSH keys: the <code>~/.ssh/authorized_keys</code> file, and that became a problem as the number of keys started to grow.</p>

<p>The way that SSH uses this file is that, when a user connects and asks for publickey authentication, SSH opens the <code>~/.ssh/authorized_keys</code> file and scans all of the keys listed in it, looking for a key which matches the key that the user presented.
This linear search is normally not a huge problem, because nobody in their right mind puts more than a few keys in their <code>~/.ssh/authorized_keys</code>, right?</p>

<figure>
<img src="https://www.hezmatt.org/~mpalmer/blog/images/2008_github_auth_keys_sideeye.jpg" alt="2008-era GitHub giving monkey puppet side-eye to the idea that nobody stores many keys in an authorized_keys file">
</figure>

<p>Of course, as a popular, rapidly-growing service, GitHub was gaining users at a fair clip, to the point that the one big file that stored all the SSH keys was starting to visibly impact SSH login times.
This problem was also not going to get any better by itself.
Something Had To Be Done.</p>

<p>EY management was keen on making sure GitHub ran well, and so despite it not <em>really</em> being a hosting problem, they were willing to help fix this problem.
For some reason, the late, great, Ezra Zygmuntowitz pointed GitHub in my direction, and let me take the time to <em>really</em> get into the problem with the GitHub team.
After examining a variety of different possible solutions, we came to the conclusion that the least-worst option was to patch OpenSSH to lookup keys in a MySQL database, indexed on the key fingerprint.</p>

<p>We didn’t take this decision on a whim – it wasn’t a case of “yeah, sure, let’s just hack around with OpenSSH, what could possibly go wrong?”.
We knew it was potentially catastrophic if things went sideways, so you can imagine how much worse the other options available were.
Ensuring that this wouldn’t compromise security was a lot of the effort that went into the change.
In the end, though, we rolled it out in early April, and lo! SSH logins were fast, and we were pretty sure we wouldn’t have to worry about this problem for a long time to come.</p>

<p>Normally, you’d think “patching OpenSSH to make mass SSH logins super fast” would be a good story on its own.
But no, this is just the opening scene.</p>

<h2 id="chekovs-gun-makes-its-appearance">Chekov’s Gun Makes its Appearance</h2>

<p>Fast forward a little under a month, to the first few days of May 2008.
I get a message from one of the GitHub team, saying that <em>somehow</em> users were able to access other users’ repos over SSH.
Naturally, as we’d recently rolled out the OpenSSH patch, which touched <em>this very thing</em>, the code I’d written was suspect number one, so I was called in to help.</p>

<figure>
<img src="https://www.hezmatt.org/~mpalmer/blog/images/the_usual_suspects.png" alt="The lineup scene from the movie The Usual Suspects">
<figcaption>
  They're called The Usual Suspects for a reason, but sometimes, it really <b>is</b> Keyser Söze
</figcaption>
</figure>

<p>Eventually, after more than a little debugging, we discovered that, somehow, there were two users with keys that had the same key fingerprint.
This <em>absolutely</em> shouldn’t happen – it’s a bit like winning the lottery twice in a row<sup id="fnref:1"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:1">1</a></sup> – unless the users had somehow shared their keys with each other, of course.
Still, it was worth investigating, just in case it was a web application bug, so the GitHub team reached out to the users impacted, to try and figure out what was going on.</p>

<p>The users professed no knowledge of each other, neither admitted to publicising their key, and couldn’t offer any explanation as to how the other person could possibly have gotten their key.</p>

<p>Then things went from “weird” to “what the…?”.
Because <em>another</em> pair of users showed up, sharing a key fingerprint – but it was a <em>different</em> shared key fingerprint.
The odds now have gone from “winning the lottery multiple times in a row” to as close to “this literally cannot happen” as makes no difference.</p>

<figure>
<img src="https://www.hezmatt.org/~mpalmer/blog/images/were_through_the_looking_glass.jpg" alt="Milhouse from The Simpsons says that We're Through The Looking Glass Here, People">
</figure>

<p>Once we were really, <em>really</em> confident that the OpenSSH patch wasn’t the cause of the problem, my involvement in the problem basically ended.
I wasn’t a GitHub employee, and EY had plenty of other customers who needed my help, so I wasn’t able to stay deeply involved in the on-going investigation of The Mystery of the Duplicate Keys.</p>

<p>However, the GitHub team did keep talking to the users involved, and managed to determine the only apparent common factor was that all the users claimed to be using Debian or Ubuntu systems, which was where their SSH keys would have been generated.</p>

<p>That was as far as the investigation had really goten, when along came May 13, 2008.</p>

<h2 id="chekovs-gun-goes-off">Chekov’s Gun Goes Off</h2>

<p>With the publication of <a href="https://security-tracker.debian.org/tracker/DSA-1571-1">DSA-1571-1</a>, everything suddenly became clear.
Through a well-meaning but ultimately disasterous cleanup of OpenSSL’s randomness generation code, the Debian maintainer had inadvertently reduced the number of possible keys that could be generated by a given user from “bazillions” to a little over 32,000.
With so many people signing up to GitHub – some of them no doubt following best practice and freshly generating a separate key – it’s unsurprising that some collisions occurred.</p>

<p>You can imagine the sense of “oooooooh, so <em>that’s</em> what’s going on!” that rippled out once the issue was understood.
I was mostly glad that we had conclusive evidence that my OpenSSH patch wasn’t at fault, little knowing how much more contact I was to have with Debian weak keys in the future, running <a href="https://pwnedkeys.com/">a huge store of known-compromised keys</a> and using them to find <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1620772">misbehaving Certificate Authorities</a>, amongst other things.</p>

<h2 id="lessons-learned">Lessons Learned</h2>

<p>While I’ve not found a description of exactly when and how Luciano Bello discovered the vulnerability that became CVE-2008-0166, I presume he first came across it some time before it was disclosed – likely before GitHub tripped over it.
The stable Debian release that included the vulnerable code had been released a year earlier, so there was plenty of time for Luciano to have discovered key collisions and go “hmm, I wonder what’s going on here?”, then keep digging until the solution presented itself.</p>

<p>The thought “hmm, that’s odd”, followed by intense investigation, leading to the discovery of a major flaw is also what ultimately brought down the recent XZ backdoor.
The critical part of that sequence is the ability to <em>do</em> that intense investigation, though.</p>

<p>When I reflect on my brush with the Debian weak keys vulnerability, what sticks out to me is the fact that I <em>didn’t</em> do the deep investigation.
I wonder if Luciano hadn’t found it, how long it might have been before it was found.
The GitHub team would have continued investigating, presumably, and perhaps they (or I) would have eventually dug deep enough to find it.
But we were all super busy – myself, working support tickets at EY, and GitHub feverishly building features and fighting the fires in their rapidly-growing service.</p>

<p>As it was, Luciano <em>was</em> able to take the time to dig in and find out what was happening, but just like the XZ backdoor, I feel like we, as an industry, got a bit lucky that someone with the skills, time, and energy was on hand at the right time to make a huge difference.</p>

<p>It’s a luxury to be able to take the time to really dig into a problem, and it’s a luxury that most of us rarely have.
Perhaps an understated takeaway is that somehow we all need to wrestle back some time to follow our hunches and really dig into the things that make us go “hmm…”.</p>

<h2 id="support-my-hunches">Support My Hunches</h2>

<p>If you’d like to help me be able to do intense investigations of mysterious software phenomena, you can <a href="https://ko-fi.com/tobermorytech">shout me a refreshing beverage on ko-fi</a>.</p>



<hr>
			
			

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MapSCII – A Braille and ASCII world map renderer for the console (133 pts)]]></title>
            <link>https://github.com/rastapasta/mapscii</link>
            <guid>39975887</guid>
            <pubDate>Tue, 09 Apr 2024 02:58:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rastapasta/mapscii">https://github.com/rastapasta/mapscii</a>, See on <a href="https://news.ycombinator.com/item?id=39975887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">MapSCII - The Whole World In Your Console. <a href="https://travis-ci.com/rastapasta/mapscii" rel="nofollow"><img src="https://camo.githubusercontent.com/d7d076fbc026aa6986f301975e2539fc1b94b7dfb9b50e4143af6a3c035c2879/68747470733a2f2f7472617669732d63692e636f6d2f726173746170617374612f6d6170736369692e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/rastapasta/mapscii.svg?branch=master"></a></h2><a id="user-content-mapscii---the-whole-world-in-your-console-" aria-label="Permalink: MapSCII - The Whole World In Your Console. " href="#mapscii---the-whole-world-in-your-console-"></a></div>
<p dir="auto">A node.js based <a href="http://wiki.openstreetmap.org/wiki/Vector_tiles" rel="nofollow">Vector Tile</a> to <a href="http://www.fileformat.info/info/unicode/block/braille_patterns/utf8test.htm" rel="nofollow">Braille</a> and <a href="https://de.wikipedia.org/wiki/American_Standard_Code_for_Information_Interchange" rel="nofollow">ASCII</a> renderer for <a href="https://en.wikipedia.org/wiki/Xterm" rel="nofollow">xterm</a>-compatible terminals.</p>
<p dir="auto"><a href="https://asciinema.org/a/117813?autoplay=1" rel="nofollow"><img src="https://cloud.githubusercontent.com/assets/1259904/25480718/497a64e2-2b4a-11e7-9cf0-ed52ee0b89c0.png" alt="asciicast"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try it out!</h2><a id="user-content-try-it-out" aria-label="Permalink: Try it out!" href="#try-it-out"></a></p>

<p dir="auto">If you're on Windows, use the open source telnet client <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html" rel="nofollow">PuTTY</a> to connect.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Use your mouse to drag and zoom in and out!</li>
<li>Discover Point-of-Interests around any given location</li>
<li>Highly customizable layer styling with <a href="https://www.mapbox.com/mapbox-gl-style-spec/" rel="nofollow">Mapbox Styles</a> support</li>
<li>Connect to any public or private vector tile server</li>
<li>Or just use the supplied and optimized <a href="https://github.com/osm2vectortiles">OSM2VectorTiles</a> based one</li>
<li>Work offline and discover local <a href="https://github.com/mapbox/vector-tile-spec">VectorTile</a>/<a href="https://github.com/mapbox/mbtiles-spec">MBTiles</a></li>
<li>Compatible with most Linux and OSX terminals</li>
<li>Highly optimized algorithms for a smooth experience</li>
<li>100% pure JavaScript! 😎</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to run it locally</h2><a id="user-content-how-to-run-it-locally" aria-label="Permalink: How to run it locally" href="#how-to-run-it-locally"></a></p>
<p dir="auto">With a modern node installation available, just start it with</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">How to install it locally</h2><a id="user-content-how-to-install-it-locally" aria-label="Permalink: How to install it locally" href="#how-to-install-it-locally"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">With npm</h3><a id="user-content-with-npm" aria-label="Permalink: With npm" href="#with-npm"></a></p>
<p dir="auto">If you haven't already got Node.js &gt;= version 10, then <a href="http://nodejs.org/" rel="nofollow">go get it</a>.</p>

<p dir="auto">If you're on OSX, or get an error about file permissions, you may need to do <code>sudo npm install -g mapscii</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">With snap</h3><a id="user-content-with-snap" aria-label="Permalink: With snap" href="#with-snap"></a></p>
<p dir="auto">In any of the <a href="https://snapcraft.io/docs/core/install" rel="nofollow">supported Linux distros</a>:</p>
<div data-snippet-clipboard-copy-content="sudo snap install mapscii"><pre><code>sudo snap install mapscii
</code></pre></div>
<p dir="auto">(This snap is maintained by <a href="https://github.com/nathanhaines/">@nathanhaines</a>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running</h2><a id="user-content-running" aria-label="Permalink: Running" href="#running"></a></p>
<p dir="auto">This is pretty simple too.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Keyboard shortcuts</h2><a id="user-content-keyboard-shortcuts" aria-label="Permalink: Keyboard shortcuts" href="#keyboard-shortcuts"></a></p>
<ul dir="auto">
<li>Arrows <strong>up</strong>, <strong>down</strong>, <strong>left</strong>, <strong>right</strong> to scroll around</li>
<li>Press <strong>a</strong> or <strong>z</strong> to zoom in and out</li>
<li>Press <strong>c</strong> to switch to block character mode</li>
<li>Press <strong>q</strong> to quit</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mouse control</h2><a id="user-content-mouse-control" aria-label="Permalink: Mouse control" href="#mouse-control"></a></p>
<p dir="auto">If your terminal supports mouse events you can drag the map and use your scroll wheel to zoom in and out.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Behind the scenes</h2><a id="user-content-behind-the-scenes" aria-label="Permalink: Behind the scenes" href="#behind-the-scenes"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Libraries</h3><a id="user-content-libraries" aria-label="Permalink: Libraries" href="#libraries"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mastering the console</h4><a id="user-content-mastering-the-console" aria-label="Permalink: Mastering the console" href="#mastering-the-console"></a></p>
<ul dir="auto">
<li><a href="https://github.com/substack/node-x256"><code>x256</code></a> for converting RGB values to closest xterm-256 <a href="https://en.wikipedia.org/wiki/File:Xterm_256color_chart.svg" rel="nofollow">color code</a></li>
<li><a href="https://github.com/CoderPuppy/term-mouse"><code>term-mouse</code></a> for mouse handling</li>
<li><a href="https://github.com/TooTallNate/keypress"><code>keypress</code></a> for input handling</li>
<li><a href="https://github.com/sindresorhus/string-width"><code>string-width</code></a> to determine visual string lengths</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Discovering the map data</h4><a id="user-content-discovering-the-map-data" aria-label="Permalink: Discovering the map data" href="#discovering-the-map-data"></a></p>
<ul dir="auto">
<li><a href="https://github.com/mapbox/vector-tile-js"><code>vector-tile</code></a> for <a href="https://github.com/mapbox/vector-tile-spec/tree/master/2.1">VectorTile</a> parsing</li>
<li><a href="https://github.com/mapbox/pbf"><code>pbf</code></a> for <a href="https://developers.google.com/protocol-buffers/" rel="nofollow">Protobuf</a> decoding</li>
<li><a href="https://github.com/mapbox/node-mbtiles"><code>mbtiles</code></a> for <a href="https://github.com/mapbox/mbtiles-spec/blob/master/1.2/spec.md">MBTiles</a> parsing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Juggling the vectors and numbers</h4><a id="user-content-juggling-the-vectors-and-numbers" aria-label="Permalink: Juggling the vectors and numbers" href="#juggling-the-vectors-and-numbers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/mapbox/earcut"><code>earcut</code></a> for polygon triangulation</li>
<li><a href="https://github.com/mourner/rbush"><code>rbush</code></a> for 2D spatial indexing of geo and label data</li>
<li><a href="https://github.com/madbence/node-bresenham"><code>bresenham</code></a> for line point calculations</li>
<li><a href="https://github.com/mourner/simplify-js"><code>simplify-js</code></a> for polyline simplifications</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Handling the flow</h4><a id="user-content-handling-the-flow" aria-label="Permalink: Handling the flow" href="#handling-the-flow"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bitinn/node-fetch"><code>node-fetch</code></a> for HTTP requests</li>
<li><a href="https://github.com/sindresorhus/env-paths"><code>env-paths</code></a> to determine where to persist downloaded tiles</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">TODOs</h3><a id="user-content-todos" aria-label="Permalink: TODOs" href="#todos"></a></p>
<ul dir="auto">
<li>
<p dir="auto">MapSCII</p>
<ul>
<li>
<p dir="auto"> GeoJSON support via <a href="https://github.com/mapbox/geojson-vt">geojson-vt</a></p>
</li>
<li>
<p dir="auto"> CLI support</p>
<ul dir="auto">
<li>[-] startup parameters
<ul>
<li> TileSource</li>
<li> Style</li>
<li> center position</li>
<li> zoom</li>
<li> demo mode?</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"> mouse control</p>
<ul>
<li> hover POIs/labels</li>
<li> hover maybe even polygons/-lines?</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">Styler</p>
<ul>
<li> respect zoom based style ranges</li>
</ul>
</li>
<li>
<p dir="auto">Renderer</p>
<ul>
<li> download and process tiles in a different thread (<a href="https://github.com/rastapasta/mapscii/issues/3" data-hovercard-type="issue" data-hovercard-url="/rastapasta/mapscii/issues/3/hovercard">#3</a>)</li>
<li> optimize renderer for large areas (<a href="https://github.com/rastapasta/mapscii/issues/6" data-hovercard-type="issue" data-hovercard-url="/rastapasta/mapscii/issues/6/hovercard">#6</a>)</li>
<li> label drawing
<ul>
<li> multi line label?</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">TileSource</p>
<ul>
<li> implement single vector-tile handling</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Special thanks</h2><a id="user-content-special-thanks" aria-label="Permalink: Special thanks" href="#special-thanks"></a></p>
<ul dir="auto">
<li><a href="https://github.com/lukasmartinelli">lukasmartinelli</a> &amp; <a href="https://github.com/manuelroth">manuelroth</a> for all their work on <a href="https://github.com/osm2vectortiles">OSM2VectorTiles</a> (global vector tiles from <a href="https://wiki.openstreetmap.org/wiki/Planet.osm" rel="nofollow">OSM Planet</a>)</li>
<li><a href="https://github.com/mourner">mourner</a> for all his work on mindblowing GIS algorithms (like the used <a href="https://github.com/mapbox/earcut">earcut</a>, <a href="https://github.com/mourner/rbush">rbush</a>, <a href="https://github.com/mourner/simplify-js">simplify-js</a>, ..)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licenses</h2><a id="user-content-licenses" aria-label="Permalink: Licenses" href="#licenses"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Map data</h3><a id="user-content-map-data" aria-label="Permalink: Map data" href="#map-data"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">The Open Data Commons Open Database License (oDbl)</h4><a id="user-content-the-open-data-commons-open-database-license-odbl" aria-label="Permalink: The Open Data Commons Open Database License (oDbl)" href="#the-open-data-commons-open-database-license-odbl"></a></p>
<p dir="auto"><a href="https://www.openstreetmap.org/" rel="nofollow">OpenStreetMap</a> is open data, licensed under the <a href="http://opendatacommons.org/licenses/odbl/" rel="nofollow">Open Data Commons Open Database License</a> (ODbL) by the <a href="http://osmfoundation.org/" rel="nofollow">OpenStreetMap Foundation</a> (OSMF).</p>
<p dir="auto">You are free to copy, distribute, transmit and adapt our data, as long as you credit OpenStreetMap and its contributors. If you alter or build upon our data, you may distribute the result only under the same licence. The full <a href="http://opendatacommons.org/licenses/odbl/1.0/" rel="nofollow">legal code</a> explains your rights and responsibilities.</p>
<p dir="auto">The cartography in our map tiles, and our documentation, are licenced under the <a href="http://creativecommons.org/licenses/by-sa/2.0/" rel="nofollow">Creative Commons Attribution-ShareAlike 2.0</a> licence (CC BY-SA).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MapSCII</h3><a id="user-content-mapscii" aria-label="Permalink: MapSCII" href="#mapscii"></a></p>
<ul dir="auto">
<li><a href="https://github.com/rastapasta/mapscii/blob/master/LICENSE">License</a></li>
<li><a href="https://github.com/rastapasta/mapscii/blob/master/AUTHORS">Authors</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BART to offer final rides on original equipment on April 20 (122 pts)]]></title>
            <link>https://www.trains.com/trn/news-reviews/news-wire/bart-to-offer-final-rides-on-original-equipment-on-april-20/</link>
            <guid>39975865</guid>
            <pubDate>Tue, 09 Apr 2024 02:52:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.trains.com/trn/news-reviews/news-wire/bart-to-offer-final-rides-on-original-equipment-on-april-20/">https://www.trains.com/trn/news-reviews/news-wire/bart-to-offer-final-rides-on-original-equipment-on-april-20/</a>, See on <a href="https://news.ycombinator.com/item?id=39975865">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><strong>'Riding into History' event will operate on original 24-mile segment to Fremont, Calif.</strong></p><div><figure id="attachment_170302" aria-describedby="caption-attachment-170302"><img fetchpriority="high" decoding="async" src="https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day.jpg" alt="Black and white photo of rapid-transit equipment in underground station" width="1000" height="761" srcset="https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day.jpg 1000w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-300x228.jpg 300w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-768x584.jpg 768w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-600x457.jpg 600w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-400x304.jpg 400w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-200x152.jpg 200w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-350x266.jpg 350w" sizes="(max-width: 1000px) 100vw, 1000px"><figcaption id="caption-attachment-170302">A Bay Area Rapid Transit prototype train poses at the Lake Merritt station in Oakland prior to the start of service, in late 1971 or early 1972. While BART removed the last of the original equipment from service last September, it will hold a farewell event on April 20. BART</figcaption></figure>
<hr>
<p>OAKLAND, Calif. — Bay Area Rapid Transit, the 131-mile electrified rail network in the San Francisco Bay Area, is offering the public a last chance to ride the 1970s-era futuristic railcars that made up its original fleet.</p>
<p>On Saturday, April 20, at 1 p.m. at the MacArthur station in Oakland, BART will commemorate the cars with a ceremony and then run two 10-car trains using original cars for the last time. Anyone can ride for the usual fare.</p>
<p>“We understand that BART cars are iconic, especially the sloped-front A cars,” said BART spokesperson Jim Allison. “We just wanted to give them a proper sendoff so that people had a chance to say goodbye to the cars that have been serving the Bay Area for more than 50 years.”</p>
<p>The special trains will run about 24 miles from MacArthur to Fremont, the first segment of BART to open 52 years ago. The trains will make the usual stops and run more loops between the two stations if needed to accommodate everyone who wants to ride, he said.</p>
<p>The “Riding into History: Final Run of the First Fleet” event will include speeches, a raffle for a couple of railcar plates, and probably some merchandise for sale, Allison said. Some details were still being decided early this month.</p>
<p>April 20 is coincidentally the same day when the electric trains of the Key System, a BART predecessor, ran their final miles in 1958.</p>
<p>The legacy fleet ended regular service in September 2023; when that date was set, BART had indicated it would eventually hold a special farewell event [see <a href="https://www.trains.com/trn/news-reviews/news-wire/bart-to-retire-last-original-cars-on-sept-11/" target="_blank" rel="noopener">“BART to retire last original cars …,”</a> Trains News Wire, Aug. 25, 2023]. Most of the legacy equipment has already been recycled, but BART is donating three cars — one each of the A, B and C versions — to the Western Railway Museum at Rio Vista Junction, which is run by the Bay Area Electric Railroad Association. Five other cars were awarded in 2022 for reuse ranging from an arcade area at an Oakland bar and grill to use in firefighter training [see “<a href="https://www.trains.com/trn/news-reviews/news-wire/bart-to-award-eight-retired-cars-for-reuse/" target="_blank" rel="noopener">BART to award eight retired cars ..,”</a> News Wire, March 16, 2022].</p>
<p>When it opened on Sept. 11, 1972, BART was the first entirely new rail transit system built in the United States in decades, built to an atypical 5-foot, 6-inch gauge for reasons <a href="https://www.bart.gov/news/articles/2022/news20220708-2" target="_blank" rel="noopener">the agency explains here</a>. Its technology, advanced for the time, included central computer control, on-board electronic propulsion and “the lightest weight car per passenger ever built,” the museum says. The intended effect was space age, not subway.</p>
<p>Museum volunteers will ride the last trains, staff a table, and speak for a few minutes at the farewell, said Andy Payne, a museum archivist and author of “Legacy Fleet,” an upcoming book about the cars.</p>
<p>The museum will receive the cars in June and intends to place them in its Loring C. Jensen Memorial Car House 3. “We are planning exhibits near the cars showcasing the history of the BART system and the legacy fleet,” he said. “In the future, if funding allows, we would love to build the <a href="https://www.wrm.org/fundraising-campaigns/rapid-transit-history-center" target="_blank" rel="noopener">Rapid Transit History Center</a>” that would feature the cars and other aspects of Bay Area electric rail history.</p>
<p>The museum runs historic equipment from several electric railroads on about 6 miles of ex-Sacramento Northern track with overhead wire, but can’t operate the BART cars, because of their gauge and need for third-rail power.</p>
<p>According to BART, the 669 cars in the legacy fleet used 1,000-volt DC electricity for propulsion, with one 150 hp motor per axle and four motors per car. The fleet had:</p>
<ul>
<li>59 A2 cars and 380 B2 cars, built by aerospace company Rohr Industries. They began service in 1972, and were rehabilitated in 1997 and 2002.</li>
<li>150 C1 cars from Alstom. They entered service in 1988, and were never rehabilitated.</li>
<li>80 C2 cars from Morrison-Knudsen. They began service in 1994, and were never rehabilitated.</li>
</ul>
<p>Each car was 70 feet long, except for the A model, 75 feet with a cab.</p>
<p>BART’s new <a href="https://www.bart.gov/about/projects/cars" target="_blank" rel="noopener">Fleet of the Future</a> consists of 775 cars from Bombardier, later bought by Alstom. Also 70 feet long, each car uses 1,000-volt DC electricity, gets power from a third rail, and has two trucks with one 194-hp motor per axle, and two axles per truck.</p>
<p><em>— Updated at 1:30 p.m. CT to correct caption information.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Distributed SQLite: Paradigm shift or hype? (233 pts)]]></title>
            <link>https://kerkour.com/distributed-sqlite</link>
            <guid>39975596</guid>
            <pubDate>Tue, 09 Apr 2024 01:51:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kerkour.com/distributed-sqlite">https://kerkour.com/distributed-sqlite</a>, See on <a href="https://news.ycombinator.com/item?id=39975596">Hacker News</a></p>
Couldn't get https://kerkour.com/distributed-sqlite: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[TSAC: Low Bitrate Audio Compression (206 pts)]]></title>
            <link>https://bellard.org/tsac/</link>
            <guid>39975331</guid>
            <pubDate>Tue, 09 Apr 2024 01:00:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bellard.org/tsac/">https://bellard.org/tsac/</a>, See on <a href="https://news.ycombinator.com/item?id=39975331">Hacker News</a></p>
<div id="readability-page-1" class="page">


<p>
TSAC is an audio compression utility reaching very low bitrates such
as 5.5 kb/s for mono or 7.5 kb/s for stereo at 44.1 kHz with a good
perceptual quality. Hence TSAC compresses a 3.5 minute stereo song to
a file of 192 KiB.
</p>
<p>
An Nvidia GPU is necessary for fast operation. CPU only is also
supported but slower.
</p>

<h2>Compression Results</h2>

<p>The audio extracts are
from <a href="https://listening-test.coresv.net/results.htm">here</a>.
</p>
  
<p>
  Waiting (Pops):
</p>
<table>
  <tbody><tr>
    <td>original<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting.wav" type="audio/wav"></audio>
    </td><td>stereo 7.26 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting_stereo.wav" type="audio/wav"></audio>
    </td><td>mono 5.61 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting_mono.wav" type="audio/wav"></audio>
    </td><td>stereo 2.99 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting_stereo_q5.wav" type="audio/wav"></audio>
  </td></tr>
</tbody></table>

<p>
  Greatest_Love_of_All_2min57 (Pops):
</p>
<table>
  <tbody><tr> 
   <td>original<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_of_All_2min57.wav" type="audio/wav"></audio>
   </td><td>stereo 6.79 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_stereo.wav" type="audio/wav"></audio>
   </td><td>mono 5.02 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_stereo.wav" type="audio/wav"></audio>
   </td><td>stereo 2.84 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_stereo_q5.wav" type="audio/wav"></audio>
  </td></tr>
</tbody></table>

<p>
  9-Have-big-expensive-car.441 (Pops):
</p>
<table>
<tbody><tr> 
   <td>original<br>
     <audio controls=""><source src="https://bellard.org/tsac/9-Have-big-expensive-car.441.wav" type="audio/wav"></audio>
   </td><td>stereo 7.81 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Have-big-expensive-car_stereo.wav" type="audio/wav"></audio>
   </td><td>mono 5.91 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Have-big-expensive-car_mono.wav" type="audio/wav"></audio>
   </td><td>stereo 3.25 kb/s<br>
     <audio controls=""><source src="https://bellard.org/tsac/Have-big-expensive-car_stereo_q5.wav" type="audio/wav"></audio>
</td></tr>
</tbody></table>

<p>
  21-classic.441 (Classic):
</p>
<table>
<tbody><tr> 
   <td>original<br>
     <audio controls=""><source src="https://bellard.org/tsac/21-classic.441.wav" type="audio/wav"></audio>
   </td><td>stereo 6.21 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/classic_stereo.wav" type="audio/wav"></audio>
   </td><td>mono 4.71 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/classic_mono.wav" type="audio/wav"></audio>
   </td><td>stereo 2.57 kb/s<br>
     <audio controls=""><source src="https://bellard.org/tsac/classic_stereo_q5.wav" type="audio/wav"></audio>
</td></tr>
</tbody></table>

<p>
  4-Sound-English-male.441 (Voice):
</p>
<table>
  <tbody><tr>
    <td>original<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441.wav" type="audio/wav"></audio>
    </td><td>mono 6.79 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441_mono.wav" type="audio/wav"></audio>
    </td><td>mono 3.74 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441_mono_q5.wav" type="audio/wav"></audio>
    </td><td>mono 2.18 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441_mono_q3.wav" type="audio/wav"></audio>
  </td></tr>
</tbody></table>

<h2>Download</h2>

<ul>
  <li>Linux version: <a href="https://bellard.org/tsac/tsac-2024-04-08.tar.gz">tsac-2024-04-08.tar.gz</a>. (<a href="https://bellard.org/tsac/readme.txt">readme.txt</a>)</li>
  <li>Windows version (experimental): <a href="https://bellard.org/tsac/tsac-2024-04-08-win64.zip">tsac-2024-04-08-win64.zip</a>.</li>
</ul>

<h2>Technical information</h2>
<ul>
  <li><code>tsac</code> is based on a modified version of
    the <a href="https://github.com/descriptinc/descript-audio-codec">Descript
      Audio Codec</a> extended for stereo and a Transformer model to further
    increase the compression ratio. Both models are quantized to 8 bits
    per parameter.</li>
  <li>The Transformer model is evaluated in a deterministic and
    reproducible way. Hence the result does not depend on the exact
    GPU or CPU model nor on the number of configured threads. This key
    point ensures that a compressed file can be decompressed using a
    different hardware or software configuration.</li>
</ul>

<hr>
Fabrice Bellard - <a href="https://bellard.org/">https://bellard.org/</a>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[1.18k drawings of plant root systems (306 pts)]]></title>
            <link>https://images.wur.nl/digital/collection/coll13/search</link>
            <guid>39974646</guid>
            <pubDate>Mon, 08 Apr 2024 23:11:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://images.wur.nl/digital/collection/coll13/search">https://images.wur.nl/digital/collection/coll13/search</a>, See on <a href="https://news.ycombinator.com/item?id=39974646">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Hello OLMo: A truly open LLM (352 pts)]]></title>
            <link>https://blog.allenai.org/hello-olmo-a-truly-open-llm-43f7e7359222?gi=760105621962</link>
            <guid>39974374</guid>
            <pubDate>Mon, 08 Apr 2024 22:26:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.allenai.org/hello-olmo-a-truly-open-llm-43f7e7359222?gi=760105621962">https://blog.allenai.org/hello-olmo-a-truly-open-llm-43f7e7359222?gi=760105621962</a>, See on <a href="https://news.ycombinator.com/item?id=39974374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a href="https://ai2.medium.com/?source=post_page-----43f7e7359222--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="AI2" src="https://miro.medium.com/v2/resize:fill:88:88/2*SvB65gf75EGAqMn3yoQBqA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://blog.allenai.org/?source=post_page-----43f7e7359222--------------------------------" rel="noopener  ugc nofollow"><div aria-hidden="false"><p><img alt="AI2 Blog" src="https://miro.medium.com/v2/resize:fill:48:48/1*CFYlEW-OV_f22ROc3Lr52g.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div><figure></figure><p id="9388">As the world races to deploy AI models that are effective and safe, the demand for Open Large Language Models (LLMs) has exploded. The massive adoption of both open and closed AI models means that AI capabilities have leapfrogged our ability to understand how they are created. Releasing the OLMo framework will provide the industry with an opportunity to understand what is going on inside AI models.</p><p id="fdbf">Today, <a href="https://allenai.org/olmo" rel="noopener ugc nofollow" target="_blank">The Allen Institute for AI (AI2) </a>has released <a href="https://huggingface.co/allenai/OLMo-7B" rel="noopener ugc nofollow" target="_blank">OLMo 7B</a>, a truly open, state-of-the-art large language model released alongside the pre-training data and training code. This empowers researchers and developers to use the best <em>and</em> open models to advance the science of language models collectively.</p><blockquote><p id="c46e">“Open foundation models have been critical in driving a burst of innovation and development around generative AI,” said Yann LeCun, Chief AI Scientist at Meta. “The vibrant community that comes from open source is the fastest and most effective way to build the future of AI.”</p></blockquote><p id="05f0">OLMo and the framework is designed to aid researchers in training and experimenting with large language models. They are available for direct download on <a href="https://huggingface.co/allenai/OLMo-7B" rel="noopener ugc nofollow" target="_blank">Hugging Face</a> and in <a href="https://github.com/allenai/OLMo" rel="noopener ugc nofollow" target="_blank">GitHub</a>. This work was made possible, in part, via a collaboration with the <a href="https://www.harvard.edu/kempner-institute/" rel="noopener ugc nofollow" target="_blank">Kempner Institute for the Study of Natural and Artificial Intelligence at Harvard University</a> and partners including <a href="https://www.amd.com/en.html" rel="noopener ugc nofollow" target="_blank">AMD</a>, <a href="https://www.csc.fi/en/home" rel="noopener ugc nofollow" target="_blank">CSC</a> (<a href="https://www.lumi-supercomputer.eu/" rel="noopener ugc nofollow" target="_blank">Lumi Supercomputer</a>), the <a href="https://www.cs.washington.edu/" rel="noopener ugc nofollow" target="_blank">Paul G. Allen School of Computer Science &amp; Engineering at the University of Washington</a> and <a href="https://www.databricks.com/" rel="noopener ugc nofollow" target="_blank">Databricks</a>.</p><p id="5d96">The framework features a suite of completely open AI development tools, including:</p><ul><li id="8b40"><strong>Full pretraining data</strong>: The model is built on AI2’s <a rel="noopener ugc nofollow" target="_blank" href="https://blog.allenai.org/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64">Dolma</a> set which features three trillion token open corpus for language model pretraining, including code that produces the training data.</li><li id="b143"><strong>Training code and model weights:</strong> The OLMo framework includes full model weights for four model variants at the 7B scale, each trained to at least 2T tokens. Inference code, training metrics and training logs are all provided.</li><li id="9b2a"><strong>Evaluation: </strong>We’ve released the evaluation suite used in development, complete with 500+ checkpoints per model, from every 1000 steps during the training process and evaluation code under the umbrella of the Catwalk project.</li></ul><blockquote><p id="923f">“I’m enthusiastic about getting OLMo into the hands of AI researchers,” said Eric Horvitz, Microsoft’s Chief Scientific Officer and a founding member of the AI2 Scientific Advisory Board. “The new offering continues Allen AI’s tradition of providing valuable open models, tools, and data, which have spurred numerous advancements in AI across the global community.”</p></blockquote><h2 id="c157"><strong>A truly open model</strong></h2><p id="7709">By making OLMo and its training data fully available to the public, AI2 has taken a big step towards collaboratively building the best open language model in the world. In the coming months, AI2 will continue to iterate on OLMo and will bring different model sizes, modalities, datasets, and capabilities into the OLMo family.</p><blockquote><p id="7f01">“Many language models today are published with limited transparency. Without having access to training data, researchers cannot scientifically understand how a model is working. It’s the equivalent of drug discovery without clinical trials or studying the solar system without a telescope,” said <a href="https://homes.cs.washington.edu/~hannaneh/" rel="noopener ugc nofollow" target="_blank">Hanna Hajishirzi</a>, OLMo project lead, a senior director of NLP Research at AI2, and a professor in the UW’s Allen School. “With our new framework, researchers will finally be able to study the science of LLMs, which is critical to building the next generation of safe and trustworthy AI.”</p></blockquote><p id="edf2">With OLMo, AI researchers and developers will experience:</p><ul><li id="c6b3"><strong>More Precision:</strong> With full insight into the training data behind the model, researchers will be able to work faster and no longer need to depend on qualitative assumptions of how we feel the model is performing but can test it scientifically.</li><li id="3b50"><strong>Less Carbon: </strong>Currently one training run is equivalent to the emissions of <a href="https://www.epa.gov/energy/greenhouse-gas-equivalencies-calculator" rel="noopener ugc nofollow" target="_blank">nine US homes for one year.</a> By opening the full training and evaluation ecosystem, it radically reduces developmental redundancies, which is critical in the decarbonization of AI</li><li id="d283"><strong>Lasting results:</strong> Keeping models and their datasets in the open and not behind APIs enables researchers to learn and build from previous models and work.</li></ul><p id="64be">“With OLMo, open <em>actually </em>means ‘open’ and everyone in the AI research community will have access to all aspects of model creation, including training code, evaluation methods, data, and so on” said <a href="https://nasmith.github.io/" rel="noopener ugc nofollow" target="_blank">Noah Smith</a>, OLMo project lead, a senior director of NLP Research at AI2, and a professor in the UW’s Allen School. “AI was once an open field centered on an active research community, but as models grew, became more expensive, and started turning into commercial products, AI work started to happen behind closed doors. With OLMo we hope to work against this trend and empower the research community to come together to better understand and engage with language models in a scientific way, leading to more responsible AI technology that benefits everyone.”</p><p id="f6a3">“With AI2’s deep expertise in natural language processing combined with AMD high-performance computing engines, the OLMo models developed on the LUMI Supercomputer powered by AMD EPYC™ CPUs and AMD Instinct™ accelerators offer a unique opportunity to truly expand AI experimentation and innovation and advance the industry like never before. This new open framework will provide the AI research community across the world with trusted resources and a platform to contribute to and work directly on language models.” — Ian Ferreria, Senior Director, AI Solutions, AMD</p><p id="70eb">“We are happy that we can contribute to this important initiative by providing the computing capacity from the LUMI supercomputer along with our expertise. Public supercomputers like LUMI play a vital role in the infrastructure for open and transparent AI.” Dr. Pekka Manninen, Director of Science and Technology, CSC</p><p id="ba67">LUMI supercomputer in Finland is hosted by CSC, and owned by EuroHPC Joint Undertaking and 10 European countries. LUMI is the fastest supercomputer in Europe, and is known for its entirely carbon-free operations and was critical in supporting the pre-training work necessary to develop OLMo.</p><p id="f366">“Databricks is excited to be collaborating with the Allen Institute for AI on the release of their OLMo open source model and framework. OLMo sets the standard for what it means to be open. Everyone in academia, industry, and the broader community will benefit enormously from access to not only the model but all of the training details, including the data, code, and intermediate checkpoints. I am especially proud that this model was developed on the Mosaic AI model training platform from Databricks. As with all great open source releases, the best is yet to come now that these artifacts and tools are in the hands of the community.” — Jonathan Frankle, Chief Scientist (Neural Networks), Databricks.</p><h2 id="d1d1">Learn more</h2><p id="d09a"><a rel="noopener ugc nofollow" target="_blank" href="https://blog.allenai.org/olmo-open-language-model-87ccfc95f580">Getting started with OLMo technical blog</a></p><p id="6458"><a href="https://allenai.org/olmo/olmo-paper.pdf" rel="noopener ugc nofollow" target="_blank">OLMo 7B technical report</a></p><p id="08bd"><a href="https://huggingface.co/allenai/OLMo-7B" rel="noopener ugc nofollow" target="_blank">Get OLMo 7B</a></p><p id="59fc">For more information on the OLMo framework and The Allen Institute for AI visit <a href="https://allenai.org/olmo" rel="noopener ugc nofollow" target="_blank">here</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[llm.c – LLM training in simple, pure C/CUDA (937 pts)]]></title>
            <link>https://github.com/karpathy/llm.c</link>
            <guid>39973467</guid>
            <pubDate>Mon, 08 Apr 2024 20:38:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/karpathy/llm.c">https://github.com/karpathy/llm.c</a>, See on <a href="https://news.ycombinator.com/item?id=39973467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">llm.c</h2><a id="user-content-llmc" aria-label="Permalink: llm.c" href="#llmc"></a></p>
<p dir="auto">LLM training in simple, pure C/CUDA. There is no need for 245MB of PyTorch or 107MB of cPython. For example, training GPT-2 (CPU, fp32) is ~1,000 lines of clean code in a single file. It compiles and runs instantly, and exactly matches the PyTorch reference implementation. I chose GPT-2 as the first working example because it is the grand-daddy of LLMs, the first time the modern stack was put together.</p>
<p dir="auto">Currently, I am working on:</p>
<ul dir="auto">
<li>direct CUDA implementation, which will be significantly faster and probably come close to PyTorch.</li>
<li>speed up the CPU version with SIMD instructions, AVX2 on x86 / NEON on ARM (e.g. Apple Silicon).</li>
<li>more modern architectures, e.g. Llama2, Gemma, etc.</li>
</ul>
<p dir="auto">For the repo, I'd like to maintain both clean, simple reference implementations alongside a also lot more optimized versions that can come close to PyTorch, but in a tiny fraction of the code and dependencies.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">quick start</h2><a id="user-content-quick-start" aria-label="Permalink: quick start" href="#quick-start"></a></p>
<p dir="auto">Download and tokenize a dataset. The <a href="https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt" rel="nofollow">tinyshakespeare</a> dataset is the fastest to download and tokenize:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python prepro_tinyshakespeare.py"><pre>python prepro_tinyshakespeare.py</pre></div>
<p dir="auto">This prints:</p>
<div data-snippet-clipboard-copy-content="Saved 32768 tokens to data/tiny_shakespeare_val.bin
Saved 305260 tokens to data/tiny_shakespeare_train.bin"><pre><code>Saved 32768 tokens to data/tiny_shakespeare_val.bin
Saved 305260 tokens to data/tiny_shakespeare_train.bin
</code></pre></div>
<p dir="auto">The .bin files are raw byte streams of int32 numbers indicating the token ids with the GPT-2 tokenizer. Alternatively you could also tokenize the <a href="https://huggingface.co/datasets/roneneldan/TinyStories" rel="nofollow">TinyStories</a> dataset with <code>prepro_tinystories.py</code>.</p>
<p dir="auto">In principle we'd be ready to the train the model right here. However the baseline CPU/fp32 reference code is so inefficient that it's not practical to train these models from scratch yet. Instead, we initialize with the GPT-2 weights released by OpenAI and just do finetuning. For that, we have to download the GPT-2 weights and save them as a checkpoint we can load in C:</p>

<p dir="auto">You'll recognize this code from nanoGPT as a simple GPT-2 reference implementation in PyTorch. This script will download the GPT-2 (124M) model, overfit a single batch of data for 10 iterations, run a few steps of generation, and most importantly it will save two files: 1) the <code>gpt2_124M.bin</code> file that contains the raw model weights for loading in C, and <code>gpt2_124M_debug_state.bin</code>, which also contains more debug state: the inputs, targets, logits and loss. This is very useful for debugging C code, for unit testing, and making sure we're exactly matching the PyTorch reference implementation. For now all we care about are the model weights in <code>gpt2_124M.bin</code>. We can now initialize with them and train in raw C. First compile the code:</p>

<p dir="auto">You can have a look inside the <code>Makefile</code> and its comments. It will try to autodetect if OpenMP is available on your system, which is very helpful for speeding up the code at very low cost of code complexity. Once <code>train_gpt2</code> is compiled, you can run it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="OMP_NUM_THREADS=8 ./train_gpt2"><pre>OMP_NUM_THREADS=8 ./train_gpt2</pre></div>
<p dir="auto">You should tune the number of threads depending on how many cores your CPU has. The program will load the model weights, the tokens, it will run a finetuning loop for a few iterations with Adam lr 1e-4, and then generate a sample from the model. The file is (I think) very readable and you should have a look. Simply, there are implementations for the forward and backward pass of all the layers, and they get strung together into a large, manual, forward/backward/update loop. The output looks like this on my MacBook Pro (Apple Silicon M3 Max):</p>
<div data-snippet-clipboard-copy-content="[GPT-2]
max_seq_len: 1024
vocab_size: 50257
num_layers: 12
num_heads: 12
channels: 768
num_parameters: 124439808
train dataset num_batches: 1192
val dataset num_batches: 128
num_activations: 73323776
val loss 5.252026
step 0: train loss 5.356189 (took 1452.121000 ms)
step 1: train loss 4.301069 (took 1288.673000 ms)
step 2: train loss 4.623322 (took 1369.394000 ms)
step 3: train loss 4.600470 (took 1290.761000 ms)
... (trunctated) ...
step 39: train loss 3.970751 (took 1323.779000 ms)
val loss 4.107781
generated: 50256 16773 18162 21986 11 198 13681 263 23875 198 3152 262 11773 2910 198 1169 6002 6386 2583 286 262 11858 198 20424 428 3135 7596 995 3675 13 198 40 481 407 736 17903 11 329 703 6029 706 4082 198 42826 1028 1128 633 263 11 198 10594 407 198 2704 454 680 1028 262 1027 28860 286 198 3237 323
step 40: train loss 4.377757 (took 1366.368000 ms)"><pre><code>[GPT-2]
max_seq_len: 1024
vocab_size: 50257
num_layers: 12
num_heads: 12
channels: 768
num_parameters: 124439808
train dataset num_batches: 1192
val dataset num_batches: 128
num_activations: 73323776
val loss 5.252026
step 0: train loss 5.356189 (took 1452.121000 ms)
step 1: train loss 4.301069 (took 1288.673000 ms)
step 2: train loss 4.623322 (took 1369.394000 ms)
step 3: train loss 4.600470 (took 1290.761000 ms)
... (trunctated) ...
step 39: train loss 3.970751 (took 1323.779000 ms)
val loss 4.107781
generated: 50256 16773 18162 21986 11 198 13681 263 23875 198 3152 262 11773 2910 198 1169 6002 6386 2583 286 262 11858 198 20424 428 3135 7596 995 3675 13 198 40 481 407 736 17903 11 329 703 6029 706 4082 198 42826 1028 1128 633 263 11 198 10594 407 198 2704 454 680 1028 262 1027 28860 286 198 3237 323
step 40: train loss 4.377757 (took 1366.368000 ms)
</code></pre></div>
<p dir="auto">The generation just gives you the token ids for now, which we have to decode back to text. We can implement this in C quite easily also, because decoding is very straight-forward, it's just string chunk lookups and prints. For now we can use tiktoken:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import tiktoken
enc = tiktoken.get_encoding(&quot;gpt2&quot;)
print(enc.decode(list(map(int, &quot;50256 16773 18162 21986 11 198 13681 263 23875 198 3152 262 11773 2910 198 1169 6002 6386 2583 286 262 11858 198 20424 428 3135 7596 995 3675 13 198 40 481 407 736 17903 11 329 703 6029 706 4082 198 42826 1028 1128 633 263 11 198 10594 407 198 2704 454 680 1028 262 1027 28860 286 198 3237 323&quot;.split()))))"><pre><span>import</span> <span>tiktoken</span>
<span>enc</span> <span>=</span> <span>tiktoken</span>.<span>get_encoding</span>(<span>"gpt2"</span>)
<span>print</span>(<span>enc</span>.<span>decode</span>(<span>list</span>(<span>map</span>(<span>int</span>, <span>"50256 16773 18162 21986 11 198 13681 263 23875 198 3152 262 11773 2910 198 1169 6002 6386 2583 286 262 11858 198 20424 428 3135 7596 995 3675 13 198 40 481 407 736 17903 11 329 703 6029 706 4082 198 42826 1028 1128 633 263 11 198 10594 407 198 2704 454 680 1028 262 1027 28860 286 198 3237 323"</span>.<span>split</span>()))))</pre></div>
<p dir="auto">which prints:</p>
<div data-snippet-clipboard-copy-content="<|endoftext|>Come Running Away,
Greater conquer
With the Imperial blood
the heaviest host of the gods
into this wondrous world beyond.
I will not back thee, for how sweet after birth
Netflix against repounder,
will not
flourish against the earlocks of
Allay"><pre><code>&lt;|endoftext|&gt;Come Running Away,
Greater conquer
With the Imperial blood
the heaviest host of the gods
into this wondrous world beyond.
I will not back thee, for how sweet after birth
Netflix against repounder,
will not
flourish against the earlocks of
Allay
</code></pre></div>
<p dir="auto">I like how Netflix comes up, it's clear that the shadow of the training past is still lurking in the model. I did not attempt to tune the finetuning hyperparameters so it's quite likely this can be improved quite a bit, most likely especially if one was to train a bit longer.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">test</h2><a id="user-content-test" aria-label="Permalink: test" href="#test"></a></p>
<p dir="auto">I am also attaching a simple unit test for making sure our C code agrees with the PyTorch code. Compile and run with:</p>
<div data-snippet-clipboard-copy-content="make test_gpt2
./test_gpt2"><pre><code>make test_gpt2
./test_gpt2
</code></pre></div>
<p dir="auto">This now loads the <code>gpt2_124M_debug_state.bin</code> file, runs a forward pass, compares the logits and loss with the PyTorch reference implementation, then it does 10 iterations of training with Adam and makes sure the losses match PyTorch.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">license</h2><a id="user-content-license" aria-label="Permalink: license" href="#license"></a></p>
<p dir="auto">MIT</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I looking into an apparently scammy looking zsh plugin manager called “zi” (166 pts)]]></title>
            <link>https://recurse.social/@dylnuge/112224580867240812</link>
            <guid>39973341</guid>
            <pubDate>Mon, 08 Apr 2024 20:25:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://recurse.social/@dylnuge/112224580867240812">https://recurse.social/@dylnuge/112224580867240812</a>, See on <a href="https://news.ycombinator.com/item?id=39973341">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[GNU Stow needs a co-maintainer (162 pts)]]></title>
            <link>https://savannah.gnu.org/bugs/index.php?65569</link>
            <guid>39973296</guid>
            <pubDate>Mon, 08 Apr 2024 20:20:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://savannah.gnu.org/bugs/index.php?65569">https://savannah.gnu.org/bugs/index.php?65569</a>, See on <a href="https://news.ycombinator.com/item?id=39973296">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="top">


<!-- end pagemenu -->


<h2><i><a href="https://savannah.gnu.org/bugs/index.php?65569">bug #65569</a></i>: Stow needs a co-maintainer</h2>

<form action="/bugs/index.php" method="post" enctype="multipart/form-data" name="item_form">






<table>
<tbody><tr>
<td>Submitter:&nbsp;</td>
<td><a href="https://savannah.gnu.org/users/aspiers">Adam Spiers &lt;aspiers&gt;</a></td>
<td colspan="2"><span> </span></td>
</tr>
<tr>
<td>Submitted:&nbsp;</td>
<td>Sun 07 Apr 2024 10:49:12 PM UTC</td>
<td colspan="2"><span></span></td>
</tr>

<tr>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td colspan="2"><span></span></td>
</tr>
<tr><td colspan="4">&nbsp;</td></tr>

<tr><td><span title="Generally high level modules or functionalities of the software (e.g. User interface, Configuration Manager, etc)">Category:</span>&nbsp;</td>
<td>None</td>
<td><span title="Impact of the item on the system (Critical, Major,...)">Severity:</span>&nbsp;</td>
<td>4 - Important</td>
</tr>

<tr><td><span title="Characterizes the nature of the item (e.g. Crash Error, Documentation Typo, Installation Problem, etc">Item Group:</span>&nbsp;</td>
<td>None</td>
<td><span title="Current status of the item">Status:</span>&nbsp;</td>
<td>None</td>
</tr>

<tr><td><span title="Whether the item can be seen by members of the group only or anybody">Privacy:</span>&nbsp;</td>
<td>Public</td>
<td><span title="Who is in charge of handling this item">Assigned to:</span>&nbsp;</td>
<td>aspiers</td>
</tr>

<tr><td><span title="Most basic status of the item: is the item considered as dealt with or not.">Open/Closed:</span>&nbsp;</td>
<td>Open</td>
</tr></tbody></table>
<p><span>* Mandatory Fields</span></p>


<!-- closing hidsubpart -->



<div id="hidsubpartcontentdiscussion">

<table>
<tbody><tr>
</tr>

<tr><td>
<a id="comment0" href="#comment0">
Sun 07 Apr 2024 10:49:12 PM UTC, <b>original submission:</b>
</a>&nbsp;<br>

</td>
<td><a href="https://savannah.gnu.org/users/aspiers">Adam Spiers &lt;aspiers&gt;</a><br>
<span><img src="https://savannah.gnu.org/images/Savannah.theme/roles/project-admin.png" alt="Group administrator" width="24" height="24"></span><img src="https://savannah.gnu.org/images/Savannah.theme/roles/assignee.png" title="In charge of this item." alt="" width="24" height="24"></td></tr>
</tbody></table>


</div><!-- closing hidsubpart -->



<div id="hidsubpartcontentattached">
<p>(Note: upload size limit is set to 16384 kB, after insertion of
the required escape characters.)</p>
<p><span> Attach Files:</span><br>
&nbsp;&nbsp;&nbsp;  <br>
&nbsp;&nbsp;&nbsp;  
<br>
<span>Comment:</span><br>
&nbsp;&nbsp;&nbsp;
</p>
<p><span>No files currently attached</span></p>


</div><!-- closing hidsubpart -->



<div id="hidsubpartcontentdependencies">
<p>Depends on the following items: None found</p>
<p>Items that depend on this one: None found</p>



</div><!-- closing hidsubpart -->



<div id="hidsubpartcontentcc">
<p>Carbon-Copy List</p><!-- end boxtitle -->
<li><!-- email --> <span title="This information is not provided to anonymous users">-email is unavailable-</span> added by <a href="https://savannah.gnu.org/users/aspiers">aspiers</a> <span>(Submitted the item)</span>
</li></div><!-- closing hidsubpart -->



<div id="hidsubpartcontentvotes">

<p>There are 0 votes so far. Votes easily highlight which items people would like to see resolved
in priority, independently of the priority of the item set by tracker
managers.</p>
<p><span>Only logged-in users can vote.</span></p>


</div><!-- closing hidsubpart -->
<p><label for="check">Please enter the title of <a href="https://en.wikipedia.org/wiki/George_Orwell">George Orwell</a>'s famous
dystopian book (it's a date):</label> </p>

</form>



<p><span>No changes have been made to this item</span>
</p><!-- closing hidsubpart -->

<p>
<a href="#top"><img src="https://savannah.gnu.org/images/Savannah.theme/arrows/top.orig.png" alt="Back to the top" width="48" height="48"></a>
</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Shorebird 1.0, Flutter Code Push (140 pts)]]></title>
            <link>https://github.com/shorebirdtech/shorebird</link>
            <guid>39973150</guid>
            <pubDate>Mon, 08 Apr 2024 20:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/shorebirdtech/shorebird">https://github.com/shorebirdtech/shorebird</a>, See on <a href="https://news.ycombinator.com/item?id=39973150">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Shorebird 🐦</h2><a id="user-content-shorebird-" aria-label="Permalink: Shorebird 🐦" href="#shorebird-"></a></p>
<p dir="auto">Shorebird is now 1.0! 🎉
<a href="https://shorebird.dev/blogs/1.0/" rel="nofollow">https://shorebird.dev/blogs/1.0/</a></p>
<p dir="auto"><a href="https://discord.gg/shorebird" rel="nofollow"><img src="https://camo.githubusercontent.com/6acba6e415f6c81398bad9a0c59c970f4aa3ad6c989444867bf013de7be7e264/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f73686f726562697264" alt="Discord" data-canonical-src="https://dcbadge.vercel.app/api/server/shorebird"></a> <a href="https://www.producthunt.com/posts/shorebird-code-push?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-shorebird-code-push" rel="nofollow"><img src="https://camo.githubusercontent.com/b08569ec81275f60134342e9de2983deedda055128c916986d5cd073276c0d8f/68747470733a2f2f6170692e70726f6475637468756e742e636f6d2f776964676574732f656d6265642d696d6167652f76312f66656174757265642e7376673f706f73745f69643d343439393436267468656d653d6e65757472616c" alt="Shorebird Code Push - Flutter over the air updates | Product Hunt" width="128" height="27" data-canonical-src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=449946&amp;theme=neutral"></a></p>
<p dir="auto"><a href="https://github.com/shorebirdtech/shorebird/actions/workflows/main.yaml"><img src="https://github.com/shorebirdtech/shorebird/actions/workflows/main.yaml/badge.svg" alt="ci"></a>
<a href="https://github.com/shorebirdtech/shorebird/actions/workflows/e2e.yaml"><img src="https://github.com/shorebirdtech/shorebird/actions/workflows/e2e.yaml/badge.svg" alt="e2e"></a>
<a href="https://codecov.io/gh/shorebirdtech/shorebird" rel="nofollow"><img src="https://camo.githubusercontent.com/df8ca8f5d16dc465d02d9a6fc25787930a4e27eddd1eb4e5154472851ee13bec/68747470733a2f2f636f6465636f762e696f2f67682f73686f726562697264746563682f73686f7265626972642f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/shorebirdtech/shorebird/branch/main/graph/badge.svg"></a>
<a href="https://github.com/shorebirdtech/shorebird/blob/main/LICENSE-MIT"><img src="https://camo.githubusercontent.com/2bb6ac78e5a9f4f688a6a066cc71b62012101802fcdb478e6e4c6b6ec75dc694/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/license-MIT-blue.svg"></a>
<a href="https://github.com/shorebirdtech/shorebird/blob/main/LICENSE-APACHE"><img src="https://camo.githubusercontent.com/36c44c97bcc8c33e0c833dde2f92c250868fb071a455eb98042ce5d5cec6073b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4170616368652d6f72616e67652e737667" alt="License: Apache" data-canonical-src="https://img.shields.io/badge/license-Apache-orange.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Visit <a href="https://docs.shorebird.dev/" rel="nofollow">https://docs.shorebird.dev</a> to get started.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Packages</h2><a id="user-content-packages" aria-label="Permalink: Packages" href="#packages"></a></p>
<p dir="auto">This repository is a monorepo containing the following packages:</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/shorebird_cli/README.md">shorebird_cli</a></td>
<td>Command-line which allows developers to interact with various Shorebird services</td>
</tr>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/shorebird_code_push_client/README.md">shorebird_code_push_client</a></td>
<td>Dart library which allows Dart applications to interact with the ShoreBird CodePush API</td>
</tr>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/shorebird_code_push_protocol/README.md">shorebird_code_push_protocol</a></td>
<td>Dart library which contains common interfaces used by Shorebird CodePush</td>
</tr>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/artifact_proxy/README.md">artifact_proxy</a></td>
<td>Dart server which supports intercepting and proxying Flutter artifact requests.</td>
</tr>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/discord_gcp_alerts/README.md">discord_gcp_alerts</a></td>
<td>Dart server which forwards GCP alerts to Discord</td>
</tr>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/jwt/README.md">jwt</a></td>
<td>Dart library for verifying Json Web Tokens</td>
</tr>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/redis_client/README.md">redis_client</a></td>
<td>Dart library for interacting with Redis</td>
</tr>
<tr>
<td><a href="https://github.com/shorebirdtech/shorebird/blob/main/packages/scoped/README.md">scoped</a></td>
<td>A simple dependency injection library built on Zones</td>
</tr>
</tbody>
</table>
<p dir="auto">For more information, please refer to the documentation for each package.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">If you're interested in contributing, please join us on
<a href="https://discord.gg/shorebird" rel="nofollow">Discord</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Environment setup</h3><a id="user-content-environment-setup" aria-label="Permalink: Environment setup" href="#environment-setup"></a></p>
<p dir="auto">Working on Shorebird requires Dart.</p>
<p dir="auto"><code>./scripts/bootstrap.sh</code> will run <code>pub get</code> all packages in the repository.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running tests</h3><a id="user-content-running-tests" aria-label="Permalink: Running tests" href="#running-tests"></a></p>
<p dir="auto">We don't yet have a script to run tests locally. For now, we recommend using
<code>very_good test -r</code> in the packages directory to run all shorebird tests.</p>
<p dir="auto">(If you run it in the root, it will find packages in bin/cache/flutter and try
to run tests there, some of which will fail.)</p>
<p dir="auto">To generate a coverage report install <code>lcov</code>:</p>

<p dir="auto">Then run tests with the <code>--coverage</code> flag:</p>
<div data-snippet-clipboard-copy-content="very_good test -r --coverage
genhtml coverage/lcov.info -o coverage"><pre><code>very_good test -r --coverage
genhtml coverage/lcov.info -o coverage
</code></pre></div>
<p dir="auto">You can view the generated coverage report via:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Tracking coverage</h3><a id="user-content-tracking-coverage" aria-label="Permalink: Tracking coverage" href="#tracking-coverage"></a></p>
<p dir="auto">The following command will generate a coverage report for the Dart packages:</p>
<div dir="auto" data-snippet-clipboard-copy-content="dart test --coverage=coverage &amp;&amp; dart pub global run coverage:format_coverage --lcov --in=coverage --out=coverage/lcov.info --packages=.dart_tool/package_config.json --check-ignore"><pre>dart <span>test</span> --coverage=coverage <span>&amp;&amp;</span> dart pub global run coverage:format_coverage --lcov --in=coverage --out=coverage/lcov.info --packages=.dart_tool/package_config.json --check-ignore</pre></div>
<p dir="auto">Coverage reports are uploaded to <a href="https://app.codecov.io/gh/shorebirdtech/shorebird" rel="nofollow">Codecov</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Shorebird projects are licensed for use under either Apache License, Version 2.0
(LICENSE-APACHE or <a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">http://www.apache.org/licenses/LICENSE-2.0</a>) MIT license
(LICENSE-MIT or <a href="http://opensource.org/licenses/MIT" rel="nofollow">http://opensource.org/licenses/MIT</a>) at your option.</p>
<p dir="auto">See our license philosophy for more information on why we license files this
way:
<a href="https://github.com/shorebirdtech/handbook/blob/main/engineering.md#licensing-philosophy">https://github.com/shorebirdtech/handbook/blob/main/engineering.md#licensing-philosophy</a></p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>