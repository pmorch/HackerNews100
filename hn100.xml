<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 11 Mar 2024 12:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: RE3 – Reversed Engineered GTA3 Source Code (121 pts)]]></title>
            <link>https://github.com/halpz/re3</link>
            <guid>39665017</guid>
            <pubDate>Mon, 11 Mar 2024 04:53:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/halpz/re3">https://github.com/halpz/re3</a>, See on <a href="https://news.ycombinator.com/item?id=39665017">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/halpz/re3/blob/master/res/images/logo_1024.png?raw=true"><img src="https://github.com/halpz/re3/raw/master/res/images/logo_1024.png?raw=true" alt="re3 logo" width="200"></a></p>
<p dir="auto"><a href="https://actions-badge.atrox.dev/GTAmodding/re3/goto?ref=master" rel="nofollow"><img src="https://camo.githubusercontent.com/1508b6f62669dc0b23cb2a1b91f8aef5dc3b946b611a59dc321682ecfe96dcaa/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e742e7376673f75726c3d6874747073253341253246253246616374696f6e732d62616467652e6174726f782e6465762532464754416d6f6464696e6725324672653325324662616467652533467265662533446d6173746572267374796c653d666c6174" alt="Build Status" data-canonical-src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2FGTAmodding%2Fre3%2Fbadge%3Fref%3Dmaster&amp;style=flat"></a>
<a href="https://discord.gg/RFNbjsUMGg" rel="nofollow"><img src="https://camo.githubusercontent.com/e1d2dd4598108ac98c8d4250d7574a307c1017ef81b319667c53a1de19332324/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d6a6f696e2d3732383944412e7376673f6c6f676f3d646973636f7264266c6f6e6743616368653d74727565267374796c653d666c6174" data-canonical-src="https://img.shields.io/badge/discord-join-7289DA.svg?logo=discord&amp;longCache=true&amp;style=flat"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Intro</h2><a id="user-content-intro" aria-label="Permalink: Intro" href="#intro"></a></p>
<p dir="auto">In this repository you'll find the fully reversed source code for GTA III (<a href="https://github.com/halpz/re3/tree/master/">master</a> branch) and GTA VC (<a href="https://github.com/halpz/re3/tree/miami/">miami</a> branch).</p>
<p dir="auto">It has been tested and works on Windows, Linux, MacOS and FreeBSD, on x86, amd64, arm and arm64.<br>
Rendering is handled either by original RenderWare (D3D8)
or the reimplementation <a href="https://github.com/aap/librw">librw</a> (D3D9, OpenGL 2.1 or above, OpenGL ES 2.0 or above).<br>
Audio is done with MSS (using dlls from original GTA) or OpenAL.</p>
<p dir="auto">The project has also been ported to the <a href="https://github.com/AGraber/re3-nx/">Nintendo Switch</a>,
<a href="https://github.com/Rinnegatamante/re3">Playstation Vita</a> and
<a href="https://github.com/GaryOderNichts/re3-wiiu/">Nintendo Wii U</a>.</p>
<p dir="auto">We cannot build for PS2 or Xbox yet. If you're interested in doing so, get in touch with us.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ul dir="auto">
<li>re3 requires PC game assets to work, so you <strong>must</strong> own <a href="https://store.steampowered.com/app/12100/Grand_Theft_Auto_III/" rel="nofollow">a copy of GTA III</a>.</li>
<li>Build re3 or download the latest build:
<ul dir="auto">
<li><a href="https://nightly.link/GTAmodding/re3/workflows/re3_msvc_x86/master/re3_Release_win-x86-librw_d3d9-mss.zip" rel="nofollow">Windows D3D9 MSS 32bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/re3_msvc_amd64/master/re3_Release_win-amd64-librw_d3d9-oal.zip" rel="nofollow">Windows D3D9 64bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/re3_msvc_amd64/master/re3_Release_win-amd64-librw_gl3_glfw-oal.zip" rel="nofollow">Windows OpenGL 64bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/build-cmake-conan/master/ubuntu-18.04-gl3.zip" rel="nofollow">Linux 64bit</a></li>
<li><a href="https://nightly.link/GTAmodding/re3/workflows/build-cmake-conan/master/macos-latest-gl3.zip" rel="nofollow">MacOS 64bit x86-64</a></li>
</ul>
</li>
<li>Extract the downloaded zip over your GTA 3 directory and run re3. The zip includes the binary, updated and additional gamefiles and in case of OpenAL the required dlls.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107704085-fbdabd00-6cbc-11eb-8406-8951a80ccb16.png"><img src="https://user-images.githubusercontent.com/1521437/107704085-fbdabd00-6cbc-11eb-8406-8951a80ccb16.png" alt="re3 2021-02-11 22-57-03-23"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107703339-cbdeea00-6cbb-11eb-8f0b-07daa105d470.png"><img src="https://user-images.githubusercontent.com/1521437/107703339-cbdeea00-6cbb-11eb-8f0b-07daa105d470.png" alt="re3 2021-02-11 22-43-44-98"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107703343-cd101700-6cbb-11eb-9ccd-012cb90524b7.png"><img src="https://user-images.githubusercontent.com/1521437/107703343-cd101700-6cbb-11eb-9ccd-012cb90524b7.png" alt="re3 2021-02-11 22-46-33-76"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/1521437/107703348-d00b0780-6cbb-11eb-8afd-054249c2b95e.png"><img src="https://user-images.githubusercontent.com/1521437/107703348-d00b0780-6cbb-11eb-8afd-054249c2b95e.png" alt="re3 2021-02-11 22-50-29-54"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Improvements</h2><a id="user-content-improvements" aria-label="Permalink: Improvements" href="#improvements"></a></p>
<p dir="auto">We have implemented a number of changes and improvements to the original game.
They can be configured in <code>core/config.h</code>.
Some of them can be toggled at runtime, some cannot.</p>
<ul dir="auto">
<li>Fixed a lot of smaller and bigger bugs</li>
<li>User files (saves and settings) stored in GTA root directory</li>
<li>Settings stored in re3.ini file instead of gta3.set</li>
<li>Debug menu to do and change various things (Ctrl-M to open)</li>
<li>Debug camera (Ctrl-B to toggle)</li>
<li>Rotatable camera</li>
<li>XInput controller support (Windows)</li>
<li>No loading screens between islands ("map memory usage" in menu)</li>
<li>Skinned ped support (models from Xbox or Mobile)</li>
<li>Rendering
<ul dir="auto">
<li>Widescreen support (properly scaled HUD, Menu and FOV)</li>
<li>PS2 MatFX (vehicle reflections)</li>
<li>PS2 alpha test (better rendering of transparency)</li>
<li>PS2 particles</li>
<li>Xbox vehicle rendering</li>
<li>Xbox world lightmap rendering (needs Xbox map)</li>
<li>Xbox ped rim light</li>
<li>Xbox screen rain droplets</li>
<li>More customizable colourfilter</li>
</ul>
</li>
<li>Menu
<ul dir="auto">
<li>Map</li>
<li>More options</li>
<li>Controller configuration menu</li>
<li>...</li>
</ul>
</li>
<li>Can load DFFs and TXDs from other platforms, possibly with a performance penalty</li>
<li>...</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">To-Do</h2><a id="user-content-to-do" aria-label="Permalink: To-Do" href="#to-do"></a></p>
<p dir="auto">The following things would be nice to have/do:</p>
<ul dir="auto">
<li>Fix physics for high FPS</li>
<li>Improve performance on lower end devices, especially the OpenGL layer on the Raspberry Pi (if you have experience with this, please get in touch)</li>
<li>Compare code with PS2 code (tedious, no good decompiler)</li>
<li><a href="https://web.archive.org/web/20210217192931/https://github.com/GTAmodding/re3/wiki/PS2-port" rel="nofollow">PS2 port</a></li>
<li>Xbox port (not quite as important)</li>
<li>reverse remaining unused/debug functions</li>
<li>compare CodeWarrior build with original binary for more accurate code (very tedious)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Modding</h2><a id="user-content-modding" aria-label="Permalink: Modding" href="#modding"></a></p>
<p dir="auto">Asset modifications (models, texture, handling, script, ...) should work the same way as with original GTA for the most part.</p>
<p dir="auto">CLEO scripts work with <a href="https://github.com/cleolibrary/CLEO-Redux">CLEO Redux</a>.</p>
<p dir="auto">Mods that make changes to the code (dll/asi, limit adjusters) will <em>not</em> work.
Some things these mods do are already implemented in re3 (much of SkyGFX, GInput, SilentPatch, Widescreen fix),
others can easily be achieved (increasing limis, see <code>config.h</code>),
others will simply have to be rewritten and integrated into the code directly.
Sorry for the inconvenience.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building from Source</h2><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<p dir="auto">When using premake, you may want to point GTA_III_RE_DIR environment variable to GTA3 root folder if you want the executable to be moved there via post-build script.</p>
<p dir="auto">Clone the repository with <code>git clone --recursive https://github.com/halpz/re3.git</code>. Then <code>cd re3</code> into the cloned repository.</p>
<details><summary>Linux Premake</summary>
<p dir="auto">For Linux using premake, proceed: <a href="https://web.archive.org/web/20210217192751/https://github.com/GTAmodding/re3/wiki/Building-on-Linux" rel="nofollow">Building on Linux</a></p>
</details>
<details><summary>Linux Conan</summary>
<p dir="auto">Install python and conan, and then run build.</p>
<div data-snippet-clipboard-copy-content="conan export vendor/librw librw/master@
mkdir build
cd build
conan install .. re3/master@ -if build -o re3:audio=openal -o librw:platform=gl3 -o librw:gl3_gfxlib=glfw --build missing -s re3:build_type=RelWithDebInfo -s librw:build_type=RelWithDebInfo
conan build .. -if build -bf build -pf package"><pre><code>conan export vendor/librw librw/master@
mkdir build
cd build
conan install .. re3/master@ -if build -o re3:audio=openal -o librw:platform=gl3 -o librw:gl3_gfxlib=glfw --build missing -s re3:build_type=RelWithDebInfo -s librw:build_type=RelWithDebInfo
conan build .. -if build -bf build -pf package
</code></pre></div>
</details>
<details><summary>MacOS Premake</summary>
<p dir="auto">For MacOS using premake, proceed: <a href="https://web.archive.org/web/20210717004757/https://github.com/GTAmodding/re3/wiki/Building-on-MacOS" rel="nofollow">Building on MacOS</a></p>
</details>
<details><summary>FreeBSD</summary>
<p dir="auto">For FreeBSD using premake, proceed: <a href="https://web.archive.org/web/20210217192740/https://github.com/GTAmodding/re3/wiki/Building-on-FreeBSD" rel="nofollow">Building on FreeBSD</a></p>
</details>
<details><summary>Windows</summary>
<p dir="auto">Assuming you have Visual Studio 2015/2017/2019:</p>
<ul dir="auto">
<li>Run one of the <code>premake-vsXXXX.cmd</code> variants on root folder.</li>
<li>Open build/re3.sln with Visual Studio and compile the solution.</li>
</ul>
<p dir="auto">Microsoft recently discontinued its downloads of the DX9 SDK. You can download an archived version here: <a href="https://archive.org/details/dxsdk_jun10" rel="nofollow">https://archive.org/details/dxsdk_jun10</a></p>
<p dir="auto"><strong>If you choose OpenAL on Windows</strong> You must read <a href="https://web.archive.org/web/20210217192855/https://github.com/GTAmodding/re3/wiki/Running-OpenAL-build-on-Windows" rel="nofollow">Running OpenAL build on Windows</a>.</p>
</details>
<blockquote>
<p dir="auto">ℹ️ premake has an <code>--with-lto</code> option if you want the project to be compiled with Link Time Optimization.</p>
</blockquote>
<blockquote>
<p dir="auto">ℹ️ There are various settings in <a href="https://github.com/halpz/re3/tree/master/src/core/config.h">config.h</a>, you may want to take a look there.</p>
</blockquote>
<blockquote>
<p dir="auto">ℹ️ re3 uses completely homebrew RenderWare-replacement rendering engine; <a href="https://github.com/aap/librw/">librw</a>. librw comes as submodule of re3, but you also can use LIBRW enviorenment variable to specify path to your own librw.</p>
</blockquote>
<p dir="auto">If you feel the need, you can also use CodeWarrior 7 to compile re3 using the supplied codewarrior/re3.mcp project - this requires the original RW33 libraries, and the DX8 SDK. The build is unstable compared to the MSVC builds though, and is mostly meant to serve as a reference.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">As long as it's not linux/cross-platform skeleton/compatibility layer, all of the code on the repo that's not behind a preprocessor condition(like FIX_BUGS) are <strong>completely</strong> reversed code from original binaries.</p>
<p dir="auto">We <strong>don't</strong> accept custom codes, as long as it's not wrapped via preprocessor conditions, or it's linux/cross-platform skeleton/compatibility layer.</p>
<p dir="auto">We accept only these kinds of PRs;</p>
<ul dir="auto">
<li>A new feature that exists in at least one of the GTAs (if it wasn't in III/VC then it doesn't have to be decompilation)</li>
<li>Game, UI or UX bug fixes (if it's a fix to original code, it should be behind FIX_BUGS)</li>
<li>Platform-specific and/or unused code that's not been reversed yet</li>
<li>Makes reversed code more understandable/accurate, as in "which code would produce this assembly".</li>
<li>A new cross-platform skeleton/compatibility layer, or improvements to them</li>
<li>Translation fixes, for languages original game supported</li>
<li>Code that increase maintainability</li>
</ul>
<p dir="auto">We have a <a href="https://github.com/halpz/re3/blob/master/CODING_STYLE.md">Coding Style</a> document that isn't followed or enforced very well.</p>
<p dir="auto">Do not use features from C++11 or later.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">History</h2><a id="user-content-history" aria-label="Permalink: History" href="#history"></a></p>
<p dir="auto">re3 was started sometime in the spring of 2018,
initially as a way to test reversed collision and physics code
inside the game.
This was done by replacing single functions of the game
with their reversed counterparts using a dll.</p>
<p dir="auto">After a bit of work the project lay dormant for about a year
and was picked up again and pushed to github in May 2019.
At the time I (aap) had reversed around 10k lines of code and estimated
the final game to have around 200-250k.
Others quickly joined the effort (Fire_Head, shfil, erorcun and Nick007J
in time order, and Serge a bit later) and we made very quick progress
throughout the summer of 2019
after which the pace slowed down a bit.</p>
<p dir="auto">Due to everyone staying home during the start of the Corona pandemic
everybody had a lot of time to work on re3 again and
we finally got a standalone exe in April 2020 (around 180k lines by then).</p>
<p dir="auto">After the initial excitement and fixing and polishing the code further,
reVC was started in early May 2020 by starting from re3 code,
not by starting from scratch replacing functions with a dll.
After a few months of mostly steady progress we considered reVC
finished in December.</p>
<p dir="auto">Since then we have started reLCS, which is currently work in progress.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">We don't feel like we're in a position to give this code a license.<br>
The code should only be used for educational, documentation and modding purposes.<br>
We do not encourage piracy or commercial use.<br>
Please keep derivate work open source and give proper credit.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[eBPF Documentary (166 pts)]]></title>
            <link>https://www.brendangregg.com/blog//2024-03-10/ebpf-documentary.html</link>
            <guid>39663135</guid>
            <pubDate>Sun, 10 Mar 2024 22:45:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brendangregg.com/blog//2024-03-10/ebpf-documentary.html">https://www.brendangregg.com/blog//2024-03-10/ebpf-documentary.html</a>, See on <a href="https://news.ycombinator.com/item?id=39663135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>eBPF is a crazy technology – like putting JavaScript into the Linux kernel –  and getting it accepted had so far been an untold story of strategy and ingenuity. The eBPF documentary, published late last year, tells this story by interviewing key players from 2014 including myself, and touches on new developments including Windows. (If you are new to eBPF, it is the name of a kernel execution engine that runs a variety of new programs in a performant and safe sandbox in the kernel, like how JavaScript can run programs safely in a browser sandbox; it is also no longer an acronym.) The documentary was played at KubeCon, and is on <a href="https://www.youtube.com/watch?v=Wb_vD3XZYOA">youtube</a>:</p>

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/Wb_vD3XZYOA?si=-i0HID5ek4hPcEOD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></center>

<p>Watching this brings me right back to 2014, to see the faces and hear their voices discussing the problems we were trying to fix. Thanks to Speakeasy Productions for doing such a great job with this <a href="https://ebpfdocumentary.com/">documentary</a>, and letting you experience what it was like in those early days. This is also a great example of all the work that goes on behind the scenes to get code merged in a large codebase like Linux.</p>

<p>When Alexei Starovoitov visited Netflix in 2014 to discuss eBPF with myself and Amer Ather, we were so entranced that we lost track of time and were eventually kicked out of the meeting room as another meeting was starting. It was then I realized that we had missed lunch! Alexei sounded so confident that I was convinced that eBPF was the future, but a couple of times he added "if the patches get merged." <em>If</em> they get merged?? They <em>have</em> to get merged, this idea is too good to waste.</p>

<p>While only several of us worked on eBPF in 2014, more joined in 2015 and later, and there are now hundreds contributing to make it what it is. A longer documentary could also interview Brendan Blanco (bcc), Yonghong Song (bcc), Sasha Goldshtein (bcc), Alastair Robertson (bpftrace), Tobais Waldekranz (ply), Andrii Nakryiko, Joe Stringer, Jakub Kicinski, Martin KaFai Lau, John Fastabend, Quentin Monnet, Jesper Dangaard Brouer, Andrey Ignatov, Stanislav Fomichev, Teng Qin, Paul Chaignon, Vicent Marti, Dan Xu, Bas Smit, Viktor Malik, Mary Marchini, and many more. Thanks to everyone for all the work.</p>

<p>Ten years later it still feels like it's early days for eBPF, and a great time to get involved: It's likely already available in your production kernels, and there are tools, libraries, and documentation to help you get started.</p>

<p>I hope you enjoy the documentary. PS. Congrats to Isovalent, the role-model eBPF startup, as Cisco recently announced they would acquire them!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lead in gasoline blunted IQ of half the U.S. population, study says (149 pts)]]></title>
            <link>https://www.nbcnews.com/health/health-news/lead-gasoline-blunted-iq-half-us-population-study-rcna19028</link>
            <guid>39662988</guid>
            <pubDate>Sun, 10 Mar 2024 22:21:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/health/health-news/lead-gasoline-blunted-iq-half-us-population-study-rcna19028">https://www.nbcnews.com/health/health-news/lead-gasoline-blunted-iq-half-us-population-study-rcna19028</a>, See on <a href="https://news.ycombinator.com/item?id=39662988">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Exposure to leaded gasoline lowered the IQ of about half the population of the United States, a new study estimates.</p><p>The peer-reviewed study, published Monday in the journal Proceedings of the National Academy of Sciences, focuses on people born before 1996 — the year the U.S. banned gas containing lead.</p><p>Overall, the researchers from Florida State University and Duke University found, childhood lead exposure cost America an estimated 824 million points, or 2.6 points per person on average.&nbsp;</p><p>Certain cohorts were more affected than others. For people born in the 1960s and the 1970s, when leaded gas consumption was skyrocketing, the IQ loss was estimated to be up to 6 points and for some, more than 7 points. Exposure to it came primarily from inhaling auto exhaust.&nbsp;</p><p>The team behind the study used gas consumption data, population estimates and other data to calculate that as of 2015, more than 170 million Americans had had blood lead levels above 5 micrograms per deciliter in their early childhood years.&nbsp;</p><p>Lead is a neurotoxin, and no amount of it is safe. Currently, 3.5 micrograms per deciliter is the reference value for blood lead levels to be considered <a href="https://www.cdc.gov/nceh/lead/prevention/blood-lead-levels.htm">high</a>; the acceptable amount was once higher.&nbsp;</p><p>Principal study author Michael McFarland, an associate professor of sociology at Florida State University and a faculty member of the university’s Center for Demography and Population Health, called the number of people affected by lead exposure “staggering.”</p><p>“This is important because we often think about lead as an issue for children, and of course it is,” he said. “But what we really wanted to know is what happens to those children who were exposed?”</p><p>In many cases, McFarland said, a 2 to 3 point IQ difference is nominal, unless an individual is on the lower side of IQ distribution.</p><p>“If you’re more toward cognitive impairment, a couple points can mean a lot,” he said.</p><p>But on a population basis, shifting the average IQ down even a small amount could have large consequences, said Sung Kyun Park, an associate professor of epidemiology and environmental health sciences at the University of Michigan School of Public Health. The entire bell curve shifts, he explained, with more of the population at what was once the extreme low end of IQ scores.</p><p>Lead used to be added to gasoline to help engines run more smoothly until other, safer additives replaced it. In addition to being linked to lower IQs, it has also been associated with heart and <a href="https://www.kidney.org/atoz/content/lead-exposure-and-kidney-function#:~:text=Most%20lead%2Drelated%20kidney%20disease,is%20stored%20in%20the%20bones.">kidney disease</a>.</p><p>Lead can be inhaled or ingested, with children particularly susceptible to its poisonous effects. Children’s blood lead levels have been dramatically lowered in the U.S. in recent decades, but lead exposure still happens, and Black children are <a href="https://pubmed.ncbi.nlm.nih.gov/33394180/#:~:text=Conclusion%3A%20Although%20lead%20exposure%20in,gap%20was%20lesser%20but%20persisted.">exposed</a> more often than white children. Monday’s study, too, estimated that most Black adults under age 45 experienced “considerably higher” levels of blood lead levels in early life than their white counterparts.&nbsp;</p><p>The racial disparities are generally due to environmental contamination and infrastructure issues that affect drinking water in low-income and minority neighborhoods, with the water crisis in <a href="https://www.nbcnews.com/news/us-news/former-michigan-gov-rick-snyder-charged-flint-water-crisis-n1253966">Flint, Michigan</a>, one of the most egregious examples in recent years.</p><p>And while children are the most vulnerable to getting very ill from lead, the toxin’s damage can show up years later, Park said. Lead exposure is believed to put people at risk for chronic and age-related diseases, including <a href="https://www.health.harvard.edu/heart-health/lead-and-heart-disease-an-underappreciated-link#:~:text=Lead%20is%20widespread%20in%20our,of%20death%20from%20cardiovascular%20disease.">cardiovascular disease</a> and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6454899/">dementia</a>.</p><p>“Lead is a never-ending story,” he said.</p><p>There are medical interventions available for children who have recently been exposed to high amounts of lead, but those wouldn’t work for adults born before 1996. Still, the study findings should not be a major cause for concern, McFarland said.</p><p>“There are a host of things that go into IQ,” he said. “This is one that is obviously negative, but if you also have a nurturing home environment, that helped your IQ.”</p></div><div data-activity-map="expanded-byline-article-bottom"><div data-testid="byline-thumbnail"><a href="https://www.nbcnews.com/author/elizabeth-chuck-ncpn341"><picture data-testid="picture"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_avif,q_auto:eco,dpr_2/newscms/2019_28/2931056/190618-elizabeth_chuck-byline1144.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_28/2931056/190618-elizabeth_chuck-byline1144.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_28/2931056/190618-elizabeth_chuck-byline1144.jpg" alt="" height="48" width="48"></picture></a></div><p><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/elizabeth-chuck-ncpn341">Elizabeth Chuck</a></span><span><a href="https://twitter.com/echuckles" target="_blank" rel="noopener noreferrer"><span></span></a><a href="https://facebook.com/elizabethNBCNews" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:elizabeth.chuck@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Elizabeth Chuck is a reporter for NBC News who focuses on health and mental health, particularly issues that affect women and children.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LocalSend: Open-source, cross-platform file sharing to nearby devices (323 pts)]]></title>
            <link>https://localsend.org</link>
            <guid>39662721</guid>
            <pubDate>Sun, 10 Mar 2024 21:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://localsend.org">https://localsend.org</a>, See on <a href="https://news.ycombinator.com/item?id=39662721">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Monte-Carlo graph search from first principles (312 pts)]]></title>
            <link>https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md</link>
            <guid>39662698</guid>
            <pubDate>Sun, 10 Mar 2024 21:33:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md">https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md</a>, See on <a href="https://news.ycombinator.com/item?id=39662698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:lightvector/KataGo" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="4sC8eYwjJZKZC1jMY2uFl4G0SB2rifYRS2EgIQnbVOVdTJ-9jHX_y81EzsUV76h92PBMaa8kVbuV5kGiZAYmQA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="lightvector/KataGo" data-current-org="" data-current-owner="lightvector" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=YKKSoNf86W26OSW3UUk3JFIvOJLtEhFnUGJtM5gYLcojbyXI3KPnZYxdE0MyU1YMZrzUDil2Zn6ypflHb4EeCyRhB99KlGOtNyXTQzk3LtkIwtHTaKwTPm%2BpjVEa7LX5Kh41Chls%2BsCbozUqIdKVjFcZWeDoRnQXLH%2FK15ih8SDdP1HG1x8TJp2p%2FvggRLRdHhhgaBlMPVusAX%2Ft7F0ef3zbl01VBBH1rJSlqps2g0KYn81toXRoIWse8eCnU0SwkZd8Yid%2BMrhOsEUDvzbT%2BhZMYVDk6JbjKoeKLWaHkkrFkT4sKZYJGftfoX44Pz2%2Fl6%2BvQ8boc34h1jvcjJryvQAAovIzjqG%2FyPMLdtPUTiujmIVieGuC1yrmW6E%2FIJ%2FLXCoiZbOnQ0ALt930KEATBo7HEHf9xclD%2FrCHTQMS4BZl7W6Hu6cjxQB0lrGntVktM79JZDZ1kl7eQRMf56hkddJFolRordxplf5c2G1FSJmYGkw8XDU9Cf%2BFHeJx0jwWsDudSSHCWs189p%2BSXs2jWiUkiiT3Uq0rfhD62RIKRWGn47e6ATucLyXYeNr4KCTRUrW9%2FnsrhVvDFQ%3D%3D--8WGaA2CStCTiRxIl--FXQcENf%2FcoX3waqXkwr38Q%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=lightvector%2FKataGo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="8b5625a74963b57aa934f82a2391c14828191e75196c792262ef707d0b4039c3" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Best Essay (241 pts)]]></title>
            <link>https://paulgraham.com/best.html</link>
            <guid>39662615</guid>
            <pubDate>Sun, 10 Mar 2024 21:20:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulgraham.com/best.html">https://paulgraham.com/best.html</a>, See on <a href="https://news.ycombinator.com/item?id=39662615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/the-best-essay-1.gif" width="121" height="18" alt="The Best Essay"><span size="2" face="verdana">March 2024<p>Despite its title this isn't meant to be the best essay. My goal
here is to figure out what the best essay would be like.</p><p>It would be well-written, but you can write well about any topic.
What made it special would be what it was about.</p><p>Obviously some topics would be better than others. It probably
wouldn't be about this year's lipstick colors. But it wouldn't be
vaporous talk about elevated themes either. A good essay has to be
surprising. It has to tell people something they don't already know.</p><p>The best essay would be on the most important topic you could tell
people something surprising about.</p><p>That may sound obvious, but it has some unexpected consequences.
One is that science enters the picture like an elephant stepping
into a rowboat. For example, Darwin first described the idea of
natural selection in an essay written in 1844.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span>
Talk about an
important topic you could tell people something surprising about.
If that's the test of a great essay, this was surely the best one
written in 1844. And indeed, the best possible essay at any given
time would usually be one describing the most important scientific
or technological discovery it was possible to make.
<span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>Another unexpected consequence: I imagined when I started writing
this that the best essay would be fairly timeless — that the best
essay you could write in 1844 would be much the same as the best
one you could write now. But in fact the opposite seems to be true.
It might be true that the best painting would be timeless in this
sense. But it wouldn't be impressive to write an essay introducing
natural selection now. The best essay <i>now</i> would be one describing
a great discovery we didn't yet know about.</p><p>If the question of how to write the best possible essay reduces to
the question of how to make great discoveries, then I started with
the wrong question. Perhaps what this exercise shows is that we
shouldn't waste our time writing essays but instead focus on making
discoveries in some specific domain. But I'm interested in essays
and what can be done with them, so I want to see if there's some
other question I could have asked.</p><p>There is, and on the face of it, it seems almost identical to the
one I started with. Instead of asking <i>what would the best essay
be?</i> I should have asked <i>how do you write essays well?</i> Though
these seem only phrasing apart, their answers diverge. The answer
to the first question, as we've seen, isn't really about essay
writing. The second question forces it to be.</p><p>Writing essays, at its best, is a way of discovering ideas. How do
you do that well? How do you discover by writing?</p><p>An essay should ordinarily start with what I'm going to call a
question, though I mean this in a very general sense: it doesn't
have to be a question grammatically, just something that acts like
one in the sense that it spurs some response.</p><p>How do you get this initial question? It probably won't work to
choose some important-sounding topic at random and go at it.
Professional traders won't even trade unless they have what they
call an <i>edge</i> — a convincing story about why in some class of
trades they'll win more than they lose. Similarly, you shouldn't
attack a topic unless you have a way in — some new insight about
it or way of approaching it.</p><p>You don't need to have a complete thesis; you just need some kind
of gap you can explore. In fact, merely having questions about
something other people take for granted can be edge enough.</p><p>If you come across a question that's sufficiently puzzling, it could
be worth exploring even if it doesn't seem very momentous. Many an
important discovery has been made by pulling on a thread that seemed
insignificant at first. How can they <i>all</i> be finches? 
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>Once you've got a question, then what? You start thinking out loud
about it. Not literally out loud, but you commit to a specific
string of words in response, as you would if you were talking. This
initial response is usually mistaken or incomplete. Writing converts
your ideas from vague to bad. But that's a step forward, because
once you can see the brokenness, you can fix it.</p><p>Perhaps beginning writers are alarmed at the thought of starting
with something mistaken or incomplete, but you shouldn't be, because
this is why essay writing works. Forcing yourself to commit to some
specific string of words gives you a starting point, and if it's
wrong, you'll see that when you reread it. At least half of essay
writing is rereading what you've written and asking <i>is this correct
and complete?</i> You have to be very strict when rereading, not just
because you want to keep yourself honest, but because a gap between
your response and the truth is often a sign of new ideas to be
discovered.</p><p>The prize for being strict with what you've written is not just
refinement. When you take a roughly correct answer and try to make
it exactly right, sometimes you find that you can't, and that the
reason is that you were depending on a false assumption. And when
you discard it, the answer turns out to be completely different.
</p><span color="#dddddd">[<a href="#f4n"><span color="#dddddd">4</span></a>]</span><p>Ideally the response to a question is two things: the first step
in a process that converges on the truth, and a source of additional
questions (in my very general sense of the word). So the process
continues recursively, as response spurs response. 
</p><span color="#dddddd">[<a href="#f5n"><span color="#dddddd">5</span></a>]</span><p>Usually there are several possible responses to a question, which
means you're traversing a tree. But essays are linear, not tree-shaped,
which means you have to choose one branch to follow at each point.
How do you choose? Usually you should follow whichever offers the
greatest combination of generality and novelty. I don't consciously
rank branches this way; I just follow whichever seems most exciting;
but generality and novelty are what make a branch exciting. 
</p><span color="#dddddd">[<a href="#f6n"><span color="#dddddd">6</span></a>]</span><p>If you're willing to do a lot of rewriting, you don't have to guess
right. You can follow a branch and see how it turns out, and if it
isn't good enough, cut it and backtrack. I do this all the time.
In this essay I've already cut a 17-paragraph subtree, in addition
to countless shorter ones. Maybe I'll reattach it at the end, or
boil it down to a footnote, or spin it off as its own essay; we'll
see. 
</p><span color="#dddddd">[<a href="#f7n"><span color="#dddddd">7</span></a>]</span><p>In general you want to be quick to cut. One of the most dangerous
temptations in writing (and in software and painting) is to keep
something that isn't right just because it contains a few good bits
or cost you a lot of effort.</p><p>The most surprising new question being thrown off at this point is
<i>does it really matter what the initial question is?</i> If the space
of ideas is highly connected, it shouldn't, because you should be
able to get from any question to the most valuable ones in a few
hops. And we see evidence that it's highly connected in the way,
for example, that people who are obsessed with some topic can turn
any conversation toward it. But that only works if you know where
you want to go, and you don't in an essay. That's the whole point.
You don't want to be the obsessive conversationalist, or all your
essays will be about the same thing. 
</p><span color="#dddddd">[<a href="#f8n"><span color="#dddddd">8</span></a>]</span><p>The other reason the initial question matters is that you usually
feel somewhat obliged to stick to it. I don't think about this when
I decide which branch to follow. I just follow novelty and generality.
Sticking to the question is enforced later, when I notice I've
wandered too far and have to backtrack. 
</p><span color="#dddddd">[<a href="#f9n"><span color="#dddddd">9</span></a>]</span>
But I think this is
the optimal solution. You don't want the hunt for novelty and
generality to be constrained in the moment. Go with it and see what
you get.<p>Since the initial question does constrain you, in the best case it
sets an upper bound on the quality of essay you'll write. If you
do as well as you possibly can on the chain of thoughts that follow
from the initial question, the initial question itself is the only
place where there's room for variation.</p><p>It would be a mistake to let this make you too conservative though,
because you can't predict where a question will lead. Not if you're
doing things right, because doing things right means making
discoveries, and by definition you can't predict those. So the way
to respond to this situation is not to be cautious about which
initial question you choose, but to write a lot of essays. Essays
are for taking risks.</p><p>Almost any question can get you a good essay. Indeed, it took some
effort to think of a sufficiently unpromising topic in the third
paragraph, because any essayist's first impulse on hearing that the
best essay couldn't be about x would be to try to write it. But if
most questions yield good essays, only some yield great ones.</p><p>Can we predict which questions will yield great essays? Considering
how long I've been writing essays, it's alarming how novel that
question feels.</p><p>One thing I like in an initial question is outrageousness. I love
questions that seem naughty in some way — for example, by seeming
counterintuitive or overambitious or heterodox. Ideally all three.
This essay is an example. Writing about the best essay implies there
is such a thing, which pseudo-intellectuals will dismiss as reductive,
though it follows necessarily from the possibility of one essay
being better than another. And thinking about how to do something
so ambitious is close enough to doing it that it holds your attention.</p><p>I like to start an essay with a gleam in my eye. This could be just
a taste of mine, but there's one aspect of it that probably isn't:
to write a really good essay on some topic, you have to be interested
in it. A good writer can write well about anything, but to stretch
for the novel insights that are the raison d'etre of the essay, you
have to care.</p><p>If caring about it is one of the criteria for a good initial question,
then the optimal question varies from person to person. It also
means you're more likely to write great essays if you care about a
lot of different things. The more curious you are, the greater the
probable overlap between the set of things you're curious about and
the set of topics that yield great essays.</p><p>What other qualities would a great initial question have? It's
probably good if it has implications in a lot of different areas.
And I find it's a good sign if it's one that people think has already
been thoroughly explored. But the truth is that I've barely thought
about how to choose initial questions, because I rarely do it. I
rarely <i>choose</i> what to write about; I just start thinking about
something, and sometimes it turns into an essay.</p><p>Am I going to stop writing essays about whatever I happen to be
thinking about and instead start working my way through some
systematically generated list of topics? That doesn't sound like
much fun. And yet I want to write good essays, and if the initial
question matters, I should care about it.</p><p>Perhaps the answer is to go one step earlier: to write about whatever
pops into your head, but try to ensure that what pops into your
head is good. Indeed, now that I think about it, this has to be the
answer, because a mere list of topics wouldn't be any use if you
didn't have edge with any of them. To start writing an essay, you
need a topic plus some initial insight about it, and you can't
generate those systematically. If only. 
</p><span color="#dddddd">[<a href="#f10n"><span color="#dddddd">10</span></a>]</span><p>You can probably cause yourself to have more of them, though. The
quality of the ideas that come out of your head depend on what goes
in, and you can improve that in two dimensions, breadth and depth.</p><p>You can't learn everything, so getting breadth implies learning
about topics that are very different from one another. When I tell
people about my book-buying trips to Hay and they ask what I buy
books about, I usually feel a bit sheepish answering, because the
topics seem like a laundry list of unrelated subjects. But perhaps
that's actually optimal in this business.</p><p>You can also get ideas by talking to people, by doing and building
things, and by going places and seeing things. I don't think it's
important to talk to new people so much as the sort of people who
make you have new ideas. I get more new ideas after talking for an
afternoon with Robert Morris than from talking to 20 new smart
people. I know because that's what a block of office hours at Y
Combinator consists of.</p><p>While breadth comes from reading and talking and seeing, depth comes
from doing. The way to really learn about some domain is to have
to solve problems in it. Though this could take the form of writing,
I suspect that to be a good essayist you also have to do, or have
done, some other kind of work. That may not be true for most other
fields, but essay writing is different. You could spend half your
time working on something else and be net ahead, so long as it was
hard.</p><p>I'm not proposing that as a recipe so much as an encouragement to
those already doing it. If you've spent all your life so far working
on other things, you're already halfway there. Though of course to
be good at writing you have to like it, and if you like writing
you'd probably have spent at least some time doing it.</p><p>Everything I've said about initial questions applies also to the
questions you encounter in writing the essay. They're the same
thing; every subtree of an essay is usually a shorter essay, just
as every subtree of a Calder mobile is a smaller mobile. So any
technique that gets you good initial questions also gets you good
whole essays.</p><p>At some point the cycle of question and response reaches what feels
like a natural end. Which is a little suspicious; shouldn't every
answer suggest more questions? I think what happens is that you
start to feel sated. Once you've covered enough interesting ground,
you start to lose your appetite for new questions. Which is just
as well, because the reader is probably feeling sated too. And it's
not lazy to stop asking questions, because you could instead be
asking the initial question of a new essay.</p><p>That's the ultimate source of drag on the connectedness of ideas:
the discoveries you make along the way. If you discover enough
starting from question A, you'll never make it to question B. Though
if you keep writing essays you'll gradually fix this problem by
burning off such discoveries. So bizarrely enough, writing lots of
essays makes it as if the space of ideas were more highly connected.</p><p>When a subtree comes to an end, you can do one of two things. You
can either stop, or pull the Cubist trick of laying separate subtrees
end to end by returning to a question you skipped earlier. Usually
it requires some sleight of hand to make the essay flow continuously
at this point, but not this time. This time I actually need an
example of the phenomenon. For example, we discovered earlier that
the best possible essay wouldn't usually be timeless in the way the
best painting would. This seems surprising enough to be
worth investigating further.</p><p>There are two senses in which an essay can be timeless: to be about
a matter of permanent importance, and always to have the same effect
on readers. With art these two senses blend together. Art that
looked beautiful to the ancient Greeks still looks beautiful to us.
But with essays the two senses diverge, because essays
teach, and you can't teach people something they already know.
Natural selection is certainly a matter of permanent importance,
but an essay explaining it couldn't have the same effect on us that
it would have had on Darwin's contemporaries, precisely because his
ideas were so successful that everyone already knows about them.
</p><span color="#dddddd">[<a href="#f11n"><span color="#dddddd">11</span></a>]</span><p>I imagined when I started writing this that the best possible essay
would be timeless in the stricter, evergreen sense: that it would
contain some deep, timeless wisdom that would appeal equally to
Aristotle and Feynman. That doesn't seem to be true. But if the
best possible essay wouldn't usually be timeless in this stricter
sense, what would it take to write essays that were?</p><p>The answer to that turns out to be very strange: to be the evergreen
kind of timeless, an essay has to be ineffective, in the sense that
its discoveries aren't assimilated into our shared culture. Otherwise
there will be nothing new in it for the second generation of readers.
If you want to surprise readers not just now but in the future as
well, you have to write essays that won't stick — essays that,
no matter how good they are, won't become part of what people in
the future learn before they read them. 
</p><span color="#dddddd">[<a href="#f12n"><span color="#dddddd">12</span></a>]</span><p>I can imagine several ways to do that. One would be to write about
things people never learn. For example, it's a long-established
pattern for ambitious people to chase after various types of prizes,
and only later, perhaps too late, to realize that some of them
weren't worth as much as they thought. If you write about that, you
can be confident of a conveyor belt of future readers to be surprised
by it.</p><p>Ditto if you write about the tendency of the inexperienced to overdo
things — of young engineers to produce overcomplicated solutions,
for example. There are some kinds of mistakes people never learn
to avoid except by making them. Any of those should be a timeless
topic.</p><p>Sometimes when we're slow to grasp things it's not just because
we're obtuse or in denial but because we've been deliberately lied
to. There are a lot of things adults </p><a href="https://paulgraham.com/lies.html"><u>lie</u></a> 
to kids about, and when
you reach adulthood, they don't take you aside and hand you a list
of them. They don't remember which lies they told you, and most
were implicit anyway. So contradicting such lies will be a source
of surprises for as long as adults keep telling them.<p>Sometimes it's systems that lie to you. For example, the educational
systems in most countries train you to win by 
</p><a href="https://paulgraham.com/lesson.html"><u>hacking the test</u></a>. But
that's not how you win at the most important real-world tests, and
after decades of training, this is hard for new arrivals in the real
world to grasp. Helping them overcome such institutional lies will
work as long as the institutions remain broken. 
<span color="#dddddd">[<a href="#f13n"><span color="#dddddd">13</span></a>]</span><p>Another recipe for timelessness is to write about things readers
already know, but in much more detail than can be transmitted
culturally. "Everyone knows," for example, that it can be rewarding
to have </p><a href="https://paulgraham.com/kids.html"><u>kids</u></a>. But till you have them you don't know precisely what
forms that takes, and even then much of what you know you may never
have put into words.<p>I've written about all these kinds of topics. But I didn't do it
in a deliberate attempt to write essays that were timeless in the
stricter sense. And indeed, the fact that this depends on one's ideas
not sticking suggests that it's not worth making a deliberate attempt
to. You should write about topics of timeless importance, yes, but
if you do such a good job that your conclusions stick and future
generations find your essay obvious instead of novel, so much the
better. You've crossed into Darwin territory.</p><p>Writing about topics of timeless importance is an instance of
something even more general, though: breadth of applicability. And
there are more kinds of breadth than chronological — applying to
lots of different fields, for example. So breadth is the ultimate
aim.</p><p>I already aim for it. Breadth and novelty are the two things I'm
always chasing. But I'm glad I understand where timelessness fits.</p><p>I understand better where a lot of things fit now. This essay has
been a kind of tour of essay writing. I started out hoping to get
advice about topics; if you assume good writing, the only thing
left to differentiate the best essay is its topic. And I did get
advice about topics: discover natural selection. Yeah, that would
be nice. But when you step back and ask what's the best you can do
short of making some great discovery like that, the answer turns
out to be about procedure. Ultimately the quality of an essay is a
function of the ideas discovered in it, and the way you get them
is by casting a wide net for questions and then being very exacting
with the answers.</p><p>The most striking feature of this map of essay writing are the
alternating stripes of inspiration and effort required. The questions
depend on inspiration, but the answers can be got by sheer persistence.
You don't have to get an answer right the first time, but there's
no excuse for not getting it right eventually, because you can keep
rewriting till you do. And this is not just a theoretical possibility.
It's a pretty accurate description of the way I work. I'm rewriting
as we speak.</p><p>But although I wish I could say that writing great essays depends mostly
on effort, in the limit case it's inspiration that makes the
difference. In the limit case, the questions are the harder thing
to get. That pool has no bottom.</p><p>How to get more questions? That is the most important question of
all.</p><p><b>Notes</b></p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
Darwin wouldn't have chosen to publish his ideas this way.
His 1844 essay, like the 1839 version that preceded it, was written more to work out
his ideas than to communicate them. But Lyell and Hooker's hands were 
forced by Alfred Wallace's independent
discovery of natural selection before Darwin had published anything.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
There might be some resistance to this conclusion on the
grounds that some of these discoveries could only be understood by
a small number of readers. But you get into all sorts of difficulties
if you want to disqualify essays on this account. How do you decide
where the cutoff should be? If a virus kills off everyone except a 
handful of people sequestered at Los Alamos,
could an essay that had been disqualified now be eligible? Etc.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
When you find yourself very curious about an apparently minor
question, that's an exciting sign. Evolution has designed you to
pay attention to things that matter. So when you're very curious
about something random, that could mean you've unconsciously noticed
it's less random than it seems.<p>[</p><a name="f4n"><span color="#000000">4</span></a>]
Corollary: If you're not intellectually honest, your writing
won't just be biased, but also boring, because you'll miss all the
ideas you'd have discovered if you pushed for the truth.<p>[</p><a name="f5n"><span color="#000000">5</span></a>]
Sometimes this process begins before you start writing.
Sometimes you've already figured out the first few things you want
to say. Schoolchildren are often taught they should decide <i>everything</i>
they want to say, and write this down as an outline before they
start writing the essay itself. Maybe that's a good way to get them
started — or not, I don't know — but it's antithetical to the
spirit of essay writing. The more detailed your outline, the less
your ideas can benefit from the sort of discovery that essays are for.<p>[</p><a name="f6n"><span color="#000000">6</span></a>]
The problem with this type of "greedy" algorithm is that you
can end up on a local maximum. If the most valuable question is
preceded by a boring one, you'll overlook it. But I can't imagine
a better strategy. There's no lookahead except by writing. So use
a greedy algorithm and a lot of time.<p>[</p><a name="f7n"><span color="#000000">7</span></a>]
I ended up reattaching the first 5 of the 17 paragraphs, and
discarding the rest.<p>[</p><a name="f8n"><span color="#000000">8</span></a>]
Stephen Fry confessed to making use of this phenomenon when
taking exams at Oxford. He had in his head a standard essay about
some general literary topic, and he would find a way to turn the
exam question toward it and then just reproduce it again.<p>Strictly speaking it's the graph of ideas that would be highly
connected, not the space, but that usage would confuse people who
don't know graph theory, whereas people who do know it will get
what I mean if I say "space".</p><p>[</p><a name="f9n"><span color="#000000">9</span></a>]
Too far doesn't depend just on the distance from the original
topic. It's more like that distance divided by the value of whatever
I've discovered in the subtree.<p>[</p><a name="f10n"><span color="#000000">10</span></a>]
Or can you? I should try writing about this. Even if the
chance of succeeding is small, the expected value is huge.<p>[</p><a name="f11n"><span color="#000000">11</span></a>]
There was a vogue in the 20th century for saying that the
purpose of art was also to teach. Some artists tried to justify
their work by explaining that their goal was not to produce something
good, but to challenge our preconceptions about art. And to be fair,
art can teach somewhat. The ancient Greeks' naturalistic sculptures
represented a new idea, and must have been extra exciting to
contemporaries on that account. But they still look good to us.<p>[</p><a name="f12n"><span color="#000000">12</span></a>]
Bertrand Russell caused huge controversy in the early 20th
century with his ideas about "trial marriage." But they make boring
reading now, because they prevailed. "Trial marriage" is what we
call "dating."<p>[</p><a name="f13n"><span color="#000000">13</span></a>]
If you'd asked me 10 years ago, I'd have predicted that schools
would continue to teach hacking the test for centuries. But now it
seems plausible that students will soon be taught individually by
AIs, and that exams will be replaced by ongoing, invisible
micro-assessments.<span color="888888"><b>Thanks</b> to Sam Altman, Trevor Blackwell, 
Jessica Livingston, Robert
Morris, Courtenay Pipkin, and Harj Taggar for reading drafts of
this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Guide to Software Engineering Contracting in UK (120 pts)]]></title>
            <link>https://codedeepdives.com/blog/guide-to-software-engineer-contracting-in-uk</link>
            <guid>39662506</guid>
            <pubDate>Sun, 10 Mar 2024 21:02:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codedeepdives.com/blog/guide-to-software-engineer-contracting-in-uk">https://codedeepdives.com/blog/guide-to-software-engineer-contracting-in-uk</a>, See on <a href="https://news.ycombinator.com/item?id=39662506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>This is my guide to contracting in the UK. Its based on my experiences, and to be honest yours might be different. But maybe this guide will help someone who is thinking of going contracting, and it might help you understand the pros/cons and what to know about it before you begin.</p>
<h3 id="what-is-contracting-and-what-is-involved">What is contracting, and what is involved?</h3>
<p>Contracting is where you work for a company, without being a permanent employee.</p>
<p>This means you get no benefits (like holiday pay), should expect no training, are expected to 'hit the ground running' and should know your tech stack pretty well. And the main benefit for this: much higher pay.</p>
<p>Someone earning £70-80k could easily get a contract paying £400-500 a day. Even on the low end of £400, £400 * 22 days worked a month = £8k/mo = £96k a year. Plus, you end up paying less tax due to the different structure.</p>
<p>Most contractors will work for a company for something like 6 weeks to 6 months. Then you set LinkedIn to 'looking for work', speak to agency recruiters, and you tell them your date rate. They'll match you up with potential roles.</p>
<p>The interview process for contract roles is really straightforward. They'll do some basic checks, but if it takes more than an hour or two you can sometimes even just refuse, and they'll accommodate that.</p>
<p>If you turn up and are rubbish, your contract will be terminated really quick. And if there are layoffs, contractors would (sometimes) already be well gone already.</p>
<p>During first COVID waves (and first lockdowns) the UK software engineer contract market completely dried up. There were almost no contracts going around (definitely not many published publicly or on LinkedIn).</p>
<p><strong>Note: none of this is legal or tax advice. This is just based on my experience, and is entirely my own opinion on how the UK contract market works. Before thinking of going contracting, please do further research. Speak to other contractors, speak to recruiters and get a feel for the contract market near you</strong></p>
<p><strong>Most of this guide also assumes you are set up as a limited company, and contracting within that</strong> but the guide is also relevant if you are contracting via an umbrella company or sole trader.</p>
<h3 id="proscons-of-contracting-in-uk">Pros/cons of contracting in UK</h3>
<h4 id="pros-of-contracting-in-uk">Pros of contracting in UK</h4>
<ul>
<li>You are your own boss (but you have clients who you have to keep happy),</li>
<li>you can select your own work hours. The contract might say something like you have to do 40hrs work a week or 8hrs a day, you can choose when they are.</li>
<li>You will not be on-call</li>
<li>You will not have to attend company off-sites (in fact you probably legally won't be able to)</li>
<li>You can have as much holiday as you want (but you only get paid for days you work)</li>
<li>For some contracts, you can work weekends (<em>at your choice</em>) which is great if you need to earn more money</li>
<li>It is easy to get a contract and start work within a day or two. I've never found it hard to find a new contract immediately. You normally know when you will be moving to a new role, so you normally have at least a few weeks.</li>
<li>You are always seeing new companies, new tech, new tech stacks, and the job never gets boring</li>
<li>More exposure to different ways of working and different frameworks</li>
<li>No performance reviews, no feedback cycles</li>
</ul>
<h4 id="cons-of-contracting-in-uk">Cons of contracting in UK</h4>
<ul>
<li>A lot of people say job security, however I do not believe this. It is so easy to find new contracts, and even perm employees are layed off.</li>
<li>the paperwork, legal and tax side is not fun. Tip: pay an accountant to do everything</li>
<li>no sick pay. You don't work, you don't get paid.</li>
<li>No benefits. No insurance, no gym, etc. But you earn a lot more so its not a huge deal, except for the pension contribution.</li>
<li>more complex to get mortgages</li>
</ul>
<h3 id="job-security-as-a-contractor">Job security as a contractor</h3>
<p>A lot of permanent employees think their jobs are much more secure than contractors. I very much disagree. Contractors can get a new role almost immediately (the only time this hasn't been true was during COVID first lockdown)</p>
<p>I think there is a bit more stress when interviewing all the time, but after a while it becomes quite easy. Landing the next role can be as easy as calling up a few recruiters and seeing what roles they have right now.</p>
<h3 id="taxetc">Tax/etc</h3>
<p><strong>I am not an accountant. Please consult with an accountant to understand the tax implications. This is just a very high level overview of tax in UK when contracting</strong></p>
<h4 id="ir35-and-other-tax-issues">IR35 and other tax issues</h4>
<ul>
<li>If you have your own ltd company, IR35 is a very important tax law that all contractors should be aware of. I don't want to give bad advice here, and I would recommend that every contractor fully understands the IR35 laws, so please Google it and read up. This cannot be skipped, and if you do not know about IR35 recruiters and hiring managers will not take you seriously.</li>
</ul>
<h4 id="is-it-worth-getting-an-accountant-when-contracting">Is it worth getting an accountant when contracting?</h4>
<ul>
<li>100% yes!</li>
<li>Get an accountant/bookkeeper to deal with all your tax things. Don't go with one of the cheap online ones, go to a proper accountant and pay them to handle everything.</li>
</ul>
<h4 id="expenses-and-tax-deductible-things">Expenses and tax deductible things</h4>
<ul>
<li>Most business expenses are tax deductible.</li>
<li>Food is not! despite what many contractors will like to tell you.</li>
<li>Laptops, monitors, travel (in most cases when contracting) are all expenses</li>
<li>If you register for VAT, you may be able to set up for flat rate VAT. This means you can't really claim back any VAT (as a contractor you probably won't have many purchases) unless its over £2k. But you can charge VAT (at 20%) but you send HMRC a smaller %. The details of this, in my opinion, are best left for an accountant to explain to you. But basically you can make another couple of % (especially in the first year, where you get an extra 1%).</li>
</ul>
<h4 id="getting-a-mortgage-as-a-contractor">Getting a mortgage as a contractor</h4>
<ul>
<li>Getting a mortgage is only slightly harder as a contractor. There are specialist  mortgage advisors who can find providers that give a mortage to contractors and self employed.</li>
</ul>
<h4 id="limited-companies-umbrella-companies-sole-trader">Limited companies, umbrella companies, sole trader</h4>
<ul>
<li><strong>Limited companies</strong> are what most contractors are. Some companies will only work with contractors who have a ltd company.  If you have this then the contracts are between the business you're contracting at, and your ltd company. If you are earning a decent day rate and are busy most months, then it is probably better in terms of tax to be set up as a limited company. It also means you can substitute yourself with someone else (just like if you hired a plumbing company, they can send who they want as long as they are qualified)</li>
<li><strong>Umbrella companies</strong> will be set up by agencies. They charge for this, and you make less due to worse tax structure. I cannot see why people do it, except it is easier</li>
<li>You can also do <strong>contracting as a sole trader</strong>, although you will be more limited with what companies will work with you. I did it as a sole trader for quite a while, until my accountant told me how I would be much better off with a ltd company.</li>
</ul>
<h4 id="business-bank-accounts">Business bank accounts</h4>
<p>Getting a business bank account is easy.</p>
<p>One of the most commonly used ones that I've seen other contractors set up is with tide (<a target="_blank" rel="noopener noreferrer" href="http://www.tide.co/">www.tide.co</a>). Do your research and see what is the best available one for you.</p>
<p>Most business bank accounts have a cost (you can probably get them for £10/mo). I think the reason tide are popular is because they charge no monthly fee (and very minimal fees for doing things like certain withdrawals).</p>
<p>You will need your business bank set up before you can accept payments from companies. Do not accept bank transfers to your personal current bank account.</p>
<p>If you are setting up a ltd company: You will be unable to set up a business bank account until you have your company set up, and have the documentation to prove it.</p>

<p><strong>Get insurance when contracting</strong>.</p>
<p>As well as it covering you in case something goes wrong (or you get sued), some companies won't work with you if you don't have insurance. It is quite quick to get insurance, and you can use price comparision sites for business insurance.</p>
<p>There are a few types, including <em>public liability insurance</em>, <em>professional indemnity insurance</em>, <em>employers' liability insurance</em> (important if you employ others in your business)</p>
<h3 id="day-rates-as-a-contractor">Day rates as a contractor</h3>
<p>In the UK everything contractors do are based on day rates. Contractors are often quite happy to share what sort of day rates they're getting with other contractors.</p>
<p>In my experience there is only a slight correlation between how good someone is at software engineering and the day rate they are getting.</p>
<h4 id="uk-london-software-engineer-contract-day-rates">UK London software engineer contract day rates</h4>
<ul>
<li>London software engineering day rates are around £400-500 (outside IR35)</li>
</ul>
<h4 id="uk-non-london-software-engineer-contract-day-rates">UK (non London) software engineer contract day rates</h4>
<ul>
<li>Outside of UK they can be lower, £300-400</li>
<li>Sometimes they can be the same as London rates.</li>
<li>Many are remote, so the location doesn't matter as much as it did a few years ago</li>
</ul>
<h4 id="how-to-calculate-contractor-day-rate-from-a-perm-salary">How to calculate contractor day rate, from a perm salary</h4>
<p>This is a funny subject, as there is no easy comparison. A perm employee is going to have benefits, sick pay, holiday. But I think from experience £70k = £400, £80 = £500, £90+ = £600+. Maybe this isn't too accurate, and might be on the low end of perm employee salary ranges.</p>
<h3 id="skills-and-attributes-as-a-contractor">Skills and attributes as a contractor</h3>
<p>Contractors are not always very skilled! I've worked with highly paid contractors who knew only the basics of how to code. But generally great engineers can command a higher price and after working with a recruiter, the recruiters will hear only positive feedback and will be keen to place you again in another role.</p>
<p>I've always specalised in certain languages and frameworks. Knowing them really well has always meant I could just present myself as an expert in whatever tech the role was for. (I'd only apply for those roles).</p>
<p>For SaaS and other typical tech startups, as well as knowing your programming language &amp; frameworks, I'd suggest you know these really well:</p>
<ul>
<li>git</li>
<li>experience with something like jira</li>
<li>(if for a FE role) experience with something like Figma or Sketch</li>
</ul>
<p>No one will be around to show you how to use git if you are a contractor and turn up without knowing how to use it.</p>
<h4 id="how-skilled-do-you-have-to-be-to-be-a-contractor">How skilled do you have to be to be a contractor?</h4>
<p>It helps to be very skilled, but really I think anyone with more than a few years of working in a perm role could land contract jobs. Most contract jobs are quite simple. They want you to quickly turn out a new feature or build something. Often its from scratch, which is nice. Sometimes its not from scratch, but you can pick and choose what contracts you work with.</p>
<h4 id="what-sorts-of-teams-will-you-be-working-with-as-a-contractor">What sorts of teams will you be working with as a contractor?</h4>
<p>A wide mix! It could be almost just you by yourself, or working with a typical cross functional squad. You won't have a manager (you might have someone to report to - but they won't be your manager)</p>
<p>You may be expected to turn up and get set up almost immediately. Unlike a perm job, there will probably be very mimimal onboarding, and if you do have to do onboarding you will not do the same as normal permanent new starters.</p>
<h3 id="getting-contractor-roles">Getting contractor roles</h3>
<p>In the UK the best way I've found to get contract roles is to simply speak to recruiters. The best place to find them is on LinkedIn. Set yourself to 'open to work', add some experiences, and contact recruiters who are posting contracts. The best way to find them is to search for things like "London JS per day" or "London JS contract" or "London JS outside ir35", and you'll find a bunch of recruiters posting their roles.</p>
<p>I read online before I started contracting like this that it is super competitive, you have to phone them the second you see them put an ad up. I never experienced this. There is enough work and there are enough roles posted that you can ignore all that. I have a feeling that recruiters might spread these lies in order to get you to only work with them.</p>
<h4 id="what-companies-are-looking-for-when-hiring-contractors">What companies are looking for when hiring contractors</h4>
<p>I've worked mostly with startups, but orgs of all sizes hire contractors (including FAANG).</p>
<h4 id="interviewing-for-contract-roles">Interviewing for contract roles</h4>
<p>Interviews are generally quite simple. There might be some simple tech test (if it takes long, you can sometimes refuse and just say you don't have time - some companies will still continue the interview process with you.)</p>
<p>There will probably not be a full behaviour type interviews, or them seeing how well you will fit in culturally.</p>
<p>If there are behaviour/culture interviews, then they will not see you as a contractor - they see you as someone they can try and turn into a perm employee. This is good - but they'll expect you to take part in everything normal employees take part in.</p>
<h4 id="speaking-to-recruiters">Speaking to recruiters</h4>
<ul>
<li>Know your date rate. If you don't know, do some research and pick a number. Don't go low.</li>
<li>Get a ltd company set up, it makes it easier and you can start working ASAP</li>
<li>Get insurance. Its not too expensive, some companeis will require it</li>
<li>Tell recruiters what rate you're looking for, what your expertise or specality is (maybe this is just what languages you have been using)</li>
</ul>
<h4 id="negotiations">Negotiations</h4>
<ul>
<li>If you go via a recruiter, they will tell you a rate (e.g. £500) but they charge the company much more (e.g. £600+). If the company <em>really</em> wants to work with you, and you have other roles you're considering you can negociate. The agency will get a smaller cut, but they are competing against other agencies and would prefer a smaller cut than no cut at all.</li>
<li>Know market rate. If you don't know market rate, just say your rate is market rate.</li>
<li>Negociations will be with the agency.</li>
<li>If you go direct: they save quite a bit by not paying recruitment agency fees. You may be able to demand a higher day rate.</li>
</ul>
<h4 id="how-to-find-work">How to find work</h4>
<ul>
<li>LinkedIn! I know other contractors find work in other ways, but linkedin has really good success rate</li>
</ul>
<h4 id="writing-a-cv-as-a-contractor">Writing a CV as a contractor</h4>
<ul>
<li>1 or 2 pages max</li>
<li>You can just put short summaries, and write what tech you used.</li>
<li>recruiters don't care about your personal bio. They care about what tech you know.</li>
<li>create a version of your cv for each role you apply to. Highlight/make bold the tech stack that you know &amp; is used for that role</li>
</ul>
<h4 id="going-from-perm-to-contract">Going from perm to contract</h4>
<ul>
<li>Legally it is questionable if you go from perm at a company to contracting at the company - especially if you do it under your own ltd company. I would not advise it. Go contract at another company.</li>
</ul>
<h4 id="going-from-contractor-to-perm">Going from contractor to perm</h4>
<ul>
<li>Its common to be offered a perm role. Companies sometimes see contractors as a part of recruiting long term perm employees.</li>
<li>The salary will be rubbish compared to your day rate, but they'll try to convince you that the benefits are worth it</li>
</ul>
<h4 id="does-educationuniversity-matter-for-getting-contractor-roles-in-uk">Does education/university matter for getting contractor roles in UK?</h4>
<p>I have never been asked about qualifications or university. I don't think it matters for software engineering contractors.</p>
<p>When hiring contractors it is a <em>little</em> like hiring a plumber. They just assume you know how to do the job and your experience are your credentials.</p>
<h4 id="going-direct-vs-finding-work-via-an-agency">Going direct vs finding work via an agency</h4>
<p>Going direct can be harder, as you have to approach CTOs (small startups) or hiring managers. But it can pay off, as a lot of companies are always hiring software engineers and often need contractors to fill up capacity.</p>
<h3 id="general-tips">General tips</h3>
<ul>
<li>Avoid having to find new contracts in late December or January - get it sorted and planning in advance. In my experience the contract market dies down a little in these months.</li>
<li>Before starting contracting, have at least some amount of savings that you can rely on if you had to have some time off between contracts (or if you get ill)</li>
<li>Always charge for day rates. Don't bother doing hourly charging.</li>
<li>Keep up to date with the ever changing IR35 laws.</li>
</ul>
<h3 id="further-resources-on-contracting-in-the-uk">Further resources on contracting in the UK</h3>
<ul>
<li>ITJobsWatch - I've never found a role through it, but it is popular: <a target="_blank" rel="noopener noreferrer" href="https://www.itjobswatch.co.uk/contract.aspx">https://www.itjobswatch.co.uk/contract.aspx</a></li>
<li>Contractor Calculator <a target="_blank" rel="noopener noreferrer" href="https://www.contractorcalculator.co.uk/">https://www.contractorcalculator.co.uk/</a></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using PostgreSQL for military geoanalytics tasks (137 pts)]]></title>
            <link>https://klioba.com/how-to-use-postgresql-for-military-geoanalytics-tasks</link>
            <guid>39662246</guid>
            <pubDate>Sun, 10 Mar 2024 20:19:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://klioba.com/how-to-use-postgresql-for-military-geoanalytics-tasks">https://klioba.com/how-to-use-postgresql-for-military-geoanalytics-tasks</a>, See on <a href="https://news.ycombinator.com/item?id=39662246">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <p><span>03 Mar 2024</span></p><p>Geoanalytics is crucial in military affairs, as a significant portion of
military data contains geoattributes. In this article, I will discuss
how to use PostgreSQL to process geospatial data and address common
geoanalytical tasks. The information will cover methods for finding the
nearest objects, distance calculations, and using geospatial indexes to
enhance these processes. We will also explore techniques for determining
a point within a polygon and geospatial aggregation. The goal of this
article is to provide practical examples and tips to enhance working
with geospatial data and contribute to the development of new solutions.</p>

<p><em>The materials and data used in the article are open-source and have
been approved by the military representatives.</em></p>

<h2 id="first-data-source-how-to-import-russian-military-polygon-data-into-postgresql">First data source: how to import russian military polygon data into PostgreSQL</h2>

<p>I will need certain datasets to initiate the analysis and showcase
PostgreSQL's capabilities in geoanalytics. I decided to start with data
on russian military facilities available on
<a href="https://www.openstreetmap.org/">OpenStreetMap</a> (OSM). The first step is
to load this data into PostgreSQL, after which we can use tools to
optimize queries and enhance their efficiency.</p>

<p>To import data on russian military objects from OSM, we will use the
<a href="https://osm2pgsql.org/">osm2pgsql</a> tool. This open-source tool
efficiently transfers data from OSM to PostgreSQL. We will load the
<a href="http://download.geofabrik.de/russia-latest.osm.pbf">russia-latest.osm.pbf</a>
file (3.4 GB) containing information about points, lines, roads, and
polygons from OSM. After loading, the file will be used to populate the
corresponding tables in PostgreSQL, where we can begin the analysis and
processing of data.</p>

<p>The script we are using includes commands for loading OSM data, creating
a new PostgreSQL database, and importing data using osm2pgsql:</p>



<p>After executing the script, five main tables will appear in our
database:</p>

<ul>
  <li><strong>osm2pgsql_properties</strong>—stores settings and properties used
during the data import.</li>
  <li><strong>planet_osm_line</strong>—contains linear elements, such as roads and
rivers.</li>
  <li><strong>planet_osm_point</strong>—includes point objects, such as buildings
(not all buildings are marked as geographic polygons, so we will
have to come up with something to be devised to work with these
points).</li>
  <li><strong>planet_osm_polygon</strong>—stores polygons representing areas, such as
military bases.</li>
  <li><strong>planet_osm_roads</strong>—stores transportation routes.</li>
</ul>

<p>To simplify the analysis of military objects, we will create a table
called <strong>military_geometries</strong>. The SQL script will select data from the
<strong>planet_osm_line</strong>, <strong>planet_osm_point</strong>, <strong>planet_osm_polygon</strong>, and
<strong>planet_osm_roads</strong> tables, filtering out military objects. A 100-meter
buffer will be applied to lines, points, and roads using
<a href="https://postgis.net/docs/ST_Buffer.html">ST_Buffer</a>. This will also
allow us to create polygons based on points and lines, providing the
ability to analyze, for example, whether a point is within the specified
polygons.</p>



<p>Executing the provided SQL script will allow us to create a
<strong>military_geometries</strong> table that will contain polygons for 9,252
military objects identified on OSM:</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image1.png" alt="">
<em>Visualization of 9,252 military sites across russia and the temporarily
occupied Autonomous Republic of Crimea using QGIS</em></p>

<p>In OSM, as in other open sources, information is subject to change. For
example, from the beginning of 2022, 2,995 military objects in russia
were deleted.</p>

<p>They say, "Screenshots don't burn", but such deletions often lead to
the <a href="https://en.wikipedia.org/wiki/Streisand_effect">Streisand effect</a>,
where attempts to hide information only attract more attention. If you
want to delve into the historical data of OSM and help identify such
anomalies, you can use resources like
<a href="https://download.geofabrik.de/russia.html">GeoFabrik.de</a>. Although this
doesn't directly relate to our analysis, I want to show how these
deleted objects look on a map, illustrating russian attempts to conceal
essential data.</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image2.jpeg" alt="">
<em>Deleted after 01/01/2022 (blue) and existing (red) geographical polygons
of military facilities in moscow</em></p>

<h2 id="second-data-source-fire-data-from-nasa-satellites">Second data source: fire data from NASA satellites</h2>

<p>As the next data source, we will utilize information from the <a href="https://www.earthdata.nasa.gov/learn/find-data/near-real-time/firms/vj114imgtdlnrt">Fire
Information for Resource Management
System</a>
(FIRMS) developed at the University of Maryland with support from NASA
and the UN in 2007. FIRMS allows real-time monitoring of active fires
worldwide, utilizing data from Aqua and Terra satellites equipped with
MODIS spectroradiometers and VIIRS on S-NPP and NOAA 20 satellites. The
information is updated every three hours and even more frequently for
the United States and Canada.</p>

<p>We will be using FIRMS data to identify fires within the territory of
russian military facilities since 2022.</p>

<p>To download fire data from the FIRMS system, we will employ the
following script, extracting all records of fires in russia from January
1, 2022, to the current date. These data will then be imported into a
new table, <strong>viirs_fire_events</strong>, in the PostgreSQL database.</p>



<p>Therefore, we will populate the <strong>viirs_fire_events</strong> table, which will
contain 1,711,475 records of fires in russia. These fires appear as
follows:</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image3.jpeg" alt="">
<em>Visualization of fires in russia since January 1, 2022 (1,711,475 fires)</em></p>

<p>The <strong>viirs_fire_events</strong> table in the PostgreSQL database will be used
to store detailed fire data, with fields for coordinates, satellite
parameters, date and time of acquisition, and other critical metadata. A
new column with a data type of <strong>GEOMETRY(POINT, 4326)</strong> will be
automatically populated based on the data from the <strong>longitude</strong> and
<strong>latitude</strong> columns.</p>



<p>Suppose you are interested in working with this data on military objects
and fires, but the described process of extracting datasets seems
time-consuming. In that case, there are exported CSV tables for you. You
can download them via the following links:
<a href="https://storage.googleapis.com/files.sql.ua/csv/military_geometries.csv">military_geometries</a>,
<a href="https://storage.googleapis.com/files.sql.ua/csv/viirs_fire_events.csv">viirs_fire_events</a>.</p>

<h2 id="searching-for-military-facilities-where-fires-occurred-points-within-the-polygon">Searching for military facilities where fires occurred: points within the polygon</h2>

<p>As for now, we have two tables: <strong>military_geometries</strong> and
<strong>viirs_fire_events</strong>. Let's try to find those military facilities that
have had fires (since the beginning of 2022) or those that have not yet
🙂.</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image4.png" alt=""></p>

<p>Let's use an SQL query with the
<a href="https://postgis.net/docs/ST_Contains.html"><strong>ST_Contains</strong></a> function to
identify military objects where fires have been detected from NASA
satellites.</p>



<p>As you've probably noticed, we've identified 129 military sites that
have experienced fires since the start of 2022. What's intriguing is
that, in some cases, these fires seem to have occurred more than once.</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image5.png" alt="">
<em>Military facilities where fires have occurred since the beginning of
2022 (the transparency of the facilities indicates the frequency of the
fire incidents)</em></p>

<p>The second aspect you may have noticed is that the specified query took
54 minutes and 15 seconds to execute, which is quite long for such a
straightforward operation. It's helpful to use the <a href="https://www.postgresql.org/docs/current/sql-explain.html">EXPLAIN
ANALYZE</a>
command to understand the reasons for this duration. This command allows
you to analyze the query execution process, identify potential
bottlenecks, and further optimize the query to improve performance.</p>



<p>In this case, when using the <strong>Nested Loop Semi Join</strong> operator, we
encountered a complexity of O(n*m), where n is 9,252 rows in the
<strong>military_geometries</strong> table, and m is 1,711,475 rows in
<strong>viirs_fire_events</strong>. This implies that each row from the first table
is compared with every row from the second table, resulting in a huge
number of operations.</p>

<p>Hence, let's discuss how we can speed up the execution of such a query
by utilizing indexes.</p>

<h2 id="productivity-boost-utilizing-indexing-in-geoanalytics">Productivity boost: utilizing indexing in geoanalytics</h2>

<p>PostgreSQL is renowned for its scalability features, offering numerous
methods for accessing geospatial data within this database. To find all
methods suitable for working with points in a two-dimensional space, we
can execute the following query:</p>



<p>As a result, we will observe at least five access methods, including
btree, hash, gist, brin, and spgist. I suggest investigating by creating
indexes for each of these methods and operator classes. After creating
the indexes, we will assess the query performance regarding fires at
military facilities in russia to determine which methods are most
effective for our task.</p>

<table>
  <thead>
    <tr>
      <th>Index type</th>
      <th>Index operator class</th>
      <th>Filtering operator</th>
      <th>Index creation time</th>
      <th>Index size</th>
      <th>Query execution time</th>
      <th>Brief explanation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>btree</td>
      <td>btree_geometry_ops</td>
      <td>There is no corresponding operator—the index is disregarded for this query.</td>
      <td>1 sec 918 ms</td>
      <td>81 MB</td>
      <td>53 min 45 sec (129 rows affected)</td>
      <td>Supports equality and range queries; retrieves data quickly and in an organized manner.</td>
    </tr>
    <tr>
      <td>hash</td>
      <td>hash_geometry_ops</td>
      <td>There is no corresponding operator—the index is disregarded for this query.</td>
      <td>3 secs 158 ms</td>
      <td>59 MB</td>
      <td>53 min 15 sec (129 rows affected)</td>
      <td>Fast equality search; not suitable for ordering or range queries.</td>
    </tr>
    <tr>
      <td>brin</td>
      <td>brin_geometry_inclusion_ops_2d</td>
      <td>@(geometry,geometry)</td>
      <td>536 ms</td>
      <td>0.032 MB</td>
      <td>28 min 3 sec (129 rows affected)</td>
      <td>Effective for large datasets with naturally ordered data; indexes block ranges rather than individual rows.</td>
    </tr>
    <tr>
      <td>gist</td>
      <td>gist_geometry_ops_2d</td>
      <td>@(geometry,geometry)</td>
      <td>11 secs 659 ms</td>
      <td>94 MB</td>
      <td>493 ms (129 rows affected)</td>
      <td>Supports a wide range of queries, including spatial searches for overlap and proximity.</td>
    </tr>
    <tr>
      <td>spgist</td>
      <td>spgist_geometry_ops_2d</td>
      <td>@(geometry,geometry)</td>
      <td>6 secs 290 ms</td>
      <td>78 MB</td>
      <td>353 ms (129 rows affected)</td>
      <td>Suitable for data with uneven distribution; supports a variety of split tree structures.</td>
    </tr>
    <tr>
      <td>gist</td>
      <td>point_ops</td>
      <td>&lt;@(point,polygon)</td>
      <td>1 secs 426 ms</td>
      <td>81 MB</td>
      <td>306 ms (returned 132 records)</td>
      <td>Perfect for point data; supports queries on spatial relationships, such as containment and intersection.</td>
    </tr>
    <tr>
      <td>spgist</td>
      <td>quad_point_ops</td>
      <td>&lt;@(point,box)</td>
      <td>4 secs 849 ms</td>
      <td>77 MB</td>
      <td>243 ms (173 rows affected)</td>
      <td>Utilizes quadtrees to index point data; effective in specific scenarios of spatial analysis.</td>
    </tr>
    <tr>
      <td>spgist</td>
      <td>kd_point_ops</td>
      <td>&lt;@(point,box)</td>
      <td>5 secs 204 ms</td>
      <td>93 MB</td>
      <td>199 ms (173 rows affected)</td>
      <td>Employs kd-trees for multidimensional point data; excellent for finding nearest neighbors.</td>
    </tr>
  </tbody>
</table>

<p><em>Note: The operator classes mentioned do not utilize geometry data types for searching; they work with &lt;@(point, polygon) and &lt;@(point, box). As a result, the row counts may not match the output (for example, a complex geographic polygon may have been simplified to a rectangle).</em></p>

<p>The results table shows that the most effective indexes for our task are
<a href="https://www.postgresql.org/docs/current/gist.html">GiST</a> and
<a href="https://www.postgresql.org/docs/current/spgist.html">SP-GiST</a>. Let's
delve into how they operate.</p>

<h2 id="how-gist-works">How GiST works</h2>

<p>Generalized Search Tree (GiST) indexes in PostgreSQL enable efficient
sorting and searching across diverse data types using the concept of
balanced trees. They provide the ability to develop custom operators for
indexing, making GiST quite versatile and adaptive to specific
requirements.</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image6.png" alt="">
<em>The hierarchical structure of the GiST index in PostgreSQL [1]</em></p>

<p>In the example of a GiST tree depicted: at the top level, there are
<strong>R1</strong> and <strong>R2</strong>, serving as bounding boxes for other elements. <strong>R1</strong>
contains <strong>R3</strong>, <strong>R4</strong>, and <strong>R5</strong>, while <strong>R3</strong>, in turn, encompasses
<strong>R8</strong>, <strong>R9</strong>, and <strong>R10</strong>. The GiST index has a hierarchical
structure, allowing for significantly faster search. Unlike B-trees,
GiST supports overlap operations and spatial relationship determination.
This is why GiST is well-suited for indexing geometric data.</p>

<h2 id="how-sp-gist-works">How SP-GiST works</h2>

<p>Space Partitioning Generalized Search Tree (SP-GiST) indexes in
PostgreSQL are designed for data structures that partition space into
non-overlapping regions, such as quadrant trees or prefix trees. They
enable the recursive division of data into subsets, forming unbalanced
trees. This makes SP-GiST indexes particularly effective for in-memory
usage, where they can quickly process queries due to fewer levels and
small data groups in each node.</p>

<p>However, SP-GiST indexes have disadvantages when stored on disk due to
the high number of disk operations required for their functioning,
especially in large databases.</p>

<p>Considering this, GiST indexes often become a better choice, especially
when working with polygons and complex spatial structures.</p>

<h2 id="finding-the-nearest-neighbors-10-fires-near-the-shahed-production-plant">Finding the nearest neighbors: 10 fires near the Shahed production plant</h2>

<p>Now, let's attempt to solve the task of finding nearest neighbors using
PostgreSQL. Using our datasets, we will try to identify ten fires that
occurred near the factory in russia, where Iranian Shahed drones are
manufactured. For more detailed information about the plant, you can
refer to the <a href="https://molfar.com/blog/alabuga-deanon">research</a>
conducted by the Molfar team. The factory is located in the special
economic zone
<a href="https://en.wikipedia.org/wiki/Alabuga_Special_Economic_Zone">Alabuga</a>
in Tatarstan, where previously cat food and automotive glass were
produced, and mushrooms were grown. However, after sanctions against
Russia, its priorities shifted, and now it plays a key role in russia's
plans for drone production.</p>

<p>One of the methods to solve this task is to create a buffer in the form
of a circle around the selected target. This buffer is recursively
expanded until the required number of results is obtained. In
PostgreSQL, this can be implemented with the following SQL query, which
forms the buffer and identifies fires that occurred within the specified
radius from the selected object:</p>



<p>This approach involves gradually expanding the buffer and analyzing the
results, which can be time-consuming.</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image7.png" alt="">
<em>A plant in Tatarstan that produces Shaheds with fire visualization
within radii of 1.5 and 10 km</em></p>

<p>Various operators supported by GiST indexes can be utilized to optimize
geospatial queries. To retrieve a list of available operators to use
with a GiST index, you can execute an SQL query that scans the
PostgreSQL system tables and provides information about operators
associated with the <strong>gist_geometry_ops_2d</strong> operator class. This will
help identify the most efficient operators for performing specific
geospatial operations in the database.</p>



<p>Our GiST index provides extensive capabilities for working with geodata,
allowing you to determine the spatial location of objects and measure
distances. The <strong>&lt;-&gt;</strong> operator enables sorting objects by proximity
to a specified point. In this example, we use this operator to identify
the ten closest fires to the specified location.</p>



<p>The query turned out to be significantly faster—15 times swifter,
compared to the previous methodology, and this is without repeated
executions with a changed radius. We can analyze the query plan to
confirm that the speed increased due to the use of an index and an
operator. This way, we'll ensure that the index was indeed involved,
which is the key to improving productivity.</p>



<p>As we can see, indexes, similar to GiST, extend analytical capabilities
beyond simple comparisons, enabling the resolution of more complex
tasks. As demonstrated in this article, open data can be effectively
utilized for quickly assessing and defining goals on a global scale,
including evaluating the success of target impact.</p>

<h2 id="ubers-h3-a-perspective-on-geospatial-analytics-and-data-aggregation">Uber's H3: a perspective on geospatial analytics and data aggregation</h2>

<p>The H3, developed by Uber, is a hexagonal grid system designed to
facilitate flexible and efficient distribution of geospatial data. It
seems that H3 has the potential to become a common standard for working
with geodata in the Armed Forces of Ukraine. Let's explore how this
tool can be used for data aggregation and solving complex geoanalytical
tasks.</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image8.png" alt="">
<em>Illustration of the Uber H3 hexagonal grid</em></p>

<p>As you can see in the image, each hexagon serves as a distinct
geographic unit, simplifying the processing of intricate geoforms into
uniform segments.</p>

<table>
  <thead>
    <tr>
      <th>Level</th>
      <th>Total number of objects</th>
      <th>Number of hexagons</th>
      <th>Number of pentagons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>122</td>
      <td>110</td>
      <td>12</td>
    </tr>
    <tr>
      <td>1</td>
      <td>842</td>
      <td>830</td>
      <td>12</td>
    </tr>
    <tr>
      <td>2</td>
      <td>5,882</td>
      <td>5,870</td>
      <td>12</td>
    </tr>
    <tr>
      <td>3</td>
      <td>41,162</td>
      <td>41,150</td>
      <td>12</td>
    </tr>
    <tr>
      <td>4</td>
      <td>288,122</td>
      <td>288,110</td>
      <td>12</td>
    </tr>
    <tr>
      <td>5</td>
      <td>2,016,842</td>
      <td>2,016,830</td>
      <td>12</td>
    </tr>
    <tr>
      <td>6</td>
      <td>14,117,882</td>
      <td>14,117,870</td>
      <td>12</td>
    </tr>
    <tr>
      <td>7</td>
      <td>98,825,162</td>
      <td>98,825,150</td>
      <td>12</td>
    </tr>
    <tr>
      <td>8</td>
      <td>691,776,122</td>
      <td>691,776,110</td>
      <td>12</td>
    </tr>
    <tr>
      <td>9</td>
      <td>4,842,432,842</td>
      <td>4,842,432,830</td>
      <td>12</td>
    </tr>
    <tr>
      <td>10</td>
      <td>33,897,029,882</td>
      <td>33,897,029,870</td>
      <td>12</td>
    </tr>
    <tr>
      <td>11</td>
      <td>237,279,209,162</td>
      <td>237,279,209,150</td>
      <td>12</td>
    </tr>
    <tr>
      <td>12</td>
      <td>1,660,954,464,122</td>
      <td>1,660,954,464,110</td>
      <td>12</td>
    </tr>
    <tr>
      <td>13</td>
      <td>11,626,681,248,842</td>
      <td>11,626,681,248,830</td>
      <td>12</td>
    </tr>
    <tr>
      <td>14</td>
      <td>81,386,768,741,882</td>
      <td>81,386,768,741,870</td>
      <td>12</td>
    </tr>
    <tr>
      <td>15</td>
      <td>569,707,381,193,162</td>
      <td>569,707,381,193,150</td>
      <td>12</td>
    </tr>
  </tbody>
</table>

<p>This is a hierarchical system consisting of 15 levels dividing the
Earth's surface into hexagons. The zero level is divided into 122
sections, 12 of which are pentagons for accurately representing the
Earth's spherical shape. We have approximately 569 trillion hexagons at
the finest level, each representing a distinct geospatial object. The
video below demonstrates how this works in practice.
<a href="https://youtu.be/RbeYPqsFGPI">https://youtu.be/RbeYPqsFGPI</a></p>

<p>PostgreSQL can integrate H3 functionality through an additional
extension. To install this extension, use the <strong>CREATE EXTENSION h3;</strong>
command, and it is available on cloud computing services, including AWS
RDS (my acknowledgments to AWS for their support of Ukraine). Once
you've installed this extension, new functions become accessible.
Let's explore those functions that might be useful for beginners:</p>

<table>
  <thead>
    <tr>
      <th>Function</th>
      <th>Input data</th>
      <th>Output data</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>h3_lat_lng_to_cell</td>
      <td>latitude: FLOAT, longitude: FLOAT, resolution: INT</td>
      <td>H3 index: BIGINT</td>
      <td>Converts latitude and longitude coordinates into an H3 index at a specified resolution level.</td>
    </tr>
    <tr>
      <td>h3_cell_to_boundary</td>
      <td>H3 index: BIGINT</td>
      <td>Array of boundary coordinates: GEOMETRY(POLYGON, 4326)</td>
      <td>Transforms an H3 index into a geometric polygon representing the boundaries of a hexagon.</td>
    </tr>
    <tr>
      <td>h3_get_resolution</td>
      <td>H3 index: BIGINT</td>
      <td>Resolution level: INT</td>
      <td>Returns the resolution level of a given H3 index.</td>
    </tr>
    <tr>
      <td>h3_cell_to_parent</td>
      <td>H3 index: BIGINT, desired resolution: INT</td>
      <td>Parent H3 index: BIGINT</td>
      <td>Converts an H3 index into its parent index at a higher hierarchy level.</td>
    </tr>
    <tr>
      <td>h3_cell_to_children</td>
      <td>H3 index: BIGINT, desired resolution: INT</td>
      <td>Array of child H3 indexes: SETOF BIGINT</td>
      <td>Converts an H3 index into an array of child indices at a lower hierarchy level.</td>
    </tr>
    <tr>
      <td>h3_polygon_to_cells</td>
      <td>geometry: GEOMETRY, resolution: INT</td>
      <td>Array of H3 indexes: SETOF BIGINT</td>
      <td>Transforms a polygon into a set of H3 indices that fully or partially cover the polygon.</td>
    </tr>
    <tr>
      <td>h3_grid_disk</td>
      <td>H3 index: BIGINT, range: INT</td>
      <td>Array of H3 indexes: SETOF BIGINT</td>
      <td>Generates an array of H3 indices representing a hexagonal grid around the central H3 index, forming a “disk” of a defined radius.</td>
    </tr>
    <tr>
      <td>h3_compact_cells</td>
      <td>Array of H3 indexes: SETOF BIGINT</td>
      <td>Array of compact H3 indexes: SETOF BIGINT</td>
      <td>Consolidates an array of H3 indices, reducing the number of indices covering the same area.</td>
    </tr>
  </tbody>
</table>

<p>To address the first task effectively, we can transform all our polygons
into arrays of H3 indexes (hexagons) of a specified level. Similarly, we
can process the centroids of fires by converting them into H3 indexes.
By obtaining BIGINT data types for these H3 indexes, we can apply a
standard B-tree index, which is particularly efficient in performing
equality comparison operations. This will significantly improve query
execution speed in complex geoanalysis tasks, ensuring fast and accurate
results.</p>

<p>Let's examine a few simple H3 functions that will help better
understand how this works in practice:</p>

<table>
  <thead>
    <tr>
      <th><img src="https://klioba.com/imgs/geoanalytics-postgresql/image9.png" alt="Image 1"></th>
      <th><img src="https://klioba.com/imgs/geoanalytics-postgresql/image10.png" alt="Image 2"></th>
      <th><img src="https://klioba.com/imgs/geoanalytics-postgresql/image11.png" alt="Image 3"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>h3_polygon_to_cells(geom, 8)</strong><br>This function converts the geometry of a military polygon into a set of H3 indexes at the eighth level of resolution, effectively dividing the polygon into hexagons, each covering an area of 0.737327598 square kilometers, enabling detailed spatial analysis.</td>
      <td><strong>h3_grid_disk(h3_polygon_to_cells(geom, 8), 1)</strong><br>If certain areas of the polygon remain uncovered after applying h3_polygon_to_cells, you can use h3_grid_disk to create an additional ring of H3 indexes. It will expand coverage by adding hexagons around existing indexes, ensuring complete coverage of the defined geographic polygon.</td>
      <td><strong>h3_polygon_to_cells(geom, 9)</strong><br>Using the <strong>h3_polygon_to_cells</strong> function with a level 9 increases the grid’s resolution to a finer scale, where each hexagon represents an area of 0.105332513 square kilometers. This allows for greater accuracy in reproducing the geometry of the geographic polygon for detailed spatial analysis. However, it also results in more hexagons, which may negatively impact query execution speed.</td>
    </tr>
  </tbody>
</table>

<p>During my presentation at PGConf.2023, the largest conference in Europe
dedicated to PostgreSQL, I had the opportunity to showcase a series of
more complex challenges that can be addressed by aggregating geospatial
data using H3. One example involved the search for other drones located
in the exact location and time, as well as the analysis of routes taken
by drones traveling together, identified in different places over a
specific period (Companion Analysis). You will have the opportunity to
learn more about this topic in the continuation of this article. In the
meantime, you can check out the materials of my
<a href="https://klioba.com/public/presentations/PostGIS_Warfare_Export.pdf">presentation</a>.</p>

<p>Within our datasets, we can analyze military objects and, through
aggregation with H3, calculate the density of these objects in russia.
The visualization of this analysis looks like this:</p>

<p><img src="https://klioba.com/imgs/geoanalytics-postgresql/image12.png" alt="">
<em>Visualization of the density of military objects in russia and the
temporarily occupied Autonomous Republic of Crimea using H3 hexagons</em></p>

<p>Using H3 for aggregating geospatial data significantly enhances
analytical capabilities, allowing for a more profound interpretation and
visualization of complex spatial relationships.</p>



<p>If you are a representative of the Armed Forces of Ukraine and are
seeking qualified support in the field of data, Big Data, or
geoanalytics, feel free to reach out to me. My team of volunteers and I
will gladly assist you with our knowledge and resources.</p>

<p>Additional resources I utilized in preparing this article:</p>

<ul>
  <li><a href="https://subscription.packtpub.com/book/data/9781800567498/3/ch03lvl1sec19/understanding-postgresql-index-types">Mastering PostgreSQL by&nbsp;Hans-Jürgen
Schönig</a></li>
  <li><a href="https://www.washingtonpost.com/investigations/2023/08/17/russia-iran-drone-shahed-alabuga/">Inside the russian effort to&nbsp;build 6,000 attack drones with Iran’s
help</a></li>
  <li><a href="https://h3geo.org/docs/core-library/restable/">Uber H3. Tables of&nbsp;Cell Statistics Across
Resolutions</a></li>
  <li><a href="https://github.com/zachasme/h3-pg/blob/main/docs/api.md">H3-PG Extension. API
Reference</a></li>
  <li><a href="https://postgis.net/documentation/">PostGIS documentation</a></li>
  <li><a href="https://www.amazon.com/PostGIS-Action-Third-Leo-Hsu/dp/1617296694">PostGIS in&nbsp;Action, Third Edition by&nbsp;Leo S. Hsu and Regina
Obe</a></li>
</ul>

<p>While preparing this article, I used an Ubuntu server with the following
characteristics and configured the PostgreSQL database as follows:</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perf Is Not Enough (177 pts)]]></title>
            <link>https://motherduck.com/blog/perf-is-not-enough/</link>
            <guid>39662234</guid>
            <pubDate>Sun, 10 Mar 2024 20:17:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://motherduck.com/blog/perf-is-not-enough/">https://motherduck.com/blog/perf-is-not-enough/</a>, See on <a href="https://news.ycombinator.com/item?id=39662234">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><h2 id="on-the-cult-of-performance-in-databases">On the cult of performance in databases</h2><p>It takes about 4.5 hours for me to go door to door from my house in Seattle to our office in San Francisco. Let’s say you built a hypersonic plane with a top speed that was 10 times faster than the usual Boeing 737-MAX (with or without the extra windy window seat). After you factor in an Uber to the airport, waiting in security lines, boarding, taxiing on the tarmac, takeoff and landing, waiting for a gate, waiting for baggage, and my Uber to the office, you’d have accomplished some amazing feats of engineering but probably only shaved off 20% of the overall travel time. That’s good, but I’m still not going to make a 10 am meeting.</p><p>The database industry has been focused on the equivalent of making faster planes. Meanwhile, security lines get longer and luggage gets lost. An ideal query optimizer won’t help you if your data is in a slightly wonky CSV file or if the question you want to ask is difficult to formulate in SQL.</p><p>Performance is the most common metric that database nerds like me use to measure our importance, and like sports fans, we tend to pick teams that we root for against everyone else. If your favorite database wins the benchmark wars, you have bragging rights at the watercooler. You can brandish your stats, <a href="https://www.fivetran.com/blog/warehouse-benchmark">backed</a> <a href="https://duckdb.org/2023/11/03/db-benchmark-update.html">up</a> <a href="https://clickhouse.com/blog/clickhouse-vs-snowflake-for-real-time-analytics-benchmarks-cost-analysis">by</a> <a href="https://www.singlestore.com/blog/tpc-benchmarking-results/">blog</a> <a href="https://www.databricks.com/blog/2021/11/15/snowflake-claims-similar-price-performance-to-databricks-but-not-so-fast.html">posts</a>, to prove to anyone who will listen that your favorite DB is the champ.</p><p>Performance in general, and general-purpose benchmarking in particular, is a poor way to choose a database. You’re better off making decisions based on ease of use, ecosystem, velocity of updates, or how well it integrates with your workflow. At best, performance is a point-in-time view of the time it will take to complete certain tasks; at worst, however, it leads you to optimize for the wrong things.</p></section>
<section><h2 id="ended-the-benchmark-wars-have">Ended, the benchmark wars have</h2><p>In 2019 GigaOm <a href="https://gigaom.com/report/data-warehouse-cloud-benchmark/">released</a> a benchmark comparing cloud data warehouses. They ran both TPC-H and TPC-DS across the three major cloud vendors plus Snowflake. The results? Azure Data Warehouse was the fastest by far, followed by Redshift. Snowflake and BigQuery were far behind.</p><img alt="img1" sizes="90vw,
                        (min-width: 728px) 688px,
                        (min-width: 960px) 840px,
                        (min-width: 1302px) 816px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg1_031f71a10d.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy"><p>At the time, I was working on BigQuery, and a lot of folks freaked out …. How could we be that much slower than Azure? However, the results didn’t match the impression we had from users. Every time a customer did a head-to-head evaluation of us vs Azure, they ended up choosing BigQuery. The market outcomes at that time were almost the reverse of the benchmarks: Snowflake and BigQuery ended up selling a lot better than Redshift, which sold much better than Azure.</p><p>If the benchmark didn’t match the customer experience, then either the benchmark was done wrong, the benchmark was testing the wrong thing, or performance turned out to not be that important after all. We did a lot of poking around, and it wasn’t the first one; the GigaOm folks are pretty good at running benchmarks and the methodology was sound. The benchmarks they ran, TPC-H and TPC-DS, are the industry standards and had a broad range of queries. They were the benchmarks we ourselves ran internally in order to judge performance, and while one can quibble with the data size or their relevance to real-world workloads, they were the best available.</p><p>So if the benchmark was a good representation of performance, and customers, by a large margin, ended up buying the systems that did poorly on the benchmark, then it leads you to believe that perhaps there are more important things than performance.</p></section>
<section><h2 id="what-does-it-mean-to-be-fast">What does it mean to be fast?</h2><p>In the 15 years that I’ve spent working on cloud databases, I’ve noticed an anti-pattern across the industry: People who build databases tend to be laser focused on the time between when someone clicks the “run” button and the time that results are ready. It is easy to see why database people would focus on just the database server time; after all that is the thing that they have the most control over. But what is actually impactful to users is the time it takes to complete a task, which is not the same thing.</p><p>In BigQuery, we outsourced building the JDBC drivers to a company that specializes in building database connectors. If you’re not familiar with JDBC, these provide a universal interface that programmers and Business Intelligence tools use to connect to a database. It made sense at the time to have a well-known expert build the interfaces.</p><p>A few years later, after numerous customer complaints, we realized that bugs in our JDBC driver were killing performance. From our perspective, the queries ran quickly, in just one or two seconds. But the way the driver was polling for query completion and pulling down the results made the queries seem like they were taking seconds or even minutes longer. This impact was exacerbated when there were a lot of query results, since the driver would often pull down all of the results one page at a time even if the user didn’t need to see all of the results. Sometimes they’d even crash because they ran out of memory.</p><p>We had been spending many engineer years making the queries fast, shaving off fractions of a second here and there from query times. But the connectors that most of our users were using added far more latency than we had saved. What’s more, we were completely blind to that fact. No one at Google actually used the JDBC drivers, and while we ran full suites of benchmarks every night, those benchmarks didn’t actually reflect the end-to-end performance our users were seeing.</p><p>Like the drunk looking for his keys under a streetlight, we looked only at the performance we could measure on our servers. The query time that users were seeing was invisible to us, and we considered it someone else’s problem. To actually fix the problem, and not just put band-aids on it, required us to reframe how we thought about performance.</p></section>
<section><h2 id="performance-is-subjective">Performance is Subjective</h2><p>Performance must be measured from the user’s perspective, not the database’s. It is a UX problem and, like any UX problem, can’t really be described in a single number. This is surprising to many people, since they think performance, like car racing, is an objective thing. Just because you can say that a Lamborghini is faster than a Prius, they believe you should also be able to say that My database is faster than Your database. But just like a Lamborghini might not get me to work any faster than a Prius (or a bicycle, if there is traffic), the actual workload for a database is going to determine which one is faster.</p><p>Subjectivity gets a bad rap; people associate it with saying, “Well, there is no way of telling which one is better, so it doesn’t matter which one we choose.” But just because the difference between a Ford F150 pickup truck and a Tesla Roadster is subjective, it doesn’t mean that my experience with both would be equivalent. Databases are the same way; if we say the performance differences between Clickhouse and Redshift are subjective, it doesn’t mean they are equivalent. It just means that which one is faster depends on how they are being used.</p><p>A couple of years ago, Clickhouse released <a href="https://benchmark.clickhouse.com/">Clickbench</a>, a benchmark that showed that Clickhouse was faster than a couple dozen databases they tested against. This was surprising to me, since at the time I was working at SingleStore, and we believed that we were broadly faster than Clickhouse. After digging into the benchmark, we saw that the benchmark didn’t do any JOINs, so operated out of a single table, and also relied heavily on counting distinct items.</p><img alt="img2" sizes="90vw,
                        (min-width: 728px) 688px,
                        (min-width: 960px) 840px,
                        (min-width: 1302px) 816px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg2_9bde75bf01.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy"><p>While you might think that it is cheesy to publish a benchmark that just does single-table scans, Clickbench actually does a pretty good job of representing a number of real workloads. If you do a lot of log analysis and need to compute distinct users to your website, this could be a good proxy for performance. That said, if you’re running a more traditional data warehousing workload using a star schema, Clickbench is going to be misleading.</p><p>Vendor benchmarks tend to focus on things that the vendor does well. The below is a diagram from “<a href="https://hannes.muehleisen.org/publications/DBTEST2018-performance-testing.pdf">Fair Benchmarking Considered Difficult</a>” describing the typical vendor benchmark result.</p><img alt="img3" sizes="90vw,
                        (min-width: 728px) 688px,
                        (min-width: 960px) 840px,
                        (min-width: 1302px) 816px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg3_0cfdf49142.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy"><p>There are tons of pitfalls in database benchmarking, and experience has shown that benchmarks typically do a poor job of capturing broad user-perceived performance. For example, BigQuery shows up very poorly in benchmarks, but the actual experience of many people is that the performance is magical. BigQuery shows up well in person because it doesn’t have any knobs and is largely self-tuning. A highly-tuned SingleStore instance will crush BigQuery at most tasks, but do you have time to spend tuning your schemas? And what happens when you add a new workload?</p><p>The DuckDB website used to have a disclaimer that said, “Please don’t complain about performance, we’re trying to focus on correctness before we try to make it fast.” Not all databases apply the same approach. You can make a car faster by removing safety gear like airbags, traction control, crumple zones, emissions controls, etc. But most people don’t want to drive a car like that. Databases are no different; you can make them faster if you remove overflow checks, don’t flush writes, give approximate results to certain operations, or don’t provide ACID guarantees. Some of the systems that do well on these benchmarks apply these kinds of short-cuts, but I wouldn’t want to use them except in controlled circumstances.</p></section>
<section><h2 id="rates-of-change">Rates of change</h2><p>Last year when I set out to create a company on top of DuckDB, a number of people pointed out to me that if you Googled DuckDB performance, a <a href="https://h2oai.github.io/db-benchmark/">benchmark</a> would come up where DuckDB got pretty badly beaten. Wasn’t I worried? Why not choose a “faster” one?</p><p>I wasn't concerned for two reasons. First, I think performance is of secondary importance. But second, DuckDB had demonstrated something that made current benchmarks moot; they improve incredibly quickly. Partly because of some architectural decisions, partly because the code base is relatively new and clean, and partly because the engineers involved are super talented, DuckDB gets better at an extraordinary rate.</p><p>And it turned out I was right to not be concerned. The most recent <a href="https://duckdb.org/2023/04/14/h2oai.html">published</a> results of that same benchmark against the latest DuckDB release show they went from the middle of the pack to leading by a healthy margin.</p><p>The broader point is that when you choose a database, the database is not frozen at that point in time. You’ll likely end up sticking with your decision for several years. The performance and features of your database are going to change a lot between now and next year, and even more so between now and five years from now.</p><p>A very important variable, then, is not just what the database can do now, but what it will be able to do a year in the future. If a bug in a database causes you to choose a competitor, that’s going to seem like a silly reason in just a few weeks if that bug has been fixed. This holds true with performance; if two different databases are improving at different rates, you’re most likely better off choosing the faster moving one. Your future self will thank you.</p></section>
<section><h2 id="no-magic-beans">No Magic Beans</h2><p>If you take a bunch of databases, all actively maintained, and iterate them out a few years, performance is going to converge. If Clickhouse is applying a technique that gives it an advantage for scan speed today, Snowflake will likely have that within a year or two. If Snowflake adds incrementally materialized views, BigQuery will soon follow. It is unlikely that important performance differences will persist over time.</p><p>As clever as the engineers working for any of these companies are, none of them possess any magic incantations or things that cannot be replicated elsewhere. Each database uses a different bag of tricks in order to get good performance. One might compile queries to machine code, another might cache data on local SSDs, and a third might use specialized network hardware to do shuffles. Given time, all of these techniques can be implemented by anyone. If they work well, they likely will show up everywhere.</p><p>George Fraser, the CEO of Fivetran did an interesting <a href="https://www.fivetran.com/blog/warehouse-benchmark">post</a> comparing performance of the main data warehouse vendors over time; while there was a pretty big dispersion in 2020, by 2022 they are much more closely clustered together. In 2020, the fastest time was 8 seconds and the slowest was 18, in 2022 three of the vendors were around 7 seconds and the slowest was 9.</p><img alt="img4" sizes="90vw,
                        (min-width: 728px) 688px,
                        (min-width: 960px) 840px,
                        (min-width: 1302px) 816px," srcset="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=640&amp;q=75 640w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=750&amp;q=75 750w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=828&amp;q=75 828w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=1080&amp;q=75 1080w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=1200&amp;q=75 1200w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=1920&amp;q=75 1920w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=2048&amp;q=75 2048w, https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=3840&amp;q=75 3840w" src="https://motherduck.com/_next/image/?url=https%3A%2F%2Fmotherduck-com-web-prod.s3.amazonaws.com%2Fassets%2Fimg%2Fimg4_981eeb2c34.png&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy"><p>The caveat to this rule, of course, is that architectural differences are hard to overcome. Shared nothing databases are at a disadvantage vs shared disk, and it took Redshift many years to switch to a primarily shared disk architecture. Lakehouses that rely on persisting metadata to an object store will have a hard time with rapid updates; this is built into the model. But these types of differences tend to show up in margins; there is, for example, no fundamental reason why Redshift would be faster or slower than Snowflake in the long run.</p></section>
<section><h2 id="the-problems-are-between-chair-and-keyboard-between-keyboard-and-database">The problems are between chair and keyboard &amp; between keyboard and database</h2><p>To a user, the important measure of performance is the time between when they have a question and when they have an answer; that can be very different from the time it takes the database to run a query.</p><p>If you step back and think about it from their point of view, there are a lot more levers you can use to achieve the goal of minimizing the time between question formulation and answer. You can make it easier to pose the question. You can make it easier to turn query results into something they can understand. You can help them get feedback when they’re not asking the right question. You can help them understand when the data has problems. You can help them get the data they need in the right place and the right shape to be able to ask the question in the first place. While these aren’t typically thought of as performance issues, improvements can speed up the workflows of analysts and data engineers to a larger degree than a better query plan.</p><p>Snowflake did a great job of making it easier to write queries. Whereas many SQL dialects are opinionated about being consistent about syntax and that there should be “one way” to do everything, Snowflake designers had the goal of making SQL that users type “just work.” For example, in Snowflake SQL, if you want to compute the difference between two dates, you can use either DATEDIFF or TIMEDIFF; both work with any reasonable type. You can specify a granularity, or not. You can use quotes around the granularity, or not. So if you just type a query, as long as the intention can be gleaned, it should “just work.” This is one of the reasons that analysts like Snowflake, since they don’t have to spend their time looking things up in the documentation.</p><p>DuckDB has innovated along these lines, as well, with their “<a href="https://duckdb.org/2023/08/23/even-friendlier-sql.html">Friendlier SQL</a>” effort, which adds a number of innovations to the SQL language to make it easier to write your queries. One example is “GROUP BY ALL.” When you write an aggregation query, it is easy to forget to list one of the fields in the GROUP BY clause. This is especially the case when you evolve queries, because you have to make changes in multiple different places. The GROUP BY ALL syntax makes it easier to both write and maintain your queries because you only need to change the query in one place (i.e. SELECT list) rather than the aggregation. This was so useful that soon after they released the feature, several other database vendors raced to add similar functionality.</p><p>Data isn’t always in a convenient format for querying. A huge amount of the world’s data is in CSV files, many of which are poorly constructed. Despite this, most Database vendors don’t take them seriously. In BigQuery, I wrote our first CSV splitter, and when it turned out to be a trickier problem than expected, we put a new grad engineer on the problem. It was never great, couldn’t do inference, and got confused if different files had slightly different schemas. It turns out the <a href="https://hannes.muehleisen.org/publications/ssdbm2017-muehleisen-csvs.pdf">CSV parsing</a> is actually hard.</p><p>If two engineers using two different databases need to read CSV data and compute a result, the one who is able to ingest their CSV file correctly the most easily is likely going to get the answer first, regardless of how fast their database is at executing queries. CSV file inference can therefore be thought of as a performance feature.</p><p>The way databases handle results has massive impacts on user experience. For example, a lot of times people run a “SELECT *” query to try to understand what’s in the table. Depending on how the database system is architected, this query can be instantaneous (returning a first page and a cursor, like MySQL), can take hours for large tables (if it has to make a copy of the table server-side, like BigQuery), or can run out of memory (if it tries to pull down all of the data into the client). Do clients have a long-running connection to the server, which can have trouble with network hiccups? Or do they poll, which can mean the query can complete in between polling cycles and make the query appear slower?</p></section>
<section><h2 id="on-sour-grapes">On Sour Grapes</h2><p>I’m a co-founder of a company building on DuckDB. This post might sound like something someone would write if they were working on a database that wasn’t fast, didn’t do well in benchmarks, or wasn’t focusing on performance. So I should mention that DuckDB is <em>fast</em>. I won’t spend a lot of time defending DuckDB performance, but DuckDB is currently top of ClickBench in a handful of machine sizes (e.g. <a href="https://benchmark.clickhouse.com/#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">c6a.4xlarge</a>) and most of the h20.ai <a href="https://duckdblabs.github.io/db-benchmark/">benchmarks</a>. And they’re not too shabby on TPC-H and TPC-DS either.</p><p>As has been mentioned before, your experience may differ! So before you go assuming any database is fast, try it out on your workload. But the point is, don’t count out the ducks!</p></section>
<section><h2 id="in-conclusion">In conclusion…</h2><p>None of the most successful database companies got that way by being faster than their competitors. Redshift was king for a while, and the thing that let Snowflake in the door was maintainability, not performance on benchmarks. Databases whose primary selling point was performance did not perform well in the market. Databases who made it easy to get jobs done fared a lot better.</p><p>To summarize:</p><ul>
<li>There are no magic beans; barring architectural differences, performance will converge over time.</li>
<li>Database engines evolve at very different speeds; the one who is moving most quickly will be the one that wins in the end.</li>
<li>Beware the database vendor that cares most about performance; that will slow them down in the long run.</li>
<li>There is no single metric of database performance; a “fast” database might be terrible on your workload.</li>
<li>The important feature of a database is how quickly you can go from idea to answer, not query to result.</li>
</ul><p>Faster queries are obviously preferable to slower ones. But if you’re choosing a database, you’re better off making sure you’re making your decision based on factors other than raw speed.</p><p>Happy Querying!</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PaperMC/Paper: The most widely used, high performance Minecraft server (170 pts)]]></title>
            <link>https://github.com/PaperMC/Paper</link>
            <guid>39662079</guid>
            <pubDate>Sun, 10 Mar 2024 19:55:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PaperMC/Paper">https://github.com/PaperMC/Paper</a>, See on <a href="https://news.ycombinator.com/item?id=39662079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">The most widely used, high-performance Minecraft server that aims to fix gameplay and mechanics inconsistencies.</p>
<p dir="auto"><strong>Support and Project Discussion:</strong></p>
<ul dir="auto">
<li><a href="https://forums.papermc.io/" rel="nofollow">Our forums</a> or <a href="https://discord.gg/papermc" rel="nofollow">Discord</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How To (Server Admins)</h2><a id="user-content-how-to-server-admins" aria-label="Permalink: How To (Server Admins)" href="#how-to-server-admins"></a></p>
<p dir="auto">Paperclip is a jar file that you can download and run just like a normal jar file.</p>
<p dir="auto">Download Paper from our <a href="https://papermc.io/downloads/paper" rel="nofollow">downloads page</a>.</p>
<p dir="auto">Run the Paperclip jar directly from your server. Just like old times</p>
<ul dir="auto">
<li>Documentation on using Paper: <a href="https://docs.papermc.io/" rel="nofollow">docs.papermc.io</a></li>
<li>For a sneak peek at upcoming features, <a href="https://github.com/PaperMC/Paper/projects">see here</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How To (Plugin Developers)</h2><a id="user-content-how-to-plugin-developers" aria-label="Permalink: How To (Plugin Developers)" href="#how-to-plugin-developers"></a></p>
<ul dir="auto">
<li>See our API patches <a href="https://github.com/PaperMC/Paper/blob/master/patches/api">here</a></li>
<li>See upcoming, pending, and recently added API <a href="https://github.com/orgs/PaperMC/projects/2/views/4">here</a></li>
<li>Paper API javadocs here: <a href="https://papermc.io/javadocs/" rel="nofollow">papermc.io/javadocs</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Repository (for paper-api)</h4><a id="user-content-repository-for-paper-api" aria-label="Permalink: Repository (for paper-api)" href="#repository-for-paper-api"></a></p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Maven</h5><a id="user-content-maven" aria-label="Permalink: Maven" href="#maven"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="<repository>
    <id>papermc</id>
    <url>https://repo.papermc.io/repository/maven-public/</url>
</repository>"><pre>&lt;<span>repository</span>&gt;
    &lt;<span>id</span>&gt;papermc&lt;/<span>id</span>&gt;
    &lt;<span>url</span>&gt;https://repo.papermc.io/repository/maven-public/&lt;/<span>url</span>&gt;
&lt;/<span>repository</span>&gt;</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="<dependency>
    <groupId>io.papermc.paper</groupId>
    <artifactId>paper-api</artifactId>
    <version>1.20.4-R0.1-SNAPSHOT</version>
    <scope>provided</scope>
</dependency>"><pre>&lt;<span>dependency</span>&gt;
    &lt;<span>groupId</span>&gt;io.papermc.paper&lt;/<span>groupId</span>&gt;
    &lt;<span>artifactId</span>&gt;paper-api&lt;/<span>artifactId</span>&gt;
    &lt;<span>version</span>&gt;1.20.4-R0.1-SNAPSHOT&lt;/<span>version</span>&gt;
    &lt;<span>scope</span>&gt;provided&lt;/<span>scope</span>&gt;
&lt;/<span>dependency</span>&gt;</pre></div>
<p dir="auto"><h5 tabindex="-1" dir="auto">Gradle</h5><a id="user-content-gradle" aria-label="Permalink: Gradle" href="#gradle"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="repositories {
    maven {
        url = uri(&quot;https://repo.papermc.io/repository/maven-public/&quot;)
    }
}

dependencies {
    compileOnly(&quot;io.papermc.paper:paper-api:1.20.4-R0.1-SNAPSHOT&quot;)
}

java {
    toolchain.languageVersion.set(JavaLanguageVersion.of(17))
}"><pre>repositories {
    maven {
        url <span>=</span> uri(<span><span>"</span>https://repo.papermc.io/repository/maven-public/<span>"</span></span>)
    }
}

dependencies {
    compileOnly(<span><span>"</span>io.papermc.paper:paper-api:1.20.4-R0.1-SNAPSHOT<span>"</span></span>)
}

java {
    toolchain.languageVersion.set(<span>JavaLanguageVersion</span>.of(<span>17</span>))
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">How To (Compiling Jar From Source)</h2><a id="user-content-how-to-compiling-jar-from-source" aria-label="Permalink: How To (Compiling Jar From Source)" href="#how-to-compiling-jar-from-source"></a></p>
<p dir="auto">To compile Paper, you need JDK 17 and an internet connection.</p>
<p dir="auto">Clone this repo, run <code>./gradlew applyPatches</code>, then <code>./gradlew createReobfBundlerJar</code> from your terminal. You can find the compiled jar in the project root's <code>build/libs</code> directory.</p>
<p dir="auto">To get a full list of tasks, run <code>./gradlew tasks</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How To (Pull Request)</h2><a id="user-content-how-to-pull-request" aria-label="Permalink: How To (Pull Request)" href="#how-to-pull-request"></a></p>
<p dir="auto">See <a href="https://github.com/PaperMC/Paper/blob/master/CONTRIBUTING.md">Contributing</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support Us</h2><a id="user-content-support-us" aria-label="Permalink: Support Us" href="#support-us"></a></p>
<p dir="auto">First of all, thank you for considering helping out, we really appreciate that!</p>
<p dir="auto">PaperMC has various recurring expenses, mostly related to infrastructure. Paper uses <a href="https://opencollective.com/" rel="nofollow">Open Collective</a> via the <a href="https://opencollective.com/opensource" rel="nofollow">Open Source Collective fiscal host</a> to manage expenses. Open Collective allows us to be extremely transparent, so you can always see how your donations are used. You can read more about financially supporting PaperMC <a href="https://papermc.io/sponsors" rel="nofollow">on our website</a>.</p>
<p dir="auto">You can find our collective <a href="https://opencollective.com/papermc" rel="nofollow">here</a>, or you can donate via GitHub Sponsors <a href="https://github.com/sponsors/PaperMC">here</a>, which will also go towards the collective.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Special Thanks To:</h2><a id="user-content-special-thanks-to" aria-label="Permalink: Special Thanks To:" href="#special-thanks-to"></a></p>
<p dir="auto"><a href="https://www.yourkit.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/2b1fd3407c9b019211acd8990647e37624d48818b6b39e33fe7f5fd46d573970/68747470733a2f2f7777772e796f75726b69742e636f6d2f696d616765732f796b6c6f676f2e706e67" alt="YourKit-Logo" data-canonical-src="https://www.yourkit.com/images/yklogo.png"></a></p>
<p dir="auto"><a href="https://www.yourkit.com/" rel="nofollow">YourKit</a>, makers of the outstanding java profiler, support open source projects of all kinds with their full featured <a href="https://www.yourkit.com/java/profiler" rel="nofollow">Java</a> and <a href="https://www.yourkit.com/.net/profiler" rel="nofollow">.NET</a> application profilers. We thank them for granting Paper an OSS license so that we can make our software the best it can be.</p>
<p dir="auto"><a href="https://www.jetbrains.com/" rel="nofollow"><img src="https://user-images.githubusercontent.com/21148213/121807008-8ffc6700-cc52-11eb-96a7-2f6f260f8fda.png" alt="" width="150"></a></p>
<p dir="auto"><a href="https://www.jetbrains.com/" rel="nofollow">JetBrains</a>, creators of the IntelliJ IDEA, supports Paper with one of their <a href="https://www.jetbrains.com/opensource/" rel="nofollow">Open Source Licenses</a>. IntelliJ IDEA is the recommended IDE for working with Paper, and most of the Paper team uses it.</p>
<p dir="auto">All our sponsors!<br>
<a href="https://papermc.io/sponsors" rel="nofollow"><img src="https://raw.githubusercontent.com/PaperMC/papermc.io/data/sponsors.png" alt="Sponsor Image"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rebuilding memchess.com from its archive (160 pts)]]></title>
            <link>https://grondilu.github.io/memchess/</link>
            <guid>39661497</guid>
            <pubDate>Sun, 10 Mar 2024 18:48:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grondilu.github.io/memchess/">https://grondilu.github.io/memchess/</a>, See on <a href="https://news.ycombinator.com/item?id=39661497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="introOverlay">
				<p>Hi! I'm a tool to teach you the most popular responses 
				to each chess opening and its variations. I'll ask you for the best move, and then I'll make any respectable move back.
				I do this by looking at what many Master (&gt;2200 Elo) chess players have played before.
				I play the most popular moves more often but still like to play rarer openings. 
				I'm in active development, and I hope I can help improve your chess game!</p><h2>MemChess</h2>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Timelock.dev – Send a secret into the future using timelock encryption (196 pts)]]></title>
            <link>https://timelock.dev/</link>
            <guid>39661482</guid>
            <pubDate>Sun, 10 Mar 2024 18:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timelock.dev/">https://timelock.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=39661482">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Kernel Hardening: Protect Linux user accounts against brute force attacks (118 pts)]]></title>
            <link>https://github.com/Kicksecure/security-misc</link>
            <guid>39660990</guid>
            <pubDate>Sun, 10 Mar 2024 17:46:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Kicksecure/security-misc">https://github.com/Kicksecure/security-misc</a>, See on <a href="https://news.ycombinator.com/item?id=39660990">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Enhances miscellaneous security settings</h2><a id="user-content-enhances-miscellaneous-security-settings" aria-label="Permalink: Enhances miscellaneous security settings" href="#enhances-miscellaneous-security-settings"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kernel hardening</h2><a id="user-content-kernel-hardening" aria-label="Permalink: Kernel hardening" href="#kernel-hardening"></a></p>
<p dir="auto">This section is inspired by the Kernel Self Protection Project (KSPP). It
implements all recommended Linux kernel settings by the KSPP and many more.</p>
<ul dir="auto">
<li><a href="https://kernsec.org/wiki/index.php/Kernel_Self_Protection_Project" rel="nofollow">https://kernsec.org/wiki/index.php/Kernel_Self_Protection_Project</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">sysctl</h3><a id="user-content-sysctl" aria-label="Permalink: sysctl" href="#sysctl"></a></p>
<p dir="auto">sysctl settings are configured via the <code>/etc/sysctl.d/30_security-misc.conf</code>
configuration file.</p>
<ul dir="auto">
<li>
<p dir="auto">A kernel pointer points to a specific location in kernel memory. These can
be very useful in exploiting the kernel so they are restricted to
<code>CAP_SYSLOG</code>.</p>
</li>
<li>
<p dir="auto">The kernel logs are restricted to <code>CAP_SYSLOG</code> as they can often leak
sensitive information such as kernel pointers.</p>
</li>
<li>
<p dir="auto">The <code>ptrace()</code> system call is restricted to <code>CAP_SYS_PTRACE</code>.</p>
</li>
<li>
<p dir="auto">eBPF is restricted to <code>CAP_BPF</code> (<code>CAP_SYS_ADMIN</code> on kernel versions prior to
5.8) and JIT hardening techniques such as constant blinding are enabled.</p>
</li>
<li>
<p dir="auto">Restricts performance events to <code>CAP_PERFMON</code> (<code>CAP_SYS_ADMIN</code> on kernel
versions prior to 5.8).</p>
</li>
<li>
<p dir="auto">Restricts loading line disciplines to <code>CAP_SYS_MODULE</code> to prevent
unprivileged attackers from loading vulnerable line disciplines with the
<code>TIOCSETD</code> ioctl which has been abused in a number of exploits before.</p>
</li>
<li>
<p dir="auto">Restricts the <code>userfaultfd()</code> syscall to <code>CAP_SYS_PTRACE</code> as <code>userfaultfd()</code>
is often abused to exploit use-after-free flaws.</p>
</li>
<li>
<p dir="auto">Kexec is disabled as it can be used to load a malicious kernel and gain
arbitrary code execution in kernel mode.</p>
</li>
<li>
<p dir="auto">Randomises the addresses for mmap base, heap, stack, and VDSO pages.</p>
</li>
<li>
<p dir="auto">Prevents unintentional writes to attacker-controlled files.</p>
</li>
<li>
<p dir="auto">Prevents common symlink and hardlink TOCTOU races.</p>
</li>
<li>
<p dir="auto">Disables SysRq key completely.</p>
<ul dir="auto">
<li>Therefore Secure Attention Key (SAK) cannot be used.</li>
<li><a href="https://www.kicksecure.com/wiki/SysRq" rel="nofollow">https://www.kicksecure.com/wiki/SysRq</a></li>
</ul>
</li>
<li>
<p dir="auto">The kernel is only allowed to swap if it is absolutely necessary. This
prevents writing potentially sensitive contents of memory to disk.</p>
</li>
<li>
<p dir="auto">TCP timestamps are disabled as it can allow detecting the system time.</p>
</li>
<li>
<p dir="auto">Enforces the logging of martian packets, those with a source address which
is blatantly wrong.</p>
</li>
<li>
<p dir="auto">Set coredump file name based on core_pattern value instead of the default of
naming it 'core'.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">mmap ASLR</h3><a id="user-content-mmap-aslr" aria-label="Permalink: mmap ASLR" href="#mmap-aslr"></a></p>
<ul dir="auto">
<li>The bits of entropy used for mmap ASLR are maxed out via
<code>/usr/libexec/security-misc/mmap-rnd-bits</code> (set to the values of
<code>CONFIG_ARCH_MMAP_RND_BITS_MAX</code> and <code>CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MAX</code>
that the kernel was built with), therefore improving its effectiveness.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Boot parameters</h3><a id="user-content-boot-parameters" aria-label="Permalink: Boot parameters" href="#boot-parameters"></a></p>
<p dir="auto">Boot parameters are outlined in configuration files located in the
<code>etc/default/grub.d/</code> directory.</p>
<ul dir="auto">
<li>
<p dir="auto">Slab merging is disabled which significantly increases the difficulty of
heap exploitation by preventing overwriting objects from merged caches and
by making it harder to influence slab cache layout.</p>
</li>
<li>
<p dir="auto">Memory zeroing at allocation and free time is enabled to mitigate some
use-after-free vulnerabilities and erase sensitive information in memory.</p>
</li>
<li>
<p dir="auto">Page allocator freelist randomization is enabled.</p>
</li>
<li>
<p dir="auto">Kernel Page Table Isolation is enabled to mitigate Meltdown and increase
KASLR effectiveness.</p>
</li>
<li>
<p dir="auto">vsyscalls are disabled as they are obsolete, are at fixed addresses and
thus, are a potential target for ROP.</p>
</li>
<li>
<p dir="auto">The kernel panics on oopses to thwart certain kernel exploits.</p>
</li>
<li>
<p dir="auto">Enables randomisation of the kernel stack offset on syscall entries.</p>
</li>
<li>
<p dir="auto">All mitigations for known CPU vulnerabilities are enabled and SMT is
disabled.</p>
</li>
<li>
<p dir="auto">IOMMU is enabled to prevent DMA attacks along with strict enforcement of
IOMMU TLB invalidation so devices will never be able to access stale data
contents.</p>
</li>
<li>
<p dir="auto">Distrust the 'randomly' generated CPU and bootloader seeds.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Kernel Modules</h3><a id="user-content-kernel-modules" aria-label="Permalink: Kernel Modules" href="#kernel-modules"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Kernel Module Signature Verification</h4><a id="user-content-kernel-module-signature-verification" aria-label="Permalink: Kernel Module Signature Verification" href="#kernel-module-signature-verification"></a></p>
<p dir="auto">Not yet due to issues:</p>
<ul dir="auto">
<li><a href="https://forums.whonix.org/t/enforce-kernel-module-software-signature-verification-module-signing-disallow-kernel-module-loading-by-default/7880/64" rel="nofollow">https://forums.whonix.org/t/enforce-kernel-module-software-signature-verification-module-signing-disallow-kernel-module-loading-by-default/7880/64</a></li>
<li><a data-error-text="Failed to load title" data-id="1976818419" data-permission-text="Title is private" data-url="https://github.com/dell/dkms/issues/359" data-hovercard-type="issue" data-hovercard-url="/dell/dkms/issues/359/hovercard" href="https://github.com/dell/dkms/issues/359">dell/dkms#359</a></li>
</ul>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/etc/default/grub.d/40_only_allow_signed_modules.cfg</code></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Disables the loading of new modules to the kernel after the fact</h4><a id="user-content-disables-the-loading-of-new-modules-to-the-kernel-after-the-fact" aria-label="Permalink: Disables the loading of new modules to the kernel after the fact" href="#disables-the-loading-of-new-modules-to-the-kernel-after-the-fact"></a></p>
<p dir="auto">Not yet due to issues:</p>
<ul dir="auto">
<li><a data-error-text="Failed to load title" data-id="1977341745" data-permission-text="Title is private" data-url="https://github.com/Kicksecure/security-misc/issues/152" data-hovercard-type="pull_request" data-hovercard-url="/Kicksecure/security-misc/pull/152/hovercard" href="https://github.com/Kicksecure/security-misc/pull/152">#152</a></li>
</ul>
<p dir="auto">A systemd service dynamically sets the kernel parameter <code>modules_disabled</code> to 1,
preventing new modules from being loaded. Since this isn't configured directly
within systemctl, it does not break the loading of legitimate and necessary
modules for the user, like drivers etc., given they are plugged in on startup.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Disables and blacklists kernel modules</h4><a id="user-content-disables-and-blacklists-kernel-modules" aria-label="Permalink: Disables and blacklists kernel modules" href="#disables-and-blacklists-kernel-modules"></a></p>
<p dir="auto">Certain kernel modules are disabled and blacklisted by default to reduce attack
surface via the <code>/etc/modprobe.d/30_security-misc.conf</code> configuration file.</p>
<ul dir="auto">
<li>
<p dir="auto">Deactivates Netfilter's connection tracking helper - this module increases
kernel attack surface by enabling superfluous functionality such as IRC
parsing in the kernel. Hence, this feature is disabled.</p>
</li>
<li>
<p dir="auto">Thunderbolt and numerous FireWire kernel modules are also disabled as they
are often vulnerable to DMA attacks.</p>
</li>
<li>
<p dir="auto">The MSR kernel module is disabled to prevent CPU MSRs from being abused to
write to arbitrary memory.</p>
</li>
<li>
<p dir="auto">Uncommon network protocols are blacklisted. This includes:</p>
<ul dir="auto">
<li>DCCP - Datagram Congestion Control Protocol</li>
<li>SCTP - Stream Control Transmission Protocol</li>
<li>RDS - Reliable Datagram Sockets</li>
<li>TIPC - Transparent Inter-process Communication</li>
<li>HDLC - High-Level Data Link Control</li>
<li>AX25 - Amateur X.25</li>
<li>NetRom</li>
<li>X25</li>
<li>ROSE</li>
<li>DECnet</li>
<li>Econet</li>
<li>af_802154 - IEEE 802.15.4</li>
<li>IPX - Internetwork Packet Exchange</li>
<li>AppleTalk</li>
<li>PSNAP - Subnetwork Access Protocol</li>
<li>p8023 - Novell raw IEEE 802.3</li>
<li>p8022 - IEEE 802.2</li>
<li>CAN - Controller Area Network</li>
<li>ATM</li>
</ul>
</li>
<li>
<p dir="auto">Disables a large array of uncommon file systems and network file systems
that reduces the attack surface especially against legacy approaches.</p>
</li>
<li>
<p dir="auto">The vivid kernel module is only required for testing and has been the cause
of multiple vulnerabilities so it is disabled.</p>
</li>
<li>
<p dir="auto">Provides some disabling of the interface between the <a href="https://www.kernel.org/doc/html/latest/driver-api/mei/mei.html" rel="nofollow">Intel Management
Engine (ME)</a>
and the OS.</p>
</li>
<li>
<p dir="auto">Incorporates much of
<a href="https://git.launchpad.net/ubuntu/+source/kmod/tree/debian/modprobe.d?h=ubuntu/disco" rel="nofollow">Ubuntu's</a>
default blacklist of modules to be blocked from automatically loading.
However, they are still permitted to load.</p>
</li>
<li>
<p dir="auto">Blocks automatic loading of the modules needed to use of CD-ROM devices by
default. Not completely disabled yet.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Other</h3><a id="user-content-other" aria-label="Permalink: Other" href="#other"></a></p>
<ul dir="auto">
<li>A systemd service clears the System.map file on boot as these contain kernel
pointers. The file is completely overwritten with zeroes to ensure it cannot
be recovered. See:</li>
</ul>
<p dir="auto"><code>/etc/kernel/postinst.d/30_remove-system-map</code></p>
<p dir="auto"><code>/lib/systemd/system/remove-system-map.service</code></p>
<p dir="auto"><code>/usr/libexec/security-misc/remove-system.map</code></p>
<ul dir="auto">
<li>Coredumps are disabled as they may contain important information such as
encryption keys or passwords. See:</li>
</ul>
<p dir="auto"><code>/etc/security/limits.d/30_security-misc.conf</code></p>
<p dir="auto"><code>/etc/sysctl.d/30_security-misc.conf</code></p>
<p dir="auto"><code>/lib/systemd/coredump.conf.d/30_security-misc.conf</code></p>
<ul dir="auto">
<li>An initramfs hook sets the sysctl values in <code>/etc/sysctl.conf</code> and
<code>/etc/sysctl.d</code> before init is executed so sysctl hardening is enabled as
early as possible. This is implemented for <code>initramfs-tools</code> only because
this is not needed for <code>dracut</code> because <code>dracut</code> does that by default, at
least on <code>systemd</code> enabled systems. Not researched for non-<code>systemd</code> systems
by the author of this part of the readme.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Network hardening</h2><a id="user-content-network-hardening" aria-label="Permalink: Network hardening" href="#network-hardening"></a></p>
<ul dir="auto">
<li>
<p dir="auto">TCP syncookies are enabled to prevent SYN flood attacks.</p>
</li>
<li>
<p dir="auto">ICMP redirect acceptance, ICMP redirect sending, source routing and IPv6
router advertisements are disabled to prevent man-in-the-middle attacks.</p>
</li>
<li>
<p dir="auto">The kernel is configured to ignore all ICMP requests to avoid Smurf attacks,
make the device more difficult to enumerate on the network and prevent clock
fingerprinting through ICMP timestamps.</p>
</li>
<li>
<p dir="auto">RFC1337 is enabled to protect against time-wait assassination attacks by
dropping RST packets for sockets in the time-wait state.</p>
</li>
<li>
<p dir="auto">Reverse path filtering is enabled to prevent IP spoofing and mitigate
vulnerabilities such as CVE-2019-14899.</p>
</li>
<li>
<p dir="auto">Unlike version 4, IPv6 addresses can provide information not only about the
originating network, but also the originating device. We prevent this from
happening by enabling the respective privacy extensions for IPv6.</p>
</li>
<li>
<p dir="auto">In addition, we deny the capability to track the originating device in the
network at all, by using randomized MAC addresses per connection per
default.</p>
</li>
</ul>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/usr/lib/NetworkManager/conf.d/80_ipv6-privacy.conf</code></li>
<li><code>/usr/lib/NetworkManager/conf.d/80_randomize-mac.conf</code></li>
<li><code>/usr/lib/systemd/networkd.conf.d/80_ipv6-privacy-extensions.conf</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bluetooth Hardening</h2><a id="user-content-bluetooth-hardening" aria-label="Permalink: Bluetooth Hardening" href="#bluetooth-hardening"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bluetooth Status: Enabled but Defaulted to Off</h3><a id="user-content-bluetooth-status-enabled-but-defaulted-to-off" aria-label="Permalink: Bluetooth Status: Enabled but Defaulted to Off" href="#bluetooth-status-enabled-but-defaulted-to-off"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Default Behavior</strong>: Although Bluetooth capability is 'enabled' in the kernel, security-misc deviates from the usual behavior by starting with Bluetooth turned off at system start. This setting remains until the user explicitly opts to activate Bluetooth.</p>
</li>
<li>
<p dir="auto"><strong>User Control</strong>: Users have the freedom to easily switch Bluetooth on and off in the usual way, exercising their own discretion. This can be done via the Bluetooth toggle through the usual way, that is either through GUI settings application or command line commands.</p>
</li>
<li>
<p dir="auto"><strong>Enhanced Privacy Settings</strong>: We enforce more private defaults for Bluetooth connections. This includes the use of private addresses and strict timeout settings for discoverability and visibility.</p>
</li>
<li>
<p dir="auto"><strong>Security Considerations</strong>: Despite these measures, it's important to note that Bluetooth technology, by its nature, may still be prone to exploits due to its history of security vulnerabilities. Thus, we recommend users to opt-out of using Bluetooth when possible.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration Details</h3><a id="user-content-configuration-details" aria-label="Permalink: Configuration Details" href="#configuration-details"></a></p>
<ul dir="auto">
<li>See configuration: <code>/etc/bluetooth/30_security-misc.conf</code></li>
<li>For more information and discussion: <a href="https://github.com/Kicksecure/security-misc/pull/145" data-hovercard-type="pull_request" data-hovercard-url="/Kicksecure/security-misc/pull/145/hovercard">GitHub Pull Request</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Understanding Bluetooth Terms</h3><a id="user-content-understanding-bluetooth-terms" aria-label="Permalink: Understanding Bluetooth Terms" href="#understanding-bluetooth-terms"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Disabling Bluetooth</strong>: This means the absence of the Bluetooth kernel module. When disabled, Bluetooth is non-existent in the system - it cannot be seen, set, configured, or interacted with in any way.</p>
</li>
<li>
<p dir="auto"><strong>Turning Bluetooth On/Off</strong>: This refers to a software toggle. Normally, on Debian systems, Bluetooth is 'on' when the system boots up. It actively searches for known devices to auto-connect and may be discoverable or visible under certain conditions. Our default ensures that Bluetooth is off on startup. However, it remains 'enabled' in the kernel, meaning the kernel can use the Bluetooth protocol and has the necessary modules.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick Toggle Guide</h3><a id="user-content-quick-toggle-guide" aria-label="Permalink: Quick Toggle Guide" href="#quick-toggle-guide"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Turning Bluetooth On</strong>: Simply click the Bluetooth button in the settings application or on the tray, and switch the toggle. It's a straightforward action that can be completed in less than a second.</p>
</li>
<li>
<p dir="auto"><strong>Turning Bluetooth Off</strong>: Follow the same procedure as turning it on but switch the toggle to the off position.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Entropy collection improvements</h2><a id="user-content-entropy-collection-improvements" aria-label="Permalink: Entropy collection improvements" href="#entropy-collection-improvements"></a></p>
<ul dir="auto">
<li>
<p dir="auto">The <code>jitterentropy_rng</code> kernel module is loaded as early as possible during
boot to gather more entropy via the
<code>/usr/lib/modules-load.d/30_security-misc.conf</code> configuration file.</p>
</li>
<li>
<p dir="auto">Distrusts the CPU for initial entropy at boot as it is not possible to
audit, may contain weaknesses or a backdoor. For references, see:
<code>/etc/default/grub.d/40_distrust_cpu.cfg</code></p>
</li>
<li>
<p dir="auto">Gathers more entropy during boot if using the linux-hardened kernel patch.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Restrictive mount options</h2><a id="user-content-restrictive-mount-options" aria-label="Permalink: Restrictive mount options" href="#restrictive-mount-options"></a></p>
<p dir="auto">A systemd service is triggered on boot to remount all sensitive partitions and
directories with significantly more secure hardened mount options. Since this
would require manual tuning for a given specific system, we handle it by
creating a very solid configuration file for that very system on package
install.</p>
<p dir="auto">Not enabled by default yet. In development. Help welcome.</p>
<ul dir="auto">
<li><a href="https://www.kicksecure.com/wiki/Dev/remount-secure" rel="nofollow">https://www.kicksecure.com/wiki/Dev/remount-secure</a></li>
<li><a data-error-text="Failed to load title" data-id="1977920813" data-permission-text="Title is private" data-url="https://github.com/Kicksecure/security-misc/issues/157" data-hovercard-type="issue" data-hovercard-url="/Kicksecure/security-misc/issues/157/hovercard" href="https://github.com/Kicksecure/security-misc/issues/157">#157</a></li>
<li><a href="https://forums.whonix.org/t/re-mount-home-and-other-with-noexec-and-nosuid-among-other-useful-mount-options-for-better-security/" rel="nofollow">https://forums.whonix.org/t/re-mount-home-and-other-with-noexec-and-nosuid-among-other-useful-mount-options-for-better-security/</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Root access restrictions</h2><a id="user-content-root-access-restrictions" aria-label="Permalink: Root access restrictions" href="#root-access-restrictions"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><code>su</code> is restricted to only users within the group <code>sudo</code> which prevents
users from using <code>su</code> to gain root access or to switch user accounts -
<code>/usr/share/pam-configs/wheel-security-misc</code> (which results in a change in
file <code>/etc/pam.d/common-auth</code>).</p>
</li>
<li>
<p dir="auto">Add user <code>root</code> to group <code>sudo</code>. This is required due to the above
restriction so that logging in from a virtual console is still possible -
<code>debian/security-misc.postinst</code></p>
</li>
<li>
<p dir="auto">Abort login for users with locked passwords -
<code>/usr/libexec/security-misc/pam-abort-on-locked-password</code>.</p>
</li>
<li>
<p dir="auto">Logging into the root account from a virtual, serial, whatnot console is
prevented by shipping an existing and empty <code>/etc/securetty</code> file (deletion
of <code>/etc/securetty</code> has a different effect).</p>
</li>
</ul>
<p dir="auto">This package does not yet automatically lock the root account password. It is
not clear if this would be sane in such a package although, it is recommended to
lock and expire the root account.</p>
<p dir="auto">In new Kicksecure builds, root account will be locked by package
dist-base-files.</p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><a href="https://www.kicksecure.com/wiki/Root" rel="nofollow">https://www.kicksecure.com/wiki/Root</a></li>
<li><a href="https://www.kicksecure.com/wiki/Dev/Permissions" rel="nofollow">https://www.kicksecure.com/wiki/Dev/Permissions</a></li>
<li><a href="https://forums.whonix.org/t/restrict-root-access/7658" rel="nofollow">https://forums.whonix.org/t/restrict-root-access/7658</a></li>
</ul>
<p dir="auto">However, a locked root password will break rescue and emergency shell.
Therefore, this package enables passwordless rescue and emergency shell. This is
the same solution that Debian will likely adapt for Debian installer:
<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=802211" rel="nofollow">https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=802211</a></p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/etc/systemd/system/emergency.service.d/override.conf</code></li>
<li><code>/etc/systemd/system/rescue.service.d/override.conf</code></li>
</ul>
<p dir="auto">Adverse security effects can be prevented by setting up BIOS password
protection, GRUB password protection and/or full disk encryption.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Console lockdown</h2><a id="user-content-console-lockdown" aria-label="Permalink: Console lockdown" href="#console-lockdown"></a></p>
<p dir="auto">This uses pam_access to allow members of group <code>console</code> to use console but
restrict everyone else (except members of group <code>console-unrestricted</code>) from
using console with ancient, unpopular login methods such as <code>/bin/login</code> over
networks as this might be exploitable. (CVE-2001-0797)</p>
<p dir="auto">This is not enabled by default in this package since this package does not know
which users shall be added to group 'console' and thus, would break console.</p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/usr/share/pam-configs/console-lockdown-security-misc</code></li>
<li><code>/etc/security/access-security-misc.conf</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Brute force attack protection</h2><a id="user-content-brute-force-attack-protection" aria-label="Permalink: Brute force attack protection" href="#brute-force-attack-protection"></a></p>
<p dir="auto">User accounts are locked after 50 failed login attempts using <code>pam_faillock</code>.</p>
<p dir="auto">Informational output during Linux PAM:</p>
<ul dir="auto">
<li>Show failed and remaining password attempts.</li>
<li>Document unlock procedure if Linux user account got locked.</li>
<li>Point out that there is no password feedback for <code>su</code>.</li>
<li>Explain locked root account if locked.</li>
</ul>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/usr/share/pam-configs/tally2-security-misc</code></li>
<li><code>/usr/libexec/security-misc/pam-info</code></li>
<li><code>/usr/libexec/security-misc/pam-abort-on-locked-password</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Access rights restrictions</h2><a id="user-content-access-rights-restrictions" aria-label="Permalink: Access rights restrictions" href="#access-rights-restrictions"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Strong user account separation</h3><a id="user-content-strong-user-account-separation" aria-label="Permalink: Strong user account separation" href="#strong-user-account-separation"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Permission Lockdown</h4><a id="user-content-permission-lockdown" aria-label="Permalink: Permission Lockdown" href="#permission-lockdown"></a></p>
<p dir="auto">Read, write and execute access for "others" are removed during package
installation, upgrade or PAM <code>mkhomedir</code> for all users who have home folders in
<code>/home</code> by running, for example:</p>

<p dir="auto">This will be done only once per folder in <code>/home</code> so users who wish to relax
file permissions are free to do so. This is to protect files in a home folder
that were previously created with lax file permissions prior to the installation
of this package.</p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>debian/security-misc.postinst</code></li>
<li><code>/usr/libexec/security-misc/permission-lockdown</code></li>
<li><code>/usr/share/pam-configs/mkhomedir-security-misc</code></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">umask</h4><a id="user-content-umask" aria-label="Permalink: umask" href="#umask"></a></p>
<p dir="auto">Default <code>umask</code> is set to <code>027</code> for files created by non-root users such as for
example user <code>user</code>. Broken. Disabled. See:</p>
<ul dir="auto">
<li><a data-error-text="Failed to load title" data-id="2068616319" data-permission-text="Title is private" data-url="https://github.com/Kicksecure/security-misc/issues/184" data-hovercard-type="issue" data-hovercard-url="/Kicksecure/security-misc/issues/184/hovercard" href="https://github.com/Kicksecure/security-misc/issues/184">#184</a></li>
</ul>
<p dir="auto">This is doing using pam module <code>pam_mkhomedir.so umask=027</code>.</p>
<p dir="auto">This means, files created by non-root users cannot be read by other non-root
users by default. While Permission Lockdown already protects the <code>/home</code> folder,
this protects other folders such as <code>/tmp</code>.</p>
<p dir="auto"><code>group</code> read permissions are not removed. This is unnecessary due to Debian's
use of User Private Groups (UPGs). See also:
<a href="https://wiki.debian.org/UserPrivateGroups" rel="nofollow">https://wiki.debian.org/UserPrivateGroups</a></p>
<p dir="auto">Default <code>umask</code> is unchanged for root, because then configuration files created
in <code>/etc</code> by the system administrator would be unreadable by "others" and break
applications. Examples include <code>/etc/firefox-esr</code> and <code>/etc/thunderbird</code>.</p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/usr/share/pam-configs/umask-security-misc</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">SUID / SGID removal and permission hardening</h3><a id="user-content-suid--sgid-removal-and-permission-hardening" aria-label="Permalink: SUID / SGID removal and permission hardening" href="#suid--sgid-removal-and-permission-hardening"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">SUID / SGID removal</h4><a id="user-content-suid--sgid-removal" aria-label="Permalink: SUID / SGID removal" href="#suid--sgid-removal"></a></p>
<p dir="auto">A systemd service removes SUID / SGID bits from non-essential binaries as these
are often used in privilege escalation attacks.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">File permission hardening</h4><a id="user-content-file-permission-hardening" aria-label="Permalink: File permission hardening" href="#file-permission-hardening"></a></p>
<p dir="auto">Various file permissions are reset with more secure and hardened defaults. These
include but are not limited to:</p>
<ul dir="auto">
<li>Limiting <code>/home</code> and <code>/root</code> to the root only.</li>
<li>Limiting crontab to root as well as all the configuration files for cron.</li>
<li>Limiting the configuration for cups and ssh.</li>
<li>Protecting the information of sudoers from others.</li>
<li>Protecting various system relevant files and modules.</li>
</ul>
<p dir="auto"><h5 tabindex="-1" dir="auto">permission-hardener</h5><a id="user-content-permission-hardener" aria-label="Permalink: permission-hardener" href="#permission-hardener"></a></p>
<p dir="auto"><code>permission-hardener</code> removes SUID / SGID bits from non-essential binaries as
these are often used in privilege escalation attacks. It is enabled by default
and applied at security-misc package installation and upgrade time.</p>
<p dir="auto">There is also an optional systemd unit which does the same at boot time that
can be enabled by running <code>systemctl enable permission-hardener.service</code> as
root. The hardening at boot time is not the default because this slows down
the boot too much.</p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/usr/bin/permission-hardener</code></li>
<li><code>debian/security-misc.postinst</code></li>
<li><code>/lib/systemd/system/permission-hardener.service</code></li>
<li><code>/etc/permission-hardener.d</code></li>
<li><a href="https://forums.whonix.org/t/disable-suid-binaries/7706" rel="nofollow">https://forums.whonix.org/t/disable-suid-binaries/7706</a></li>
<li><a href="https://www.kicksecure.com/wiki/SUID_Disabler_and_Permission_Hardener" rel="nofollow">https://www.kicksecure.com/wiki/SUID_Disabler_and_Permission_Hardener</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Access rights relaxations</h3><a id="user-content-access-rights-relaxations" aria-label="Permalink: Access rights relaxations" href="#access-rights-relaxations"></a></p>
<p dir="auto">This is not enabled yet because hidepid is not enabled by default.</p>
<p dir="auto">Calls to <code>pkexec</code> are redirected to <code>lxqt-sudo</code> because <code>pkexec</code> is
incompatible with <code>hidepid=2</code>.</p>
<p dir="auto">See:</p>
<ul dir="auto">
<li><code>/usr/bin/pkexec.security-misc</code></li>
<li><a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=860040" rel="nofollow">https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=860040</a></li>
<li><a href="https://forums.whonix.org/t/cannot-use-pkexec/8129" rel="nofollow">https://forums.whonix.org/t/cannot-use-pkexec/8129</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Application-specific hardening</h2><a id="user-content-application-specific-hardening" aria-label="Permalink: Application-specific hardening" href="#application-specific-hardening"></a></p>
<ul dir="auto">
<li>Enables "<code>apt-get --error-on=any</code>" which makes apt exit non-zero for
transient failures. - <code>/etc/apt/apt.conf.d/40error-on-any</code>.</li>
<li>Enables APT seccomp-BPF sandboxing - <code>/etc/apt/apt.conf.d/40sandbox</code>.</li>
<li>Deactivates previews in Dolphin.</li>
<li>Deactivates previews in Nautilus -
<code>/usr/share/glib-2.0/schemas/30_security-misc.gschema.override</code>.</li>
<li>Deactivates thumbnails in Thunar.</li>
<li>Thunderbird is hardened with the following options:
<ul dir="auto">
<li>Displays domain names in punycode to prevent IDN homograph attacks (a
form of phishing).</li>
<li>Strips email client information for sent email headers.</li>
<li>Stripts user time information from sent email headers by replacing the
originating time zone with UTC and rounding the timestamp to the nearest
minute.</li>
<li>Disables scripting when viewing pdf files.</li>
<li>Disables implicit outgoing connections.</li>
<li>Disables all and any kind of telemetry.</li>
</ul>
</li>
<li>Security and privacy enhancements for gnupg's config file
<code>/etc/skel/.gnupg/gpg.conf</code>. See also:
<ul dir="auto">
<li><a href="https://raw.github.com/ioerror/torbirdy/master/gpg.conf">https://raw.github.com/ioerror/torbirdy/master/gpg.conf</a></li>
<li><a data-error-text="Failed to load title" data-id="18132846" data-permission-text="Title is private" data-url="https://github.com/ioerror/torbirdy/issues/11" data-hovercard-type="pull_request" data-hovercard-url="/ioerror/torbirdy/pull/11/hovercard" href="https://github.com/ioerror/torbirdy/pull/11">ioerror/torbirdy#11</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">project scope of application-specific hardening</h3><a id="user-content-project-scope-of-application-specific-hardening" aria-label="Permalink: project scope of application-specific hardening" href="#project-scope-of-application-specific-hardening"></a></p>
<p dir="auto">Added in December 2023.</p>
<p dir="auto">Before sending pull requests to harden arbitrary applications, please note the
scope of security-misc is limited to default installed applications in
Kicksecure, Whonix. This includes:</p>
<ul dir="auto">
<li>Thunderbird, VLC Media Player, KeepassXC</li>
<li>Debian Specific System Components (APT, DPKG)</li>
<li>System Services (NetworkManager IPv6 privacy options, MAC address
randomization)</li>
<li>Actually used development utilities such as <code>git</code>.</li>
</ul>
<p dir="auto">It will not be possible to review and merge "1500" settings profiles for
arbitrary applications outside of this context.</p>
<p dir="auto">The main objective of security-misc is to harden Kicksecure and its derivatives,
such as Whonix, by implementing robust security settings. It's designed to be
compatible with Debian, reflecting a commitment to clean implementation and
sound design principles. However, it's important to note that security-misc is a
component of Kicksecure, not a substitute for it. The intention isn't to
recreate Kicksecure within security-misc. Instead, specific security
enhancements, like for example recommending a curated list of security-focused
default packages (e.g., <code>libpam-tmpdir</code>), should be integrated directly into
those appropriate areas of Kicksecure (e.g.<code>kicksecure-meta-packages</code>).</p>
<p dir="auto">Discussion: <a data-error-text="Failed to load title" data-id="1977539173" data-permission-text="Title is private" data-url="https://github.com/Kicksecure/security-misc/issues/154" data-hovercard-type="issue" data-hovercard-url="/Kicksecure/security-misc/issues/154/hovercard" href="https://github.com/Kicksecure/security-misc/issues/154">#154</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">development philosophy</h3><a id="user-content-development-philosophy" aria-label="Permalink: development philosophy" href="#development-philosophy"></a></p>
<p dir="auto">Added in December 2023.</p>
<p dir="auto">"Maintainability is a key priority [1]. Before modifying settings in the
downstream security-misc, it's essential to first engage with upstream
developers to propose these changes as defaults. This step should only be
bypassed if there's a clear, prior indication from upstream that such changes
won't be accepted. Additionally, before implementing any workarounds, consulting
with upstream is necessary to future unmaintainable complexity.</p>
<p dir="auto">If debugging features are disabled, pull requests won't be merged until there is
a corresponding pull request for the debug-misc package to re-enable these. This
is to avoid configuring the system into a corner where it can be no longer
debugged.</p>
<p dir="auto">[1] <a href="https://www.kicksecure.com/wiki/Dev/maintainability" rel="nofollow">https://www.kicksecure.com/wiki/Dev/maintainability</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Opt-in hardening</h2><a id="user-content-opt-in-hardening" aria-label="Permalink: Opt-in hardening" href="#opt-in-hardening"></a></p>
<p dir="auto">Some hardening is opt-in as it causes too much breakage to be enabled by
default.</p>
<ul dir="auto">
<li>
<p dir="auto">An optional systemd service mounts <code>/proc</code> with <code>hidepid=2</code> at boot to
prevent users from seeing another user's processes. This is disabled by
default because it is incompatible with <code>pkexec</code>. It can be enabled by
executing <code>systemctl enable proc-hidepid.service</code> as root.</p>
</li>
<li>
<p dir="auto">A systemd service restricts <code>/proc/cpuinfo</code>, <code>/proc/bus</code>, <code>/proc/scsi</code> and
<code>/sys</code> to the root user. This hides a lot of hardware identifiers from
unprivileged users and increases security as <code>/sys</code> exposes a lot of
information that shouldn't be accessible to unprivileged users. As this will
break many things, it is disabled by default and can optionally be enabled
by executing <code>systemctl enable hide-hardware-info.service</code> as root.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">miscellaneous</h2><a id="user-content-miscellaneous" aria-label="Permalink: miscellaneous" href="#miscellaneous"></a></p>
<ul dir="auto">
<li>
<p dir="auto">hardened malloc compatibility for haveged workaround
<code>/lib/systemd/system/haveged.service.d/30_security-misc.conf</code></p>
</li>
<li>
<p dir="auto">set <code>dracut</code> <code>reproducible=yes</code> setting</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">legal</h2><a id="user-content-legal" aria-label="Permalink: legal" href="#legal"></a></p>
<p dir="auto"><code>/usr/lib/issue.d/20_security-misc.issue</code></p>
<p dir="auto"><a data-error-text="Failed to load title" data-id="2000357720" data-permission-text="Title is private" data-url="https://github.com/Kicksecure/security-misc/issues/167" data-hovercard-type="pull_request" data-hovercard-url="/Kicksecure/security-misc/pull/167/hovercard" href="https://github.com/Kicksecure/security-misc/pull/167">#167</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Related</h2><a id="user-content-related" aria-label="Permalink: Related" href="#related"></a></p>
<ul dir="auto">
<li>Linux Kernel Runtime Guard (LKRG)</li>
<li>tirdad - TCP ISN CPU Information Leak Protection.</li>
<li>Kicksecure (TM) - a security-hardened Linux Distribution</li>
<li>And more.</li>
<li><a href="https://www.kicksecure.com/wiki/Linux_Kernel_Runtime_Guard_LKRG" rel="nofollow">https://www.kicksecure.com/wiki/Linux_Kernel_Runtime_Guard_LKRG</a></li>
<li><a href="https://github.com/Kicksecure/tirdad">https://github.com/Kicksecure/tirdad</a></li>
<li><a href="https://www.kicksecure.com/" rel="nofollow">https://www.kicksecure.com</a></li>
<li><a href="https://github.com/Kicksecure">https://github.com/Kicksecure</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Discussion</h2><a id="user-content-discussion" aria-label="Permalink: Discussion" href="#discussion"></a></p>
<p dir="auto">Happening primarily in forums.</p>
<p dir="auto"><a href="https://forums.whonix.org/t/kernel-hardening/7296" rel="nofollow">https://forums.whonix.org/t/kernel-hardening/7296</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to install <code>security-misc</code></h2><a id="user-content-how-to-install-security-misc" aria-label="Permalink: How to install security-misc" href="#how-to-install-security-misc"></a></p>
<p dir="auto">See <a href="https://www.kicksecure.com/wiki/Security-misc#install" rel="nofollow">https://www.kicksecure.com/wiki/Security-misc#install</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Build deb Package from Source Code</h2><a id="user-content-how-to-build-deb-package-from-source-code" aria-label="Permalink: How to Build deb Package from Source Code" href="#how-to-build-deb-package-from-source-code"></a></p>
<p dir="auto">Can be build using standard Debian package build tools such as:</p>

<p dir="auto">See instructions. (Replace <code>generic-package</code> with the actual name of this
package <code>security-misc</code>.)</p>
<ul dir="auto">
<li><strong>A)</strong>
<a href="https://www.kicksecure.com/wiki/Dev/Build_Documentation/generic-package/easy" rel="nofollow">easy</a>,
<em>OR</em></li>
<li><strong>B)</strong> <a href="https://www.kicksecure.com/wiki/Dev/Build_Documentation/generic-package" rel="nofollow">including verifying software
signatures</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<ul dir="auto">
<li><a href="https://forums.kicksecure.com/" rel="nofollow">Free Forum Support</a></li>
<li><a href="https://www.kicksecure.com/wiki/Professional_Support" rel="nofollow">Professional Support</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Donate</h2><a id="user-content-donate" aria-label="Permalink: Donate" href="#donate"></a></p>
<p dir="auto"><code>security-misc</code> requires <a href="https://www.kicksecure.com/wiki/Donate" rel="nofollow">donations</a> to
stay alive!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How far are we from intelligent visual deductive reasoning? (105 pts)]]></title>
            <link>https://arxiv.org/abs/2403.04732</link>
            <guid>39660780</guid>
            <pubDate>Sun, 10 Mar 2024 17:17:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.04732">https://arxiv.org/abs/2403.04732</a>, See on <a href="https://news.ycombinator.com/item?id=39660780">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2403.04732">Download PDF</a>
    <a href="https://arxiv.org/html/2403.04732v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated incredible strides on diverse vision language tasks. We dig into vision-based deductive reasoning, a more sophisticated but less explored realm, and find previously unexposed blindspots in the current SOTA VLMs. Specifically, we leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop relational and deductive reasoning relying solely on visual clues. We perform comprehensive evaluations of several popular VLMs employing standard strategies such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test, IntelligenceTest, and RAVEN. The results reveal that despite the impressive capabilities of LLMs in text-based reasoning, we are still far from achieving comparable proficiency in visual deductive reasoning. We found that certain standard strategies that are effective when applied to LLMs do not seamlessly translate to the challenges presented by visual reasoning tasks. Moreover, a detailed analysis reveals that VLMs struggle to solve these tasks mainly because they are unable to perceive and comprehend multiple, confounding abstract patterns in RPM examples.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yizhe Zhang [<a href="https://arxiv.org/show-email/13e3e3c2/2403.04732">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2403.04732v1">[v1]</a></strong>
        Thu, 7 Mar 2024 18:35:54 UTC (372 KB)<br>
    <strong>[v2]</strong>
        Fri, 8 Mar 2024 06:47:08 UTC (372 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DBeaver – open-source database client (380 pts)]]></title>
            <link>https://github.com/dbeaver/dbeaver</link>
            <guid>39660592</guid>
            <pubDate>Sun, 10 Mar 2024 16:52:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dbeaver/dbeaver">https://github.com/dbeaver/dbeaver</a>, See on <a href="https://news.ycombinator.com/item?id=39660592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://twitter.com/dbeaver_news" rel="nofollow"><img src="https://camo.githubusercontent.com/b70463ff01e6ae39a114237bf0c68119b0c263cb02ac9221eca9f8a4c1c6066f/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f68747470732f747769747465722e636f6d2f646265617665725f6e6577732e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f77253230253430646265617665725f6e657773" alt="Twitter URL" data-canonical-src="https://img.shields.io/twitter/url/https/twitter.com/dbeaver_news.svg?style=social&amp;label=Follow%20%40dbeaver_news"></a>
<a href="https://app.codacy.com/gh/dbeaver/dbeaver/dashboard?utm_source=gh&amp;utm_medium=referral&amp;utm_content=&amp;utm_campaign=Badge_grade" rel="nofollow"><img src="https://camo.githubusercontent.com/d05355599ca92620d1db7ad405e5ea2fe3660e07eec3b546457157219c564880/68747470733a2f2f6170702e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6661306262396366356139303463376438373432346638663633353162613932" alt="Codacy Badge" data-canonical-src="https://app.codacy.com/project/badge/Grade/fa0bb9cf5a904c7d87424f8f6351ba92"></a>
<a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow"><img src="https://camo.githubusercontent.com/87187083b393d712bc79c097c68073fbed88ed9864ed0769133bd3d575bfaab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f63726f6e6e2d64652f6a6972612d73796e632e737667" alt="Apache 2.0" data-canonical-src="https://img.shields.io/github/license/cronn-de/jira-sync.svg"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/dbeaver/dbeaver/wiki/images/dbeaver-icon-64x64.png"><img src="https://github.com/dbeaver/dbeaver/wiki/images/dbeaver-icon-64x64.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">DBeaver</h2><a id="user-content-dbeaver" aria-label="Permalink: DBeaver" href="#dbeaver"></a></p>
<p dir="auto">Free multi-platform database tool for developers, SQL programmers, database administrators and analysts.<br>
Supports any database which has JDBC driver (which basically means - ANY database).
<a href="https://dbeaver.com/download/" rel="nofollow">Commercial versions</a> also support non-JDBC datasources such as
MongoDB, Cassandra, Couchbase, Redis, BigTable, ScyllaDB, DynamoDB, etc.
You can find the list of all databases supported in commercial versions
<a href="https://dbeaver.com/databases/" rel="nofollow">here</a>.</p>
<ul dir="auto">
<li>Has a lot of <a href="https://github.com/dbeaver/dbeaver/wiki">features</a> including metadata editor, SQL editor, rich data editor, ERD, data export/import/migration, SQL execution plans, etc.</li>
<li>Based on <a href="https://wiki.eclipse.org/Rich_Client_Platform" rel="nofollow">Eclipse</a> platform.</li>
<li>Uses plugins architecture and provides additional functionality for the following databases: MySQL/MariaDB, PostgreSQL, Greenplum, Oracle, IBM Db2, Exasol, SQL Server, Sybase/SAP ASE, SQLite, Firebird, H2, HSQLDB, Derby, Teradata, Vertica, Netezza, Informix, etc.</li>
</ul>
<p dir="auto"><a href="https://dbeaver.io/product/dbeaver-ss-mock.png" rel="nofollow"><img src="https://camo.githubusercontent.com/d9e31d7f4fc407d573e90125a3ad077803af3c58088f5e030815d539673128e0/68747470733a2f2f646265617665722e696f2f70726f647563742f646265617665722d73732d6d6f636b2e706e67" width="400" data-canonical-src="https://dbeaver.io/product/dbeaver-ss-mock.png"></a>
<a href="https://dbeaver.io/product/dbeaver-ss-erd.png" rel="nofollow"><img src="https://camo.githubusercontent.com/20a96531862d22860a614bbe11363178777717fbb631520f7504f0a2e04df174/68747470733a2f2f646265617665722e696f2f70726f647563742f646265617665722d73732d6572642e706e67" width="400" data-canonical-src="https://dbeaver.io/product/dbeaver-ss-erd.png"></a>
<a href="https://dbeaver.io/product/dbeaver-ss-classic-new.png" rel="nofollow"><img src="https://camo.githubusercontent.com/9f4cf34e518eff92c16deb140981014a2b6ed221c1de0440bad4e625de9a6362/68747470733a2f2f646265617665722e696f2f70726f647563742f646265617665722d73732d636c61737369632d6e65772e706e67" width="400" data-canonical-src="https://dbeaver.io/product/dbeaver-ss-classic-new.png"></a>
<a href="https://dbeaver.io/product/dbeaver-ss-dark-new.png" rel="nofollow"><img src="https://camo.githubusercontent.com/485a0f57eab1abbc47534e5452890cc8578e1edc74569146051eb27263c57d22/68747470733a2f2f646265617665722e696f2f70726f647563742f646265617665722d73732d6461726b2d6e65772e706e67" width="400" data-canonical-src="https://dbeaver.io/product/dbeaver-ss-dark-new.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download</h2><a id="user-content-download" aria-label="Permalink: Download" href="#download"></a></p>
<p dir="auto">You can download prebuilt binaries from <a href="https://dbeaver.io/download" rel="nofollow">official website</a> or directly from <a href="https://github.com/dbeaver/dbeaver/releases">GitHub releases</a>.<br>
You can also download <a href="https://dbeaver.io/files/ea" rel="nofollow">Early Access</a> version. We publish daily.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running</h2><a id="user-content-running" aria-label="Permalink: Running" href="#running"></a></p>
<p dir="auto">Just run an installer (or unzip an archive) and run <code>dbeaver</code>.</p>
<p dir="auto">Note: DBeaver needs Java to run. <a href="https://adoptium.net/" rel="nofollow">Open JDK 17</a> is included in all DBeaver distributions.
You can change default JDK version by replacing directory <code>jre</code> in dbeaver installation folder.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dbeaver/dbeaver/wiki">WIKI</a></li>
<li><a href="https://github.com/dbeaver/dbeaver/issues">Issue tracker</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build from sources</h2><a id="user-content-build-from-sources" aria-label="Permalink: Build from sources" href="#build-from-sources"></a></p>
<p dir="auto"><a href="https://github.com/dbeaver/dbeaver/wiki/Build-from-sources">See this article.</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notes</h2><a id="user-content-notes" aria-label="Permalink: Notes" href="#notes"></a></p>
<ul dir="auto">
<li>For bug reports and feature requests - please <a href="https://github.com/dbeaver/dbeaver/issues">create a ticket</a>.</li>
<li>If you have any questions, ideas, etc - please <a href="https://github.com/dbeaver/dbeaver/discussions">start a discussion</a>.</li>
<li>Pull requests are welcome.</li>
<li>Visit <a href="https://dbeaver.io/" rel="nofollow">https://dbeaver.io</a> or <a href="https://dbeaver.com/" rel="nofollow">https://dbeaver.com</a> for more information.</li>
<li>Follow us on <a href="https://twitter.com/dbeaver_news/" rel="nofollow">Twitter</a> and <a href="https://www.facebook.com/DBeaverCorporation" rel="nofollow">Facebook</a></li>
<li>Thanks for using DBeaver! Star if you like it.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribution: help the Beaver!</h2><a id="user-content-contribution-help-the-beaver" aria-label="Permalink: Contribution: help the Beaver!" href="#contribution-help-the-beaver"></a></p>
<p dir="auto">Hooray, we have reached 30k+ stars on GitHub and continue to grow!<br>
That's really cool, and we are glad that you like DBeaver.</p>
<ul dir="auto">
<li>We are actively looking for new source code contributors. We have added labels “Good first issue” and “Help wanted” to some tickets. If you want to be a part of our development team, just be brave and take a ticket.</li>
<li>You can buy <a href="https://dbeaver.com/buy/" rel="nofollow">one of our commercial versions</a>. They include NoSQL databases support, additional extensions, and official online support. Also, licensed users have priorities in bug fixes and the development of new features.</li>
</ul>
<p dir="auto">Thank you!</p>
<ul dir="auto">
<li><a href="https://github.com/dbeaver/dbeaver/graphs/contributors">DBeaver Team</a> (contributors)</li>
</ul>
<hr>
<p dir="auto"><a href="https://github.com/dbeaver/cloudbeaver/"><img src="https://github.com/dbeaver/cloudbeaver/wiki/images/cloudbeaver-logo.png" width="250"></a></p>
<p dir="auto">DBeaver is a desktop client.<br>
If you are looking for a web-based database management tool - check our new product: <a href="https://cloudbeaver.io/" rel="nofollow">CloudBeaver</a>.<br>
It is based on DBeaver platform and thus supports any database and most of DBeaver features.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yi: Open Foundation Models by 01.AI (189 pts)]]></title>
            <link>https://arxiv.org/abs/2403.04652</link>
            <guid>39659781</guid>
            <pubDate>Sun, 10 Mar 2024 15:12:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.04652">https://arxiv.org/abs/2403.04652</a>, See on <a href="https://news.ycombinator.com/item?id=39659781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=01.AI">01.AI</a>: <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Young,+A">Alex Young</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+B">Bei Chen</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C">Chao Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+C">Chengen Huang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+G">Ge Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+G">Guanwei Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+H">Heng Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu,+J">Jiangcheng Zhu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+J">Jianqun Chen</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang,+J">Jing Chang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+K">Kaidong Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+P">Peng Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Q">Qiang Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yue,+S">Shawn Yue</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+S">Senbin Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+S">Shiming Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+T">Tao Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xie,+W">Wen Xie</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang,+W">Wenhao Huang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu,+X">Xiaohui Hu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren,+X">Xiaoyi Ren</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Niu,+X">Xinyao Niu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nie,+P">Pengcheng Nie</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+Y">Yuchi Xu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Y">Yudong Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+Y">Yue Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cai,+Y">Yuxuan Cai</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gu,+Z">Zhenyu Gu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+Z">Zhiyuan Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai,+Z">Zonghong Dai</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2403.04652">Download PDF</a>
    <a href="https://arxiv.org/html/2403.04652v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities. The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models. Our base models achieve strong performance on a wide range of benchmarks like MMLU, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like AlpacaEval and Chatbot Arena. Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline. For finetuning, we polish a small scale (less than 10K) instruction dataset over multiple iterations such that every single instance has been verified directly by our machine learning engineers. For vision-language, we combine the chat language model with a vision transformer encoder and train the model to align visual representations to the semantic space of the language model. We further extend the context length to 200K through lightweight continual pretraining and demonstrate strong needle-in-a-haystack retrieval performance. We show that extending the depth of the pretrained checkpoint through continual pretraining further improves performance. We believe that given our current results, continuing to scale up model parameters using thoroughly optimized data will lead to even stronger frontier models.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Wenhao Huang [<a href="https://arxiv.org/show-email/788b47ce/2403.04652">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 7 Mar 2024 16:52:49 UTC (9,681 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Profession by Isaac Asimov (1957) (129 pts)]]></title>
            <link>https://www.abelard.org/asimov.php</link>
            <guid>39659729</guid>
            <pubDate>Sun, 10 Mar 2024 15:04:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abelard.org/asimov.php">https://www.abelard.org/asimov.php</a>, See on <a href="https://news.ycombinator.com/item?id=39659729">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 
    <td> <p><span size="6" color="#CCCC00">O</span>f course, Reading Day had been different. Partly, there was the 
        simple fact of childhood. A boy of eight takes many extraordinary things 
        in stride. One day you can’t read and the next day you can. That’s 
        just the way things are. Like the sun shining.</p>
      <p>And then not so much depended upon it. There were no recruiters just 
        ahead, waiting and jostling for the lists and scores on the coming Olympics. 
        A boy or girl who goes through the Reading Day is just someone who has 
        ten more years of undifferentiated living upon Earth’s crawling 
        surface; just someone who returns to his family with one new ability.</p>
      <p>By the time Education Day came, ten years later, George wasn’t 
        even sure of most of the details of his own Reading Day.</p>
      <p>Most clearly of all, he remembered it to be a dismal September day with 
        a mild rain falling. (September for Reading Day; November for. Education 
        Day; May for Olympics. They made nursery rhymes out of it.) George had 
        dressed by the wall lights, with his parents far more excited than he 
        himself was. His father was a Registered Pipe Fitter and had found his 
        occupation on Earth. This fact had always been a humiliation to him, although, 
        of course, as anyone could see plainly, most of each generation must stay 
        on Earth in the nature of things.</p>
      <p>There had to be farmers and miners and even technicians on Earth. It 
        was only the late-model, high-specialty professions that were in demand 
        on the Outworlds, and only a few millions a year out of Earth’s 
        eight billion population could be exported. Every man and woman on Earth 
        couldn’t be among that group.</p>
      <p>But every man and woman could hope that at least one of his children 
        could be one, and Platen, Senior, was certainly no exception. It was obvious 
        to him (and, to be sure, to others as well) that George was notably intelligent 
        and quick-minded. He would be bound to do well and he would have to, as 
        he was an only child. If George didn’t end on an Outworld, they 
        would have to wait for grandchildren before a next chance would come along, 
        and that was too far in the future to be much consolation.</p>
      <p>Reading Day would not prove much, of course, but it would be the only 
        indication they would have before the big day itself. Every parent on 
        Earth would be listening to the quality of reading when his child came 
        home with it; listening for any particularly easy flow of words and building 
        that into certain omens of the future. There were few families that didn’t 
        have at least one hopeful who, from Reading Day on, was the great hope 
        because of the way he handled his trisyllabics.</p>
      <p>Dimly, George was aware of the cause of his parents’ tension, and 
        if there was any anxiety in his young heart that drizzly morning, it was 
        only the fear that his father’s hopeful expression might fade out 
        when he returned home with his reading.</p>
      <p>The children met in the large assembly room of the town’s Education 
        Hall. All over Earth, in millions of local halls, throughout that month, 
        similar groups of children would he meeting. George felt depressed by 
        the grayness of the room and by the other children, strained and stiff 
        in unaccustomed finery.</p>
      <p>Automatically, George did as all the rest of the children did. He found 
        the small clique that represented the children on his floor of the apartment 
        house and joined them.</p>
      <p>Trevelyan, who lived immediately next door, still wore his hair childishly 
        long and was years removed from the sideburns and thin, reddish mustache 
        that he was to grow as soon as he was physiologically capable of it.</p>
      <p>Trevelyan (to whom George was then known as Jawjee) said, “Bet 
        you’re scared.”</p>
      <p>“I am not,’ said George. Then, confidentially, “My 
        folks got a hunk of printing up on the dresser in my room, and when I 
        come home, I’m going to read it for them.” (George’s 
        main suffering at the moment lay in the fact that he didn’t quite 
        know where to put his hands. He had been warned not to scratch his head 
        or rub his ears or pick his nose or put his hands into his pockets. This 
        eliminated almost every possibility.)</p>
      <p>Trevelyan put <em>his </em>hands in his pockets and said, “My father 
        isn’t worried.”</p>
      <p>Trevelyan, Senior, had been a Metallurgist on Diporia for nearly seven 
        years, which gave him a superior social status in his neighborhood even 
        though he had retired and returned to Earth.</p>
      <p>Earth discouraged these re-immigrants because of population problems, 
        but a small trickle did return. For one thing the cost of living was lower 
        on Earth, and what was a trifling annuity on Diporia, say, was a comfortable 
        income on Earth. Besides, there were always men who found more satisfaction 
        in displaying their success before the friends and scenes of their childhood 
        than before all the rest of the Universe besides.</p>
      <p>Trevelyan, Senior further explained that if he stayed on Diporia, so 
        would his children, and Diporia was a one-spaceship world. Back on Earth, 
        his kids could end up anywhere, even Novia.</p>
      <p>Stubby Trevelyan had picked up that item early. Even before Reading Day, 
        his conversation was based on the carelessly assumed fact that his ultimate 
        home would be in Novia.</p>
      <p>George, oppressed by thoughts of the other’s future greatness and 
        his own small-time contrast, was driven to belligerent defense at once.</p>
      <p>“My father isn’t worried either. He just wants to hear me 
        read because he knows I’ll be good. I suppose your father would 
        just as soon not hear you because he knows you’ll be all wrong.”</p>
      <p>“I will not be all wrong. Reading is <em>nothing. </em>On Novia, 
        I’ll <em>hire </em>people to read to me.”</p>
      <p>“Because you won’t be able to read yourself, on account of 
        you’re <em>dumb!”</em></p>
      <p>“Then how come I’ll be on Novia?”</p>
      <p>And George, driven, made the great denial, “Who says you’ll 
        be on Novia? Bet you don’t go anywhere.”</p>
      <p>Stubby Trevelyan reddened. “I won’t be a Pipe Fitter like 
        your old man.”</p>
      <p>“Take that back, you dumbhead.”</p>
      <p>“You take <em>that</em> back.”</p>
      <p>They stood nose to nose, not wanting to fight but relieved at having 
        something familiar to do in this strange place. Furthermore, now that 
        George had curled his hands into fists and lifted them before his face, 
        the problem of what to do with his hands was, at least temporarily, solved. 
        Other children gathered round excitedly.</p>
      <p>But then it all ended when a woman’s voice sounded loudly over 
        the public address system. There was instant silence everywhere. George 
        dropped his fists and forgot Trevelyan.</p>
      <p>“Children,” said the voice, “we are going to call out 
        your names. As each child is called, he or she is to go to one of the 
        men waiting along the side walls. Do you see them? They are wearing red 
        uniforms so they will be easy to find. The girls will go to the right. 
        The boys will go to the left. Now look about and see which man in red 
        is nearest to you –”�</p>
      <p>George found his man at a glance and waited for his name to be called 
        off. He had not been introduced before this to the sophistications of 
        the alphabet and the length of time it took to reach his own name grew 
        disturbing.</p>
      <p>The crowd of children thinned; little rivulets made their way to each 
        of the red-clad guides.</p>
      <p>When the name ‘George Platen’ was finally called, his sense 
        of relief was exceeded only by the feeling of pure gladness at the fact 
        that Stubby Trevelyan still stood in his place, uncalled.</p>
      <p>George shouted back over his shoulder as he left, “Yay, Stubby, 
        maybe they don’t want you.”</p>
      <p>That moment of gaiety quickly left. He was herded into a line and directed 
        down corridors in the company of strange children. They all looked at 
        one another, large-eyed and concerned, but beyond a snuffling, “Quitcher 
        pushing” and “Hey, watch out” there was no conversation.</p>
      <p>They were handed little slips of paper which they were told must remain 
        with them. George stared at his curiously. Little black marks of different 
        shapes. He knew it to be printing but how could anyone make words out 
        of it? He couldn’t imagine.</p>
      <p>He was told to strip; he and four other boys who were all that now remained 
        together. All the new clothes came shucking off and four eight-year-olds 
        stood naked and small, shivering more out of embarrassment than cold. 
        Medical technicians came past, probing them, testing them with odd instruments, 
        pricking them for blood. Each took the little cards and made additional 
        marks on them with little black rods that produced the marks, all neatly 
        lined up, with great speed. George stared at the new marks, but they were 
        no more comprehensible than the old. The children were ordered back into 
        their clothes.</p>
      <p>They sat on separate little chairs then and waited again. Names were 
        called again and ‘George Platen’ came third.</p>
      <p>He moved into a large room, filled with frightening instruments with 
        knobs and glassy panels in front. There was a desk in the very center, 
        and behind it a man sat, his eyes on the papers piled before him.</p>
      <p>He said, “George Platen?”</p>
      <p>“Yes, sir,<sup>” </sup>said George, in a shaky whisper. All 
        this waiting and all this going here and there was making him nervous. 
        He wished it were over.</p>
      <p>The man behind the desk said, “I am Dr Lloyd, George. How are you?”</p>
      <p>The doctor didn’t look up as he spoke. It was as though he had 
        said those words over and over again and didn’t have to look up 
        any more.</p>
      <p>“I’m all right.”</p>
      <p>“Are you afraid, George?”</p>
      <p>“N – no, sir,” said George, sounding afraid even in 
        his own ears.</p>
      <p>“That’s good,” said the doctor, “because there’s 
        nothing to be afraid of you know. Let’s see, George. It says here 
        on your card that your father is named Peter and that he’s a Registered 
        Pipe Fitter and your mother is named Amy and is a Registered Home Technician. 
        Is that right?”</p>
      <p>“Y – yes, sir.”</p>
      <p>“And your birthday is 13 February,and you had an ear infection 
        about a year ago. Right?”</p>
      <p>“Yes, sir.”</p>
      <p>“Do you know how I know all these things?”</p>
      <p>“It’s on the card, I think, sir.”</p>
      <p>“That’s right.” The doctor looked up at George for 
        the first time and smiled. He showed even teeth and looked much younger 
        than George’s father. Some of George’s nervousness vanished.</p>
      <p>The doctor passed the card to George. “Do you know what all those 
        things there mean, George?”</p>
      <p>Although George knew he did not he was startled by the sudden request 
        into looking at the card as though he might understand now through some 
        sudden stroke of fate. But they were just marks as before and he passed 
        the card back. “No, sir.”</p>
      <p>“Why not?”</p>
      <p>George felt a sudden pang of suspicion concerning the sanity of this 
        doctor. Didn’t he know why not?</p>
      <p>George said, “I can’t read, sir.”</p>
      <p>“Would you like to read?”</p>
      <p>“Yes, sir.”</p>
      <p>“Why, George?”</p>
      <p>George stared, appalled. No one had ever asked him that. He had no answer. 
        He said falteringly, “I don’t know, sir.”</p>
      <p>“Printed information will direct you all through your life. There 
        is so much you’ll have to know even after Education Day. Cards like 
        this one will tell you. Books will tell you. Television screens will tell 
        you. Printing will tell you such useful things and such interesting things 
        that not being able to read would be as bad as not being able to see. 
        Do you understand?”</p>
      <p>“Yes, sir.”</p>
      <p>“Are you afraid, George?”</p>
      <p>“No, sir.”</p>
      <p>“Good. Now I’ll tell you exactly what we’ll do first. 
        I’m going to put these wires on your forehead just over the corners 
        of your eyes. They’ll stick there but they won’t hurt at all. 
        Then, I’ll turn on something that will make a buzz. It will sound 
        funny and it may tickle you, but it won’t hurt. Now if it does hurt, 
        you tell me, and I’ll turn it off right away, but it won’t 
        hurt. All right?”</p>
      <p>George nodded and swallowed.</p>
      <p>“Are you ready?”</p>
      <p>George nodded. He closed his eyes while the doctor busied himself. His 
        parents had explained this to him. They, too, had said it wouldn’t 
        hurt, but then there were always the older children. There were the ten- 
        and twelve-year-olds who howled after the eight-year-olds waiting for 
        Reading Day, “Watch out for the needle.” There were the others 
        who took you off in confidence and said, “They got to cut your head 
        open. They use a sharp knife that big with a hook on it,” and so 
        on into horrifying details.</p>
      <p>George had never believed them but he had had nightmares, and now he 
        closed his eyes and felt pure terror.</p>
      <p>He didn’t feel the wires at his temple. The buzz was a distant 
        thing, and there was the sound of his own blood in his ears, ringing hollowly 
        as though it and he were in a large cave. Slowly he chanced opening his 
        eyes.</p>
      <p>The doctor had his back to him. From one of the instruments a strip of 
        paper unwound and was covered with a thin, wavy purple line. The doctor 
        tore off pieces and put them into a slot in another machine. He did it 
        over and over again. Each time a little piece of film came out which the 
        doctor looked at. Finally, he turned toward George with a queer frown 
        between his eyes.</p>
      <p>The buzzing stopped.</p>
      <p>George said breathlessly, “Is it over?”</p>
      <p>The doctor said, “Yes,” but he was still frowning.</p>
      <p>“Can I read now?’ asked George. He felt no different.</p>
      <p>The doctor said, “What?” then smiled very suddenly and briefly. 
        He said, “It works fine, George. You’ll be reading in fifteen 
        minutes. Now we’re going to use another machine this time and it 
        will take longer. I’m going to cover your whole head, and when I 
        turn it on you won’t be able to see or hear anything for a while, 
        but it won’t hurt. Just to make sure I’m going to give you 
        a little switch to hold in your hand. If anything hurts, you press the 
        little button and everything shuts off. All right?”</p>
      <p>In later years, George was told that the little switch was strictly a 
        dummy; that it was introduced solely for confidence. He never did know 
        for sure, however, since he never pushed the button.</p>
      <p>A large smoothly curved helmet with a rubbery inner lining was placed 
        over his head and left there. Three or four little knobs seemed to grab 
        at him and bite into his skull, but there was only a little pressure that 
        faded. No pain.</p>
      <p>The doctor’s voice sounded dimly. “Everything all right, 
        George?”</p>
      <p>And then, with no real warning, a layer of thick felt closed down all 
        about him. He was disembodied, there was no sensation, no universe, only 
        himself and a distant murmur at the very ends of nothingness telling him 
        something – telling him – telling him –</p>
      <p>He strained to hear and understand but there was all that thick felt 
        between.</p>
      <p>Then the helmet was taken off his head, and the light was so bright that 
        it hurt his eyes while the doctor’s voice drummed at his ears.</p>
      <p>The doctor said, “Here’s your card, George. What does it 
        say?”</p>
      <p>George looked at his card again and gave out a strangled shout. The marks 
        weren’t just marks at all. They made up words. They were words just 
        as clearly as though something were whispering them in his ears. He could 
        hear them being whispered as he looked at them.</p>
      <p>“What does it say, George?”</p>
      <p>“It says – it says – ‘Platen, George. Born 13 
        February 6492 of Peter and Amy Platen in...’”� He broke off.</p>
      <p>“You can read, George,” said the doctor. “It’s 
        all over.”</p>
      <p>“For good? I won’t forget how?”</p>
      <p>“Of course not” The doctor leaned over to shake hands gravely. 
        “You will be taken home now.”</p>
      <p>It was days before George got over this new and great talent of his. 
        He read for his father with such facility that Platen, Senior, wept and 
        called relatives to tell the good news.</p>
      <p>George walked about town, reading every scrap of printing he could find 
        and wondering how it was that none of it had ever made sense to him before.</p>
      <p>He tried to remember how it was not to be able to read and 
        he couldn’t. As far as his feeling about it was concerned, he had 
        always been able to read. Always.</p></td>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tenstorrent unveils Grayskull, its RISC-V answer to GPUs (257 pts)]]></title>
            <link>https://www.techradar.com/pro/firm-headed-by-legendary-chip-architect-behind-amd-zen-finally-releases-first-hardware-days-after-being-selected-to-build-the-future-of-ai-in-japan-tenstorrent-unveils-grayskull-its-risc-v-answer-to-gpus</link>
            <guid>39658787</guid>
            <pubDate>Sun, 10 Mar 2024 13:15:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techradar.com/pro/firm-headed-by-legendary-chip-architect-behind-amd-zen-finally-releases-first-hardware-days-after-being-selected-to-build-the-future-of-ai-in-japan-tenstorrent-unveils-grayskull-its-risc-v-answer-to-gpus">https://www.techradar.com/pro/firm-headed-by-legendary-chip-architect-behind-amd-zen-finally-releases-first-hardware-days-after-being-selected-to-build-the-future-of-ai-in-japan-tenstorrent-unveils-grayskull-its-risc-v-answer-to-gpus</a>, See on <a href="https://news.ycombinator.com/item?id=39658787">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>Tenstorrent, the firm led by legendary chip architect Jim Keller, the mastermind behind <a data-analytics-id="inline-link" href="https://www.techradar.com/tag/amd" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.techradar.com/tag/amd">AMD</a>'s Zen architecture and Tesla's original self-driving chip, has launched its first hardware. Grayskull is a RISC-V alternative&nbsp;to GPUs that is designed to be easier to program and scale, and reportedly excels at handling run-time sparsity and conditional computation.</p><p>Off the back of this, Tenstorrent has also unveiled its Grayskull-powered DevKits - the standard Grayskull e75 and the more powerful Grayskull e150. Both are inference-only hardware designed for AI development, and come with TT-Buda and TT-Metalium software. The former is for running models right away, while the latter is for users who want to customize their models or write new ones.</p><p>The Santa Clara-based tech firm's milestone launch comes hot on the heels of a partnership with Japan's Leading-edge Semiconductor Technology Center (LSTC). Tenstorrent's RISC-V and Chiplet IP will be used to build a state-of-the-art 2nm AI Accelerator, with the ultimate goal of revolutionizing AI performance in Japan.</p><h2 id="by-the-power-of-grayskull-3">By the power of Grayskull!</h2><p>The Grayskull e75 model is a low-profile, half-length PCIe Gen 4 board with a single Grayskull processor, operating at 75W. The more advanced e150 model is a standard height, 3/4 length PCIe Gen 4 board containing one Grayskull processor operating at up to 200W, and balancing power and throughput.</p><p>Tenstorrent processors comprise a grid of cores known as Tensix Cores and come with network communication hardware so they can talk with one another directly over networks, instead of through DRAM.</p><p>The Grayskull DevKits support a wide range of models, including BERT for natural language processing tasks, ResNet for image recognition, Whisper for speech recognition and translation, YOLOv5 for real-time object detection, and U-Net for image segmentation.</p><p>The Grayskull e75 and e150 DevKits are <a data-analytics-id="inline-link" href="https://tenstorrent.com/cards/" target="_blank" data-url="https://tenstorrent.com/cards/">available for purchase</a> now at $599 and $799, respectively.</p><h3 id="section-more-from-techradar-pro"><span>More from TechRadar Pro</span></h3><ul><li><a href="https://www.techradar.com/pro/virtually-unhackable-chip-could-make-gpu-more-power-efficient-and-much-faster-at-ai-by-combining-light-and-silicon-for-a-fundamental-mathematical-operation" data-before-rewrite-localise="https://www.techradar.com/pro/virtually-unhackable-chip-could-make-gpu-more-power-efficient-and-much-faster-at-ai-by-combining-light-and-silicon-for-a-fundamental-mathematical-operation">Virtually unhackable' chip could make GPU power efficient and faster at AI</a></li><li><a href="https://www.techradar.com/pro/exclusive-nvidias-fastest-ai-chip-ever-is-finally-available-for-preorder-and-you-can-get-the-gh200-for-as-little-as-dollar499-per-hour" data-before-rewrite-localise="https://www.techradar.com/pro/exclusive-nvidias-fastest-ai-chip-ever-is-finally-available-for-preorder-and-you-can-get-the-gh200-for-as-little-as-dollar499-per-hour">Nvidia's fastest AI chip ever is finally available for preorder</a></li><li><a href="https://www.techradar.com/pro/will-arm-start-to-build-its-own-chips-soon-strategic-cortex-x-collaboration-with-samsung-may-well-be-first-step-in-that-direction" data-before-rewrite-localise="https://www.techradar.com/pro/will-arm-start-to-build-its-own-chips-soon-strategic-cortex-x-collaboration-with-samsung-may-well-be-first-step-in-that-direction">Will Arm start to build its own chips soon?</a></li></ul>
</div><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-nFKGmYZYDgvgnw6r42ekcK"><section><p>Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed!</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: LlamaGym – fine-tune LLM agents with online reinforcement learning (205 pts)]]></title>
            <link>https://github.com/KhoomeiK/LlamaGym</link>
            <guid>39658610</guid>
            <pubDate>Sun, 10 Mar 2024 12:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/KhoomeiK/LlamaGym">https://github.com/KhoomeiK/LlamaGym</a>, See on <a href="https://news.ycombinator.com/item?id=39658610">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/khoomeik/LlamaGym/main/llamagym.png"><img src="https://raw.githubusercontent.com/khoomeik/LlamaGym/main/llamagym.png" height="250" alt="Llama Gym"></a>
</p>
<p dir="auto">
  <em>Fine-tune LLM agents with online reinforcement learning</em>
</p>
<p dir="auto">
    <a href="https://pypi.org/project/llamagym/" rel="nofollow">
        <img alt="Python" src="https://camo.githubusercontent.com/0562f16a4ae7e35dae6087bf8b7805fb7e664a9e7e20ae6d163d94e56b94f32d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534" data-canonical-src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&amp;logo=python&amp;logoColor=ffdd54">
        <img alt="Version" src="https://camo.githubusercontent.com/f7e0da485cde2af0a033ee6f422809b27bf8fdffc9651afe45154c43e2831bf4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6c616d6167796d3f7374796c653d666f722d7468652d626164676526636f6c6f723d333637304130" data-canonical-src="https://img.shields.io/pypi/v/llamagym?style=for-the-badge&amp;color=3670A0">
    </a>
</p>
<p dir="auto">
<a href="https://reworkd.ai/" rel="nofollow">🔗 Agents for Web Data Extraction</a>
<span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>
<a href="https://x.com/khoomeik/status/1766805213644800011" rel="nofollow">🐦 Twitter</a>
</p><p dir="auto"><h2 tabindex="-1" dir="auto">LlamaGym</h2><a id="user-content-llamagym" aria-label="Permalink: LlamaGym" href="#llamagym"></a></p>
<p dir="auto">"Agents" originated in reinforcement learning, where they learn by interacting with an environment and receiving a reward signal. However, LLM-based agents today do not learn online (i.e. continuously in real time) via reinforcement.</p>
<p dir="auto">OpenAI created <a href="https://github.com/Farama-Foundation/Gymnasium">Gym</a> to standardize and simplify RL environments, but if you try dropping an LLM-based agent into a Gym environment for training, you'd find it's still quite a bit of code to handle LLM conversation context, episode batches, reward assignment, PPO setup, and more.</p>
<p dir="auto">LlamaGym seeks to simplify fine-tuning LLM agents with RL. Right now, it's a single <code>Agent</code> abstract class that handles all the issues mentioned above, letting you quickly iterate and experiment with agent prompting &amp; hyperparameters across any Gym environment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Fine-tuning an LLM-based agent to play in a Gym-style environment with RL has never been easier! Once you install LlamaGym...</p>

<p dir="auto">First, implement 3 abstract methods on the Agent class:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llamagym import Agent

class BlackjackAgent(Agent):
    def get_system_prompt(self) -> str:
        return &quot;You are an expert blackjack player.&quot;

    def format_observation(self, observation) -> str:
        return f&quot;Your current total is {observation[0]}&quot;

    def extract_action(self, response: str):
        return 0 if &quot;stay&quot; in response else 1"><pre><span>from</span> <span>llamagym</span> <span>import</span> <span>Agent</span>

<span>class</span> <span>BlackjackAgent</span>(<span>Agent</span>):
    <span>def</span> <span>get_system_prompt</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:
        <span>return</span> <span>"You are an expert blackjack player."</span>

    <span>def</span> <span>format_observation</span>(<span>self</span>, <span>observation</span>) <span>-&gt;</span> <span>str</span>:
        <span>return</span> <span>f"Your current total is <span><span>{</span><span>observation</span>[<span>0</span>]<span>}</span></span>"</span>

    <span>def</span> <span>extract_action</span>(<span>self</span>, <span>response</span>: <span>str</span>):
        <span>return</span> <span>0</span> <span>if</span> <span>"stay"</span> <span>in</span> <span>response</span> <span>else</span> <span>1</span></pre></div>
<p dir="auto">Then, define your base LLM (as you would for any fine-tuning job) and instantiate your agent:</p>
<div dir="auto" data-snippet-clipboard-copy-content="model = AutoModelForCausalLMWithValueHead.from_pretrained(&quot;Llama-2-7b&quot;).to(device)
tokenizer = AutoTokenizer.from_pretrained(&quot;Llama-2-7b&quot;)
agent = BlackjackAgent(model, tokenizer, device)"><pre><span>model</span> <span>=</span> <span>AutoModelForCausalLMWithValueHead</span>.<span>from_pretrained</span>(<span>"Llama-2-7b"</span>).<span>to</span>(<span>device</span>)
<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>"Llama-2-7b"</span>)
<span>agent</span> <span>=</span> <span>BlackjackAgent</span>(<span>model</span>, <span>tokenizer</span>, <span>device</span>)</pre></div>
<p dir="auto">Finally, write your RL loop as usual and simply call your agent to act, reward, and terminate:</p>
<div dir="auto" data-snippet-clipboard-copy-content="env = gym.make(&quot;Blackjack-v1&quot;)

for episode in trange(5000):
    observation, info = env.reset()
    done = False

    while not done:
        action = agent.act(observation) # act based on observation
        observation, reward, terminated, truncated, info = env.step(action)
        agent.assign_reward(reward) # provide reward to agent
        done = terminated or truncated

    train_stats = agent.terminate_episode() # trains if batch is full"><pre><span>env</span> <span>=</span> <span>gym</span>.<span>make</span>(<span>"Blackjack-v1"</span>)

<span>for</span> <span>episode</span> <span>in</span> <span>trange</span>(<span>5000</span>):
    <span>observation</span>, <span>info</span> <span>=</span> <span>env</span>.<span>reset</span>()
    <span>done</span> <span>=</span> <span>False</span>

    <span>while</span> <span>not</span> <span>done</span>:
        <span>action</span> <span>=</span> <span>agent</span>.<span>act</span>(<span>observation</span>) <span># act based on observation</span>
        <span>observation</span>, <span>reward</span>, <span>terminated</span>, <span>truncated</span>, <span>info</span> <span>=</span> <span>env</span>.<span>step</span>(<span>action</span>)
        <span>agent</span>.<span>assign_reward</span>(<span>reward</span>) <span># provide reward to agent</span>
        <span>done</span> <span>=</span> <span>terminated</span> <span>or</span> <span>truncated</span>

    <span>train_stats</span> <span>=</span> <span>agent</span>.<span>terminate_episode</span>() <span># trains if batch is full</span></pre></div>
<p dir="auto">Some reminders:</p>
<ul dir="auto">
<li>above code snippets are mildly simplified above but a fully working example is available in <a href="https://github.com/KhoomeiK/LlamaGym/blob/main/examples/blackjack.py"><code>examples/blackjack.py</code></a></li>
<li>getting online RL to converge is notoriously difficult so you'll have to mess with hyperparameters to see improvement
<ul dir="auto">
<li>your model may also benefit from a supervised fine-tuning stage on sampled trajectories before running RL (we may add this feature in the future)</li>
</ul>
</li>
<li>our implementation values simplicity so is not as compute efficient as e.g. <a href="https://github.com/flowersteam/lamorel">Lamorel</a>, but easier to start playing around with</li>
<li>LlamaGym is a weekend project and still a WIP, but we love contributions!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Relevant Work</h2><a id="user-content-relevant-work" aria-label="Permalink: Relevant Work" href="#relevant-work"></a></p>
<ul dir="auto">
<li><a href="https://github.com/flowersteam/Grounding_LLMs_with_online_RL">Grounding Large Language Models with Online Reinforcement Learning</a>
<ul dir="auto">
<li><a href="https://github.com/flowersteam/lamorel">Lamorel: Language Models for Reinforcement Learning</a></li>
</ul>
</li>
<li><a href="https://github.com/WeihaoTan/TWOSOME">True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<div data-snippet-clipboard-copy-content="bibtex
@misc{pandey2024llamagym,
  title        = {LlamaGym: Fine-tune LLM agents with Online Reinforcement Learning},
  author       = {Rohan Pandey},
  year         = {2024},
  howpublished = {GitHub},
  url          = {https://github.com/KhoomeiK/LlamaGym}
}"><pre><code>bibtex
@misc{pandey2024llamagym,
  title        = {LlamaGym: Fine-tune LLM agents with Online Reinforcement Learning},
  author       = {Rohan Pandey},
  year         = {2024},
  howpublished = {GitHub},
  url          = {https://github.com/KhoomeiK/LlamaGym}
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>