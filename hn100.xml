<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 06 Nov 2024 18:30:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Switch 2 will be backwards compatible with Switch, Nintendo confirms (145 pts)]]></title>
            <link>https://www.videogameschronicle.com/news/nintendo-switchs-successor-will-be-backwards-compatible-with-switch-nintendo-confirms/</link>
            <guid>42062841</guid>
            <pubDate>Wed, 06 Nov 2024 14:32:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.videogameschronicle.com/news/nintendo-switchs-successor-will-be-backwards-compatible-with-switch-nintendo-confirms/">https://www.videogameschronicle.com/news/nintendo-switchs-successor-will-be-backwards-compatible-with-switch-nintendo-confirms/</a>, See on <a href="https://news.ycombinator.com/item?id=42062841">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content_body"><p><a title="Platforms > Nintendo [4,806 articles]" href="https://www.videogameschronicle.com/platforms/nintendo/">Nintendo</a> has confirmed that the successor to the <a title="Platforms > Nintendo Switch [4,864 articles]" href="https://www.videogameschronicle.com/platforms/nintendo/switch/">Nintendo Switch</a> will be backward compatible with the Nintendo Switch.</p><p>In a post on X, a message from Nintendo president <a title="People > Shuntaro Furukawa [219 articles]" href="https://www.videogameschronicle.com/people/shuntaro-furukawa/">Shuntaro Furukawa</a> also announced that further information about the successor to the Nintendo Switch would come “at a later date.”</p><p>“This is Furukawa,” the message reads. “At today’s Corporate Management Policy Briefing, we announced that Nintendo Switch software will also be playable on the successor to Nintendo Switch.</p><p>“Nintendo Switch Online will be available on the successor to Nintendo Switch as well. Further information about the successor to Nintendo Switch, including its compatibility with Nintendo Switch, will be announced at a later date.”</p><p>The post also confirmed that Nintendo Switch Online would be available on the successor console. No further details on its implementation were announced.</p><p>Earlier today, <a href="https://www.videogameschronicle.com/news/nintendos-president-says-no-change-to-switch-2-announce-plan/">Nintendo reiterated it still intends</a> to announce its next console hardware before the end of its current fiscal year, which concludes on March 31, 2025.</p><p>President Shuntaro Furukawa made the comments during an online press conference on Tuesday, following the publication of <a href="https://www.videogameschronicle.com/news/nintendo-has-lowered-its-switch-forecast-after-sales-declined-31/">Nintendo’s latest earnings results</a>, but the executive did not add any additional details.</p><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">This is Furukawa. At today's Corporate Management Policy Briefing, we announced that Nintendo Switch software will also be playable on the successor to Nintendo Switch. Nintendo Switch Online will be available on the successor to Nintendo Switch as well. Further information about…</p>— 任天堂株式会社（企業広報・IR） (@NintendoCoLtd) <a href="https://twitter.com/NintendoCoLtd/status/1853972163033968794?ref_src=twsrc%5Etfw">November 6, 2024</a></blockquote></div><p>According to a report, developers have reportedly been briefed <a href="https://www.videogameschronicle.com/news/developers-reportedly-told-not-to-expect-switch-2-to-launch-before-april-2025/">not to expect&nbsp;Nintendo’s next console to launch before April 2025</a>.</p><p>“No developer I’ve spoken to expects it to be launching this financial year,” said <a target="_blank" rel="noopener" href="https://www.gamesindustry.biz/krafton-saves-tango-gameworks-and-numbers-all-of-the-numbers-gi-microcast">GI.biz</a> journalist Chris Dring. “In fact, they’ve been told not to expect it in the [current] financial year. A bunch of people I spoke to hope it’s out in April or May time, still early next year, not late.</p><p>“I don’t think any of us wants a late launch for Switch 2 because we all want a new Nintendo console, everyone gets very excited for it, and we don’t want that crunch of&nbsp;<a title="Games > Grand Theft Auto 6 [72 articles]" href="https://www.videogameschronicle.com/games/grand-theft-auto-6/">Grand Theft Auto 6</a>&nbsp;and Switch and all that kind of stuff on top of each other.”</p><p>Having launched in March 2017, Switch is in its eighth year on the market. In July, it surpassed the Famicom as the Nintendo console&nbsp;<a href="https://www.videogameschronicle.com/news/its-official-no-nintendo-console-has-lasted-as-long-as-switch-without-being-replaced/">with the longest lifespan before being replaced</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Private Cloud Compute Security Guide (163 pts)]]></title>
            <link>https://security.apple.com/documentation/private-cloud-compute/</link>
            <guid>42062230</guid>
            <pubDate>Wed, 06 Nov 2024 13:48:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.apple.com/documentation/private-cloud-compute/">https://security.apple.com/documentation/private-cloud-compute/</a>, See on <a href="https://news.ycombinator.com/item?id=42062230">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Bitcoin has made a new all-time high price (140 pts)]]></title>
            <link>https://www.coinbase.com/price/bitcoin</link>
            <guid>42062211</guid>
            <pubDate>Wed, 06 Nov 2024 13:47:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.coinbase.com/price/bitcoin">https://www.coinbase.com/price/bitcoin</a>, See on <a href="https://news.ycombinator.com/item?id=42062211">Hacker News</a></p>
Couldn't get https://www.coinbase.com/price/bitcoin: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[What has case distinction but is neither uppercase nor lowercase? (126 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20241031-00/?p=110443</link>
            <guid>42061313</guid>
            <pubDate>Wed, 06 Nov 2024 12:39:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20241031-00/?p=110443">https://devblogs.microsoft.com/oldnewthing/20241031-00/?p=110443</a>, See on <a href="https://news.ycombinator.com/item?id=42061313">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-110443">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>If you go exploring the Unicode Standard, you may be surprised to find that there are some characters that have case distinction yet are themselves neither uppercase nor lowercase.</p>
<p>Oooooh, spooky.</p>
<p>In other words, it is a character <var>c</var> with the properties that</p>
<ul>
<li>toUpper(<var>c</var>) ≠ toLower(<var>c</var>), yet</li>
<li><var>c</var> ≠ toUpper(<var>c</var>) and <var>c</var> ≠ toLower(<var>c</var>).</li>
</ul>
<p>Congratulations, you found the mysterious third case: Title case.</p>
<p>There are some Unicode characters that occupy a single code point but represent two graphical symbols packed together. For example, the Unicode character ǳ (U+01F1 LATIN SMALL LETTER DZ), looks like two Unicode characters placed next to each other: dz (U+0064 LATIN SMALL LETTER D followed by U+007A LATIN SMALL LETTER Z).</p>
<p>These diagraphs are characters in the alphabets of some languages, most notably Hungarian. In those languages, the diagraph is considered a separate letter of the alphabet. For example, the first ten letters of the Hungarian alphabet are¹</p>
<table>
<tbody>
<tr>
<td>a</td>
<td>á</td>
<td>b</td>
<td>c</td>
<td>cs</td>
<td>d</td>
<td>dz</td>
<td>dzs</td>
<td>e</td>
<td>é</td>
</tr>
</tbody>
</table>
<p>These digraphs (and one trigraph) have three forms.</p>
<table>
<tbody>
<tr>
<th>Form</th>
<th>Result</th>
</tr>
<tr>
<td>Uppercase</td>
<td>Ǳ</td>
</tr>
<tr>
<td>Title case</td>
<td>ǲ</td>
</tr>
<tr>
<td>Lowercase</td>
<td>ǳ</td>
</tr>
</tbody>
</table>
<p>Unicode includes four diagraphs in its encoding.</p>
<table>
<tbody>
<tr>
<th>Uppercase</th>
<th>Title case</th>
<th>Lowercase</th>
</tr>
<tr>
<td>Ǆ</td>
<td>ǅ</td>
<td>ǆ</td>
</tr>
<tr>
<td>Ǉ</td>
<td>ǈ</td>
<td>ǉ</td>
</tr>
<tr>
<td>Ǌ</td>
<td>ǋ</td>
<td>ǌ</td>
</tr>
<tr>
<td>Ǳ</td>
<td>ǲ</td>
<td>ǳ</td>
</tr>
</tbody>
</table>
<p>But wait, we have a Unicode code point for the dz digraph, but we don’t have one for the cs digraph or the dzs trigraph. What’s so special about dz?</p>
<p>These digraphs owe their existence in Unicode not to Hungarian but to Serbo-Croatian. Serbo-Croatian is written in both Latin script (Croatian) and Cyrillic script (Serbian), and these digraphs permit one-to-one transliteration between them.¹</p>
<p>Just another situation where the world is more complicated than you think. You thought you understood uppercase and lowercase, but there’s another case in between that you didn’t know about.</p>
<p><b>Bonus chatter</b>: The fact that dz is treated as a single letter in Hungarian means that if you search for “mad”, it should not match “<span lang="hu">madzag</span>” (which means “string”) because the “dz” in “<span lang="hu">madzag</span>” is a single letter and not a “d” followed by a “z”, no more than “lav” should match “law” just because the first part of the letter “w” looks like a “v”. Another surprising result if you mistakenly use a literal substring search rather than a locale-sensitive one. We’ll look at locale-sensitive substrings searches next time.</p>
<p>¹ I got this information from the Unicode Standard, Version 15.0, <a href="https://www.unicode.org/versions/Unicode15.0.0/ch07.pdf"> Chapter 7</a>: “Europe I”, Section 7.1: “Latin”, subsection “Latin Extended-B: U+0180-U+024F”, sub-subsection “Croatian Digraphs Matching Serbian Cyrillic Letters.”</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/RaymondChen_5in-150x150.jpg" alt="Raymond Chen"></p></div><p>Raymond has been involved in the evolution of Windows for more than 30 years. In 2003, he began a Web site known as The Old New Thing which has grown in popularity far beyond his wildest imagination, a development which still gives him the heebie-jeebies. The Web site spawned a book, coincidentally also titled The Old New Thing (Addison Wesley 2007). He occasionally appears on the Windows Dev Docs Twitter account to tell stories which convey no useful information.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: SuperSplat – open-source 3D Gaussian Splat Editor (133 pts)]]></title>
            <link>https://playcanvas.com/supersplat/editor?load=https://raw.githubusercontent.com/willeastcott/assets/main/toy-cat.ply&amp;camera.overlay=false&amp;show.bound=false</link>
            <guid>42060856</guid>
            <pubDate>Wed, 06 Nov 2024 12:07:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://playcanvas.com/supersplat/editor?load=https://raw.githubusercontent.com/willeastcott/assets/main/toy-cat.ply&#x26;camera.overlay=false&#x26;show.bound=false">https://playcanvas.com/supersplat/editor?load=https://raw.githubusercontent.com/willeastcott/assets/main/toy-cat.ply&#x26;camera.overlay=false&#x26;show.bound=false</a>, See on <a href="https://news.ycombinator.com/item?id=42060856">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Influencers Database with Audio Signals (206 pts)]]></title>
            <link>https://old.reddit.com/r/cursor/comments/1gku61m/i_created_this_app_in_two_weekends_with_cursor/</link>
            <guid>42058309</guid>
            <pubDate>Wed, 06 Nov 2024 09:03:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/cursor/comments/1gku61m/i_created_this_app_in_two_weekends_with_cursor/">https://old.reddit.com/r/cursor/comments/1gku61m/i_created_this_app_in_two_weekends_with_cursor/</a>, See on <a href="https://news.ycombinator.com/item?id=42058309">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/cursor/comments/1gku61m/i_created_this_app_in_two_weekends_with_cursor/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[New images of Jupiter (316 pts)]]></title>
            <link>https://www.missionjuno.swri.edu/junocam/processing?source=all&amp;ob_from=2024-10-01&amp;ob_to=2024-11-01&amp;phases%5B%5D=PERIJOVE+66&amp;perpage=16</link>
            <guid>42057851</guid>
            <pubDate>Wed, 06 Nov 2024 07:30:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.missionjuno.swri.edu/junocam/processing?source=all&#x26;ob_from=2024-10-01&#x26;ob_to=2024-11-01&#x26;phases%5B%5D=PERIJOVE+66&#x26;perpage=16">https://www.missionjuno.swri.edu/junocam/processing?source=all&#x26;ob_from=2024-10-01&#x26;ob_to=2024-11-01&#x26;phases%5B%5D=PERIJOVE+66&#x26;perpage=16</a>, See on <a href="https://news.ycombinator.com/item?id=42057851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="section_info" tabindex="0">

						<h2>IMAGE PROCESSING GALLERY</h2>

<section>
	<nav>
			<a role="button" href="#Welcome" id="labelfor-Welcome">Welcome!</a>
			<a role="button" href="#PJ1Images" id="labelfor-PJ1Images">PJ–1 Images</a>
			<a role="button" href="#GalleryOrganization" id="labelfor-GalleryOrganization">Gallery Organization</a>
			<a role="button" href="#AboutJunoCamImages" id="labelfor-AboutJunoCamImages">About JunoCam Images</a>
	</nav>
	
	<section aria-labelledby="labelfor-Welcome" id="Welcome" tabindex="0">	<span role="button"><p>Welcome!</p></span>
	<div><p>This is where we post raw images from <a href="https://www.missionjuno.swri.edu/media-gallery/instruments?show=fig_562e2fa248b496f704cf3f8a&amp;m=179" target="">JunoCam</a>. We invite you to
download them, do your own image processing, and we encourage you to upload
your creations for us to enjoy and share. The types of image processing
we’d love to see range from simply cropping an image to highlighting a
particular atmospheric feature, as well as adding your own color enhancements,
creating collages and adding advanced color reconstruction.</p><p>One of the biggest challenges for Juno is <a href="https://www.missionjuno.swri.edu/jupiter/magnetosphere?show=hs_jupiter_magnetosphere_story_radiation-belts">Jupiter's intense radiation belts</a>, which are expected to limit the lifetime of both Juno’s engineering and science subsystems. <i>JunoCam is now showing the effects of that radiation on some of its parts</i>.&nbsp; <a href="https://www.missionjuno.swri.edu/junocam/processing?source=junocam&amp;phases[]=PERIJOVE+56" target="">PJ56 images</a> show a reduction in our dynamic range and an increase in background and noise. We invite citizen scientists to explore new ways to process these images to continue to bring out the beauty and mysteries of Jupiter and its moons. </p><p>For those of you who have contributed – thank you! Your labors of love have illustrated articles
about Juno, Jupiter and JunoCam. Your
products show up in all sorts of places.&nbsp; We have used them to report to the scientific community. We are writing papers for scientific journals
and using your contributions – always with appropriate attribution of
course. Some creations are works of art
and we are working out ways to showcase them as art.</p></div>
</section><section aria-labelledby="labelfor-PJ1Images" id="PJ1Images" tabindex="0">	<span role="button"><p>PJ–1 Images</p></span>
	<div><p>The first perijove pass of Jupiter was a test run for
JunoCam. The set of 28 images taken
were designed to find optimal viewing geometries and camera settings. For example, we took 4 images of the north
pole. We used two different settings for
the time-delayed-integration (TDI), which determines the integration time, to
see which would be best for the polar region and a very high TDI level (long
exposure) to try to detect Jupiter’s aurora. We imaged at two different geometries, looking directly down at the pole
and looking at closest range at a more oblique angle, to see which would give
us the best results. We ran through a
similar set of tests for the south pole. Another comparison we made was to test different compression
settings.</p><p>

We
have a methane filter, included for the polar science investigation, that is
almost at the limits of our detector’s wavelength range. To get enough photons for an image we need to
use a very long exposure. In some images
this results in scattered light in the image.&nbsp;
For science purposes we will simply crop out the portions of the image
that include this artifact. Work is in
progress to determine exactly what conditions cause stray light problems so
that this can be minimized for future imaging.</p></div>
</section><section aria-labelledby="labelfor-GalleryOrganization" id="GalleryOrganization" tabindex="0">	<span role="button"><p>Gallery Organization</p></span>
	<div><p>The gallery displays images from JunoCam itself, as well as uploads from the community.&nbsp;</p><p>The&nbsp;JunoCam images&nbsp;are identified by a small spacecraft icon. You will see both raw and processed versions of the images as they become available. The JunoCam movie posts have too many images to post individually, so we are making &nbsp;them available for download in batches as zip files.</p><p>You can&nbsp;filter&nbsp;the gallery by many different characteristics, including by Perijove Pass, Points of Interest and Mission Phase. If you have a favorite “artist” you can create your own gallery.&nbsp; Click on “Submitted by” on the left, select your favorite artist(s), and then click on “Filter”.</p><p><i>A special note about the&nbsp;<i>Earth Flyby mission phase</i>&nbsp;images</i><i>: these were acquired in 2013 when Juno flew past Earth.&nbsp;Examples of processed images are shown; most contributions are from amateurs.</i></p></div>
</section><section aria-labelledby="labelfor-AboutJunoCamImages" id="AboutJunoCamImages" tabindex="0">	<span role="button"><p>About JunoCam Images</p></span>
	<div><p>Like previous MSSS cameras (e.g., Mars Reconnaissance Orbiter’s Mars Color Imager) Junocam is a "pushframe" imager. The detector has multiple filter strips, each with a different bandpass, bonded directly to its photoactive surface. Each strip extends the entire width of the detector, but only a fraction of its height; Junocam's filter strips are 1600 pixels wide and about 155 rows high. The filter strips are scanned across the target by spacecraft rotation. At the nominal spin rate of 2 RPM, frames are acquired about every 400 milliseconds. Junocam has four filters: three visible (red/green/blue) and a narrowband "methane" filter centered at about 890 nm.&nbsp;</p><p>The spacecraft spin rate would cause more than a pixel's worth of image blurring for exposures longer than about 3.2 milliseconds. For the illumination conditions at Jupiter such short exposures would result in unacceptably low SNR, so the camera provides Time-Delayed-Integration (TDI). TDI vertically shifts the image one row each 3.2 milliseconds over the course of the exposure, cancelling the scene motion induced by rotation. Up to about 100 TDI steps can be used for the orbital timing case while still maintaining the needed frame rate for frame-to-frame overlap. For Earth Flyby the light levels are high enough that TDI is not needed except for the methane band and for nightside imaging. &nbsp;</p><p>Junocam pixels are 12 bits deep from the camera but are converted to 8 bits inside the instrument using a lossless "companding" table, a process similar to gamma correction, to reduce their size.&nbsp; All Junocam products on the missionjuno website are in this 8-bit form as received on Earth.&nbsp; Scientific users interested in radiometric analysis should use the "RDR" data products archived with the Planetary Data System, which have been converted back to a linear 12-bit scale.</p></div>
</section></section>
						

					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Former President Trump is projected to win the presidency (1253 pts)]]></title>
            <link>https://thehill.com/homenews/campaign/4969061-trump-wins-presidential-election/</link>
            <guid>42057647</guid>
            <pubDate>Wed, 06 Nov 2024 06:49:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehill.com/homenews/campaign/4969061-trump-wins-presidential-election/">https://thehill.com/homenews/campaign/4969061-trump-wins-presidential-election/</a>, See on <a href="https://news.ycombinator.com/item?id=42057647">Hacker News</a></p>
Couldn't get https://thehill.com/homenews/campaign/4969061-trump-wins-presidential-election/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Useful built-in macOS command-line utilities (538 pts)]]></title>
            <link>https://weiyen.net/articles/useful-macos-cmd-line-utilities</link>
            <guid>42057431</guid>
            <pubDate>Wed, 06 Nov 2024 05:51:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://weiyen.net/articles/useful-macos-cmd-line-utilities">https://weiyen.net/articles/useful-macos-cmd-line-utilities</a>, See on <a href="https://news.ycombinator.com/item?id=42057431">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-mdx-content="true"><article><p>Sometimes when I'm bored, I like to look at the list of <a href="https://ss64.com/mac/">macOS Bash commands</a>. Here's some commands that I found interesting:</p><h2>Access your Keychain programmatically</h2><p>If you store your secrets in the Keychain (and you should!), you can access them programmatically using <code>security</code>.</p><pre><p><span>security find-internet-password </span><span>-s</span><span> </span><span>"https://example.com"</span></p></pre><p>I found this useful for writing automated scripts that used locally-stored credentials.</p><p>Link: <a href="https://ss64.com/mac/security.html">https://ss64.com/mac/security.html</a></p><p>Bonus tip: If you are using 1Password, there is a <a href="https://developer.1password.com/docs/ssh/get-started#install-the-1password-cli">1Password CLI</a> that you can use to access your 1Password items from the command line.</p><h2>Open files from the terminal</h2><p>If you want to open a file from the terminal, you can use the <code>open</code> command.</p><pre><p><span>open</span><span> file.txt</span></p></pre><p>This will open the file in the default application for that file type, as if you had double-clicked it in the Finder.</p><p>Link: <a href="https://ss64.com/mac/open.html">https://ss64.com/mac/open.html</a></p><h2>Copy and paste</h2><p><code>pbcopy</code> and <code>pbpaste</code> are command-line utilities that allow you to copy and paste text to the pasteboard (what other operating systems might call the "clipboard").</p><p><code>pbcopy</code> takes whatever was given in the standard input, and places it in the pasteboard.</p><pre><p><span>echo</span><span> </span><span>"Hello, world!"</span><span> </span><span>|</span><span> pbcopy</span><span>;</span></p></pre><p><code>pbpaste</code> takes whatever is in the pasteboard and prints it to the standard output.</p><pre><p><span>pbpaste</span></p><p><span></span><span>&gt;&gt;</span><span> Hello, world</span><span>!</span></p></pre><p>This is very useful for getting data from files into the browser, or other GUI applications.</p><h4>Links:</h4><ul><li><a href="https://ss64.com/mac/pbcopy.html">https://ss64.com/mac/pbcopy.html</a></li><li><a href="https://ss64.com/mac/pbpaste.html">https://ss64.com/mac/pbpaste.html</a></li></ul><h2>UTC date</h2><p>If you work with servers a lot, it can be useful to know the current time in UTC, when e.g. looking at<!-- --> <!-- -->server logs.</p><p>This is a one-liner in the terminal:</p><pre><p><span>date</span><span> </span><span>-u</span></p></pre><p>Alternatively, you can use</p><pre><p><span>TZ</span><span>=</span><span>UTC </span><span>date</span></p></pre><p>Link: <a href="https://ss64.com/mac/date.html">https://ss64.com/mac/date.html</a></p><h2>Internet speedtest</h2><p>If you want to run an Internet speedtest, you can run one directly from the terminal with</p><pre><p><span>networkQuality  </span></p></pre><p>Link: <a href="https://ss64.com/mac/networkquality.html">https://ss64.com/mac/networkquality.html</a></p><h2>Prevent your Mac from sleeping</h2><p>If you are want to keep your Mac from sleeping, you can run <code>caffeinate</code> in the terminal.</p><pre><p><span>caffeinate</span></p></pre><p><code>caffeinate</code> will keep your Mac awake until you stop it, e.g. by pressing Ctrl+C. <code>caffeinate</code> used to<!-- --> <!-- -->be a third-party tool, but it is now built-in to macOS.</p><p>I use this mostly to prevent my Mac from sleeping when I am running a server.</p><p>Link: <a href="https://ss64.com/mac/caffeinate.html">https://ss64.com/mac/caffeinate.html</a></p><h2>Generate UUIDs</h2><p>If you need to generate a UUID, you can use the <code>uuidgen</code> command.</p><pre><p><span>uuidgen</span></p></pre><p>By default <code>uuidgen</code> outputs a UUID in uppercase. You can combine this with <code>tr</code> and <code>pbcopy</code> to copy the UUID to the clipboard in lowercase.</p><pre><p><span>uuidgen </span><span>|</span><span> </span><span>tr</span><span> </span><span>'[:upper:]'</span><span> </span><span>'[:lower:]'</span><span> </span><span>|</span><span> pbcopy</span></p></pre><p>I use this a lot when writing unit tests that require IDs.</p><p>Link: <a href="https://ss64.com/mac/uuidgen.html">https://ss64.com/mac/uuidgen.html</a></p><h2>Honourable mentions</h2><ul><li><code>mdfind</code>: Spotlight search, but in the terminal. I generally use Spotlight itself (or rather the excellent <a href="https://www.raycast.com/">Raycast</a>). <a href="https://ss64.com/mac/mdfind.html">Link</a></li><li><code>say</code>: This command makes your Mac speak the text you give it. <a href="https://ss64.com/mac/say.html">Link</a></li><li><code>screencapture</code>: This command allows you to take screenshots and save them to a file. I prefer using <code>cmd-shift-5</code> for this. <a href="https://ss64.com/mac/screencapture.html">Link</a></li><li><code>networksetup</code>: This command allows you to configure your network settings programmatically. I found its API very intimidating, and so I haven't really used it much. <a href="https://ss64.com/mac/networksetup.html">Link</a></li></ul></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why the deep learning boom caught almost everyone by surprise (180 pts)]]></title>
            <link>https://www.understandingai.org/p/why-the-deep-learning-boom-caught</link>
            <guid>42057139</guid>
            <pubDate>Wed, 06 Nov 2024 04:05:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.understandingai.org/p/why-the-deep-learning-boom-caught">https://www.understandingai.org/p/why-the-deep-learning-boom-caught</a>, See on <a href="https://news.ycombinator.com/item?id=42057139">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>During my first semester as a computer science graduate student at Princeton, I took </span><a href="https://www.cs.princeton.edu/courses/archive/fall08/cos402/schedule.html" rel="">COS 402: Artificial Intelligence</a><span>. Toward the end of the semester there was a lecture about neural networks. This was in the fall of 2008, and I got the distinct impression—both from that lecture and the textbook—that neural networks had become a backwater.</span></p><p><span>Neural networks had delivered some impressive results in the late 1980s and early 1990s. But then progress stalled. By 2008, many researchers had moved on to mathematically elegant approaches such as </span><a href="https://en.wikipedia.org/wiki/Support_vector_machine" rel="">support vector machines</a><span>.</span></p><p>I didn’t know it at the time, but a team at Princeton—in the same computer science building where I was attending lectures—was working on a project that would upend the conventional wisdom and demonstrate the power of neural networks. That team, led by Prof. Fei-Fei Li, wasn’t working on a better version of neural networks. They were hardly thinking about neural networks at all.</p><p>Rather, they were creating a new image dataset that would be far larger than any that had come before: 14 million images, each labeled with one of nearly 22,000 categories.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg" width="1456" height="966" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:966,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc313065d-0756-4a35-afa2-2718e23103b7_1600x1062.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Fei-Fei Li speaking at a Clinton Global Initiative meeting in September. (Photo by Craig Barritt/Getty Images for Clinton Global Initiative)</figcaption></figure></div><p><span>Li tells the story of ImageNet in her recent memoir, </span><em><a href="https://us.macmillan.com/books/9781250897930/theworldsisee" rel="">The Worlds I See</a></em><span>. As she worked on the project, she faced a lot of skepticism from friends and colleagues.</span></p><p>“I think you’ve taken this idea way too far,” a mentor told her a few months into the project in 2007. “The trick is to grow with your field. Not to leap so far ahead of it.”</p><p>It wasn’t just that building such a large dataset was a massive logistical challenge. People doubted the machine learning algorithms of the day would benefit from such a vast collection of images.</p><p><span>“Pre-ImageNet, people did not believe in data,” </span><a href="https://www.youtube.com/watch?v=JgQ1FJ_wow8" rel="">Li said</a><span> in a September interview at the Computer History Museum. “Everyone was working on completely different paradigms in AI with a tiny bit of data.”</span></p><p>Ignoring negative feedback, Li pursued the project for more than two years. It strained her research budget and the patience of her graduate students. When she took a new job at Stanford in 2009, she took several of those students—and the ImageNet project—with her to California.</p><p>ImageNet received little attention for the first couple of years after its release in 2009. But in 2012, a team from the University of Toronto trained a neural network on the ImageNet dataset, achieving unprecedented performance in image recognition. That groundbreaking AI model, dubbed AlexNet after lead author Alex Krizhevsky, kicked off the deep learning boom that has continued until the present day.</p><p>AlexNet would not have succeeded without the ImageNet dataset. AlexNet also would not have been possible without a platform called CUDA that allowed Nvidia’s graphics processing units (GPUs) to be used in non-graphics applications. Many people were skeptical when Nvidia announced CUDA in 2006.</p><p>So the AI boom of the last 12 years was made possible by three visionaries who pursued unorthodox ideas in the face of widespread criticism. One was Geoffrey Hinton, a University of Toronto computer scientist who spent decades promoting neural networks despite near-universal skepticism. The second was Jensen Huang, the CEO of Nvidia, who recognized early that GPUs could be useful for more than just graphics.</p><p>The third was Fei-Fei Li. She created an image dataset that seemed ludicrously large to most of her colleagues. But it turned out to be essential for demonstrating the potential of neural networks trained on GPUs.</p><p>A neural network is a network of thousands, millions, or even billions of neurons. Each neuron is a mathematical function that produces an output based on a weighted average of its inputs.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png" width="557" height="327" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5155a894-375b-4993-8694-89952cf538f2_557x327.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:327,&quot;width&quot;:557,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5155a894-375b-4993-8694-89952cf538f2_557x327.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Suppose you want to create a network that can identify handwritten decimal digits like the number two in the red square above. Such a network would take in an intensity value for each pixel in an image and output a probability distribution over the ten possible digits—0, 1, 2, and so forth.</p><p>To train such a network, you first initialize it with random weights. Then you run it on a sequence of example images. For each image, you train the network by strengthening the connections that push the network toward the right answer (in this case, a high probability value for the “2” output) and weakening connections that push toward a wrong answer (a low probability for “2” and high probabilities for other digits). If trained on enough example images, the model should start to predict a high probability for “2” when shown a two—and not otherwise.</p><p>In the late 1950s, scientists started to experiment with basic networks that had a single layer of neurons. However, their initial enthusiasm cooled as they realized that such simple networks lacked the expressive power required for complex computations.&nbsp;</p><p>Deeper networks—those with multiple layers—had the potential to be more versatile. But in the 1960s, no one knew how to train them efficiently. This was because changing a parameter somewhere in the middle of a multi-layer network could have complex and unpredictable effects on the output.</p><p>So by the time Hinton began his career in the 1970s, neural networks had fallen out of favor. Hinton wanted to study them, but he struggled to find an academic home to do so. Between 1976 and 1986, Hinton spent time at four different research institutions: Sussex University, the University of California San Diego (UCSD), a branch of the UK Medical Research Council, and finally Carnegie Mellon, where he became a professor in 1982.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg" width="1456" height="1165" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1165,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1eeb101-b3b2-4229-98e7-8bbfdceb9a12_1600x1280.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Geoffrey Hinton speaking in Toronto in June. (Photo by Mert Alper Dervis/Anadolu via Getty Images)</figcaption></figure></div><p><span>In a </span><a href="https://www.nature.com/articles/323533a0" rel="">landmark 1986 paper</a><span>, Hinton teamed up with two of his former colleagues at UCSD, David Rumelhart and Ronald Williams, to describe a technique called </span><a href="https://en.wikipedia.org/wiki/Backpropagation" rel="">backpropagation</a><span> for efficiently training deep neural networks.</span></p><p>Their idea was to start with the final layer of the network and work backwards. For each connection in the final layer, the algorithm computes a gradient—a mathematical estimate of whether increasing the strength of that connection would push the network toward the right answer. Based on these gradients, the algorithm adjusts each parameter in the model’s final layer.</p><p><span>The algorithm then propagates these gradients backwards to the second-to-last layer. A key innovation here is a formula—based on the </span><a href="https://en.wikipedia.org/wiki/Chain_rule" rel="">chain rule</a><span> from high school calculus—for computing the gradients in one layer based on gradients in the following layer. Using these new gradients, the algorithm updates each parameter in the second-to-last layer of the model. Then the gradients get propagated backwards to the third-to-last layer and the whole process repeats once again.</span></p><p>The algorithm only makes small changes to the model in each round of training. But as the process is repeated over thousands, millions, billions, or even trillions of training examples, the model gradually becomes more accurate.</p><p>Hinton and his colleagues weren’t the first to discover the basic idea of backpropagation. But their paper popularized the method. As people realized it was now possible to train deeper networks, it triggered a new wave of enthusiasm for neural networks.</p><p>Hinton moved to the University of Toronto in 1987 and began attracting young researchers who wanted to study neural networks. One of the first was the French computer scientist Yann LeCun, who did a year-long postdoc with Hinton before moving to Bell Labs in 1988.</p><p><span>Hinton’s backpropagation algorithm allowed LeCun to train models deep enough to perform well on real-world tasks like handwriting recognition. By the mid-1990s, LeCun’s technology was working so well that banks </span><a href="https://x.com/ylecun/status/1412545237659029507" rel="">started to use it</a><span> for processing checks.</span></p><p><span>“At one point, LeCun’s creation read more than 10 percent of all checks deposited in the United States,” wrote Cade Metz in his 2022 book </span><em><a href="https://www.penguinrandomhouse.com/books/565698/genius-makers-by-cade-metz/" rel="">Genius Makers</a></em><span>.</span></p><p>But when LeCun and other researchers tried to apply neural networks to larger and more complex images, it didn’t go well. Neural networks once again fell out of fashion, and some researchers who had focused on neural networks moved on to other projects.</p><p>Hinton never stopped believing that neural networks could outperform other machine learning methods. But it would be many years before he’d have access to enough data and computing power to prove his case.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac3c98d-15c7-4b9f-8535-df3b3c83fa48_1600x1066.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Jensen Huang speaking in Denmark in October. (Photo by MADS CLAUS RASMUSSEN/Ritzau Scanpix/AFP via Getty Images)</figcaption></figure></div><p>The brains of every personal computer is a central processing unit (CPU). These chips are designed to perform calculations in order, one step at a time. This works fine for conventional software like Windows and Office. But some video games require so many calculations that they strain the capabilities of CPUs. This is especially true of games like Quake, Call of Duty, and Grand Theft Auto that render three-dimensional worlds many times per second.</p><p>So gamers rely on GPUs to accelerate performance. Inside a GPU are many execution units—essentially tiny CPUs—packaged together on a single chip. During gameplay, different execution units draw different areas of the screen. This parallelism enables better image quality and higher frame rates than would be possible with a CPU alone.</p><p>Nvidia invented the GPU in 1999 and has dominated the market ever since. By the mid-2000s, Nvidia CEO Jensen Huang suspected that the massive computing power inside a GPU would be useful for applications beyond gaming. He hoped scientists could use it for compute-intensive tasks like weather simulation or oil exploration.</p><p>So in 2006, Nvidia announced the CUDA platform. CUDA allows programmers to write “kernels,” short programs designed to run on a single execution unit. Kernels allow a big computing task to be split up into bite-sized chunks that can be processed in parallel. This allows certain kinds of calculations to be completed far faster than with a CPU alone.</p><p><span>But there was little interest in CUDA when it was first introduced, </span><a href="https://www.newyorker.com/magazine/2023/12/04/how-jensen-huangs-nvidia-is-powering-the-ai-revolution" rel="">wrote Steven Witt</a><span> in the New Yorker last year:</span></p><blockquote><p>When CUDA was released, in late 2006, Wall Street reacted with dismay. Huang was bringing supercomputing to the masses, but the masses had shown no indication that they wanted such a thing.</p><p>“They were spending a fortune on this new chip architecture,” Ben Gilbert, the co-host of “Acquired,” a popular Silicon Valley podcast, said. “They were spending many billions targeting an obscure corner of academic and scientific computing, which was not a large market at the time—certainly less than the billions they were pouring in.”</p><p>Huang argued that the simple existence of CUDA would enlarge the supercomputing sector. This view was not widely held, and by the end of 2008 Nvidia’s stock price had declined by seventy per cent…</p><p>Downloads of CUDA hit a peak in 2009, then declined for three years. Board members worried that Nvidia’s depressed stock price would make it a target for corporate raiders.</p></blockquote><p>Huang wasn’t specifically thinking about AI or neural networks when he created the CUDA platform. But it turned out that Hinton’s backpropagation algorithm could easily be split up into bite-sized chunks. And so training neural networks turned out to be a killer app for CUDA.</p><p>According to Witt, Hinton was quick to recognize the potential of CUDA:</p><blockquote><p>In 2009, Hinton’s research group used Nvidia’s CUDA platform to train a neural network to recognize human speech. He was surprised by the quality of the results, which he presented at a conference later that year. He then reached out to Nvidia. “I sent an e-mail saying, ‘Look, I just told a thousand machine-learning researchers they should go and buy Nvidia cards. Can you send me a free one?’ ” Hinton told me. “They said no.”</p></blockquote><p><span>Despite the snub, Hinton and his graduate students, Alex Krizhevsky and Ilya Sutskever, obtained a pair of </span><a href="https://www.techpowerup.com/gpu-specs/geforce-gtx-580.c270" rel="">Nvidia GTX 580 GPUs</a><span> for the AlexNet project. Each GPU had 512 execution units, allowing Krizhevsky and Sutskever to train a neural network hundreds of times faster than would be possible with a CPU. This speed allowed them to train a larger model—and to train it on many more training images. And they would need all that extra computing power to tackle the massive ImageNet dataset.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg" width="1456" height="1003" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1003,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9d73ea7-e2a7-4934-922c-0a660b983023_1600x1102.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Fei-Fei Li at the SXSW conference in 2018. (Photo by Hubert Vestil/Getty Images for SXSW)</figcaption></figure></div><p>Fei-Fei Li wasn’t thinking about either neural networks or GPUs as she began a new job as a computer science professor at Princeton in January of 2007. While earning her PhD at Caltech, she had built a dataset called Caltech 101 that had 9,000 images across 101 categories.</p><p>That experience had taught her that computer vision algorithms tended to perform better with larger and more diverse training datasets. Not only had Li found her own algorithms performed better when trained on Caltech 101, other researchers started training their models using Li’s dataset and comparing their performance to one another. This turned Caltech 101 into a benchmark for the field of computer vision.</p><p><span>So when she got to Princeton, Li decided to go much bigger. She became obsessed with an </span><a href="http://wexler.free.fr/library/files/biederman%20%281987%29%20recognition-by-components.%20a%20theory%20of%20human%20image%20understanding.pdf" rel="">estimate</a><span> by vision scientist Irving Biederman that the average person recognizes roughly 30,000 different kinds of objects. Li started to wonder if it would be possible to build a truly comprehensive image dataset—one that included every kind of object people commonly encounter in the physical world.</span></p><p>A Princeton colleague told Li about WordNet, a massive database that attempted to catalog and organize 140,000 words. Li called her new dataset ImageNet, and she used WordNet as a starting point for choosing categories. She eliminated verbs and adjectives as well as intangible nouns like “truth.” That left a list of 22,000 countable objects, ranging from ambulance to zucchini.</p><p>She planned to take the same approach she’d taken with the Caltech 101 dataset: use Google’s image search to find candidate images, then have a human being verify them. For the Caltech 101 dataset, Li had done this herself over the course of a few months. This time she would need more help. She planned to hire dozens of Princeton undergraduates to help her choose and label images.</p><p>But even after heavily optimizing the labeling process—for example, pre-downloading candidate images so they’re instantly available for students to review—Li and her graduate student, Jia Deng, calculated it would take more than 18 years to select and label millions of images.</p><p>The project was saved when Li learned about Amazon Mechanical Turk, a crowdsourcing platform Amazon had launched a couple of years earlier. Not only was AMT’s international workforce more affordable than Princeton undergraduates, the platform was far more flexible and scalable. Li’s team could hire as many people as they needed, on demand, and pay them only as long as they had work available.</p><p>AMT cut the time needed to complete ImageNet down from 18 to two years. Li writes that her lab spent two years “on the knife-edge of our finances” as they struggled to complete the ImageNet project. But they had enough funds to pay three people to look at each of the 14 million images in the final data set.</p><p>ImageNet was ready for publication in 2009, and Li submitted it to the Conference on Computer Vision and Pattern Recognition, which was held in Miami that year. Their paper was accepted, but it didn’t get the kind of recognition Li hoped for.</p><p>“ImageNet was relegated to a poster session,” Li writes. “This meant that we wouldn’t be presenting our work in a lecture hall to an audience at a predetermined time, but would instead be given space on the conference floor to prop up a large-format print summarizing the project in hopes that passersby might stop and ask questions… After so many years of effort, this just felt anticlimactic.”</p><p>To generate public interest, Li turned ImageNet into a competition. Realizing that the full dataset might be too unwieldy to distribute to dozens of contestants, she created a much smaller (but still massive) dataset with 1,000 categories and 1.4 million images.</p><p>The first year’s competition in 2010 generated a healthy amount of interest, with 11 teams participating. The winning entry was based on support vector machines. Unfortunately, Li writes, it was “only a slight improvement over cutting-edge work found elsewhere in our field.”</p><p>The second year of the ImageNet competition attracted fewer entries than the first. The winning entry in 2011 was another support vector machine, and it just barely improved on the performance of the 2010 winner. Li started to wonder if the critics had been right. Maybe “ImageNet was too much for most algorithms to handle.”</p><p>“For two years running, well-worn algorithms had exhibited only incremental gains in capabilities, while true progress seemed all but absent,” Li writes. “If ImageNet was a bet, it was time to start wondering if we’d lost.”</p><p>But when Li reluctantly staged the competition a third time in 2012, the results were totally different. Geoff Hinton’s team was the first to submit a model based on a deep neural network. And its top-5 accuracy was 85 percent—10 percentage points better than the 2011 winner.</p><p>Li’s initial reaction was incredulity: “Most of us saw the neural network as a dusty artifact encased in glass and protected by velvet ropes.”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg" width="1456" height="996" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:996,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5340e4be-da9e-4722-852e-a733b527153a_1600x1095.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Yann LeCun testifying before a Senate committee in September. (Photo by Kevin Dietsch/Getty Images)</figcaption></figure></div><p>The ImageNet winners were scheduled to be announced at the European Conference on Computer Vision in Florence, Italy. Li, who had a baby at home in California, was planning to skip the event. But when she saw how well AlexNet had done on her dataset, she realized this moment would be too important to miss: “I settled reluctantly on a twenty-hour slog of sleep deprivation and cramped elbow room.”</p><p>On an October day in Florence, Alex Krizhevsky presented his results to a standing-room-only crowd of computer vision researchers. Fei-Fei Li was in the audience. So was Yann LeCun.</p><p>Cade Metz reports that after the presentation, LeCun stood up and called AlexNet “an unequivocal turning point in the history of computer vision. This is proof.”</p><p>The success of AlexNet vindicated Hinton’s faith in neural networks, but it was arguably an even bigger vindication for LeCun.</p><p><span>AlexNet was a convolutional neural network, a type of neural network that LeCun had developed 20 years earlier to recognize handwritten digits on checks. (For more details on how CNNs work, see the </span><a href="https://arstechnica.com/science/2018/12/how-computers-got-shockingly-good-at-recognizing-images/" rel="">in-depth explainer</a><span> I wrote for Ars Technica in 2018.) Indeed, there were few architectural differences between AlexNet and LeCun’s image recognition networks from the 1990s.</span></p><p><span>AlexNet was simply far larger. In a </span><a href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="">1998 paper</a><span>, LeCun described a document recognition network with seven layers and 60,000 trainable parameters. AlexNet had eight layers, but these layers had </span><em>60 million</em><span> trainable parameters.</span></p><p>LeCun could not have trained a model that large in the early 1990s because there were no computer chips with as much processing power as a 2012-era GPU. Even if LeCun had managed to build a big enough supercomputer, he would not have had enough images to train it properly. Collecting those images would have been hugely expensive in the years before Google and Amazon Mechanical Turk.</p><p>And this is why Fei-Fei Li’s work on ImageNet was so consequential. She didn’t invent convolutional networks or figure out how to make them run efficiently on GPUs. But she provided the training data that large neural networks needed to reach their full potential.</p><p><span>The technology world immediately recognized the importance of AlexNet. Hinton and his students formed a shell company with the goal to be “acquihired” by a big tech company. Within months, </span><a href="https://www.wired.com/story/secret-auction-race-ai-supremacy-google-microsoft-baidu/" rel="">Google purchased the company</a><span> for $44 million. Hinton worked at Google for the next decade while retaining his academic post in Toronto. Ilya Sutskever spent a few years at Google before becoming a cofounder of OpenAI.</span></p><p>AlexNet also made Nvidia GPUs the industry standard for training neural networks. In 2012, the market valued Nvidia at less than $10 billion. Today, Nvidia is one of the most valuable companies in the world, with a market capitalization north of $3 trillion. That high valuation is driven mainly by overwhelming demand for GPUs like the H100 that are optimized for training neural networks.</p><p><span>“That moment was pretty symbolic to the world of AI because three fundamental elements of modern AI converged for the first time,”</span><a href="https://youtu.be/JgQ1FJ_wow8?si=DzSpFUhLsPyRt7Nu&amp;t=811" rel=""> Li said</a><span> in a September interview at the Computer History Museum. “The first element was neural networks. The second element was big data, using ImageNet. And the third element was GPU computing.”</span></p><p><span>Today leading AI labs believe the key to progress in AI is to train huge models on vast data sets. Big technology companies are in such a hurry to build the data centers required to train larger models that they’ve started to </span><a href="https://www.npr.org/2024/09/20/nx-s1-5120581/three-mile-island-nuclear-power-plant-microsoft-ai" rel="">lease out entire nuclear power plants</a><span> to provide the necessary power.</span></p><p>You can view this as a straightforward application of the lessons of AlexNet. But I wonder if we ought to draw the opposite lesson from AlexNet: that it’s a mistake to become too wedded to conventional wisdom.</p><p>“Scaling laws” have had a remarkable run in the 12 years since AlexNet, and perhaps we’ll see another generation or two of impressive results as the leading labs scale up their foundation models even more.</p><p>But we should be careful not to let the lessons of AlexNet harden into dogma. I think there’s at least a chance that scaling laws will run out of steam in the next few years. And if that happens, we’re going to need a new generation of stubborn nonconformists to notice that the old approach isn’t working and try something different.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What if your computer beeps each time it sends data to Google? (360 pts)]]></title>
            <link>https://berthub.eu/articles/posts/tracker-beeper/</link>
            <guid>42057036</guid>
            <pubDate>Wed, 06 Nov 2024 03:21:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://berthub.eu/articles/posts/tracker-beeper/">https://berthub.eu/articles/posts/tracker-beeper/</a>, See on <a href="https://news.ycombinator.com/item?id=42057036">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><nav id="main-menu" aria-label="Main Menu">
  
</nav>

      

      <main id="content">


<article>
  

  
  

  <div>
  <p>A week ago, I finally got round to implementing an idea I’d been toying with for years: what if your computer made a little bit of noise every time it sent data to Google?</p>
<p>From studying logs, I’d long known just how many sites send all your visits and clicks to (at least) Google, but a log that you have to manually create first and then analyze is not very dramatic. You need to work on it and finally you think “well yeah that is a lot”.</p>
<center>
<video controls="" width="90%">
    <source src="https://berthub.eu/articles/trackerbeeper.mp4" type="video/mp4">
    Sorry, your browser doesn't support embedded videos.
</video>
</center>
<p>The video above beeps only on Google, and it shows how the <a href="https://werkenvoornederland.nl/">official Dutch government jobs site</a> (which also advertises for the intelligence and security services) sends your every click to Google - despite never asking for your permission to do so. It also reports to Google if you clicked the button “apply for this job”, or even “call us for information”. Nice.</p>
<p>I announced the tool in a tweet:</p>
<p><img loading="lazy" src="https://berthub.eu/articles/beeper-tweet.png"></p>
<p>And within a week, the video received a million views. This spurred me on to add support for Facebook and dozens of the other trackers that infest our sites. Behold the noise when you visit some well known news sites:</p>
<center>
<video controls="" width="90%">
    <source src="https://berthub.eu/articles/trackerbeeper-wow.mp4" type="video/mp4">
    Sorry, your browser doesn't support embedded videos.
</video>
</center>

<ul>
<li><a href="https://www.rtlnieuws.nl/tech/artikel/5329774/google-tracking-klikker-googerteller-bert-hubert-privacy-online">RTLNieuws.nl</a></li>
<li><a href="https://9to5google.com/2022/08/22/app-beeps-send-data-google/">9to5Google</a></li>
<li><a href="https://www.it-daily.net/shortnews/google-teller-browser-plugin-macht-ein-geraeusch-wenn-google-daten-erhaelt">it-daily.net</a></li>
<li><a href="https://stadt-bremerhaven.de/googerteller-app-piept-jedes-mal-wenn-der-rechner-daten-an-google-uebertraegt/">Stadt Bremerhaven</a></li>
<li><a href="https://tarnkappe.info/artikel/datenschutz/googerteller-dem-datenkraken-auf-der-spur-254630.html">Tarnkappe.info</a></li>
</ul>
<h2 id="status-of-the-software">Status of the software</h2>
<p>For now, <a href="https://github.com/berthubert/googerteller">it is still pretty rough stuff</a>, suitable only for Linux, OSX and BSD users comfortable entering command lines. The goals are:</p>
<ol>
<li>Continue development on Linux until the necessary features are implemented and stable</li>
<li>Perhaps simultaneously make an Apple / OSX version available that runs with a single click</li>
<li>Create a Windows version</li>
<li>Perhaps perhaps try to implement something similar on iOS and Android, which will not be easy: phones prefer to snitch on you in full privacy</li>
</ol>
<h2 id="live-demo-installation">Live demo installation</h2>
<p>I would also <strong>love</strong> to turn this into a live demo for use on phones and tablets. The idea would then be to have a low power WiFi network. There’s a big QR code (on a poster or a big screen). If you scan that, your phone asks you if you want to join the demo WiFi.</p>
<p>And when you do and use your phone, big speakers make the tracker noises. For extra points, make one speaker per tracker, so a huge Google speaker, one for Facebook and dozens of smaller ones.</p>
<p>Especially Android phones leak information 24/7 so this should be a pretty convincing demo.</p>
<p>If anyone wants to help make this happen, let me know. All it requires is a Raspberry Pi and another phone to deliver internet connectivity.</p>
<h2 id="further-goals">Further Goals</h2>
<ul>
<li>Support all popular trackers</li>
<li>Configurable which ones you want to hear about</li>
<li>With configurable sounds (also in stereo, so “google” in the middle, “Facebook” on the right speaker)</li>
</ul>

</div>

  



</article>

<nav>
  
</nav>




      </main>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Title drops in movies (397 pts)]]></title>
            <link>https://www.titledrops.net/</link>
            <guid>42056923</guid>
            <pubDate>Wed, 06 Nov 2024 02:48:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.titledrops.net/">https://www.titledrops.net/</a>, See on <a href="https://news.ycombinator.com/item?id=42056923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-svelte-h="svelte-re3d2b">I'm sure you all know the part of the movie where one of the characters says <i>the actual title of the movie</i>
		and you're like
		<img loading="lazy" src="https://www.titledrops.net/img/leonardo_pointing.jpg"></p> <p>The overall meta-ness of this is - of course - nothing new. And filmmakers and scriptwriters
		have been doing it since the dawn of the medium itself<span data-svelte-h="svelte-1lmooii">*</span>. It's known in film speak as a <strong data-svelte-h="svelte-u51ftf">title drop</strong>.</p> <p data-svelte-h="svelte-yuztv1">Consequently, there's tons of examples throughout movie history that range from the iconic (see
		Back to the Future's above)<br> via the eccentric,</p> <p><img loading="lazy" src="https://www.titledrops.net/img/drops/eternal_sunshine_drop.jpg"></p><p data-svelte-h="svelte-3rfu4h">the very much self-aware</p> <p><img loading="lazy" src="https://www.titledrops.net/img/drops/hot_tub_drop.jpg"></p><p data-svelte-h="svelte-1c1pags">to the downright cringe.</p> <p><img loading="lazy" src="https://www.titledrops.net/img/drops/suicide_squad_drop.jpg"></p><p data-svelte-h="svelte-1b81rdb">But how common are these title drops really? Has this phenomenon gained momentum over time with
		our postmodern culture becoming ever more meta? Can we predict anything about the quality of a
		film based on how many times its title is mentioned? And what does a movie title mean, anyway?</p> <p>There have been <a href="https://datanaut.blog/posts/title-drops-in-movies/" target="_blank" data-svelte-h="svelte-6w8ywg">analyses</a>
		and
		<a href="https://www.buzzfeed.com/jeremyhayes1/movie-title-in-the-movie-moments" target="_blank" data-svelte-h="svelte-a9m0z6">oh</a> <a href="https://www.newyorker.com/humor/daily-shouts/the-thirty-greatest-titular-lines-in-movie-history" target="_blank" data-svelte-h="svelte-10ewxdq">so</a> <a href="https://www.watchmojo.com/articles/top-10-movie-title-name-drops#:~:text=%231%3A%20%E2%80%9CBack%20to%20the%20Future%E2%80%9D%20(1985)&amp;text=It%20would%20top%20this%20podium,%2Ddrops%20go%2C%20it's%20exemplary!" target="_blank" data-svelte-h="svelte-125zz3k">so</a> <a href="https://screenrant.com/worst-title-drops-movies-reddit/" target="_blank" data-svelte-h="svelte-143sq03">many</a> <a href="https://www.gamesradar.com/50-greatest-movie-title-drops/" target="_blank" data-svelte-h="svelte-1ozhrnj">listicles</a>
		of the title drop phenomenon before, but they are small and anecdotal. Here's the first extensive
		analysis of title drops for a dataset of <strong data-svelte-h="svelte-1b0xmtx">73,921 movies</strong> that amount to
		<strong data-svelte-h="svelte-1r2vhv">roughly 61% of movies on IMDb</strong> with at least 100 user votes<span data-svelte-h="svelte-1lmooii">*</span>. I'm looking at <strong data-svelte-h="svelte-1dmwuha">movies released between 1940 and 2023</strong>.
		<img loading="lazy" src="https://www.titledrops.net/img/charts/movie_histogram.svg"> Special thanks go to my friends at
		<a href="https://opensubtitles.com/" target="_blank" data-svelte-h="svelte-6ld4nw">OpenSubtitles.com</a> for providing this data!</p> <h3>Let's talk data</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><p data-svelte-h="svelte-1b16of4">I started out with two datasets: 89,242 (English) movie subtitles from <a href="https://opensubtitles.com/" target="_blank">OpenSubtitles.com</a>
		and metadata for 121,797 movies from
		<a href="https://developer.imdb.com/non-commercial-datasets/" target="_blank">IMDb</a>. After
		joining them and filtering them for broken subtitle files I was left with a total of 73,921
		subtitled movies. With that out of the way, I realized that the tougher task was still ahead of
		me: answering the question what even <em>was</em> a title drop?</p> <p>The naïve approach is - of course - to simply look for the movie's name anywhere in the
		subtitles. Which is a fantastic approach for movies like <a href="https://imdb.com/title/tt0088763" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">Back to the Future</a> with a nice unique title:</p>  <p>But this quickly breaks down if we look at movies like <a href="https://imdb.com/title/tt0910869" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">E</a> or <a href="https://imdb.com/title/tt2302966" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">I</a> <span data-svelte-h="svelte-1lmooii">*</span>, which lead to way too many matches.</p> <p data-svelte-h="svelte-1cgcrje">We also run into problems with every movie that is a sequel (Rocky III, Hot Tub Time Machine 2)
		since none of the characters will add the sequel number to character names/oversized bathing
		equipment. Similarly, the <a href="https://www.thewrap.com/2016-movie-titles-colon-record-captain-america-rogue-one/" target="_blank">rise of the colon</a>
		in movie titles would make for some very awkward dialogue (LUKE: "Gosh Mr. Kenobi, it's almost like
		we're in the middle of some <i>Star Wars Episode Four: A New Hope</i>!").
		<img loading="lazy" src="https://www.titledrops.net/img/dead_poets_fake.jpeg">
		(See also the
		<a href="https://knowyourmeme.com/memes/he-didnt-say-that-movie-titles-in-movie-lines" target="_blank">He Didn't Say That</a>
		meme.)</p> <p>So I applied a few rules to my title matching in the dialogue. Leading 'The', 'An' and 'A's and
		special characters like dashes are ignored, sequel numbers both Arabic and Roman are dropped
		(along with 'Episode...', 'Part...' etc.) and titles containing a colon are split and either
		side counts as a title drop. So for <a href="https://imdb.com/title/tt0120737" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">The Lord of the Rings: The Fellowship of the Ring</a>
		either "Lord of the Rings" or "Fellowship of the Ring" would count as title drops (feel free to hover
		over the visualizations to explore the matches)!</p>  <p data-svelte-h="svelte-1byeszk">With the data cleaning out of the way, let's get down to business!</p> <h3>Stats</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><div data-svelte-h="svelte-jpwz7q"><p>Alright, so here's the number you've all been waiting for (drumroll):
		</p><p> <strong>36.5% - so about a third - of movies have at least one title drop during their runtime.</strong></p><p>
		Also, there's a total of 277,668 title drops for all 26,965 title-dropping movies which means that
		there's an
		<strong>average of 10.3 title drops per movie that title drops</strong>. If they do it, they
		really go for it.</p></div> <p>So who are the most excessive offenders in mentioning their titles over the course of the film?
		The overall star when it comes to fiction only came out last year: it's <a href="https://imdb.com/title/tt1517268" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">Barbie</a> by Greta Gerwig with an impressive
		<strong data-svelte-h="svelte-14d7fe0">267 title drops within its 1 hour and 54 minutes runtime</strong>, clocking in at a
		whopping <strong data-svelte-h="svelte-dufrow">2.34 BPM (Barbies Per Minute)</strong>.</p> <p>On the non-fiction side of documentaries the winner is <a href="https://imdb.com/title/tt11178402" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">Mickey: The Story of a Mouse</a>
		with <strong data-svelte-h="svelte-1rvxecz">309 title drops in only 90 minutes</strong>, so
		<strong data-svelte-h="svelte-covmcq">3.43 Mickeys Per Minute</strong>!</p> <div><h4>Top ten number of title drops in one movie</h4> <p><img src="https://www.titledrops.net/img/deco/scribble-wavy.svg"> </p></div> <div><p data-svelte-h="svelte-1b6n1rq">Fiction only</p>   <p data-svelte-h="svelte-1teau28">Fiction + Documentaries</p></div>  <p data-svelte-h="svelte-t9zag4">What's interesting about the (Fiction) list here is that it's pretty international: only two of
		the top ten movies come from Hollywood, 6 are from India, one from Indonesia and one from
		Turkey. So it's definitely an international phenomenon.</p> <h3>Names in titles</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><p>Looking at the top ten list you might have noticed this little icon <img src="https://www.titledrops.net/img/person-circle-outline-svgrepo-com.svg">
		signifying a movie where the data says it's named after one of its characters<span data-svelte-h="svelte-1lmooii">*</span>.</p> <p data-svelte-h="svelte-1sdzjv0">Unsurprisingly, movies named after one of their characters have <strong>an average of 24.7 title drops</strong>, more than twice as much as the usual 10.3. Protagonists have a tendency to pop up repeatedly
		in a film, so their names usually do the same.
		<br>
		Similarly, movies named after a protagonist have a <strong>title drop rate of 88.5%</strong>
		while only 34.2% of other movies drop their titles.
		<img loading="lazy" src="https://www.titledrops.net/img/charts/named_vs_unnamed.svg"></p> <details><summary data-svelte-h="svelte-qu4307">A note on the data here</summary> <hr>
			This is the more experimental part of the analysis. To figure out if a movie was named after its
			protagonist I've used
			<a href="https://datasets.imdbws.com/" target="_blank" data-svelte-h="svelte-xvznn2">IMDb's Principals Dataset</a>
			that lists character names for the first couple of actors and compared that to the movie's title.<br>
			This approach yields reliable results, but of course misses movies when the character the movie
			is named after does not appear on that list. So you might find movies that miss the
			<img loading="lazy" src="https://www.titledrops.net/img/person-circle-outline-svgrepo-com.svg"> 'Named'
			icon even though they're clearly named after a character.

			<p>

			Special characters in the title and character name are also challenging: for example, <a href="https://imdb.com/title/tt0253828" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">Tosun Pasa</a> which actually has a ş character in its title - wrong on IMDb (Pasa) as well as the subtitles
			(Pasha) - or <a href="https://imdb.com/title/tt0910970" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">WALL·E</a> with the challenging · in the middle: Even
			though there are mentions of "Wall-E" in the subtitles, the script - looking for "WALL·E" - wouldn't
			detect it. (I've fixed both of these films manually - but there might be more!)

			</p><p>
			Titles or surnames also usually prevent being counted as title drops according to our definitions.
			<a href="https://imdb.com/title/tt0066078" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">Michael The Brave</a>,
			<a href="https://imdb.com/title/tt0064553" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">King Lear</a> or <a href="https://imdb.com/title/tt0072684" target="_blank"><img src="https://www.titledrops.net/img/film-strip-fill.svg">Barry Lyndon</a> might mention a character's name ('Michael', 'Lear', 'Barry') but leave out the title or surname
			- so zero drops.

			</p><p>
			Nevertheless, there do exist named films where you would expect a title drop which doesn't come!
			Examples are:
			</p>

			Anyway - back to the analysis!
			<hr></details> <p data-svelte-h="svelte-1yzg0zi">An interesting category are movies named after a character that only have a single title drop -
		making it all the more meaningful?</p> <div><h4>Movies named after a character with single title drops</h4> <p><img src="https://www.titledrops.net/img/deco/scribble-wavy.svg"> </p></div>  <h3>"Real" title drops</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><p data-svelte-h="svelte-1h25k9n">Title-drop connoisseurs might sneer at this point and well-actually us that a "real" title drop
		should only happen once in a film. That there's this one memorable (or cringe-y) scene where the
		protagonist looks directly at the camera and declares the title of the film with as much pathos
		as they can muster. Or as a nice send-off in the last spoken line.</p> <p><img loading="lazy" src="https://www.titledrops.net/img/little_women_moe_side_by_side.jpg"></p><div data-svelte-h="svelte-1uojp5d"><p>Such single drops happen surprisingly often:<br> <strong>11.3% of all movies do EXACTLY ONE title drop during their runtime.</strong></p><p>
		Which means that there's about twice as many movies having multiple title drops than single ones.</p></div> <p><img loading="lazy" src="https://www.titledrops.net/img/charts/count_percentage.svg"></p><p data-svelte-h="svelte-hkq436">In the single drop case it is more likely that the filmmakers were adding a title drop very
		consciously.</p> <div><h4>Highest rated single drop movies</h4> <p><img src="https://www.titledrops.net/img/deco/scribble-wavy.svg"> </p></div> <div><p data-svelte-h="svelte-1b6n1rq">Fiction only</p>   <p data-svelte-h="svelte-1teau28">Fiction + Documentaries</p></div>  <p data-svelte-h="svelte-1t9sgt8">Single drops often happen in a key scene and explain the movie's title: what mysterious
		fellowship the first Lord of the Rings is named after. Or that the audience waiting for some
		dark knight to show up must simply accept that it's been the Batman all along.</p> <h3>Title drops over the years</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><p data-svelte-h="svelte-uw6c0s">One suspicion I had was that the very meta act of having a character speak the name of the movie
		they're in would be something gaining more and more traction over the last two or three decades.</p> <p data-svelte-h="svelte-5yxcef">And indeed, if we look at the average number of movies with title drops over the decades we can
		see that there's a certain upwards trend. The 1960s and 1970s seemed to be most averse to
		mentioning their title in the film, while it's become more common-place over the last years.

		<img loading="lazy" src="https://www.titledrops.net/img/charts/deviation_by_decade.svg"></p> <div><h4>Highest title drops by decade</h4> <p><img src="https://www.titledrops.net/img/deco/scribble-wavy.svg"> </p></div>  <div><p data-svelte-h="svelte-zrarij">Most drops</p>   <p data-svelte-h="svelte-1lsvmm9">Best rated (at least 1 drop)</p></div>  <p data-svelte-h="svelte-1o5djl7">If we dig deeper, this growth over the decades comes with a clearer explanation: splitting up
		movies by single- and multi-title drops shows that while the tendency of movies to drop their
		title exactly once keeps more or less steady, the number of multi-drop films is on the rise.</p> <p><img loading="lazy" src="https://www.titledrops.net/img/charts/decs_single_vs_multi.svg"></p><p data-svelte-h="svelte-xxse9f">Your explanation for this (More movies are being named after their protagonists? Movies are more
		productified so brand recognition becomes an important concern?) is probably as good as mine 🤷</p> <h3>A sign of quality?</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><p data-svelte-h="svelte-zyvhke">Another question I wanted to answer was if a high number of title drops was a sign of a bad
		movie. Think of all the trashy slasher and horror movies about Meth Marmots and Killer
		Ballerinas - wouldn't their characters in the sparse dialogues constantly mention the title for
		brand recognition and all that?</p> <p><img loading="lazy" src="https://www.titledrops.net/img/charts/rating_vs_drops.svg"></p><p data-svelte-h="svelte-btkys1">Interestingly though, there's no strong connection between film quality (expressed as IMDb
		rating (YMMV)) and the probability of title-dropping.</p> <h3>Genres and title drops</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><p data-svelte-h="svelte-5mtp2k">An aspect that certainly <em>does</em> have an impact on the probability of a title drop though is
		the genre of a film.</p> <p data-svelte-h="svelte-12p4e2m">If you think back to the discussion about names in titles from earlier, genres like Biography
		and other non-fiction genres like Sport and History - almost by definition - mention their
		subject in both the title and throughout the film.</p> <p data-svelte-h="svelte-z5f9mt">Accordingly, the probability of a title drop varies wildly by genre. Non-fiction films have a
		strong tendency towards title-dropping, while more fiction-oriented genres like Crime, Romance
		and War don't.</p> <p data-svelte-h="svelte-89tmax"><img loading="lazy" src="https://www.titledrops.net/img/charts/deviation_by_genre_styled_anno.svg"></p> <h3>What does a movie title mean?</h3> <p><img src="https://www.titledrops.net/img/deco/scribble-scratchy.svg"></p><p data-svelte-h="svelte-xmexhq">Finally, we can ask the question: what even <em>is</em> a movie title?
		</p> <p data-svelte-h="svelte-xsiy58">I couldn't find a complete classification in the scientific literature (<a href="https://www.tandfonline.com/doi/abs/10.1080/02666286.2015.1053037" target="_blank">"What's in a name? The art of movie titling"</a>
		by Ingrid Haidegger comes the closest). Movie titles are an interesting case, since they have to
		work as a description of a product, a marketing instrument, but also as the title of a piece of art.<br>
		Consequently, it's a field ripe with
		<a href="https://www.michigandaily.com/arts/film/good-movie-titles-or-how-i-learned-to-stop-worrying-and-love-the-overly-complex-naming-scheme/" target="_blank">opinions</a>,
		<a href="https://variety.com/2023/film/features/how-are-movie-titles-decided-hollywood-1235554998/" target="_blank">science and experimentation</a>
		and
		<a href="https://www.cleveland.com/movies/2017/10/50_coolest_movie_titles_ever.html" target="_blank">listicles</a>.</p> <p data-svelte-h="svelte-qw1d0v">The most extensive classification of media titles in general I could find is
		<a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/TitleTropes" target="_blank">TVTropes' Title Tropes list</a>
		which lists over 180 (!) different types of tropes alone. Some of those tropes are:</p>  <p data-svelte-h="svelte-1dt3wh9">While naming a movie is a very creative task and pretty successfully defies classification, we
		can still look at the overall shape of movie titles and see if that has any impact on the number
		of title drops.</p> <p>One such simple aspect is the length of the title itself. As you would expect there's a negative
		correlation (if only a slight one<span data-svelte-h="svelte-1lmooii">*</span>)
		between the length of a title and the number of title drops it does.
		<img loading="lazy" src="https://www.titledrops.net/img/charts/title_length.svg"></p> <p data-svelte-h="svelte-10d3gzs">Still, there are some fun examples for <em>reaaaaally</em>
		long movie titles that nevertheless do at least one title drop:</p>  <p data-svelte-h="svelte-1l1h6zn">And while these previous examples only drops parts from before or after the colon, this next
		specimen actually does an impressive full title drop:</p>  <p><img loading="lazy" src="https://www.titledrops.net/img/deco/scribble1.svg"></p><p data-svelte-h="svelte-vvmi2w">And with that, we're done with the overarching analysis! Feel free to drop us an <a href="mailto:do@minik.us" target="_blank">e-mail</a>
		or follow up on <a href="https://twitter.com/dominikus" target="_blank">X</a>/<a href="https://twitter.com/al_ice_t" target="_blank">X</a>,
		<a href="https://bsky.app/profile/do.minik.us" target="_blank">Bluesky</a>
		or
		<a href="https://vis.social/@dominikus" target="_blank">Mastodon</a>

		if you have comments, questions, praise ❤️</p> <p data-svelte-h="svelte-4xjs5i">Oh, and one more thing:<br>
		If you're curious, here's the full dataset for you to explore!</p> <div><h4>Explore all movies!</h4> <p><img src="https://www.titledrops.net/img/deco/scribble-wavy.svg"> </p></div>  <p data-svelte-h="svelte-aoox60">Analysis + development by <a href="https://do.minik.us/" target="_blank">Dominikus Baur</a><br>
		Design by <a href="https://www.alicethudt.de/" target="_blank">Alice Thudt</a><br></p> <p data-svelte-h="svelte-sqhboi">Datasets provided by <a href="https://opensubtitles.com/" target="_blank">OpenSubtitles.com</a>
		and
		<a href="https://developer.imdb.com/non-commercial-datasets/" target="_blank">IMDb</a>.</p> <p data-svelte-h="svelte-p8xh42">Data: <a href="https://github.com/dominikus/titledrops.net" target="_blank">https://github.com/dominikus/titledrops.net</a></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[98.css – A design system for building faithful recreations of old UIs (277 pts)]]></title>
            <link>https://jdan.github.io/98.css/</link>
            <guid>42056918</guid>
            <pubDate>Wed, 06 Nov 2024 02:46:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jdan.github.io/98.css/">https://jdan.github.io/98.css/</a>, See on <a href="https://news.ycombinator.com/item?id=42056918">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <hr>
    <p>A design system for building faithful recreations of old UIs.</p>

    <p>
      <a href="http://npm.im/98.css" rel="nofollow">
        <img alt="npm" src="https://98badges.now.sh/api/version">
      </a>
      <a href="https://unpkg.com/98.css" rel="nofollow">
        <img alt="gzip size" src="https://98badges.now.sh/api/size">
      </a>
    </p>

    <h2 id="intro">Intro</h2>
    <p>
      98.css is a CSS library for building interfaces that look like Windows 98.
      See more <a href="https://github.com/jdan/98.css">on GitHub</a>.
    </p>

    

    <p>
      This library relies on the usage of <strong>semantic HTML</strong>. To make a button, you'll need
      to use a <code>&lt;button&gt;</code>. Input elements require labels. Icon buttons rely on
      <code>aria-label</code>. This page will guide you through that process, but accessibility is a primary
      goal of this project.
    </p>

    <p>
      You can override many of the styles of your elements while maintaining the appearance provided by
      this library. Need more padding on your buttons? Go for it. Need to add some color to your input labels?
      Be our guest.
    </p>

    <p>
      <strong>This library does not contain any JavaScript</strong>, it merely styles your HTML with some CSS.
      This means 98.css is compatible with your frontend framework of choice.
    </p>

    <p>
      Here is an example of <a href="https://codesandbox.io/s/objective-chandrasekhar-t5t6h?file=/src/index.js">98.css used with React</a>, and
      <a href="https://codesandbox.io/s/late-sound-miqho?file=/index.html">an example with vanilla JavaScript</a>. The fastest way to use 98.css is to import it from unpkg.
    </p>

    <pre><code>&lt;link
  rel="stylesheet"
  href="https://unpkg.com/98.css"
&gt;</code></pre>

    <p>
      You can install 98.css from the <a href="https://github.com/jdan/98.css/releases">GitHub releases page</a>, or <a href="https://www.npmjs.com/package/98.css">from npm</a>.
    </p>
    <pre><code>npm install 98.css</code></pre>

    <h2 id="components">Components</h2>

    <section>
      <h3 id="button">Button</h3>
      <div>
        <blockquote>
          A <em>command button</em>, also referred to as a push button, is a control
          that causes the application to perform some action when the user clicks it.

          
        </blockquote>

        <p>
          A standard button measures 75px wide and 23px tall, with a raised outer and inner border.
          They are given 12px of horizontal padding by default.
        </p>

        <div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>button</span>&gt;</span>Click me<span>&lt;/<span>button</span>&gt;</span>
<span>&lt;<span>input</span> <span>type</span>=<span>"submit"</span> /&gt;</span>
<span>&lt;<span>input</span> <span>type</span>=<span>"reset"</span> /&gt;</span></code></pre>
      </details>
    </div>

        <p>
          When buttons are clicked, the raised borders become sunken.
          The following button is simulated to be in the pressed (active) state.
        </p>

        
        <div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>button</span>&gt;</span>I am being pressed<span>&lt;/<span>button</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          Disabled buttons maintain the same raised border, but have a "washed out"
          appearance in their label.
        </p>

        <div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>button</span> <span>disabled</span>&gt;</span>I cannot be clicked<span>&lt;/<span>button</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          Button focus is communicated with a dotted border, set 4px within the contents of the button.
          The following example is simulated to be focused.
        </p>

        <div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>button</span>&gt;</span>I am focused<span>&lt;/<span>button</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h3 id="checkbox">Checkbox</h3>
      <div>
        <blockquote>
          A <em>check box</em> represents an independent or non-exclusive choice.
          
        </blockquote>

        <p>
          Checkboxes are represented with a sunken panel, populated with a "check" icon when
          selected, next to a label indicating the choice.
        </p>

        <p>
          Note: You <strong>must</strong> include a corresponding label <strong>after</strong>
          your checkbox, using the <code>&lt;label&gt;</code> element with a <code>for</code> attribute
          pointed at the <code>id</code> of your input. This ensures the checkbox is easy to use with
          assistive technologies, on top of ensuring a good user experience for all (navigating with the tab key,
          being able to click the entire label to select the box).
        </p>

        <div>
      <p>
<label for="example1">This is a checkbox</label></p><details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>input</span> <span>type</span>=<span>"checkbox"</span> <span>id</span>=<span>"example1"</span>&gt;</span>
<span>&lt;<span>label</span> <span>for</span>=<span>"example1"</span>&gt;</span>This is a checkbox<span>&lt;/<span>label</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          Checkboxes can be selected and disabled with the standard <code>checked</code> and <code>disabled</code>
          attributes.
        </p>

        <p>
          When grouping inputs, wrap each input in a container with the <code>field-row</code> class. This ensures
          a consistent spacing between inputs.
        </p>

        <div>
      <p>
  <label for="example2">I am checked</label>
</p>
<p>
  <label for="example3">I am inactive</label>
</p>
<p>
  <label for="example4">I am inactive but still checked</label>
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>checked</span> <span>type</span>=<span>"checkbox"</span> <span>id</span>=<span>"example2"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"example2"</span>&gt;</span>I am checked<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>disabled</span> <span>type</span>=<span>"checkbox"</span> <span>id</span>=<span>"example3"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"example3"</span>&gt;</span>I am inactive<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>checked</span> <span>disabled</span> <span>type</span>=<span>"checkbox"</span> <span>id</span>=<span>"example4"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"example4"</span>&gt;</span>I am inactive but still checked<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h3 id="option-button">OptionButton</h3>
      <div>
        <blockquote>
          An <em>option button</em>, also referred to as a radio button, represents a single
          choice within a limited set of mutually exclusive choices. That is, the user can choose only
          one set of options.

          
        </blockquote>

        <p>
          Option buttons can be used via the <code>radio</code> type on an input element.
        </p>

        <p>
          Option buttons can be grouped by specifying a shared <code>name</code> attribute on each
          input. Just as before: when grouping inputs, wrap each input in a container with the
          <code>field-row</code> class to ensure a consistent spacing between inputs.
        </p>

        <div>
      <p>
  <label for="radio5">Yes</label>
</p>
<p>
  <label for="radio6">No</label>
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"radio5"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"first-example"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"radio5"</span>&gt;</span>Yes<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"radio6"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"first-example"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"radio6"</span>&gt;</span>No<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          Option buttons can also be <code>checked</code> and <code>disabled</code> with their corresponding
          HTML attributes.
        </p>

        <div>
      <p>
  <label for="radio7">Peanut butter should be smooth</label>
</p>
<p>
  <label for="radio8">I understand why people like crunchy peanut butter</label>
</p>
<p>
  <label for="radio9">Crunchy peanut butter is good</label>
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"radio7"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"second-example"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"radio7"</span>&gt;</span>Peanut butter should be smooth<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>checked</span> <span>disabled</span> <span>id</span>=<span>"radio8"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"second-example"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"radio8"</span>&gt;</span>I understand why people like crunchy peanut butter<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>input</span> <span>disabled</span> <span>id</span>=<span>"radio9"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"second-example"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"radio9"</span>&gt;</span>Crunchy peanut butter is good<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h3 id="group-box">GroupBox</h3>
      <div>
        <blockquote>
          A <em>group box</em> is a special control you can use to organize a set of
          controls. A group box is a rectangular frame with an optional label that surrounds
          a set of controls.

          
        </blockquote>

        <p>
          A group box can be used by wrapping your elements with the <code>fieldset</code> tag.
          It contains a sunken outer border and a raised inner border, resembling an engraved box
          around your controls.
        </p>

        <div>
      
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>fieldset</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>Select one:<span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"radio10"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"fieldset-example"</span>&gt;</span>
    <span>&lt;<span>label</span> <span>for</span>=<span>"radio10"</span>&gt;</span>Diners<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"radio11"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"fieldset-example"</span>&gt;</span>
    <span>&lt;<span>label</span> <span>for</span>=<span>"radio11"</span>&gt;</span>Drive-Ins<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"radio12"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"fieldset-example"</span>&gt;</span>
    <span>&lt;<span>label</span> <span>for</span>=<span>"radio12"</span>&gt;</span>Dives<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>fieldset</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          You can provide your group with a label by placing a <code>legend</code> element
          within the <code>fieldset</code>.
        </p>

        <div>
      
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>fieldset</span>&gt;</span>
  <span>&lt;<span>legend</span>&gt;</span>Today's mood<span>&lt;/<span>legend</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"radio13"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"fieldset-example2"</span>&gt;</span>
    <span>&lt;<span>label</span> <span>for</span>=<span>"radio13"</span>&gt;</span>Claire Saffitz<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"radio14"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"fieldset-example2"</span>&gt;</span>
    <span>&lt;<span>label</span> <span>for</span>=<span>"radio14"</span>&gt;</span>Brad Leone<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"radio15"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"fieldset-example2"</span>&gt;</span>
    <span>&lt;<span>label</span> <span>for</span>=<span>"radio15"</span>&gt;</span>Chris Morocco<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"radio16"</span> <span>type</span>=<span>"radio"</span> <span>name</span>=<span>"fieldset-example2"</span>&gt;</span>
    <span>&lt;<span>label</span> <span>for</span>=<span>"radio16"</span>&gt;</span>Carla Lalli Music<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>fieldset</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h3 id="text-box">TextBox</h3>
      <div>
        <blockquote>
          A <em>text box</em> (also referred to as an edit control) is a
          rectangular control where the user enters or edits text. It can
          be defined to support a single line or multiple lines of text.

          
        </blockquote>

        <p>
          Text boxes can rendered by specifying a <code>text</code> type on an
          <code>input</code> element. As with checkboxes and radio buttons, you
          should provide a corresponding label with a properly set <code>for</code>
          attribute, and wrap both in a container with the <code>field-row</code> class.
        </p>

        <div>
      <p><label for="text17">Occupation</label>
  
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text17"</span>&gt;</span>Occupation<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"text17"</span> <span>type</span>=<span>"text"</span> /&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          Additionally, you can make use of the <code>field-row-stacked</code> class
          to position your label above the input instead of beside it.
        </p>

        <div>
      <p><label for="text18">Address (Line 1)</label>
  
</p>
<p><label for="text19">Address (Line 2)</label>
  
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row-stacked"</span> <span>style</span>=<span>"width: 200px"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text18"</span>&gt;</span>Address (Line 1)<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"text18"</span> <span>type</span>=<span>"text"</span> /&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row-stacked"</span> <span>style</span>=<span>"width: 200px"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text19"</span>&gt;</span>Address (Line 2)<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"text19"</span> <span>type</span>=<span>"text"</span> /&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          To support multiple lines in the user's input, use the <code>textarea</code>
          element instead.
        </p>

        <div>
      <p><label for="text20">Additional notes</label>
  
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row-stacked"</span> <span>style</span>=<span>"width: 200px"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text20"</span>&gt;</span>Additional notes<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>textarea</span> <span>id</span>=<span>"text20"</span> <span>rows</span>=<span>"8"</span>&gt;</span><span>&lt;/<span>textarea</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          Text boxes can also be disabled and have value with their corresponding HTML attributes.
        </p>

        <div>
      <p><label for="text21">Favorite color</label>
  
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text21"</span>&gt;</span>Favorite color<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"text21"</span> <span>disabled</span> <span>type</span>=<span>"text"</span> <span>value</span>=<span>"Windows Green"</span>/&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          Other types of HTML5 text inputs are also supported.
        </p>

        <div>
      <p><label for="text22">Email</label>
  
</p>
<p><label for="text23">Password</label>
  
</p>
<p><label for="text24">Favorite Number</label>
  
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row-stacked"</span> <span>style</span>=<span>"width: 200px"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text22"</span>&gt;</span>Email<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"text22"</span> <span>type</span>=<span>"email"</span> <span>value</span>=<span>"admin@contoso.com"</span>/&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row-stacked"</span> <span>style</span>=<span>"width: 200px"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text23"</span>&gt;</span>Password<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"text23"</span> <span>type</span>=<span>"password"</span> <span>value</span>=<span>"hunter2"</span>/&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>class</span>=<span>"field-row-stacked"</span> <span>style</span>=<span>"width: 200px"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"text24"</span>&gt;</span>Favorite Number<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"text24"</span> <span>type</span>=<span>"number"</span> <span>value</span>=<span>"98"</span>/&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

      </div>


    </section>

    <section>
      <h3 id="slider">Slider</h3>
      <div>
        <blockquote>
          A <em>slider</em>, sometimes called a trackbar control, consists of a bar that
          defines the extent or range of the adjustment and an indicator that
          shows the current value for the control...

          
        </blockquote>

        <p>
          Sliders can rendered by specifying a <code>range</code> type on an
          <code>input</code> element.
        </p>

        <div>
      <p><label for="range25">Volume:</label>
  <label for="range26">Low</label>
  
  <label for="range27">High</label>
</p>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span> <span>style</span>=<span>"width: 300px"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"range25"</span>&gt;</span>Volume:<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"range26"</span>&gt;</span>Low<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"range26"</span> <span>type</span>=<span>"range"</span> <span>min</span>=<span>"1"</span> <span>max</span>=<span>"11"</span> <span>value</span>=<span>"5"</span> /&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"range27"</span>&gt;</span>High<span>&lt;/<span>label</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          You can make use of the <code>has-box-indicator</code> class replace the
          default indicator with a box indicator, furthermore the slider can be wrapped
          with a <code>div</code> using <code>is-vertical</code> to display the input vertically.
        </p>

        <p>
          Note: To change the length of a vertical slider, the <code>input</code> width
          and <code>div</code> height.
        </p>

        <div>
      
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"field-row"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"range28"</span>&gt;</span>Cowbell<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"is-vertical"</span>&gt;</span>
    <span>&lt;<span>input</span> <span>id</span>=<span>"range28"</span> <span>class</span>=<span>"has-box-indicator"</span> <span>type</span>=<span>"range"</span> <span>min</span>=<span>"1"</span> <span>max</span>=<span>"3"</span> <span>step</span>=<span>"1"</span> <span>value</span>=<span>"2"</span> /&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h3 id="dropdown">Dropdown</h3>
      <div>
        <blockquote>
          A <em>drop-down list box</em> allows the selection of only a
          single item from a list. In its closed state, the control displays
          the current value for the control. The user opens the list to change
          the value.

          
        </blockquote>

        <p>
          Dropdowns can be rendered by using the <code>select</code> and <code>option</code>
          elements.
        </p>

        <div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>select</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>5 - Incredible!<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>4 - Great!<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>3 - Pretty good<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>2 - Not so great<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>1 - Unfortunate<span>&lt;/<span>option</span>&gt;</span>
<span>&lt;/<span>select</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          By default, the first option will be selected. You can change this by
          giving one of your <code>option</code> elements the <code>selected</code>
          attribute.
        </p>

        <div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>select</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>5 - Incredible!<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>4 - Great!<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>selected</span>&gt;</span>3 - Pretty good<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>2 - Not so great<span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span>&gt;</span>1 - Unfortunate<span>&lt;/<span>option</span>&gt;</span>
<span>&lt;/<span>select</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <h3 id="window">Window</h3>
    <p>
      The following components illustrate how to build complete windows using
      98.css.
    </p>

    <section>
      <h4 id="title-bar">Title Bar</h4>
      <div>
        <blockquote>
          At the top edge of the window, inside its border, is the title bar
          (also reffered to as the caption or caption bar), which extends across
          the width of the window. The title bar identifies the contents of the
          window.

          
        </blockquote>

        <blockquote>
          Include command buttons associated with the common commands of the
          primary window in the title bar. These buttons act as shortcuts to specific
          window commands.

          
        </blockquote>

        <p>
          You can build a complete title bar by making use of three classes,
          <code>title-bar</code>, <code>title-bar-text</code>, and <code>title-bar-controls</code>.
        </p>

        <div>
      
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"title-bar"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>A Title Bar<span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-controls"</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Close"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          We make use of <code>aria-label</code> to render the Close button, to let
          assistive technologies know the intent of this button. You may also use
          "Minimize", "Maximize", "Restore" and "Help" like so:
        </p>

        <div>
      

<br>



<br>


      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"title-bar"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>A Title Bar<span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-controls"</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Minimize"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Maximize"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Close"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>

<span>&lt;<span>br</span> /&gt;</span>

<span>&lt;<span>div</span> <span>class</span>=<span>"title-bar"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>A Maximized Title Bar<span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-controls"</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Minimize"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Restore"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Close"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>

<span>&lt;<span>br</span> /&gt;</span>

<span>&lt;<span>div</span> <span>class</span>=<span>"title-bar"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>A Helpful Bar<span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-controls"</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Help"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Close"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>
		<p>
          You can make a title bar "inactive" by adding <code>inactive</code> class,
		  useful when making more than one window.
        </p>
		 <div>
      
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"title-bar inactive"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>An inactive title bar<span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-controls"</span>&gt;</span>
    <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Close"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h4 id="window-contents">Window contents</h4>
      <div>
        <blockquote>
          Every window has a boundary that defines its shape.

          
        </blockquote>

        <p>
          To give our title bar a home, we make use of the <code>window</code>
          class. This provides a raised outer and inner border, as well as some
          padding. We can freely resize the window by specifying a width in the
          container style.
        </p>

        <div>
      
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"window"</span> <span>style</span>=<span>"width: 300px"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar"</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>A Complete Window<span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-controls"</span>&gt;</span>
      <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Minimize"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
      <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Maximize"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
      <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Close"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          To draw the contents of the window, we use the <code>window-body</code>
          class under the title bar.
        </p>

        <div>
      <div>
  <div>
    <p>A Window With Stuff In It</p>
    
  </div>
  <p>There's so much room for activities!</p>
</div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"window"</span> <span>style</span>=<span>"width: 300px"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar"</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>A Window With Stuff In It<span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-controls"</span>&gt;</span>
      <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Minimize"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
      <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Maximize"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
      <span>&lt;<span>button</span> <span>aria-label</span>=<span>"Close"</span>&gt;</span><span>&lt;/<span>button</span>&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"window-body"</span>&gt;</span>
    <span>&lt;<span>p</span>&gt;</span>There's so much room for activities!<span>&lt;/<span>p</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h4 id="status-bar">Status Bar</h4>
      <div>
        <blockquote>
          A status bar is a special area within a window, typically the bottom, that displays information
          about the current state of what is being viewed in the window or any other contextual information, such as keyboard
          state.

          
        </blockquote>

        <p>
          You can render a status bar with the <code>status-bar</code> class,
          and <code>status-bar-field</code> for every child text element.
        </p>

        <div>
      <div>
  <div>
    <p>A Window With A Status Bar</p>
  </div>
  <div>
<p> There are just so many possibilities:</p>
<ul>
    <li>A Task Manager</li>
    <li>A Notepad</li>
    <li>Or even a File Explorer!</li>
</ul>
  </div>
  <div>
    <p>Press F1 for help</p>
    <p>Slide 1</p>
    <p>CPU Usage: 14%</p>
  </div>
</div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"window"</span> <span>style</span>=<span>"width: 320px"</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar"</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"title-bar-text"</span>&gt;</span>A Window With A Status Bar<span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"window-body"</span>&gt;</span>
<span>&lt;<span>p</span>&gt;</span> There are just so many possibilities:<span>&lt;/<span>p</span>&gt;</span>
<span>&lt;<span>ul</span>&gt;</span>
    <span>&lt;<span>li</span>&gt;</span>A Task Manager<span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span>&gt;</span>A Notepad<span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span>&gt;</span>Or even a File Explorer!<span>&lt;/<span>li</span>&gt;</span>
<span>&lt;/<span>ul</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"status-bar"</span>&gt;</span>
    <span>&lt;<span>p</span> <span>class</span>=<span>"status-bar-field"</span>&gt;</span>Press F1 for help<span>&lt;/<span>p</span>&gt;</span>
    <span>&lt;<span>p</span> <span>class</span>=<span>"status-bar-field"</span>&gt;</span>Slide 1<span>&lt;/<span>p</span>&gt;</span>
    <span>&lt;<span>p</span> <span>class</span>=<span>"status-bar-field"</span>&gt;</span>CPU Usage: 14%<span>&lt;/<span>p</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>


    </div></section>

    <section>
      <h3 id="tree-view">TreeView</h3>
      <div>
        <blockquote>
          A <em>tree view control</em> is a special list box control
          that displays a set of objects as an indented outline based
          on their logical hierarchical relationship.

          
        </blockquote>

        <p>
          To render a tree view, use an <code>ul</code> element with the
          <code>tree-view</code> class. The children of this list (<code>li</code>
          elements), can contain whatever you'd like.
        </p>

        <div>
      <ul>
  <li>We can put</li>
  <li><strong>✨ Whatever ✨</strong></li>
  <li>We want in here</li>
</ul>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>ul</span> <span>class</span>=<span>"tree-view"</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>We can put<span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span><span>&lt;<span>strong</span> <span>style</span>=<span>"color: purple"</span>&gt;</span>✨ Whatever ✨<span>&lt;/<span>strong</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>We want in here<span>&lt;/<span>li</span>&gt;</span>
<span>&lt;/<span>ul</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          To make this a tree, we can nest further <code>ul</code> elements
          (no class needed on these). This will provide them with a nice dotted
          border and indentation to illustrate the structure of the tree.
        </p>
        <p>
          To create expandable sections, wrap child lists inside of
          <code>details</code> elements.
        </p>

        <div>
      <ul>
  <li>Table of Contents</li>
  <li>What is web development?</li>
  <li>
    CSS
    <ul>
      <li>Selectors</li>
      <li>Specificity</li>
      <li>Properties</li>
    </ul>
  </li>
  <li>
    <details open="">
      <summary>JavaScript</summary>
      <ul>
        <li>Avoid at all costs</li>
        <li>
          <details>
            <summary>Unless</summary>
            <ul>
              <li>Avoid</li>
              <li>
                <details>
                  <summary>At</summary>
                  <ul>
                    <li>Avoid</li>
                    <li>At</li>
                    <li>All</li>
                    <li>Cost</li>
                  </ul>
                </details>
              </li>
              <li>All</li>
              <li>Cost</li>
            </ul>
          </details>
        </li>
      </ul>
    </details>
  </li>
  <li>HTML</li>
  <li>Special Thanks</li>
</ul>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>ul</span> <span>class</span>=<span>"tree-view"</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>Table of Contents<span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>What is web development?<span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>
    CSS
    <span>&lt;<span>ul</span>&gt;</span>
      <span>&lt;<span>li</span>&gt;</span>Selectors<span>&lt;/<span>li</span>&gt;</span>
      <span>&lt;<span>li</span>&gt;</span>Specificity<span>&lt;/<span>li</span>&gt;</span>
      <span>&lt;<span>li</span>&gt;</span>Properties<span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;/<span>ul</span>&gt;</span>
  <span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>
    <span>&lt;<span>details</span> <span>open</span>&gt;</span>
      <span>&lt;<span>summary</span>&gt;</span>JavaScript<span>&lt;/<span>summary</span>&gt;</span>
      <span>&lt;<span>ul</span>&gt;</span>
        <span>&lt;<span>li</span>&gt;</span>Avoid at all costs<span>&lt;/<span>li</span>&gt;</span>
        <span>&lt;<span>li</span>&gt;</span>
          <span>&lt;<span>details</span>&gt;</span>
            <span>&lt;<span>summary</span>&gt;</span>Unless<span>&lt;/<span>summary</span>&gt;</span>
            <span>&lt;<span>ul</span>&gt;</span>
              <span>&lt;<span>li</span>&gt;</span>Avoid<span>&lt;/<span>li</span>&gt;</span>
              <span>&lt;<span>li</span>&gt;</span>
                <span>&lt;<span>details</span>&gt;</span>
                  <span>&lt;<span>summary</span>&gt;</span>At<span>&lt;/<span>summary</span>&gt;</span>
                  <span>&lt;<span>ul</span>&gt;</span>
                    <span>&lt;<span>li</span>&gt;</span>Avoid<span>&lt;/<span>li</span>&gt;</span>
                    <span>&lt;<span>li</span>&gt;</span>At<span>&lt;/<span>li</span>&gt;</span>
                    <span>&lt;<span>li</span>&gt;</span>All<span>&lt;/<span>li</span>&gt;</span>
                    <span>&lt;<span>li</span>&gt;</span>Cost<span>&lt;/<span>li</span>&gt;</span>
                  <span>&lt;/<span>ul</span>&gt;</span>
                <span>&lt;/<span>details</span>&gt;</span>
              <span>&lt;/<span>li</span>&gt;</span>
              <span>&lt;<span>li</span>&gt;</span>All<span>&lt;/<span>li</span>&gt;</span>
              <span>&lt;<span>li</span>&gt;</span>Cost<span>&lt;/<span>li</span>&gt;</span>
            <span>&lt;/<span>ul</span>&gt;</span>
          <span>&lt;/<span>details</span>&gt;</span>
        <span>&lt;/<span>li</span>&gt;</span>
      <span>&lt;/<span>ul</span>&gt;</span>
    <span>&lt;/<span>details</span>&gt;</span>
  <span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>HTML<span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>Special Thanks<span>&lt;/<span>li</span>&gt;</span>
<span>&lt;/<span>ul</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <section>
      <h3 id="tabs">Tabs</h3>
      <div>
        <blockquote>
          A <em>tab control</em> is analogous to a divider in a file cabinet or notebook.
          You can use this control to define multiple logical pages or sections of information within the same window.

          
        </blockquote>

        <p>
          To render a tab list, use a <code>menu</code> element with the
          <code>[role=tablist]</code> attribute. The children of this menu (<code>li</code>
          elements), should get a <code>[role=tab]</code> attribute.
        </p>

        <p>
          Tabs should be managed by adding custom javascript code.
          All you need is to add the <code>[aria-selected=true]</code> attribute to the active tab.
        </p>

        <div>
      <div>
  <p>Hello, world!</p>

  <menu role="tablist">
    <li role="tab" aria-selected="true"><a href="#tabs">Desktop</a></li>
    <li role="tab"><a href="#tabs">My computer</a></li>
    <li role="tab"><a href="#tabs">Control panel</a></li>
    <li role="tab"><a href="#tabs">Devices manager</a></li>
    <li role="tab"><a href="#tabs">Hardware profiles</a></li>
    <li role="tab"><a href="#tabs">Performance</a></li>
  </menu>
  
</div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"window-body"</span>&gt;</span>
  <span>&lt;<span>p</span>&gt;</span>Hello, world!<span>&lt;/<span>p</span>&gt;</span>

  <span>&lt;<span>menu</span> <span>role</span>=<span>"tablist"</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span> <span>aria-selected</span>=<span>"true"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Desktop<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>My computer<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Control panel<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Devices manager<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Hardware profiles<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Performance<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;/<span>menu</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"window"</span> <span>role</span>=<span>"tabpanel"</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"window-body"</span>&gt;</span>
      <span>&lt;<span>p</span>&gt;</span>the tab content<span>&lt;/<span>p</span>&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>

        <p>
          To create multirows tabs, add a <code>multirows</code>
          class to the <code>menu</code> tag.
        </p>

        <div>
      <div>
  <p>Hello, world!</p>

  <menu role="tablist">
    <li role="tab"><a href="#tabs">Desktop</a></li>
    <li role="tab"><a href="#tabs">My computer</a></li>
    <li role="tab"><a href="#tabs">Control panel</a></li>
    <li role="tab"><a href="#tabs">Devices manager</a></li>
    <li role="tab"><a href="#tabs">Hardware profiles</a></li>
    <li role="tab"><a href="#tabs">Performance</a></li>
  </menu>
  <menu role="tablist">
    <li role="tab"><a href="#tabs">Users</a></li>
    <li role="tab"><a href="#tabs">Network</a></li>
    <li role="tab"><a href="#tabs">Programs</a></li>
    <li role="tab"><a href="#tabs">Services</a></li>
    <li role="tab"><a href="#tabs">Resources</a></li>
    <li role="tab"><a href="#tabs">Advanced</a></li>
  </menu>
  
</div>
      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"window-body"</span>&gt;</span>
  <span>&lt;<span>p</span>&gt;</span>Hello, world!<span>&lt;/<span>p</span>&gt;</span>

  <span>&lt;<span>menu</span> <span>role</span>=<span>"tablist"</span> <span>class</span>=<span>"multirows"</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Desktop<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>My computer<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Control panel<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Devices manager<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Hardware profiles<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Performance<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;/<span>menu</span>&gt;</span>
  <span>&lt;<span>menu</span> <span>role</span>=<span>"tablist"</span> <span>class</span>=<span>"multirows"</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Users<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Network<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Programs<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Services<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Resources<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
    <span>&lt;<span>li</span> <span>role</span>=<span>"tab"</span>&gt;</span><span>&lt;<span>a</span> <span>href</span>=<span>"#tabs"</span>&gt;</span>Advanced<span>&lt;/<span>a</span>&gt;</span><span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;/<span>menu</span>&gt;</span>
  <span>&lt;<span>div</span> <span>class</span>=<span>"window"</span> <span>role</span>=<span>"tabpanel"</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"window-body"</span>&gt;</span>
      <span>&lt;<span>p</span>&gt;</span>the tab content<span>&lt;/<span>p</span>&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></code></pre>
      </details>
    </div>
              </div>
    </section>
    <section>

      <h3 id="table-view">TableView</h3>
      <div>
        <p>
          To render a table view, use a table element. Wrap it with a div element with <code>sunken-panel</code> class to provide proper border and overflow container.
        </p>
        <p>
          With a bit of extra scripting you can make table view interactive. Give <code>interactive</code> class to
          table element to show pointer cursor when hovering over body rows. Table rows can be given
          <code>highlighted</code> class to appear selected.
        </p>

        <div>
      <div>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Version</th>
        <th>Company</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>MySQL ODBC 3.51 Driver</td>
        <td>3.51.11.00</td>
        <td>MySQL AB</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
      <tr>
        <td>SQL Server</td>
        <td>3.70.06.23</td>
        <td>Microsoft Corporation</td>
      </tr>
    </tbody>
  </table>
</div>

      <details>
        <summary>Show code</summary>
        <pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"sunken-panel"</span> <span>style</span>=<span>"height: 120px; width: 240px;"</span>&gt;</span>
  <span>&lt;<span>table</span> <span>class</span>=<span>"interactive"</span>&gt;</span>
    <span>&lt;<span>thead</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>th</span>&gt;</span>Name<span>&lt;/<span>th</span>&gt;</span>
        <span>&lt;<span>th</span>&gt;</span>Version<span>&lt;/<span>th</span>&gt;</span>
        <span>&lt;<span>th</span>&gt;</span>Company<span>&lt;/<span>th</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
    <span>&lt;/<span>thead</span>&gt;</span>
    <span>&lt;<span>tbody</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>MySQL ODBC 3.51 Driver<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.51.11.00<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>MySQL AB<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
      <span>&lt;<span>tr</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>SQL Server<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>3.70.06.23<span>&lt;/<span>td</span>&gt;</span>
        <span>&lt;<span>td</span>&gt;</span>Microsoft Corporation<span>&lt;/<span>td</span>&gt;</span>
      <span>&lt;/<span>tr</span>&gt;</span>
    <span>&lt;/<span>tbody</span>&gt;</span>
  <span>&lt;/<span>table</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>script</span>&gt;</span><span>
  <span>document</span>.querySelectorAll(<span>'table.interactive'</span>).forEach(<span><span>element</span> =&gt;</span> {
    element.addEventListener(<span>'click'</span>, <span>(<span>event</span>) =&gt;</span> {
      <span>const</span> row = event.path.find(<span><span>element</span> =&gt;</span> element.tagName === <span>'TR'</span> &amp;&amp; element.parentElement.tagName === <span>'TBODY'</span>);
      <span>if</span> (row) {
        row.classList.toggle(<span>'highlighted'</span>);
      }
    })
  });
</span><span>&lt;/<span>script</span>&gt;</span></code></pre>
      </details>
    </div>
      </div>
    </section>

    <h2 id="issues-contributing-etc">Issues, Contributing, etc.</h2>

    <p>
      98.css is <a href="https://github.com/jdan/98.css/blob/main/LICENSE">MIT licensed</a>.
    </p>

    <p>
      Refer to <a href="https://github.com/jdan/98.css/issues">the GitHub issues page</a> to see bugs
      in my CSS or report new ones. I'd really like to see your pull requests (especially those new to
      open-source!) and will happily provide code review. 98.css is a fun, silly project and I'd like
      to make it a fun place to build your open-source muscle.
    </p>

    <p>
      Thank you for checking my little project out, I hope it brought you some joy today. Consider
      <a href="https://github.com/jdan/98.css/stargazers">starring/following along on GitHub</a> and maybe
      subscribing to more fun things on <a href="https://twitter.com/jdan">my twitter</a>. 👋
    </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Only 5.3% of US welders are women. After years as a professor, I became one (185 pts)]]></title>
            <link>https://theconversation.com/only-5-3-of-welders-in-the-us-are-women-after-years-as-a-writing-professor-i-became-one-heres-what-i-learned-240431</link>
            <guid>42056420</guid>
            <pubDate>Wed, 06 Nov 2024 00:24:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/only-5-3-of-welders-in-the-us-are-women-after-years-as-a-writing-professor-i-became-one-heres-what-i-learned-240431">https://theconversation.com/only-5-3-of-welders-in-the-us-are-women-after-years-as-a-writing-professor-i-became-one-heres-what-i-learned-240431</a>, See on <a href="https://news.ycombinator.com/item?id=42056420">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Although I have a good gig as <a href="https://engl.iastate.edu/profiles/jo-mackiewicz/">a full professor at Iowa State University</a>, I’ve daydreamed about learning a trade – something that required both my mind and my hands. </p>

<p>So in 2018, I started <a href="https://www.dmacc.edu/pathways/em/welding.html">night courses</a> in welding at Des Moines Area Community College. For three years, I studied different types of welding and during the day worked on a book about the <a href="https://sunypress.edu/Books/W/Welding-Technical-Communication">communication between welding teachers and students</a>. I wasn’t the only woman who became interested in trades work during this time. Recognizing the good pay and job security, U.S. women have moved in greater numbers into skilled trades such as welding and fabrication within the past 10 years. </p>

<p>From 2017 to 2022, the number of women in trades rose <a href="https://iwpr.org/wp-content/uploads/2023/07/Quick-Figure-construction-July-2023.pdf">from about 241,000 to nearly 354,000</a>. That’s an increase of about 47%. Even so, women still constitute just <a href="https://www.dol.gov/agencies/wb/data/occupations/occupations-smallest-share-women-workers">5.3% of welders in the United States</a>. </p>

<p>When I received my diploma in welding in May 2022, I’d already found the place I wanted to work: <a href="https://www.yelp.com/biz/howe-welding-and-metal-fabrication-ames">Howe’s Welding and Metal Fabrication</a>. I’d met the owner, Jim Howe, when I visited his three-man shop in Ames, Iowa, in January 2022 for research on a second book about communication in skilled trades. </p>

<p>Howe’s shop focuses on repairs and one-off fabrication, not large-scale production of single items. Under Howe’s tutelage, I’ve fabricated skis for the machines that make the rumble strips in the road, shepherd’s hooks for bird feeders, fence poles and stainless-steel lampshade frames. I’ve repaired trailers, wheelchair ramps, office chairs and lawn mowers. </p>

<figure>
            <a href="https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="Work tables in a metal shop covered with objects." data-src="https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/625315/original/file-20241012-15-sevyrh.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>Work tables at Howe’s. My table is the one in front with the pans on it. It’s difficult to use the table in the middle because everyone piles parts there.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<figure>
            <a href="https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="The bottom of an aluminum lawn chair that has been repaired with tig welds." data-src="https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/625321/original/file-20241012-17-ie39we.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>I fixed the slats on an aluminum lawn chair by bending aluminum strips and TIG welding them to the chair’s sides.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<p>Both my experience at Howe’s and my research at nine other fabrication facilities in Iowa have shown me that – at least for the time being – tradeswomen must find workarounds for commonly encountered challenges. Some of these challenges are physical. These could include being unable to easily reach or move necessary material and tools. Or they could be emotional, such as encountering sexism. As I explore in my forthcoming book, “Learning Skilled Trades in the Workplace,” this is true even in a welcoming environment like Howe’s shop, where I work with a supportive and helpful boss and co-workers.</p>

<figure>
            <a href="https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="Welding tools in a machine shop." data-src="https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/625317/original/file-20241012-15-93dmgi.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>The machine shop at Howe’s houses various lathes, mills and drill presses, as well as other machines.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<h2>Questions of competence</h2>

<p>Being a tradeswoman means being scrutinized for competence. One of the tradeswomen I interviewed for the book told me this story about being tested by more experienced tradesmen: </p>

<p>“I remember them tacking together a couple of pieces of metal for me and saying, ‘Okay, I want you to weld a six millimeter weld here and an eight millimeter weld here,’ and I was so nervous because these are the guys that I’m going to work with, and I just was so nervous and I laid down the welds and put my hood up and the guy goes, ‘Well, goddamn, bitch can weld,’ and I was like, ‘Oh my god, thank god.’” </p>

<p>I’ve felt this same scrutiny from Howe’s customers. Once, two customers watched me as I used <a href="https://www.peddinghaus.com/hydraulic-ironworker-machine/peddiworker/machines/37">the ironworker</a> to punch ovals in rectangular tubing. I had to step on the pedal to lower the punch, find the indentation of the spot to punch, hold a combination square against the metal to ensure the oblong shape was parallel to the tubing’s edge, step on the pedal and pull <a href="https://www.southernfabsales.com/hubfs/docs/introduction-to-ironworkers-and-notchers.pdf">the stripper</a> toward me.</p>

<p>I could feel <a href="https://www.mayoclinichealthsystem.org/hometown-health/speaking-of-health/managing-high-functioning-anxiety">my legs turn to jelly</a> as I performed the steps and – as I perceived it – <a href="https://journals.uwyo.edu/index.php/workingclassstudies/article/view/6119/5283">represented the trade competence of all womankind</a>. I’m resentful of these silent evaluations, particularly when I’m learning something new and trying to keep all my fingers. </p>

<figure>
            <a href="https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="An arm to a large steel umbrella." data-src="https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/625322/original/file-20241012-15-5gwvdw.JPG?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>I welded an arm back onto a large umbrella.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<h2>Overcoming the environment</h2>

<p>The standards <a href="https://www.osha.gov/laws-regs/regulations/standardnumber/1910">established by the Occupational Safety and Health Administration</a>, or OSHA, don’t necessarily account for all the physicality of trades work. On the day Jim told me to bend 20 pieces of ½-inch round stock, I had to use all my weight to pull the <a href="https://www.hossfeldbender.com/">Hossfeld bender</a>’s arm to make the S shapes. </p>

<figure>
            <a href="https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A man using a Hossfeld bender." data-src="https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=800&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=800&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=800&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=1005&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=1005&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=1005&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/625265/original/file-20241011-15-hw291v.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>My boss, Jim Howe, sets up the Hossfeld bender. That’s the same Hossfeld that I’ve used to make parts of lampshade frames, fence stakes and S hooks.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<p>The 20 S hooks would hang on a bar and hold the 18 <a href="https://en.wikipedia.org/wiki/Come-along">come-alongs</a> that Jim had accumulated. Tired after I’d finished all the bending, I sighed as Jim told me to hang all the come-alongs on a mobile rack he had bought at auction for just this purpose.</p>

<p>I had to squat to pick each one up and use my legs and then arms to lift each to a newly made hook. But I didn’t complain. Stoicism is a <a href="https://doi.org/10.1177/0018726709349922">workaround to credibility</a>.</p>

<figure>
            <a href="https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="S hooks with come-alongs hanging from them." data-src="https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=450&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=566&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/625260/original/file-20241011-15-iiytk3.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Making S hooks on the Hossfeld bender wore me out even before I had to hang the come-alongs on them.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<h2>Navigating sexist comments</h2>

<p>My interactions with Howe’s customers have been peppered with low-grade sexism. Trying to determine the reason for my presence, one customer asked me, “Are you the new secretary?” </p>

<p>Another man <a href="https://spssi.onlinelibrary.wiley.com/doi/10.1111/0022-4537.00200">commented on my appearance</a>, comparing me to my co-worker: “You’re better looking than the guy I talked to before.” Such harassment remains common for tradeswomen and ranges from mild, to violent, to just plain creepy, as when one man, paying his bill at the front desk, whispered, “Your hands are dirty.”  </p>

<p>Women in trades have reported encounters with customers who doubted their competence and <a href="https://doi.org/10.1111/gwao.12443">who refused to deal with them, seeking a man instead</a>.</p>

<figure>
            <p><img alt="A metal stand for a sign." data-src="https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=529&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=529&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=529&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=664&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=664&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=664&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/629404/original/file-20241031-15-8qgi5f.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p>
            <figcaption>
              <span>I made a sign for Ada Hayden Park in Ames, Iowa. The metal stand holds a placard naming the donors who funded a kayak launch.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<p>Some customers at Howe’s fit this pattern. I’ve noticed that if I’m at the front desk with a male co-worker, men will often look past me and address them, even though I’m older and, as far as they know, more experienced. Other customers like to tell me how to do my job. </p>

<p>One man, watching me while I cut 8-foot lengths of tubing for him, told me that I could simply hook my tape measure over the saw blade and subtract ⅛-inch to find the correct length. Piqued after I explained why his method wouldn’t work for a precise measurement, he responded by quizzing me on something I wasn’t likely to know: the purpose of <a href="https://www.ustape.com/hidden-features-of-measuring-tape/">the black diamonds on my tape measure</a>.</p>

<p>The man in the audience at the academic conference who wants to lecture rather than ask a question of the woman who is the speaker has become a trope. The pontificating metal-shop customer should be, too. Like other tradeswomen, I’ve learned to work around unwanted comments, including uninvited conversations with men bent on signaling their expertise.</p>

<figure>
            <p><img alt="A yellow tape measure that shows a black diamond at 19 3/16 inches." data-src="https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=449&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=449&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=449&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=564&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=564&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=564&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/629402/original/file-20241031-15-mvh6r5.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p>
            <figcaption>
              <span>Tape measures have diamonds every 19 3/16 inches. The diamonds, called truss marks, indicate the correct spacing of engineered floor joists.</span>
              <span><span>Jo Mackiewicz</span></span>
            </figcaption>
          </figure>

<h2>Toward greater expertise</h2>

<p>My soon-to-be-published book doesn’t focus solely or even mostly on my experiences as a woman in a welding and fabrication shop. Rather, it looks at the nonlinear process of learning skilled trades – a process that is, for tradeswomen, sometimes frustrated by scrutiny, physical challenges and sexism, which require workarounds.</p>

<p>Nevertheless, along this journey, I’ve leaned on the strength of the tradeswomen before me. Although these women have been “<a href="https://search.worldcat.org/title/1045589328">alone in a crowd</a>,” they’ve consistently worked around challenges toward broader and deeper expertise.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[More Oracle Layoffs Started Nov. 1, Cloud Unit Impacted (108 pts)]]></title>
            <link>https://www.channelfutures.com/channel-business/more-oracle-layoffs-started-nov-1-cloud-unit-impacted#</link>
            <guid>42056330</guid>
            <pubDate>Wed, 06 Nov 2024 00:04:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.channelfutures.com/channel-business/more-oracle-layoffs-started-nov-1-cloud-unit-impacted#">https://www.channelfutures.com/channel-business/more-oracle-layoffs-started-nov-1-cloud-unit-impacted#</a>, See on <a href="https://news.ycombinator.com/item?id=42056330">Hacker News</a></p>
Couldn't get https://www.channelfutures.com/channel-business/more-oracle-layoffs-started-nov-1-cloud-unit-impacted#: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla is eliminating its advocacy division (211 pts)]]></title>
            <link>https://www.theverge.com/2024/11/5/24289124/mozilla-foundation-layoffs-advocacy-global-programs</link>
            <guid>42055979</guid>
            <pubDate>Tue, 05 Nov 2024 23:04:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/11/5/24289124/mozilla-foundation-layoffs-advocacy-global-programs">https://www.theverge.com/2024/11/5/24289124/mozilla-foundation-layoffs-advocacy-global-programs</a>, See on <a href="https://news.ycombinator.com/item?id=42055979">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Mozilla Foundation laid off 30 percent of its workforce and completely eliminated its advocacy and global programs divisions, <a href="https://techcrunch.com/2024/11/05/mozilla-foundation-lays-off-30-staff-drops-advocacy-division/"><em>TechCrunch </em>reports</a>.&nbsp;</p><p>While Mozilla is best known for its Firefox web browser, the Mozilla Foundation — the parent of the Mozilla Corporation — describes itself as standing up “for the health of the internet.” With its advocacy and global programs divisions gone, its impact may be lessened going forward.</p><p>“Fighting for a free and open internet will always be core to our mission, and advocacy continues to be a critical tool in that work. We’re revisiting how we pursue that work, not stopping it,” Brandon Borrman, the Mozilla Foundation’s communications chief, said in an email to <em>The Verge. </em>Borrman declined to confirm exactly how many people were laid off, but said it was about “30% of the current team.”</p><p>This is Mozilla’s <a href="https://www.theverge.com/2024/2/13/24072184/mozilla-is-laying-off-around-60-workers-and-scaling-back-its-mastodon-instance">second round of layoffs this year</a>. In February, the Mozilla Corporation laid off around 60 workers said it would be making a “strategic correction” that would involve involve cutting back its work on a Mastodon instance. Mozilla shut down its virtual 3D platform and refocused its efforts on Firefox and AI. The Mozilla Foundation had around 120 employees before this more recent round of layoffs, according to <em>TechCrunch</em>.</p><p>In an email sent to all employees on October 30th, Nabhia Syed, the foundation’s executive director, said that the advocacy and global programs divisions “are no longer part of our structure.”</p><p>“Navigating this topsy-turvy, distracting time requires laser focus — and sometimes saying goodbye to the excellent work that has gotten us this far because it won’t get us to the next peak,” wrote Syed, who previously worked as the chief executive of <em>The Markup</em>, an investigative news site. “Lofty goals demand hard choices.”&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unix Programmer's Manual Third Edition [pdf] (1973) (170 pts)]]></title>
            <link>https://dspinellis.github.io/unix-v3man/v3man.pdf</link>
            <guid>42055644</guid>
            <pubDate>Tue, 05 Nov 2024 22:12:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dspinellis.github.io/unix-v3man/v3man.pdf">https://dspinellis.github.io/unix-v3man/v3man.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=42055644">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[What Shapes Do Matrix Multiplications Like? (143 pts)]]></title>
            <link>https://www.thonking.ai/p/what-shapes-do-matrix-multiplications</link>
            <guid>42055616</guid>
            <pubDate>Tue, 05 Nov 2024 22:08:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications">https://www.thonking.ai/p/what-shapes-do-matrix-multiplications</a>, See on <a href="https://news.ycombinator.com/item?id=42055616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>A while back, Karpathy tweeted that </span><em>increasing</em><span> the size of his matmul made it run faster. Surprisingly, it’s not just </span><em>relatively</em><span> faster, it takes less </span><em>absolute</em><span> time. In other words, despite doing more work, it is executing in less time.</span></p><p>This may seem intuitively quite strange. Is cuBLAS just messing up somehow? Why doesn’t the matrix multiplication kernel just pad it to a larger shape? </p><p>It has become tribal knowledge that the particular shapes chosen for matmuls has a surprisingly large effect on their performance. But … why? Can this be understood by mere mortals?</p><p>Let’s take a crack at it.</p><p>First, let’s plot FLOPs achieved for square matmuls. By the end of this article, I will aim to explain all the strange squiggly lines. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg" width="1456" height="965" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/da2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:965,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fda2b6db5-95ca-47c9-adb5-6f5ca85c92f0_2418x1602.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>There are 3 general concepts to understand that explain the majority of performance variation among matmul shapes.</p><ol><li><p>Compute Intensity/Parallelization: This explains the general upward trend</p></li><li><p>Tiling: This explains the multiple tiers of lines.</p></li><li><p>Wave Quantization: This explains the strange striped lines.</p></li></ol><p>First of all, as we move along the x-axis, the matrix multiplications generally get more performant. There’s two primary reasons for this. </p><p>The first one is simply “more work/more parallelism”. There are a large number of fixed overheads that come with launching a kernel (e.g. creating new SMs, waiting for all SMs to finish, etc.), and so, the more work we have to do, the less important those fixed overheads are. Along with more work comes more parallelism, and since GPUs have a ton of parallel cores, you need a surprising amount of work in order to fill a GPU up with enough parallelism.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png" width="478" height="363.09615384615387" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1106,&quot;width&quot;:1456,&quot;resizeWidth&quot;:478,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5b2ae02-19be-4af7-8fc4-037f7476761b_2196x1668.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Data movement is expensive!</figcaption></figure></div><p><span>The second one is “arithmetic intensity”. As I’ve </span><a href="https://horace.io/brrr_intro.html" rel="">written about before</a><span>, memory accesses are much more expensive than compute. So, since a square matmul performs 3N^2 memory accesses and 2N^3 FLOPs, at a very minimum, N needs to be in the hundreds before we start spending more time on compute than memory!</span></p><p><span>The desire for sufficient Arithmetic Intensity and Parallelism also compound. For example, let’s say you have your output matrix is </span><code>1024 x 1024</code><span>. If you let each SM compute a </span><code>128 x 128 </code><span>slice of the output, that’s only 64 pieces of “work” for your GPU, not even enough for each one of an A100’s 108 SMs ! If you decrease your output slice size to 64 x 64, we now have 256 pieces of “work” for our GPU, but our arithmetic intensity has also decreased by a factor of 4.</span></p><p>With smaller matrix sizes, you need to worry about problems like this that don’t show up with larger matrices. </p><p>Now that we understand the overall structure of the plot, the next question is: why is the plot all over the place? Why, even for very large matrices, do the TFLOPS jumping between &gt;250 and &lt;100?</p><p>To give a hint, let’s color-code each dot by the highest power of 2 it’s divisible by.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg" width="1456" height="1087" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1087,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F245e1a67-e758-4561-9521-72191ef5992f_1513x1130.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>As it turns out, the multiple “levels” of FLOPS are due to their shapes’ divisibility. For example, when the shape is odd, the matmul performs significantly worse than when the shape is even. The matmul performs even better when the shape is divisible by 8, with even more performance gains when it’s divisible by 16 or 32.</p><p><span>Now, merely knowing about this effect is very practically useful, but what actually causes this effect? As it turns out, the answer is tiling. But, what even </span><em>is</em><span> tiling? And why does it cause such substantial performance issues?</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png" width="1456" height="454" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:454,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:110115,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5939a8fd-8356-45a6-8e83-db6fd48c014d_2116x660.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Taken from https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#tile-quant</figcaption></figure></div><p><span>Some online have mentioned </span><a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#tile-quant" rel="">tile quantization</a><span> as the culprit. Tile quantization certainly can impact performance, but </span><em>only at tile boundary sizes</em><span>. Basically, tile quantization occurs when the size of your matrix multiplication increases such that the GPU needs to launch another “chunk” of work. For example, imagine that you could multiply 8 elements at a time with a SIMD instruction. Now, if you went from 32 elements to 33 elements (a 3% increase in problem size), you go from needing 4 SIMD instructions to 5 (a 25% increase). Note that crucially, when tile quantization is the culprit, your absolute runtime still grows monotonically, although your efficiency may drop.</span></p><p><span>However, in our above plot, we see much more drastic performance drops! Moreover, like in Karpathy’s original example, we see that the </span><em>absolute runtime decreases despite problem size increasing</em><span>. So, tile quantization cannot be the explanation here.</span></p><p>The true cause is that tiling is just fundamentally worse for certain memory layouts. In other words, by the time we’re trying to execute the matmul, you’ve already lost. The memory layout is poor and your performance will suffer.</p><p>Let’s look at some examples!</p><p>First, let’s think about how our matrix’s memory layout looks like when our size is a multiple of the cache line (pretend it’s 4 elements). </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png" width="520" height="371.55555555555554" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/819f8836-c521-4363-b170-49ee039569c6_1170x836.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:836,&quot;width&quot;:1170,&quot;resizeWidth&quot;:520,&quot;bytes&quot;:624255,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F819f8836-c521-4363-b170-49ee039569c6_1170x836.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>I choose to show 3 “cache lines” per row because our matrix logically has 12 elements per row.</figcaption></figure></div><p><span>We see that each row starts on a cache line</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-142904770" href="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications#footnote-1-142904770" target="_self" rel="">1</a></span><span>. Among other advantages, this means that we don’t need to perform any “unnecessary” loads to load all yellow elements. We can just load the 3 cache lines that the yellow elements are part of.</span></p><p>However, what happens if we increase the number of elements per row from 12 to 13? </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png" width="520" height="317.14701601164484" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:838,&quot;width&quot;:1374,&quot;resizeWidth&quot;:520,&quot;bytes&quot;:759750,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57fffe15-4659-44e1-b516-0944867b9f96_1374x838.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Each logical row (which have 13 elements) no longer starts aligned with a cache line.</figcaption></figure></div><p><span>With an unaligned layout, each row is misaligned relative to our cache line. In other words, if we start loading the beginning of the green row, we </span><em>must</em><span> redundantly load the last element of the blue row as well.</span></p><p>Now, let’s look at what happens when we actually try to load an entire “tile” from these memory layouts.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg" width="1456" height="623" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:623,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf2a2033-e9bf-44b8-8961-5b50c25eda91_2032x870.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Shaded regions = elements we’re trying to load. Crossed out regions = elements we don’t need but must load due to it being in the same cache line.</figcaption></figure></div><p>With the aligned layout, this is very clean! We issue one load per row. One for the 4 blue elements, one for the 4 green elements, one for the 4 yellow elements, and one for the 4 pink elements. </p><p>With the unaligned layout, things are much messier. For example, in order to load the first 4 green elements, we must issue 2 loads! One that gets the last blue element + the first 3 green elements, and one that gets the 4th green element. A similar pattern occurs with loading the 4 yellow elements as well as the 4 pink elements.</p><p><span>So, when our matrix size is divisible by the cache line (which is 32 elements on a GPU), tiling fits nicely within the cache line, and our memory loads are maximally efficient. When it’s not… the kernel needs many more workarounds in order to end up the proper alignment.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-142904770" href="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications#footnote-2-142904770" target="_self" rel="">2</a></span></p><p>This is why even very small changes in our matrix size can lead to substantially worsened performance.</p><p>Ok, so we’ve understood most of the variation in matmul performance. But what about these strange stripes up here? All of these points are with matmuls that are divisible by 32 already. Seeing that the peaks are separated by 256, our first guess might be that this is also memory-layout related, just at a larger scale.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png" width="844" height="466" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:466,&quot;width&quot;:844,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F040453ca-4ac6-4275-bc84-7765a0bc70c4_844x466.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Some truly mysterious patterns….</figcaption></figure></div><p><span>However, as it turns out, these peaks (2944 and 3120) do </span><em>not </em><span>occur when the matrix shapes are divisible by 256, but instead they’re at 128 mod 256! </span></p><p><span>As it turns out, these peaks are not caused by poor memory-layouts, they’re instead caused by a (neatly-named) phenomenon called </span><em>wave quantization</em><span>.</span></p><p>The main idea behind wave quantization is quite simple. </p><p><span>Let’s say we have N parallel tasks (which each take a second) and N CPUs. </span><br><span>Q: How long does it perform to take all tasks?</span><br><span>A: 1 second</span></p><p><span>Q: What about if we have (N+1) parallel tasks, and N CPUs?</span><br><span>A: 2 seconds(!) Now, one CPU must perform two tasks, taking a total of 2 seconds.</span></p><p>So, despite adding just one task, we’ve doubled our overall latency.</p><p>This is exactly what wave quantization is, except with CPUs =&gt; SMs and tasks =&gt; thread blocks.</p><p>As your matrix size increases, the total number of tiles/blocks increases. When this crosses a multiple of the # of SMs, your perf drops since you need to execute an additional "wave".</p><p>Now, let's apply our newfound knowledge to actually explain these curves! Let’s try looking at this sudden drop in performance around 1792 first.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png" width="244" height="429.5299539170507" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:764,&quot;width&quot;:434,&quot;resizeWidth&quot;:244,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d21d15-54c6-44ad-a522-1fa775badc59_434x764.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Since wave quantization depends a lot on the actual kernel parameters, we must look at what kernels are actually being run.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png" width="1456" height="173" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:173,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81f276b8-3a39-418f-b586-8c016abb4285_2532x300.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Using the profiler, we see that we're running a CUTLASS-based matmul with a tile size of 256x128. Note that our matmul kernel *doesn't change at all*, but our perf drops from 60+ TF/s at N=1791 to 43 TF/s at N=1793. </p><p>Now, some basic arithmetic. Our tile grid has dimensions 1792/256 = 7 and 1792/128 = 14. That gives us 7 * 14 = 98 tiles. Since an A100 has 108 SMs, that's still one wave. However, with N=1793 we need to increase the size of our grid. (7+1)*(14+1) = 120 tiles, or 2 waves!</p><p>Now, let’s look at the previous (mysterious) stripes. Specifically, we’ll look at N=3200.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png" width="476" height="262.81516587677726" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:466,&quot;width&quot;:844,&quot;resizeWidth&quot;:476,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c110a2b-9845-4305-b9f0-40c2d61b7831_844x466.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Mysterious no more!</figcaption></figure></div><p><span>Profiling it, we see that the </span><em>proximal</em><span> cause is not actually wave quantization. Instead, CuBLAS decided to  change algorithms. But, why did CuBLAS decide to change algorithms?</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png" width="1456" height="244" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:244,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ccbbbd2-2f3f-46a1-b542-e575decf2f6d_1792x300.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Well, (3200/128) * (3200/128) = 625. 625/108 = 5.8 waves. Thus, at N=3232 we would create another wave.</p><p>In this case, though, it seems that 160x128 still isn't a great tile size. Since the resulting grid (26x21) results in 5.05 waves...</p><p>Well, CuBLAS isn't perfect!</p><p>Beyond the obvious matrix multiplication shape issues, performance loss due to wave quantization often ends up being tricky to find, since it depends upon things like the batch size as well. However, if you take a closer look at each matmul, you might find that there’s another 10-15% performance you can squeeze out of it by choosing the shapes more carefully!</p><p><span>I will note that it’s possible that wave quantization effects may soon be a thing of the past. New matrix multiplication technology like </span><a href="https://arxiv.org/abs/2301.03598" rel="">stream-k</a><span> allow us to completely bypass wave quantization effects. Perhaps I’ll explain the basic idea behind matmul implementation strategies someday.</span></p><p><span>As it turns out, torch.compile does try and pad your matmuls to have the right shape! See the code </span><a href="https://github.com/pytorch/pytorch/blob/6b1f13ea2f3b1bcd575620eecd7d84a4d2e3eb76/torch/_inductor/fx_passes/pad_mm.py#L90" rel="">here</a><span>, or try this benchmark.</span></p><pre><code>import torch
torch.set_default_device('cuda')
from triton.testing import do_bench

def f(a, b):
    return torch.mm(a, b)

a = torch.randn(4096, 4096, dtype=torch.bfloat16)
b = torch.randn(4096, 4095, dtype=torch.bfloat16)
print("eager: ", do_bench(lambda: f(a, b)))
cf = torch.compile(f)
print("compiled: ", do_bench(lambda: cf(a, b)))
&gt;&gt; eager: 1.4077268838882446
&gt;&gt; compiled: 0.6021425127983093</code></pre><p>However, there are still limitations that mean it makes sense for users to manually pad their shapes. </p><p>For one, padding requires a full copy! Although torch.compile can often fuse this into a preceding op, in the case where the matrix being padded comes from the input (like a weight matrix), there’s no way to avoid this copy.</p><p>Second, resolving wave quantization is far more difficult.</p><p><span>Overall, I hope the topic of "how do I squeeze the most out of my matmuls" is an interesting one. There's still many more intricacies in matmul perf that I didn’t have the time to get to, as well (I’m sure) many more intricacies that I don’t know! Here’s the </span><a href="https://gist.github.com/Chillee/f86675147366a7a0c6e244eaa78660f7#file-4-matmul-bench-py" rel="">main code</a><span> to replicate the results.</span></p><p>Also, here’s some quiz questions to test your understanding! I will publish a brief explanation of the answers at some later point.</p><p><strong>1:</strong><span> Let's say I have a </span><code>[M x K] @ [K x N]</code><span> matmul. Which one of these configurations will have the best perf? Think about the actual ramifications of tiling! Both matrices are in row-major layout (i.e. K and N are the innermost dimensions)</span><br><span>A: M=2047, K=N=2048 </span><br><span>B: K=2047, M=N=2048 </span><br><span>C: N=2047, M=K=2048</span></p><p><strong>2: </strong><span>Let’s say I have an A100 with 108 SMs, and I want to benchmark a number of matmuls with no wave quantization. How would I go about constructing the shapes for these matmuls?</span></p><p><strong>3: </strong><span>Based off this post, would you expect that making your batch size a power of 2 leads to more efficient performance?</span></p><div><p><strong>4: </strong><span>Similar to Question 1, let’s say we have a A: [M x K] @ B: [K x N] matmul.  However, now, A is in column-major (i.e. </span><code>torch.randn(K, M).t()</code><span>) while B is still row-major. What is the best configuration now?</span></p><p><span>A: M=2047, K=N=2048 </span><br><span>B: K=2047, M=N=2048 </span><br><span>C: N=2047, M=K=2048</span></p></div><p><strong>5: </strong><span>Let’s say that we have this code.</span></p><pre><code>A = torch.randn(4096, 4096)
B = torch.randn(4096, 4096)
B = B[:, :4095] # B now has shape [4096, 4095]</code></pre><p>Would you expect that we have good performance on a matmul between A and B?</p><p><span>Solutions can be found below</span><br></p><div data-component-name="DigestPostEmbed"><a href="https://www.thonking.ai/p/answer-key-what-shapes-do-matrix" target="_blank" rel="noopener"></a><div><a href="https://www.thonking.ai/p/answer-key-what-shapes-do-matrix" target="_blank" rel="noopener"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,h_212,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 424w, https://substackcdn.com/image/fetch/w_848,h_424,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 848w, https://substackcdn.com/image/fetch/w_1272,h_636,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 1272w, https://substackcdn.com/image/fetch/w_1300,h_650,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 1300w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1300,h_650,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png" sizes="100vw" alt="Answer Key: What Shapes Do Matrix Multiplications Like?" srcset="https://substackcdn.com/image/fetch/w_424,h_212,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 424w, https://substackcdn.com/image/fetch/w_848,h_424,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 848w, https://substackcdn.com/image/fetch/w_1272,h_636,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 1272w, https://substackcdn.com/image/fetch/w_1300,h_650,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bd02621-bbe2-44c9-8fa3-4809a5087400_1828x600.png 1300w" width="1300" height="650"></picture></a></div></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tracking down a mysterious skateboarder from 1979 (179 pts)]]></title>
            <link>https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979</link>
            <guid>42055558</guid>
            <pubDate>Tue, 05 Nov 2024 22:00:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979">https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979</a>, See on <a href="https://news.ycombinator.com/item?id=42055558">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Here’s a really cool picture:</p><div data-attrs="{&quot;instagram_id&quot;:&quot;DB42tOlymvY&quot;,&quot;title&quot;:&quot;A post shared by @tonyhawk&quot;,&quot;author_name&quot;:&quot;tonyhawk&quot;,&quot;thumbnail_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/__ss-rehost__IG-meta-DB42tOlymvY.jpg&quot;,&quot;timestamp&quot;:null,&quot;belowTheFold&quot;:false}" data-component-name="InstagramToDOM"><p><a href="https://instagram.com/p/DB42tOlymvY" target="_blank" rel=""><img src="https://substackcdn.com/image/fetch/w_640,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F__ss-rehost__IG-meta-DB42tOlymvY.jpg"></a></p></div><p><span>A former colleague from my TV days, Michelle Chernicoff, sent me this picture of a young girl skateboarding underneath an umbrella on a rainy day. She saw it after Tony Hawk </span><a href="https://www.instagram.com/p/DB42tOlymvY/" rel="">posted it to his Instagram page</a><span> on Saturday. According to his caption, Tony </span><em>really</em><span> wanted to know who it was:</span></p><blockquote><p>New fav mystery skater unlocked: from Fayetteville Observer (NC), 1973. Style, grace, confidence, and… goofy footed, in the rain!! I hope she’s still around.</p></blockquote><p><span>Folks, we love two things around here: </span><a href="https://www.ncrabbithole.com/p/tony-hawk-went-to-some-coffee-shops" rel="">Tony Hawk</a><span> and </span><a href="https://www.ncrabbithole.com/p/steven-spielberg-indiana-jones-nc-highway-patrol" rel="">decades-old mysteries</a><span>. </span></p><p><span>There were two initial clues: The date and the newspaper. I plugged the picture into Google Image Search to see if I could find the original post. Back on September 21, blackarchives.co had </span><a href="https://www.instagram.com/blackarchives.co/p/DALpuCIur9i/?img_index=1" rel="">posted a collection of images</a><span> taken by </span><em>Fayetteville Observer</em><span> photographers between 1973 and 1987. The image of the skateboarder in the rain was the first one in the carousel. Tony Hawk himself commented the same day: “New fav skater unlocked.”</span></p><p><span>Next, I did some searches on the </span><em>Observer</em><span>’s website. The image showed up in </span><a href="https://www.fayobserver.com/picture-gallery/news/2019/06/21/from-the-archives-fayetteville-observer/69320732007/" rel="">a monthly roundup of old ‘70s photos</a><span> that staff photographer </span><a href="https://www.instagram.com/aacraft/" rel="">Andrew Craft</a><span> had pulled from the paper’s negative archive in 2019 (“Anytime I come across a skateboarding image I always scan it,” he said later in an Instagram comment). This photo also included a date: January 20, 1979 (not 1973, as Hawk’s post said). But that was it. No location. No name. No back story.</span></p><p>So I turned to the people you turn to when times get tough: Librarians.</p><p><a href="https://x.com/TarHeelFoodways" rel="">John O’Connor</a><span> is the manager of the Robinson-Spangler Carolina Room at the Charlotte Mecklenburg Library. He’s also a </span><em>Rabbit Hole</em><span> reader, and he’s helped me try to find archival material in the past. I sent him a message on Sunday morning to see if his library had </span><em>Fayetteville Observer</em><span> on microfilm. No, he said, but he’d call the Cumberland County Public Library as soon as they opened in the afternoon. There, library associate Matt Morgan got the film out, found the January 21, 1979 edition of the </span><em>Fayetteville Observer</em><span>, and sent over what he found:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png" width="1048" height="1254" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1254,&quot;width&quot;:1048,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1852844,&quot;alt&quot;:&quot;scan of 1979 newspaper&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="scan of 1979 newspaper" title="scan of 1979 newspaper" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d8188e-8522-4222-959a-46ed2463aeea_1048x1254.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>There, on page 1B, was the image and the caption that had the rest of the details:</p><blockquote><p>Shaundra Shane didn’t want to get wet, but the idea of spending a Saturday without her skateboard was to much to handle. So she got her umbrella and wheeled down Dinsmore Drive.</p></blockquote><p><span>From there, I tracked down the 10-year-old girl in the picture. She’s 56 now, still lives in Fayetteville, and her name is Shaunda, not Shaundra (the caption misspelled it). I reached out Sunday night, and we talked after she got off of work on Monday afternoon. She remembers the day the picture was taken. An </span><em>Observer</em><span> photographer, the late Steve Aldridge, lived across the street from her on Dinsmore Drive. “Mr. Steve saw me out there riding my skateboard in the rain,” she says. He asked her if she could get permission from her grandparents to take a picture. He also asked if she could come back with a prop. “He wanted me to have an umbrella, so I got an umbrella,” she says. “He took that picture and that was it.”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png" width="1456" height="920" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9b72356c-16c8-453b-948f-77042873849b_2076x1312.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:920,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4286930,&quot;alt&quot;:&quot;Google map street view of Dinsmore Drive in 2023&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Google map street view of Dinsmore Drive in 2023" title="Google map street view of Dinsmore Drive in 2023" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b72356c-16c8-453b-948f-77042873849b_2076x1312.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A 2023 view from the area where the original picture was taken on Dinsmore Drive in Fayetteville (via Google Street View)</figcaption></figure></div><p>Shaunda lived with her grandparents in a neighborhood that she loved. Family and friends were all close by. She’d been a skater for about a year, ever since her uncle brought her a little pink board with metal wheels. Her friends were more into roller skating back then, but going to the rink was kind of boring, she thought. It was limiting. Skateboarding allowed her to explore. “I was free,” Shaunda says. “You’re outside. There’s the wind. There’s just, like, a freeness, you know?”</p><p>Shaunda was the only member of her group that skateboarded, and she kept doing it for years. She got faster. Started learning tricks. But she stopped skateboarding after she got her first boyfriend in middle school. As a teenager, she started spending more time with him and less time on the board. Plus, she didn’t need to skateboard to get around—he had a car.</p><p>After that, skateboarding and the image of her doing it faded from her life. “It was just a picture in the paper,” she says. At some point, a car backed over her little pink board.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>Shaunda went on living. She moved to a new place in Fayetteville. She got married and divorced. She had three kids. She started working as a patient access specialist at Cape Fear Valley Health.</p><p>Then, back in September, she got a call from a woman who still lived in her old neighborhood. She told Shaunda that she had the old picture of her skateboarding in the rain and gave it to her. A week later, the same picture started to show up on Facebook. Shaunda called up her friend, who swore that she didn’t put the image online. “I said, well, did your mom do it? And she was like, girl, my mom don’t know how to post nothing on Facebook,” she says, laughing.</p><p>It was just a coincidence. Someone online had rediscovered the picture at the same time as Shaunda’s friend. And for a while, that was it. Shaunda made it her profile picture. A few friends tagged her when they saw the image online. They made comments. They liked her ponytails. They dropped fire emojis.</p><p>Then Tony Hawk posted the picture. And then I called.</p><p><span>“It's amazing,” Shaunda says. “I kind of have butterflies, you know? I definitely do know who Tony Hawk is. I have watched Tony Hawk.” The </span><em>Fayetteville Observer</em><span> got in touch, and they’re having her re-create the photo, 45 years later (UPDATE: </span><a href="https://www.fayobserver.com/story/lifestyle/2024/11/04/who-is-the-mystery-skater-shared-by-tony-hawk-shares-fayetteville-observer-photo/76047957007/?taid=672975236877af0001c06d8e" rel="">Here’s the picture</a><span>). A local skate shop has been in touch. Her phone is blowing up.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic" width="400" height="533.2417582417582" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:400,&quot;bytes&quot;:1193953,&quot;alt&quot;:&quot;Shaunda Shane, modern day pic&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Shaunda Shane, modern day pic" title="Shaunda Shane, modern day pic" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd319cf1d-eb81-453a-af17-f81cd522a979_2316x3088.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Shaunda Shane, today.</figcaption></figure></div><p><span>Also, she had to learn what it meant to ride “goofy footed.” It’s when you ride a board with your right foot forward instead of your left. “Oh,” Shaunda says. “Well, I </span><em>am</em><span> left-handed.”</span></p><p>Shaunda said she hasn’t quite been able to re-create the freedom she felt on a board all those years ago, although riding a motorcycle comes pretty close. In any event, she doesn’t really have the time to skateboard now anyway. “I mean, literally all I do is work,” she jokes. “Trying to pay these bills.”</p><p>Her son skateboards, though. And so, months ago, she got back up on a board for the first time in years. Just for a little bit. She’s a little afraid of falling, but the picture really brings back memories of a free-ranging childhood in a nice little neighborhood. “I probably would be skateboarding now,” she says, “if I really thought I could.”</p><p><strong>MANY UPDATES (11/5/24, 9:06 a.m.):</strong><span> First up, Tony Hawk has seen this article and </span><a href="https://x.com/deftlyinane/status/1853651377840374245" rel="">name-dropped Shaunda in an Instagram story</a><span>, and Shaunda is aware that Tony Hawk has name-dropped her, but she hasn’t read this story yet because she was on her way to work. We’re all leading busy lives, people!</span></p><div data-attrs="{&quot;instagram_id&quot;:&quot;DB_l10pPUn5&quot;,&quot;title&quot;:&quot;A post shared by @tonyhawk&quot;,&quot;author_name&quot;:&quot;tonyhawk&quot;,&quot;thumbnail_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/__ss-rehost__IG-meta-DB_l10pPUn5.jpg&quot;,&quot;timestamp&quot;:null,&quot;belowTheFold&quot;:true}" data-component-name="InstagramToDOM"><p><a href="https://instagram.com/p/DB_l10pPUn5" target="_blank" rel=""><img src="https://substackcdn.com/image/fetch/w_640,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F__ss-rehost__IG-meta-DB_l10pPUn5.jpg" loading="lazy"></a></p></div><p><span>Also, the </span><em>Fayetteville Observer</em><span> posted its version of this story last night, which included the new picture of Shaunda riding a skateboard with an umbrella (</span><a href="https://www.fayobserver.com/story/lifestyle/2024/11/04/who-is-the-mystery-skater-shared-by-tony-hawk-shares-fayetteville-observer-photo/76047957007/?taid=672975236877af0001c06d8e" rel="">you can go to their website to see it</a><span>). The phenomenally talented </span><a href="https://www.instagram.com/aacraft" rel="">Andrew Craft</a><span> took that photo. He’s also the one who scanned the original picture of Shaunda from 1979 and posted it online, and really, there’s no story here without him. He also </span><a href="https://www.fayobserver.com/picture-gallery/news/local/2024/11/04/from-the-archives-fayetteville-nc-skateboarders-in-the-70s-and-80s/76054303007/?taid=67296e172eec1a0001fac113" rel="">posted even </a><em><a href="https://www.fayobserver.com/picture-gallery/news/local/2024/11/04/from-the-archives-fayetteville-nc-skateboarders-in-the-70s-and-80s/76054303007/?taid=67296e172eec1a0001fac113" rel="">more </a></em><a href="https://www.fayobserver.com/picture-gallery/news/local/2024/11/04/from-the-archives-fayetteville-nc-skateboarders-in-the-70s-and-80s/76054303007/?taid=67296e172eec1a0001fac113" rel="">historical photos of skateboarders</a><span> around Fayetteville, including another archival shot of Shaunda skateboarding with two friends. Check it out.</span></p><p><span>Lastly, a correction: I originally said that riding goofy foot meant riding with your left foot forward. It’s actually the opposite, which I would have known had I been paying attention TO THE PICTURE THAT I BASED THIS ENTIRE STORY ON. Anyhow, I regret the error. My penance shall be listening to the </span><a href="https://tonyhawkgames.fandom.com/wiki/Tony_Hawk%27s_Pro_Skater_2_Soundtrack" rel="">Tony Hawk’s Pro Skater 2 soundtrack</a><span> for the rest of the day (which I was gonna do anyway).</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979/comments" rel=""><span>Leave a comment</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla Foundation lays off 30% staff, drops advocacy division (180 pts)]]></title>
            <link>https://techcrunch.com/2024/11/05/mozilla-foundation-lays-off-30-staff-drops-advocacy-division/</link>
            <guid>42054867</guid>
            <pubDate>Tue, 05 Nov 2024 20:29:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/11/05/mozilla-foundation-lays-off-30-staff-drops-advocacy-division/">https://techcrunch.com/2024/11/05/mozilla-foundation-lays-off-30-staff-drops-advocacy-division/</a>, See on <a href="https://news.ycombinator.com/item?id=42054867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">The Mozilla Foundation, the nonprofit arm of the Firefox browser maker Mozilla, has laid off 30% of its employees as the organization says it faces a “relentless onslaught of change.”</p>

<p>When reached by TechCrunch, Mozilla Foundation’s communications chief Brandon Borrman confirmed the layoffs in an email.</p>







<p>“The Mozilla Foundation is reorganizing teams to increase agility and impact as we accelerate our work to ensure a more open and equitable technical future for us all. That unfortunately means ending some of the work we have historically pursued and eliminating associated roles to bring more focus going forward,” read the statement shared with TechCrunch.</p>

<p>According to its annual tax filings, the Mozilla Foundation <a href="https://projects.propublica.org/nonprofits/organizations/200097189" target="_blank" rel="noreferrer noopener nofollow">reported having 60 employees</a> during the 2022 tax year. The number of employees at the time of the layoffs was closer to 120 people, according to a person with knowledge. When asked by TechCrunch, Mozilla’s spokesperson did not dispute the figure.</p>

<p>This is the second layoff at Mozilla this year, the first <a href="https://techcrunch.com/2024/02/13/mozilla-downsizes-as-it-refocuses-on-firefox-and-ai-read-the-memo/">affecting dozens of employees</a> who work on the side of the organization that builds the popular Firefox browser.</p>

<p>Mozilla is <a href="https://www.mozilla.org/en-US/about/governance/organizations/" target="_blank" rel="noreferrer noopener nofollow">made up of several organizations</a>, one of which is the Mozilla Corporation, which develops Firefox and other technologies, and another is its nonprofit and tax-exempt Foundation, which oversees Mozilla’s corporate governance structure and sets the browser maker’s policies.</p>

<p>Much of Mozilla’s work focused on advocating for privacy, inclusion, and decentralization of technologies, and “to create safer, more transparent online experiences for everyone,” which ultimately benefit the browser maker and its users.</p>

<p>Announcing the layoffs in an email to all employees on October 30, the Mozilla Foundation’s executive director Nabiha Syed confirmed that two of the foundation’s major divisions — <a href="https://blog.mozilla.org/en/mozilla/mozilla-welcomes-ashley-boyd-vp-of-advocacy/" target="_blank" rel="noreferrer noopener nofollow">advocacy</a> and <a href="https://foundation.mozilla.org/en/blog/welcoming-j-bob-alotta-mozilla-foundations-new-vp-global-programs/" target="_blank" rel="noreferrer noopener nofollow">global programs</a> — are “no longer a part of our structure.” </p>

<p>After publication, Borrman told TechCrunch that “advocacy is still a central tenet of Mozilla Foundation’s work and will be embedded in all the other functional areas,” without providing specifics.</p>

<p>The move, according to Syed, is in part to produce a “unified, powerful narrative from the Foundation,” including revamping the foundation’s strategic communications.</p>







<p>“Our mission at Mozilla is more high-stakes than ever,” wrote Syed in an email to staff, a copy of which was shared with TechCrunch. “We find ourselves in a relentless onslaught of change in the technology (and broader) world, and the idea of putting people before profit feels increasingly radical.”&nbsp;</p>

<p>“Navigating this topsy-turvy, distracting time requires laser focus — and sometimes saying goodbye to the excellent work that has gotten us this far because it won’t get us to the next peak. Lofty goals demand hard choices,” wrote Syed.</p>

<p>Syed, who joined <a href="https://foundation.mozilla.org/en/blog/mozilla-foundation-welcomes-nabiha-syed-as-executive-director/" target="_blank" rel="noreferrer noopener nofollow">the Mozilla Foundation in February</a>, previously served as chief executive at data journalism and investigative news site The Markup.</p>

<p><em>Updated with comment from Mozilla.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Traceroute Isn't Real (146 pts)]]></title>
            <link>https://gekk.info/articles/traceroute.htm</link>
            <guid>42054835</guid>
            <pubDate>Tue, 05 Nov 2024 20:22:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gekk.info/articles/traceroute.htm">https://gekk.info/articles/traceroute.htm</a>, See on <a href="https://news.ycombinator.com/item?id=42054835">Hacker News</a></p>
<div id="readability-page-1" class="page">
<p><strong><a href="https://gekk.info/">gekk.info</a> « <a href="https://gekk.info/articles/index.html">articles</a></strong></p>




<h2>Traceroute isn't real, or: Whoops! Everyone Was Wrong Forever</h2>



<p>There is no such thing as traceroute.</p>
<p>I used to deliver network training at work. It was freeform, I was given wide latitude to design it as I saw fit, so I focused on things that I had seen people struggling with - clearly explaining VLANs in a less abstract manner than most literature, for instance, as well as actually explaining how QoS queuing works, which very few people understand properly.</p>
<p>One of the "chapters" in my presentation was about traceroute, and it more or less said <em>"Don't use it, because you don't know how, and almost nobody you'll talk to does either, so try your best to ignore them."</em> This is not just my opinion, it's backed up by people much more experienced than me. For a good summary I highly recommend <a href="https://www.slideshare.net/RichardSteenbergen/a-practical-guide-to-correctly-troubleshooting-with-traceroute" target="_blank" rel="nofollow noopener noreferrer">this presentation</a>.</p>
<p>But as good as that deck is, I always felt it left out a crucial piece of information: Traceroute, <em>as far as the industry is concerned</em>, does not exist.</p>
<p>Look it up. There is no RFC. There are no ports for traceroute, no rules in firewalls to accommodate it, no best practices for network operators. Why is that?</p>
<h3>Traceroute has no history</h3>
<p>First off: Yes, there <em>is</em> a traceroute RFC. It's <a href="https://datatracker.ietf.org/doc/html/rfc1393" target="_blank" rel="nofollow noopener noreferrer">RFC1393</a>, it's 31 years old, and to my knowledge nothing supports it. The RFCs are jam-packed with brilliant ideas nobody implemented. This is one of them. The traceroute we have is completely unrelated to this.</p>
<p>Unsurprisingly however, it's a good description of how a traceroute protocol <em>should</em> work. You send a packet to a given destination, with a special flag set, and any machine it passes through observes the flag and says "oh, this packet is meant to be traced," so it generates an ICMP Traceroute response and sends it back to the originating host.</p>
<p>The host, then, sends a single packet and receives a flood of responses describing the path that packet took, definitively. Great! Or, I mean, it would be, if anything supported it. And if it was 1993.</p>
<p>As the linked presentation explains, traceroute simply no longer works in the modern world, at least not "as designed" - and it no longer <em>can</em> work that way, for several reasons not the least that networks have been abstracted in ways it did not anticipate.</p>
<p>There are now things like MPLS, which operate by encapsulating IP - in other words, putting a bag over a packets head, throwing it in the back of a van, driving it across town and letting it loose so it has no idea how far it's traveled. Without getting much further into how that works: It is completely impossible for it to satisfy the expectations of traceroute.</p>
<p>This "tool" works purely at layer 3, so it's impossible for it to adapt to the sort of "layer 12-dimensional-chess" type shenanigan that MPLS does - and there are other problems, but they're all getting ahead of reality, since traceroute never even worked correctly as intended, and there's no reason it would.</p>
<p>Traceroute, you see, is "clever," which is an engineering term that means "fragile." When programmers discover something "clever," any ability they may have had to assess its sustainability or purpose-fit often goes out the window, because it's far more important to embrace the "cleverness" than to solve a problem reliably.</p>
<p>The RFC process is likely not perfect - it's basically an enormous committee system, so, that's troubling - but it does at least constitute a review and consensus process. Had someone written out a spec for traceroute, and then vendors had agreed to implement it, that would be one thing. But that is not what happened.</p>
<h3>Traceroute is a filthy hack</h3>
<p>From the traceroute man page (1987):</p>
<pre>Implemented by Van Jacobson from a suggestion by Steve Deering.
Debugged by a cast of thousands with particularly cogent
suggestions or fixes from C. Philip Wood, Tim Seaver and Ken Adelman.</pre>
<p>I can't find any proper history of the tool, but my <em>impression</em> and my <em>assumption</em> is that it is simply a behavior that someone <em>noticed was possible</em>. Engineers did not get together and design a system for this; some people just realized that it was <em>a side effect of other network behavior not intended to accomplish this goal.</em></p>
<p>In other words, it's an exploit, and that is really the best way to describe both how it works, and why it's a bad idea.</p>
<hr>
<p><strong>Here's how traceroute works:</strong></p>
<p>When you send a packet to a destination, it often has to go through multiple routers, or "hops."</p>
<p>To prevent packets from cycling indefinitely in a network due to routing loops (router A points to router B which points to router A...) they include a Time-To-Live field, which is set to a reasonably high value when a packet is created, and each machine that the packet passes through decrements that field by one.</p>
<p>When the field hits zero, the packet gets thrown away. <em>As a courtesy,</em> the router that's dropping the packet has the <em>option</em> to generate a new packet, using the ICMP protocol, with the subtype <em>"TTL Exceeded,"</em> and send it back to the originating machine, to let it know there's something wrong with the network path.</p>
<p>These clever fellows in 1987 realized that by manipulating the TTL value, you can choose which router will send that ICMP message.</p>
<p>Send a packet with the TTL set to 1. The first router you hit will decrement it to zero. The packet is now "dead", so it drops the packet, and sends back TTL Exceeded. That response will originate from the router's own IP address - congratulations, you now have the IP of the first hop.</p>
<p>Now send another with the TTL set to 2. The first router will decrement it to 1 and pass it, and the <em>second</em> one will decrement to zero and drop it. Now you have <em>its</em> IP address.</p>
<p>Repeat, increasing TTL each time, until the final hop responds. You now have your complete path.</p>
<hr>
<p>This is indeed quite clever, but don't lose sight of what is going on here. TTL Exceeded is simply <em>not meant for this.</em> It is a message meant to diagnose a specific, unrelated kind of network malfunction. It's not intended for tracing paths, and for reasons I'll explain, it's also exactly the kind of feature that may exist in a lab, and in the first few experimental networks, but gets abandoned as soon as money enters the picture.</p>
<h3>DJ Shadow - Why Hip Hop Sucks In 96 (It's The Money)</h3>
<p><em>TTL Exceeded</em> is not a "feature."</p>
<p>Features are things that enable functionality. It doesn't do that.</p>
<p>Features are things that affect end-user experience. It doesn't do that.</p>
<p>TTL Exceeded is purely informational. It's useful to exactly one person: a network engineer. It would be absolutely untenable to report this sort of error to an end user, since there's positively nothing they can do about it, so no application will ever do this.</p>
<p>Not only were these messages not intended for end users, they weren't even intended for network operators as we know them now.</p>
<p>In 1987, virtually every network admin could get an email address for the admin of pretty much any other network, worldwide, with a couple phone calls or a whois lookup. That meant it was practical to troubleshoot <em>other peoples networks</em>, which are often where these errors are seen. Nowadays? Forget about it. Hah. Wow. <em>No way.</em></p>
<p>If you get a TTL Exceeded while trying to reach another host through the <em>internet</em>, there is a zero percent probability that you can get traction on your problem unless you are a Fortune 500 - and even then it will be tough. At least half the companies that are likely to be involved simply do not provide any form of support for problems involving less than millions of hosts.</p>
<p>It is, generally speaking, not possible to call AT&amp;T and say "Hey, when I try to ping one of your subscribers in California from a Level3 circuit in New York, I'm hitting a routing loop." I have worked for an ISP with direct peering with those networks and that simply never worked. We got incompetent, consumer-grade support techs and the issue went nowhere, if we even had a contact at all.</p>
<p>It's even harder to call the exchange partners, the network providers that may sit in between AT&amp;T and Level3 in this equation. Nobody will even tell you who they are, and if they did, <em>there is simply nobody to call.</em> Those phone numbers don't exist unless you're a network engineer at one of their direct partners who is calling to report that a fiber port is down.</p>
<p>No, AT&amp;T is not going to push your complaint up the line to XO. Haha. No.</p>
<p>Problems like this are fairly rare these days, which makes it even less likely that anyone will be on hand to work on them. Most of the time, IME, they get resolved through Brownian Troubleshooting: large scale network maintenance happens for unrelated reasons and <em>incidentally</em> fixes the problem.</p>
<p>So traceroute, on an internet scale, has been useless for ages. You think you see a routing problem? So what? There's absolutely nothing you can do about it.</p>
<p>With that information, go ahead and ask yourself if you think anyone, at any network hardware company, has given a shit about implementing TTL Exceeded since the 90s. The answer is obvious: No. Without a doubt, this is not on anyone's priority list.</p>
<p>If you're at Juniper, nobody is clamoring for this. You do not have ISPs threatening to switch to Cisco (lmao!) just because you didn't implement TTL Exceeded correctly, because they aren't using it. The kind of problems ISPs care about are "we lost the entire US northeast" or "we can't reach Comcast, at all." The NOCs involved at that point may use traceroute, but they will get by without it. Nobody is going to make a C-level escalation with Juniper over it.</p>
<p>So, as a network hardware vendor, with a certain budget and a whole galaxy of internet standards to implement, are you going to put time into this? Absolutely not.</p>
<p>Academics, perhaps. People doing research and experiments at universities 35 years ago might have stuck to the specs religiously, but there is <em>no financial reason whatsoever to implement this correctly.</em></p>
<p>But then, we're ahead of ourselves again. Because what is a "correct" implementation?</p>
<h3>Nothing involving a router is "correct", but</h3>
<p>RFC 792, <em>"INTERNET CONTROL MESSAGE PROTOCOL",</em> explains how to implement TTL Exceeded (which I believe is technically called "Time Exceeded"):</p>
<pre>   Description

      If the gateway processing a datagram finds the time to live field
      is zero it must discard the datagram.  The gateway <em>may</em> also notify
      the source host via the time exceeded message.

      If a host reassembling a fragmented datagram cannot complete the
      reassembly due to missing fragments within its time limit it
      discards the datagram, and it <em>may</em> send a time exceeded message.</pre>
<p>Anyone who knows how to read an RFC understands the crushing solemnity of MAY.</p>
<p>Something that you MAY do is something that WILL NOT be done when it counts. MAY, in RFC terminology, means exactly what the dictionary says it should: The implementer can do it if they want.</p>
<p>That means that it is "standards-compliant" to create a router that has absolutely no implementation of ICMP TTL Exceeded. "May" can mean "never." It is completely up to the vendor.</p>
<p>And wouldn't you know it: vendors <em>do</em>, in fact, choose to <em>never</em> send these messages, and for good reason: It's hard!</p>
<p>The linked presentation (seriously! read it! please! you will benefit!) addresses why this is, and in short it comes down to the fact that routers are basically supercomputers. Consider that a core router at an ISP is potentially handling <em>billions</em> of packets per second. Running all that through a conventional CPU is absurd, and nobody has done this in decades.</p>
<p>Instead, routers contain custom, purpose-built hardware - called the <em>data plane</em> - consisting of dedicated silicon with the sole ability to look at <em>the parts of a packet that matter for routing purposes</em> and ask a couple very simple questions, e.g. <em>"Do I have a way to get this to its next hop?"</em> and <em>"does it still have time to live?"</em></p>
<p>There are probably other details, but you get my point - it's <em>highly</em> optimized.</p>
<p>99.99% of the packets that pass through such a device simply come in one port, get glanced at, and are then hurled out of another port so the silicon can get on to the next packet. During all of this, the actual <em>computer</em> part of the router, the thing that can make complex decisions, is idle.</p>
<p>Yes, routers do contain general-purpose computers; they're pitiful little things. From the linked presentation (read it!!):</p>
<pre>A 320-640+ Gbps router may only have a 600MHz CPU
ICMP generation is <em>NOT</em> a priority for the router.
</pre>
<p>Yeah. The CPU is... Not Fast.</p>
<p>As I implied, this is how supercomputers often work: you have a <em>massive</em> array of extremely fast processors, that can only solve certain, very well defined kinds of problems, and then off to the side you have some horrible little Core i3 Ideapad Yoga whose sole job is to feed program and data into the thing and then pull the string on its back.</p>
<p>With a supercomputer, feeding it invalid data will simply crash the process and you'll have to start all over. That's not an option with networks, since you can't control the incoming data, so routers need a way to handle exception scenarios. That's where the computer - known as the <em>control plane</em> - comes in.</p>
<p>In addition to feeding configs to the data plane, the control plane CPU is responsible for handling unexpected situations. If an interface goes down, the data plane simply starts dropping packets (if it has no other paths.) It takes no other actions; it's the control plane's job to notice this event and do something about it, e.g. sending SNMP traps so someone in a NOC can investigate.</p>
<p>I don't know how many <em>TTLs</em> get <em>Exceeded</em> these days, but even if a router sees tons of them every day, there's nothing it can do to fix the problem, and sending TTL Exceeded is a <em>MAY</em>, not a <em>MUST</em>, so no vendor is going to spend an extra $100,000 to design circuitry to generate and return those responses. That means that any packet that runs out of TTL will have to get forwarded to the control plane, which will decide if and when to send a response.</p>
<p>It goes without saying that the control plane is a very busy little bee. It's bad enough that it has to handle all the "exceptions", which are going to be <em>plentiful</em> in a carrier network with millions of hosts passing through it, but it <em>also</em> has to handle any actual self-destined traffic.</p>
<p>In addition to the millions of hosts that an internet router has to arbitrate between, it also has its own IP addresses, which people rudely try to interact with all day long. When you ping a router, you're making that poor little 600MHz ARM chip find time to deal with your traffic, <em>not</em> the terabit-per-second monster that it's married to. Same goes for SNMP queries, regular config backups, and other forms of management access.</p>
<p>Other than traceroute, <em>TTL Exceeded</em> serves very little purpose in the modern world, and with traceroutes being such a tiny percentage of traffic, it is perfectly reasonable for network admins to not care if it works or not. When you put all this together, it becomes apparent that most network providers are never going to spend a second thinking about this.</p>
<p>You can easily confirm this is true. Run a traceroute... anywhere. Yahoo dot com. You will see nodes that never respond, 9 times out of 10.</p>
<h3>The Worst Diagnostics In The World</h3>
<p>I cannot even guess how many times I have seen network techs see one hop not respond and say "well it looks like hop 5 is down, so that's your problem," even though hop 6 is responding.</p>
<p>It is impossible for me to imagine how they think the internet works, but they're playing against a stacked deck, because traceroute is just <em>the worst diagnostic tool imaginable.</em></p>
<p>A good tool gives you a go, a no-go, or information. That is, it tells you something is working, or broken, or provides data you can interpret.</p>
<p>Traceroute does provide a single "go" outcome: If you see a trace get <em>all the way through to the last node</em>, well, okay, that's a success. The path is probably fine.</p>
<p>However, it also only provides a single "no-go" outcome, and it's not the one people think. Lack of response from hosts is not a failure. The <em>sole</em> failure you can identify reliably from traceroute is a network loop. If you see the same pair of nodes respond over and over, then you have a loop.</p>
<p>...and that information is almost completely useless, because this is the exact problem that TTL Exceeded is meant to diagnose, so you can just use it as intended. Just ping the target, and you'll see a TTL Exceeded response from one of the two routers that is looping the packet, identifying the failure point. Admittedly, traceroute does tell you <em>both</em> of those names, which is convenient.</p>
<p>Inadvertent routing loops are incredibly rare however, and 99% of the ones that I have seen were actually caused by network interfaces being down, and would have been discovered and resolved through ordinary, thorough network review.</p>
<p>As far as information? Well, read the presentation. The information provided by traceroute is limited, objectively incorrect and misleading in many cases, and fiendishly hard to interpret.</p>
<p>Lack of response from a node means nothing.</p>
<p>Even if <em>all</em> the nodes past a certain point aren't responding, <em>that also means nothing.</em></p>
<p>If the nodes have high latency, <em>that also means nothing.</em></p>
<p>If they respond on some probes and not others, <em>that also means nothing.</em></p>
<p><em>Nothing you see in a traceroute means anything, because it is all accidental.</em></p>
<p>You are sending a packet through a network that <em>did not plan for it</em>. Nobody has taken steps to ensure your traceroute should succeed. There are no "Traceroute" checkboxes or statements in router configs. There's a really spicy reason for that, too: Traceroute does not even meet the most minimal definitions of a network protocol.</p>
<p>It's not a special kind of ICMP message, or a UDP or TCP packet that uses a defined port. You cannot "permit traceroute" in a firewall, because it has no standard characteristics. A lot of people think traceroute sends pings - this is an option, but never the default behavior AFAIK.</p>
<p>By default, traceroute simply sends <em>a gibberish UDP packet on a random pair of ephemeral ports.</em> The entire point is to be thrown away before a host even gets a <em>chance</em> to consume it, so the contents are irrelevant.</p>
<p>That means that if you were <em>trying</em> to prepare a network to handle traceroute, you wouldn't be able to. From a network perspective, traceroute does not exist.</p>
<p>It's simply an exploit, a trick someone discovered, so it's to be expected that it has no defined qualities. It's just random junk being thrown at a host, hoping that everything along the paths responds in a way that they are <em>explicitly not required to.</em> Is it any surprise that the resulting signal to noise ratio is awful?</p>
<h3>So What Does All This Mean</h3>
<p>It means that you can't run a traceroute unless you <em>know what you expect to see.</em></p>
<p>When you're tracing inside a network that you control - such as a large enterprise WAN, multiple sites connected with VPNs, or an ISP that you work for - you can guess what each hop will look like, or at least look at the results and suss out whether they looks like they "should."</p>
<p>If you trace from, say, a server at one business location to one at another, you might see your local prem router, then a network edge router, a few core routers, another edge and then another prem router.</p>
<p>From this you can guess, pretty reliably, that you made it all the way to the destination, but either had trouble reaching the specific host (investigate the local router/firewall) or that the host is ACLed or doesn't send ICMP responses (do packet captures on the host.)</p>
<p>If you're tracing through a network you don't control, you have <em>no idea</em> how it's supposed to work. If you're a seasoned network tech who's seen some shit (and, ideally, worked on provider-scale networks) then you can run a traceroute over an unknown network and <em>maybe, possibly,</em> suss out something, but there are no guidelines, it's pure gut feeling: <em>does this look right?</em></p>
<p>If you aren't that experienced however, you should avoid it, because you are not immune to propaganda. When you see high latency, hops not responding or whatever, that information will stick in your head. Despite your best efforts, it will affect the course of your troubleshooting even though you would not be able to say, if asked, what those results <em>meant</em> and what should be <em>done with them.</em></p>
<p>As a diagnostician, you should ask yourself one question before performing any test: <em>"What would I do if the outcome was x? And what if it was y?"</em></p>
<p>Can you fill in x and y? Can you answer either question? If not - why run the test?</p>
<p>And if you <em>do</em> run the traceroute anyway, <em>god forbid</em> you mention it to someone else. Do not write down the results unless you think you actually know what they mean, because no matter how offhandedly you do it, whoever comes across it is <em>guaranteed</em> to see it as a lifeline.</p>
<p>Network techs are mostly incompetent. It is a sad truth, and it's not their fault. People get pressed into jobs that they are told are far less complicated than they actually are. It has been my experience that <em>easily</em> 75% of people working networking jobs are operating in a state of absolute terror, trying to keep their head above water with problems they don't really understand at all.</p>
<p>If you say "hop five isn't responding," congratulations - you just identified "the cause of the problem" as far as all those folks are concerned, and there's no way to get that piss out of the pool.</p>
<p>Whoever you said it in front of is going to refuse, <em>aggressively</em>, to do a lick of additional troubleshooting until "hop five" starts responding. If that's clearly a node that nobody on the conf call or email thread has access to, then everyone's going to throw up their hands and say "Well I Guess We Just Have To Hope It Starts Working." I have seen this countless times.</p>
<p>It happens because, fundamentally, troubleshooting networks <em>sucks.</em></p>
<p>If you don't have total control of the entire path, end to end, with admin access <em>and</em> expertise on every node along the way, there is no way to get a complete picture of what's going on. That kind of access is extremely rare; you're probably a high-ranking network architect if you have it; and <em>even with all that access</em> there are still plenty of cases where you simply cannot see what's wrong, because it's happening either too fast, or in a place that's impossible to inspect.</p>
<p>As a result, networking is full of superstition. People casting spells, executing words of power, trying to read tea leaves and declaring that the end times are coming, not because the hard info isn't available, but because it's incredibly difficult to obtain and interpret.</p>
<h3>The Thanksgiving Uncle Problem</h3>
<p>Read the presentation. It does a better job than this messy post at illustrating the problem. Even if you don't understand networking, by the time you're done, you will be convinced that this is too complicated for <em>most people</em>, full stop. There are just too many unknowns.</p>
<p>You will hate me for making you read this. You will regret it, because you will now be the only person in every conversation who understands these things, and the knowledge is damning. You will have to sit, silently, as everyone around you makes egregious errors in diagnostics that lead them down completely incorrect paths. This is the <em>Thanksgiving Uncle Problem.</em></p>
<p>That's the situation where you, a gay leftist, go to Thanksgiving dinner with the family, and a shitty uncle sits across from you and begins telling lies about society, about people of color, about gay marriage, and so on. If you're self-destructive, you engage him. It will not go well.</p>
<p>The reason for this is that, in order for him to accept <em>anything</em> you say, he needs to accept that many of his foundational beliefs about the world are wrong. Ideas like "the police protect us" and "children need a mom and a dad" have been part of his worldview for so long that he has, without question, made <em>millions</em> of decisions based on these assumptions.</p>
<p>In order for him to discard them, he has to admit that he has been making a fool of himself, doing incredibly wrong and often <em>harmful</em> things, for his entire life. That is too much guilt to handle, and he - and most people - will do anything possible to avoid accepting it. Certainly, this is not a door he's willing to open when he's on his fourth mimosa and doing his best not to think about the goddamn insurance adjuster job he has to go back to on Monday.</p>
<p>So you will read this slideshow, and then you will sit on conference calls thinking, "My god. They are all wrong. And they've always been wrong. And <em>I can't help them,</em> because they will fight me tooth and claw to continue being wrong."</p>
<p>I have no advice on how to deal with this, but it's better to be correct than to be comfortable.</p>
<p><small>Footnote: Ironically, it seems very possible to me that the systems that most consistently enable this are the cheapest routers on the market. Every single home "gateway" ever sold runs Linux, where the ICMP implementation is a core kernel feature, not a user provided daemon.</small></p><small>
<p>I would not be surprised at all if the Linux kernel devs actually <em>have</em> made sure that TTL Exceeded is implemented and enabled by default - and since most Linux-based routers do everything in pure software, there is no data/control plane split to worry about, so sending an Exceeded is more or less "free."</p>
</small><p><small>This would only make a difference for traceroute if Linux was used for anything other than the cheapest endpoint routers, but it's still very funny.</small></p>
<hr>
<h2>Addendum #1</h2>
<p>I reviewed that slide deck again and learned that I conflated a couple concepts.</p>
<p>Yes, the control plane <em>may</em> be responsible for handling exceptions, including ICMP generation, but it is apparently more likely (at least, at the scale of equipment that I am discussing) that the data plane has a <em>fast path</em> and <em>slow path</em>, both located in the data plane, and the slowpath is responsible for handling this work. The control plane, in such a device, <em>only</em> handles data destined to the router's own IP.</p>
<p>However, the slowpath is (per Richard Steenbergen, the author of that presentation; we will trust his research is valid) <em>still</em> a general-purpose CPU instead of custom silicon, so functionally, the point I was making is still valid: There is a very slow computer handling these packets.</p>
<p>Steenbergen uses this fact to make the point that, because these slow-path CPUs <em>are</em> so slow, they are usually rate-limited. Yes, this means that <em>some number of TTL Exceeded messages will simply be thrown away, even if they are enabled.</em></p>
<p>The example given is that a handful of users running MTR (do not get me started on this bastard program) can actually hit this rate limit. This is an outstanding example because I have seen something similar in practice.</p>
<p>Consider what that would look like, and how common it would be: If you have a NOC full of people who think they know what they're doing, but don't, that only enhances the probability that everyone is trying to troubleshoot on their own instead of doing a screenshare and coordinating their efforts - thus, you have six guys running MTR to the same IP.</p>
<p>If they hit that rate limit, what do they see? Nodes suddenly not responding! Randomly, in fact - sometimes responding, sometimes not! That means it's not just a hop that doesn't respond to traceroutes, but <em>packet loss!</em> Wow! We found the problem!</p>
<p>Of course, if four of them hit Ctrl+C, the PL would mysteriously vanish. Huh! Weird! Well, it must be an intermittent issue in <em>squints at resolved hostname</em> Hurricane Electric's network. I'm <em>sure</em> they have a flapping port they haven't noticed (lol.) Just send them a trouble ticket!</p>
<p>By the time this useless waste of effort has resolved (e.g. HE has received, acked, investigated, and declared the ticket No Trouble Found and rejected it) the problem has probably gone away due to unrelated network weather effects. The NOC guys all tell each other that HE was lying about their broken network, slap each other on the back for being smarter than the other bastards, and go out for beers.</p>
<p>How do I know this? Because I've been part of it!</p>
<p>My employer used to have an unholy number of customer sites terminated with little Linux shitboxes - you know the sort, they used to be common as dirt. Tiny Soekris-esque SBCs in folded sheet metal boxes with 12V power supplies, running horrible little SoCs and a copy of Busybox from before the fall of Rome. We had reasons for it that I won't go into.</p>
<p>These things were underpowered to put it mildly. They could route maybe 30 mbps, and if you turned on any firewall functionality that dropped to 10. This was at a time when a <em>tremendous</em> number of customers were on connections no faster than 5 mbps, so, this wasn't a huge problem. We got rid of them all when bandwidths skyrocketed.</p>
<p>But what used to happen is that you'd have three or four people looking at one of these things at once, and you'd start seeing packet loss. And there you go, the customer has a bad connection. Kick it to the ISP and close the ticket, right?</p>
<p>I can't count how many times this happened, but I do remember after about four years of doing this, I had come up with a method for getting more accurate latency stats: just ping -i .1. Absolutely <em>hammer</em> the thing with pings while you have the customer test their usual business processes, and it'll be easier to see latency spikes if something is eating up too much bandwidth.</p>
<p>What I discovered is that running two of these in parallel would produce exactly 50% packet loss, with total reliability. I then tested and found that if I just fired up three or four <em>normal</em> pings, at the default interval, it would do the same thing. 30% or 40% packet loss.</p>
<p>There is no telling how many issues we prolonged because everyone was running their own pings simultaneously and the kernel was getting overloaded and throwing some of them out. This is a snapshot of every network support center, everywhere. It is a bad scene.</p>

	<p><a href="https://gekk.info/articles/index.html">List of Articles</a></p>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Companies Are Ditching the Cloud: The Rise of Cloud Repatriation (182 pts)]]></title>
            <link>https://thenewstack.io/why-companies-are-ditching-the-cloud-the-rise-of-cloud-repatriation/</link>
            <guid>42054813</guid>
            <pubDate>Tue, 05 Nov 2024 20:19:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/why-companies-are-ditching-the-cloud-the-rise-of-cloud-repatriation/">https://thenewstack.io/why-companies-are-ditching-the-cloud-the-rise-of-cloud-repatriation/</a>, See on <a href="https://news.ycombinator.com/item?id=42054813">Hacker News</a></p>
Couldn't get https://thenewstack.io/why-companies-are-ditching-the-cloud-the-rise-of-cloud-repatriation/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Fisker EVs Hired an IT Spy Who Funneled Millions to N. Korea's Missile Program (132 pts)]]></title>
            <link>https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi</link>
            <guid>42054791</guid>
            <pubDate>Tue, 05 Nov 2024 20:16:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi">https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi</a>, See on <a href="https://news.ycombinator.com/item?id=42054791">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    <strong><span>Follow us today...</span></strong>
    <a href="https://www.facebook.com/sharer.php?u=https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi" target="_blank">
      <img src="https://www.torquenews.com/profiles/torquenews/facebook.png" loading="lazy" width="64" height="64" alt="Facebook icon">
    </a>&nbsp;
    <a href="https://x.com/share?text=Fisker+EVs+Hired+An+IT+Spy+Who+Funneled+Millions+To+North+Korea%E2%80%99s+Missile+Program%2C+CEO+Henrik+Fisker%2C+Says+%E2%80%9CThe+Case+Is+With+the+FBI%E2%80%9D%20-%C2%A0via%C2%A0@torquenewsauto&amp;url=https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi">
      <img src="https://www.torquenews.com/profiles/torquenews/x.png" loading="lazy" width="64" height="64" alt="X icon">
    </a>&nbsp;
    <a href="https://t.me/teslaev" target="_blank" title="Join us on Telegram!">
      <img src="https://www.torquenews.com/profiles/torquenews/telegram.png" loading="lazy" width="64" height="64" alt="Telegram icon">
    </a>&nbsp;
    <a href="https://www.reddit.com/submit?url=https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi&amp;title=Fisker+EVs+Hired+An+IT+Spy+Who+Funneled+Millions+To+North+Korea%E2%80%99s+Missile+Program%2C+CEO+Henrik+Fisker%2C+Says+%E2%80%9CThe+Case+Is+With+the+FBI%E2%80%9D" target="_blank" title="Join us on Reddit!">
      <img src="https://www.torquenews.com/profiles/torquenews/reddit.png" loading="lazy" width="64" height="64" alt="Reddit icon">
    </a>
  </p><div><p>Welcome to the shocking world of automotive espionage.&nbsp;</p>
<p>It appears North Korea is targeting U.S. automakers. A report from <a href="https://www.autonews.com/manufacturing/an-fisker-hired-north-korean-spy/" target="_blank">Automotive News</a> (by subscription) reveals that <a href="https://www.torquenews.com/fisker" target="_blank">Fisker Inc.</a>, the <a href="https://www.fiskerinc.com/" target="_blank">Ocean SUV electric car</a> manufacturer located in Manhattan Beach, California, hired an IT worker who was a spy for the North Korean government to steal money for its missile program.&nbsp;</p>
<blockquote><p>
AN says, "A remote information technology employee hired by&nbsp;Fisker Inc.&nbsp;turned out to be a spy for the North Korean government."
</p></blockquote>
<p>North Korea targeted Fisker and other automakers.</p>
<p>The report from the Danish magazine The Engineer said Fisker was among numerous U.S. automobile companies targeted by a money laundering scheme that funneled more than a staggering $6 million to North Korea's ballistic missile program.</p>
<blockquote><p>
AN says, "The story, based on documents filed by the U.S. Department of Justice, says Fisker hired a remote IT worker named Kou Thao in October 2021. But Thao's purported address in Arizona belonged to a woman named Christina Chapman, who set up laptop computers that the North Koreans accessed through Russia and China."
</p></blockquote>
<p>Fisker filed for bankruptcy shortly after firing the spy.&nbsp;</p>
<p>Fisker terminated Thao in September 2023 after the Justice Department notified the electric vehicle maker that it was being scammed. The financial strain caused by the espionage activities could have led to <a href="https://www.reuters.com/business/autos-transportation/ev-startup-fisker-files-bankruptcy-2024-06-18/" target="_blank">Fisker&nbsp;filing for bankruptcy</a>&nbsp;nine months later, in June 2024.</p>
<p>The report says Fisker wasn't the only automaker targeted by the spy. The Justice Department's April indictment of Chapman identifies one of her co-conspirators as "Frank C.," a contractor who worked for "a Fortune 500 iconic American automotive manufacturer located in Detroit, Michigan," starting in April 2022.&nbsp;</p>
<p>The Justice Department document doesn't name the company. Two American Fortune 500 automakers are in Detroit, Michigan: General Motors and Ford Motor Company.&nbsp;</p>
<p>The <a href="https://www.wsj.com/tech/north-korean-spies-are-infiltrating-u-s-companies-through-it-jobs-e45a1be8" target="_blank">Wall Street Journal</a> (by subscription) report says that North Korean spies are infiltrating U.S. companies through IT jobs, and companies unknowingly hire North Koreans for hundreds of low-level jobs, "giving Pyongyang access to cash and IP."</p>
<p>The FBI is aware of the problem.</p>
<p>The FBI warned companies about North Korea's highly tailored, difficult-to-detect social engineering campaigns against employees of decentralized finance ("DeFi"), cryptocurrency, and similar businesses to deploy malware and steal company cryptocurrency.</p>
<p>The FBI issued this public service announcement on September 3, 2024.</p>
<p><em>The Democratic People's Republic of Korea ("DPRK" aka North Korea) is conducting highly tailored, difficult-to-detect social engineering campaigns against employees of decentralized finance ("DeFi"), cryptocurrency, and similar businesses to deploy malware and steal company cryptocurrency.</em></p>
<p><em>North Korean social engineering schemes are not just complex, but also elaborate, often compromising victims with sophisticated technical acumen. Given the scale and persistence of this malicious activity, even those well-versed in cybersecurity practices can be vulnerable to North Korea's determination to compromise networks connected to cryptocurrency assets.</em></p>
<p><em>North Korean malicious cyber actors researched various targets connected to cryptocurrency exchange-traded funds (ETFs) over the last several months. This research included pre-operational preparations suggesting North Korean actors may attempt malicious cyber activities against companies associated with cryptocurrency ETFs or other cryptocurrency-related financial products.</em></p>
<p><em>For companies active in or associated with the cryptocurrency sector, the FBI emphasizes North Korea employs sophisticated tactics to steal cryptocurrency funds. It is a persistent threat to organizations with access to large quantities of cryptocurrency-related assets or products.</em></p>
<p>Regarding it being a target of a North Korean spy, CEO Henrik Fisker told The Engineer that the case "is with the FBI" and declined to comment further.</p>
<p>I am&nbsp;<a href="https://www.torquenews.com/users/denis-flierl" target="_blank">Denis Flierl</a>, a Senior Torque News Writer since 2012. I’ve invested over 13 years in the automotive industry in a consulting role, working with every major car brand. I am an experienced Rocky Mountain Automotive Press member. You'll find my expert Subaru analysis <a href="https://www.torquenews.com/subaru" target="_blank">here</a>. Follow me on my X&nbsp;<a href="https://twitter.com/SubaruReport" target="_blank"><strong>SubaruReport</strong></a><strong>,&nbsp;</strong><a href="https://twitter.com/AllSubaru" target="_blank"><strong>All&nbsp;Subaru</strong></a><strong>, </strong><a href="https://twitter.com/WRX_STI_News" target="_blank"><strong>WRXSTI</strong></a>, <a href="https://twitter.com/DenisFlierl" target="_blank"><strong>@DenisFlierl</strong></a>,&nbsp;<a href="https://www.facebook.com/SubaruReport" target="_blank">Facebook</a>, and&nbsp;<a href="https://www.instagram.com/subaru.report/" target="_blank">Instagram</a>.</p>
<p>Photo credit: Denis Flierl via Fisker Inc.</p>
</div><p>
    <strong><span>Follow us today...</span></strong>
    <a href="https://www.facebook.com/sharer.php?u=https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi" target="_blank">
      <img src="https://www.torquenews.com/profiles/torquenews/facebook.png" loading="lazy" width="64" height="64" alt="Facebook icon">
    </a>&nbsp;
    <a href="https://x.com/share?text=Fisker+EVs+Hired+An+IT+Spy+Who+Funneled+Millions+To+North+Korea%E2%80%99s+Missile+Program%2C+CEO+Henrik+Fisker%2C+Says+%E2%80%9CThe+Case+Is+With+the+FBI%E2%80%9D%20-%C2%A0via%C2%A0@torquenewsauto&amp;url=https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi">
      <img src="https://www.torquenews.com/profiles/torquenews/x.png" loading="lazy" width="64" height="64" alt="X icon">
    </a>&nbsp;
    <a href="https://t.me/teslaev" target="_blank" title="Join us on Telegram!">
      <img src="https://www.torquenews.com/profiles/torquenews/telegram.png" loading="lazy" width="64" height="64" alt="Telegram icon">
    </a>&nbsp;
    <a href="https://www.reddit.com/submit?url=https://www.torquenews.com/1084/fisker-evs-hired-it-spy-who-funneled-millions-north-koreas-missile-program-case-fbi&amp;title=Fisker+EVs+Hired+An+IT+Spy+Who+Funneled+Millions+To+North+Korea%E2%80%99s+Missile+Program%2C+CEO+Henrik+Fisker%2C+Says+%E2%80%9CThe+Case+Is+With+the+FBI%E2%80%9D" target="_blank" title="Join us on Reddit!">
      <img src="https://www.torquenews.com/profiles/torquenews/reddit.png" loading="lazy" width="64" height="64" alt="Reddit icon">
    </a>
  </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. chip revival plan chooses sites (159 pts)]]></title>
            <link>https://spectrum.ieee.org/nstc</link>
            <guid>42054779</guid>
            <pubDate>Tue, 05 Nov 2024 20:14:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/nstc">https://spectrum.ieee.org/nstc</a>, See on <a href="https://news.ycombinator.com/item?id=42054779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="U.S. Chip Revival Plan Chooses Sites"><p>Last week the organization tasked with running the the <a href="https://www.semiconductors.org/chips-rd-programs/" target="_blank">biggest chunk</a> of <a href="https://spectrum.ieee.org/tag/chips-act" target="_blank">U.S. CHIPS Act’s</a> US $13 billion R&amp;D program made some significant strides: The <a href="https://www.nist.gov/chips/research-development-programs/national-semiconductor-technology-center" target="_blank">National Semiconductor Technology Center (NSTC)</a>  released a strategic plan and selected the sites of two of three planned facilities and released a new strategic plan. The locations of the two sites—a <a href="https://www.nist.gov/news-events/news/2024/11/biden-harris-administration-announces-sunnyvale-ca-expected-location-second" target="_blank"><u>“design and collaboration” center</u></a> in Sunnyvale, Calif., and a lab devoted to advancing the <a href="https://www.nist.gov/news-events/news/2024/10/biden-harris-administration-announces-ny-creates-albany-nanotech-complex" target="_blank"><u>leading edge of chipmaking</u></a>, in Albany, N.Y.—build on an existing ecosystem at each location, experts say. The location of the third planned center—a chip prototyping and packaging site that could be especially <a href="https://spectrum.ieee.org/power-electronics" target="_self"><u>critical for speeding semiconductor startups</u></a>—is still a matter of speculation.</p><p>“The NSTC represents a once-in-a-generation opportunity for the U.S. to accelerate the pace of innovation in semiconductor technology,” <a href="https://natcast.org/leadership" target="_blank"><u>Deirdre Hanford</u></a>, CEO of Natcast, the nonprofit that runs the NSTC centers, said in a <a href="https://natcast.org/biden-harris-announces-second-chips-flagship-facility" rel="noopener noreferrer" target="_blank"><u>statement</u></a>. According to the strategic plan, which covers 2025 to 2027, the NSTC is meant to accomplish three goals: extend U.S. technology leadership, reduce the time and cost to prototype, and build and sustain a semiconductor workforce development ecosystem. The three centers are meant to do a mix of all three. </p><h2>New York gets extreme ultraviolet lithography</h2><p>NSTC plans to direct $825 million into the Albany project. The site will be dedicated to extreme ultraviolet lithography, a technology that’s essential to making the most advanced logic chips. The <a href="https://ny-creates.org/ny-creates-campus-complex/" rel="noopener noreferrer" target="_blank"><u>Albany Nanotech Complex</u></a>, which has already seen more than $25 billion in investments from the state and industry partners over two decades, will form the heart of the future NSTC center. It already has an<a href="https://spectrum.ieee.org/tag/euv" target="_self"><u> EUV lithography</u></a> machine on site and has begun an expansion to install a next-generation version, called <a href="https://spectrum.ieee.org/high-na-euv" target="_self"><u>high-NA EUV</u></a>, which promises to produce even finer chip features. Working with a tool recently installed in Europe, <a href="https://spectrum.ieee.org/tag/ibm">IBM</a>, a long-time tenant of the Albany research facility, reported record yields of <a href="https://research.ibm.com/blog/new-euv-patterning-yield-benchmarks" rel="noopener noreferrer" target="_blank"><u>copper interconnects built every 21 nanometers</u></a>, a pitch several nanometers tighter than possible with ordinary <a href="https://spectrum.ieee.org/high-na-euv">EUV</a>. </p><p>“It’s fulfilling to see that this ecosystem can be taken to the national and global level through CHIPS Act funding,” said <a href="https://research.ibm.com/people/mukesh-khare" rel="noopener noreferrer" target="_blank"><u>Mukesh Khare</u></a>, general manager of IBM’s <a href="https://spectrum.ieee.org/topic/semiconductors/">semiconductors</a> division, speaking from the future site of the NSTC EUV center. “It’s the right time, and we have all the ingredients.”</p><p>While only a few companies are capable of manufacturing cutting edge logic using EUV, the impact of the NSTC center will be much broader, Khare argues. It will extend down as far as early-stage startups with ideas or materials for improving the chipmaking process “An EUV R&amp;D center doesn’t mean just one machine,” says Khare. “It needs so many machines around it… It’s a very large ecosystem.”</p><h2>Silicon Valley lands the design center</h2><p>The design center is tasked with conducting advanced research in <a href="https://spectrum.ieee.org/tag/chip-design" target="_self"><u>chip design</u></a>, electronic design automation (EDA), chip and system architectures, and<a href="https://spectrum.ieee.org/tag/security" target="_self"><u> hardware security</u></a>. It will also host the NSTC’s design enablement gateway—a program that provides NSTC members with a secure, cloud-based access to design tools, reference processes and designs, and shared data sets, with the goal of reducing the time and cost of design. Additionally, it will house workforce development, member convening, and administration functions. </p><p>Situating the design center in Silicon Valley, with its concentration of research universities, venture capital, and workforce, seems like the obvious choice to many experts. “I can’t think of a better place,” says Patrick Soheili, co-founder of interconnect technology startup Eliyan, which is based in Santa Clara, Calif.</p><p><a href="https://www.linkedin.com/in/abhijeet-chakraborty-1a21931/" rel="noopener noreferrer" target="_blank"><u>Abhijeet Chakraborty</u></a>, vice president of engineering in the technology and product group at Silicon Valley-based <a href="https://www.synopsys.com/" rel="noopener noreferrer" target="_blank"><u>Synopsys</u></a>, a leading maker of EDA software, sees Silicon Valley’s expansive tech ecosystem as one of its main advantages in landing the NSTC’s design center. The region concentrates companies and researchers involved in the whole spectrum of the industry from semiconductor process technology to cloud software.</p><p>Access to such a broad range of industries is increasingly important for <a href="https://spectrum.ieee.org/tag/chip-design">chip design</a> startups, he says. “To design a chip or component these days you need to go from concept to design to validation in an environment that takes care of the entire stack,” he says. It’s prohibitively expensive for a startup to do that alone, so one of Chakraborty’s hopes for the design center is that it will help startups access the design kits and other data needed to operate in this new environment.</p><h2>Packaging and prototyping still to come</h2><p>A third promised center for prototyping and packaging is still to come. “The big question is where does the packaging and prototyping go?” says Mark Granahan, cofounder and CEO of Pennsylvania-based <a href="https://spectrum.ieee.org/power-electronics" target="_blank">power semiconductor startup Ideal Semiconductor</a>. “To me that’s a great opportunity.” He points out that because there is so little packaging technology infrastructure in the United States, any ambitious state or region should have a shot at hosting such a center. One of the original intentions of the act, after all, was to expand the number of regions of the country that are involved in the semiconductor industry.</p><p>But that hasn’t stopped some already tech-heavy regions from wanting it. “Oregon offers the strongest ecosystem for such a facility,” a spokesperson for <a href="https://www.intel.com/content/www/us/en/foundry/overview.html" rel="noopener noreferrer" target="_blank"><u>Intel</u></a>, whose technology development is done there. “The state is uniquely positioned to contribute to the success of the NSTC and help drive technological advancements in the U.S. semiconductor industry.”</p><p>As NSTC makes progress, Granahan’s concern is that bureaucracy will expand with it and slow efforts to boost the U.S. chip industry. Already the layers of control are multiplying. The <a href="https://www.nist.gov/chips" rel="noopener noreferrer" target="_blank"><u>Chips Office</u></a> at the National Institute of Standards and Technology executes the Act. The NSTC is administered by the nonprofit <a href="https://natcast.org/" rel="noopener noreferrer" target="_blank"><u>Natcast</u></a>, which directs the EUV center, which is in a facility run by another nonprofit, <a href="https://ny-creates.org/" rel="noopener noreferrer" target="_blank"><u>NY CREATES</u></a>. “We want these things to be agile and make local decisions.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First time ever, AMD outsells Intel in the datacenter space (432 pts)]]></title>
            <link>https://www.tomshardware.com/pc-components/cpus/for-the-first-time-ever-amd-outsells-intel-in-the-datacenter-space</link>
            <guid>42054449</guid>
            <pubDate>Tue, 05 Nov 2024 19:27:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/pc-components/cpus/for-the-first-time-ever-amd-outsells-intel-in-the-datacenter-space">https://www.tomshardware.com/pc-components/cpus/for-the-first-time-ever-amd-outsells-intel-in-the-datacenter-space</a>, See on <a href="https://news.ycombinator.com/item?id=42054449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>For well more than two decades, Intel has been the undisputed leader in the market for datacenter CPUs. Intel's Xeon processors powered the vast majority of servers, whereas AMD's processors commanded a single-digit market share just some seven or eight years ago. However, the situation has changed drastically. While Intel's Xeon CPUs still power the majority of servers, the most expensive machines now use AMD's EPYC processors. This is why AMD's datacenter business unit now outsells Intel's datacenter and AI business group, as observed by&nbsp;<a data-analytics-id="inline-link" href="https://x.com/SKundojjala/status/1853041284157682063" data-url="https://x.com/SKundojjala/status/1853041284157682063" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">SemiAnalysis</a>.</p><p>Indeed, AMD's datacenter segment revenue reached&nbsp;<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-rakes-in-cash-with-best-quarterly-revenue-ever-amid-datacenter-business-rise-but-gaming-business-craters" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/amd-rakes-in-cash-with-best-quarterly-revenue-ever-amid-datacenter-business-rise-but-gaming-business-craters">$3.549 billion</a>&nbsp;in the third quarter, whereas Intel's datacenter and AI group's earnings were&nbsp;<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-lost-usd16-6-billion-in-q3-reports-usd13-3-billion-in-revenue" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-lost-usd16-6-billion-in-q3-reports-usd13-3-billion-in-revenue">$3.3 billion</a>&nbsp;in Q3 2024. Just two years ago, Intel's DCAI group earned $5 billion - $6 billion per quarter. But as AMD's EPYC processors have gained competitive advantages over Intel's Xeon CPUs, Intel has had to sell its server chips at significant discounts, which has reduced the company's revenue and profit margins.</p><p>It is noteworthy that Intel's flagship&nbsp;<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intels-latest-flagship-128-core-xeon-cpu-costs-usd17-800-granite-rapids-sets-a-new-high-watermark" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intels-latest-flagship-128-core-xeon-cpu-costs-usd17-800-granite-rapids-sets-a-new-high-watermark">128-core Xeon 6980P 'Granite Rapids' processor costs $17,800</a>, making it the company's most expensive standard CPU ever. By contrast, AMD's most expensive 96-core EPYC 6979P processor costs $11,805. If demand for Intel's Xeon 6900-series processors remains high and the company can supply these CPUs in decent volumes, then Intel's datacenter revenue will likely get back on track and surpass AMD's datacenter sales. However, Intel still has to ramp up production of its Granite Rapids products.&nbsp;</p><p>While both Intel and AMD now earn around $3-3.5 billion per quarter selling datacenter CPUs, Nvidia earns much more from its datacenter GPUs and networking chips, which are required to make AI processors work in concert in datacenters. In fact, sales of Nvidia's networking products totaled&nbsp;<a data-analytics-id="inline-link" href="https://s201.q4cdn.com/141608511/files/doc_financials/2025/Q225/Q2FY25-CFO-Commentary.pdf" data-url="https://s201.q4cdn.com/141608511/files/doc_financials/2025/Q225/Q2FY25-CFO-Commentary.pdf" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">$3.668 billion</a>&nbsp;in the company's second quarter of fiscal 2025. Meanwhile, compute GPU sales reached $22.604 billion in Q2 FY2025, which far surpasses the combined sales of Intel and AMD datacenter hardware. Altogether, Nvidia sold nearly $42 billion worth of AI and HPC GPUs in the first half of this year, and it is likely that the company will sell even more datacenter processors in the second half.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-gRFTK4rNSThvy54UVmstUM"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tencent Hunyuan-Large (135 pts)]]></title>
            <link>https://github.com/Tencent/Tencent-Hunyuan-Large</link>
            <guid>42054186</guid>
            <pubDate>Tue, 05 Nov 2024 18:52:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Tencent/Tencent-Hunyuan-Large">https://github.com/Tencent/Tencent-Hunyuan-Large</a>, See on <a href="https://news.ycombinator.com/item?id=42054186">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
    <a href="https://github.com/Tencent/Tencent-Hunyuan-Large/blob/main/README_CN.md">中文</a>&nbsp; ｜ English
</p>
<p dir="auto">
 <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4f7f1dcd99f1e24cb8787dc695f3fb708e2f9799fe3559366a3d58139e74491a/68747470733a2f2f647363616368652e74656e63656e742d636c6f75642e636e2f75706c6f61642f75706c6f616465722f68756e7975616e2d363462343138666430353263303333623232386530346263373762626334623534666437663562632e706e67"><img src="https://camo.githubusercontent.com/4f7f1dcd99f1e24cb8787dc695f3fb708e2f9799fe3559366a3d58139e74491a/68747470733a2f2f647363616368652e74656e63656e742d636c6f75642e636e2f75706c6f61642f75706c6f616465722f68756e7975616e2d363462343138666430353263303333623232386530346263373762626334623534666437663562632e706e67" width="400" data-canonical-src="https://dscache.tencent-cloud.cn/upload/uploader/hunyuan-64b418fd052c033b228e04bc77bbc4b54fd7f5bc.png"></a> <br>
</p>
<p dir="auto">
    🫣&nbsp;<a href="https://huggingface.co/tencent/Tencent-Hunyuan-Large" rel="nofollow"><b>Hugging Face</b></a>&nbsp;&nbsp; |  &nbsp;&nbsp;🖥️&nbsp;&nbsp;<a href="https://llm.hunyuan.tencent.com/" rel="nofollow"><b>official website</b></a>&nbsp;&nbsp;｜&nbsp;&nbsp;🕖&nbsp;&nbsp; <a href="https://cloud.tencent.com/product/hunyuan" rel="nofollow"><b>HunyuanAPI</b></a>
</p><p dir="auto">
    <a href="https://arxiv.org/abs/2411.02265" rel="nofollow"><b>Technical Report</b></a>&nbsp;&nbsp;｜&nbsp;&nbsp; <a href="https://huggingface.co/spaces/tencent/Hunyuan-Large" rel="nofollow"><b>Demo</b></a>&nbsp;&nbsp;&nbsp;｜&nbsp;&nbsp; <a href="https://cloud.tencent.com/document/product/851/112032" rel="nofollow"><b>Tencent Cloud TI</b></a>&nbsp;&nbsp;&nbsp;</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Introduction</h2><a id="user-content-model-introduction" aria-label="Permalink: Model Introduction" href="#model-introduction"></a></p>
<p dir="auto">With the rapid development of artificial intelligence technology, large language models (LLMs) have made significant progress in fields such as natural language processing, computer vision, and scientific tasks. However, as the scale of these models increases, optimizing resource consumption while maintaining high performance has become a key challenge. To address this challenge, we have explored Mixture of Experts (MoE) models. The currently unveiled Hunyuan-Large (Hunyuan-MoE-A52B) model is the largest open-source Transformer-based MoE model in the industry, featuring a total of 389 billion parameters and 52 billion active parameters. This is currently the largest open-source Transformer-based MoE model in the industry, featuring a total of 389 billion parameters and 52 billion active parameters.</p>
<p dir="auto">By open-sourcing the Hunyuan-Large model and revealing related technical details, we hope to inspire more researchers with innovative ideas and collectively advance the progress and application of AI technology. We welcome you to join our open-source community to explore and optimize future AI models together!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Introduction to Technical Advantages</h3><a id="user-content-introduction-to-technical-advantages" aria-label="Permalink: Introduction to Technical Advantages" href="#introduction-to-technical-advantages"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Model</h4><a id="user-content-model" aria-label="Permalink: Model" href="#model"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>High-Quality Synthetic Data</strong>: By enhancing training with synthetic data, Hunyuan-Large can learn richer representations, handle long-context inputs, and generalize better to unseen data.</p>
</li>
<li>
<p dir="auto"><strong>KV Cache Compression</strong>: Utilizes Grouped Query Attention (GQA) and Cross-Layer Attention (CLA) strategies to significantly reduce memory usage and computational overhead of KV caches, improving inference throughput.</p>
</li>
<li>
<p dir="auto"><strong>Expert-Specific Learning Rate Scaling</strong>: Sets different learning rates for different experts to ensure each sub-model effectively learns from the data and contributes to overall performance.</p>
</li>
<li>
<p dir="auto"><strong>Long-Context Processing Capability</strong>: The pre-trained model supports text sequences up to 256K, and the Instruct model supports up to 128K, significantly enhancing the ability to handle long-context tasks.</p>
</li>
<li>
<p dir="auto"><strong>Extensive Benchmarking</strong>: Conducts extensive experiments across various languages and tasks to validate the practical effectiveness and safety of Hunyuan-Large.</p>
</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">inference Framework</h4><a id="user-content-inference-framework" aria-label="Permalink: inference Framework" href="#inference-framework"></a></p>
<ul dir="auto">
<li>This open-source release offers two inference backend options tailored for the Hunyuan-Large model: the popular vLLM-backend and the TRT-LLM-backend. Both solutions include optimizations for enhanced performance. For instance, the introduction of a new CLA structure significantly reduces GPU memory usage, achieving a 50% savings in the KV-Cache portion, which ensures efficient handling of long text scenarios. Additionally, by employing FP8 quantization, we achieve a 50% reduction in memory usage compared to traditional FP16/BF16 quantization, while maintaining precision and resulting in a 70% increase in throughput. Meanwhile, by leveraging the efficient operators at the core of TRT-LLM, the performance of the TRT-LLM solution surpasses that of vLLM by over 30%. The TRT-LLM solution is widely used in Tencent's Hunyuan project. In this release, we are initially open-sourcing the vLLM solution, with plans to release the TRT-LLM solution in the near future.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Training Framework</h4><a id="user-content-training-framework" aria-label="Permalink: Training Framework" href="#training-framework"></a></p>
<ul dir="auto">
<li>The Hunyuan-Large open-source model is fully compatible with the Hugging Face format, enabling researchers and developers to perform model fine-tuning using the hf-deepspeed framework. Additionally, we support training acceleration through the use of flash attention. To further assist in the adoption process, we have made the corresponding training scripts and model implementations publicly available to the community through this release, facilitating subsequent model training and fine-tuning operations based on these resources.</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Related News</h2><a id="user-content-related-news" aria-label="Permalink: Related News" href="#related-news"></a></p>
<ul dir="auto">
<li>2024.11.5 <a href="https://cloud.tencent.com/product/ti" rel="nofollow">TI Platform</a> has integrated Hunyuan-Large model already, you can easily train and deploy it in just a few steps. Visit <a href="https://console.cloud.tencent.com/tione/v2/aimarket/detail/hunyuan_series?PublicAlgoGroupId=hunyuan-large-chat&amp;detailTab=demo" rel="nofollow">Chat with Hunyuan-Large</a> to experience real-time conversations with the model, and explore <a href="https://cloud.tencent.com/document/product/851/112032" rel="nofollow">Hunyuan-Large Best Practice on TI</a> to create your own customized Hunyuan-Large model.</li>
<li>2024.11.5 We have open-sourced <strong>Hunyuan-A52B-Pretrain</strong>, <strong>Hunyuan-A52B-Instruct</strong>, and <strong>Hunyuan-A52B-Instruct-FP8</strong> on Hugging Face. We also released a technical report and a training and inference operations manual, providing detailed information on the model's capabilities and the procedures for training and inference.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark Evaluation</h2><a id="user-content-benchmark-evaluation" aria-label="Permalink: Benchmark Evaluation" href="#benchmark-evaluation"></a></p>
<p dir="auto"><strong>Hunyuan-Large pre-trained model</strong> achieves the best overall performance compared to both Dense and MoE based
competitors having similar activated parameter sizes.  For aggregated benchmarks such as MMLU, MMLU-Pro, and CMMLU,
Hunyuan-Large consistently achieves the best performance, confirming its comprehensive abilities on aggregated tasks.
Hunyuan-Large also shows superior performance in commonsense understanding and reasoning, and classical NLP tasks
such as QA and reading comprehension tasks (e.g., CommonsenseQA, PIQA and TriviaQA).<br>
For the mathematics capability, Hunyuan-Large outperforms all baselines in math datasets of GSM8K and MATH,
and also gains the best results on CMATH in Chinese.We also observe that Hunyuan-Large achieves the overall
best performance in all Chinese tasks (e.g., CMMLU, C-Eval).</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>LLama3.1-405B</th>
<th>LLama3.1-70B</th>
<th>Mixtral-8x22B</th>
<th>DeepSeek-V2</th>
<th>Hunyuan-Large</th>
</tr>
</thead>
<tbody>
<tr>
<td>MMLU</td>
<td>85.2</td>
<td>79.3</td>
<td>77.8</td>
<td>78.5</td>
<td><strong>88.4</strong></td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>61.6</strong></td>
<td>53.8</td>
<td>49.5</td>
<td>-</td>
<td>60.2</td>
</tr>
<tr>
<td>BBH</td>
<td>85.9</td>
<td>81.6</td>
<td>78.9</td>
<td>78.9</td>
<td><strong>86.3</strong></td>
</tr>
<tr>
<td>HellaSwag</td>
<td>-</td>
<td>-</td>
<td><strong>88.7</strong></td>
<td>87.8</td>
<td>86.8</td>
</tr>
<tr>
<td>CommonsenseQA</td>
<td>85.8</td>
<td>84.1</td>
<td>82.4</td>
<td>-</td>
<td><strong>92.9</strong></td>
</tr>
<tr>
<td>WinoGrande</td>
<td>86.7</td>
<td>85.3</td>
<td>85.0</td>
<td>84.9</td>
<td><strong>88.7</strong></td>
</tr>
<tr>
<td>PIQA</td>
<td>-</td>
<td>-</td>
<td>83.6</td>
<td>83.7</td>
<td><strong>88.3</strong></td>
</tr>
<tr>
<td>NaturalQuestions</td>
<td>-</td>
<td>-</td>
<td>39.6</td>
<td>38.7</td>
<td><strong>52.8</strong></td>
</tr>
<tr>
<td>DROP</td>
<td>84.8</td>
<td>79.6</td>
<td>80.4</td>
<td>80.1</td>
<td><strong>88.9</strong></td>
</tr>
<tr>
<td>ARC-C</td>
<td><strong>96.1</strong></td>
<td>92.9</td>
<td>91.2</td>
<td>92.4</td>
<td>95.0</td>
</tr>
<tr>
<td>TriviaQA</td>
<td>-</td>
<td>-</td>
<td>82.1</td>
<td>79.9</td>
<td><strong>89.2</strong></td>
</tr>
<tr>
<td>CMMLU</td>
<td>-</td>
<td>-</td>
<td>60.0</td>
<td>84.0</td>
<td><strong>90.2</strong></td>
</tr>
<tr>
<td>C-Eval</td>
<td>-</td>
<td>-</td>
<td>59.6</td>
<td>81.7</td>
<td><strong>91.9</strong></td>
</tr>
<tr>
<td>C3</td>
<td>-</td>
<td>-</td>
<td>71.4</td>
<td>77.4</td>
<td><strong>82.3</strong></td>
</tr>
<tr>
<td>GSM8K</td>
<td>89.0</td>
<td>83.7</td>
<td>83.7</td>
<td>79.2</td>
<td><strong>92.8</strong></td>
</tr>
<tr>
<td>MATH</td>
<td>53.8</td>
<td>41.4</td>
<td>42.5</td>
<td>43.6</td>
<td><strong>69.8</strong></td>
</tr>
<tr>
<td>CMATH</td>
<td>-</td>
<td>-</td>
<td>72.3</td>
<td>78.7</td>
<td><strong>91.3</strong></td>
</tr>
<tr>
<td>HumanEval</td>
<td>61.0</td>
<td>58.5</td>
<td>53.1</td>
<td>48.8</td>
<td><strong>71.4</strong></td>
</tr>
<tr>
<td>MBPP</td>
<td><strong>73.4</strong></td>
<td>68.6</td>
<td>64.2</td>
<td>66.6</td>
<td>72.6</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Hunyuan-Large-Instruct</strong> achieves consistent improvements on most types of tasks compared to LLMs having similar
activated parameters, indicating the effectiveness of our post-training.    Delving into the model performance
in different categories of benchmarks, we find that our instruct model achieves the best performance on MMLU and MATH dataset.<br>
Notably, on the MMLU dataset, our model demonstrates a significant improvement, outperforming the LLama3.1-405B model by 2.6%.<br>
This enhancement is not just marginal but indicative of the Hunyuan-Large-Instruct’s superior understanding and reasoning
capabilities across a wide array of language understanding tasks. The model’s prowess is further underscored in its performance
on the MATH dataset, where it surpasses the LLama3.1-405B by a notable margin of 3.6%.<br>
Remarkably, this leap in accuracy is achieved with only 52 billion activated parameters, underscoring the efficiency of our model.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>LLama3.1 405B Inst.</th>
<th>LLama3.1 70B Inst.</th>
<th>Mixtral 8x22B Inst.</th>
<th>DeepSeekV2.5 Chat</th>
<th>Hunyuan-Large Inst.</th>
</tr>
</thead>
<tbody>
<tr>
<td>MMLU</td>
<td>87.3</td>
<td>83.6</td>
<td>77.8</td>
<td>80.4</td>
<td><strong>89.9</strong></td>
</tr>
<tr>
<td>CMMLU</td>
<td>-</td>
<td>-</td>
<td>61.0</td>
<td>-</td>
<td><strong>90.4</strong></td>
</tr>
<tr>
<td>C-Eval</td>
<td>-</td>
<td>-</td>
<td>60.0</td>
<td>-</td>
<td><strong>88.6</strong></td>
</tr>
<tr>
<td>BBH</td>
<td>-</td>
<td>-</td>
<td>78.4</td>
<td>84.3</td>
<td><strong>89.5</strong></td>
</tr>
<tr>
<td>HellaSwag</td>
<td>-</td>
<td>-</td>
<td>86.0</td>
<td><strong>90.3</strong></td>
<td>88.5</td>
</tr>
<tr>
<td>ARC-C</td>
<td><strong>96.9</strong></td>
<td>94.8</td>
<td>90.0</td>
<td>-</td>
<td>94.6</td>
</tr>
<tr>
<td>GPQA_diamond</td>
<td><strong>51.1</strong></td>
<td>46.7</td>
<td>-</td>
<td>-</td>
<td>42.4</td>
</tr>
<tr>
<td>MATH</td>
<td>73.8</td>
<td>68.0</td>
<td>49.8</td>
<td>74.7</td>
<td><strong>77.4</strong></td>
</tr>
<tr>
<td>HumanEval</td>
<td>89.0</td>
<td>80.5</td>
<td>75.0</td>
<td>89.0</td>
<td><strong>90.0</strong></td>
</tr>
<tr>
<td>AlignBench</td>
<td>6.0</td>
<td>5.9</td>
<td>6.2</td>
<td>8.0</td>
<td><strong>8.3</strong></td>
</tr>
<tr>
<td>MT-Bench</td>
<td>9.1</td>
<td>8.8</td>
<td>8.1</td>
<td>9.0</td>
<td><strong>9.4</strong></td>
</tr>
<tr>
<td>IFEval strict-prompt</td>
<td><strong>86.0</strong></td>
<td>83.6</td>
<td>71.2</td>
<td>-</td>
<td>85.0</td>
</tr>
<tr>
<td>Arena-Hard</td>
<td>69.3</td>
<td>55.7</td>
<td>-</td>
<td>76.2</td>
<td><strong>81.8</strong></td>
</tr>
<tr>
<td>AlpacaEval-2.0</td>
<td>39.3</td>
<td>34.3</td>
<td>30.9</td>
<td>50.5</td>
<td><strong>51.8</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto"><h2 tabindex="-1" dir="auto">Data</h2><a id="user-content-data" aria-label="Permalink: Data" href="#data"></a></p>
<p dir="auto">Hunyuan-Large provides model training-related processes. In this section, you can process the training data format for use in model training.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Training Data Format and Processing</h3><a id="user-content-training-data-format-and-processing" aria-label="Permalink: Training Data Format and Processing" href="#training-data-format-and-processing"></a></p>
<p dir="auto">Training data is processed into a messages format as follows. The default system prompt for training and inference is "You are a helpful assistant." Below are examples of single-turn and multi-turn data:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Single-Turn Data Format

messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;海水为什么是咸的&quot; },
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;海水是咸的主要是因为其中含有许多溶解在水中的盐类和矿物质。这些盐类和矿物质来自于地球表面的岩石和土壤中的化学物质，随着时间的推移，它们被带到了海洋中。当海水蒸发时，水分蒸发掉了，但盐类和矿物质仍然留在水中，导致海水变得更加咸味。因此，海水的咸度是由其中的盐类和矿物质的含量决定的。&quot;}
]

# Multi-Turn Data Format
messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;知道重庆森林这部电影吗？&quot; },
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;知道呀，是一部由王家卫导演的片子。&quot; },
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot; 而主演里更是有王菲，一上映便受到追捧。&quot; },
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;所以此片获得了第14届香港电影金像奖最佳影片奖。&quot;}
]

from tokenizers import ByteLevelBPETokenizer
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(&quot;./models&quot;, use_fast=False, trust_remote_code=True)

ids = tokenizer.apply_chat_template(messages)
"><pre><span># Single-Turn Data Format</span>

<span>messages</span> <span>=</span> [
    {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a helpful assistant."</span>},
    {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"海水为什么是咸的"</span> },
    {<span>"role"</span>: <span>"assistant"</span>, <span>"content"</span>: <span>"海水是咸的主要是因为其中含有许多溶解在水中的盐类和矿物质。这些盐类和矿物质来自于地球表面的岩石和土壤中的化学物质，随着时间的推移，它们被带到了海洋中。当海水蒸发时，水分蒸发掉了，但盐类和矿物质仍然留在水中，导致海水变得更加咸味。因此，海水的咸度是由其中的盐类和矿物质的含量决定的。"</span>}
]

<span># Multi-Turn Data Format</span>
<span>messages</span> <span>=</span> [
    {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a helpful assistant."</span>},
    {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"知道重庆森林这部电影吗？"</span> },
    {<span>"role"</span>: <span>"assistant"</span>, <span>"content"</span>: <span>"知道呀，是一部由王家卫导演的片子。"</span> },
    {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>" 而主演里更是有王菲，一上映便受到追捧。"</span> },
    {<span>"role"</span>: <span>"assistant"</span>, <span>"content"</span>: <span>"所以此片获得了第14届香港电影金像奖最佳影片奖。"</span>}
]

<span>from</span> <span>tokenizers</span> <span>import</span> <span>ByteLevelBPETokenizer</span>
<span>from</span> <span>transformers</span> <span>import</span> <span>AutoTokenizer</span>

<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>"./models"</span>, <span>use_fast</span><span>=</span><span>False</span>, <span>trust_remote_code</span><span>=</span><span>True</span>)

<span>ids</span> <span>=</span> <span>tokenizer</span>.<span>apply_chat_template</span>(<span>messages</span>)</pre></div>
<p dir="auto">For more usage references, see the <code>./models/test.py</code> file.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto">You can quickly get started by referring to the content in the <a href="https://github.com/Tencent/Tencent-Hunyuan-Large/blob/main/examples/README.md">Quick Start Guide</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Training</h2><a id="user-content-model-training" aria-label="Permalink: Model Training" href="#model-training"></a></p>
<p dir="auto">To simplify the Training process, HunyuanLLM provides a pre-built Docker image:</p>
<p dir="auto"><a href="https://hub.docker.com/repository/docker/hunyuaninfer/hunyuan-large/general" rel="nofollow">hunyuaninfer/hunyuan-large</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hardware Requirements</h3><a id="user-content-hardware-requirements" aria-label="Permalink: Hardware Requirements" href="#hardware-requirements"></a></p>
<p dir="auto">Tested on H20, without enabling <code>make_moe_param_leaf_module</code> and using <code>zero3+offload</code>, with a <code>max_seq_length</code> of 2048, full fine-tuning requires at least 32 GPUs, and LoRA fine-tuning requires at least 8 GPUs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Training Performance</h3><a id="user-content-training-performance" aria-label="Permalink: Training Performance" href="#training-performance"></a></p>
<p dir="auto">With the minimum configuration (8 GPUs for LoRA fine-tuning), <code>per_device_train_batch_size</code> is set to 1, and <code>gradient_accumulation_steps</code> is set to 1, resulting in approximately 35 seconds per iteration.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Launch Method</h3><a id="user-content-launch-method" aria-label="Permalink: Launch Method" href="#launch-method"></a></p>
<p dir="auto">Refer to: <a href="https://huggingface.co/docs/transformers/v4.19.2/en/main_classes/trainer" rel="nofollow">HuggingFace Transformers Trainer</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Single-Machine Training</h4><a id="user-content-single-machine-training" aria-label="Permalink: Single-Machine Training" href="#single-machine-training"></a></p>
<p dir="auto">In the <code>train</code> directory, execute:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt
bash train.sh"><pre>pip install -r requirements.txt
bash train.sh</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Multi-Machine Training</h4><a id="user-content-multi-machine-training" aria-label="Permalink: Multi-Machine Training" href="#multi-machine-training"></a></p>
<p dir="auto">To start training on multiple machines, follow the steps below and ensure that all machines are within the same cluster.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Configure Passwordless SSH Login Between Machines</h5><a id="user-content-configure-passwordless-ssh-login-between-machines" aria-label="Permalink: Configure Passwordless SSH Login Between Machines" href="#configure-passwordless-ssh-login-between-machines"></a></p>
<p dir="auto">The following steps use two machines as an example, with their IPs represented as <code>${ip1}</code> and <code>${ip2}</code>. These operations are performed within a Docker container.</p>
<p dir="auto">First, configure passwordless SSH between containers on each machine.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ssh-keygen			# Generate id_rsa and id_rsa.pub for passwordless login
ssh-keygen -t rsa -A    # Generate /etc/ssh/ssh_host_rsa_key and ssh_host_ecdsa_key for starting 'SSH listen' later
/usr/sbin/sshd -p 36005 -o ListenAddress=0.0.0.0        # Start SSH listen
echo &quot;Port 36005&quot; > ~/.ssh/config   # Change SSH connection port to 36005
passwd root    # Set root password to avoid alerts from monitoring platforms"><pre>ssh-keygen			<span><span>#</span> Generate id_rsa and id_rsa.pub for passwordless login</span>
ssh-keygen -t rsa -A    <span><span>#</span> Generate /etc/ssh/ssh_host_rsa_key and ssh_host_ecdsa_key for starting 'SSH listen' later</span>
/usr/sbin/sshd -p 36005 -o ListenAddress=0.0.0.0        <span><span>#</span> Start SSH listen</span>
<span>echo</span> <span><span>"</span>Port 36005<span>"</span></span> <span>&gt;</span> <span>~</span>/.ssh/config   <span><span>#</span> Change SSH connection port to 36005</span>
passwd root    <span><span>#</span> Set root password to avoid alerts from monitoring platforms</span></pre></div>
<p dir="auto">Note: The <code>36005</code> here is an example. You can choose any port, but ensure that the port is <strong>open</strong> and <strong>not occupied by other processes</strong>.</p>
<p dir="auto">Next, within the container on each machine, execute:</p>

<p dir="auto"><strong>Copy the output SSH public key and paste it into the <code>~/.ssh/authorized_keys</code> file, with one public key per line. This must be done on every machine.</strong> Ultimately, the <code>~/.ssh/authorized_keys</code> file on each machine should be identical and contain the public keys of all machines.</p>
<p dir="auto">It's important to note that during multi-node training, the code executed on each node must be consistent. It is recommended to mount a shared network drive. If mounting a shared drive is not possible, you need to manually copy the dataset, scripts, and code to the same directory on all machines.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Start Multi-Machine Training</h5><a id="user-content-start-multi-machine-training" aria-label="Permalink: Start Multi-Machine Training" href="#start-multi-machine-training"></a></p>
<p dir="auto">Once the preparation steps are completed and dependencies are confirmed to be installed (if not, execute <code>pip install -r requirements.txt</code> to install), you can add the following configuration at the beginning of <code>train.sh</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export HOST_GPU_NUM=8
# Current machine IP
export LOCAL_IP=${ip1}
# Multi-node machine IPs, separated by commas
export NODE_IP_LIST=&quot;${ip1}:8,${ip2}:8&quot;
# Number of machine nodes
export NODES=2
export NODE_NUM=$((${NODES} * ${HOST_GPU_NUM}))"><pre><span>export</span> HOST_GPU_NUM=8
<span><span>#</span> Current machine IP</span>
<span>export</span> LOCAL_IP=<span>${ip1}</span>
<span><span>#</span> Multi-node machine IPs, separated by commas</span>
<span>export</span> NODE_IP_LIST=<span><span>"</span><span>${ip1}</span>:8,<span>${ip2}</span>:8<span>"</span></span>
<span><span>#</span> Number of machine nodes</span>
<span>export</span> NODES=2
<span>export</span> NODE_NUM=<span><span>$((</span><span>${NODES}</span> <span>*</span> <span>${HOST_GPU_NUM}</span><span>))</span></span></pre></div>
<p dir="auto">Note: Replace <code>${ip1}</code> and <code>${ip2}</code> with the actual IP addresses!</p>
<p dir="auto">Then, on the machine with <code>${ip1}</code>, execute <code>bash train.sh</code> in the <code>train/</code> directory. Note that on the first run, you might see the following output:</p>
<div data-snippet-clipboard-copy-content="The authenticity of host '[ip]:36005 ([ip]:36005)' can't be established.
ECDSA key fingerprint is xxxxxx.
ECDSA key fingerprint is MD5:xxxxxx.
Are you sure you want to continue connecting (yes/no)?"><pre lang="ssh"><code>The authenticity of host '[ip]:36005 ([ip]:36005)' can't be established.
ECDSA key fingerprint is xxxxxx.
ECDSA key fingerprint is MD5:xxxxxx.
Are you sure you want to continue connecting (yes/no)?
</code></pre></div>
<p dir="auto">At this point, type <code>yes</code> to continue.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Key Parameters</h5><a id="user-content-key-parameters" aria-label="Permalink: Key Parameters" href="#key-parameters"></a></p>
<p dir="auto">The key parameters in the script are as follows:</p>
<ul dir="auto">
<li><code>--deepspeed</code>: This parameter should point to a DeepSpeed configuration file. The <code>train</code> folder provides three default DeepSpeed configuration files: <code>ds_zero2_no_offload.json</code>, <code>ds_zero3_no_offload.json</code>, <code>ds_zero3_offload.json</code>. The required GPU memory decreases in this order.</li>
<li><code>--model_name_or_path</code>: The path to the HF pre-trained model. Ensure this path contains the <code>modeling_hunyuan.py</code> and <code>configuration_hunyuan.py</code> files; otherwise, it cannot be loaded.</li>
<li><code>--tokenizer_name_or_path</code>: The path to the tokenizer folder. Ensure this path contains the <code>tokenization_hy.py</code> file; otherwise, it cannot be loaded.</li>
<li><code>--train_data_file</code>: The path to the training file, which should be a JSONL file.</li>
<li><code>--output_dir</code>: The output directory where logs, tensorboard files, and model weights will be stored.</li>
<li><code>--per_device_train_batch_size</code>: The batch size per GPU.</li>
<li><code>--gradient_accumulation_steps</code>: The number of gradient accumulation steps. The global batch size is <code>per_device_train_batch_size * gradient_accumulation_steps * dp_size</code>.</li>
<li><code>--max_steps</code>: The total number of training steps.</li>
<li><code>--save_steps</code>: The number of steps between saving checkpoints.</li>
<li><code>--use_lora</code>: Whether to use LoRA for training. This also accepts <code>--lora_rank</code>, <code>--lora_alpha</code>, and <code>--lora_dropout</code> parameters. LoRA is applied by default to the 'q_proj', 'k_proj', 'v_proj', 'o_proj' parameters. If you need to change this, modify it in the code. Note: <strong>When using LoRA for training, only the LoRA weights are saved, not the base model weights</strong>. If you need to merge LoRA weights, see the "LoRA Weight Merging" section below.</li>
<li><code>--make_moe_param_leaf_module</code>: When using zero3 and MoE training, treat the MoE module as a leaf module, meaning its parameters are not split by zero3. This option is expected to significantly increase memory usage.</li>
<li><code>--gradient_checkpointing</code>: Enable gradient checkpointing.</li>
<li><code>--train_attention_params_only</code>: Whether to train only the attention parameters.</li>
<li><code>--learning_rate</code>: The maximum learning rate during training.</li>
<li><code>--min_lr</code>: The minimum learning rate during training.</li>
<li><code>--use_flash_attn</code>: 开启 flash-attention 进行训练加速</li>
</ul>
<p dir="auto"><strong>Note:</strong></p>
<ul dir="auto">
<li>If you want to continue training from a previously saved checkpoint instead of loading pre-trained weights, specify <code>--resume_from_checkpoint</code> with the path to the checkpoint from the previous training. Do not specify <code>--model_name_or_path</code>, as this will only load the weights and not the training state.</li>
<li>When continuing training from a checkpoint, there might be slight deviations in loss due to randomness introduced by some non-deterministic algorithms, which is considered normal. Refer to: <a href="https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one#randomness" rel="nofollow">HuggingFace Transformers Trainer Randomness</a></li>
<li>When <code>--model_name_or_path</code> is specified, all model-related parameters will be ignored.</li>
<li>Samples within a batch will be padded to align with the longest sample in the batch, with each sample having a maximum length of <code>max_seq_length</code>. Any excess will be truncated.</li>
<li>If you encounter warnings about bias weights not being loaded, you can ignore them, as biases are not used in Hunyuan-Large.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">What to Do If Out of Memory?</h4><a id="user-content-what-to-do-if-out-of-memory" aria-label="Permalink: What to Do If Out of Memory?" href="#what-to-do-if-out-of-memory"></a></p>
<p dir="auto">Refer to: <a href="https://www.deepspeed.ai/docs/config-json/" rel="nofollow">DeepSpeed Configuration</a></p>
<p dir="auto">You can try modifying the DeepSpeed configuration by removing the auto attribute from these parameters and reducing their values:</p>
<ul dir="auto">
<li><code>stage3_param_persistence_threshold</code></li>
<li><code>stage3_prefetch_bucket_size</code></li>
<li><code>stage3_max_reuse_distance</code></li>
<li><code>stage3_max_reuse_distance</code></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Merging LoRA Models</h4><a id="user-content-merging-lora-models" aria-label="Permalink: Merging LoRA Models" href="#merging-lora-models"></a></p>
<p dir="auto">The saved LoRA weights cannot be merged into the zero3 model during training because, with zero3 enabled, model weights are split across different data parallel ranks. If you want to merge LoRA weights into the base model, you can do so offline to obtain the merged weight file. Execute <code>merge_lora_weight.sh</code> to merge the LoRA weights with the base model weights. The parameters include:</p>
<ul dir="auto">
<li><code>--base_model_path</code>: Directory of the base model weights</li>
<li><code>--adapter_model_path</code>: Directory of the LoRA weights</li>
<li><code>--output_path</code>: Directory to save the merged weights</li>
<li><code>--save_dtype</code>: Data format for storing the merged weights, available options include: fp16, bf16, fp32</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Inference and Deployment</h2><a id="user-content-inference-and-deployment" aria-label="Permalink: Inference and Deployment" href="#inference-and-deployment"></a></p>
<p dir="auto">HunyuanLLM uses TRT-LLM and vLLM for deployment. We are open sourcing the vLLM deployment (see Reasoning with vLLM), and the TRT-LLM deployment (see Reasoning with TRT-LLM) will be available in the near future.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using TRT-LLM for Inference</h2><a id="user-content-using-trt-llm-for-inference" aria-label="Permalink: Using TRT-LLM for Inference" href="#using-trt-llm-for-inference"></a></p>
<p dir="auto">To be opened</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using vLLM for Inference</h2><a id="user-content-using-vllm-for-inference" aria-label="Permalink: Using vLLM for Inference" href="#using-vllm-for-inference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker:</h3><a id="user-content-docker" aria-label="Permalink: Docker:" href="#docker"></a></p>
<p dir="auto">To simplify the deployment process, HunyuanLLM provides a pre-built Docker image:</p>
<p dir="auto"><a href="https://hub.docker.com/repository/docker/hunyuaninfer/hunyuan-large/general" rel="nofollow">hunyuaninfer/hunyuan-large</a>. You only need to download the model files and start the Docker container using the code below to begin model inference.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run --name hunyuanLLM_infer -itd --privileged --user root --net=host --ipc=host --gpus=8 hunyuaninfer/hunyuan-large:infer-open-source"><pre>docker run --name hunyuanLLM_infer -itd --privileged --user root --net=host --ipc=host --gpus=8 hunyuaninfer/hunyuan-large:infer-open-source</pre></div>
<p dir="auto">Note: Docker container privilege management. The above code uses privileged mode (<code>--privileged</code>) to start the Docker container, which grants the container higher privileges, increasing the risk of data leakage and cluster security threats. It is recommended to avoid using privileged mode unless necessary to reduce security risks. For scenarios where privileged mode is required, conduct a thorough security assessment and implement appropriate security monitoring and hardening measures.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configure Passwordless SSH Login Between Machines</h3><a id="user-content-configure-passwordless-ssh-login-between-machines-1" aria-label="Permalink: Configure Passwordless SSH Login Between Machines" href="#configure-passwordless-ssh-login-between-machines-1"></a></p>
<p dir="auto">The following steps use two machines as an example, with their IPs represented as <code>${ip1}</code> and <code>${ip2}</code>. These operations are performed within a Docker container.</p>
<p dir="auto">First, run <code>passwd</code> on both machines to set a password, for example: <code>Tmp123,./</code></p>
<p dir="auto">Copy <code>inference/login_ssh.py</code> into the container and execute the following command, ensuring the IP and password are correctly entered.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 login_ssh.py --ips ${ip1},${ip2} --port 36000 --password=Tmp123,./"><pre>python3 login_ssh.py --ips <span>${ip1}</span>,<span>${ip2}</span> --port 36000 --password=Tmp123,./</pre></div>
<p dir="auto"><strong>Note 📢: Before starting, be sure to verify multi-machine communication using VLLM's debugging script: <a href="https://docs.vllm.ai/en/latest/getting_started/debugging.html" rel="nofollow">https://docs.vllm.ai/en/latest/getting_started/debugging.html</a></strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">BF16 Deployment</h3><a id="user-content-bf16-deployment" aria-label="Permalink: BF16 Deployment" href="#bf16-deployment"></a></p>
<p dir="auto">BF16 requires 16 H800 or H20 GPUs for deployment. After verifying that multi-machine communication is correct, execute the following steps:</p>
<p dir="auto">Before running the commands, set the following environment variables:</p>
<div dir="auto" data-snippet-clipboard-copy-content="${LOCAL_IP}: The IP corresponding to bond1 on the current machine
${MODEL_PATH}: Path to the Hunyuan LLM model"><pre><span>${LOCAL_IP}</span>: The IP corresponding to bond1 on the current machine
<span>${MODEL_PATH}</span>: Path to the Hunyuan LLM model</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 1: Start Ray</h4><a id="user-content-step-1-start-ray" aria-label="Permalink: Step 1: Start Ray" href="#step-1-start-ray"></a></p>
<p dir="auto">Ray is an open-source library for parallel and distributed Python. In this section, we use Ray to achieve multi-machine communication.</p>
<p dir="auto">Ray Component Configuration Hardening: The default configuration of Ray components does not enable authentication mechanisms for service ports (e.g., 6379, 8265), posing risks of unauthorized access and command execution. It is recommended to deploy Ray components only in trusted internal network environments or ensure strict access control list (ACL) policies are implemented for these ports to prevent unauthorized network access.</p>
<p dir="auto">First, start Ray on each node (either in the background or by keeping the terminal running):</p>
<p dir="auto">On the head node:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export VLLM_HOST_IP=${LOCAL_IP}
export NCCL_SOCKET_IFNAME=bond1
export GLOO_SOCKET_IFNAME=bond1
ray start --block --head --node-ip-address=${LOCAL_IP} --port=6379"><pre><span>export</span> VLLM_HOST_IP=<span>${LOCAL_IP}</span>
<span>export</span> NCCL_SOCKET_IFNAME=bond1
<span>export</span> GLOO_SOCKET_IFNAME=bond1
ray start --block --head --node-ip-address=<span>${LOCAL_IP}</span> --port=6379</pre></div>
<p dir="auto">On all worker nodes:</p>
<p dir="auto">Note: Replace <code>{HEAD NODE $LOCAL_IP}</code> with the actual <code>${LOCAL_IP}</code> of the head node.</p>
<div dir="auto" data-snippet-clipboard-copy-content="export VLLM_HOST_IP=${LOCAL_IP}
export NCCL_SOCKET_IFNAME=bond1
export GLOO_SOCKET_IFNAME=bond1
ray start --block --address={HEAD NODE $LOCAL_IP}:6379 --node-ip-address=${LOCAL_IP}"><pre><span>export</span> VLLM_HOST_IP=<span>${LOCAL_IP}</span>
<span>export</span> NCCL_SOCKET_IFNAME=bond1
<span>export</span> GLOO_SOCKET_IFNAME=bond1
ray start --block --address={HEAD NODE <span>$LOCAL_IP</span>}:6379 --node-ip-address=<span>${LOCAL_IP}</span></pre></div>
<p dir="auto">If Ray fails to start, execute <code>ray stop</code> and then run the above commands again.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 2: Execute Inference</h4><a id="user-content-step-2-execute-inference" aria-label="Permalink: Step 2: Execute Inference" href="#step-2-execute-inference"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Method 1: Command Line Inference</h4><a id="user-content-method-1-command-line-inference" aria-label="Permalink: Method 1: Command Line Inference" href="#method-1-command-line-inference"></a></p>
<p dir="auto">Below is a code snippet demonstrating how to quickly request the chat model using <code>vLLM</code>:</p>
<p dir="auto">Note: vLLM Component Remote Code Execution Protection. In the code below, if the <code>trust-remote-code</code> configuration option of the vLLM component is enabled, it will allow loading and executing code from remote model repositories, which may lead to the execution of malicious code. Unless explicitly required by business needs, it is recommended to keep this configuration option disabled to reduce potential security threats.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import os
from vllm import LLM, SamplingParams

model_path=os.environ.get('MODEL_PATH')

llm = LLM(model=model_path,
        tokenizer=model_path,
        trust_remote_code=True,
        max_model_len=10240,
        dtype='bfloat16',
        tensor_parallel_size=16,
        pipeline_parallel_size=1,
        disable_log_stats=False,
        gpu_memory_utilization=0.98,
        disable_custom_all_reduce=True,
        #distributed_executor_backend='ray',
        enforce_eager=True,
        max_num_seqs=8,
        use_v2_block_manager=True,
        quantization=None)

prompts = [&quot;海水为什么是咸的&quot;]

sampling_params = SamplingParams(
    temperature=0.7, top_p=0.6, max_tokens=200, top_k=20, repetition_penalty=1.05)

outputs = llm.generate(prompts, sampling_params)

# Print the outputs.
for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f&quot;Prompt: {prompt!r}, Generated text: {generated_text!r}&quot;)"><pre><span>import</span> <span>os</span>
<span>from</span> <span>vllm</span> <span>import</span> <span>LLM</span>, <span>SamplingParams</span>

<span>model_path</span><span>=</span><span>os</span>.<span>environ</span>.<span>get</span>(<span>'MODEL_PATH'</span>)

<span>llm</span> <span>=</span> <span>LLM</span>(<span>model</span><span>=</span><span>model_path</span>,
        <span>tokenizer</span><span>=</span><span>model_path</span>,
        <span>trust_remote_code</span><span>=</span><span>True</span>,
        <span>max_model_len</span><span>=</span><span>10240</span>,
        <span>dtype</span><span>=</span><span>'bfloat16'</span>,
        <span>tensor_parallel_size</span><span>=</span><span>16</span>,
        <span>pipeline_parallel_size</span><span>=</span><span>1</span>,
        <span>disable_log_stats</span><span>=</span><span>False</span>,
        <span>gpu_memory_utilization</span><span>=</span><span>0.98</span>,
        <span>disable_custom_all_reduce</span><span>=</span><span>True</span>,
        <span>#distributed_executor_backend='ray',</span>
        <span>enforce_eager</span><span>=</span><span>True</span>,
        <span>max_num_seqs</span><span>=</span><span>8</span>,
        <span>use_v2_block_manager</span><span>=</span><span>True</span>,
        <span>quantization</span><span>=</span><span>None</span>)

<span>prompts</span> <span>=</span> [<span>"海水为什么是咸的"</span>]

<span>sampling_params</span> <span>=</span> <span>SamplingParams</span>(
    <span>temperature</span><span>=</span><span>0.7</span>, <span>top_p</span><span>=</span><span>0.6</span>, <span>max_tokens</span><span>=</span><span>200</span>, <span>top_k</span><span>=</span><span>20</span>, <span>repetition_penalty</span><span>=</span><span>1.05</span>)

<span>outputs</span> <span>=</span> <span>llm</span>.<span>generate</span>(<span>prompts</span>, <span>sampling_params</span>)

<span># Print the outputs.</span>
<span>for</span> <span>output</span> <span>in</span> <span>outputs</span>:
    <span>prompt</span> <span>=</span> <span>output</span>.<span>prompt</span>
    <span>generated_text</span> <span>=</span> <span>output</span>.<span>outputs</span>[<span>0</span>].<span>text</span>
    <span>print</span>(<span>f"Prompt: <span><span>{</span><span>prompt</span>!r<span>}</span></span>, Generated text: <span><span>{</span><span>generated_text</span>!r<span>}</span></span>"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Method 2: Service-Based Inference</h4><a id="user-content-method-2-service-based-inference" aria-label="Permalink: Method 2: Service-Based Inference" href="#method-2-service-based-inference"></a></p>
<p dir="auto">Below we demonstrate how to deploy the model using <code>vLLM</code> in a service-based manner and make requests.</p>
<p dir="auto">Run the following on the head node:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export VLLM_HOST_IP=${LOCAL_IP}
export NCCL_SOCKET_IFNAME=bond1
export GLOO_SOCKET_IFNAME=bond1"><pre><span>export</span> VLLM_HOST_IP=<span>${LOCAL_IP}</span>
<span>export</span> NCCL_SOCKET_IFNAME=bond1
<span>export</span> GLOO_SOCKET_IFNAME=bond1</pre></div>
<p dir="auto">Next, start the service by running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd inference
sh run_server.sh"><pre><span>cd</span> inference
sh run_server.sh</pre></div>
<p dir="auto"><em>Tips</em>: Troubleshooting, if you encounter the following error:</p>
<div dir="auto" data-snippet-clipboard-copy-content="ray.exceptions.RaySystemError: System error: No module named 'transformers_modules' traceback: Traceback (most recent call last):
ModuleNotFoundError: No module named 'transformers_modules'"><pre><span>ray</span>.<span>exceptions</span>.<span>RaySystemError</span>: <span>System</span> <span>error</span>: <span>No</span> <span>module</span> <span>named</span> <span>'transformers_modules'</span> <span>traceback</span>: <span>Traceback</span> (<span>most</span> <span>recent</span> <span>call</span> <span>last</span>):
<span>ModuleNotFoundError</span>: <span>No</span> <span>module</span> <span>named</span> <span>'transformers_modules'</span></pre></div>
<p dir="auto">Copy the <code>~/.cache/huggingface/modules/</code> directory from the head node to the corresponding path on all worker nodes.</p>
<p dir="auto">After successfully running <code>run_server.sh</code>, execute the request script:</p>

<p dir="auto">Be sure to modify <code>${LOCAL_IP}</code> and <code>${MODEL_PATH}</code> in <code>openapi.sh</code> to values match the corresponding service.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quantized Model Deployment:</h3><a id="user-content-quantized-model-deployment" aria-label="Permalink: Quantized Model Deployment:" href="#quantized-model-deployment"></a></p>
<p dir="auto">This section describes the process of deploying a quantized model using vLLM.</p>
<p dir="auto">Image: The deployment image is the same as for BF16.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Int8 Quantized Model Deployment:</h4><a id="user-content-int8-quantized-model-deployment" aria-label="Permalink: Int8 Quantized Model Deployment:" href="#int8-quantized-model-deployment"></a></p>
<p dir="auto">To deploy the Int8-weight-only version of the Hunyuan-L model, simply set the environment variables in <code>run_server_int8.sh</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="${MODEL_PATH}: Path to the BF16 model
${LOCAL_IP}: The IP corresponding to bond1 on the current machine"><pre><span>${MODEL_PATH}</span>: Path to the BF16 model
<span>${LOCAL_IP}</span>: The IP corresponding to bond1 on the current machine</pre></div>
<p dir="auto">Then, start the Int8 service by running:</p>

<p dir="auto">After successfully running <code>run_server_int8.sh</code>, execute the request script:</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">FP8 Quantized Model Deployment:</h4><a id="user-content-fp8-quantized-model-deployment" aria-label="Permalink: FP8 Quantized Model Deployment:" href="#fp8-quantized-model-deployment"></a></p>
<p dir="auto">To deploy the W8A8C8 version of the Hunyuan-L model, simply set the environment variables in <code>run_server_fp8.sh</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="${MODEL_PATH}: Path to the FP8 model
${LOCAL_IP}: The IP corresponding to bond1 on the current machine"><pre><span>${MODEL_PATH}</span>: Path to the FP8 model
<span>${LOCAL_IP}</span>: The IP corresponding to bond1 on the current machine</pre></div>
<p dir="auto">Then, start the FP8 service by running:</p>

<p dir="auto">After successfully running <code>run_server_fp8.sh</code>, execute the request script:</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">FP8 BENCHMARK</h4><a id="user-content-fp8-benchmark" aria-label="Permalink: FP8 BENCHMARK" href="#fp8-benchmark"></a></p>
<p dir="auto">This part introduces the Benchmark of Hunyuan Large Instruct FP8 quantitative model.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Dataset</th>
<th>BF16</th>
<th>W8A8C8-FP8</th>
</tr>
</thead>
<tbody>
<tr>
<td>ARC-C</td>
<td>94.6</td>
<td>94.2</td>
</tr>
<tr>
<td>C-Eval</td>
<td>88.6</td>
<td>89.2</td>
</tr>
<tr>
<td>CMMLU</td>
<td>90.4</td>
<td>89.8</td>
</tr>
<tr>
<td>MMLU</td>
<td>89.9</td>
<td>88.9</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Inference Performance</h3><a id="user-content-inference-performance" aria-label="Permalink: Inference Performance" href="#inference-performance"></a></p>
<p dir="auto">This section presents the efficiency test results of deploying various models (original and quantized) using vLLM, including inference speed (tokens/s) under different batch sizes.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Inference Framework</th>
<th>Model</th>
<th>Number of GPUs (H20)</th>
<th>input_length</th>
<th>batch=1</th>
<th>batch=4</th>
</tr>
</thead>
<tbody>
<tr>
<td>vLLM</td>
<td>Hunyuan-Large</td>
<td>16</td>
<td>2048</td>
<td>20.2</td>
<td>75.5</td>
</tr>
<tr>
<td>vLLM</td>
<td>Hunyuan-Large(int8 weight only)</td>
<td>8</td>
<td>2048</td>
<td>19.3</td>
<td>73.6</td>
</tr>
<tr>
<td>vLLM</td>
<td>Hunyuan-Large(W8A8C8-FP8)</td>
<td>8</td>
<td>2048</td>
<td>19.8</td>
<td>74.9</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tokenizer</h2><a id="user-content-tokenizer" aria-label="Permalink: Tokenizer" href="#tokenizer"></a></p>
<p dir="auto">The tokenizer used in the HunYuan-Large model balances compression rate and effectiveness, ensuring that embeddings are sufficiently trained. The vocabulary includes 100K tokens integrated from tiktoken. Additionally, we trained an extra 29K Chinese tokens using a large amount of high-quality Chinese training data to enhance the model's Chinese capabilities and the tokenizer's compression rate. Combined, our new tokenizer improves the compression rate compared to the LLaMA3 tokenizer, increasing from 2.78 characters/token to 3.13 characters/token.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hunyuan API</h2><a id="user-content-hunyuan-api" aria-label="Permalink: Hunyuan API" href="#hunyuan-api"></a></p>
<p dir="auto">You can experience our Hunyuan-Large model on Tencent Cloud. For details, please visit: <a href="https://cloud.tencent.com/document/product/1729/97730" rel="nofollow">https://cloud.tencent.com/document/product/1729/97730</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interactive Demo Web</h2><a id="user-content-interactive-demo-web" aria-label="Permalink: Interactive Demo Web" href="#interactive-demo-web"></a></p>
<p dir="auto">The Hunyuan-Large web demo is now open. Visit <a href="https://huggingface.co/spaces/tencent/Hunyuan-Large" rel="nofollow">https://huggingface.co/spaces/tencent/Hunyuan-Large</a> to easily experience our model.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Training/Inference on TI</h2><a id="user-content-traininginference-on-ti" aria-label="Permalink: Training/Inference on TI" href="#traininginference-on-ti"></a></p>
<p dir="auto">Tencent Cloud's <a href="https://cloud.tencent.com/product/ti" rel="nofollow">TI Platform</a> is a comprehensive machine learning platform tailored for AI engineers. With the Hunyuan-Large model already integrated, you can easily train and deploy it in just a few steps. Visit <a href="https://console.cloud.tencent.com/tione/v2/aimarket/detail/hunyuan_series?PublicAlgoGroupId=hunyuan-large-chat&amp;detailTab=demo" rel="nofollow">Chat with Hunyuan-Large</a> to experience real-time conversations with the model, and explore <a href="https://cloud.tencent.com/document/product/851/112032" rel="nofollow">Hunyuan-Large Best Practice on TI</a> to create your own customized Hunyuan-Large model.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you find our work helpful, feel free to give us a cite.</p>
<div data-snippet-clipboard-copy-content="@misc{sun2024hunyuanlargeopensourcemoemodel,
      title={Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent}, 
      author={Xingwu Sun and Yanfeng Chen and Yiqing Huang and Ruobing Xie and Jiaqi Zhu and Kai Zhang and Shuaipeng Li and Zhen Yang and Jonny Han and Xiaobo Shu and Jiahao Bu and Zhongzhi Chen and Xuemeng Huang and Fengzong Lian and Saiyong Yang and Jianfeng Yan and Yuyuan Zeng and Xiaoqin Ren and Chao Yu and Lulu Wu and Yue Mao and Tao Yang and Suncong Zheng and Kan Wu and Dian Jiao and Jinbao Xue and Xipeng Zhang and Decheng Wu and Kai Liu and Dengpeng Wu and Guanghui Xu and Shaohua Chen and Shuang Chen and Xiao Feng and Yigeng Hong and Junqiang Zheng and Chengcheng Xu and Zongwei Li and Xiong Kuang and Jianglu Hu and Yiqi Chen and Yuchi Deng and Guiyang Li and Ao Liu and Chenchen Zhang and Shihui Hu and Zilong Zhao and Zifan Wu and Yao Ding and Weichao Wang and Han Liu and Roberts Wang and Hao Fei and Peijie She and Ze Zhao and Xun Cao and Hai Wang and Fusheng Xiang and Mengyuan Huang and Zhiyuan Xiong and Bin Hu and Xuebin Hou and Lei Jiang and Jiajia Wu and Yaping Deng and Yi Shen and Qian Wang and Weijie Liu and Jie Liu and Meng Chen and Liang Dong and Weiwen Jia and Hu Chen and Feifei Liu and Rui Yuan and Huilin Xu and Zhenxiang Yan and Tengfei Cao and Zhichao Hu and Xinhua Feng and Dong Du and Tinghao She and Yangyu Tao and Feng Zhang and Jianchen Zhu and Chengzhong Xu and Xirui Li and Chong Zha and Wen Ouyang and Yinben Xia and Xiang Li and Zekun He and Rongpeng Chen and Jiawei Song and Ruibin Chen and Fan Jiang and Chongqing Zhao and Bo Wang and Hao Gong and Rong Gan and Winston Hu and Zhanhui Kang and Yong Yang and Yuhong Liu and Di Wang and Jie Jiang},
      year={2024},
      eprint={2411.02265},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.02265}, 
}"><pre><code>@misc{sun2024hunyuanlargeopensourcemoemodel,
      title={Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent}, 
      author={Xingwu Sun and Yanfeng Chen and Yiqing Huang and Ruobing Xie and Jiaqi Zhu and Kai Zhang and Shuaipeng Li and Zhen Yang and Jonny Han and Xiaobo Shu and Jiahao Bu and Zhongzhi Chen and Xuemeng Huang and Fengzong Lian and Saiyong Yang and Jianfeng Yan and Yuyuan Zeng and Xiaoqin Ren and Chao Yu and Lulu Wu and Yue Mao and Tao Yang and Suncong Zheng and Kan Wu and Dian Jiao and Jinbao Xue and Xipeng Zhang and Decheng Wu and Kai Liu and Dengpeng Wu and Guanghui Xu and Shaohua Chen and Shuang Chen and Xiao Feng and Yigeng Hong and Junqiang Zheng and Chengcheng Xu and Zongwei Li and Xiong Kuang and Jianglu Hu and Yiqi Chen and Yuchi Deng and Guiyang Li and Ao Liu and Chenchen Zhang and Shihui Hu and Zilong Zhao and Zifan Wu and Yao Ding and Weichao Wang and Han Liu and Roberts Wang and Hao Fei and Peijie She and Ze Zhao and Xun Cao and Hai Wang and Fusheng Xiang and Mengyuan Huang and Zhiyuan Xiong and Bin Hu and Xuebin Hou and Lei Jiang and Jiajia Wu and Yaping Deng and Yi Shen and Qian Wang and Weijie Liu and Jie Liu and Meng Chen and Liang Dong and Weiwen Jia and Hu Chen and Feifei Liu and Rui Yuan and Huilin Xu and Zhenxiang Yan and Tengfei Cao and Zhichao Hu and Xinhua Feng and Dong Du and Tinghao She and Yangyu Tao and Feng Zhang and Jianchen Zhu and Chengzhong Xu and Xirui Li and Chong Zha and Wen Ouyang and Yinben Xia and Xiang Li and Zekun He and Rongpeng Chen and Jiawei Song and Ruibin Chen and Fan Jiang and Chongqing Zhao and Bo Wang and Hao Gong and Rong Gan and Winston Hu and Zhanhui Kang and Yong Yang and Yuhong Liu and Di Wang and Jie Jiang},
      year={2024},
      eprint={2411.02265},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.02265}, 
}
</code></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">Contact Us</h2><a id="user-content-contact-us" aria-label="Permalink: Contact Us" href="#contact-us"></a></p>
<p dir="auto">If you would like to leave a message for our R&amp;D and product teams, Welcome to contact our open-source team . You can also contact us via email (<a href="mailto:hunyuan_opensource@tencent.com">hunyuan_opensource@tencent.com</a>).</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>