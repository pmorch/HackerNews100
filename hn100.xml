(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 04 Aug 2025 20:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Offline.kids – Screen-free activities for kids (124 pts)]]></title>
            <link>https://offline.kids/</link>
            <guid>44789192</guid>
            <pubDate>Mon, 04 Aug 2025 17:50:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://offline.kids/">https://offline.kids/</a>, See on <a href="https://news.ycombinator.com/item?id=44789192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><ul><li>
<figure><a href="https://offline.kids/teaching-kids-to-lose-gracefully/" target="_self"><img loading="lazy" decoding="async" width="1536" height="1024" src="https://offline.kids/wp-content/uploads/2025/06/Teaching-Kids-to-Lose-Gracefully.png" alt="Teaching Kids to Lose Gracefully" srcset="https://offline.kids/wp-content/uploads/2025/06/Teaching-Kids-to-Lose-Gracefully.png 1536w, https://offline.kids/wp-content/uploads/2025/06/Teaching-Kids-to-Lose-Gracefully-300x200.png 300w" sizes="auto, (max-width: 1536px) 100vw, 1536px"></a></figure>

<p><time datetime="2025-06-05T08:26:49+00:00">June 5, 2025</time></p>

<h2><a href="https://offline.kids/teaching-kids-to-lose-gracefully/" target="_self">Teaching Kids to Lose Gracefully</a></h2>

<div><p>Losing a game can feel devastating for kids — but it’s also an important opportunity to help them build resilience and empathy. In this gentle guide, we share practical tips for parents and carers to support children in learning how to handle setbacks with confidence and grace.</p><p><a href="https://offline.kids/teaching-kids-to-lose-gracefully/">View post</a></p></div>
</li><li>
<figure><a href="https://offline.kids/solo-play-ideas-for-kids-when-you-need-a-moment/" target="_self"><img loading="lazy" decoding="async" width="1536" height="1024" src="https://offline.kids/wp-content/uploads/2025/06/Solo-Play-Activities.png" alt="Solo Play Ideas for Kids (When You Need a Moment)" srcset="https://offline.kids/wp-content/uploads/2025/06/Solo-Play-Activities.png 1536w, https://offline.kids/wp-content/uploads/2025/06/Solo-Play-Activities-300x200.png 300w" sizes="auto, (max-width: 1536px) 100vw, 1536px"></a></figure>

<p><time datetime="2025-05-29T11:40:34+00:00">May 29, 2025</time></p>

<h2><a href="https://offline.kids/solo-play-ideas-for-kids-when-you-need-a-moment/" target="_self">Solo Play Ideas for Kids (When You Need a Moment)</a></h2>

<div><p>Sometimes kids need something they can do on their own — while you’re on a work call, cooking dinner, or just taking a breath. Here’s a list of solo activities you can try with your child, grouped by age. Some are linked to full activity guides on Offline.Kids, and others are simple ideas you can…</p><p><a href="https://offline.kids/solo-play-ideas-for-kids-when-you-need-a-moment/">View post</a></p></div>
</li><li>
<figure><a href="https://offline.kids/wed-love-your-feedback-help-shape-offline-kids/" target="_self"><img loading="lazy" decoding="async" width="1536" height="1024" src="https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration.png" alt="We’d Love Your Feedback – Help Shape Offline.Kids" srcset="https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration.png 1536w, https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration-300x200.png 300w, https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration-1024x683.png 1024w, https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration-768x512.png 768w" sizes="auto, (max-width: 1536px) 100vw, 1536px"></a></figure>

<p><time datetime="2025-05-22T13:36:59+00:00">May 22, 2025</time></p>

<h2><a href="https://offline.kids/wed-love-your-feedback-help-shape-offline-kids/" target="_self">We’d Love Your Feedback – Help Shape Offline.Kids</a></h2>

<div><p>Hi there 👋 Offline.Kids is a passion project — started by a tired parent (me!) looking for simple, low-effort ways to spend meaningful time with my daughter. If you’ve ever found yourself Googling “easy activities for kids” with one eye on the clock and the other on your coffee, you’re in the right place. Now…</p><p><a href="https://offline.kids/wed-love-your-feedback-help-shape-offline-kids/">View post</a></p></div>
</li><li>
<figure><a href="https://offline.kids/smartphone-free-childhood-create-powerful-new-video/" target="_self"><img loading="lazy" decoding="async" width="1280" height="720" src="https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb.jpg" alt="Smartphone Free Childhood create powerful new video" srcset="https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb.jpg 1280w, https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb-300x169.jpg 300w, https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb-1024x576.jpg 1024w, https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb-768x432.jpg 768w" sizes="auto, (max-width: 1280px) 100vw, 1280px"></a></figure>

<p><time datetime="2025-05-22T10:53:34+00:00">May 22, 2025</time></p>

<h2><a href="https://offline.kids/smartphone-free-childhood-create-powerful-new-video/" target="_self">Smartphone Free Childhood create powerful new video</a></h2>

<div><p>Discover how the Smartphone Free Childhood movement is empowering parents and carers to protect kids from smartphone harm — with community, courage, and hope.</p><p><a href="https://offline.kids/smartphone-free-childhood-create-powerful-new-video/">View post</a></p></div>
</li></ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I asked four former friends why we stopped speaking (2023) (108 pts)]]></title>
            <link>https://www.vogue.com/article/reconnecting-with-ex-friends</link>
            <guid>44788783</guid>
            <pubDate>Mon, 04 Aug 2025 17:18:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vogue.com/article/reconnecting-with-ex-friends">https://www.vogue.com/article/reconnecting-with-ex-friends</a>, See on <a href="https://news.ycombinator.com/item?id=44788783">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" tabindex="-1"><article lang="en-US"><div><header><div data-testid="ContentHeaderContainer"><figure><div><p><span><div data-testid="aspect-ratio-container"><picture><source media="(max-width: 767px)" srcset="https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_120,c_limit/00-story%20(2).jpg 120w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_240,c_limit/00-story%20(2).jpg 240w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_320,c_limit/00-story%20(2).jpg 320w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_640,c_limit/00-story%20(2).jpg 640w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_960,c_limit/00-story%20(2).jpg 960w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_120,c_limit/00-story%20(2).jpg 120w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_240,c_limit/00-story%20(2).jpg 240w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_320,c_limit/00-story%20(2).jpg 320w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_640,c_limit/00-story%20(2).jpg 640w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_960,c_limit/00-story%20(2).jpg 960w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_1280,c_limit/00-story%20(2).jpg 1280w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_1600,c_limit/00-story%20(2).jpg 1600w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_1920,c_limit/00-story%20(2).jpg 1920w, https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_2240,c_limit/00-story%20(2).jpg 2240w" sizes="100vw"><img alt="Women at beach with tear running through it" src="https://assets.vogue.com/photos/64e9155ea6d093ac3c19bb62/master/w_2560%2Cc_limit/00-story%2520(2).jpg"></picture></div></span></p><p><span>Photo: Getty Images</span></p></div></figure></div></header></div><div data-testid="ArticlePageChunks" data-attribute-verso-pattern="article-body"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>On a warm July evening, I dove into bed and grabbed my phone, giddy and anxious. As I scrolled through TikTok, attempting to calm my nerves, a Google Calendar notification flashed on the screen: “VIDEO CALL WITH SIMONE.”</p><p>Before I could swipe the reminder away, Simone FaceTimed me. I attempted to rehearse my greeting as the call buffered: <em>Should I keep it cool with a, “Hey, what’s good?” No, that sounds cold. What about a Keke Palmer-esque, “Girl!” No, that’s doing too much. “Good evening?” No, it’s not evening her time, that doesn’t even make sen—</em></p><p>“Girl!” Simone said with a chuckle.</p><p>I couldn’t help but crack a smile. As I’d learned over the course of our six-year friendship, her warmth never failed to replace my anxiety with joy.</p><p>“Damn, it’s been a <em>minute</em>.” she added.</p><p>She was right. Though Simone is my closest friend, we don’t see or talk to each other often. Both are my fault. In 2020, after months holed up in my tiny Washington, D.C. apartment, I decided to wait out the winter at my mother’s cottage in Kenya. It was just what the doctor ordered, and a few months later, I decided to move to Nairobi permanently.</p><p>My move changed our friendship—it changed <em>all</em> of my friendships, actually. I tried to stay in touch with my friends stateside for a while, but as time went on, FaceTime dates became harder to plan, and fewer voice notes were exchanged via WhatsApp. Now, I don’t know if I can call any of them friends anymore—and my relationship with Simone felt like it was hanging by a thread.</p><p>Things in Kenya aren’t much better. Though I’m Kenyan by ethnicity, I grew up abroad, in the US and UK, and I’ve found that my foreign accent and perspective other me, even within my family. These days, my social life tends to begin and end with nights on the couch, re-watching <em>Shameless</em> with my boyfriend. I’m ashamed and terrified about that reality; it feels dangerous to rely on only him for human connection.</p><p>After all, friends are witnesses to your life. They enrich the living experience. Not having that makes me feel like that tree that falls in the forest alone: Can anybody hear me? Do I matter?</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Marriage and family therapist Shontel Cargill promises me that these feelings are normal. She says that friendship loss in one’s mid-to-late 20s is common for several reasons: life transitions, romantic relationships, evolution of priorities, and more. And while it doesn’t happen to everyone, for some, friendship loss “can lead to psychological distress,” sparking issues with anxiety, depression, trust, and self-esteem. <em>Check, check, check, and check.</em></p><p>Cargill says that talking about your struggles with others can help the healing process, but I’ll be honest—that hasn’t worked for me. Most people I’ve spoken to about my predicament don’t get it, which only makes me feel worse. I tried to bring it up on my aforementioned call with Simone, but her empathetic smile and pitying eyes said it all: She couldn’t relate. Lucky her.</p><p>I needed answers. Concrete ones—not those generic suggestions that I “put myself out there” or “just give it time.” Everyone around me had managed to hold on to friends throughout their lives; everyone seemed to be on girls’ trips and boozy brunches; seemed to have a tribe of confidants ready to drop everything for them. And here I was, a lonely, overworked 28-year-old who spent way too much time in her apartment, wondering why she didn’t have any of that.</p><p>So, like a good journalist, I decided to investigate. After speaking to Simone, I determined that I’d reach out to some of my former friends directly, and see if we could have a conversation about why we “broke up.” Many declined, and understandably so. But to my surprise, a few agreed to participate in my crazy scheme.&nbsp;</p><p>Here are those conversations—and their revelations. Their names have been changed.</p><p>Celine</p><p>Circumstance brought Celine and me together. We were both new freshmen at an international school in Nairobi, and our shared fear proved the perfect BFF elixir. Celine was sweet and reserved, with a quiet confidence that I admired—even more so when I got older. But she wanted to do her own thing and I, a not-so-confident 14-year-old, wanted to fit in. I had a hunger for popularity, and when I realized that Celine didn’t share that, I neglected the friendship. Soon, it evaporated.</p><p>Celine remembered things similarly.</p><p>“Once school started, we new kids were initially welcomed into the group of ‘misfits’ that every high school has,” she wrote to me via Facebook. “But eventually, we broke away—you, to join the funny kids, a group of hilarious and friendly people who could match your unparalleled wit and high-octane energy and me, to join the kids at the back of the bus, literally and figuratively.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>I thought that by the end of high school, we were strangers. But Celine reminded me that we had our special moments, and that there was always love between the two of us. “By senior year, we were moving in completely different circles, even in our somewhat tiny school. But, to my mind, there wasn’t an acrimonious end to our friendship, and we could always share a funny moment here and there. We just evolved in different directions,” she wrote.</p><p>Celine’s kindness surprised me—the pain of friendship breakups past had colored the way I thought about <em>all</em> of my former chums. I forgot that people can grow apart and still love each other from afar. Celine lives in Europe, and the chances of us revitalizing our former bond are slim. But I feel a sense of peace, knowing that we’ll always be rooting for each other.</p><p>Steve</p><p>My cousin Steve and I have always had a love-hate relationship. I despised him when we were young—during one squabble, I was so consumed with fury that I took our shared Game Boy Advance and threw it down the stairs, destroying it—but, peppered throughout my memories of us going toe-to-toe are flashes of roaring laughter. The more joyful side of our relationship really developed when I started at the international school. He had already been a student there for a few years, and to my surprise, he took me under his wing. Those were some of the best years of my life—we partied (arguably too much), we cried, we learned. We were free. And when my boyfriend died in a tragic accident during our senior year, Steve became my fiercest protector. He allowed me to grieve, however I chose to. When he held my hand it felt like he’d never let go.</p><p>But he did, because he had to. It was time to go to college, and for us to have our own adventures. I tried to stay connected to him, but it didn’t seem like he was interested in pursuing an adult friendship. Texts would go unanswered, calls missed, and after a while, my bond with Steve felt as lost as my youth.</p><p>When I first floated the idea of this article to Steve, he didn’t think our relationship qualified. “We’re family,” he explained on WhatsApp. “And the thing about family is, relationships can wax and wane and friends drift apart, but, you know, families still have to come back together.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>That is true. Steve and I are bonded by blood, so he’ll always be a part of my life in some capacity. But being family is not synonymous with being friends, and I think the understanding that we’re irrevocably tied may be part of why we aren’t close anymore. Why try, when I know I’ll see you at some cousin’s wedding or brother’s baby shower?</p><p>So, we had another conversation. Steve was hesitant—it took weeks for him to get back to me—and he didn’t say much, but he did change the way I looked at our estrangement.</p><p>He described what he considered a defining moment in our friendship’s collapse. In 2017, Steve and I both found ourselves living at home in Kenya, depressed and unemployed. Our college years were tough, and we needed a break to figure things out. Looking back, I remember my own pain being my top priority. I barely noticed that Steve was struggling too, and it goes without saying that I wasn’t there for him. We were in Kenya for months, but only spent one, disastrous night together, when we barely spoke. (I, for one, was too busy making out with my cousin’s friend.)</p><p>“I don’t know if you remember that night, but I remember I took you home and spent all night talking to you and consoling you,” Steve told me. He went on to explain that at the time, we were in exactly the same place emotionally, but we weren’t there for each other. “We were both Kenyan-Americans who had this lovely upbringing, and we both faced trials and adversities when it comes to the United States,” he recounted. “We almost had to come back home to recuperate, and to find some sort of moral guide. We were going through something so similar and there were so many anecdotes and so much support that we could have given to one another, but we really didn't.”</p><p>If anything, Steve found our relationship one-sided, feeling that the support he showed me was never reciprocated. But that, I argued, wasn’t <em>entirely</em> fair. I’ve tried to be there for Steve over the years, but he’s evasive and holds his emotions very close to his chest. How can I show up for someone who doesn’t let me in?</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>This, he could understand. “I’m usually the one who’s more distant,” he admitted.</p><p>Yet Steve asked an interesting question toward the end of the conversation—one that I can’t stop thinking about. “Can we boil down our lack of a relationship to a series of instances?” He asked. “Or is it more that at some point, neither of us felt lonely enough to put in the work to maintain the relationship?”</p><p>Our conversation ended with Steve suggesting that closeness comes solely from in-person interactions. Because he lives stateside and I’m in Kenya, the likelihood of us having that time is slim to none. I don’t know where my relationship with Steve stands now, but I do know that I feel defeated and misunderstood by him. Maybe that will change one day, but if not, I’ll just have to be content with the friendship we had—or, the one <em>I</em> thought we had, anyway.</p><p>Matt</p><p>Matt, I met in college. He was a year older, and worked behind the front desk of my dorm. It wasn’t long before his polite smiles as I entered the building graduated to conversations about classes, crushes, and Greek life. Soon after that, we became proper friends.</p><p>Matt was the first person who made college feel like home to me. He made the <em>US</em> feel like home. I hadn’t lived stateside in years, and to my surprise, I was out of the loop with American culture. I often felt out of place—except, that is, when I was with Matt. A white Texan-Californian whose family runs a 5K every Thanksgiving, he was, to my surprise, made of everything I was made of.</p><p>It’s possible that even then, our connection wasn’t the healthiest. I remember being jealous of his other relationships, particularly with our mutual friend Madison. As they grew closer, I felt left out, and like I had to fight for his love and attention. I sensed that Matt knew what was happening, and that he didn’t like what he saw.</p><p>Years passed, and Matt and I remained close, even after we both graduated from college. But then, he decided to move back to Texas.</p><p>I don’t know why Matt and I didn’t try harder to stay in touch. I wanted to visit him, but my minimum-wage salary was not going to cover travel costs. He seemed to have little interest in texts or FaceTimes, but I would still try to reach out every now and again to see how he was doing. He was nice enough during those virtual interactions, but it was clear he had moved on. I found myself wondering if our relationship meant more to me than it did to him.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Those insecurities came to a head a few years ago. My boyfriend and I were in a really bad place, and I found myself alone and devastated. I needed a friend, so I reached out to Matt—and boy, did I trauma dump on him. He was kind and listened patiently, but I didn’t hear from him for months after that. Then, when he finally resurfaced, he leveled with me, explaining that what I had gone through was a lot to be confronted with, especially after we hadn’t spoken in a while. As a somewhat overly emotional person with deep abandonment issues, that was all I needed to hear. I got it, but I was crushed. I’m still crushed.</p><p>“I think you’re really hard on yourself,” Matt said in a voice message recently, when I rehashed all of this. It wasn’t that I had driven him away, he urged, but that he (like Steve) had a different communication style, and was more reticent. “I’m hyper-focused on whatever environment I’m in at the moment, and I know that seems really annoying to say, but that hyper-awareness stops me from reaching out to people,” he continued. “l think about you every single day—like, you are one of my best friends in my entire life—but I’m so bad at reminding you and other people I love of that.”</p><p>As I wiped away tears, Matt went on to open up about how he’s changed over the years, and how it’s shifted the way he looks at the Boyfriend Incident. He explained that back then, he’d thought that relationships were simple: If you and your beau weren’t getting along, you should leave him. That mentality affected the way that he responded to my woes. Besides, he’d been going through troubles of his own. “I don’t think either of us were in a good place,” he confessed.</p><p>Matt said a lot of wonderful things about me and our friendship during our conversation, but one thing meant the most. “In my mid 20s, I was really selfish,” he said. “But I’m currently at a point where I don’t really care about things for myself. Now that I’m almost 30, my loved ones and my friendship are all that really matter.”</p><p>I was so inspired by Matt’s introspection. Not only did it give me hope for our future as friends, but it also felt like proof that these conversations, however hard and emotional, were worth it.</p><p>Dominique</p><p>When I first met Dominique, I was sure we would be friends forever. It was sorority rush, and amid the sea of women I spoke to that hellish week, Dominique stood out. That wasn’t only because we were two of the handful of Black women participating in the Greek process; Dominique was also fabulous and accessible, she was effortlessly warm and hilarious, and she had a glow that reminded you not to take life too seriously.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>I learned to love everything about Dominique—not just her star quality, but also her vulnerability, her darkness. She quickly became my most treasured friend. There wasn’t anything we couldn’t do or talk about. We could party together, we could drink wine at home together, we could cry together, we could gently call each other out. We could save each other.</p><p>I didn’t want to do anything without her by my side.</p><p>I can’t pinpoint when things changed in our friendship. I had to leave college for a semester due to medical issues, and during that period I was disengaged from everyone close to me. It cost me a lot of friends, including Dominique, to an extent. When I returned, she was distant. She had graduated and was moving on from our college life, yes, but the rift felt deeper than that. She wasn’t there when I needed her most, but I also wasn’t telling her what I needed.</p><p>I held onto that resentment, and Dominique and I continued to grow apart. She found herself in a dangerously toxic relationship, and instead of helping her, I just worried from afar.</p><p>Out of all of these daunting conversations with my former friends, I was most nervous to talk to Dominique. I knew I’d failed her as a friend, and I wasn’t sure if I was prepared for her to not-so-gently call me out on it.</p><p>Yet she did the opposite. She couldn’t have been kinder or more gracious about what happened between us. “I am in my maturity now, [and] I have come to an understanding and a realization that I am not a person that’s good at maintaining friendships,” she confessed to me. I was shocked. Beautiful, brilliant, lovely Dominique, not good with friendships? 2015 me wouldn’t have believed it.</p><p>It turns out that Dominique felt the same way I did. She’d thought I’d shut her out, and instead of talking to me about it, she’d taken a step back. <em>Maybe we’re not as close as I think we are</em>, she’d mused, adding that she felt “out of the loop” when I was struggling with my health. She’d become “comfortable with the idea [that] there were other people that were closer to you than me.” All the while, I’d thought that <em>I</em> wasn’t as important to her as she was to me. We both agreed that nothing concrete had happened; neglected feelings had just led us to stop communicating.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>I can’t believe Dominique and I waited so many years to have this conversation. I’d harbored so much guilt, confusion, and pain over our friendship. It had haunted me, and played a big role in the way I saw myself as a friend. And all this time, Dominique had thought the same of herself.</p><p>I don’t know if Dominique and I will ever be friends like we used to be, but the olive branch has been extended. And, for the first time, I feel hopeful.</p><p>At first, my motivation for talking to my former friends about why we fell out of touch was a little masochistic. I thought I was a bad friend, and my loneliness was a product of my own self-centeredness, my stubbornness, my tendency to either vent or withhold. I thought I deserved to be punished by the people I’d wronged.</p><p>I’m not walking away from these conversations with the conviction that I’m a <em>good</em> friend, or even a good person. However, talking with my ex-friends did remind me that loving people—even platonically—isn’t easy. Sometimes you hurt your friends, sometimes they hurt you, and sometimes there’s no hurt at all, but they still fade away like a memory. Life is short, but it’s long, too. If you’re lucky, people will come in and out of your life and, for however long they’re there, you’ll feel loved.</p><p>So, should I tackle my ex-boyfriends next?</p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I spent 6 years building a ridiculous wooden pixel display (435 pts)]]></title>
            <link>https://benholmen.com/blog/kilopixel/</link>
            <guid>44787902</guid>
            <pubDate>Mon, 04 Aug 2025 16:16:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benholmen.com/blog/kilopixel/">https://benholmen.com/blog/kilopixel/</a>, See on <a href="https://news.ycombinator.com/item?id=44787902">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h2>TL,DR: I built the world's most impractical 1000-pixel display and anyone in the world can draw on it</h2>

<iframe width="560" height="315" src="https://www.youtube.com/embed/4OUF7sfAuHA?si=f_ypc5pkT7tevWDZ&amp;controls=0&amp;modestbranding=1&amp;rel=0&amp;showinfo=0&amp;autoplay=1&amp;mute=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>If you just want to play with it, goto <a href="https://kilopx.com/?ref=blog">kilopx.com</a>.</p>

<h3>The backstory</h3>

<p>Six years ago I had an idea to build a large, inefficient display with a web interface that anyone could interact with. I've enjoyed <a href="https://en.wikipedia.org/wiki/Danny_Rozin">Danny Rozin's unconvenional mirrors</a> over the years and was inspired by an <a href="https://github.com/TomWhitwell/SlowMovie">eInk movie player that played at 24 frames per <em>hour</em></a> that got me thinking about a laborious display that could slowly assemble an image.</p>

<p>I landed on the idea of a 40×25 pixel grid of pixels, turned one by one by a single mechanism. Compared to our modern displays with millions of pixels changing 60 times a second, a wooden display that changes a single pixel 10 times a <em>minute</em> is an incredibly inefficient way to create an image. Conveniently, 40×25 = 1,000 pixels, leading to the name <em>Kilopixel</em> and the six-letter domain name <a href="https://kilopx.com/?ref=blog">kilopx.com</a>. How do you back down from that? That's the best domain name I've ever owned.</p>

<p>So I got to work. This project has everything: a web app, a physical controller, a custom CNC build, generated gcode, tons of fabrication, 3d modeling, 3d printing, material sourcing - so much to get lost in. It's the most ambitious project I've ever built.</p>

<h3>The first prototype: 21×3 pixels</h3>

<p>My first thought was to use a wooden gantry that would ride on some sort of track. Since I'm most comfortable working with wood, it's my default prototyping medium. However, I quickly pivoted to extruded aluminum and the excellent <a href="https://openbuildspartstore.com/v-slot-linear-rail-1/">hardware kits from Openbuilds</a> that include pulleys, gantry parts, extruded aluminum, and timing belts. It's very similar to the materials used in 3D printer frames, and connects very easily with off the shelf stepper motors. This allowed me to build a gantry with X and Y, essentially a wall-mounted XY plotter. I built the first prototype with two stepper motors, a Raspberry Pi, a CNC controller, and a beefy power supply. It allowed me to generating and sending instructions to the CNC controller to move to a particular pixel, turning that pixel, and reading values from sensors. It also revealed quite a few problems with my pixel choices and pixel manipulation mechanisms.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/prototype-1-1.jpg" alt="The first prototype" width="1440" height="1440" loading="lazy"></p>

<h3>1,000 of anything is <em>expensive</em></h3>

<p>Picking pixels was a real adventure. I've tried ping pong balls, styrofoam balls, bouncy balls, wooden balls, 3d printed balls, golf balls, foam balls...anything approximately spherical and about 1-1.5in in diameter. The problems I encountered were largely cost (even a 50¢ ball is $500 of balls), weight (again, a thousand of these things), and availability. For a long time I thought ping pong balls were my best bet, so I purchased a few hundred of them, 3d printed painting jigs, and spray painted them. I used a hot nail to melt two opposite holes on each ball so they could be strung up on the display.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/ping-pong-pixels-1.jpg" alt="Painting ping pong pixels" width="1080" height="1080" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/ping-pong-pixels-2.jpg" alt="Painting ping pong pixels" width="1080" height="1080" loading="lazy">
</p>

<h3>Ping pong balls are basically soda cans</h3>

<p>You can stand on a soda can, <em>as long as it's not open</em>. Open the can, and it crushes easily. Ping pong balls are the same way. They're relatively strong until you melt two holes in them. Then they can be deformed, which is fatal to any spray paint you've put on them. And not only are they fragile, but the cheap ones are inconsistently sized, and a half millimeter here and there adds up when you have a row of 40 balls. Ping pong balls were a no-go.</p>

<h3>Nerfed</h3>

<p>My next attempt at a cheap, spherical pixel was foam Nerf balls - much smaller than ping pong balls, and only available in bright colors. They accepted spray paint OK but the paint deteriorated over time.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/prototype-2-pixel-1.jpg" alt="Nerf balls covered in black paint" width="1440" height="1920" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/prototype-2-pixel-2.jpg" alt="Nerf balls half painted in black paint" width="1440" height="1920" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/prototype-2.jpg" alt="The second prototype" width="1440" height="1080" loading="lazy">
</p>

<p>It was difficult to consistently bore a hole through the nerf balls, and they really liked to grab the wire and were hard to turn. I struggled to consistently turn them and I wasn't thrilled with the bright colors.</p>

<p>I also tried bouncy balls (hard to drill a hole, hard to paint, inconsistent sizes, heavy), wooden balls (not very round, hard to paint a crisp line, heavy), and styrofoam balls (hard to paint with acrylic paint, and they melt with spray paint).</p>

<h3>Turning balls</h3>

<p>I had the idea to use a small, slow motor to rotate a LEGO wheel against the ping pong ball. I'd use a reflectivity sensor to detect if it was showing black or white, and stop once the pixel was rotated properly. I modeled and printed a custom hub for a LEGO wheel, a few different mechanisms to move the wheel in and out of contact of the sphere, and an interface for the gantry. I tried using a solenoid to push the motor into the ball, which was underpowered, and a servo. Neither approach worked great and ultimately I decided this ball turning approach was a dead end.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/gantry-with-servo.png" alt="Gantry mechanism with servo" width="906" height="970" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/lego-wheel-hub.png" alt="LEGO wheel hub" width="906" height="970" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/prototype-2-wheel.jpg" alt="Wheel turning mechanism" width="1440" height="1080" loading="lazy">
</p>

<h3>Pivoting to non-spherical pixels</h3>

<p>In 2024 I had a couple of productive conversations with <a href="https://sideprojectpodcast.com/episodes/kilopixel-with-ben-holmen">Joe Tannenbaum on the Side Project podcast</a> and <a href="https://overengineered.fm/episodes/the-art-of-pairing-with-strangers-w-ben-holmen">Chris Morrell on the Over Engineered podcast</a>. Those conversations helped me consider that maybe balls were not the way to go - I thought about flaps and illuminated buttons, then settled on a cubic wooden pixel. I also decided to manufacture the pixels myself because I'm very comfortable in my wood shop. This decision cost me a huge amount of time because doing things one thousand times takes <em>forever</em>, but I was really pleased with how it operated and looked.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/painting-timelapse.gif" alt="Painting a thousand pixels timelapse" width="480" height="270" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/finished-pixel.jpg" alt="Finished pixel" width="1440" height="1080" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/many-pixels.jpg" alt="Hundreds of pixels" width="1440" height="1080" loading="lazy">
</p>

<h3>Building the grid</h3>

<p>I'd learned from earlier prototypes that I needed to strictly define a grid and not depend on the pixels themselves for spacing. That 40mm pixel might be 39.5mm, or 41mm. And that variation adds up across 40 pixels - you might be 10mm off by the end of the row. So for my (hopefully final) build I created 25 thin shelves, drilled 40 holes in each one using a jig to enforce consistent spacing, and threaded pixels on 40 metal wires. This was painstaking and time consuming - I broke it down into multiple sessions over several weeks. But it did create a very predictable grid of pixels and guaranteed that each pixel moved completely independently of the surrounding pixels.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/pixel-assembly.jpg" alt="Dozens of pixels being assembled" width="1440" height="1080" loading="lazy">
<img src="https://benholmen.com/assets/images/kilopixel/assembling-timelapse.gif" alt="Assembling the pixels timelapse" width="480" height="270" loading="lazy">
</p>

<p>Finally, I had my first thousand-pixel display and it seemed promising! I could stop here and have some interesting wall art - and it feels amazing to swipe across with your hand. But we're not stopping! In Wisconsin, we say <em>Forward!</em></p>

<h3>A CNC machine in my office</h3>

<p>I've used a hobby CNC machine in my wood shop for many years, so I was familiar with the basics of CNC and the possibilities for this project. Generally speaking, a CNC machine is something that takes very specific movement instructions written in a language called gcode, and uses those instructions to move to a certain position and do something like drill a hole, cut a groove, or burn with a laser. Stepper motors are typically used because they move very predictably when they receive electrical signals from a CNC controller. Common hobby CNC machines include laser engravers (Glowforge), milling machines (X-Carve), and 3D printers. They all use movement instructions to move X, Y, and Z axes very precisely and do things at those coordinates.</p>

<p>It's easy to find a basic CNC controller that can be used for a CNC mill, a laser engraver, or plotter. These CNC controllers accept gcode over USB/serial, and turn stepper motors to put the machine in the correct position. They typically run <a href="https://github.com/gnea/grbl">grbl</a>, an open source gcode parser that runs on Arduinos.</p>

<p>The Kilopixel is essentially a 2-axis machine that uses the third axis for the pixel poking mechanism.</p>

<p>I connected a Raspberry Pi to the CNC controller and use it for two purposes: querying my API to get the next pixel, writing the appropriate gcode to get there, activating the pixel poker, and then reading a light sensor to determine the physical state of the pixel. It then returns that state to the API and continues the loop. This is run with a Python script and depends on <a href="https://github.com/joan2937/pigpio">pigpio</a> to read the light sensor over GPIO pins.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/completed-display.jpg" alt="Completed Kilopixel display" width="1440" height="1117" loading="lazy"></p>

<h3>Poking pixels</h3>

<p>The pixels rotate and have a notch that registers every 90° to encourage them to align properly. To turn them, I created a reciprocating poking mechanism that uses a flexible glue stick to push on the edge of the pixel. As the pixel turns, the poker moves to the right and lifts up slightly, then moves out of the way and retracts. This is all controlled by gcode and is a rather finicky part of the whole machine.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/poker-1.gif" alt="Prototype stepper motor poker" loading="lazy" width="480" height="270">
<img src="https://benholmen.com/assets/images/kilopixel/poker-2.gif" alt="Pixel poker poking the pixels" loading="lazy" width="480" height="480">
</p>

<h3>We're changing pixels. What should we draw?</h3>

<p>At this point, I have a thousand pixel display that listens to an API and changes pixels one-by-one. So what does the API say?</p>

<p>The API is controlled by a <a href="https://kilopx.com/?ref=blog">web app</a> that is the source of truth for what should be on the display. It has a few modes:</p>

<ul>
<li>User-submitted: anyone can submit a 40×25 image to be drawn, and the most popular submission will be drawn next. Loop forever.</li>
<li>Real-time collaboration: there's a single picture being drawn, and anyone can change any pixel in real time. This doesn't work great with many participants, but is a solid choice if I install the Kilopixel in a coffee shop or something.</li>
<li>Idle modes: I wrote a few algorithms to generate shapes and patterns, but my favorite mode is a clock that can barely keep up with drawing itself.</li>
</ul>

<p>For the public launch of the Kilopixel I chose the user-submitted mode, and you can <a href="https://kilopx.com/draw?ref=blog">submit your own right now</a>. Or <a href="https://kilopx.com/submissions?ref=blog">vote for the submissions</a> you want to see drawn next.</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/kilopx.com-submissions.png" alt="Screenshot of kilopx.com showing user submissions" loading="lazy" width="1496" height="1340">
<img src="https://benholmen.com/assets/images/kilopixel/kilopx.com-draw.png" alt="Screenshot of kilopx.com showing user submissions" loading="lazy" width="1496" height="1340">
</p>

<p>I tinkered with a few stacks for the web app over the years, using it as an excuse to try new things. At first it was a node/Socket.IO app, then a Laravel + Livewire app, and finally a Laravel + InertiaJS + VueJS app. It's hosted on a modest DigitalOcean VPS. It also runs locally on my laptop to record and upload video.</p>

<h3>Putting it out there</h3>

<p>Since the inception of the project, I really wanted this to be something that I shared with at least a few people. It's neat to have in my office, but if it was just for my own enjoyment, it wouldn't be worth all this effort.</p>

<p>I originally planned to hang this in my friend's coffee shop and let a few people at a time interact with it. I still love this idea! And I might do it.</p>

<p>But what I'm really excited about it putting this on the internet for <em>everyone</em> and that means recording and streaming the display in my office. Here's the setup:</p>

<p><img src="https://benholmen.com/assets/images/kilopixel/streaming-setup.jpg" alt="" width="1440" height="930" loading="lazy"></p>

<p>There are two webcams involved: one mounted directly on the pixel poker for a closeup, and one wide shot. The two cameras are combined in OBS where I can stream to YouTube, and the wide shot is also recorded continuously using ffmpeg. Streaming to YouTube provides a live view of the physical device alongside the digital queue of submissions. The camera, USB hub, and light are hung from the ceiling with a respectful amount of jank for the streaming phase of this project.</p>

<p>Besides streaming, the laptop is running a scheduled job that queries the API to see if a submission has recently finished drawing. If it does, it generates a rather complex ffmpeg command to generate a one minute timelapse of the submission being drawn. The timelapse is uploaded to kilopx.com and posted to Bluesky where it can be shared by the creator of the artwork - <a href="https://bsky.app/profile/kilopx.com/post/3lutmwu7kls2v">for example, pixel art by Matt Stauffer</a></p>

<h3>Something physical, in my office, controlled by the internet. What could go wrong?</h3>

<p>I've built some defensive features into the web app so I can mitigate common abuse patterns if they become a problem. I've decided to not lock it down prematurely - I think it might be fun to see what people can do with this thing! Voting is open to anyone with a few basic session checks, submission of artwork requires a Bluesky OAuth login, and I have a mechanism to quickly delete problem submissions.</p>

<p>I'll see what the internet does and adapt accordingly!</p>

<h3>What next?</h3>

<p>I'm sincerely hoping the internet has fun with this project for a bit! Once it winds down, I've considered turning control of the display over to an internet friend - after all, it just hits an API, why not yours? If you're interested, <a href="https://benholmen.com/cdn-cgi/l/email-protection#ceacaba08eacaba0a6a1a2a3aba0e0ada1a3">email me</a>.</p>

<p>And then, the final destination will be behind me on my webcam - I'll let anyone on a video call monkey with my background to their heart's content. What could go wrong?</p>

<p>In the meantime, please <a href="https://kilopx.com/draw?ref=blog">submit something</a> or just <a href="https://kilopx.com/?ref=blog">follow along</a>!</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla withheld data, lied, misdirected police to avoid blame in Autopilot crash (392 pts)]]></title>
            <link>https://electrek.co/2025/08/04/tesla-withheld-data-lied-misdirected-police-plaintiffs-avoid-blame-autopilot-crash/</link>
            <guid>44787780</guid>
            <pubDate>Mon, 04 Aug 2025 16:07:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/08/04/tesla-withheld-data-lied-misdirected-police-plaintiffs-avoid-blame-autopilot-crash/">https://electrek.co/2025/08/04/tesla-withheld-data-lied-misdirected-police-plaintiffs-avoid-blame-autopilot-crash/</a>, See on <a href="https://news.ycombinator.com/item?id=44787780">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="841" src="https://electrek.co/wp-content/uploads/sites/3/2025/08/Tesla-Autopilot-crash-data-lies-Elon-Musk.png?w=1600" alt="" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/Tesla-Autopilot-crash-data-lies-Elon-Musk.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/Tesla-Autopilot-crash-data-lies-Elon-Musk.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/Tesla-Autopilot-crash-data-lies-Elon-Musk.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/Tesla-Autopilot-crash-data-lies-Elon-Musk.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Tesla was caught withholding data, lying about it, and misdirecting authorities in the wrongful death case involving Autopilot that it lost this week.</p>



<p>The automaker was undeniably covering up for Autopilot.</p>



<p>Last week, a jury found Tesla partially liable for a wrongful death involving a crash on Autopilot. I explained the case in the verdict in <a href="https://electrek.co/2025/08/01/tesla-tsla-is-found-liable-in-fatal-autopilot-crash-has-to-pay-329-million/" target="_blank" rel="noreferrer noopener">this article </a>and <a href="https://www.youtube.com/watch?v=fzV1i7LeRrw">video</a>.</p>



<p>But we now have access to the trial transcripts, which confirm that Tesla was extremely misleading in its attempt to place all the blame on the driver.</p>	
	



<p>The company went as far as to actively withhold critical evidence that explained Autopilot’s performance around the crash.</p>



<h3 id="h-tesla-withheld-the-crash-snapshot-data-that-its-own-server-received-within-minutes-of-the-collision">Tesla <strong>withheld the crash‑snapshot data that its own server received within minutes of the collision</strong></h3>



<p>Within about three minutes of the crash, the Model S uploaded a “collision snapshot”—video, CAN‑bus streams, EDR data, etc.—to Tesla’s servers, the “Mothership”, and received an acknowledgement. The vehicle then deleted its local copy, resulting in Tesla being the only entity having access.</p>



<p>What ensued were years of battle to get Tesla to acknowledge that this collision snapshot exists and is relevant to the case.</p>



<p>The police repeatedly attempted to obtain the data from the collision snapshot, but Tesla led the authorities and the plaintiffs on a lengthy journey of deception and misdirection that spanned years.</p>



<p>Here, in chronological order, is what happened based on all the evidence in the trial transcript:</p>



<h3><strong>1 | 25 Apr 2019 – The crash and an instant upload Tesla pretended never happened</strong></h3>



<p><span>Within ~3 minutes of the cras</span>h, the Model S packaged sensor video, CAN‑bus, EDR, and other streams into a single&nbsp;“snapshot_collision_airbag-deployment.tar”&nbsp;file and pushed it to Tesla’s server, then deleted its local copy.</p>



<p>We know that now, thanks to forensic evidence extracted from the onboard computer.</p>



<p>The plaintiffs hired Alan Moore, a mechanical engineer who specializes in accident reconstruction, to forensically recover data from the Autopilot ECU (computer).</p>



<p>Based on the data, Moore was able to confirm that Tesla had this “collision snapshot” all along, but “unlinked” it from the vehicle:</p>



<blockquote>
<p><em>“That tells me within minutes of this crash Tesla had all of this data … the car received an acknowledgement … then said ‘OK, I’m done, I’m going to unlink it.’”</em></p>
</blockquote>



<p>The plaintiffs tried to obtain this data, but Tesla told them that it didn’t exist.</p>



<p>Tesla’s written discovery responses were shown during the trial to prove that the company acted as if this data were not available.</p>



<hr>



<h3><strong>2 | 23 May 2019 – Tesla’s lawyer scripts the homicide investigator’s evidence request</strong></h3>



<p>Corporal Riso, a homicide investigator with the Florida Highway Patrol (FHP), sought Tesla’s help in retrieving telemetry data to aid in reconstructing the crash.</p>



<p>He was put in contact with Tesla attorney Ryan McCarthy and asked if he needed to subpoena Tesla to get the crash data.</p>



<p>Riso said of McCarthy during the trial:</p>



<blockquote>
<p><em>“He said it’s not necessary. <strong>‘Write me a letter and I’ll tell you what to put in the letter.’</strong>”</em></p>
</blockquote>



<p>At the time, he didn’t see Tesla as an adversary in this case and thought that McCarthy would facilitate the retrieval of the data without having to go through a formal process. However, the lawyer crafted the letter to avoid sending the police the full crash data.</p>



<p>Riso followed the instructions verbatim. He said during the trial:</p>



<blockquote>
<p>“I specifically wrote down what the attorney at Tesla told me to write down in the letter.”</p>
</blockquote>



<p>But McCarthy specifically crafted the letter to ommit sharing the colllision snapshot, which includes bundled video, EDR, CAN bus, and Autopilot data.</p>



<p>Instead, Tesla provided the police with infotainment data with call logs, a copy of the Owner’s Manual, but not the actual crash telemetry from the Autopilot ECU.</p>



<p>Tesla never said that it already had this data for more than a month by now.</p>



<hr>



<h3><strong>3 | June 2019 – A staged “co‑operation” that corrupts evidence</strong></h3>



<p>Tesla got even more deceptice when the police specifically tried to collect the data directly from the Autopilot computer.</p>



<p>On June 19, 2019, Riso physically removed the MCU and Autopilot ECU from the Tesla.</p>



<p>Again, the investigator thought that Tesla was being collaborative with the investigation at the time so he asked the company how to get the data out of the computer. He said at the trial:</p>



<blockquote>
<p>I had contacted Mr. McCarthy and asked him how I can get this data off of the computer components. He said that he would coordinate me meeting with a technician at their service center, the Tesla service center in Coral Gables.</p>
</blockquote>



<p>Tesla arranged for Riso to meet Michael Calafell, a Tesla technician, at the local service center in in Coral Gables with the Autopilot ECU and the Model S’ MCU, the two main onboard computers.</p>



<p>To be clear, Tesla already had all this data in its servers and could have just sent it to Riso, but instead, they lured him into its service center with the piece of evidence in his custody.</p>



<p>What ensued was pure cinema.</p>



<p>Michael Calafell, who testified never having been tasked with extracting data from an Autopilot ECU before, connected both computers to a Model S in the shop to be able to access them, but he then claimed that the data was “corrupted” and couldn’t be access.</p>



<p>Riso said during his testimony:</p>



<blockquote>
<p><strong>I brought the center tablet [MCU] and the flat silver box [Autopilot ECU] with multicolored connectors to the Tesla service center.”</strong></p>
</blockquote>



<blockquote>
<p><strong>“I watched Mr. Calafell the whole time. The evidence was in my custody. I did not let it out of my sight.”</strong></p>
</blockquote>



<p>However, the situation got a lot more confusing as Calafell swore in an affidavit that he didn’t actually power the ECU, only the MCU, on that day, June 19.</p>



<p>Only years later, when Alan Moore, the forensic engineer hired by the plaintiff, managed to get access to the Autopilot ECU, we learned that Tesla undeniably powered up the computer on June 19 and the data was accessible.</p>



<hr>



<h3><strong>4 | 2019 – 2024 – Repeated denials and discovery stonewalling</strong></h3>



<p>Through years of communications with the police, the plaintiffs and the court through the investigation and later the discovery process for the lawsuit, Tesla never mentioned that it had all the data that explained how Autopilot saw the crash, which everyone was seeking, sitting on its servers for years.</p>



<p>The facts are:</p>



<ul>
<li>Tesla had the data on its servers within minutes of the crash</li>



<li>When the police sought the data, Tesla redirected them toward other data</li>



<li>When the police sought Tesla’s help in extracting it from the computer, Tesla falsely claimed it was “corrupted”</li>



<li>Tesla invented an “auto-delete” feature that didn’t exist to try explain why it couldn’t originally find the data in the computer</li>



<li>When the plaintiffs asked for the data, Tesla said that it didn’t exist</li>



<li>Tesla only admitted to the existence of the data once presented with forensic evidence that it was created and transfered to its servers.</li>
</ul>



<hr>



<h3 id="h-5-late-2024-court-orders-a-bit-for-bit-nand-flash-image"><strong>5 | Late 2024 – Court orders a bit‑for‑bit NAND‑flash image</strong></h3>



<p>By late 2024, the court allowed the plantiffs to have a third-party expert access the Autopilot ECU to try to acccess the data that Tesla claimed was now corrupted.</p>



<p>The court allowed the forensic engineers to do a bit-for-bit NAND flash image, which consists of a complete, sector-by-sector copy of the data stored on a NAND flash memory chip, including all data, metadata, and error correction code (ECC) information.</p>



<p>The engineers quickly found that all the data was there despite Tesla’s previous claims.</p>



<p>Moore, the forensic engineer hired by the plaintiffs, said:</p>



<blockquote>
<p>“Tesla engineers said this couldn’t be done… yet it was done by people outside Tesla.”</p>
</blockquote>



<p>Now, the plaintiffs had access to everything.</p>



<hr>



<h3><strong>6 | Feb‑Mar 2025 – The forensic “treasure‑trove” reveals the file name &amp; checksum</strong></h3>



<p>Moore was astonished by all the data found through cloning the Autopilot ECU:</p>



<blockquote>
<p>“For an engineer like me, the data out of those computers was a treasure‑trove of how this crash happened.”</p>
</blockquote>



<p>The data that Tesla had provided was not as easily searchable, the videos were grainy, and it was missing key alerts and timestamps about Autopilot and its decision-making leading up to the crash.</p>



<p>On top of all the data being so much more helpful, Moore found unallocated space and metadata for ‘snapshot_collision_airbag‑deployment.tar’, including its SHA‑1 checksum and the exact server path.</p>



<hr>



<h3><strong>7 | May 2025 – Subpoenaed server logs corner Tesla</strong></h3>



<p>Armed with the the newly found metadata, plaintiffs were able to subpoenaed Tesla’s AWS logs. </p>



<p>Tesla still fought them, but facing a sanctions hearing, Tesla finally produced the untouched TAR file plus access logs showing it had been stored <strong>since 18:16 PDT on 25 Apr 2019</strong>—the same three‑minute timestamp Moore had highlighted.</p>



<p>The automaker had to admit to have the data all along.</p>



<p>During the trial, Mr. Schreiber, attorney for the plaintiffs, claimed that Tesla used the data for its own internal analysis of the crash:</p>



<blockquote>
<p>They not only had the snapshot — they used it in their own analysis. It shows Autopilot was engaged. It shows the acceleration and speed. It shows McGhee’s hands off the wheel.</p>
</blockquote>



<p>Yet, it didn’t give access to the police nor the family of the victim who have been trying to understand what happened to their daughter.</p>



<hr>



<h3><strong>8 | July 2025 Trial – The puzzle laid bare for the jury</strong></h3>



<p>Finally, this entire situation was laid bare in front of the jury last month and certainly influenced the jury in their verdict.</p>



<p>The jury was confronted with clear evidence of Tesla trying to hide data about the crash, and then, they were shown what that data revealed.</p>



<p>The data recovered made a few things clear:</p>



<ul>
<li>Autopilot was active</li>



<li>Autosteer was controlling the vehicle</li>



<li>No manual braking or steering override was detected from the driver</li>



<li>There was <strong>no record of a “Take Over Immediately” alert</strong>, despite approaching a T-intersection with a stationary vehicle in its path.</li>



<li>Moore found logs showing <strong>Tesla systems were capable of issuing such warnings</strong>, but <strong>did not</strong> in this case.</li>



<li>Map and vision data from the ECU revealed:
<ul>
<li>Map data from the Autopilot ECU included a flag that the area was a <strong>“restricted Autosteer zone.”</strong></li>



<li>Despite this, the system <strong>allowed Autopilot to remain engaged</strong> at full speed.</li>
</ul>
</li>
</ul>



<p>Moore commented on the last point:</p>



<blockquote>
<p>“Tesla had the map flag. The car knew it was in a restricted zone, yet Autopilot did not disengage or issue a warning.”</p>
</blockquote>



<p>This was critical to the case as one of the arguments was that Tesla dangerously let owners use Autopilot on roads it was not designed to operate on as it was specifically trained for highways.</p>



<p>The National Transportation Safety Board (NTSB) had even worn Tesla about it and the automaker didn’t geofenced the system:.</p>



<p>The NTSB had wrote Tesla:</p>



<blockquote>
<p>“Incorporate system safeguards that limit the use of automated vehicle control systems to those conditions for which they were designed (the vehicle’s operational design domain).”</p>
</blockquote>



<p>The driver was responsible for the crash and he admitted as such. He admitted to not using Autopilot properly and not paying attention during the crash.</p>



<p>However, the main goal of the plaintiffs in this case was to assign part of the blame for the crash to Tesla for not preventing such abuse of the system despite the clear risk.</p>



<p>The logic is that if Tesla had implemted geofencing and better driver monitoring, the driver, McGee, would have never been able to use Autopilot in this case, which could have potentially avoidded putting himself in the situation that led to the crash.</p>



<p>That’s on top of Autopilot failing at what Tesla has repeatedly claim it could do: stop those crashes from happening in the first place.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>Tesla fans need to do a quick exercise in empathy right now. The way they are discussing this case, such as claiming the plaintiffs are just looking for a payout, is truly appalling.</p>



<p>You should put yourself in the family’s shoes. If your daughter died in a car crash, you’d want to know exactly what happened, identify all contributing factors, and try to eliminate them  to give some meaning to this tragic loss and prevent it from happening to someone else.</p>



<p>It’s an entirely normal human reaction. And to make this happen in the US, you must go through the courts.</p>



<p>Secondly, Tesla fans need to do a quick exercise in humbleness. They act like they know exactly what this case is about and assume that it will “just be thrown out in appeal.”</p>



<p>The truth is that unless you read the entire transcripts and saw all the evidence, you don’t know more about it than the 12 jurors who unanimously decided to assign 33% of the blame for the crash to Tesla.</p>



<p>And that’s the core of the issue here. They want to put all the blame on the driver, and what the plaintiffs were trying to do was just assign part of the blame on Tesla, and the jurors agreed.</p>



<p>The two sides are not that far off from each other. They both agreed that most of the blame goes to the driver, and even the driver appears to agree with that. He admitted to being distracted and he quickly settled with the plaintiffs.</p>




	<p>This case was only meant to explore how Tesla’s marketing and deployment of Autopilot might have contributed to the crash, and after looking at all the evidence, the jury agreed that it did.</p>



<p>There’s no doubt that the driver should bare most of the responsability and there’s no doubt that he didn’t use Autopilot properly.</p>



<p>However, there’s also no doubt that Autopilot was active, didn’t prevent the crash despite Tesla claiming it is safer than humans, and Tesla was warned to use better geo-fencing and driver monitoring to prevent abuse of the system like that.</p>



<p>I think a 33% blame in this case is more than fair.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p><p><a href="https://bit.ly/450t9Bz"><img src="https://electrek.co/wp-content/uploads/sites/3/2025/07/NativeBanner_ElecktrekDisplayAds_BeaumontRev2.jpg?quality=82&amp;strip=all" alt="" width="750" height="150"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A deep dive into Rust and C memory interoperability (110 pts)]]></title>
            <link>https://notashes.me/blog/part-1-memory-management/</link>
            <guid>44786962</guid>
            <pubDate>Mon, 04 Aug 2025 15:12:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notashes.me/blog/part-1-memory-management/">https://notashes.me/blog/part-1-memory-management/</a>, See on <a href="https://news.ycombinator.com/item?id=44786962">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">   <blockquote>
<p><strong>“Memory oppresses me.” - Severian, The Book of the New Sun</strong></p>
<p><strong>Interviewer</strong>: “What happens if you allocate memory with C’s malloc and try to free it with Rust’s dealloc, if you get a pointer to the memory from C?”</p>
<p><strong>Me</strong>: “If we do it via FFI then there’s a possibility the program may continue working (because the underlying structs share the same memory layout? right? …right?)”</p>
<p><em>Now if you have any experience working with memory management, you know that this is a dangerous answer. But I didn’t know it at the time. I was just trying to get through the interview.</em></p>
<p>But I realized at that moment that I had been treating memory allocators like black boxes. I knew the rules - never mix allocators - but I didn’t truly understand <em>why</em>. So here’s my attempt at de-mystifying memory management, starting with the fundamentals and building a testing laboratory to explore what happens when different memory worlds collide.</p>
</blockquote>
<h2 id="prerequisites">Prerequisites<a href="#prerequisites">#</a></h2>
<p>To get the most from this article, you should be familiar with:</p>
<ul>
<li>Basic Rust and C programming</li>
<li>Pointers and memory management concepts</li>
<li>Command line tools (bash, gcc, cargo)</li>
<li>Basic understanding of stack vs heap</li>
</ul>
<p>Don’t worry if you’re not an expert, I’m not one either - but I’ll explain concepts as best I can!</p>
<h2 id="table-of-contents">Table of Contents<a href="#table-of-contents">#</a></h2>
<ol>
<li><a href="#the-interview-question-that-started-everything">The Interview Question That Started Everything</a></li>
<li><a href="#why-memory-allocators-dont-mix">Why Memory Allocators Don’t Mix</a></li>
<li><a href="#memory-fundamentals-building-our-mental-model">Memory Fundamentals: Building Our Mental Model</a></li>
<li><a href="#building-a-memory-testing-laboratory">Building a Memory Testing Laboratory</a></li>
<li><a href="#first-experiments-surprising-results">First Experiments: Surprising Results</a></li>
<li><a href="#key-takeaways-and-whats-next">Key Takeaways and What’s Next</a></li>
</ol>
<h2 id="the-interview-question-that-started-everything">The Interview Question That Started Everything<a href="#the-interview-question-that-started-everything">#</a></h2>
<p>It was Friday afternoon when I had an interview for an amazing startup which focuses on building very high performance systems. The interview experience was intense while being highly rewarding. We touched upon topics async runtimes, memory management, rust FFI etc.</p>
<p>The intention wasn’t to test my language specific knowledge but being able to reason about how these systems work at a level closer to the machine.</p>
<p>It caught me a little offguard. It’s not something I had prepared for. However, to be a good systems engineer, It is essential to develop a knack for the fundamentals - understanding how things work all the way down to the metal. Whether it’s the intricacies of the CPU cache hierarchy, memory alignment, or the behavior of allocators under concurrency, these low-level details can have profound impacts on system performance and correctness.</p>
<p>That experience prompted me to reflect on my own gaps and sparked a sort of yearning to dig deeper into the topic. Hence, I decided to do this and start a journey to understand memory management better, starting with the basics and building a comprehensive testing framework to explore the interactions between Rust and C memory allocators.</p>
<h2 id="why-memory-allocators-dont-mix">Why Memory Allocators Don’t Mix<a href="#why-memory-allocators-dont-mix">#</a></h2>
<p>Before diving into the technical details, let’s understand the fundamental problem. But first, we need to establish what different exit codes mean when testing memory operations:</p>
<h3 id="understanding-exit-codes-in-memory-testing">Understanding Exit Codes in Memory Testing<a href="#understanding-exit-codes-in-memory-testing">#</a></h3>
<p>When experimenting with memory allocators, the exit code tells us exactly what happened:</p>





























<table><thead><tr><th>Exit Code</th><th>Signal</th><th>Meaning</th><th>Safety</th></tr></thead><tbody><tr><td>0</td><td>None</td><td>Process completed “successfully”</td><td>⚠️ <strong>DANGEROUS</strong> - Silent corruption</td></tr><tr><td>-11 or 139</td><td>SIGSEGV</td><td>Segmentation fault - invalid memory access</td><td>✅ Safe - OS detected bad access</td></tr><tr><td>-6 or 134</td><td>SIGABRT</td><td>Program aborted - allocator detected corruption</td><td>✅ Safe - Allocator safety checks worked</td></tr></tbody></table>
<blockquote>
<p>⚠️ <strong>The Hidden Danger of Exit Code 0</strong></p>
<p>When mixing allocators, exit code 0 is the worst possible outcome. It means memory corruption occurred but went undetected. Your program continues running with a corrupted heap - a time bomb that will explode unpredictably later. A crash (SIGSEGV or SIGABRT) is actually the safe outcome because it prevents further corruption.</p>
</blockquote>
<p>Now, when you write:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// dangerous.rs</span></span>
<span><span>let</span><span> ptr </span><span>=</span><span> unsafe</span><span> { </span><span>libc</span><span>::</span><span>malloc</span><span>(</span><span>64</span><span>) };</span></span></code></pre><p><span>rust</span></p></div>
<p>You’re not just getting 64 bytes of memory. You’re entering into a complex contract with a specific allocator implementation. That allocator needs to track:</p>
<ul>
<li>How much memory you requested</li>
<li>Whether this chunk is free or allocated</li>
<li>Where the next and previous chunks are</li>
<li>Thread ownership information</li>
<li>Debugging metadata (in debug builds)</li>
</ul>
<p>Different allocators store this information differently. When you later call:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// dangerous.rs</span></span>
<span><span>unsafe</span><span> { </span><span>std</span><span>::</span><span>alloc</span><span>::</span><span>dealloc</span><span>(ptr </span><span>as</span><span> *mut</span><span> u8</span><span>, layout) };</span></span></code></pre><p><span>rust</span></p></div>
<blockquote>
<p>⚠️ <strong>The Metadata Mismatch</strong></p>
<p>Rust’s allocator looks for its metadata format at specific offsets from your pointer. If it finds glibc’s metadata instead, the best case is an immediate crash. The worst case? Silent corruption that manifests as mysterious bugs hours later.</p>
</blockquote>
<h2 id="memory-fundamentals-building-our-mental-model">Memory Fundamentals: Building Our Mental Model<a href="#memory-fundamentals-building-our-mental-model">#</a></h2>
<p>To understand why allocators clash, we need to build a mental model of how memory actually works in modern systems.</p>
<h3 id="virtual-memory-the-grand-illusion">Virtual Memory: The Grand Illusion<a href="#virtual-memory-the-grand-illusion">#</a></h3>
<p>Every process on a modern operating system lives in its own virtual address space. On a 64-bit Linux system, your process sees:
<img src="https://notashes.me/_astro/memory-layout-of-a-process.CPUe2S_j_Zy5Jpx.webp" alt="virtual address space layout" width="1280" height="720" loading="lazy" decoding="async"></p>
<p>This is all an illusion. These addresses don’t correspond directly to physical RAM. Instead, the CPU and operating system work together to translate virtual addresses to physical addresses on every memory access. Understanding this translation is crucial because it affects everything from allocator design to the performance impact of memory access patterns.</p>
<h3 id="the-true-cost-of-memory-access">The True Cost of Memory Access<a href="#the-true-cost-of-memory-access">#</a></h3>
<p>To understand memory access costs, let’s trace what happens when our test program accesses a typical heap address. During our experiments, malloc returned addresses like <code>0x00007fab8c3d2150</code>. This isn’t random - addresses starting with <code>0x00007f</code> are in the standard heap region on 64-bit Linux systems.</p>
<p>Here’s how the CPU translates this virtual address to physical RAM:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Virtual Address Translation (x86_64 with 4-level paging)</span></span>
<span><span></span></span>
<span><span>Virtual Address: 0x00007fab8c3d2150 (from our malloc experiment)</span></span>
<span><span></span></span>
<span><span>Bit Layout:</span></span>
<span><span>┌─────────┬─────────┬─────────┬─────────┬────────────┐</span></span>
<span><span>│  PML4   │   PDP   │   PD    │   PT    │   Offset   │</span></span>
<span><span>│ [47:39] │ [38:30] │ [29:21] │ [20:12] │   [11:0]   │</span></span>
<span><span>├─────────┼─────────┼─────────┼─────────┼────────────┤</span></span>
<span><span>│  0x0FE  │  0x1AE  │  0x118  │  0x1D2  │   0x150    │</span></span>
<span><span>└─────────┴─────────┴─────────┴─────────┴────────────┘</span></span>
<span><span></span></span>
<span><span>Where:</span></span>
<span><span>- PML4 = Page Map Level 4 (top-level page table)</span></span>
<span><span>- PDP = Page Directory Pointer</span></span>
<span><span>- PD = Page Directory  </span></span>
<span><span>- PT = Page Table</span></span>
<span><span>- Offset = Position within the 4KB page</span></span>
<span><span></span></span>
<span><span>Translation Steps:</span></span>
<span><span>1. CR3 register + (PML4 index × 8) → PML4 entry → PDP base address</span></span>
<span><span>2. PDP base + (PDP index × 8) → PDP entry → PD base address  </span></span>
<span><span>3. PD base + (PD index × 8) → PD entry → PT base address</span></span>
<span><span>4. PT base + (PT index × 8) → PT entry → Physical page base</span></span>
<span><span>5. Physical page base + offset (0x150) → Final physical address</span></span>
<span><span></span></span>
<span><span>Cost: 4 memory accesses without TLB hit</span></span>
<span><span>      ~1 cycle with TLB hit (typical case)</span></span></code></pre><p><span>plaintext</span></p></div>
<p>The Translation Lookaside Buffer (TLB) is a specialized cache that stores recent virtual-to-physical address mappings. When you access memory sequentially (like iterating through an array), the TLB hit rate approaches 100%, making translation nearly free. But random access patterns can cause TLB misses, adding ~100 cycles per access - which is why memory access patterns matter so much for performance.</p>
<h3 id="the-heap-where-dynamic-memory-lives">The Heap: Where Dynamic Memory Lives<a href="#the-heap-where-dynamic-memory-lives">#</a></h3>
<p>When you call <code>malloc(64)</code>, you’re asking the allocator to find 64 bytes of free memory on the heap. But this simple request triggers a complex chain of events:</p>
<ol>
<li><strong>Thread-Local Cache Check</strong>: Modern allocators first check thread-local caches to avoid lock contention</li>
<li><strong>Central Cache Search</strong>: If the thread cache is empty, check central free lists</li>
<li><strong>Free List Management</strong>: Search through free lists organized by size classes</li>
<li><strong>Heap Expansion</strong>: If no suitable chunk exists, request more memory from the OS</li>
</ol>
<p>The allocator must also deal with fragmentation:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Heap State After Various Allocations/Deallocations:</span></span>
<span><span></span></span>
<span><span>[Used:16][Free:32][Used:64][Free:16][Used:32][Free:64]</span></span>
<span><span></span></span>
<span><span>Request for 48 bytes:</span></span>
<span><span>- First free chunk (32 bytes): Too small ✗</span></span>
<span><span>- Second free chunk (16 bytes): Too small ✗  </span></span>
<span><span>- Third free chunk (64 bytes): Success ✓</span></span>
<span><span></span></span>
<span><span>Even though we have 112 bytes free total, they're not contiguous!</span></span></code></pre><p><span>plaintext</span></p></div>
<h3 id="cpu-cache-architecture-the-hidden-performance-layer">CPU Cache Architecture: The Hidden Performance Layer<a href="#cpu-cache-architecture-the-hidden-performance-layer">#</a></h3>
<p>Modern CPUs have multiple cache levels to bridge the massive speed gap between CPU and RAM:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>CPU Cache Hierarchy (typical Intel/AMD x86_64)</span></span>
<span><span>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span></span>
<span><span></span></span>
<span><span>CPU Core</span></span>
<span><span>├─ Registers (16-32, ~0 cycles)</span></span>
<span><span>├─ L1 Cache (32-64KB, ~4-5 cycles)</span></span>
<span><span>├─ L2 Cache (256KB-1MB, ~12-15 cycles)</span></span>
<span><span>└─ L3 Cache (8-32MB shared, ~40-60 cycles)</span></span>
<span><span>    │</span></span>
<span><span>    └─── Main Memory (~100-300 cycles)</span></span>
<span><span></span></span>
<span><span>Cache Line Size: 64 bytes (x86_64)</span></span></code></pre><p><span>plaintext</span></p></div>
<p><em>Note: These are typical values - actual latencies vary by CPU model and generation</em></p>
<blockquote>
<p>💡 <strong>False Sharing: The Hidden Performance Killer</strong></p>
<p>This architecture has profound implications. Consider false sharing:</p>
<div tabindex="0" data-language="c"><pre><code><span><span>struct</span><span> thread_stats {</span></span>
<span><span>    int</span><span> thread1_counter;</span><span>  // Offset 0-3</span></span>
<span><span>    int</span><span> thread2_counter;</span><span>  // Offset 4-7  </span></span>
<span><span>    // Both in same 64-byte cache line!</span></span>
<span><span>};</span></span></code></pre><p><span>c</span></p></div>
<p>When thread 1 updates its counter, it invalidates the entire cache line on other cores. Thread 2 must wait for exclusive access to update its counter, even though they’re touching different variables. In our experiments, this caused an <strong>8.67x performance penalty</strong> - from 359.7M ops/sec down to 41.4M ops/sec!</p>
<p><strong>How we measured this</strong>: Using <code>perf stat -e L1-dcache-loads,L1-dcache-load-misses ./false_sharing_test</code>, we observed 891M L1 cache misses with false sharing vs only 12M without - a 74x increase in cache misses!</p>
</blockquote>
<h2 id="building-a-memory-testing-laboratory">Building a Memory Testing Laboratory<a href="#building-a-memory-testing-laboratory">#</a></h2>
<p>Understanding theory is one thing. Seeing it explode in practice is another. Armed with knowledge about virtual memory, heap structure, and cache architecture, I needed to build a comprehensive testing framework that could safely explore what happens when different memory worlds collide.</p>
<p>The framework needed to:</p>
<ol>
<li>Test multiple allocator implementations</li>
<li>Safely handle (and analyze) crashes</li>
<li>Measure performance without affecting results</li>
<li>Provide detailed debugging information</li>
</ol>
<blockquote>
<p>📊 <strong>Testing Infrastructure Overview:</strong></p>
<p><strong>Key Components:</strong></p>
<ul>
<li><strong>Subprocess isolation</strong>: Each test runs in its own process via <code>Command::new()</code></li>
<li><strong>C library loading</strong>: <code>export LD_LIBRARY_PATH=../c-lib:$LD_LIBRARY_PATH</code></li>
<li><strong>Exit code analysis</strong>: Maps signals to meaningful results</li>
<li><strong>Performance tools</strong>: <code>perf stat</code>, custom timing, cache analysis</li>
</ul>
<p><strong>Repository Structure:</strong></p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>rust-c-memory-interop/</span></span>
<span><span>├── c-lib/           # Custom allocator implementations</span></span>
<span><span>├── rust-ffi/        # Rust test binaries and FFI bindings</span></span>
<span><span>├── tools/           # Analysis scripts (bash)</span></span>
<span><span>│   ├── run_crash_tests.sh  # Runs crash tests in subprocesses</span></span>
<span><span>│   ├── perf_analysis.sh    # Generates performance analysis code</span></span>
<span><span>│   └── deep_analysis.sh    # Generates memory analysis code</span></span>
<span><span>└── test_results/    # Output from experiments</span></span></code></pre><p><span>plaintext</span></p></div>
<p><strong>Note</strong>: The bash scripts in <code>tools/</code> dynamically generate Rust code for specialized analysis. This keeps the main codebase clean while allowing complex experiments.</p>
</blockquote>
<p>Here’s the framework I built:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// rust-ffi/src/comprehensive_tests.rs</span></span>
<span><span>use</span><span> std</span><span>::</span><span>collections</span><span>::</span><span>HashMap</span><span>;</span></span>
<span><span>use</span><span> std</span><span>::</span><span>time</span><span>::</span><span>Instant</span><span>;</span></span>
<span></span>
<span><span>#[derive(</span><span>Debug</span><span>, </span><span>Clone</span><span>)]</span></span>
<span><span>pub</span><span> struct</span><span> TestResult</span><span> {</span></span>
<span><span>    pub</span><span> test_name</span><span>:</span><span> String</span><span>,</span></span>
<span><span>    pub</span><span> allocator</span><span>:</span><span> String</span><span>,</span></span>
<span><span>    pub</span><span> success</span><span>:</span><span> bool</span><span>,</span></span>
<span><span>    pub</span><span> duration</span><span>:</span><span> std</span><span>::</span><span>time</span><span>::</span><span>Duration</span><span>,</span></span>
<span><span>    pub</span><span> metrics</span><span>:</span><span> HashMap</span><span>&lt;</span><span>String</span><span>, </span><span>f64</span><span>&gt;,</span></span>
<span><span>    pub</span><span> notes</span><span>:</span><span> Vec</span><span>&lt;</span><span>String</span><span>&gt;,</span></span>
<span><span>}</span></span>
<span></span>
<span><span>pub</span><span> struct</span><span> ComprehensiveTestSuite</span><span> {</span></span>
<span><span>    results</span><span>:</span><span> Vec</span><span>&lt;</span><span>TestResult</span><span>&gt;,</span></span>
<span><span>}</span></span>
<span></span>
<span><span>impl</span><span> ComprehensiveTestSuite</span><span> {</span></span>
<span><span>    pub</span><span> fn</span><span> new</span><span>() </span><span>-&gt;</span><span> Self</span><span> {</span></span>
<span><span>        Self</span><span> {</span></span>
<span><span>            results</span><span>:</span><span> Vec</span><span>::</span><span>new</span><span>(),</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    pub</span><span> fn</span><span> run_all_tests</span><span>(</span><span>&amp;mut</span><span> self</span><span>) {</span></span>
<span><span>        println!</span><span>(</span><span>"=== Comprehensive Memory Allocator Test Suite ===</span><span>\n</span><span>"</span><span>);</span></span>
<span></span>
<span><span>        // Basic functionality tests</span></span>
<span><span>        self</span><span>.</span><span>test_basic_allocation</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_alignment_requirements</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_size_classes</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        // Performance tests</span></span>
<span><span>        self</span><span>.</span><span>test_allocation_performance</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_fragmentation_behavior</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_cache_efficiency</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        // Safety tests</span></span>
<span><span>        self</span><span>.</span><span>test_metadata_corruption</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_allocator_mixing</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        // Generate report</span></span>
<span><span>        self</span><span>.</span><span>generate_report</span><span>();</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<h3 id="implementing-multiple-allocators">Implementing Multiple Allocators<a href="#implementing-multiple-allocators">#</a></h3>
<p>To test allocator interactions, I implemented four different allocators in C, each with distinct characteristics and use cases:</p>
<p><strong>1. Standard malloc wrapper</strong> - <em>A thin pass-through to glibc’s malloc</em>:</p>
<blockquote>
<p><strong>Use case</strong>: General-purpose allocation, the default for most C programs <br>
<strong>Pros</strong>: Fast, well-tested, handles fragmentation well <br>
<strong>Cons</strong>: No built-in debugging, metadata can be corrupted</p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// allocators.c - Just forwards to system malloc/free</span></span>
<span><span>void*</span><span> standard_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    void*</span><span> ptr </span><span>=</span><span> malloc</span><span>(size);</span></span>
<span><span>    printf</span><span>(</span><span>"[C] standard_malloc(</span><span>%zu</span><span>) = </span><span>%p\n</span><span>"</span><span>, size, ptr);</span></span>
<span><span>    return</span><span> ptr;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>void</span><span> standard_free</span><span>(</span><span>void*</span><span> ptr</span><span>) {</span></span>
<span><span>    free</span><span>(ptr);</span></span>
<span><span>    printf</span><span>(</span><span>"[C] standard_free(</span><span>%p</span><span>)</span><span>\n</span><span>"</span><span>, ptr);</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p><strong>2. Debug allocator</strong> - <em>Adds magic values before and after user data to detect buffer overflows and corruption</em>:</p>
<blockquote>
<p><strong>Use case</strong>: Development and debugging, catching memory corruption early <br>
<strong>Pros</strong>: Detects buffer overflows, use-after-free, double-free <br>
<strong>Cons</strong>: ~20 bytes overhead per allocation, slower than standard malloc</p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// debug_allocator.c</span></span>
<span><span>#define</span><span> MALLOC_MAGIC_HEADER</span><span> 0x</span><span>DEADBEEF</span><span>  // Classic magic number for "dead beef"</span></span>
<span><span>#define</span><span> MALLOC_MAGIC_FOOTER</span><span> 0x</span><span>CAFEBABE</span><span>  // Java's magic number, means "cafe babe"</span></span>
<span></span>
<span><span>typedef</span><span> struct</span><span> alloc_header {</span></span>
<span><span>    uint32_t</span><span> magic;</span></span>
<span><span>    size_t</span><span> size;</span></span>
<span><span>    uint32_t</span><span> flags;</span></span>
<span><span>    void*</span><span> debug_info;</span></span>
<span><span>} </span><span>alloc_header_t</span><span>;</span></span>
<span></span>
<span><span>void*</span><span> debug_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    size_t</span><span> total_size </span><span>=</span><span> sizeof</span><span>(</span><span>alloc_header_t</span><span>) </span><span>+</span><span> size </span><span>+</span><span> sizeof</span><span>(</span><span>uint32_t</span><span>);</span></span>
<span><span>    void*</span><span> raw_ptr </span><span>=</span><span> malloc</span><span>(total_size);</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (</span><span>!</span><span>raw_ptr) </span><span>return</span><span> NULL</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    alloc_header_t</span><span>*</span><span> header </span><span>=</span><span> (</span><span>alloc_header_t</span><span>*</span><span>)raw_ptr;</span></span>
<span><span>    header-&gt;magic </span><span>=</span><span> MALLOC_MAGIC_HEADER;</span></span>
<span><span>    header-&gt;size </span><span>=</span><span> size;</span></span>
<span><span>    header-&gt;flags </span><span>=</span><span> 0</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    // User pointer starts after header</span></span>
<span><span>    void*</span><span> user_ptr </span><span>=</span><span> (</span><span>char*</span><span>)raw_ptr </span><span>+</span><span> sizeof</span><span>(</span><span>alloc_header_t</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    // Footer at the end</span></span>
<span><span>    uint32_t*</span><span> footer </span><span>=</span><span> (</span><span>uint32_t*</span><span>)((</span><span>char*</span><span>)user_ptr </span><span>+</span><span> size);</span></span>
<span><span>    *</span><span>footer </span><span>=</span><span> MALLOC_MAGIC_FOOTER;</span></span>
<span><span>    </span></span>
<span><span>    return</span><span> user_ptr;</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p>Memory layout for debug allocator:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>[HEADER: 16 bytes] [USER DATA: requested size] [FOOTER: 4 bytes]</span></span>
<span><span>├─ Magic (4B)      ├─ Your actual data        └─ Magic (4B)</span></span>
<span><span>├─ Size (8B)       │                              0xCAFEBABE</span></span>
<span><span>├─ Flags (4B)      │</span></span>
<span><span>└─ 0xDEADBEEF      └─ Returned pointer points here</span></span></code></pre><p><span>plaintext</span></p></div>
<p><strong>3. Direct mmap allocator</strong> - <em>Bypasses the heap entirely, requesting memory pages directly from the OS</em>:</p>
<blockquote>
<p><strong>Use case</strong>: Large allocations, security-sensitive code, custom memory management <br>
<strong>Pros</strong>: Isolated from heap corruption, guaranteed zeroed memory, can be marked read-only <br>
<strong>Cons</strong>: Minimum allocation is 4KB (page size), slow for small allocations</p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// mmap_allocator.c</span></span>
<span><span>void*</span><span> mmap_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    size_t</span><span> page_size </span><span>=</span><span> sysconf</span><span>(_SC_PAGESIZE);</span></span>
<span><span>    size_t</span><span> alloc_size </span><span>=</span><span> ((size </span><span>+</span><span> page_size </span><span>-</span><span> 1</span><span>) </span><span>/</span><span> page_size) </span><span>*</span><span> page_size;</span></span>
<span><span>    </span></span>
<span><span>    void*</span><span> ptr </span><span>=</span><span> mmap</span><span>(</span><span>NULL</span><span>, alloc_size, PROT_READ </span><span>|</span><span> PROT_WRITE, </span></span>
<span><span>                     MAP_PRIVATE </span><span>|</span><span> MAP_ANONYMOUS, </span><span>-</span><span>1</span><span>, </span><span>0</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (ptr </span><span>==</span><span> MAP_FAILED) </span><span>return</span><span> NULL</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    // Store size in first 8 bytes</span></span>
<span><span>    *</span><span>((</span><span>size_t*</span><span>)ptr) </span><span>=</span><span> alloc_size;</span></span>
<span><span>    return</span><span> (</span><span>char*</span><span>)ptr </span><span>+</span><span> sizeof</span><span>(</span><span>size_t</span><span>);</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p><strong>4. Arena allocator</strong> - <em>A bump allocator that allocates from a large pool and frees everything at once</em>:</p>
<blockquote>
<p><strong>Use case</strong>: Temporary allocations, parsing, per-request memory in servers <br>
<strong>Pros</strong>: Extremely fast allocation (just pointer bump), no fragmentation, cache-friendly <br>
<strong>Cons</strong>: Can’t free individual allocations, may waste memory</p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// arena_allocator.c</span></span>
<span><span>typedef</span><span> struct</span><span> arena {</span></span>
<span><span>    void*</span><span> memory;</span></span>
<span><span>    size_t</span><span> size;</span></span>
<span><span>    size_t</span><span> used;</span></span>
<span><span>    struct</span><span> arena</span><span>*</span><span> next;</span></span>
<span><span>} </span><span>arena_t</span><span>;</span></span>
<span></span>
<span><span>void*</span><span> arena_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    // Align to 8 bytes - required for 64-bit pointers and doubles</span></span>
<span><span>    // Formula: (size + 7) &amp; ~7 rounds up to next multiple of 8</span></span>
<span><span>    size </span><span>=</span><span> (size </span><span>+</span><span> 7</span><span>) </span><span>&amp;</span><span> ~</span><span>7</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (</span><span>!</span><span>g_arena </span><span>||</span><span> g_arena-&gt;used </span><span>+</span><span> size </span><span>&gt;</span><span> g_arena-&gt;size) {</span></span>
<span><span>        // Need new arena</span></span>
<span><span>        arena_t</span><span>*</span><span> new_arena </span><span>=</span><span> malloc</span><span>(</span><span>sizeof</span><span>(</span><span>arena_t</span><span>));</span></span>
<span><span>        new_arena-&gt;memory </span><span>=</span><span> malloc</span><span>(</span><span>1024</span><span> *</span><span> 1024</span><span>);</span><span> // 1MB chunks</span></span>
<span><span>        new_arena-&gt;size </span><span>=</span><span> 1024</span><span> *</span><span> 1024</span><span>;</span></span>
<span><span>        new_arena-&gt;used </span><span>=</span><span> 0</span><span>;</span></span>
<span><span>        new_arena-&gt;next </span><span>=</span><span> g_arena;</span></span>
<span><span>        g_arena </span><span>=</span><span> new_arena;</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    void*</span><span> ptr </span><span>=</span><span> (</span><span>char*</span><span>)g_arena-&gt;memory </span><span>+</span><span> g_arena-&gt;used;</span></span>
<span><span>    g_arena-&gt;used </span><span>+=</span><span> size;</span></span>
<span><span>    return</span><span> ptr;</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<h3 id="creating-safe-crash-tests">Creating Safe Crash Tests<a href="#creating-safe-crash-tests">#</a></h3>
<p>The most challenging part was creating tests that could crash safely and provide useful diagnostics. Since mixing allocators can cause segmentation faults, I needed to isolate each test in a subprocess:</p>
<blockquote>
<p>📊 <strong>Why Subprocess Isolation?</strong></p>
<ul>
<li><strong>Main process safety</strong>: Crashes in subprocess don’t kill the test harness</li>
<li><strong>Exit code capture</strong>: Can detect SIGSEGV (-11) vs SIGABRT (-6) vs success (0)</li>
<li><strong>Output collection</strong>: Capture stdout/stderr even when process crashes</li>
<li><strong>Timeout protection</strong>: Prevent infinite loops with <code>timeout</code> command</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// crash_tests.rs</span></span>
<span><span>use</span><span> std</span><span>::</span><span>process</span><span>::</span><span>{</span><span>Command</span><span>, </span><span>Stdio</span><span>};</span></span>
<span><span>use</span><span> std</span><span>::</span><span>io</span><span>::</span><span>Write</span><span>;</span></span>
<span></span>
<span><span>// Note: Crash test subprocess management is handled by tools/run_crash_tests.sh</span></span>
<span><span>// This bash script approach provides better isolation and exit code handling.</span></span>
<span></span>
<span><span>// The actual crash tests are implemented in crash_tests.rs:</span></span>
<span><span>fn</span><span> test_rust_free_c_malloc</span><span>() {</span></span>
<span><span>    println!</span><span>(</span><span>"=== Test: Rust dealloc on C malloc ==="</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    unsafe</span><span> {</span></span>
<span><span>        let</span><span> ptr </span><span>=</span><span> standard_malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>        println!</span><span>(</span><span>"C malloc returned: {:p}"</span><span>, ptr);</span></span>
<span><span>        </span></span>
<span><span>        // This is UNDEFINED BEHAVIOR - mixing allocators!</span></span>
<span><span>        let</span><span> layout </span><span>=</span><span> Layout</span><span>::</span><span>from_size_align</span><span>(</span><span>64</span><span>, </span><span>8</span><span>)</span><span>.</span><span>unwrap</span><span>();</span></span>
<span><span>        println!</span><span>(</span><span>"Attempting Rust dealloc with layout: {:?}"</span><span>, layout);</span></span>
<span><span>        std</span><span>::</span><span>alloc</span><span>::</span><span>dealloc</span><span>(ptr </span><span>as</span><span> *mut</span><span> u8</span><span>, layout);</span></span>
<span><span>        </span></span>
<span><span>        println!</span><span>(</span><span>"If you see this, it didn't crash immediately..."</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>The crash test script (<code>tools/run_crash_tests.sh</code>) runs each test with timeout protection:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>timeout</span><span> 5</span><span> ./target/release/crash_tests</span><span> $test </span><span>&gt;&gt;</span><span> $OUTPUT_FILE </span><span>2&gt;&amp;1</span></span>
<span><span>EXIT_CODE</span><span>=</span><span>$?</span></span>
<span></span>
<span><span>case</span><span> $EXIT_CODE </span><span>in</span></span>
<span><span>    0</span><span>)</span></span>
<span><span>        echo</span><span> "Result: NO CRASH (dangerous - undefined behavior likely)"</span></span>
<span><span>        ;;</span></span>
<span><span>    134</span><span>)</span></span>
<span><span>        echo</span><span> "Result: SIGABRT (allocator detected corruption)"</span></span>
<span><span>        ;;</span></span>
<span><span>    139</span><span>)</span></span>
<span><span>        echo</span><span> "Result: SIGSEGV (segmentation fault)"</span></span>
<span><span>        ;;</span></span>
<span><span>esac</span></span></code></pre><p><span>bash</span></p></div>
<h2 id="first-experiments-surprising-results">First Experiments: Surprising Results<a href="#first-experiments-surprising-results">#</a></h2>
<p>With the laboratory built, it was time to start experimenting. My first test was the obvious one - what happens when you mix allocators?</p>
<h3 id="experiment-1-the-basic-mix">Experiment 1: The Basic Mix<a href="#experiment-1-the-basic-mix">#</a></h3>
<p>To test allocator mixing safely, I ran each test in a subprocess to catch crashes:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// From our test harness</span></span>
<span><span>fn</span><span> test_allocator_mixing</span><span>() {</span></span>
<span><span>    let</span><span> child </span><span>=</span><span> Command</span><span>::</span><span>new</span><span>(</span><span>"./test_binary"</span><span>)</span></span>
<span><span>        .</span><span>arg</span><span>(</span><span>"mix_allocators"</span><span>)</span></span>
<span><span>        .</span><span>output</span><span>()</span></span>
<span><span>        .</span><span>expect</span><span>(</span><span>"Failed to execute test"</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    // In the subprocess:</span></span>
<span><span>    unsafe</span><span> fn</span><span> mix_allocators</span><span>() {</span></span>
<span><span>        let</span><span> c_ptr </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>        println!</span><span>(</span><span>"C malloc returned: {:p}"</span><span>, c_ptr);</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> layout </span><span>=</span><span> Layout</span><span>::</span><span>from_size_align</span><span>(</span><span>64</span><span>, </span><span>8</span><span>)</span><span>.</span><span>unwrap</span><span>();</span></span>
<span><span>        std</span><span>::</span><span>alloc</span><span>::</span><span>dealloc</span><span>(c_ptr </span><span>as</span><span> *mut</span><span> u8</span><span>, layout);</span></span>
<span><span>        </span></span>
<span><span>        println!</span><span>(</span><span>"If you see this, we got lucky..."</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    let</span><span> exit_code </span><span>=</span><span> child</span><span>.</span><span>status</span><span>.</span><span>code</span><span>()</span><span>.</span><span>unwrap_or</span><span>(</span><span>-</span><span>1</span><span>);</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>I expected an immediate crash. What I got surprised me:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>C malloc returned: 0x55cd332f5be0</span></span>
<span><span>Attempting Rust dealloc with layout: Layout { size: 64, align: 8 }</span></span>
<span><span>If you see this, it didn't crash immediately...</span></span>
<span><span></span></span>
<span><span>Exit code: 0</span></span></code></pre><p><span>plaintext</span></p></div>
<p>Remember our exit code table? Exit code 0 is the <strong>worst possible outcome</strong>. The program continued with corrupted heap metadata - a silent time bomb.</p>
<blockquote>
<p>🔥 <strong>DANGER: Exit Code 0 with Memory Corruption</strong></p>
<p>This is a nightmare scenario:</p>
<ul>
<li>✅ Your tests pass</li>
<li>✅ Your program runs “normally”</li>
<li>❌ Heap metadata is silently corrupted</li>
<li>❌ Random crashes will occur later</li>
<li>❌ Data corruption is unpredictable</li>
<li>❌ Security vulnerabilities are introduced</li>
</ul>
<p>A crash (SIGSEGV/SIGABRT) is actually the <strong>safe</strong> outcome!</p>
</blockquote>
<p>Let’s understand why this happened instead of crashing immediately.</p>
<h3 id="experiment-2-understanding-the-non-crash">Experiment 2: Understanding the Non-Crash<a href="#experiment-2-understanding-the-non-crash">#</a></h3>
<p>Why didn’t it crash? Time for some detective work. I needed to peek at the raw memory around our allocation to understand glibc’s metadata structure.</p>
<blockquote>
<p>📊 <strong>Tools Used for Memory Inspection:</strong></p>
<ul>
<li><strong>Memory access</strong>: <code>std::slice::from_raw_parts</code> - Rust’s way to view raw memory as a byte slice</li>
<li><strong>Offset calculation</strong>: <code>pointer.offset(-16)</code> - Look 16 bytes before the returned pointer</li>
<li><strong>Why -16?</strong>: glibc stores chunk metadata in the 8-16 bytes before user data</li>
<li><strong>Run command</strong>: <code>./tools/deep_analysis.sh</code> (dynamically generates and runs analysis code)</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// deep_analysis.sh dynamically generates this analysis code:</span></span>
<span><span>fn</span><span> analyze_glibc_malloc_internals</span><span>() {</span></span>
<span><span>    unsafe</span><span> {</span></span>
<span><span>        // Allocate different sizes to trigger different paths</span></span>
<span><span>        let</span><span> small </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>24</span><span>);      </span><span>// Fastbin</span></span>
<span><span>        let</span><span> medium </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>512</span><span>);    </span><span>// Smallbin  </span></span>
<span><span>        let</span><span> large </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>131072</span><span>);  </span><span>// Large bin or mmap</span></span>
<span><span>        </span></span>
<span><span>        // Peek at malloc chunk headers (glibc specific)</span></span>
<span><span>        // Chunk format: size | flags in lowest 3 bits</span></span>
<span><span>        if</span><span> !</span><span>small</span><span>.</span><span>is_null</span><span>() {</span></span>
<span><span>            let</span><span> chunk_ptr </span><span>=</span><span> (small </span><span>as</span><span> *mut</span><span> usize</span><span>)</span><span>.</span><span>offset</span><span>(</span><span>-</span><span>1</span><span>);</span></span>
<span><span>            let</span><span> chunk_size </span><span>=</span><span> *</span><span>chunk_ptr </span><span>&amp;</span><span> !</span><span>0x7</span><span>;</span></span>
<span><span>            let</span><span> flags </span><span>=</span><span> *</span><span>chunk_ptr </span><span>&amp;</span><span> 0x7</span><span>;</span></span>
<span><span>            </span></span>
<span><span>            println!</span><span>(</span><span>"Small chunk header:"</span><span>);</span></span>
<span><span>            println!</span><span>(</span><span>"  Size: {} (0x{:x})"</span><span>, chunk_size, chunk_size);</span></span>
<span><span>            println!</span><span>(</span><span>"  Flags: 0x{:x}"</span><span>, flags);</span></span>
<span><span>            println!</span><span>(</span><span>"    PREV_INUSE: {}"</span><span>, flags </span><span>&amp;</span><span> 0x1</span><span> !=</span><span> 0</span><span>);</span></span>
<span><span>            println!</span><span>(</span><span>"    IS_MMAPPED: {}"</span><span>, flags </span><span>&amp;</span><span> 0x2</span><span> !=</span><span> 0</span><span>);</span></span>
<span><span>        }</span></span>
<span><span>        </span></span>
<span><span>        libc</span><span>::</span><span>free</span><span>(small);</span></span>
<span><span>        libc</span><span>::</span><span>free</span><span>(medium);</span></span>
<span><span>        libc</span><span>::</span><span>free</span><span>(large);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>To run this analysis:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>cd</span><span> rust-ffi</span></span>
<span><span>export</span><span> LD_LIBRARY_PATH</span><span>=</span><span>../c-lib:$LD_LIBRARY_PATH</span></span>
<span><span>cargo</span><span> run</span><span> --release</span><span> --bin</span><span> deep_analysis</span></span></code></pre><p><span>bash</span></p></div>
<p>This revealed glibc’s metadata structure:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Memory layout around allocation:</span></span>
<span><span>Offset -16 to -1 (before user ptr):</span></span>
<span><span>00 00 00 00 00 00 00 00 51 00 00 00 00 00 00 00</span></span>
<span><span>Offset 0 to 15 (user data):</span></span>
<span><span>00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span></span></code></pre><p><span>plaintext</span></p></div>
<p>That <code>0x51</code> at offset -8 is the key. Let me break it down:</p>
<ul>
<li>Bottom 3 bits are flags:
<ul>
<li>Bit 0 (0x1): PREV_INUSE - previous chunk is allocated</li>
<li>Bit 1 (0x2): IS_MMAPPED - chunk from mmap (not set here)</li>
<li>Bit 2 (0x4): NON_MAIN_ARENA - from thread arena (not set)</li>
</ul>
</li>
<li>Upper bits: 0x50 = 80 bytes total chunk size</li>
</ul>
<p>So: User requested 64 bytes, glibc allocated an 80-byte chunk (16 bytes metadata overhead).</p>
<p>When Rust’s allocator looked for its metadata at a different offset, it found zeros - which by pure chance didn’t trigger an immediate crash. But the heap is now corrupted, and any subsequent allocation could fail catastrophically.</p>
<h3 id="experiment-3-the-allocator-matrix">Experiment 3: The Allocator Matrix<a href="#experiment-3-the-allocator-matrix">#</a></h3>
<p>I systematically tested every combination:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// allocator_matrix.rs</span></span>
<span><span>fn</span><span> test_allocator_mixing</span><span>() {</span></span>
<span><span>    let</span><span> allocators </span><span>=</span><span> vec!</span><span>[</span><span>"standard"</span><span>, </span><span>"debug"</span><span>, </span><span>"mmap"</span><span>, </span><span>"arena"</span><span>];</span></span>
<span><span>    let</span><span> mut</span><span> results </span><span>=</span><span> Vec</span><span>::</span><span>new</span><span>();</span></span>
<span><span>    </span></span>
<span><span>    for</span><span> alloc </span><span>in</span><span> &amp;</span><span>allocators {</span></span>
<span><span>        for</span><span> dealloc </span><span>in</span><span> &amp;</span><span>allocators {</span></span>
<span><span>            if</span><span> alloc </span><span>!=</span><span> dealloc {</span></span>
<span><span>                let</span><span> result </span><span>=</span><span> test_mix</span><span>(alloc, dealloc);</span></span>
<span><span>                results</span><span>.</span><span>push</span><span>(result);</span></span>
<span><span>            }</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    // Print results matrix</span></span>
<span><span>    println!</span><span>(</span><span>"</span><span>\n</span><span>Allocator Mixing Results:"</span><span>);</span></span>
<span><span>    println!</span><span>(</span><span>"Alloc with → Free with = Result"</span><span>);</span></span>
<span><span>    println!</span><span>(</span><span>"─────────────────────────────────"</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    for</span><span> result </span><span>in</span><span> results {</span></span>
<span><span>        println!</span><span>(</span><span>"{:10} → {:10} = {:?}"</span><span>, </span></span>
<span><span>                 result</span><span>.</span><span>allocator, </span></span>
<span><span>                 result</span><span>.</span><span>deallocator, </span></span>
<span><span>                 result</span><span>.</span><span>outcome);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>The results painted a clear picture:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Allocator Mixing Results:</span></span>
<span><span>Alloc with → Free with = Result</span></span>
<span><span>─────────────────────────────────</span></span>
<span><span>standard   → debug      = CRASH (Abort: invalid magic number)</span></span>
<span><span>standard   → mmap       = CRASH (Segfault: munmap on malloc'd memory)</span></span>
<span><span>standard   → arena      = NO-OP (arena doesn't free individual chunks)</span></span>
<span><span>debug      → standard   = CRASH (Segfault: bad metadata offset)</span></span>
<span><span>debug      → mmap       = CRASH (Segfault: munmap on malloc'd memory)</span></span>
<span><span>debug      → arena      = NO-OP</span></span>
<span><span>mmap       → standard   = CRASH (Abort: free on mmap'd memory)</span></span>
<span><span>mmap       → debug      = CRASH (Abort: bad magic number)</span></span>
<span><span>mmap       → arena      = NO-OP</span></span>
<span><span>arena      → standard   = CRASH (double free when arena resets)</span></span>
<span><span>arena      → debug      = CRASH (Abort: bad magic number)</span></span>
<span><span>arena      → mmap       = CRASH (Segfault: munmap on malloc'd memory)</span></span></code></pre><p><span>plaintext</span></p></div>
<blockquote>
<p><strong>Update</strong>: Our actual crash tests revealed a more nuanced reality:</p>
<ul>
<li><strong>Rust/C mixing often doesn’t crash immediately</strong> (Exit code 0)</li>
<li><strong>Only certain combinations trigger immediate detection</strong> (like double_free)</li>
<li><strong>Silent corruption is the most common outcome</strong> - far more dangerous than crashes</li>
</ul>
</blockquote>
<p>Key insights:</p>
<ul>
<li>Debug allocator’s magic number checks catch corruption fastest (SIGABRT)</li>
<li>Standard/mmap mixing fails at the syscall level (SIGSEGV)</li>
<li>Arena allocator’s NO-OP behavior creates memory leaks</li>
<li>Every non-matching combination eventually fails - it’s just a matter of when</li>
</ul>
<h3 id="experiment-4-size-class-discovery">Experiment 4: Size Class Discovery<a href="#experiment-4-size-class-discovery">#</a></h3>
<blockquote>
<p><strong>What are size classes?</strong> Memory allocators don’t allocate exact byte amounts. Instead, they round up to predefined “size classes” to reduce fragmentation and improve performance. For example, if you request 20 bytes, you might actually get 24 bytes. This standardization allows the allocator to efficiently reuse freed chunks and maintain free lists for common sizes.</p>
</blockquote>
<p>One fascinating discovery was how allocators organize memory into these size classes. I used glibc’s <code>malloc_usable_size()</code> function to discover the actual allocated sizes:</p>
<blockquote>
<p>📊 <strong>Tools for Size Class Discovery:</strong></p>
<ul>
<li><strong>Function</strong>: <code>libc::malloc_usable_size()</code> - Returns actual allocated size</li>
<li><strong>Platform</strong>: Linux-specific (requires <code>#[cfg(target_os = "linux")]</code>)</li>
<li><strong>Method</strong>: Allocate every size from 1-256 bytes, track when actual size changes</li>
<li><strong>Purpose</strong>: Understand memory overhead and fragmentation</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// size_classes.rs - Part of comprehensive_tests</span></span>
<span><span>fn</span><span> discover_size_classes</span><span>() {</span></span>
<span><span>    println!</span><span>(</span><span>"Discovering allocator size classes...</span><span>\n</span><span>"</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    let</span><span> mut</span><span> size_to_actual </span><span>=</span><span> HashMap</span><span>::</span><span>new</span><span>();</span></span>
<span><span>    </span></span>
<span><span>    for</span><span> size </span><span>in</span><span> 1</span><span>..=</span><span>256</span><span> {</span></span>
<span><span>        unsafe</span><span> {</span></span>
<span><span>            let</span><span> ptr </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(size);</span></span>
<span><span>            </span></span>
<span><span>            #[cfg(target_os </span><span>=</span><span> "linux"</span><span>)]</span></span>
<span><span>            {</span></span>
<span><span>                // This function reveals the actual chunk size</span></span>
<span><span>                let</span><span> actual </span><span>=</span><span> libc</span><span>::</span><span>malloc_usable_size</span><span>(ptr) </span><span>as</span><span> usize</span><span>;</span></span>
<span><span>                size_to_actual</span><span>.</span><span>insert</span><span>(size, actual);</span></span>
<span><span>            }</span></span>
<span><span>            </span></span>
<span><span>            libc</span><span>::</span><span>free</span><span>(ptr);</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    // Find size class boundaries</span></span>
<span><span>    let</span><span> mut</span><span> current_class </span><span>=</span><span> 0</span><span>;</span></span>
<span><span>    for</span><span> size </span><span>in</span><span> 1</span><span>..=</span><span>256</span><span> {</span></span>
<span><span>        let</span><span> actual </span><span>=</span><span> size_to_actual[</span><span>&amp;</span><span>size];</span></span>
<span><span>        if</span><span> actual </span><span>!=</span><span> current_class {</span></span>
<span><span>            println!</span><span>(</span><span>"Size class boundary at {} bytes → {} bytes actual"</span><span>, </span></span>
<span><span>                     size, actual);</span></span>
<span><span>            current_class </span><span>=</span><span> actual;</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>To run this analysis:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>./target/release/comprehensive_tests</span><span> |</span><span> grep</span><span> "Size class"</span></span></code></pre><p><span>bash</span></p></div>
<p>Results showed glibc’s size class optimization:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Size class boundary at 1 bytes → 24 bytes actual</span></span>
<span><span>Size class boundary at 25 bytes → 40 bytes actual</span></span>
<span><span>Size class boundary at 41 bytes → 56 bytes actual</span></span>
<span><span>Size class boundary at 57 bytes → 72 bytes actual</span></span>
<span><span>Size class boundary at 73 bytes → 88 bytes actual</span></span>
<span><span>...</span></span></code></pre><p><span>plaintext</span></p></div>
<blockquote>
<p>⚠️ <strong>The 2300% Overhead</strong></p>
<p>The minimum allocation is 24 bytes - even for a single byte! This 2300% overhead for tiny allocations explains why pooling small objects is so important.</p>
</blockquote>
<h3 id="hidden-danger-use-after-free-data-persistence">Hidden Danger: Use-After-Free Data Persistence<a href="#hidden-danger-use-after-free-data-persistence">#</a></h3>
<p>One of the most surprising discoveries was how much data survives after <code>free()</code>. I tested this by filling memory with a pattern, freeing it, then immediately reallocating to see what remained:</p>
<blockquote>
<p>📊 <strong>Use-After-Free Analysis Method:</strong></p>
<ul>
<li><strong>Pattern</strong>: Fill with incrementing bytes (0x00, 0x01, 0x02…)</li>
<li><strong>Test</strong>: Free the memory, immediately allocate same size</li>
<li><strong>Detection</strong>: Compare byte-by-byte to see what survived</li>
<li><strong>Tool</strong>: Part of <code>deep_analysis</code> binary, see Experiment 2.3 in EXPERIMENTS.md</li>
</ul>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// From EXPERIMENTS.md - Experiment 2.3</span></span>
<span><span>void</span><span> analyze_use_after_free</span><span>() {</span></span>
<span><span>    uint8_t*</span><span> ptr </span><span>=</span><span> malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    // Fill with recognizable pattern</span></span>
<span><span>    for</span><span> (</span><span>size_t</span><span> i </span><span>=</span><span> 0</span><span>; i </span><span>&lt;</span><span> 64</span><span>; i</span><span>++</span><span>) {</span></span>
<span><span>        ptr</span><span>[i] </span><span>=</span><span> (</span><span>uint8_t</span><span>)(i </span><span>&amp;</span><span> 0x</span><span>FF</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    free</span><span>(ptr);</span></span>
<span><span>    </span></span>
<span><span>    // Immediately allocate same size</span></span>
<span><span>    uint8_t*</span><span> new_ptr </span><span>=</span><span> malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (new_ptr </span><span>==</span><span> ptr) {</span><span>  // Often get same address back</span></span>
<span><span>        // Count surviving bytes...</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p>In our tests:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Size 64: 48/64 bytes survived (75.0%)</span></span>
<span><span>First 32 bytes after free:</span></span>
<span><span>00 00 00 00 00 00 00 00 20 6e 56 3f fc 7f 00 00  &lt;- Free list pointers</span></span>
<span><span>10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f  &lt;- Original data intact!</span></span></code></pre><p><span>plaintext</span></p></div>
<p>Only the first 16 bytes get overwritten with free list management pointers. The rest of your data remains in memory, readable by any subsequent allocation that reuses this chunk. This is a severe security risk - sensitive data like passwords or keys can persist long after being “freed”.</p>
<h3 id="experiment-5-performance-baselines">Experiment 5: Performance Baselines<a href="#experiment-5-performance-baselines">#</a></h3>
<p>Before diving into complex performance analysis (coming in Part 3), I established baselines using our performance analysis tools:</p>
<blockquote>
<p>📊 <strong>Performance Measurement Tools:</strong></p>
<ul>
<li><strong>Timing</strong>: <code>std::time::Instant</code> for high-resolution timing</li>
<li><strong>Warmup</strong>: 1000 allocations to prime the allocator caches</li>
<li><strong>Statistical method</strong>: 100,000 iterations, take median of 5 runs</li>
<li><strong>CPU isolation</strong>: Disabled frequency scaling, pinned to specific cores</li>
<li><strong>Script</strong>: <code>tools/perf_analysis.sh</code> automates the full benchmark</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// perf_analysis.sh dynamically generates performance benchmarking code:</span></span>
<span><span>fn</span><span> benchmark_allocator</span><span>&lt;</span><span>F</span><span>, </span><span>G</span><span>&gt;(name</span><span>:</span><span> &amp;</span><span>str</span><span>, alloc_fn</span><span>:</span><span> F</span><span>, free_fn</span><span>:</span><span> G</span><span>, size</span><span>:</span><span> usize</span><span>)</span></span>
<span><span>where</span></span>
<span><span>    F</span><span>:</span><span> Fn</span><span>(</span><span>usize</span><span>) </span><span>-&gt;</span><span> *mut</span><span> c_void,</span></span>
<span><span>    G</span><span>:</span><span> Fn</span><span>(</span><span>*mut</span><span> c_void),</span></span>
<span><span>{</span></span>
<span><span>    const</span><span> ITERATIONS</span><span>:</span><span> usize</span><span> =</span><span> 100_000</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    // Warmup</span></span>
<span><span>    for</span><span> _ </span><span>in</span><span> 0</span><span>..</span><span>1000</span><span> {</span></span>
<span><span>        let</span><span> ptr </span><span>=</span><span> alloc_fn</span><span>(size);</span></span>
<span><span>        if</span><span> !</span><span>ptr</span><span>.</span><span>is_null</span><span>() {</span></span>
<span><span>            free_fn</span><span>(ptr);</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    // Actual benchmark</span></span>
<span><span>    let</span><span> start </span><span>=</span><span> Instant</span><span>::</span><span>now</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> mut</span><span> pointers </span><span>=</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(iterations);</span></span>
<span><span>        for</span><span> _ </span><span>in</span><span> 0</span><span>..</span><span>iterations {</span></span>
<span><span>            unsafe</span><span> {</span></span>
<span><span>                let</span><span> ptr </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(size);</span></span>
<span><span>                pointers</span><span>.</span><span>push</span><span>(ptr);</span></span>
<span><span>            }</span></span>
<span><span>        }</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> alloc_time </span><span>=</span><span> start</span><span>.</span><span>elapsed</span><span>();</span></span>
<span><span>        let</span><span> alloc_rate </span><span>=</span><span> iterations </span><span>as</span><span> f64</span><span> /</span><span> alloc_time</span><span>.</span><span>as_secs_f64</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> start </span><span>=</span><span> Instant</span><span>::</span><span>now</span><span>();</span></span>
<span><span>        for</span><span> ptr </span><span>in</span><span> pointers {</span></span>
<span><span>            unsafe</span><span> {</span></span>
<span><span>                libc</span><span>::</span><span>free</span><span>(ptr);</span></span>
<span><span>            }</span></span>
<span><span>        }</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> free_time </span><span>=</span><span> start</span><span>.</span><span>elapsed</span><span>();</span></span>
<span><span>        let</span><span> free_rate </span><span>=</span><span> iterations </span><span>as</span><span> f64</span><span> /</span><span> free_time</span><span>.</span><span>as_secs_f64</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        println!</span><span>(</span><span>"Size {:5}: {:7.1}M allocs/sec, {:7.1}M frees/sec"</span><span>,</span></span>
<span><span>                 size, alloc_rate </span><span>/</span><span> 1_000_000.0</span><span>, free_rate </span><span>/</span><span> 1_000_000.0</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>To reproduce these measurements:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>cd</span><span> rust-ffi</span></span>
<span><span>cargo</span><span> build</span><span> --release</span><span> --bin</span><span> perf_test</span></span>
<span><span>export</span><span> LD_LIBRARY_PATH</span><span>=</span><span>../c-lib:$LD_LIBRARY_PATH</span></span>
<span><span>./target/release/perf_test</span></span></code></pre><p><span>bash</span></p></div>
<p>Initial results from our testing:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Size    16: 17.1M allocs/sec, 32.3M frees/sec (58.3ns alloc, 31.0ns free)</span></span>
<span><span>Size    64: 12.8M allocs/sec, 31.9M frees/sec (78.0ns alloc, 31.3ns free)</span></span>
<span><span>Size   256:  5.6M allocs/sec,  9.3M frees/sec (177ns alloc, 107ns free)</span></span>
<span><span>Size  1024:  2.0M allocs/sec,  5.3M frees/sec (490ns alloc, 188ns free)</span></span>
<span><span>Size  4096:  0.5M allocs/sec,  2.3M frees/sec (1.9μs alloc, 428ns free)</span></span></code></pre><p><span>plaintext</span></p></div>
<p>Key observations:</p>
<ul>
<li>Small allocations are incredibly fast due to thread-local caching (tcache)</li>
<li>Free is consistently 2-6x faster than allocation</li>
<li>Performance degrades with size due to cache misses and syscalls for large allocations</li>
</ul>
<blockquote>
<p><strong>What is tcache?</strong> Thread-local cache (tcache) is glibc’s optimization that gives each thread its own small cache of recently freed chunks. This avoids lock contention and makes small allocations extremely fast - no need to access the global heap. Chunks up to 1032 bytes (64 chunks × 7 size classes) can be cached per thread.</p>
</blockquote>
<ul>
<li>But beware: these are best-case numbers with perfect cache conditions!</li>
</ul>
<h2 id="key-takeaways-and-whats-next">Key Takeaways and What’s Next<a href="#key-takeaways-and-whats-next">#</a></h2>
<p>This first part of our journey revealed several critical insights:</p>
<blockquote>
<p>💡 <strong>Key Insights from Our Experiments</strong></p>
<ol>
<li>
<p><strong>Exit Code 0 is the enemy</strong> - Our tests showed that mixing allocators often doesn’t crash immediately (exit code 0), creating silent corruption that’s far more dangerous than an immediate segfault</p>
</li>
<li>
<p><strong>Metadata tells the story</strong> - That <code>0x51</code> value revealed glibc stores size (0x50) + flags (0x1) before each allocation. Different allocators expect metadata at different offsets, causing the mixing failures</p>
</li>
<li>
<p><strong>Memory overhead is shocking</strong> - A 1-byte allocation consumes 24 bytes (2300% overhead!). Understanding size classes is crucial for efficient memory use</p>
</li>
<li>
<p><strong>Data persists after free</strong> - 75% of freed memory remains intact, creating serious security risks. Only the first 16 bytes get overwritten with free list pointers</p>
</li>
<li>
<p><strong>Cache effects dominate performance</strong> - False sharing caused an 8.67x slowdown in our tests. Memory layout matters as much as algorithm choice</p>
</li>
<li>
<p><strong>Every allocator combination fails differently</strong> - Our matrix showed debug allocators catch errors fastest (SIGABRT), while arena allocators silently leak memory</p>
</li>
</ol>
</blockquote>
<p>Going back to the interview question: “What happens if you allocate with malloc and free with Rust?”</p>
<p>Now we know: You’ll get exit code 0 (the dangerous silent corruption), followed by unpredictable crashes later. The only safe answer is “never do this.”</p>
<p>In <strong>Part 2</strong>, we’ll dive deeper with core dump analysis, explore how attackers exploit these vulnerabilities, and see what actually happens at the moment of crash. We’ll use gdb to trace through the exact instruction where things go wrong.</p>
<blockquote>
<p>🔍 <strong>Preview of Debugging Tools in Part 2:</strong></p>
<ul>
<li><strong>Core dumps</strong>: <code>ulimit -c unlimited</code> and analyzing with <code>gdb</code></li>
<li><strong>Memory inspection</strong>: <code>x/32gx $rsp</code> to examine stack contents</li>
<li><strong>Backtrace analysis</strong>: <code>bt full</code> to see the exact crash location</li>
<li><strong>LD_PRELOAD hooks</strong>: Intercept malloc/free to trace allocations</li>
</ul>
</blockquote>
<p>Stay tuned for <strong>Part 2</strong>, where things get really interesting - we’ll trigger crashes on purpose, analyze core dumps, and see what actually happens when allocators collide. Spoiler: it’s even messier than you might think.</p>
<hr>
<blockquote>
<p>📝 <strong>Repository &amp; Testing Environment</strong></p>
<p>All code from this series is available at <a href="https://github.com/notashes/rust-c-memory-interop" rel="nofollow noopener noreferrer" target="_blank">https://github.com/notashes/rust-c-memory-interop<span> ↗</span></a>.</p>
<p>Tests were conducted on:</p>
<ul>
<li>Linux 6.5</li>
<li>glibc 2.39</li>
<li>Rust 1.75</li>
<li>Intel Core i7</li>
</ul>
<p>Your crashes may vary, but the principles remain constant.</p>
</blockquote>
<h3 id="debugging-tips-when-things-go-wrong">Debugging Tips: When Things Go Wrong<a href="#debugging-tips-when-things-go-wrong">#</a></h3>
<p>When working with FFI and memory allocators, here are essential debugging techniques:</p>
<p><strong>1. Enable Address Sanitizer (ASan)</strong>:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span># For C code</span></span>
<span><span>gcc</span><span> -fsanitize=address</span><span> -g</span><span> your_code.c</span></span>
<span></span>
<span><span># For Rust (in Cargo.toml)</span></span>
<span><span>[profile.dev]</span></span>
<span><span>opt-level</span><span> =</span><span> 0</span></span>
<span><span>debug</span><span> =</span><span> true</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>2. Use Valgrind for memory leak detection</strong>:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>valgrind</span><span> --leak-check=full</span><span> --show-leak-kinds=all</span><span> ./your_program</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>3. Core dump analysis</strong>:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span># Enable core dumps</span></span>
<span><span>ulimit</span><span> -c</span><span> unlimited</span></span>
<span></span>
<span><span># After crash, analyze with gdb</span></span>
<span><span>gdb</span><span> ./your_program</span><span> core</span></span>
<span><span>(</span><span>gdb</span><span>) </span><span>bt</span><span> full</span><span>  # Full backtrace</span></span>
<span><span>(</span><span>gdb</span><span>) </span><span>info</span><span> registers</span></span>
<span><span>(</span><span>gdb</span><span>) </span><span>x/32xg</span><span> $rsp  </span><span># Examine stack</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>4. Common FFI pitfalls to watch for</strong>:</p>
<ul>
<li><strong>Ownership confusion</strong>: Document who owns each pointer</li>
<li><strong>Lifetime mismatches</strong>: Rust may drop memory C still references</li>
<li><strong>ABI mismatches</strong>: Ensure calling conventions match</li>
<li><strong>Null checks</strong>: C functions may return NULL, Rust expects Option</li>
</ul>
<p><strong>5. Red flags in crash output</strong>:</p>
<ul>
<li><code>free(): invalid pointer</code> - Wrong allocator or corrupted metadata</li>
<li><code>double free or corruption</code> - Classic use-after-free</li>
<li><code>malloc(): memory corruption</code> - Heap metadata damaged</li>
<li>Exit code 0 with corruption - The worst case, silent failure</li>
</ul>
<h3 id="how-to-reproduce-these-experiments">How to Reproduce These Experiments<a href="#how-to-reproduce-these-experiments">#</a></h3>
<p>Want to see these crashes yourself? Here’s how to run the key experiments:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span># Clone the repository</span></span>
<span><span>git</span><span> clone</span><span> https://github.com/notashes/rust-c-memory-interop</span></span>
<span><span>cd</span><span> rust-c-memory-interop</span></span>
<span></span>
<span><span># Build the C library</span></span>
<span><span>cd</span><span> c-lib</span></span>
<span><span>make</span></span>
<span></span>
<span><span># Build Rust binaries</span></span>
<span><span>cd</span><span> ../rust-ffi</span></span>
<span><span>cargo</span><span> build</span><span> --release</span></span>
<span></span>
<span><span># Run crash tests (safely in subprocesses)</span></span>
<span><span>cd</span><span> ..</span></span>
<span><span>./tools/run_crash_tests.sh</span></span>
<span></span>
<span><span># Run dynamic analysis tools</span></span>
<span><span>./tools/deep_analysis.sh</span><span>    # Generates and runs memory analysis</span></span>
<span><span>./tools/perf_analysis.sh</span><span>    # Generates and runs performance benchmarks</span></span>
<span></span>
<span><span># View results</span></span>
<span><span>cat</span><span> test_results/crash_test_results_detailed.txt</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>Key Tools You’ll Need:</strong></p>
<ul>
<li><code>gcc</code> and <code>make</code> for C library</li>
<li><code>cargo</code> for Rust</li>
<li><code>perf</code> for performance analysis (optional)</li>
<li><code>gdb</code> for debugging crashes (optional)</li>
<li>Linux system (for glibc-specific features)</li>
</ul>     </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI promised efficiency. Instead, it's making us work harder (156 pts)]]></title>
            <link>https://afterburnout.co/p/ai-promised-to-make-us-more-efficient</link>
            <guid>44786790</guid>
            <pubDate>Mon, 04 Aug 2025 15:01:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://afterburnout.co/p/ai-promised-to-make-us-more-efficient">https://afterburnout.co/p/ai-promised-to-make-us-more-efficient</a>, See on <a href="https://news.ycombinator.com/item?id=44786790">Hacker News</a></p>
Couldn't get https://afterburnout.co/p/ai-promised-to-make-us-more-efficient: Error: getaddrinfo ENOTFOUND afterburnout.co]]></description>
        </item>
        <item>
            <title><![CDATA[Objects should shut the fuck up (175 pts)]]></title>
            <link>https://dustri.org/b/objects-should-shut-the-fuck-up.html</link>
            <guid>44786367</guid>
            <pubDate>Mon, 04 Aug 2025 14:33:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dustri.org/b/objects-should-shut-the-fuck-up.html">https://dustri.org/b/objects-should-shut-the-fuck-up.html</a>, See on <a href="https://news.ycombinator.com/item?id=44786367">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content" role="main">
        <article>
          <header>
            <h2>
              <a href="https://dustri.org/b/objects-should-shut-the-fuck-up.html" rel="bookmark" title="Permalink to Objects should shut the fuck up">Objects should shut the fuck up</a>
               
            </h2>
          </header>
          <div>
            <p>I have a small car, and it has a dual-tank: gas and
<a href="https://en.wikipedia.org/wiki/Liquefied_petroleum_gas">LPG</a>, which is a great
way to reduce my car-related budget, as LPG is way cheaper. Unfortunately, when
the tank is starting to get depleted, the car will emit strident and loud beeps
to notify me about it. And every single time time, it startles me like Hell,
which isn't something I appreciate very much, especially when I'm steering a 1
ton metal box to overtake a trailer at <a href="https://en.wikipedia.org/wiki/Autoroutes_of_France#Motorway_speed_limits">130km/h on the
highway</a>.
To make things even double-plus-good, a full-screen "LPG tank almost depleted!"
message will cover the whole dashboard. The very same dashboard that constantly
have at its bottom the current level of said LPG tank.</p>
<p>The only time I want my car to maybe make some noise is when some critical shit
is happening, like the oil level decreasing at an alarming rate. Having it yell
at me that I'm only able to drive around 100 more kilometers on LPG, while I
have a <strong>full gasoline tank</strong> affording me a total autonomy of like 1000
kilometres is anything but. I hate this, I hate that it's not configurable, I
hate that it's waking everyone asleep in the car (especially toddlers), and I
fucking hate that my car is actively lowering the safety of its passengers by
scaring its driver. And of course, the notification will repeat a couple of
times, at seemingly random intervals, likely because the complete bellend who
designed this terrible scheme is taking the ever-lowering worldwide car-crash
statistics as a personal affront, and is on a mission from God to fix this.</p>
<p>This major papercut made me think about how making noise for anything but the
direst emergency should be an off-by-default privilege that only the user can
explicitly grant, instead if being the default for all electricity-powered
objects. I'm a CyberSecurity Professional™, earning a living breaking into
computer and computer-adjacent systems, so I own the bare minimum in terms of
Smart Devices™, and yet, yet I realised that I still have a non-zero amount of
infernal noise-making crap.</p>
<p>For example, my washing machine has an obnoxious alarm when it completes a
cycle, that can fortunately be disabled via a (hidden!) menu. Now, I get it, it
might be useful to have some kind of alarm so that you don't forget your
soaking clothes and have them rot into a new variant of whatever medieval
disease. But, the alarm, while exceedingly loud, only lasts a handful of
seconds, making it close to useless. Moreover, if you forget your laundry long
enough for it to decay, you kind of deserve to have a Nurgle cult growing in
your basement. Even assuming for the sake of the argument that this
anti-feature could somehow be useful, this isn't the only yapping caused of
this fiendish machine: the fucking "beep" happening every time one turns the
knob or presses a button can't be deactivated. And don't you fucking dare talk
to me about accessibility: all buttons are touch-sensitive, so useless to
visual-impaired users, and all tones are exactly the same, making them
absolutely useless for anything but waking up/startling the sleeping and
unsuspecting house inhabitants. But this isn't everything, of course there is
more: it has a "cute" tone when it starts, for no fucking reason at all. Why is
this a thing? Who the fuck thought it would be a good idea? What's the
reasoning behind this? It's a washing machine, there is no complicated fragile
boot sequence, no hazardous warm-up shenanigans: I press the power-on button,
it starts. Imagine having this ludicrous behaviour on all your objects: Opening
your faucet? "DUDUDUDUUUUUUUU!" Unlocking your front-door?
"LULULUUUUULULUUUUUU!" Turning on the cooktop hood?
"LALALAAAAAAALAAAAAALAAAAA!" Maybe turning your lights on in your living room?
The Ride of the Valkyries starts blasting at full volume.</p>
<p>As electricity is green-ish and cheap-ish where I'm living, I have the luxury
of having a drier as well, forming an unholy honky duo with the washing
machine: while it thankfully doesn't have a startup sound, the interaction-beep
can't be disabled there as well, nor can the alarm. You know, the alarm telling
me that my clothes are dry… There is no reasons, let alone urgency, that I
should get any form of audio notification about this. I could spent 6 months in
the hospital after a car crash because of the aforementioned LPG <a href="https://en.wikipedia.org/wiki/Seven_trumpets">seven
trumpets</a>, come back to my place,
and find my cloths still impeccably dry.</p>
<p>The kitchen isn't spared either: my hotplates will try their very best to make
everyone deaf should something like a dishcloth, or perish the though, some
water be present on more than two touch-sensitive buttons at once. I fail to
conceptualize what the issue is here, and why this warrants all this racket:
doing nothing would be perfectly acceptable. Heck, if something really has to
be done for whatever regulation bullshit or whatnot, how about blinking the
lights used to convey that the plates are hot? Or, if you really need to take
action, just turn them off automatically. Really, anything but something that
would shame a car alarm in every way.</p>
<p>But the very best, my complete favourite, "the world class, maybe even the
world champion" (kudos if you know where this is coming from), is a fucking
baby-phone that beeps when you turn it on. The use-case is "monitoring a
sleeping child", and the loud beep tends to wake the aforementioned kid up. May
the gormless cock-up who created this absolute potato of a device spend his
entire life walking on legos.</p>
<p>Fortunately, everything isn't complete garbage in this world, and I even have a
couple of examples at hand:</p>
<ul>
<li>My dishwasher: no sound whatsoever, it simply opens up when it's done.</li>
<li>My fridge: should I improperly close its door, it'll emit some faint noise
  for like 30 seconds. It's a totally valid important notification, as nobody
      wants to burn electricity to cold the room while the food goes bad.</li>
<li>My ebook reader: it's physically unable to produce any sound.</li>
</ul>
<p>The world is dire enough as it is without having me adding to my shopping
criteria "does it shut the fuck up?" to an already long list. If you're
designing objects, please take some time to test their notification mechanism
near an asleep toddler and/or a sleep-deprived lunatic, instead of making
piling more noisy interruptions to our already notification-saturated reality.</p>
          </div>
        </article>
      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Toyota Corolla of programming (143 pts)]]></title>
            <link>https://deprogrammaticaipsum.com/the-toyota-corolla-of-programming/</link>
            <guid>44785759</guid>
            <pubDate>Mon, 04 Aug 2025 13:49:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deprogrammaticaipsum.com/the-toyota-corolla-of-programming/">https://deprogrammaticaipsum.com/the-toyota-corolla-of-programming/</a>, See on <a href="https://news.ycombinator.com/item?id=44785759">Hacker News</a></p>
<div id="readability-page-1" class="page"><article role="document"><div><p><span><span>I</span>n</span> 1995, an otherwise unknown software developer released the first version of a new scripting language whose explicit aim was to make applications for this new platform called “The World Wide Web”. After starting as a small project, and thanks to the crazy dot-com years, it grew dramatically to become one of the most widely used programming languages of all time. After some stumbling first steps, it eventually got some sort of standardization in 1997, even reluctantly including some OOP features to please community and pundits alike.</p><p>However, no matter how hard it tried, this language and its users were mocked for decades by so-called “serious” programmers, who derided its “WTF”-level syntax, the quirks of its runtime model, its ever-increasing amount of security issues, or the gazillion frameworks that sprang around it. Despite the backlash, this language and its community prevailed, eventually getting a huge second act, including some explicit support from Big Tech themselves. Nowadays, as the language reaches the glorious age of 30, a new project drives its future evolution thanks to the strengths of the Go programming language.</p><p>Interestingly enough, the description spread across the two paragraphs above fits not just one but two programming languages: on one side, PHP, heavily inspired by Perl and <a href="https://groups.google.com/g/comp.infosystems.www.authoring.cgi/c/PyJ25gZ6z7A/m/M9FkTUVDfcwJ?lidx=2&amp;wpid=363176&amp;pli=1">released</a> by Rasmus Lerdorf in June 1995 with the name “Personal Home Page Tools”; and on the other hand JavaScript, designed by Brendan Eich and <a href="https://web.archive.org/web/20060111090514/http://wp.netscape.com/newsref/pr/newsrelease67.html">released</a> December of that same year by Netscape.</p><p>But the parallels between both languages do not stop there. In 1997, they got both some level of standardization, thanks to <a href="https://www.php.net/manual/phpfi2.php">PHP/FI 2</a> and <a href="https://www.ecma-international.org/wp-content/uploads/ECMA-262_1st_edition_june_1997.pdf">ECMA-262</a>. During the 2010s, each language got major support from Facebook on one side, and Google and Microsoft on the other side. And in 2025, they both got a major revamp effort based on the <a href="https://deprogrammaticaipsum.com/the-age-of-concurrency/">Go programming language</a>: a new PHP runtime called <a href="https://frankenphp.dev/">FrankenPHP</a>, and the recently announced <a href="https://devblogs.microsoft.com/typescript/typescript-native-port/">TypeScript compiler</a>.</p><p>PHP and JavaScript represent two faces of the same coin: web programming, both server-side and client-side. The growth of the <a href="https://deprogrammaticaipsum.com/from-hypertext-to-spas-to-hypertext/">World Wide Web</a> transformed them into major players, despite their (let us be honest) quite jarring initial design flaws, their slow committee-based evolution, and the seemingly endless series of security flaws that plagued their respective ecosystems.</p><p>An oft-quoted <a href="https://www.stroustrup.com/quotes.html">smirk</a> by Bjarne Stroustrup, the creator of C++, states that</p><blockquote><p>There are only two kinds of languages: the ones people complain about and the ones nobody uses.</p></blockquote><p>Two years ago we published an issue about <a href="https://deprogrammaticaipsum.com/programming-the-liberal-arts/">BASIC</a>, the programming language that all developers love to hate but which single-handedly defined a whole era in our industry. It is only fair that we dedicate some words to PHP, the one everyone also complains about, the one everyone <a href="https://php-ceo.medium.com/">laughs</a> about, yet <a href="https://kinsta.com/php-market-share/">apparently</a> powers between 70 and 80 percent of the world’s websites; needless to say, an impressive number, no matter how hard you look at it, and no matter how much “serious” programmers laugh about it.</p><p>Throughout history, programming languages have received interesting, if revealing, epithets. C is said to be “portable assembly”. <a href="https://deprogrammaticaipsum.com/write-anywhere-run-once/">Java</a> is good for “write once, debug anywhere”. <a href="https://deprogrammaticaipsum.com/the-state-of-python-in-2021/">Python</a> is usually referred to as “executable pseudocode”. <a href="https://deprogrammaticaipsum.com/innovationscript/">JavaScript</a> “was created in 10 days, and it shows”. Perl is the <a href="https://www.wired.com/story/programmers-arent-humble-anymore-nobody-codes-in-perl/">“duct tape of the Internet”</a>.</p><p>And, well, PHP is either a “fractal of bad design” (seriously, people?) or an acronym meaning “Pretty Horrific Programming”. Ouch.</p><p>Here is how I see things: PHP is the <em>lingua franca</em> of affordable <del>cloud</del> web hosting options; or, in other terms, the <a href="https://en.wikipedia.org/wiki/Toyota_Corolla">Toyota Corolla</a> of programming languages: boring, solid, easy, and affordable. You can find, almost anywhere in the world, an affordable web hosting option offering the saint quadrinity of LAMP: Linux, Apache, MySQL, and PHP; an operating system, a web server, a database server, and a scripting language, in an inexpensive package, enabling the masses to go further. Paraphrasing George Clooney, what else?</p><p>These days, PHP features many traits of a modern programming language; let us enumerate some, beginning with its fully <a href="https://github.com/php/php-src">open-source</a> nature. It has advanced <a href="https://deprogrammaticaipsum.com/the-hype-cycle-of-oop/">OOP</a> features like <a href="https://www.php.net/manual/en/language.oop5.traits.php">traits</a>, <a href="https://www.php.net/manual/en/language.oop5.property-hooks.php">property hooks</a>, <a href="https://www.php.net/manual/en/language.namespaces.php">namespaces</a>, <a href="https://www.php.net/manual/en/language.attributes.overview.php">attributes</a>, and <a href="https://www.php.net/manual/en/language.types.enumerations.php">enums</a>. It includes functional programming constructs, like <a href="https://www.php.net/manual/en/functions.anonymous.php">closures</a> with capture lists and <a href="https://www.php.net/manual/en/functions.arrow.php">arrow functions</a>, and a “pipe” operator <a href="https://thephp.foundation/blog/2025/07/11/php-85-adds-pipe-operator/">coming next November</a> (rejoice, OCaml and F# developers!). PHP has associative arrays, and a rudimentary yet fast, useful, and growing type checking system (remember: <code>declare(strict_types=1);</code> is your friend) including <a href="https://www.php.net/manual/en/language.types.never.php"><code>never</code></a> and <a href="https://www.php.net/manual/en/language.types.declarations.php">nullable types</a>. It bundles a full library of algorithms ready to use, following the “batteries included” mantra, and if all else fails, there is a powerful and open-source <a href="https://getcomposer.org/">package manager</a> with <a href="https://packagist.org/">enough packages</a> to make <code>npm</code> blush. There is excellent support for <a href="https://phpunit.de/index.html">unit testing</a>. As scripting programming languages go, it is quite fast to compile and execute. It has its own ecosystem of conferences, <a href="https://afieldguidetoelephpants.net/">a mascot</a>, and even a powerful <a href="https://www.jetbrains.com/phpstorm/">IDE</a> made by none other than JetBrains.</p><p>But, alas, it does feature <a href="https://www.php.net/manual/en/control-structures.goto.php">a <code>goto</code> operator</a>. Oh, là, là! What would Dijkstra say! Not to mention those pesky variables prefixed with a stupid dollar sign, and a cringeworthy <code>foreach</code> statement. The ignominy!</p><p>Most so-called “serious” programmers would be wise to step down from their ivory tower and take a look at PHP in 2025 before an LLM kicks them out of their job. The language has seen major, steady, and consistent revamps for the past decade, including a stable release rhythm once per year, every November, plus a dedicated team that has been <a href="https://www.cvedetails.com/vendor/74/PHP.html">consistently</a> removing security vulnerabilities, and removing obsolete APIs with newer and safer ones.</p><p>I know they should take another look at PHP, because I myself had to step down from my own ivory tower and do that. It is only fair to state my <em>mea culpa</em>: back in 2009 I participated in a (admittedly useless) community effort called “I Hate PHP” (of which the Internet Archive has duly kept <a href="https://web.archive.org/web/20071213013127/https://www.ihatephp.net/">a copy</a>) where my name appeared prominently on the front page. I plead guilty, your honor.</p><p>In my defense, I will argue that those were the somewhat darker ages of PHP. Those were the times of <a href="https://www.oreilly.com/library/view/beyond-java/0596100949/">Bruce Tate’s “Beyond Java”</a> and its long diatribes against PHP spread in the pages therein.</p><p>Remember the long-gone <a href="https://web.archive.org/web/20050210035857/http://phpsec.org/">PHP Security Consortium</a>? Are the days of <a href="https://bobby-tables.com/">Little Bobby Tables</a> over? Let us be honest; not really. You can still release code with SQL injection vulnerabilities if you want (hint: avoid the <code>.</code> operator as much as you can. For all things that are no database queries, <a href="https://www.php.net/manual/en/language.types.string.php#language.types.string.parsing">string interpolation</a> is your friend).</p><p>The <a href="https://deprogrammaticaipsum.com/pastor-manul-laphroaig/">Rt. Rvd. Pastor Manul Laphroaig</a>, in his <a href="https://archive.org/details/Pocorgtfo01/page/n13/mode/2up">sermon</a> to the Beloved Congregation of the First United Church of the Weird Machines, claimed that there is divinity in every programming language… including PHP:</p><blockquote><p>If a language like PHP introduces so many people to pwnage, then that is its divinity. It provides a first step for children to learn how program execution goes astray, with control and data so easy to mangle.</p></blockquote><p>Amen.</p><p>Nowadays, what I see now is a healthy, thriving <a href="https://deprogrammaticaipsum.com/the-tragedy-of-the-common-enemy/">community</a> around PHP. One that, with the exception from JetBrains, is not encumbered by the whims of a FAANG or any other “Big Tech” firm. And the <a href="https://thephp.foundation/">PHP Foundation</a> is driving the evolution of its <a href="https://github.com/php-fig/fig-standards/">standards</a> towards the future, hopefully navigating that unstable space between money and people.</p><p>Take these numbers with a grain of salt, but if we look at language ratings, there is a lot of terrain to reclaim back: on TIOBE, even if PHP was named <a href="https://web.archive.org/web/20050113041221/http://www.tiobe.com/tpci.htm">language of the year 2004</a>, it presently appears at the <a href="https://www.tiobe.com/tiobe-index/php/">15th position</a> and going down: it used to be 3rd in 2010. In the IEEE ranking, it appears in the <a href="https://spectrum.ieee.org/top-programming-languages-2024">13th position</a>, and on the <a href="https://pypl.github.io/PYPL.html">7th position</a> at PYPL, which is quite a drop in the past 20 years. But hey! It appears <a href="https://redmonk.com/sogrady/2025/06/18/language-rankings-1-25/">4th</a> at the RedMonk ranking, and the <a href="https://redmonk.com/rstephens/files/2025/06/redmonk-language-rankings-jan-2025-1.png">graph</a> shows that the fall from 2013 to now has not been <em>that</em> strong. Not all is lost!</p><p>Jokes aside, the most important developments in the history of PHP had to do with the engines used to power it. For decades, the <a href="https://www.zend.com/">Zend engine</a> served as the reference point for the evolution of the language; designed for the needs of the World Wide Web of 1999 (a world of LAMP stacks) and as good as it was for its time, it could not evolve gracefully into a world of DevOps, containers, and <a href="https://deprogrammaticaipsum.com/antonomasia/">Kubernetes</a> orchestrators.</p><p>(Raise your hand if you have ever tried to put together a <code>Dockerfile</code> with Nginx, <a href="https://www.php.net/manual/en/install.fpm.php">FPM</a>, and <a href="https://supervisord.org/">Supervisor</a>, to run some forgotten PHP 7.1 application. I feel your pain, my friend.)</p><p>Thankfully, we can move away from Zend now. Thanks to the unpredictable power of its community, there is this thing called <a href="https://frankenphp.dev/">FrankenPHP</a>. This project has been recently <a href="https://thephp.foundation/blog/2025/06/08/php-30/">adopted</a> by the PHP Foundation as an official runtime, and it ticks all the boxes that could propel PHP into another orbit.</p><p>FrankenPHP not only dramatically simplifies the creation of containers, but it also provides new execution models for PHP code, all while offering 100% compatibility with the massive existing codebase. We talk more about FrankenPHP <a href="https://deprogrammaticaipsum.com/k%C3%A9vin-dunglas/">in the Vidéothèque section</a> this month.</p><p>As nice as FrankenPHP is, I do not count on the end of the backlash against PHP anytime soon. The language will continue to suffer the stigma of its humble beginnings. <a href="https://en.wikipedia.org/wiki/Rasmus_Lerdorf">Rasmus Lerdorf</a> did not get an interview in <a href="https://www.oreilly.com/library/view/masterminds-of-programming/9780596801670/">“Masterminds of Programming”</a>, because PHP is the quintessential language built in a bazaar, as the fruit of an accidental <del>affair</del> design. Nor will Rasmus be invited to the next <a href="https://deprogrammaticaipsum.com/jean-sammet/">HOPL conference</a>, despite the unreasonable popularity of the language, nor will PHP be used for PhD dissertations (other than those related to security, that is). To add insult to injury, PHP is not even mentioned in the <a href="https://deprogrammaticaipsum.com/geoffrey-james/">Tao of Programming</a> (OK, OK, it was published in 1987, I give you that).</p><p>But thankfully IEEE’s “Computer Magazine” did pay attention to PHP, and followed suit with an interview of Rasmus in both <a href="https://www.computer.org/csdl/magazine/co/2012/11/mco2012110006/13rRUILLkze">written</a> and <a href="https://www.youtube.com/watch?v=YIGRXEzjE6c">video</a> formats, published in 2012.</p><p>At least that. In that interview, Rasmus states the core philosophy behind the bazaar:</p><blockquote><p>I learned a bit along the way that, for this to grow, I had to give up control of PHP—I had to let other people have some control. (…) It’s not just them contributing to my project—it becomes our project, and that really changed the nature of PHP.</p></blockquote><p>Cover photo by <a href="https://unsplash.com/@kobuagency?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">KOBU Agency</a> on <a href="https://unsplash.com/photos/hello-world-text-67L18R4tW_w?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p></div></article><p>Continue reading <a href="https://deprogrammaticaipsum.com/k%C3%A9vin-dunglas/">Kévin Dunglas</a> or go back to
<a href="https://deprogrammaticaipsum.com/issue/issue-083-php">Issue 083: PHP</a>.<br>Download this issue as a <a href="https://deprogrammaticaipsum.com/pdf/issue-083-php.pdf">PDF</a> or <a href="https://deprogrammaticaipsum.com/epub/issue-083-php.epub">EPUB</a> file and read it on your preferred device.<br>Did you like this article? Consider <a href="https://deprogrammaticaipsum.com/newsletter/">subscribing</a> to our newsletter or <a href="https://deprogrammaticaipsum.com/contribute/">contributing</a> to the sustainability of this magazine. Thanks!</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perplexity is using stealth, undeclared crawlers to evade no-crawl directives (793 pts)]]></title>
            <link>https://blog.cloudflare.com/perplexity-is-using-stealth-undeclared-crawlers-to-evade-website-no-crawl-directives/</link>
            <guid>44785636</guid>
            <pubDate>Mon, 04 Aug 2025 13:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/perplexity-is-using-stealth-undeclared-crawlers-to-evade-website-no-crawl-directives/">https://blog.cloudflare.com/perplexity-is-using-stealth-undeclared-crawlers-to-evade-website-no-crawl-directives/</a>, See on <a href="https://news.ycombinator.com/item?id=44785636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>2025-08-04</p><section><p>5 min read</p><img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5MASs8Vb8NUgKEKxHQEBiz/a6983d0188bf0279b82af7134905da6c/image6.png" alt=""><div><p>We are observing stealth crawling behavior from Perplexity, an AI-powered answer engine. Although Perplexity initially crawls from their declared user agent, when they are presented with a network block, they appear to obscure their crawling identity in an attempt to circumvent the website’s preferences. We see continued evidence that Perplexity is repeatedly modifying their user agent and changing their source <a href="https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/"><u>ASNs</u></a> to hide their crawling activity, as well as ignoring — or sometimes failing to even fetch — <a href="https://www.cloudflare.com/learning/bots/what-is-robots-txt/"><u>robots.txt</u> </a>files.</p><p>The Internet as we have known it for the past three decades is <a href="https://blog.cloudflare.com/content-independence-day-no-ai-crawl-without-compensation/"><u>rapidly changing</u></a>, but one thing remains constant: it is built on trust. There are clear preferences that crawlers should be transparent, serve a clear purpose, perform a specific activity, and, most importantly, follow website directives and preferences. Based on Perplexity’s observed behavior, which is incompatible with those preferences, we have de-listed them as a verified bot and added heuristics to our managed rules that block this stealth crawling.</p>
    <p>
      <h3 id="how-we-tested">How we tested</h3>
      
    </p>
    <p>We received complaints from customers who had both disallowed Perplexity crawling activity in their <code>robots.txt</code> files and also created WAF rules to specifically block both of Perplexity’s <a href="https://docs.perplexity.ai/guides/bots"><u>declared crawlers</u></a>: <code>PerplexityBot</code> and <code>Perplexity-User</code>. These customers told us that Perplexity was still able to access their content even when they saw its bots successfully blocked. We confirmed that Perplexity’s crawlers were in fact being blocked on the specific pages in question, and then performed several targeted tests to confirm what exact behavior we could observe.</p><p>We created multiple brand-new domains, similar to <code>testexample.com</code> and <code>secretexample.com</code>. These domains were newly purchased and had not yet been indexed by any search engine nor made publicly accessible in any discoverable way. We implemented a <code>robots.txt</code> file with directives to stop any respectful bots from accessing any part of a website: &nbsp;</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/66QyzKuX9DQqQYPvCZpw4m/78e7bbd4ff79dd2f1523e70ef54dab9e/BLOG-2879_-_2.png" alt="robots.txt file on our text website" width="1456" height="254" loading="lazy">
          </figure><p>We conducted an experiment by querying Perplexity AI with questions about these domains, and discovered Perplexity was still providing detailed information regarding the exact content hosted on each of these restricted domains. This response was unexpected, as we had taken all necessary precautions to prevent this data from being retrievable by their <a href="https://www.cloudflare.com/learning/bots/what-is-a-web-crawler/"><u>crawlers</u></a>.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/08ZLg0OE7vX8x35f9rDeg/a3086959793ac565b329fbbab5e52d1e/BLOG-2879_-_3.png" alt="Perplexity answering questions about our test website that should have not been accessible by Perplexity" width="855" height="453" loading="lazy">
          </figure>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5uHc0gooXlr98LB56KBb3g/b7dae5987a64f2442d1f89cf21e974ba/BLOG-2879_-_4.png" alt="Perplexity not checking for the presence of a robots.txt file" width="1574" height="616" loading="lazy">
          </figure>
    <p>
      <h3 id="obfuscating-behavior-observed">Obfuscating behavior observed</h3>
      
    </p>
    <p><b>Bypassing Robots.txt and undisclosed IPs/User Agents</b></p><p>Our multiple test domains explicitly prohibited all automated access by specifying in robots.txt and had specific WAF rules that blocked crawling from <a href="https://docs.perplexity.ai/guides/bots"><u>Perplexity’s public crawlers</u></a>.&nbsp;We observed that Perplexity uses not only their declared user-agent, but also a generic browser intended to impersonate Google Chrome on macOS when their declared crawler was blocked. </p><table><tbody><tr><td><p>Declared</p></td><td><p>Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Perplexity-User/1.0; +https://perplexity.ai/perplexity-user)</p></td><td><p>20-25m daily requests</p></td></tr><tr><td><p>Stealth</p></td><td><p>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36</p></td><td><p>3-6m daily requests</p></td></tr></tbody></table><p>Both their declared and undeclared crawlers were attempting to access the content for scraping contrary to the web crawling norms as outlined in RFC <a href="https://datatracker.ietf.org/doc/html/rfc9309"><u>9309</u></a>.</p><p>This undeclared crawler utilized multiple IPs not listed in <a href="https://docs.perplexity.ai/guides/bots"><u>Perplexity’s official IP range</u></a>, and would rotate through these IPs in response to the restrictive robots.txt policy and block from Cloudflare. In addition to rotating IPs, we observed requests coming from different ASNs in attempts to further evade website blocks. This activity was observed across tens of thousands of domains and millions of requests per day. We were able to fingerprint this crawler using a combination of machine learning and network signals.</p><p>An example:&nbsp;</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4UKtFs1UPddDh9OCtMuwzC/bcdabf5fdd9b0d029581b14a90714d91/unnamed.png" alt="Perplexity crawling workflow based on observations" width="1600" height="973" loading="lazy">
          </figure><p>Of note: when the stealth crawler was successfully blocked, we observed that Perplexity uses other data sources — including other websites — to try to create an answer. However, these answers were less specific and lacked details from the original content, reflecting the fact that the block had been successful.&nbsp;</p>
    <p>
      <h2 id="how-well-meaning-bot-operators-respect-website-preferences">How well-meaning bot operators respect website preferences</h2>
      
    </p>
    <p>In contrast to the behavior described above, the Internet has expressed clear preferences on how good crawlers should behave. All well-intentioned crawlers acting in good faith should:</p><p><b>Be transparent</b>. Identify themselves honestly, using a unique user-agent, a declared list of IP ranges or <a href="https://developers.cloudflare.com/bots/concepts/bot/verified-bots/web-bot-auth/"><u>Web Bot Auth</u></a> integration, and provide contact information if something goes wrong.</p><p><b>Be well-behaved netizens</b>. Don’t flood sites with excessive traffic, <a href="https://www.cloudflare.com/learning/bots/what-is-data-scraping/"><u>scrape</u></a> sensitive data, or use stealth tactics to try and dodge detection.</p><p><b>Serve a clear purpose</b>. Whether it’s powering a voice assistant, checking product prices, or making a website more accessible, every bot has a reason to be there. The purpose should be clearly and precisely defined and easy for site owners to look up publicly.</p><p><b>Separate bots for separate activities</b>. Perform each activity from a unique bot. This makes it easy for site owners to decide which activities they want to allow. Don’t force site owners to make an all-or-nothing decision. </p><p><b>Follow the rules</b>. That means checking for and respecting website signals like <code>robots.txt</code>, staying within rate limits, and never bypassing security protections.</p><p>More details are outlined in our official <a href="https://developers.cloudflare.com/bots/concepts/bot/verified-bots/policy/"><u>Verified Bots Policy Developer Docs</u></a>.</p><p>OpenAI is an example of a leading AI company that follows these best practices. They clearly <a href="https://platform.openai.com/docs/bots"><u>outline their crawlers</u> and </a>give detailed explanations for each crawler’s purpose. They respect robots.txt and do not try to evade either a robots.txt directive or a network level block. And <a href="https://openai.com/index/introducing-chatgpt-agent/"><u>ChatGPT Agent</u></a> is signing http requests using the newly proposed open standard <a href="https://developers.cloudflare.com/bots/concepts/bot/verified-bots/web-bot-auth/"><u>Web Bot Auth</u></a>.</p><p>When we ran the same test as outlined above with ChatGPT, we found that ChatGPT-User fetched the robots file and stopped crawling when it was disallowed. We did not observe follow-up crawls from any other user agents or third party bots. When we removed the disallow directive from the robots entry, but presented ChatGPT with a block page, they again stopped crawling, and we saw no additional crawl attempts from other user agents. Both of these demonstrate the appropriate response to website owner preferences.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/HMJjS7DRmu4octZ99HX8K/753966a88476f80d7a981b1c135fd251/BLOG-2879_-_6.png" alt="BLOG-2879 - 6" width="1200" height="265" loading="lazy">
          </figure>
    <p>
      <h2 id="how-can-you-protect-yourself">How can you protect yourself?</h2>
      
    </p>
    <p>All the undeclared crawling activity that we observed from Perplexity’s hidden User Agent was scored by our bot management system as a bot and was unable to pass managed challenges. Any bot management customer who has an existing block rule in place is already protected. Customers who don’t want to block traffic can set up rules to <a href="https://developers.cloudflare.com/waf/custom-rules/use-cases/challenge-bad-bots/"><u>challenge requests</u></a>, giving real humans an opportunity to proceed. Customers with existing challenge rules are already protected. Lastly, we added signature matches for the stealth crawler into our <a href="https://developers.cloudflare.com/bots/concepts/bot/#ai-bots"><u>managed rule</u></a> that <a href="https://developers.cloudflare.com/bots/additional-configurations/block-ai-bots/"><u>blocks AI crawling activity</u></a>. This rule is available to all customers, including our free customers.&nbsp;&nbsp;</p>
    <p>
      <h2 id="whats-next">What’s next?</h2>
      
    </p>
    <p>We announced <a href="https://blog.cloudflare.com/content-independence-day-no-ai-crawl-without-compensation/"><u>Content Independence Day</u></a> almost one month ago, giving content creators and publishers more control over how their content is accessed. Today, over two and a half million websites have chosen to completely disallow AI training through our managed robots.txt feature or our <a href="https://developers.cloudflare.com/bots/concepts/bot/#ai-bots"><u>managed rule blocking AI Crawlers</u></a>. Every Cloudflare customer is now able to selectively decide which declared AI crawlers are able to access their content in accordance with their business objectives.</p><p>We expected a change in bot and crawler behavior based on these new features, and we expect that the techniques bot operators use to evade detection will continue to evolve. Once this post is live the behavior we saw will almost certainly change, and the methods we use to stop them will keep evolving as well.&nbsp;</p><p>Cloudflare is actively working with technical and policy experts around the world, like the IETF efforts to standardize <a href="https://ietf-wg-aipref.github.io/drafts/draft-ietf-aipref-vocab.html?cf_target_id=_blank"><u>extensions to robots.txt</u></a>, to establish clear and measurable principles that well-meaning bot operators should abide by. We think this is an important next step in this quickly evolving space.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/25VWBDa33UWxDOtqEVEx5o/41eb4ddc262551b83179c1c23a9cb1e6/BLOG-2879_-_7.png" alt="BLOG-2879 - 7" width="1200" height="262" loading="lazy">
          </figure></div></section><div><p>Cloudflare's connectivity cloud protects <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, helps customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerates any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">wards off DDoS attacks</a>, keeps <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/cloudforce-one/">Cloudforce One</a><a href="https://blog.cloudflare.com/tag/threat-intelligence/">Threat Intelligence</a><a href="https://blog.cloudflare.com/tag/ai-bots/">AI Bots</a><a href="https://blog.cloudflare.com/tag/bots/">Bots</a><a href="https://blog.cloudflare.com/tag/ai/">AI</a><a href="https://blog.cloudflare.com/tag/bot-management/">Bot Management</a><a href="https://blog.cloudflare.com/tag/security/">Security</a><a href="https://blog.cloudflare.com/tag/generative-ai/">Generative AI</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Read your code (116 pts)]]></title>
            <link>https://etsd.tech/posts/rtfc/</link>
            <guid>44785562</guid>
            <pubDate>Mon, 04 Aug 2025 13:33:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://etsd.tech/posts/rtfc/">https://etsd.tech/posts/rtfc/</a>, See on <a href="https://news.ycombinator.com/item?id=44785562">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article"> <p>If you’d told me 2–3 years ago that in 2025, one of my top pieces of advice for the new generation of developers would be “<em>read your code</em>” (we’re not even talking about re-reading it)… I’m not sure I would’ve believed you.</p>
<h2 id="what-this-article-covers">What This Article Covers</h2>
<p>I’m not here to lecture anyone, but <strong>if you’re aiming to build serious projects</strong> these days, it might be worth learning how to approach AI coding tools the right way.</p>
<p><strong>This post covers:</strong></p>
<ul>
<li>Three critical risks of poor <em>vibe-coding</em> practices</li>
<li>Two effective approaches for production-grade AI-assisted development</li>
<li>Practical tips to maintain code quality while leveraging AI speed</li>
</ul>
<p><strong>Vibe-Coding Refresh</strong></p>
<p>Maybe it’s time we take a fresh look at what vibe-coding actually is. It’s more than just hobby prompting to get code — it’s a practice that serious developers should learn to master. What it means to me:
<mark>Vibe-Coding is a dialogue-based coding process between a human and an AI where the human guides and the AI implements.</mark></p>
<h2 id="its-possible-to-ship-code-without-ever-reading-it">It’s possible to ship code without ever reading it.</h2>
<p>Since Claude Code and Windsurf arrived, it’s now totally possible to get working results without reading a single line of code. You can vibe-code without ever leaving your chat window and just operate based on outcomes - I’ve tried that, out of curiosity.</p>
<p>Even if it doesn’t work on the first try (though it often does), you just explain what’s wrong, and voilà — working result incoming.</p>
<h2 id="but-this-comes-with-three-critical-issues">But This Comes With Three Critical Issues</h2>
<h3 id="1-a-weakened-architecture">1. A Weakened Architecture</h3>
<p>Not reviewing AI-generated code <strong>will</strong> lead to serious problems.</p>
<p>First up: the slow but sure breakdown of your architecture… assuming you even took the time to plan one in the first place.</p>
<p>From experience, even with well-crafted prompts and clearly defined plans for a new feature, Claude Code (which I love, by the way) still sometimes goes off-script. Make sure to properly configure your @CLAUDE.md files to avoid this as much as possible.</p>
<p><strong>Example of architectural drift:</strong></p>
<pre tabindex="0" data-language="javascript"><code><span><span>// Your established pattern: services handle business logic</span></span>
<span><span>class</span><span> UserService</span><span> {</span></span>
<span><span>  async</span><span> getUserProfile</span><span>(</span><span>userId</span><span>)</span><span> {</span></span>
<span><span>    const</span><span> user</span><span> =</span><span> await</span><span> db</span><span>.</span><span>users</span><span>.</span><span>findById</span><span>(</span><span>userId</span><span>);</span></span>
<span><span>    return</span><span> this</span><span>.</span><span>formatUserData</span><span>(</span><span>user</span><span>);</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// What Claude might generate if unchecked:</span></span>
<span><span>// Business logic creeping into controllers</span></span>
<span><span>app</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/profile/:id</span><span>'</span><span>,</span><span> async</span><span> (</span><span>req</span><span>,</span><span> res</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span><span>  const</span><span> user</span><span> =</span><span> await</span><span> db</span><span>.</span><span>users</span><span>.</span><span>findById</span><span>(</span><span>req</span><span>.</span><span>params</span><span>.</span><span>id</span><span>);</span></span>
<span><span>  // Formatting logic that belongs in service layer</span></span>
<span><span>  const</span><span> formattedUser</span><span> =</span><span> {</span></span>
<span><span>    name</span><span>:</span><span> user</span><span>.</span><span>firstName</span><span> +</span><span> '</span><span> '</span><span> +</span><span> user</span><span>.</span><span>lastName</span><span>,</span></span>
<span><span>    memberSince</span><span>:</span><span> new</span><span> Date</span><span>(</span><span>user</span><span>.</span><span>createdAt</span><span>)</span><span>.</span><span>getFullYear</span><span>()</span></span>
<span><span>  }</span><span>;</span></span>
<span><span>  res</span><span>.</span><span>json</span><span>(</span><span>formattedUser</span><span>);</span></span>
<span><span>});</span></span></code></pre>
<p>If you don’t catch it early, those small inconsistencies become part of the codebase—and your favorite assistant will be tempted to follow those bad examples in the future.</p>
<p><mark>You’re still the architect!</mark></p>
<p>Everyone keeps saying it these days: treat your AI like a (brilliant) new junior dev<sup><a href="#user-content-fn-brillant-junior-dev" id="user-content-fnref-brillant-junior-dev" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>. And what does a junior dev do before starting a new feature? They read through the existing codebase. Which means any weak or messy design choices are likely to get repeated.</p>
<p>And by the way, you’d never push junior dev code without reviewing it.</p>
<p>Now more than ever, we’re all responsible for the architecture. We spend more time guiding the AI on how to code than writing the actual code ourselves.</p>
<h3 id="2-loss-of-implementation-knowledge">2. Loss of Implementation Knowledge</h3>
<blockquote>
<p>You cannot delegate the act of thinking.</p>
</blockquote>
<p><em>Alain (French philosopher, 19th century)</em></p>
<p><strong>If you’re only focused on the end result,</strong> you’ll soon know as little as your users about how things actually work. You may be the most advanced user of your own app — but <strong>you won’t own your domain anymore</strong>.</p>
<p><strong>Why does that matter?</strong></p>
<p>In every experience I’ve had — especially when building my latest startup<sup><a href="#user-content-fn-from-0-to-exit-in-2-years" id="user-content-fnref-from-0-to-exit-in-2-years" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> — I’ve learned that apps and features don’t take shape at implementation time. They’re designed upstream: business rules, tech and infrastructure decisions all take form before you touch the keyboard. They come to you while commuting, while chatting, or—often—while in the shower.</p>
<p>Depending on your level of responsibility, you may or may not be involved outside of work. But you’ll probably agree that your best ‘Aha!’ moments didn’t happen in front of VS Code.</p>
<p>If you don’t have the structure of your domain — its concepts and abstractions — constantly simmering somewhere in the back of your mind, you won’t be able to fully leverage the creative potential of modern tech.</p>
<p><mark>If you really think you don’t need this knowledge, your business might not be all that “Tech” to begin with.</mark> In that case, use a well-structured Notion doc, or a no-code tool—you’ll save a ton of time and money.</p>
<p>And don’t hesitate to leave your code editor and chat with an AI that doesn’t have access to your codebase—our good old rubber duck didn’t either, and that’s precisely why it worked.</p>
<h3 id="3-security-vulnerabilities">3. Security Vulnerabilities</h3>
<p>Are you working on a production app? Then you must care about security. Most web security issues are avoided through knowledge and experience. But a lax implementation or fuzzy access scopes, and you’re in serious trouble.</p>
<p><strong>Example that happened to me last week:</strong></p>
<pre tabindex="0" data-language="javascript"><code><span><span>// What I asked for: "List user's projects"</span></span>
<span><span>// What Claude generated:</span></span>
<span><span>app</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api/projects/:id</span><span>'</span><span>,</span><span> async</span><span> (</span><span>req</span><span>,</span><span> res</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span><span>  const</span><span> projectId</span><span> =</span><span> req</span><span>.</span><span>body</span><span>.</span><span>id</span><span>; </span><span>// From the client</span></span>
<span><span>  const</span><span> project</span><span> =</span><span> await</span><span> db</span><span>.</span><span>projects</span><span>.</span><span>find</span><span>(</span><span>{</span><span> id</span><span>:</span><span> projectId</span><span> }</span><span>);</span></span>
<span><span>  res</span><span>.</span><span>json</span><span>(</span><span>project</span><span>);</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// What it should have been:</span></span>
<span><span>app</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api/projects/:id</span><span>'</span><span>,</span><span> async</span><span> (</span><span>req</span><span>,</span><span> res</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span><span>  const</span><span> projectId</span><span> =</span><span> req</span><span>.</span><span>body</span><span>.</span><span>id</span><span>;</span></span>
<span><span>  const</span><span> userId</span><span> =</span><span> req</span><span>.</span><span>authenticatedUser</span><span>.</span><span>id</span><span>; </span><span>// From auth middleware</span></span>
<span><span>  const</span><span> project</span><span> =</span><span> await</span><span> db</span><span>.</span><span>projects</span><span>.</span><span>find</span><span>(</span><span>{</span></span>
<span><span>    id</span><span>:</span><span> projectId</span><span>,</span></span>
<span><span>    where</span><span>:</span><span> {</span><span> userId</span><span>:</span><span> userId</span><span> }</span></span>
<span><span>  }</span><span>);</span></span>
<span><span>  res</span><span>.</span><span>json</span><span>(</span><span>project</span><span>);</span></span>
<span><span>});</span></span></code></pre>
<p>The AI, focused on the end goal, implemented exactly what I asked for… except that it never once verified whether the resource actually belonged to the current user. <strong>Classic mistake.</strong></p>
<p>Sure, you can tell me: “always include access control in your prompt”, but some flaws only become obvious during implementation. Ever had a security insight pop into your head while coding a feature?</p>
<p>You can’t be too careful. A misworded prompt, a misunderstood intention, an unreviewed commit—and bam, you’ve got a breach. I fear this will become more common with hastily vibe-coded projects.</p>
<p><mark>Security has always needed to be part of the implementation process. Why should that change now?</mark></p>
<h2 id="two-ways-to-vibe-code-responsibly">Two Ways to Vibe-Code Responsibly</h2>
<p>As stated in <a href="https://www-cdn.anthropic.com/58284b19e702b49db9302d5b6f135ad8871e7658.pdf">this great ressource</a> by Anthropic, there are two viable ways to vibe-code a production-ready project in 2025:</p>
<blockquote>
<p>Learn to distinguish between tasks that work well asynchronously (peripheral features, prototyping) versus those needing synchronous supervision (core business logic, critical fixes). Abstract tasks on the product’s edges can be handled with “auto-accept mode,” while core functionality requires closer oversight.</p>
</blockquote>
<h3 id="1-fast-prototyping-with-auto-accept-mode">1. Fast Prototyping with Auto-Accept Mode</h3>
<p>Here, you use the AI in auto-pilot mode. Describe the expected output, provide specs, and let it run. Before ending the session, <strong>you review what’s been done</strong>, and adjust as needed.</p>
<p>This works well when:</p>
<ul>
<li>You’re working on a topic you’re not familiar with</li>
<li>Generating test scaffolding (but still review the tests — a test that doesn’t test anything meaningful is just a green checkmark)</li>
<li>Exploring new libraries or frameworks</li>
</ul>
<h3 id="2-synchronous-coding-for-core-features">2. Synchronous Coding for Core Features</h3>
<p>This is where the real innovation is happening in our field. <strong>Pair-vibe-coding, without auto-accept</strong>, is the most effective way to ship quality features. Every suggestion is a chance to either accept or iterate.</p>
<p>And that changes everything: at every small step, you can correct direction before things drift. <mark>It’s always easier to straighten a sapling than a grown tree.</mark> The earlier you lock down good concepts and interfaces in your architecture, the better future suggestions from the AI will be.</p>
<p><strong>Plan your session:</strong> When you start a session, begin with a clear plan. Read it carefully, regardless of your approach, and don’t validate it unless you fully agree with it. The plan is to the session what the seed is to the tree: bad seed, bad soil, no fruit.</p>
<h2 id="the-vibe-coding-checklist">The Vibe-Coding Checklist</h2>
<p>Before pushing any AI-generated code:</p>
<ul>
<li> <strong>Architecture Check</strong>: Does this follow our established patterns?</li>
<li> <strong>Security Review</strong>: Are all resources properly scoped to users?</li>
<li> <strong>Tests</strong>: Do they actually test meaningful behavior?</li>
</ul>
<p>But also, do not forget to check:</p>
<ul>
<li> <strong>Documentation</strong>: Will <em>you</em> understand this in 6 months?</li>
<li> <strong>Error Handling</strong>: Are edge cases covered?</li>
<li> <strong>Performance</strong>: Any obvious N+1 queries or inefficiencies?</li>
</ul>
<p>And above all, make sure to:</p>
<ul>
<li> <mark>Leave with some <strong>knowledge</strong> of the new code</mark>.</li>
</ul>
<h2 id="to-wrap-it-up">To Wrap It Up</h2>
<p>AI coding assistants are powerful tools, but they’re amplifiers of your expertise, not replacements for it. The day you stop understanding your codebase is the day you stop being its architect.</p>
<p><strong>Teams:</strong> don’t cancel code reviews thinking Claude Code acts as a second dev alongside the one assigned to the feature. Bugs aren’t the biggest threat—losing mastery of your domain and architecture is. That’s the real roadblock to innovation.</p>
<p><strong>Engineers:</strong> you can usually let the AI <em>RTFM</em> but you: <mark>Read That F*cking Code</mark>!</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-brillant-junior-dev">
<p><a href="https://youtu.be/w4rG5GY9IlA?si=vZDXi8NtyPmxILMB&amp;t=217">Learning Software Engineering During the Era of AI | Raymond Fu | TEDxCSTU</a> <a href="#user-content-fnref-brillant-junior-dev" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-from-0-to-exit-in-2-years">
<p><a href="https://www.linkedin.com/pulse/from-0-exit-within-2-years-bootstrapped-philippe-vanderstigel/">From 0 to exit within 2 years | Philippe Vanderstigel</a> <a href="#user-content-fnref-from-0-to-exit-in-2-years" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Century-old stone “tsunami stones” dot Japan's coastline (2015) (109 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/century-old-warnings-against-tsunamis-dot-japans-coastline-180956448/</link>
            <guid>44785107</guid>
            <pubDate>Mon, 04 Aug 2025 12:51:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/century-old-warnings-against-tsunamis-dot-japans-coastline-180956448/">https://www.smithsonianmag.com/smart-news/century-old-warnings-against-tsunamis-dot-japans-coastline-180956448/</a>, See on <a href="https://news.ycombinator.com/item?id=44785107">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/smart-news/century-old-warnings-against-tsunamis-dot-japans-coastline-180956448/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[DrawAFish.com Postmortem (146 pts)]]></title>
            <link>https://aldenhallak.com/blog/posts/draw-a-fish-postmortem.html</link>
            <guid>44784743</guid>
            <pubDate>Mon, 04 Aug 2025 12:10:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aldenhallak.com/blog/posts/draw-a-fish-postmortem.html">https://aldenhallak.com/blog/posts/draw-a-fish-postmortem.html</a>, See on <a href="https://news.ycombinator.com/item?id=44784743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                <p><img src="https://aldenhallak.com/blog/images/drawafish-hero.jpg" alt="DrawAFish.com website screenshot - 100 hand drawn fish swimming in a tank."></p><p>DrawAFish.com</p>
            </div>

            <h2>TL;DR:</h2>
            <ul>
                <li><strong>Incident Duration:</strong> ~6 hours (2AM–8AM EST)</li>
                <li><strong>Impact:</strong>
                    <ul>
                        <li>Username vandalism (slurs)</li>
                        <li>Offensive fish approved / safe fish removed</li>
                    </ul>
                </li>
                <li><strong>Root Causes:</strong>
                    <ol>
                        <li>Legacy 6-digit admin password exposed in past data breach</li>
                        <li>Username update API lacked authentication</li>
                        <li>JWT not tied to specific user</li>
                    </ol>
                </li>
                <li><strong>Mitigation:</strong> Manual reversal of mod actions, fixed authorization logic, backups reviewed</li>
                <li><strong>Takeaway:</strong> hwoopsy daisy 🙂</li>
            </ul>

            <div>
                <p><img src="https://aldenhallak.com/blog/images/hackernews-pointing.jpg" alt="Post 'Show HN: Draw A Fish and watch it swim with the others' on the #1 spot of hacker news, highlighted, circled, lots of red arrows pointing to it."></p><p>Did you see? Did you see it? What it says? What it says on top of the website?
                </p>
            </div>

            <p>If you were on HackerNews on <a href="https://news.ycombinator.com/front?day=2025-08-01" target="_blank">Aug 1 2025</a>, you may have seen <a href="https://drawafish.com/">DrawAFish.com</a>.
                Because it was in the number 1 spot. You also may have seen it if you follow me on <a href="https://instagram.com/verybigandstrong" target="_blank">instagram</a>. You also probably saw
                that I was in the #1 spot on Hackernews there too. Because I posted about it a lot. And also if you
                talked to me in person you probably heard about it. And then you probably heard a lot of quotes from
                <i>The Social Network</i> (2010) where I replaced various words with "Fish."</p>

            <blockquote>
                "A million fish isn't cool. You know what's cool? <a href="https://www.youtube.com/watch?v=4e0n7vTLz1U" target="_blank">A billion fish</a>."
            </blockquote>

            <p>If you read the post on Hackernews, you saw that the website was an exercise in
                vibe-coding. I used Copilot to implement features, and I used it to implement features <i>fast</i>.</p>

            <p> In my career,<sup><a href="#footnote-0" id="ref-0">[0]</a></sup> I have learned the art of "Blameless
                Postmortems." The problem with a Blameless
                Postmortem is that it doesn't really work when you're the sole contributor. So this is a blameful
                postmortem. And I blame me. (Not the LLM, sorry).</p>

            <p>If you saw the website only on August 1, you probably do not understand why I need to write a postmortem
                at
                all. Everything went swimmingly (ha, ha). But if you had the displeasure of viewing my website between
                the hours of 2AM (20 minutes after I went to sleep) and 8AM (when I woke up)<sup><a href="#footnote-1" id="ref-1">[1]</a></sup> EST on Aug 3, then you would have seen chaos. Every single username was
                transformed to a heinous slur, many unsavory fish had made it into the fishtank, and many beautiful fish
                were gone. How did this happen?</p>

            <h2>The Vulnerabilities</h2>

            <div>
                <p><img src="https://aldenhallak.com/blog/images/hacked.jpg" alt="Screenshot showing a hacked user profile with username changed to 'Stinky Fart Man'"></p><p>This is not what they changed my username to. I'll let you use your
                    imagination.</p>
            </div>

            <ol>
                <li>
                    <p><strong>Legacy admin password exposed in data breach:</strong> When creating the website, I used
                        my childhood username and my childhood 6-digit password for testing. I think the first time it
                        leaked was on Neopets.com.<sup><a href="#footnote-2" id="ref-2">[2]</a></sup> I then set up
                        Google Auth. From then on, I only logged in with Google Auth. But the password remained. I
                        simply forgot. This allowed some of the most intelligent and brilliant minds on the internet to
                        find my password on the Neopets data leak paste, log in as an admin, and approve and disapprove
                        some really disgusting and horrible fish.</p>

                    <p>On the plus side, the brilliant minds (while attempting to ban every single user) managed to
                        accidentally ban themselves. So that vulnerability was only an active issue for an hour or so.
                    </p>
                </li>

                <li>
                    <p><strong>Username update API lacked authentication:</strong> I vibe coded the profile backend,
                        which allows users to modify their username. I added this feature last minute, figured I'd
                        review it later, and then didn't. The username modification did not perform any auth logic
                        whatsoever. whoopsy</p>
                </li>

                <li>
                    <p><strong>JWT not tied to specific user:</strong> There was another security vulnerability - I
                        used the JWT to authorize login, but never confirmed that the JWT token belonged to the userId /
                        email associated with it in the admin actions. So you could log in with my username and password,
                        grab the JWT, and then send that along with your request. While this was a mistake, it ended up
                        saving me. Fortunately, hackernews user @<a href="https://news.ycombinator.com/user?id=iceweaselfan44" target="_blank">iceweaselfan44</a> used this vulnerability to authorize as an admin and
                        delete the really bad fish. He was awake, on the other side of the world, removing fish and
                        helping out.<sup><a href="#footnote-3" id="ref-3">[3]</a></sup></p>
                </li>
            </ol>

            <h2>The Recovery</h2>

            <div>
                <p><img src="https://aldenhallak.com/blog/images/moderation-logs.jpg" alt="A moderation log that shows a moderation action done at 3AM and undone in the morning."></p><p>Moderation logs. There are so many of these.</p>
            </div>

            <p>I woke up at around 7:45 am, saw a couple pings and messages, and immediately rushed to my desktop.<sup><a href="#footnote-4" id="ref-4">[4]</a></sup> Fortunately, I had set up firebase backups.
                Unfortunately, I had set them up wrong. I spent a good hour or so diagnosing the errors and then quickly
                pushed changes to require authentication.</p>

            <p>I had a mod log set up, so undoing the changes was as simple as writing an annoying script that just
                undid all the mod actions. Did I learn my lesson about vibe coding? Maybe. I vibe coded the script,
                looked over the code, and did a dry run first.</p>

            <p>I banned the other mod account ran by IceWeasel<sup><a href="#footnote-5" id="ref-5">[5]</a></sup> and
                patched the JWT bug - at which point he reached out to me and explained how he created it. We then
                hopped on a call and he took a look at the codebase, where he expertly suggested a refactor that would
                be more idiomatic with current security practices. And then when I blindly pushed it and it broke
                everything, he expertly committed some more changes that fixed it.</p>

            <h2>Reflection</h2>

            <p>At this point, you're probably thinking: geeze man. Wow. youve gotta be stupid.</p>

            <p>And I'd like to get on my hands and knees and beg for your suspension of belief when I say: yes I am but
                not when it comes to my job. It is really fun to just have high velocity, and it is really fun to not do
                code reviews and to just push stuff. Sometimes it feels like all I do at work is review code and write
                docs - and the code I write at work is lately deeply within legacy systems and makes my brain hurt
                sometimes. I have good reviews! Just ask my coworkers! The ones that hate me hate me because I leave TOO
                many comments and am TOO thorough (or they are jealous of my handsome good looks and devilish charm).
            </p>

            <p>So when I decided to learn how to build on GCP and vibe code a small app that I figured a handful of
                people would see, I took it easy on the code reviews. I let Copilot do all the work, I wrote no tests,
                and instead of writing TODOs and Documentation I simply said "I'll remember to change my password / add
                auth / understand this code later." And then I didn't do that. Whoops!</p>

            <p>It would be very nice for my ego to blame the LLM here. But LLMs are a tool. They let you generate a lot
                of code really fast, and sometimes that is good. Sometimes it is not. And it is up to you to review it,
                and decide what code gets committed.</p>

            <!-- Lessons learned image suggestion: Meme or infographic about vibe coding vs proper development -->
            <div>
                <p><img src="https://aldenhallak.com/blog/images/llms-dont-commit.jpg" alt="Very crudely draw MS-Paint sticker for 'LLMs don't commit code, people do'. It's drawn over a sticker that says 'Guns don't kill people, people do.'"></p><p>I am selling these stickers for 100 dollars each. Please reach out to purchase
                    them.</p>
            </div>

            <hr>

            <p><small><sup id="footnote-0">[0]</sup> Nearly 5 years at the same company. <a href="#ref-0">↩</a></small>
            </p>

            <p><small><sup id="footnote-1">[1]</sup> I usually try to sleep more than this. I want to sleep more than
                    this. But my fancy "smart" ikea roller blinds that keep it dark at night and bright when I wake up
                    fell down because I taped them to the wall very poorly. <a href="#ref-1">↩</a></small></p>

            <p><small><sup id="footnote-2">[2]</sup> I remember being a kid and forgetting my password and thinking "wow
                    it's nice how they just email you your password, instead of resetting it. More websites should do
                    that." <a href="#ref-2">↩</a></small></p>

            <p><small><sup id="footnote-3">[3]</sup> The JWT token issue was the only vuln that really required knowing
                    how anything worked. I don't think it's a coincidence that there was a correlation between being a
                    studious / diligent person and actively being a helpful force. <a href="#ref-3">↩</a></small></p>

            <p><small><sup id="footnote-4">[4]</sup> Which is next to my bed. I live in New York.<sup><a href="#footnote-4a" id="ref-4a">[4a]</a></sup><br>
                    <sup id="footnote-4a">[4a]</sup> You may have heard differently, especially if you saw my <a href="https://imgur.com/WDqhtIu.jpg" target="_blank">doxxing</a><sup><a href="#footnote-4b" id="ref-4b">[4b]</a></sup> on the unsavory website. Fortunately, my publicly listed
                    information appears to be a little out of date. <a href="https://x.com/MCBananaPeelZ/status/1774139530041303368" target="_blank">The first time I
                        was doxxed</a> was much scarier. <a href="#ref-4a">↩</a><br>
                    <sup id="footnote-4b">[4b]</sup> To be fair, I deserved the doxxing for removing the weird and
                    offensive fish and slurs. <a href="#ref-4b">↩</a> <a href="#ref-4">↩</a></small></p>

            <p><small><sup id="footnote-5">[5]</sup> Only because it had no identifying information at all - just didn't
                    know who this person was. He reached out later and we chatted over discord and now we're cool. <a href="#ref-5">↩</a></small></p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Palantir Is Extending Its Reach Even Further into Government (175 pts)]]></title>
            <link>https://www.wired.com/story/palantir-government-contracting-push/</link>
            <guid>44784498</guid>
            <pubDate>Mon, 04 Aug 2025 11:44:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/palantir-government-contracting-push/">https://www.wired.com/story/palantir-government-contracting-push/</a>, See on <a href="https://news.ycombinator.com/item?id=44784498">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>President Donald Trump’s</span> administration has dramatically expanded its work with Palantir, elevating the company cofounded by Trump ally Peter Thiel as the government’s go-to software developer. Following massive contract terminations for consulting giants and government contractors like Accenture, Booz Allen, and Deloitte, Palantir has emerged ahead. Now the data analytics firm is partnering with those companies—offering them a lifeline while consolidating its own power.</p><p>Palantir has become one of the few winners in the Trump administration’s cost-cutting efforts, <a data-offer-url="https://www.nytimes.com/2025/05/30/technology/trump-palantir-data-americans.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nytimes.com/2025/05/30/technology/trump-palantir-data-americans.html&quot;}" href="https://www.nytimes.com/2025/05/30/technology/trump-palantir-data-americans.html" rel="nofollow noopener" target="_blank">receiving more than $113 million</a> in federal spending since the beginning of the year, according to The New York Times. Palantir’s US government revenue has grown by more than $ 370 million compared to this time last year, according to the company’s <a data-offer-url="https://investors.palantir.com/news-details/2025/Palantir-Reports-Q1-2025-Revenue-Growth-of-39-YY-U-S--Revenue-Growth-of-55-YY-Raises-FY-2025-Revenue-Guidance-to-36-YY-Growth-and-U-S--Comm-Revenue-Guidance-to-68-YY-Crushing-Consensus-Expectations/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://investors.palantir.com/news-details/2025/Palantir-Reports-Q1-2025-Revenue-Growth-of-39-YY-U-S--Revenue-Growth-of-55-YY-Raises-FY-2025-Revenue-Guidance-to-36-YY-Growth-and-U-S--Comm-Revenue-Guidance-to-68-YY-Crushing-Consensus-Expectations/&quot;}" href="https://investors.palantir.com/news-details/2025/Palantir-Reports-Q1-2025-Revenue-Growth-of-39-YY-U-S--Revenue-Growth-of-55-YY-Raises-FY-2025-Revenue-Guidance-to-36-YY-Growth-and-U-S--Comm-Revenue-Guidance-to-68-YY-Crushing-Consensus-Expectations/" rel="nofollow noopener" target="_blank">most recent quarterly earnings report</a>. Before making remarks at last week’s AI Summit in DC, Trump thanked a variety of cabinet secretaries and tech leaders, <a href="https://www.youtube.com/live/tBNX9x5GgPE?feature=shared&amp;t=922">including Palantir chief technology officer Shyam Sankar</a>. “We buy a lot of things from Palantir,” Trump said. “Are we paying our bills? I think so.”</p><p>Instead of replacing these more traditional contractors, Palantir’s software is becoming the core tool deployed by them in government systems, placing Palantir in a newly central role.</p><p>The White House itself is thrilled by this partnership: “The Trump Administration has high-standard [sic] when spending American’s hard-earned tax dollars—which is why agencies have partnered with Palantir, a top-tier American company renowned for their longstanding history of innovation, results, and increasing government efficiency,” says White House spokesperson Taylor Rogers.</p><p>Palantir did not immediately respond to requests for comment.</p><p>In April, <a href="https://www.wired.com/story/palantir-doge-irs-mega-api-data/">WIRED reported that Palantir was working alongside IRS engineers</a> to build what sources called a “mega API,” which would unify all data across the agency. An API, or application programming interface, enables applications and databases to exchange data and possibly compare it against other interoperable datasets. Once completed, this mega API could become the “read center of all IRS systems.” Immigration and Customs Enforcement <a href="https://www.wired.com/story/ice-palantir-immigrationos/">contracted Palantir for $30 million</a> to track self-deportations in April. The company has also won federal contracts more recently, like a $795 million award from the Pentagon in May to expand its Maven Smart System program. The total contract ceiling for the Army’s Maven program is now $1.3 billion.</p><p>This growth comes as some of the companies Palantir has chosen to partner with have lost billions in government contract cuts. In April, defense secretary Pete Hegseth announced plans to cut $5.1 billion in IT consulting contracts with companies including Accenture, Booz Allen, and Deloitte. <a href="https://media.defense.gov/2025/Apr/10/2003687449/-1/-1/1/SECRETARY-OF-DEFENSE-PETE-HEGSETH-UPDATE-ON-CONTINUING-ELIMINATION-OF-WASTEFUL-SPENDING-AT-THE-DOD.PDF">In a memo announcing the cuts</a>, Hegseth said that the Pentagon would be forced to bring more of its IT work in-house.</p><p>“These contracts represent non-essential spending on third party consultants to perform services more efficiently performed by the highly skilled members of our DoD workforce using existing resources,” Hegseth wrote.</p><p>Palantir’s partnerships with these companies vary, but each one makes it easier for Palantir to extend the reach of its software and AI technology across the federal government. With Accenture’s government branch, Palantir will train and certify at least 1,000 Accenture workers on its Foundry software as well as its AI tech, <a data-offer-url="https://newsroom.accenture.com/news/2025/palantir-and-accenture-federal-services-join-forces-to-help-federal-government-agencies-reinvent-operations-with-ai" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://newsroom.accenture.com/news/2025/palantir-and-accenture-federal-services-join-forces-to-help-federal-government-agencies-reinvent-operations-with-ai&quot;}" href="https://newsroom.accenture.com/news/2025/palantir-and-accenture-federal-services-join-forces-to-help-federal-government-agencies-reinvent-operations-with-ai" rel="nofollow noopener" target="_blank">according to an Accenture press release</a> The companies also said that together they could create “a 360-degree view” of government agency budgets, something the so-called Department of Government Efficiency (DOGE) has sought to build and use to review federal spending. (Palantir <a data-offer-url="https://t.co/5mcFHsKEje" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://t.co/5mcFHsKEje&quot;}" href="https://t.co/5mcFHsKEje" rel="nofollow noopener" target="_blank">partnered with Accenture before in 2022</a>, but this is the first partnership to focus on US government clients.)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“We are teaming up with Accenture Federal Services to accelerate AI across the U.S. Government, working to address federal agencies’ highest-priority operational challenges,” Palantir posted to X last month.</p><p>"What makes this partnership so uniquely powerful is Accenture’s expertise working with the federal government and our ability to bring commercial capabilities to government solutions, combined with Palantir’s deep experience in government software," Julie Sweet, chair and CEO of Accenture, said in a press release. “Together, we will harness the ever-growing power of AI to help the federal government succeed in its critical mission to modernize and reinvent its operations—with stronger data flows, transparency and resilience—to better serve warfighters, citizens and all its stakeholders.”</p><p>Accenture did not immediately respond to a request for comment.</p><p>While Palantir has become a major government contractor in its own right, partnering with contracting giants could enable the software company to scale at a much faster rate, leveraging long-standing relationships these larger contractors have with virtually every federal agency. “It's actually a pretty savvy business decision on the part of both Palantir, then also what you would call a traditional, more legacy-oriented, like defense or just government contractors,” says Jessica Tillipman, associate dean for government procurement law at George Washington University. “If they’re newer to certain areas and others have that footprint, that’s how it would benefit Palantir.”</p><p>Last week, Palantir and Deloitte announced a partnership that includes what they call the “Enterprise Operating System” (EOS) to unify data across organizations. At government agencies like the Internal Revenue Service and reportedly at the Social Security Administration (SSA), Palantir is already working to combine agency datasets, allowing what were previously disparate datasets to communicate with one another more easily.</p><p>"Deloitte shares Palantir's commitment to decisive action and a dedication to delivering meaningful, lasting results for commercial and government clients," said Jason Girzadas, Deloitte US CEO, said in a press release announcing the partnership. "Expanding our preferred relationship at this pivotal moment provides our clients with Palantir's latest advances in AI, combined with Deloitte's engineering scale and deep sector experience."</p><p>Deloitte did not immediately respond to a request for comment.</p><p>Palantir struck some of these deals prior to Trump taking office as well. In December of last year, <a data-offer-url="https://www.boozallen.com/menu/media-center/q3-2025/partnership-to-accelerate-defense-mission-innovation.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.boozallen.com/menu/media-center/q3-2025/partnership-to-accelerate-defense-mission-innovation.html&quot;}" href="https://www.boozallen.com/menu/media-center/q3-2025/partnership-to-accelerate-defense-mission-innovation.html" rel="nofollow noopener" target="_blank">Booz Allen partnered with Palantir</a> specifically, working together on building out defense IT infrastructure.</p><p>“To have one company monopolize and become the gatekeeper of software in the government, to become an ‘app factory,’ for the government, in a sense, where they're in every agency, they're part of the defense complex and the intelligence complex, brings huge concerns regarding fairness, regarding competition, and puts Palantir in a very unique position that maybe has never existed,” says Juan Sebastián Pinto, a former Palantir employee and critic of the company.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KDE Plasma prepares crackdown on focus-stealing window behavior under Wayland (113 pts)]]></title>
            <link>https://www.neowin.net/news/kde-plasma-prepares-crackdown-on-focus-stealing-window-behavior-under-wayland/</link>
            <guid>44784312</guid>
            <pubDate>Mon, 04 Aug 2025 11:22:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.neowin.net/news/kde-plasma-prepares-crackdown-on-focus-stealing-window-behavior-under-wayland/">https://www.neowin.net/news/kde-plasma-prepares-crackdown-on-focus-stealing-window-behavior-under-wayland/</a>, See on <a href="https://news.ycombinator.com/item?id=44784312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                                    <span>When you purchase through links on our site, we may earn an affiliate commission. <a href="https://www.neowin.net/terms">Here’s how it works</a>.</span>
                        
                        
                        <p>
    
    <time datetime="Aug 4, 2025 07:20 EDT" pubdate="pubdate">
    Aug 4, 2025 07:20 EDT
    </time>
         · <span>Hot!</span>    
    
    
    </p>

                    </div><div itemprop="articleBody">
                                                                        <p><img alt="KDE Plasma" src="https://cdn.neowin.com/news/images/uploaded/2025/06/1750516218_kde-plasma-2.webp"></p>

<p>One of the most <a href="https://www.neowin.net/news/kde-is-fixing-blurry-screens-by-snapping-almost-1x-scale-factors-back-to-1x-on-wayland/">interesting things about Wayland</a> is how it handles window focus, unlike X11, where focus stealing can be frustrating and even a security risk. Its main advantage is a mechanism that prevents focus stealing. The protocol that plays a role in this is known as "XDG Activation."</p>

<p>Here's how it works: Say you double-click a PDF file in your file manager. The file manager first asks the Wayland compositor for a special, single-use "activation token". This request is tied directly to your click, proving a human wanted this to happen.</p>

<p>The file manager then launches your PDF viewer and hands it the token. The PDF viewer, upon starting, shows this token to the compositor and asks to be activated. The compositor checks if the token is legit and, if so, gives the PDF viewer focus.</p>

                            <!-- PLACE THIS SECTION INSIDE OF YOUR BODY WHERE YOU WANT THE VIDEO PLAYER TO RENDER -->
            <p>If the token is missing, old, or otherwise invalid, the compositor says no. The viewer window will not get focus, and instead, its icon in the taskbar will start flashing to grab your attention.</p>

<figure><a href="https://cdn.neowin.com/news/images/uploaded/2025/08/1754304760_bildschirmfoto_20250731_143103-1024x740.webp"><img alt="KWrite text editor window window has no focus colors are softened Task bar with a couple of apps KWrite icon has an orange background behind it indicating KWrite is demanding attention" height="740" src="https://cdn.neowin.com/news/images/uploaded/2025/08/1754304760_bildschirmfoto_20250731_143103-1024x740.webp" width="1024"></a>

<figcaption>Flashing icon in the taskbar | Image: <a href="https://blog.broulik.de/2025/08/on-window-activation/">Kai-Uwe Broulik</a></figcaption></figure><p>Kai-Uwe Broulik, a KDE developer, recently wrote about the plan to "switch on KWin’s focus stealing on Wayland at a low level". This means KWin, the window manager for KDE Plasma, will begin enforcing this properly.</p>

<p>Under X11, new or dialog windows can only grab focus if their application was most recently active, a check often based on a timestamp called <code>_NET_WM_USER_TIME</code>. It was a flimsy system at best. For example, Kai cited how the prevention logic on X11 would sometimes stop the Adobe Flash Player fullscreen window from showing on top of a YouTube video. On X11, an application could just call <strong><code>XSetInputFocus</code></strong> on another app's window, and while KWin would try to undo it, focus did flicker for a moment.</p>

<p>Over on Wayland, things are much better with XDG Activation, but some apps still violate the protocol through improper usage. In situations like that, KWin would, by default, just focus any new window that opened. This is changing.</p>

<p>A new "Extreme" setting for "Focus Stealing Prevention" in the Window Management settings will force KWin to activate a window if and only if it requests activation with a valid token.</p>

<figure><a href="https://cdn.neowin.com/news/images/uploaded/2025/08/1754304876_screenshot_20250802_100046-1024x658.webp"><img alt="Window Behavior configuration dialog various window-related tabs and options mouse cursor pointing at a combo box Focus stealing prevention whose current item is Extreme" height="658" src="https://cdn.neowin.com/news/images/uploaded/2025/08/1754304876_screenshot_20250802_100046-1024x658.webp" width="1024"></a>

<figcaption>Image: <a href="https://blog.broulik.de/2025/08/on-window-activation/">Kai-Uwe Broulik</a></figcaption></figure><p>Using this stricter mode, developers Xaver Hugl and Kai-Uwe Broulik have already fixed a ton of issues, introducing several key changes:</p>

<ul>
<li>Dolphin no longer discards its activation token when launching a new instance.</li>
	<li>KRunner, Kickoff, and other Plasmoid popups now correctly request activation.</li>
	<li>LayerShell-Qt now requests activation on show and properly reads the <strong><code>XDG_ACTIVATION_TOKEN</code></strong> from the environment.</li>
	<li>Allowing privileged clients like Plasma to request tokens correctly.</li>
	<li>Ignoring modifier key presses for focus prevention logic, since they are often part of a global shortcut.</li>
</ul>
<p>The work extends to the backend as well, with the DBusRunner specification now gaining a <code>SetActivationToken</code> method that is called just before an action runs. Baloo, the desktop search runner, now uses this to ensure that opening files in an existing application window works correctly.</p>

<p>You can learn more on <a href="https://blog.broulik.de/2025/08/on-window-activation/">Kai's blog post.</a></p>
                        
                        
                                                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GHz spiking neuromorphic photonic chip with in-situ training (105 pts)]]></title>
            <link>https://arxiv.org/abs/2506.14272</link>
            <guid>44784297</guid>
            <pubDate>Mon, 04 Aug 2025 11:21:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2506.14272">https://arxiv.org/abs/2506.14272</a>, See on <a href="https://news.ycombinator.com/item?id=44784297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2506.14272">View PDF</a></p><blockquote>
            <span>Abstract:</span>Neuromorphic photonic computing represents a paradigm shift for next-generation machine intelligence, yet critical gaps persist in emulating the brain's event-driven, asynchronous dynamics,a fundamental barrier to unlocking its full potential. Here, we report a milestone advancement of a photonic spiking neural network (PSNN) chip, the first to achieve full-stack brain-inspired computing on a complementary metal oxide semiconductor-compatible silicon platform. The PSNN features transformative innovations of gigahertz-scale nonlinear spiking dynamics,in situ learning capacity with supervised synaptic plasticity, and informative event representations with retina-inspired spike encoding, resolving the long-standing challenges in spatiotemporal data integration and energy-efficient dynamic processing. By leveraging its frame-free, event-driven working manner,the neuromorphic optoelectronic system achieves 80% accuracy on the KTH video recognition dataset while operating at ~100x faster processing speeds than conventional frame-based approaches. This work represents a leap for neuromorphic computing in a scalable photonic platform with low latency and high throughput, paving the way for advanced applications in real-time dynamic vision processing and adaptive decision-making, such as autonomous vehicles and robotic navigation.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Xuhan Guo [<a href="https://arxiv.org/show-email/1e050960/2506.14272" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 17 Jun 2025 07:37:25 UTC (4,396 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mastercard deflects blame for NSFW games being taken down (509 pts)]]></title>
            <link>https://www.pcgamer.com/games/mastercard-deflects-blame-for-nsfw-games-being-taken-down-but-valve-says-payment-processors-specifically-cited-a-mastercard-rule-about-damaging-the-brand/</link>
            <guid>44783566</guid>
            <pubDate>Mon, 04 Aug 2025 09:27:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/games/mastercard-deflects-blame-for-nsfw-games-being-taken-down-but-valve-says-payment-processors-specifically-cited-a-mastercard-rule-about-damaging-the-brand/">https://www.pcgamer.com/games/mastercard-deflects-blame-for-nsfw-games-being-taken-down-but-valve-says-payment-processors-specifically-cited-a-mastercard-rule-about-damaging-the-brand/</a>, See on <a href="https://news.ycombinator.com/item?id=44783566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN.jpg" alt="KIEV, UKRAINE - 2020/01/24: In this photo illustration the Bank cards mastercard on computer keyboard. (Photo Illustration by Igor Golovniov/SOPA Images/LightRocket via Getty Images)" srcset="https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/3KG3rFXYAbaPno99GQK8VN.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Getty Images)</span>
</figcaption>
</div>

<div id="article-body">
<p>Two weeks after Valve confirmed it had <a data-analytics-id="inline-link" href="https://www.pcgamer.com/software/platforms/valve-confirms-credit-card-companies-pressured-it-to-delist-certain-adult-games-from-steam/" data-before-rewrite-localise="https://www.pcgamer.com/software/platforms/valve-confirms-credit-card-companies-pressured-it-to-delist-certain-adult-games-from-steam/">removed a pile of NSFW games from Steam</a> because of pressure from credit card companies—and one week after <a data-analytics-id="inline-link" href="https://www.pcgamer.com/gaming-industry/itch-io-latest-in-platforms-pressured-by-credit-card-companies-as-well-as-activist-group-collective-shout-which-has-successfully-caught-an-award-winning-indie-and-more-in-the-crossfire/" data-before-rewrite-localise="https://www.pcgamer.com/gaming-industry/itch-io-latest-in-platforms-pressured-by-credit-card-companies-as-well-as-activist-group-collective-shout-which-has-successfully-caught-an-award-winning-indie-and-more-in-the-crossfire/">Itch.io followed suit</a>—Mastercard has <a data-analytics-id="inline-link" href="https://www.mastercard.com/us/en/news-and-trends/press/2025/august/clarifying-recent-headlines-on-gaming-content.html" target="_blank" data-url="https://www.mastercard.com/us/en/news-and-trends/press/2025/august/clarifying-recent-headlines-on-gaming-content.html" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">released a statement</a> denying responsibility for the takedowns, saying it "allows all lawful purchases" to be processed through its systems.</p><p>"Mastercard has not evaluated any game or required restrictions of any activity on game creator sites and platforms, contrary to media reports and allegations," the company says<em>.</em></p><p>"Our payment network follows standards based on the rule of law. Put simply, we allow all lawful purchases on our network. At the same time, we require merchants to have appropriate controls to ensure Mastercard cards cannot be used for unlawful purchases, including illegal adult content."</p><p>It's an odd statement at first glance, because while the content removed by Steam and Itch.io may violate laws in some countries, it's fully legal in the US—objectionable and gross as hell in some cases, sure, but still within the boundaries of the law. Apart from that, both Valve and Itch.io explicitly stated that payment processors are the reason games were deindexed or removed from sale entirely.</p><p>Mastercard's 'out' here seems to be found in the structure of its operations. The company's website says it is "neither an issuer [a merchant bank] nor an acquirer [a bank, credit union, or other entity that provides debit cards or lines of credit to consumers]," but rather that it "<a data-analytics-id="inline-link" href="https://sea.mastercard.com/en-region-sea/business/merchants/start-accepting/payment-process.html" target="_blank" data-url="https://sea.mastercard.com/en-region-sea/business/merchants/start-accepting/payment-process.html" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">provide[s] the technology and the network that power transactions</a>." In other words, Mastercard does not process payments, it facilitates the systems that do.</p><p>In the case of Itch.io, the platform specifies in its "<a data-analytics-id="inline-link" href="https://itch.io/updates/update-on-nsfw-content" target="_blank" data-url="https://itch.io/updates/update-on-nsfw-content" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">update on NSFW content</a>" that its payment processors are Paypal and Stripe—and Stripe, which supports a <a data-analytics-id="inline-link" href="https://stripe.com/ae/payments/payment-methods" target="_blank" data-url="https://stripe.com/ae/payments/payment-methods" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">range of payment methods</a> including Visa and Mastercards, was the one <a data-analytics-id="inline-link" href="http://itch.io/" target="_blank" data-url="http://itch.io" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Itch.io</a> "suspended the ability to pay with for 18+ content for the foreseeable future."</p><p>Similarly, both <a data-analytics-id="inline-link" href="https://www.verotel.com/en/index.html?lang=en" target="_blank" data-url="https://www.verotel.com/en/index.html?lang=en" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Verotel</a> and <a data-analytics-id="inline-link" href="https://ccbill.com/" target="_blank" data-url="https://ccbill.com/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">CCBill</a>, which were recently recommended by the IGDA as "alternatives to overly risk-averse financial partners," accept major credit cards as payment methods.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-tMB45j7AvDWp2uiMV2GJFb"><section><p>Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.</p></section></div><p>In a statement provided to PC Gamer, Valve said that it had tried to work things out with Mastercard directly prior to removing the games, and suggested that Mastercard did have at least an indirect influence on the outcome.</p><p>"Mastercard did not communicate with Valve directly, despite our request to do so," a Valve representative said. "Mastercard communicated with payment processors and their acquiring banks. Payment processors communicated this with Valve, and we replied by outlining Steam’s policy since 2018 of attempting to distribute games that are legal for distribution.</p><p>"Payment processors rejected this, and specifically cited Mastercard’s Rule 5.12.7 and risk to the Mastercard brand."</p><figure><blockquote><p>"Mastercard did not communicate with Valve directly, despite our request to do so."</p><figcaption><cite>Valve representative</cite></figcaption></blockquote></figure><p><a data-analytics-id="inline-link" href="https://www.mastercard.us/content/dam/public/mastercardcom/na/global-site/documents/mastercard-rules.pdf" target="_blank" data-url="https://www.mastercard.us/content/dam/public/mastercardcom/na/global-site/documents/mastercard-rules.pdf" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Mastercard's Rule 5.12.7</a> relates to "illegal or brand-damaging transactions," and states:</p><p><em>A Merchant must not submit to its Acquirer, and a Customer must not submit to the Interchange System, any Transaction that is illegal, or in the sole discretion of the Corporation, may damage the goodwill of the Corporation or reflect negatively on the Marks.</em></p><p>That includes, according to the rules, any product or services that "is patently offensive and lacks serious artistic value (such as, by way of example and not limitation, images of nonconsensual sexual behavior, sexual exploitation of a minor, nonconsensual mutilation of a person or body part, and bestiality), or any other material that the Corporation deems unacceptable to sell in connection with a Mark."</p><p>Acquirers—the financial institutions that provide the cards and lines of credit—who fail to take action in response to complaints are subject to significant penalties, monetary and otherwise.</p><p>Regardless of the role Mastercard played in all of this, directly or indirectly, its "clarification" sure makes it seem like the pressure is being felt. Which from a gamer perspective, at least, is a good thing: As others have mentioned, a public pressure campaign certainly seemed to work for Collective Shout, the Australian anti-porn crusaders who <a data-analytics-id="inline-link" href="https://www.pcgamer.com/gaming-industry/australian-anti-porn-group-claims-responsibility-for-steams-new-censorship-rules-in-victory-against-porn-sick-brain-rotted-pedo-gamer-fetishists-and-things-only-get-weirder-from-there/" data-before-rewrite-localise="https://www.pcgamer.com/gaming-industry/australian-anti-porn-group-claims-responsibility-for-steams-new-censorship-rules-in-victory-against-porn-sick-brain-rotted-pedo-gamer-fetishists-and-things-only-get-weirder-from-there/">started this whole thing</a>—regardless of how the gears turn behind the curtain, there's no reason to think it can't work the other way too.</p>
</div>


<div id="slice-container-authorBio-tMB45j7AvDWp2uiMV2GJFb"><p>Andy has been gaming on PCs from the very beginning, starting as a youngster with text adventures and primitive action games on a cassette-based TRS80. From there he graduated to the glory days of Sierra Online adventures and Microprose sims, ran a local BBS, learned how to build PCs, and developed a longstanding love of RPGs, immersive sims, and shooters. He began writing videogame news in 2007 for The Escapist and somehow managed to avoid getting fired until 2014, when he joined the storied ranks of PC Gamer. He covers all aspects of the industry, from new game announcements and patch notes to legal disputes, Twitch beefs, esports, and Henry Cavill. Lots of Henry Cavill.</p></div>
</section>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTMX is hard, so let's get it right (123 pts)]]></title>
            <link>https://github.com/BookOfCooks/blog/blob/master/htmx-is-hard-so-lets-get-it-right.md</link>
            <guid>44783266</guid>
            <pubDate>Mon, 04 Aug 2025 08:30:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/BookOfCooks/blog/blob/master/htmx-is-hard-so-lets-get-it-right.md">https://github.com/BookOfCooks/blog/blob/master/htmx-is-hard-so-lets-get-it-right.md</a>, See on <a href="https://news.ycombinator.com/item?id=44783266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>


                <li>
      

      <div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
          <p>
            GitHub Copilot
          </p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_product_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
          <p>
            GitHub Spark
              <span>
                New
              </span>
          </p><p>
        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_product_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
          <p>
            GitHub Models
              <span>
                New
              </span>
          </p><p>
        Manage and compare prompts
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
          <p>
            GitHub Advanced Security
          </p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
          <p>
            Actions
          </p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    
                </ul>
              </div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
          <p>
            Codespaces
          </p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
          <p>
            Issues
          </p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
          <p>
            Code Review
          </p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
          <p>
            Discussions
          </p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
          <p>
            Code Search
          </p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
          

      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      

      <div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
          <p>
            GitHub Sponsors
          </p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
          <p>
            The ReadME Project
          </p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      

      <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
          <p>
            Enterprise platform
          </p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:BookOfCooks/blog" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="WPAnYliyY1FgoOA8Va2qojQcgE4Z6D0ngRZ_ocMapCiw8P8hwCSETk0Gq9pKOzyy1sg4y5mC3UTOxjHJzymdKg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="BookOfCooks/blog" data-current-org="" data-current-owner="BookOfCooks" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=BookOfCooks%2Fblog" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/BookOfCooks/blog/blob/master/htmx-is-hard-so-lets-get-it-right.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="a0e1293e471f60ad624a289d0e30d910c8c92e00d39582f686e5d00a39e54016" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-d67da881-3dd5-4124-9b48-94824db9f093" for="icon-button-c7ce36fd-9a1c-48af-bbba-ecfabb410fa9" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.260d30274859410b0337.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.76259b61ecc822265749.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>

      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Job-seekers are dodging AI interviewers (385 pts)]]></title>
            <link>https://fortune.com/2025/08/03/ai-interviewers-job-seekers-unemployment-hiring-hr-teams/</link>
            <guid>44783155</guid>
            <pubDate>Mon, 04 Aug 2025 08:04:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2025/08/03/ai-interviewers-job-seekers-unemployment-hiring-hr-teams/">https://fortune.com/2025/08/03/ai-interviewers-job-seekers-unemployment-hiring-hr-teams/</a>, See on <a href="https://news.ycombinator.com/item?id=44783155">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>The next time you get buttoned-up and sit down for a long-awaited job interview, you might not find a human on the other end of the call. Instead, job-hunters are now joining <a href="https://fortune.com/company/zoom/" target="_blank" aria-label="Go to https://fortune.com/company/zoom/">Zoom</a> meetings only to <a href="https://www.tiktok.com/@leohumpsalot/video/7501016832850103583" target="_blank" rel="noopener" aria-label="Go to https://www.tiktok.com/@leohumpsalot/video/7501016832850103583">be greeted by</a> AI interviewers. Candidates tell <em>Fortune </em>they’re either confused, intrigued, or straight-up dejected when the robotic, faceless bots join the calls.&nbsp;</p><div>



<p>“Looking for a job right now is so demoralizing and soul-sucking, that to submit yourself to that added indignity is just a step too far,” Debra Borchardt, a seasoned writer and editor who has been on the job-hunt for three months, tells <em>Fortune. </em>“Within minutes, I was like, ‘I don’t like this. This is awful.’ It started out normal…Then it went into the actual process of the interview, and that’s when it got a little weird.”



</p><p>AI interviewers are only the newest <a href="https://fortune.com/2024/09/05/ai-changing-job-hunting-recruiting/" target="_self" aria-label="Go to https://fortune.com/2024/09/05/ai-changing-job-hunting-recruiting/">change to the</a> hiring process that has <a href="https://fortune.com/2025/06/11/ai-hiring-process-employee-skills-candidate/" target="_self" aria-label="Go to https://fortune.com/2025/06/11/ai-hiring-process-employee-skills-candidate/">been upended</a> by the advanced technology. With HR teams dwindling and hiring managers tasked to review <a href="https://fortune.com/2025/05/25/insurance-giant-progressive-is-hiring-12000-workers-this-year-and-its-using-ai-to-parse-through-hundreds-of-thousands-of-applications/" target="_self" aria-label="Go to https://fortune.com/2025/05/25/insurance-giant-progressive-is-hiring-12000-workers-this-year-and-its-using-ai-to-parse-through-hundreds-of-thousands-of-applications/">thousands of</a> applicants for a single role, they’re <a href="https://fortune.com/2024/09/24/two-page-resume-new-normal-ai-job-seekers/" target="_self" aria-label="Go to https://fortune.com/2024/09/24/two-page-resume-new-normal-ai-job-seekers/">optimizing their</a> jobs <a href="https://fortune.com/2024/09/04/how-ai-changing-future-recruiting-job-search/" target="_self" aria-label="Go to https://fortune.com/2024/09/04/how-ai-changing-future-recruiting-job-search/">by using AI to</a> filter top applicants, schedule candidate interviews, and automate correspondence about next steps in the process. AI interviewers may be a god-send for middle-managers, but job-seekers see them as only another hurdle in the <a href="https://fortune.com/2025/07/14/gen-z-job-hunting-harder-millions-unemployed-millennial-gen-x-careers-ai-entry-level-work/" target="_self" aria-label="Go to https://fortune.com/2025/07/14/gen-z-job-hunting-harder-millions-unemployed-millennial-gen-x-careers-ai-entry-level-work/">intense hunt for</a> work.&nbsp;



</p><p>The experience for some job-hunters has been so poor that they’re swearing off interviews conducted by AI altogether. Candidates tell <em>Fortune </em>that AI interviewers make them feel unappreciated to the point where they’d rather skip out on potential job opportunities, reasoning the company’s culture can’t be great if human bosses won’t make the time to interview them. But HR experts argue the opposite; since AI interviewers can help hiring managers save time in first-round calls, the humans have more time to have more meaningful conversations with applicants down the line.&nbsp;



</p><p>Job-seekers and HR are starkly divided on how they feel about the tech, but one thing is fact—AI interviewers aren’t going anywhere.&nbsp;</p><p>“The truth is, if you want a job, you’re gonna go through this thing,” Adam Jackson, CEO and founder of Braintrust, a company that distributes AI interviewers, tells <em>Fortune. </em>“If there were a large portion of the job-seeking community that were wholesale rejecting this, our clients wouldn’t find the tool useful… This thing would be chronically underperforming for our clients. And we’re just not seeing that—we’re seeing the opposite.”



</p><h2>Job-seekers are dodging AI interviewers&nbsp;</h2>



<p>Social media has been <a href="https://www.tiktok.com/@petobsessed777/video/7499996920622992682?q=AI%20interviewer&amp;t=1753974873967" target="_blank" rel="noopener" aria-label="Go to https://www.tiktok.com/@petobsessed777/video/7499996920622992682?q=AI%20interviewer&amp;t=1753974873967">exploding with</a> job-seekers detailing their AI interviewer <a href="https://www.tiktok.com/@meghantheeyogi/video/7532986697219362079?q=AI%20interviewer&amp;t=1753974873967" target="_blank" rel="noopener" aria-label="Go to https://www.tiktok.com/@meghantheeyogi/video/7532986697219362079?q=AI%20interviewer&amp;t=1753974873967">experiences</a>: describing bots hallucinating and <a href="https://www.tiktok.com/@loeybugxo/video/7500355242530245930?q=AI%20interviewer&amp;t=1753974873967" target="_blank" rel="noopener" aria-label="Go to https://www.tiktok.com/@loeybugxo/video/7500355242530245930?q=AI%20interviewer&amp;t=1753974873967">repeating questions</a> on end, calling the robotic <a href="https://www.tiktok.com/@sebwhatseb/video/7501713243182746902?q=AI%20interviewer&amp;t=1753974873967" target="_blank" rel="noopener" aria-label="Go to https://www.tiktok.com/@sebwhatseb/video/7501713243182746902?q=AI%20interviewer&amp;t=1753974873967">conversations awkward</a>, or saying it’s less nerve-wracking than talking to a human. Despite how much hiring managers love AI interviewers, job-seekers aren’t sold on the idea just yet.&nbsp;



</p><p>Allen Rausch, a 56-year-old technical writer who has worked at <a href="https://fortune.com/company/amazon-com/" target="_self" aria-label="Go to https://fortune.com/company/amazon-com/">Amazon</a> and <a href="https://fortune.com/company/electronic-arts/" target="_self" aria-label="Go to https://fortune.com/company/electronic-arts/">Electronic Arts</a>, has been on the job hunt for two months since getting laid off from his previous role at InvestCloud. In looking for new opportunities, he was “startled” to run into AI interviewers for the first time—let alone on three occasions for separate jobs. All of the meetings would last up to 25 minutes, and featured woman-like cartoons with female voices. It asked basic career questions, running through his resume and details about the job opening, but couldn’t answer any of his questions on the company or culture. 



</p><p>Rausch says he’s only open to doing more AI interviews if they don’t test his writing skills, and if human connection is guaranteed at some point later in the process.



</p><p>“Given the percentage of responses that I’m getting to just basic applications, I think a lot of AI interviews are wasting my time,” he tells <em>Fortune.</em> “I would probably want some sort of a guarantee that, ‘Hey, we’re doing this just to gather initial information, and we are going to interview you with a human being [later].’”</p><p>While Rausch withstood multiple AI interviews, Borchardt couldn’t even sit through a single one. The 64-year-old editorial professional says things went downhill when the robotic interviewer simply ran through her resume, asking her to repeat all of her work experiences at each company listed. The call was impersonal, irritating, and to Borchardt, quite lazy. She ended the interview in less than 10 minutes.&nbsp;



</p><p>“After about the third question, I was like, ‘I’m done.’ I just clicked exit,” she says. “I’m not going to sit here for 30 minutes and talk to a machine… I don’t want to work for a company if the HR person can’t even spend the time to talk to me.”



</p><p>Alex Cobb, a professional now working at U.K. energy company Murphy Group, also encountered an AI interviewer several months ago searching for a new role. While he’s sympathetic towards how many applications HR has to sift through, he finds AI interviewers to be “weird” and ultimately ineffective in fully assessing human applicants. The experience put a bad taste in his mouth, to the point where Cobb won’t pursue any AI-proctored interviews in the foreseeable future.&nbsp;



</p><p>“If I know from looking at company reviews or the hiring process that I will be using AI interviewing, I will just not waste my time, because I feel like it’s a cost-saving exercise more than anything,” Cobb tells <em>Fortune.</em> “It makes me feel like they don’t value my learning and development. It makes me question the culture of the company—are they going to cut jobs in the future because they’ve learned robots can already recruit people? What else will they outsource that to do?”



</p><h2>AI interviewers are a god-send for squeezed hiring managers&nbsp;</h2>



<p>While many job-seekers are backing away from taking AI interviews, hiring managers are accepting the technology with open arms. A large part of it comes from necessity.&nbsp;</p><p>“They’re becoming more common in early-stage screening because they can streamline high-volume hiring,” Priya Rathod, workplace trends editor at Indeed, tells <em>Fortune.</em> “You’re seeing them all over. But for high-volume hiring like customer service or retail or entry-level tech roles, we’re just seeing this more and more… It’s doing that first-stage work that a lot of employers need in order to be more efficient and save time.”



</p><p>It should be noted that not all AI interviewers are created equal—there’s a wide range of AI interviewers entering the market. Job-seekers who spoke with <em>Fortune </em>described monotonous, robotic-voiced bots with pictures of strange feminized avatars. But some AI interviewers, like the one created by Braintrust, distribute a faceless bot with a more natural sounding voice. Its CEO says applicants using the tech are overall happy with their experience—and its hiring manager clientele are enthusiastic, too.&nbsp;



</p><p>However, Jackson admits AI interviewers still have their limitations, despite how revolutionary they are for HR teams.



</p><p>“It does 100 interviews, and it’s going to hand back the best 10 to the hiring manager, and then the human takes over,” he says. “AI is good at objective skill assessment—I would say even better than humans. But [when it comes to] cultural fit, I wouldn’t even try to have AI do that.”
</p></div><p><strong>Introducing the 2025 Fortune 500</strong>, the definitive ranking of the biggest companies in America.&nbsp;<a href="https://fortune.com/ranking/fortune500/?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=plea_text" target="_self" aria-label="Go to https://fortune.com/ranking/fortune500/?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=plea_text">Explore this year's list.</a></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Poorest US workers hit hardest by slowing wage growth (190 pts)]]></title>
            <link>https://www.ft.com/content/cfb77a53-fef8-4382-b102-c217e0aa4b25</link>
            <guid>44781189</guid>
            <pubDate>Mon, 04 Aug 2025 00:57:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/cfb77a53-fef8-4382-b102-c217e0aa4b25">https://www.ft.com/content/cfb77a53-fef8-4382-b102-c217e0aa4b25</a>, See on <a href="https://news.ycombinator.com/item?id=44781189">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div id="heroOffer-Hero offers-632e2b54-4d33-4f18-ac4e-d808b608e179" data-component="heroOffer" data-component-unique-name="Hero offers" data-o3-theme="inverse"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2><span><span>Try unlimited access</span></span></h2><h2><span><span>Only </span><span>Dkr10</span><span> for 4 weeks</span></span></h2></p><p><span><span>Then </span><span>Dkr535</span><span> per month.
Complete digital access to quality FT journalism on any device. 
Cancel anytime during your trial.</span></span></p></div></div><div id="recommendedOffers-Recommended Offers" data-component="recommendedOffers" data-component-unique-name="Recommended Offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_standard.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>Standard Digital</h3></p></div><p><span><span>Dkr349</span><span> per month</span></span></p><p><span><span>Essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>Premium Digital</h3></p></div><p><span><span>Dkr535</span><span> per month</span></span></p><p><span><span>Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_bundle.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>Print + Premium Digital</h3></p></div><p><span><span>Dkr556</span><span> per month</span></span></p><p><span><span>Complete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.</span></span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription Options Offers API" data-o3-theme="inverse"><h2>Explore our full range of subscriptions.</h2><div><div><div><h3>For individuals</h3></div><p>Discover all the plans currently available in your country</p></div><div><div><h3> For multiple readers</h3></div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT" data-o3-theme="inverse"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=cfb77a53-fef8-4382-b102-c217e0aa4b25">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why doctors hate their computers (2018) (108 pts)]]></title>
            <link>https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers</link>
            <guid>44781116</guid>
            <pubDate>Mon, 04 Aug 2025 00:41:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers">https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers</a>, See on <a href="https://news.ycombinator.com/item?id=44781116">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure data-testid="cne-audio-embed-figure"></figure><p>On a sunny afternoon in May, 2015, I joined a dozen other surgeons at a downtown Boston office building to begin sixteen hours of mandatory computer training. We sat in three rows, each of us parked behind a desktop computer. In one month, our daily routines would come to depend upon mastery of Epic, the new medical software system on the screens in front of us. The upgrade from our home-built software would cost the hospital system where we worked, Partners HealthCare, a staggering $1.6 billion, but it aimed to keep us technologically up to date.</p><p>More than ninety per cent of American hospitals have been computerized during the past decade, and more than half of Americans have their health information in the Epic system. Seventy thousand employees of Partners HealthCare—spread across twelve hospitals and hundreds of clinics in New England—were going to have to adopt the new software. I was in the first wave of implementation, along with eighteen thousand other doctors, nurses, pharmacists, lab techs, administrators, and the like.</p><p>The surgeons at the training session ranged in age from thirty to seventy, I estimated—about sixty per cent male, and one hundred per cent irritated at having to be there instead of seeing patients. Our trainer looked younger than any of us, maybe a few years out of college, with an early-Justin Bieber wave cut, a blue button-down shirt, and chinos. Gazing out at his sullen audience, he seemed unperturbed. I learned during the next few sessions that each instructor had developed his or her own way of dealing with the hostile rabble. One was encouraging and parental, another unsmiling and efficient. Justin Bieber took the driver’s-ed approach: You don’t want to be here; I don’t want to be here; let’s just make the best of it.</p><p>I did fine with the initial exercises, like looking up patients’ names and emergency contacts. When it came to viewing test results, though, things got complicated. There was a column of thirteen tabs on the left side of my screen, crowded with nearly identical terms: “chart review,” “results review,” “review flowsheet.” We hadn’t even started learning how to enter information, and the fields revealed by each tab came with their own tools and nuances.</p><p>But I wasn’t worried. I’d spent my life absorbing changes in computer technology, and I knew that if I pushed through the learning curve I’d eventually be doing some pretty cool things. In 1978, when I was an eighth grader in Ohio, I built my own four-kilobyte computer from a mail-order kit, learned to program in <em>BASIC</em>, and was soon playing the arcade game Pong on our black-and-white television set. The next year, I got a an Apple II computer and eventually became the first kid in my school to turn in a computer-printed essay (and, shortly thereafter, the first to ask for an extension “because the computer ate my homework”). As my Epic training began, I expected my patience to be rewarded in the same way.</p><p>My hospital had, over the years, computerized many records and processes, but the new system would give us one platform for doing almost everything health professionals needed—recording and communicating our medical observations, sending prescriptions to a patient’s pharmacy, ordering tests and scans, viewing results, scheduling surgery, sending insurance bills. With Epic, paper lab-order slips, vital-signs charts, and hospital-ward records would disappear. We’d be greener, faster, better.</p><p>But three years later I’ve come to feel that a system that promised to increase my mastery over my work has, instead, increased my work’s mastery over me. I’m not the only one. A 2016 study found that physicians spent about two hours doing computer work for every hour spent face to face with a patient—whatever the brand of medical software. In the examination room, physicians devoted half of their patient time facing the screen to do electronic tasks. And these tasks were spilling over after hours. The University of Wisconsin found that the average workday for its family physicians had grown to eleven and a half hours. The result has been epidemic levels of burnout among clinicians. Forty per cent screen positive for depression, and seven per cent report suicidal thinking—almost double the rate of the general working population.</p><p>Something’s gone terribly wrong. Doctors are among the most technology-avid people in society; computerization has simplified tasks in many industries. Yet somehow we’ve reached a point where people in the medical profession actively, viscerally, volubly hate their computers.</p><p>On May 30, 2015, the Phase One Go-Live began. My hospital and clinics reduced the number of admissions and appointment slots for two weeks while the staff navigated the new system. For another two weeks, my department doubled the time allocated for appointments and procedures in order to accommodate our learning curve. This, I discovered, was the real reason the upgrade cost $1.6 billion. The software costs were under a hundred million dollars. The bulk of the expenses came from lost patient revenues and all the tech-support personnel and other people needed during the implementation phase.</p><p>In the first five weeks, the I.T. folks logged twenty-seven thousand help-desk tickets—three for every two users. Most were basic how-to questions; a few involved major technical glitches. Printing problems abounded. Many patient medications and instructions hadn’t transferred accurately from our old system. My hospital had to hire hundreds of moonlighting residents and pharmacists to double-check the medication list for every patient while technicians worked to fix the data-transfer problem.</p><p>Many of the angriest complaints, however, were due to problems rooted in what Sumit Rana, a senior vice-president at Epic, called “the Revenge of the Ancillaries.” In building a given function—say, an order form for a brain MRI—the design choices were more political than technical: administrative staff and doctors had different views about what should be included. The doctors were used to having all the votes. But Epic had arranged meetings to try to adjudicate these differences. Now the staff had a say (and sometimes the doctors didn’t even show), and they added questions that made their jobs easier but other jobs more time-consuming. Questions that doctors had routinely skipped now stopped them short, with “field required” alerts. A simple request might now involve filling out a detailed form that took away precious minutes of time with patients.</p><p>Rana said that these growing pains were predictable. The Epic people always build in a period for “optimization”—reconfiguring various functions according to feedback from users. “The first week,” he told me, “people say, ‘How am I going to get through this?’ At a year, they say, ‘I wish you could do this and that.’&nbsp;”</p><p>I saw what he meant. After six months, I’d become fairly proficient with the new software. I’d bring my laptop with me to each appointment, open but at my side. “How can I help?” I’d ask a patient. My laptop was available for checking information and tapping in occasional notes; after the consultation, I completed my office report. Some things were slower than they were with our old system, and some things had improved. From my computer, I could now remotely check the vital signs of my patients recovering from surgery in the hospital. With two clicks, I could look up patient results from outside institutions that use Epic, as many now do. For the most part, my clinical routine did not change very much.</p><p>As a surgeon, though, I spend most of my clinical time in the operating room. I wondered how my more office-bound colleagues were faring. I sought out Susan Sadoughi, whom an internist friend described to me as one of the busiest and most efficient doctors in his group. Sadoughi is a fifty-year-old primary-care physician, originally from Iran, who has worked at our hospital for twenty-four years. She’s married to a retired Boston police lieutenant and has three kids. Making time in her work and family schedule to talk to me was revealingly difficult. The only window we found was in the early morning, when we talked by phone during her commute.</p><p>Sadoughi told me that she has four patient slots per hour. If she’s seeing a new patient, or doing an annual physical, she’ll use two slots. Early on, she recognized that technology could contribute to streamlining care. She joined a committee overseeing updates of a home-built electronic-medical-record system we used to rely on, helping to customize it for the needs of her fellow primary-care physicians. When she got word of the new system, she was optimistic. Not any longer. She feels that it has made things worse for her and her patients. Before, Sadoughi almost never had to bring tasks home to finish. Now she routinely spends an hour or more on the computer after her children have gone to bed.</p><p>She gave me an example. Each patient has a “problem list” with his or her active medical issues, such as difficult-to-control diabetes, early signs of dementia, a chronic heart-valve problem. The list is intended to tell clinicians at a glance what they have to consider when seeing a patient. Sadoughi used to keep the list carefully updated—deleting problems that were no longer relevant, adding details about ones that were. But now everyone across the organization can modify the list, and, she said, “it has become utterly useless.” Three people will list the same diagnosis three different ways. Or an orthopedist will list the same generic symptom for every patient (“pain in leg”), which is sufficient for billing purposes but not useful to colleagues who need to know the specific diagnosis (e.g., “osteoarthritis in the right knee”). Or someone will add “anemia” to the problem list but not have the expertise to record the relevant details; Sadoughi needs to know that it’s “anemia due to iron deficiency, last colonoscopy 2017.” The problem lists have become a hoarder’s stash.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“They’re long, they’re deficient, they’re redundant,” she said. “Now I come to look at a patient, I pull up the problem list, and it means nothing. I have to go read through their past notes, especially if I’m doing urgent care,” where she’s usually meeting someone for the first time. And piecing together what’s important about the patient’s history is at times actually harder than when she had to leaf through a sheaf of paper records. Doctors’ handwritten notes were brief and to the point. With computers, however, the shortcut is to paste in whole blocks of information—an entire two-page imaging report, say—rather than selecting the relevant details. The next doctor must hunt through several pages to find what really matters. Multiply that by twenty-some patients a day, and you can see Sadoughi’s problem.</p><p>The software “has created this massive monster of incomprehensibility,” she said, her voice rising. Before she even sets eyes upon a patient, she is already squeezed for time. And at each step along the way the complexity mounts.</p><p>“Ordering a mammogram used to be one click,” she said. “Now I spend three extra clicks to put in a diagnosis. When I do a Pap smear, I have eleven clicks. It’s ‘Oh, who did it?’ Why not, by default, think that <em>I</em> did it?” She was almost shouting now. “I’m the one putting the order in. Why is it asking me what date, if the patient is in the office today? When do you think this actually happened? It is incredible!” The Revenge of the Ancillaries, I thought.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a21322&quot;}" href="https://www.newyorker.com/cartoon/a21322" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>“Don’t judge my client by the covers of the books he reads.”</span></p><p><span>Cartoon by P. C. Vey</span></p></div></span></p></figure><p>She continued rattling off examples like these. “Most days, I will have done only around thirty to sixty per cent of my notes by the end of the day,” she said. The rest came after hours. Spending the extra time didn’t anger her. The pointlessness of it did.</p><p>Difficulties with computers in the workplace are not unique to medicine. Matt Spencer is a British anthropologist who studies scientists instead of civilizations. After spending eighteen months embedded with a group of researchers studying fluid dynamics at Imperial College London, he made a set of observations about the painful evolution of humans’ relationship with software in a 2015 paper entitled “<a data-offer-url="https://www.mitpressjournals.org/doi/abs/10.1162/POSC_a_00184?journalCode=posc" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.mitpressjournals.org/doi/abs/10.1162/POSC_a_00184?journalCode=posc&quot;}" href="https://www.mitpressjournals.org/doi/abs/10.1162/POSC_a_00184?journalCode=posc" rel="nofollow noopener" target="_blank">Brittleness and Bureaucracy</a>.”</p><p>Years before, a graduate student had written a program, called Fluidity, that allowed the research group to run computer simulations of small-scale fluid dynamics—specifically, ones related to the challenge of safely transporting radioactive materials for nuclear reactors. The program was elegant and powerful, and other researchers were soon applying it to a wide range of other problems. They regularly added new features to it, and, over time, the program expanded to more than a million lines of code, in multiple computer languages. Every small change produced unforeseen bugs. As the software grew more complex, the code became more brittle—more apt to malfunction or to crash.</p><p>The I.B.M. software engineer Frederick Brooks, in his classic 1975 book, “<a data-offer-url="https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1541429715&amp;sr=1-1&amp;keywords=The+Mythical+Man-Month" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1541429715&amp;sr=1-1&amp;keywords=The+Mythical+Man-Month&quot;}" href="https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1541429715&amp;sr=1-1&amp;keywords=The+Mythical+Man-Month" rel="nofollow noopener" target="_blank" data-aps-asin="0201835959" data-aps-asc-tag="">The Mythical Man-Month</a>,” called this final state the Tar Pit. There is, he said, a predictable progression from a cool program (built, say, by a few nerds for a few of their nerd friends) to a bigger, less cool program product (to deliver the same function to more people, with different computer systems and different levels of ability) to an even bigger, very uncool program system (for even more people, with many different needs in many kinds of work).</p><p>Spencer plotted the human reaction that accompanied this progression. People initially embraced new programs and new capabilities with joy, then came to depend on them, then found themselves subject to a system that controlled their lives. At that point, they could either submit or rebel. The scientists in London rebelled. “They were sick of results that they had gotten one week no longer being reproducible a week later,” Spencer wrote. They insisted that the group spend a year rewriting the code from scratch. And yet, after the rewrite, the bureaucratic shackles remained.</p><p>As a program adapts and serves more people and more functions, it naturally requires tighter regulation. Software systems govern how we interact as groups, and that makes them unavoidably bureaucratic in nature. There will always be those who want to maintain the system and those who want to push the system’s boundaries. Conservatives and liberals emerge.</p><p>Scientists now talked of “old Fluidity,” the smaller program with fewer collaborators which left scientists free to develop their own idiosyncratic styles of research, and “new Fluidity,” which had many more users and was, accordingly, more rule-bound. Changes required committees, negotiations, unsatisfactory split-the-difference solutions. Many scientists complained to Spencer in the way that doctors do—they were spending so much time on the requirements of the software that they were losing time for actual research. “I just want to do science!” one scientist lamented.</p><p>Yet none could point to a better way. “While interviewees would make their resistance known to me,” Spencer wrote, “none of them went so far as to claim that Fluidity could be better run in a different manner.” New Fluidity had capabilities that no small, personalized system could ever provide and that the scientists couldn’t replace.</p><p>The Tar Pit has trapped a great many of us: clinicians, scientists, police, salespeople—all of us hunched over our screens, spending more time dealing with constraints on how we do our jobs and less time simply doing them. And the only choice we seem to have is to adapt to this reality or become crushed by it.</p><p>Many have been crushed. The Berkeley psychologist Christina Maslach has spent years studying the phenomenon of occupational burnout. She focussed on health care early on, drawn by the demanding nature of working with the sick. She defined burnout as a combination of three distinct feelings: emotional exhaustion, depersonalization (a cynical, instrumental attitude toward others), and a sense of personal ineffectiveness. The opposite, a feeling of deep engagement in one’s work, came from a sense of energy, personal involvement, and efficacy. She and her colleagues developed a twenty-two-question survey known as the Maslach Burnout Inventory, which, for nearly four decades, has been used to track the well-being of workers across a vast range of occupations, from prison guards to teachers.</p><p>In recent years, it has become apparent that doctors have developed extraordinarily high burnout rates. In 2014, fifty-four per cent of physicians reported at least one of the three symptoms of burnout, compared with forty-six per cent in 2011. Only a third agreed that their work schedule “leaves me enough time for my personal/family life,” compared with almost two-thirds of other workers. Female physicians had even higher burnout levels (along with lower satisfaction with their work-life balance). A Mayo Clinic analysis found that burnout increased the likelihood that physicians switched to part-time work. It was driving doctors out of practice.</p><p>Burnout seemed to vary by specialty. Surgical professions such as neurosurgery had especially poor ratings of work-life balance and yet lower than average levels of burnout. Emergency physicians, on the other hand, had a better than average work-life balance but the highest burnout scores. The inconsistencies began to make sense when a team at the Mayo Clinic discovered that one of the strongest predictors of burnout was how much time an individual spent tied up doing computer documentation. Surgeons spend relatively little of their day in front of a computer. Emergency physicians spend a lot of it that way. As digitization spreads, nurses and other health-care professionals are feeling similar effects from being screen-bound.</p><p>Sadoughi told me of her own struggles—including a daily battle with her Epic “In Basket,” which had become, she said, clogged to the point of dysfunction. There are messages from patients, messages containing lab and radiology results, messages from colleagues, messages from administrators, automated messages about not responding to previous messages. “All the letters that come from the subspecialists, I can’t read ninety per cent of them. So I glance at the patient’s name, and, if it’s someone that I was worried about, I’ll read that,” she said. The rest she deletes, unread. “If it’s just a routine follow-up with an endocrinologist, I hope to God that if there was something going on that they needed my attention on, they would send me an e-mail.” In short, she hopes they’ll try to reach her at yet another in-box.</p><p>As I observed more of my colleagues, I began to see the insidious ways that the software changed how people work together. They’d become more disconnected; less likely to see and help one another, and often less able to. Jessica Jacobs, a longtime office assistant in my practice—mid-forties, dedicated, with a smoker’s raspy voice—said that each new software system reduced her role and shifted more of her responsibilities onto the doctors. Previously, she sorted the patient records before clinic, drafted letters to patients, prepped routine prescriptions—all tasks that lightened the doctors’ load. None of this was possible anymore. The doctors had to do it all themselves. She called it “a ‘stay in your lane’ thing.” She couldn’t even help the doctors navigate and streamline their computer systems: office assistants have different screens and are not trained or authorized to use the ones doctors have.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“You can’t learn more from the system,” she said. “You can’t do more. You can’t take on extra responsibilities.” Even fixing minor matters is often not in her power. She’d recently noticed, for instance, that the system had the wrong mailing address for a referring doctor. But, she told me, “all I can do is go after the help desk thirteen times.”</p><p>Jacobs felt sad and sometimes bitter about this pattern of change: “It’s disempowering. It’s sort of like they want any cookie-cutter person to be able to walk in the door, plop down in a seat, and just do the job exactly as it is laid out.”</p><p>Sadoughi felt much the same: “The first year Epic came in, I was so close to saying, ‘That’s it. I’m done with primary care, I’m going to be an urgent-care doctor. I’m not going to open another In Basket.’ It took all this effort reëvaluating my purpose to stick with it.”</p><p>Gregg Meyer sympathizes, but he isn’t sorry. As the chief clinical officer at Partners HealthCare, Meyer supervised the software upgrade. An internist in his fifties, he has the commanding air, upright posture, and crewcut one might expect from a man who spent half his career as a military officer.</p><p>“I’m the veteran of four large-scale electronic-health-records implementations,” he told me in his office, overlooking downtown Boston. Those included two software overhauls in the military and one at Dartmouth-Hitchcock Medical Center, where he’d become the chief clinical officer. He still sees patients, and he experiences the same frustrations I was hearing about. Sometimes more: he admits he’s not as tech-savvy as his younger colleagues.</p><p>“But we think of this as a system for <em>us</em> and it’s not,” he said. “It is for <em>the patients</em>.” While some sixty thousand staff members use the system, almost ten times as many patients log into it to look up their lab results, remind themselves of the medications they are supposed to take, read the office notes that their doctor wrote in order to better understand what they’ve been told. Today, patients are the fastest-growing user group for electronic medical records.</p><p>Computerization also allows clinicians to help patients in ways that hadn’t been possible before. In one project, Partners is scanning records to identify people who have been on opioids for more than three months, in order to provide outreach and reduce the risk of overdose. Another effort has begun to identify patients who have been diagnosed with high-risk diseases like cancer but haven’t received prompt treatment. The ability to adjust protocols electronically has let Meyer’s team roll out changes far faster as new clinical evidence comes in. And the ability to pull up records from all hospitals that use the same software is driving real improvements in care.</p><p>Meyer gave me an example. “The care of the homeless population of Boston took a quantum leap,” he said. With just a few clicks, “we can see the fact that they had three TB rule-outs”—three negative test results for tuberculosis—“someplace else in town, which means, O.K., I don’t have to put him in an isolation room.”</p><p>In Meyer’s view, we’re only just beginning to experience what patient benefits are possible. A recent study bolsters his case. Researchers looked at Medicare patients admitted to hospitals for fifteen common conditions, and analyzed how their thirty-day death rates changed as their hospitals computerized. The results shifted over time. In the first year of the study, deaths actually increased 0.11 per cent for every new function added—an apparent cost of the digital learning curve. But after that deaths dropped 0.21 per cent a year for every function added. If computerization causes doctors some annoyance but improves patient convenience and saves lives, Meyer is arguing, isn’t it time we all got on board?</p><p>“I’m playing the long game,” he said. “I have full faith that all that stuff is just going to get better with time.”</p><p>And yet it’s perfectly possible to envisage a system that makes care ever better for those who receive it and ever more miserable for those who provide it. Hasn’t this been the story in many fields? The complaints of today’s health-care professionals may just be a white-collar, high-tech equivalent of the century-old blue-collar discontent with “Taylorization”—the industrial philosophy of fragmenting work into components, standardizing operations, and strictly separating those who design the workflow from those who do the work. As Frederick Winslow Taylor, the Progressive Era creator of “scientific management,” put it, “In the past, the man has been first; in the future, the system must be first.” Well, we are in that future, and the system is the computer.</p><p>Indeed, the computer, by virtue of its brittle nature, seems to require that it come first. Brittleness is the inability of a system to cope with surprises, and, as we apply computers to situations that are ever more interconnected and layered, our systems are confounded by ever more surprises. By contrast, the systems theorist David Woods notes, human beings are designed to handle surprises. We’re resilient; we evolved to handle the shifting variety of a world where events routinely fall outside the boundaries of expectation. As a result, it’s the people inside organizations, not the machines, who must improvise in the face of unanticipated events.</p><p>Last fall, the night before daylight-saving time ended, an all-user e-mail alert went out. The system did not have a way to record information when the hour from 1 <em>A.M.</em> to 1:59 <em>A.M.</em> repeated in the night. This was, for the system, a surprise event. The only solution was to shut down the lab systems during the repeated hour. Data from integrated biomedical devices (such as monitoring equipment for patients’ vital signs) would be unavailable and would have to be recorded by hand. Fetal monitors in the obstetrics unit would have to be manually switched off and on at the top of the repeated hour.</p><p>Medicine is a complex adaptive system: it is made up of many interconnected, multilayered parts, and it is meant to evolve with time and changing conditions. Software is not. It is complex, but it does not adapt. That is the heart of the problem for its users, us humans.</p><p>Adaptation requires two things: mutation and selection. Mutation produces variety and deviation; selection kills off the least functional mutations. Our old, craft-based, pre-computer system of professional practice—in medicine and in other fields—was all mutation and no selection. There was plenty of room for individuals to do things differently from the norm; everyone could be an innovator. But there was no real mechanism for weeding out bad ideas or practices.</p><p>Computerization, by contrast, is all selection and no mutation. Leaders install a monolith, and the smallest changes require a committee decision, plus weeks of testing and debugging to make sure that fixing the daylight-saving-time problem, say, doesn’t wreck some other, distant part of the system.</p><p>For those in charge, this kind of system oversight is welcome. Gregg Meyer is understandably delighted to have the electronic levers to influence the tens of thousands of clinicians under his purview. He had spent much of his career seeing his hospitals blighted by unsafe practices that, in the paper-based world, he could do little about. A cardiologist might decide to classify and treat patients with congestive heart failure differently from the way his colleagues did, and with worse results. That used to happen all the time.</p><p>“Now there’s a change-control process,” Meyer said. “When everything touches everything, you have to have change-control processes.”</p><p>But those processes cannot handle more than a few change projects at a time. Artisanship has been throttled, and so has our professional capacity to identify and solve problems through ground-level experimentation. Why can’t our work systems be like our smartphones—flexible, easy, customizable? The answer is that the two systems have different purposes. Consumer technology is all about letting me be me. Technology for complex enterprises is about helping groups do what the members cannot easily do by themselves—work in coördination. Our individual activities have to mesh with everyone else’s. What we want and don’t have, however, is a system that accommodates both mutation and selection.</p><p>Human beings do not only rebel. We also create. We force at least a certain amount of mutation, even when systems resist. Consider that, in recent years, one of the fastest-growing occupations in health care has been medical-scribe work, a field that hardly existed before electronic medical records. Medical scribes are trained assistants who work alongside physicians to take computer-related tasks off their hands. This fix is, admittedly, a little ridiculous. We replaced paper with computers because paper was inefficient. Now computers have become inefficient, so we’re hiring more humans. And it sort of works.</p><p>Not long ago, I spent a day following Lynden Lee as he scribed at a Massachusetts General Hospital primary-care practice. Lee, a twenty-three-year-old graduate of Boston University, is an Asian-American raised in Illinois, and, like many scribes, he was doing the job, earning minimum wage, while he applied to medical school. He worked for Allan Goroll, a seventy-two-year-old internist of the old school—fuzzy eyebrows, steel-wool hair, waist-length white coat.</p><p>Lee, wearing the scribe uniform of neatly tucked oxford shirt and khakis, went to get the morning’s first patient from the waiting room. He’d developed a short speech to introduce himself: “I help take notes, so that Dr. Goroll can spend more time with you instead of typing at the computer. But, of course, if there’s anything you need to say, or would like to discuss with Dr. Goroll, in private, I can certainly leave the room.”</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a22228&quot;}" href="https://www.newyorker.com/cartoon/a22228" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>“It’s fine to know your ABCs and your colors, but really you just have to be able to sit still and control your bladder.”</span></p><p><span>Cartoon by Barbara Smaller</span></p></div></span></p></figure><p>The first patient was Zoya Shteynberg, a fifty-seven-year-old immigrant from the Soviet Union with copper-red hair and red-rimmed glasses. She is the wife of a dentist, who is also a patient of Goroll’s. “I take care of his whole family—his mother, his wife, their daughters,” he said. “Zoya runs the office.”</p><p>Goroll faced Shteynberg across his desk. To his left, his computer sat untouched. To his right, Lee stood behind a wheeled laptop stand, his fingers already tapping at the keys. He’d pulled up information for Goroll to review as he came in—the notes from Shteynberg’s last visit with him, and recent visits to other specialists—and was starting to write a new medical note. The story Shteynberg told was complex, and unfolded, as medical stories often do, in pieces that were difficult to connect. She had been having sudden, unusual episodes. They sometimes made her short of breath, at other times nauseated. While driving her car, she had an attack in which her heart raced and she felt so light-headed that she feared she might pass out. She had a history of high blood pressure, and she had frequent ear congestion.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Goroll probed and listened, while Lee recorded the details. Every once in a while, the doctor asked Lee to look up information—the trend of her last blood-pressure measurements, or the results of various tests she’d had. He paused to tell Lee how to organize the information: to list faintness, high blood pressure, and ear congestion as three separate problems, not one.</p><p>When it came time for a physical examination, Lee and I stood behind a curtain, giving Shteynberg privacy. Goroll called out his findings for Lee to record. (“Skin: warm and dry, no pallor.”) While Shteynberg dressed, he stood with Lee outside the room and instructed him about tests he wanted done. Lee couldn’t sign any orders, but he could enter them in the computer for Goroll to review and authorize later. We returned to the room, and the doctor summarized his observations for Shteynberg. He wasn’t alarmed, but he had no explanation yet for her episodes. He listed a few possibilities and follow-up tests. Then he told her, “Am I worried about these things? No.”</p><p>She was relieved. “Me, either,” she said.</p><p>Scribes aren’t a perfect solution. Underpaid and minimally trained, they learn mostly on the go, and turn over rapidly (most within months). Research has found error rates between twenty-four and fifty per cent in recording key data; Goroll still spends time after clinic reviewing the charts and correcting errors. But Lee spared him many hours a week, and Goroll was thrilled about it. He got back enough time to start work on the eighth edition of a textbook he has written on primary-care medicine. And, because of his scribe, he was able to give his patient his complete attention throughout the consultation. In recent years, he’d found this increasingly difficult.</p><p>Shteynberg said she was all in favor of scribes: “Because now Dr. Goroll will come right up in front of my eyes, and he listens.” She explained that he used to look at his screen, instead of at her, and type while he spoke.</p><p>“That bothered you?” he asked, surprised.</p><p>“Oh, yes,” she said.</p><p>We are already seeing the next mutation. During the past year, Massachusetts General Hospital has been trying out a “virtual scribe” service, in which India-based doctors do the documentation based on digitally recorded patient visits. Compared with “live scribing,” this system is purportedly more accurate—since the scribes tend to be fully credentialled doctors, not aspiring med students—for the same price or cheaper. IKS Health, which provides the service, currently has four hundred physicians on staff in Mumbai giving support to thousands of patient visits a day in clinics across the United States. The company expects to employ more than a thousand doctors in the coming year, and it has competitors taking the same approach.</p><p>Siddhesh Rane is one of its doctor-scribes. A thirty-two-year-old orthopedic surgeon from a town called Kolhapur, he seemed like any of my surgical colleagues here in Boston, direct, driven, with his photo I.D. swaying on a lanyard around his neck. He’d joined the company for the learning opportunity, he said, not the pay (although many of the IKS staffers were better paid than they would be in a local medical practice).</p><p>He explained the virtual-scribe system to me when we spoke via Skype. With the patient’s permission, physicians record an entire patient visit with a multidirectional microphone, then encrypt and transmit the recording online. In India, Rane listens to the visit and writes a first draft of the office note. Before starting the work, he went through a careful “onboarding” process with each of the American physicians he works with. One, Nathalee Kong, a thirty-one-year-old internist, was based at an M.G.H. clinic in Revere, a working-class community north of Boston. For a week, Rane listened to recordings of her patient visits and observed how she wrote them up. For another week, they wrote parallel notes, to make sure Rane was following Kong’s preferences. They agreed on trigger phrases; when she says to the patient, “Your exam is normal except for&nbsp;.&nbsp;.&nbsp;. ,” Rane can record the usual elements of her head-to-toe exam without her having to call each one out.</p><p>A note for a thirty-minute visit takes Rane about an hour to process. It is then reviewed by a second physician for quality and accuracy, and by an insurance-coding expert, who confirms that it complies with regulations—and who, not incidentally, provides guidance on taking full advantage of billing opportunities. IKS Health says that its virtual-scribe service pays for itself by increasing physician productivity—in both the number of patients that physicians see and the amount billed per patient.</p><p>Kong was delighted by the arrangement. “Now all I have to do is listen to the patient and be present,” she told me. When taking a family history, she said, “I don’t have to go back and forth: ‘O.K., so your mom had breast cancer. Let me check that off in the computer before I forget.’ I’m just having a natural conversation with another human being, instead of feeling like I’m checking off a box, which I literally was doing.”</p><p>Before working with Rane, Kong rarely left the office before 7 <em>P.M.</em>, and even then she had to do additional work at home in order to complete her notes. Now she can leave at five o’clock. “I’m hopeful that this prevents me from burning out,” she said. “That’s something I was definitely aware of going into this profession—something that I really feared.” What’s more, she now has the time and the energy to explore the benefits of a software system that might otherwise seem to be simply a burden. Kong manages a large number of addiction patients, and has learned how to use a list to track how they are doing as a group, something she could never have done on her own. She has also learned to use a function that enters a vaccine table into patients’ notes, allowing her to list the vaccinations they should have received and the ones they are missing.</p><p>Her biggest concern now? That the scribes will be taken away. Yet can it really be sustainable to have an additional personal assistant—a fully trained doctor in India, no less—for every doctor with a computer? And, meanwhile, what’s happening across the globe? Who is taking care of the patients all those scribing doctors aren’t seeing?</p><p>There’s a techno-optimist view of how this story will unfold. Big technology companies are already circling to invest in IKS Health. They see an opportunity for artificial intelligence to replace more and more of what Rane does. This prospect doesn’t worry Rane very much; by the time technology has taken his place, he hopes to have set up a clinic of his own, and perhaps get to use the system himself. It’s not hard to believe that our interfaces for documenting and communicating will get easier, more intuitive, less annoying.</p><p>But there’s also a techno-pessimist version of the story. A 2015 study of scribes for emergency physicians in an Atlanta hospital system found that the scribes produced results similar to what my Boston colleagues described—a thirty-six-per-cent reduction in the doctors’ computer-documentation time and a similar increase in time spent directly interacting with patients. Two-thirds of the doctors said that they “liked” or even “loved” having a scribe. Yet they also reported no significant change in their job satisfaction. With the time that scribes freed up, the system simply got doctors to take on more patients. Their workload didn’t lighten; it just shifted.</p><p>Studies of scribes in other health systems have found the same effect. Squeezing more patients into an hour is better than spending time entering data at a keyboard. More people are taken care of. But are they being taken care of well? As patients, we want the caring and the ingenuity of clinicians to be augmented by systems, not defeated by them. In an era of professional Taylorization—of the stay-in-your-lane ethos—that does not seem to be what we are getting.</p><p>Putting the system first is not inevitable. Postwar Japan and West Germany eschewed Taylor’s method of industrial management, and implemented more collaborative approaches than was typical in the U.S. In their factories, front-line workers were expected to get involved when production problems arose, instead of being elbowed aside by top-down management. By the late twentieth century, American manufacturers were scrambling to match the higher quality and lower costs that these methods delivered. If our machines are pushing medicine in the wrong direction, it’s our fault, not the machines’ fault.</p><p>Some people are pushing back. Neil&nbsp;R. Malhotra is a boyish, energetic, forty-three-year-old neurosurgeon who has made his mark at the University of Pennsylvania as something of a tinkerer. He has a knack for tackling difficult medical problems. In the past year alone, he has published papers on rebuilding spinal disks using tissue engineering, on a better way to teach residents how to repair cerebral aneurysms, and on which spinal-surgery techniques have the lowest level of blood loss. When his hospital’s new electronic-medical-record system arrived, he immediately decided to see if he could hack the system.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>He wasn’t a programmer, however, and wasn’t interested in becoming one. So he sought out Judy Thornton, a software analyst from the hospital’s I.T. department. Together, they convened an open weekly meeting, currently on Thursday mornings, where everyone in the neurosurgery department—from the desk clerks to the medical staff to the bosses—could come not just to complain about the system but also to reimagine it. Department members feared that Malhotra’s pet project would be a time sink. Epic heard about his plans to fiddle around with its system and reacted with alarm. The hospital lawyers resisted, too. “They didn’t want us to build something that potentially had a lot of intellectual property in someone else’s system,” Malhotra said.</p><p>But he managed to keep the skeptics from saying no outright. Soon, he and his fellow-tinkerers were removing useless functions and adding useful ones. Before long, they had built a faster, more intuitive interface, designed specifically for neurosurgery office visits. It would capture much more information that really mattered in the care of patients with brain tumors, cerebral aneurysms, or spinal problems.</p><p>Now there was mutation <em>and</em> selection—through a combination of individual ingenuity and group preference. One new feature the department embraced, for instance, enlists the help of patients. At the end of a visit, doctors give the keyboard to patients, who provide their firsthand ratings of various factors that show how they’re progressing: their ability to walk without assistance, or their level of depression and anxiety. The data on mobility before surgery turned out to predict which patients would need to be prepared for time in a rehabilitation center and which ones could go straight home from the hospital.</p><p>Malhotra’s innovations showed that there were ways for users to take at least some control of their technology—to become, with surprising ease, creators. Granted, letting everyone tinker inside our medical-software systems would risk crashing them. But a movement has emerged to establish something like an app store for electronic medical records, one that functions much the way the app store on your smartphone does. If the software companies provided an “application programming interface,” or A.P.I., staff could pick and choose apps according to their needs: an internist could download an app to batch patients’ prescription refills; a pediatric nurse could download one to set up a growth chart.</p><p>Electronic-medical-record companies have fought against opening up their systems this way because of the loss of control (and potential revenue) doing so would entail. In the past couple of years, though, many have begun to bend. Even Epic has launched its “App Orchard.” It’s still in the early stages—only about a hundred apps are available, and there are strict limits on what kinds of customization it enables—but it’s a step in the right direction.</p><p>“You know what I’m excited about?” Malhotra said to me. “Walking.” He had collected data on the walking ability of ten thousand patients—both before and after surgery. “In any set of patients, what is our goal? It’s to maintain mobility or, in many cases, improve it.” Previously, his department could track only rates of survival and complications. Now he’s experimenting with an app that could live on patients’ phones and provide more granular data about their recovery process. “You’d turn on the neurosurgery module when you are seeing us, which would wake up at those time points to give you a notification saying, ‘Hey, can you do these surveys? They help your care, and you can do them on your phone.’&nbsp;”</p><p>I told him about a similar app my research team was experimenting with, which collects step counts, among other measures, after surgery. But we had no way to adjust our electronic medical records so that clinicians could readily find a particular patient’s results.</p><p>“Step counts!” Malhotra said. “Oh, if we just had step counts.” His wheels were turning. What if they made a tab in the electronic medical record with whatever data on activity patients were willing to provide?</p><p>“You could do that?” I said.</p><p>“Sure. Why not?”</p><p>It’s a beguiling vision. Many fear that the advance of technology will replace us all with robots. Yet in fields like health care the more imminent prospect is that it will make us all behave like robots. And the people we serve need something more than either robots or robot-like people can provide. They need human enterprises that can adapt to change.</p><p>It was a Monday afternoon. I was in clinic. I had no scribe, in India or otherwise; no cool app to speed me through my note-writing or serve up all my patient’s information in some nifty, instantly absorbable visual. It was just me, my computer, a file of papers, and John Cameron, a lanky, forty-three-year-old construction supervisor who’d been healthy all his life, felt fine, but was told to see a surgeon for reasons that he still didn’t completely understand.</p><p>It all started, he told me, with a visit to his primary-care provider for a routine physical. I held a printout of the doctor’s note. (My high-tech hack is to have key materials printed out, because it takes too long to flip between screens.) It said that she’d found a calcium level so high it was a wonder that Cameron wasn’t delirious. The internist sent him to an endocrinologist, who found, deep in his electronic records, a forgotten history of several benign skin lesions. The specialist wondered if Cameron had a rare genetic syndrome that’s known to cause tumors and, in turn, hormone abnormalities, skin lesions, and high calcium levels.</p><p>The diagnosis seemed very unlikely, but a battery of tests had turned up surprising results, including abnormal levels of a pituitary hormone. I needed to log into the computer to check the original lab reports. He watched me silently click one tab after another. Minutes passed. I became aware of how long it was taking me to pull up the right results. Finally, I let go of the mouse and took Cameron to the examining table. When I’d finished the exam and we sat down again at my little computer desk against the wall, I told him what I’d determined. He had a parathyroid tumor, it had pushed his calcium levels dangerously high, and it needed to be removed surgically. I took out a pen and paper, and drew a picture to explain how the surgery would be done. First, though, we needed to get his calcium under control. The abnormal levels of the pituitary hormone suggested that he might have a tumor in his pituitary gland as well—and might even have the unusual genetic syndrome. I was less sure about this, I told him, so I wanted to do more testing and get an opinion from an expert at my hospital.</p><p>Cameron’s situation was too complicated for a thirty-minute slot. We’d gone way over time. Other patients were waiting. Plus, I still had to type up all my findings, along with our treatment plan.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a22297&quot;}" href="https://www.newyorker.com/cartoon/a22297" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>“Now, when she gets home, just turn your nose up and walk away. Humans love that.”</span></p><p><span>Cartoon by Elisabeth McNair</span></p></div></span></p></figure><p>“Any questions?” I asked, hoping he’d have none.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“It’s a lot to take in,” he said. “I feel normal. It’s hard to imagine all this going on.” He looked at me, expecting me to explain more.</p><p>I hesitated. Let’s talk after the new tests come back, I said.</p><p>Later, I thought about how unsatisfactory my response was. I’d wanted to put my computer away—to sort out what he’d understood and what he hadn’t, to learn a bit about who he really was, to make a connection. But I had that note to type, and the next patient stewing across the hall.</p><p>The story of modern medicine is the story of our human struggle with complexity. Technology will, without question, continually increase our ability to make diagnoses, to peer more deeply inside the body and the brain, to offer more treatments. It will help us document it all—but not necessarily to make sense of it all. Technology inevitably produces more noise and new uncertainties.</p><p>Perhaps a computer could have alerted me to the possibility of a genetic disorder in John Cameron, based on his history of skin lesions and the finding of high calcium. But our systems are forever generating alerts about possible connections—to the point of signal fatigue. Just ordering medications and lab tests triggers dozens of alerts each day, most of them irrelevant, and all in need of human reviewing and sorting. There are more surprises, not fewer. The volume of knowledge and capability increases faster than any individual can manage—and faster than our technologies can make manageable for us. We ultimately need systems that make the right care simpler for both patients and professionals, not more complicated. And they must do so in ways that strengthen our human connections, instead of weakening them.</p><p>A week or two after my visit with Cameron, I called him to review his laboratory results. A scan had pinpointed a parathyroid tumor in the right side of his neck, which would be straightforward to remove. A test showed that he didn’t have the genetic syndrome, after all, and a brain scan showed no pituitary tumor.</p><p>I had more time for his questions now, and I let him ask them. When we were done and I was about to get off the phone, I paused. I asked him if he’d noticed, during our office visit, how much time I’d spent on the computer.</p><p>“Yes, absolutely,” he said. He added, “I’ve been in your situation. I knew you were just trying to find the information you needed. I was actually trying not to talk too much, because I knew you were in a hurry, but I needed you to look the information up. I wanted you to be able to do that. I didn’t want to push you too far.”</p><p>It was painful to hear. Forced to choose between having the right technical answer and a more human interaction, Cameron picked having the right technical answer. I asked him what he meant about having been in my situation. As a construction-site supervisor, he said, he spends half his day in front of his laptop and half in front of people. His current job was overseeing the construction of a thirty-eight-unit apartment complex in town. “I have to make sure that things are being done per design and the specifications,” he said. That involves looking up lots of information, logging inspection data, and the like. But, at the same time, he has to communicate with lots of people. “I have to be out in the field checking and dealing with subcontractors and employees of our own.”</p><p>The technology at his disposal has grown more powerful in recent years. “We have cloud-based quality-control software, where we document the job at different stages. I can use that information for punch lists and quality-control checks. We also have a time-lapse camera where we can go back and look at things that we might’ve missed.” The technology is more precise, but it’s made everything more complicated and time-consuming. He faces the same struggle that I do.</p><p>Cameron was philosophical about it. He’s worked with big construction companies and small ones and used numerous software systems along the way. He couldn’t do without them. And yet, he said, “all these different technologies and apps on these iPads, all the stuff that I’ve had to use over the years, they’re supposed to make our job easier. But they’re either slow, or they’re cumbersome, or they require a lot of data entry and they’re not efficient.” The system inundates his subcontractors with e-mail alerts, for instance. “&nbsp;‘You gotta submit this, you’re behind on that, you didn’t finish the punch list.’ The project managers and superintendents and subcontractors eventually say, ‘Enough’s enough. We can’t deal with all these e-mails. It’s ridiculous.’ So they ignore them all. Then nothing gets done. You end up on the phone, back to the old-school way. Because it’s a people business.”</p><p>He went on, “I don’t allow anybody to work on my job unless they go through a one-hour orientation with me. I have to know these guys personally. They have to know me. Millions of years human beings evolved to look at each other in the face, to use facial expression to create connection.”</p><p>I’d talked to dozens of experts, but Cameron might have been the wisest of them all. There was something comforting about the way he accepted the inevitability of conflict between our network connections and our human connections. We can retune and streamline our systems, but we won’t find a magical sweet spot between competing imperatives. We can only insure that people always have the ability to turn away from their screens and see each other, colleague to colleague, clinician to patient, face to face.</p><p>The next time I saw Cameron was on the day of his operation. He lay on a stretcher outside the operating room, waiting to be wheeled in. A computer screen on a boom loomed over the bed, showing the safety checks I still had to do.</p><p>I shook Cameron’s hand and was introduced to his wife, who was in a chair beside him. They smiled nervously. It was his first time going under anesthesia. I told them about who would be on the surgical team with me and what was going to happen. I reached for the computer. But then I hesitated. I remembered when I’d turned my back on Cameron at our last encounter.</p><p>“Let’s go through these checks together,” I said.</p><p>I angled the screen toward the couple. Side by side, we confirmed that his medical history was up to date, that the correct surgical site was marked on his body, that I’d reviewed his medication allergies. His shoulders began to relax. His wife’s did, too.</p><p>“Are you ready?” I asked.</p><p>“I am,” he said.&nbsp;♦</p><p>An earlier version of this article mistakenly stated that the author built a one-kilobyte computer in 1978. He actually built a four-kilobyte computer. It also stated that the author bought a Commodore 64 in 1979; in fact, he bought an Apple II computer.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Typed languages are better suited for vibecoding (249 pts)]]></title>
            <link>https://solmaz.io/typed-languages-are-better-suited-for-vibecoding</link>
            <guid>44780878</guid>
            <pubDate>Sun, 03 Aug 2025 23:55:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://solmaz.io/typed-languages-are-better-suited-for-vibecoding">https://solmaz.io/typed-languages-are-better-suited-for-vibecoding</a>, See on <a href="https://news.ycombinator.com/item?id=44780878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>My &gt;10 year old programming habits have changed since <a href="https://www.anthropic.com/claude-code">Claude Code</a> launched. Python is less likely to be my go-to language for new projects anymore. I am managing projects in languages I am not fluent in—TypeScript, Rust and Go—and seem to be doing pretty well.</p>

<p>It seems that typed, compiled, etc. languages are better suited for vibecoding, because of the safety guarantees. This is unsurprising in hindsight, but it was counterintuitive because by default I “vibed” projects into existence in Python since forever.</p>

<p>Paradoxically, after a certain size of project, I can move faster and safer with e.g. Claude Code + Rust, compared to Claude Code + Python, despite the low-levelness of the code<sup id="fnref:1"><a href="#fn:1" rel="footnote" role="doc-noteref">1</a></sup>. This is possible purely because of AI tools.</p>

<p>For example, I refactored large chunks of our TypeScript frontend code at TextCortex. Claude Code runs <code>tsc</code> after finishing each task and ensures that the code compiles before committing. This let me move much faster compared to how I would have done it in Python, which does not provide compile-time guarantees. I am amazed every time how my 3-5k line diffs created in a few hours don’t end up breaking anything, and instead even increase stability.</p>

<p>LLMs are <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/">leaky abstractions</a>, sure. But they now work well enough so that they solve the problem Python solved for me (fast prototyping), without the disadvantages of Python (lower safety guarantees, slowness, ambiguity<sup id="fnref:2"><a href="#fn:2" rel="footnote" role="doc-noteref">2</a></sup>).</p>

<p>Because of this, I predict a decrease in Python adoption in companies, specifically for production deployments, even though I like it so much.</p>

<hr>



  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to grow almost anything (193 pts)]]></title>
            <link>https://howtogrowalmostanything.notion.site/htgaa25</link>
            <guid>44780540</guid>
            <pubDate>Sun, 03 Aug 2025 22:55:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://howtogrowalmostanything.notion.site/htgaa25">https://howtogrowalmostanything.notion.site/htgaa25</a>, See on <a href="https://news.ycombinator.com/item?id=44780540">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A study of lights at night suggests dictators lie about economic growth (2022) (144 pts)]]></title>
            <link>https://www.economist.com/graphic-detail/2022/09/29/a-study-of-lights-at-night-suggests-dictators-lie-about-economic-growth</link>
            <guid>44780515</guid>
            <pubDate>Sun, 03 Aug 2025 22:50:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/graphic-detail/2022/09/29/a-study-of-lights-at-night-suggests-dictators-lie-about-economic-growth">https://www.economist.com/graphic-detail/2022/09/29/a-study-of-lights-at-night-suggests-dictators-lie-about-economic-growth</a>, See on <a href="https://news.ycombinator.com/item?id=44780515">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="immersive-article-template"><section><h2>Satellite data hints at the scale of their deception</h2></section><div><div><section><p data-component="paragraph"><span data-caps="initial">B</span><small>enito Mussolini</small> was a tyrant, but at least he made the trains run on time. Or so the story goes. Dictators are often seen as ruthless but effective. Official <small>GDP</small> figures support this view. Since 2002 average reported economic growth in autocracies has been twice as fast as in democracies. </p></section><p>This article appeared in the Graphic detail section of the print edition under the headline “Shining light on lies”</p><div data-test-id="chapterlist" data-tracking-id="content-well-chapter-list"><ul><li><a href="https://www.economist.com/graphic-detail/2022/09/29/a-study-of-lights-at-night-suggests-dictators-lie-about-economic-growth" id="bbba1a34-a388-429a-91e7-f4f193da2eb8" data-analytics="article:reports_headline:1" data-test-id="chapterlist-link-0"><span data-testid="right-economist-red-false"><span>→</span></span><span>A study of lights at night suggests dictators lie about economic growth</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="How not to run a country" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20221001_DE_UK.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the October 1st 2022 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2022-10-01" data-analytics="sidebar:weekly_edition"><span data-testid="right-economist-red-true"><span>⇒</span></span><span>Explore the edition</span></a></p></div></div></div><div><div><figure><img alt="" loading="lazy" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 1440px) 700px, (min-width: 1280px) 50vw, (min-width: 960px) 66vw, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20250802_WOT921.png 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20250802_WOT921.png 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20250802_WOT921.png 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20250802_WOT921.png 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20250802_WOT921.png 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20250802_WOT921.png 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20250802_WOT921.png 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20250802_WOT921.png 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20250802_WOT921.png 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250802_WOT921.png 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250802_WOT921.png"></figure></div><hr><hr></div></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So you want to parse a PDF? (368 pts)]]></title>
            <link>https://eliot-jones.com/2025/8/pdf-parsing-xref</link>
            <guid>44780353</guid>
            <pubDate>Sun, 03 Aug 2025 22:24:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eliot-jones.com/2025/8/pdf-parsing-xref">https://eliot-jones.com/2025/8/pdf-parsing-xref</a>, See on <a href="https://news.ycombinator.com/item?id=44780353">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>Suppose you have an appetite for tilting at windmills. Let's say you love pain. Well then why not write a PDF parser today?</p>

<h2>The ideal world: how the specification should work</h2>

<p>Conceptually parsing a PDF is fairly simple:</p>

<ul>
<li>First, locate the version header comment at the start of the file</li>
<li>Next you need to locate the pointer to the cross-reference</li>
<li>Then you can find all object offsets</li>
<li>Finally you locate and build the trailer dictionary which points to the catalog dicitionary</li>
</ul>

<h3>Introduction to PDF objects</h3>

<p>A PDF object wraps some valid PDF content, numbers, strings, dictionaries, etc., in an object and generation number. The content is surrounded by the <code>obj/endobj</code> markers, for example a simple number may have its own PDF object:</p>

<pre><code>16 0 obj
620
endobj
</code></pre>

<p>This declares that object 16 with generation 0 contains the number 620.</p>

<p>A PDF file is effectively a graph of objects that may reference each other. Objects reference other objects by use of indirect references. These have the format "16 0 R" which indicates that the content
should be found in object 16 (generation number 0). In this case that would point to the object 16 containing the number 620. It is up to producer applications to split file content into objects as they wish, though the specification requires that certain object types be indirect.</p>

<h3>Finding the cross-reference offset</h3>

<p>To avoid the need to scan the entire file, PDFs declare a cross-reference table (xref). This is an index pointing to where each object in the file lives.</p>

<p>Each file ends with a pointer to the cross-reference file:</p>

<pre><code>&lt;&lt; %trailer &gt;&gt;
startxref
116
%%EOF
</code></pre>

<p>This tells the parser to jump to byte offset 116 to find the xref table (or stream). In theory this pointer is right at the end of the file, according to the specification:</p>

<blockquote>
  <p>Applications should read a PDF file from its end. The last line of the file contains only the end-of-file marker, <code>%%EOF</code></p>
</blockquote>

<p>Though the specification says the <code>%%EOF</code> marker should be on the last line, in practice, things are much messier. For example, Adobe Acrobat only requires it to be within the last 1024 bytes. In real files it can appear anywhere.</p>

<p>In addition files encountered in the wild lacked a linebreak before the offset declaration, or had a typo, e.g. <code>startref</code>.</p>

<p>Let's assume you're able to find the declared cross-reference offset for now.</p>

<h3>Finding all object offsets</h3>

<p>At the specified offset you should find a well-formatted xref table:</p>

<pre><code>xref
7 4
0000000000 65535 f 
0000109882 00000 n 
0000109933 00000 n 
0000140066 00000 n 
</code></pre>

<p>After the <code>xref</code> indicator appears, followed by a line break, the first object number and count of objects in the subsection are given. This means: start at object 7 and list 4 objects. Each line gives the byte offset, generation number, and status (n for in-use, f for free). From this, we know where to find objects 8-10 in the file.</p>

<p>So in the example above -- skipping the free entry for object 7 -- this xref table tells where to find the following objects:</p>

<ul>
<li>Object 8 (generation 0) at offset 109882</li>
<li>Object 9 (generation 0) at offset 109933</li>
<li>Object 10 (generation 0) at offset 140066</li>
</ul>

<p>Note: files can have multiple xref tables or streams, linked by <code>/Prev</code> entries in their trailers.</p>

<h3>Locating the trailer dictionary</h3>

<p>Finally, above the startxref marker, you'll find the trailer dictionary. This provides key metadata, most importantly, where to find the root object. Once you have that, you can follow references and begin interpreting the content.</p>

<h2>The real world: where your pain begins</h2>

<p>Assuming everything is well behaved and you have a reasonable parser for PDF objects this is fairly simple. But you cannot assume everything is well behaved. That would be very foolish, foolish indeed. You're in PDF hell
now. PDF isn't a specification, it's a social construct, it's a vibe. The more you struggle the deeper you sink. You live in the bog now, with the rest of us, far from the sight of God. If your parser expects files to obey the specification it will fail and people will think it is broken and pitiable. They will think that you are very silly.</p>

<h3>The challenges of locating the xref pointer</h3>

<p>We've already mentioned a few unexpected ways locating the pointer to the first cross-reference can fail:</p>

<ul>
<li>It is not at the end of the file, nor within the last 1024 bytes of the file.</li>
<li>It is misspelled.</li>
<li>It is not in the format you'd expect.</li>
</ul>

<p>But assuming you find a pointer, that's where the real fun begins. Because the pointer is not your friend, it is the first lie, you don't appreciate how deep the rabbit hole goes.
In screening 3977 files taken from the <a href="https://digitalcorpora.s3.amazonaws.com/s3_browser.html#corpora/files/CC-MAIN-2021-31-PDF-UNTRUNCATED/">common crawl corpus</a> at random we detected 23 files with a bad xref declaration. This works out to a roughly 0.5% failure rate in the sample set.</p>

<h3>PDF content starting at a non-zero offset</h3>

<p>In these files the <code>startxref</code> pointer is incorrect due to a non-zero PDF content start.</p>

<p>This happens when there's junk data before the <code>%PDF-</code> version header. This shifts every single byte offset in the file.
For example, the declared startxref pointer might be 960, but the actual location is at 970 because of the 10 bytes of junk data at the beginning:</p>

<pre><code>ten bytes!%PDF-1.4
%âãÏÓ
4 0 obj
(content follows)
endobj
% more content
xref
0 5
% ...
&lt;&lt; &gt;&gt;
startxref
960
%%EOF
</code></pre>

<p>In order to adjust for this you should capture the offset of the version header in your file. If the first pointer is incorrect you should also try the offset of the first pointer plus the content start offset. But you still need to check both.</p>

<p>This problem accounted for roughly 50% of errors in the sample set.</p>

<h3>The pointer is in the middle of the xref table</h3>

<p>For some files there is no content preceding the version header, however the pointer is still wrong and it points inside the xref table content at a random offset.</p>

<p>For example jumping directly to the specified offset takes you to this position:</p>

<pre><code>endobj xref
0 246
0000000000 65535 f 
0000184481 00000 n 
00000&lt;---
</code></pre>

<p>This was the case for roughly 5 files in the error set.</p>

<h3>The pointer is 'close' to the xref</h3>

<p>Similar to the previous error, here there is no version header offset but following the pointer takes you 'almost' to the xref. The most common cases were to be off by a single whitespace/newline, or
in the <code>endobj</code> marker of the previous object:</p>

<pre><code>endobj
--&gt; xref
0 4
</code></pre>

<p>or:</p>

<pre><code>--&gt;endobj
xref
0 7
</code></pre>

<h3>The pointer is correct but the xref offsets are incorrect</h3>

<p>Sometimes the pointer correctly jumps to the <code>xref</code> marker but if you parse the object offsets from the table they are incorrect. The table offsets can also be incorrect when the xref offset is also incorrect.</p>

<p>It can also be the case that offsets are correct for some objects in the table but wrong for others. This was the case for file 0002544.pdf in the sample set which had an initial pointer off-by-7. The locations in the xref table's first subsection were correct, then offsets that were off-by-4 bytes for subsequent subsections.</p>

<h3>The first pointer is correct but the previous offset is incorrect</h3>

<p>When a file has been modified the file's trailer (or xref stream dictionary) can contain a <code>/Prev</code> pointer. This is used to construct a chain of xref tables and streams. Several files had correct initial pointers
however when parsing the trailer's previous offset the second location was incorrect. One file contained a value of <code>0</code> for the previous pointer which indicates that it had incorrectly written the
default value, rather than an offset.</p>

<h3>The xref table is not well formatted</h3>

<p>Beyond the xref pointer issues seen in the sample set, the table structure itself can be malformed in unexpected ways.</p>

<p>The following examples were reported as Github issues for <a href="https://github.com/UglyToad/PdfPig">PdfPig</a>.</p>

<p>No linebreak after <code>xref</code>, for example:</p>

<pre><code>xref5 2
0000000000 65535 f 
0000134883 00000 n 
</code></pre>

<p>More object entries in a subsection than declared in the header, for example if only 2 objects are declared the table can contain more:</p>

<pre><code>xref
0 2
0000000000 65535 f 
0000000230 00000 n 
0000000520 00000 n 
0000001000 00000 n 
</code></pre>

<p>Garbage in the middle of the table, for example:</p>

<pre><code>xref
0 2
0000000000 65535 f
0000455.8483a a010 00000 n 
</code></pre>

<h2>Conclusion</h2>

<p>We looked at how parsing a PDF should proceed according to the specification. We then compared this with a survey of sample files where we saw a 0.5% error rate due to non-compliant files.
All tested PDF viewers (PDF.js, Adobe, Sumatra) were able to open these files because most parsers are extended to support non-compliant files.</p>

<p>This serves as a brief survey of the challenges of parsing a single part of the PDF specification (22 pages out of 1,300 total from version 1.7).</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[One Dataset. No Warning. Google Took Everything. You're Not Safe Either (103 pts)]]></title>
            <link>https://medium.com/@russoatlarge_93541/i-built-a-privacy-app-google-banned-me-over-a-dataset-used-in-ai-research-66bc0dfb2310</link>
            <guid>44779797</guid>
            <pubDate>Sun, 03 Aug 2025 21:03:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@russoatlarge_93541/i-built-a-privacy-app-google-banned-me-over-a-dataset-used-in-ai-research-66bc0dfb2310">https://medium.com/@russoatlarge_93541/i-built-a-privacy-app-google-banned-me-over-a-dataset-used-in-ai-research-66bc0dfb2310</a>, See on <a href="https://news.ycombinator.com/item?id=44779797">Hacker News</a></p>
Couldn't get https://medium.com/@russoatlarge_93541/i-built-a-privacy-app-google-banned-me-over-a-dataset-used-in-ai-research-66bc0dfb2310: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>