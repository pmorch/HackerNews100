<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 08 Aug 2023 13:00:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[TSMC, Bosch, Infineon, and NXP to build fab in Germany (171 pts)]]></title>
            <link>https://pr.tsmc.com/english/news/3049</link>
            <guid>37047053</guid>
            <pubDate>Tue, 08 Aug 2023 10:48:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pr.tsmc.com/english/news/3049">https://pr.tsmc.com/english/news/3049</a>, See on <a href="https://news.ycombinator.com/item?id=37047053">Hacker News</a></p>
Couldn't get https://pr.tsmc.com/english/news/3049: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Run Firefox on ChromeOS (183 pts)]]></title>
            <link>https://support.mozilla.org/en-US/kb/run-firefox-chromeos</link>
            <guid>37044625</guid>
            <pubDate>Tue, 08 Aug 2023 04:49:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.mozilla.org/en-US/kb/run-firefox-chromeos">https://support.mozilla.org/en-US/kb/run-firefox-chromeos</a>, See on <a href="https://news.ycombinator.com/item?id=37044625">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      
      <main role="main">
      
      
  <section id="document-list">
    <header>
      <div>
          
          <p><a href="https://support.mozilla.org/en-US/products/firefox" title="Firefox">
            <img src="https://assets-prod.sumo.prod.webservices.mozgcp.net/media/uploads/products/2020-04-14-08-36-13-8dda6f.png" height="48" width="48" alt="">
          </a></p>

          
        </div>
    </header>

    
    <article>
      
  
  
      <section id="doc-content">
    
      <p>Firefox can now be installed on Chromebooks and other devices running ChromeOS. This article will explain the system requirements needed in order to run Firefox on ChromeOS and how to set this up.
</p>
<h2 id="w_how-to-run-firefox-on-chromeos">How to run Firefox on ChromeOS</h2>
<p>To run Firefox on ChromeOS, you first need to ensure that your system meets the following requirements:
</p>
<h2 id="w_system-requirements">System Requirements</h2>
<ul><li><strong>x86 based Chromebook running ChromeOS 80 or later</strong>
</li></ul>
<p>You can check this by going to <code>chrome://version</code> in the Chrome browser address bar. <a href="https://support.google.com/chromebook/answer/177889">Follow these instructions from Google</a> if you need to upgrade your OS.
</p>
<ul><li><strong>Enable Linux support for ChromeOS</strong>
</li></ul>
<p><a href="https://support.google.com/chromebook/answer/9145439">Click here</a> to learn more about how to set up Linux (Beta) on your Chromebook.
</p><p>Once you've enabled Linux, check the Terminal to see if you have the correct version:
</p><p><code>cat /etc/os-release</code>
</p><p>If the version is not 10 (buster) or above, you'll need to run the update script:
</p><p><code>sudo bash /opt/google/cros-containers/bin/upgrade_container</code>
</p><p>This script will take some time depending on how fast your Chromebook and internet speeds are. Once it's done, you'll need to restart your Linux container. You can either right click the <em>Terminal</em> icon and select <strong>Shut down Linux (Beta)</strong> or just restart your Chromebook.
</p>
<ul><li><strong>Enable Flatpak</strong>
</li></ul>
<p>Flatpak is a new packaging format for Linux, <a href="https://flatpak.org/setup/Chrome%20OS/">click here</a> to learn how to add Flatpak support.
</p>
<h2 id="w_install-firefox">Install Firefox</h2>
<p>Once the setup is complete, you can install Firefox from a Terminal:
</p><p><code>flatpak install firefox</code>
</p>
    
  </section>

      

      
      
        
      
    </article>

    

    <section id="doc-contributors">
    <p>These fine people helped write this article:</p> 
  </section>

    <div>
    <p><img src="https://assets-prod.sumo.prod.webservices.mozgcp.net/static/volunteer.a3be8d331849774b.png" alt="Illustration of hands"></p><div>
      <h3>Volunteer</h3>
      <p>Grow and share your expertise with others. Answer questions and improve our knowledge base.</p>
      <p><strong><a href="https://support.mozilla.org/en-US/contribute">Learn More</a></strong></p>
    </div>
  </div>

    
      
  

    

  </section>

      </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Noclip.website: A digital museum of video game levels (293 pts)]]></title>
            <link>https://noclip.website</link>
            <guid>37043934</guid>
            <pubDate>Tue, 08 Aug 2023 02:55:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noclip.website">https://noclip.website</a>, See on <a href="https://news.ycombinator.com/item?id=37043934">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Ferromagnetic half levitation of LK-99-like synthetic samples (293 pts)]]></title>
            <link>https://arxiv.org/abs/2308.03110</link>
            <guid>37043447</guid>
            <pubDate>Tue, 08 Aug 2023 01:46:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2308.03110">https://arxiv.org/abs/2308.03110</a>, See on <a href="https://news.ycombinator.com/item?id=37043447">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2308.03110">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  We successfully synthesized polycrystalline LK-99-like ceramic samples with a
solid-state-sintering method. Powder X-ray diffraction shows that the main
contents are $\mathrm{Pb_{10-x}Cu_x(PO_4)_6O}$ and $\mathrm{Cu_2S}$, consistent
with recent reports [<a data-arxiv-id="2307.12037" href="https://arxiv.org/abs/2307.12037">arXiv:2307.12037</a>; <a data-arxiv-id="2308.01192" href="https://arxiv.org/abs/2308.01192">arXiv:2308.01192</a>]. In some small flaky
fragments, we successfully observed ``half levitation'' atop a
$\mathrm{Nd_2Fe_{14}B}$ magnet. Using magnetization measurements on such small
pieces, as well as on a large piece which does not exhibit the half levitation,
we show that the samples ubiquitously contain weak yet definitive soft
ferromagnetic components. We argue that, together with the pronounced shape
anisotropy of the small fragments, the soft ferromagnetism is sufficient to
explain the observed half levitation in strong vertical magnetic fields. Our
measurements do not indicate the presence of the Meissner effect, nor zero
resistance, in our samples, leading us to believe that our samples do not
exhibit superconductivity.

    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Kaizhen Guo [<a href="https://arxiv.org/show-email/19ee69e6/2308.03110">view email</a>]
      <br>
    <strong>[v1]</strong>
    
        Sun, 6 Aug 2023 13:34:28 UTC (15,105 KB)<br>
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Absence of superconductivity in LK-99 at ambient conditions (139 pts)]]></title>
            <link>https://arxiv.org/abs/2308.03544</link>
            <guid>37043196</guid>
            <pubDate>Tue, 08 Aug 2023 01:12:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2308.03544">https://arxiv.org/abs/2308.03544</a>, See on <a href="https://news.ycombinator.com/item?id=37043196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2308.03544">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  The report of synthesis of modified Lead apatite (LK-99) with evidence of
superconductivity at more than boiling water temperature has steered the whole
scientific community. There have been several failures to reproduce
superconductivity in LK-99 including partial successes. Here, we have continued
our efforts to synthesize phase pure LK-99 with improved precursors. The
process has been followed as suggested by Sukbae Lee et. al., [1,2]. The phase
purity of each precursor is evidenced by Powder X-ray diffraction (PXRD) and
well fitted by Rietveld refinement. The PXRD confirms the synthesis of phase
pure polycrystalline LK-99 with apatite structure. The freshly synthesized
sample does not show any signature of superconductivity levitation on a magnet
(diamagnetism). The magnetization measurements on SQUID also show that LK-99 is
diamagnetic at 280 K, there is no sign of superconductivity in LK-99 at room
temperature. Moreover, we have also performed first principle calculations to
investigate the electronic band structure of the LK-99 near Fermi level. Our
study verifies that the Cu doped lead apatite (LK-99) has bands crossing at
Fermi level, indicating generation of strong correlation in the system.

    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Veer Awana Dr [<a href="https://arxiv.org/show-email/c89e0e5c/2308.03544">view email</a>]
      <br>
    <strong>[v1]</strong>
    
        Mon, 7 Aug 2023 12:48:56 UTC (1,705 KB)<br>
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Malignant melanoma deploys elegant molecular mechanism to evade immune responses (199 pts)]]></title>
            <link>https://www.cancer.columbia.edu/news/cancers-cloaking-device-revealed</link>
            <guid>37042790</guid>
            <pubDate>Tue, 08 Aug 2023 00:17:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cancer.columbia.edu/news/cancers-cloaking-device-revealed">https://www.cancer.columbia.edu/news/cancers-cloaking-device-revealed</a>, See on <a href="https://news.ycombinator.com/item?id=37042790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
    
<figure><p><img data-srcset="https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_200/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=RyuNyun6 200w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_260/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=843deu_F 260w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_320/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=KT8D_rnH 320w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_400/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=3ccysXnh 400w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_520/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=i_cBDhna 520w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_640/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=f10Jz9Y_ 640w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_800/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=n8QOZ55i 800w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_1040/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=FSLZcxHQ 1040w, https://www.cancer.columbia.edu/sites/default/files/styles/cola_media_1280/public/media/images/2022-01/f68acf10-2375-11eb-b620-4faedbcca387.jpg?itok=sJSXKjOY 1280w" alt="" sizes="(min-width: 1200px) 560px, (min-width: 768px) 50vw, 100vw">
  
  </p>


<figcaption><p>Ben Izar, MD, PhD </p></figcaption>
</figure>
  </div>

<p>Malignant melanoma, a dangerous type of skin cancer, deploys an elegant molecular mechanism to evade natural immune responses and the therapies intended to boost them, according to new work led by scientists at the <a href="https://www.cancer.columbia.edu/cancer.columbia.edu">Herbert Irving Comprehensive Cancer Center</a> (HICCC). The findings, published in the current issue of Cancer Cell, explain how these tumors resist an important class of treatments, and suggests new strategies for attacking this and possibly other types of cancer as well.</p>
<p>Normally, the immune system eliminates abnormal cells, but cancers can elude it in various ways. For the past few years, <a href="https://www.cancer.columbia.edu/profile/benjamin-izar-md">Benjamin Izar, MD, PhD</a>, assistant professor of medicine at Columbia University <a href="https://www.vagelos.columbia.edu/">Vagelos College of Physicians and Surgeons</a> and a member of the HICCC, has been studying how malignant melanoma, the deadliest form of skin cancer, hides itself from immune cells. Initially, Izar’s team identified a signature pattern of gene expression changes associated with melanoma’s apparent cloaking device. “This signature was composed of a couple of hundred genes, so it was difficult to prioritize which of these may be the major functional driver,” says Izar.</p>
<p>More recent experiments singled out a cell surface protein called CD58; in laboratory experiments, tumor cells that suppressed their CD58 expression got much better at escaping immune surveillance. CD58 stimulates T cells, white blood cells especially important for anti-tumor responses. “The activity of T cells is regulated in a variety of ways, so they eliminate cancer or infected cells, but don’t go overboard causing damage to normal tissues,” says Izar. The findings hinted at how melanomas might be hiding from T cells, but didn’t provide the whole story. “This was the basis for asking ‘what are the mechanisms by which CD58 loss may drive cancer immune evasion?’” says Izar, who is the senior author on the new paper.</p>
<p>Izar’s team, including a network of collaborators at institutions across the US and Europe, developed several new techniques to find the answer. To validate their earlier laboratory results, the scientists analyzed samples from melanoma patients before and during treatment with immune-targeting therapies, confirming that real tumors decrease CD58 expression while evading immunity. Meanwhile, “Patricia Ho, an outstanding MD/PhD student in my lab, performed a cool [molecular and cellular] analysis to identify, in an unbiased fashion, the key regulator of CD58: [the protein] CMTM6,” says Izar. The investigators also developed a special mouse model carrying specific human genes and cell types to see exactly how CD58, CMTM6, and other proteins operate in tumors facing the immune system in real time.</p>
<p>The results show that CMTM6 acts as a stabilizer, inhibiting the degradation of both CD58, which stimulates T cell activity, and another cell surface protein called PD-L1, which inhibits it. In fact, these two opposing signaling proteins compete with each other for CMTM6, so by reducing the amount of the pro-T cell CD58, tumor cells free up more of the CMTM6 to stabilize the anti-T cell PD-L1. “This is a double whammy to T cell activity: loss of activation and increased inhibition,” says Izar.</p>
<p>The work helps explain how malignant melanomas readily acquire resistance to immune-targeting therapies and points to ways drug developers might reverse the signaling pattern to restore the tumor’s vulnerability, exchanging its cloaking device for a high-visibility jumpsuit.</p>
<p>“We found, to our knowledge, the first example of a regulatory protein … that balances this yin and yang of immuno-stimulatory and inhibitory signals on cancer cells,” says Izar, adding that “it’s extremely likely that this mechanism is important in other cancers as well.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[To opt out of Grammarly AI training requires business account with 500+ users (136 pts)]]></title>
            <link>https://front-end.social/@fox/110846484782705013</link>
            <guid>37042779</guid>
            <pubDate>Tue, 08 Aug 2023 00:15:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://front-end.social/@fox/110846484782705013">https://front-end.social/@fox/110846484782705013</a>, See on <a href="https://news.ycombinator.com/item?id=37042779">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[I would rather see my books get pirated than this (654 pts)]]></title>
            <link>https://janefriedman.com/i-would-rather-see-my-books-pirated/</link>
            <guid>37042561</guid>
            <pubDate>Mon, 07 Aug 2023 23:52:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://janefriedman.com/i-would-rather-see-my-books-pirated/">https://janefriedman.com/i-would-rather-see-my-books-pirated/</a>, See on <a href="https://news.ycombinator.com/item?id=37042561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
			
<figure><img decoding="async" width="1000" height="667" src="https://janefriedman.com/wp-content/uploads/2023/08/amazon_goodreads_AI-blogpost-1000x667.png" alt="Image: flames and smoke erupt from a garbage dumpster." srcset="https://janefriedman.com/wp-content/uploads/2023/08/amazon_goodreads_AI-blogpost-1000x667.png 1000w, https://janefriedman.com/wp-content/uploads/2023/08/amazon_goodreads_AI-blogpost-450x300.png 450w, https://janefriedman.com/wp-content/uploads/2023/08/amazon_goodreads_AI-blogpost-768x512.png 768w, https://janefriedman.com/wp-content/uploads/2023/08/amazon_goodreads_AI-blogpost.png 1200w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p><strong>Update: </strong>Hours after this post was published, my Goodreads profile was cleaned of the offending titles. However, the garbage books remain available for sale at Amazon with my name attached.</p>



<p>I did file a report with Amazon, complaining that these books were using my name and reputation without my consent. Amazon’s response: “Please provide us with any trademark registration numbers that relate to your claim.” When I replied that I did not have a trademark for my name, they closed the case and said the books would not be removed from sale.</p>



<hr>



<p>There’s not much that makes me angry these days about writing and publishing. I’ve seen it all. I know what to expect from Amazon and Goodreads. Meaning: I don’t expect much, and I assume I will be continually disappointed. Nor do I have the power to change how they operate. My energy-saving strategy: move on and focus on what you can control.</p>



<p>That’s going to become much harder to do if Amazon and Goodreads don’t start defending against the absolute garbage now being spread across their sites.</p>



<p>I know my work gets pirated and frankly I don’t care. (I’m not saying other authors shouldn’t care, but that’s not a battle worth my time today.)</p>



<p><strong>But here’s what does rankle me: </strong>garbage books getting uploaded to Amazon where my name is credited as the author. (<a href="https://www.amazon.com/dp/B0CDCNNX39?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" target="_blank" rel="noreferrer noopener">Here’s but one example.</a>) Whoever’s doing this is obviously preying on writers who trust my name and think I’ve actually written these books. I have not. Most likely they’ve been generated by AI.</p>



<p>It might be possible to ignore this nonsense on some level since these books aren’t receiving customer reviews (so far), and mostly they sink to the bottom of search results (although not always). At the very least, if you look at my <a href="https://www.amazon.com/stores/Jane-Friedman/author/B004KHXQ0U?ref=ap_rdr&amp;store_ref=ap_rdr&amp;isDramIntegrated=true&amp;shoppingPortalEnabled=true" target="_blank" rel="noreferrer noopener">author profile on Amazon</a>, these junk books don’t appear. A reader who applies some critical thinking might think twice before accepting these books as mine.</p>



<p>Still, it’s not great. And it falls on me, the author—the one with a reputation at stake—to get these misleading books removed from Amazon. I’m not even sure it’s possible. I don’t own the copyright to these junk books. I don’t exactly “own” my name either—lots of other people who are also legit authors share my name, after all. So on what grounds can I successfully demand this stop, at least in Amazon’s eyes? I’m not sure.</p>



<p><strong>To add insult to injury, these sham books are getting added to <a href="https://www.goodreads.com/author/show/625709.Jane_Friedman" target="_blank" rel="noreferrer noopener">my official Goodreads profile</a>. </strong>A reasonable person might think I control what books are shown on my Goodreads profile, or that I approve them, or at the very least I could have them easily removed. Not so.</p>



<p>If you need to have your Goodreads profile corrected—as far as the books credited to you—you have to reach out to volunteer “librarians” on Goodreads, which requires joining a group, then posting in a comment thread that you want illegitimate books removed from your profile.</p>



<p>When I complained about this on Twitter/X, an author responded that she had to report 29 illegitimate books in just the last week alone. 29!</p>



<p>With the flood of AI content now published at Amazon, sometimes attributed to authors in a misleading or fraudulent manner, how can anyone reasonably expect working authors to spend every week for the rest of their lives policing this? And if authors <em>don’t</em> police it, they will certainly hear about it, from readers concerned about these garbage books, and from readers who credulously bought this crap and have complaints. Or authors might not hear any thing at all, and lose a potential reader forever.</p>



<p>We desperately need guardrails on this landslide of misattribution and misinformation. Amazon and Goodreads, I beg you to create a way to verify authorship, or for authors to easily block fraudulent books credited to them. Do it now, do it quickly.</p>



<p>Unfortunately, even if and when you get these insane books removed from your official profiles, they will still be floating around out there, with your name, on two major sites that gets millions of visitors, just waiting to be “discovered.” And there’s absolutely nothing you can do about it.</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img src="https://janefriedman.com/wp-content/uploads/2023/05/cropped-00-J-Friedman-headshot-copy.jpg" width="100" height="100" alt="" itemprop="image"></p><div itemprop="description"><p>Jane Friedman&nbsp;(<a href="http://twitter.com/janefriedman">@JaneFriedman</a>) has 25 years of experience in the media &amp; publishing industry. She is the publisher of <a href="http://hotsheetpub.com/">The Hot Sheet</a>, the essential newsletter on the publishing industry for authors, and was named Publishing Commentator of the Year by Digital Book World in 2019.</p>
<p>In addition to being a professor with The Great Courses (<a href="http://www.thegreatcourses.com/courses/how-to-publish-your-book.html">How to Publish Your Book</a>), she is the author of <a href="http://amzn.to/2yBgAfl"><em>The Business of Being a Writer</em></a> (University of Chicago Press), which received a starred review from Library Journal.</p>
<p>Jane speaks regularly at conferences and industry events such as Digital Book World and Frankfurt Book Fair, and has served on panels with the National Endowment for the Arts and the Creative Work Fund. <a href="https://janefriedman.com/about">Find out more.</a></p>
</div></div>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Overworked and Underpaid, VFX Workers Vote to Unionize at Marvel (364 pts)]]></title>
            <link>https://www.vulture.com/2023/08/vfx-workers-vote-to-unionize-at-marvel-for-the-first-time.html</link>
            <guid>37041394</guid>
            <pubDate>Mon, 07 Aug 2023 21:45:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vulture.com/2023/08/vfx-workers-vote-to-unionize-at-marvel-for-the-first-time.html">https://www.vulture.com/2023/08/vfx-workers-vote-to-unionize-at-marvel-for-the-first-time.html</a>, See on <a href="https://news.ycombinator.com/item?id=37041394">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="www.vulture.com/_components/article/instances/cll0zor9q000j0ichxijvyiym@published" data-content-channel="Movies" data-crosspost="" data-type="Breaking-News-Original Reporting" data-syndication="original" data-headline="Overworked and Underpaid, VFX Workers Vote to Unionize at Marvel" data-authors="Chris Lee" data-publish-date="2023-08-07" data-tags="movies, marvel, disney, vfx, iatse, iatse strike, writer's strike 2023, 2023 sag strike, daredevil: born again, loki, 'historic first step', vulture homepage lede, vulture section lede" data-issue-date="" data-components-count="12">


  
  
  
  <header>
    
  </header>
  <section>
    <div data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/31e/1db/22742e68cb7da900d5bd3968c1b7a0e19b-Marvelnew.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/31e/1db/22742e68cb7da900d5bd3968c1b7a0e19b-Marvelnew.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/31e/1db/22742e68cb7da900d5bd3968c1b7a0e19b-Marvelnew.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/31e/1db/22742e68cb7da900d5bd3968c1b7a0e19b-Marvelnew.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/31e/1db/22742e68cb7da900d5bd3968c1b7a0e19b-Marvelnew.2x.rhorizontal.w700.jpg" width="700" height="467"> <img src="https://pyxis.nymag.com/v1/imgs/31e/1db/22742e68cb7da900d5bd3968c1b7a0e19b-Marvelnew.rhorizontal.w700.jpg" data-content-img="" width="700" height="467" fetchpriority="high"> </picture>
          </div>
            <div>
              <p>
                  A supermajority of Marvel’s 52-member on-set production crew signed authorization cards indicating they wish to be represented by the International Alliance of Theatrical Stage Employees.
                <span>Photo: Marvel Entertainment</span>
              </p>
            </div>
              </div>
            <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zor9q000i0ichdt2irj8l@published" data-word-count="100">Call it the Hollywood-labor-organizing version of <em>Avengers Assemble!</em> On the heels of more than a year’s worth of <a href="https://www.vulture.com/article/a-vfx-artist-on-what-its-like-working-for-marvel.html">damning</a> <a href="https://www.vulture.com/2023/02/marvel-vfx-workers-on-ant-man-and-the-wasp-quantumania.html">disclosures</a> around Marvel Studios’ systematic overworking and underpayment of visual-effects workers on its blockbuster movies and streaming series, VFX crews at Marvel have finally petitioned to demand <a href="https://www.vulture.com/2023/01/inside-the-vfx-union-brewing-in-hollywood.html">union recognition</a> from the studio. On Monday, a group of more than 50 on-set employees filed a petition for an election to be represented by the International Alliance of Theatrical Stage Employees (IATSE) with the National Labor Relations Board. The workers are asking for the election to be held as early as August 21.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp3m3000h3b6xd2ypja31@published" data-word-count="76">This marks the first time visual-effects professionals have banded together to demand the same rights, wage protections, and professional watchdog oversight enjoyed by workers in almost every other segment of the entertainment industry. The supermajority of Marvel’s 52-member on-set production crew signed authorization cards to indicate they wish to be represented by the powerful labor union representing some 170,000 artisans, technicians, stagehands, and craftspeople across TV, film, and live theater in the United States and Canada.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp3of000i3b6x0ofvhhkt@published" data-word-count="64">“For almost half a century, workers in the visual-effects industry have been denied the same protections and benefits their coworkers and crewmates have relied upon since the beginning of the Hollywood film industry,” VFX organizer for IATSE Mark Patch said in a statement. “This is a historic first step for VFX workers coming together with a collective voice demanding respect for what we do.”</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp3q5000j3b6xgo8q7cb1@published" data-word-count="120">In an era when around 90 percent of all films in release feature varying degrees of VFX fine-tuning (and it’s not uncommon for a show like <em>Stranger Things</em> to showcase up to <a href="https://www.hollywoodreporter.com/tv/tv-features/stranger-things-vfx-sound-artists-creating-vecna-1235199328/">4,400 visual-effects shots</a> across a single season), workers within the field have remained stubbornly, confoundingly unrepresented by any professional union or guild. While fellow <a href="https://www.studiobinder.com/blog/what-is-below-the-line-definition/">below-the-line</a> workers in such divisions as costumes and wardrobe; hair and makeup; lighting, props and paint; and script supervision have been historically championed by IATSE, underappreciated VFX professionals have been unable to claim benefits such as paid overtime and health care, and have been at the mercy of pronounced labor shortages and managers’ unrealistic deadlines — despite the workers’ increasing indispensability within popular culture.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp3s5000k3b6xlja3408c@published" data-word-count="52">“Turnaround times don’t apply to us, protected hours don’t apply to us, and pay equity doesn’t apply to us,” said VFX coordinator Bella Huffman. “Visual effects must become a sustainable and safe department for everyone who’s suffered far too long and for all newcomers who need to know they won’t be exploited.”</p>

  

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp3u0000l3b6xw4ostcgd@published" data-word-count="124">The petition for voluntary union recognition from Marvel and its parent company, Disney, arrives amid what the Los Angeles <em>Times</em> has taken to calling the “hot labor summer”: a cultural inflection point when both the Writers Guild and Screen Actors Guild are on strike against the Alliance of Motion Picture and Television Producers, <a href="https://www.vulture.com/article/sag-strike-movies-tv-shows-paused.html">halting productions</a> across Hollywood and throwing the upcoming movie-release corridor into chaos. Just as crucially, however, VFX’s newly strident demands for a seat at the collective-bargaining table also play out against a backdrop of increasing fan displeasure with (and <a href="https://www.vulture.com/article/ant-man-and-the-wasp-quantumania-movie-review-marvel.html">critical opprobrium</a> toward) the quality of computer-generated imagery in Marvel Studios movies and series, coming perhaps not coincidentally just months after the firing of Marvel’s president of postproduction and VFX, <a href="https://www.vulture.com/2023/04/victoria-alonso-firing-disney-marvel.html">Victoria Alonso</a>.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp3w0000m3b6x2ygyuj0m@published" data-word-count="42">Even with the group’s NLRB petition, a VFX workers strike is not out of the question; it is perhaps the most battle-tested and surefire route to union recognition. (Representatives at Disney and Marvel did not respond to requests for comment from Vulture.)</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp3y6000n3b6xff72l4i2@published" data-word-count="116">Leading off the collective-bargaining push with Marvel’s on-set VFX specialists — data wranglers, production managers, witness camera operators, and assistants employed on such MCU series as <a href="https://www.vulture.com/tv/loki/"><em>Loki</em></a> and <em>Daredevil: Born Again, </em>as opposed to the people supplying visual effects in postproduction — arrives as no accident. Thanks to the studio’s fire hose of movie and TV series output (it will oversee the release of five movies and four shows in 2023 alone), Marvel is regarded in VFX circles as the industry’s biggest “bully,” with the capacity to flood effects houses with more work than they know what to do with or ruin careers and standings of those who do not live up to Marvel’s sky-high expectations.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp406000o3b6xbsw691ku@published" data-word-count="188">Hence, as the thinking goes, securing union recognition for a relatively small yet high-profile group of Marvel’s so-called “production-side” professionals would stand as proof of concept for the overall viability of an industry-wide unionization push. Production-side unity would lead to solidarity at postproduction houses, which would then, in turn, unionize one by one, leading to an inevitable tipping point. The template for this sort of thing was set in the animation world last February when production workers for Adult Swim’s <em>Rick &amp; Morty</em> and Hulu’s <em>Solar Opposites </em><a href="https://www.cartoonbrew.com/artist-rights/production-workers-on-rick-and-morty-and-solar-opposites-file-to-unionize-213740.html">filed a petition</a> with the NLRB for a union election, sparking a new wave of unionization for workers throughout the animation industry by becoming the first to be represented by the IATSE-affiliated Animation Guild. Soon after, workers at the Los Angeles branch of the award-winning production house <a href="https://titmouse.net/">Titmouse</a> joined the guild to begin collective bargaining for their first union contract. And those efforts ultimately compelled a coalition of production workers on the shows <em>American Dad</em>, <em>Family Guy,</em> and <em>The Simpsons</em> <a href="https://deadline.com/2022/07/the-simpsons-family-guy-american-dad-workers-repped-by-animation-guild-1235058303/">to also unionize</a> under the Animation Guild, teeing up new collective-bargaining negotiations for increased benefits with 20th Television Animation last summer.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cll0zp41r000p3b6x2o37ogua@published" data-word-count="78">“We are witnessing an unprecedented wave of solidarity that’s breaking down old barriers in the industry and proving we’re all in this fight together,” said IATSE International president Matthew D. Loeb. “That doesn’t happen in a vacuum. Entertainment workers everywhere are sticking up for each other’s rights; that’s what our movement is all about. I congratulate these workers on taking this important step and using their collective voice. I urge Marvel Studios to voluntarily recognize their union immediately.”</p>

  

    </div>

    


          



      <span>For the First Time, VFX Workers Vote to Unionize at Marvel</span>



  </section>

  
  
</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to stop the “login with Google” pop up window? (184 pts)]]></title>
            <link>https://support.google.com/accounts/thread/212592288/how-to-stop-the-login-with-google-pop-up-window?hl=en</link>
            <guid>37041047</guid>
            <pubDate>Mon, 07 Aug 2023 21:15:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.google.com/accounts/thread/212592288/how-to-stop-the-login-with-google-pop-up-window?hl=en">https://support.google.com/accounts/thread/212592288/how-to-stop-the-login-with-google-pop-up-window?hl=en</a>, See on <a href="https://news.ycombinator.com/item?id=37041047">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <header role="none"><div data-stats-ve="57"><header ng-non-bindable="" id="gb" role="banner"><div><div><div id="material-bar-custom-product-name"><p><a href="https://support.google.com/accounts">Google Account Help</a></p></div><div><form action="/accounts/search" method="get" role="search"></form></div></div><div ng-non-bindable="" data-ogsr-up=""><p><a href="https://accounts.google.com/ServiceLogin?hl=en&amp;passive=true&amp;continue=http://support.google.com/accounts/thread/212592288/how-to-stop-the-login-with-google-pop-up-window%3Fhl%3Den&amp;ec=GAZAdQ" target="_top"><span>Sign in</span></a></p></div></div></header></div><div role="menubar"><div><p><a href="https://support.google.com/" role="link">Google Help</a></p></div><ul role="menu"><p><a href="https://support.google.com/accounts/?hl=en" id="onebar-helpcenter" role="link"><li>Help Center</li></a><a href="https://support.google.com/accounts/community?hl=en" id="onebar-community" role="link"><li>Community</li></a><a href="https://myaccount.google.com/" id="onebar-product" role="link"><li>Google Account</li></a></p><p id="sc-burger-bottom" role="none"><a href="https://www.google.com/intl/en/privacy.html" id="onebar-privacy-policy" role="link"><li>Privacy Policy</li></a><a href="https://www.google.com/accounts/TOS" id="onebar-tos" role="link"><li>Terms of Service</li></a><a href="about:invalid#zjslayoutz" id="onebar-feedback" role="link"><li>Submit feedback</li></a></p></ul></div>   <div role="dialog"><p>Send feedback on...</p><div role="radiogroup"><div data-stats-id="send-content-feedback-radio" onclick="document.getElementById('content-feedback-radio').click();" role="radio"><p><label for="content-feedback-radio" role="presentation">This help content &amp; information</label></p></div><div data-stats-id="send-helpcenter-feedback-radio" onclick="document.getElementById('helpcenter-feedback-radio').click();" role="radio"><p><label for="helpcenter-feedback-radio" role="presentation">General Help Center experience</label></p></div></div></div><div role="navigation" data-stats-ve="32"><div @i18n:aria-label="Aria label for the helpcenter sections element" aria-label="Helpcenter sections"><ul><li><a aria-current="false" href="https://support.google.com/accounts/?hl=en">Help Center</a></li><li><a aria-current="true" href="https://support.google.com/accounts/community?hl=en">Community</a></li><li><a aria-current="false" href="https://support.google.com/accounts/announcements/12343128">Get Started with Google Account</a></li></ul></div><div><p><span><a aria-label="Google Account (Open in a new window)" data-stats-ve="36" href="https://myaccount.google.com/" target="_blank"><span itemprop="title">Google Account</span><svg viewBox="0 0 24 24"><path d="M19 19H5V5h7V3H5c-1.11 0-2 .9-2 2v14c0 1.1.89 2 2 2h14c1.1 0 2-.9 2-2v-7h-2v7zM14 3v2h3.59l-9.83 9.83 1.41 1.41L19 6.41V10h2V3h-7z"></path></svg></a></span>    </p></div></div>   </header> <div id="hcfe-content" role="main">            <article class="page" sc-render-smart-button="false" itemscope="">         </article>       </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raku: A Language for Gremlins (346 pts)]]></title>
            <link>https://buttondown.email/hillelwayne/archive/raku-a-language-for-gremlins/</link>
            <guid>37040681</guid>
            <pubDate>Mon, 07 Aug 2023 20:42:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.email/hillelwayne/archive/raku-a-language-for-gremlins/">https://buttondown.email/hillelwayne/archive/raku-a-language-for-gremlins/</a>, See on <a href="https://news.ycombinator.com/item?id=37040681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                

                
                    
                        <p>I just added a big new section to learntla: <a href="https://learntla.com/topics/optimization.html" target="_blank">Optimizing TLA+ Model Checking</a>. I take a spec and then show 15 different optimizations, many of them getting a 10x runtime improvement. Patreon notes <a href="https://www.patreon.com/posts/notes-on-tla-87093195" target="_blank">here</a>. Besides that I've done very little writing the last couple weeks. I'm just in a slump: I sit down to write and the words all come out wrong. It happens sometimes and there's nothing to do about it but wait it out. </p>
<p>So instead of working I've been learning <a href="https://raku.org/" target="_blank">Raku</a>.<sup id="fnref:perl6"><a href="#fn:perl6">1</a></sup> It originally got on my radar after I ranted about <a href="https://buttondown.email/hillelwayne/archive/i-am-disappointed-by-dynamic-typing/" target="_blank">dynamic languages</a> and a couple of users told me I'd like Raku. I finally checked it out last week to see if it'd make a good "calculator language". I use a hodgepodge of Python, <a href="https://hillelwayne.com/post/j-notation/" target="_blank">J</a>, <a href="https://hillelwayne.com/post/frink/" target="_blank">Frink</a>, and Excel to do math and they all have their own big drawbacks, so it'd be nice if Raku could round them out.</p>
<p>After several days of experiments, I'm at a loss of <em>how</em> to describe Raku. The best I can come up with is that the language was designed by a bunch of really intelligent gremlins. Gremlins who spent a lot of time gathering feedback from other gremlins. </p>
<h3>Weird Operators</h3>
<p>Raku has no qualms about using Unicode operators. You check set membership with ∈. There's also ∉, ∋, and ∌. It's also fine with alphanumeric infix operators. String repetition op is <code>x</code>. Function composition is <code>o</code>.</p>
<div><pre><span></span><code>&gt; <span>"a"</span> <span>x</span> <span>3</span>
<span>aaa</span>
&gt; <span>my</span> <span>&amp;f</span> = <span>&amp;sqrt</span> <span>o</span> <span>&amp;abs</span>
{<span>noise</span>}
&gt; <span>f</span> -<span>3</span>
<span>1.7320508075688772</span>
</code></pre></div>

<p><code>X</code> gives you the cross product of a list, <code>Xf</code> applies <code>f</code> to each element of the cross product, <code>Zf</code> does the same with zip.</p>
<div><pre><span></span><code>&gt; <span>&lt;a b c&gt;</span> <span>X</span> <span>&lt;1 2 3&gt;</span>
((<span>a</span> <span>1</span>) (<span>a</span> <span>2</span>) (<span>a</span> <span>3</span>) (<span>b</span> <span>1</span>) (<span>b</span> <span>2</span>) (<span>b</span> <span>3</span>) (<span>c</span> <span>1</span>) (<span>c</span> <span>2</span>) (<span>c</span> <span>3</span>))
&gt; <span>&lt;a b c&gt;</span> <span>Xx</span> <span>&lt;1 2 3&gt;</span>
(<span>a</span> <span>aa</span> <span>aaa</span> <span>b</span> <span>bb</span> <span>bbb</span> <span>c</span> <span>cc</span> <span>ccc</span>)
&gt; <span>&lt;a b c&gt;</span> <span>Zx</span> <span>&lt;1 2 3&gt;</span>
(<span>a</span> <span>bb</span> <span>ccc</span>)
</code></pre></div>

<p>If <code>f</code> is an infix operator, then <code>[f]</code> reduces a list and <code>[\f]</code> accumulates it: </p>
<div><pre><span></span><code>&gt; [+] <span>&lt;1 2 3 4 5&gt;</span>
<span>15</span>
&gt; [\+] <span>&lt;1 2 3 4 5&gt;</span>
(<span>1</span> <span>3</span> <span>6</span> <span>10</span> <span>15</span>)
</code></pre></div>

<p><code>~~</code> is the "anything goes" matcher.</p>
<div><pre><span></span><code>&gt; <span>"abc"</span> ~~ <span>"abc"</span> <span># do the strings match?</span>
<span>True</span>
&gt; <span>"abc"</span> ~~ <span>Str</span> <span># is abc a string?</span>
<span>True</span>
&gt; <span>"abc"</span> ~~ {.<span>chars</span> == <span>3</span>} <span># is abc length 3?</span>
<span>True</span>
&gt; <span>so</span> <span>"abc"</span> ~~<span> /^b/</span> <span>#does abc start with b?</span>
<span>False</span>
</code></pre></div>

<p>Finally, there's <code>...</code>.</p>
<div><pre><span></span><code>&gt; <span>0</span>,<span>1</span>,<span>2</span>..<span>.10</span>
(<span>0</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span> <span>8</span> <span>9</span> <span>10</span>)

&gt; <span>0</span>,<span>2</span>,<span>4</span>..<span>.10</span>
(<span>0</span> <span>2</span> <span>4</span> <span>6</span> <span>8</span> <span>10</span>)

&gt; <span>1</span>,<span>2</span>,<span>4</span>..<span>.10</span>
(<span>1</span> <span>2</span> <span>4</span> <span>8</span>)
</code></pre></div>

<h3>Defining operators</h3>
<p>So you know how some languages let you define infix operators? Raku lets you also define new circumfix and <em>postcircumfix</em> operators.</p>
<div><pre><span></span><code><span># circumfix</span>
<span>sub</span> <span>circumfix:</span><span>&lt;[∀ zz&gt;</span>(<span>$inner</span>){<span>sum</span>(<span>$inner</span>)}
&gt; [∀ <span>1</span>,<span>3</span>,<span>5</span>..<span>.10</span> <span>zz</span>
<span>25</span>

<span># vector inner product!</span>
<span>sub</span> <span>postcircumfix:</span><span>&lt;| ⟩&gt;</span>(<span>@left</span>, <span>@inside</span>){[+] (<span>@left</span> <span>Z</span>* <span>@inside</span>)}
&gt; <span>&lt;1 2 3&gt;</span>|<span>&lt;4 5 6&gt;</span>⟩
<span>32</span>
</code></pre></div>

<p>In addition to left- and right-associative infix operators, you can define operators to be chain associative (like how <code>x &lt; y &lt; z</code> is <code>x &lt; y &amp;&amp; y &lt; z</code>) and "list" associative (<code>a op b op c</code> is <code>op(a, b, c)</code>).</p>
<h3>Multiple dispatch</h3>
<p>So Raku has "multiple dispatch", meaning that you overload a function with multiple different type signatures and it will choose the appropriate one. </p>
<div><pre><span></span><code><span># @ is for iterable types</span>

<span>multi</span> <span>f</span>(<span>$x</span>,<span>@arr</span>) {<span>@arr</span>.<span>map</span>(-&gt; <span>$elem</span> {<span>$elem</span> + <span>$x</span>})}
<span>multi</span> <span>f</span>(<span>@arr</span>, <span>$x</span>) {<span>@arr</span>.<span>map</span>(-&gt; <span>$elem</span> {<span>$elem</span> + <span>$x</span>})}
<span>multi</span> <span>f</span>(<span>@arr1</span>, <span>@arr2</span>) {<span>@arr1</span> <span>Z</span>+ <span>@arr2</span>}

&gt; <span>f</span>(<span>2</span>, <span>&lt;1 2 3&gt;</span>);
(<span>3</span> <span>4</span> <span>5</span>)

&gt; <span>f</span>(<span>&lt;1 2 3&gt;</span>, <span>&lt;3 4 5&gt;</span>)
(<span>4</span> <span>6</span> <span>8</span>)
</code></pre></div>

<p>This isn't weird, lots of languages have multiple dispatch. What <em>is</em> weird is that you can also dispatch based on a <em>runtime predicate of the value</em>.</p>
<div><pre><span></span><code><span>multi</span> <span>my_abs</span>(<span>Int</span> <span>$x</span> <span>where</span> {<span>$x</span> &gt; <span>0</span>}) {<span>$x</span>}
<span>multi</span> <span>my_abs</span>(<span>Int</span> <span>$x</span>) {-<span>$x</span>}

&gt; <span>map</span> <span>&amp;my_abs</span>, <span>&lt;-4 4&gt;</span>
</code></pre></div>

<p>Also the signature of a function is a first-class value, as are the parameters in the signature.</p>
<h3>Miscellaneous Things</h3>
<ul>
<li>If you define a <code>MAIN</code> function, any parameters you give it will be automatically turned into CLI flags.</li>
<li>Objects have way more preloaded methods than I've seen in any language, and I used to do Rails. The <a href="https://docs.raku.org/type/List" target="_blank">List object</a> has methods for getting all permutations, all k-combinations, and all sliding windows.</li>
<li><a href="https://docs.raku.org/type/Junction" target="_blank">Junctions</a> are this weird type-value-thing for doing multiple comparisons at once. <code>1|2</code> expands to <code>any(1, 2)</code>, so <code>1 &lt; 1|2</code>. <code>1&amp;2</code> expands to <code>all(1, 2)</code>, so <code>1 !&lt; 1&amp;2</code>.<ul>
<li>Oh yeah and you can negate any infix operator by prefixing it with <code>!</code>.</li>
</ul>
</li>
<li>Raku is the only language I've ever seen that has <code>$kebab-case</code> names <em>and</em> infix subtraction, I'm guessing because sigils disambiguate <code>x-y</code>.</li>
<li>The <a href="https://docs.raku.org/language/regexes" target="_blank">regex syntax</a> isn't backwards compatible with Perl 5. For <em>thirty years</em> languages followed the PCRE "standard" and Perl 6 just…  threw it all away.</li>
</ul>
<hr>
<p>That's just a tiny slice of all the weird Raku features, since I've only been looking at calculator applications so far. I haven't even learned about the object system, packages, or <a href="https://docs.raku.org/language/grammar_tutorial" target="_blank">grammars</a>! And even so, I <em>still</em> left out a ton of stuff. Like in a function body, <code>samewith</code> will call the same function with new arguments.</p>
<p>I think if I had to maintain a Raku legacy codebase my brain would explode. I have no idea how people would manage to write this language In The Large. At the same time, it seems incredible for programming In The Small. One-off scripts, computations, personal tooling, all the kinds of things I wanted to do with it in the first place.</p>
<p>I've also seen some really frustrating things:</p>
<ol>
<li>The documentation is really poor and the heavy reliance on symbols makes it hard to search for things. I've learned a lot of poorly-documented languages but Raku is much bigger and more complex than any of them and it can be real demotivating.</li>
<li>The REPL crashes on Windows if I type in any Unicode. The compiler is also pretty slow, with even small files taking half a second or more. Iterating on things is painful.</li>
<li>I hate the sigil thing. I spent half an hour debugging a problem because I wrote <code>$x</code> instead of <code>@x</code>.</li>
</ol>
<p>Overall? Maybe I'm just a gremlin at heart, but I think I like this language and want it to succeed. I assume I'll have a more balanced picture thoughts after I use it in anger. I just hope that over time the compile times and documentation improve.</p>

                    
                

                
                    <p><em>If you're reading this on the web, you can subscribe <a href="https://buttondown.email/hillelwayne" target="_blank">here</a>. Updates are 6x a month. My main website is <a href="https://www.hillelwayne.com/" target="_blank">here</a>.</em></p>
                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Doculite – Use SQLite as a Document Database (137 pts)]]></title>
            <link>https://www.npmjs.com/package/doculite</link>
            <guid>37040359</guid>
            <pubDate>Mon, 07 Aug 2023 20:14:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npmjs.com/package/doculite">https://www.npmjs.com/package/doculite</a>, See on <a href="https://news.ycombinator.com/item?id=37040359">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article> <div id="readme"><h2>Doculite</h2>
<p>DocuLite lets you use SQLite like Firebase Firestore. It's written in Typescript and an adapter on top of sqlite3 and sqlite. It support listeners on documents, collections, and basic queries. Feedback &amp; Bugs to <a href="mailto:thedoculite@gmail.com">thedoculite@gmail.com</a>.
This is early work, so please treat it appropriately.</p>
<h2>Current features</h2>
<h2>1. Initialize a DB</h2>
<p>Example:</p>
<pre><code>import { Database } from "doculite"
const db = new Database();
</code></pre>
<h2>2. Create Collections and Set Documents</h2>
<p>Collections are created on first insertion of a document. They are represented by a SQLite Table.</p>
<pre><code>// create ref to the doc. Doc ID optional.

const usersRef = db.collection("users").doc("123");
const refWithoutId = db.collection("users").doc();

// Any valid Javascript object that can be parsed to valid JSON can be inserted as a document.

await usersRef.set({ username: "John Doe", createdAt: "123", updatedAt: "123" });
await refWithoutId.set({ username: "Jane Doe" });

</code></pre>
<h2>3. Get a particular document</h2>
<pre><code>// define ref
const usersRef = db.collection("users").doc("123");
// get
const user = await usersRef.get();
// print
console.log(user); // prints { username: "John Doe" };

</code></pre>
<h2>4. Update Documents in Collections</h2>
<pre><code>// ref
const usersRef = db.collection("users").doc("123");

// Properties existing on both old and new object will be updated.
// Properties only existing on the new object will be added.

// If merge is false, properties only present on the old object will be deleted.
// Merge is true by default

await ref.set({ username: "DERP Doe", updatedAt: "345" }, { merge: true });
// document in DB is now { username: "DERP Doe", updatedAt: "345", createdAt: "123" }

await ref.set({ username: "DERP Doe", updatedAt: "345" }, { merge: false });
// document in DB is now { username: "DERP Doe", updatedAt: "345" }

</code></pre>
<h2>5. Delete Documents in Collection</h2>
<pre><code>const db = new Database();

const ref = db.collection("users").doc("deletable");

await ref.set({ username: "deletableUsername", updatedAt: 123123 });

await ref.delete();

const doc = await ref.get();

console.log(doc) // prints null

</code></pre>
<h2>6. Listen to real-time updates of documents.</h2>
<pre><code>
// ref to doc
const ref = db.collection("users").doc("123");

// snapshot listener returns unsubscribe function
const unsub = ref.onSnapshot((doc) =&gt; {
console.log("Omg the user doc is updating!", doc?.username);
});

await ref.set({ username: "SHEESH Doe", updatedAt: 2 });
// prints: `Omg the user doc is updating! SHEESH Doe`

// unsub
unsub();

</code></pre>
<h2>7. Query Documents in a collection by equality comparison</h2>
<pre><code>
const usersRef = db.collection("users");

await usersRef.doc().set({ username: "Doculite", updatedAt: 234 });

const query = usersRef.where("username", "Doculite");

const docs = await query.get();

const user = docs[0]

console.log(user.username) // prints `Doculite`

</code></pre>
<h2>Potential roadmap:</h2>
<ol>
<li>Better query-based system</li>
<li>Stability and speed updates</li>
<li>Delete collections</li>
<li>Subcollections</li>
<li>Listeners on queries / multiple documents</li>
<li>Queries with other comparison operators (&lt;, &gt;, &gt;=, &lt;=, contains, etc.)</li>
<li>Queries for multiple variables (without indexes, probably)</li>
<li>Queries with Full Text Search (without indexes, probably)</li>
</ol>
<pre><code>
</code></pre>
</div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[True shape of lithium revealed for the first time (182 pts)]]></title>
            <link>https://phys.org/news/2023-08-true-lithium-revealed.html</link>
            <guid>37040205</guid>
            <pubDate>Mon, 07 Aug 2023 20:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2023-08-true-lithium-revealed.html">https://phys.org/news/2023-08-true-lithium-revealed.html</a>, See on <a href="https://news.ycombinator.com/item?id=37040205">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/true-shape-of-lithium.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/true-shape-of-lithium.jpg" data-sub-html="UCLA researchers developed a way to deposit lithium metal onto a surface while avoiding a layer of corrosion that usually forms. Without that corrosion, the metal takes a previously unseen form, a tiny 12-sided figure. Credit: Li Lab/UCLA">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/true-shape-of-lithium.jpg" alt="True shape of lithium revealed for the first time" title="UCLA researchers developed a way to deposit lithium metal onto a surface while avoiding a layer of corrosion that usually forms. Without that corrosion, the metal takes a previously unseen form, a tiny 12-sided figure. Credit: Li Lab/UCLA" width="800" height="530">
             <figcaption>
                UCLA researchers developed a way to deposit lithium metal onto a surface while avoiding a layer of corrosion that usually forms. Without that corrosion, the metal takes a previously unseen form, a tiny 12-sided figure. Credit: Li Lab/UCLA
            </figcaption>        </figure>
    </div>
<p>Rechargeable lithium-ion batteries power smartphones, electric vehicles and storage for solar and wind energy, among other technologies.

										  
											        </p>
										 
										 											  
<p>They descend from another technology, the lithium-metal battery, that hasn't been developed or adopted as broadly. There's a reason for that: While lithium-metal batteries have the potential to hold about double the energy that lithium-ion batteries can, they also present a far greater risk of catching fire or even exploding.
</p><p>Now, a study by members of the California NanoSystems Institute at UCLA reveals a fundamental discovery that could lead to safer lithium-metal batteries that outperform today's lithium-ion batteries. The research was published today in the journal <i>Nature</i>.
</p><p>Metallic lithium reacts so easily with chemicals that, under normal conditions, corrosion forms almost immediately while the metal is being laid down on a surface such as an electrode. But the UCLA investigators developed a technique that prevents that corrosion and showed that, in its absence, lithium atoms assemble into a surprising shape—the rhombic dodecahedron, a 12-sided figure similar to the dice used in role-playing games like Dungeons and Dragons.
</p><p>"There are thousands of papers on lithium metal, and most descriptions of the structure is qualitative, such as 'chunky' or 'column-like,'" said Yuzhang Li, the study's corresponding author, an assistant professor of chemical and biomolecular engineering at the UCLA Samueli School of Engineering and a member of CNSI.
</p><p>"It was surprising for us to discover that when we prevented surface corrosion, instead of these ill-defined shapes, we saw a singular polyhedron that matches theoretical predictions based on the metal's crystal structure. Ultimately, this study allows us to revise how we understand lithium-metal batteries."
</p><p>At tiny scales, a lithium-ion battery stores positively charged lithium atoms in a cage-like structure of carbon that coats an electrode. By contrast, a lithium-metal battery instead coats the electrode with metallic lithium. That packs 10 times more lithium into the same space compared to <a href="https://phys.org/tags/lithium-ion+batteries/" rel="tag">lithium-ion batteries</a>, which accounts for the increase in both performance and danger.
</p><p>The process for laying down the lithium coating is based on a 200-plus-year-old technique that employs electricity and solutions of salts called electrolytes. Often, the lithium forms microscopic branching filaments with protruding spikes. In a battery, if two of those spikes crisscross, it can cause a <a href="https://phys.org/tags/short+circuit/" rel="tag">short circuit</a> that could lead to an explosion.


											  													    </p>
											  
											  <p>The revelation of the true shape of lithium—that is, in the absence of corrosion—suggests that the explosion risk for lithium-metal batteries can be abated, because the atoms accumulate in an orderly form instead of one that can crisscross. The discovery could also have substantial implications for high-performance energy technology.
</p><p>"Scientists and engineers have produced over two decades' worth of research into synthesizing metals including gold, platinum and silver into shapes such as nanocubes, nanospheres and nanorods," Li said. "Now that we know the shape of lithium, the question is, Can we tune it so that it forms cubes, which can be packed in densely to increase both the safety and performance of batteries?"
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/true-shape-of-lithium-1.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/true-shape-of-lithium-1.jpg" data-sub-html="A rendering of the rhombic dodecahedron shape that lithium atoms formed on a surface with the researchers’ technique for avoiding corrosion, top, with four illustrations (middle, bottom&nbsp;rows) showing the irregular shapes that appeared in conditions where corrosion formed. Credit: Li Lab/UCLA">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/true-shape-of-lithium-1.jpg" alt="True shape of lithium revealed for the first time" title="A rendering of the rhombic dodecahedron shape that lithium atoms formed on a surface with the researchers’ technique for avoiding corrosion, top, with four illustrations (middle, bottom&nbsp;rows) showing the irregular shapes that appeared in conditions where corrosion formed. Credit: Li Lab/UCLA">
             <figcaption>
                A rendering of the rhombic dodecahedron shape that lithium atoms formed on a surface with the researchers’ technique for avoiding corrosion, top, with four illustrations (middle, bottom&nbsp;rows) showing the irregular shapes that appeared in conditions where corrosion formed. Credit: Li Lab/UCLA
            </figcaption>        </figure>
    </div>

<p>Until now, the prevailing view had been that the choice of electrolytes in solution determines the shape that lithium forms on a surface—whether the structure resembles chunks or columns. The UCLA researchers had a different idea.
</p><p>"We wanted to see if we could deposit lithium so quickly that we outpace the reaction that causes the corrosion film," said UCLA doctoral student Xintong Yuan, the study's first author. "That way, we could potentially see how the lithium wants to grow in the absence of that film."
</p><p>The researchers developed a new technique for depositing lithium faster than corrosion forms. They ran current through a much smaller electrode in order to push electricity out faster—much like the way that partially blocking the nozzle of a garden hose causes water to shoot out more forcefully.
</p><p>A balance was required, however, because speeding up the process too much would lead to the same spiky structures that cause short circuits; the team addressed that issue by adjusting the shape of their tiny electrode.
</p><p>They laid down lithium on surfaces using four different electrolytes, comparing results between a standard technique and their new method. With corrosion, the lithium formed four distinct microscopic shapes. However, with their corrosion-free process, they found that the lithium formed miniscule dodecahedrons—no bigger than 2 millionths of a meter, or about the average length of a single bacterium—in all four cases.
</p><p>The researchers were able to see the shape of lithium thanks to an imaging technique called <a href="https://phys.org/tags/cryo-electron+microscopy/" rel="tag">cryo-electron microscopy</a>, or cryo-EM, which beams electrons through frozen samples in order to show details down to the atomic level while inhibiting damage to the samples.
</p><p>Cryo-EM has become ubiquitous in biosciences for determining the structures of proteins and viruses. Use for <a href="https://phys.org/tags/materials+science/" rel="tag">materials science</a> is growing, and the UCLA researchers had two key advantages.
</p><p>First, when Li was a graduate student, he demonstrated that cryo-EM can be used to analyze lithium, which falls to pieces when exposed to an electron beam at room temperature. Second, the team performed experiments at CNSI's Electron Imaging Center for Nanomachines, which is home to several cryo-EM instruments that have been customized to accommodate the types of samples used in materials research.
</p><p>"Cross-pollination between the biology and chemistry communities is producing new ideas," said Matthew Mecklenburg, a co-author of the study and managing director of the imaging center. "We're applying our extensive experience analyzing small molecules, proteins and viruses using cryo-EM methods in new ways to look at battery materials that are sensitive to the electron beam."
</p><p>Li said the new technique for depositing <a href="https://phys.org/tags/lithium/" rel="tag">lithium</a> still requires further work to optimize it.
										 																				
																				</p><div>
																						<p><strong>More information:</strong>
												Yuzhang Li, Ultrafast deposition of faceted Li polyhedra by outpacing SEI formation, <i>Nature</i> (2023).  <a data-doi="1" href="https://dx.doi.org/10.1038/s41586-023-06235-w" target="_blank">DOI: 10.1038/s41586-023-06235-w</a>. <a href="https://www.nature.com/articles/s41586-023-06235-w" target="_blank">www.nature.com/articles/s41586-023-06235-w</a>
																						
																						</p><p>
													<strong>Journal information:</strong>
																											<a href="https://phys.org/journals/nature/"><cite>Nature</cite></a>
														<a href="http://www.nature.com/nature/index.html" target="_blank" rel="nofollow">
															<svg>
																<use href="https://phys.b-cdn.net/tmpl/v6/img/svg/sprite.svg#icon_open" x="0" y="0"></use>
															</svg>
														</a> 
																									</p>
																					</div>
                               											
																					
                              										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												True shape of lithium revealed for the first time (2023, August 2)
												retrieved 7 August 2023
												from https://phys.org/news/2023-08-true-lithium-revealed.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open-source canvas drawing web app, built using React (206 pts)]]></title>
            <link>https://github.com/diogocapela/flatdraw</link>
            <guid>37038908</guid>
            <pubDate>Mon, 07 Aug 2023 18:50:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/diogocapela/flatdraw">https://github.com/diogocapela/flatdraw</a>, See on <a href="https://news.ycombinator.com/item?id=37038908">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">flatdraw</h2>
<p dir="auto">A simple canvas drawing web application built using <a href="https://typescriptlang.org/" rel="nofollow">TypeScript</a>, <a href="https://react.dev/" rel="nofollow">React</a>, and <a href="https://nextjs.org/" rel="nofollow">Next.js</a>.</p>
<p dir="auto"><strong>Live demo:</strong> <a href="https://flatdraw.com/" rel="nofollow">flatdraw.com</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/diogocapela/flatdraw/blob/main/docs/screenshot.png"><img src="https://github.com/diogocapela/flatdraw/raw/main/docs/screenshot.png" alt=""></a></p>
<h2 tabindex="-1" dir="auto">Requirements</h2>
<ul dir="auto">
<li><a href="https://nodejs.org/" rel="nofollow">Node.js</a> (the specific version is defined in the <a href="https://github.com/diogocapela/flatdraw/blob/main/.nvmrc"><code>.nvmrc</code></a> file)</li>
</ul>
<h2 tabindex="-1" dir="auto">Getting started</h2>
<p dir="auto">Copy the content of <code>.env.example</code> to a new <code>.env</code> file and fill in the required environment variables. You can get your Unsplash API keys <a href="https://unsplash.com/developers" rel="nofollow">here</a>.</p>

<p dir="auto">Install all the dependencies.</p>

<p dir="auto">Run the development server.</p>

<p dir="auto">Open <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a> with your browser to see the result.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">Open source under the terms of the <a href="https://github.com/diogocapela/flatdraw/blob/main/LICENSE">MIT License</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zoom's TOS Permit Training AI on User Content Without Opt-Out (277 pts)]]></title>
            <link>https://stackdiary.com/zoom-terms-now-allow-training-ai-on-user-content-with-no-opt-out/</link>
            <guid>37038494</guid>
            <pubDate>Mon, 07 Aug 2023 18:24:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stackdiary.com/zoom-terms-now-allow-training-ai-on-user-content-with-no-opt-out/">https://stackdiary.com/zoom-terms-now-allow-training-ai-on-user-content-with-no-opt-out/</a>, See on <a href="https://news.ycombinator.com/item?id=37038494">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
							
<p>Well, well, well... It looks like <a href="https://stackdiary.com/brave-selling-copyrighted-data-for-ai-training/" target="_blank" rel="noreferrer noopener">Brave</a> isn't the only company out there that is willing to bet all its chips on reusing other people's content for AI training. </p>



<p>Zoom Video Communications, Inc. <a href="https://explore.zoom.us/en/terms/" target="_blank" rel="noreferrer noopener">recently updated its Terms of Service</a> to encompass what some critics are calling a significant invasion of user privacy.</p>



<p>In a detailed perusal of the newly updated terms, two sections - <strong>10.2</strong> and <strong>10.4</strong> - stand out for their broad-ranging implications on how Zoom is permitted to utilize user data. These sections establish Zoom's rights to compile and utilize "Service Generated Data," which is any telemetry data, product usage data, diagnostic data, and similar content or data that Zoom collects in connection with users' use of their services or software.</p>



<p>Zoom's updated policy states that all rights to Service Generated Data are retained solely by Zoom. This extends to Zoom's rights to modify, distribute, process, share, maintain, and store such data "for any purpose, to the extent and in the manner permitted under applicable law."</p>



<p>What raises alarm is the explicit mention of the company's right to use this data for machine learning and artificial intelligence, including training and tuning of algorithms and models. This effectively allows Zoom to train its AI on customer content without providing an opt-out option, a decision that is likely to spark significant debate about user privacy and consent.</p>



<p>Additionally, under section 10.4 of the updated terms, Zoom has secured a "perpetual, worldwide, non-exclusive, royalty-free, sublicensable, and transferable license" to redistribute, publish, access, use, store, transmit, review, disclose, preserve, extract, modify, reproduce, share, use, display, copy, distribute, translate, transcribe, create derivative works, and process Customer Content.</p>



<p>Zoom justifies these actions as necessary for providing services to customers, supporting the services, and improving its services, software, or other products. However, the implications of such terms are far-reaching, particularly as they appear to permit Zoom to use customer data for any purpose relating to the uses or acts described in section 10.3.</p>



<p>Privacy advocates and legal experts are expected to scrutinize these updated terms closely. Many argue that they push the boundaries of what is acceptable in terms of consent, data privacy, and individual rights. While Zoom's intentions may be focused on improving their platform and delivering better service, the breadth and depth of these changes may leave many users uncomfortable and seeking assurances about how their data is being used.</p>



<p>Zoom has yet to comment (added below) on the updates and potential concerns raised by these changes. As this unfolds, the debate around privacy in the digital age and the responsibility of companies in respecting user privacy continues to intensify.</p>



<p><em><a href="https://news.ycombinator.com/item?id=37021160" target="_blank" rel="noreferrer noopener">Discuss on Hacker News</a></em></p>



<hr>



<h3>An update</h3>



<p>Biella Coleman picked this story up and <a href="https://twitter.com/BiellaColeman/status/1688332659108257792" target="_blank" rel="noreferrer noopener">tweeted it out</a>, which got this trending and invoked a response from Zoom. </p>



<p>Aparna Bawa, COO at Zoom, <a href="https://news.ycombinator.com/item?id=37029700" target="_blank" rel="noreferrer noopener">left a comment on Hacker News</a>,</p>



<blockquote>
<p>To clarify, Zoom customers decide whether to enable generative AI features (recently launched on a free trial basis) and separately whether to share customer content with Zoom for product improvement purposes.</p>



<p>Also, Zoom participants receive an in-meeting notice or a Chat Compose pop-up when these features are enabled through our UI, and they will definitely know their data may be used for product improvement purposes.</p>
</blockquote>



<p>I myself also got an email from a spokesperson, who said that, <em>"Zoom customers decide whether to enable generative AI features, and separately whether to share customer content with Zoom for product improvement purposes."</em>.</p>



<p>While these are all lovely responses, and at least they're being involved in the discussion, they don't actually answer the <strong>10.4</strong> clause in the Terms of Service, which states,</p>



<blockquote>
<p>You agree to grant and hereby grant Zoom a perpetual, worldwide, non-exclusive, royalty-free, sublicensable, and transferable license and all other rights required or necessary to redistribute, publish, import, access, use, store, transmit, review, disclose, preserve, extract, modify, reproduce, share, use, display, copy, distribute, translate, transcribe, create derivative works, and process Customer Content and to perform all acts with respect to the Customer Content, including AI and ML training and testing.</p>
</blockquote>



<p>Unless these are rectified and clarified, this means that Zoom can do exactly what they say they can do because you are agreeing to grant all the abovementioned permissions. I cannot stress enough that these aren't just "words at a wall" - in the <strong>10.2</strong> clause, you literally consent to Zoom using your data for AI/ML; you do not have a choice to opt-out because opting-out is not part of the terms.</p>



<p>Zoom has published a blog post on the matter; <a href="https://twitter.com/Zoom/status/1688550493717417985" target="_blank" rel="noreferrer noopener">you can see the tweet here</a>. </p>



<p>I'm linking to the tweet (and you can also read <a href="https://news.ycombinator.com/item?id=37034980" target="_blank" rel="noreferrer noopener">this Hacker News comment</a>) because there should be discourse (unfortunately, for Zoom, it's not in their favor) around this rather than blank statements.</p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A beginner's guide to Git version control (250 pts)]]></title>
            <link>https://developers.redhat.com/articles/2023/08/02/beginners-guide-git-version-control</link>
            <guid>37038457</guid>
            <pubDate>Mon, 07 Aug 2023 18:21:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.redhat.com/articles/2023/08/02/beginners-guide-git-version-control">https://developers.redhat.com/articles/2023/08/02/beginners-guide-git-version-control</a>, See on <a href="https://news.ycombinator.com/item?id=37038457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>Git is a widely used distributed version control system that allows software development teams to have multiple local copies of the project's source code that are independent of each other. Version control has come to be associated with Git—it is unquestionably the best version control program for new developers to start learning due to its popularity and wealth of resources related to its use. Read on for an overview of the basics.</p>

<h2>Git configuration: Linux</h2>

<p>Most Linux installations have Git, but to check, execute the following command in your terminal:</p>

<pre><code>$ git --version</code></pre>

<p>You should get output that is similar to the following:</p>

<pre>git version 2.40.1</pre>

<h2>Git configuration: Windows</h2>

<p>Git searches the <code>$HOME</code> directory for the <code>.gitconfig</code> file on Windows systems.</p>

<p>We need to tell Git to keep track of our login and email when we use it, as shown in the code snippet below. This makes it possible for other code contributors to identify the change's author and our contact information in case of problems.</p>

<pre><code>$ git config --global user.name "username"

$ git config --global user.email "useremail"</code></pre>

<p>Use the following command if you need assistance:</p>

<pre><code>$ git help config</code></pre>

<p>This command will open a browser containing configuration commands. Essentially, the <code>help</code> command gives a manual from the help page for the given command.</p>

<p>You can also use the same command in the following ways:</p>

<pre><code>$ git config --help</code></pre>

<p>Use the following command to view configurations:</p>

<pre><code>$ git config -l</code></pre>

<h2>Working with repositories</h2>

<p>A directory that Git will track is called a <strong>repository</strong>,<strong>&nbsp;</strong>or repo. The Git repository contains the whole of our project. Git will trace any change we make. We'll use the command below to create a test directory:</p>

<pre><code>$ mkdir test</code></pre>

<p>We can then use the following command to enter the test directory:</p>

<pre><code>$ cd test</code></pre>

<p>Running <code>git init</code> command inside the directory lets Git know that it is a Git repository:</p>

<pre><code>$ git init&nbsp;

Empty Git repository created and initialised in /home/uname/test/.git</code></pre>

<p>Now a Git repository exists in this directory. Showing the <code>.git</code> file that Git generated inside the directory will be helpful; use the command as follows:</p>

<pre><code>$ ls -a</code></pre>

<p><strong>Output:</strong></p>

<pre>.git</pre>

<p>The directory is now a Git repository. In fact, deleting the <code>.git</code> directory will uninitialize the repository (this can be very helpful when you're just starting out). Run the following command to make your directory a non-Git repository:</p>

<pre><code>$ rm.git -rf</code></pre>

<p>Use this only if you truly want to start over because it will remove Git from the directory completely.</p>

<p>Let's create two files in the test directory with the names <code>file1</code> and <code>file2</code>. This will show how Git tracks files:</p>

<pre><code>$ touch file1.txt
$ touch file2.txt</code></pre>

<h2>Staging files: git add&nbsp;</h2>

<p>The principles of the staging environment and the commit are essential to Git. You can add, change, or remove files as you work. However, anytime you reach an important stage or complete a portion of the work, you should move the files to a staging environment. Files that have been <strong>staged</strong> are ready to be committed to the repository you are working on. (We'll discuss commits in more detail in a later section.)</p>

<p>We can see what Git is tracking using the following command:</p>

<pre><code>$ git status

On branch main

No commits yet

Untracked files:

&nbsp;&nbsp;(use "git add &lt;file&gt;..." to include in what will be committed)

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file1.txt
&nbsp; &nbsp; &nbsp; &nbsp; File2.txt</code></pre>

<p><code>git status</code> displays a list of newly added or modified files and directories in the Git repository. In our example,&nbsp;<code>file1.txt</code> and <code>file2.txt</code> have been modified.</p>

<p>We must stage the files in order to instruct Git to keep track of changes. Let's use the <code>add</code> command to stage <code>file1.txt</code>:</p>

<pre><code>$ git add file1.txt

$ git status
On branch master
No commits yet
Changes to be committed:
&nbsp; &nbsp;(use "git rm --cached &lt;file&gt;..." to unstage)
&nbsp; &nbsp; &nbsp; &nbsp; new file: file1.txt
Untracked files:
&nbsp; (use "git add &lt;file&gt;..." to include in what will be committed)
&nbsp; &nbsp; &nbsp; &nbsp; file2.txt</code></pre>

<p>Notice that <code>file1.txt</code> is listed under <strong>Changes to be committed</strong> by Git. This indicates that Git is keeping note of any modifications made to this file in order to commit those modifications to the repository. Let's add <code>file2.txt</code> now:</p>

<pre><code>$ git add file2.txt


$ git status
...
Changes to be committed:
&nbsp; (use "git rm --cached &lt;file&gt;..." to unstage)
&nbsp; &nbsp; &nbsp; &nbsp; new file: file1.txt
&nbsp; &nbsp; &nbsp; &nbsp; new file: file2.txt</code></pre>

<p>You can instruct Git to monitor a file or directory using the <code>add</code> command or to stop tracking a file or directory with the <code>unstaging</code> command.</p>

<p>The git <code>rm</code> command is used to remove individual files or a set of files using the filename, as shown below. The <code>git rm --cached</code> command maintains a file in the working directory while removing it from the Git index.&nbsp;</p>

<pre><code>$ git rm --cached file1.txt
rm file1.txt

$ git status
…
Untracked files: (
&nbsp; use "git add &lt;file&gt;..." to include in what will be committed)
&nbsp; &nbsp; &nbsp; &nbsp; file1.txt
</code></pre>

<p>The <code>file1.txt</code> file is no longer being tracked.</p>

<h2>Keeping track of untracked files</h2>

<p>We frequently need a quick way to tell Git to add everything that is untracked to the staging area. We can do this by using <code>*</code> or <code>.</code>:</p>

<pre><code>$ git add --all</code></pre>

<pre><code>$ git add .</code></pre>

<pre><code>$ git add *</code></pre>

<p>Stage all changes (new, changed, and deleted) files by using <code>--all</code> rather than specific filenames.</p>

<h2>Commits</h2>

<p>Git uses <strong>commits</strong> to make changes to files and directories permanent. In a sense, every commit represents a new version of our repository. Even while a commit can be seen to be a more permanent change, Git makes it simple to undo those changes, which is the strength of version control with Git.</p>

<p>For Git users, this alters the fundamental development model. Git developers have the option to build up commits in their local repo before making a change and committing it to the main repository. It accomplishes this by tracking the history of commits. Git's main purpose is to allow users to make commits. Everything we wanted to stage has already been done, so we can now make those modifications.&nbsp;<code>git commit</code> is used to do this.</p>

<p>When using the <code>git commit</code> command, we recommend always including two arguments: <code>-a</code> and <code>-m</code>.</p>

<h3>Stage all modified files: git commit -a</h3>

<p>Add all untracked files to the staging area with the <code>-a</code> or <code>--all</code>&nbsp;option. Note that only previously added files and folders are added using this method. Use the <code>add</code> command first if a file or directory has to be added that hasn't already been.</p>

<h3>Commit messages: git commit -m</h3>

<p>A commit message should always be included when making a commit. The <code>-m</code> or <code>--message</code> option is used for this. This message should be brief and descriptive, with just enough information included in the commit statement to summarize your actions since the last commit.</p>

<pre><code>$ git commit -am "my first git commit"</code></pre>

<h3>View change history: git log</h3>

<p>To view the history of changes that have been committed to a Git repository, use the <code>git log</code> command:</p>

<pre><code>$ git log</code></pre>

<p>In order to make our output easier to read and only to show the first seven characters of the commit ID, we'll also use the option <code>--oneline</code> command:</p>

<pre><code>$ git log -oneline</code></pre>

<p><strong>Output:</strong></p>

<pre>cf0p490 (HEAD -&gt; main) my first git commit</pre>

<p>In this example, the commit ID's first seven characters are <code>cf0p490</code>. There will be a lot of commits; thus each one needs to have its own identification. We can move the <code>HEAD</code> pointer around as necessary.</p>

<h2>Publishing changes: git push</h2>

<p>Finally, the <code>git push</code> command is used to upload content from a local repository to a remote repository. <strong>Pushing</strong> refers to the process of transferring commits from your local repository to a remote repository.</p>

<pre><code>$ git push</code></pre>

<p>Or:</p>

<pre><code>$ git push origin branchname</code></pre>

<h2>Where to learn more</h2>

<p>Explore more Git resources on Red Hat Developer for new and advanced users:</p>

<ul><li><a href="https://developers.redhat.com/cheat-sheets/git-cheat-sheet">Git cheat sheet</a></li>
	<li><a href="https://developers.redhat.com/articles/2022/07/20/git-workflows-best-practices-gitops-deployments">Git best practices: Workflows for GitOps deployments</a></li>
	<li><a href="https://developers.redhat.com/articles/2022/02/02/protect-secrets-git-cleansmudge-filter">Protect secrets in Git with the clean/smudge filter</a></li>
	<li><a href="https://developers.redhat.com/blog/2020/02/25/how-to-ignore-files-in-git-without-gitignore">How to ignore files in Git without .gitignore</a></li>
</ul>
					
															
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The combined power of F# and C# (198 pts)]]></title>
            <link>https://steven-giesel.com/blogPost/2f70d926-ec92-4dfe-b278-18f78078253d</link>
            <guid>37038425</guid>
            <pubDate>Mon, 07 Aug 2023 18:19:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steven-giesel.com/blogPost/2f70d926-ec92-4dfe-b278-18f78078253d">https://steven-giesel.com/blogPost/2f70d926-ec92-4dfe-b278-18f78078253d</a>, See on <a href="https://news.ycombinator.com/item?id=37038425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div b-gj8cwnhyng=""><p>Where C# is the most dominant language in the .NET world, other languages are built on top of the Framework that deserves their respective place. F# is strong when it comes down to functional programming! In this blog post, we will leverage the power of F# and C# to showcase where both excel!</p>
<h2 id="why-does-it-work">Why does it work?</h2>
<p>Before I go into the details of the code, I want to explain why this works. Why can we use F# code in C# and vice versa? The answer is simple: the .NET Framework is a runtime that can execute code written in different languages. The runtime is responsible for compiling the code to an intermediate language (IL) that the runtime can execute. If your code is dependent on other libraries, you are not relying on the source code but the IL code of that library. I already had a whole blog post about that: <a href="https://steven-giesel.com/blogPost/aa23a1c9-8ab2-4b05-9bd2-52624af7b684">"<em>What is the difference between C#, .NET, IL and JIT?</em>"</a>. Have a read here if you are interested in more details.</p>
<p><img src="https://linkdotnetblog.azureedge.net/blog/20220612_CSharpDotNetJit/Dotnet.webp" alt=".NET"></p>
<h2 id="f">F#</h2>
<p>Here is a very brief introduction: F# is a functional-first programming language in the .NET ecosystem. It is designed to provide the expressive power of functional programming alongside the robustness of object-oriented paradigms. It enjoys all of the benefits of the .NET Framework itself: open-source, platform-independent, and strongly typed.</p>
<pre><code>let rec factorial n =
    if n = 0 then 1 else n * factorial (n - 1)

printfn "Factorial of 5 is %d" (factorial 5)
</code></pre>
<p>F# also has some distinct features C# does not offer, the most prominent: <a href="https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/discriminated-unions">Discriminated unions</a>.</p>
<h2 id="the-use-case">The use case</h2>
<p>I want to showcase where F# excels - and oftentimes, that can be the domain layer of your application. Especially then when you have a lot of calculations (basically where functional programming excels in the first place). Let's create a small domain project that is written in F# and see how it could look like in C#. I will create a "small online" shop that can take orders and calculate a discount (a percentage or a fixed amount). Before we go into F#, have a look at the C# code:</p>
<pre><code>
public class Product 
{
    public string Name { get; set; }
    public decimal Price { get; set; }
}

public class OrderLine 
{
    public Product Product { get; set; }
    public int Quantity { get; set; }
}

public enum DiscountType { Percentage, FixedAmount }

public class Discount 
{
    public DiscountType Type { get; set; }
    public decimal Value { get; set; }
}

public record Order(List&lt;OrderLine&gt; OrderLines, Discount Discount)
{
    public decimal CalculateTotalPrice() 
    {
        decimal subtotal = OrderLines.Sum(ol =&gt; ol.Product.Price * ol.Quantity);
        decimal totalDiscount = 0M;

        if (Discount != null) {
            totalDiscount = Discount.Type == DiscountType.Percentage 
                                ? subtotal * Discount.Value / 100M 
                                : Discount.Value;
        }

        return subtotal - totalDiscount;
    }
}
</code></pre>
<p>Now for the sake of simplicity, I left out a lot of validation and error handling. I hope you get the idea anyway. Now let's see how this would look like in F#:</p>
<pre><code>type Product = { Name: string; Price: decimal }
type OrderLine = { Product: Product; Quantity: int }

type Discount = 
    | Percentage of float
    | FixedAmount of decimal

type Order(orderLines: OrderLine list, discount: Discount option) =
    member this.CalculateTotalPrice() =
        let subtotal = List.sumBy (fun ol -&gt; ol.Product.Price * (decimal ol.Quantity)) orderLines
        let totalDiscount =
            discount
            |&gt; Option.map (fun d -&gt; 
                match d with
                | Percentage p -&gt; subtotal * (decimal p / 100M)
                | FixedAmount f -&gt; f)
            |&gt; Option.defaultValue 0M
        subtotal - totalDiscount
</code></pre>
<p>Wow - that is really slim. Let's go through the code step by step. First, we have the <code>Product</code> and <code>OrderLine</code> types. They are just simple records that hold the data. Then we have the <code>Discount</code> type. This is a discriminated union that can either be a <code>Percentage</code> or a <code>FixedAmount</code>. The <code>Order</code> type class takes a list of <code>OrderLine</code> and an optional <code>Discount</code>. The <code>CalculateTotalPrice</code> method is the same as in the C# example. The only difference is that we use the <code>Option</code> type to handle the <code>null</code> case. The <code>Option</code> type is a discriminated union that can either be <code>Some</code> or <code>None</code>. We can use pattern matching to handle both cases. In this case we use the <code>Option.map</code> function to map the <code>Discount</code> to a <code>decimal</code> value. If the <code>Discount</code> is <code>None</code> we use the <code>Option.defaultValue</code> function to return <code>0M</code>.</p>
<p>Now we can easily integrate that to a controller:</p>
<pre><code>[ApiController]
[Route("api/orders")]
public class OrderController : ControllerBase
{
    private static readonly List&lt;Order&gt; Orders = new();

    [HttpPost]
    public ActionResult&lt;Order&gt; CreateOrder([FromBody] List&lt;OrderLine&gt; orderLines, [FromBody] Discount discount)
    {
        var fsharpOrderLines = ListModule.OfSeq(orderLines);
        var order = new Order(fsharpOrderLines, discount);
        Orders.Add(order);
        return CreatedAtAction(nameof(GetOrderById), new { id = Orders.Count - 1 }, order);
    }

    [HttpGet("{id:int}")]
    public ActionResult&lt;Order&gt; GetOrderById(int id)
    {
        if (id &lt; 0 || id &gt;= Orders.Count)
        {
            return NotFound();
        }

        return Orders[id];
    }

    [HttpGet("{id:int}/total")]
    public ActionResult&lt;decimal&gt; GetOrderTotalPrice(int id)
    {
        if (id &lt; 0 || id &gt;= Orders.Count)
        {
            return NotFound();
        }

        return Orders[id].CalculateTotalPrice();
    }

    [HttpGet]
    public ActionResult&lt;IEnumerable&lt;Order&gt;&gt; GetAllOrders()
    {
        return Orders;
    }
}
</code></pre>
<p>There might be a very special line here that needs some clarification:</p>
<pre><code>var fsharpOrderLines = ListModule.OfSeq(orderLines);
</code></pre>
<p>The <code>ListModule.OfSeq</code> function is a helper function that converts a <code>List&lt;T&gt;</code> to a <code>seq&lt;T&gt;</code>. The <code>seq&lt;T&gt;</code> type is a sequence of elements. It is a lazy collection that is only evaluated when needed. This is a very powerful concept that is used a lot in F#. You can read more about it <a href="https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/sequences">here</a>. In this case we need to convert the <code>List&lt;T&gt;</code> to a <code>seq&lt;T&gt;</code> because the <code>Order</code> type expects a <code>seq&lt;T&gt;</code> as input.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I hope this blog post gave you a good overview of how you can use F# and C# together. It can be a very powerful tool, and F# has some unique strengths that can make your life easier!</p>
<h2 id="resources">Resources</h2>
<ul>
<li>Source code to this blog post: <a href="https://github.com/linkdotnet/BlogExamples/tree/main/FSharpCombined">here</a></li>
<li>All my sample code is hosted in this repository: <a href="https://github.com/linkdotnet/BlogExamples">here</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Aeroflot deactivates brakes on nine aircraft, relies solely on reverse thrust (217 pts)]]></title>
            <link>https://aeroxplorer.com/articles/aeroflot-deactivates-brakes-on-nine-aircraft-relies-solely-on-reverse-thrust.php</link>
            <guid>37038278</guid>
            <pubDate>Mon, 07 Aug 2023 18:09:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aeroxplorer.com/articles/aeroflot-deactivates-brakes-on-nine-aircraft-relies-solely-on-reverse-thrust.php">https://aeroxplorer.com/articles/aeroflot-deactivates-brakes-on-nine-aircraft-relies-solely-on-reverse-thrust.php</a>, See on <a href="https://news.ycombinator.com/item?id=37038278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <!--BEGIN BODY-->
                    
                    
                    
                    <p>It has been one and a half years since <a target="_blank" href="https://aeroxplorer.com/articles/ukrainian-civil-airspace-closed.php">the Russian invasion of Ukraine</a>. Since the onset of the war, many sanctions have been placed on Russia, including on the country's aviation industry. Many parts in (western made) Russian passenger aircraft that would normally be easily replaced are rapidly wearing out with no replacement parts in sight due to the import of spare aircraft parts from Boeing and Airbus being banned since March 2022.&nbsp;</p><p>Due to the aforementioned sanctions, Russian flag carrier Aeroflot is experiencing problems replacing worn-out brakes on "foreign" (non-Russian-made) aircraft.</p><figure><img loading="lazy" src="https://cdn.aeroxplorer.com/large/TEB-PMqbC8cGnKGcbaCJVqhy.jpg"><figcaption>Photo: A T | AeroXplorer</figcaption></figure><p><br>Due to Aeroflot's inability to replace worn-out brakes on its fleet, the airline has requested that its pilots turn off the brakes on affected aircraft. Currently, nine Aeroflot planes are flying with turned brakes: five Boeing 777-300ERs, one Airbus A330-300, one Airbus A320, and two Airbus A321s.&nbsp;</p><p>An aircraft can land without brakes, as during landing most of the work of stopping a commercial aircraft is done through the use of thrust reversers. However, landing without the aid of brakes will significantly increase the amount of runway an aircraft uses on landing. Brakes are also necessary for aborting takeoffs, through the use of Auto Brakes, which automatically activate should pilots decide to abort a takeoff for whatever reason.&nbsp;</p><p>Despite the airline requesting pilots turn off brakes on affected aircraft, mechanics and technicians in Aeroflot's flight operations department are actively warning pilots of the increased risk of runway overruns. When pilots land an affected Aeroflot aircraft (without brakes), "...The aircraft will tend to turn to the side...especially when landing on a wet runway with a side [side] wind..."&nbsp;</p><p>According to The Moscow Times, Russian Airlines are allowed to refuse the repair of aircraft brakes for up to 10 days, after which they must either be replaced or turned off, with a notification of the Federal Agency for Air Transport (FATA) required.&nbsp;</p><figure><img loading="lazy" src="https://cdn.aeroxplorer.com/large/TEB-OkB9TGwo6uOx0i6j4tjr.jpg"><figcaption>Photo: AeroXplorer | Lukasz S.</figcaption></figure><br>&nbsp;<h2>Russian aviation is becoming progressively more dangerous.&nbsp;</h2><p>As of August 2022, there does not appear to be any end in sight to the seemingly endless Russia-Ukraine conflict and subsequent sanctions. Due to the scarce supply of aircraft parts, many Russian airlines, including Aeroflot, are cannibalizing their own aircraft for parts. Demand within the Russian passenger aviation industry is growing, and most of Russia's civilian aircraft fleet is comprised of foreign aircraft.&nbsp;</p><p>While Russia is attempting to increase its domestic aircraft production with aerospace companies by the likes of Irkut (Yakovlev), and Tupolev, this will happen gradually. So for now, the Russian aviation industry will remain in a dangerous position in which the risk of crashes will remain at a drastically high level, primarily due to sanctions.&nbsp;</p><h2>Aeroflot - One Of The Oldest Airlines In The World.&nbsp;</h2><figure><img loading="lazy" src="https://cdn.aeroxplorer.com/large/XhqQl3aaA8ovFX8mfO2Z.jpg"><figcaption>Photo: AeroXplorer | Cody Newton</figcaption></figure><p>Founded in 1923, 100-year-old Aeroflot has a fleet of 172 aircraft, most all composed of Airbus and Boeing. Currently, just two aircraft in the airline's fleet are Russian-made - two Sukhoi SuperJet SSJ-100-95s. Since Russia's invasion of Ukraine, the airline has made an additional 389 aircraft orders with Russian plane-makers Sukhoi, Tupolev, and Irkut (Yakovlev) to make up for canceled aircraft orders with Airbus and Boeing.</p><p>Prior to 2022, the airline had over 200 routes, connecting cities within Russia and abroad. The airline also had numerous other routes in the form of codeshares through its SKYTEAM alliance membership, which was also suspended following the resumption of the Russia-Ukraine war.&nbsp;</p>
                    
                    
                    
                    <!--END BODY-->
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ChainForge, a visual tool for prompt engineering and LLM evaluation (159 pts)]]></title>
            <link>https://chainforge.ai/docs/</link>
            <guid>37038053</guid>
            <pubDate>Mon, 07 Aug 2023 17:54:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chainforge.ai/docs/">https://chainforge.ai/docs/</a>, See on <a href="https://news.ycombinator.com/item?id=37038053">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
              <article>
                
                  

  
  



<p><img alt="prompt-inj-attack" src="https://chainforge.ai/docs/prompt_injection_attack.png"></p>
<p>ChainForge is an open-source visual programming environment for prompt engineering, LLM evaluation and experimentation. With ChainForge, you can evaluate the robustness of prompts and text generation models with little to no coding required. Features include:</p>
<ul>
<li><strong>Query multiple LLMs at once</strong> to test prompt ideas and variations quickly and effectively. Or query the same LLM at different settings.</li>
<li><strong>Compare response quality across prompt permutations, across models, and across model settings</strong> to choose the best prompt and model for your use case. </li>
<li><strong>Setup evaluation metrics</strong> with code or LLM-based scorers and automatically plot results across prompts, prompt parameters, models, or model settings.</li>
<li><strong>Hold multiple conversations at once across template parameters and chat models.</strong> Template chat messages and inspect and evaluate outputs at each turn of a chat conversation.</li>
</ul>
<p>ChainForge is in active development and is provided as an <a href="https://chat.openai.com/share/313422ed-cbd1-4b25-b51f-11e872cfb1f1">open beta test</a>.</p>
<h2 id="how-to-install">How to Install</h2>
<h3 id="install-chainforge-locally">Install ChainForge locally</h3>
<div><pre><span></span><code>pip<span> </span>install<span> </span>chainforge<span> </span>
chainforge<span> </span>serve
</code></pre></div>
<p><strong>Open <a href="http://localhost:8000/">localhost:8000</a> in a Chrome, Firefox, Edge or Brave browser.</strong> For more details on installation, such as setting API keys as environment variables, see <a href="https://chainforge.ai/docs/getting_started/">Getting Started</a>.</p>
<h3 id="or-try-out-chainforge-online-chainforgeaiplay">Or try out ChainForge online @ <a href="https://chainforge.ai/play"><strong><span>chainforge.ai</span>/<span>play</span></strong></a></h3>
<p>The web version is limited, yet includes a magical feature called the <strong>Share Button</strong>:</p>
<p><img alt="share-btn" src="https://user-images.githubusercontent.com/5251713/250916534-1c69900b-5a0f-4055-bbd3-ea191e93ecde.gif"></p>
<p>With Share, you can send your LLM experiments to others as links. Simply click Share to generate a unique weblink for your LLM experiment and copy it to your clipboard. For instance, here's <a href="https://chainforge.ai/play/?f=28puvwc788bog">an experiment that tries to get an LLM to reveal a secret key</a>.</p>
<div>
<p>Note</p>
<p>ChainForge is compatible with Google Chrome and Mozilla Firefox. 
You will need an API key for the LLM(s) you wish to use. We do not store your API keys —not in a cookie, localStorage, or server. 
Because of this, you must set your API keys every time you load ChainForge. 
If you prefer not to worry about it, we recommend installing ChainForge locally 
and <a href="https://chainforge.ai/docs/getting_started/">setting your API keys as environment variables</a>.</p>
</div>
<h2 id="about-us">About Us</h2>
<p>ChainForge is created by <a href="http://ianarawjo.therottingcartridge.com/">Ian Arawjo</a>, a postdoctoral scholar at Harvard in the <a href="https://glassmanlab.seas.harvard.edu/">Glassman Lab</a> of the Harvard HCI group. Collaborators include PhD students <a href="https://priyan.info/">Priyan Vaithilingam</a> and <a href="https://seas.harvard.edu/person/chelse-swoopes">Chelse Swoopes</a> and faculty members <a href="http://glassmanlab.seas.harvard.edu/glassman.html">Elena Glassman</a> and <a href="https://www.bewitched.com/about.html">Martin Wattenberg</a>.</p>
<h3 id="how-to-cite">How to Cite</h3>
<p>If you use ChainForge for research purposes, or build upon the source code, we ask that you cite this project in any related publications. The BibTeX you can use for now is:</p>
<div><pre><span></span><code><span>@misc</span><span>{</span><span>Arawjo_2023</span><span>,</span>
<span>  </span><span>author</span><span> </span><span>=</span><span> </span><span>{Arawjo, Ian and Vaithilingam, Priyan and Swoopes, Chelse and Wattenberg, Martin and Glassman, Elena}</span><span>,</span>
<span>  </span><span>title</span><span> </span><span>=</span><span> </span><span>{ChainForge}</span><span>,</span>
<span>  </span><span>year</span><span> </span><span>=</span><span> </span><span>{2023}</span><span>,</span>
<span>  </span><span>howpublished</span><span> </span><span>=</span><span> </span><span>{\url{https://www.chainforge.ai/}}</span>
<span>}</span>
</code></pre></div>






                
              </article>
            </div>
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Car Bloat: “Huge Cars Are Terrible for Society” (284 pts)]]></title>
            <link>https://kottke.org/23/08/car-bloat-huge-cars-are-terrible-for-society</link>
            <guid>37038007</guid>
            <pubDate>Mon, 07 Aug 2023 17:51:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kottke.org/23/08/car-bloat-huge-cars-are-terrible-for-society">https://kottke.org/23/08/car-bloat-huge-cars-are-terrible-for-society</a>, See on <a href="https://news.ycombinator.com/item?id=37038007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><img src="https://kottke.org/plus/misc/images/compare-carsized.jpg" width="1000" height="442" alt="Compare Carsized"></p>

<p>David Zipper, who researches and writes about mobility and transportation, recently <a href="https://mastodon.social/@davidzipper/110843841107933007">did a big thread on Mastodon</a> (and <a href="https://bsky.app/profile/davidzipper.bsky.social/post/3k4a4elm25e2p">Bluesky</a>) about car bloat: the way in which cars and trucks have gotten much bigger and heavier in the US over the past few decades and how it's bad for society. The whole thread is worth a read...here are a couple of Zipper's points:</p>

<blockquote><p>Tall vehicles have bigger blind spots and are more likely to strike a person's torso or head. Heavier vehicles exert more force crashing into a person, bicycle, or smaller car. They also have longer braking distances.</p></blockquote>

<blockquote><p>Heavier cars exert more pressure on tires, eroding them faster. Tire particles are absorbed into water, where they damage ecosystems. They also float through the air, harming human health when ingested.</p></blockquote>

<p>For further reading, Zipper links to a number of pieces he's written in recent months: <a href="https://www.fastcompany.com/90854942/the-blatant-greenwashing-of-suvs">The Blatant Greenwashing of SUVs</a>, <a href="https://www.theatlantic.com/technology/archive/2023/07/electric-vehicles-tires-wearing-out-particulates/674750/">EVs Are Sending Toxic Tire Particles Into the Water, Soil, and Air</a>, <a href="https://slate.com/business/2023/06/electric-vehicles-auto-haulers-weight-capacity-roads.html">Carry That Weight</a>, and <a href="https://slate.com/business/2022/11/suv-size-truck-bloat-pedestrian-deaths.html">The Car Safety Feature That Kills the Other Guy</a>. Zipper's solution to these problems is government action: for example, <a href="https://slate.com/business/2023/01/electric-cars-hummer-ev-tax-fees-weight-joe-biden.html">taxing vehicles by weight</a>, testing vehicles for pedestrian and cyclist safety, or requiring drivers have commercial driver's licenses for larger vehicles.</p>

<p>The image above is from Carsized and <a href="https://www.carsized.com/en/cars/compare/volkswagen-jetta-2005-sedan-vs-ram-1500-2018-4-door-pickup-crew-cab-5/">compares a 2018 Dodge Ram to a 2005 VW Jetta</a>.</p>


<p>More about...</p>
<ul><li><a href="https://kottke.org/tag/cars">cars</a></li><li><a href="https://kottke.org/tag/David%20Zipper">David Zipper</a></li><li><a href="https://kottke.org/tag/USA">USA</a></li>
</ul>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux Guide for Power Users (182 pts)]]></title>
            <link>https://xnacly.me/posts/2022/linux-for-powerusers/</link>
            <guid>37037520</guid>
            <pubDate>Mon, 07 Aug 2023 17:19:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xnacly.me/posts/2022/linux-for-powerusers/">https://xnacly.me/posts/2022/linux-for-powerusers/</a>, See on <a href="https://news.ycombinator.com/item?id=37037520">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="single"><p><time datetime="2022-08-23 00:00:00 +0000 UTC">Aug 23, 2022</time>
<span>·</span>
<span>Edited on
<time datetime="2023-08-03 09:52:20 +0200 +0200">Aug 3, 2023</time></span>
<span>·</span>
<span>3713 words</span>
<span>·</span>
<span>18 minute read</span></p><div><h2 id="what-to-expect">What to expect <a href="#what-to-expect">##</a></h2><p>This guide is meant as a loose inspiration for a poweruser looking to switch to Linux. It showcases:</p><ul><li>window manager, terminal, i3status, nvim, git, fish, wallpapers and dunst configuration</li><li>basic package manager usage</li><li>some information about everything you need to know to really configure a power users system.</li></ul><p>If you already know how to install Linux skip <a href="#installing-a-distro">Installing</a> and go straight to
<a href="#what-do-we-need-how-do-we-get-it">What do we need, how do we get it</a></p><p>If you want to see Screenshots of the results click <a href="#screenshots-1">here</a>.</p><p>If you want to take a look at my dofiles, they are <a href="https://github.com/xnacly/dotfiles" target="_blank" rel="noopener">here</a></p><h2 id="getting-started-with-the-lingo-what-is-all-this-stuff">Getting started with the Lingo (What is all this stuff) <a href="#getting-started-with-the-lingo-what-is-all-this-stuff">##</a></h2><h3 id="linux--gnu">Linux <code>(+-/GNU)</code> <a href="#linux--gnu">###</a></h3><p>Linux is the kernel of your distro, written in C and Assembly by Linus Torvalds and thousands of contributors.</p><p>The kernel manages most of your installed drivers, allocates your resources and generally acts as an interface between
soft- and hardware.</p><p><img src="https://xnacly.me/linux/linux_kernel.webp" alt="kernel_hardware"></p><p>The <code>+-/Gnu</code> in the heading is a reference to the Linux kernel using GNU code and extensions, and therefore some people
think the Linux kernel should be named with the post-fix <code>/Gnu</code> or <code>+Gnu</code>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p>Most people use Linux as a synopsis for everything included in a distribution, such as kernel, drivers, desktop
environment, window manager, shell, etc. even though Linux is just the name of the kernel. Everyone knows what you’re
talking about by just calling everything Linux.</p><blockquote><p><strong>View the current kernel version and build by running</strong></p><div><pre tabindex="0"><code data-lang="bash"><span><span>1</span><span>$: uname -a
</span></span><span><span>2</span><span><span># outdated wsl kernel</span>
</span></span><span><span>3</span><span>Linux THINK-**** 4.4.0-19041-Microsoft <span>#1237-Microsoft Sat Sep 11 14:32:00 PST 2021 x86_64 x86_64 x86_64 GNU/Linux</span>
</span></span></code></pre></div></blockquote><h3 id="distribution">Distribution <a href="#distribution">###</a></h3><p>As hinted above a distribution is a package of software. Most Linux distribution contain the Kernel, some sort of
desktop environment, a window manager, multiple Apps such as a word processor and a Webbrowser.</p><p>Some Distros are known for their gigantic package repositories like <a href="https://www.debian.org/index.en.html" target="_blank" rel="noopener">Debian</a> and
<a href="https://arch/linux.org/" target="_blank" rel="noopener">Arch</a>, other are famous for their security like e.g.
<a href="https://www.redhat.com/en/technologies//linux-platforms/enterprise-linux" target="_blank" rel="noopener">RedHat</a> or the discontinued
<a href="https://www.centos.org/" target="_blank" rel="noopener">CentOS</a>. There are some distros which shine by being different or minimal, such as
<a href="https://nixos.org/" target="_blank" rel="noopener">NixOS</a> (unconventional package managing), <a href="https://artix/linux.org/" target="_blank" rel="noopener">Artix</a> (different init system)
or <a href="https://voidlinux.org/" target="_blank" rel="noopener">Void Linux</a> (all the before + support for musl libc implementation)</p><p>No one really knows how many distros there
<a href="https://upload.wikimedia.org/wikipedia/commons/b/b5//linux_Distribution_Timeline_21_10_2021.svg" target="_blank" rel="noopener">are</a>, because everyone
can make one and switching between them is very easy.</p><h4 id="package-manager">Package manager <a href="#package-manager">####</a></h4><p>A package manager is a tool which installes, removes and updates software for you. No more going to a random website and
downloading an <code>*.exe</code> file only to have your hdd bricked after disabling the antivirus and running the totally
legitimate vbux generator. Package managers are accessed using the terminal, but some desktop environments include
graphical user interfaces for managing packages.</p><p>A package manager such as pacman is relatively secure due to package signing and other measures which were put in place
to save users from malicious software.</p><p>Almost all distributions contain a package manager, the most famous are: <code>apt</code>, <code>pacman</code> and <code>dnf</code>.</p><p>package manager cli examples:</p><div><pre tabindex="0"><code data-lang="bash"><span><span> 1</span><span><span># install a tool named neovim</span>
</span></span><span><span> 2</span><span>sudo apt install neovim
</span></span><span><span> 3</span><span>sudo pacman -S neovim
</span></span><span><span> 4</span><span>
</span></span><span><span> 5</span><span><span># check for new updates, upgrade the system</span>
</span></span><span><span> 6</span><span>sudo apt update <span>&amp;&amp;</span> sudo apt upgrade
</span></span><span><span> 7</span><span>sudo pacman -Syyu
</span></span><span><span> 8</span><span>
</span></span><span><span> 9</span><span><span># remove neovim</span>
</span></span><span><span>10</span><span>sudo apt remove neovim
</span></span><span><span>11</span><span>sudo pacman -R neovim
</span></span></code></pre></div><p>In this tutorial we will use <a href="https://manjaro.org/" target="_blank" rel="noopener">Manjaro</a>, therefore you can focus on the package manager included in
the distribution: <code>pacman</code>.</p><h4 id="desktop-environment-de-vs-window-manager-wm">Desktop environment (DE) vs window manager (WM) <a href="#desktop-environment-de-vs-window-manager-wm">####</a></h4><p>A desktop environment such as <a href="https://www.gnome.org/" target="_blank" rel="noopener">GNOME</a> bundles a file manager, terminal, window manager, settings
and more into the GNOME package. Everything in it is tightly integrated and applications in the bundle often look
similar and depend on the same libraries. A <code>de</code> handles almost everything the user interacts with inside the GUI, such
as volume management, connecting to networks, mounting drives, theming and other.</p><h3 id="which-distro-to-choose">Which distro to choose? <a href="#which-distro-to-choose">###</a></h3><p>I love pacman and getting new software updates fast, therefore i personally use Arch Linux, which can sometimes require
knowledge or some time to maintain. The distro we intend to use is based on arch Linux, but has a lot of preconfigured
software, making it interesting for beginners and advanced users.</p><blockquote><p><strong>Is Manjaro better than other distros?</strong></p><p>Manjaro is not superior or inferior to any other Linux distribution, they all do the same. Manjaro has its own package
manager, themes, tools and custom Kernels.</p></blockquote><p>The above was taken from the manjaro download page and i agree wholeheartedly with the first part. Roll a die and pick a
random distro, it won’t really matter.</p><h4 id="rolling-release-vs-stable-release-continuous-delivery">Rolling release vs Stable release (Continuous delivery) <a href="#rolling-release-vs-stable-release-continuous-delivery">####</a></h4><p>To always have the newest and shiniest software at hand, one could decide to pick a distro with a rolling release
circle<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, which can at best (or worst) have several updates available a day. Like everything else RR
distros have up- and downsides, you can read further about them <a href="https://itsfoss.com/rolling-release/" target="_blank" rel="noopener">here</a></p><p>Releasing on a specified time frame is defined as a continuous delivery or stable releases. Distros following this
pattern have the convincing argument of stability and tested packages in their repos.</p><p>I personally never had stability issues on arch Linux and ppas annoy the shit out of me, therefore i use Arch :).</p><p>Relevant:</p><p><img src="https://xnacly.me/linux/arch.webp" alt="arch_meme"></p><h2 id="reasons-for-manjaro-linux">Reasons for Manjaro Linux <a href="#reasons-for-manjaro-linux">##</a></h2><p>As said before, in this tutorial we will be using Manjaro due to it:</p><ul><li>being based on arch<ul><li>having rolling release updates</li><li>having pacman and yay installed</li></ul></li><li>containing a fully configured system (yes bloat, idc its a beginners tutorial)</li><li>(ofc) being Linux</li></ul><h2 id="installing-a-distro">Installing a Distro <a href="#installing-a-distro">##</a></h2><blockquote><p>This section will explain how to install manjaro linux in a virtual machine in depth</p></blockquote><p>Before installing on real hardware i would recommend you to spin up a virtual machine and install Manjaro there. I will
now describe a simplified way to install your operating system:</p><ol><li>Install <a href="https://www.virtualbox.org/wiki/Downloads" target="_blank" rel="noopener">Oracle VirtualBox</a> (select <code>Windows hosts</code>)</li><li>Head to the manjaro download page <a href="https://manjaro.org/download" target="_blank" rel="noopener">here</a>, scroll down till you see the
<code>OFFICIAL EDITIONS</code> badge.</li></ol><p><img src="https://xnacly.me/linux/manjaro_download.webp" alt="manjaro_download"></p><ol start="3"><li>Download a minimal version of one of the three editions (I picked gnome).<blockquote><p><strong>DISCLAIMER</strong></p><p>For simplicitie’s sake, we will not check the authenticity of the downloaded image, one should however always
check this before installing on bare metal.</p></blockquote></li><li>Start Virtual Box and click on <code>new</code></li></ol><p><img src="https://xnacly.me/linux/vb_1.webp" alt="virtual box new vm"></p><ol start="5"><li>Name your box with whatever you want, and select <code>Type: Linux</code> and <code>Version: Arch Linux (64-bit)</code></li></ol><p><img src="https://xnacly.me/linux/vb_2.webp" alt="virtual box new vm name and type"></p><ol start="6"><li>Go with the default for <code>memory size</code>:</li></ol><p><img src="https://xnacly.me/linux/vb_3.webp" alt="virtual box new vm memory"></p><ol start="7"><li>You want to create a new hard drive:</li></ol><p><img src="https://xnacly.me/linux/vb_4.webp" alt="virtual box new vm hard drive"></p><p>with the following attributes (you will be asked for these in the next few windows):</p><ul><li>VDI (VirtualBox Disk Image)</li><li>dynamically allocated</li><li>25GB</li></ul><ol start="8"><li><p>Hit enter and you have your vm</p></li><li><p>Head to <code>Settings-&gt;System-&gt;Boot Order</code> and move the <code>Hard Disk</code> option to the top of the list (this allows the vm to
boot into the operating system after installation and reboot)</p></li><li><p>Go to <code>Settings-&gt;Storage</code> and add a new iso by following this image:</p></li></ol><p><img src="https://xnacly.me/linux/vb_5.webp" alt="virtual box new vm add iso"></p><ol start="11"><li><p>Click on <code>open-&gt;choose-&gt;ok</code></p></li><li><p>Now click on <code>start</code></p></li><li><p>Wait till the system boots (you should see some logs), click on <code>launch installer</code> and go trough it.</p></li></ol><ul><li>Location: go with the default</li><li>Keyboard: go with your keyboard layout</li><li>Partions: select <code>Erase disk</code></li><li>Users: fill the input fields, choose a password you can remember (for vms i always use root) and check the box which
says <code>Use the same password for the administrator account</code></li></ul><ol start="14"><li>Hit install and install now in the next prompt.</li><li>Check the <code>restart now</code> box and click on <code>✓Done</code> (the vm will now reboot into the freshly installed os)</li><li>Login with your very strong password from 13. and explore the system:</li></ol><p><img src="https://xnacly.me/linux/manjaro_result.webp" alt="manjaro result"></p><h2 id="what-do-we-need-how-do-we-get-it">What do we need, how do we get it? <a href="#what-do-we-need-how-do-we-get-it">##</a></h2><p>Wikipedia defines a power user as:</p><blockquote><p>a user of computers, software and other electronic devices, who uses advanced features of computer hardware, operating
systems, programs, or websites which are not used by the average user.</p><p>A power user might not have extensive technical knowledge of the systems they use but is rather characterized by
competence or desire to make the most intensive use of computer programs or systems.</p></blockquote><p>I however would also mention the power users desire to get work done quickly and not have his workflow interrupted.</p><p>This can be done by making use of a window manager such as <a href="https://i3wm.org/" target="_blank" rel="noopener">i3[-gaps]</a> to:</p><ul><li>tile windows</li><li>use workspaces</li><li>auto start applications</li><li>automatically move applications on start to a workspace</li><li>have a fancy bar on one border of the screen</li><li>manage your windows solely via keyboard shortcuts you configure</li><li>have a cool <a href="https://reddit.com/r/unixporn" target="_blank" rel="noopener">r/unixporn</a> setup</li></ul><p>The downside of most window manager setups is the need to configure every feature you would get by using a desktop
environment yourself, such as volume, wifi and wallpaper management. But don’t worry i got you covered on that full
system configuration.</p><h3 id="application-overview">Application overview <a href="#application-overview">###</a></h3><ul><li>Notification daemon: dunst (lightweight and configurable)</li><li>Window manager: i3-gaps (i3 fork with gaps)</li><li>File explorer: Nautilus (comes with gnome)</li><li>Shell: fish (very nice autocompletion and prompts)</li><li>Terminal Emulator: kitty (i like the name and i need font ligatures for my neovim setup)</li><li>Editor: Neovim (its the new and improved new and improved vi)</li><li>Wallpaper setter: nitrogen (its minimal)</li></ul><h2 id="getting-started">Getting Started <a href="#getting-started">##</a></h2><h3 id="installing-software">Installing software <a href="#installing-software">###</a></h3><h4 id="understanding-pacman">Understanding <code>pacman</code> <a href="#understanding-pacman">####</a></h4><p>Pacman has a not so beginner friendly interface (it uses flags such as <code>-S</code> instead of <code>install</code> or <code>add</code>), i will
therefore now follow with a simplified guide for pacman.</p><blockquote><p>Always consult the man pages<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> or the wiki<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> for more info Pacman is very easy to use
for simple and complex tasks. It’s flags are consistent and if you really think about it they make a lot of sense, it
is also a lot simpler than apt, like I contrasted in <a href="#package-manager">Package manager</a>.</p></blockquote><h5 id="pacman-usage"><code>pacman</code> usage <a href="#pacman-usage">#####</a></h5><div><pre tabindex="0"><code data-lang="bash"><span><span>1</span><span><span># install a package</span>
</span></span><span><span>2</span><span>pacman -S firefox
</span></span><span><span>3</span><span><span># remove a package</span>
</span></span><span><span>4</span><span>pacman -R firefox
</span></span><span><span>5</span><span><span># search a package</span>
</span></span><span><span>6</span><span>pacman -Ss firefox
</span></span><span><span>7</span><span><span># full system upgrade</span>
</span></span><span><span>8</span><span>pacman -Syyu
</span></span></code></pre></div><h2 id="configuring-your-system">Configuring your system <a href="#configuring-your-system">##</a></h2><blockquote><p>This section will explain how to install and configure certian software</p></blockquote><h3 id="files">.files <a href="#files">###</a></h3><p>Dotfiles are files starting with a <code>.</code>. These files are hidden by default and can be viewed using the <code>-a</code> flag for ls:</p><div><pre tabindex="0"><code data-lang="bash"><span><span> 1</span><span>$: <span>pwd</span>
</span></span><span><span> 2</span><span>/home/teo
</span></span><span><span> 3</span><span>
</span></span><span><span> 4</span><span><span># (l)i(s)t directory content</span>
</span></span><span><span> 5</span><span><span>#   [-l: long listing format]</span>
</span></span><span><span> 6</span><span>$: ls -l
</span></span><span><span> 7</span><span>total <span>0</span>
</span></span><span><span> 8</span><span>drwxr-xr-x <span>1</span> teo teo <span>4096</span> Aug <span>24</span> 09:29 Documents
</span></span><span><span> 9</span><span>
</span></span><span><span>10</span><span><span># (l)i(s)t directory content</span>
</span></span><span><span>11</span><span><span>#   [-l: long listing format, -a: list all files (includes hidden)]</span>
</span></span><span><span>12</span><span>$: ls -la
</span></span><span><span>13</span><span>total <span>16</span>
</span></span><span><span>14</span><span>drwxr-x--- <span>1</span> teo  teo  <span>4096</span> Aug <span>24</span> 09:29 .
</span></span><span><span>15</span><span>drwxr-xr-x <span>1</span> root root <span>4096</span> Aug  <span>5</span> 09:15 ..
</span></span><span><span>16</span><span>-rw------- <span>1</span> teo  teo   <span>409</span> Aug <span>23</span> 14:31 .bash_history
</span></span><span><span>17</span><span>-rw-r--r-- <span>1</span> teo  teo   <span>220</span> Aug  <span>5</span> 09:15 .bash_logout
</span></span><span><span>18</span><span>-rw-r--r-- <span>1</span> teo  teo  <span>3771</span> Aug  <span>5</span> 09:15 .bashrc
</span></span><span><span>19</span><span>drwxr-xr-x <span>1</span> teo  teo  <span>4096</span> Aug  <span>5</span> 09:15 .landscape
</span></span><span><span>20</span><span>-rw-r--r-- <span>1</span> teo  teo     <span>0</span> Aug <span>24</span> 09:29 .motd_shown
</span></span><span><span>21</span><span>-rw-r--r-- <span>1</span> teo  teo   <span>807</span> Aug  <span>5</span> 09:15 .profile
</span></span><span><span>22</span><span>-rw-r--r-- <span>1</span> teo  teo     <span>0</span> Aug  <span>5</span> 09:15 .sudo_as_admin_successful
</span></span><span><span>23</span><span>-rw------- <span>1</span> teo  teo  <span>2361</span> Aug  <span>5</span> 11:26 .viminfo
</span></span><span><span>24</span><span>drwxr-xr-x <span>1</span> teo  teo  <span>4096</span> Aug <span>24</span> 09:29 Documents
</span></span></code></pre></div><p>In the above one can directly see a config file such as <code>.bashrc</code>. This file for instance contains all the configuration for bash, as the name suggests.</p><blockquote><p><strong>Freedesktop.org: XDG basedir specs</strong></p><p><em><code>$XDG_CONFIG_HOME</code> defines the base directory relative to which user-specific configuration files should be stored.
If <code>$XDG_CONFIG_HOME</code> is either not set or empty, a default equal to <code>$HOME/.config</code> should be used.</em> <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p></blockquote><p>Config files are often stored in files prefixed by a <code>.</code>, or in the <code>.config</code> directory, therefore they are called dotfiles..</p><h3 id="neovim-editor">Neovim (Editor) <a href="#neovim-editor">###</a></h3><p>To get started we need to get our hands on a powerful editor, such as vim or the new and improved vim: neovim.</p><p>Neovim is useful with its defaults, but a minimal config can help to get the most out of it.</p><p>Open a new terminal, paste the following:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>1</span><span><span># install the neovim package using pacman as the superuser</span>
</span></span><span><span>2</span><span>sudo pacman -S neovim
</span></span><span><span>3</span><span><span># (c)hange (d)irectory to the user config which can be found at ~/.config</span>
</span></span><span><span>4</span><span><span>cd</span> ~/.config
</span></span><span><span>5</span><span><span># (m)a(k)e a new (dir)ectory named nvim</span>
</span></span><span><span>6</span><span>mkdir nvim
</span></span><span><span>7</span><span><span># create a new file named init.vim in the ~/.config/nvim folder</span>
</span></span><span><span>8</span><span>nvim nvim/init.vim
</span></span></code></pre></div><p>now you should see neovim’s interface.:</p><p><img src="https://xnacly.me/linux/vim_config.webp" alt="vim_config"></p><p>press <code>i</code> to switch to insert mode and paste the following configuration using <code>ctrl+shift+v</code>:</p><div><pre tabindex="0"><code data-lang="vim"><span><span> 1</span><span>set number								<span>" enable line numbers</span>
</span></span><span><span> 2</span><span>set hidden 								<span>" hide buffers</span>
</span></span><span><span> 3</span><span>syntax on                               <span>" Enables syntax highlighing</span>
</span></span><span><span> 4</span><span>set nowrap                              <span>" Display long lines as just one line</span>
</span></span><span><span> 5</span><span>set encoding=utf<span>-8</span>                      <span>" The encoding displayed</span>
</span></span><span><span> 6</span><span>set fileencoding=utf<span>-8</span>                  <span>" The encoding written to file</span>
</span></span><span><span> 7</span><span>set ruler								<span>" Show the cursor position all the time</span>
</span></span><span><span> 8</span><span>set cmdheight=<span>2</span>                         <span>" More space for displaying messages</span>
</span></span><span><span> 9</span><span>set iskeyword+=-                      	<span>" treat dash separated words as a word text object</span>
</span></span><span><span>10</span><span>set splitbelow                          <span>" Horizontal splits will automatically be below</span>
</span></span><span><span>11</span><span>set splitright                          <span>" Vertical splits will automatically be to the right</span>
</span></span><span><span>12</span><span>set t_Co=<span>256</span>                            <span>" Support 256 colors</span>
</span></span><span><span>13</span><span>set conceallevel=<span>0</span>                      <span>" So that I can see `` in markdown files</span>
</span></span><span><span>14</span><span>set tabstop=<span>4</span>                           <span>" Insert 2 spaces for a tab</span>
</span></span><span><span>15</span><span>set shiftwidth=<span>4</span>                        <span>" Change the number of space characters inserted for indentation</span>
</span></span><span><span>16</span><span>set smarttab                            <span>" Makes tabbing smarter will realize you have 2 vs 4</span>
</span></span><span><span>17</span><span>set expandtab                           <span>" Converts tabs to spaces</span>
</span></span><span><span>18</span><span>set smartindent                         <span>" Makes indenting smart</span>
</span></span><span><span>19</span><span>set autoindent                          <span>" Good auto indent</span>
</span></span><span><span>20</span><span>set showtabline=<span>2</span>                       <span>" Always show tabs</span>
</span></span><span><span>21</span><span>set noshowmode                          <span>" We don't need to see things like -- INSERT -- anymore</span>
</span></span><span><span>22</span><span>set updatetime=<span>300</span>                      <span>" Faster completion</span>
</span></span><span><span>23</span><span>set timeoutlen=<span>500</span>                      <span>" By default timeoutlen is 1000 ms</span>
</span></span><span><span>24</span><span>set formatoptions-=cro                  <span>" Stop newline continution of comments</span>
</span></span><span><span>25</span><span>set termguicolors						<span>" allow vim to change term colors</span>
</span></span><span><span>26</span><span>set incsearch 							<span>" enable incremental search</span>
</span></span><span><span>27</span><span>set smartcase							<span>" searches case insensitive until an uppercase character is supplied</span>
</span></span><span><span>28</span><span>set nobackup							<span>" disables backup files</span>
</span></span><span><span>29</span><span>set spell!								<span>" spellchecking</span>
</span></span><span><span>30</span><span>set spelllang=en,de						<span>" set languages for spellchecking</span>
</span></span></code></pre></div><p>Now hit <code>Esc</code> and type <code>:w</code> and after that <code>:source %</code> to reload the neovim configuration</p><blockquote><p><strong>Escaping vim</strong></p><p>there are several ways to exit vim:</p><table><thead><tr><th>Method</th><th>What happens</th></tr></thead><tbody><tr><td><code>Esc:q!</code> or <code>ZQ</code></td><td>exit and discard</td></tr><tr><td><code>Esc:w</code> or <code>ZZ</code></td><td>exit and save</td></tr></tbody></table></blockquote><h4 id="plugins-fuzzy-file-finder-nerd-tree">Plugins (fuzzy file finder, nerd tree) <a href="#plugins-fuzzy-file-finder-nerd-tree">####</a></h4><p>Add the following to your vim config (<code>~/.config/nvim/init.vim</code>) to install vim plug (a package manager for vim).</p><div><pre tabindex="0"><code data-lang="vim"><span><span>1</span><span><span>" installs vim plug if it isnt already installed</span>
</span></span><span><span>2</span><span><span>if</span> empty(glob(<span>'~/.config/nvim/autoload/plug.vim'</span>))
</span></span><span><span>3</span><span>  silent !curl -fLo ~<span>/.config/</span>nvim<span>/autoload/</span>plug.vim --create-dirs
</span></span><span><span>4</span><span>    \ https:<span>//</span>raw.githubusercontent.com<span>/junegunn/</span>vim-plug<span>/master/</span>plug.vim
</span></span><span><span>5</span><span><span>endif</span>
</span></span></code></pre></div><p>To add plugins to vim we need to do the following:</p><div><pre tabindex="0"><code data-lang="vim"><span><span> 1</span><span>call plug#begin(<span>'~/.config/nvim/autoload/plugged'</span>)
</span></span><span><span> 2</span><span><span>    " define fzf as a plugin</span>
</span></span><span><span> 3</span><span>    Plug <span>'junegunn/fzf'</span>, { <span>'do'</span>: { -&gt; fzf#install() } }
</span></span><span><span> 4</span><span><span>
</span></span></span><span><span> 5</span><span><span>    " plugins for icons in the file tree</span>
</span></span><span><span> 6</span><span>    Plug <span>'kyazdani42/nvim-web-devicons'</span>
</span></span><span><span> 7</span><span>    Plug <span>'ryanoasis/vim-devicons'</span>
</span></span><span><span> 8</span><span><span>
</span></span></span><span><span> 9</span><span><span>    " syntax support for the file tree</span>
</span></span><span><span>10</span><span>    Plug <span>'tiagofumo/vim-nerdtree-syntax-highlight'</span>
</span></span><span><span>11</span><span><span>
</span></span></span><span><span>12</span><span><span>    " plugin to display a file tree</span>
</span></span><span><span>13</span><span>    Plug <span>'scrooloose/NERDTree'</span>
</span></span><span><span>14</span><span><span>
</span></span></span><span><span>15</span><span><span>    " add the closing pair to ("'{[</span>
</span></span><span><span>16</span><span>    Plug <span>'jiangmiao/auto-pairs'</span>
</span></span><span><span>17</span><span>call plug#end()
</span></span></code></pre></div><p>Now:</p><ol><li>type in <code>:w</code> and <code>:source %</code> to reload the config</li><li>type in <code>:PlugInstall</code> and exit with <code>ZZ</code></li></ol><p>Go back into the vim config and add the following lines to interact with the plugins we just installed.:</p><div><pre tabindex="0"><code data-lang="vim"><span><span>1</span><span><span>" this defines space as out custom button to start key combinations such as space+f to fuzzy search</span>
</span></span><span><span>2</span><span><span>let</span> mapleader=<span>"\&lt;space&gt;"</span>
</span></span><span><span>3</span><span><span>
</span></span></span><span><span>4</span><span><span>" map space+f to the command ':FZF' which starts the fuzzy finder window</span>
</span></span><span><span>5</span><span>nnoremap &lt;silent&gt; &lt;Leader&gt;f :FZF&lt;CR&gt;
</span></span><span><span>6</span><span><span>
</span></span></span><span><span>7</span><span><span>" map ctrl+b to the file tree</span>
</span></span><span><span>8</span><span>nnoremap &lt;silent&gt; &lt;C-b&gt; :NERDTreeToggle&lt;CR&gt;
</span></span></code></pre></div><p>To view available shortcuts for the <code>NerdTree</code> press <code>ctrl+b</code> to toggle the tree window and press <code>?</code> to view help.</p><h5 id="screenshots">Screenshots <a href="#screenshots">#####</a></h5><h6 id="fzf">Fzf <a href="#fzf">######</a></h6><p><img src="https://xnacly.me/linux/fzf.webp" alt="fzf"></p><h6 id="nerdtree">NerdTree <a href="#nerdtree">######</a></h6><p><img src="https://xnacly.me/linux/nerdtree_and_vim.webp" alt="nerdtree"></p><h3 id="fish-shell">Fish (Shell) <a href="#fish-shell">###</a></h3><p>Install fish</p><p>Set fish as the default shell:</p><h3 id="git-version-control-tool">Git (Version control tool) <a href="#git-version-control-tool">###</a></h3><p>Install git:</p><p>Go to <a href="https://github.com/" target="_blank" rel="noopener">github</a></p><ol><li>sign in or sign up</li><li>click on your profile picture</li><li>click on settings.</li><li>now navigate to</li></ol><p><code>Settings-&gt;Developer Settings-&gt;Personal access tokens-&gt;Generate new token</code></p><ol start="5"><li>name it <code>manjar-vm</code></li><li>click on the <code>repo</code> checkbox</li><li>scroll to the bottom and click on generate token.</li><li>copy the token into a notepad (should be prefixed with <code>ghp_</code>)</li></ol><p>To push or pull from github, one must first authenticate to their service. This needs to be done using the git config.<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p><div><pre tabindex="0"><code data-lang="bash"><span><span> 1</span><span><span># tell git to store your credentials indefinitly</span>
</span></span><span><span> 2</span><span>git config --global credential.helper store
</span></span><span><span> 3</span><span><span># set your username exactly as the username you selected on github (replace xnacly with your username)</span>
</span></span><span><span> 4</span><span>git config --global user.name <span>"xnacly"</span>
</span></span><span><span> 5</span><span><span># set your email exactly as the email you selected on github (replace with your username)</span>
</span></span><span><span> 6</span><span>git config --global user.email <span>"47723417+xNaCly@users.noreply.github.com"</span>
</span></span><span><span> 7</span><span>
</span></span><span><span> 8</span><span><span># to check if everything worked, run:</span>
</span></span><span><span> 9</span><span>git config --global --list
</span></span><span><span>10</span><span><span># should spit this out:</span>
</span></span><span><span>11</span><span><span># user.name=xnacly</span>
</span></span><span><span>12</span><span><span># user.email=47723417+xNaCly@users.noreply.github.com</span>
</span></span></code></pre></div><p>Now go to <a href="https://github.com/new" target="_blank" rel="noopener">github/new repo</a> to create a new private repo</p><ol><li>name it <code>manjaro vm test</code></li><li>click on <code>Private</code></li><li>scroll down and create your repo.</li><li>copy the repo url from the blue box (<code>https://github.com/&lt;username&gt;/test.git</code>)</li></ol><div><pre tabindex="0"><code data-lang="bash"><span><span>1</span><span><span># replace &lt;username&gt; with your github username</span>
</span></span><span><span>2</span><span><span># You will be prompted for your email and your password,</span>
</span></span><span><span>3</span><span><span># input the email used to sign in to github,</span>
</span></span><span><span>4</span><span><span># as the password you will need to use the access token we generated before.</span>
</span></span><span><span>5</span><span>git clone https://github.com/&lt;username&gt;/test.git
</span></span><span><span>6</span><span><span># cloning into 'test'...</span>
</span></span><span><span>7</span><span><span># Username for 'https://github.com':</span>
</span></span><span><span>8</span><span><span># Password for ... :</span>
</span></span><span><span>9</span><span><span># warning: You appear to have cloned an empty repository</span>
</span></span></code></pre></div><p>You are now authenticated to github. Test your config by creating a readme and pushing it to master:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>1</span><span><span>echo</span> <span>"# Test repo"</span> &gt; README.md
</span></span><span><span>2</span><span>git add -A
</span></span><span><span>3</span><span>git commit -m <span>"init commit"</span>
</span></span><span><span>4</span><span>git push
</span></span></code></pre></div><p>Now go to the repo and refresh by pressing <code>Ctrl+r</code> and see your changes have been pushed into master.</p><h3 id="i3-window-manager">i3 (Window manager) <a href="#i3-window-manager">###</a></h3><p>To display anything and manage our windows, we will need the i3gaps group:</p><div><pre tabindex="0"><code data-lang="text"><span><span>1</span><span>[sudo] password for teo:
</span></span><span><span>2</span><span>:: There are 5 members in group i3:
</span></span><span><span>3</span><span>:: Repository community
</span></span><span><span>4</span><span>   1) i3-gaps  2) i3-wm  3) i3blocks  4) i3lock  5) i3status
</span></span><span><span>5</span><span>
</span></span><span><span>6</span><span>Enter a selection (default=all):
</span></span></code></pre></div><p>Input your password and hit <code>Enter</code>.</p><p>Now logout and select i3:</p><p><img src="https://xnacly.me/linux/i3_select.webp" alt="i3_select"></p><p>After boot you will be prompted to generate a config, hit <code>Enter</code>.</p><p><img src="https://xnacly.me/linux/i3_firstboot.webp" alt="i3_first_boot"></p><p>Select the default key as the <code>Super</code>-Key, it should be the <code>Win</code> button. Hit Enter to write the config.</p><p><img src="https://xnacly.me/linux/i3_firstboot_config.webp" alt="i3_first_config"></p><p>i3 has a pretty unique keymap, here are the most basics ones:</p><table><thead><tr><th>Keycombination</th><th>what it does</th></tr></thead><tbody><tr><td><code>Super+Enter</code></td><td>open a terminal</td></tr><tr><td><code>Super+Shift+q</code></td><td>close a window</td></tr><tr><td><code>Super+d</code></td><td>start application launcher</td></tr><tr><td><code>Super+Shift+c</code></td><td>reload i3 config</td></tr><tr><td><code>Super+Shift+r</code></td><td>reload i3</td></tr><tr><td><code>Super+Shift+e</code></td><td>exit i3 prompt</td></tr><tr><td><code>Super+[0-9]</code></td><td>switch to workspace 1-10</td></tr><tr><td><code>Super+Shift+[0-9]</code></td><td>move focused window to workspace 1-10</td></tr></tbody></table><p>See the <a href="https://i3wm.org/docs/userguide.html" target="_blank" rel="noopener">i3 docs</a> for keybindings and configuration help, also see my <a href="https://github.com/xNaCly/dotfiles/blob/master/i3/config" target="_blank" rel="noopener">i3 config</a> for inspiration.</p><h3 id="i3status-i3-status-bar">i3status (i3 status bar) <a href="#i3status-i3-status-bar">###</a></h3><p>i3status is very easily configurable.</p><div><pre tabindex="0"><code data-lang="bash"><span><span>1</span><span><span># (c)hange (d)irectory to the user config which can be found at ~/.config</span>
</span></span><span><span>2</span><span><span>cd</span> ~/.config
</span></span><span><span>3</span><span><span># (m)a(k)e a new (dir)ectory named i3status</span>
</span></span><span><span>4</span><span>mkdir i3status
</span></span><span><span>5</span><span><span># open the config in neovim</span>
</span></span><span><span>6</span><span>nvim i3status/i3status.conf
</span></span></code></pre></div><p>Now in neovim, paste the following:</p><div><pre tabindex="0"><code data-lang="text"><span><span> 1</span><span>general {
</span></span><span><span> 2</span><span>        interval = 1
</span></span><span><span> 3</span><span>}
</span></span><span><span> 4</span><span>
</span></span><span><span> 5</span><span>order += "volume master"
</span></span><span><span> 6</span><span>order += "tztime local"
</span></span><span><span> 7</span><span>
</span></span><span><span> 8</span><span>tztime local {
</span></span><span><span> 9</span><span>        format = "%d.%m %H:%M "
</span></span><span><span>10</span><span>}
</span></span><span><span>11</span><span>
</span></span><span><span>12</span><span>volume master {
</span></span><span><span>13</span><span>        format = "%volume"
</span></span><span><span>14</span><span>        format_muted = "--%"
</span></span><span><span>15</span><span>        device = "pulse"
</span></span><span><span>16</span><span>}
</span></span></code></pre></div><p>This config updates every 1 second and only displays the time, date and volume.
To apply this configuration, we will need to change the configuration file i3status looks at. To do this, we need to change the following in <code>~/.config/i3/config</code> by supplying the file path to neovim, like so:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>1</span><span>nvim ~/.config/i3/config
</span></span></code></pre></div><p><img src="https://xnacly.me/linux/i3status_old.webp" alt="i3status_old"></p><div><pre tabindex="0"><code data-lang="text"><span><span>184</span><span>bar {
</span></span><span><span>185</span><span>	status_command i3status
</span></span><span><span>186</span><span>}
</span></span></code></pre></div><p>to</p><p><img src="https://xnacly.me/linux/i3status_new.webp" alt="i3status_new"></p><div><pre tabindex="0"><code data-lang="text"><span><span>184</span><span>bar {
</span></span><span><span>185</span><span>	status_command i3status -c ~/.config/i3status/i3status.conf
</span></span><span><span>186</span><span>}
</span></span></code></pre></div><h3 id="kitty-terminal-emulator">Kitty (Terminal Emulator) <a href="#kitty-terminal-emulator">###</a></h3><p>Kitty is very fast and full of features.</p><p>Install kitty:</p><p>Configure Kitty by opening <code>~/.config/kitty/kitty.conf</code> using neovim and pasting the following in the file:</p><div><pre tabindex="0"><code data-lang="text"><span><span> 1</span><span>font_family                 JetBrainsMono Nerd Font         # configure font family
</span></span><span><span> 2</span><span>bold_font                   auto
</span></span><span><span> 3</span><span>italic_font                 auto
</span></span><span><span> 4</span><span>bold_italic_font            auto
</span></span><span><span> 5</span><span>font_size                   13.0
</span></span><span><span> 6</span><span>window_padding_width        5                               # space between window borders and text in terminal
</span></span><span><span> 7</span><span>enable_audio_bell           no                              # disable loud alarm when misinput happens
</span></span><span><span> 8</span><span>remember_window_size        no
</span></span><span><span> 9</span><span>initial_window_width        82c
</span></span><span><span>10</span><span>initial_window_height       24c
</span></span><span><span>11</span><span>confirm_os_window_close     0                               # kitty asks you if you reall want to close it if a process is running, this disables the prompt
</span></span></code></pre></div><p>To replace the default terminal with kitty, open <code>~/.config/i3/config</code> with neovim:</p><ol><li>Search for <code>i3-sensible</code> by pressing <code>/i3-sensible</code> in normal mode</li><li>Replace <code>i3-sensible-terminal</code> with kitty</li></ol><div><pre tabindex="0"><code data-lang="text"><span><span>44</span><span># Use Mouse+$mod to drag floating windows to their wanted position
</span></span><span><span>45</span><span>floating_modifier $mod
</span></span><span><span>46</span><span>
</span></span><span><span>47</span><span># start a terminal
</span></span><span><span>48</span><span>bindsym $mod+Return exec i3-sensible-terminal
</span></span><span><span>49</span><span>
</span></span><span><span>50</span><span># kill focused window
</span></span><span><span>51</span><span>bindsym $mod+Shift+q kill
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="text"><span><span>44</span><span># Use Mouse+$mod to drag floating windows to their wanted position
</span></span><span><span>45</span><span>floating_modifier $mod
</span></span><span><span>46</span><span>
</span></span><span><span>47</span><span># start a terminal
</span></span><span><span>48</span><span>bindsym $mod+Return exec kitty
</span></span><span><span>49</span><span>
</span></span><span><span>50</span><span># kill focused window
</span></span><span><span>51</span><span>bindsym $mod+Shift+q kill
</span></span></code></pre></div><h3 id="dunst-notification-daemon">Dunst (Notification daemon) <a href="#dunst-notification-daemon">###</a></h3><p>Gnome ships a cli utility which we will use to test our notification daemon. Running <code>notify-send "test"</code> on our current system results in an <code>GDBus</code> error.
To fix this we will have to install <a href="https://wiki.archlinux.org/title/Dunst" target="_blank" rel="noopener">dunst</a>.:</p><p><img src="https://xnacly.me/linux/dbus_error.webp" alt="dbus_error"></p><p>Sending a new notification will now result in a small window popping up on our screen for a few seconds:</p><p><img src="https://xnacly.me/linux/dunst.webp" alt="dunst"></p><h3 id="nitrogen-wallpaper-setter">Nitrogen (Wallpaper setter) <a href="#nitrogen-wallpaper-setter">###</a></h3><p>Setting a Wallpaper is easier than all the technical incompetent people on <a href="https://www.reddit.com/r/pcmasterrace/" target="_blank" rel="noopener">r/PcMasterRace</a> say. Just install <code>nitrogen</code>, add your picture, done.</p><ol><li>Download an image to the <code>~/Pictures</code> directory</li><li>Add the <code>~/Pictures</code> directory as a source to nitrogen<p><img src="https://xnacly.me/linux/nitrogen_walktrough.webp" alt="nitrogen_walktrough"></p></li><li>Click on the now added image (1), select the prefered alignment option (2) and click <code>apply</code> (3)<p><img src="https://xnacly.me/linux/nitrogen_after_selection.webp" alt="nitrogen_after_selection"></p></li><li>Done.<p><img src="https://xnacly.me/linux/wallpaper_applied.webp" alt="wallpaper_applied"></p></li></ol><blockquote><p><strong>Warning</strong></p><p>This configuration is not permanent, every restart will require you to set your wallpaper again.</p></blockquote><p>To prevent the walllpaper reset we can read the nitrogen manpage<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>, which explains the <code>--restore</code> option. To use this option and let nitrogen start on boot, we will edit our i3 config.:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>1</span><span>nvim ~/.config/i3/config
</span></span></code></pre></div><ol><li>Press <code>Shift+g</code> to jump to the last line of the file.</li><li>Now press <code>o</code> to switch into insert mode in the line below.</li><li>We will now insert a <code>exec --no-startup-id</code> statement, read more about it here<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup></li></ol><div><pre tabindex="0"><code data-lang="text"><span><span>184</span><span>bar {
</span></span><span><span>185</span><span>	status_command i3status
</span></span><span><span>186</span><span>}
</span></span><span><span>187</span><span>exec --no-startup-id nitrogen --restore
</span></span></code></pre></div><p>Your wallpaper will now be restored on boot.</p><h2 id="wrapping-up">Wrapping up. <a href="#wrapping-up">##</a></h2><p>After reading through this guide and following each step, you can now:</p><ul><li>understand the difference between a distro and the kernel</li><li>install linux in a virtual machine</li><li>use a package manager</li><li>use basic vim</li><li>understand the basics of the unix file system</li><li>use a floating window manager</li><li>use git to version your files</li><li>configure software (i3, vim)</li></ul><p>If there is anything wrong or you are having questions just create a new issue <a href="https://github.com/xnacly/blog/issues/new" target="_blank" rel="noopener">here</a></p><p>I will some day follow up on this and make a ricing guide, but until now you should be able to evolve your workflows and get comfy using i3.</p><p>I appended some Screenshots to visualise the result of this guide.</p><h3 id="screenshots-1">Screenshots <a href="#screenshots-1">###</a></h3><p><img src="https://xnacly.me/linux/screenshot.webp" alt="screenshot"></p><p><img src="https://xnacly.me/linux/c_workflow_tree.webp" alt="c workflow"></p><p><img src="https://xnacly.me/linux/c_workflow.webp" alt="c_workflow2"></p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Zoom’s terms of service and practices apply to AI features (284 pts)]]></title>
            <link>https://blog.zoom.us/zooms-term-service-ai/</link>
            <guid>37037196</guid>
            <pubDate>Mon, 07 Aug 2023 16:59:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.zoom.us/zooms-term-service-ai/">https://blog.zoom.us/zooms-term-service-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=37037196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                    
                    <div>
                        <p><a href="https://blog.zoom.us/author/shashim/" title="Smita Hashim">
								                                    <img src="https://blog.zoom.us/wp-content/uploads/2023/03/Smita-headshot-124x124.jpeg" data-src="https://blog.zoom.us/wp-content/uploads/2023/03/Smita-headshot-124x124.jpeg" alt="Smita Hashim" title="Smita Hashim">
								                            </a>
                        </p>
                        
                    </div>
					                        <p><img src="https://blog.zoom.us/wp-content/uploads/2023/02/blog-global-email.png" data-src="https://blog.zoom.us/wp-content/uploads/2023/02/blog-global-email.png" alt="How Zoom’s terms of service and practices apply to AI features">
							                        </p>
					                    <!--?xml encoding="UTF-8" ?--><p>It’s important to us at Zoom to empower our customers with innovative and secure communication solutions. We’ve updated our <a href="https://explore.zoom.us/en/terms/" target="_blank" rel="noreferrer noopener">terms of service</a> (in section 10.4) to further confirm that we will not use audio, video, or chat customer content to train our artificial intelligence models without your consent.</p>



<p>As part of our commitment to transparency and user control, we are providing clarity on our approach to two essential aspects of our services: Zoom’s AI features and customer content sharing for product improvement purposes. Our goal is to enable Zoom account owners and administrators to have control over these features and decisions, and we’re here to shed light on how we do that and how that affects certain customer groups.</p>



<h2><strong>Recent<em> </em>terms<em> </em>of service changes&nbsp;</strong></h2>



<p>We strive to provide transparency about data ownership in our terms of service. These terms of service work together with our privacy statement and in-product privacy notices, which in turn aim to ensure that usage of customer content is based on your consent.&nbsp;&nbsp;</p>



<p>We changed our terms of service in March 2023 to be more transparent about how we use and who owns the various forms of content across our platform.&nbsp;</p>



<ol><li>In Section 10.1 (coupled with 10.6), our intention was to make clear that customers create and own their own video, audio, and chat content. We have permission to use this customer content to provide value-added services based on this content, but our customers continue to own and control their content. For example, a customer may have a webinar that they ask us to livestream on YouTube. Even if we use the customer video and audio content to livestream, they own the underlying content.</li><li>Section 10.2 covers that there is certain information about how our customers in the aggregate use our product — telemetry, diagnostic data, etc. This is commonly known as service generated data. We wanted to be transparent that we consider this to be our data so that we can use service generated data to make the user experience better for everyone on our platform. For example, it is helpful to know generally what time of day in a particular region we have heavy usage so we can better balance loads in our data centers and provide better video quality for all of our users.</li><li>In Section 10.4, our intention was to make sure that if we provided value-added services (such as a meeting recording), we would have the ability to do so without questions of usage rights. The meeting recording is still owned by the customer, and we have a license to that content in order to deliver the service of recording. An example of a machine learning service for which we need license and usage rights is our automated scanning of webinar invites / reminders to make sure that we aren’t unwittingly being used to spam or defraud participants. The customer owns the underlying webinar invite, and we are licensed to provide the service on top of that content.<strong>&nbsp; For AI, we do not use audio, video, or chat content for training our models without customer consent</strong>. </li></ol><h2>What this means for healthcare and education customers</h2>



<p>We will not use customer content, including education records or protected health information, to train our artificial intelligence models without your consent.&nbsp;</p>



<p>We routinely enter into student data protection agreements with our education customers and legally required business associate agreements (BAA) with our healthcare customers. Our practices and handling of education records, pupil data, and protected healthcare data are controlled by these separate terms and applicable laws.</p>



<h2 id="h-generative-ai-features"><strong>Generative AI features</strong></h2>



<p>We recently introduced two powerful generative AI features – Zoom IQ Meeting Summary and Zoom IQ Team Chat Compose – on a <strong>free trial</strong> basis to enhance your Zoom experience. These features offer automated meeting summaries and AI-powered chat composition. <strong>Zoom account owners and administrators control whether to enable these AI features for their accounts.</strong></p>



<p>When you choose to enable Zoom IQ Meeting Summary or Zoom IQ Team Chat Compose, you will also be presented with a transparent consent process for training our AI models using your customer content. Your content is used solely to improve the performance and accuracy of these AI services. And even if you chose to share your data, it will not be used for training of any third-party models.&nbsp;</p>



<h2><strong>Account owners or administrators provide consent&nbsp;</strong></h2>



<p>Here is an example of our UI through which a customer admin opts in to one of our new generative AI features.&nbsp;</p>



<figure><a href="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1.jpg"><img width="960" height="540" alt="" sizes="(max-width: 960px) 100vw, 960px" data-src="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1.jpg" data-srcset="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1.jpg 960w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1-300x169.jpg 300w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1-768x432.jpg 768w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1-540x304.jpg 540w" src="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1.jpg" srcset="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1.jpg 960w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1-300x169.jpg 300w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1-768x432.jpg 768w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_17_Updated-1-540x304.jpg 540w"></a><figcaption>How account owners and administrators enable and control the Zoom IQ for Meeting Summary feature and data sharing.</figcaption></figure><h2><strong>Participants receive notice through our user interface</strong></h2>



<p>We inform you and your meeting participants when Zoom’s generative AI services are in use. Here’s an example of how we provide in-meeting notification.</p>



<figure><a href="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification.jpg"><img loading="lazy" width="960" height="540" alt="" sizes="(max-width: 960px) 100vw, 960px" data-src="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification.jpg" data-srcset="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification.jpg 960w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification-300x169.jpg 300w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification-768x432.jpg 768w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification-540x304.jpg 540w" src="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification.jpg" srcset="https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification.jpg 960w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification-300x169.jpg 300w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification-768x432.jpg 768w, https://blog.zoom.us/wp-content/uploads/2023/08/Slide_18_-_Meeting_Summary_In-Meeting_Notification-540x304.jpg 540w"></a><figcaption>A meeting participant’s view of the Meeting Summary notification once the host enables the feature.</figcaption></figure><p><strong>To reiterate: we do not use audio, video, or chat content for training our models without customer consent.</strong></p>



<p>We remain committed to transparency, and our aim is to provide you with the tools you need to make informed decisions about your Zoom account. We value your privacy and are continuously working to enhance our services while respecting your rights and preferences.</p>



<p>Thank you for being part of the Zoom community. Together, we’ll continue to create meaningful and seamless collaboration experiences through Zoom.</p>



<p><em>Editor’s note: This blog post was edited on August 7th, 2023 at 11:30 a.m. PT to include the most up to date information on our terms of service.&nbsp;</em></p>
                    					                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gnu/Hurd strikes back: How to use the legendary OS in a (somewhat) practical way (258 pts)]]></title>
            <link>https://mhatta.medium.com/gnu-hurd-strikes-back-4021433d506d</link>
            <guid>37036851</guid>
            <pubDate>Mon, 07 Aug 2023 16:38:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mhatta.medium.com/gnu-hurd-strikes-back-4021433d506d">https://mhatta.medium.com/gnu-hurd-strikes-back-4021433d506d</a>, See on <a href="https://news.ycombinator.com/item?id=37036851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="2219">How to use the legendary OS in a (somewhat) practical way</h2><div><a rel="noopener follow" href="https://mhatta.medium.com/?source=post_page-----4021433d506d--------------------------------"><div aria-hidden="false"><p><img alt="Masayuki Hatta" src="https://miro.medium.com/v2/resize:fill:88:88/1*iymbpAmgHzQ4DfBbzlv7fw.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div></div><figure><figcaption>Photo by <a href="https://unsplash.com/@ajebi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ken Goulding</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="1f82">GNU/Hurd is alive and kickin’</h2><p id="9c1b">The <a href="https://en.wikipedia.org/wiki/GNU_Hurd" rel="noopener ugc nofollow" target="_blank">GNU/Hurd</a> is the Sagrada Família of the Software World: having started to develop in 1990, the GNU/Hurd has yet to reach version 1.0. The Linux kernel, on the other hand, began development in 1993 and was initially considered a “kludge” until the Hurd was completed. It is now matured and widely used.</p><p id="7e47">Like the Loch Ness Monster, many believe that GNU/Hurd is vaporware and does not exist. It <strong>does</strong> exist and continues to evolve, albeit at a slow pace. Just recently, the <a href="https://www.gnu.org/software/hurd/news/2023-06-11-debian_gnu_hurd_2023.html" rel="noopener ugc nofollow" target="_blank">Debian GNU/Hurd 2023</a> has been released. You can use the GNU/Hurd right now.</p><h2 id="39db">GNU/Hurd? GNU Hurd? or Debian GNU/Hurd?</h2><p id="9e3e">There has been a well-known <a href="https://en.wikipedia.org/wiki/GNU/Linux_naming_controversy" rel="noopener ugc nofollow" target="_blank">ideological controversy</a> over the names GNU and Linux. Anywise, it would be helpful to sort out the word.</p><p id="0bce">GNU is the name of a Unix-compatible operating system (an acronym of “GNU is Not Unix”), and the <a href="https://www.gnu.org/" rel="noopener ugc nofollow" target="_blank">GNU Project</a> is a project to create GNU. Hence, a flavor of GNU that adopted Linux as its kernel is GNU/Linux. There was also GNU/kFreeBSD, which adopted the FreeBSD kernel, although it has recently been <a href="https://blog.aurel32.net/goodbye-kfreebsd.html" rel="noopener ugc nofollow" target="_blank">discontinued</a>.</p><p id="d754">To simplify it further,</p><ul><li id="e957">Linux = kernel (the core of the operating system).</li><li id="2df7">GNU = so-called user land (the part of the operating system that is not the kernel and that deals with users, such as the GNU Core Utilities, the GNU tool chain such as GCC, etc.).</li></ul><p id="af1f">Unlike the Linux kernel, the Hurd is not a “kernel.” In a way,</p><ul><li id="798a">“Hurd” = GNU Mach (microkernel) + GNU Hurd (system servers) + <a href="https://www.gnu.org/software/hurd/microkernel/mach/mig/gnu_mig.html" rel="noopener ugc nofollow" target="_blank">GNU MIG</a> (Mach Interface Generator)</li></ul><p id="a9b7">are roughly equivalent to a “kernel.” The GNU Hurd is a herd of servers that implements many functions, including user authentication, binary execution, the file system, networking, and even /dev/null as a server separate from the kernel. There are currently <a href="https://www.debian.org/ports/hurd/hurd-doc-server" rel="noopener ugc nofollow" target="_blank">24 servers</a> consisting of the Hurd.</p><figure><figcaption>Linux corresponds to the left, Hurd to the middle, from Wikipedia.</figcaption></figure><p id="1714">So, although slightly imprecise, GNU Hurd (without the slash) is the name of the group of user-mode servers, and GNU/Hurd is the name of the Unix-compatible operating system that uses the “Hurd” as its “kernel.” Therefore, a kind of GNU that adopted the Hurd is an operating system called GNU/Hurd.</p><p id="cfbe">There are already several distributions based on GNU/Hurd. The best known is <a href="https://www.debian.org/ports/hurd/index.en.html" rel="noopener ugc nofollow" target="_blank">Debian GNU/Hurd</a>. I am using this one because I am a Debian developer and familiar with Debian. The <a href="https://guix.gnu.org/en/download/latest/" rel="noopener ugc nofollow" target="_blank">GNU Guix system on the GNU Hurd</a> is another interesting one.</p><h2 id="6f7d">Running Debian GNU/Hurd in the cloud</h2><p id="e39d">The GNU Hurd’s hardware support is poor, so trying to run it on modern physical machines is suicide. In the cloud, however, “virtual” devices are standardized. There is no need to support various devices as in the real world.</p><p id="43d4">However, <a href="https://wiki.libvirt.org/Virtio.html" rel="noopener ugc nofollow" target="_blank">virtio</a> still needs to be supported by the current GNU/Hurd. So we have to get creative. Having a cloud provider based on <a href="https://www.openstack.org/" rel="noopener ugc nofollow" target="_blank">OpenStack</a> would be nice, since we have to tweak the image parameters directly using command line tools. I use <a href="https://fuga.cloud/" rel="noopener ugc nofollow" target="_blank">Fuga Cloud</a>.</p><p id="212c">First, download and deploy the image.</p><pre><span id="a5ed">$ wget http://cdimage.debian.org/cdimage/ports/12.0/hurd-i386/debian-hurd.img.tar.xz<br>$ tar xJf debian-hurd.img.tar.xz</span></pre><p id="e359">This is a 5GB pre-installed image, consisting of 4GB of user space and 1GB of swap space. This should be enough for now, since GNU/Hurd is a tiny OS compared to Linux.</p><p id="7cdf">The next thing you need is an OpenStack command-line tool. For Debian or Ubuntu, for example, there is a <a href="https://packages.debian.org/bookworm/python3-openstackclient" rel="noopener ugc nofollow" target="_blank">python3-openstackclient</a> package. I have no experience with it, but it seems to be available for Windows as well. Then you have to do some setup. Fuga Cloud’s OpenStack CLI tutorials (<a href="https://docs.fuga.cloud/how-to-use-the-openstack-cli-tools-on-linux" rel="noopener ugc nofollow" target="_blank">for Linux</a>, f<a href="https://docs.fuga.cloud/how-to-use-the-openstack-cli-tools-on-windows" rel="noopener ugc nofollow" target="_blank">or Windows</a>) are useful even if you don’t use them.</p><p id="dd47">Now you need to upload the image to the cloud. You need to set the properties: “hw_disk_bus” to “ide” and “hw_vif_model” to “e1000” (or “rtl8139”) as these are only supported devices on GNU/Hurd. Also, uploading may take some time. A progress bar ( — progress) would be nice.</p><pre><span id="57c1">$ openstack image create --property hw_disk_bus=ide --property hw_cdrom_bus=ide --property hw_vif_model=e1000 --disk-format raw --container-format bare "Debian GNU/Hurd 2023" --file debian-hurd.img --progress</span></pre><p id="7af4">After that, you can use the OpenStack web interface to create an instance based on the custom image you just uploaded. I am using one of Fuga Cloud’s cheapest plans (“t2.small”: 1 CPU, 1.23 GB RAM, 20 GiB SSD), but it seems to be enough.</p><p id="dd52">After booting (via GRUB), open the console for now from OpenStack and log in as “root” (the password is empty, so simply hit Enter). After that, you can immediately create your own user account.</p><pre><span id="a26e"># adduser yourloginname</span></pre><figure><figcaption>A gnu will welcome you.</figcaption></figure><p id="c8dd">This image is prepared to configure the network with DHCP, so you should already be able to log in with SSH (using your user account’s login password) once the instance is booted. Then, you put your SSH public key in ~/.ssh/authorized_keys, and you can SSH login as usual.</p><p id="496e">Everything else can be handled similarly to Debian GNU/Linux, because it is Debian after all. If you are using it as a server that is open to the outside world, don’t forget to set the root password.</p><h2 id="c90b">Why GNU/Hurd?</h2><p id="f7bf">GNU/Hurd has a number of interesting features. The most famous of these is probably the <a href="https://www.gnu.org/software/hurd/hurd/translator.html" rel="noopener ugc nofollow" target="_blank">translator</a>. The translator allows users to create local implementations of the programs that handle access to specific directories and files. It is like a supercharged version of mount. It implements symbolic links, sockets, etc. The translator provides extreme flexibility.</p><p id="f34d">It is possible to run multiple instances of the Hurd on a single instance of GNU Mach, the microkernel. It’s called <a href="https://www.gnu.org/software/hurd/hurd/neighborhurd.html" rel="noopener ugc nofollow" target="_blank">neighborhurd</a>. Each neighborhurd is essentially isolated, so it’s like a supercharged Docker. There is also <a href="https://www.gnu.org/software/hurd/hurd/subhurd.html" rel="noopener ugc nofollow" target="_blank">subhurd</a>, which uses some of the resources provided by another Hurd.</p><p id="f0df">Personally, one reason for using GNU/Hurd is that the Linux kernel has become too huge. Look at this:</p><figure><figcaption>Source Lines of Code Comparison. Measured by David A Wheeler’s <a href="https://dwheeler.com/sloccount/" rel="noopener ugc nofollow" target="_blank">SLOCCount</a>.</figcaption></figure><p id="1f5c">I don’t think that anyone is able to grasp the full picture of Linux anymore. It was also said that the Hurd would never be finished because it was too complex and too large. That is no longer the case. <strong>GNU/Hurd is a relatively small OS!</strong> Maybe the development of the microkernel and the Hurd required the development of Linux and the development of virtualization after all.</p><p id="83ac">Also, there are a variety of interesting budding operating systems, but they are largely experimental and often not practically usable; the GNU/Hurd is Unix(POSIX)-compatible, so most things work (roughly 65% of the Debian archive can be built for the Hurd).</p><h2 id="fdfe">Challenges</h2><p id="852e">One big problem would be systemd. systemd has not yet (or forever) been ported to the Hurd. systemd is very popular in the Linux world these days, and there are many packages that depend on systemd. <a href="https://www.gnu.org/software/shepherd/" rel="noopener ugc nofollow" target="_blank">GNU shepherd</a> is promising, but not yet complete.</p><p id="0922">As mentioned above, hardware support for GNU/Hurd is poor, but it is hard to rewrite device drivers from scratch now. <a href="https://rumpkernel.github.io/" rel="noopener ugc nofollow" target="_blank">Rump Kernels</a> is an interesting solution and is being actively implemented (<a href="https://archive.fosdem.org/2022/schedule/event/dzammit/attachments/slides/4850/export/events/attachments/dzammit/slides/4850/rump_hurd_talk.pdf" rel="noopener ugc nofollow" target="_blank">a nice recent FOSDEM presentation PDF</a>).</p><p id="2ee0">And, of course, there are a whole lot of <a href="https://www.gnu.org/software/hurd/open_issues.html" rel="noopener ugc nofollow" target="_blank">open issues</a>.</p><h2 id="153c">Conclusion</h2><p id="e992"><strong>Try GNU/Hurd</strong>! I enjoy it a lot. It’s an old world and a new world. I am pretty sure you will like it too.</p><h2 id="b9a0"><strong>Further Resources</strong></h2><ul><li id="9dd8"><a href="https://www.gnu.org/software/hurd/" rel="noopener ugc nofollow" target="_blank">The Official site of GNU Hurd</a></li><li id="e032"><a href="https://www.debian.org/ports/hurd/index.en.html" rel="noopener ugc nofollow" target="_blank">The Official site of Debian GNU/Hurd</a></li><li id="0938"><a href="https://www.gnu.org/software/hurd/mailing_lists.html" rel="noopener ugc nofollow" target="_blank">Mailing Lists and its archives</a></li><li id="c81e"><a href="https://www.gnu.org/software/hurd/irc.html" rel="noopener ugc nofollow" target="_blank">IRC</a> (Looks like this is still the official communication channel in 2023…)</li></ul><h2 id="11ea">The Source Code of the Hurd</h2><p id="6f7e">They are all managed by Git.</p><ul><li id="fdb1"><a href="https://git.savannah.gnu.org/cgit/hurd/gnumach.git" rel="noopener ugc nofollow" target="_blank">GNU Mach</a></li><li id="a567"><a href="https://git.savannah.gnu.org/cgit/hurd/hurd.git/" rel="noopener ugc nofollow" target="_blank">GNU Hurd</a></li><li id="24c9"><a href="https://git.savannah.gnu.org/cgit/hurd/mig.git/" rel="noopener ugc nofollow" target="_blank">GNU MIG</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Traffic safety “nudges” can cause number of crashes to increase (2022) (106 pts)]]></title>
            <link>https://www.science.org/doi/full/10.1126/science.abm3427</link>
            <guid>37036339</guid>
            <pubDate>Mon, 07 Aug 2023 16:09:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/doi/full/10.1126/science.abm3427">https://www.science.org/doi/full/10.1126/science.abm3427</a>, See on <a href="https://news.ycombinator.com/item?id=37036339">Hacker News</a></p>
Couldn't get https://www.science.org/doi/full/10.1126/science.abm3427: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Kafka Is Dead, Long Live Kafka (298 pts)]]></title>
            <link>https://www.warpstream.com/blog/kafka-is-dead-long-live-kafka</link>
            <guid>37036291</guid>
            <pubDate>Mon, 07 Aug 2023 16:06:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.warpstream.com/blog/kafka-is-dead-long-live-kafka">https://www.warpstream.com/blog/kafka-is-dead-long-live-kafka</a>, See on <a href="https://news.ycombinator.com/item?id=37036291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><h2>TL;DR</h2><p>WarpStream is a Kafka protocol compatible data streaming platform built directly on top of S3. It's delivered as a single, stateless Go binary so there are no local disks to manage, no brokers to rebalance, and no ZooKeeper to operate. WarpStream is 5-10x cheaper than Kafka in the cloud because data streams directly to and from S3 instead of using inter-zone networking, which can be over 80% of the infrastructure cost of a Kafka deployment at scale.</p><p>If you just want to get your hands dirty, you can try <a href="https://docs.warpstream.com/warpstream/tutorials/demo" target="_blank">our demo</a> in under 30s.</p><p>Otherwise, read on!</p><h2>Kafka is Dead, Long Live Kafka</h2><p>Chances are you probably had a strong reaction to the title of this post. In our experience, Kafka is one of the most polarizing technologies in the data space. Some people hate it, some people swear by it, but almost every technology company uses it.</p><p>Kafka was first open sourced in 2011, and quickly became the default infrastructure for building streaming architectures. Jay Kreps' now well-known <a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying" target="_blank">The Log</a> blog post is still one of my favorite blog posts ever because it walks through why the distributed log abstraction that Kafka provides is so powerful.</p><p>But it’s not 2011 anymore. A lot has changed about how we build modern software, primarily a major shift towards cloud environments, and yet Kafka has remained more or the less the same. Many organizations have managed to “lift and shift” Kafka into their cloud environments, but let’s be honest, nobody is really happy with the result. Kafka is expensive, finicky, and difficult to run for most organizations who use it.</p><p>Kafka <em>itself</em> is not the problem. It’s a great piece of software that was well suited for the environment it was created for: LinkedIn’s data centers in 2011. However, it is an unusually poor fit for modern workloads for two reasons:</p><ol role="list"><li>Cloud economics – by design, Kafka’s replication strategy will rack up massive inter AZ bandwidth costs.</li><li>Operational overhead – running your own Kafka cluster literally requires a dedicated team and sophisticated custom tooling.</li></ol><p>We're going to pick on Kafka for the rest of this post, but keep in mind that everything we're saying about Kafka applies equally to any similar system that stores data on locals disks (however briefly), regardless of which programming language its implemented in.</p><h2>Kafka-nomics</h2><p>The diagram below depicts a typical 3 availability zone Kafka cluster:&nbsp;</p><figure><p><img src="https://global-uploads.webflow.com/64baaecd9c5c9b1b6c38aa0e/64c00427b989db231aac3e45_kafka_arch.png" loading="lazy" alt=""></p></figure><p>Every GiB of data that is produced must be written cross zone 2/3rds of the time<sup>1</sup>, and subsequently replicated by the partition leader to the followers in the other two zones for durability and availability reasons. Every time a GiB of data is transferred across zones, it costs $0.02<sup>2</sup>, $0.01 for egress in the source zone and $0.01 for ingress in the destination zone.</p><p>$0.01*⅔ + $0.02 *2 == $0.053 for every GiB of data that you stream through your Kafka cluster <em>in the best case scenario<sup>3</sup></em>. The cost of storing a GiB of data in S3 <em>for a month</em> is only $0.021<sup>4</sup>, so for the same price as copying data from a producer to a consumer via Kafka, you could store that data in S3 <em>for over two months</em>. In practice, for any Kafka cluster with substantial throughput, the hardware costs are negligible since 70-90% of the cost of the workload is just inter-zone bandwidth fees. <a href="https://www.confluent.io/blog/understanding-and-optimizing-your-kafka-costs-part-1-infrastructure/#networking" target="_blank">Confluent has a good write up about this problem as well</a>.</p><p>It’s important to stress that this inter-AZ bandwidth problem is fundamental to how Kafka works. Kafka was designed to run in LinkedIn’s data centers, where the network engineers didn’t charge their application developers for moving data around. But today, most Kafka users are running it on a public cloud, an environment with completely different constraints and cost models. Unfortunately, unless your organization can commit to 10s or 100s of millions of dollars per year in cloud spend, there is no escaping the physics of this problem.</p><p>It’s not just a question of throughput either, even a low throughput Kafka cluster with long retention can have large storage requirements. In this case, Kafka’s approach of triply replicating the data on expensive local SSDs costs roughly 10-20x more<sup>5</sup> per GiB than using object storage like S3 assuming the <em>best case scenario of 100% disk utilization.</em></p><h2>Accidental SRE</h2><p>Most developers first encounter Kafka because they have a real problem they want to solve. However, before they can begin solving their problems, they must first learn about:</p><ol role="list"><li>Kafka (brokers, coordinators, watermarks, etc)</li><li>ZooKeeper (or KRaft)</li><li>Leader elections</li><li>Partitions (how many partitions do I need? Unclear, but better get it right because you can never change it!)</li><li>Consumer groups</li><li>Rebalancing</li><li>Broker tuning</li><li>Client tuning</li><li>etc</li></ol><p>Kafka’s “data plane” (brokers) and consensus-based “control plane” (controllers, ZooKeeper, etc) all run directly on local SSDs that must be managed with expertise and care. In practice, self-hosted Kafka clusters require a dedicated team of experts and significant amounts of custom tooling before even basic operations like node replacements and scaling clusters can be performed safely and reliably. For example, the Apache Kafka built in partition reassignment tool cannot even generate plans for decommissioning brokers when you (inevitably) experience a hardware failure:</p><blockquote>The partition reassignment tool does not have the ability to automatically generate a reassignment plan for decommissioning brokers yet. As such, the admin has to come up with a reassignment plan to move the replica for all partitions hosted on the broker to be decommissioned, to the rest of the brokers. This can be relatively tedious as the reassignment needs to ensure that all the replicas are not moved from the decommissioned broker to only one other broker.</blockquote><p>In many cases, offloading cluster management to a hosted provider like <a href="https://aws.amazon.com/msk/" target="_blank">AWS MSK</a> doesn’t even solve the operational burden problem. For example, the <a href="https://docs.aws.amazon.com/msk/latest/developerguide/bestpractices.html#bestpractices-balance-cluster" target="_blank">MSK documentation on how to rebalance a cluster</a> (a very routine operation) just links to the <a href="https://kafka.apache.org/documentation/#basic_ops_cluster_expansion" target="_blank">Apache Kafka documentation</a> which involves hand-editing JSON to specify which partitions should be migrated to which brokers and includes helpful commentary like:</p><blockquote>The partition reassignment tool does not have the capability to automatically study the data distribution in a Kafka cluster and move partitions around to attain an even load distribution. As such, the admin has to figure out which topics or partitions should be moved around.</blockquote><p>There are open source solutions like <a href="https://github.com/linkedin/cruise-control" target="_blank">Cruise Control</a> that can help ease this burden, but that is yet another set of concepts that need to learned, services that need to deployed and monitored, and sharp edges that need to be encountered. Cruise Control itself is a JVM&nbsp;application that depends on both Apache Kafka and ZooKeeper. Hardly a lightweight solution.</p><p>Unfortunately, in many cases developers set out to solve a business problem, and end up becoming Kafka SREs instead.</p><h2>S3 Is All You Need</h2><p>The high costs of using Kafka (both in dollars and engineering hours) means that today businesses can only afford to use it for their most high value use-cases like fraud detection and CDC. The cost of entry is simply too high for anything else.</p><p>When we were at Datadog, we built <a href="https://www.datadoghq.com/blog/engineering/introducing-husky/" target="_blank">Husky, a columnar database purpose-built for observability data that ran directly on top of S3.</a> When we were done, we had a (mostly) stateless and auto scaling data lake that was extremely cost effective, never ran out of disk space, and was trivial to operate. Almost overnight our Kafka clusters suddenly looked <em>ancient</em> by comparison.</p><p>Kafka bandwidth volumes at Datadog were measured in double-digit GiB/s and broker storage was measured in PiB’s of NVMEs<sup>6</sup>. Maintaining this level of infrastructure using open source Kafka, custom tooling, and bare VMs was no small feat. Luckily the responsible engineering teams at Datadog were extremely capable and made it work, but even after many years of investment, the automation simply couldn’t compete with the millions of engineering hours that have gone into making systems like S3 extremely robust, scalable, cost effective, <em>and elastic</em>.</p><p>In general, large storage workloads running in cloud environments stand no chance of competing with the <a href="https://www.youtube.com/watch?v=sc3J4McebHE" target="_blank">economics, reliability, scalability, and elasticity of object storage</a>. This is why “big data” technologies like Snowflake and Databricks don’t even try. Instead, they <em>lean into</em> cloud economics by designing their systems from the ground up around commodity object storage.</p><p>Companies like Uber, Datadog, and many others have made Kafka work for them despite all of its flaws. But there are <em>so many </em>interesting problems that will never get solved if the existing Kafka implementation remains the barrier to entry. That’s why we care about this space, and that’s why we set out to build something that would make data streaming infrastructure as accessible as S3.</p><p>If we could build a Kafka-like system directly on top of S3, that would solve two of the major problems with Kafka in one fell swoop; costs would be massively reduced, and most traditional Kafka operational headaches would disappear overnight. No major cloud provider charges for networking costs between VMs and object storage, and AWS employs literally <em>hundreds</em> of engineers whose only job is to make sure that S3 runs reliably and scales infinitely, so you don’t have to.</p><p>Of course, that’s easier said than done, and there is a good reason no one has done it yet: figuring out how to build low latency streaming infrastructure on-top of a high latency storage medium like S3, while still providing the full semantics of the Kafka protocol, without introducing <em>any</em> local disks, is a very tricky problem!</p><p>So we asked ourselves: “What would Kafka look like if it was redesigned from the ground up <em>today</em> to run in modern cloud environments, directly on top of object storage, with no local disks to manage, but still had to support the existing Kafka protocol?”</p><p>WarpStream is our answer to that question.</p><h2>Introducing WarpStream</h2><p>WarpStream is a Kafka protocol compatible data streaming platform that runs directly on top of any commodity object store (AWS&nbsp;S3, GCP&nbsp;GCS, Azure Blob Storage, etc). It incurs zero inter-AZ bandwidth costs, has no local disks to manage, and can run completely within your VPC.</p><p>That’s a lot to digest, so let’s unpack it by comparing WarpStream’s architecture to Kafka’s:</p><figure><p><img src="https://global-uploads.webflow.com/64baaecd9c5c9b1b6c38aa0e/64cea23a28ed31049a11cfbf_with1%20(1).png" loading="lazy" alt=""></p></figure><p>Instead of Kafka brokers, WarpStream has “Agents”. Agents are stateless Go binaries (no JVM!) that speak the Kafka protocol, but unlike a traditional Kafka broker, any WarpStream Agent can act as the “leader” for any topic, commit offsets for any consumer group, or act as the coordinator for the cluster. No Agent is special, so auto-scaling them based on CPU-usage or network bandwidth is trivial.</p><p>How did we accomplish this if Apache Kafka requires running Apache ZooKeeper (or KRaft) and a bunch of stateful brokers with local SSDs and replication?</p><ol role="list"><li>We separated storage and compute (by offloading data to S3)</li><li>We separated data from metadata (by offloading metadata to a custom metadata store)</li></ol><p>Offloading all storage to object storage like S3 allows users to trivially scale the number of WarpStream Agents in response to changes in load with <em>zero data rebalancing</em>. It also enables faster recovery from failures because any request can be retried on another Agent immediately. It also mostly eliminates hotspots, where some Kafka brokers would have dramatically higher load than others due to uneven amounts of data in each partition. That means you can say goodbye to manually rebalancing partitions, and don't need to learn about complex solutions like Cruise Control.</p><p>The other pillar of WarpStream's design is separating data from metadata, just like a modern data lake does. We store the metadata for every WarpStream “Virtual Cluster” in a custom metadata database that was written from the ground up to solve this exact problem in the most performant and cost effective way possible. In fact, we’re so confident in the efficiency of our metadata store, we’ll host WarpStream Virtual Clusters for you <a href="https://warpstream.com/pricing"><em>for free</em></a>.</p><p>You can read more about <a href="https://docs.warpstream.com/warpstream/background-information/warpstreams-architecture" target="_blank">WarpStream’s architecture in our documentation</a>, but to summarize: WarpStream offloads all of the hard problems of data replication, durability, and availability to an object storage bucket so you never have to think about it, but all of your data <em>stays inside your cloud account</em>. The only data that ever leaves your cloud account with WarpStream is the workload <em>metadata</em> that is required for consensus, like the order of the batches in your partitions.</p><p>Modern practitioners who want to introduce large scale data streaming pipelines into their infrastructure today don’t have many good choices. They either have to spend a lot of money <em>and</em> create an entire dedicated team of engineers whose only job is to operate Kafka, or they have to pay a vendor for a hosted solution and spend <em>even more money</em>, making many of their streaming use-cases economically infeasible.</p><p>We think WarpStream can provide a better option that leverages the cloud as a strength instead of a weakness, and unlocks a whole new set of possibilities in the data streaming world.</p><p>You don’t just have to take our word for it though, we brought receipts! The image below shows the interzone networking costs of our entire cloud account (measured using the excellent <a href="https://www.vantage.sh/" target="_blank">vantage.sh</a>), including the continuous streaming workload we run in our test environment. This workload continuously produces 140MiB/s of data and consumes it with three dedicated consumers for a total of 560MiB/s in continuous data transfer.</p><figure><p><img src="https://global-uploads.webflow.com/64baaecd9c5c9b1b6c38aa0e/64c035b364da3c257915926f_Screenshot%202023-07-25%20at%203.49.10%20PM.png" loading="lazy" alt=""></p></figure><p>You can see that we average &lt; $15/day in interzone networking fees, whereas the exact same workload run using a Kafka cluster would cost 0.14GiB * $0.053/GiB * 60 * 60 * 24 == <strong>$641</strong> <strong>per day</strong> <strong>in interzone networking fees alone.</strong></p><p>We didn’t just replace these interzone networking costs with hardware or S3 API costs either. This same workload costs &lt; $40/day in S3 API operation costs:</p><figure><p><img src="https://global-uploads.webflow.com/64baaecd9c5c9b1b6c38aa0e/64c035bcfda4aa35de9d76ef_Screenshot%202023-07-25%20at%203.50.11%20PM.png" loading="lazy" alt=""></p></figure><p>It also only requires 27 vCPUs worth of Agent hardware / VMs.</p><p>In terms of total cost of ownership, WarpStream will reduce the cost of most Kafka workloads by 5-10x. For example, here is a comparison of the cost of running a sustained 1GiB/s Kafka workload vs the equivalent using WarpStream:</p><figure><p><img src="https://global-uploads.webflow.com/64baaecd9c5c9b1b6c38aa0e/64d060d06b645b27d6a23140_Screenshot%202023-08-06%20at%2010.10.56%20PM.png" loading="lazy" alt=""></p><figcaption>Footnote 7 for self hosted Kafka hardware costs, footnote 8 for self hosted Kafka network costs.<strong> Note that this table assumes the best case scenario that the Kafka cluster is properly configured to use the follower fetch functionality to reduce interzone networking costs for consumers. If it’s not, the Kafka costs would be much higher.&nbsp;It also omits the cost of engineering salaries for the self hosted Kafka setup.</strong></figcaption></figure><p>The table above demonstrates clearly that for high volume Kafka workloads, the hardware costs are negligible because the cost of the workload is dominated by inter-zone networking fees. WarpStream eliminates those networking fees entirely.</p><p>Of course, it's not all sunshine and rainbows. Engineering is about trade-offs, and we’ve made a significant one with WarpStream: latency. The current implementation has a P99 of ~400ms for Produce requests because we never acknowledge data until it has been durably persisted in S3 and committed to our cloud control plane. In addition, our current P99 latency of data end-to-end from producer-to-consumer is around 1s:</p><figure><p><img src="https://global-uploads.webflow.com/64baaecd9c5c9b1b6c38aa0e/64bff6c3e52acac923301fa7_CaSz12FWNfCOGHT2snOa6q1erJeqvhESfRx_X6ZHt-Fe81JVVgRlXk9wvSamfMnzG5Epjwl5VARA176g8k-kmAGiTancoQOoBT1iDZJgjKXceXv-XFKsnEn2ncDGM4rjeCja_JriSlDDn7LQ9B8vh5o.png" alt=""></p></figure><p>If your workload can tolerate a P99 of ~1s of producer-to-consumer latency, then WarpStream can reduce your total data streaming costs by 5-10x per GiB, with <em>almost</em> zero operational overhead. We don’t have a proprietary interface either; it’s just Kafka, so there is no vendor lock in. Finally, WarpStream runs in any environment with an object store implementation, so we can meet you where you’re at with S3 in AWS, GCS in GCP, and Azure Blob Storage in Azure.</p><p>If you’ve made it this far, you may have noticed that WarpStream mainly addresses two of the major problems with Kafka: cloud economics and operational overhead. We think that there is a third major problem with Kafka: developer UX. In our view, partitions are way too low level of an abstraction to program against for writing any non-trivial stream processing application, and we think that WarpStream’s architecture puts us in a unique position to help developers write stream processing applications in a novel way that’s much closer to how they’re used to writing traditional applications.</p><p>We’ll talk about that more in a future blog post, but the first thing we wanted to do is meet developers where they are and offer them an improved version of a tool they’re already familiar with.</p><p>WarpStream is currently in developer preview. That means you can <a href="https://console.warpstream.com/signup" target="_blank">sign up</a> in a completely self-serve manner, and <a href="https://docs.warpstream.com/warpstream/" target="_blank">follow our documentation</a> to start playing around with it. You can run WarpStream yourself locally on your laptop, or you can even deploy it to your staging environment. WarpStream is not yet ready for production use, but if you’re interested in using it in production we’d love to hear from you. You can reach us on <a href="https://discord.gg/RhECYPHJ" target="_blank">discord</a>, <a href="https://join.slack.com/t/warpstreamlab-uwt2030/shared_invite/zt-20nj8a1v7-HVTTV_MCWsCH7pLuMuObvw" target="_blank">slack</a>, or by emailing us directly at:&nbsp;<a href="mailto:founders@warpstreamlabs.com">founders@warpstreamlabs.com</a></p><p>If you just want to get your hands dirty, you can try <a href="https://docs.warpstream.com/warpstream/tutorials/demo" target="_blank">our demo</a> in under 30s:</p><div><pre><b><span>        $ </span>curl https://console.warpstream.com/install.sh | bash</b></pre>
<pre><b><span>        $ </span>warpstream demo</b></pre></div><p>‍</p><ol start="" role="list"><li>&nbsp;Because the partition leader is in a different zone.</li><li>See the <a href="https://aws.amazon.com/ec2/pricing/on-demand/" target="_blank">“Data transfer within the AWS region”</a> section.</li><li>The worst case scenario is that your Kafka cluster is not configured with the follower fetch feature and you’re paying inter-zone bandwidth fees <em>for each of your consumers </em>as well.</li><li>https://aws.amazon.com/s3/pricing/</li><li>&nbsp;($0.452/hr (i3en.xlarge) * 24 * 30)/(2500GiB) == $0.13/GiB month. $0.13 * 3x replication == $0.39/GiB month vs $0.021/GiB month on S3</li><li>https://www.datadoghq.com/blog/engineering/introducing-kafka-kit-tools-for-scaling-kafka/</li><li>9 * i3en.6xl + ZK</li><li>($(0.04 + ((2/3) * 0.02)) * 60 * 60 * 24 * 365)+$223000</li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Police Raid Worldcoin Warehouse in Nairobi (338 pts)]]></title>
            <link>https://www.capitalfm.co.ke/news/2023/08/police-raid-worldcoin-cryptocurrency-warehouse-in-nairobi/</link>
            <guid>37036277</guid>
            <pubDate>Mon, 07 Aug 2023 16:05:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.capitalfm.co.ke/news/2023/08/police-raid-worldcoin-cryptocurrency-warehouse-in-nairobi/">https://www.capitalfm.co.ke/news/2023/08/police-raid-worldcoin-cryptocurrency-warehouse-in-nairobi/</a>, See on <a href="https://news.ycombinator.com/item?id=37036277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
            <!-- Share buttons by mashshare.net - Version: 3.8.9-->
<p><strong>NAIROBI, Kenya, Aug 7 – Police raided a warehouse belonging to WorldCoin cryptocurrency in Nairobi and carted away documents over the weekend.</strong>



</p><p>The officers went to the offices along Mombasa Road armed with a search warrant and left with machines they believe stores data gathered by the firm.



</p><p>The team took the data to the Directorate of Criminal Investigations headquarters for analysis.



</p><p>Data Commissioner Immaculate Kassait defended her office and said Tools for Humanity, the parent company of Worldcoin, failed to disclose its true intentions during registration.



</p><p>The government has suspended Worldcoin’s operations in Kenya, citing security concerns paving the way for investigations into the activities of the company.



</p><p>However, privacy experts worry that sensitive data gathered from scanning a person’s iris might get into the wrong hands.



</p><p>The Kenyan Capital Markets Authority (CMA) stated it was concerned about the ongoing registration and notified Kenyans that Worldcoin was not regulated in Kenya.



</p><p>Under Kenyan law, individuals have a right to not have any personal information unnecessarily required or unnecessarily revealed.



</p><p>Worldcoin, founded by US tech entrepreneur Sam Altman, offers free crypto tokens to people who agree to have their eyeballs scanned.</p>



<p>&nbsp;On Thursday, Worldcoin said it is planning to implement crowd-control measures and collaborate with the government before resuming work.



</p><p>Worldcoin, founded by US tech entrepreneur Sam Altman, offers free crypto tokens to people who agree to have their eyeballs scanned.



</p><p>It claims to be creating a new global “identity and financial network”.



</p><p>Altman, who founded Open AI, which built chat bot ChatGPT, says he hopes the initiative will help confirm if someone is a human or a robot. He also says this could lead to everyone being paid a universal basic income but it is not clear how.



</p><p>Worldcoin says it chose Kenya as the first African country to launch the platform because of the already booming tech space, and the more than four million Kenyans who are already trading in crypto.



</p><p>It has also launched in various countries including Indonesia, France Japan, Germany, Spain and the UK. Data watchdogs in some countries have already said they are examining Worldcoin.



</p><p>Interior Cabinet Secretary Kithure Kindiki suspended the firm’s activities in Kenya to pave the way for a probe into the legality of its operations.



</p><p>He Thursday appeared before Parliament to among other issues state the precautionary steps taken by the government on the already mined data.



</p><p>“The aforesaid entity is not registered as a legal entity in Kenya.”</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to generate tested software packages using LLMs, a sandbox and a while loop (116 pts)]]></title>
            <link>https://github.com/modal-labs/devlooper</link>
            <guid>37035448</guid>
            <pubDate>Mon, 07 Aug 2023 15:03:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/modal-labs/devlooper">https://github.com/modal-labs/devlooper</a>, See on <a href="https://news.ycombinator.com/item?id=37035448">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><g-emoji alias="hatched_chick" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f425.png">🐥</g-emoji> devlooper</h2>
<p dir="auto"><code>devlooper</code> is a program synthesis agent that autonomously fixes its output by running tests!</p>
<p dir="auto">Here's <code>devlooper</code> in action, taking 11 iterations to create a Python library that generates voronoi diagrams:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/5786378/257645025-0dfa6086-96e2-484b-92c8-23d1017471ab.gif"><img width="600" alt="devlooper demo" src="https://user-images.githubusercontent.com/5786378/257645025-0dfa6086-96e2-484b-92c8-23d1017471ab.gif"></a>
</p>
<h2 tabindex="-1" dir="auto">⚙️ How it works</h2>
<p dir="auto">This project extends <a href="https://github.com/smol-ai/developer">smol developer</a> by giving it access to a <a href="https://modal.com/docs/guide/sandbox" rel="nofollow">sandbox</a> to run tests in. The agent iterates until all tests pass, by updating the code and fixing the environment (installing packages).</p>
<h3 tabindex="-1" dir="auto"><g-emoji alias="package" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4e6.png">📦</g-emoji> Environment templates</h3>
<p dir="auto">The project uses environment "templates" to define the basic setup and test harness for a given language/framework. For now, three templates are provided:</p>
<ul dir="auto">
<li>React + Jest</li>
<li>Python</li>
<li>Rust</li>
</ul>
<p dir="auto">However, any language/framework should work, as long as it can be installed within a container. Contributions for more templates are welcome (see <a href="https://github.com/modal-labs/devlooper/blob/main/src/env_templates.py"><code>env_templates.py</code></a>).</p>
<h3 tabindex="-1" dir="auto">🏖️ Sandbox</h3>
<p dir="auto">We use <a href="http://modal.com/" rel="nofollow">Modal</a>'s new <a href="https://modal.com/docs/guide/sandbox" rel="nofollow">Sandbox</a> primitive to run tests in an isolated environment and fetch the output. This allows us to construct the image incrementally as well (similar to building up a Dockerfile in layers that are cached).</p>
<h3 tabindex="-1" dir="auto"><g-emoji alias="robot" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f916.png">🤖</g-emoji> Debug loop</h3>
<p dir="auto">In each iteration, the agent runs the test command for the environment. If a non-zero exit code is received, the agent passes the <code>stdout</code> and <code>stderr</code> from the sandbox to the LLM to diagnose the error. This diagnosis is used in a separate step to generate a <code>DebugPlan</code> consisting of three types of actions:</p>
<ol dir="auto">
<li>Inspect and fix a file</li>
<li>Install a package in the image</li>
<li>Run commands in the image</li>
</ol>
<p dir="auto">More types of actions can be implemented pretty easily — once again, contributions are welcome!</p>
<p dir="auto">Running the diagnosis as a separate step seems to boost model accuracy by quite a bit (instead of immediately predicting the <code>DebugPlan</code>). We suspect the benefits are similar to why Chain-of-Thought prompting works so well.</p>
<h2 tabindex="-1" dir="auto">🧑‍🚀 Usage</h2>
<h3 tabindex="-1" dir="auto">Set up</h3>
<ul dir="auto">
<li>Create a <a href="http://modal.com/" rel="nofollow">Modal</a> account (<a href="mailto:akshat@modal.com">reach out to us</a> if you are still on the waitlist!)</li>
<li>Install <code>modal</code> in your current Python environment</li>
</ul>

<ul dir="auto">
<li>Create a Modal token</li>
</ul>

<ul dir="auto">
<li>Create an <a href="https://openai.com/" rel="nofollow">OpenAI</a> account and get an API key</li>
<li><a href="https://modal.com/secrets/create" rel="nofollow">Create a Modal secret</a> named <code>openai-secret</code></li>
</ul>
<h3 tabindex="-1" dir="auto">Generate!</h3>
<p dir="auto">You're ready to generate! From the root directory of this repo, <code>modal run</code> the program with your choice of <code>prompt</code> and <code>template</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="modal run src.main --prompt=&quot;a simple 2D graphics library&quot; --template=&quot;rust&quot;"><pre>modal run src.main --prompt=<span><span>"</span>a simple 2D graphics library<span>"</span></span> --template=<span><span>"</span>rust<span>"</span></span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="modal run src.main --prompt=&quot;a todo-list app&quot; --template=&quot;react&quot;"><pre>modal run src.main --prompt=<span><span>"</span>a todo-list app<span>"</span></span> --template=<span><span>"</span>react<span>"</span></span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="modal run src.main --prompt=&quot;a webscraper that checks if there are new reservations for a given restaurant on Resy&quot; --template=&quot;python&quot;"><pre>modal run src.main --prompt=<span><span>"</span>a webscraper that checks if there are new reservations for a given restaurant on Resy<span>"</span></span> --template=<span><span>"</span>python<span>"</span></span></pre></div>
<p dir="auto">Once all tests pass, the output will be written to <code>output/</code> in the same directory by default. This can be overridden using <code>--output-path</code>.</p>
<h2 tabindex="-1" dir="auto">✨ Showcase</h2>
<p dir="auto"><em>Coming soon</em></p>
<h2 tabindex="-1" dir="auto"><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">🔮</g-emoji> Future directions</h2>
<p dir="auto">This project is mostly a proof of concept, and there's a lot of cool additions that will make this better. Here are some ideas:</p>
<ul dir="auto">
<li>Allowing feedback from users in the loop, or accepting an existing project + plan as input and making suggested changes to it.</li>
<li>Making the debugging prompt better with relevant parts of the code, retrieved using embeddings.</li>
<li>Go out and fetch the documentation for a package if needed.</li>
<li>Using previous edits in the prompt somewhere to prevent the model from going into a loop.</li>
<li>Synthesizing <code>EnvTemplate</code>s from scratch.</li>
<li>Generalizing this to more LLMs, including open-source ones!</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Snappy UIs with WebAssembly and Web Workers (119 pts)]]></title>
            <link>https://mofi.loud.red/blog/wasm-and-workers</link>
            <guid>37035178</guid>
            <pubDate>Mon, 07 Aug 2023 14:45:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mofi.loud.red/blog/wasm-and-workers">https://mofi.loud.red/blog/wasm-and-workers</a>, See on <a href="https://news.ycombinator.com/item?id=37035178">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2>Snappy UIs With WebAssembly and Web Workers</h2>
	<p>Published: 2023-08-07</p>
	<p>Our web app allows users can change the length of a song or find loops present in it for infinite listening, remixing, or for their next next video edit or performance. After uploading a song, there is an initial server-side analysis step after which the audio can be manipulated completely in the browser. Users can alter the desired length or mark sections of audio to prefer or avoid which will regenerate results. To make these manipulations responsive and snappy, computations happen client-side and do not need another network call (which would introduce additional latency). To make this possible, we rely on using a <a href="https://developer.mozilla.org/en-US/docs/WebAssembly" rel="noopener" target="_blank">WebAssembly</a> binary executed inside of a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers" rel="noopener" target="_blank">Web Worker</a> (several of them actually, running in parallel). In this post, we will go over some more details of how this works.</p>
<h3>Running Fast(er) With WebAssembly</h3>
<p><a href="https://developer.mozilla.org/en-US/docs/WebAssembly" rel="noopener" target="_blank">WebAssembly</a> allows web developers to use low-level code delivered in a binary format that runs at speeds you would not be able to achieve with just JavaScript. WebAssembly (or Wasm for short) describes a low-level assembly-like language that can be targeted from a higher-level language like C, C++, or Rust. The nice thing is that you get to choose which language you want to use, as long as you can find a way to compile it down to a Wasm binary!</p>
<p>We use <a href="https://www.assemblyscript.org/" rel="noopener" target="_blank">AssemblyScript</a> which allows us to write our high-level code in TypeScript (strongly typed JavaScript). Since the rest of our client-side code is also written in TypeScript (which in turn gets compiled to “regular” JavaScript), this allows us to share code between the code delivered as part of our UI (using JS) and the binary (using Wasm). We get to share type definitions of the data being passed in and out of the compiled binary and some interop that makes it easier to pass data back and forth. While code written with AssemblyScript looks very similar to TypeScript, it needs some modifications before being able to be compiled with AssemblyScript (by defining more granular types for example).</p>
<p>AssemblyScript code might look something like the following:</p>
<pre><!-- HTML_TAG_START --><code><span>export</span> <span>function</span> <span>compute</span><span>(</span>array<span>:</span> StaticArray<span>&lt;</span>f64<span>&gt;</span><span>,</span> target<span>:</span> i32<span>)</span><span>:</span> Result <span>{</span>
	<span>const</span> total <span>=</span> <span>10</span><span>;</span>
	<span>const</span> sum <span>=</span> <span>0</span><span>;</span>

	<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> total<span>;</span> i<span>++</span><span>)</span> <span>{</span>
		sum <span>+=</span> array<span>[</span>i<span>]</span><span>;</span>
	<span>}</span>

	<span>return</span> <span>{</span> sum <span>}</span><span>;</span>
<span>}</span></code><!-- HTML_TAG_END --></pre>
<p>Here, we are writing a function that sums up the first 10 items from <code>array</code> and returns it wrapped in an object. In our code, we return more than just one item inside of this object. The nice thing with AssemblyScript is that it will take care of properly passing this structured data across the JS/Wasm boundary.</p>
<h3>Keeping Things Responsive With Web Workers</h3>
<p>While the Wasm binary is faster than a JavaScript implementation would be, it still takes a non-neglible time to run. If we were to just call the <code>compute</code> function inside of our Svelte front-end, we would run it in the main thread and lock up the UI, causing a bad user experience as the webpage would appear frozen. To fix this, we run that code inside of a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers" rel="noopener" target="_blank">Web Worker</a>. Doing this will allow us to run the search algorithm in a separate thread so the main thread is available to respond to the user.</p>
<p>In our case, to perform a search, a worker needs some context on the structure of the song. We first initialize a worker with the song analysis results from the server (this requires us to send data from the main thread into the worker thread), then ask it to execute a search with the target length. Since this context only changes when the user changes the song they are working on, we can reuse a worker given we are editing the same song and just need to vary the target duration or the preferences.</p>
<p>Since that code runs in separate execution context in a separate thread, how can we implement cross-thread communication? Using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Channel_Messaging_API" rel="noopener" target="_blank">Channel Messaging API</a>’s <code>postMessage</code> method! This method allows us to send a message across the thread boundary.</p>
<p>Our code that manages the worker looks something like the following:</p>
<pre><!-- HTML_TAG_START --><code><span>import</span> Worker <span>from</span> <span>"./worker?worker"</span><span>;</span>

<span>const</span> worker <span>=</span> <span>new</span> <span>Worker</span><span>(</span><span>)</span><span>;</span>

<span>// intialize the worker</span>
worker<span>.</span><span>postMessage</span><span>(</span><span>{</span>
	type<span>:</span> <span>"populate"</span><span>,</span>
	data<span>:</span> <span>new</span> <span>Float64Array</span><span>(</span>searchContext<span>)</span><span>,</span>
<span>}</span><span>)</span><span>;</span>
<span>// wait for worker to be initialized (see "loaded" event below)</span>

<span>function</span> <span>search</span><span>(</span>
	<span>callback</span><span>:</span> <span>(</span>ratio<span>:</span> Result<span>)</span> <span>=&gt;</span> <span>void</span><span>,</span>
	target<span>:</span> <span>number</span><span>,</span>
	onProgress<span>?</span><span>:</span> <span>(</span>ratio<span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> <span>void</span><span>,</span>
<span>)</span> <span>{</span>
	worker<span>.</span><span>onmessage</span> <span>=</span> <span>(</span><span>{</span> data<span>:</span> <span>{</span> type<span>,</span> data <span>}</span> <span>}</span><span>)</span> <span>=&gt;</span> <span>{</span>
		<span>if</span> <span>(</span>type <span>===</span> <span>"finish"</span><span>)</span> <span>{</span>
			<span>callback</span><span>(</span>data <span>as</span> Result<span>)</span><span>;</span>
			<span>// check if there are waiting tasks</span>
		<span>}</span> <span>else</span> <span>if</span> <span>(</span>type <span>===</span> <span>"progress"</span><span>)</span> <span>{</span>
			onProgress<span>?.</span><span>(</span>data<span>)</span><span>;</span>
		<span>}</span>
	<span>}</span><span>;</span>

	<span>// execute search</span>
	worker<span>.</span><span>postMessage</span><span>(</span><span>{</span>
		type<span>:</span> <span>"process"</span><span>,</span>
		data<span>:</span> <span>{</span> target <span>}</span><span>,</span>
	<span>}</span><span>)</span><span>;</span>
<span>}</span></code><!-- HTML_TAG_END --></pre>
<p>The <code>worker.ts</code> referenced above (the <code>?worker</code> suffix is a <a href="https://vitejs.dev/guide/features.html#web-workers" rel="noopener" target="_blank">Vite feature</a>) has some code to handle the messages from the main thread and copy the search context into its local memory and then run our WebAssembly code when needed:</p>
<pre><!-- HTML_TAG_START --><code><span>let</span> cachedData<span>:</span> Float64Array<span>;</span>

<span>onmessage</span> <span>=</span> <span>async</span> <span>(</span><span>{</span> data<span>:</span> <span>{</span> type<span>,</span> data <span>}</span> <span>}</span><span>:</span> <span>{</span> data<span>:</span> <span>{</span> type<span>:</span> <span>string</span><span>;</span> data<span>:</span> <span>any</span> <span>}</span> <span>}</span><span>)</span> <span>=&gt;</span> <span>{</span>
	<span>const</span> <span>{</span> compute <span>}</span> <span>=</span> <span>await</span> <span>import</span><span>(</span><span>"./wasm/assembly"</span><span>)</span><span>;</span>

	<span>if</span> <span>(</span>type <span>===</span> <span>"populate"</span><span>)</span> <span>{</span>
		cachedData <span>=</span> data<span>;</span>

		<span>postMessage</span><span>(</span><span>{</span>
			type<span>:</span> <span>"loaded"</span><span>,</span>
		<span>}</span><span>)</span><span>;</span>
	<span>}</span> <span>else</span> <span>if</span> <span>(</span>type <span>===</span> <span>"process"</span><span>)</span> <span>{</span>
		<span>const</span> <span>{</span> target <span>}</span> <span>=</span> data<span>;</span>

		<span>postMessage</span><span>(</span><span>{</span>
			type<span>:</span> <span>"finish"</span><span>,</span>
			data<span>:</span> <span>compute</span><span>(</span>cachedData<span>,</span> target<span>)</span><span>,</span>
		<span>}</span><span>)</span><span>;</span>
	<span>}</span>
<span>}</span><span>;</span></code><!-- HTML_TAG_END --></pre>
<p>Note: as <a href="https://news.ycombinator.com/item?id=36489267" rel="noopener" target="_blank">pointed out on Hacker News</a>, if you are running Firefox, the dynamic import above <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1540913" rel="noopener" target="_blank">requires Firefox 113 or newer</a>.</p>
<p>As mentioned before, keeping a copy of the search result is possible since the analysis context required is shared across searches. This avoids some overhead when the user initializes a new search (by altering the target length or region preferences) by avoiding having to copy it in for every search.</p>
<h3>Reusing Workers</h3>
<p>In Mofi, users get to choose from multiple results of generated songs. Since these searches can run in parallel and we want to get results shown to the user as quickly as possible, we run multiple instances of Web Workers at the same time. This allows us to have results “trickle in” as each worker finishes processing.</p>
<p><img src="https://mofi.loud.red/_app/immutable/assets/results.72e94103.png" alt="Screenshot of multiple search results"></p>
<p>We don’t want to run too many workers at once, however: after we reach the number of physical cores, the cost of switching between threads starts to outweight the benefits of parallelization and computation incurs a performance hit. To manage this, we use a pool of workers. When a new request comes in to look for a result, we try to find a worker that will handle the request:</p>
<ul><li>If we haven’t filled the pool of workers yet, we have space to create one, so we initialize a new instance of the worker and populate it with data. Once it has finished initialization, we can send over the request.</li>
<li>If there is an idle worker in our pool, we take one and let it perform the search. The advantage of this is that reusing the worker allows us to skip initialization since it already has the context needed to perform the search.</li>
<li>If there is no idle worker, we add the request along with a callback to a list of waiting tasks. Once a worker finishes a task, the scheduler takes the next task off of the queue and processes it.</li></ul>
<p>Having a pool of workers also let’s us stop all searches by terminating all workers:</p>
<pre><!-- HTML_TAG_START --><code><span>export</span> <span>function</span> <span>terminate</span><span>(</span><span>)</span> <span>{</span>
	waitingTasks <span>=</span> <span>[</span><span>]</span><span>;</span>
	busyWorkers<span>.</span><span>forEach</span><span>(</span><span>(</span>worker<span>)</span> <span>=&gt;</span> worker<span>.</span><span>terminate</span><span>(</span><span>)</span><span>)</span><span>;</span>
	busyWorkers <span>=</span> <span>[</span><span>]</span><span>;</span>
<span>}</span></code><!-- HTML_TAG_END --></pre>
<p>This happens when the user issues a new search. At this point, all running workers are looking for outdated results so we don’t need them anymore.</p>
<h3>Tip: Progress Updates</h3>
<p>A worker can only return data once completed, but we also want to show a progress indicator even when its task has not finished. To do this, inside of the worker code, we create a global <code>onProgress</code> helper function that allows us to send a message to the main thread like this:</p>
<pre><!-- HTML_TAG_START --><code><span>(</span>globalThis <span>as</span> <span>any</span><span>)</span><span>.</span><span>onProgress</span> <span>=</span> <span>(</span>ratio<span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> <span>{</span>
	<span>postMessage</span><span>(</span><span>{</span>
		type<span>:</span> <span>"progress"</span><span>,</span>
		data<span>:</span> ratio<span>,</span>
	<span>}</span><span>)</span><span>;</span>
<span>}</span><span>;</span></code><!-- HTML_TAG_END --></pre>
<p>Then, inside the AssemblyScript code, we can add this:</p>
<pre><!-- HTML_TAG_START --><code><span><span>@</span><span>external</span></span><span>(</span><span>"env"</span><span>,</span> <span>"onProgress"</span><span>)</span>
<span>export</span> <span>declare</span> <span>function</span> <span>onProgress</span><span>(</span>ratio<span>:</span> <span>number</span><span>)</span><span>:</span> <span>void</span><span>;</span></code><!-- HTML_TAG_END --></pre>
<p>which allows us to “import” the function and call it inside of the Wasm binary and send incremental updates before returning the final result:</p>
<pre><!-- HTML_TAG_START --><code><span><span>+</span><span> import { onProgress } from "./glue";
</span></span>
export function compute(array: StaticArray&lt;f64&gt;, target: i32): Result {
	const total = 10;
	const sum = 0;

	for (let i = 0; i &lt; total; i++) {
		sum += array[i];
<span><span>+</span><span>		onProgress(i / total);
</span></span>	}

	return { sum };
}</code><!-- HTML_TAG_END --></pre>
<p>This is a simplified example and this loop would finish fast, but in the case of long-running loop iterations the progress updates will be more beneficial.</p>
<h3>Wrapping Up</h3>
<p>Using WebAssembly and Web Workers, we are able to shift the iterative aspect of Mofi’s audio manipulation to the client to make the experience more responsive and snappy. This project was exciting for me to build because it got me using novel web technologies to build a performant application that mostly runs in the browser. In the future, I hope to be able to analyze the audio in the browser too, but it looks difficult to do at this stage.</p>
<p>Thank you for reading, and if you haven’t already, please give Mofi a try!</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fantastic Learning Resources (174 pts)]]></title>
            <link>https://matklad.github.io/2023/08/06/fantastic-learning-resources.html</link>
            <guid>37034994</guid>
            <pubDate>Mon, 07 Aug 2023 14:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2023/08/06/fantastic-learning-resources.html">https://matklad.github.io/2023/08/06/fantastic-learning-resources.html</a>, See on <a href="https://news.ycombinator.com/item?id=37034994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>

    <h2>
    <a href="#Fantastic-Learning-Resources"><span>Fantastic Learning Resources</span> <time datetime="2023-08-06">Aug 6, 2023</time></a>
    </h2>
<p><span>People sometimes ask me: </span>“<span>Alex, how do I learn X?</span>”<span>. This article is a compilation of advice I</span>
<span>usually give. This is </span>“<span>things that worked for me</span>”<span> rather than </span>“<span>the most awesome things on earth</span>”<span>. I</span>
<span>do consider every item on the list to be fantastic though, and I am forever grateful to people</span>
<span>putting these resources together.</span></p>
<section id="Learning-to-Code">

    <h2>
    <a href="#Learning-to-Code"><span>Learning to Code</span> </a>
    </h2>
<p><span>I don</span>’<span>t think I have any useful advice on how to learn programming from zero. The rest of the post</span>
<span>assumes that you at least can, given sufficient time, write simple programs. E.g., a program that</span>
<span>reads a list of integers from an input textual file, sorts them using a quadratic algorithm, and</span>
<span>writes the result to a different file.</span></p>
</section>
<section id="Project-Euler">

    <h2>
    <a href="#Project-Euler"><span>Project Euler</span> </a>
    </h2>
<p><a href="https://projecteuler.net/archives">https://projecteuler.net/archives</a><span> is fantastic. The first 50 problems or so are a perfect </span>“<span>drill</span>”
<span>to build programming muscle, to go from </span>“<span>I can write a program to sort a list of integers</span>”<span> to </span>“<span>I can</span>
<em><span>easily</span></em><span> write a program to sort a list of integers</span>”<span>.</span></p>
<p><span>Later problems are very heavily math based. If you are mathematically inclined, this is perfect </span>—
<span>you got to solve fun puzzles while also practicing coding. If advanced math isn</span>’<span>t your cup of tea,</span>
<span>feel free to stop doing problems as soon as it stops being fun.</span></p>
</section>
<section id="Modern-Operating-System">

    <h2>
    <a href="#Modern-Operating-System"><span>Modern Operating System</span> </a>
    </h2>
<p><a href="https://en.wikipedia.org/wiki/Modern_Operating_Systems">https://en.wikipedia.org/wiki/Modern_Operating_Systems</a><span> is fantastic. A </span><a href="https://en.wikipedia.org/wiki/Operating_Systems:_Design_and_Implementation"><span>version of the</span>
<span>book</span></a><span> was the first</span>
<span>thick programming related tome I devoured. It gives a big picture of the inner workings of software</span>
<span>stack, and was a turning point for me personally. After reading this book I realized that I want to</span>
<span>be a programmer.</span></p>
</section>
<section id="Nand-to-Tetris">

    <h2>
    <a href="#Nand-to-Tetris"><span>Nand to Tetris</span> </a>
    </h2>
<p><a href="https://www.nand2tetris.org/">https://www.nand2tetris.org</a><span> is fantastic. It plays a similar </span>“<span>big picture</span>”<span> role as MOS,</span>
<span>but this time you are the painter. In this course you build a whole computing system yourself,</span>
<span>starting almost from nothing. It doesn</span>’<span>t teach you how the real software/hardware stack works, but</span>
<span>it thoroughly dispels any magic, and is extremely fun.</span></p>
</section>
<section id="CSES-Problem-Set">

    <h2>
    <a href="#CSES-Problem-Set"><span>CSES Problem Set</span> </a>
    </h2>
<p><a href="https://cses.fi/problemset/">https://cses.fi/problemset/</a><span> is fantastic. This is a list of algorithmic problems, which is</span>
<span>meticulously crafted to cover all the standard topics to a reasonable depth. This is by far the best</span>
<span>source for practicing algorithms.</span></p>
</section>
<section id="Programming-Languages">

    <h2>
    <a href="#Programming-Languages"><span>Programming Languages</span> </a>
    </h2>
<p><a href="https://www.coursera.org/learn/programming-languages">https://www.coursera.org/learn/programming-languages</a><span> is fantastic. This course is a whirlwind tour</span>
<span>across several paradigms of programming, and makes you really </span><em><span>get</span></em><span> what programming languages are</span>
<span>about (and variance).</span></p>
</section>
<section id="Compilers">

    <h2>
    <a href="#Compilers"><span>Compilers</span> </a>
    </h2>
<p><a href="http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=Compilers">http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=Compilers</a><span> is fantastic. In this</span>
<span>course, you implement a working compiler for a simple, but real programming language. Note that you</span>
<span>can implement your compiler in any language.</span></p>
</section>
<section id="Software-Architecture">

    <h2>
    <a href="#Software-Architecture"><span>Software Architecture</span> </a>
    </h2>
<p><a href="https://www.tedinski.com/archive/">https://www.tedinski.com/archive/</a><span> is fantastic. Work through the whole archive in chronological</span>
<span>order. This is by far the best resource on </span>“<span>programming in the large</span>”<span>.</span></p>
</section>
<section id="Random-Bits-of-Advice">

    <h2>
    <a href="#Random-Bits-of-Advice"><span>Random Bits of Advice</span> </a>
    </h2>
<p><span>What follows are some things I</span>’<span>ve learned for myself. Take with a pinch of salt!</span></p>
<section id="On-Mentorship">

    <h3>
    <a href="#On-Mentorship"><span>On Mentorship</span> </a>
    </h3>
<p><span>Having a great mentor is fantastic, but mentors are not always available. Luckily, programming can</span>
<span>be mastered without a mentor, if you got past the initial learning step. When you code, you get </span><em><span>a</span>
<span>lot</span></em><span> of feedback, and, through trial and error, you can process the feedback to improve your skills.</span>
<span>In fact, the hardest bit is actually finding the problems to solve (and this article suggests many).</span>
<span>But if you have the problem, you can self-improve noticing the following:</span></p>
<ul>
<li>
<span>How you verify that the solution works.</span>
</li>
<li>
<span>Common bugs and techniques to avoid them in the future.</span>
</li>
<li>
<span>Length of the solution: can you solve the problem using shorter, simpler code?</span>
</li>
<li>
<span>Techniques </span>—<span> can you apply anything you</span>’<span>ve read about this week? How would the problem be solved</span>
<span>in Haskell? Could you apply pattern from language X in language Y?</span>
</li>
</ul>
<p><span>In this context it is important to solve the same problem repeatedly. E.g., you could try solving</span>
<span>the same model problem in all languages you know, with a month or two break between attempts.</span>
<span>Repeatedly doing the same thing and noticing differences and similarities between tries is the</span>
<span>essence of self-learning.</span></p>
</section>
<section id="On-Programming-Languages">

    <h3>
    <a href="#On-Programming-Languages"><span>On Programming Languages</span> </a>
    </h3>
<p><span>Learning your first programming language is a nightmare, because you are learning your editing</span>
<span>environment (PyScripter, IntelliJ IDEA, VS Code) first, simple algorithms second, and the language</span>
<span>itself third. It gets much easier afterwards!</span></p>
<p><span>Learning different programming languages is one of the best way to improve your programming skills.</span>
<span>By seeing what</span>’<span>s similar, and what</span>’<span>s different, you deeper learn how the things work under the hood.</span>
<span>Different languages put different idioms to the forefront, and learning several expands your</span>
<span>vocabulary considerably. As a bonus, after learning N languages, learning N+1st becomes a question</span>
<span>of skimming through the official docs.</span></p>
<p><span>In general, you want to cover big families of languages: Python, Java, Haskell, C, Rust, Clojure</span>
<span>would be a good baseline. Erlang, Forth, and Prolog would be good additions afterwards.</span></p>
</section>
<section id="On-Algorithms">

    <h3>
    <a href="#On-Algorithms"><span>On Algorithms</span> </a>
    </h3>
<p><span>There are three levels of learning algorithms</span></p>
<dl>
<dt><span>Level 1</span></dt>
<dd>
<p><span>You are not actually learning algorithms, you are learning programming. At this stage, it doesn</span>’<span>t</span>
<span>matter how long your code is, how pretty it is, or how efficient it is. The only thing that</span>
<span>matters is that it solve the problem. Generally, this level ends when you are fairly comfortable</span>
<span>with recursion. Few first problems from Project Euler are a great resource here.</span></p>
</dd>
<dt><span>Level 2</span></dt>
<dd>
<p><span>Here you learn algorithms proper. The goal here is mostly encyclopedic knowledge of common</span>
<span>techniques. There are quite a few, but not too many of those. At this stage, the most useful thing</span>
<span>is understanding the math behind the algorithms </span>—<span> being able to explain algorithm using</span>
<span>pencil&amp;paper, prove its correctness, and analyze Big-O runtime. Generally, you want to learn the</span>
<span>name of algorithm or technique, read and grok the full explanation, and then implement it.</span></p>
<p><span>I recommend doing an abstract implementation first (i.e., not </span>“<span>HashMap to solve problem X</span>”<span>, but</span>
“<span>just HashMap</span>”<span>). Include tests in your implementation. Use randomized testing (e.g., when testing</span>
<span>sorting algorithms, don</span>’<span>t use a finite set of example, generate a million random ones).</span></p>
<p><span>It</span>’<span>s OK and even desirable to implement the same algorithm multiple times. When solving problems,</span>
<span>like CSES, you </span><em><span>could</span></em><span> abstract your solutions and re-use them, but it</span>’<span>s better to code everything</span>
<span>from scratch every time, until you</span>’<span>ve fully internalized the algorithm.</span></p>
</dd>
<dt><span>Level 3</span></dt>
<dd>
<p><span>One day, long after I</span>’<span>ve finished my university, I was a TA for an algorithms course. The lecturer</span>
<span>for the course was the person who originally taught me to program, through a similar algorithms</span>
<span>course. And, during one coffee break, he said something like</span></p>

<figure>
<blockquote><p><span>We don</span>’<span>t teach algorithms so that students can code Dijkstra with their eyes closed on the job.</span>
<span>They probably won</span>’<span>t have to code any fancy algorithms themselves.</span></p>
<p><span>We teach algorithms so that students learn to think about invariants and properties when writing</span>
<span>code. Real-life code is usually simple enough that it mostly works if you just throw spaghetti</span>
<span>onto the wall. But it doesn</span>’<span>t always work. To write correct, robust code at work, you need to</span>
<span>think about invariants.</span></p>
<p><span>The trick with algorithms is that coding them is hard. The only way to avoid bugs is to force</span>
<span>yourself to think in terms of invariants.</span></p>
</blockquote>

</figure>
<p><span>I was thunderstruck! I didn</span>’<span>t realize that</span>’<span>s the reason why I am learning (well, teaching at that</span>
<span>point) algorithms! Before, I always muddled through my algorithms by randomly tweaking generally</span>
<span>correct stuff until it works. E.g., with a binary search, just add </span><code>+1</code><span> somewhere until it doesn</span>’<span>t</span>
<span>loop on random arrays. After hearing this advice, I went home and wrote my millionth binary</span>
<span>search, but this time I actually added comments with loop invariants, and it worked from the first</span>
<span>try! I applied similar techniques for the rest of the course, and since then my subjective</span>
<span>perception of bug rate (for normal work code) went down dramatically.</span></p>
<p><span>So this is the third level of algorithms </span>—<span> you hone your coding skills to program without bugs.</span>
<span>If you are already fairly comfortable with algorithms, try doing CSES again. But this time, spend</span>
<span>however much you need double-checking the code </span><em><span>before</span></em><span> submission, but try to get everything</span>
<span>correct on the first try.</span></p>
</dd>
</dl>
</section>
<section id="On-Algorithm-Names">

    <h3>
    <a href="#On-Algorithm-Names"><span>On Algorithm Names</span> </a>
    </h3>
<p><span>Here</span>’<span>s the list of things you might want to be able to do, algorithmically. You don</span>’<span>t need to be</span>
<span>able to code everything on the spot. I think it would help if you know what each word is about, and</span>
<span>have implemented the thing at least once in the past.</span></p>
<p><span>Linear search, binary search, quadratic sorting, quick sort, merge sort, heap sort, binary heap,</span>
<span>growable array (aka ArrayList, vector), doubly-linked list, binary search tree, avl tree, red-black</span>
<span>tree, B-tree, splay tree, hash table (chaining and open addressing), depth first search, breadth first</span>
<span>search, topological sort, strongly connected components, minimal spanning tree (Prim &amp; Kruskal),</span>
<span>shortest paths (bfs, Dijkstra, Floyd–Warshall, Bellman–Ford), substring search (quadratic,</span>
<span>Rabin-Karp, Boyer-Moore, Knuth-Morris-Pratt), trie, Aho-Corasick, dynamic programming (longest</span>
<span>common subsequence, edit distance).</span></p>
</section>
<section id="On-Larger-Programs">

    <h3>
    <a href="#On-Larger-Programs"><span>On Larger Programs</span> </a>
    </h3>
<p><span>A very powerful exercise is coding a medium-sized project from scratch. Something that takes more</span>
<span>than a day, but less than a week, and has a meaningful architecture which can be just right, or</span>
<span>messed up. Here are some great projects to do:</span></p>
<dl>
<dt><span>Ray Tracer</span></dt>
<dd>
<p><span>Given an analytical description of a 3D scene, convert it to a colored 2D image, by simulating a</span>
<span>path of a ray of light as it bounces off objects.</span></p>
</dd>
<dt><span>Software Rasterizer</span></dt>
<dd>
<p><span>Given a description of a 3D scene as a set of triangles, convert it to a colored 2D image by</span>
<span>projecting triangles onto the viewing plane and drawing the projections in the correct order.</span></p>
</dd>
<dt><span>Dynamically Typed Programming Language</span></dt>
<dd>
<p><span>An </span><em><span>interpreter</span></em><span> which reads source code as text, parses it into an AST, and directly executes the</span>
<span>AST (or maybe converts AST to the byte code fore some speed up)</span></p>
</dd>
<dt><span>Statically Typed Programming Language</span></dt>
<dd>
<p><span>A </span><em><span>compiler</span></em><span> which reads source code as text, and spits out a binary (WASM would be a terrific</span>
<span>target).</span></p>
</dd>
<dt><span>Relational Database</span></dt>
<dd>
<p><span>Several components:</span></p>
<ul>
<li>
<span>Storage engine, which stores data durably on disk and implements on-disk ordered data structures</span>
<span>(B-tree or LSM)</span>
</li>
<li>
<span>Relational data model which is implemented on top of primitive ordered data structures.</span>
</li>
<li>
<span>Relational language to express schema and queries.</span>
</li>
<li>
<span>Either a TCP server to accept transactions as a database server, or an API for embedding for an</span>
<span>in-processes </span>“<span>embedded</span>”<span> database.</span>
</li>
</ul>
</dd>
<dt><span>Chat Server</span></dt>
<dd>
<p><span>An exercise in networking and asynchronous programming. Multiple client programs connect to a</span>
<span>server program. A client can send a message either to a specific different client, or to all other</span>
<span>clients (broadcast). There are many variations on how to implement this: blocking read/write</span>
<span>calls, </span><code>epoll</code><span>, </span><code>io_uring</code><span>, threads, callbacks, futures, manually-coded state machines.</span></p>
</dd>
</dl>
<p><span>Again, it</span>’<span>s more valuable to do the same exercise six times with variations, than to blast through</span>
<span>everything once.</span></p>
</section>
</section>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Phind V2 – A GPT-4 agent that’s connected to the internet and your code (164 pts)]]></title>
            <link>https://www.phind.com/hn</link>
            <guid>37034951</guid>
            <pubDate>Mon, 07 Aug 2023 14:29:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phind.com/hn">https://www.phind.com/hn</a>, See on <a href="https://news.ycombinator.com/item?id=37034951">Hacker News</a></p>
Couldn't get https://www.phind.com/hn: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Request: Re-open JPEG XL issue (254 pts)]]></title>
            <link>https://bugs.chromium.org/p/chromium/issues/detail?id=1451807</link>
            <guid>37034912</guid>
            <pubDate>Mon, 07 Aug 2023 14:26:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1451807">https://bugs.chromium.org/p/chromium/issues/detail?id=1451807</a>, See on <a href="https://news.ycombinator.com/item?id=37034912">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="footer">
 
 
 <p><a href="https://bugs.chromium.org/p/monorail/adminIntro" title="Monorail ">About Monorail</a>
 <a href="https://chromium.googlesource.com/infra/infra/+/main/appengine/monorail/doc/userguide/README.md">User Guide</a>
 <a href="https://chromium.googlesource.com/infra/infra/+/main/appengine/monorail/doc/release-notes.md">Release Notes</a>
 <a href="https://bugs.chromium.org/p/monorail/issues/entry?template=Online%20Feedback" target="_blank">Feedback on Monorail</a>
 <a href="https://chromium.googlesource.com/infra/infra/+/main/appengine/monorail/doc/terms.md">Terms</a>
 <a href="https://www.google.com/policies/privacy/">Privacy</a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sandy Bridge: Setting Intel’s modern foundation (195 pts)]]></title>
            <link>https://chipsandcheese.com/2023/08/04/sandy-bridge-setting-intels-modern-foundation/</link>
            <guid>37034906</guid>
            <pubDate>Mon, 07 Aug 2023 14:25:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2023/08/04/sandy-bridge-setting-intels-modern-foundation/">https://chipsandcheese.com/2023/08/04/sandy-bridge-setting-intels-modern-foundation/</a>, See on <a href="https://news.ycombinator.com/item?id=37034906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Processor companies typically iterate off proven designs, and for good reason. Changing too many things at once introduces a lot of risk. A lot of changing parts makes it hard to get a good picture of overall performance, so it also makes tuning difficult. Pentium 4 and Bulldozer made clean breaks from prior architectures, and both were unsuccessful designs. But sometimes, making a clean break does pay off.</p>
<p>Sandy Bridge is one such case. It inherited architectural features from Intel’s prior P6 and Netburst architectures, but can’t be considered a member of either line. Unlike Netburst, Sandy Bridge was so successful that Intel’s high performance cores to this day can trace their lineage to back to it. In the early 2010s, Sandy Bridge was so successful that Intel went completely unchallenged in the high end CPU market. And as a testament to the architecture’s solid design, Sandy Bridge CPUs still deliver enough performance to remain usable across a range of everyday tasks.</p>
<h2>Block Diagram</h2>
<p>Sandy Bridge is a four-wide, out-of-order architecture with three ALU ports and two AGU ports. The same applies to prior generations from the P6 family. Core 2 (Merom) and the first generation Core i7/5/3 CPUs (Nehalem) were also four-wide, and have the same execution port count. But core width and execution resources are one thing, and feeding them is another. Sandy Bridge is far better at keeping itself fed, thanks to improvements throughout the pipeline and cache hierarchy.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17974" data-permalink="https://chipsandcheese.com/2023/08/04/sandy-bridge-setting-intels-modern-foundation/sandybridge-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?fit=1151%2C1110&amp;ssl=1" data-orig-size="1151,1110" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sandybridge.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?fit=1151%2C1110&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?fit=688%2C663&amp;ssl=1" decoding="async" width="688" height="663" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?resize=688%2C663&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?w=1151&amp;ssl=1 1151w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?resize=768%2C741&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?w=1151&amp;ssl=1 1151w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?resize=768%2C741&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/sandybridge.drawio.png?resize=688%2C663&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<h2>Frontend: Branch Prediction</h2>
<p>Branch prediction is vital to CPU performance, especially for out-of-order CPUs that can speculate far ahead of a branch. Sandy Bridge dramatically advances branch predictor performance compared to Nehalem, and can recognize much longer patterns. According to Microprocessor Report (MPR), Sandy Bridge does not use classic 2-bit counters for its history table. Instead, entries use 1-bit counters, with a “confidence” bit shared across multiple entries. Thus, Sandy Bridge was able to implement a larger history table with the same amount storage.</p>
<figure><p><img data-lazy-fallback="1" decoding="async" loading="lazy" id="17954" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_branchhist.png?ssl=1" alt="" width="1161" height="690" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_branchhist.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><img data-lazy-fallback="1" decoding="async" loading="lazy" id="17955" src="https://i1.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/westmere_branchhist.png?ssl=1" alt="" width="1157" height="690" data-lazy-src="https://i1.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/westmere_branchhist.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p></figure>
<p>A larger history table lets Sandy Bridge recognize longer patterns when there are a few difficult to predict branches, and avoid destructive aliasing when a lot of branches are in play. Intel made a large improvement in direction prediction, and that’s important because Sandy Bridge can speculate farther than Nehalem can.</p>
<h3>Branch Target Tracking</h3>
<p>Intel made similar optimizations to the branch target buffer (BTB), a structure that remembers where branches went so the branch predictor can steer the frontend with minimal delay. Instead of directly holding branch targets, Sandy Bridge stores branch offsets and adds those to the current program counter to calculate the branch target. Most branches jump short distances, so most BTB entries can be small. MPR further states that Nehalem’s BTB had 64 bit entries, which I find very unlikely. x86-64 virtual addresses are only 48 bits wide, and Nehalem uses 40-bit physical addressing. Using 64-bits to store a branch target would be an exercise in stupidity because the upper 16 bits would always be zero. Maybe 64 bits refers to the total size of the BTB entry, including tag and state bits.</p>
<p>Compared to Nehalem, Sandy Bridge doubles the BTB capacity from 2048 entries to 4096 entries. Intel accomplished this doubling of capacity with no penalty, which is quite an impressive feat. AMD’s Bulldozer increased BTB capacity from 2048 entries in K10 to 5120 entries, but had to do so by adding a slower BTB level.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17976" data-permalink="https://chipsandcheese.com/2023/08/04/sandy-bridge-setting-intels-modern-foundation/snb_btb/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?fit=945%2C494&amp;ssl=1" data-orig-size="945,494" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_btb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?fit=945%2C494&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?fit=688%2C360&amp;ssl=1" decoding="async" loading="lazy" width="688" height="360" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?resize=688%2C360&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?w=945&amp;ssl=1 945w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?resize=768%2C401&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?w=945&amp;ssl=1 945w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?resize=768%2C401&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/05/snb_btb.png?resize=688%2C360&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<p>Sandy Bridge’s main BTB has 2 cycles of latency. That matches Bulldozer’s 512 entry L1 BTB, and is much faster than Bulldozer’s 5 cycle L2 BTB. However, 2 cycle latency still means the frontend loses a cycle after a taken branch. To mitigate this, Sandy Bridge can handle up to eight branches with single cycle latency, possibly by using a very fast L0 BTB. AMD didn’t get similar capability until Zen released in 2017.</p>
<p>Interestingly, I was unable to reach full BTB capacity. However, Matt Godbolt has run extensive tests to <a href="https://xania.org/201602/haswell-and-ivy-btb">measure BTB capacity on Ivy Bridge</a> (the 22nm die shrink of Sandy Bridge), and concluded that the BTB has 4096 entries. Furthermore, he measured 2048 BTB entries on Nehalem. </p>
<h3>Return Stack</h3>
<p>Returns are used to exit from a function back to the calling code, and are quite common. They’re also easy to predict, because returns will almost always match up with a function call. CPUs take advantage of this by using a stack to predict returns. Sandy Bridge’s return stack has 16 entries, which should be adequate for most cases. Bulldozer has a larger 24 entry return stack. AMD can cope better with deeply nested function calls, though there’s probably diminishing returns to increasing return stack depth.</p>
<h3>Indirect Branch Prediction</h3>
<p>Returns are a special case of indirect branches, or branches that go to multiple targets. Predicting indirect branch destinations is quite a bit more difficult, but also important because they’re commonly used for method calls in object oriented languages. </p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18371" data-permalink="https://chipsandcheese.com/snb_indirectbranch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?fit=772%2C462&amp;ssl=1" data-orig-size="772,462" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_indirectbranch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?fit=772%2C462&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?fit=688%2C412&amp;ssl=1" decoding="async" loading="lazy" width="688" height="412" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?resize=688%2C412&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?w=772&amp;ssl=1 772w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?resize=768%2C460&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?w=772&amp;ssl=1 772w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?resize=768%2C460&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_indirectbranch.png?resize=688%2C412&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<p>Sandy Bridge’s indirect predictor can track up to 128 targets, achieved with 64 branches going to two targets each. For a single branch, the predictor can pick between up to 24 targets.</p>
<h2>Frontend: Fetch and Decode</h2>
<p>Once the branch predictor has determined where to go, the frontend has to bring instructions into the core. Sandy Bridge’s frontend inherits features from Nehalem, but gets a new 1536 entry, 8-way micro-op cache. The micro-op cache holds decoded instructions, allowing the core to skip the traditional fetch and decode path. In that sense, it’s similar to Netburst’s trace cache. Both architectures can deliver instructions with lower power and lower latency when feeding the pipeline from the micro-op or trace cache. But Sandy Bridge doesn’t try to cache traces. Rather, micro-op cache lines directly correspond to 32-byte aligned memory regions. Compared to Netburst, Sandy Bridge gets better caching efficiency, because Netburst’s trace cache might store the same instruction many times to improve fetch bandwidth around taken branches.</p>
<figure><table><tbody><tr><td>Component</td><td>Sandy Bridge</td><td>Netburst</td><td>Bulldozer</td></tr><tr><td>L1 Instruction Cache</td><td>32 KB</td><td>N/A, replaced by trace cache</td><td>64 KB with Predecode Metadata</td></tr><tr><td>Conventional Fetch and Decode</td><td>16 bytes per cycle from L1i<br>4-wide decode</td><td>1-wide decode from L2</td><td>32 bytes per cycle from L1i (24 bytes for a single thread)</td></tr><tr><td>Micro-Op Caching</td><td>1.5K entry micro-op cache, 6 micro-op lines<br>28 entry micro-op queue per-thread, use as a loop buffer</td><td>12K entry trace cache, 6 micro-op lines</td><td>N/A</td></tr><tr><td>Comments</td><td>Balanced approach, though with less instruction caching capacity than Bulldozer</td><td>High performance for small code footprints, especially around taken branches. Very poor performance on trace cache miss</td><td>Maximum L1 instruction caching capacity. High L1i bandwidth to deal with AVX</td></tr></tbody></table><figcaption>Summarizing different frontend approaches</figcaption></figure>
<p>But Sandy Bridge’s micro-op cache is still optimized for high speed and low power, rather than caching efficiency. It’s virtually addressed, meaning that program addresses don’t have to be translated to do a micro-op cache lookup. To maintain consistency between virtual and physical addresses (i.e. handle cases where the OS changes mappings between virtual and physical addresses), the L1 instruction cache and instruction TLB (iTLB) are inclusive of the micro-op cache. An iTLB miss implies a micro-op cache miss, and iTLB evictions can flush the micro-op cache. On top of that, some instruction patterns can’t be filled into the micro-op cache:</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/image.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18401" data-permalink="https://chipsandcheese.com/2023/08/04/sandy-bridge-setting-intels-modern-foundation/image-70/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/image.png?fit=633%2C270&amp;ssl=1" data-orig-size="633,270" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/image.png?fit=633%2C270&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/image.png?fit=633%2C270&amp;ssl=1" decoding="async" loading="lazy" width="633" height="270" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/image.png?resize=633%2C270&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/image.png?resize=633%2C270&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>From Intel’s optimization manual</figcaption></figure></div>
<p>Therefore, Sandy Bridge’s micro-op cache augments the traditional fetch and decode mechanism instead of replacing it. Because micro-op cache hitrate isn’t expected to be as good as with a traditional L1i cache, the micro-op cache is used in a way that minimizes penalties when code spills out of it. Intel only transitions to the micro-op cache after a branch, meaning the frontend isn’t constantly checking the micro-op cache tags and wasting power when hitrate may be low.</p>
<p>Compared to its primary competitors and prior Intel architectures, Sandy Bridge can achieve excellent performance with small instruction footprints but relatively long instruction lengths. Dense compute kernels come to mind here, because they’ll use longer AVX instructions executing in small loops.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18349" data-permalink="https://chipsandcheese.com/snb_ifetch8/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?fit=1155%2C474&amp;ssl=1" data-orig-size="1155,474" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_ifetch8" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?fit=1155%2C474&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?fit=688%2C282&amp;ssl=1" decoding="async" loading="lazy" width="688" height="282" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?resize=688%2C282&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?w=1155&amp;ssl=1 1155w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?resize=768%2C315&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?w=1155&amp;ssl=1 1155w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?resize=768%2C315&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch8.png?resize=688%2C282&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Using 8 byte NOPs here</figcaption></figure></div>
<p>Once code spills out of the micro-op cache, frontend throughput takes a sharp drop. However, the L1 instruction cache can still provide enough bandwidth if instructions are around 4 bytes. Integer code typically has average instruction lengths a bit below 4 bytes.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18348" data-permalink="https://chipsandcheese.com/snb_ifetch4/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?fit=1154%2C472&amp;ssl=1" data-orig-size="1154,472" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_ifetch4" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?fit=1154%2C472&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?fit=688%2C281&amp;ssl=1" decoding="async" loading="lazy" width="688" height="281" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?resize=688%2C281&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?w=1154&amp;ssl=1 1154w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?resize=768%2C314&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?w=1154&amp;ssl=1 1154w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?resize=768%2C314&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_ifetch4.png?resize=688%2C281&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<p>If code spills out of the L1i, instruction throughput takes a sharp drop. But while it’s a step behind modern chips, it compares well to its competition. Bulldozer struggles even more if it has to fetch code from L2, though the large L1i should reduce how often that happens.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18404" data-permalink="https://chipsandcheese.com/snb_frontend/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?fit=1696%2C519&amp;ssl=1" data-orig-size="1696,519" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_frontend" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?fit=1696%2C519&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?fit=688%2C211&amp;ssl=1" decoding="async" loading="lazy" width="688" height="211" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=688%2C211&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?w=1696&amp;ssl=1 1696w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=768%2C235&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1536%2C470&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1200%2C367&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1600%2C490&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1320%2C404&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?w=1696&amp;ssl=1 1696w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=768%2C235&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1536%2C470&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1200%2C367&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1600%2C490&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=1320%2C404&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?w=1376&amp;ssl=1 1376w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_frontend.png?resize=688%2C211&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Zen 4 has apparently added a loop buffer, making the frontend strategy very similar to Sandy Bridge’s</figcaption></figure></div>
<p>In the end, Sandy Bridge has a very complex frontend compared to prior Intel architectures, or indeed anything else of its time. The core can incredibly feed its pipeline from four different sources. At first, that sounds like a non-intuitive and complex solution. But imitation and longevity are the sincerest forms of flattery for microarchitecture design. Today, ARM and AMD use similar frontend strategies in their high performance cores, which speaks to the strength of Sandy Bridge’s design.</p>
<h2>Rename and Allocate</h2>
<p>After instructions have been converted into micro-ops, backend resources have to be allocated to track them and enable out-of-order execution. This stage is called the renamer, because it performs register renaming to break false dependencies. It’s also a convenient place to pull more tricks that expose additional parallelism to the backend. For example, operations that always result in zero can be set to have no dependencies. Register to register copies can be eliminated by manipulating the register alias tables. Sandy Bridge recognizes zeroing idioms, but Intel was not able to implement move elimination. That would have to wait until Ivy Bridge.</p>
<h2>Execution Engine</h2>
<p>Sandy Bridge’s out-of-order execution engine is a fresh design. At a high level, it’s Netburst but bigger and less stupid. By that, I mean it uses a PRF based execution scheme where data values are stored in physical register flies, and pointers to register file entries get moved around instead of the values themselves. Contrast that with P6’s ROB based execution scheme, which stores register values in the ROB. When an instruction retires, P6 copies its result from the ROB to a retired register file. Apparently, P6 also stored input values in its scheduler. That may have simplified design because all the info needed to execute a micro-op can come from the scheduler, but bloats scheduler size.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18015" data-permalink="https://chipsandcheese.com/sandybridge_ooo-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?fit=1778%2C555&amp;ssl=1" data-orig-size="1778,555" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sandybridge_ooo.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?fit=1778%2C555&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?fit=688%2C215&amp;ssl=1" decoding="async" loading="lazy" width="688" height="215" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=688%2C215&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?w=1778&amp;ssl=1 1778w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=768%2C240&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1536%2C479&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1200%2C375&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1600%2C499&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1320%2C412&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?w=1778&amp;ssl=1 1778w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=768%2C240&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1536%2C479&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1200%2C375&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1600%2C499&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=1320%2C412&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?w=1376&amp;ssl=1 1376w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/sandybridge_ooo.drawio.png?resize=688%2C215&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Overly simplified comparison of OoO execution schemes. 128-bit values apply to Core 2 and later. Early P6 generations only had to move up to 80-bit values</figcaption></figure></div>
<p>These inefficiencies were probably fine on early P6 variants, where the largest register values were 80-bits wide. Nehalem’s 128-bit SSE registers were pushing things a bit, but growing transistor budgets and process improvements let it get by. Sandy Bridge is a different story. 256-bit AVX registers are no joke, and Intel needed to move those giant values around as little as possible. By going to a PRF based scheme, Intel was able to provide a full width AVX implementation while also greatly increasing reordering capacity.</p>
<figure><table><tbody><tr><td>Structure</td><td>Applies if instruction…</td><td>Sandy Bridge</td><td>Nehalem</td></tr><tr><td>Reorder Buffer (ROB)</td><td>Exists</td><td>168 entry</td><td>128 entry</td></tr><tr><td>Integer Register File</td><td>Writes to an integer register</td><td>160 entry<br>~122 speculative</td><td>N/A (128 speculative)</td></tr><tr><td>FP/Vector Register File</td><td>Writes to a FP/vector register</td><td>144 entry<br>~113 speculative</td><td>N/A (128 speculative)</td></tr><tr><td>Load Queue</td><td>Reads from memory</td><td>64</td><td>48</td></tr><tr><td>Store Queue</td><td>Writes to memory</td><td>36</td><td>32</td></tr><tr><td>Branch Order Buffer</td><td>Affects control flow</td><td>48</td><td>N/A (128 speculative)</td></tr></tbody></table></figure>
<p>Intel’s PRF implementation has some quirks as well. Apparently, Sandy Bridge has a Physical Register Reclaim Table (PRRT) structure in addition to separate freelists for each register file. The PRRT is responsible for telling the retirement stage what register (if any) can be reclaimed when an instruction retires, but notably doesn’t have enough entries to cover the entire ROB. </p>

<p>Sandy Bridge can therefore have its reordering capacity limited by how many total registers it can allocate, even if the relevant register file has free entries. </p>
<h3>Execution Units</h3>
<p>Once the scheduler has determined that a micro-op is ready for execution, it’s sent to Sandy Bridge’s six execution ports. It’s easier to think of this as five ports (three for math, two for memory), because a sixth port is only used to handle stores. Stores on Intel CPUs use both an AGU port and a store data port, so the store data port doesn’t allow higher instruction throughput.</p>
<p>Execution units are generally well distributed across the ports, but there are weak points compared to newer CPUs. That especially applies for vector and floating point execution. If code has a lot of shuffle operations, port 5 can see heavy load because it has to handle all vector shuffles and branches.</p>
<div>
<figure><img data-lazy-fallback="1" data-attachment-id="18206" data-permalink="https://chipsandcheese.com/idf_avx/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_avx.jpg?fit=600%2C396&amp;ssl=1" data-orig-size="600,396" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="idf_avx" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_avx.jpg?fit=600%2C396&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_avx.jpg?fit=600%2C396&amp;ssl=1" decoding="async" loading="lazy" width="600" height="396" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_avx.jpg?resize=600%2C396&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_avx.jpg?resize=600%2C396&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Slide from IDF 2010 showing AVX implementation</figcaption></figure></div>
<p>Floating point workloads dominated by adds or multiplies (but not a roughly even mix of both) could see port bottlenecks on ports 1 and 0, respectively. That’s really only a disadvantage compared to more modern architectures, as prior generations of Intel CPUs had similar limitations.</p>
<h3>Memory Execution</h3>
<p>Operations that access memory are sent down Sandy Bridge’s two address generation pipelines. Prior Intel architectures had specialized AGU pipes, with one for loads and the other for stores. Sandy Bridge uses a more flexible setup where both pipes can handle either loads or stores. Loads tend to be far more common than stores, so Sandy Bridge should see far less contention on the AGU ports.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_snb_memory.jpg?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18212" data-permalink="https://chipsandcheese.com/idf_snb_memory/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_snb_memory.jpg?fit=600%2C346&amp;ssl=1" data-orig-size="600,346" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="idf_snb_memory" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_snb_memory.jpg?fit=600%2C346&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_snb_memory.jpg?fit=600%2C346&amp;ssl=1" decoding="async" loading="lazy" width="600" height="346" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_snb_memory.jpg?resize=600%2C346&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/idf_snb_memory.jpg?resize=600%2C346&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Slide from IDF 2010</figcaption></figure></div>
<p>However, AGU throughput is still a stumbling block for Sandy Bridge. Per-cycle, the L1D can theoretically service three accesses, but the AGUs can only provide two addresses. In 2013, Intel’s Haswell introduced a triple AGU setup, letting it sustain 3 memory operations per cycle. AMD did the same in 2019 with Zen 2. It’s not a big deal but newer CPUs do better.</p>
<h3>Memory Disambiguation, and Load/Store Penalites</h3>
<p>After addresses are calculated, the load/store unit has to make sure memory dependencies are satisfied. Loads that overlap with earlier in-flight stores have to get their data forwarded, but checking for partial overlaps can be complicated. Nehalem had a very sophisticated comparison mechanism, and could handle all cases where the store is completely contained within a later load. The same applies to Sandy Bridge, but the check appears to be done in two stages. </p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18261" data-permalink="https://chipsandcheese.com/snb_stlf-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?fit=2415%2C1186&amp;ssl=1" data-orig-size="2415,1186" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_stlf" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?fit=2415%2C1186&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?fit=688%2C338&amp;ssl=1" decoding="async" loading="lazy" width="688" height="338" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=688%2C338&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?w=2415&amp;ssl=1 2415w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=768%2C377&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1536%2C754&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=2048%2C1006&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1200%2C589&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1600%2C786&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1320%2C648&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?w=2415&amp;ssl=1 2415w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=768%2C377&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1536%2C754&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=2048%2C1006&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1200%2C589&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1600%2C786&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=1320%2C648&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?w=1376&amp;ssl=1 1376w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_stlf.png?resize=688%2C338&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<p>First, Sandy Bridge does a quick check to see if accesses overlap the same 4 byte aligned region. It only does a more thorough check if there is an overlap. Successful store forwarding has a latency of 5-6 cycles, while partial overlap cases take 17-18 cycles, or 24-25 cycles if they cross a cacheline boundary. Store forwarding is a lot less sophisticated for vector accesses. Sandy Bridge can only forward the lower or upper half of a 128-bit store, and does so with a latency of 7-8 cycles.</p>
<h3>Address Translation and Paging</h3>
<p>All modern operating systems rely on virtual memory to keep misbehaving processes from tripping over each other or bringing down the entire system. Virtual memory requires virtual program-visible addresses to be translated to physical addresses. Sandy Bridge uses a two-level cache of address translations to speed this up. First, a 64 entry DTLB can provide translations without penalty. If the L1 DTLB is missed, Sandy Bridge can get the translation from a 1024 entry L2 TLB, with an additional 7 cycles of latency.</p>
<p>Address translations get messy if an access crosses a page boundary, because the underlying data might be very far apart in physical memory. On Sandy Bridge, a split-page load costs 36 cycles, while a split-page store costs 25 cycles. Forwarding doesn’t work across page boundaries, where you can see a 36 cycle penalty if the store spans pages. If both the load and store cross a page boundary, the penalty goes to 53 cycles. Modern CPUs improve on these penalties, but Sandy Bridge already turns in a far better performance than its AMD competition.</p>
<h2>Cache Performance</h2>
<p>Intel standardized on a triple-level caching setup starting with Nehalem. Sandy Bridge carries the high level caching scheme forward, but with important improvements. Starting at L1, the improved AGU setup gives Sandy Bridge twice as much load bandwidth as Nehalem. L2 bandwidth also improves, though it’s nowhere near the 32 bytes per cycle that Sandy Bridge should be theoretically capable of. </p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18238" data-permalink="https://chipsandcheese.com/snb_st_bw/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?fit=1100%2C498&amp;ssl=1" data-orig-size="1100,498" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_st_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?fit=1100%2C498&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?fit=688%2C311&amp;ssl=1" decoding="async" loading="lazy" width="688" height="311" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?resize=688%2C311&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?w=1100&amp;ssl=1 1100w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?resize=768%2C348&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?w=1100&amp;ssl=1 1100w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?resize=768%2C348&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_st_bw.png?resize=688%2C311&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<p>At L3, we see a slight bandwidth advantage for Sandy Bridge. The Xeon X5650 and E5-1650 both serve their cores with 12 MB of L3 cache arranged into six slices, but do so very differently. Westmere and Nehalem use a centralized Global Queue (GQ) in front of the L3 cache. All L3 request tracking can happen at the GQ so that approach is probably easier to implement and verify. But it’s not scalable.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="13484" data-permalink="https://chipsandcheese.com/2023/01/22/bulldozer-amds-crash-modernization-frontend-and-execution-engine/bdz_l3_arch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?fit=960%2C687&amp;ssl=1" data-orig-size="960,687" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bdz_l3_arch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?fit=960%2C687&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?fit=688%2C492&amp;ssl=1" decoding="async" loading="lazy" width="688" height="492" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?resize=688%2C492&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?w=960&amp;ssl=1 960w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?resize=768%2C550&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?w=960&amp;ssl=1 960w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?resize=768%2C550&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/12/bdz_l3_arch.png?resize=688%2C492&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<p>Higher core counts mean more L3 and memory requests in flight, so the GQ needs more entries to cope. A larger GQ means more requests to scan when making decisions on request priority<sup>2</sup>. All of this has to be handled with low latency. The GQ is not ideal for that either, because every request has to go through the centralized queue in the middle of the chip, even if the L3 slice holding the relevant data is quite close to the requesting core.</p>
<p>Sandy Bridge ditches the GQ in favor of a divide-and-conquer approach. L3 lookup and request tracking functionality gets distributed across the L3 slices, which are connected via a ring bus. The request scheduler at each L3 slice can be smaller than the GQ, and can run at core clocks. In the end, the ring bus delivers massive bandwidth advantages:</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18243" data-permalink="https://chipsandcheese.com/snb_mt_bw/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?fit=1088%2C445&amp;ssl=1" data-orig-size="1088,445" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_mt_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?fit=1088%2C445&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?fit=688%2C281&amp;ssl=1" decoding="async" loading="lazy" width="688" height="281" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?resize=688%2C281&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?w=1088&amp;ssl=1 1088w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?resize=768%2C314&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?w=1088&amp;ssl=1 1088w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?resize=768%2C314&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_mt_bw.png?resize=688%2C281&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>
<p>Even under heavy load, the E5-1650 (Sandy Bridge) can provide more than 9 bytes per cycle of bandwidth to each of its six cores. Each of the X5650’s cores in contrast can only average 4.7 bytes per cycle. Sandy Bridge’s advantage extends past bandwidth. Latency improves because requests can take a more direct route to the destination slice, instead of always going through GQ in the center of the die. Simpler request arbiters probably help latency too.</p>
<figure><img data-lazy-fallback="1" data-attachment-id="18237" data-permalink="https://chipsandcheese.com/snb_latency_cycles/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?fit=931%2C446&amp;ssl=1" data-orig-size="931,446" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_latency_cycles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?fit=931%2C446&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?fit=688%2C330&amp;ssl=1" decoding="async" loading="lazy" width="688" height="330" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?resize=688%2C330&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?w=931&amp;ssl=1 931w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?resize=768%2C368&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?w=931&amp;ssl=1 931w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?resize=768%2C368&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_cycles.png?resize=688%2C330&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>In terms of core clocks, Sandy Bridge drops latency by about 7 cycles. That’s already a good improvement. But we can only capture the magnitude of Sandy Bridge’s progress when we look at actual latency. 10.3 ns is an excellent figure for a 12 MB cache. I really have to give it to Intel’s engineers here because they delivered a massive leap in L3 performance even when their prior design would have had no problems competing against AMD.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18254" data-permalink="https://chipsandcheese.com/snb_latency_ns/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?fit=931%2C446&amp;ssl=1" data-orig-size="931,446" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_latency_ns" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?fit=931%2C446&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?fit=688%2C330&amp;ssl=1" decoding="async" loading="lazy" width="688" height="330" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?resize=688%2C330&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?w=931&amp;ssl=1 931w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?resize=768%2C368&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?w=931&amp;ssl=1 931w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?resize=768%2C368&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_latency_ns.png?resize=688%2C330&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Sandy Bridge destroys Westmere in L3 latency.</figcaption></figure></div>
<p>However, Sandy Bridge doesn’t improve latency across the board. L2 latency regresses by two cycles compared to Nehalem, though the E5-1650’s higher clock speed means actual latency is very similar. 12 cycle L2 latency is very acceptable in any case.</p>
<h2>Cache Coherency Performance</h2>
<p>L3 performance is an excellent way to measure Sandy Bridge’s interconnect performance, because L3 traffic makes up most of the traffic going across the ring bus. Another way to check interconnect performance is testing how long it takes to bounce data between pairs of cores. While this form of traffic is quite rare and therefore less optimized, it can show the interconnect topology.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="18421" data-permalink="https://chipsandcheese.com/snb_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?fit=1039%2C281&amp;ssl=1" data-orig-size="1039,281" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="snb_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?fit=1039%2C281&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?fit=688%2C186&amp;ssl=1" decoding="async" loading="lazy" width="688" height="186" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?resize=688%2C186&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?w=1039&amp;ssl=1 1039w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?resize=768%2C208&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?w=1039&amp;ssl=1 1039w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?resize=768%2C208&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/06/snb_c2c.png?resize=688%2C186&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Sandy Bridge and Nehalem/Westmere both handle coherency by using the L3 as a probe filter. The L3 keeps core valid bits alongside each line</figcaption></figure></div>
<p>Sandy Bridge sees slightly varying core to core latencies, depending on how far cores are from the L3 slice that owns the cache slice. On Westmere and Nehalem, all requests flow through a centralized arbiter. Latencies are more uniform, and are uniformly higher. The E5-1650’s worst case is better than the X5650’s best case.</p>
<p>Alongside non-contested L3 performance, Sandy Bridge’s core-to-core latency performance demonstrates the excellence of its ring bus design. Again, imitation and longevity are the sincerest forms of flattery for CPU features. Today, Intel continues to use a ring bus in client CPUs, and AMD has done the same (starting with Zen 3).</p>
<h2>Final Words</h2>
<p>Sandy Bridge is now more than a decade old, but Intel architectures today can still trace their origins to iterative changes built on top of Sandy Bridge’s base. As another compliment to Sandy Bridge, its concepts have shown up in successful architectures outside of Intel. AMD’s Zen line uses a micro-op cache and a distributed L3 design, though implementation details differ. Micro-op caches also appear on ARM’s latest high performance designs.</p>
<p>Today, Sandy Bridge remains surprisingly usable, even if more modern CPUs beat it into the ground in head-to-head benchmarking. That’s because it does the important things right. Its branch predictor performs well. Out-of-order buffers are well balanced, and the pipeline in general has few penalties. Caches have low latency and adequate bandwidth. Modern CPUs do better in most of those categories, but are often chasing diminishing returns. In short, there’s not a lot that Sandy Bridge did wrong.</p>
<p>When Sandy Bridge does fall short compared to modern CPUs, it’s generally in specific categories of applications. For example, its execution port count looks absolutely anemic compared to CPUs just a generation later. But feeding the execution resources is more important than having a lot of them, so having fewer ports isn’t a big deal. Sandy Bridge also isn’t as wide as newer CPUs, but again core width is not as important as feeding that width. </p>
<p>Most impressively, Intel made enormous strides without serious competition. A slightly improved Nehalem would have been enough to beat AMD’s Bulldozer. Instead, Intel created a fresh design that left AMD completely in the dust. Then, Intel made iterative improvements that kept the company well ahead of any competition. When looking back at Sandy Bridge and the years after its release, I can’t help but miss the old Intel. Intel in the early 2010s was bold and confident, introducing performance and power efficiency improvements on a steady pace. Today’s Intel barely keeps its footing against a resurgent AMD. That said, Intel has a tradition of learning from setbacks and coming back stronger. They recovered from the Pentium FDIV bug and grew to dominate the PC market. They recovered from the misstep of Netburst to deliver Core 2, and then used what they learned from both architecture lines to create Sandy Bridge. Hopefully, Intel will have another Sandy Bridge or Core 2 moment in the years to come.</p>
<p>If you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our&nbsp;<a href="https://www.patreon.com/ChipsandCheese">Patreon</a>&nbsp;or our&nbsp;<a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ">PayPal</a>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;<a href="https://discord.gg/TwVnRhxgY2">Discord</a>.</p>
<h2>References</h2>
<ol>
<li>Linley Gwennap, Sandy Bridge Spans Generations, Microprocessor Report</li>
<li>The Uncore: A Modular Approach to Feeding the HIgh-Performance Cores, Intel Technology Journal, Volume 14, Issue 3</li>
</ol>

<div data-post_id="10949" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-10949 box-instance-id-1">

<ul>
<li>
<p><img data-lazy-fallback="1" alt="clamchowder" src="https://secure.gravatar.com/avatar/83de286347cdfc84e1bb10146350467e?s=80&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/83de286347cdfc84e1bb10146350467e?s=160&amp;d=identicon&amp;r=g 2x" height="80" width="80" loading="lazy" decoding="async" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"> </p>

</li>
</ul>
</div>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Axilla – Open-source TypeScript framework for LLM apps (124 pts)]]></title>
            <link>https://github.com/axilla-io/ax</link>
            <guid>37034575</guid>
            <pubDate>Mon, 07 Aug 2023 14:00:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/axilla-io/ax">https://github.com/axilla-io/ax</a>, See on <a href="https://news.ycombinator.com/item?id=37034575">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/axilla-io/ax/blob/main/assets/logo.png"><img src="https://github.com/axilla-io/ax/raw/main/assets/logo.png"></a>
</p>
<h2 tabindex="-1" dir="auto">Ax — A comprehensive AI framework for TypeScript</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/axilla-io/ax/workflows/Github%20CI/badge.svg"><img src="https://github.com/axilla-io/ax/workflows/Github%20CI/badge.svg" alt="Github CI"></a> <a href="https://join.slack.com/t/axilladevelopers/shared_invite/zt-212wj3ek0-NHzIFtVg1lxL1t0ViPbysA" rel="nofollow"><img src="https://camo.githubusercontent.com/2c4c9c1347665f000876c59609340a9f907c208a667bad54bc809d13279aa2e4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4a6f696e2532304f7572253230436f6d6d756e6974792d536c61636b2d626c7565" alt="Slack" data-canonical-src="https://img.shields.io/badge/Join%20Our%20Community-Slack-blue"></a></p>
<p dir="auto">Ax is a collection of modules designed for creating robust AI applications. These modules can be adopted incrementally, thus providing a modular and scalable end-to-end solution.
Used together, they form an end-to-end framework for developing AI applications.</p>
<h2 tabindex="-1" dir="auto">Modules</h2>
<ul dir="auto">
<li><a href="https://github.com/axilla-io/ax/blob/main/packages/axgen"><strong>axgen</strong></a>: A framework for connecting your data to large language models</li>
<li><a href="https://github.com/axilla-io/ax/blob/main/packages/axeval"><strong>axeval</strong></a>: A framework for evaluating LLM output quality</li>
</ul>
<p dir="auto">In addition to the above modules, we're working on the following modules:</p>
<ul dir="auto">
<li><strong>axextract</strong>: A library for efficient data processing, particularly loading, transforming, and chunking documents from arbitrary sources. Most useful for applications that need to load and preprocess data for vector search.</li>
<li><strong>axserve</strong>: A serving framework to run any LLM model (OSS or otherwise). It will also provide middleware options for user throttling, analytics, and logging</li>
<li><strong>axtune</strong>: A library focused on fine-tuning models</li>
</ul>
<h2 tabindex="-1" dir="auto"><a href="https://docs.axilla.io/" rel="nofollow">Documentation</a></h2>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">The modules can be installed independently, for incremental adoption and bundle size minimization.</p>
<div data-snippet-clipboard-copy-content="npm install axgen
npm install axeval"><pre><code>npm install axgen
npm install axeval
</code></pre></div>
<h2 tabindex="-1" dir="auto">Goals</h2>
<p dir="auto">Ax aspires to deconstruct the complex paradigms of working with LLMs into manageable and intuitive components.
Our library takes a code-first approach, emphasizing the importance of flexibility and control for developers.
As a foundational framework, Ax empowers developers to build higher-level TypeScript AI features and products seamlessly.</p>
<h2 tabindex="-1" dir="auto">Examples</h2>
<p dir="auto">Here is an example <a href="https://github.com/axilla-io/demo-ui">open source UI</a> showcasing what axgen can do, with a <a href="https://www.loom.com/share/458f9b6679b740f0a5c78a33fffee3dc" rel="nofollow">short video</a> walkthrough.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto"><a href="https://github.com/axilla-io/ax/blob/main/LICENSE.md">MIT</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MIT Press: Open Access Materials (108 pts)]]></title>
            <link>https://archive.org/details/mit_press_open_access?tab=collection</link>
            <guid>37034350</guid>
            <pubDate>Mon, 07 Aug 2023 13:43:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archive.org/details/mit_press_open_access?tab=collection">https://archive.org/details/mit_press_open_access?tab=collection</a>, See on <a href="https://news.ycombinator.com/item?id=37034350">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Not Using Zoom (268 pts)]]></title>
            <link>https://the.webm.ink/not-using-zoom</link>
            <guid>37034145</guid>
            <pubDate>Mon, 07 Aug 2023 13:26:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://the.webm.ink/not-using-zoom">https://the.webm.ink/not-using-zoom</a>, See on <a href="https://news.ycombinator.com/item?id=37034145">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Dear client,</p>

<p>Setting aside the earlier challenges of using Zoom under ChromeOS and Linux, I have mostly been <strong>declining invitations to Zoom calls</strong> because of the terms they introduced from April 2023 in section 10 of their <a href="https://explore.zoom.us/en/terms/" rel="nofollow">Terms of Service</a> which seem to force every user, with no opt-out to the Terms available and with recourse only via arbitration, to agree that Zoom can:</p>
<ol><li>Train their AI on anything uploaded or created on Zoom (including transcripts and recordings) and use the consequent model for absolutely anything;</li>
<li>Have indefinite and ownership-equivalent rights to do so in the future and</li>
<li>Be indemnified by me if it turns out someone else owns the IP or has their rights infringed (for example to confidential materials everyone on the call is entitled to review).</li></ol>

<p>I prefer <a href="https://meet.jit.si/" rel="nofollow">Jitsi</a> instead; it has equivalent functionality, is platform independent, can be used without an account, is open source and can be self-hosted.</p>

<h2 id="details">Details</h2>

<p>In the <a href="https://explore.zoom.us/en/terms/" rel="nofollow">terms</a>, “data, content, files, documents, or other materials” that you use in a Zoom session (“Customer Input”), as well as recordings and transcripts, and any other glitter Zoom sprinkles over them, is called “Customer Content”.</p>

<p>10.4(ii) then sees you granting a broad license to Customer Content “for the purpose of product and service development, marketing, analytics, quality assurance, machine learning, artificial intelligence, training, testing, improvement of the Services, Software, or Zoom’s other products, services, and software, or any combination thereof”</p>

<p>If the stuff you shared belongs to someone else, 10.6 sees you agreeing “you are solely responsible for the Customer Content” and notably for getting consent from third parties and providing notices according to whatever laws happen to be applicable to the combination of people involved.</p>

<p>In addition to all this, in 10.6 you “represent and warrant that you have the right to upload Customer Input and for Zoom to provide, create, or make available any Customer Content to you, and that such use or provision by you, your End User, or Zoom does not violate or infringe any rights of any third party.” &nbsp;So according to 25(i) &amp; (iii) you are basically indemnifying them if they train their AI with someone else's IP you happen to have – for example, a client brief you are discussing internally, or a legal case you are working on under privilege.</p>

<p>There is no opt-out or scope control to use in the Terms for AI training. Zoom's COO <a href="https://news.ycombinator.com/item?id=37029700" rel="nofollow">says</a> the actual use of the AI features is opt-in, but that doesn't seem relevant as the Terms grant permission regardless and the Customer Content exists whether you use the AI features or not.</p>

<p>My non-lawyer read suggests this is an exceptionally risky thing for anyone to agree if they are in possession of IP or under NDA concerning someone else's secrets, and I will be avoiding Zoom (even if they revert the terms – can't take the chance on future changes like this).</p>

<hr>

<h3 id="notes-tags-mentions">Notes, Tags &amp; Mentions</h3>
<ul><li>I believe this analysis is correct as of August 7th 2023; please contact me at once if it is not, see my <a href="https://webm.ink/" rel="nofollow">hub</a>, especially if it's because they changed the terms of use!</li>
<li>Here's <a href="https://web.archive.org/web/20230301000542/https://explore.zoom.us/en/terms/" rel="nofollow">the immediately prior version of the terms</a>. You can clearly see that the new section 10 has been introduced in the <a href="https://web.archive.org/web/20230725013414/https://explore.zoom.us/en/terms/" rel="nofollow">new version</a>. The version in effect today (dated July 27) seems to differ only in to paragraphs about tax paperwork according to <a href="https://www.copyscape.com/compare.php" rel="nofollow">Copyscape</a>.</li>
<li><a href="https://the.webm.ink/tag:Proprietary" rel="nofollow"><span>#</span><span>Proprietary</span></a> <a href="https://the.webm.ink/tag:Video" rel="nofollow"><span>#</span><span>Video</span></a> <a href="https://the.webm.ink/tag:Terms" rel="nofollow"><span>#</span><span>Terms</span></a></li></ul>

<p><em>To discuss this post please reply from Mastodon etc. (search for the URL) &amp; include <code><a href="https://the.webm.ink/@/webmink@meshed.cloud" rel="nofollow">@<span>webmink@meshed.cloud</span></a></code> as WriteFreely still doesn't display replies. <a href="https://the.webm.ink/About" rel="nofollow">More</a>.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The $1M shot that changed sports contests forever (260 pts)]]></title>
            <link>https://www.espn.com/nba/story/_/id/36146138/million-dollar-shot-michael-jordan-chicago-bulls-1993</link>
            <guid>37033899</guid>
            <pubDate>Mon, 07 Aug 2023 13:07:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.espn.com/nba/story/_/id/36146138/million-dollar-shot-michael-jordan-chicago-bulls-1993">https://www.espn.com/nba/story/_/id/36146138/million-dollar-shot-michael-jordan-chicago-bulls-1993</a>, See on <a href="https://news.ycombinator.com/item?id=37033899">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><ul><li><p><img src="https://a.espncdn.com/combiner/i?img=/i/columnists/full/hockensmith_ryan.png&amp;h=80&amp;w=80&amp;scale=crop" alt="" width="40" height="40"></p><p>Ryan Hockensmith<span>Apr 11, 2023, 08:00 AM ET</span></p><div><p><a href="#">Close</a></p><ul>Ryan Hockensmith is a Penn State graduate who joined ESPN in 2001. He is a survivor of bacterial meningitis, which caused him to have multiple amputation surgeries on his feet. He is a proud advocate for those with disabilities and addiction issues. He covers everything from the NFL and UFC to pizza-chucking and analysis of Tom Cruise's running ability.</ul></div></li></ul></div><p><b>RIGHT BEFORE HE HEAVED</b> the million-dollar shot, the one that would launch an era of sports contests and change his life forever, Don Calhoun took a long look at his shoes.</p><p>He was only out here standing on the floor of Chicago Stadium on April 14, 1993, 15 feet from <a href="https://www.espn.com/nba/player/_/id/1035/michael-jordan" target="_blank">Michael Jordan</a> and the <a href="https://www.espn.com/nba/team/_/name/chi/chicago-bulls" target="_blank">Bulls</a>, because of his shoes. "Those won't scuff the court," an arena worker said as she signed Calhoun up for a $1 million, three-quarter-court contest shot that the Bulls had been running every night.</p><p>As he stared at his feet, waiting to be told it was his turn to take the shot, he was warned, "Whatever you do, don't step over the free throw line." Calhoun, a 23-year-old office supply salesman from the Chicago area, darted his eyes from his non-scuffing sneakers to the free throw line about 80 feet from the hoop he needed to make.</p><p>The impossibility of the shot was settling in. He wasn't going to be able to shoot it with both hands; he'd have to throw it like a quarterback. The Bulls had held the promotion 19 times that year already. Two people clunked the backboard. Another clanged the rim. The other 16 were air balls. Nobody came close. The best estimate of someone like Calhoun making that shot? Less than 1%.</p><p>But then, a calm came over him. He thought about his brother Clarence, who had told him five years earlier, just before he died, that Michael Jordan would soon be the best player in the NBA and the Bulls would be a dynasty. He thought about his bittersweet feelings toward the sport of basketball -- he loved the game and was good at it, but he never made his high school team.</p><p>It might sound ridiculous, but as Calhoun stood there and heard his name announced, he became sure -- <i>100% certain</i> -- that the shot was going to go in. The last thing he remembers is the steady hum of 18,600 people rising to cheer for him. As the Bulls huddled up nearby, Calhoun palmed the ball in one hand. The free throw line warning was bouncing around inside his head, and for a second, he felt his flow get disrupted.</p><p>But the flow came back as he stepped past the end line. He took one fast dribble, thought to himself, "This is for Clarence," and then threw a high-arching rocket.</p><p>As the ball sailed toward the hoop, Calhoun's eyes again turned toward his feet and he saw that he was <i>very</i> close to the free throw line -- but a few inches behind. Whew. When he looked up again, he had a moment of panic. He'd thrown it too far and too hard.</p><p>"It looked like it was going to hit the shot clock," he says.</p><p>But then the ball began to sink. It dropped, and dropped, and dropped, and... <i>swish</i>. Right through the net. Calhoun threw his arms toward the rafters, and the crowd let out one of those levels of cheers that aggravates the arena neighbors.</p><p>Then the real mayhem began.</p><p>The ensuing 30 seconds might be the most joyous footage of that Bulls team ever. Seriously, watch the most celebratory moments from "The Last Dance," and compare those with the clips you will inevitably see this April 14 on social media on the 30th anniversary of Calhoun's heave. <a href="https://www.espn.com/nba/player/_/id/3815/john-paxson" target="_blank">John Paxson</a> and <a href="https://www.espn.com/nba/player/_/id/919/scott-williams" target="_blank">Scott Williams</a> go wild. Some player just off-camera slaps Calhoun's ass over and over again, and even one of the game refs comes over, hits him on the back and hands him the ball from the shot. Phil Jackson stands there with an incredulous grin, looking like he just won the $1 million.</p><p>Suddenly, Calhoun found himself bumped and butt-slapped directly into the middle of the Bulls huddle, where the other players parted and there stood <a href="https://www.espn.com/nba/player/_/id/663/scottie-pippen" target="_blank">Scottie Pippen</a> and Michael Jordan. Calhoun was the team's 13th man at that moment. Calhoun was in there for a good 10 seconds when he felt Jordan slap him on the back and lean into his ear.</p><p>"Great shot, kid," Jordan said.</p><p>Calhoun says he can still hear the way Jordan was yelling "Woo!" behind him the entire time. After the game, Michael Wilbon, then at The Washington Post, wrote, "Jordan, smiling in a child-like way I've never seen on the court, threw both arms around his neck and squeezed." As the celebration exploded around him, Calhoun felt as if his life was going to change. He was the toast of Chicago for the next 24 hours, with the shot going viral by 1993 standards, with newscasts and newspapers all showing the clip so much that Calhoun's shot is now referenced as the beginning of a boom in contests at sporting events. And best of all, Calhoun was about to become a millionaire.</p><p>Or so he thought.</p><hr><p><b>BY THE TIME DON CALHOUN</b> made his shot, in-game contests had begun to pop up here and there across the country. But Calhoun's make caused an eruption in popularity. Chris Hamman, VP at industry leader SCA Promotions, thinks "The Calhoun Shot," as it's become known in the business, might have doubled or even tripled the number of contests.</p><p>"These types of contests grew quite a bit, and a lot of NBA teams started doing similar contests," says Hamman, whose dad, Bob, founded SCA Promotions, which has been insuring sports contests since the mid-1980s. Chris compares Calhoun's make with the impact Chris Moneymaker had on poker in 2003 when he went from an $86 online qualifier to winning the World Series of Poker (and $2.5 million).</p><p>The contests took off afterward. They were the perfect way to keep 15,000-plus people engaged during TV timeouts and between quarters. They were wildly popular crowd-pleasers back then, and remain slam dunk #ViralContent in the social media era. SCA Promotions has insured billions of dollars of sports contests since the mid-1980s, paying out something like $250 million in winnings over the years, according to Bob Hamman. (SCA was not the insurer of the Calhoun Shot).</p><p>As the Hammans note, the perfect contest is like the most tempting carnival game: just feasible enough to make people think they can do it while actually being extremely difficult. Everybody at the Bulls game that night in 1993 probably had sunk a long shot or two at some point in their life. In reality, Jordan himself might not have made one if you gave him 100 tries. "With the shot that Don Calhoun made, you could have <a href="https://www.espn.com/nba/player/_/id/3975/stephen-curry" target="_blank">Steph Curry</a> out there and still make money," Chris Hamman says.</p><p>But, as was the case with Calhoun, people do win enough to keep contest dreams alive. SCA Promotions insures more than $100 million in sports contests every year, and the Hammans love telling stories of paying off winners ... because the vast majority of holes-in-one and half-court shots never happen. It's a little like when sportsbooks leak out those betting slips of the fan who hit a 12-team parlay that cost $40 and pays out $250,000. The good news fuels the delusion of it happening to you.</p><p>One of the Hammans' favorite winners was a <a href="https://www.espn.com/mlb/team/_/name/ari/arizona-diamondbacks" target="_blank">Diamondbacks</a> fan, Gylene Hoyle, who won a 1999 radio contest where she had to pick one Arizona player and an inning. If that player hit a home run in that exact inning during a specific game, she'd win $1 million.</p><p>Seems doable, right? The math is actually obscene. She picked <a href="https://www.espn.com/mlb/player/_/id/1823/jay-bell" target="_blank">Jay Bell</a>, who was in the middle of a monster year (38 home runs and 112 RBIs). She had about a 1-in-2,916 chance. And yet, Bell came to the plate in the sixth inning with the bases loaded. He fouled off two straight two-strike pitches, then hit a home run on a pitch that could have been ball four. Afterward, he acknowledged that he knew about the contest and swung hoping to get someone $1 million. "That one stung," Bob Hamman says.</p><p>The math on insuring high-stakes contests generally works the same way. Brokers come up with a likelihood that a random contestant could win -- the Hammans say a three-quarter-court shot is less than 1%, for example -- and divide it into the prize amount, then charge about twice that to insure it. For a $1 million contest with a 1% success rate, that means it'd cost the team $20,000 every time they run it.</p><p>Once the details are ironed out, insurance companies come up with all the fine print. Contestants usually must be randomly selected from the crowd. If it's one shot, there's no warmup toss or second attempt. If it's three makes in 30 seconds, three makes in 30.1 seconds is close but no money. For something like a hockey shot that must go through a tiny plywood cutout and into a goal, the shot has to be entirely through. Not mostly through. Not on the line. <i>Entirely</i> through.</p><p>Insurance companies are unforgiving with teams that don't explain the rules right, and it's not unusual for franchises to end up paying out the contest themselves if there are any issues. The PR hit of stiffing a middle school geometry teacher out of $25,000 generally isn't worth it.</p><p>But lawsuits and disagreements happen, and that's what almost happened to Don Calhoun. One key stipulation in most insurance policies is that the contestant can't have played an "organized" version of the sport in question for a certain time period before the contest -- usually, five years.</p><p>Calhoun grew up in Chicago playing hoops on the playground with Clarence. Both had trouble making it onto junior high and varsity teams despite what seemed to be a worthy skill set. They were tough guards who loved dogging opposing ball handlers on defense. But they also played a brand of streetball that didn't always translate well to high school hoops.</p><p>They certainly had talent, though. Clarence graduated and played at a junior college for his freshman year, then transferred to <a href="https://www.espn.com/mens-college-basketball/team/_/id/305/depaul-blue-demons" target="_blank">DePaul</a> to walk onto the basketball team as a sophomore. Don, then a senior in high school, drew inspiration from Clarence's unwillingness to quit basketball despite a high school career that didn't pan out -- he, too, planned to go to a small school to play hoops before transferring to a bigger school.</p><p>But one weekend, Clarence was on his way home from school to hang out with his family for a few days when the Calhouns got a dreaded phone call. He had gotten tired on the drive home, pulled over to rest, and been struck and killed by another car. He was 20.</p><p>Don was devastated. He didn't graduate that spring on time as he grieved. But he went back to school in the fall and got his diploma. He slowly landed in a headspace where he wanted to use his brother's memory as fuel. He bounced around at two community colleges and walked on with both basketball teams. One newspaper account from the time says he was 3-for-12 shooting in 11 career games.</p><p>But Don eventually walked away from school and from any formal basketball. He found out his longtime girlfriend was pregnant, so he got a job as an office supply salesman. Binders, notebooks, day planners, you name it, Don Calhoun was the guy to talk to. He was making a decent living, and he eventually had a son. The little boy's name? Clarence Calhoun II.</p><p>When Clarence was 3, Don hugged him and told him to watch the Bulls game that night because Dad might be on TV. Clarence remembers his mom letting him stay up, although he's not sure he saw the actual shot. He just recalls yelling and pointing at the screen as he watched his dad leap up and down with Michael Jordan and the Chicago Bulls. Then he went to bed.</p><p>Calhoun says that he marked on the forms that he had played some college basketball three years earlier and that the contest people shrugged about it. The insurance company disagreed, and the weekend after he had won, local news media began to report that Calhoun might not be getting the money. That prompted the Bulls to hold a news conference, where Calhoun sat beside Jerry Reinsdorf and several contest sponsors.</p><p>"It is unclear at this time whether the company that insured the event will pay on the policy," a joint statement read. "However, regardless of its decision, [restaurant group] Lettuce Entertain You, Coca-Cola (Foundation) and the Chicago Bulls will honor the $1 million award and ensure that this event has a happy ending."</p><p>Calhoun left that day knowing that the win was, in fact, going to be a win. He would immediately receive his first of 20 annual $50,000 payments. In the coming weeks, he appeared on "The Tonight Show with Jay Leno" and got a cup of coffee as a member of the Harlem Globetrotters. He was, unbelievably, the unofficial mayor of Chicago for a brief period. When Wilbon called Calhoun's company for his story, someone answered by saying, "Reliable Office Superstore. This is the home of one-shot Don Calhoun, the million-dollar man."</p><p>He never got many details about how the sponsors and insurance company worked it out. He just took yes as an answer. It wasn't until a few weeks later that he found out that he might have needed a key assist from a secret source: Michael Jordan himself.</p><hr><p><b>AFTER CALHOUN</b> made the shot, he was asked to stay on the floor and do an endless string of TV hits and print interviews. As he bounced from camera setup to camera setup near the Chicago locker room, Bulls players kept leaving and spotting him on their way out. Almost every player came over, said congratulations and signed his basketball. "It took me three years to make a million dollars, and it took him five seconds," <a href="https://www.espn.com/nba/player/_/id/279/horace-grant" target="_blank">Horace Grant</a> joked afterward.</p><p>Calhoun got signatures from Grant, Scottie Pippen, John Paxson and <a href="https://www.espn.com/nba/player/_/id/23" target="_blank">B.J. Armstrong</a>, plus two Heat players who swung by, Rony Seikaly and Steve Smith. And then, as he got ready to do another live hit, Calhoun saw Jordan and a Bulls staffer come out and stand nearby. Calhoun made eye contact with Jordan, who smiled back at him and was clearly there waiting to say hello to him. Calhoun wanted to run over and ditch whatever TV interview he was about to do, but producers kept telling him they were about to go live any second now.</p><p>When the lights went on, Calhoun did the best interview he could as he watched in dismay what was happening on the other side of the camera. Jordan said something to the Bulls staffer and left. Calhoun wasn't going to meet MJ, after all, and it crushed him. The Bulls worker said he could leave the ball behind and they'd try to get Jordan to sign it.</p><p>But Calhoun had other plans. He didn't want to leave the building without that ball, so he took it. He thought there was a chance he might run into Jordan somewhere down the road, then he could get an autograph.</p><p>Over the next few days, news broke all over the country that Calhoun's winnings seemed to be in jeopardy. Calhoun clung to that ball, and it provided him hope. He had made the shot. The crowd had gone completely wild. The Bulls had pulled him into their huddle. He had left with the ball. That was all real, and he would have it forever. The $1 million? He sure hoped it was coming his way. But he also felt an odd peace about the money. The experience alone certainly wouldn't pay for Clarence's school clothes. But it wasn't nothing, either. It was priceless.</p><p>As reports swirled, fan outrage was palpable in Chicago, which created enough heat on the franchise to figure out some way to pay the local office supply salesman his damn money. That led to the news conference and the first $50,000 check.</p><p>But what to do about his beloved basketball? The next school year, he had heard from a friend that Jordan always attended one of his kid's home games at a specific school in the area. So he showed up that night -- with his ball and two magazines -- and tried to walk up to Jordan. The Bulls star had his own section away from the crowd, complete with security that kept people from doing exactly what Calhoun was trying to do.</p><p>Calhoun was stopped on his approach by a Jordan security guy, who said Jordan had a firm policy of no autographs at his kids' events. Calhoun explained who he was and that Jordan had seemed to really want to meet him back in April. The security guy wouldn't budge. "No autographs at his kids' stuff," the guy repeated.</p><p>But Calhoun had a funny feeling that he shouldn't give up. He asked the security to <i>pretty-pretty-pretty please</i> tell Jordan that the guy who made The Calhoun Shot had come to the game hoping for his signature. The security guy shook his head. Calhoun was even willing to just hand the guy the ball to take to Jordan. No luck.</p><p>"Michael doesn't do anything when he's at one of his kid's games," Calhoun was told.</p><p>An unlikely thing happened near the end of the game, though. The security guard came to Calhoun in the stands and told him he could walk with Jordan to his car after the game. So Calhoun got his ball and Sharpie ready, then met up with the Jordan crew as he left the high school.</p><p>The first thing out of Jordan's mouth? "Did you get your money?" Jordan asked.</p><p>Calhoun said yes, and Jordan told him something that caught him off guard. "We made them give it to you," Jordan said. "We were upset that they were trying to not pay you."</p><p>Calhoun was stunned. He had heard rumors that the Bulls players were agitated at the thought of him getting stiffed. But this was confirmation that Michael Jordan himself helped make him a millionaire. (Jordan declined an interview request for this story; the Bulls also passed on participating.)</p><p>As they got to a set of doors, Calhoun knew Jordan's car was waiting for him on the other side. He asked whether Jordan would sign his ball, and MJ said no, that he had to stick to his principle of no autographs at his kids' stuff. "Bring it down to my steakhouse and drop it off, then I'll sign it," he said.</p><p>Calhoun waved goodbye that night and thanked Jordan once more for advocating on his behalf. But as he left later, he felt a pang as he considered just pulling up to Jordan's restaurant, dropping off the ball and hoping for the best.</p><p>The ball had grown to mean so much to him. It wasn't the signatures, or that he thought the ball might be worth something like $20,000. Its actual worth was beyond what someone could pay. It represented the agony of losing Clarence and trying to carry his brother's message with his own son. It represented the end of the bitter, unfulfilled taste that "organized" basketball had left in his mouth. It represented closing that chapter of his life when he had to fight and claw to pay every bill for his family, opening up 20 years where he knew he had a financial backstop each year.</p><p>Was he really going to hand the ball to some random steakhouse assistant manager and cross his fingers, hoping he'd see it again?</p><p>The answer was... yes, he was going to do exactly that. He felt as if Jordan's signature was too important as the coda to the story of the ball. So he drove over there one day and implored the person he handed it to for help, saying that this ball meant so much to him, that MJ's signature was the last missing component of an artifact from the most important moment of his life.</p><p>It must have worked. A few weeks later, he got a call to pick up the ball. "Michael signed it, and he wishes you well," Calhoun was told.</p><p>The ball became a family heirloom over the next three decades. But not in the way you'd expect. Calhoun never locked it up in a vault or even put it in a protective case in the house. He left it in the basement of his house, and Clarence and Calhoun's other three kids would dribble it and throw it around. He wanted his kids to be able to touch and feel something that had altered the trajectory of their family. "I'll always keep it for you," Don told Clarence.</p><p>For the next 20 years, Calhoun would get a check for $50,000 every year. Of that money, he'd have to set aside around $12,000 for taxes. He kept his office sales job for a few more years, and the other $38,000 (about $79,000 in 2023 dollars) was a very nice supplemental living. But, as Calhoun says, it was more like a bump up within the middle class. "In reality, you're not rich," he says. "You're not a millionaire."</p><p>Maybe he didn't have generational wealth. But he was about to experience a generational breakthrough.</p><hr><p><b>AS THE 30th ANNIVERSARY</b> of the shot approaches, Calhoun takes a few weeks to decide whether he will talk about the shot, the money or any of it. He hasn't done many interviews over the years. Eventually, he agreed to one but asked that his current location and occupation be left out of the story. Let's say he's living within a few hours of Chicago in the Midwest, and he works the second shift at a solid job.</p><p>He's not hesitant because he's a particularly shy person -- once he gets rolling on the phone, he's funny and unafraid to argue, and he comes off as very open and honest as he talks. Toward the end of an hourlong interview, he asks, "How can I get to the Hall of Fame?"</p><p>When the answer is a surprised chuckle, he says, "Don't you laugh. I want to be in the Hall of Fame. I think I deserve it."</p><p>He seems to be goofing around, but Calhoun changes lanes easily between being confident and reserved. He talks about the shot like he knew it was going in the entire time, yet it never sounds particularly braggy. He seems as if he had his 15 minutes and is content with that ... but also thinks it'd be nice to have a small shrine to it.</p><p>Calhoun is 53 now. He catches the video only every few years, when somebody will show him a tweet or video link to a clip that you will most likely see every April 14 for the rest of eternity.</p><p>Calhoun is neither rich nor poor, at least in the traditional sense of the word. He does, however, feel wealthy when he talks about his four kids. The Calhoun Shot gave them all a better life. His youngest, Terrelle, is 20 and lives in Austin, Texas. Naomi, 22, is in nursing school. Gabriela, 28, is a teacher. And Clarence II, 33, is living out something beyond his own wildest dreams -- and his dad's.</p><p>Don Calhoun's oldest son became a good prep basketball player at East Aurora High School and graduated in 2008. With five years of $50,000 checks left, Don encouraged Clarence to finish the job he and his brother had started years earlier: graduating from college. Clarence loved that idea. What a cool way to pay tribute to the uncle he never met but was named after. The problem was, he still didn't know what he wanted to be when he grew up.</p><p>For the first few years after high school, he bounced between community colleges before getting into Wiley College, an HBCU in Marshall, Texas. He had developed an interest in the human body, especially biology. But college was no joke. Clarence Calhoun II limped to a 1.6 GPA in his first semester. It wasn't that he couldn't handle the coursework or the social life or the amount of work it took. It was the totality of doing all of those things all at once. He didn't know a single person who had experience at this level of education. He was a rookie, surrounded by rookies.</p><p>That's when he met a Ukrainian physician named Dr. Valentyn Siniak. Siniak was at Wiley teaching while he took mandatory tests to begin practicing medicine in the U.S. Calhoun was blown away by the level of support Siniak provided. Calhoun isn't sure exactly what Siniak saw in him, but he saw something.</p><p>In emails to Calhoun, Siniak began calling him "Dr. Clarence Calhoun." When Calhoun asked him for guidance on how he could get his grades up, Siniak made him laugh out loud. "I think you should start tutoring other students," Siniak said.</p><p>"Tutoring?" Calhoun said. "I'm struggling to learn everything myself. How can I teach others?" Siniak thought this would give Calhoun an extra nudge to learn the material and boost his own command.</p><p>Siniak was <i>exactly</i> right. So right, in fact, that Calhoun sighs and shakes his head on a Zoom describing this section of his life. He still can't fathom the way Siniak manifested belief into Calhoun's life. His grades soared, and he liked working with other students. He had to work his ass off to get there -- at one point, campus security officers would close up the science building for the night, knowing Calhoun was still in there. He'd study most of the night, inflate a mattress for a few hours and wake up the next day ready to do it again. "I found out I was smarter than I thought I was," Calhoun says now.</p><p>And so in 2013, Calhoun graduated from college just as his dad's $50,000 annual checks ended. He was the first in his family to get a college degree, and he battled and scrapped every day to get it.</p><p>He also had found out that his girlfriend was pregnant and that they were having a boy. When he told Don, he said, "Know what we're going to name him, Dad?"</p><p>Don began to think about it for a second ... and then it hit him. He didn't say a word, and his son didn't either. They laughed, hugged and celebrated the upcoming birth of Clarence Calhoun III.</p><p>Clarence Calhoun II started to chart a course for the next phase of his life, which had come into focus for him. "I want to be a doctor," he told his dad, and he began to try to get into medical school. He worked jobs at Jiffy Lube, a toxicology lab and other places before he finally passed his labs and got accepted. This was happening. Not only was a Calhoun going to earn his degree but he felt as if he might actually become the Dr. Clarence Calhoun his instructor, Dr. Siniak, had predicted in his emails.</p><p>That's why it breaks the younger Calhoun's heart to tell this next part of the story. Siniak didn't get to see Calhoun get his degree. In January 2013, Siniak was struck and killed while riding a motorcycle in Texas. "Having him believe in me helped me believe in myself," Calhoun says. "My biggest downfall that was keeping me from excelling was my confidence. I just didn't think I could. I didn't have anybody around me who had done it."</p><p>Over the next eight years, he passed his boards and did his residency, and an envelope arrived in May 2021 that he couldn't wait to open. The piece of paper inside made it official: He was now Dr. Clarence Calhoun.</p><p>He went to his dad's house to show him in person, and they had a long embrace. Don couldn't stop smiling. After a minute, he walked out of the room and came back holding two things he was giving to his son.</p><p>One was the shoes he had worn during The Calhoun Shot. Clarence noticed they had a signature on them. They were autographed by ... none other than Don Calhoun, which makes Clarence laugh to this day when he holds them up. His dad can be a goofball -- an inspiring goofball. "He drops spiritual motivation all the time, and that's always needed," Clarence says. "In moments when it feels like life is too difficult, he helps you figure out how you can do it."</p><p>For the second item, Don Calhoun didn't hand it to him. He reared back and threw a push pass at his son's chest.</p><p>"Here, I want you to have this," and he chucked an old basketball at his son. Clarence Calhoun II hadn't seen the ball from The Calhoun Shot in 10-15 years, and now it was going to live with him and his son. The two older Calhouns, Don and Clarence, hugged once more. And as Dr. Clarence Calhoun left that day, with a basketball under one arm and some old shoes under the other, his whole life felt like sinking a less than 1% three-quarter-court shot.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>