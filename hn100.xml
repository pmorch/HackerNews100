<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 15 Apr 2025 13:30:14 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[4chan hacked. Hacker reopens /QA/ and leaks all admins emails (203 pts)]]></title>
            <link>https://old.reddit.com/r/4chan/comments/1jzkjlg/4chan_hacked_hacker_reopens_qa_and_leaks_all/</link>
            <guid>43691334</guid>
            <pubDate>Tue, 15 Apr 2025 11:30:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/4chan/comments/1jzkjlg/4chan_hacked_hacker_reopens_qa_and_leaks_all/">https://old.reddit.com/r/4chan/comments/1jzkjlg/4chan_hacked_hacker_reopens_qa_and_leaks_all/</a>, See on <a href="https://news.ycombinator.com/item?id=43691334">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><hr>

<h2>Community:</h2>

<p><strong>Posts:</strong> /<a href="https://www.reddit.com/r/4chan/new/">new</a>/ /<a href="https://www.reddit.com/r/4chan/hot/">hot</a>/ /<a href="https://www.reddit.com/r/4chan/rising/">rising</a>/ /<a href="https://www.reddit.com/r/4chan/gilded/">gilded</a>/<br>
<strong>Best:</strong> /<a href="https://www.reddit.com/r/4chan/top/">day</a>/ /<a href="https://www.reddit.com/r/4chan/top/?sort=top&amp;t=week">week</a>/ /<a href="https://www.reddit.com/r/4chan/top/?sort=top&amp;t=month">month</a>/ /<a href="https://www.reddit.com/r/4chan/top/?sort=top&amp;t=year">year</a>/ /<a href="https://www.reddit.com/r/4chan/top/?sort=top&amp;t=all">all</a>/  </p>

<p><strong><em>Chat now with local singles!</em></strong>  </p>

<p>/<a href="https://www.reddit.com/chat/r/4chan/channel/343662_6b2573d529f800ceef326da71e13bb6a9de782e3/join">a</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_f86d5fc7bdaf09c426df7813bf1c67d46d15006f/join">b</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_eed3db47f1f7ca1ddab9d42d877a3614e3bb7ea9/join">biz</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_3f2b65504a81d3e556358bb5f1530fe68baf1f94/join">ck</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_15e946f2db5eb0d8787e4809523b56042323a63d/join">co</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_eefc635a36d1c9d910b370f956ac544ab298409f/join">diy</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/205434_04282ce39a208ce313848d0d5ea095efa5bae118/join">fa</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_baef63c244205db7f0a6a76c19ab7bde4ad5c858/join">fit</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_43510f7693eaba06afae4c1a9aa6b22d62887e15/join">k</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_258d605db8a8cb7f5bc088e30eb444c841aa121f/join">lit</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_3a9f6a817e8ae39b957b48cc11e2508b9489790d/join">mlp</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_2d76e3016c21a3a2b0fcf89abb377e2f52c3d739/join">mlpol</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_a96b341a1c565b265df18811b70f112d53f6527d/join">mu</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_6fa799f46bd3df5d302bd4fd91b13f4adb5cbb30/join">o</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_b3345e56f2e198ca1581ace327f42984e87bd71a/join">pol</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_df887d49f86f8597ca61658ea9bb83d735e49c29/join">r9k</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_dc72c284199781a4f5755ee6e505ddb3c054946a/join">s4s</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_4d4c8fbe77a6b408cce295a1724f258273582aaa/join">sci</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_5b6dd40f7d4733b7e547b0fc7fb6ec88db2dc70c/join">sp</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_0e092be5e18cdb325616bcaceef0f738bdf40af3/join">tg</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_5d0e6e3cd84c84bcce15e81691be2a85e5e4b6a0/join">tv</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_6a7a801d2abbef0fa6642376b93781f9d4debeb0/join">v</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_69df75f21b7947bf5c9d79cc35cadf3d1e6ff1e0/join">x</a>/ /<a href="https://www.reddit.com/chat/r/4chan/channel/343662_8252e0b914aa70162e238f3f0fcbc351d4eb948a/join">help desk</a>/  </p>

<p><strong>More Subreddits:</strong>   </p>

<p>/<a href="https://old.reddit.com/r/ChrisChanSonichu">ChrisChanSonichu</a>/</p>

<p>/<a href="https://old.reddit.com/r/r4chanmeta">r4chanmeta</a>/ /<a href="https://old.reddit.com/r/titsorgtfo">titsorgtfo</a>/ /<a href="https://old.reddit.com/r/4chanExploitables">4chanExploitables</a>/ /<a href="https://old.reddit.com/r/4ChanMeta">4ChanMeta</a>/ /<a href="https://old.reddit.com/r/Gondola">Gondola</a>/ /<a href="https://old.reddit.com/r/braveryjerk">braveryjerk</a>/ /<a href="https://old.reddit.com/r/4chanCopypasta">4chanCopypasta</a>/ /<a href="https://old.reddit.com/r/baneposting">baneposting</a>/</p>

<hr>

<h2>Rules:</h2>

<ol>
<li><p><strong>Mods = Gods</strong><br>
Do NOT break any rules that the mods might invent on the spot.  </p></li>
<li><p><strong>4chan Only</strong><br>
Do NOT post anything unrelated to 4chan. Do NOT link directly to 4chan.org. Do NOT post anything from unrelated websites. Screencaps from 4chan are ideal.  </p></li>
<li><p><strong>New Content Only</strong><br>
Do NOT post screencaps over a year old, do NOT repost, and do NOT omit the date and time stamp. Those posts belong in <a href="https://old.reddit.com/r/classic4chan">/r/classic4chan</a> (RIP).</p></li>
<li><p><strong>High Quality Only</strong><br>
This applies to quality content and quality presentation. Crop your post so it's actually legible. Don't post garbage that isn't entertaining.  </p></li>
<li><p><strong>No Redditry</strong><br>
Do NOT act like a basic reddit bitch. This includes cliche reddit phrases, subreddit mentions, puns, song lyrics, novelty accounts, getting lots of karma on a single post, sperging out at someone like a 13 year old on Xbox, and other dummy things that make you a manchild.<br>
E.g. not my proudest fap, <a href="https://old.reddit.com/r/theydidthemath">/r/theydidthemath</a>, I did nazi that coming, cake day, Fake and Gay, /u/[somethingstupid], 1000 upvotes, etc.  </p></li>
<li><p><strong>No Doxxing</strong><br>
Do NOT reveal personal information, or post 4chan screenshots that contain personal information of any individual. Do not post 4chan screenshots of Reddit account names or calls for raids. Remember, NYPA.  </p></li>
<li><p><strong>No CP</strong><br>
Do not post nude images of underage children, or say that nude images of underage children aren't child pornography, or say that nude images of underage children are okay, or describe images of underage children in text form.<br>
If we see you do this anywhere on Reddit, we will report you to the law enforcement agency of where you live.</p></li>
<li><p><strong>NSFW marking</strong><br>
Do NOT forget to mark NSFW content. The overall subreddit is SFW, so people need to really know when a submission is legit NSFW. (Potty Words are not NSFW).  </p></li>
<li><p><strong>No Grooming</strong><br>
No agendaposting.</p></li>
<li><p><strong>Admin abuse</strong><br>
The admins bypassed the mods and directly took action on the subreddit.</p></li>
</ol>

<hr>

<h2>Mods Statement:</h2>

<hr>

<p>We personally severely dislike reddit and everyone who frequents it. We believe it's a shitty, destructive echo chamber that does public harm as an internet publisher. We think this website discourages real interpersonal communication, and encourages addict-like consumption.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Whistleblower details how DOGE may have taken sensitive NLRB data (200 pts)]]></title>
            <link>https://www.npr.org/2025/04/15/nx-s1-5355896/doge-nlrb-elon-musk-spacex-security</link>
            <guid>43691142</guid>
            <pubDate>Tue, 15 Apr 2025 10:55:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2025/04/15/nx-s1-5355896/doge-nlrb-elon-musk-spacex-security">https://www.npr.org/2025/04/15/nx-s1-5355896/doge-nlrb-elon-musk-spacex-security</a>, See on <a href="https://news.ycombinator.com/item?id=43691142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="resg-s1-59636">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/400/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/800/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/1000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/1300/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/1600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/2000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/2600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/png">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/1100/quality/50/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3600x2025+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fad%2F9a%2F7e9500df48c4b4523a0001c3be41%2Fdoge-main.png" alt="" fetchpriority="high">
        </picture>
</div>
<div>
    <div>
        <p>
                The DOGE team may have taken data related to union organizing and labor complaints and hid its tracks, according to a whistleblower.
                <b aria-label="Image credit">
                    
                    Charlotte Gomez for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Charlotte Gomez for NPR
        
    </span>
</p></div>
   </div>
   <p>In the first days of March, a team of advisers from President Trump's new Department of Government Efficiency initiative arrived at the Southeast Washington, D.C., headquarters of the National Labor Relations Board.</p>   <p>The small, independent federal agency investigates and adjudicates complaints about unfair labor practices. It stores reams of potentially sensitive data, from confidential information about employees who want to form unions to proprietary business information.</p>   <p>The DOGE employees, who are effectively led by White House adviser and billionaire tech CEO Elon Musk, appeared to have their sights set on accessing the NLRB's internal systems. They've said their unit's overall mission is to review agency data for compliance with the new administration's policies and to cut costs and maximize efficiency.</p>   
   <p>But according to an official whistleblower disclosure shared with Congress and other federal overseers that was obtained by NPR, subsequent interviews with the whistleblower and records of internal communications, technical staff members were alarmed about what DOGE engineers did when they were granted access, particularly when those staffers noticed a spike in data leaving the agency. It's possible that the data included sensitive information on unions, ongoing legal cases and corporate secrets — data that four labor law experts tell NPR should almost never leave the NLRB and that has nothing to do with making the government more efficient or cutting spending.</p>   
   
<!-- END ID="RESNX-S1-5355896-100" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Meanwhile, according to the disclosure and records of internal communications, members of the DOGE team asked that their activities not be logged on the system and then appeared to try to cover their tracks behind them, turning off monitoring tools and manually deleting records of their access — evasive behavior that several cybersecurity experts interviewed by NPR compared to what criminal or state-sponsored hackers might do.</p>   <div id="resg-s1-59679">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/1000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/1300/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/2000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/2600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/6750x4500+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F48%2Ff5%2F1bb3e223420e87981a07ebfe8776%2Fgettyimages-2203694324.jpg" alt="White House senior adviser Elon Musk walks to the White House after landing in Marine One with President Trump on March 9." loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                White House senior adviser Elon Musk walks to the White House after landing in Marine One with President Trump on March 9.
                <b aria-label="Image credit">
                    
                    Samuel Corum/Getty Images
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Samuel Corum/Getty Images
        
    </span>
</p></div>
   </div>
   <p>The employees grew concerned that the NLRB's confidential data could be exposed, particularly after they started detecting suspicious log-in attempts from an IP address in Russia, according to the disclosure. Eventually, the disclosure continued, the IT department launched a formal review of what it deemed a serious, ongoing security breach or potentially illegal removal of personally identifiable information. The whistleblower believes that the suspicious activity warrants further investigation by agencies with more resources, like the Cybersecurity and Infrastructure Security Agency or the FBI.</p>   
   <p>The labor law experts interviewed by NPR fear that if the data gets out, it could be abused, including by private companies with cases before the agency that might get insights into damaging testimony, union leadership, legal strategies and internal data on competitors — Musk's SpaceX among them. It could also intimidate whistleblowers who might speak up about unfair labor practices, and it could sow distrust in the NLRB's independence, they said.</p>   
   
<!-- END ID="RESNX-S1-5355896-101" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>The new revelations about DOGE's activities at the labor agency come from a whistleblower in the IT department of the NLRB, who disclosed his concerns to Congress and the U.S. Office of Special Counsel in a detailed report that was then provided to NPR. Meanwhile, his attempts to raise concerns internally within the NLRB preceded someone "physically taping a threatening note" to his door that included sensitive personal information and overhead photos of him walking his dog that appeared to be taken with a drone, according to a cover letter attached to his disclosure filed by his attorney, Andrew Bakaj of the nonprofit Whistleblower Aid.</p>   <p>The whistleblower's account is corroborated by internal documentation and was reviewed by 11 technical experts across other government agencies and the private sector. In total, NPR spoke to over 30 sources across the government, the private sector, the labor movement, cybersecurity and law enforcement who spoke to their own concerns about how DOGE and the Trump administration might be handling sensitive data, and the implications for its exposure. Much of the following account comes from the whistleblower's official disclosure and interviews with NPR.</p>   <p>"I can't attest to what their end goal was or what they're doing with the data," said the whistleblower, Daniel Berulis, in an interview with NPR. "But I can tell you that the bits of the puzzle that I can quantify are scary. ... This is a very bad picture we're looking at."</p>   
   
<!-- END ID="RESNX-S1-5355896-102" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>The whistleblower's story sheds further light on how DOGE is operating inside federal systems and comes on the heels of <a href="https://www.npr.org/2025/03/26/nx-s1-5339842/doge-data-access-privacy-act-social-security-treasury-opm-lawsuit" target="_blank">testimony in more than a dozen court cases</a> across the United States that reveal how DOGE rapidly gained access to <a href="https://www.npr.org/2025/03/11/nx-s1-5305054/doge-elon-musk-security-data-information-privacy" target="_blank">private financial and personal information on hundreds of millions of Americans</a>. It's unclear how or whether DOGE is protecting the privacy of that data. Meanwhile, the threatening note, though its origins are unknown, is reflective of the current climate of fear and intimidation toward whistleblowers.</p>   
   
<!-- END ID="RESNX-S1-5355896-103" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Tim Bearese, the NLRB's acting press secretary, denied that the agency granted DOGE access to its systems and said DOGE had not requested access to the agency's systems. Bearese said the agency conducted an investigation after Berulis raised his concerns but "determined that no breach of agency systems occurred."</p>   <p>Notwithstanding the NLRB's denial, the whistleblower's disclosure to Congress and other federal overseers includes forensic data and records of conversations with colleagues that provide evidence of DOGE's access and activities. Meanwhile, NPR's extensive reporting makes clear that DOGE's access to data is a widespread concern. Across the government, 11 sources directly familiar with internal operations in federal agencies and in Congress told NPR that they share Berulis' concerns, and some have seen other evidence that DOGE is exfiltrating sensitive data for unknown reasons.</p>   
   <p>A representative of DOGE did not respond to NPR's requests for comment.<br></p>   <h3>Taking apart computers to protecting government data</h3>   <p>Instead of a brand-new car for a 16th-birthday present, Berulis got his first computer.</p>   <p>It's a familiar story for tech nerds the world over: He methodically took the machine apart "to figure out how it works," just like he had dissected radios from the thrift store years earlier. "I electrocuted myself once," he recalled.</p>   <p>Berulis was always interested in public service, but the traditional paths didn't suit him.</p>   
   
<!-- END ID="RESNX-S1-5355896-104" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>A knee injury prevented him from joining the military. He served as a volunteer firefighter for a period and donated his time working for a local rape crisis hotline, answering calls from victims in need of someone to listen. But, he told NPR, "I had an interest in serving my country."</p>   <p>Berulis had been a technical consultant for many years, including in auditing and modernizing corporate systems, when a job opened up at the National Labor Relations Board.</p>   <div id="resg-s1-60225">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/1000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/1300/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/2000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/2600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8523x5682+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F7a%2F5b%2F795c00cd46f99044a94aa1d5923c%2Fdoge-edit-1.jpg" alt="Daniel Berulis started working at the National Labor Relations Board about six months before President Trump started his second term." loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                Daniel Berulis started working at the National Labor Relations Board about six months before President Trump started his second term.
                <b aria-label="Image credit">
                    
                    Grace Raver/NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Grace Raver/NPR
        
    </span>
</p></div>
   </div>
   <p>While he didn't know much about the agency, Berulis<strong> </strong>quickly found its mission to protect employees' rights in line with his long-standing desire "to help people."</p>   <p>He started about six months before President Trump was inaugurated for his second term this past January. Berulis said he hit the ground running, securing the NLRB's cloud-based data servers and reinforcing what's called "zero trust" principles, which means that users can get access only to the parts of the system they need in order to do their jobs — no more, no less. That way, if an attacker gets hold of a single username and password, the attacker can't access the whole system.</p>   <p>"When I first started, it was a dream come true," he said. "There was a great opportunity to build up and do some good." But after the inauguration, he described a "culture of fear" descending over the agency.<br></p>   
   <h3>DOGE arrives&nbsp;</h3>   <p>The first week of March, engineers associated with DOGE arrived at the NLRB's headquarters, according to Berulis' disclosure. Beforehand, they had asked about what software, hardware, programming languages and applications the NLRB was using. DOGE learned that it used commercially available cloud infrastructure that businesses typically use, which connects to government cloud systems at other agencies and can be accessed remotely.</p>   <p>Berulis said he and several colleagues saw a black SUV and police escort enter the garage, after which building security let the DOGE staffers in. They interacted with a small number of staffers, never introducing themselves to most of the IT team.</p>   <p>Berulis says he was told by colleagues that DOGE employees demanded the highest level of access, what are called "tenant owner level" accounts inside the independent agency's computer systems, with essentially unrestricted permission to read, copy and alter data, according to Berulis' disclosure.</p>   <p>When an IT staffer suggested a streamlined process to activate those accounts in a way that would let their activities be tracked, in accordance with NLRB security policies, the IT staffers were told to stay out of DOGE's way, the disclosure continues.</p>   <p>For cybersecurity professionals, a failure to log activity is a cardinal sin and contradicts best practices as recommended by the <a href="https://www.nist.gov/cyberframework" target="_blank">National Institute of Standards and Technology</a> and the Department of Homeland Security's Cybersecurity and Infrastructure Security Agency, as well as the FBI and the National Security Agency.</p>   <p>"That was a huge red flag," said Berulis. "That's something that you just don't do. It violates every core concept of security and best practice."</p>   <div data-crop-type="" id="resg-s1-59634">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/400/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/800/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1300/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/png">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1100/quality/50/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F09%2Fe2%2F9f2467c44b4d83977ce269bc6eed%2Fdoge-spot-01.png" alt="Doge_Spot_01.png" loading="lazy">
        </picture>
</div>
   <p>Those forensic digital records are important for record-keeping requirements and they allow for troubleshooting, but they also allow experts to investigate potential breaches, sometimes even tracing the attacker's path back to the vulnerability that let them inside a network. The records can also help experts see what data might have been removed. Basic logs would likely not be enough to demonstrate the extent of a bad actor's activities, but it would be a start. There's no reason for any legitimate user to turn off logging or other security tools, cybersecurity experts say.</p>   
   <p>"None of this is normal," said Jake Braun, the executive director of the Cyber Policy Initiative at the University of Chicago's Harris School of Public Policy and former acting principal deputy national cyber director at the White House, in an interview with NPR about the whistleblower's disclosure. "This type of activity is why the government buys insider-threat-monitoring technology. So we can know things like this are happening and stop sensitive data exfiltration before it happens," he told NPR.</p>   <p>However, the NLRB's budget hasn't had the money to pay for tools like that for years, Berulis said.<br></p>   <h3>A backdoor to government systems?</h3>   <p>A couple of days after DOGE arrived, Berulis saw something else that alarmed him while browsing the internet over the weekend.</p>   <p>Massachusetts Institute of Technology graduate and DOGE engineer Jordan Wick had been sharing information about coding projects he was working on to his public account with GitHub, a website that allows developers to create, store and collaborate on code.</p>   <p>After journalist Roger Sollenberger started <a href="https://x.com/SollenbergerRC/status/1895609294810464390" target="_blank">posting on X</a> about the account, Berulis noticed something Wick was working on: a project, or repository, titled "NxGenBdoorExtract."</p>   <p>Wick made it private before Berulis could investigate further, he told NPR. But to Berulis, the title itself was revealing.</p>   <p>"So when I saw this tool, I immediately panicked, just for lack of a better term," he said. "I kind of had a conniption and said, 'Whoa, whoa, whoa.'" He immediately alerted his whole team.</p>   <p>While NPR was unable to recover the code for that project, the name itself suggests that Wick could have been designing a backdoor, or "Bdoor," to extract files from the NLRB's internal case management system, known as NxGen, according to several cybersecurity experts who reviewed Berulis' conclusions.</p>   <p>Wick did not respond to NPR's requests for comment.</p>   <div id="resg-s1-60224">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/400/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/800/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/1000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/1300/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/1600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/2000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/2600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/png">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/1100/quality/50/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/538x575+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F8f%2Fe2%2Fb5ea0e5d406bba8c5eb9fc343604%2Fdoge-github-data-annotation.png" alt="A screenshot of DOGE engineer Jordan Wick's public GitHub account that shows &quot;NxGenBdoorExtract.&quot; The name itself suggests that Wick could have been designing a backdoor, or &quot;Bdoor,&quot; to extract files from the NLRB's internal case management system." loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                A screenshot of DOGE engineer Jordan Wick's public GitHub account that shows "NxGenBdoorExtract." The name itself suggests that Wick could have been designing a backdoor, or "Bdoor," to extract files from the NLRB's internal case management system.
                <b aria-label="Image credit">
                    
                    Daniel Berulis/Annotation by NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Daniel Berulis/Annotation by NPR
        
    </span>
</p></div>
   </div>
   <p>"It definitely seems rather odd to name it that," said one of the engineers who built NxGen and asked for anonymity so as not to jeopardize their ability to work with the government again. "Or brazen, if you're not worried about consequences."</p>   
   <p>"The whole idea of removing logging and [getting] tenant-level access is the most disturbing part to me," the engineer said.</p>   <p>NxGen is an <a href="https://www.governmentattic.org/57docs/NLRBnxGenCMSreplace2024-2025.pdf" target="_blank">internal system</a> that was designed specifically for the NLRB in-house, according to several of the engineers who created the tool and who all spoke to NPR on condition of anonymity to avoid retaliation or adverse consequences for any future government work.</p>   <p>The engineers explained that while many of the NLRB's records are eventually made public, the NxGen case management system hosts proprietary data from corporate competitors, personal information about union members or employees voting to join a union, and witness testimony in ongoing cases. Access to that data is protected by numerous federal laws, including the Privacy Act.</p>   <p>Those engineers were also concerned by DOGE staffers' insistence that their activities not be logged, allowing them to probe the NLRB's systems and discover information about potential security flaws or vulnerabilities without being detected.</p>   <p>"If he didn't know the backstory, any [chief information security officer] worth his salt would look at network activity like this and assume it's a nation-state attack from China or Russia," said Braun, the former White House cyber official.<br></p>   <h3>Putting the puzzle pieces together</h3>   <p>About a week after arriving, the DOGE engineers had left the NLRB and deleted their accounts, according to Berulis' disclosure to Congress.</p>   <p>In the office, Berulis had had limited visibility into what the DOGE team was up to in real time.</p>   <p>That's partly because, he said, the NLRB isn't advanced when it comes to detecting insider threats or potentially malicious actors inside the agency itself. "We as an agency have not evolved to account for those," he explained. "We were looking for [bad actors] outside," he said.</p>   <p>But he counted on DOGE leaving at least a few traces of its activity behind, puzzle pieces he could assemble to try to put together a picture of what happened — details he included in his official disclosure.</p>   
   <p>First, at least one DOGE account was created and later deleted for use in the NLRB's cloud systems, hosted by Microsoft: "<a href="mailto:DogeSA_2d5c3e0446f9@nlrb.microsoft.com" target="_blank">DogeSA_2d5c3e0446f9@nlrb.microsoft.com</a>."</p>   <p>Then, DOGE engineers installed what's called a "container," a kind of opaque virtual computer that can run programs on a machine without revealing its activities to the rest of the network. On its own, that wouldn't be suspicious, though it did allow the engineers to work invisibly and left no trace of its activities once it was removed.</p>   <p>Then, Berulis started tracking sensitive data leaving the places it's meant to live, according to his official disclosure. First, he saw a chunk of data exiting the NxGen case management system's "nucleus," inside the NLRB system, Berulis explained. Then, he saw a large spike in outbound traffic leaving the network itself.</p>   <div id="resg-s1-60219">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/1000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/1300/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/2000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/2600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2048x1455+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F3e%2F38%2F4f7753974f60b1833783b65ddd52%2Fdoge-data-leaving.jpg" alt="This screenshot shows a large spike in outbound traffic leaving the NLRB system." loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                This screenshot shows a large spike in outbound traffic leaving the NLRB system.
                <b aria-label="Image credit">
                    
                    Whistleblower Aid
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Whistleblower Aid
        
    </span>
</p></div>
   </div>
   <p>From what he could see, the data leaving, almost all text files, added up to around 10 gigabytes — or the equivalent of a full stack of encyclopedias if someone printed them, he explained. It's a sizable chunk of the total data in the NLRB system, though the agency itself hosts over 10 terabytes in historical data. It's unclear which files were copied and removed or whether they were consolidated and compressed, which could mean even more data was exfiltrated. It's also possible that DOGE ran queries looking for specific files in the NLRB's system and took only what it was looking for, according to the disclosure.</p>   <p data-pym-loader="" data-child-src="https://apps.npr.org/dailygraphics/graphics/doge-nlrb-diagrams-20250404/container.html" id="responsive-embed-doge-nlrb-diagrams-20250404-container"> Loading... </p>
   
<!-- END ID="RESNX-S1-5355896-105" CLASS="BUCKETWRAP STATICHTML" -->
   <p>Regardless, that kind of spike is extremely unusual, Berulis explained, because data almost never directly leaves from the NLRB's databases. In his disclosure, Berulis shared a screenshot tracking data entering and exiting the system, and there's only one noticeable spike of data going out. He also confirmed that no one at the NLRB had been saving backup files that week or migrating data for any projects.</p>   <p>Even when external parties like lawyers or overseers like the inspector general are granted guest accounts on the system, it's only to view the files relevant to their case or investigation, explained labor law experts who worked with or at the NLRB, in interviews with NPR.</p>   <p>"None of that confidential and deliberative information should ever leave the agency," said Richard Griffin, who was the NLRB general counsel from 2013 to 2017, in an interview with NPR.<br></p>   <h3>"We are under assault right now"</h3>   <p>For cybersecurity experts, that spike in data leaving the system is a key indicator of a breach, Berulis explained.</p>   
   <p>"We are under assault right now," he remembered thinking.</p>   <p>When Berulis asked his IT colleagues whether they knew why the data was exfiltrated or whether anyone else had been using containers to run code on the system in recent weeks, no one knew anything about it or the other unusual activities on the network, according to his disclosure. In fact, when they looked into the spike, they found that logs that were used to monitor outbound traffic from the system were absent. Some actions taken on the network, including data exfiltration, had no attribution — except to a "deleted account," he continued. "Nobody knows who deleted the logs or how they could have gone missing," Berulis<strong> </strong>said.</p>   <p>The IT team met to discuss insider threats — namely, the DOGE engineers, whose activities it had little insight into or control over. "We had no idea what they did," he explained. Those conversations are reflected in his official disclosure.</p>   <p>They eventually launched a formal breach investigation, according to the disclosure, and prepared a request for assistance from the Cybersecurity and Infrastructure Security Agency (CISA). However, those efforts were disrupted without an explanation, Berulis said. That was deeply troubling to Berulis, who felt he needed help to try to get to the bottom of what happened and determine what new vulnerabilities might be exploited as a result.</p>   <p>In the days after Berulis and his colleagues prepared a request for CISA's help investigating the breach, Berulis found a printed letter in an envelope taped to his door, which included threatening language, sensitive personal information and overhead pictures of him walking his dog, according to the cover letter attached to his official disclosure. It's unclear who sent it, but the letter made specific reference to his decision to report the breach. Law enforcement is investigating the letter.</p>   
   <p>"If the underlying disclosure wasn't concerning enough, the targeted, physical intimidation and surveillance of my client is. If this is happening to Mr. Berulis, it is likely happening to others and brings our nation more in line with authoritarian regimes than with open and free democracies," wrote Bakaj, his attorney, in a statement sent to NPR. "It is time for everyone – and Congress in particular – to acknowledge the facts and stop our democracy, freedom, and liberties from slipping away, something that will take generations to repair."</p>   <p>In part because of the stymied internal investigation and the attempts to silence him, Berulis decided to come forward publicly.</p>   <p>In fact, despite all that, Berulis managed to uncover some stranger and more troubling details about what happened while DOGE was logged on, which he enumerated in his official declaration.</p>   <p>Unknown users also gave themselves a high-level access key, what's called a SAS token, meaning "shared access signature," to access storage accounts, before deleting it. Berulis said there was no way to track what they did with it.</p>   <p>Someone had disabled controls that would prevent insecure or unauthorized mobile devices from logging on to the system without the proper security settings. There was an interface exposed to the public internet, potentially allowing malicious actors access to the NLRB's systems. Internal alerting and monitoring systems were found to be manually turned off. Multifactor authentication was disabled. And Berulis noticed that an unknown user had exported a "user roster," a file with contact information for outside lawyers who have worked with the NLRB.</p>   <p>Berulis said he noticed five PowerShell downloads on the system, a task automation program that would allow engineers to run automated commands. There were several code libraries that got his attention — tools that he said appeared to be designed to automate and mask data exfiltration. There was a tool to generate a seemingly endless number of IP addresses called "requests-ip-rotator," and a commonly used automation tool for web developers called "browserless" — both repositories starred or favorited by Wick, the DOGE engineer, according to an archive of his GitHub account reviewed by NPR.</p>   
   <p>While investigating the data taken from the agency, Berulis tried to determine its ultimate destination. But whoever had exfiltrated it had disguised its destination too, according to the disclosure.</p>   <p>DOGE staffers had permission to access the system, but removing data is another matter.</p>   <p>Berulis says someone appeared to be doing something called DNS tunneling to prevent the data exfiltration from being detected. He came to that conclusion, outlined in his disclosure, after he saw a traffic spike in DNS requests parallel to the data being exfiltrated, a spike 1,000 times the normal number of requests.</p>   <p>When someone uses this kind of technique, they set up a domain name that pings the target system with questions or queries. But they configure the compromised server so that it answers those DNS queries by sending out packets of data, allowing the attacker to steal information that has been broken down into smaller chunks.</p>   <p>"We've seen Russian threat actors do things like this on U.S. government systems," said one threat intelligence researcher who requested anonymity because they weren't authorized to speak publicly by their employer. That analyst, who has extensive experience hunting nation-state-sponsored hackers, reviewed the whistleblower's technical claims.</p>   <p>"The difference is, they were given the keys to the front door," the researcher continued. While the researcher clarified that it would be difficult to fully verify what happened without full access to the NLRB system, they said Berulis' conclusions and accompanying evidence were a cause for concern. "None of this is standard," they said.</p>   <p>Russ Handorf, who served in the FBI for a decade in various cybersecurity roles, also reviewed Berulis' extensive technical forensic records and analysis and spoke to NPR about his conclusions.</p>   <p>"All of this is alarming," he said. "If this was a publicly traded company, I would have to report this [breach] to the Securities and Exchange Commission. The timeline of events demonstrates a lack of respect for the institution and for the sensitivity of the data that was exfiltrated. There is no reason to increase the security risk profile by disabling security controls and exposing them, less guarded, to the internet. They didn't exercise the more prudent standard practice of copying the data to encrypted and local media for escort."</p>   <p>"Until there's an investigation done, there's no way to definitively prove who did it," Handorf concluded.<br></p>   <h3>"No reason whatsoever for accessing the information"</h3>   <div id="resg-s1-60227">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/1000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/1300/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/2000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/2600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5000x3335+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff0%2F87%2F4722e7324f15aaa3ec8dbfdcebea%2Fgettyimages-1172591604.jpg" alt="The National Labor Relations Board seal hangs inside a hearing room at the agency's headquarters in Washington, D.C., in 2019." loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                The National Labor Relations Board seal hangs inside a hearing room at the agency's headquarters in Washington, D.C., in 2019.
                <b aria-label="Image credit">
                    
                    Andrew Harrer/Bloomberg via Getty Images
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Andrew Harrer/Bloomberg via Getty Images
        
    </span>
</p></div>
   </div>
   <p>DOGE's intentions with regard to the NLRB data remain unclear. Many of the systems that DOGE embedded itself in across the rest of the government <a href="https://www.npr.org/2025/03/08/nx-s1-5321323/trump-doge-gsa-federal-buildings" target="_blank">have payment or employment data</a>, information that it could use to evaluate which grants and programs to halt and whom to fire.</p>   
   
<!-- END ID="RESNX-S1-5355896-106" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>But the case management system is very different.</p>   <p>It houses information about ongoing contested labor cases, lists of union activists, internal case notes, personal information from Social Security numbers to home addresses, proprietary corporate data and more information that never gets published openly.</p>   
   
<!-- END ID="RESNX-S1-5355896-107" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Experts interviewed by NPR acknowledge that there are inefficiencies across government that warrant further review, but they say they don't see a single legitimate reason that DOGE staffers would need to remove the data from the case management system to resolve those problems.</p>   <p>"There is no reason whatsoever for accessing the information. Now, could any agency be more efficient? More effective? Positively. But what you need for that is people who understand what the agency does. That is not by mining data, putting algorithms in and creating a breach of security," said Harley Shaiken, a professor emeritus at the University of California, Berkeley who specializes in labor and information technology.</p>   <p>"There is nothing that I can see about what DOGE is doing that follows any of the standard procedures for how you do an audit that has integrity and that's meaningful and will actually produce results that serve the normal auditing function, which is to look for fraud, waste and abuse," said Sharon Block, the executive director of Harvard Law School's Center for Labor and a Just Economy and a former NLRB board member.</p>   <p>"The mismatch between what they're doing and the established, professional way to do what they say they're doing ... that just kind of gives away the store, that they are not actually about finding more efficient ways for the government to operate," Block said.</p>   <p>For labor law experts, the mere possibility that sensitive records were copied is a serious danger that could create a chilling effect for employees everywhere who turn to the National Labor Relations Board for protection.</p>   <p>"Just saying that they have access to the data is intimidating," said Kate Bronfenbrenner, the director of labor education research at Cornell University and co-director of the Worker Empowerment Research Network. "People are going to go, 'I'm not going to testify before the board because, you know, my employer might get access.'"</p>   <p>Bronfenbrenner, the child of immigrant parents who fled the Soviet Union and Nazi-controlled Germany, said she spends a lot of time thinking about how systems can crumble under the right circumstances. "You know, there's this belief that we have these checks and balances … but anyone who's part of the labor movement should know that's not true," she told NPR.</p>   <p>With access to the data, it would make it easier for companies to fire employees for union organizing or keep blacklists of organizers — illegal activities under federal labor laws enforced by the NLRB. But "people get fired in this country all the time for the lawful act of trying to organize a union," said Block.</p>   <p>Having a copy of the opposing counsel's notes as companies prepare for legal challenges would also be an attractive possibility, she continued.</p>   
   
<!-- END ID="RESNX-S1-5355896-108" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>It's not just employees who might suffer if this data got out. Companies also sometimes provide detailed statements on internal business planning and corporate structure in the midst of unfair-labor-practice complaint proceedings. If a company was attempting to fire someone who it alleged had disclosed trade secrets and was fighting an unfair-labor-practice complaint based around that decision, those trade secrets might come up in the board's investigation too. That information would be valuable to competitors, regulators and others.</p>   <p>Overall, the potential exposure of the NLRB's data could have serious implications.</p>   <p>"I think it is very concerning," said Shaiken. "It could result in damage to individual workers, to union-organizing campaigns and to unions themselves," he said.</p>   <p>"It is bringing a wrecking ball into the dentist office, meaning this is wildly disproportionate and raises real dangers," Shaiken continued.<br></p>   <h3>A conflict of interest and the dangers of exposure</h3>   <p>Labor law experts were particularly concerned about what they described as clear conflicts of interest, particularly when it comes to Elon Musk, his companies and his vast network of former employees and allies who are now getting access to government jobs and data.</p>   
   
<!-- END ID="RESNX-S1-5355896-109" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Trump and Musk, during an interview with Fox News's Sean Hannity, said Musk would recuse himself from anything involving his companies. "I haven't asked the president for anything ever," <a href="https://www.whitehouse.gov/remarks/2025/02/interview-of-president-trump-and-elon-musk-by-sean-hannity-the-sean-hannity-show/" target="_blank">Musk said</a>. "I'm getting a sort of a daily proctology exam here. You know, it's not like I'll be getting away [with] something in the dead of night." However, DOGE has been granted high-level access to a lot of data that could benefit Musk, and there has been no evidence of a firewall preventing misuse of that data.</p>   
   
<!-- END ID="RESNX-S1-5355896-110" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>There are multiple ongoing cases involving Musk and the NLRB. For one, after a group of former SpaceX employees lodged a complaint with the NLRB, lawyers representing SpaceX, some of whom were <a href="https://www.npr.org/2025/03/27/nx-s1-5341559/lawyer-represented-musk-spacex-downsize-federal-contractors-watchdog" target="_blank">recently hired into government jobs</a>, <a href="https://www.npr.org/2024/11/18/nx-s1-5192918/spacex-amazon-nlrb-labor-board-elon-musk" target="_blank">filed suit against the NLRB.</a> They argued that the agency's structure is unconstitutional.</p>   <div id="resg-s1-60218">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/1000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/1300/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/2000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/2600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/8256x5504+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F77%2Ff8%2F29b23df04f55968adadb2255f074%2Fgettyimages-2185639186.jpg" alt="Elon Musk speaks with then-President-elect Donald Trump and guests at a viewing of the launch of the sixth test flight of the SpaceX Starship rocket on November 19, 2024, in Brownsville, Texas." loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                Elon Musk speaks with then-President-elect Donald Trump and guests at a viewing of the launch of the sixth test flight of the SpaceX Starship rocket on Nov. 19, 2024, in Brownsville, Texas.
                <b aria-label="Image credit">
                    
                    Brandon Bell/Getty Images
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Brandon Bell/Getty Images
        
    </span>
</p></div>
   </div>
   <p>Sen. Chris Murphy, D-Conn. <a href="https://www.murphy.senate.gov/newsroom/press-releases/murphy-presses-labor-secretary-nominee-on-protecting-sensitive-data-and-the-nlrb-from-elon-musk" target="_blank">raised his concerns </a>about Musk accessing sensitive labor investigation data on cases against his companies or competitors during the confirmation hearing for Trump's labor secretary, Lori Chavez-DeRemer, in mid-February. He pressed her to answer whether she believed the NLRB is constitutional and to commit to keeping sensitive data confidential. While she said she was committed to "privacy" and said she respects the NLRB's "authority," she insisted that Trump "has the executive power to exercise it as he sees fit."</p>   <p>All this is happening in the context of a broader attempt by the White House to hamstring labor agencies.</p>   <p>The NLRB was created "to guarantee workers' rights to organize and to address problems that workers have in the workplace," said Shaiken, of UC Berkeley. Under President Joe Biden, he recalled, the labor movement enjoyed an unusual amount of support from Washington. "But what we have seen is a sharp slamming of the brakes to that and putting the vehicle in reverse in terms of what Trump has done so far," he continued.</p>   <p>In addition to sending DOGE to the NLRB, the Trump administration tried to neutralize the board's power to enforce labor law by removing its member Gwynne Wilcox. Courts have gone <a href="https://bsky.app/profile/kyledcheney.bsky.social/post/3lm7wvvih4c27" target="_blank">back and forth</a> on whether Wilcox's removal was illegal, as presidents are meant to demonstrate cause for dismissal of independent board members.</p>   <p>Representatives of DOGE and former colleagues of Musk's who have been installed across the federal government have failed to reassure the public or the courts that they have taken the proper precautions to protect the data they're ingesting and that private business interests won't influence how that data is used or what policy decisions are made, Block and the other labor law experts interviewed by NPR say.</p>   <p>"It's not that he's a random person who's getting information that a random person shouldn't have access to," said Harvard Law's Block. "But if they really did get everything, then he has information about the cases the government is building against him," she said.</p>   <p>"DOGE is, whether they admit it or not, headed by somebody who is the subject of active investigation and prosecution of cases. It is incredibly troubling," she said.</p>   <p>Musk's company xAI could also benefit from sucking up all the data DOGE has collected to train its algorithms. Cybersecurity experts like Bruce Schneier, a well-known cryptographer and adjunct lecturer at the Harvard Kennedy School, have <a href="https://www.hks.harvard.edu/faculty-research/policy-topics/science-technology-data/doge-putting-countrys-data-and-computing" target="_blank">pointed to this concern</a> at length in interviews and written pieces.</p>   <p>According to two federal government sources who were not authorized to speak publicly about their workplaces and who shared email documentation with NPR, managers have consistently been warning employees that their data could be subject to AI review, particularly their email responses to the Musk-led campaign to get federal employees to detail "what they did last week" in five bullet points every Monday.</p>   <p>"It's not a flight of imagination to see several DOGE staffers release some of that [data] surreptitiously to Musk or people close to him," said Shaiken.<br></p>   <h3>Access for adversaries</h3>   <div data-crop-type="" id="resg-s1-59635">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/400/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/800/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1300/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2000/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/2600/quality/85/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/png">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/1100/quality/50/format/png/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/2500x1875+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F31%2Fac%2F88dc9f014080a4834083d858806b%2Fdoge-spot-02.png" alt="Doge_Spot_02.png" loading="lazy">
        </picture>
</div>
   <p>If the data isn't properly protected after it leaves the agency or if DOGE left a digital door open to the agency itself, data could also be exposed to potential sale or theft by criminals or foreign adversaries. An attacker could also try to take advantage of the connections between the NLRB's cloud account and other government cloud environments, using their access to the NLRB as a foothold to move to other networks.</p>   <p>"Both criminals and foreign adversaries traditionally have used information like this to enrich themselves through a variety of actions," explained Handorf, the former FBI cyber official. "That includes blackmail, targeting and prioritizing intellectual property theft for espionage or even harming a company to enrich another."</p>   <p>Within minutes after DOGE accessed the NLRB's systems, someone with an IP address in Russia started trying to log in, according to Berulis' disclosure. The attempts were "near real-time," according to the disclosure. Those attempts were blocked, but they were especially alarming. Whoever was attempting to log in was using one of the newly created DOGE accounts — and the person had the correct username and password, according to Berulis. While it's possible the user was disguising their location, it's highly unlikely they'd appear to be coming from Russia if they wanted to avoid suspicion, cybersecurity experts interviewed by NPR explained.</p>   <p>On their own, a few failed login attempts from a Russian IP address aren't a smoking gun, those cybersecurity experts interviewed by NPR said. But given the overall picture of activity, it's a concerning sign that foreign adversaries may already be searching for ways into government systems that DOGE engineers may have left exposed.</p>   <p>"When you move fast and break stuff, the opportunity to ride the coattails of authorized access is ridiculously easy to achieve," said Handorf. What he means is that if DOGE engineers left access points to the network open, it would be very easy for spies or criminals to break in and steal data behind DOGE.</p>   <p>He said he could also see foreign adversaries trying to recruit or pay DOGE team members for access to sensitive data. "It would not surprise me if DOGE is accidentally compromised."</p>   <p>"This is exactly why we usually architect systems using best practices like the principle of least privilege," Ann Lewis, the former director of Technology Transformation Services at the General Services Administration, told NPR in an interview. "The principle of least privilege is a fundamental cybersecurity concept … that states that users should have only the minimum rights, roles and permissions required to perform their roles and responsibilities. This protects access to high-value data and critical assets and helps prevent unauthorized access, accidental damage from user errors and malicious actions. "</p>   <p>Bakaj, Berulis' lawyer, told NPR in a written statement: "This case has been particularly sensitive as it involves the possibility of sophisticated foreign intelligence gaining access to sensitive government systems, which is why we went to the Senate Intelligence Committee directly."<br></p>   <h3><strong>A troubling pattern</strong></h3>   <p>The NLRB isn't alone in those concerns.</p>   <p>In over a dozen lawsuits in federal courts <a href="https://www.npr.org/2025/03/26/nx-s1-5339842/doge-data-access-privacy-act-social-security-treasury-opm-lawsuit" target="_blank">around the country</a>, judges have demanded that DOGE explain why it needs such expansive access to sensitive data on Americans, from Social Security records to private medical records and tax information. But the Trump administration has been unable to give consistent and clear answers, largely dismissing cybersecurity and privacy concerns.</p>   <p>In one case dealing with Treasury Department payment systems that control trillions of dollars in federal spending, U.S. District Judge Jeannette Vargas <a href="https://www.npr.org/2025/03/31/nx-s1-5345708/doge-data-access-labor-cfpb-hhs" target="_blank">blocked DOGE access</a> on Feb. 21, finding "a real possibility exists that sensitive information has already been shared outside of the Treasury Department, in potential violation of federal law."</p>   <p>It's an <a href="https://oversightdemocrats.house.gov/news/press-releases/committee-democrats-are-shining-light-doges-dark-dealings" target="_blank">area of focus </a>for Democratic lawmakers on the House Committee on Oversight and Government Reform.</p>   <div id="resg-s1-60265">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/1000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/1300/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/2000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/2600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3128x2085+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F00%2F20%2Fbce2d3214d218b126bca9a259595%2Fap25072786044651.jpg" alt="U.S. District Judge Jeannette Vargas blocked DOGE access to the Treasury Department over the possibility that &quot;sensitive information has already been shared outside of the Treasury Department.&quot;" loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                U.S. District Judge Jeannette Vargas blocked DOGE access to the Treasury Department over the possibility that "sensitive information has already been shared outside of the Treasury Department."
                <b aria-label="Image credit">
                    
                    Alex Brandon/AP
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Alex Brandon/AP
        
    </span>
</p></div>
   </div>
   <p>An aide for the Democratic minority on the House Oversight Committee who was not authorized to speak publicly told NPR that the committee is in possession of multiple verifiable reports showing that DOGE has exfiltrated sensitive government data across agencies for unknown purposes, revealing that Berulis' disclosure is not an isolated incident.</p>   
   
<!-- END ID="RESNX-S1-5355896-111" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>But government cybersecurity officials are already resigning or being fired, forced to relocate or put on administrative leave all over the federal government, from the <a href="https://www.npr.org/2025/02/11/nx-s1-5293521/foreign-influence-elections-cisa-trump" target="_blank">Cybersecurity and Infrastructure Security Agency</a> to the <a href="https://www.npr.org/2025/03/20/nx-s1-5333655/interior-department-budget-cuts-doge" target="_blank">Interior Department</a>. That has limited their power to respond to the ongoing disruptions or keep track of what DOGE is doing.</p>   
   
<!-- END ID="RESNX-S1-5355896-112" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>One of the first people to speak out about DOGE's access to sensitive data was Erie Meyer, who resigned as the chief technology officer at the Consumer Financial Protection Bureau (CFPB) in February. She has provided testimony in ongoing court cases surrounding DOGE's access and also spoke to NPR in an interview. The CFPB has sensitive and potentially market-moving data. Meyer said DOGE employees granted themselves "God-tier" access to the CFPB's systems, turned off auditing and event logs and put the cybersecurity experts responsible for insider threat detection on administrative leave. When IT experts at the CFPB planned to conduct an "after action" report on DOGE's activities, they were stonewalled, she continued.</p>   <p>When she heard about how DOGE engineers operated at the NLRB, particularly the steps they took to obfuscate their activities, she recognized a pattern.</p>   <p>"I am trembling," she said upon hearing about the potential exposure of data from the NLRB. "They can get every piece of whistleblower testimony, every report, everything. This is not good."</p>   <p>Other technical employees working with government agencies who spoke to NPR shared Berulis' concerns.</p>   <p>"Our cyber teams are pissed because they have to sit on their hands when every single alarm system we have regarding insider threats is going off," said one employee at an agency of the Interior Department who requested anonymity, fearing retribution. Cybersecurity teams wanted to shut off new users' access to the system, the employee continued, but were ordered to stand down.</p>   <p>Meanwhile, in a <a href="https://federalnewsnetwork.com/commentary/2025/03/letter-to-the-editor-46-former-gsa-executives-say-cuts-to-cause-irreversible-damage/?readmore=1" target="_blank">letter published</a> on March 13 on Federal News Network, 46 former senior officials from the General Services Administration, one of the government agencies hardest hit by DOGE's cost-cutting efforts and that oversees nearly all federal buildings and purchasing, wrote that they believed "highly-sensitive IT systems are being put at risk and sensitive information is being downloaded to unknown, unvetted external sources in clear violation of privacy and data-protection rules."<br></p>   <h3>The tip of the iceberg</h3>   <p>The Trump administration could be trying to codify DOGE's practices into how the government shares information, said Kel McClanahan, the executive director of nonprofit public interest law firm National Security Counselors, who is representing federal employees in a lawsuit concerning the Office of Personnel Management's use of a private email server.</p>   <p>Weeks after DOGE staffers descended on federal buildings across Washington, Trump issued an <a href="https://www.whitehouse.gov/fact-sheets/2025/03/fact-sheet-president-donald-j-trump-eliminates-information-silos-to-stop-waste-fraud-and-abuse-60f3/" target="_blank">executive order</a> urging increased data sharing "by eliminating information silos" in what's seen by experts like McClanahan as an attempt to give DOGE engineers further top cover in accessing and amalgamating sensitive federal data, despite laws concerning privacy and cybersecurity.</p>   <p>"The entire reason we have a Privacy Act is that Congress realized 50 years ago that the federal government was just overflowing with information about normal everyday people and needed some guardrails in place," McClanahan told NPR. "The information silos are there for a reason," he continued. "It's astonishing to me that the very people who not a handful of years ago were screaming about the government tracking us with vaccines now cheer for feeding every piece of information about themselves into Elon Musk's stupid Skynet."</p>   <p>DOGE appears to still be in the process of visiting federal agencies across the country, including just recently the Securities and Exchange Commission, according to one former government source directly familiar with the matter who requested anonymity to share information they weren't authorized to share. Across the government, it's unclear how much sensitive data has been removed and collected and combined.</p>   <p>It's also unclear where the labor data went and who has access to it. But for experts in workers' rights, the threat is immediate and existential.</p>   <p>"This shocks the conscience," said Richard Griffin, the former general counsel of the NLRB. "And if DOGE operatives captured and removed case files, it could constitute a violation of the <a href="https://www.npr.org/2025/03/13/1238261955/over-a-dozen-lawsuits-to-stop-doge-data-access-are-betting-on-a-1974-law" target="_blank">Privacy Act</a>."</p>   <p>For Berulis, it was important to speak out, because he believes people deserve to know how the government's data and computer systems are at risk, and to prevent further damage. As a former IT consultant, Berulis says he would have been fired for operating like DOGE.</p>   <div id="resg-s1-60230">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/1000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/1300/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/2000/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/2600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/1000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 1000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/1300/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 1300w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/2000/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 2000w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/2600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg 2600w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg" sizes="(min-width: 1300px) 1238px, (min-width: 1025px) calc(100vw - 60px), (min-width: 768px) calc(100vw - 60px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5666x3777+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fed%2Fe4%2F8bca795840cfa0e88e4efe5b0144%2Fdoge-edit-3.jpg" alt="Daniel Berulis hopes that there might be further investigations into mishandling of sensitive data across the federal government." loading="lazy">
        </picture>
</div>
<div>
    <div>
        <p>
                Daniel Berulis hopes that there might be further investigations into mishandling of sensitive data across the federal government.
                <b aria-label="Image credit">
                    
                    Grace Raver/NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Grace Raver/NPR
        
    </span>
</p></div>
   </div>
   <p>Disclosing his concerns "was a moral imperative at this point," he said. "I've never encountered this in my 20 years of IT."</p>   <p>His hope is that there might be further investigations into mishandling of sensitive data across the federal government.</p>   <p>"I believe with all my heart that this goes far beyond just case data," he said. "I know there are [people] at other agencies who have seen similar behavior. I firmly believe that this is happening maybe even to a greater extent at other agencies."</p>   <p>For overseers, investigators and IT experts in a similar position, he hopes to provide a road map of what to look for.</p>   <p>"It was my goal by disclosing to Congress not to focus on me at all, but to give them information that they might not necessarily have, the things that you don't necessarily look for unless you know where to look," he continued.</p>   <p>The NLRB said it would cooperate with any investigations that stem from Berulis' disclosure to Congress.</p>   <p>"As an agency protecting employee rights, the NLRB respects its employee's right to bring whistleblower claims to Congress and the Office of Special Counsel, and the Agency looks forward to working with those entities to resolve the complaints," said Bearese, the agency's acting spokesperson, in a statement.</p>   <p>Berulis had a simple request for the DOGE engineers: "Be transparent. If you have nothing to hide, don't delete logs, don't be covert. ... Be open, because that's what efficiency is really about. If this is all a huge misunderstanding, then just prove it. Put it out there. That's all I'm asking."</p>   <p>But ultimately, if the systems that DOGE accesses are left insecure, it might not matter if its intentions are honorable, he concluded.</p>   <p>"This could just be the start of the operation. ... They still haven't crossed that boundary where they're plugged into every federal system out there," he continued. "So maybe there is still time."</p>   <p><strong><em>NPR's Stephen Fowler contributed reporting. NPR's Brett Neely edited this story.&nbsp;</em></strong></p>   <p><em>Have information or evidence to share about DOGE's access to data inside the federal government?&nbsp;Reach out to the author, </em><a href="https://www.npr.org/people/1038324514/jenna-mclaughlin" target="_blank"><em>Jenna McLaughlin</em></a><em>, through encrypted communications on Signal at jennamclaughlin.54. </em><a href="https://www.npr.org/people/1219684807/stephen-fowler" target="_blank"><em>Stephen Fowler</em></a><em> is available on Signal at stphnfwlr.25. Please use a nonwork device.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: MCP-Shield – Detect security issues in MCP servers (102 pts)]]></title>
            <link>https://github.com/riseandignite/mcp-shield</link>
            <guid>43689178</guid>
            <pubDate>Tue, 15 Apr 2025 05:15:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/riseandignite/mcp-shield">https://github.com/riseandignite/mcp-shield</a>, See on <a href="https://news.ycombinator.com/item?id=43689178">Hacker News</a></p>
Couldn't get https://github.com/riseandignite/mcp-shield: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Hacking a Smart Home Device (2024) (246 pts)]]></title>
            <link>https://jmswrnr.com/blog/hacking-a-smart-home-device</link>
            <guid>43688658</guid>
            <pubDate>Tue, 15 Apr 2025 03:12:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jmswrnr.com/blog/hacking-a-smart-home-device">https://jmswrnr.com/blog/hacking-a-smart-home-device</a>, See on <a href="https://news.ycombinator.com/item?id=43688658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>How I reverse engineered an ESP32-based smart home device to gain remote control access and integrate it with Home Assistant.</p><h2><a href="#introduction" title="Introduction"><span>Introduction</span></a></h2><p>Recently, I've been slightly obsessed with connecting anything and everything in my house to <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.home-assistant.io/"><span>Home Assistant</span></a>. There's something so satisfying about having everything connected and automated in one application; I can finally forget every random mobile app for a different brand of smart product.</p><p>But there is one product I own that stubbornly doesn't connect to anything other than its own mobile app. It's a sleek air purifier that is unfortunately let down by its disappointing app.</p><p>So many modern products depend on an internet connection and cloud account for basic functions, and who knows what unnecessary data they collect or technical vulnerabilities they add to the home network?</p><p>I want to control this expensive air purifier just like the rest of my smart gadgets. And that marks the start of this challenging yet undoubtedly fun journey.</p><p><strong>It's time to hack an air purifier! 😆</strong></p><p>By the way, if you enjoy my content, you can <a target="_blank" rel="noopener noreferrer" href="https://buymeacoffee.com/jmswrnr"><span>Buy Me a Coffee</span></a> to support my content creation!</p><div><p>The contents of this post are intended for educational purposes on the process of reverse engineering IoT smart devices and network protocols. </p><p>Hacking can be a scary term, so I'd like to make it clear that my intentions were solely to upgrade the smart device I've purchased to integrate with my smart home system. Doing so does not affect any other instances of this product or its cloud services. Therefore, any sensitive product-specific data, such as private keys, domains, or API endpoints, have been obfuscated or redacted from this post.</p><p>Tinkering with your devices will likely void any warranty and carries a risk of permanently damaging the device; do so at your own risk.</p></div><h2><a href="#the-plan" title="The Plan"><span>The Plan</span></a></h2><p>If we're going to hack this device to be controlled by custom software, we're going to need to understand its current capabilities and plan a point of attack, requiring the least amount of work to achieve our goal. </p><p>The device already supports remote control with its own mobile app, which annoyingly requires a cloud account to use. By toggling my phone's Bluetooth, WiFi, and 5G, I was able to confirm that the app required an internet connection to control the device. Remote control was not possible locally via Bluetooth or WiFi.</p><p>This means the mobile app and device must be connected to a cloud server for the remote control to be possible. So, somewhere in that network, data between the device and its cloud server must be the fan speed and everything else the app controls. </p><p>So, that is our point of attack:</p><ul><li><p>If we can intercept the device's network traffic and change those values, we have control of the device. </p></li><li><p>If we can emulate all of the server responses, we have control of the device without depending on an internet connection and its cloud server.</p></li></ul><h2><a href="#mobile-app-analysis" title="Mobile App Analysis"><span>Mobile App Analysis</span></a></h2><p>One of the first things I looked into was the remote control mobile app. This can be a quick way to gather some information, as Android apps can be relatively simple to pull apart.</p><p>Apps on Android are stored as a <code>.apk</code> file. With a quick search online, you can find a website to download a specific app's latest <code>.apk</code>. If you didn't know, the format of an <code>.apk</code> is technically a <code>.zip</code> file! you can simply extract them to browse the app's contents.</p><p>Android apps include compiled Java executables, usually named <code>classes.dex</code>. You can convert these to a <code>.jar</code> file with <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/pxb1988/dex2jar"><span>dex2jar</span></a> and use <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/java-decompiler/jd-gui"><span>jd-gui</span></a> to browse the contents as reconstructed source code.</p><p>Locating the app <code>MainActivity.class</code> revealed that it is built with React Native!</p><div><pre><code><span><span>package</span><span> com</span><span>.</span><span>smartdeviceapp</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>import</span><span> com</span><span>.</span><span>facebook</span><span>.</span><span>react</span><span>.</span><span>ReactActivity</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>public</span><span> </span><span>class</span><span> </span><span>MainActivity</span><span> </span><span>extends</span><span> </span><span>ReactActivity</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>protected</span><span> String </span><span>getMainComponentName</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>return</span><span> </span><span>"SmartDeviceApp"</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>For Android apps built with React Native, you can find the JavaScript bundle in <code>assets/index.android.bundle</code>. </p><p>A quick scan of the app's bundle revealed it uses a secure WebSocket connection:</p><div><pre><code><span><span>self</span><span>.</span><span>ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"wss://smartdeviceapi.---.com"</span><span>)</span><span>;</span></span></code></pre></div><p>There isn't too much interest here in this Android app; as expected, it connects with their cloud server in order to remote control the smart device. It's worth a quick look due to the simplicity of getting some readable source code. We can always reference this bundle to see if any shared values or logic can be found there.</p><h2><a href="#network-inspection" title="Network Inspection"><span>Network Inspection</span></a></h2><p>Next up, it's time to have a look at the network traffic between the device and its cloud server; this is what we're trying to intercept and, ideally, emulate.</p><p>I use Pi-hole locally, which is a DNS server that blocks tracking and some ads, but it also has a useful feature to browse DNS queries by device. By navigating to the <code>Tools &gt; Network</code> page and selecting the device's local network address, we can see it's querying the DNS server for the address of the cloud server's domain:</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="811" height="99" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 811px" srcset="https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/2ace8e71d5ec9263c46f755a4a1609e91b68704c-811x99.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>So now we know the cloud server's domain it's connecting to, we can use the <code>Local DNS</code> feature to send that network traffic to my local workstation (<code>192.168.0.10</code>) instead of their cloud server:</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="453" height="173" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 453px" srcset="https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/d1a377dd0c49cbb6798bc4269f9bfa706d6ee68a-453x173.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>We can then use <a target="_blank" rel="noopener noreferrer" href="https://www.wireshark.org/"><span>Wireshark</span></a> to take a look at the traffic coming in from the smart device. We can do this by monitoring the workstation network interface with a filter of <code>ip.addr == 192.168.0.61</code> (smart device address).</p><p>By doing this, I was able to see UDP packets being sent from the smart device to the workstation on the port <code>41014</code>! </p><h2><a href="#packet-analysis" title="Packet Analysis"><span>Packet Analysis</span></a></h2><p>So, we know the smart device uses UDP to communicate with its cloud server. But right now, it's trying to communicate with my workstation and is expecting it to respond like its cloud server.</p><p>We can use a simple UDP proxy for our workstation to act as a relay between the smart device and its cloud server. </p><p>I used <a target="_blank" rel="noopener noreferrer" href="https://www.cloudflare.com/en-gb/learning/dns/what-is-1.1.1.1/"><span>Cloudflare's DNS resolver</span></a> (<code>1.1.1.1</code>) to look up the real IP address for their cloud server (because my Pi-hole DNS would have just resolved to my workstation's local IP address). Then I used <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.npmjs.com/package/node-udp-forwarder"><span>node-udp-forwarder</span></a> as a simple method to relay the traffic to their cloud server:</p><div><div><pre><code><span><span>udpforwarder \
</span></span><span><span></span><span>--</span><span>destinationPort </span><span>41014</span><span> </span><span>--</span><span>destinationAddress </span><span>X</span><span>.</span><span>X</span><span>.</span><span>X</span><span>.</span><span>X</span><span> \
</span></span><span><span></span><span>--</span><span>protocol udp4 </span><span>--</span><span>port </span><span>41014</span></span></code></pre></div><p><code>X.X.X.X</code> being the real IP address of their cloud server.</p></div><p>Looking at Wireshark again, we can see all the network traffic between the smart device and its cloud server!</p><p>When booting the device, it would send a packet to the server with data like this:</p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 31 02 01 23 45 67  89 AB CD EF FF 00 01 EF</span><span>  U.1..#Eg........
</span></span><span><span></span><span>00000010</span><span>  1E 9C 2C C2 BE FD 0C 33  20 A5 8E D6 EF 4E D9 E3</span><span>  ..,....3 ....N..
</span></span><span><span></span><span>00000020</span><span>  6B 95 00 8D 1D 11 92 E2  81 CA 4C BD 46 C9 CD 09</span><span>  k.........L.F...
</span></span><span><span></span><span>00000030</span><span>  0E                               </span><span>                 .</span></span></code></pre></div><p>The server would then respond with the following:</p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 2F 82 01 23 45 67  89 AB CD EF FF 37 34 9A</span><span>  U./..#Eg.....74.
</span></span><span><span></span><span>00000010</span><span>  7E E6 59 7C 5D 0D AF 71  A0 5F FA 88 13 B0 BE 8D</span><span>  ~.Y|]..q._......
</span></span><span><span></span><span>00000020</span><span>  ED A0 AB FA 47 ED 99 9A  06 B9 80 96 95 C0 96  </span><span>   ....G..........</span></span></code></pre></div><p>All of the packets after this seemed to share a similar structure. They did not include any readable strings but were full of what appeared to be random bytes of data; this could be the <a target="_blank" rel="noopener noreferrer nofollow" href="https://en.wikipedia.org/wiki/Avalanche_effect"><span>Avalanche effect</span></a> pointing toward encryption.</p><p>I searched around to see if this packet structure was an existing protocol. I read that DTLS is used by some smart devices and that it is based on UDP.</p><p>However, Wireshark does support the detection of DTLS packets but listed this packet as UDP, which means it couldn't determine a UDP-based protocol from the data. I double-checked with the DTLS specification, but that described a header format different from what we see in the packet, so we know DTLS isn't used here.</p><p>At this point, we hit a blocker; we don't understand how the data is formatted in these packets, which means we can't manipulate or emulate anything yet.</p><p>This would have been a lot easier if it used a well-documented protocol, but where's the fun in that?</p><h2><a href="#physical-disassembly" title="Physical Disassembly"><span>Physical Disassembly</span></a></h2><p>We know there are 2 applications that understand how to read this packet data: the smart device and its cloud server. And well, I don't have their cloud server handy, so it's time to take a look inside the smart device!</p><p>It was quite easy to disassemble with a few easily accessible screws. Inside was the main PCB containing the microcontroller, a port connecting to the fan, and a ribbon cable to the control panel on the front.</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="2444" height="1286" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 2444px" srcset="https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/007257763d8f8dc8b6fdafc5e662deec344e866d-2444x1286.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>The main controller is labeled as an <code>ESP32-WROOM-32D</code>. This microcontroller is commonly used in smart devices and features WiFi and Bluetooth.</p><p>I stumbled across the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/BlackVS/ESP32-reversing"><span>ESP32-reversing</span></a> GitHub repo, which contained a nice list of ESP32-related reverse engineering resources.</p><h2><a href="#serial-connection" title="Serial Connection"><span>Serial Connection</span></a></h2><p>The ESP32 contains a flash chip, which is where the firmware containing application logic is most likely stored. </p><p>The manufacturer of the ESP32 provides a utility called <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/espressif/esptool"><span>esptool</span></a> to communicate with the ROM bootloader in the ESP32. With this tool, it's possible to read data from the flash, but first, we must establish a serial connection!</p><p>Referencing the <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.espressif.com/sites/default/files/documentation/esp32-wroom-32_datasheet_en.pdf"><span>ESP32 datasheet</span></a>, we can find the pin layout diagram:</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="515" height="623" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 515px" srcset="https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/3965e510a5e3bf781a590b23878118d590ad8cea-515x623.svg?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><p>Here, we can see the <code>TXD0</code>(35) and <code>RXD0</code>(34) pins. We need to connect a wire to both of these pins and a ground pin for a serial connection. </p><p>The device PCB had a few pin holes, which are commonly connected to the pins for debugging and flashing; I was able to visually follow the traces from both of these serial pins to the holes! This allowed me to easily solder on breakout headers that I could temporarily plug jumper wires into. Otherwise, I would have likely carefully soldered directly to the chip pins.</p><p>With a multimeter set to continuity mode, I was able to locate which hole was ground by referencing the <code>GND</code>(38) pin on the ESP32.</p><p>Now, we need a port to handle this UART serial communication. I used my <a target="_blank" rel="noopener noreferrer nofollow" href="https://flipperzero.one/"><span>Flipper Zero</span></a>, which has a handy <code>USB-UART Bridge</code> application under the <code>GPIO</code> category. </p><p>Using 3 jumper wires, I connected them together:</p><ul><li><p>Flipper Zero <code>TX</code> &lt;--&gt; <code>RX</code> ESP32 </p></li><li><p>Flipper Zero <code>RX</code> &lt;--&gt; <code>TX</code> ESP32 </p></li><li><p>Flipper Zero <code>GND</code> &lt;--&gt; <code>GND</code> ESP32 </p></li></ul><div><p>The <code>TX</code> and <code>RX</code> wires are intentionally crossed here; we want to transmit data to the other device's receiving line!</p></div><p>In Windows Device Manager, under the <code>Ports (COM &amp; LPT)</code> category, I found my Flipper Zero UART device as <code>COM7</code>. Using <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.chiark.greenend.org.uk/~sgtatham/putty/"><span>Putty</span></a> configured to a Serial connection on <code>COM7</code> at <code>115200</code> speed, I was able to successfully connect to the Flipper Zero. While searching around, I saw this speed was often used for the ESP32, so I decided to go with it here.</p><p>When booting up the smart device, I noticed a bunch of log data from the serial output:</p><div><div><pre><code><span><span>rst</span><span>:</span><span>0x1</span><span> </span><span>(</span><span>POWERON_RESET</span><span>)</span><span>,</span><span>boot</span><span>:</span><span>0x13</span><span> </span><span>(</span><span>SPI_FAST_FLASH_BOOT</span><span>)</span><span>
</span></span><span><span>configsip</span><span>:</span><span> </span><span>0</span><span>,</span><span> SPIWP</span><span>:</span><span>0xee</span><span>
</span></span><span><span>clk_drv</span><span>:</span><span>0x00</span><span>,</span><span>q_drv</span><span>:</span><span>0x00</span><span>,</span><span>d_drv</span><span>:</span><span>0x00</span><span>,</span><span>cs0_drv</span><span>:</span><span>0x00</span><span>,</span><span>hd_drv</span><span>:</span><span>0x00</span><span>,</span><span>wp_drv</span><span>:</span><span>0x00</span><span>
</span></span><span><span>mode</span><span>:</span><span>DIO</span><span>,</span><span> clock div</span><span>:</span><span>2</span><span>
</span></span><span><span>load</span><span>:</span><span>0x3fff0030</span><span>,</span><span>len</span><span>:</span><span>4476</span><span>
</span></span><span><span>ho </span><span>0</span><span> tail </span><span>12</span><span> room </span><span>4</span><span>
</span></span><span><span>load</span><span>:</span><span>0x40078000</span><span>,</span><span>len</span><span>:</span><span>13512</span><span>
</span></span><span><span>ho </span><span>0</span><span> tail </span><span>12</span><span> room </span><span>4</span><span>
</span></span><span><span>load</span><span>:</span><span>0x40080400</span><span>,</span><span>len</span><span>:</span><span>3148</span><span>
</span></span><span><span>entry </span><span>0x400805f0</span><span>
</span></span><span><span></span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>
</span></span><span><span></span><span>**</span><span>    Starting SmartDevice    </span><span>**</span><span>
</span></span><span><span></span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>**</span><span>
</span></span><span><span>This </span><span>is</span><span> esp32 chip </span><span>with</span><span> </span><span>2</span><span> CPU core</span><span>(</span><span>s</span><span>)</span><span>,</span><span> WiFi</span><span>/</span><span>BT</span><span>/</span><span>BLE</span><span>,</span><span> silicon revision </span><span>1</span><span>,</span><span> 4MB external flash
</span></span><span><span>Minimum free heap size</span><span>:</span><span> </span><span>280696</span><span> </span><span>bytes</span><span>
</span></span><span><span>nvs_flash_init ret</span><span>:</span><span> </span><span>0</span><span>
</span></span><span><span>Running app </span><span>from</span><span>:</span><span> factory
</span></span><span>Mounting FAT filesystem
</span><span><span>csize</span><span>:</span><span> </span><span>1</span><span>
</span></span><span><span></span><span>122</span><span> KiB total drive space</span><span>.</span><span>
</span></span><span><span></span><span>0</span><span> KiB available</span><span>.</span><span>
</span></span><span>FAT filesystem mounted
</span><span>SERIAL GOOD
</span><span>CapSense Init
</span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>serial
</span></span><span><span>Serial Number</span><span>:</span><span> 0123456789abcdefff
</span></span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>dev_key</span><span>.</span><span>key
</span></span><span>Device key ready
</span><span><span>Base64 Public Key</span><span>:</span><span> </span><span>**</span><span>REDACTED</span><span>**</span><span>
</span></span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>SmartDevice</span><span>-</span><span>root</span><span>-</span><span>ca</span><span>.</span><span>crt
</span></span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>SmartDevice</span><span>-</span><span>signer</span><span>-</span><span>ca</span><span>.</span><span>crt
</span></span><span><span>Addtimeout</span><span>:</span><span> </span><span>10000</span><span>,</span><span> </span><span>id</span><span>:</span><span> </span><span>0</span><span>
</span></span><span>RELOAD FALSE
</span><span><span>Opening</span><span>[</span><span>rb</span><span>]</span><span>:</span><span> </span><span>/</span><span>spiflash</span><span>/</span><span>server_config
</span></span><span>MP PARSE DONE
</span><span><span>Server</span><span>:</span><span> smartdeviceep</span><span>.</span><span>-</span><span>-</span><span>-</span><span>.</span><span>com</span><span>:</span><span>41014</span></span></code></pre></div><p>We can pick out some useful information from this output:</p><ul><li><p>The device has a 4MB flash chip.</p></li><li><p>The application runs from <code>factory</code>, which is a common partition name for the default application flashed at the factory.</p></li><li><p>A FAT filesystem is mounted.</p></li><li><div><p>The application reads files for:</p><ul><li><p>Serial number</p></li><li><p>Device key</p></li><li><p>Two CA certificates (root and signer)</p></li><li><p>Server config</p></li></ul></div></li></ul></div><h2><a href="#dumping-flash" title="Dumping Flash"><span>Dumping Flash</span></a></h2><p>Awesome, now we have a working serial connection, we can focus on dumping the flash, hoping it contains information on how to read these packets!</p><p>To read the flash, we need to boot the ESP32 in a different mode, specifically what it calls the <code>Download Boot</code> mode. This is technically explained in the <code>Strapping Pins</code> section of the datasheet. But TL;DR, I held a jumper wire from a <code>GND</code> port on my Flipper Zero to the <code>IO0</code>(25) pin on the ESP32 while it boots. </p><p>Checking the serial output with Putty, we can see this successfully boots the smart device into the <code>Download Boot</code> mode:</p><div><pre><code><span><span>rst</span><span>:</span><span>0x1</span><span> </span><span>(</span><span>POWERON_RESET</span><span>)</span><span>,</span><span>boot</span><span>:</span><span>0x3</span><span> </span><span>(</span><span>DOWNLOAD_BOOT</span><span>(</span><span>UART0</span><span>/</span><span>UART1</span><span>/</span><span>SDIO_REI_REO_V2</span><span>)</span><span>)</span><span>
</span></span><span><span>waiting </span><span>for</span><span> download</span></span></code></pre></div><p>Now we can close Putty and switch over to a Terminal to use esptool. </p><p>We're able to dump the entire 4MB of flash data from the ESP32 with the following command:</p><div><pre><code><span><span>esptool </span><span>-</span><span>p </span><span>COM7</span><span> </span><span>-</span><span>b </span><span>115200</span><span> read_flash </span><span>0</span><span> </span><span>0x400000</span><span> flash</span><span>.</span><span>bin</span></span></code></pre></div><p>I dumped the flash a couple of times to ensure I had a good read and backed them up in case we accidentally brick something because then we can flash back the dump.</p><div><p>To read the flash successfully using the Flipper Zero, I had to change its config to specify the baud rate of <code>115200</code> instead of <code>Host</code>.</p></div><h2><a href="#flash-analysis" title="Flash Analysis"><span>Flash Analysis</span></a></h2><p>We have the ESP32 flash dumped into a single binary file, and now we need to make sense of it. I found <a target="_blank" rel="noopener noreferrer" href="https://github.com/jmswrnr/esp32knife"><span>esp32knife</span></a> to be the best utility for this.</p><p>It reads the flash file and extracts a bunch of useful information. It was also the only utility that successfully reformatted this dump into ELF format with correctly mapped virtual memory, but more on that later! Let's see what we can find:</p><div><pre><code><span><span>python esp32knife</span><span>.</span><span>py </span><span>--</span><span>chip</span><span>=</span><span>esp32 load_from_file </span><span>.</span><span>/</span><span>flash</span><span>.</span><span>bin</span></span></code></pre></div><p>This logs out a lot of information and saves the output data to a <code>./parsed</code> folder.</p><p>The first file of interest here is <code>partitions.csv</code>, this table maps areas of data in the flash:</p><div><div><pre><code><span><span># </span><span>ESP</span><span>-</span><span>IDF</span><span> Partition Table
</span></span><span><span># Name</span><span>,</span><span>   Type</span><span>,</span><span> SubType</span><span>,</span><span>  Offset</span><span>,</span><span>   Size</span><span>,</span><span> Flags
</span></span><span><span>nvs</span><span>,</span><span>      data</span><span>,</span><span> nvs</span><span>,</span><span>      </span><span>0x9000</span><span>,</span><span>   16K</span><span>,</span><span>
</span></span><span><span>otadata</span><span>,</span><span>  data</span><span>,</span><span> ota</span><span>,</span><span>      </span><span>0xd000</span><span>,</span><span>   8K</span><span>,</span><span>
</span></span><span><span>phy_init</span><span>,</span><span> data</span><span>,</span><span> phy</span><span>,</span><span>      </span><span>0xf000</span><span>,</span><span>   4K</span><span>,</span><span>
</span></span><span><span>factory</span><span>,</span><span>  app</span><span>,</span><span>  factory</span><span>,</span><span>  </span><span>0x10000</span><span>,</span><span>  768K</span><span>,</span><span>
</span></span><span><span>ota_0</span><span>,</span><span>    app</span><span>,</span><span>  ota_0</span><span>,</span><span>    </span><span>0xd0000</span><span>,</span><span>  768K</span><span>,</span><span>
</span></span><span><span>ota_1</span><span>,</span><span>    app</span><span>,</span><span>  ota_1</span><span>,</span><span>    </span><span>0x190000</span><span>,</span><span> 768K</span><span>,</span><span>
</span></span><span><span>storage</span><span>,</span><span>  data</span><span>,</span><span> fat</span><span>,</span><span>      </span><span>0x250000</span><span>,</span><span> 1M</span><span>,</span><span>
</span></span><span></span></code></pre></div><p>Here, we can see a few interesting entries:</p><ul><li><p>There are three application partitions. Two are labeled <code>ota</code>, which is where over-the-air firmware updates are written. The other is labeled <code>factory</code>, and we know from the serial output during boot this is the application partition that is currently used.</p></li><li><p>That <code>storage</code> partition has the FAT type, this like likely the FAT filesystem we saw mounting in the serial output.</p></li><li><p><code>nvs</code> is a key-value storage partition, there may be some useful data here.</p></li></ul></div><div><p>Other readers have mentioned that this flash dump could have been protected if the device had enabled flash encryption (which it does not in this case). </p></div><h2><a href="#device-storage" title="Device Storage"><span>Device Storage</span></a></h2><p>I was initially curious to see what data was in the <code>nvs</code> key-value storage partition. </p><p>The latest state of this data was extracted to <code>part.0.nvs.cvs</code>, and the only interesting data I could see was my WiFi SSID and password. But I also found the full historical changelog of values in <code>part.0.nvs.txt</code> and that revealed a couple of previously used WiFi credentials; what<strong>!?</strong> did someone use this thing before me?😆</p><p>Following that, it was time to look at the contents of the FAT <code>storage</code> partition. I found <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.osforensics.com/tools/mount-disk-images.html"><span>OSFMount</span></a> to be a great Windows application for this; it mounts the filesystem image as a virtual disk and allows writing to it!</p><p>This revealed a few interesting files that we saw from the serial output earlier:</p><div><div><pre><code><span><span>dev_info
</span></span><span>dev_key.key
</span><span>serial
</span><span>server_config
</span><span>SmartDevice-root-ca.crt
</span><span>SmartDevice-signer-ca.crt
</span><span>wifi_config</span></code></pre></div><p>I inspected the contents of these files and found:</p><ul><li><p><code>dev_info</code> - a UUID labeled <code>firmware</code>, likely the version installed</p></li><li><p><code>dev_key.key</code> - 256-bit private key (prime256v1), the public key for this was printed to the serial output labeled <code>Device key</code>!</p></li><li><p><code>serial</code> - the serial number</p></li><li><p><code>server_config</code> - the address and port number we found earlier</p></li><li><p><code>SmartDevice-root-ca.crt</code> - a CA certificate with a 256-bit public key (prime256v1)</p></li><li><p><code>SmartDevice-signer-ca.crt</code> - a CA certificate with a 256-bit public key (prime256v1) and the root certificate as its CA (certificate authority)</p></li><li><p><code>wifi_config</code> - my WiFi SSID and password</p></li></ul></div><p>The <code>dev_key.key</code> file started with  <code>-----BEGIN EC PRIVATE KEY-----</code> which is an Elliptic Curve private key; I used <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.openssl.org/"><span>openssl</span></a> to verify this with:</p><div><pre><code><span><span>openssl ec </span><span>-</span><span>in</span><span> dev_key</span><span>.</span><span>key </span><span>-</span><span>text </span><span>-</span><span>noout</span></span></code></pre></div><p>And the two <code>.crt</code> files started with <code>-----BEGIN CERTIFICATE-----</code> which I also verified using openssl with:</p><div><pre><code><span><span>openssl x509 </span><span>-</span><span>in</span><span> </span><span>.</span><span>/</span><span>SmartDevice</span><span>-</span><span>root</span><span>-</span><span>ca</span><span>.</span><span>crt </span><span>-</span><span>text </span><span>-</span><span>noout
</span></span><span><span>openssl x509 </span><span>-</span><span>in</span><span> </span><span>.</span><span>/</span><span>SmartDevice</span><span>-</span><span>signer</span><span>-</span><span>ca</span><span>.</span><span>crt </span><span>-</span><span>text </span><span>-</span><span>noout</span></span></code></pre></div><p>Having the certificates and device key stored on the device strongly indicates they are used to encrypt the UDP network packet data.</p><h2><a href="#initial-static-analysis" title="Initial Static Analysis"><span>Initial Static Analysis</span></a></h2><p>Now we've taken a look at the storage, it's time to look at the application which runs on the device. </p><p>We know it's running the <code>factory</code> partition, so I opened the <code>part.3.factory</code> file in the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/NationalSecurityAgency/ghidra"><span>Ghidra</span></a> CodeBrowser. Ghidra is a free and open-source suite of reverse engineering tools from the NSA; it's an alternative to the paid <a target="_blank" rel="noopener noreferrer nofollow" href="https://hex-rays.com/ida-pro/"><span>IDA Pro</span></a>.</p><p>This file we're opening is the partition image direct from the flash; it's comprised of multiple segments of data, each getting mapped to different virtual memory regions on the ESP32. For example, data at offset <code>0x17CC4</code> in the partition image is actually mapped to <code>0x40080ce0</code> in the device's virtual memory, so although this file contains all of the application logic and data, Ghidra won't understand how to resolve any absolute memory references, at least for now. There will be more on this later!</p><p>The ESP32 microprocessor uses the Xtensa instruction set, and Ghidra has recently added support for this! When loading the image, you can select the language <code>Tensilica Xtensa 32-bit little-endian</code>. We can run the auto analysis; although it won't give us great results just yet, we can still look at any defined strings it is able to find.</p><h2><a href="#string-theory" title="String Theory"><span>String Theory</span></a></h2><p>Text strings in a compiled application are a fast-track way of locating and understanding logic when reverse engineering; they can reveal a lot about the application. </p><p>Because this compiled file only contains bytecode instructions for the processor, there are no function names, data types, or parameters. It can initially seem like a giant blob of nonsense, but as soon as you a string reference like <code>Failed to read wifi config file</code>, you can start to piece together what the logic is doing. Reverse engineering compiled applications can be difficult, but it is certainly a rewarding challenge.</p><p>So, I had a look through the <code>Defined Strings</code> window in Ghidra to see what I could find, and noticed all of the strings we saw in the serial output, such as:</p><div><div><pre><code><span><span>000031c4	</span><span>"Serial Number: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>000031fc	</span><span>"Device key ready</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003228	</span><span>"Base64 Public Key: %s</span><span>\r</span><span>\n</span><span>"</span></span></code></pre></div><p>As expected, the address is the string's location in the partition image. Ideally, this should be the address in the virtual memory when running on the ESP32; that way, we can see any bytecode that references this string. We'll tackle that soon!</p></div><p>In close proximity to these strings were some others of interest:</p><div><div><pre><code><span><span>000030d0	</span><span>"Message CRC error</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003150	</span><span>"Seed Error: %d</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>000031c4	</span><span>"Serial Number: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>000031fc	</span><span>"Device key ready</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003228	</span><span>"Base64 Public Key: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>00003240	</span><span>"Error reading root cert!!!!</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003260	</span><span>"Error reading signer cert!!!!</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003280	</span><span>"PRNG fail</span><span>\r</span><span>"</span><span>
</span></span><span><span>0000328c	</span><span>"ECDH setup failed</span><span>\r</span><span>"</span><span>
</span></span><span><span>000032a0	</span><span>"mbedtls_ecdh_gen_public failed</span><span>\r</span><span>"</span><span>
</span></span><span><span>000032c0	</span><span>"mbedtls_mpi_read_binary failed</span><span>\r</span><span>"</span><span>
</span></span><span><span>000032e0	</span><span>"Error copying server key to ECDH</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003304	</span><span>"mbedtls_ecdh_compute_shared failed: 0x%4.4X</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>00003334	</span><span>"Error accessing shared secret</span><span>\r</span><span>"</span><span>
</span></span><span><span>00003354	</span><span>"####### MBED HKDF failed: -0x%4.4X ########</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>00003384	</span><span>"Sign failed</span><span>\n</span><span>  ! mbedtls_ecp_group_copy returned 0x%4.4X</span><span>\n</span><span>"</span><span>
</span></span><span><span>000033c0	</span><span>"Sign failed</span><span>\n</span><span>  ! mbedtls_ecp_copy returned 0x%4.4X</span><span>\n</span><span>"</span><span>
</span></span><span><span>000033f4	</span><span>"Sign failed: 0x%4.4X</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>3f403d30	</span><span>"Write ECC conn packet</span><span>\r</span><span>\n</span><span>"</span></span></code></pre></div><p>There is so much useful information that we can extract from these strings. Even without reading the assembly, we can start to assume what it's doing with the data.</p><p>Here's what I noticed:</p><ul><li><p>CRC error code: this is a checksum algorithm that could be part of the packet data.</p></li><li><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/Mbed-TLS/mbedtls"><span>mbedtls</span></a> is an open-source library implementing cryptographic primitives, X509 certificate manipulation, and SSL/TLS and DTLS protocols.</p></li><li><p>ECDH and HKDF primitive functions are used directly from mbedtls. We already know it's not using the DTLS protocol, so we can assume it's using them to implement a custom protocol.</p></li><li><div><p>We can also assume the files mentioned nearby are also related:</p><ul><li><p>Serial number</p></li><li><p>Device key</p></li><li><p>Root certificate</p></li><li><p>Signer certificate</p></li></ul></div></li><li><p>An "ECC conn packet" is sent from the client; this is part of the ECDH key exchange process; we'll also get to that later!</p></li></ul></div><h2><a href="#ghidra-setup" title="Ghidra Setup"><span>Ghidra Setup</span></a></h2><p>Ok, it's about time we configure Ghidra to analyze this ESP32 application better.</p><p>First up, esp32knife supports reformatting the binary partition image for the application into an ELF format, which Ghidra can better understand. I had to make a small tweak for it to support the <code>RTC_DATA</code> segment, which I've pushed to my fork on GitHub: <a target="_blank" rel="noopener noreferrer" href="https://github.com/jmswrnr/esp32knife/commit/6d632b7ca10aaf5c73da4a469a1e62efb2e03a18"><span>feat: add support for RTC_DATA image segment</span></a>. </p><p>We can then import the more useful <code>part.3.factory.elf</code> instead of the <code>part.3.factory</code> binary partition image.</p><p>But when importing this time, we want to do a couple of things before running the auto analysis, so let's opt out of doing that for now.</p><p>Next, we can use the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/leveldown-security/SVD-Loader-Ghidra"><span>SVD-Loader-Ghidra</span></a> script to import the peripheral structs and memory maps from the official <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/espressif/svd/blob/main/svd/esp32.svd"><span>esp32.svd</span></a> file.</p><p>We can also use the built-in <code>SymbolImportScript</code> script to load labels for all ROM functions. I've published a file with all ROM function labels for the ESP32 ready for Ghidra here: <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/jmswrnr/3095b39f8b1f3631489a5db75a275875"><span>ESP32_ROM_LABELS.txt</span></a>. This will help us identify common ROM functions like <code>printf</code>.</p><p>Finally, we run the auto-analysis from the menu bar <code>Analysis &gt; Auto Analyze</code>.</p><p>Let's see what that does to the strings we found earlier:</p><div><div><pre><code><span><span>3f4031c4	</span><span>"Serial Number: %s</span><span>\r</span><span>\n</span><span>"</span><span>
</span></span><span><span>3f4031fc	</span><span>"Device key ready</span><span>\r</span><span>"</span><span>
</span></span><span><span>3f403228	</span><span>"Base64 Public Key: %s</span><span>\r</span><span>\n</span><span>"</span></span></code></pre></div><p>We can now see the same strings are mapped correctly to their virtual memory addresses, meaning the analysis will detect any pointers or instructions that reference them!</p></div><div><p>There are multiple versions of the ESP32, such as <code>ESP32c2</code>, and <code>ESP32s2</code>. The ROM labels and <code>.svd</code> file I've linked are for the default <code>ESP32.</code> if you have a different version, you'll need to import the specific <code>.svd</code> and create specific ROM labels following the README in my gist.</p></div><h2><a href="#firmware-modification" title="Firmware Modification"><span>Firmware Modification</span></a></h2><p>Up until this point, I have the PCB awkwardly positioned to keep the fan and control panel connected. So, I wanted to see if it would still function with them unplugged. Unfortunately, it did not; the serial logged the following:</p><div><pre><code><span><span>I2C read reg fail1
</span></span><span>No Cap device found!
</span><span>REGuru Meditation Error: Core  0 panic'ed (IllegalInstruction). Exception was unhandled.
</span><span>Memory dump at 0x400da020</span></code></pre></div><p>Now we have Ghidra configured nicely, I took a look at the address mentioned in the log; it was assembly right next to a reference for the <code>No Cap device found!</code> string, and at the start of the function, it logs <code>"CapSense Init\r"</code>. This must be for the control panel that uses capacitive sensing input!</p><p>I named this function in Ghidra to <code>InitCapSense</code>:</p><div><pre><code><span><span>void</span><span> </span><span>InitCapSense</span><span>(</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>                       
</span></span><span><span>  </span><span>FUN_401483e0</span><span>(</span><span>"CapSense Init\r"</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>// ... CapSense logic</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>I then followed the references to this function back to another function that appeared to be starting as a task/service; I renamed this one <code>StartCapSenseService:</code></p><div><pre><code><span><span>void</span><span> </span><span>StartCapSenseService</span><span>(</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  _DAT_3ffb2e2c </span><span>=</span><span> </span><span>FUN_40088410</span><span>(</span><span>1</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>3</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>FUN_4008905c</span><span>(</span><span>InitCapSense</span><span>,</span><span> </span><span>&amp;</span><span>DAT_3f40243c</span><span>,</span><span> </span><span>0x800</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>10</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>0x7fffffff</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>return</span><span>;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>Again, I followed the function references and found the function that calls <code>StartCapSenseService</code>. Using Ghidra's Patch Instruction feature, I replaced the <code>call</code> instruction with a <code>nop</code>  (no operation) instruction to remove the function call:</p><div><pre><code><span><span>// Original</span><span>
</span></span><span><span></span><span>400d9a28  </span><span>25 63 af</span><span>    call8</span><span>     FUN_4008905c
</span><span>
</span></span><span><span></span><span>400d9a2b  </span><span>65 31 00</span><span>    call8</span><span>     StartCapSenseService
</span><span>
</span></span><span><span></span><span>400d9a2e  </span><span>e5 37 00</span><span>    call8</span><span>     FUN_400d9dac
</span><span>
</span></span><span>
</span><span><span></span><span>// Patched</span><span>
</span></span><span><span></span><span>400d9a28  </span><span>25 63 af</span><span>    call8</span><span>     FUN_4008905c
</span><span>
</span></span><span><span></span><span>400d9a2b  </span><span>f0 20 00</span><span>    nop
</span><span>
</span></span><span><span></span><span>400d9a2e  </span><span>e5 37 00</span><span>    call8</span><span>     FUN_400d9dac</span></span></code></pre></div><p>We want to flash this change to the ESP32, so I replaced the bytes that were modified, not in this ELF file, but in the <code>part.3.factory</code> binary partition image, because that is in a raw format directly from the flash, so it will be easy to write back. I use a hex editor to find &amp; replace the bytes:</p><p><code>2564af 653100 e53700</code> -&gt; <code>2563af f02000 e53700</code></p><p>Then, I wrote this modified image to the ESP32 flash at the offset <code>0x10000</code>, that is the offset from the partition table for the factory partition:</p><div><pre><code><span><span>esptool </span><span>-</span><span>p </span><span>COM7</span><span> </span><span>-</span><span>b </span><span>115200</span><span> write_flash </span><span>0x10000</span><span> </span><span>.</span><span>/</span><span>patched</span><span>.</span><span>part</span><span>.</span><span>3</span><span>.</span><span>factory</span></span></code></pre></div><p>But when trying to boot this, we get an error from the serial output:</p><div><pre><code><span><span>E </span><span>(</span><span>983</span><span>)</span><span> esp_image</span><span>:</span><span> Checksum failed</span><span>.</span><span> Calculated </span><span>0xc7</span><span> read </span><span>0x43</span><span>
</span></span><span><span>E </span><span>(</span><span>987</span><span>)</span><span> boot</span><span>:</span><span> Factory app partition </span><span>is</span><span> </span><span>not</span><span> bootable</span></span></code></pre></div><p>Alright, so there is a checksum. Luckily, the code inside esptool knows how to calculate this, so I threw together a quick little script to fix the checksums for an application partition image: <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/jmswrnr/esp32knife/commit/1a2c6eadca6cc43b7a3bb33e4d957cbde8d44388"><span>feat: add image checksum repair script</span></a>.</p><p>Now, we can use this to repair the checksums and flash the repaired image:</p><div><pre><code><span><span>python esp32fix</span><span>.</span><span>py </span><span>--</span><span>chip</span><span>=</span><span>esp32 app_image </span><span>.</span><span>/</span><span>patched</span><span>.</span><span>part</span><span>.</span><span>3</span><span>.</span><span>factory
</span></span><span>
</span><span><span>esptool </span><span>-</span><span>p </span><span>COM7</span><span> </span><span>-</span><span>b </span><span>115200</span><span> write_flash </span><span>0x10000</span><span> </span><span>.</span><span>/</span><span>patched</span><span>.</span><span>part</span><span>.</span><span>3</span><span>.</span><span>factory</span><span>.</span><span>fixed</span></span></code></pre></div><p>I tried booting the device without the control panel again; everything now works ok! We have successfully just modified the smart device's firmware!</p><h2><a href="#packet-header" title="Packet Header"><span>Packet Header</span></a></h2><p>Let's get back to focusing on the packets. We know the packets do not follow a well-known protocol, meaning we must figure out the structure ourselves.</p><p>I captured the packets from the device booting numerous times and compared them to each other. I noticed the first thirteen bytes were similar to other packets, while the rest of the packet seemed to be encrypted.</p><p>Here's the first packet received from the server between boots; you can see the data matches up until the offset <code>0x0D</code>:</p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 2F 82 01 23 45 67  89 AB CD EF FF 37 34 9A</span><span>  U./..#Eg.....74.
</span></span><span><span></span><span>00000010</span><span>  7E E6 59 7C 5D 0D AF 71  A0 5F FA 88 13 B0 BE 8D</span><span>  ~.Y|]..q._......
</span></span><span><span></span><span>00000020</span><span>  ED A0 AB FA 47 ED 99 9A  06 B9 80 96 95 C0 96  </span><span>   ....G..........
</span></span><span><span></span><span>
</span></span><span><span></span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  55 00 2F 82 01 23 45 67  89 AB CD EF FF 81 85 3F</span><span>  U./..#Eg.......?
</span></span><span><span></span><span>00000010</span><span>  8A 10 F5 02 A5 F0 BD 28  73 C2 8C 05 71 6E E4 A3</span><span>  .......(s...qn..
</span></span><span><span></span><span>00000020</span><span>  A6 36 FD 5C E0 D5 AC 3E  1A D5 C5 88 99 86 28  </span><span>   .6.\...&gt;......(</span></span></code></pre></div><p>It wasn't too difficult to figure out the first couple of values, then I noticed the remaining nine bytes matched the serial number from the device's serial output, and there we have the packet header format:</p><div><div><pre><code><span><span>55 </span><span>// magic byte to identity the protocol</span><span>
</span></span><span><span></span><span>00 31 </span><span>// length of the packet in bytes</span><span>
</span></span><span><span></span><span>02 </span><span>// message identifier</span><span>
</span></span><span><span></span><span>01 23 45 67 89 AB CD EF FF </span><span>// device serial</span></span></code></pre></div><ul><li><p>A magic byte is commonly used to identify a piece of data in a specific format uniquely.</p></li><li><p>A size-related byte and message ID are very common to expect in a packet like this.</p></li></ul></div><p>The packets first sent and received had a slightly different format to those that followed; there were always the bytes <code>00 01</code> after the header in the client packet, and it was the only packet with the message ID of <code>0x02</code>.</p><p>Comparing it to the other packets, I noticed a pattern with the message ID:</p><ul><li><p><code>0x02</code> - First packet sent from smart device</p></li><li><p><code>0x82</code> - First packet received from cloud server</p></li><li><p><code>0x01</code> - All other packets sent from smart device</p></li><li><p><code>0x81</code> - All other packets received from cloud server</p></li></ul><p>You can see the higher bits in this value represent if it's a client request (<code>0x00</code>) or a server response (<code>0x80</code>). And the lower bits are different between the first exchange (<code>0x02</code>) and all other packets (<code>0x01</code>).</p><h2><a href="#packet-checksum" title="Packet Checksum"><span>Packet Checksum</span></a></h2><p>We noticed a string in the application earlier that said <code>"Message CRC error\r"</code> which implied there is a CRC checksum in the packet. It would be helpful to know if there is a checksum in the data so it doesn't interfere with any decryption attempts. </p><p>I followed the references to this string, and a single function references it. </p><p>Let's take a look at the Decompiled code for that function:</p><div><pre><code><span><span>// ...</span><span>
</span></span><span><span>iVar1 </span><span>=</span><span> </span><span>FUN_4014b384</span><span>(</span><span>0</span><span>,</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>(</span><span>uint</span><span>)</span><span>_DAT_3ffb2e40 </span><span>+</span><span> </span><span>0x3ffb2e42</span><span>)</span><span>;</span><span>
</span></span><span><span>iVar2 </span><span>=</span><span> </span><span>FUN_400ddfc0</span><span>(</span><span>&amp;</span><span>DAT_3ffb2e44</span><span>,</span><span> _DAT_3ffb2e40 </span><span>-</span><span> </span><span>2</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>if</span><span> </span><span>(</span><span>iVar1 </span><span>==</span><span> iVar2</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>if</span><span> </span><span>(</span><span>DAT_3ffb2e47 </span><span>==</span><span> </span><span>'\x01'</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>FUN_400db5c4</span><span>(</span><span>0x3ffb2e48</span><span>,</span><span> _DAT_3ffb2e40 </span><span>-</span><span> </span><span>6</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>DAT_3ffb2e47 </span><span>==</span><span> </span><span>'\x02'</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>FUN_401483e0</span><span>(</span><span>s_Connection_message_3f4030e4</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  pcVar3 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span>  _DAT_3ffb3644 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span><span></span><span>else</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>FUN_401483e0</span><span>(</span><span>s_Message_CRC_error_3f4030d0</span><span>)</span><span>;</span><span>
</span></span><span><span>  pcVar3 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span>  _DAT_3ffb3644 </span><span>=</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>0x0</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span><span></span><span>// ...</span></span></code></pre></div><p>We can see the <code>s_Message_CRC_error</code> label being used in the <code>else</code> block, so the <code>if</code> statement must verify the CRC data for a message.</p><p>This logic compares the results of 2 functions <code>FUN_4014b384</code> and <code>FUN_400ddfc0</code>. If this is verifying the checksum of a packet, one must generate a checksum for the packet data, and the other must read the checksum value from the packet. </p><p>We could use the arguments to help us decide which is which, but let's take a look at both:</p><div><div><pre><code><span><span>uint </span><span>FUN_4014b384</span><span>(</span><span>int param_1</span><span>,</span><span> byte </span><span>*</span><span>param_2</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  uint uVar1</span><span>;</span><span>
</span></span><span>  
</span><span><span>  </span><span>if</span><span> </span><span>(</span><span>param_1 </span><span>==</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> </span><span>(</span><span>uint</span><span>)</span><span>*</span><span>param_2 </span><span>*</span><span> </span><span>0x100</span><span> </span><span>+</span><span> </span><span>(</span><span>uint</span><span>)</span><span>param_2</span><span>[</span><span>1</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>else</span><span> </span><span>{</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> </span><span>(</span><span>uint</span><span>)</span><span>*</span><span>param_2 </span><span>+</span><span> </span><span>(</span><span>uint</span><span>)</span><span>param_2</span><span>[</span><span>1</span><span>]</span><span> </span><span>*</span><span> </span><span>0x100</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>return</span><span> uVar1 </span><span>&amp;</span><span> </span><span>0xffff</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span></span></code></pre></div><p>This doesn't look like a CRC function. It actually looks like a function that reads a 16-bit uint with configurable endianness; here's why:</p><ul><li><p>Multiplying a value by <code>0x100</code> (256) is the equivalent of shifting left by 8 bits (half of a 16-bit value), so <code>0x37</code> becomes <code>0x3700</code>. The logic in the first <code>if</code> code block adds this to the byte at index[1]; this is the next byte after it in memory, so that's basically reading a big-endian uint16 from the <code>param_2</code> pointer</p></li><li><p>The logic of the <code>else</code> code block is similar but shifts the second byte instead of the first, thus reading a little-endian uint16. So, the <code>param_1</code> parameter configures the endianness of the result.</p></li><li><p>The return statement does a bitwise AND (<code>&amp;</code>) operator on the return value with <code>0xFFFF</code>, this restricts the value to 16 bits of data by zeroing out any higher bits.</p></li></ul></div><div><div><pre><code><span><span>uint </span><span>FUN_400ddfc0</span><span>(</span><span>byte </span><span>*</span><span>param_1</span><span>,</span><span> uint param_2</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  uint uVar1</span><span>;</span><span>
</span></span><span><span>  uint uVar2</span><span>;</span><span>
</span></span><span><span>  byte </span><span>*</span><span>pbVar3</span><span>;</span><span>
</span></span><span>  
</span><span><span>  pbVar3 </span><span>=</span><span> param_1 </span><span>+</span><span> </span><span>(</span><span>param_2 </span><span>&amp;</span><span> </span><span>0xffff</span><span>)</span><span>;</span><span>
</span></span><span><span>  uVar1 </span><span>=</span><span> </span><span>0xffff</span><span>;</span><span>
</span></span><span><span>  </span><span>for</span><span> </span><span>(</span><span>;</span><span> pbVar3 </span><span>!=</span><span> param_1</span><span>;</span><span> param_1 </span><span>=</span><span> param_1 </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> </span><span>(</span><span>uint</span><span>)</span><span>*</span><span>param_1 </span><span>&lt;&lt;</span><span> </span><span>8</span><span> </span><span>^</span><span> uVar1</span><span>;</span><span>
</span></span><span><span>    uVar2 </span><span>=</span><span> uVar1 </span><span>&lt;&lt;</span><span> </span><span>1</span><span>;</span><span>
</span></span><span><span>    </span><span>if</span><span> </span><span>(</span><span>(</span><span>short</span><span>)</span><span>uVar1 </span><span>&lt;</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>      uVar2 </span><span>=</span><span> uVar2 </span><span>^</span><span> </span><span>0x1021</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>    uVar1 </span><span>=</span><span> uVar2 </span><span>&amp;</span><span> </span><span>0xffff</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span>  </span><span>return</span><span> uVar1</span><span>;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>Now, this looks a lot more like a checksum function; there's a <code>for</code> loop with a bunch of bitwise operators inside.</p><p>I open up one of the captured packets into <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/WerWolv/ImHex"><span>ImHex</span></a>, a hex editor for reverse engineers. This has a handy feature to show the checksum of the currently selected data. </p><p>Because the other function reads a 16-bit uint, I select CRC-16 and start selecting regions of bytes that would likely be hashed, leaving 2 bytes unselected where I think the 16-bit hash could be.</p><p>No luck so far, but then I noticed you can configure the CRC-16 parameters in ImHex. So, I tried a cheap shortcut and set up ImHex to calculate CRC-16 checksums with a bunch of different parameter combinations using the values found in the decompiled function.</p><p>Success! The last 2 bytes of the packet turned out to be a CRC checksum of all other data in the packet, specifically CRC-16 with <code>0x1021</code> polynomial and <code>0xFFFF</code> initial value. I checked this with other packets, and they all passed the checksum.</p></div><p>Now we know the last 2 bytes of every packet are a CRC-16 checksum and can exclude it from any decryption attempts!</p><h2><a href="#key-exchange" title="Key Exchange"><span>Key Exchange</span></a></h2><p>Earlier, we noticed <code>mbedtls</code> primitives labeled as ECDH and HKDF. So, what exactly are they?</p><p>ECDH (Elliptic Curve Diffie–Hellman Key Exchange) is a key agreement protocol that allows 2 parties (like the smart device and its cloud server), each having an elliptic-curve public–private key pair, to establish a shared secret over an insecure channel (UDP). I found a great explanation of this in more detail in "Practical Cryptography for Developers": <a target="_blank" rel="noopener noreferrer nofollow" href="https://cryptobook.nakov.com/asymmetric-key-ciphers/ecdh-key-exchange"><span>ECDH Key Exchange</span></a>.</p><p>Essentially, if the smart device and server generate an EC key pair and exchange their public keys, they can use the other's public key with their private key to compute a shared secret key. This shared secret key could be used to encrypt and decrypt the packets! And even though they exchange public keys over the insecure network, you still need one of the private keys in order to compute the shared key.</p><p>This is ideal for securing packets like this, and the first packet sent by the client is actually named the <code>ECC conn packet</code> in the logs:</p><div><pre><code><span><span>UDP Connect</span><span>:</span><span> smartdeviceep.---.com
</span></span><span><span>smartdeviceep.---.com = </span><span>192.168</span><span>.</span><span>0.10</span><span>
</span></span><span>UDP Socket created
</span><span>UDP RX Thread Start
</span><span>Write ECC conn packet</span></code></pre></div><p>This is great progress; we know the first packet exchange is likely exchanging EC public keys to establish an ECDH key agreement to encrypt all the other packets.</p><p>If we ignore the packet header (13 bytes from the start) and checksum (2 bytes at the end), we can see the contents of the packets for this potential key exchange are both 32 bytes (256 bits), which would be a valid size for a public key. Even though the client's request has <code>00 01</code> at the start, we can assume this is some unimportant data descriptor as it doesn't change value between boots:</p><div><pre><code><span><span>// Client request packet contents:</span><span>
</span></span><span><span></span><span>
</span></span><span><span></span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span>
</span></span><span><span></span><span>00000000</span><span>  00 01 D1 C2 B3 41 70 17  75 12 F7 69 25 17 50 4A</span><span>  .....Ap.u..i%.PJ
</span></span><span><span></span><span>00000010</span><span>  C5 DD D4 98 06 FE 24 6B  96 FD 56 14 4A 70 7E 51</span><span>  ......$k..V.Jp~Q
</span></span><span><span></span><span>00000020</span><span>  55 57                            </span><span>                UW
</span></span><span><span></span><span>
</span></span><span><span></span><span>// Server response packet contents:</span><span>
</span></span><span><span></span><span>
</span></span><span><span></span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  07 A8 02 73 52 42 1F 1F  C1 41 B4 E4 5B D9 A9 9A</span><span>  ...sRB...A..[...
</span></span><span><span></span><span>00000010</span><span>  5A DD 0F 94 F1 AB 9E E8  86 C7 99 7E 08 68 52 C5</span><span>  Z..........~.hR.</span></span></code></pre></div><p>Ok, so what is the HKDF? That is HMAC-based key derivation. It can be used to convert shared secrets computed from Diffie–Hellman into key material suitable for use in encryption. Wow, that makes a lot of sense; it's most likely doing exactly that to derive a key to encrypt and decrypt the other packets.</p><h2><a href="#cryptography-analysis" title="Cryptography Analysis"><span>Cryptography Analysis</span></a></h2><p>To be able to decrypt these packets, we need to understand exactly how the key for encryption is generated. That includes any possible input data as well as configurable options.</p><p>It's safe to assume the ECDH and HKDF functions are used for the packet data, so focusing on the key generation process, I summarize the variables we need to understand:</p><ul><li><div><p>ECDH:</p><ul><li><p>Public key</p></li><li><p>Private key</p></li></ul></div></li><li><div><p>HKDF</p><ul><li><p>Hashing method</p></li><li><p>Output key size</p></li><li><p>Optional salt</p></li><li><p>Optional info</p></li></ul></div></li></ul><p>The smart device and its cloud server both exchange 256 bits of data during what we assume is the key exchange process. But remember, the smart device firmware also loads the following keys from storage:</p><ul><li><p>256-bit device key pair (private &amp; public)</p></li><li><p>256-bit cloud server <code>"root"</code> public key</p></li><li><p>256-bit cloud server <code>"signer"</code> public key</p></li></ul><p>There are a lot of possibilities here, so I take another look at the application in Ghidra. By following the error strings, I located the function which generates this key! I steadily work my way through labeling functions and variables by comparing the assembly to the mbedtls source code. I was able to annotate and simplify it to the following pseudocode:</p><div><div><pre><code><span><span>int</span><span> </span><span>GenerateNetworkKey</span><span>(</span><span>uchar </span><span>*</span><span>outputKey</span><span>,</span><span> uchar </span><span>*</span><span>outputRandomBytes</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>// Generate an ECDH key pair</span><span>
</span></span><span><span>  char privateKey1 </span><span>[</span><span>12</span><span>]</span><span>;</span><span>
</span></span><span><span>  char publicKey1 </span><span>[</span><span>36</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_ecdh_gen_public</span><span>(</span><span>
</span></span><span><span>    ecpGroup</span><span>,</span><span> 
</span></span><span><span>    privateKey1</span><span>,</span><span> 
</span></span><span><span>    publicKey1</span><span>,</span><span> 
</span></span><span><span>    </span><span>(</span><span>char </span><span>*</span><span>)</span><span>mbedtls_ctr_drbg_random</span><span>,</span><span> 
</span></span><span>    drbgContext
</span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Overwrite generated private key?</span><span>
</span></span><span><span>  </span><span>mbedtls_mpi_read_binary</span><span>(</span><span>privateKey1</span><span>,</span><span> </span><span>(</span><span>uchar </span><span>*</span><span>)</span><span>(</span><span>_DAT_3ffb3948 </span><span>+</span><span> </span><span>0x7c</span><span>)</span><span>,</span><span> </span><span>1</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Overwrite generated public key?</span><span>
</span></span><span><span>  </span><span>mbedtls_ecp_copy</span><span>(</span><span>publicKey1</span><span>,</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>(</span><span>_DAT_3ffb3948 </span><span>+</span><span> </span><span>0x88</span><span>)</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Load another public key?</span><span>
</span></span><span><span>  char publicKey2 </span><span>[</span><span>36</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_ecp_copy</span><span>(</span><span>publicKey2</span><span>,</span><span> </span><span>(</span><span>char </span><span>*</span><span>)</span><span>(</span><span>_DAT_3ffb38cc </span><span>+</span><span> </span><span>0x88</span><span>)</span><span>)</span><span>;</span><span>
</span></span><span>  
</span><span><span>  </span><span>// Compute shared secret key using privateKey1 and publicKey 2</span><span>
</span></span><span><span>  char computedSharedSecret </span><span>[</span><span>100</span><span>]</span><span>;</span><span>
</span></span><span><span>  uchar binarySharedSecret </span><span>[</span><span>35</span><span>]</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_ecdh_compute_shared</span><span>(</span><span>
</span></span><span><span>    ecpGroup</span><span>,</span><span>
</span></span><span><span>    computedSharedSecret</span><span>,</span><span>
</span></span><span><span>    publicKey2</span><span>,</span><span>
</span></span><span><span>    privateKey1</span><span>,</span><span>
</span></span><span><span>    </span><span>(</span><span>char </span><span>*</span><span>)</span><span>mbedtls_ctr_drbg_random</span><span>,</span><span>
</span></span><span>    drbgContext
</span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_mpi_write_binary</span><span>(</span><span>computedSharedSecret</span><span>,</span><span> binarySharedSecret</span><span>,</span><span> </span><span>0x20</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Generate random bytes</span><span>
</span></span><span><span>  </span><span>mbedtls_ctr_drbg_random</span><span>(</span><span>globalDrbgContext</span><span>,</span><span> outputRandomBytes</span><span>,</span><span> </span><span>0x20</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>// Derive key</span><span>
</span></span><span><span>  mbedtls_md_info_t </span><span>*</span><span>md </span><span>=</span><span> </span><span>mbedtls_md_info_from_type</span><span>(</span><span>MBEDTLS_MD_SHA256</span><span>)</span><span>;</span><span>
</span></span><span><span>  uchar</span><span>*</span><span> deviceSerialNumber </span><span>=</span><span> </span><span>(</span><span>uchar </span><span>*</span><span>)</span><span>GetDeviceSerialNumber</span><span>(</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>mbedtls_hkdf</span><span>(</span><span>
</span></span><span><span>    md</span><span>,</span><span> 
</span></span><span><span>    binarySharedSecret</span><span>,</span><span> </span><span>// salt</span><span>
</span></span><span><span>    </span><span>0x20</span><span>,</span><span>
</span></span><span><span>    outputRandomBytes</span><span>,</span><span> </span><span>// input</span><span>
</span></span><span><span>    </span><span>0x20</span><span>,</span><span>
</span></span><span><span>    deviceSerialNumber</span><span>,</span><span> </span><span>// info</span><span>
</span></span><span><span>    </span><span>9</span><span>,</span><span>
</span></span><span><span>    outputKey</span><span>,</span><span>
</span></span><span><span>    </span><span>0x10</span><span>
</span></span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>Being able to interpret assembly or even the decompiled code in Ghidra is certainly an acquired skill; I'd like to emphasize this took a while to figure out, with many breaks in between!</p><p>This function does something unusual; here's what we can learn from it:</p><ul><li><p>The generated ECDH key pair is discarded and replaced by keys loaded from somewhere else in memory, which is strange. Because the ECDH key pair generation function isn't used elsewhere in the application, it's likely these keys are the files from the firmware storage we saw earlier.</p></li><li><p>The algorithm used for the HKDF is <code>SHA-256</code>.</p></li><li><p>The computed shared secret is used as the HKDF <code>salt</code>.</p></li><li><p>Random bytes are generated as the HKDF <code>input</code>. </p></li><li><p>The device serial number is used as the HKDF <code>info</code>. </p></li><li><p>The HKDF output key size is <code>0x10</code> (16 bytes / 128 bits).</p></li></ul></div><p>We now have a much better understanding of how the smart device generates the potential encryption key. </p><p>It's useful to keep in mind that their cloud server also has to generate this key, meaning it needs to have all the same input variables to the HKDF. </p><p>Knowing this, we can recap the three dynamic inputs to the HKDF function and understand how the server will also have them:</p><ul><li><p><code>salt</code> - Shared secret:  The server must have access to the same private and public keys used for the ECDH shared secret computation or use the public to our private and the private to our public.</p></li><li><p><code>input</code> - Random bytes: The server must have access to these randomly generated bytes on the smart device; either we send these bytes to the server, or technically, the server could recreate the pseudo RNG method used. However, the generated bytes have the size of <code>0x20</code> (32 bytes / 256 bits) which exactly matches the size of the data sent in the key exchange packet, so it's highly likely we're sending it there!</p></li><li><p><code>info</code> - <strong>Device serial number:</strong> We already know the device serial number is part of the packet header, so the server easily has access to this value. </p></li></ul><p>Curious to know what the application did with these randomly generated bytes, I checked what the calling function did with them:</p><div><div><pre><code><span><span>stack</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>0x00</span><span>;</span><span>
</span></span><span><span>stack</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>0x01</span><span>;</span><span>
</span></span><span><span></span><span>GenerateNetworkKey</span><span>(</span><span>&amp;</span><span>KeyOutput</span><span>,</span><span> stack</span><span>[</span><span>2</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>log</span><span>(</span><span>2</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>"Write ECC conn packet\r\n"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>SendPacket</span><span>(</span><span>(</span><span>int</span><span>)</span><span>param_1</span><span>,</span><span> </span><span>2</span><span>,</span><span> stack</span><span>[</span><span>0</span><span>]</span><span>,</span><span> </span><span>0x22</span><span>)</span><span>;</span></span></code></pre></div><p>We can see the random bytes from <code>GenerateNetworkKey</code> are written out to the stack, and better yet, the <code>00 01</code> bytes are written to the stack just before it, and then all <code>0x22</code> bytes are sent in the packet. That exactly matches the format we saw in the key exchange packet!  </p></div><h2><a href="#logging-key-data" title="Logging Key Data"><span>Logging Key Data</span></a></h2><p>Much progress has been made via static analysis, and the final value we need to calculate the decryption key is the shared secret.</p><p>At this point of reverse engineering, I hadn't reversed the functions as cleanly as shown in this blog post and wanted to try to dynamically obtain keys directly from the device.</p><p>Debugging via JTAG would be the sensible choice here. However, I didn't notice breakout points for these pins on the PCB, and I wanted to avoid soldering directly to the ESP32 pins, so I thought I'd challenge myself to patch the firmware to print it over serial!</p><p>The CapSense service is still disabled, so I thought I'd write a function over that logic to print out the shared secret key and call it right after it was computed!</p><p>So, planning in pseudocode, I'd want to add my function call to the <code>GenerateNetworkKey</code> function. Right after it has generated the key.:</p><div><pre><code><span><span>int</span><span> </span><span>GenerateNetworkKey</span><span>(</span><span>uchar </span><span>*</span><span>outputKey</span><span>,</span><span> uchar </span><span>*</span><span>outputRandomBytes</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>// ... </span><span>
</span></span><span>  
</span><span><span>  </span><span>// Add my function call:</span><span>
</span></span><span><span>  </span><span>print_key</span><span>(</span><span>binarySharedSecret</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Custom function saved over unused logic:</span><span>
</span></span><span><span></span><span>void</span><span> </span><span>print_key</span><span>(</span><span>char </span><span>*</span><span>key</span><span>)</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>for</span><span> </span><span>(</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> </span><span>32</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>log</span><span>(</span><span>"%2.2x"</span><span>,</span><span> key</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>While referring to the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/eerimoq/hardware-reference/blob/master/esp32/xtensa%20Instruction%20Set%20Architecture%20(ISA)%20Reference%20Manual.pdf"><span>Xtensa instruction set architecture manual</span></a>, I threw together some assembly like this:</p><div><div><pre><code><span><span>// Original</span><span>
</span></span><span><span></span><span>400dbf2d  </span><span>25 4b 6c</span><span>    call8</span><span>     GetDeviceSerialNumber</span><span>
</span></span><span>
</span><span><span></span><span>// Patched</span><span>
</span></span><span><span></span><span>400dbf2d  </span><span>e5 ff fd</span><span>    call8</span><span>     print_key</span><span>
</span></span><span>
</span><span><span></span><span>// print_key:</span><span>
</span></span><span><span></span><span>400d9f2c  </span><span>36 41 00</span><span>    entry</span><span>     </span><span>a1</span><span>,</span><span> 0x20</span><span>
</span></span><span><span></span><span>400d9f3b  </span><span>42 c2 20</span><span>    addi</span><span>      </span><span>a4</span><span>,</span><span> </span><span>a2</span><span>,</span><span> 0x20</span><span>
</span></span><span><span></span><span>400d9f3e  </span><span>52 a0 02</span><span>    movi</span><span>      </span><span>a5</span><span>,</span><span> 0x2</span><span>
</span></span><span><span></span><span>400d9f41  </span><span>61 ea db</span><span>    l32r</span><span>      </span><span>a6</span><span>,</span><span> PTR_s_%2.2x </span><span>// "%2.2x"</span><span>
</span></span><span><span></span><span>400d9f44  </span><span>d2 02 00</span><span>    l8ui</span><span>      </span><span>a13</span><span>,</span><span> </span><span>a2</span><span>,</span><span> 0x0</span><span>
</span></span><span><span></span><span>400d9f47  </span><span>60 c6 20</span><span>    mov</span><span>       </span><span>a12</span><span>,</span><span> </span><span>a6</span><span>
</span></span><span><span></span><span>400d9f4a  </span><span>50 b5 20</span><span>    mov</span><span>       </span><span>a11</span><span>,</span><span> </span><span>a5</span><span>
</span></span><span><span></span><span>400d9f4d  </span><span>50 a5 20</span><span>    mov</span><span>       </span><span>a10</span><span>,</span><span> </span><span>a5</span><span>
</span></span><span><span></span><span>400d9f50  </span><span>22 c2 01</span><span>    addi</span><span>      </span><span>a2</span><span>,</span><span> </span><span>a2</span><span>,</span><span> 0x1</span><span>
</span></span><span><span></span><span>400d9f53  </span><span>25 ed 05</span><span>    call8</span><span>     log</span><span>
</span></span><span><span></span><span>400d9f56  </span><span>27 94 ea</span><span>    bne</span><span>       </span><span>a4</span><span>,</span><span> </span><span>a2</span><span>,</span><span> LAB_400d9f44</span><span>
</span></span><span><span></span><span>400d9f59  </span><span>22 a0 00</span><span>    movi</span><span>      </span><span>a2</span><span>,</span><span> 0x0</span><span>
</span></span><span><span></span><span>400d9f5c  </span><span>90 00 00</span><span>    retw</span><span>
</span></span><span></span></code></pre></div><p>We patch over the <code>GetDeviceSerialNumber</code> function call because this is directly after the generation of the shared secret key, and the pointer to the key is still in the register <code>a2</code>.</p></div><p>I flashed the modified firmware, booted up the device, and checked the serial output:</p><div><pre><code><span><span>Write ECC conn packet
</span></span><span>e883eaed93c63d2c09cddebce6bb15a7f4cb5cedf00c1d882b8b292796254c9c</span></code></pre></div><p>Success! We've printed out the shared secret key! </p><p>I rebooted the device numerous times to see if the key changed, and it remained the same. It is most likely computed using the keys in the firmware storage, but now we have the computed static value, we don't need to reverse the computation process.</p><h2><a href="#packet-decryption" title="Packet Decryption"><span>Packet Decryption</span></a></h2><p>Alright, we now understand the method to derive the decryption key and have all input values; it looks something like this: </p><div><pre><code><span><span>const</span><span> hkdfOutputKey </span><span>=</span><span> </span><span>hkdf</span><span>(</span><span>{</span><span>
</span></span><span><span>  </span><span>method</span><span>:</span><span> </span><span>'SHA-256'</span><span>,</span><span>
</span></span><span><span>  </span><span>salt</span><span>:</span><span> Buffer</span><span>.</span><span>from</span><span>(</span><span>
</span></span><span><span>    </span><span>'e883eaed93c63d2c09cddebce6bb15a7f4cb5cedf00c1d882b8b292796254c9c'</span><span>,</span><span> </span><span>'hex'</span><span>
</span></span><span><span>  </span><span>)</span><span>,</span><span>
</span></span><span><span>  </span><span>input</span><span>:</span><span> randomBytesFromDeviceKeyExchangePacket</span><span>,</span><span>
</span></span><span><span>  </span><span>info</span><span>:</span><span> deviceSerialNumber</span><span>,</span><span>
</span></span><span><span>  </span><span>outputKeySize</span><span>:</span><span> </span><span>0x10</span><span>,</span><span>
</span></span><span><span></span><span>}</span><span>)</span><span>;</span></span></code></pre></div><p>To be on the safe side, I wrote another firmware patch to print the key output from the HKDF call and tried recreating the key from captured packets. It works! That confirms we have correctly reverse-engineered the key creation function and are able to replicate the key creation logic in our own application.</p><p>But now we need to find which encryption algorithm is used. I refer back to the function which formats packets and found the call to the encryption function:</p><div><div><pre><code><span><span>char randomBytes </span><span>[</span><span>16</span><span>]</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Write device serial</span><span>
</span></span><span><span></span><span>memcpy</span><span>(</span><span>0x3ffb3ce0</span><span>,</span><span> deviceSerialNumber</span><span>,</span><span> </span><span>9</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Generate and write random bytes</span><span>
</span></span><span><span></span><span>mbedtls_ctr_drbg_random</span><span>(</span><span>globalDrbgContext</span><span>,</span><span> randomBytes</span><span>,</span><span> </span><span>0x10</span><span>)</span><span>
</span></span><span><span></span><span>memcpy</span><span>(</span><span>0x3ffb3ce9</span><span>,</span><span> randomBytes</span><span>,</span><span> </span><span>0x10</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Write packet data</span><span>
</span></span><span><span></span><span>memcpy</span><span>(</span><span>0x3ffb3cf9</span><span>,</span><span> data</span><span>,</span><span> dataSize</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Pad with random bytes</span><span>
</span></span><span><span></span><span>mbedtls_ctr_drbg_random</span><span>(</span><span>globalDrbgContext dataSize </span><span>+</span><span> </span><span>0x3ffb3cf9</span><span>,</span><span> paddingSize</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Run encryption on the data + padding</span><span>
</span></span><span><span></span><span>FUN_400e2368</span><span>(</span><span>0x3ffb3cf9</span><span>,</span><span> dataSize </span><span>+</span><span> paddingSize</span><span>,</span><span> </span><span>&amp;</span><span>HKDFOutputKey</span><span>,</span><span> randomBytes</span><span>)</span><span>;</span></span></code></pre></div><p>I noticed that after the device serial number is copied to the packet, 16 random bytes are generated and copied directly after it. These bytes are also provided to the encryption function. So, we know they are an input variable to the encryption algorithm.</p></div><p>We know the key is 128 bits, with another 128 bits of additional random data.</p><p>I looked into the encryption function, which is very clearly crypto-related due to the looping of a bunch of bitwise operations, and noticed a reference to a static block of data.</p><p>This data started with <code>63 7C 77 7B F2 6B 6F C5</code>, a search in the mbedtls source code revealed it is the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/Mbed-TLS/mbedtls/blob/47c74a477378ec3f0d1ba80547db836e078fa3a0/library/aes.c#L78"><span>AES Forward S-Box</span></a>!</p><p>I decided to jump straight into attempting AES decryption on the captured packets and <strong>successfully decrypted a packet!! 🎉</strong></p><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  00 00 65 00 53 00 82 A4  74 79 70 65 AF 6D 69 72</span><span>  ..e.S...type.mir
</span></span><span><span></span><span>00000010</span><span>  72 6F 72 5F 64 61 74 61  5F 67 65 74 A4 64 61 74</span><span>  ror_data_get.dat
</span></span><span><span></span><span>00000020</span><span>  61 85 A9 74 69 6D 65 73  74 61 6D 70 CF 00 00 01</span><span>  a..timestamp....
</span></span><span><span></span><span>00000030</span><span>  8D 18 05 31 FB A9 46 41  4E 5F 53 50 45 45 44 00</span><span>  ...1..FAN_SPEED.
</span></span><span><span></span><span>00000040</span><span>  A5 42 4F 4F 53 54 C2 A7  46 49 4C 54 45 52 31 00</span><span>  .BOOST..FILTER1.
</span></span><span><span></span><span>00000050</span><span>  A7 46 49 4C 54 45 52 32  00 07 07 07 07 07 07 07</span><span>  .FILTER2........</span></span></code></pre></div><p>The algorithm was <code>AES-128-CBC</code> and the additional random data was used as the <code>IV</code> (Initialization vector).</p><h2><a href="#mitm-attack" title="MITM Attack"><span>MITM Attack</span></a></h2><p>We can now create an MITM (man in the middle) attack that does not require any firmware patching. This is because the private key of the device is now known, the key derivation logic has been reverse-engineered, and any required dynamic data is exposed over the insecure network.</p><p>If it correctly implemented ECDH, the smart device would have a unique private key that isn't exposed, and our easiest route of attack would be to generate our own server key pair and do any firmware modifications so the device accepts our custom public key.</p><p>But because of their custom protocol's design, we can write an MITM script that can intercept, decrypt, and potentially modify network communications without any modifications to the smart device. So, that's what we're going to do!</p><p>The main aim now is to decrypt and log as much data as possible; then, we can reference that to write a local server endpoint that entirely replaces their cloud server.</p><p>I hack together a quick Node.js script to do this:</p><div><div><pre><code><span><span>const</span><span> dns </span><span>=</span><span> </span><span>require</span><span>(</span><span>"dns"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> udp </span><span>=</span><span> </span><span>require</span><span>(</span><span>"dgram"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> crypto </span><span>=</span><span> </span><span>require</span><span>(</span><span>"crypto"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> hkdf </span><span>=</span><span> </span><span>require</span><span>(</span><span>"futoin-hkdf"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> fs </span><span>=</span><span> </span><span>require</span><span>(</span><span>"fs"</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// Key Gen</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> sharedSecretKey </span><span>=</span><span> Buffer</span><span>.</span><span>from</span><span>(</span><span>
</span></span><span><span>  </span><span>"e883eaed93c63d2c09cddebce6bb15a7f4cb5cedf00c1d882b8b292796254c9c"</span><span>,</span><span>
</span></span><span><span>  </span><span>"hex"</span><span>
</span></span><span><span></span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>calculateAesKey</span><span>(</span><span>deviceSerialNumber</span><span>,</span><span> inputData</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>return</span><span> </span><span>hkdf</span><span>(</span><span>inputData</span><span>,</span><span> </span><span>16</span><span>,</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>salt</span><span>:</span><span> sharedSecretKey</span><span>,</span><span>
</span></span><span><span>    </span><span>info</span><span>:</span><span> deviceSerialNumber</span><span>,</span><span>
</span></span><span><span>    </span><span>hash</span><span>:</span><span> </span><span>"SHA-256"</span><span>,</span><span>
</span></span><span><span>  </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Packet Parsing</span><span>
</span></span><span>
</span><span><span></span><span>let</span><span> latestAesKey </span><span>=</span><span> </span><span>null</span><span>;</span><span>
</span></span><span><span></span><span>let</span><span> packetCounter </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> proxyLogDir </span><span>=</span><span> path</span><span>.</span><span>join</span><span>(</span><span>__dirname</span><span>,</span><span> </span><span>"decrypted-packets"</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>decryptPacket</span><span>(</span><span>data</span><span>,</span><span> deviceSerial</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>const</span><span> </span><span>IV</span><span> </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>0xd</span><span>,</span><span> </span><span>0x1d</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>const</span><span> encryptedBuffer </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>0x1d</span><span>,</span><span> data</span><span>.</span><span>length </span><span>-</span><span> </span><span>2</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>const</span><span> decipher </span><span>=</span><span> crypto</span><span>.</span><span>createDecipheriv</span><span>(</span><span>
</span></span><span><span>    </span><span>"aes-128-cbc"</span><span>,</span><span>
</span></span><span><span>    latestAesKey</span><span>,</span><span>
</span></span><span><span>    parsed</span><span>.</span><span>IV</span><span>
</span></span><span><span>  </span><span>)</span><span>;</span><span>
</span></span><span><span>  decipher</span><span>.</span><span>setAutoPadding</span><span>(</span><span>false</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>return</span><span> Buffer</span><span>.</span><span>concat</span><span>(</span><span>[</span><span>decipher</span><span>.</span><span>update</span><span>(</span><span>encryptedBuffer</span><span>)</span><span>,</span><span> decipher</span><span>.</span><span>final</span><span>(</span><span>)</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>logPacket</span><span>(</span><span>data</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>const</span><span> messageId </span><span>=</span><span> data</span><span>.</span><span>readUInt8</span><span>(</span><span>3</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>const</span><span> deviceSerial </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>4</span><span>,</span><span> </span><span>4</span><span> </span><span>+</span><span> </span><span>9</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>  </span><span>if</span><span> </span><span>(</span><span>messageId </span><span>===</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>// Key Exchange</span><span>
</span></span><span><span>    </span><span>const</span><span> randomlyGeneratedBytes </span><span>=</span><span> data</span><span>.</span><span>subarray</span><span>(</span><span>0xf</span><span>,</span><span> data</span><span>.</span><span>length </span><span>-</span><span> </span><span>2</span><span>)</span><span>;</span><span>
</span></span><span><span>    latestAesKey </span><span>=</span><span> </span><span>calculateAesKey</span><span>(</span><span>deviceSerial</span><span>,</span><span> randomlyGeneratedBytes</span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>// Encrypted Packets</span><span>
</span></span><span><span>    fs</span><span>.</span><span>writeFileSync</span><span>(</span><span>
</span></span><span><span>      path</span><span>.</span><span>join</span><span>(</span><span>proxyLogDir</span><span>,</span><span> </span><span>`</span><span>packet-</span><span>${</span><span>id</span><span>}</span><span>.bin</span><span>`</span><span>)</span><span>,</span><span>
</span></span><span><span>      </span><span>decryptPacket</span><span>(</span><span>data</span><span>)</span><span>
</span></span><span><span>    </span><span>)</span><span>;</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Networking</span><span>
</span></span><span>
</span><span><span>dns</span><span>.</span><span>setServers</span><span>(</span><span>[</span><span>"1.1.1.1"</span><span>,</span><span> </span><span>"[2606:4700:4700::1111]"</span><span>]</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> </span><span>PORT</span><span> </span><span>=</span><span> </span><span>41014</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> cloudIp </span><span>=</span><span> dns</span><span>.</span><span>resolve4</span><span>(</span><span>"smartdeviceep.---.com"</span><span>)</span><span>[</span><span>0</span><span>]</span><span>;</span><span>
</span></span><span><span></span><span>const</span><span> cloud </span><span>=</span><span> udp</span><span>.</span><span>createSocket</span><span>(</span><span>"udp4"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>let</span><span> latestClientIp </span><span>=</span><span> </span><span>null</span><span>;</span><span>
</span></span><span><span></span><span>let</span><span> latestClientPort </span><span>=</span><span> </span><span>null</span><span>;</span><span>
</span></span><span>
</span><span><span>cloud</span><span>.</span><span>on</span><span>(</span><span>"message"</span><span>,</span><span> </span><span>function</span><span> </span><span>(</span><span>data</span><span>,</span><span> info</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>logPacket</span><span>(</span><span>data</span><span>)</span><span>;</span><span>
</span></span><span><span>  local</span><span>.</span><span>send</span><span>(</span><span>data</span><span>,</span><span> latestClientIp</span><span>,</span><span> latestClientPort</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> local </span><span>=</span><span> udp</span><span>.</span><span>createSocket</span><span>(</span><span>"udp4"</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>local</span><span>.</span><span>bind</span><span>(</span><span>PORT</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span>local</span><span>.</span><span>on</span><span>(</span><span>"message"</span><span>,</span><span> </span><span>function</span><span> </span><span>(</span><span>data</span><span>,</span><span> info</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>logPacket</span><span>(</span><span>data</span><span>)</span><span>;</span><span>
</span></span><span><span>  latestClientIp </span><span>=</span><span> info</span><span>.</span><span>address</span><span>;</span><span>
</span></span><span><span>  latestClientPort </span><span>=</span><span> info</span><span>.</span><span>port</span><span>;</span><span>
</span></span><span><span>  cloud</span><span>.</span><span>send</span><span>(</span><span>data</span><span>,</span><span> </span><span>PORT</span><span>,</span><span> cloudIp</span><span>)</span><span>;</span><span>
</span></span><span><span></span><span>}</span><span>)</span><span>;</span><span>
</span></span><span></span></code></pre></div><p>Here, we combine all of our research to implement an MITM attack.</p><p>Just like when we first captured packets, we configure Node.js to use Cloudflare's DNS resolver to bypass our local DNS server.</p><p>We create a UDP socket locally to accept packets from the smart device and also a socket to communicate with the cloud server.</p><ul><li><p>Anything we receive from the smart device, we log and send to the cloud server</p></li><li><p>Anything we receive from the cloud server, we log and send to the smart device</p></li></ul><p>We treat packets with the <code>messageId</code> of 2 to be the key exchange packet where the smart device send the random bytes to the server, we then calculate the AES key used to decrypt future packets.</p></div><p>While capturing, I used their mobile app to remotely control the smart device so we could reference the logs and replicate the logic ourselves.</p><h2><a href="#data-exchange-format" title="Data Exchange Format"><span>Data Exchange Format</span></a></h2><p>We now have the decrypted packet data, but the data is still in a serialized binary format:</p><div><div><pre><code><span><span>Hex View</span><span>  00 01 02 03 04 05 06 07  08 09 0A 0B 0C 0D 0E 0F
</span></span><span><span></span><span> </span><span>
</span></span><span><span></span><span>00000000</span><span>  01 00 64 00 29 00 82 A4  74 79 70 65 A7 63 6F 6E</span><span>  ..d.)...type.con
</span></span><span><span></span><span>00000010</span><span>  6E 65 63 74 A8 66 69 72  6D 77 61 72 65 C4 10 00</span><span>  nect.firmware...
</span></span><span><span></span><span>00000020</span><span>  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 83</span><span>  ................</span></span></code></pre></div><p>My mind was deep in the world of reverse engineering, and I managed to reverse the structure for all packets and hack together some JavaScript to convert the data to and from JSON.</p><p>The header was quite simple, again just some IDs and length, but in little endianness:</p><ul><li><p><code>01 00</code> - packet ID</p></li><li><p><code>64 00</code> - transaction ID</p></li><li><p><code>29 00</code> - serialized data length</p></li></ul><p>And with some tinkering, I figured out the serialized format:</p><ul><li><p><code>82</code> - Map</p></li><li><p><code>A4</code> - String of 4 length</p></li><li><p><code>A7</code> - String of 7 length</p></li></ul><p>This was fun to reverse because the typing was more described in bits, but it's clearly readable from the bytes for these simple cases.</p></div><p>Looking back on this, I'm not sure why I didn't look for an existing solution that matches this serialized binary data format; I was expecting everything to be a custom solution at this point. But having a search now, this is just <a target="_blank" rel="noopener noreferrer nofollow" href="https://msgpack.org/"><span>MessagePack</span></a>, so I guess I just reverse-engineered and wrote a partial msgpack implementation 😆</p><p>Switching over to a popular implementation, we can see the data is easily unpacked into JSON:</p><div><pre><code><span><span>const</span><span> </span><span>{</span><span> unpack</span><span>,</span><span> pack </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'msgpackr'</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> packedData </span><span>=</span><span> Buffer</span><span>.</span><span>from</span><span>(</span><span>
</span></span><span><span>  </span><span>'82A474797065A7636F6E6E656374A86669726D77617265C41000000000000000000000000000000000'</span><span>,</span><span> 
</span></span><span><span>  </span><span>'hex'</span><span>
</span></span><span><span></span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>const</span><span> unpackedData </span><span>=</span><span> </span><span>unpack</span><span>(</span><span>packedData</span><span>)</span><span>;</span><span>
</span></span><span>
</span><span><span></span><span>// unpackedData:</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'connect'</span><span>,</span><span>
</span></span><span><span>  </span><span>firmware</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><h2><a href="#network-log-analysis" title="Network Log Analysis"><span>Network Log Analysis</span></a></h2><p>In preparation for writing a custom local server for the smart device, let's take a look at the unpacked network logs we've captured:</p><p><strong>🔑 Key Exchange Packet:</strong></p><p>The smart device sends random bytes to the server to be used in the HKDF.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>D1C2B34170177512F7692517504AC5DDD49806FE246B96FD56144A707E515557</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>00000000000000000000000000000000</span></span></code></pre></div><p>↙️ <strong>Get Device State:</strong></p><p>The smart device fetches its initial state from the server when it boots.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>'mirror_data_get'</span><span> </span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'mirror_data_get'</span><span>,</span><span>
</span></span><span><span>  </span><span>data</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>timestamp</span><span>:</span><span> </span><span>1705505010171n</span><span>,</span><span>
</span></span><span><span>    </span><span>FAN_SPEED</span><span>:</span><span> </span><span>0</span><span>,</span><span>
</span></span><span><span>    </span><span>BOOST</span><span>:</span><span> </span><span>false</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER1</span><span>:</span><span> </span><span>0</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER2</span><span>:</span><span> </span><span>0</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>🔗 <strong>On Connect:</strong></p><p>When the smart device connects to the server, it sends its current firmware UUID. The server responds with the potential UUID for a firmware or config update that could be downloaded.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'connect'</span><span>,</span><span>
</span></span><span><span>  </span><span>firmware</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'connect'</span><span>,</span><span>
</span></span><span><span>  </span><span>server_time</span><span>:</span><span> </span><span>1706098993961n</span><span>,</span><span>
</span></span><span><span>  </span><span>firmware</span><span>:</span><span> </span><span>&lt;</span><span>Buffer ab cd ef ab cd ef ab cd ef ab cd ef ab cd ef ab</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>config</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>calibration</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>conditioning</span><span>:</span><span> </span><span>&lt;</span><span>Buffer </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span> </span><span>00</span><span>&gt;</span><span>,</span><span>
</span></span><span><span>  </span><span>server_address</span><span>:</span><span> </span><span>'smartdeviceep.---.com'</span><span>,</span><span>
</span></span><span><span>  </span><span>server_port</span><span>:</span><span> </span><span>41014</span><span>,</span><span>
</span></span><span><span>  </span><span>rtc_sync</span><span>:</span><span> </span><span>{</span><span> </span><span>ss</span><span>:</span><span> </span><span>13</span><span>,</span><span> </span><span>mm</span><span>:</span><span> </span><span>23</span><span>,</span><span> </span><span>hh</span><span>:</span><span> </span><span>12</span><span>,</span><span> </span><span>DD</span><span>:</span><span> </span><span>24</span><span>,</span><span> </span><span>MM</span><span>:</span><span> </span><span>1</span><span>,</span><span> </span><span>YYYY</span><span>:</span><span> </span><span>2024</span><span>,</span><span> </span><span>D</span><span>:</span><span> </span><span>3</span><span> </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>⤵️ <strong>Server Updates Smart Device State:</strong></p><p>When the server wants to update the smart device's state, it will send a packet like this.</p><div><pre><code><span><span>// Server Request</span><span>
</span></span><span><span></span><span>{</span><span> 
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'mirror_data'</span><span>,</span><span>
</span></span><span><span>  </span><span>data</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>FAN_SPEED</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>BOOST</span><span>:</span><span> </span><span>false</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>⤴️ <strong>Smart Device Updates Server State:</strong></p><p>The smart device sends its latest state to the server whenever it changes.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'mirror_data'</span><span>,</span><span>
</span></span><span><span>  </span><span>data</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>timestamp</span><span>:</span><span> </span><span>1706105072142n</span><span>,</span><span>
</span></span><span><span>    </span><span>FAN_SPEED</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>BOOST</span><span>:</span><span> </span><span>false</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER1</span><span>:</span><span> </span><span>0</span><span>,</span><span>
</span></span><span><span>    </span><span>FILTER2</span><span>:</span><span> </span><span>0</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>'mirror_data'</span><span> </span><span>}</span></span></code></pre></div><p>🛜 <strong>Keep Alive:</strong></p><p>The smart device frequently sends a keep-alive packet to the server so the server can potentially use the open connection to send state updates.</p><div><pre><code><span><span>// Smart Device Request</span><span>
</span></span><span><span></span><span>{</span><span>
</span></span><span><span>  </span><span>type</span><span>:</span><span> </span><span>'keep_alive'</span><span>,</span><span>
</span></span><span><span>  </span><span>stats</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>rssi</span><span>:</span><span> </span><span>-</span><span>127n</span><span>,</span><span>
</span></span><span><span>    </span><span>rtt</span><span>:</span><span> </span><span>684</span><span>,</span><span>
</span></span><span><span>    </span><span>pkt_drop</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>con_count</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span></span><span><span>    </span><span>boot_str</span><span>:</span><span> </span><span>''</span><span>,</span><span>
</span></span><span><span>    </span><span>uptime</span><span>:</span><span> </span><span>100080</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>// Server Response</span><span>
</span></span><span><span></span><span>{</span><span> </span><span>type</span><span>:</span><span> </span><span>'keep_alive'</span><span> </span><span>}</span></span></code></pre></div><h2><a href="#mqtt-bridge" title="MQTT Bridge"><span>MQTT Bridge</span></a></h2><p>We're going to need a way to connect Home Assistant to our custom server, which handles the smart device networking. <a target="_blank" rel="noopener noreferrer nofollow" href="https://mqtt.org/"><span>MQTT</span></a> is ideal for this; it's a protocol designed for IoT messaging and can be easily configured within Home Assistant. For this, I set up the <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/eclipse/mosquitto"><span>Mosquitto</span></a> addon for Home Assistant, an open-source MQTT broker that connects everything together.</p><p>The connection chain will look like this:</p><p><code>Home Assistant</code> &lt;--&gt; <code>MQTT Broker</code> &lt;--&gt; <code>Custom Server</code> &lt;--&gt; <code>Smart Device</code>.</p><p>The custom server logic in pseudocode would look something like this:</p><div><div><pre><code><span><span>function</span><span> </span><span>HandleSmartDeviceRequest</span><span>(</span><span>req</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>switch</span><span> </span><span>(</span><span>req</span><span>.</span><span>type</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>case</span><span> </span><span>'mirror_data_get'</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>      </span><span>// Device wants state, send latest MQTT state or default fallback</span><span>
</span></span><span><span>      device</span><span>.</span><span>send</span><span>(</span><span>{</span><span> </span><span>fan_speed</span><span>:</span><span> mqtt</span><span>.</span><span>get</span><span>(</span><span>'fan_speed'</span><span>)</span><span> </span><span>||</span><span> </span><span>0</span><span> </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span>      </span><span>return</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>    </span><span>case</span><span> </span><span>'mirror_data'</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>      </span><span>// Device state has changed, publish and retain in MQTT broker</span><span>
</span></span><span><span>      mqtt</span><span>.</span><span>publish</span><span>(</span><span>'fan_speed'</span><span>,</span><span> req</span><span>.</span><span>fan_speed</span><span>,</span><span> </span><span>{</span><span> </span><span>retain</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span>      </span><span>return</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span><span>
</span></span><span>
</span><span><span></span><span>function</span><span> </span><span>HandleMQTTMessage</span><span>(</span><span>topic</span><span>,</span><span> msg</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>  </span><span>switch</span><span> </span><span>(</span><span>topic</span><span>)</span><span> </span><span>{</span><span>
</span></span><span><span>    </span><span>case</span><span> </span><span>'set_fan_speed'</span><span>:</span><span> </span><span>{</span><span>
</span></span><span><span>      </span><span>// MQTT wants to change state, forward to device</span><span>
</span></span><span><span>      device</span><span>.</span><span>send</span><span>(</span><span>{</span><span> </span><span>fan_speed</span><span>:</span><span> msg</span><span>.</span><span>fan_speed </span><span>}</span><span>)</span><span>;</span><span>
</span></span><span><span>      </span><span>return</span><span>;</span><span>
</span></span><span><span>    </span><span>}</span><span>
</span></span><span><span>  </span><span>}</span><span>
</span></span><span><span></span><span>}</span></span></code></pre></div><p>This logic seems quite minimal but is carefully designed. The latest state is retained in the MQTT broker. However, the source of truth for state updates is always the device, meaning the state will never update in the MQTT broker unless the device updates it via the custom server. This covers a couple of edge cases:</p><ul><li><p>If the state update was unsuccessful, we should not display the state as updated.</p></li><li><p>The state update should be reflected via the MQTT broker if the smart device was updated via its physical control panel.</p></li></ul></div><p>The three main cases we are supporting here are:</p><ul><li><p>When the smart device boots and initially connects to the custom server, it requests the latest state; we can attempt to obtain this from the MQTT broker's retained value or fall back to a default state.</p></li><li><p>When Home Assistant wants to update the state, it will send a command to the MQTT broker. We can subscribe to this command topic from the custom server and forward the request to the smart device.</p></li><li><p>When the smart device's state changes for any reason, it sends the <code>mirror_data</code> packet to update the server state; we send this value to the MQTT broker to update the state and tell it to retain the data as the latest value.</p></li></ul><p>I run this custom server alongside Mosquitto and Home Assistant on my small home automation server. Then configured my Pi-hole local DNS to resolve the cloud server's domain to my custom server.</p><h2><a href="#home-assistant-integration" title="Home Assistant Integration"><span>Home Assistant Integration</span></a></h2><p>The final step in this process is configuring Home Assistant to map the MQTT topics to a device type. For my air purifier, the closest integration was an <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.home-assistant.io/integrations/fan.mqtt/"><span>MQTT Fan</span></a>; in my <code>configuration.yaml</code> I added something like this:</p><div><div><pre><code><span><span>mqtt</span><span>:</span><span>
</span></span><span><span>  </span><span>fan</span><span>:</span><span>
</span></span><span><span>    </span><span>-</span><span> </span><span>name</span><span>:</span><span> </span><span>"Air Purifier"</span><span>
</span></span><span><span>      </span><span>unique_id</span><span>:</span><span> </span><span>"air_purifier.main"</span><span>
</span></span><span><span>      </span><span>state_topic</span><span>:</span><span> </span><span>"air_purifier/on/state"</span><span>
</span></span><span><span>      </span><span>command_topic</span><span>:</span><span> </span><span>"air_purifier/on/set"</span><span>
</span></span><span><span>      </span><span>payload_on</span><span>:</span><span> </span><span>"true"</span><span>
</span></span><span><span>      </span><span>payload_off</span><span>:</span><span> </span><span>"false"</span><span>
</span></span><span><span>      </span><span>percentage_state_topic</span><span>:</span><span> </span><span>"air_purifier/speed/state"</span><span>
</span></span><span><span>      </span><span>percentage_command_topic</span><span>:</span><span> </span><span>"air_purifier/speed/set"</span><span>
</span></span><span><span>      </span><span>speed_range_min</span><span>:</span><span> </span><span>1</span><span>
</span></span><span><span>      </span><span>speed_range_max</span><span>:</span><span> </span><span>4</span></span></code></pre></div><p>I added topics to control the fan speed and turn the device on and off.</p></div><p><strong>Everything works!</strong> I've been running this for a couple of weeks now, and it has worked fine without any issues! I've even set up a little automation, so if my separate air monitor's PM2.5 or VOC level gets too high, it boosts the air purifier for a while!</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><p><img alt="" loading="lazy" width="580" height="700" decoding="async" data-nimg="1" sizes="(max-width: 744px) 100vw, (max-width: 1300px) 66vw, 400px" srcset="https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=640&amp;q=85&amp;fit=max&amp;auto=format 640w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=750&amp;q=85&amp;fit=max&amp;auto=format 750w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=828&amp;q=85&amp;fit=max&amp;auto=format 828w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=1080&amp;q=85&amp;fit=max&amp;auto=format 1080w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=1200&amp;q=85&amp;fit=max&amp;auto=format 1200w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=1920&amp;q=85&amp;fit=max&amp;auto=format 1920w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=2048&amp;q=85&amp;fit=max&amp;auto=format 2048w, https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format 3840w" src="https://cdn.sanity.io/images/kecg41hi/production/6c8ce057d5252c6b90e7dfb3dbb0c010962c1bb7-580x700.png?w=3840&amp;q=85&amp;fit=max&amp;auto=format"></p></div><h2><a href="#technical-recap" title="Technical Recap"><span>Technical Recap</span></a></h2><p>For better or worse, the engineers behind the service decided not to implement a standard protocol like DTLS. They created a custom solution which introduced some downsides to the system:</p><ul><li><div><p>We're not certain if each device has its own unique private key, but whether it does or not, both have downsides:</p><ul><li><p>If all devices share the same firmware private key, the attacker needs to reverse engineer just a single device to MITM attack any other devices.</p></li><li><p>However, if every device has its own unique private key, the server must keep a data store mapping device serial numbers to the key of each device. So, In the case of any data loss, the server would entirely lose the ability to respond to any device communications; that is a scary thought for the business. Unless there is an insecure network fallback in place, which is equally alarming and time-consuming to develop</p></li></ul></div></li><li><p>Because the firmware contains a private key that is static, an attacker needs a single firmware dump to obtain the key and perform an MITM attack. Whereas, if an EC private key was instead generated at runtime, write access would be required in order to patch the server public key or application firmware, which could be protected by other means.</p></li></ul><p>Also, the mobile app has a 1-star review on the app store. It makes me wonder if there is a correlation between the unexpectedly custom technical implementation and the abnormally poor end-user app experience. Building a custom system is far more than just the initial development; systems need support, and bugs need fixing. </p><p>Overall, it wasn't a bad implementation from a security perspective; you'd still need physical access to attack the device; there are pros and cons to everything and variables that aren't visible from our perspective.</p><p>The custom implementation increased the obscurity of network communication. However, <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Security_through_obscurity"><span>Security through obscurity</span></a> is simply a short-term win. While it may deter generic attacks on standard technical implementations. In the bigger picture, it's just an annoying yet passable hoop for an attacker to jump through. </p><p>I've had a few conversations recently about why engineers build from the ground up vs. using proven standards. And that's a very interesting topic; I'll save that for another post!</p><h2><a href="#conclusion" title="Conclusion"><span>Conclusion</span></a></h2><p>What a crazy journey that was! </p><p>I'd like to emphasize that the reverse-engineering process was not as smooth as it may seem from this post; I've done my best to format everything to be best read by you. But in reality, I was often in the dark, unsure if the next thing would work or not, and juggling many tasks and theories, iteratively making progress in multiple places to test my assumptions ASAP.</p><p>I tried some things that hit dead-ends and weren't worth dedicated sections in this post:</p><ul><li><p>I tried running the firmware in <a target="_blank" rel="noopener noreferrer nofollow" href="https://github.com/espressif/qemu"><span>Espressif's fork of QEMU</span></a>, patched out the CapSense service, and loaded virtual e-fuses to match the MAC address from the firmware, all to find out it doesn't support WiFi emulation. It was fun to see it booting virtually, though!</p></li><li><p>I also tried flashing a different serial number, device key, and certificates to see if that affected anything before I got around to fully reversing the application logic. I didn't get much from this. Turns out this likely would have just affected the computed shared secret used for the HKDF salt, which we dumped anyway.</p></li></ul><p>I've certainly sharpened a variety of skills from this project. I'm also proud I achieved my goal of adding this device to Home Assistant! The moment I managed to successfully decrypt the first packet was great; everything just clicked into place.</p><p>I'm still curious to explore creating an open-source project to de-cloud and debug smart home products; I've learned much more about the technical aspects of achieving that.</p><p>Thanks for reading! I hope you found some value in this post. I put a massive amount of effort into creating it, probably more than I did actually doing the project itself. It would be amazing to receive feedback on the format!</p><p>I'd also really appreciate it if you could help share the post. </p><p>You can drop a follow on <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/jmswrnr"><span>X</span></a> to stay updated with what I'm doing.</p><p>If you found it helpful and would like to support my content creation, you can <a target="_blank" rel="noopener noreferrer" href="https://buymeacoffee.com/jmswrnr"><span>Buy Me a Coffee</span></a>! Your support helps me continue creating content and sharing my passion for reverse engineering!</p><p>Take it easy 👋</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Palestinian activist arrested by ICE while expecting U.S. citizenship interview (160 pts)]]></title>
            <link>https://www.cbc.ca/lite/story/1.7510325</link>
            <guid>43688069</guid>
            <pubDate>Tue, 15 Apr 2025 01:18:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/lite/story/1.7510325">https://www.cbc.ca/lite/story/1.7510325</a>, See on <a href="https://news.ycombinator.com/item?id=43688069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><div><article id="article"><p>The Associated Press | Posted: April 15, 2025 12:16 AM | Last Updated: 4 hours ago</p><p>Mohsen Mahdawi, a legal permanent resident, had led protests against the war in Gaza</p><div role="figure" data-pw="imageEmbed"><p>Image  |  Immigration Palestinian Student Detained</p><p>Caption: This image taken from a video shows Mohsen Mahdawi being detained at the U.S. Citizenship and Immigration Services office in Colchester, Vt., on Monday. The video was taken by Christopher Helali, a friend who accompanied Mahdawi to a meeting at the office.  (Christopher Helali via AP)</p></div><p>A Palestinian man who led protests against the war in Gaza as a student at Columbia University was arrested Monday at a Vermont immigration office where he expected to be interviewed about finalizing his U.S. citizenship, his attorneys said.</p><p>Mohsen Mahdawi, a legal permanent resident who has held a green card since 2015, was detained at the U.S. Citizenship and Immigration Services office in Colchester, Vt., by Immigration and Customs Enforcement agents, his lawyers said.</p><p>The attorneys said they do not know where he is and have filed a petition in federal court seeking an order barring the government from removing him from the state or country.</p><p>"The Trump administration detained Mohsen Mahdawi in direct retaliation for his advocacy on behalf of Palestinians and because of his identity as a Palestinian. His detention is an attempt to silence those who speak out against the atrocities in Gaza. It is also unconstitutional," attorney Luna Droubi said in an email.</p><p>According to the court filing, Mahdawi was born in a refugee camp in the West Bank and moved to the United States in 2014.</p><p>He recently completed coursework at Columbia in New York and was expected to graduate in May before beginning a master's degree program there in the fall.</p><p>The petition describes him as a committed Buddhist who believes in "non-violence and empathy as a central tenet of his religion."</p><h2>Arrest 'immoral, inhumane, and illegal'</h2><p>As a student, Mahdawi was an outspoken critic of Israel's military campaign in Gaza and organized campus protests until March 2024.</p><p>He co-founded the Palestinian Student Union at Columbia with Mahmoud Khalil, another Palestinian permanent resident of the U.S. and graduate student who recently was detained by ICE.</p><p>Khalil was the first person arrested under President Donald Trump's promised crackdown on students who joined campus protests against the war in Gaza.</p><p>On Friday, an immigration judge in Louisiana ruled that Khalil can be deported as a national security risk.</p><p>Christopher Helali, a friend of Mahdawi who lives near him in Vermont, was present outside the immigration office when Mahdawi was detained and recorded a video of Mahdawi being led away by authorities.</p><p>In the video, which Helali released on social media Monday, Mahdawi is shown giving a peace sign with his hands and being led away to a car.</p><p>Helali described Mahdawi as a peaceful demonstrator who has worked to foster dialogue about the struggle of Palestinians in his homeland.</p><p>Helali said he and Mahdawi were aware that Mahdawi could be detained today and that his friend went forward with the appointment anyway.</p><p>"And rightfully so, he was nervous for what was going on around him. But he was very much resolute in coming to this interview and coming today because he didn't do anything wrong and was a law-abiding citizen, or soon-to-be citizen," Helali said.</p><p>Vermont's congressional delegation issued a statement condemning Mahdawi's arrest, saying that instead of taking one of the final steps in his citizenship process, he was handcuffed by armed officers with their faces covered.</p><p>"This is immoral, inhumane and illegal. Mr. Mahdawi, a legal resident of the United States, must be afforded due process under the law and immediately released from detention," said the statement from Sen. Bernie Sanders, Sen. Peter Welch and Rep. Becca Balint.</p></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The problem with "vibe coding" (124 pts)]]></title>
            <link>https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html</link>
            <guid>43687767</guid>
            <pubDate>Tue, 15 Apr 2025 00:26:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html">https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html</a>, See on <a href="https://news.ycombinator.com/item?id=43687767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">
					<article>
						
						
						<p>The whole “vibe coding” thing is another reminder that quite a lot of people working in tech don’t understand the difference between programs and products.</p>

<p>To me, programs are “works on my machine” code. The kind of things many of us crank out a few times every week. Experiments, prototypes… that script you hacked up to rename all the MP4 files in a folder? You know the one. No error checking. Hard-coded path names. Does it work on Windows? Who cares? I’m on Linux right now and I got work to do.</p>

<p>I have dozens of these kinds of programs I use every day. They’re tools I use to automate bits of my work. They crash all the time (“what? Oh… that person has a backslash in the title of their presentation… interesting.”) - but that doesn’t matter; I fix them, I get the results I need, I move on. The code is just a means to an end. The result is what matters.</p>

<p>If you’re writing software that you’re planning to ship; to distribute to other people, perhaps even sell it to paying customers? Well, now that’s a whole different ball game.</p>

<p>Probably the single most important lesson I’ve learned in my career, the thing that I would argue is the hallmark of “experience”, is understanding just how much work it takes to turn a working <em>program</em> into a viable <em>product</em>. It’s why developer estimates are so notoriously optimistic - and why experienced developers are so notoriously cynical. Let’s say you crank out a bit of code that’ll take responses from a web form and add them in an Excel spreadsheet. That’s not that hard… yay! we just built a Typeform competitor in one afternoon! Except, no, you didn’t. You made one thing work one time on one computer. You haven’t considered encoding, internationalization, concurrency, authentication, telemetry, billing, branding, mobile devices, deployment. You haven’t hit any of the weird limits yet - ever had a system work brilliantly for the first 65,535 requests and then fall over? You don’t have a product. At best, you have a proof-of-concept of a good idea that, if some very smart people work very hard, might become a viable product.</p>

<p>One of the genuinely positive things about tools like Copilot and ChatGPT is that they empower people with minimal development experience to create their own programs. Little programs that do useful things - and that’s <em>awesome</em>. More power to the users.</p>

<p>But that’s not product development, it’s programming. They aren’t the same thing. Not even close.</p>

					</article>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Temu pulls its U.S. Google Shopping ads (219 pts)]]></title>
            <link>https://searchengineland.com/temu-pulls-us-google-shopping-ads-454260</link>
            <guid>43687495</guid>
            <pubDate>Mon, 14 Apr 2025 23:43:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://searchengineland.com/temu-pulls-us-google-shopping-ads-454260">https://searchengineland.com/temu-pulls-us-google-shopping-ads-454260</a>, See on <a href="https://news.ycombinator.com/item?id=43687495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articlebody">

													
												
						
						
						<div>
<p>Temu completely shut off Google Shopping ads in the U.S. on April 9, with its App Store ranking subsequently plummeting from a typical third or fourth position to 58th in just three days. </p>



<p>The company’s impression share, which measures how often their ads appear compared to eligibility, dropped sharply before disappearing completely from advertiser auction data by April 12.</p>



<p>The timing coincided with the Trump administration’s hardened stance on Chinese imports, raising tariffs to 125% while maintaining a more moderate approach to other trading partners.</p>



<p><strong>First seen.</strong> Mike Ryan, head of ecommerce insights at Smarter Ecommerce, shared this news on <a href="https://www.linkedin.com/posts/mikeryanretail_%F0%9D%97%A7%F0%9D%97%B2%F0%9D%97%BA%F0%9D%98%82-%F0%9D%97%B5%F0%9D%97%AE%F0%9D%98%80-%F0%9D%97%B9%F0%9D%97%B2%F0%9D%97%B3%F0%9D%98%81-%F0%9D%98%81%F0%9D%97%B5%F0%9D%97%B2-%F0%9D%97%AF%F0%9D%98%82%F0%9D%97%B6%F0%9D%97%B9%F0%9D%97%B1%F0%9D%97%B6%F0%9D%97%BB%F0%9D%97%B4-activity-7317519336426901504-Kucf/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAB0N7MBstWf5SblEci2G1F3WzMSeIW1b7s" target="_blank" rel="noopener">LinkedIn</a>:</p>


<div>
<figure><img fetchpriority="high" decoding="async" width="800" height="487" src="https://searchengineland.com/wp-content/seloads/2025/04/1744632561651.jpeg.webp" alt="1744632561651" srcset="https://searchengineland.com/wp-content/seloads/2025/04/1744632561651.jpeg.webp 800w,https://searchengineland.com/wp-content/seloads/2025/04/1744632561651-555x338.jpeg.webp 555w,https://searchengineland.com/wp-content/seloads/2025/04/1744632561651-186x113.jpeg.webp 186w,https://searchengineland.com/wp-content/seloads/2025/04/1744632561651-768x468.jpeg.webp 768w" sizes="(max-width: 800px) 100vw, 800px"></figure></div>


<p><strong>Between the lines</strong>. Temu’s business model relied on heavily subsidized orders from parent company PDD to drive market share growth, despite operating at a loss on individual sales.</p>



<ul>
<li>New tariffs, combined with crackdowns on “de minimis” import loopholes, have severely undermined Temu’s direct-from-manufacturer approach.</li>



<li>The company’s inability to maintain app performance without advertising for even a single day demonstrates the fragility of its market position.</li>
</ul>



<p><strong>Why we care</strong>. Ecommerce advertisers may experience temporary relief in digital advertising costs as Temu’s aggressive spending vanishes from auction platforms. Similar rapid market exits (e.g., Amazon during early pandemic lockdowns) led to drops in cost-per-click metrics. Some reduction in CPM rates is expected, potentially lowering both CPC and cost-per-conversion for remaining advertisers.</p>



<p><strong>Tariffs</strong>. The underlying causes of Temu’s retreat (tariffs and import restrictions) could ultimately prove more damaging to the ecommerce landscape, particularly for small and medium-sized businesses.</p>



<p><strong>Bottom line</strong>. Unlike failed competitor Wish.com, Temu’s parent company remains fundamentally sound. With U.S. trade policy still in flux and facing internal opposition even within the administration, Temu’s retreat may not be permanent.</p>
</div>
						
						<hr>
						
						

						<div>
			<p>New on Search Engine Land</p>
			<section>
				<ul>

					
					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
					<article>
						
					</article>

					
				</ul>
			</section>
		</div>


											
<!-- START EOS SPACE -->

<!-- END EOS SPACE -->					
						


<div>
	<p>About the author</p>
	<div>
				<div>
						<p><img src="https://searchengineland.com/anu-adegbola-2" alt="Anu Adegbola" width="140" height="140" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20140%20140'%3E%3C/svg%3E"></p>
											</div>
				<div>
						
						

						<p><span>Anu Adegbola has been Paid Media Editor of Search Engine Land</span><span> since 2024. She covers</span><span> paid search, paid social, retail media, video and more.<p>In 2008, Anu's career started with</p></span><span><span>&nbsp;delivering digital marketing campaigns (mostly but not exclusively Paid Search) by building strategies, maximising ROI, automating repetitive processes and bringing efficiency from every part of marketing departments through inspiring leadership both on agency, client and marketing tech side.</span></span></p>
<p><span><span>Outside editing Search Engine Land article she is the founder of PPC networking event - <a href="https://ppc.live/" target="_blank" rel="noopener">PPC Live</a> and host of </span></span><span><span>weekly podcast <a href="https://www.themarketinganu.com/podcast" target="_blank" rel="noopener">PPCChat Roundup</a>.</span></span></p>

<p><span><span>She is also an international speaker with some of the stages she has presented on being SMX (US), SMX (Munich), Friends of Search (Amsterdam), brightonSEO, The Marketing Meetup, HeroConf (PPC Hero), SearchLove, BiddableWorld, SESLondon, PPC Chat Live, AdWorld Experience (Bologna) and more.</span></span></p>					</div>
			</div>
</div>
						
						<br>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Cost of Being Crawled: LLM Bots and Vercel Image API Pricing (106 pts)]]></title>
            <link>https://metacast.app/blog/engineering/postmortem-llm-bots-image-optimization</link>
            <guid>43687431</guid>
            <pubDate>Mon, 14 Apr 2025 23:33:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://metacast.app/blog/engineering/postmortem-llm-bots-image-optimization">https://metacast.app/blog/engineering/postmortem-llm-bots-image-optimization</a>, See on <a href="https://news.ycombinator.com/item?id=43687431">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>A misconfiguration that might have cost us $7,000</p><p><img alt="LLM bots + Next.js image optimization = recipe for bankruptcy (post-mortem)" loading="lazy" width="1200" height="630" decoding="async" data-nimg="1" sizes="100vw" srcset="https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=640&amp;q=75 640w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=750&amp;q=75 750w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=828&amp;q=75 828w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=1080&amp;q=75 1080w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=1200&amp;q=75 1200w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=1920&amp;q=75 1920w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=2048&amp;q=75 2048w, https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=3840&amp;q=75 3840w" src="https://metacast.app/_next/image?url=%2Fimages%2Fblog%2Fengineering%2Fpostmortem-llm-bots-image-optimization%2Fcover-postmortem-llm-bots-image-optimization.png&amp;w=3840&amp;q=75"></p><div><div><p><img alt="Author's picture" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" srcset="https://metacast.app/_next/image?url=%2Fimages%2Fpeople%2Filya-avatar.jpg&amp;w=128&amp;q=75 1x, https://metacast.app/_next/image?url=%2Fimages%2Fpeople%2Filya-avatar.jpg&amp;w=256&amp;q=75 2x" src="https://metacast.app/_next/image?url=%2Fimages%2Fpeople%2Filya-avatar.jpg&amp;w=256&amp;q=75"></p><p>Ilya Bezdelev</p></div><p>Published on <time datetime="2025-02-10T13:33:07.000Z">February	10, 2025</time></p></div><hr><div><div><p>Table of Contents</p><ol><li><a href="#tldr">TL;DR</a></li><li><a href="#context">Context</a></li><li><a href="#how-we-discovered-the-problem">How we discovered the problem</a><ol><li><a href="#step-1-a-cost-spike">Step 1: A cost spike</a></li><li><a href="#step-2-image-optimization-api-usage-spike">Step 2: Image Optimization API usage spike</a></li><li><a href="#step-3-tens-of-thousands-of-requests-from-llm-bots">Step 3: Tens of thousands of requests from LLM bots</a></li></ol></li><li><a href="#mitigation">Mitigation</a><ol><li><a href="#step-1-stop-the-bleeding">Step 1: Stop the bleeding</a></li><li><a href="#step-2-disable-image-optimization">Step 2: Disable Image Optimization</a></li><li><a href="#step-3-robotstxt">Step 3: robots.txt</a><ol><li><a href="#user-agents-of-llm-bots">User agents of LLM bots</a></li><li><a href="#user-agents-of-search-engine-crawlers">User agents of search engine crawlers</a></li><li><a href="#user-agents-of-seo-bots">User agents of SEO bots</a></li></ol></li></ol></li><li><a href="#how-do-we-prevent-this-in-the-future">How do we prevent this in the future?</a><ol><li><a href="#continue-with-a-sensitive-spend-limit">Continue with a sensitive spend limit</a></li><li><a href="#mindset-for-scale">Mindset for scale</a></li><li><a href="#ready-for-defense">Ready for defense</a></li></ol></li><li><a href="#social-media-response">Social media response</a></li><li><a href="#parting-thoughts">Parting thoughts</a></li><li><a href="#upd-vercel-changed-their-image-optimization-pricing">UPD: Vercel changed their image optimization pricing</a></li></ol></div><h2 id="tldr"><a href="#tldr">TL;DR</a></h2>
<p>On Friday, Feb 7, 2025 we had an incident with our Next.js web app hosted on Vercel that could've cost us $7,000 if we didn't notice it in time.</p>
<p>We had a spike in LLM bot traffic coming from Amazonbot, Claudebot, Meta and an unknown bot. Together they sent 66.5k requests to our site within a single day. Bots scraped thousands of images that used Vercel's Image Optimization API, which cost us $5 per 1k images.</p>
<p>The misconfiguration on our side combined with the aggressive bot traffic created an economically risky situation for our tiny bootstrapped startup.</p>
<h2 id="context"><a href="#context">Context</a></h2>
<p>Metacast is a podcast tech startup. Our main product is a <a href="https://metacast.app/">podcast app</a> for iOS and Android.</p>
<p>For every podcast episode on the platform, our web app has a web page. Our platform has ~1.4M episodes, which means we have 1.4M web pages that are discoverable by crawlers. These pages are generated server-side at request time, then cached.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/lex-podcast-page-metacast.png" alt="Lex Fridman Podcast"></p>
<h2 id="how-we-discovered-the-problem"><a href="#how-we-discovered-the-problem">How we discovered the problem</a></h2>
<h3 id="step-1-a-cost-spike"><a href="#step-1-a-cost-spike">Step 1: A cost spike</a></h3>
<p>First, we received a cost alert from Vercel saying that we've hit 50% of the budget for resources metered by usage.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-cost-alert.png" alt="Vercel cost alert"></p>
<h3 id="step-2-image-optimization-api-usage-spike"><a href="#step-2-image-optimization-api-usage-spike">Step 2: Image Optimization API usage spike</a></h3>
<p>We looked into it and saw that it's driven by the Image Optimization API, which peaked on Feb 7.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-image-optimization-usage-summary.jpg" alt="Image Optimization Usage"></p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-image-optimization-chart.jpg" alt="Image Optimization Usage Chart"></p>
<p>Every page in the podcast directory has an image of a podcast cover (source image dimensions are 3000x3000px). With Image Optimization, podcast covers were reduced to 1/10th of the size, then cached. Image Optimization made the web app really snappy. It worked like a charm, except it turned out to be very expensive.</p>
<p>Vercel <a href="https://vercel.com/docs/image-optimization/limits-and-pricing">charges</a> $5 for every 1,000 images optimized. With thousands of requests coming our way, we were accumulating cost at the rate of $5 per each 1k image requests. In the worst case scenario, if all 1.4M images were crawled we'd hypothetically be looking at a $7k bill from Vercel.</p>
<h3 id="step-3-tens-of-thousands-of-requests-from-llm-bots"><a href="#step-3-tens-of-thousands-of-requests-from-llm-bots">Step 3: Tens of thousands of requests from LLM bots</a></h3>
<p>We looked at the user agents of requests in the Firewall in Vercel and saw Amazonbot, ClaudeBot, meta_externalagent and an unknown bot disguising itself as a browser.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-user-agent-stats.png" alt="User Agents"></p>
<p>We can't say definitively which bots were downloading images, because we are on the Pro plan on Vercel and no longer have access to logs from Friday. We only know that it was bot traffic.</p>
<h2 id="mitigation"><a href="#mitigation">Mitigation</a></h2>
<h3 id="step-1-stop-the-bleeding"><a href="#step-1-stop-the-bleeding">Step 1: Stop the bleeding</a></h3>
<p>Both of us used to work at AWS where we internalized the golden rule of incident recovery - <strong>stop the bleeding first, do a long-term fix later</strong>.</p>
<p>We configured firewall rules in Vercel to block bots from Amazon, Anthropic, OpenAI and Meta. To be fair, OpenAI didn't crawl our site, but we blocked it as a preventative measure.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-firewall-rules.jpg" alt="Firewall rules"></p>
<h3 id="step-2-disable-image-optimization"><a href="#step-2-disable-image-optimization">Step 2: Disable Image Optimization</a></h3>
<p>First, we disabled image optimization by adding an <code>unoptimized</code> property to podcast images in Next.js. Our reasoning was that users accessing the pages will get the latest version of the page with unoptimized images.</p>
<p>We didn't consider that:</p>
<ul>
<li>Bots had already crawled thousands of pages and would crawl the <em>optimized</em> images using the URLs they extracted from the "old" HTML.</li>
<li>Our site enabled image optimization for all external hosts.</li>
</ul>
<p>The latter is the most embarrassing part of the story. We missed an obvious exploit in the web app.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="javascript" data-theme="github-dark-dimmed github-light"><code data-language="javascript" data-theme="github-dark-dimmed github-light"><span data-line=""><span>const</span><span> nextConfig</span><span> =</span><span> {</span></span>
<span data-line=""><span>  images: {</span></span>
<span data-line=""><span>    remotePatterns: [</span></span>
<span data-line=""><span>      {</span></span>
<span data-line=""><span>        protocol: </span><span>'https'</span><span>,</span></span>
<span data-line=""><span>        hostname: </span><span>'**'</span><span>,</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>      {</span></span>
<span data-line=""><span>        protocol: </span><span>'http'</span><span>,</span></span>
<span data-line=""><span>        hostname: </span><span>'**'</span><span>,</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>    ],</span></span>
<span data-line=""><span>  },</span></span>
<span data-line=""><span>  ...</span></span></code></pre></figure>
<p>To explain why we did this in the first place, we need to add some important context about podcasting.</p>
<p>We do not own the podcast content displayed on our site. Similar to other podcast apps like Apple and Spotify, we ingest podcast information from RSS feeds and display it in our directory. The cover images are hosted on specialized podcast hosting platforms like <a href="https://transistor.fm/">Transistor</a>, <a href="https://www.buzzsprout.com/">Buzzsprout</a>, and others. But podcasts could be hosted anywhere from a WordPress website to an S3 bucket. It is impractical to allowlist all possible hosts.</p>
<p>Optimizing an image meant that Next.js downloaded the image from one of those hosts to Vercel first, optimized it, then served to the users. If we wanted to make our site snappy, we had to either build and maintain an image optimization pipeline ourselves or use the built-in capability. As a scrappy startup for whom a web app was at best secondary, we chose the faster route without thinking much about it.</p>
<p>In retrospect, we should've researched how it works. We're lucky no one started using our site as an image optimization API.</p>
<p>To mitigate the problem entirely, we disabled image optimization for any external URLs. Now, image optimization is only enabled for images hosted on our own domain. Podcast covers load noticeably slower. We'll need to do something about it eventually.</p>
<p>But this is not all.</p>
<h3 id="step-3-robotstxt"><a href="#step-3-robotstxt">Step 3: robots.txt</a></h3>
<p>Of course, we knew about <code>robots.txt</code>, a file that tells crawlers whether they're allowed to crawl the site or not.</p>
<p>Since both of us were new to managing a large-scale content site (our background is in backends, APIs, and web apps behind auth), we didn't even think about LLM bots. It's just not something that was on our radar. So, our <code>robots.txt</code> was a simple allow-all except for a few paths that we disallowed.</p>
<p>Our first reaction was to disable all bot traffic except Google. But when we understood that the root cause of the problem lied in the misconfigured image optimization, we decided to keep our site open to all LLM and search engine bots. Serving the text content doesn't cost us much, but we may benefit from being shown as a source of data in LLMs, which would be similar to being shown on a search engine results page (SERP).</p>
<p>We generate <code>robots.txt</code> programmatically using <a href="https://nextjs.org/docs/app/api-reference/file-conventions/metadata/robots">robots.ts</a> in Next.js. We researched the bots and added their user agents to our code. If we ever need to disable any of the bots, we can do so very quickly now. While we were at it, we disabled some paths for SEO bots like Semrush and MJ12Bot.</p>
<p>Note that <code>robots.txt</code> only works if bots respect it. It's honor-based system and there are still bad bots out there that ignore it and/or attempt to disguise themselves as users.</p>
<h4 id="user-agents-of-llm-bots"><a href="#user-agents-of-llm-bots">User agents of LLM bots</a></h4>
<table>
<thead>
<tr>
<th>User Agent</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Amazonbot</code></td>
<td><a href="https://developer.amazon.com/amazonbot">Amazon</a></td>
</tr>
<tr>
<td><code>CCBot</code></td>
<td><a href="https://commoncrawl.org/faq">Common Crawl</a></td>
</tr>
<tr>
<td><code>ClaudeBot</code></td>
<td><a href="https://privacy.anthropic.com/en/articles/10023637-does-anthropic-crawl-data-from-the-web-and-how-can-site-owners-block-the-crawler">Anthropic</a></td>
</tr>
<tr>
<td><code>GPTBot</code></td>
<td><a href="https://platform.openai.com/docs/bots/">OpenAI</a></td>
</tr>
<tr>
<td><code>Meta-ExternalAgent</code></td>
<td><a href="https://developers.facebook.com/docs/sharing/webmasters/web-crawlers/">Meta</a></td>
</tr>
<tr>
<td><code>PerplexityBot</code></td>
<td><a href="https://docs.perplexity.ai/guides/bots">Perplexity</a></td>
</tr>
</tbody>
</table>
<h4 id="user-agents-of-search-engine-crawlers"><a href="#user-agents-of-search-engine-crawlers">User agents of search engine crawlers</a></h4>
<table>
<thead>
<tr>
<th>User Agent</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Applebot</code></td>
<td><a href="https://support.apple.com/en-us/119829">Apple</a></td>
</tr>
<tr>
<td><code>Baiduspider</code></td>
<td><a href="https://www.baidu.com/search/robots_english.html">Baidu</a></td>
</tr>
<tr>
<td><code>Bingbot</code></td>
<td><a href="https://www.bing.com/webmasters/help/which-crawlers-does-bing-use-8c184ec0">Bing</a></td>
</tr>
<tr>
<td><code>ChatGPT-User</code> &amp; <code>OAI-SearchBot</code></td>
<td><a href="https://platform.openai.com/docs/bots/">OpenAI</a></td>
</tr>
<tr>
<td><code>DuckDuckBot</code></td>
<td><a href="https://duckduckgo.com/duckduckgo-help-pages/results/duckduckbot/">DuckDuckGo</a></td>
</tr>
<tr>
<td><code>Googlebot</code></td>
<td><a href="https://developers.google.com/search/docs/crawling-indexing/googlebot">Google</a></td>
</tr>
<tr>
<td><code>ImageSift</code></td>
<td><a href="https://imagesift.com/about">ImageSift by Hive</a></td>
</tr>
<tr>
<td><code>Perplexity‑User</code></td>
<td><a href="https://docs.perplexity.ai/guides/bots">Perplexity</a></td>
</tr>
<tr>
<td><code>YandexBot</code></td>
<td><a href="https://www.yandex.com/support/webmaster/robot-workings/user-agent.html">Yandex</a></td>
</tr>
</tbody>
</table>
<h4 id="user-agents-of-seo-bots"><a href="#user-agents-of-seo-bots">User agents of SEO bots</a></h4>
<table>
<thead>
<tr>
<th>User Agent</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>AhrefsBot</code></td>
<td><a href="https://ahrefs.com/robot">Ahrefs</a></td>
</tr>
<tr>
<td><code>DataForSeoBot</code></td>
<td><a href="https://dataforseo.com/dataforseo-bot">DataForSeoBot</a></td>
</tr>
<tr>
<td><code>DotBot</code></td>
<td><a href="https://moz.com/help/moz-procedures/crawlers/dotbot">DotBot</a></td>
</tr>
<tr>
<td><code>MJ12bot</code></td>
<td><a href="https://mj12bot.com/">MS12Bot</a></td>
</tr>
<tr>
<td><code>SemrushBot</code></td>
<td><a href="https://www.semrush.com/bot/">Semrush</a></td>
</tr>
</tbody>
</table>
<h2 id="how-do-we-prevent-this-in-the-future"><a href="#how-do-we-prevent-this-in-the-future">How do we prevent this in the future?</a></h2>
<p>We will start with the one thing we've done well.</p>
<h3 id="continue-with-a-sensitive-spend-limit"><a href="#continue-with-a-sensitive-spend-limit">Continue with a sensitive spend limit</a></h3>
<p>We had a very sensitive spend limit alert. We knew we should not be spending much on Vercel, so we set it very low. When it triggered, we knew something was off.</p>
<p>This may be the most important lesson to all startups and big enterprises alike - always set spend limits for your infrastructure, or the bill may ruin you. You can probably negotiate with Vercel, AWS, GCP, etc. and they'll reduce or forgive your bill. But it's best to not put yourself in a situation where you have to ask for a favor.</p>
<h3 id="mindset-for-scale"><a href="#mindset-for-scale">Mindset for scale</a></h3>
<p>We've learned a ton and have (hopefully) attuned ourselves to:</p>
<ul>
<li><strong>The scale we're operating at</strong> – we're serving millions of pages and need to be prepared for user traffic at that scale. The bots gave us a taste for what it would've been like had our app gone viral.</li>
<li><strong>The scale of web crawlers, both good and bad</strong> – we need to be prepared to be "anthropized", "openAIed", "amazoned", or "semrushed." It's the new <a href="https://en.wikipedia.org/wiki/Slashdot_effect">slasdot effect</a> but without the benefit of immediate gratification.</li>
</ul>
<h3 id="ready-for-defense"><a href="#ready-for-defense">Ready for defense</a></h3>
<p>We've now better understood the options we have for firewalling ourselves from bots if we have to do so in the future. We can use Vercel firewall as the first line of defense or add a more advanced WAF from Cloudflare if things get dire.</p>
<p>See this post from Cloudflare: <a href="https://blog.cloudflare.com/declaring-your-aindependence-block-ai-bots-scrapers-and-crawlers-with-a-single-click/">Declare your AIndependence: block AI bots, scrapers and crawlers with a single click</a></p>

<p>When we discovered the rate at which bots were crawling our site, we <a href="https://www.linkedin.com/posts/ilyabezdelev_our-site-is-getting-totally-slammed-by-activity-7293596095778074624-MD_I">posted about it</a> on LinkedIn. We were just sharing what's going on in real time, but boy did it hit the nerve. Almost 400k impressions, 2.4k likes, 270+ comments, 120+ reposts.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/linkedin-post.jpg" alt="LinkedIn post stats"></p>
<p>We've gone through all comments on the post and responded to most of them.</p>
<p>Lots of folks offered solutions like <a href="https://blog.cloudflare.com/declaring-your-aindependence-block-ai-bots-scrapers-and-crawlers-with-a-single-click/">CloudFlare</a>, using middleware, rate limiting, etc. Some offered to feed junk back to LLM bots.</p>
<p>We learned about <a href="https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/">tarpit</a> tools like <a href="https://iocaine.madhouse-project.org/">iocaine</a> and <a href="https://zadzmo.org/code/nepenthes/">Nepenthes</a>.</p>
<blockquote>
<p><em>You could lure them into a honeypot?<br>
Like nepenthes or locaine.<br>
If you feel like poisoning the ai well</em></p>
</blockquote>
<p>People rightfully pointed out that you can get ruined by infinite scalability of cloud resources.</p>
<blockquote>
<p><em>that's my biggest concern about cloud providers. You make a small mistake (everyone does) and the costs can skyrocket overnight.</em></p>
</blockquote>
<p>We learned that some people aren't aware of the LLM bot crawling activity or the scale of it. They thanked us for raising awareness.</p>
<blockquote>
<p><em>WOW - thanks for alerting us.</em></p>
</blockquote>
<p>Some people had been surprised by bots just like we were.</p>
<blockquote>
<p><em>Same here. At first I was super excited to get so many new subscriptions. We did reCaptcha and Cloudflare. Things have quieted down. Thanks for posting. I thought we were the only ones</em></p>
</blockquote>
<p>Some aren't surprised at all and see it as a problem.</p>
<blockquote>
<p><em>Very recognizable (unfortunately). These (predominantly AI) bots started noticeably hitting our platform back in May/June 2024. Lots of time &amp; efforts wasted to keep our bills in check. We also found out that not all of them respect Robots.txt, so indeed a WAF is needed as well. I can(not) imagine how painful this must/will be for smaller businesses...</em></p>
</blockquote>
<p>Some people blamed us for not being prepared and called us out on calling out AI companies. Others defended us. Virality is a double-edged sword.</p>
<p>A large portion of the comments were claiming that data scraping is unethical, illegal, etc. People were outraged. It wasn't our intention, but our post brought the issue to the zeitgeist of that day.</p>
<h2 id="parting-thoughts"><a href="#parting-thoughts">Parting thoughts</a></h2>
<p><strong>There's a part of me that is glad that this happened.</strong></p>
<p>We got a taste of operating a web app at scale before reaching scale. It was easy to block bots, but had it been caused by user traffic, we'd have to swallow the cost or downgrade the experience. Bots were the canaries in a coalmine.</p>
<p><strong>Any technology has negative externalities.</strong></p>
<p>Some are obvious, some aren't. Of all the things that were happening, I was worried that we'd get penalized by podcast hosters whose endpoints we were hitting at the same rate as bots requested images from our site.</p>
<p><strong>Operating at scale on the internet is a game of defense</strong></p>
<p>We can rant about bots as much as we want, but that <em>is</em> the reality we operate in. So we better acknowledge it and deal with it.</p>
<p>P.S. We'll be discussing this topic on the next episode of the <a href="https://metacast.app/podcasts/7d7e381e-907c-5b22-aefc-1fc8311d2a71">Metacast: Behind the scenes</a> podcast. Follow us wherever you listen to podcasts to hear the story with more nuance.</p>
<h2 id="upd-vercel-changed-their-image-optimization-pricing"><a href="#upd-vercel-changed-their-image-optimization-pricing">UPD: Vercel changed their image optimization pricing</a></h2>
<p>On Feb 18, 2025, just a few days after we published this blog post, Vercel <a href="https://vercel.com/changelog/faster-transformations-and-reduced-pricing-for-image-optimization">changed</a> their image optimization pricing. With the new pricing we'd not have faced a huge bill.</p>
<p><img src="https://metacast.app/images/blog/engineering/postmortem-llm-bots-image-optimization/vercel-new-pricing.webp" alt="New Image Optimization pricing on Vercel"></p>
<p>However, this wouldn't address the problem that we need to optimize images hosted outside of our domain. We ended up implementing our own image optimization.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tomb Engine (172 pts)]]></title>
            <link>https://tombengine.com/</link>
            <guid>43686936</guid>
            <pubDate>Mon, 14 Apr 2025 22:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tombengine.com/">https://tombengine.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43686936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="6f3696b0" data-element_type="container" data-widget_type="text-editor.default" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}" data-elementor-type="footer" data-elementor-id="1421" data-elementor-post-type="elementor_library">
				<p><span>This is a community project which is not affiliated with Core Design, Eidos Interactive, or Embracer Group AB. Tomb Raider is a registered trademark of Embracer Group AB. TombEngine is not be sold. The code is open-source to encourage contributions and to be used for study purposes. We are not responsible for illegal uses of this source code. This source code is released as-is and continues to be maintained by non-paid contributors in their free time.</span></p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel sells 51% stake in Altera to private equity firm on a $8.75B valuation (287 pts)]]></title>
            <link>https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025</link>
            <guid>43686773</guid>
            <pubDate>Mon, 14 Apr 2025 21:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025">https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025</a>, See on <a href="https://news.ycombinator.com/item?id=43686773">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Raghib Hussain appointed chief executive officer of Altera.</p><div nonce="ijCpSEMuRnL490hOs/kXNA==">

					
						

					<!--?xml encoding="utf-8" ?--><p>SANTA CLARA, Calif.; SAN JOSE, Calif.; and MENLO PARK, Calif., April 14, 2025 – Intel Corporation today announced that it has entered into a definitive agreement to sell 51% of its Altera business to Silver Lake, a global leader in technology investing.</p><p>The transaction, which values Altera at $8.75 billion, establishes Altera’s operational independence and makes it the largest pure-play FPGA (field programmable gate array) semiconductor solutions company. Altera offers a proven and highly scalable architecture and tool chain and is focused on driving growth and FPGA innovation to meet the demands and opportunities of an AI-driven market.</p><p>Intel will own the remaining 49% of the Altera business, enabling it to participate in Altera’s future success while focusing on its core business.</p><p>Intel also announced that Raghib Hussain will succeed Sandra Rivera as chief executive officer of Altera, effective May 5, 2025. Hussain is a highly accomplished and visionary technology executive with strong business acumen and engineering credentials. He joins Altera from his previous role as president of Products and Technologies at Marvell. Prior to joining Marvell in 2018, Hussain served as chief operating officer of Cavium, a company he co-founded. Prior to Cavium, Hussain held engineering roles at both Cisco and Cadence and helped found VPNet, an enterprise security company.</p><p>“Today’s announcement reflects our commitment to sharpening our focus, lowering our expense structure and strengthening our balance sheet,” said Lip-Bu Tan, chief executive officer of Intel. “Altera continues to make progress repositioning its product portfolio to participate in the fastest growing and most profitable segments of the FPGA market. We are grateful for Sandra’s strong leadership and lasting impact throughout her 25-year Intel career and wish her continued success as she begins a new chapter. Raghib is a superb executive we selected to lead the business forward based on his vast industry experience and proven track record of success. We look forward to partnering with Silver Lake upon closing of the transaction, as their industry expertise will help to accelerate Altera's efforts and unlock additional economic value for Intel.”</p><p>“This investment represents a once-in-a-generation opportunity to invest in a scale leader in advanced semiconductors. Together with Raghib, we will be focused on strengthening Altera’s technology leadership position and investing in emerging AI-driven markets such as edge computing and robotics,” said Kenneth Hao, chairman and managing partner of Silver Lake. “We look forward to working closely with Intel as a strategic partner who will continue to provide U.S.-based foundry services and complementary engagement with customers.”</p><p>“I am excited to lead Altera in its next chapter, and this milestone with Silver Lake furthers Altera’s journey to be the world's No. 1 FPGA solutions provider,” said Hussain. “Backed by Silver Lake’s strong track record and now with clarity of focus as an independent company, Altera is well-positioned to build on its momentum and deliver breakthrough FPGA-based solutions that are shaping the future of compute driven by AI. I am grateful for the impact Sandra has made and the team she has built as we begin Altera’s next phase of growth.”</p><p>Altera has been at the forefront of driving FPGA innovations for more than 40 years. The company provides leading programmable solutions that are easy-to-use and deploy in a range of strategically important segments such as industrial, communications, data center and military, aerospace, and government, as well as emerging markets such as AI/edge and robotics. Its broad portfolio of programmable semiconductor solutions, software and development tools deliver the reliability and flexibility needed to accelerate customer technology innovation.</p><p>The transaction is expected to close in the second half of 2025, subject to customary closing conditions.</p><p>Upon closing, Intel expects to deconsolidate Altera’s financial results from Intel’s consolidated financial statements. In Fiscal Year 2024, Altera generated revenues of $1.54 billion, GAAP gross margin of $361 million and GAAP operating loss of $615 million. Altera’s Fiscal Year 2024 non-GAAP gross margin was $769 million and non-GAAP operating income was $35&nbsp;million. Reconciliations between the GAAP and non-GAAP measures are provided below.</p><p>Morgan Stanley &amp; Co. LLC acted as financial advisor to Intel.</p><p><strong>Forward-Looking Statements</strong></p><p>This release contains forward-looking statements that involve a number of risks and uncertainties, including with respect to the terms and anticipated timing of closing the agreed upon sale of a controlling interest in Altera and the potential benefits of such sale to Intel and Altera. Such statements involve risks and uncertainties that could cause actual results to differ materially from those expressed or implied, including:&nbsp; the risk that the transaction may not be completed in a timely manner or at all, including as a result of a failure to receive regulatory approvals; the occurrence of any event, change or other circumstance that could give rise to the termination of the transaction; the risk that the expected benefits of the transaction, including as a result of the increased independence of Altera, may not be realized; the risk of future loss of the Altera business by Intel as a result of the sale of a controlling interest in Altera; disputes or potential litigation related to the transaction or the ownership, control and operation of the Altera business, including as it relates to Intel; unanticipated costs related to the transaction or the Altera business that may be incurred; risks as to the retention of key Altera personnel and customers; risks related to the diversion of management’s attention during the pendency of the transaction; potential adverse reactions or changes to business relationships resulting from the announcement or completion of the transaction; changes in demand for Altera’s semiconductor products; the high level of competition and rapid technological change in the semiconductor industry; and other risks and uncertainties described in Intel’s 2024 Form 10-K and our other filings with the SEC.</p><p>Given these risks and uncertainties, readers are cautioned not to place undue reliance on such forward-looking statements. Readers are urged to carefully review and consider the various disclosures made in this release and in other documents we file from time to time with the SEC that disclose risks and uncertainties that may affect our business.</p><p>All information in this press release reflects Intel management views as of the date hereof unless an earlier date is specified. Intel does not undertake, and expressly disclaims any duty, to update such statements, whether as a result of new information, new developments, or otherwise, except to the extent that disclosure may be required by law.</p><p><strong>Non-GAAP Financial Measures</strong></p><p>This release contains references to non-GAAP financial measures: Altera non-GAAP gross margin and Altera non-GAAP operating income / (loss) measures. Set out below are reconciliations of these measures to the most directly comparable GAAP financial measures. The non-GAAP financial measures disclosed herein should not be considered a substitute for, or superior to, the financial measures prepared in accordance with GAAP. Please refer to “Explanation of Non-GAAP Measures” in Intel’s earnings release dated Jan. 30, 2025 for a detailed explanation of the adjustments made to the comparable GAAP measures, the ways management uses the non-GAAP measures, and the reasons why management believes the non-GAAP measures provide investors with useful supplemental information.</p><table nonce="ijCpSEMuRnL490hOs/kXNA==">
<tbody>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Twelve Months Ended</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">(in Millions; Unaudited)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Dec 28, 2024</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">GAAP gross margin</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="><strong>$ 361</strong></td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Acquisition-related adjustments</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">402</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Share-based compensation</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">6</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Non-GAAP gross margin</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">$ 769</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">GAAP operating income / (loss)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="><strong>$ (615)</strong></td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Acquisition-related adjustments</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">491</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Share-based compensation</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">122</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Restructuring and other charges</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">37</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Non-GAAP operating income / (loss)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">$ 35</td>
</tr>
</tbody>
</table><p><strong>About Intel</strong></p><p>Intel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to <a href="https://newsroom.intel.com/">newsroom.intel.com</a> and <a href="https://intel.com/">intel.com</a>.</p><p><strong>About Altera</strong><br>
Altera is a leading supplier of programmable hardware, software, and development tools that empower designers of electronic systems to innovate, differentiate, and succeed in their markets. With a broad portfolio of industry-leading FPGAs, SoCs, and design solutions, Altera enables customers to achieve faster time-to-market and unmatched performance in applications spanning data centers, communications, industrial, automotive, and more. For more information, visit&nbsp;<a href="http://www.altera.com./">www.altera.com.</a></p><p><strong>About Silver Lake</strong><br>
Silver Lake is a global technology investment firm, with approximately $104 billion in combined assets under management and committed capital and a team of professionals based in North America, Europe and Asia. Silver Lake’s portfolio companies collectively generate nearly $252 billion of revenue annually and employ approximately 433,000 people globally.</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is Entropy? (245 pts)]]></title>
            <link>https://jasonfantl.com/posts/What-is-Entropy/</link>
            <guid>43684560</guid>
            <pubDate>Mon, 14 Apr 2025 18:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jasonfantl.com/posts/What-is-Entropy/">https://jasonfantl.com/posts/What-is-Entropy/</a>, See on <a href="https://news.ycombinator.com/item?id=43684560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>People say many things about entropy: entropy increases with time, entropy is disorder, entropy increases with energy, entropy determines the arrow of time, etc.. But I have no idea what entropy is, and from what I find, neither do most other people. This is the introduction I wish I had when first told about entropy, so hopefully you find it helpful. My goal is that by the end of this long post we will have a rigorous and intuitive understanding of those statements, and in particular, why the universe looks different when moving forward through time versus when traveling backward through time.</p><p>This journey begins with defining and understanding entropy. There are multiple formal definitions of entropy across disciplines—thermodynamics, statistical mechanics, information theory—but they all share a central idea: <strong>entropy quantifies uncertainty</strong>. The easiest introduction to entropy is through Information Theory, which will lead to entropy in physical systems, and then finally to the relationship between entropy and time.</p><h2 id="information-theory"><span>Information Theory</span><a href="#information-theory"><i></i></a></h2><p>Imagine you want to communicate to your friend the outcome of some random events, like the outcome of a dice roll or the winner of a lottery, but you want to do it with the fewest number of bits (only 1s and 0s) as possible. How few bits could you use?</p><p>The creator of Information Theory, Claude Shannon, was trying to answer questions such as these during his time at Bell labs. He was developing the mathematical foundations of communication and compression, and eventually he discovered that the minimum number of bits required for a message was directly related to the uncertainty of the message. He was able to then formulate an equation to quantify the uncertainty of a message. When he shared it with his physicist colleague at Bell Labs, John von Neumann, von Neumann suggested calling it <em>entropy</em> for two reasons:</p><blockquote><p>Von Neumann, Shannon reports, suggested that there were two good reasons for calling the function “entropy”. “It is already in use under that name,” he is reported to have said, “and besides, it will give you a great edge in debates because nobody really knows what entropy is anyway.” Shannon called the function “entropy” and used it as a measure of “uncertainty,” interchanging the two words in his writings without discrimination.<br> — <em>Harold A. Johnson (ed.),</em> <em>Heat Transfer, Thermodynamics and Education: Boelter Anniversary Volume</em> (New York: McGraw-Hill, 1964), p. 354.</p></blockquote><p>Later we will see that the relationship between Shannon’s entropy and the pre-existing definition of entropy was more than coincidental, they are deeply intertwined.</p><p>But now let us see how Shannon found definitions for these usually vague terms of “information” and “uncertainty”.</p><p>In Information Theory, the information of an observed state is formally defined as the number of bits needed to communicate that state (at least for a system with equally likely outcomes with powers of two, we’ll see shortly how to generalize this). Here are some examples of information:</p><ul><li>If I flip a fair coin, it will take one bit of information to tell you the outcome: I use a <code>0</code> for head and a <code>1</code> for tails.</li><li>If I roll a fair 8-sided dice, I can represent the outcome with 3 bits: I use <code>000</code> for a 1, <code>001</code> for 2, <code>010</code> for 3, etc.</li></ul><p>The more outcomes a system can have, the more bits (information) it will require to represent its outcome. If a system has $N$ equally likely outcomes, then it will take $\text{log}_2(N)$ bits of information to represent an outcome of that system.</p><p>Entropy is defined as the expected number of bits of information needed to represent the state of a system (this is a lie, but it’s the most useful definition for the moment, we’ll fix it later). So the entropy of a coin is 1 since on average we expect it to take 1 bit of information to represent the outcome of the coin. An 8-sided dice will have an entropy of 3 bits, since we expect it to take an average of 3 bits to represent the outcome.</p><p>It initially seems that entropy is an unnecessary definition since we can just look at how many bits it takes to represent the outcome of our system and use that value, but this is only true when the chance of the outcomes are all equally likely.</p><p>Imagine now that I have a weighted 8-sided dice, so the number 7 comes up $50$% of the time while the rest of the faces come up $\approx 7.14$% of the time. Now, if we are clever, we can reduce the expected number of bits needed to communicate the outcome of the dice. We can decide to represent a 7 with a <code>0</code>, and all the other numbers will be represented with <code>1XXX</code> where the <code>X</code>s are some unique bits. This would mean that $50$% percent of the time we only have to use 1 bit of information to represent the outcome, and the other $50$% of the time we use 4 bits, so the expected number of bits (the entropy of the dice) is 2.5. This is lower than the 3 bits of entropy for the fair 8-sided dice.</p><p>Fortunately, we don’t need to come up with a clever encoding scheme for every possible system, there exists a pattern to how many bits of information it takes to represent a state with probability $p$. We know if $p=0.5$ such as in the case of a coin landing on heads, then it takes 1 bit of information to represent that outcome. If $p=0.125$ such as in the case of a fair 8-sided dice landing on the number 5, it takes 3 bits of information to represent that outcome. If $p=0.5$ such as in the case of our unfair 8-sided dice landing on the number 7, then it takes 1 bit of information, just like the coin, which shows us that all that matters is the probability of the outcome. With this, we can discover an equation for the number of bits of information needed for a state with probability $p$.</p><p>\[I(p) = -\text{log}_2(p)\]</p><p>This value $I$ is usually called <em>information content</em> or <em>surprise</em>, since the lower the probability of a state occurring, the higher the surprise when it does occur.</p><p>When the probability is low, the surprise is high, and when the probability is high, the surprise is low. This is a more general formula then “the number of bits needed” since it allows for states that are exceptionally likely (such as $99$% likely) to have surprise less then 1, which would make less sense if we tried to interpret the value as “the number of needed bits to represent the outcome”.</p><p>And now we can fix our definition of entropy (the lie I told earlier). Entropy is not necessarily the expected number of bits used to represent a system (although it is when you use an optimal encoding scheme), but more generally the entropy is the expected <em>surprise</em> of the system.</p><p>And now we can calculate the entropy of systems like a dice or a coin or any system with known probabilities for its outcomes. The expected surprise (entropy) of a system with $N$ possible outcomes each with probability $p_i$ (all adding up to 1) can be calculated as</p><p>\[\begin{align} \sum_{i=1}^{N} p_i \cdot I(p_i) = - \sum_{i=1}^{N} p_i \cdot \text{log}_2(p_i)\label{shannon_entropy}\tag{Shannon entropy}\\ \end{align}\]</p><p>And notice that if all the $N$ probabilities are the same (so $p_i = \frac{1}{N}$), then the entropy equation can simplify to</p><p>\[- \sum_{i=1}^{N} p_i \cdot \text{log}_2(p_i) \Rightarrow \text{log}_2(N)\]</p><p>Here are some basic examples using $\eqref{shannon_entropy}$.</p><ul><li>The entropy of a fair coin is</li></ul><p>\[- ( 0.5 \cdot \text{log}_2(0.5) + 0.5 \cdot \text{log}_2(0.5)) = \text{log}_2(2) = 1\]</p><ul><li>The entropy of a fair 8-sided dice is</li></ul><p>\[- \sum_{i=1}^{8} 0.125 \cdot \text{log}_2(0.125) = \text{log}_2(8) = 3\]</p><ul><li>The entropy of an unfair 8-sided dice, where the dice lands on one face $99$% of the time and lands on the other faces the remaining $1$% of the time with equal probability (about $0.14$% each), is</li></ul><p>\[- (0.99 \cdot \text{log}_2(0.99) + \sum_{i=1}^{7} 0.0014 \cdot \text{log}_2(0.0014)) = 0.10886668511648723\]</p><p>Hopefully it is a bit more intuitive now that entropy represents uncertainty. An 8-sided dice would have higher entropy than a coin since we are more uncertain about the outcome of the 8-sided dice than we are about the coin (8 equally likely outcomes are more uncertain than only 2 equally likely outcomes). But a highly unfair 8-sided dice has less entropy than even a coin since we have very high certainty about the outcome of the unfair dice. Now we have an actual equation to quantify that uncertainty (entropy) about a system.</p><p>It is not clear right now how this definition of entropy has anything to do with disorder, heat, or time, but this idea of entropy as uncertainty is fundamental to understanding the entropy of the universe which we will explore shortly. For reference, this definition of entropy is called Shannon entropy.</p><p>We will move on now, but I recommend looking further into Information Theory. It has many important direct implications for data compression, error correction, cryptography, and even linguistics, and touches nearly any field that deals with uncertainty, signals, or knowledge.</p><h2 id="physical-entropy"><span>Physical Entropy</span><a href="#physical-entropy"><i></i></a></h2><p>Now we will see entropy from a very different lens, that of Statistical Mechanics. We begin with the tried-and-true introduction to entropy which every student is given.</p><h3 id="balls-in-a-box"><span>Balls in a box</span><a href="#balls-in-a-box"><i></i></a></h3><p>I shall give you a box with 10 balls in it, $p_0$ through $p_9$, and we will count how many balls are on the left side of the box and on the right side of the box. Assume every ball is equally likely to be on either side. Immediately we can see it is highly unlikely that we count all the balls are on the left side of the box, and more likely that we count an equal number of balls on each side. Why is that?</p><p>Well, there is only one state in which we count all the balls on the left, and that is if every ball is on the left (truly astounding, but stay with me). But there are many ways in which the box is balanced: We could have $p_0$ through $p_4$ one side and the rest on the other, or the same groups but flipped from left to right, or we could have all the even balls on one side and the odd on the other, or again flipped, or any of the other many possible combinations.</p><p>This box is a system that we can measure the entropy of, at least once I tell you how many balls are counted on each side. It can take a moment to see, but imagine the box with our left and right counts as a system where the outcome will be finding out where all the individual balls are in the box, similar to rolling a dice and seeing which face it lands on.</p><p>This would mean that the box where we count all the balls on the left side only has one possible outcome: all the balls are on the left side. We would take this to mean that this system has $0$ entropy (no expected surprise) since we already know where we will find each individual ball.</p><p>The box with balanced sides (5 on each) has many possible equally likely outcomes, and in fact, we can count them. A famous equation in combinatorics is the N-choose-k equation, which calculates exactly this scenario. It tells us that there are 252 possible ways in which we can place 5 balls on each side. The entropy for this system would then be $- \sum_{i=1}^{252} \frac{1}{252} \cdot \text{log}_2(\frac{1}{252}) = \text{log}_2(252) = 7.9772799235$. This is the same as calculating the entropy of a 252-sided dice.</p><p>And if we were to increase the number of balls, the entropy of the balanced box would increase since there would then be even more possible combinations that could make up a balanced box.</p><p>We should interpret these results as: The larger the number of ways there are to satisfy the large-scale measurement (counting the number of balls on each side), the higher the entropy of the system. When all the balls are on the left, there is only one way to satisfy that measurement and so it has a low entropy. When there are many ways to balance it on both sides, it has high entropy.</p><p>Here we see 1000 balls bouncing around in a box. They will all start on the left, so the box would have 0 entropy, but once the balls start crossing to the right and changing the count on each side, the entropy will increase.</p><p><a href="https://jasonfantl.com/assets/img/posts/Entropy/2_cell_box.gif"><img data-src="/assets/img/posts/Entropy/2_cell_box.gif" alt=" balls in a box with its entropy " width="300" data-proofer-ignore=""></a></p><p>In Statistical Mechanics, the formal term for the large-scale measurement is the <em>macrostate</em>, and the specific states that can satisfy that measurement are <em>microstates</em>. We would call the measurement of the number of balls on each side of the box the macrostate, and the different combinations of positions of individual balls the microstates. So rephrasing the above: There is only one microstate representing the macrostate of all balls being counted on one side, and there are many microstates representing the macrostate of a balanced box.</p><p>But why did we decide to measure the number of balls on the left and right? We could have measured a different macrostate, and the entropy would be different.</p><h3 id="macrostates"><span>Macrostates</span><a href="#macrostates"><i></i></a></h3><p>Imagine instead of selecting the left and right halves of the box to count the number of balls, we instead count how many balls are in each pixel of the box. In this scenario, the entropy would almost always be maximized, as the balls rarely share a pixel. Even if all the balls were on the left side of the box, they would likely still each occupy a different pixel, and the measured entropy would be the same as if the balls were evenly distributed in the box.</p><p>If we use an expensive instrument to measure the box and track the balls with high precision, then the entropy would rarely change and would be very high. If we instead use an inexpensive instrument that can only tell if a ball is on the left or right of the box, then the entropy will be low and could very easily fluctuate if some of the balls temporarily end up on the same side of the box.</p><p>Let’s run exactly the same simulation of 1000 balls in the box again, still starting with the balls on the left. But, this time we count how many balls are in each cell in a 50x50 grid, as opposed to the previous two cells (the left and right cells). The entropy will be high since there are many microstates that represent a bunch of cells with only 1 ball in it, and the entropy won’t change much since two balls rarely share the same cell. Recall that if two balls share the same cell, the count would go up, and there are fewer microstates that satisfy a cell with a count of 2 compared to two cells with a count of 1 in each.</p><p><a href="https://jasonfantl.com/assets/img/posts/Entropy/50_cell_box.gif"><img data-src="/assets/img/posts/Entropy/50_cell_box.gif" alt=" balls in a box with its entropy " width="300" data-proofer-ignore=""></a></p><p>Entropy is not intrinsic to the physical system alone, but rather to our description of it as well — i.e., the macrostate we’re measuring, and the resolution at which we observe it.</p><p>This process of measuring a lower-resolution version of our system (like counting how many balls are on the left or right side of a box) is called <em>coarse-graining</em>.</p><p>How we choose/measure the macrostate, that is, how we coarse-grain the system, is dependent on the problem we are solving.</p><ul><li>Imagine you have a box of gas (like our balls in a box, but at the scale of $10^{25}$ balls in the box), and we place a temperature-reader on the left and right side of the box. This gives us a macrostate of two counts of the average ball speed on the left and right sides of the box. We can then calculate the entropy by comparing when the temperature-readers are equal to when they are different by $T$ degrees. Once we learn how time and entropy interact, we will use this model to show that the two temperature-readers are expected to converge to the same value over time.</li><li>Imagine you sequence the genome of many different people in a population, you could choose many different macrostates based on what you care about. You could count how many of each nucleotide there are in all the sequences, allowing you to quantify how variable the four nucleotides are in DNA. You could calculate the entropy of every individual position in the DNA sequence by counting how many nucleotide types are used in that position across the population, allowing you to identify portions of DNA that are constant across individuals or vary across individuals.</li></ul><p>How you choose to measure the macrostate can come in many forms for the same system, depending on what you are capable of measuring and/or what you care about measuring.</p><p>But once we have a macrostate, we need a way to identify all the microstates and assign probabilities to them.</p><h3 id="microstates"><span>Microstates</span><a href="#microstates"><i></i></a></h3><p>When we were looking at the positions of balls in a box in equally sized cells, it was easy to see that every ball was equally likely to be in any of the cells, so each microstate was equally likely. This made calculating the entropy very simple, we just used the simplified version of $\eqref{shannon_entropy}$ to find that for $W$ microstates that satisfy a given macrostate, the entropy of the system is $\text{log}_{2}(W)$. It isn’t too hard to extend this idea to microstates that are not equally likely.</p><p>For example, let’s calculate the entropy of a box with 5 balls on the left and 5 balls on the right, but we replace one of the balls in the box with a metal ball that is pulled by a magnet to the left. In this case, the probability of each microstate is no longer equally likely. If we assume there is an $80$% chance that the metal ball is on the left side instead of the right side, then the entropy of the box can be calculated as follows: For all of the 252 microstates, 126 of them have the metal ball on the left, which has a $0.8$ chance of being true, and the other 126 have the metal ball on the right with a $0.2$ chance. This means using the $\eqref{shannon_entropy}$ we get an entropy of</p><p>\[- \sum_{i=1}^{126} \frac{0.2}{126} \cdot \text{log}_2(\frac{0.2}{126}) - \sum_{i=1}^{126} \frac{0.8}{126} \cdot \text{log}_2(\frac{0.8}{126}) = 7.69921\]</p><p>This is a little less than the box with normal balls which had $7.9772799235$ entropy. This is exactly what we should expect, we are a bit more certain about the outcome of this system since we knew where one of the balls was more likely to be.</p><p>But this raises a subtle question: why did we choose this particular set of microstates? For example, if we have the macrostate of 5 balls on the left and 5 balls on the right, but we decide to use the 50x50 grid of cells to describe the microstates, then there are far more microstates that satisfy the macrostate compared to when we were using the 2x1 grid of left and right.</p><p>Let’s calculate the entropy for those two examples. Keep in mind they both have the same macrostate: 5 balls on the left and 5 balls on the right.</p><ul><li>If we choose to use the microstates of looking at the position of individual balls between two cells splitting the box in half, then we can use n-choose-k to calculate that there are 252 possible combinations of balls across the two cells. This gives us an entropy of $\text{log}_2(252) = 7.977279923$.</li><li>If we choose to use the microstates of looking at the position of individual balls between 50x50 (2500) cells splitting the box into a grid, then we can use n-choose-k to calculate that there are 252 possible combinations of balls across the two halves of the box, for each of which every ball could be in any of 50x25 (1250) cells. This gives us an entropy of $\text{log}_2(252*1250^{10}) = 110.8544037$.</li></ul><p>This result lines up very well with our Information-theoretic understanding of entropy: when we allow more microstates to represent the same macrostate, we are more uncertain about the microstate our system is in. But this result does raise some concerns.</p><p>If different microstates give different entropy, how do we choose the right microstates for our problem? Unlike the macrostate, this decision of which microstates to use is not determined by our instruments or the scope of the problem, it has to be determined by the person making the calculation. Often for physical systems people will use the set of microstates that capture all the relevant information related to the macrostate. For example, if our macrostate is about balls on the left or right side of a box, then we probably don’t care about the ball’s velocity or mass or anything else but the ball position.</p><p>Another concern is that it feels wrong that the same physical system with the same macrostate can have different entropies depending on the microstate representation we use. Usually, we expect physical systems to have invariant measurements regardless of the internal representation we decide to use for our measurement. But this is incorrect for entropy. We need to recall that entropy is the uncertainty of a system and that the definition of entropy is completely dependent on what we are uncertain about, which for physical systems are the microstates. This would be similar to someone asking “How many parts make up that machine?”, to which we should respond “How do you define a ‘part’?”. When we ask “What is the entropy of this macrostate?”, we need to respond with “What microstates are we using?”.</p><p>With all that said, there is some small truth to what our intuition is telling us, although it doesn’t apply to the general case. While the entropy of the system changes when we change the microstates, the relative differences in entropy across macrostates will be equal <em>if</em> the new microstates uniformly multiply the old microstates. That is, if each original microstate is split into the same number of refined microstates, then the entropy of every macrostate increases by a constant. We’re getting lost in the terminology, an example will demonstrate.</p><p>Let us again take the 10 balls in a box, and we will calculate the entropy of the system for a few different macrostates and microstate representations. We indicate the number of balls on each side of the box with <code>(L, R)</code>, where <code>L</code> is the number of balls on the left and <code>R</code> is the number of balls on the right. Then we calculate the entropy using the microstate of a 2x1 grid of cells (just the left and right halves of the box) and for the 50x50 grid of cells.</p><div><table><thead><tr><th>&nbsp;</th><th>(10,0)</th><th>(9,1)</th><th>(8,2)</th><th>(7,3)</th><th>(6,4)</th><th>(5,5)</th><th>(4,6)</th><th>(3,7)</th><th>(2,8)</th><th>(1,9)</th><th>(0,10)</th></tr></thead><tbody><tr><td>2x1</td><td>0.00000</td><td>3.32193</td><td>5.49185</td><td>6.90689</td><td>7.71425</td><td>7.97728</td><td>7.71425</td><td>6.90689</td><td>5.49185</td><td>3.32193</td><td>0.00000</td></tr><tr><td>50x50</td><td>102.87712</td><td>106.19905</td><td>108.36898</td><td>109.78401</td><td>110.59137</td><td>110.85440</td><td>110.59137</td><td>109.78401</td><td>108.36898</td><td>106.19905</td><td>102.87712</td></tr></tbody></table></div><p>And if we look, we will see that the entropy in the 50x50 grid microstate values is just the 2x1 grid values plus a constant. The relative entropy in both cases would be identical. This is even more clear if we mathematically show how the entropy is calculated. For the 2x1 grid we use the equation $\text{log}_2({10 \choose L})$, and for the 50x50 grid we use $\text{log}_2(1250^{10} {10 \choose L}) = \text{log}_2(1250^{10}) + \text{log}_2({10 \choose L})$. Mathematically we can see that it is the same as the entropy of the 2x1 grid offset by $\text{log}_2(1250^{10})$.</p><p>You can imagine if we added another dimension along the microstates that we would increase the entropy again by a constant. For example, if each of the 10 balls could be one of 3 colors, then the number of microstates would grow by a factor of $3^{10}$, and so the entropy of the whole system would increase by $\text{log}_2(3^{10})$.</p><p>Our intuition was correct when we used different microstates that are multiples of each other, but that intuition fails if the microstates are not so neatly multiples of each other. An easy example of this is if we represent the left side of the box as one cell and the right as a 50x25 grid of cells, then the entropy looks very different. Below is the table again, but with the added row of our non-homogenous microstates. An example of how we calculate the entropy of macrostate $(3, 7)$ is: there are 120 equally likely ways to place 3 balls on the left and 7 balls on the right, but the balls on the right can also be in $1250^7$ different states, so the entropy is $\text{log}_2(120 \cdot 1250^7) = 78.920877252$.</p><div><table><thead><tr><th>&nbsp;</th><th>(10,0)</th><th>(9,1)</th><th>(8,2)</th><th>(7,3)</th><th>(6,4)</th><th>(5,5)</th><th>(4,6)</th><th>(3,7)</th><th>(2,8)</th><th>(1,9)</th><th>(0,10)</th></tr></thead><tbody><tr><td>2x1</td><td>0.00000</td><td>3.32193</td><td>5.49185</td><td>6.90689</td><td>7.71425</td><td>7.97728</td><td>7.71425</td><td>6.90689</td><td>5.49185</td><td>3.32193</td><td>0.00000</td></tr><tr><td>50x50</td><td>102.87712</td><td>106.19905</td><td>108.36898</td><td>109.78401</td><td>110.59137</td><td>110.85440</td><td>110.59137</td><td>109.78401</td><td>108.36898</td><td>106.19905</td><td>102.87712</td></tr><tr><td>mixed</td><td>0.00000</td><td>13.60964</td><td>26.06728</td><td>37.77003</td><td>48.86510</td><td>59.41584</td><td>69.44052</td><td>78.92088</td><td>87.79355</td><td>95.91134</td><td>102.87712</td></tr></tbody></table></div><p>A funny thing to note is that when all the balls are on the left, the entropy is zero, but when all the balls are on the right, the entropy is maximized. And again, hopefully, this makes sense from our understanding of entropy, that it measures uncertainty relative to our microstates. If we know all the balls are on the left, then we know they must be in the single left cell, so no uncertainty. If we know the balls are all on the right, then they could be in any of $1250^{10}$ microstates, so high uncertainty.</p><p>Clearly, we need to be careful and aware of what microstates we are choosing when measuring the entropy of a system. Fortunately, for most physical systems we use the standard microstates of a uniform grid of positions and momentums of the balls (particles) in the system. Another standard microstate to use is the continuous space of position and momentum.</p><h3 id="continuous-microstates"><span>Continuous Microstates</span><a href="#continuous-microstates"><i></i></a></h3><p>So far, we’ve looked at discrete sets of microstates — such as balls in cells. But in physical systems, microstates are often continuous: positions and momenta can vary over a continuum. How do we compute entropy in this setting? This is not related to the rest of the explanation, but it is an interesting tangent to explore.</p><p>Let’s return to our 10 balls in a 2D box. If each ball can occupy any position in the square, then the microstate of the system is a point in a $20$-dimensional space (2 dimensions per ball). The number of possible microstates is infinite — and each individual one has infinitesimal probability.</p><p>In this setting, we use a probability density function $\rho(x)$, and entropy becomes a continuous integral:</p><p>\[S = - \int_X \rho(x) \log_2 \rho(x) \, dx\]</p><p>This is called differential entropy. It generalizes Shannon entropy to continuous systems, though it has some subtleties — it can be negative, and it’s not invariant under coordinate transformations.</p><p>If the density is uniform, say $\rho(x) = \frac{1}{V}$ over a region of volume $V$, then the entropy becomes:</p><p>\[S = - \int_X \frac{1}{V} \log_2 \left( \frac{1}{V} \right) dx = \log_2(V)\]</p><p>So entropy still grows with the logarithm of the accessible state volume, just as in the discrete case.</p><p>This formalism is particularly natural in quantum mechanics, where the wavefunction $\psi(x)$ defines a probability density $\rho(x) = |\psi(x)|^2$. Consider a 1D Gaussian wavefunction:</p><p>\[\psi(x) = \left( \frac{1}{\pi \sigma^2} \right)^{1/4} e^{-x^2 / (2 \sigma^2)}\]</p><p>Its entropy (in bits) is:</p><p>\[S = - \int_{-\infty}^{\infty} \rho(x) \log_2 \rho(x) \, dx = \frac{1}{2} \log_2(2 \pi e \sigma^2)\]</p><p>This shows that wider distributions have higher entropy, as expected: a more spread-out wavefunction indicates more uncertainty in the particle’s location.</p><p>For instance:</p><ul><li>If $\sigma = 1$, then $S \approx 2.047$</li><li>If $\sigma = 3$, then $S \approx 3.600$</li></ul><p>Which again should make sense: When we are less certain about a system, like where a particle will be when measured, the more entropy it has.</p><p>And a quick issue to address: If the state space is unbounded, like momentum in classical mechanics, then the entropy can diverge. This isn’t a problem in practice because physical systems typically have probability distributions (like Gaussians) that decay quickly enough at infinity to keep the entropy finite. When that’s not the case, we either limit the system to a finite region or focus on entropy differences, which remain well-defined even when absolute entropy diverges.</p><p>But let’s get back to our main topic, and we’ll get back into it with a historical overview.</p><h3 id="standard-usage-of-entropy"><span>Standard Usage of Entropy</span><a href="#standard-usage-of-entropy"><i></i></a></h3><p>Eighty years before Claude Shannon developed Information Theory, <a href="https://en.wikipedia.org/wiki/Ludwig_Boltzmann">Ludwig Boltzmann</a> formulated a statistical definition of entropy for an ideal gas. He proposed that the entropy $S$ of a system is proportional to the logarithm of the number of microstates $W$ consistent with a given macrostate:</p><p>\[\begin{align} S = k_{B} \ln(W) \label{boltzmann_entropy}\tag{Boltzmann entropy} \end{align}\]</p><p>This equation should look familiar: it’s the equal-probability special case of the Shannon entropy we’ve been using, just with a change of base (from $\log_2$ to $\ln$) and a scaling factor $k_B$ (Boltzmann’s constant). The connection between Boltzmann’s statistical mechanics and Shannon’s information theory is more than historical coincidence—both quantify uncertainty, whether in physical states or messages.</p><p>A few years later, <a href="https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs">Josiah Willard Gibbs</a> generalized Boltzmann’s definition to cases where microstates are not equally likely. His formulation remains the standard definition of entropy in modern physics:</p><p>\[\begin{align} S = -k_B \sum_{i} p_i \ln(p_i) \label{gibbs_entropy}\tag{Gibbs entropy} \end{align}\]</p><p>This is formally identical to Shannon entropy, again differing only in logarithm base and physical units. But Gibbs’s generalization was a profound leap: it enabled thermodynamics to describe systems in contact with heat baths, particle reservoirs, and other environments where probability distributions over microstates are non-uniform. This made entropy applicable far beyond ideal gases—covering chemical reactions, phase transitions, and statistical ensembles of all kinds.</p><p>Now that we have a formal understanding of entropy with some historical background, let’s try to understand how entropy relates to our universe and in particular to time.</p><h3 id="time"><span>Time</span><a href="#time"><i></i></a></h3><p>How does time play a role in all of this?</p><p>When you drop a spot of milk into tea, it always spreads and mixes, and yet you never see the reverse where the milk molecules spontaneously separate and return to a neat droplet. When ocean waves crash into the shore, the spray and foam disperse, but we never see that chaos reassemble into a coherent wave that launches back into the sea. These examples are drawn from this <a href="https://www.youtube.com/watch?v=ROrovyJXSnM">lecture on entropy</a> by Richard Feynman. If you were shown a reversed video of these events, you’d immediately recognize something was off. This sounds obvious at first, but it actually isn’t clear this should be true if we just look at the laws of physics. All the known laws of physics are time-reversible (the wave function collapse seems to be debatable), which just means that they <em>do</em> look the same playing forward and backward. The individual molecules all obey these time-reversible laws, and yet the cup of tea gets murky from the milk always mixing in.</p><p>This highlights a fundamental paradox: the microscopic laws of physics are time-reversible, but the macroscopic world is not. If you took a video of two atoms bouncing off each other and played it backward, it would still look physically valid, but play a video of milk mixing into coffee backward, and it looks obviously wrong.</p><p>We want to build a simplified model of time in a way that reflects both the time-reversibility of microscopic laws and the time-asymmetry of macroscopic behavior. Let’s imagine the complete state of a physical system, like a box of particles, as a single point in a high-dimensional space called phase space, with each dimension corresponding to a particle’s position and momentum. As time evolves, the system traces out a continuous trajectory through this space.</p><p>The laws of physics, such as Newton’s equations, Hamiltonian mechanics, or Schrödinger’s equation, all govern this trajectory. They are deterministic and time-reversible. That means if you reverse the momenta of all particles at any moment, the system will retrace its path backward through state space.</p><p>So far everything is time-reversible, including this view of how the universe moves through time. But we will see that even in this toy model, time appears to have a preferred direction, an <em>arrow of time</em>.</p><p>The key lies in coarse-graining. When we observe the world, we don’t see every microscopic detail. Instead, we measure macrostates: aggregate properties like temperature, pressure, position of an object, or color distribution in a cup of tea. Each macrostate corresponds to many underlying microstates — and not all macrostates are created equal.</p><p>For example, consider a box sliding across the floor and coming to rest due to friction. At the microscopic level, the system is just particles exchanging momentum, and all time-reversible. But we certainly would not call this action time-reversible, we never see a box spontaneously start speeding up from stand-still. But, if we took the moment after the box comes to a rest due to friction, and you reversed the velocities of all the particles (including those in the floor that absorbed the box’s kinetic energy as heat), the box <em>would</em> spontaneously start moving and slide back to its original position. This would obey Newton’s laws, but it’s astronomically unlikely. Why?</p><p>The number of microstates where the energy is spread out as heat (the box is at rest, and the molecules in the floor are jiggling) vastly outnumber the microstates where all that energy is coordinated to move the box. The stand-still macrostate has high entropy while the spontaneous-movement macrostate has low entropy. When the system evolves randomly or deterministically from low entropy, it is overwhelmingly likely to move toward higher entropy simply because there are more such microstates.</p><p>If you had perfect knowledge of all particles in the universe (i.e., you lived at the level of microstates), time wouldn’t seem to have a direction. But from the perspective of a coarse-grained observer, like us, entropy tends to increase. And that’s why a movie of tea mixing looks natural, but the reverse looks fake. At the level of physical laws, both are valid. But one is typical, and one is astronomically rare, all because we coarse-grained.</p><p>To drive the point home, let’s again look at the balls in a box. We’ll define macrostates by dividing the box into a grid of cells and counting how many balls are in each bin.</p><p>Now suppose the balls move via random small jitters (our toy model of microscopic dynamics). Over time, the system will naturally tend to explore the most probable macrostates, as the most probable macrostates have far more microstates for you to wander into. That is, entropy increases over time, not because of any fundamental irreversibility in the laws, but because high-entropy macrostates are far more typical.</p><p>If we started the simulation with all the balls packed on the left, that’s a very specific (low entropy) macrostate. As they spread out, the number of compatible microstates grows, and so does the entropy.</p><p>This leads to a crucial realization: Entropy increases because we started in a low-entropy state. This is often called the <a href="https://en.wikipedia.org/wiki/Past_hypothesis">Past Hypothesis</a>, the postulate that the universe began in an extremely low-entropy state. Given that, the Second Law of Thermodynamics follows naturally. The arrow of time emerges not from the dynamics themselves, but from the statistical unlikelihood of reversing them after coarse-graining, and the fact that we began in a low-entropy state.</p><p>You could imagine once a system reaches near-maximum entropy that it no longer looks time-irreversible. The entropy of such a system would <a href="https://en.wikipedia.org/wiki/Fluctuation_theorem">fluctuate a tiny bit</a> since entropy is an inherently statistical measure, but they would be small enough not to notice. For example, while it is clear when a video of milk being poured into tea (a low-entropy macrostate) is playing forward as opposed to backward, you couldn’t tell if a video of already-combined milk and tea (a high-entropy macrostate) being swirled around is playing forward or backward.</p><p>While there are tiny fluctuations in entropy, they are not enough to explain the large-scale phenomena that sometimes seem to violate this principle that we just established of entropy always increasing with time.</p><h3 id="violations-of-the-second-law"><span>Violations of the Second Law?</span><a href="#violations-of-the-second-law"><i></i></a></h3><p>Some real-world examples seem to contradict the claim that entropy always increases. For instance, oil and water separate after mixing, dust clumps into stars and planets, and we build machines like filters and refrigerators that separate mixed substances. Aren’t these violations?</p><p>The issue is we have only been considering the position of molecules, while physical systems have many different properties which allow for more microstates. For example, if we start considering both the position and velocity of balls in a box, then the entropy can be high even while all the balls are on the left side of the box since every ball could have a different velocity. If the balls were all on the left <em>and</em> the velocities were all the same, then the entropy would be low. Once we consider velocity as well, entropy can increase both from more spread out positions and more spread out velocities.</p><p>When water and oil separate, the positions of the molecules separate into top and bottom, which appears to decrease positional entropy. However, this separation actually increases the total entropy of the system. Why? Water molecules strongly prefer to form hydrogen bonds with other water molecules rather than interact with oil molecules. When water molecules are forced to be near oil molecules in a mixed state, they must adopt more constrained arrangements to minimize unfavorable interactions, reducing the number of available microstates. When water and oil separate, water molecules can interact freely with other water molecules in more configurations, and oil molecules can interact with other oil molecules more freely. This increase in available microstates for molecular arrangements and interactions more than compensates for the decrease in positional mixing entropy. So, while the entropy decreases if we only consider the general positions of molecules (mixed versus separated), the total entropy increases when we account for all the molecular interactions, orientations, and local arrangements. This demonstrates why we need to consider all properties of a system when calculating its entropy.</p><p>When stars or planets form together from dust particles floating around in space and clump together from gravity, it would seem that even when we consider position and velocity of the particles that the entropy might be decreasing. Even though the particles speed up to clump together, they slow down after they collide, seemingly decreasing entropy. This is because we are again failing to consider the entire system. When particles collide with each other, their speed decreases a bit by turning that kinetic energy into radiation, causing photons to get sent out into space. If we considered a system where radiation isn’t allowed, then the kinetic energy would just get transferred from one particle to another through changes in velocity, and the entropy of the system would still be increasing because of the faster velocities. Once we start considering the entropy of the position, velocity, and <em>all</em> particles in a system, we can consider <em>all</em> the microstates that are equally likely and calculate the correct entropy.</p><p>Similarly, once we consider the entire system around a refrigerator, the decrease in entropy disappears. The entropy from the power generated to run the refrigerator and the heat moved from the inside to the outside of the refrigerator will offset the decrease in entropy caused by cooling the inside of the refrigerator. Local decreases in entropy <em>can</em> be generated, as long as the entropy of the entire system is still increasing.</p><p>Ensure that the entire system is being considered when analyzing the entropy of a system, with the position, velocity, other interactions of particles, that all particles are included, and that the entire system is actually being analyzed.</p><h3 id="disorder"><span>Disorder</span><a href="#disorder"><i></i></a></h3><p>Entropy is sometimes described as “disorder,” but this analogy is imprecise and often misleading. In statistical mechanics, entropy has a rigorous definition: it quantifies the number of microstates compatible with a given macrostate. That is, entropy measures our uncertainty about the exact microscopic configuration of a system given some coarse-grained, macroscopic description.</p><p>So where does the idea of “disorder” come from?</p><p>Empirically, macrostates we label as “disordered” often correspond to a vastly larger number of microstates than those we consider “ordered”. For example, in a child’s room, there are many more configurations where toys are scattered randomly than ones where everything is neatly shelved. Since the scattered room corresponds to more microstates, it has higher entropy.</p><p>But this connection between entropy and disorder is not fundamental. The problem is that “disorder” is subjective—it depends on human perception, context, and labeling. For instance, in our earlier example of 1000 balls bouncing around a box, a perfectly uniform grid of balls would have high entropy due to the huge number of possible microstates realizing it. And yet to a human observer, such a grid might appear highly “ordered.”</p><p>The key point is: entropy is objective and well-defined given a macrostate and a set of microstates, while “disorder” is a human-centric heuristic concept that sometimes, but not always, tracks entropy. Relying on “disorder” to explain entropy risks confusion, especially in systems where visual symmetry or regularity masks the underlying statistical structure.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion"><i></i></a></h2><p>So here are some thoughts in regard to some common statements made about entropy:</p><ul><li>Entropy is a measure of disorder.<ul><li>“disorder” is a subjective term for states of a system that humans don’t find useful/nice, and usually has much higher entropy than the “ordered” macrostate that humans create. Because of this, when entropy increases, it is more likely that we end up in disordered state, although not guaranteed.</li></ul></li><li>Entropy always increases in a closed system.<ul><li>This is a statistical statement that for all practical purposes is true, but is not guaranteed and can fail when you look at very small isolated systems or measure down to the smallest details of a system. It also assumes you started in a low-entropy state, giving your system space to increase in entropy. This has the neat implication that since our universe has been observed to be increasing in entropy, it must have begun in a low-entropy state.</li></ul></li><li>Heat flows from hot to cold because of entropy.<ul><li>Heat flows from hot to cold because the number of ways in which the system can be non-uniform in temperature is much lower than the number of ways it can be uniform in temperature, and so as the system “randomly” moves to new states, it will statistically end up in states that are more uniform.</li></ul></li><li>Entropy is the only time-irreversible law of physics.<ul><li>All the fundamental laws of physics are time-reversible, but by coarse-graining and starting from a lower-entropy state, a system will statistically move to a higher-entropy state. This means if a system is already in a near-maximum entropy state (either because of its configuration or because of the choice for coarse-graining) or we don’t coarse-grain, then entropy will not look time-irreversible.</li></ul></li></ul><p>And here is some further reading, all of which I found supremely helpful in learning about entropy.</p><ul><li><a href="https://www.youtube.com/watch?v=ROrovyJXSnM">Lecture on entropy by Richard Feynman</a></li><li><a href="https://scholar.harvard.edu/files/schwartz/files/6-entropy.pdf">Lecture notes on entropy from the Statistical Mechanics course at Harvard taught by Matthew Schwartz</a></li><li><a href="https://math.ucr.edu/home/baez/what_is_entropy.pdf">A both friendly and rigorous textbook on entropy by John C. Baez</a></li><li><a href="https://www.youtube.com/watch?v=VCXqELB3UPg">A youtube video on entropy using actual balls bouncing in a box</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Harvard's response to federal government letter demanding changes (1218 pts)]]></title>
            <link>https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/</link>
            <guid>43684536</guid>
            <pubDate>Mon, 14 Apr 2025 18:28:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/">https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/</a>, See on <a href="https://news.ycombinator.com/item?id=43684536">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

			<div>
				
<div><p>Dear Members of the Harvard Community,</p><p>&nbsp;For three-quarters of a century, the federal government has awarded grants and contracts to Harvard and other universities to help pay for work that, along with investments by the universities themselves, has led to groundbreaking innovations across a wide range of medical, engineering, and scientific fields. These innovations have made countless people in our country and throughout the world healthier and safer. In recent weeks, the federal government has threatened its partnerships with several universities, including Harvard, over accusations of antisemitism on our campuses. These partnerships are among the most productive and beneficial in American history. New frontiers beckon us with the prospect of life-changing advances—from treatments for diseases such as Alzheimer’s, Parkinson’s, and diabetes, to breakthroughs in artificial intelligence, quantum science and engineering, and numerous other areas of possibility. For the government to retreat from these partnerships now risks not only the health and well-being of millions of individuals but also the economic security and vitality of our nation.</p><p>&nbsp;Late Friday night, the administration issued an updated and expanded list of demands, warning that Harvard must comply if we intend to “maintain [our] financial relationship with the federal government.” It makes clear that the intention is not to work with us to address antisemitism in a cooperative and constructive manner. Although some of the demands outlined by the government are aimed at combating antisemitism, the majority represent direct governmental regulation of the “intellectual conditions” at Harvard.</p><p>&nbsp;I encourage you to&nbsp;<a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf" target="_blank" rel="noreferrer noopener">read the letter</a>&nbsp;to gain a fuller understanding of the unprecedented demands being made by the federal government to control the Harvard community. They include requirements to “audit” the viewpoints of our student body, faculty, staff, and to “reduc[e] the power” of certain students, faculty, and administrators targeted because of their ideological views. We have informed the administration through our legal counsel that&nbsp;<a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Harvard-Response-2025-04-14.pdf" target="_blank" rel="noreferrer noopener">we will not accept their proposed agreement</a>. The University will not surrender its independence or relinquish its constitutional rights.</p><p>&nbsp;The administration’s prescription goes beyond the power of the federal government. It violates Harvard’s First Amendment rights and exceeds the statutory limits of the government’s authority under Title VI. And it threatens our values as a private institution devoted to the pursuit, production, and dissemination of knowledge. No government—regardless of which party is in power—should dictate what private universities can teach, whom they can admit and hire, and which areas of study and inquiry they can pursue.</p><p>&nbsp;Our motto—Veritas, or truth—guides us as we navigate the challenging path ahead. Seeking truth is a journey without end. It requires us to be open to new information and different perspectives, to subject our beliefs to ongoing scrutiny, and to be ready to change our minds. It compels us to take up the difficult work of acknowledging our flaws so that we might realize the full promise of the University, especially when that promise is threatened.</p><p>&nbsp;We have made it abundantly clear that we do not take lightly our moral duty to fight antisemitism. Over the past fifteen months, we have taken many steps to address antisemitism on our campus. We plan to do much more. As we defend Harvard, we will continue to:&nbsp;</p></div>



<ul>
<li>nurture a thriving culture of open inquiry on our campus; develop the tools, skills, and practices needed to engage constructively with one another; and broaden the intellectual and viewpoint diversity within our community;&nbsp;</li>



<li>affirm the rights and responsibilities we share; respect free speech and dissent while also ensuring that protest occurs in a time, place, and manner that does not interfere with teaching, learning, and research; and enhance the consistency and fairness of disciplinary processes; and&nbsp;</li>



<li>work together to find ways, consistent with law, to foster and support a vibrant community that exemplifies, respects, and embraces difference. As we do, we will also continue to comply with&nbsp;<em>Students For Fair Admissions v. Harvard</em>, which ruled that Title VI of the Civil Rights Act makes it unlawful for universities to make decisions “on the basis of race.”&nbsp;</li>
</ul>



<div><p>These ends will not be achieved by assertions of power, unmoored from the law, to control teaching and learning at Harvard and to dictate how we operate. The work of addressing our shortcomings, fulfilling our commitments, and embodying our values is ours to define and undertake as a community. Freedom of thought and inquiry, along with the government’s longstanding commitment to respect and protect it, has enabled universities to contribute in vital ways to a free society and to healthier, more prosperous lives for people everywhere. All of us share a stake in safeguarding that freedom. We proceed now, as always, with the conviction that the fearless and unfettered pursuit of truth liberates humanity—and with faith in the enduring promise that America’s colleges and universities hold for our country and our world.</p><p>&nbsp;Sincerely,<br>Alan M. Garber</p></div>
			</div>

			

			
		</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Federal Government's letter to Harvard demanding changes [pdf] (150 pts)]]></title>
            <link>https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf</link>
            <guid>43684386</guid>
            <pubDate>Mon, 14 Apr 2025 18:13:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf">https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=43684386">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why is there no P2P streaming protocol like BitTorrent? (127 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43684286</link>
            <guid>43684286</guid>
            <pubDate>Mon, 14 Apr 2025 18:04:07 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43684286">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="43689896"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43689896" href="https://news.ycombinator.com/vote?id=43689896&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Part of the reason bit torrent works really well is that the file is downloaded in random order. It lets everyone cooperate, while still being robust to bad peers, bad network connections, churn etc.</p><p>If you want live high quality streaming, a lot of reasons bit torrent works so well goes away.</p><p>Latency matters. In bit torrent if the peer goes away, no big deal, just try again in 5 minutes with another peer, you are downloading in random order, who cares if one piecs is delayed 5 minutes. In a live stream your app is broken if it cuts out for 5 minutes.</p><p>In bit torrent, everyone can divide the work - clients try to download the part of the file the least number of people have, quickly rare parts of the file spread everywhere. In streaming everyone needs the same piece at the same time.</p><p>Bit torrent punishes people who dont contribute by deprioritizing sending stuff to peers that freeride. It can do this on the individual level. In a p2p streaming setup, you probably have some peers getting the feed, and then sending it to other peers. The relationship isnt reciperocal so its harder to punish freeriders as you can't at the local level know if the peer you are sending data to is pushing data to the other nodes it is supposed to or not.</p><p>I'm sure some of these have work arounds, but they are hard problems that aren't really satisfactorily solved</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690651"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690651" href="https://news.ycombinator.com/vote?id=43690651&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>This comments on why bittorrent <i>as is</i> isn't used for live streaming, not why P2P shouldn't be used for live streaming</p><p>&gt; Latency matters. In bit torrent if the peer goes away, no big deal, just try again in 5 minutes with another peer, you are downloading in random order, who cares if one piecs is delayed 5 minutes. In a live stream your app is broken if it cuts out for 5 minutes.</p><p>First of all, BitTorrent clients do not download in random order or wait 5 minutes. They usually download the rarest block first, but can do whatever they want, whenever they want.</p><p>Second, standard HLS sets a nominal segment size of 6 seconds (some implementations will go as high as 10 seconds), and a client will usually cache multiple segments before playing (e.g., 3). This mean that you have 18 seconds before a segment becomes critical.</p><p>This is not a difficult thing for a P2P network to handle. You'd adapt things to introduce timing information and manage number of hops, but each client can maintain a connection to a number of other clients and have sufficient capacity to fill a segment if a connection fails. Various strategies could be used to distribute load while avoiding latency penalties.</p><p>Low-latency HLS uses much smaller segments and would be more demanding, but isn't impossible to manage.</p><p>&gt; BitTorrent punishes people who dont contribute</p><p>Private communities punish this behavior, BitTorrent clients do not. Most new downloads will appear as freeriders for a long time, and only over long periods far exceeding the download time will enough compatible seeding opportunities arise for them to contribute in any substantial way.</p><p>The network does not need everyone to seed, it only needs <i>enough</i> people to seed.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43689985"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43689985" href="https://news.ycombinator.com/vote?id=43689985&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>If I remember correctly, PopcornTime was able to stream via BT.
Your claims are mostly correct, but I think some compromises can be made to make BT clients streaming proof. For example:</p><p>1. locally-randomizing segments download order</p><p>2. Create a larger buffer</p><p>3. Prioritize parts coming from slower connections</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690128"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690128" href="https://news.ycombinator.com/vote?id=43690128&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>This is still just streaming a static file though. Adjusting which segment to get will work, buffering will work, and people don't mind their movie starting a few seconds after they press play.</p><p>If I'm streaming live, I need the frame immediately, and it doesn't help much to get later frames after the frame I'm missing.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691330"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43691330" href="https://news.ycombinator.com/vote?id=43691330&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Live streaming is, by nature, a "one-to-many" distribution model, where content flows from a single source to many viewers in real time.</p><p>BT, on the other hand, is fundamentally designed for "many-to-many" distribution, where peers share pieces of content with each other over time.
This isn't just a question of tweaking the protocol—it's a fundamentally different problem. Unless you're willing to compromise on the immediacy of the stream, using BT for true live streaming isn't really a good fit.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690224"><td></td></tr>
                <tr id="43690445"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43690445" href="https://news.ycombinator.com/vote?id=43690445&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>For pseudo-live streams such as sports events, that would be totally fine. People can have slightly out of sync streams, delayed by various amounts.</p><p>But you can't live stream a conversation with someone if you have a 10s delay.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690346"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43690346" href="https://news.ycombinator.com/vote?id=43690346&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>The issue is everyone is watching the same part of the file at the same time. Offsetting by 10 seconds does not change that.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690924"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_43690924" href="https://news.ycombinator.com/vote?id=43690924&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>The time offset impedes the ability of viewers to interact with the streamer via chat, which for many people (incl. myself) is the whole reason to watch live instead of a recording.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43690541"><td></td></tr>
                        <tr id="43690079"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690079" href="https://news.ycombinator.com/vote?id=43690079&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>The main difference is liveness of the stream. Live streams are much much more difficult and much less forgiving.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43690241"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690241" href="https://news.ycombinator.com/vote?id=43690241&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I am not convinced about the random order stuff. If most people will stream from the start then the start will be more seeded? So it's all good.</p><p>And the order is requested by the client, and there are clients that go in the sequential order, like Deluge</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690282"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690282" href="https://news.ycombinator.com/vote?id=43690282&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>The benefit of a random order is that it forces you to actually keep all the packets, which makes upload more likely. Streaming lets you get away with not storing the whole file, which makes bad actors more likely.</p><p>And, sure, some BT clients can stream the data, but what the default is makes a huge difference.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43691282"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43691282" href="https://news.ycombinator.com/vote?id=43691282&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>yes you are correct, BitTorrent - sequential download also works exactly like that.</p><p>people seem to have need for 0ms nano ultra low latency streams for watching movies,... they are insane. they want to be extraordinary high speed traders but with movies not stocks. insane</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690365"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690365" href="https://news.ycombinator.com/vote?id=43690365&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>If we are talking about a live stream (and not a stream of a static file), having the start be more seeded is useless.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691307"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43691307" href="https://news.ycombinator.com/vote?id=43691307&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>mpeg stream / TS filetype / DVB-T/C/S broadcast IS static file, all 3 is same format, this format deals with every point you made... download specs and educate yourself.</p><p>same with streaming audio, chunk IS static file, so every phone call you made last 30 years is static file.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691346"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43691346" href="https://news.ycombinator.com/vote?id=43691346&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>and there is no reason for bittorrent to not being able to send/download 3000 TS chunks / static files for 3 hour movie in sequential order.</p><p>and no reason for your MPV/VLC/PotPlayer to not render that in sequential order.</p><p>even when you have only first 2 pieces.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43690554"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690554" href="https://news.ycombinator.com/vote?id=43690554&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>If everybody starts at the start then it will be very poorly seeded when everybody wants it, before the being well seeded right when nobody needs it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691295"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43691295" href="https://news.ycombinator.com/vote?id=43691295&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>"well seeded" means what exactly?</p><p>if i can send 2 copies of piece to 2 people immediately as i got it, then if my download takes 20 ms and sending it another 20 ms is it "well seeded" for those 3 people after 50 ms? or after how much time it is "well seeded" ?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691496"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43691496" href="https://news.ycombinator.com/vote?id=43691496&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>A precise answer to that question entails more math than I'm willing to do right here in the middle of my Easter holiday. You should understand my argument more as a sketch of proof.</p><p>That being said I have a small correction. If you want to stream to two peers (that is you have a network with 3 fully connected nodes, one being the originator of the stream) and the link latency for all links is 20ms, then your lowest latency path to each node is exactly 20ms, as the originating node could simply send the content to each client.</p><p>The unfortunate realization is that 20ms is then also the optimal stream delay, assuming you care about the shortest possible latency for your live streaming service. The clients will therefore end up with the content exactly when they were supposed to show it, and therefore they would have no time to forward it to anyone else, lest that downstream would get the content AFTER they were supposed to show it.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="43690530"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690530" href="https://news.ycombinator.com/vote?id=43690530&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I don't think people are appreciating the nuance of what you're saying. Most of what you are saying isn't accurate for netflix style streaming, which would actually be more aptly called "video on demand", but is very applicable to "live streaming" in the sense of live sporting events or news broadcasts.</p><p>Video-on-demand is perfectly implementable on top of BitTorrent. As you say, there are some latency pitfalls you'll have to avoid, but that's nothing you can't hack yourself out of.</p><p>Livestreaming is a different beast. As you say, the problem with livestreaming is that everyone needs the same content at the same time. If I spend 200ms downloading the next 500ms worth of content, then there's nobody to share it with, they all spent the 200ms doing the same. BitTorrent relies on the time shift that is allowed between me downloading the content and you requesting it. If you request it before I've got it, well I can't fulfil that request, only the guy I intend to get it from can.</p><p>If you wanted to implement something like that, you would probably pick a tree of seeders where the protocol would pick a subset of trusted nodes that it would upload the content to before then allowing them to seed it, and the have them doing the same recursively.</p><p>That would obviously introduce a bunch of complexity and latency, and would very much not be BitTorrent anymore.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691043"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43691043" href="https://news.ycombinator.com/vote?id=43691043&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I don't think he's saying it needs to <i>be</i> BitTorrent, just applying some principles from it.</p><p>For example, say you have a cluster of people on the call in the US and another cluster in the UK. Ping times are 100ms or more across the ocean, there will be some random packets lost, but ping times within the UK are around 15ms max. By working co-operatively and sharing among themselves the clients in one cluster can fill in missing packets from a different cluster far quicker than the requesting them from the originating host.</p><p>In general, the ability to request missing packets from a more local source should be able to improve overall video call quality. It still might be "too late", because for minimal latency, you might choose to use packets as soon as they arrive and maybe even treat out-of-order packets as missing, and just display a blockier video instead, but if the clients can tolerate a little more latency (maybe a tunable setting, like 50ms more than the best case) then it should in theory work better than current systems.</p><p>I've been mulling over some of these ideas myself in the past, but it's never been high enough on my TODO list to try anything out.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691117"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43691117" href="https://news.ycombinator.com/vote?id=43691117&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>&gt; By working co-operatively and sharing among themselves the clients in one cluster can fill in missing packets from a different cluster far quicker than the requesting them from the originating host.</p><p>That's only true if you assume the nodes operate sequentially, which is not given. If the nodes operate independently from one another (which they would, being non-cooperating) they'd all get a response in ~100ms (computation and signaling time is negligible here), which is faster than they could get it cooperatively, even if we assume perfect cooperation (100ms for the first local node + 15ms from there). It's parallelism. Doing less work might seem theoretically nice, but if you have the capacity to do the same work twice simultaneously you avoid the synchronization.</p><p>Basically, it falls somewhere in my loose "tree based system" sketch. In this case the "trusted" nodes would be picked based on ping time clustering, but the basic sketch that you pick a subset of nodes to be your local nodes and then let that structure recursively play out is the same.</p><p>The problem you run into is latency. There's no good way to pick a global latency figure for the whole network, since it varies by how deep into the tree you are. As the tree grows deeper, you end up having to retune the delay. The only other option is to grow in width at which point you've just created a another linear growth problem, albeit with a lower slope.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="43691675"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43691675" href="https://news.ycombinator.com/vote?id=43691675&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>The real reason is that bandwidth is dirt cheap, if you know what are you are doing at scale.</p><p>For 'hobbyists' there is a lot of complexity with setting up your own streaming infrastructure compared to just using YouTube or Twitch.</p><p>Then for media companies who want to own it, they can just buy their own infra and networking which is outrageously cheap. HE.net advertises 40gbit/sec of transit for $2200/month. I'm oversimplifying this somewhat, you do have issues with cheap transit and probably need backups especially for certain regions. But there isn't much of a middleground between hobbyists and big media cos.</p><p>For piracy (live sports streams), I've read about <a href="https://en.wikipedia.org/wiki/Ace_Stream" rel="nofollow">https://en.wikipedia.org/wiki/Ace_Stream</a> being used for this exact purposes FWIW. This was a while back but I know it had a lot of traction at one point.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690934"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43690934" href="https://news.ycombinator.com/vote?id=43690934&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>For a while, I was CTO of a company called Livestation [0], which as the Wikipedia article states, was "originally based on peer-to-peer technology acquired from Microsoft Research".</p><p>This P2P stack was meant to allow for mass scaling of lowish latency video streaming, even in parts of the World with limited peer bandwidth to original content source servers. The VC-1 format got into a legal quagmire, as most video streaming protocols do, and it speaks volumes that by the time I turned up in ~2012-ish, the entire stack was RTMP, RTSP, HDS and HLS with zero evidence of that P2P tech stack in production.</p><p>My main role was to get the ingest stack out of a DC and into cloud, while also dealing with a myriad of poor design decisions that led to issues (yes, that 2013 outage in the first paragraph of the wiki article was on my watch).</p><p>At no point did anybody suggest to me that what we really needed to fix our attention back to was P2P streaming, beyond the fact the company built a version of Periscope (Twitter's first live streaming product), and launched it weeks/months before they did, and were pivoting towards a social media platform, at which point I decided to go do other things.</p><p>The technical and legal problems are real, and covered elsewhere here. People want reliable delivery. Even Spotify, YouTube and others who have licensed content and could save a pile by moving to DRM-ified P2P don't go near it, and that should tell you something about the challenges.</p><p>I'd love more widespread adoption of P2P tech, but not convinced we'll ever see it in AV any time soon, unfortunately.</p><p>[0] <a href="https://en.wikipedia.org/wiki/LiveStation" rel="nofollow">https://en.wikipedia.org/wiki/LiveStation</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43689852"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43689852" href="https://news.ycombinator.com/vote?id=43689852&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>There is peertube and webtorrent, but they does not seem to catch the mainstream users.</p><p>In my opinion, NAT and the extensive tracking that has led users to distrust sharing their IP addresses are the reasons why it hasn't caught on.</p><p>Imagine YouTube using P2P technology, it would save lot of money spent on caching servers.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43689920"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43689920" href="https://news.ycombinator.com/vote?id=43689920&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Peertube and web torrent aren't doing live streams as far as i know, just stream of pre-recorded video, which is still a lot harder for p2p than random order download, but not in the same ballpark as a livestream.</p><p>&gt; Imagine YouTube using P2P technology, it would save lot of money spent on caching servers.</p><p>I think its money well spent.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690291"><td></td></tr>
                <tr id="43690460"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43690460" href="https://news.ycombinator.com/vote?id=43690460&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Hmm interesting i didn't know that.</p><p>I couldn't find much docs on how it works, just <a href="https://docs.joinpeertube.org/contribute/architecture#live" rel="nofollow">https://docs.joinpeertube.org/contribute/architecture#live</a></p><p>Sounds like they break the stream into very small segments and publish each of those with bit torrent (?), they seem to claim about 30 second delay and scale in the hundreds but not thousands. Certainly impressive if true, i wouldnt of thought such an approach would scale so well. Of course its still a far cry from twitch, but nonetheless impressive.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="43684337"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43684337" href="https://news.ycombinator.com/vote?id=43684337&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>People have tried to build BitTorrent clients to do this. As far as I know they never took off. The primary problem is you oftentimes don't get people who want to share back or who have firewalls or other connections that don't allow them to share back. So you end up with a few people who end up seeding everything out. The second problem is in order to watch a streaming protocol things need to arrive in order. It is totally possible to do with BitTorrent and request the blocks in the order that you want but you may not always be able to get them in the order you want.</p><p>In general people aren't tolerant of lag and spinning circles and other such things when they're trying to watch streaming content. If you're fine with just watching it a little bit later might as well queue it up and left the whole thing down load so it's ready when you're ready.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690332"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690332" href="https://news.ycombinator.com/vote?id=43690332&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Popcorn Time did this and it worked great. Starting a torrent wasn't instant, but once a buffer was built up, it streamed just fine.</p><p>Popcorn Time got taken down pretty hard because they became too popular too fast.</p><p>A commercial solution could have a seed server optimized for streaming the initial segments of video files to kickstart the stream, and let basic torrents deal with the rest of the stream.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691533"><td></td></tr>
                  <tr id="43689937"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43689937" href="https://news.ycombinator.com/vote?id=43689937&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>The biggest issue I've seen with these is the networking limitations in a browser - there might be hundreds of seeders for a video and using a normal streaming torrent video player works well, but as torrent clients in the browser need to use WebRTC / WebTorrent, there might be just 0-5 seeders supporting it. I don't see much adoption for WebTorrents before the widely used standard Bittorrent clients support the protocol.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690233"><td></td></tr>
            <tr id="43684395"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43684395" href="https://news.ycombinator.com/vote?id=43684395&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>what about having something reasonable for lag, like 30-60 seconds would that make a big difference or you think it would just eventually degrade too? 
Also do you think there's any way you can prioritize seeders in such a protocol? like some kind of algorithm that the more you share the more you're prioritized in getting the most up to date packets.</p><p>The main reason I would think it would be useful is 1. since streaming sites seem to lose a lot of money and 2. sports streams are really bad, even paid ones. I have dazn and two other sports streaming services and they still lag and are only 720p</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690001"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690001" href="https://news.ycombinator.com/vote?id=43690001&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>&gt; what about having something reasonable for lag, like 30-60 seconds would that make a big difference or you think it would just eventually degrade too?</p><p>I think you would probably need something more in the neighbourhood of 10 minutes to really make a difference. If you could make a stable p2p live streaming app with the number of peers all watching the same stream in the hundreds and only 30 seconds latency, i'd consider that pretty amazing.</p><p>&gt; Also do you think there's any way you can prioritize seeders in such a protocol? like some kind of algorithm that the more you share the more you're prioritized in getting the most up to date packets.</p><p>If we are talking about a livestream (and not "netflix" type streaming) then i don't think seeders are a thing. You can't seed a file that isn't finished being created yet.</p><p>If you mean more generally punishing free-riders, i think  that is difficult in a live stream as generally data would be coming in from a different set of peers than the peers you are sending data out to, so its difficult (maybe not impossible) to know who is misbehaving.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43684581"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43684581" href="https://news.ycombinator.com/vote?id=43684581&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>With sports streams you specifically want low lag, don’t you? It’s no fun being spoilered by people cheering (or not) next door.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43684632"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43684632" href="https://news.ycombinator.com/vote?id=43684632&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>i wouldn't mind a minute of lag tbh if the quality and reliability was better. I'm pay $20 a month for dazn and it still lags and buffers lol</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43689490"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43689490" href="https://news.ycombinator.com/vote?id=43689490&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>stremio works fine and is quite popular.</p><p>It's similar to popcorn time that was killed by legal ways so I'd say they did take off.</p><p>Stremio smartly avoids being killed by making pirating an optional plugin you have to install from another site so they get deniability.</p><p>It works well and save my ass from needing 1000s' of subscriptions.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690656"><td></td></tr>
                        <tr id="43685220"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43685220" href="https://news.ycombinator.com/vote?id=43685220&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>There was Joost in 2008, from Skype founders. Skype was originally P2P until Microsoft acquisition and killing this legally questionable feature - need to feed the big brother (:
Joost raised ~$50M.</p><p>I remember it as it was one of rare apps built in XUL, the same framework as Mozilla apps (Firefox).</p><p><a href="https://en.m.wikipedia.org/wiki/Joost" rel="nofollow">https://en.m.wikipedia.org/wiki/Joost</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43691327"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43691327" href="https://news.ycombinator.com/vote?id=43691327&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I built a proof of concept doing exactly that a few years ago[0]. The codebase is unmaintained and the demo website has been down for a wee while too, but it's basically this idea.
Only issue is that the overhead to establish WebRTC connection is heavy, so it's not exactly lightweight...</p><p>0: <a href="https://github.com/pldubouilh/live-torrent">https://github.com/pldubouilh/live-torrent</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43684982"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43684982" href="https://news.ycombinator.com/vote?id=43684982&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>The only entities that could use such a thing are major streaming platforms, and projects trying to stream copyrighted content without consent.</p><p>The former don't want to use it as it degrades their control over the content, and the later don't want to make a new system cause systems that are built on torrents are good enough.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43689511"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43689511" href="https://news.ycombinator.com/vote?id=43689511&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I worked for a company called Streamroot which sold exactly this, and I can tell your first paragraph is indeed correct but the second isn't: we had major streaming platforms as customers when I was there (not global giants like Netflix or YouTube, but big european players like Canal+ or Eurosport) and we also had plenty of warez websites (streaming sport, animes, porn, etc.).</p><p>I then left and the company later got acquired by Level 3 so I don't know exactly how it evolved but it's likely that they abandoned the illegal streaming market for reputational reasons and stuck with big players.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690576"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690576" href="https://news.ycombinator.com/vote?id=43690576&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>&gt; I then left and the company later got acquired by Level 3 so I don't know exactly how it evolved</p><p>It just struck me that there are probably plenty of large media companies that use all sorts of proprietary video streaming products for distribution that we've never heard of, simply because the tech isn't available to consumers.</p><p>Media companies are generally pretty secretive about their tech (Netflix being the exception to this rule), so there isn't much to be found about this. The piracy community (because, let's be real here) also won't be interested in a non-free (speech and beer) streaming solutions like these. So that's probably why there is just very little public information available.</p><p>But if you use paid digital TV products (Eurosport being a perfect example here) then you are probably already using all sorts of P2P streaming protocols you've never heard of.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43688758"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43688758" href="https://news.ycombinator.com/vote?id=43688758&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>&gt; degrades their control over the content</p><p>Encryption (can work with sharing), signatures, fall back to CDN. Control is not an issue.</p><p>&gt; torrents are good enough.</p><p>Torrents can't do the massive market of livestream, like sports or season finales or reality TV / news.  This is the entire point of the question.</p><p>&gt; The only entities</p><p>And everyone kicked off of YouTube or doesn't want to use big corporations on principal, like Hacker Cons or the open source community.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43689580"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43689580" href="https://news.ycombinator.com/vote?id=43689580&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>&gt; Encryption (can work with sharing), signatures, fall back to CDN. Control is not an issue.</p><p>And of course if an encryption key gets leaked, you can just rotate it. Since it’s a stream, past content is not as important.</p><p>(That said, I don’t think it will help — any DRM can be cracked, and there’s plenty of online TV streaming sites even with the current centralized systems.)</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691040"><td></td></tr>
                  <tr id="43691031"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43691031" href="https://news.ycombinator.com/vote?id=43691031&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>"Torrents can't do the massive market of livestream"
CAN do, why are we not using them is not technical reason, it is that most people just pay apple tv / netflix and not have to install anything on their computer, and UI / interface is 10000 times better.</p><p>or very similar point - i had conversation with some big youtuber and person was confused why he is not more popular with certain demographic. reason was that said demographic was watching on big TV and content he was filming was big head directly in front of camera. so they do not like having 3 feet big head right in front of them... most young people watch things on mobile..</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43689282"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43689282" href="https://news.ycombinator.com/vote?id=43689282&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>There are streaming sites on the high-seas that use webtorrent. Interestingly (at least for me), this bypasses firewall based IPS/inspection that looks for bittorrent because it's all https. People use it to stream movies at work lol. Good for them I guess.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43691430"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43691430" href="https://news.ycombinator.com/vote?id=43691430&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>Have you checked out webtorrents? You can download movies from the P2P network sequentially and so watch them while they download.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690976"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43690976" href="https://news.ycombinator.com/vote?id=43690976&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>This used to exist in 2008 and it was perfect. It was called Joost and worked like this:
- P2P streaming
- You get a big menu of channel logos
- You click on a channel and it would start the first episode of a randomly chosen series from that channel, or it would continue from where you left off
- There might have been a "zap" function? I'm not sure
- The GUI was so nice and large that if you connected a Wii Remote to your PC, you had the best TV experience from your couch, ever: Just press a button to bring up the menu, aim at the channel you want to switch to, done.</p><p>Such a shame that it failed, nothing after it ever came close.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43684987"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43684987" href="https://news.ycombinator.com/vote?id=43684987&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>This tech has been developed several times but ultimately CDNs are now so cheap that P2P is pointless. You can't ignore development cost since it dominates all other costs in this case.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690825"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690825" href="https://news.ycombinator.com/vote?id=43690825&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>If CDNs are so cheap, why is YouTube insistent that they should get paid for their bandwidth? I already pay for my bandwidth and am quite happy to use it for something like YouTube.</p><p>The real reason is centralised architecture gives them control and ability to extract rent.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43687925"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43687925" href="https://news.ycombinator.com/vote?id=43687925&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>It <i>is</i> a thing.</p><p>For livestreams there's AceStream built on BitTorrent, but I think it's closed-source. They do have some SDK but I never looked into it. It's mostly used by IPTV pirates. I've used it a few times and it's hit-or-miss but when it works well I have been able to watch livestreams in HD/FullHD without cuts. Latency is always very bad though.</p><p>Then for video-on-demand there are some web-based ones like PeerTube (FOSS) and I think BitChute? Sadly webtorrent is very limited.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43684763"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43684763" href="https://news.ycombinator.com/vote?id=43684763&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>AceStream is P2P, its primary use is to stream pirated live sports though. But looking it up, it seems to have been infected by "blockchain!" geniuses.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43687988"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43687988" href="https://news.ycombinator.com/vote?id=43687988&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>It still works without any blockchain and there are dockerfiles and images for using it with CLI only on github. It's closed source through and the UI was a forked version of VLC - it's also been suspected to spread malware - CLI tools look fine through but who knows.</p><p>Surprisingly the channels that are available work really well if you just use the mpegts stream.</p><p>In a past life I've added a few channels to a tvheadend instance on a VPS. It reliable crashed Kodi watching some channels and I've wondered if it's just broken streams or something more interesting is going on.</p><p>If you open the ports and watch popular channels it's easily saturating bandwidth - there is no limit.</p><p>I've since stopped using it it's the kind of thing that breaks not often enough to be not useless but often enough to be annoying.</p><p>It's IPv4 only and seems to use it's own tracker or at least calls to some URLs for initial peer discovery.</p><p>Building something similar as true open source would be great but I guess the usecase is mostly illegal streaming.</p><p>Be careful - it's attempting to use upnp to open ports on the router and even if just looking through the lists makes you upload fragments.</p><p>Still fascinating tool. It's getting to close to what op is looking for but I think it has scalability issues and everything about it is kind of shady and opaque.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43691259"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43691259" href="https://news.ycombinator.com/vote?id=43691259&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>Lots of technical discussions - but the real answer is that bittorrent/P2P was displaced by Netflix for all but a small number of hard-core users. That, combined with legal threats, and that p2p required volume/scale to work well, meant that the critical mass died. It was a sad day that we, the users of the internet, en-mass exchanged bittorrent for streaming companies.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43685467"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43685467" href="https://news.ycombinator.com/vote?id=43685467&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>There's iroh.computer which can use a relay/ do direct nat punching.</p><p>They use bao hashing which is something that I discovered through them (IIRC) and its really nice.</p><p>Could create such a protocol though bittorrent/ipfs is fine</p><p>I once wanted to create a website which was just a static website.</p><p>and I used some ipfs gateway to push it with my browser and got a link of that static website, all anonymous.</p><p>Kind of great tbh.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43685530"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43685530" href="https://news.ycombinator.com/vote?id=43685530&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Shame it's being abused by crypto bros who want to treat it as money.</p><p>There are other genuinely useful crypto projects (like Monero for privacy and I don't like the idea of smart contracts)</p><p>I really want to tell you the fact that most crypto is scam. These guys first went into crypto and now I am seeing so much crypto + AI.</p><p>As someone who genuinely is interested in crypto from a technology (decentralization perspective)</p><p>I see transactions as a byproduct not the end result &amp; I see people wanting to earn a quick buck feel really weird.</p><p>Also crypto isn't safe. I just think like now its better to correlate as a tech stock though 99% of the time, its run by scams, so absolutely worse.</p><p>The technology is still fascinating. But just because the technology is fascinating doesn't mean its valuable. Many people are overselling their stuff.</p><p>That being said, I have actually managed to use crypto to create a permanent storage (something like ipfs but its forced to store it forever) , so I think this can be used where anonymity/decentralized is required. But still, this thing could be done without including money in the process as well &amp; crypto is still not as decentralized as one might imagine.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690199"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690199" href="https://news.ycombinator.com/vote?id=43690199&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>&gt; Shame it's being abused by crypto bros who want to treat it as money.</p><p>Iroh contributor here. I don't know what you are referring to. Iroh is just a library to provide direct QUIC connections between devices, even if they are behind a NAT. We don't have any plans doing a blockchain or an ICO or anything like that.</p><p>I am not aware of any project called Iroh that is a scam, but if there is, please provide a link here. <i>It's not us</i>.</p><p>I know there have been some scammers trying to make a BLAKE3 coin or something, a year ago.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690874"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43690874" href="https://news.ycombinator.com/vote?id=43690874&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I actually wasn't referring to iroh but rather ipfs / the stratos thing that I mentioned.</p><p>My only gripe with iroh currently is that its browser wasm feels too much for me/ I don't want to learn rust.</p><p>So I actually wanted to build something that required connectivity and I used nostr because nostr is great for website and not gonna lie ,its awesome as well (but nostr is also riddled with crypto bros :( )</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691262"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43691262" href="https://news.ycombinator.com/vote?id=43691262&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>OK, thanks for the clarification.</p><p>I have nothing against crypto in principle, but I really don't want Iroh to be associated with crypto scams.</p><p>Iroh is just a library for p2p connections. You can use it for crypto, but I would say that the majority of our users are non-crypto(currency).</p><p>We will try to make the wasm version easier to use, but if nostr works well for you, go for it! Not the right place if you want to avoid crypto bros though :-)</p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="43690337"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43690337" href="https://news.ycombinator.com/vote?id=43690337&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I am a contributor to Iroh ( <a href="https://github.com/n0-computer/iroh">https://github.com/n0-computer/iroh</a> ), an open source library for direct QUIC connections between devices that can be behind a NAT.</p><p>Our library is general purpose and can be used whenever you need direct connections, but on top of Iroh we also provide iroh-blobs, which provides BLAKE3 verified streaming over our QUIC connections.</p><p>Blobs currently is a library that provides low level primitives and point to point streaming (see e.g. <a href="https://www.iroh.computer/sendme" rel="nofollow">https://www.iroh.computer/sendme</a> as an example/demo )</p><p>We are currently working on extending blobs to also allow easy concurrent downloading from multiple providers. We will also provide pluggable content discovery mechanisms as well as a lightweight content tracker implementation.</p><p>There is an experimental tracker here: <a href="https://github.com/n0-computer/iroh-experiments/tree/main/content-discovery">https://github.com/n0-computer/iroh-experiments/tree/main/co...</a></p><p>Due to the properties of the BLAKE3 tree hash you can start sharing content even before you have completely downloaded it, so blobs is very well suited to the use case described above.</p><p>We already did a few explorations regarding media streaming over iroh connections, see for example <a href="https://www.youtube.com/watch?v=K3qqyu1mmGQ" rel="nofollow">https://www.youtube.com/watch?v=K3qqyu1mmGQ</a> .</p><p>The big advantage of iroh over bittorrent is that content can be shared efficiently from even behind routers that don't allow manual or automatic port mapping, such as many carrier grade NAT setups.</p><p>Another advantage that BLAKE3 has over the bittorrent protocol is that content is verified <i>incrementally</i>. If somebody sends you wrong data you will notice after at most ~16 KiB. Bittorrent has something similar in the form of piece hashes, but those are more coarse grained. Also, BLAKE3 is extremely fast due to a very SIMD friendly design.</p><p>We are big fans of bittorrent and actually use parts of bittorrent, the mainline DHT, for our node discovery.</p><p>Here is a talk from last year explaining how iroh works in detail: <a href="https://www.youtube.com/watch?v=uj-7Y_7p4Dg" rel="nofollow">https://www.youtube.com/watch?v=uj-7Y_7p4Dg</a> , also briefly covering the blobs protocol.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690851"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43690851" href="https://news.ycombinator.com/vote?id=43690851&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>It's hard to beat CDNs for streaming because the number of hops is low.  Basically any p2p technology would have to mirror the way existing livestreams work; a local well-connected peer sucks down the livestream from farther away and rebroadcasts it to local peers.  Anything else introduces latency or wastes WAN bandwidth.  Peers are also rarely situated where they have moderate downstream and exceptional (local) upstream.</p><p>IPv6 multicast is probably the way forward for livestreams but I haven't really been keeping up on recent developments.  In theory there could be dynamic registrations of multicast addresses that ISPs could opt-in to subscribe to and route for their customers.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690987"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690987" href="https://news.ycombinator.com/vote?id=43690987&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>( not a criticism of you/your post )</p><p>it is insane to me, for people to have need to watch toxic channels like LinusTechTips livestream, regurgitating weeks old toxic marketing disinformation and having need to have that 0ms latency... XD</p><p>why everyone needs low latency for one way stream? unnecessary hurdle just to have that hurdle. no benefit to anything.</p><p>but agree with you that if companies already forget existence of IPv4, internet will be simpler, faster and more usable. for less price for everyone.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690947"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690947" href="https://news.ycombinator.com/vote?id=43690947&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>hops and latency in general does not really matter in streaming context after the first few seconds, which are a bottle neck due to connecting to peers that might or might not exist</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43684925"><td></td></tr>
            <tr id="43690262"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43690262" href="https://news.ycombinator.com/vote?id=43690262&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>You need good latency for streaming, torrents can get to a decent speed but the latency will always be bad.</p><p>Modern streaming protocols sometimes go to absurd lengths to avoid too many hops so you get the data as soon as possible... torrent has so many jumps and negotiations to get to the actual file. It's good for decentralization but decentralization and efficiency go against each other.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43691163"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43691163" href="https://news.ycombinator.com/vote?id=43691163&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>A related thing: wasn't PopcornTime using bittorent to stream movies? Did it have any notable difference from Bittorent or any notable issue/drawback? I never used it, but it sounded like a big thing at the time.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43686882"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43686882" href="https://news.ycombinator.com/vote?id=43686882&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>BitTorrent is already a streamable P2P protocol. You just need a client that can prioritize downloading the file parts in order.</p><p>It is a thing.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43687153"><td></td></tr>
                <tr id="43687188"><td></td></tr>
                <tr id="43690513"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43690513" href="https://news.ycombinator.com/vote?id=43690513&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>But its not really p2p in the sense the original poster meant (as in its not an overlay network). Its p2p in the sense that tcp/ip is p2p, not in the sense that bit torrent is.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43690239"><td></td></tr>
            <tr id="43687223"><td></td></tr>
                <tr id="43687316"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43687316" href="https://news.ycombinator.com/vote?id=43687316&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>It did.</p><p>All of it started with the webtorrent project though. One of the first demos was booting Ubuntu while streaming the incomplete live ISO image, quite impressive for the time.</p><p>This is great tech for media files. Currently better than any other. But making it would make those media files very easy to redistribute, and it is hard to change that without loosing the P2Pness goodies.</p><p>If Popcorn Time had a synchronized multi-resolution catalog, bandwidth-sensitive auto switch and some paid seed servers, it would be better than any other streaming service (technically speaking).</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43690914"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43690914" href="https://news.ycombinator.com/vote?id=43690914&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>you can install Qbittorrent client, after loading torrent file/magnet link, right click on that torrent and click on Download in sequential order.</p><p>torrent PROTOCOL does not require to download random pieces, in random order.</p><p>ONLY bittorrent, inc. COMPANY which releases "Utorrent" and "Bittorent" NAMED APPLICATIONS/PROGRAMS does not want legal trouble from media/music companies. Because STREAMING is other legal category then downloading. There is no other reason for torrent PROTOCOL to not deliver file pieces in sequential order.</p><p>if you need instant nanosecond delayed stream, those does not exist anywhere, even radio, tv stations over the air are delayed so they all transmit synchronized. so 0 latency and synchronized can be mistaken for each other.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43691768"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43691768" href="https://news.ycombinator.com/vote?id=43691768&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I believe there is actually a reason why you want to transfer random blobs instead of from the start: it is waste of resources when a node needs to upload the same block multiple times to the network, if it could be uploading different blocks.</p><p>&gt; if you need instant nanosecond delayed stream</p><p>I believe nobody was suggesting that.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43689401"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43689401" href="https://news.ycombinator.com/vote?id=43689401&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>A lot of comments mention it has been a thing in various forms through the internet’s brief history. The interesting question is why didn’t it take off—especially when the technology was there.</p><p>One possibility as you allude to is licensing. In a P2P streaming model “rights” holders want to collect royalties on content distribution. I’m not sure of a way you could make this feel legal short of abolishing copyright, but if you could build a way to fairly collect royalties, I wonder if you’d make inroads with enforcers. But overall that problem seems to have been solved with ads and subscription fees.</p><p>Another data point is that the behemoths decided to serve content digitally. Netflix and Spotify showed up. The reason the general population torrented music is because other than a CD changer, having a digital library was a requirement in order to listen to big playlists of songs on your… Zune. Or iPod. That problem doesn't exist anymore and so the demand dried up. There was also an audiophile scene but afaik with Apple Lossless the demand there has diminished too.</p><p>And finally, since people were solving the problem for real, we also entertained big deal solutions to reduce the strain on the network. If you stream P2P your packets take the slow lane. Netflix and other content providers build out hardware colocated with last mile ISPs so that content distribution can happen even more efficiently than in a P2P model.</p><p>In short: steaming turned into a real “industry”. Innovators and capitalists threw lots of time and money at the problem. Streaming platforms emerged, for better and for worse. And here we are today, on the cusp of repeating the past because short sighted business mongers have balkanized access  with exclusive content libraries for the user numbers.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43689686"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43689686" href="https://news.ycombinator.com/vote?id=43689686&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>I think there is acestream though I don't think it could do 1000s of users. It was my go to for watching live sports back in the day I dont watch sports so no longer kept up with it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43685761"><td></td></tr>
            <tr id="43685437"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43685437" href="https://news.ycombinator.com/vote?id=43685437&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I would see that easiest way to bring something like that would be some adaptation of m4u format, just instead of URLs to video it could have URL to torrent/magnet.</p><p>one issue I can imagine would be that each part would discover peers independently where assumption that most peers of previous parts should be expected to also have those files.</p><p>second idea would be to use ipfs in that way instead of torrent. that would probably have much easier time for reusing peer discovery between parts and also would solve issue when to stop seeding as this is already build in into protocol.</p><p>I guess that creating distributed twitch basing on ipfs would be feasible but not sure how many people would like to install ipfs node before that could use that.
that's kind of chicken and egg problem, you need a lot of people before this system starts work really well, but to get interest it need to really perform well so people would migrate from twitch like services.</p><p>ofc you can use public gateways. afaik cloudflare have public ipfs endpoint that could serve as fallback</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43685701"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43685701" href="https://news.ycombinator.com/vote?id=43685701&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>I would think that the easiest way would be to not use torrents, because torrents have fixed top-level hashes. Instead, create a new protocol like bittorrent but streaming.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43690000"><td></td></tr>
            <tr id="43689912"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43689912" href="https://news.ycombinator.com/vote?id=43689912&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>You could utilize webtorrents, with a master seed, to in theory get really high scaling of content download, as one would scale peers at the same time of leetchers. Add a cordination server on top to sync timings and you should be there.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43690231"><td></td></tr>
            <tr id="43684448"><td></td></tr>
                <tr id="43684524"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43684524" href="https://news.ycombinator.com/vote?id=43684524&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>looks interesting! surprised something like that never caught on. I looking for something like Twitch basically. It has really good quality and is live. But obviously Twitch is just losing money and using all Amazons resources so I wanted to see if there's a more sustainable p2p approach</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43685892"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43685892" href="https://news.ycombinator.com/vote?id=43685892&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>For massive video distribution, getting acquired by a company with "infinite bandwidth" is the sustainable approach.</p><p>Orchestrating p2p realtime video distribution is going to have a lot of problems, and spend VC money until someone acquires you is just a lot easier.</p><p>Here's a small list of challenges you'd face:</p><p>You'll need to have a pretty good distribution network to handle users who just can't manage to p2p connect.</p><p>Figuring out the right amount of user's bandwidth you can use without people getting upset; there's a lot of internet accounts with bandwidth quotas, especially for mobile</p><p>Trying to arrange so that users connect to users with the least transmission delays would be needed to reduce overall latency. Between cross oceanic connections having unavoidable latency, the potential of buffer bloat, and having a reasonable jitter buffer, pretty soon you have wild delays and potential rebuffering.</p><p>Bandwidth constraints / layer switching is going to be a big challenge; it's one thing when your server can just push the best stream the client can manage, but if you're streaming from a peer and the stream is too big, the peer probably doesn't have a smaller stream to switch to <i>and</i> there's no good way to know if where the bandwidth constraint is ... maybe you should switch to the same stream from someone else or maybe you should switch to a smaller stream. Can you get even packets from one peer and odd packets from another ... should you?</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43684706"><td></td></tr>
                <tr id="43684906"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43684906" href="https://news.ycombinator.com/vote?id=43684906&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Thanks! i will just check it out.</p><p>I just meant like never caught on as in like it's not super popular, but looks like it's on the come up. would be nice to have a real youtube competitor lol</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43685341"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43685341" href="https://news.ycombinator.com/vote?id=43685341&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>Yes. It's the typical 'hen &amp; egg' problem. I'm watching there from time to time, and even found some things (independent trance/ambient/goa music) which didn't exist on YT at all! Though the selection is limited, compared to YT or whatever, it's less algorithmic, and because of this you're not forced to use most exaggerated grimacing or clickbaity titles, <i>IF</i> you have no commercial interests and give a shit about ads.</p><p>If that's your thing. And you have some sort of presence online elsewhere, then you can link to peertube, no matter which, or selfhosted, without problem.</p><p>That's why I pointed you to it. If you need/want the most massive audience, because of platform familarity/network effect, then probably not. At least not now. But someone has to start somehow :)</p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="43687196"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43687196" href="https://news.ycombinator.com/vote?id=43687196&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>The only way this will be possible is if there is widespread adoption of an Internet overlay network similar to Tailscale in its design. Fortunately or unfortunately depending on how you look at it Tailscale is limited to Layer 3 so Multicast doesn't work (it depends on IGMP to function correctly).</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43689669"><td></td></tr>
                <tr id="43690457"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43690457" href="https://news.ycombinator.com/vote?id=43690457&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>AFAIK IPv6 multicast across the internet is pretty much dead. ISPs seem to block it because of its DDoS potential. They use it themselves of course (very useful for streaming live TV across their private VLANs) but as an outsider you'll have to convince every ISP and backbone provider to trust your multicast stream, which they probably won't.</p><p>Tailscale (or any other P2P overlay network) could solve this problem by re-enabling the multicast support that most ISPs block. It's not a terrible idea.</p><p>Edit: a comment elsewhere linked <a href="https://www.librecast.net/librecast.html" rel="nofollow">https://www.librecast.net/librecast.html</a> which seems to be doing exactly this.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43689649"><td></td></tr>
                  <tr id="43691042"><td></td></tr>
            <tr id="43684361"><td></td></tr>
                <tr id="43689544"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43689544" href="https://news.ycombinator.com/vote?id=43689544&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>I had a teacher in uni who was fairly convinced that some kind of intelligent multicast was the solution here.</p><p>But after working in ISP for a while I realised that the issue is getting ISP's to use cool protocols is just impossible and everything must be built at higher levels.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43684916"><td></td></tr>
                <tr id="43689647"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43689647" href="https://news.ycombinator.com/vote?id=43689647&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>You might have a look at Librecast [0] which is a R&amp;D project funded by Horizons Europe NGI0 programme via NLnet, aiming to the bring multicast to the current unicast internet and smoothen the transition of projects that adopt it. A great intro to multicast and Librecast is given in Brett Sheffield's 2020 LinuxConfAU talk "Privacy and Decentralization with Multicast" that is available on Peertube [1].</p><p>&gt; To enable multicast on the unicast Internet we start by building an encrypted overlay network using point-to-point links between participating nodes. Once established, our overlay network can run whatever protocols we require, unimpeded by routers and middleboxes and which is resistant to interception, interference and netblocks.</p><p>[0] <a href="https://www.librecast.net/librecast-strategy-2025.html" rel="nofollow">https://www.librecast.net/librecast-strategy-2025.html</a></p><p>[1] <a href="https://spectra.video/w/9cBGzMceGAjVfw4eFV78D2" rel="nofollow">https://spectra.video/w/9cBGzMceGAjVfw4eFV78D2</a></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43690492"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43690492" href="https://news.ycombinator.com/vote?id=43690492&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>The protocol seems like an excellent idea, but #3365a3 on black for the website text is one of the worst designs for open-source project websites I've seen yet.</p><p>Off-topic but I'm impressed with how many potentially revolutionary projects get funding from NLNet.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43687052"><td></td></tr>
                <tr id="43687144"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43687144" href="https://news.ycombinator.com/vote?id=43687144&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>Mbone was fake multicast (today you'd be better off using a CDN) and I don't know if it's still operating.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43684542"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43684542" href="https://news.ycombinator.com/vote?id=43684542&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>i guess but im thinking like multicast with the people sharing like bittorrent, just live. so you'd need to factor in people leaving and people leeching</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43687104"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43687104" href="https://news.ycombinator.com/vote?id=43687104&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>So a multicast like derivative that is peer aware and can redistribute locally any available parts - which would require some sort of caching, which would probably break copyright etc... So perhaps that's the reason why nothing exists. \o/</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43687170"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43687170" href="https://news.ycombinator.com/vote?id=43687170&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>I would not be surprised if the rise of CG-NAT put another nail in the proverbial coffin of P2P video streaming and related sharing.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43685674"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43685674" href="https://news.ycombinator.com/vote?id=43685674&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>Build it. Use Go. Maybe nknorg/nnet for P2P. Signed HLS segments. Have Go also serve the web front-end with a WASM web worker. Public nodes can run on a very lightweight VPS/server with an autocert domain. Viewers browser join the swarm with WASM-- this way people can just type in a web address so it's very user friendly but the domain doesn't actually have to serve any data. I would just use a trusted pubkey to sign P2P updates so nodes can block naughty IP addresses. Should get you very friendly user experience, easy node deployment, pretty low latency, and bittorrent level of legal resilience.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43689526"><td></td></tr>
            <tr id="43690087"><td></td></tr>
            <tr id="43685136"><td></td></tr>
            <tr id="43689365"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43689365" href="https://news.ycombinator.com/vote?id=43689365&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>There are at least two projects like this for watching anime. I won't name them in this forum but they do exist if you look for them.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43689693"><td></td></tr>
            <tr id="43689039"><td></td></tr>
                <tr id="43690511"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43690511" href="https://news.ycombinator.com/vote?id=43690511&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div>
                  <p>Twitch streamers seem to be fine with the 10-60 second latency Twitch adds, depending on how bad their network is performing. Requirements will differ per industry but I don't think latency is a killer necessarily.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43684773"><td></td></tr>
                <tr id="43685218"><td></td></tr>
                <tr id="43690133"><td></td></tr>
            <tr id="43685415"><td></td></tr>
                        <tr id="43690007"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43690007" href="https://news.ycombinator.com/vote?id=43690007&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>As I understand it, P2P requires information sharing so when your distribution network grows this eventually turns into a performance bottleneck. You'll also need rather sophisticated mitigations against bad actors in the distribution network, like nodes that forward bad packets instead of distributing the good packets they receive and got requests for.</p><p>You might want to look into the tradeoffs Discord decided to go with, <a href="https://discord.com/blog/how-discord-handles-two-and-half-million-concurrent-voice-users-using-webrtc" rel="nofollow">https://discord.com/blog/how-discord-handles-two-and-half-mi...</a>.</p><p>Here's some boilerplate for rolling your own, <a href="https://blog.swmansion.com/building-a-globally-distributed-webrtc-service-with-elixir-webrtc-stunner-and-cilium-cluster-mesh-54553bc066ad?gi=945b73e26b32" rel="nofollow">https://blog.swmansion.com/building-a-globally-distributed-w...</a>.</p><p>In theory you could gain resilience from a P2P architecture but you're going to have to sacrifice some degree of live-ness, i.e. have rendering clients hold relatively large buffers, to handle jitters, network problems, hostile nodes and so on.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43689957"><td></td></tr>
            <tr id="43689543"><td></td></tr>
                <tr id="43689591"><td></td></tr>
                  <tr id="43690501"><td></td></tr>
            <tr id="43686701"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43686701" href="https://news.ycombinator.com/vote?id=43686701&amp;how=up&amp;goto=item%3Fid%3D43684286"></a></center>    </td><td><br><div><p>&gt; Also i think it wouldnt have to be live, people would definitely not mind some amount of lag.</p><p>I work on low latency and live broadcast.  The appropriate latency of any video stream is the entire duration of it.  Nobody else seems to share this opinion though.</p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Web Server (134 pts)]]></title>
            <link>https://simplewebserver.org/</link>
            <guid>43684009</guid>
            <pubDate>Mon, 14 Apr 2025 17:43:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simplewebserver.org/">https://simplewebserver.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43684009">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Run multiple &amp; in the background</h2><p>Run multiple web servers at the same time, even when the app is closed.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AudioX: Diffusion Transformer for Anything-to-Audio Generation (139 pts)]]></title>
            <link>https://zeyuet.github.io/AudioX/</link>
            <guid>43683907</guid>
            <pubDate>Mon, 14 Apr 2025 17:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zeyuet.github.io/AudioX/">https://zeyuet.github.io/AudioX/</a>, See on <a href="https://news.ycombinator.com/item?id=43683907">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <!-- <section class="hero"> -->
  <section>
    <!-- <div class="hero-body"> -->
    <div>
          
          

          <p><span><sup>1</sup>HKUST</span>
          </p>

          <p><span><sup>†</sup>Corresponding authors
            </span>
          </p>
          
        </div>
    
    <!-- </section> -->

    <div>
        <!-- Abstract. -->
        <div>
            <h2>Abstract</h2>
            <p>
                Audio and music generation have emerged as crucial tasks in many applications, yet existing approaches face significant limitations: they operate in isolation without unified capabilities across modalities, suffer from scarce high-quality, multi-modal training data, and struggle to effectively integrate diverse inputs. In this work, we propose AudioX, a unified Diffusion Transformer model for Anything-to-Audio and Music Generation. Unlike previous domain-specific models, AudioX can generate both general audio and music with high quality, while offering flexible natural language control and seamless processing of various modalities including text, video, image, music, and audio. Its key innovation is a multi-modal masked training strategy that masks inputs across modalities and forces the model to learn from masked inputs, yielding robust and unified cross-modal representations. To address data scarcity, we curate two comprehensive datasets: vggsound-caps with 190K audio captions based on the VGGSound dataset, and V2M-caps with 6 million music captions derived from the V2M dataset. Extensive experiments demonstrate that AudioX not only matches or outperforms state-of-the-art specialized models, but also offers remarkable versatility in handling diverse input modalities and generation tasks within a unified architecture. 
              </p>
          </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <div>
            <h2>Demo Video</h2>
    
            
    
          </div>

        <!--/ Paper video. -->
      </div>

    <div>
    

            

            
  <!-- 单个任务示例：Text-to-Audio Generation -->
  <div>
    <!-- 外层容器，带边框 -->


      <!-- 任务标题 -->
      <h2>Text-to-Audio Generation</h2>

      <!-- 预览区域：2-3个示例 -->
      <div>
          <!-- 示例3 -->
          <div>
            <p><strong>Prompt:</strong>
              <br>  
              Thunder and rain during a sad piano solo</p>
            </div>          
          <!-- 示例1 -->
          <div>
            <p><strong>Prompt:</strong>
              <br>  
              Typing on a keyboard</p>
            </div>
          <!-- 示例2 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Ocean waves crashing</p>
            </div>           
     

        </div>

      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      <div>

            <div>
              <p><strong>Prompt:</strong>
                A person is snoring</p>
              </div>              
            <div>
              <p><strong>Prompt:</strong> A toilet flushing</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> Rain falling on a rooftop</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> An airplane is taking flight</p>
              </div>                                                   
            <div>
              <p><strong>Prompt:</strong> An explosion and crackling</p>
              </div>
            
            <div>
              <p><strong>Prompt:</strong> Footsteps in snow</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> A cat meowing repeatedly</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> Food and oil sizzling</p>
              </div>
            <!-- 继续添加更多 sample-item ... -->
          </div>

  </div>


  <!-- 单个任务示例：Text-to-Music Generation -->
  <div>
    <!-- 外层容器，带边框 -->

      <!-- 任务标题 -->
      <h2>Text-to-Music Generation</h2>

      <!-- 预览区域：2-3个示例 -->
      <div>
          <!-- 示例1 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Orchestral, epic, with drums, strings, 
              <br>  
              and brass</p>
            </div>
          <!-- 示例2 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Electronic dance music with synthesizers, bass, drums, and a slow build-up</p>
            </div>
          <!-- 示例3 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Sad emotional soundtrack with ambient textures and solo cello</p>
            </div>
        </div>

      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      <div>
            <div>
              <p><strong>Prompt:</strong> 
                A suspenseful scene in a haunted mansion</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                An orchestral music piece for a fantasy world</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                
                Uplifting ukulele tune for a travel vlog</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                
                Romantic acoustic guitar music for a sunset scene</p>
              </div>                                                
            <div>
              <p><strong>Prompt:</strong> 
                Smooth urban R&amp;B beat with a mellow groove</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> 
                Produce upbeat electronic music for a dance party</p>
              </div>
            
            <div>
              <p><strong>Prompt:</strong> 
                Playful 8-bit chiptune music for a retro platformer game</p>
              </div> 
            
            <div>
              <p><strong>Prompt:</strong> 
                Ambient synth music in a deep space setting</p>
              </div>             
            <!-- 继续添加更多 sample-item ... -->
          </div>


  </div>




    
            <!-- Video-to-Audio Generation -->
            <div>

                <h2>Video-to-Audio Generation</h2>
                

      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      

            </div>
    
            <!-- Video-to-Music Generation -->
            <div>

                <h2>Video-to-Music Generation</h2>
                
      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      
          </div>
    




    </div>
    
    
    
    
    

    
    <div>
            <h2>Teaser</h2>
            <!-- <div class="columns is-centered"> -->
            <p><img src="https://zeyuet.github.io/AudioX/static/images/teaser.png" alt="Teaser." height="100%" width="100%"></p><p>
                (a) Overview of AudioX, illustrating its capabilities across various tasks. (b) Radar chart comparing the performance of different methods across multiple benchmarks. AudioX demonstrates superior Inception Scores (IS) across a diverse set of datasets in audio and music generation tasks.
              </p>
          </div>

    <div>
            <h2>Method</h2>
            <!-- <div class="columns is-centered"> -->
            <p><img src="https://zeyuet.github.io/AudioX/static/images/method-.png" alt="Method." height="100%" width="100%"></p><p>
                The AudioX Framework.
              </p>
          </div>


    <div id="BibTeX">
        <h2>BibTeX</h2>
        <p>
          If you find our work useful, please consider citing:</p>
        <pre><code>@article{tian2025audiox,
          title={AudioX: Diffusion Transformer for Anything-to-Audio Generation},
          author={Tian, Zeyue and Jin, Yizhu and Liu, Zhaoyang and Yuan, Ruibin and Tan, Xu and Chen, Qifeng and Xue, Wei and Guo, Yike},
          journal={arXiv preprint arXiv:2503.10522},
          year={2025}
        }</code></pre>
      </div>



    
    
    
    

    






</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Podman Quadlets with Podman Desktop (163 pts)]]></title>
            <link>https://podman-desktop.io/blog/podman-quadlet</link>
            <guid>43683641</guid>
            <pubDate>Mon, 14 Apr 2025 17:16:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://podman-desktop.io/blog/podman-quadlet">https://podman-desktop.io/blog/podman-quadlet</a>, See on <a href="https://news.ycombinator.com/item?id=43683641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><p><img decoding="async" loading="lazy" alt="banner" src="https://podman-desktop.io/assets/images/banner-b4811c66dc40efde426f577bd07fc7fd.png" width="1216" height="832"></p>
<p>Containers are typically deployed in Kubernetes clusters.
However, for smaller-scale use cases such as on a single-node server or during development, Kubernetes can be overkill.</p>
<p>What’s a more lightweight solution for running autonomous applications with multiple interacting containers?</p>
<p>In this blog, we'll dive into what Quadlets are, their benefits, and how to use them within Podman Desktop.</p>
<h2 id="what-are-quadlets">What Are Quadlets?<a href="#what-are-quadlets" aria-label="Direct link to What Are Quadlets?" title="Direct link to What Are Quadlets?">​</a></h2>
<p>Podman Quadlets allow you to manage containers declaratively using systemd<sup><a href="#user-content-fn-1-4453df" id="user-content-fnref-1-4453df" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>.
Since version 4.4, Podman can create, start, and manage containers (including pulling images, creating volumes, and managing pods) through systemd.</p>
<p>Quadlets are simplified configuration files—recognized by their specific extensions,
such as <code>*.container</code>, <code>*.pod</code>, or <code>*.image</code> that are processed during startup or when you reload the daemon using the <code>systemctl daemon-reload</code> command.</p>
<p>Quadlets generate the equivalent systemd unit files, streamlining the container management process.</p>
<h3 id="why-use-quadlets">Why Use Quadlets?<a href="#why-use-quadlets" aria-label="Direct link to Why Use Quadlets?" title="Direct link to Why Use Quadlets?">​</a></h3>
<ul>
<li><strong>Declarative Configuration</strong>: Similar to Compose or Kubernetes manifests, Quadlets allow you to declare what you want to run, simplifying the workload setup.</li>
<li><strong>Tight System Integration</strong>: Quadlets align with Podman’s philosophy of integrating seamlessly with Linux, leveraging systemd’s process management capabilities.</li>
<li><strong>Ease of Automation</strong>: Quadlets make it simple to configure containers to start at boot, restart on failure, and more.</li>
</ul>
<h3 id="example-a-quadlet-file-for-nginx">Example: A Quadlet File for Nginx<a href="#example-a-quadlet-file-for-nginx" aria-label="Direct link to Example: A Quadlet File for Nginx" title="Direct link to Example: A Quadlet File for Nginx">​</a></h3>
<p>Below is an example of an <code>nginx.container</code> Quadlet file, which starts an nginx container at boot:</p>
<div><p>~/.config/containers/systemd/nginx.container</p><div><pre tabindex="0"><code><span><span># nginx.container</span><br></span><span><span>[Container]</span><br></span><span><span>ContainerName=nginx</span><br></span><span><span>Image=nginx</span><br></span><span><span>PublishPort=80:8080</span><br></span><span><span></span><br></span><span><span>[Service]</span><br></span><span><span>Restart=always</span><br></span></code></pre></div></div>
<p>This configuration ensures the container restarts automatically if stopped, and exposes port 8080.</p>
<h2 id="using-the-podman-quadlet-extension-in-podman-desktop">Using the Podman Quadlet Extension in Podman Desktop<a href="#using-the-podman-quadlet-extension-in-podman-desktop" aria-label="Direct link to Using the Podman Quadlet Extension in Podman Desktop" title="Direct link to Using the Podman Quadlet Extension in Podman Desktop">​</a></h2>
<p>Managing Quadlets directly on non-Linux platforms can be challenging due to virtualized environments (e.g., WSL or Hyper-V).
Fortunately, the Podman Desktop extension Podman Quadlet simplifies this process, enabling you to list, generate, and edit Quadlets visually.</p>
<h3 id="key-features-of-the-extension">Key Features of the Extension<a href="#key-features-of-the-extension" aria-label="Direct link to Key Features of the Extension" title="Direct link to Key Features of the Extension">​</a></h3>
<ul>
<li><strong>Integration with Podlet</strong>: Generates Quadlets from existing Podman objects<sup><a href="#user-content-fn-2-4453df" id="user-content-fnref-2-4453df" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>.</li>
<li><strong>Quadlet Management UI</strong>: Provides a dedicated interface to list, edit, delete, start, and stop Quadlets.</li>
<li><strong>Logs Viewer</strong>: Fetches and displays systemd logs using journalctl for troubleshooting.</li>
</ul>
<h3 id="installation">Installation<a href="#installation" aria-label="Direct link to Installation" title="Direct link to Installation">​</a></h3>
<p>If you already have the latest version of Podman Desktop, you can <a href="podman-desktop:extension/podman-desktop.quadlet"><strong>click here to install the Podman Quadlet extension</strong></a>.</p>
<p>Alternatively, navigate to the Extensions page within Podman Desktop to install it.</p>
<h3 id="list-quadlets-clipboard">List Quadlets <!-- -->📋<a href="#list-quadlets-clipboard" aria-label="Direct link to list-quadlets-clipboard" title="Direct link to list-quadlets-clipboard">​</a></h3>
<p>On the Podman Quadlet page, you can view all the Quadlets available across your Podman machines. To update the list, click <strong>Refresh</strong>.</p>
<p><img src="https://podman-desktop.io/assets/images/podman-quadlet-home-light-dd43d64eaf29d2f9b622f501dff42ffb.png" alt="Quadlets List"><img src="https://podman-desktop.io/assets/images/podman-quadlet-home-dark-c9e82c34f0facb36b072159c54b56ce9.png" alt="Quadlets List"></p><p>In Podman Desktop, you can see that a dedicated icon is used for the containers managed by a Quadlet.</p>
<p><img src="https://podman-desktop.io/assets/images/container-icon-quadlet-light-b86c5a14b2a3f6583a0efa67e6b87b28.png" alt="Container Quadlet Icon"><img src="https://podman-desktop.io/assets/images/container-icon-quadlet-dark-813e9532612012aad3a46278d8db8f2d.png" alt="Container Quadlet Icon"></p><h3 id="generate-quadlets-hammer">Generate Quadlets <!-- -->🔨<a href="#generate-quadlets-hammer" aria-label="Direct link to generate-quadlets-hammer" title="Direct link to generate-quadlets-hammer">​</a></h3>
<p>To generate a Quadlet from an existing container, you’ll need to install <a href="https://github.com/containers/podlet" target="_blank" rel="noopener noreferrer">Podlet</a>. The extension simplifies installation.</p>
<p>Use one of the following ways to install Podlet:</p>
<ul>
<li>Go to <strong> Settings &gt; CLI Tools</strong> and install Podlet using the Podman Quadlet extension.</li>
<li>Download Podlet manually from its <a href="https://github.com/containers/podlet/releases" target="_blank" rel="noopener noreferrer">GitHub release page</a>.</li>
</ul>
<p><img src="https://podman-desktop.io/assets/images/cli-podlet-light-c3a1435d0d7961b4a62a38e29ffd63fc.png" alt="Podlet Installation"><img src="https://podman-desktop.io/assets/images/cli-podlet-dark-58159bbeed8fc3dda26e0e88dfe891ca.png" alt="Podlet Installation"></p><h4 id="example-generate-a-container-quadlet">Example: Generate a Container Quadlet<a href="#example-generate-a-container-quadlet" aria-label="Direct link to Example: Generate a Container Quadlet" title="Direct link to Example: Generate a Container Quadlet">​</a></h4>
<ol>
<li>Start a container using Podman:</li>
</ol>
<div><pre tabindex="0"><code><span><span>podman</span><span> run </span><span>--name</span><span> nginx-demo </span><span>-d</span><span> </span><span>-p</span><span> </span><span>80</span><span>:8080 nginx</span><br></span></code></pre></div>
<ol start="2">
<li>In Podman Desktop, find your container on the Containers page.</li>
<li>Click the <strong>overflow menu</strong> icon and select <strong>Generate Quadlet</strong>.</li>
</ol>
<p><img src="https://podman-desktop.io/assets/images/generate-quadlet-action-light-9d7bc4b162aa72adeb6d1bf91f72acd7.png" alt="Container actions"><img src="https://podman-desktop.io/assets/images/generate-quadlet-action-dark-76b7699d969dd5f80fd28c6b3acd1fe2.png" alt="Container actions"></p><ol start="4">
<li>Click <strong>Generate</strong> to finalize the Quadlet.</li>
</ol>
<p><img src="https://podman-desktop.io/assets/images/generate-form-options-light-e09f8de6226947ec69a1548ff8624a0e.png" alt="Quadlet Generate Form"><img src="https://podman-desktop.io/assets/images/generate-form-options-dark-53ccd0966f5fbee1dbd9f9e5223d80d1.png" alt="Quadlet Generate Form"></p><ol start="5">
<li>Optional: Edit the Quadlet configuration details.</li>
<li>Click <strong>Load into machine</strong>.</li>
</ol>
<p><img src="https://podman-desktop.io/assets/images/generate-form-edit-light-a63038e484f23e452c00c67c2f4ea2ff.png" alt="Quadlet Generate Form"><img src="https://podman-desktop.io/assets/images/generate-form-edit-dark-ebea360be56e8a803c6e5fdd677ca98c.png" alt="Quadlet Generate Form"></p><p>Congrats 🎉 you created your first Quadlet!</p>
<h3 id="edit-quadlets-pen">Edit Quadlets <!-- -->🖊<a href="#edit-quadlets-pen" aria-label="Direct link to edit-quadlets-pen" title="Direct link to edit-quadlets-pen">​</a></h3>
<p>Click the Quadlet <strong>STATUS</strong> icon to view its details page, which has three tabs:</p>
<ul>
<li><strong>Generated</strong>: View the systemd unit generated by Podman (read-only).</li>
<li><strong>Source</strong>: Edit the Quadlet file directly.</li>
<li><strong>Logs</strong>: Monitor logs for the service using journalctl.</li>
</ul>
<p>You can make changes to the Quadlet’s source file and apply updates as needed.</p>
<p><img src="https://podman-desktop.io/assets/images/quadlet-details-source-light-c4da0f3f8b8a56d3cc4c3dff0fa5c796.png" alt="Quadlet Details Source"><img src="https://podman-desktop.io/assets/images/quadlet-details-source-dark-b1496cbe3e4692864ad17d1675a71e6d.png" alt="Quadlet Details Source"></p><h3 id="view-quadlet-logs-scroll">View Quadlet Logs <!-- -->📜<a href="#view-quadlet-logs-scroll" aria-label="Direct link to view-quadlet-logs-scroll" title="Direct link to view-quadlet-logs-scroll">​</a></h3>
<p>Since a Quadlet's corresponding resource is managed by systemd we can access corresponding unit's logs using journalctl.</p>
<p><img src="https://podman-desktop.io/assets/images/quadlet-details-logs-light-017268786f1d799f5e324c1fae9b7989.png" alt="Quadlet Details Logs"><img src="https://podman-desktop.io/assets/images/quadlet-details-logs-dark-ddad799f50f58aa48e7e931de1c052b1.png" alt="Quadlet Details Logs"></p><h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>Podman Quadlets provide a powerful way to manage containers declaratively with systemd, bridging the gap between lightweight container management and full orchestration tools like Kubernetes.</p>
<p>With the Podman Quadlet extension in Podman Desktop, users gain a convenient interface to manage Quadlets visually, reducing complexity and saving time.</p>
<p>Try it today and streamline your container workflows!</p>
<!-- -->
<section data-footnotes="true">
<ol>
<li id="user-content-fn-1-4453df">
<p><a href="https://docs.podman.io/en/latest/markdown/podman-systemd.unit.5.html" target="_blank" rel="noopener noreferrer">https://docs.podman.io/en/latest/markdown/podman-systemd.unit.5.html</a> <a href="#user-content-fnref-1-4453df" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2-4453df">
<p><a href="https://github.com/containers/podlet" target="_blank" rel="noopener noreferrer">https://github.com/containers/podlet</a> <a href="#user-content-fnref-2-4453df" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4.1 in the API (604 pts)]]></title>
            <link>https://openai.com/index/gpt-4-1/</link>
            <guid>43683410</guid>
            <pubDate>Mon, 14 Apr 2025 17:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/gpt-4-1/">https://openai.com/index/gpt-4-1/</a>, See on <a href="https://news.ycombinator.com/item?id=43683410">Hacker News</a></p>
Couldn't get https://openai.com/index/gpt-4-1/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. and El Salvador Say They Won't Return Man Who Was Mistakenly Deported (257 pts)]]></title>
            <link>https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs</link>
            <guid>43683405</guid>
            <pubDate>Mon, 14 Apr 2025 17:01:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs">https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs</a>, See on <a href="https://news.ycombinator.com/item?id=43683405">Hacker News</a></p>
Couldn't get https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Is a Systemic Risk to the Tech Industry (113 pts)]]></title>
            <link>https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/</link>
            <guid>43683071</guid>
            <pubDate>Mon, 14 Apr 2025 16:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/">https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/</a>, See on <a href="https://news.ycombinator.com/item?id=43683071">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <p><strong><em>Before we go any further: I hate to ask you to do this, but I need your help — I'm up for this year's Webbys for the best business podcast award. I know it's a pain in the ass, but</em></strong><a href="https://vote.webbyawards.com/PublicVoting?ref=wheresyoured.at#/2025/podcasts/individual-episode/business"><strong><em> <u>can you sign up and vote for Better Offline</u></em></strong></a><strong><em>? I have never won an award in my life, so help me win this one.</em></strong></p><hr><p><strong><em>Soundtrack: </em></strong><a href="https://www.youtube.com/watch?v=L4PztrhXkXohttps%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DL4PztrhXkXo&amp;ref=wheresyoured.at"><strong><em><u>Mastodon - High Road</u></em></strong></a></p><hr><p>I wanted to start this newsletter with a pithy anecdote about chaos, both that caused by Donald Trump's tariffs and the brittle state of the generative AI bubble.</p><p>Instead, I am going to write down some questions, and make an attempt to answer them.</p><h2 id="how-much-cash-does-openai-have"><strong>How Much Cash Does OpenAI Have?</strong></h2><p>Last week, OpenAI closed "<a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?ref=wheresyoured.at"><u>the largest private tech funding round in history</u></a>," where it "raised"&nbsp; an astonishing "$40 billion," and the reason that I've put quotation marks around it is that OpenAI has only raised $10 billion of the $40 billion, with the rest arriving by "the end of the year."&nbsp;</p><p>The remaining $30 billion — $20 billion of which will (allegedly) be provided by SoftBank — is partially contingent on OpenAI's conversion from a non-profit to a for-profit by the end of 2025, and if it fails,<a href="https://www.cnbc.com/2025/03/31/openai-funding-could-be-cut-by-10-billion-if-for-profit-move-lags.html?ref=wheresyoured.at"> <u>SoftBank will only give OpenAI a further $20 billion</u></a>. The round also valued OpenAI at $300 billion.</p><p>To put that in context, OpenAI had revenues of $4bn in 2024. This deal <em>values OpenAI at 75 times its revenue</em>. That’s a bigger gulf than Tesla at its peak market cap — a company that was, in fact, worth more than all other legacy car manufacturers combined, despite making far less than them, and shipping a fraction of their vehicles.&nbsp;</p><p>I also want to add that, as of writing this sentence,<strong> this money is yet to arrive.</strong><a href="https://group.softbank/en/news/press/20250401?ref=wheresyoured.at"><strong> </strong><u>SoftBank's filings</u></a> say that the money will arrive mid-April — and that SoftBank would be borrowing as much as $10 billion to finance the round, with the option to syndicate part of it to other investors. For the sake of argument, I'm going to assume this money actually arrives.</p><p>Filings also suggest that "in certain circumstances" the second ($30 billion) tranche could arrive "in early 2026." This isn't great. <strong>It also seems that SoftBank's $10 billion commitment is contingent on getting a loan, "...financed through borrowings from Mizuho Bank, Ltd., among other financial institutions."</strong></p><p><a href="https://www.theverge.com/openai/640894/chatgpt-has-hit-20-million-paid-subscribers?ref=wheresyoured.at"><u>OpenAI also revealed it now has 20 million paying subscribers</u></a> and over 500 million weekly active users. If you're wondering why it doesn’t talk about <em>monthly</em> active users, it's because they'd likely be much higher than 500 million, which would<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=It%20would%20also%20suggest%20a%20conversion%20rate%20of%202.583%25%20from%20free%20to%20paid%20users%20on%20ChatGPT%20%E2%80%94%20an%20astonishingly%20bad%20number%2C%20one%20made%20worse%20by%20the%20fact%20that%20every%20single%20user%20of%20ChatGPT%2C%20regardless%20of%20whether%20they%20pay%2C%20loses%20the%20company%20money."> <u>reveal exactly how poorly OpenAI converts free ChatGPT users to paying ones</u></a>, and how few people use ChatGPT in their day-to-day lives.</p><p>The Information reported back in January that<a href="https://www.theinformation.com/articles/openai-tightens-grip-on-high-end-of-app-market-muratis-startup-gets-a-name?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>OpenAI was generating $25 million in revenue a month from its $200-a-month "Pro" subscribers</u></a> (<a href="https://techcrunch.com/2025/01/05/openai-is-losing-money-on-its-pricey-chatgpt-pro-plan-ceo-sam-altman-says/?ref=wheresyoured.at"><u>it still loses money on every one of them</u></a>), suggesting around 125,000 ChatGPT Pro subscribers. Assuming the other 19,875,000 users are paying $20 a month, that puts its revenue at about $423 million a month, or about $5 billion a year, from ChatGPT subscriptions.&nbsp;</p><p>This is what reporters mean when they say "annualized revenue" by the way — it's literally the monthly revenue multiplied by 12.</p><p><a href="https://www.bloomberg.com/news/articles/2025-03-26/openai-expects-revenue-will-triple-to-12-7-billion-this-year?ref=wheresyoured.at"><u>Bloomberg reported recently that OpenAI expects its 2025 revenue to "triple" to $12.7 billion this year</u></a>.<a href="https://www.wheresyoured.at/oai-business/#:~:text=Licensing%20Access%20To%20Models%20And%20Services%20%E2%80%94%2027%25%20of%20revenue%20(approximately%20%241%20billion)."> <u>Assuming a similar split of revenue to 2024</u></a>, this would require OpenAI to nearly double its annualized subscription revenue from Q1 2025 (from $5 billion to around $9.27 billion) <strong>and nearly quadruple API revenue </strong>(from 2024's revenue of $1 billion, which includes Microsoft's 20% payment for access to OpenAI's models, to $3.43 billion).</p><p>While these are messy numbers, it's unclear how OpenAI intends to pull this off.</p><p>The Information reported in February<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>that it planned to do so by making $3 billion a year selling "agents,"</u></a> with ChatGPT subscriptions ($7.9 billion) and API calls ($1.8 billion) making up the rest. This, of course, is utter bollocks.<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=Counterpoint%3A%20OpenAI%20has%20a%20new%20series%20of%20products%20that%20could%20open%20up%20new%20revenue%20streams%20such%20as%20Operator%2C%20its%20%22agent%22%20product%2C%20and%20%22Deep%20Research%2C%22%20their%20research%20product."> <u>OpenAI's "agents" can't do even the simplest tasks,</u></a> and<a href="https://www.cnbc.com/2025/02/03/softbank-commits-to-joint-venture-with-openai.html?ref=wheresyoured.at"> <u>three billion dollars of the $12.7 billion figure appears to be a commitment made by SoftBank to purchase</u></a> OpenAI's tech for its various subsidiaries and business units.&nbsp;</p><p>Let's say out the numbers precisely:</p><ul><li><strong>Incoming monthly revenue: </strong>roughly $425 million, give or take.</li><li><strong>Theoretical revenue from Softbank:</strong> $250 million a month. However, I can find no proof that SoftBank has begun to make these payments or, indeed, that it intends to make them.</li><li><strong>Liquidity:</strong><ul><li>$10 billion <strong>that it is yet to receive</strong> from SoftBank and a syndicate of investors including Microsoft, <strong>potentially.</strong></li><li><a href="https://openai.com/index/new-credit-facility-enhances-financial-flexibility/?ref=wheresyoured.at"><u>An indeterminate amount of remaining capital on the $4 billion credit facility provided by multiple banks</u></a> back in October 2024, raised alongside a funding round that valued the company at $157 billion.<ul><li>As a note, this announcement stated that OpenAI had "access to over $10 billion in liquidity."</li></ul></li><li><strong>Based on reports, OpenAI will not have access to the rest of its $40bn funding until "the end of the year," and it's unclear what part of the end of the year.</strong></li></ul></li></ul><p>We can assume, in this case, that OpenAI likely has, in the best case scenario, <strong>access to roughly $16 billion in liquidity at any given time. </strong>It's reasonable to believe that OpenAI will raise more <em>debt</em> this year, and I'd estimate it does so to the tune of around $5 billion or $6 billion. Without it, I am not sure what it’s going to do.</p><p><strong>As a reminder: OpenAI loses money on every single user.</strong></p><h2 id="what-are-openais-obligations"><strong>What Are OpenAI's Obligations?</strong></h2><p>When I wrote "<a href="https://www.wheresyoured.at/to-serve-altman/"><u>How Does OpenAI Survive</u></a>?" and "<a href="https://www.wheresyoured.at/oai-business/"><u>OpenAI Is A Bad Business</u></a>," I used reported information to explain how this company was, at its core, unsustainable.</p><p>Let's refresh our memories.</p><h3 id="compute-costs-at-least-13-billion-in-2025-with-microsoft-alone-and-as-much-as-594-million-to-coreweave"><strong>Compute Costs: at least $13 billion in 2025 <em>with Microsoft alone</em>, and as much as $594 million to CoreWeave.</strong></h3><ul><li><strong>In 2024,</strong><a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=As%20a%20note,run%20this%20company."><strong> <u>OpenAI spent $9 billion to lose $5 billion</u></strong></a><strong>.</strong><ul><li>This figure includes the $3 billion spent on training new models and $2 billion on running them.</li></ul></li></ul><p>It seems, from even a cursory glance, that OpenAI's costs are increasing dramatically. The Information reported earlier in the year that<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"> <u>OpenAI projects to spend <strong>$13 billion on compute with Microsoft alone in 2025</strong></u></a><strong>,</strong><a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"><strong> </strong><u>nearly <em>tripling</em> what it spent in total on compute in 2024 ($5 billion)</u></a>.</p><p>This suggests that OpenAI's costs are skyrocketing, and that was before<a href="https://techcrunch.com/2025/03/31/openais-new-image-generator-is-now-available-to-all-users/?ref=wheresyoured.at"> <u>the launch of its new image generator</u></a> which led to multiple complaints from Altman<a href="https://x.com/sama/status/1905296867145154688?ref=wheresyoured.at"> <u>about a lack of available GPUs</u></a>,<a href="https://x.com/sama/status/1907098207467032632?ref=wheresyoured.at"> <u>leading to OpenAI's CEO saying to expect "stuff to break" and delays in new products</u></a>. Nevertheless, even if we assume OpenAI factored in the compute increases into its projections, <strong>it still expects to pay Microsoft $13 billion for compute this year.</strong></p><p>This number, however, doesn't include the $12.9 billion five-year-long compute deal signed with CoreWeave,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>a deal that was a result of Microsoft declining to pick up the option to buy said compute itself</u></a>.<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=The%20recent%20analyst%20forecasts%20took%20into%20account%20its%20largest%20ever%20single%20contract%2C%20a%20%2411.9%20billion%20deal%20with%20OpenAI%20that%20CoreWeave%20said%20would%20begin%20in%20October.%20That%20means%20it%20will%20only%20be%20able%20to%20book%20those%20revenues%20toward%20the%20tail%20end%20of%20this%20year."> <u>Payments for this deal, according to The Information, start in October 2025</u></a>, and assuming that it's evenly paid (the terms of these contracts are generally secret, even in the case of public companies), this would <strong>still amount to roughly $2.38 billion a year.</strong></p><p>However, for the sake of argument, let's consider the payments are around $198 million a month, though there are scenarios — such as, say,<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Four%20%2D%20CoreWeave%20Is%20Using%20A%20Suspicious%20and%20Unproven%20Partner%20To%20Build%20its%20Entire%20Infrastructure"> <u>CoreWeave's buildout partner not being able to build the data centers</u></a> or<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Three%3A%20CoreWeave%20Does%20Not%20Have%20Access%20To%20The%20Capital%20Necessary%20To%20Meet%20Its%20Obligations"> <u>CoreWeave not having the money to pay to build them</u></a> — where OpenAI might pay less.</p><p>To be clear, and I’ll explain in greater detail later, this wouldn’t be a good thing, either. While it would be off the hook for some of its payments, it would also be without the compute that’s essential for it to continue growing, serving existing customers, and building new AI models. Cash and compute are <em>both</em> essential to OpenAI’s survival.&nbsp;&nbsp;</p><h3 id="stargate-1-billion"><strong>Stargate: $1 Billion+</strong></h3><p><a href="https://www.reuters.com/technology/openai-softbank-each-commit-19-bln-stargate-data-center-venture-information-2025-01-23/?ref=wheresyoured.at"><u>OpenAI has dedicated somewhere in the region of $19 billion to the Stargate data center project</u></a>, along with another $19 billion provided by SoftBank and an indeterminate amount by other providers.</p><p><a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"><u>Based on reporting from Bloomberg</u></a>, OpenAI plans to have 64,000 Blackwell GPUs running "by the end of 2026," or roughly $3.84 billion worth of them. I should also note that Bloomberg said that 16,000 of these chips would be operational by Summer 2025, though it's unclear if that will actually happen.</p><p>Though it's unclear who actually pays for what parts of Stargate, it's safe to assume that OpenAI will have to, <strong>at the very least, put a billion dollars into a project that is meant to be up and running by the end of 2026,</strong> if not more.</p><p>As of now, Stargate has exactly one data center under development in Abilene, Texas, and as above, it's unclear how that's going, though <a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"><u>a recent piece from The Information reported</u></a> that it was currently "empty and incomplete," and that if it stays that way, "OpenAI could walk away from the deal, which would cost Oracle billions of dollars." Though the article takes pains to assure the reader that won't be likely, even an <em>inkling</em> of such a possibility is a bad sign.</p><p><a href="https://www.businessinsider.com/texas-stargate-data-center-build-cost-2025-1?ref=wheresyoured.at"><u>Business Insider's reporting on the site in Abilene calls it a</u></a> "$3.4 billion data center development" (<a href="https://crusoe.ai/newsroom/crusoe-blue-owl-capital-primary-digital-joint-venture/?ref=wheresyoured.at"><u>as did the press release from site developer Crusoe</u></a>), though these numbers don't include GPUs, hardware, or the labor necessary to run them. Right now, Crusoe is (according to Business Insider) building "six new data centers, each with a minimum square footage...[which will] join the two it is already constructing for Oracle." Oracle has signed, according to The Information, a 15-year-long lease with Crusoe for its data centers, all of which will be rented to OpenAI.</p><p>In any case, OpenAI’s exposure could be much, much higher than the $1bn posited at the start of this section (and I’ll explain in greater depth how I reached that figure at the bottom of this section). If OpenAI has to contribute significantly to the costs associated with building Stargate, it could be on the hook for <em>billions</em>.<a href="https://www.datacenterdynamics.com/en/news/crusoe-begins-construction-on-second-phase-of-abilene-texas-data-center-campus-will-add-six-buildings/?ref=wheresyoured.at">&nbsp;</a></p><p><a href="https://www.datacenterdynamics.com/en/news/crusoe-begins-construction-on-second-phase-of-abilene-texas-data-center-campus-will-add-six-buildings/?ref=wheresyoured.at"><u>Data Center Dynamics reports that the Abilene site is meant to have 200MW of compute capacity in the first half of 2025, and then as much as 1.2GW by "mid-2026."</u></a><u> To give you a sense of total costs for this project, </u><a href="https://www.latitudemedia.com/news/catalyst-explaining-the-watt-bit-spread/?ref=wheresyoured.at#:~:text=But%20I%20think%20that,the%20CapEx%20deployment%20opportunity."><u>former Microsoft VP of Energy Brian Janous said in January</u></a> that it costs about $25 million a megawatt (or $25 billion a gigawatt), meaning that the initial capital expenditures for Stargate to spin up its first 200MW data center will be around $5 billion, spiraling to $30 billion for the entire project.&nbsp;</p><p>Or perhaps even more. The Information has reported that the site, which could be "...potentially one of the world's biggest AI data centers," could cost "$50 billion to $100 billion in the coming years."&nbsp;</p><p><strong>Assuming we stick with the lower end of the cost estimates, it’s likely that OpenAI is on the hook for over $5 billion for the Abilene site based on the $19 billion it has agreed to contribute to the <em>entire </em>Stargate project, the (often disagreeing) cost projections of the facility), and the contributions of other partners.&nbsp;</strong></p><p>This expenditure won’t come all at once, and will be spread across several years. Still, assuming even the rosiest numbers, it's hard to see how OpenAI doesn't have to pony up $1 billion in 2025, with similar annual payments going forward until its completion, and that is likely because the development of this site is going to be heavily delayed by both tariffs, labor shortages, and Oracle's (as reported by The Information) trust in "scrappy but unproven startups to develop the project."</p><h3 id="other-costs-at-least-35-billion"><strong>Other costs: at least $3.5 billion</strong></h3><p><a href="https://www.theinformation.com/articles/openai-projections-imply-losses-tripling-to-14-billion-in-2026?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Based on reporting from The Information last year</u></a>, OpenAI will spend <em>at least $2.5 billion</em> across salaries, "data" (referring to buying data from other companies), hosting and other cost of sales, and sales and marketing, and then another billion on what infrastructure OpenAI owns.</p><p>I expect the latter cost to balloon with OpenAI's investment in physical infrastructure for Stargate.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdTLWNPUZ-Y3kviQD7Sn0ojL9bEazTw2r7G-JOiNtwC8ac3-d_DsBNExz6VYKwjyo6C2Tp1K6h1-4KeAT0bY89YsF7HFhQHZI7l-ok8rNK1AuoeynifiUxsvRPbVSQUYUPxs0l1?key=MFOPt-R0auIdYEYVFbbAfdWf" alt="" loading="lazy" width="624" height="564"></figure><h2 id="how-does-openai-meet-its-obligations"><strong>How Does OpenAI Meet Its Obligations?</strong></h2><h3 id="openai-could-spend-28-billion-or-more-in-2025-and-lose-over-14-billion-while-having-an-absolute-maximum-of-20-billion-in-liquidity"><strong>OpenAI Could Spend $28 Billion Or More In 2025, and Lose over $14 Billion while having an absolute maximum of $20 billion in liquidity</strong></h3><p><a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=The%20New%20York%20Times%20reports%20that%20OpenAI%20projects%20it%27ll%20make%20%2411.6%20billion%20in%202025%2C%20and%20assuming%20that%20OpenAI%20burns%20at%20the%20same%20rate%20it%20did%20in%202024%20%E2%80%94%20spending%20%242.25%20to%20make%20%241"><u>Based on previous estimates, OpenAI spends about $2.25 to make $1.</u></a> At that rate, it's likely that OpenAI's costs <em>in its rosiest revenue projections of $12.7 billion </em>are at least $28 billion — <strong>meaning that it’s on course to burn at least $14 billion in 2025.</strong></p><p>Assuming that OpenAI has <strong>all of its liquidity from last year </strong>(it doesn't, but for sake of argument, let’s pretend it still has the full $10 billion), <strong>as well as the $10 billion from SoftBank</strong>, it is <em>still</em> unclear how it meets its obligations.</p><p>While OpenAI likely has preferential payment structures with all vendors, such as its discounted rates with Microsoft for Azure cloud services, it will still have to pay them, especially in the case of costs related to Stargate, many of which will be up-front costs. In the event that its costs are as severe as reporting suggests, it’s likely the company will find itself needing to raise more capital — whether through equity (or the weird sort-of equity that it issues) or through debt.&nbsp;</p><p>And yes, while OpenAI has some revenue, it comes at a terrible cost, and anything that isn’t committed to paying for salaries and construction fees will likely be immediately funnelled directly into funding the obscene costs behind inference and training models like GPT 4.5 — a "<a href="https://www.wheresyoured.at/power-cut/#:~:text=The%20bad%20news%20was%20that%2C%20and%20I%20quote%2C%20GPT%204.5%20is%20%E2%80%9C...a%20giant%2C%20expensive%20model%2C%E2%80%9D"><u>giant expensive model</u></a>" to run that<a href="https://help.openai.com/en/articles/10658365-gpt-4-5-in-chatgpt?ref=wheresyoured.at"> <u>the company has nevertheless pushed to every user</u></a>.</p><p>Worse still, OpenAI has, while delaying its next model (GPT-5),<a href="https://techcrunch.com/2025/04/04/openai-says-itll-release-o3-after-all-delays-gpt-5/?ref=wheresyoured.at"> <u>promised to launch its o3 reasoning model after saying it wouldn't do so</u></a>, which is strange, because it turns out that o3 is actually <em>way</em> more expensive to run than people thought.&nbsp;</p><p>Reasoning models are almost always more expensive to operate, as they involve the model “checking” its work, which, in turn, requires more calculations and more computation. Still, o3 is ludicrously expensive even for this category, with the Arc Prize Foundation (a non-profit that makes the ARC-AGI test for benchmarking models) estimating that it will cost<a href="https://techcrunch.com/2025/04/02/openais-o3-model-might-be-costlier-to-run-than-originally-estimated/?ref=wheresyoured.at"> <em><u>$30,000 a task.</u></em></a></p><h3 id="softbank-has-to-borrow-money-to-meet-its-openai-and-stargate-obligations-leading-to-softbanks-financial-condition-likely-deteriorating"><strong>SoftBank Has To Borrow Money To Meet Its OpenAI and Stargate Obligations, leading to SoftBank's  "...financial condition likely deteriorating."</strong></h3><p>As of right now, SoftBank has committed to the following:</p><ul><li>At least $30 billion ($7.5 of the initial $10 billion, and $22.5 billion of the remaining $30 billion) in funding as part of OpenAI's recent $40bn funding round.<ul><li>This assumes that SoftBank finds others to invest with it. <a href="https://group.softbank/en/news/press/20250401?ref=wheresyoured.at"><u>SoftBank's filings surrounding OpenAI's funding</u></a> also suggest that SoftBank is, ultimately, on the hook for the entire $40 billion, but <em>can</em> syndicate with other investors.<a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?ref=wheresyoured.at"> <u>Reporting suggests that syndication will happen with Coatue, Microsoft and other investors</u></a>.</li><li>If OpenAI fails to convert to a for-profit, that $40bn figure is slashed to $30, although, again, SoftBank’s share of the final sum is contingent upon whether it finds other investors to join the deal.&nbsp;</li></ul></li><li><a href="https://www.cnbc.com/2025/02/03/softbank-commits-to-joint-venture-with-openai.html?ref=wheresyoured.at"><u>$3 billion in spend on OpenAI "tech."</u></a></li><li>$19 billion for the Stargate data center project,<a href="https://www.theinformation.com/articles/softbanks-son-goes-on-a-new-borrowing-binge-to-fund-ai?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>which SoftBank takes financial responsibility for</u></a>.<ul><li><strong>Total: $52 billion or $62 billion, with at least $20 billion due by the end of 2025.</strong></li></ul></li></ul><p>SoftBank's exposure to OpenAI is materially harming the company.<a href="https://www.wsj.com/business/deals/openai-softbank-investment-debt-51b4a130?ref=wheresyoured.at"> <u>To quote the Wall Street Journal:</u></a></p><blockquote>Ratings agency S&amp;P Global said last week that SoftBank’s “financial condition will likely deteriorate” as a result of the OpenAI investment and that its plans to add debt could lead the agency to consider downgrading SoftBank’s ratings.&nbsp;</blockquote><p>While one might argue that SoftBank has a good amount of cash, the Journal also adds that it’s&nbsp; somewhat hamstrung in its use as a result of CEO Masayoshi Son's reckless gambles:</p><blockquote>SoftBank had a decent buffer of $31 billion of cash as of Dec. 31, but the company has also pledged to hold much of that in reserve to quell worried investors. SoftBank has committed not to borrow more than 25% of the value of all of its holdings, which means it will likely need to sell some of the other parts of its empire to pay for the rest of the OpenAI deal.</blockquote><p>Worse still, it seems, as mentioned before, that SoftBank will be financing the entirety of the first $10 billion — or $7.5 billion, assuming it finds investors to syndicate the first tranche, and they follow through right until the moment Masayoshi Son hits ‘send’ on the wire transfer .</p><p>As a result, SoftBank will likely have to start selling off parts of its valuable holdings in companies like Alibaba and ARM, or, worse still,<a href="https://www.wheresyoured.at/power-cut/#:~:text=On%20the%20subject%20of%20Softbank%E2%80%99s%20holdings"> <u>parts of its ailing investments from its Vision Fund</u></a>, resulting in a material loss on its underwater deals.</p><p>This is an untenable strategy, and I'll explain why.</p><h3 id="openai-needs-at-least-40-billion-a-year-to-survive-and-its-costs-are-increasing"><strong>OpenAI Needs At Least $40 billion A Year To Survive, And Its Costs Are Increasing</strong></h3><p>While we do not have much transparency into OpenAI's actual day-to-day finances, we can make the educated guess that its costs are <em>increasing</em> based on the amount of capital it’s raising. If OpenAI’s costs were flat, or only mildly increasing, we’d expect to see raises roughly the same size as previous ones. Its $40bn raise is nearly <em>six</em> times the previous funding round.&nbsp;</p><p>Admittedly, multiples like that aren’t particularly unusual. If a company raises $300,000 in a pre-seed round, and $3m in a Series A round, that’s a tenfold increase. But we’re not talking about hundreds of thousands of dollars, or even millions of dollars. We’re talking about <em>billions</em> of dollars. If OpenAI’s funding round with Softbank goes as planned, it’ll raise the equivalent of the entire GDP of Estonia — a fairly wealthy country itself, and one that’s also a member of Nato and the European Union. That alone should give you a sense of the truly insane scale of this.&nbsp;</p><p>Insane, sure, but undoubtedly necessary. <a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=this%20year%20to-,%2428%20billion%20in%202028,-.%20The%20spending%20forecast"><u>Per The Information</u></a>, OpenAI expects to spend as much as $28 billion in compute on Microsoft's Azure cloud in 2028. Over a third of OpenAI's revenue, per the same article, will come from SoftBank's (alleged) spend.It's reasonable to believe that OpenAI will, as a result, need to raise in excess of $40 billion in funding a year, though it's reasonable to believe that it will need to raise more along the lines of $50 billion or more a year until it reaches profitability. This is due to both its growing cost of business, as well as its various infrastructure commitments, both in terms of Stargate, as well as with third-party suppliers like CoreWeave and Microsoft.&nbsp;</p><blockquote><strong>Counterpoint: OpenAI could reduce costs:</strong> While this is <u>theoretically</u> possible, there is no proof that this is taking place.<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information claims that</u></a> "...OpenAI would turn profitable by the end of the decade after the buildout of Stargate," but there is no suggestion as to how it might do so, or how building more data centers would somehow reduce its costs.This is especially questionable when you realize that<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=OpenAI%20pays%20just%20over%2025%25%20of%20the%20cost%20of%20Azure%E2%80%99s%20GPU%20compute%20as%20part%20of%20its%20deal%20with%20Microsoft%20%E2%80%94%20around%20%241.30%2Dper%2DGPU%2Dper%2Dhour%20versus%20the%20regular%20Azure%20cost%20of%20%243.40%20to%20%244."> <u>Microsoft is already providing discounted pricing on Azure compute</u></a>. We don’t know if these discounts are below Microsoft’s break-even point — which it wouldn’t, nor would any other company offer, if they didn’t have something else to incentivize it, such as equity or a profit-sharing program. Microsoft, for what it’s worth, has both of those things.&nbsp;</blockquote><p>OpenAI CEO Sam Altman's statements around costs also suggest that they're increasing. In late February,<a href="https://techcrunch.com/2025/02/27/openai-ceo-sam-altman-says-the-company-is-out-of-gpus/?ref=wheresyoured.at"> <u>Altman claimed that OpenAI was "out of GPUs</u></a>." While this suggests that there’s demand for some products — like its image-generating tech, which enjoyed a viral day in the sun in March — it also means that to meet the demand it needs to spend more. And, at the risk of repeating myself, that demand doesn’t necessarily translate into profitability.&nbsp;</p><h3 id="softbank-cannot-fund-openai-long-term-as-openais-costs-are-projected-to-be-320-billion-in-the-next-five-years"><strong>SoftBank Cannot Fund OpenAI Long-Term, as OpenAI's costs are projected to be $320 billion in the next five years</strong></h3><p>As discussed above, SoftBank has to overcome significant challenges to fund both OpenAI and Stargate, and when I say "fund," I mean <strong>fund the current state of both projects, assuming no further obligations.</strong></p><p>The Information reports that<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>OpenAI forecasts that it will spend $28 billion on compute with Microsoft alone in 2028</u></a>. The same article also reports that OpenAI "would turn profitable by the end of the decade after the buildout of Stargate," suggesting that OpenAI's operating expenses will grow exponentially year-over-year.</p><p>These costs, per The Information, are astronomical:</p><blockquote>The reason for the expanding cash burn is simple: OpenAI is spending whatever revenue comes in on computing needs for operating its existing models and developing new models. The company expects those costs to surpass $320 billion overall between 2025 and 2030.<p>The company expects more than half of that spending through the end of the decade to fund research-intensive compute for model training and development. That spending will rise nearly sixfold from current rates to around $40 billion per year starting in 2028. OpenAI projects its spending on running AI models will surpass its training costs in 2030.</p></blockquote><p>SoftBank has had to (and will continue having to) go to remarkable lengths to fund OpenAI's current ($40 billion) round, lengths so significant that it may lead to its credit rating being further downgraded.</p><p>Even if we assume the best case scenario — OpenAI successfully converts to a for-profit entity by the end of the year, and receives the full $30 billion — it seems unlikely (if not impossible) for it to continue raising the amount of capital they need to continue operations. As I’ve argued in previous newsletters, there are only a few entities that can provide the kinds of funding that OpenAI needs. These include big tech-focused investment firms like Softbank, sovereign wealth funds (like those of Saudi Arabia and the United Emirates), and perhaps the largest tech companies.</p><p>These entities can meet OpenAI’s needs, but not all the time. It’s not realistic to expect Softbank, or Microsoft, or the Saudis, or Oracle, or whoever, to provide $40bn <em>every year</em> for the foreseeable future.&nbsp;</p><p>This is especially true for Softbank. Based on its current promise to not borrow more than 25% of its holdings, it is near-impossible that SoftBank will be able to continue funding OpenAI at this rate ($40 billion a year), and $40 billion a year may not actually be enough.</p><p>Based on<a href="https://group.softbank/en/ir/stock/sotp?ref=wheresyoured.at"> <u>its last reported equity value of holdings</u></a>, SoftBank's investments and other assets are worth around $229 billion, meaning that it can borrow just over $57bn while remaining compliant with these guidelines.</p><p>In any case, it is unclear how SoftBank can fund OpenAI, but it's far clearer that <em>nobody else is willing to.</em></p><h3 id="openai-is-running-into-capacity-issues-suggesting-material-instability-in-its-business-or-infrastructure-%E2%80%94-and-its-unclear-how-it-expands-further"><strong>OpenAI Is Running Into Capacity Issues, Suggesting Material Instability In Its Business or Infrastructure — And It's Unclear How It Expands Further</strong></h3><p>Before we go any further, it's important to note that OpenAI does not really have its own compute infrastructure. The majority of its compute is provided by Microsoft, though, as mentioned above,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>OpenAI now has a deal with CoreWeave to take over Microsoft's future options for more capacity</u></a>.</p><p>Anyway, in the last 90 days, Sam Altman has complained about a lack of GPUs and pressure on OpenAI's servers multiple times. Forgive me for repeating stuff from above, but this is necessary.</p><ul><li><a href="https://x.com/sama/status/1895203654103351462?ref=wheresyoured.at"><u>On February 27,</u></a> he lamented how GPT 4.5 was a "giant, expensive model," adding that it was "hard to perfectly predict growth surges that lead to GPU shortages." He also added that they would be adding tens of thousands of GPUs in the following week, then hundreds of thousands of GPUs "soon."</li><li><a href="https://x.com/sama/status/1905000759336620238?ref=wheresyoured.at"><u>On March 26</u></a>, he said that "images in chatgpt are wayyyy more popular than [OpenAI] expected," delaying the free tier launch as a result.</li><li><a href="https://x.com/sama/status/1905296867145154688?ref=wheresyoured.at"><u>On March 27</u></a>, he said that OpenAI's "GPUs [were] melting," adding that it was "going to introduce some temporary rate limits" while it worked out how to "make it more efficient."</li><li><a href="https://x.com/rohanjamin/status/1905721967216599199?ref=wheresyoured.at"><u>On March 28</u></a>, he retweeted Rohan Sahai, the product team lead on OpenAI's Sora video generation model, who said "The 4o image gen demand has been absolutely incredible. Been super fun to watch the Sora feed fill up with great content...GPUs are also melting in Sora land unfortunately so you may see longer wait times / capacity issues over coming days."</li><li><a href="https://x.com/sama/status/1906210479695126886?ref=wheresyoured.at"><u>On March 30</u></a>, he said "can yall please chill on generating images this is insane our team needs sleep."</li><li><a href="https://x.com/sama/status/1907098207467032632?ref=wheresyoured.at"><u>On April 1</u></a>, he said that "we are getting things under control, but you should expect new releases from openai [sic] to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges." He also added that OpenAI is "working as fast we can to really get stuff humming; if anyone has GPU capacity in 100k chunks we can get asap please call!"</li></ul><p>These statements, in a bubble, seem either harmless or like OpenAI's growth is skyrocketing — the latter of which might indeed be true, but bodes ill for a company that burns money on every single user.</p><p>Any mention of rate limits or performance issues suggests that OpenAI is having significant capacity issues, and at this point it's unclear what further capacity it can actually expand to outside of that currently available. Remember,<a href="https://www.datacenterdynamics.com/en/news/microsoft-cancels-up-to-2gw-of-data-center-projects-says-td-cowen/?ref=wheresyoured.at"> <u>Microsoft has now pulled out of as much as 2GW of data center projects</u></a>,<a href="https://www.datacenterdynamics.com/en/news/microsoft-backs-away-from-1bn-data-center-plans-in-licking-county-ohio/?ref=wheresyoured.at"> <u>walked away from a $1 billion data center development in Ohio</u></a>, and<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>declined the option on $12bn of compute from CoreWeave that OpenAI had to pick up</u></a> — meaning that it may be pushing up against the limits of what is physically available.</p><p>While the total available capacity of GPUs at many providers like Lambda and Crusoe is unknown, we know that CoreWeave has approximately 360MWavailable,<a href="https://www.wheresyoured.at/power-cut/#:~:text=For%20some%20context,at%20this%20time."> <u>compared to Microsoft's 6.5 to 7.5 Gigawatts</u></a>, a large chunk of which already powers OpenAI.</p><p>If OpenAI is running into capacity issues, it could be one of the following:</p><ul><li>OpenAI is running up against the limit of what Microsoft has available, or is willing to offer the company.<a href="https://www.theinformation.com/articles/openai-eases-away-from-microsoft-data-centers?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported in October 2024</u></a> that OpenAI was frustrated with Microsoft, which said it wasn’t moving fast enough to supply it with servers.</li><li>While OpenAI's capacity is sufficient, It does not have the resources available to easily handle bursts in user growth in a stable manner.</li></ul><p>Per The Information's reporting, Microsoft "promised OpenAI 300,000 NVIDIA GB200 (Blackwell) chips by the end of 2025," or roughly $18 billion of chips. It's unclear if this has changed<a href="https://techcrunch.com/2025/01/21/microsoft-is-no-longer-openais-exclusive-cloud-provider/?ref=wheresyoured.at"> <u>since Microsoft allowed OpenAI to seek other compute in late January 2025</u></a>.</p><p>I also don't believe that OpenAI has any other viable options for <em>existing compute infrastructure outside of Microsoft.</em><a href="https://www.cnbc.com/2025/03/26/the-concern-with-coreweaves-250000-nvidia-chips-ahead-of-its-ipo.html?ref=wheresyoured.at"><em> </em><u>CoreWeave's current data centers mostly feature NVIDIA's aging "Hopper" GPUs</u></a>, and while it could — and likely is! — retrofitting its current infrastructure with Blackwell chips, doing so is not easy. Blackwell chips require far more powerful cooling and server infrastructure to make them run smoothly (<a href="https://www.theinformation.com/articles/nvidias-top-customers-face-delays-from-glitchy-ai-chip-racks?rc=kz8jh3&amp;ref=wheresyoured.at"><u>a problem which led to a delay in their delivery to most customers</u></a>), and even if CoreWeave was able to replace every last Hopper GPU with Blackwell (it won't), it still wouldn't match what OpenAI needs to expand.</p><p>One might argue that it simply needs to wait for the construction of the Stargate data center, or for CoreWeave to finish the gigawatt or so of construction it’s working on.</p><p><a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Per%20its%20S,its%20current%20commitments."><u>As I've previously written</u></a>, I have serious concerns over the viability of CoreWeave ever completing its (alleged) contracted 1.3 Gigawatts of capacity.</p><p>Per my article:</p><blockquote>Per its S-1, CoreWeave has contracted for around 1.3 Gigawatts of capacity, which it expects to roll out over the coming years, and based on NextPlatform's math, <strong>CoreWeave will have to spend in excess of $39 billion to build its contracted compute. It is unclear how it will fund doing so, and it's fair to assume that CoreWeave does not currently have the capacity to cover its current commitments.</strong></blockquote><p>However, even if I were to humour the idea, it is impossible that any of this project is done by the end of the year, or even in 2026. I can find no commitments to any timescale, other than the fact that OpenAI will allegedly start paying CoreWeave in October (<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=The%20recent%20analyst%20forecasts%20took%20into%20account%20its%20largest%20ever%20single%20contract%2C%20a%20%2411.9%20billion%20deal%20with%20OpenAI%20that%20CoreWeave%20said%20would%20begin%20in%20October.%20That%20means%20it%20will%20only%20be%20able%20to%20book%20those%20revenues%20toward%20the%20tail%20end%20of%20this%20year."><u>per The Information</u></a>), which could very well be using current capacity.</p><p>I can also find no evidence that Crusoe, the company building the Stargate data center, has <em>any</em> compute available. Lambda,<a href="https://lambda.ai/blog/lambda-raises-320m-to-build-a-gpu-cloud-for-ai?srsltid=AfmBOopeWiVs7rtdEu5gHfszLlR2caTYw9u_avGGz6Go2D-izzkM5CBL&amp;ref=wheresyoured.at"> <u>a GPU compute company that raised $320 million earlier in this year</u></a>, and<a href="https://www.datacenterdynamics.com/en/analysis/true-believers-lambda-labs-ai-cloud-dreams/?ref=wheresyoured.at"> <u>according to Data Center Dynamics</u></a> "operates out of colocation data centers in San Francisco, California, and Allen, Texas, and is backed by more than $820 million in funds raised just this year," suggesting that it may not have their own data centers at all. Its ability to scale is entirely contingent on the availability of whatever data center providers it has relationships with.&nbsp;</p><p>In any case, this means that OpenAI's only real choice for GPUs is CoreWeave or Microsoft. While it's hard to calculate precisely,<a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"> <u>OpenAI's best case scenario is that 16,000 GPUs come online in the summer of 2025</u></a> as part of the Stargate data center project.</p><p>That's a drop in the bucket compared to the 300,000 Blackwell GPUs that Microsoft had previously promised.</p><h3 id="any-capacity-or-expansion-issues-threaten-to-kneecap-openai"><strong>Any capacity or expansion issues threaten to kneecap OpenAI</strong></h3><p>OpenAI is, regardless of how you or I may feel about generative AI, one of the fastest-growing companies of all time. It currently has, according to its own statements, 500 million weekly active users. Putting aside that each user is unprofitable, such remarkable growth — especially as it's partially a result of its extremely resource-intensive image generator — is also a strain on its infrastructure.</p><p>The vast majority of OpenAI's users are free customers using ChatGPT, with only around 20 million paying subscribers, and the vast majority on the cheapest $20 plan. OpenAI's services — even in the case of image generation — are relatively commoditized, meaning that users can, if they really care, go and use any number of other different Large Language Model services. They can switch to Bing Image Creator, or Grok, or Stable Diffusion, or whatever.</p><p>Free users are also a burden on the company — especially with such a piss-poor conversion rate — losing it money with each prompt (which is also the case with paying customers), and the remarkable popularity of its image generation service only threatens to bring more burdensome one-off customers that will generate a few abominable Studio Ghibli pictures and then never return.</p><p>If OpenAI's growth continues at this rate, it will run into capacity issues, and it does not have much room to expand. While we do not know how much capacity it’s taking up with Microsoft, or indeed whether Microsoft is approaching capacity or otherwise limiting how much of it OpenAI can take, we do know that OpenAI has seen reason to beg for access to more GPUs.</p><p>In simpler terms, even if OpenAI wasn’t running out of money, even if OpenAI wasn’t horrifyingly unprofitable, it also may not have enough GPUs to continue providing its services in a reliable manner.</p><p>If that's the case, there really isn't much that can be done to fix it other than:</p><ul><li>Significantly limiting free users' activity on the platform, which is OpenAI's primary mechanism for revenue growth and customer acquisition.</li><li>Limiting activity or changing the economics behind its paid product, to quote Sam Altman, "<a href="https://x.com/sama/status/1889679681047482730?ref=wheresyoured.at"><u>find[ing] some way to let people to pay for compute they want to use more dynamically.</u></a>"<ul><li><a href="https://x.com/sama/status/1897036361506689206?ref=wheresyoured.at"><u>On March 4th</u></a>, Altman solicited feedback on "...an idea for paid plans: your $20 plus subscription converts to credits you can use across features like deep research, o1, gpt-4.5, sora, etc...no fixed limits per feature and you choose what you want; if you run out of credits you can buy more."</li><li><a href="https://x.com/sama/status/1876104315296968813?ref=wheresyoured.at"><u>On January 5th</u></a>, Sam Altman revealed that OpenAI is currently losing money on every paid subscription, including its $200-a-month "pro" subscription.</li><li><a href="https://www.theinformation.com/articles/openai-plots-charging-20-000-a-month-for-phd-level-agents?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=OpenAI%20CEO%20Sam,200%20a%20month.%E2%80%9D"><u>Buried in an article from The Information from March 5</u></a> is a comment that suggests it’s considering measures like changing its pricing model, with "...Sam Altman reportedly [telling] developers in London [in February] that OpenAI is primed to charge 20% or 30% of Pro customers a higher price because of how many research queries they’re doing, but he suggested an “a la carte” or pay-as-you-go approach. When it comes to agents, though, “we have to charge much more than $200 a month.”</li></ul></li></ul><p>The problem is that these measures, even if they succeed in generating more money for the company, <strong>also need to reduce the burden on OpenAI's available infrastructure.</strong></p><p><a href="https://www.wheresyoured.at/power-cut/#:~:text=Data%20center%20buildouts,a%20year%20ago."><u>Remember: data centers can take three to six years to build</u></a>, and even with the Stargate's accelerated (and I'd argue unrealistic) timelines, OpenAI isn't even unlocking a tenth of Microsoft's promised compute (16,000 GPUs online this year versus the 300,000 GPUs promised by Microsoft).</p><h3 id="what-might-capacity-issues-look-like-and-what-are-the-consequences"><strong>What Might Capacity Issues Look Like? And What Are The Consequences?</strong></h3><p>Though downtime might be an obvious choice, capacity issues at OpenAI will likely manifest in hard limits on what free users can do, some of which I've documented above. Nevertheless, I believe the real pale horses of capacity issues come from <strong>arbitrary limits on any given user group,</strong> meaning both free and paid users. Sudden limits on what a user can do — a reduction in the number of generations of images of videos for paid users, any introduction of "peak hours," or any increases in prices are a sign that OpenAI is running out of GPUs, which it has already publicly said is happening.</p><p>However, the really obvious one would be <em>service degradation</em> — delays in generations of any kind,<a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-500-internal-server-error.html?ref=wheresyoured.at#:~:text=An%20HTTP%20500%20status%20code,it%20from%20fulfilling%20the%20request."> <u>500 status code errors</u></a>, or ChatGPT failing to fully produce an answer. OpenAI has, up until this point, had fairly impressive uptime. Still, if it is running up against a wall, this streak will end.</p><p>The consequences depend on how often these issues occur, and to whom they occur. If free users face service degradation, they will bounce off the product, as their use is likely far more fleeting than a paid user, which will begin to erode OpenAI's growth. Ironically, rapid (and especially unprecedented) growth in one of OpenAI’s competitors, like xAI or Anthropic, could also represent a pale horse for OpenAI.&nbsp;</p><p>If <em>paid</em> users face service degradation, it's likely this will cause the most harm to the company, as while paid users still lose OpenAI money in the end, <em>it at least receives some money in exchange.</em></p><p>OpenAI has effectively one choice here: getting more GPUs from Microsoft, and its future depends heavily both on its generosity <em>and</em> there being enough of them at a time when Microsoft<a href="https://www.wheresyoured.at/power-cut/"> <u>has pulled back</u></a><a href="https://sherwood.news/tech/microsoft-cancels-2-gigawatts-worth-of-data-centers-analysts-say/?ref=wheresyoured.at"> <u>from two gigawatts of data centers</u></a><a href="https://www.reuters.com/technology/microsoft-pulls-back-more-data-center-leases-us-europe-analysts-say-2025-03-26/?ref=wheresyoured.at"> <em><u>specifically because of it moving away from providing compute for OpenAI</u></em></a><em>.</em></p><p>Admittedly, OpenAI has previously spent more on training models than inference (actually running them) and the company might be able to smooth downtime issues by shifting capacity. This would, of course, have a knock-on effect on its ability to continue developing new models, and the company is already losing ground, particularly when it comes to Chinese rivals like DeepSeek.</p><h3 id="openai-must-convert-to-a-for-profit-entity-by-the-end-of-2025-or-it-loses-10-billion-in-funding-and-doing-so-may-be-impossible"><strong>OpenAI Must Convert To A For-Profit Entity By The End of 2025 Or It Loses $10 Billion In Funding, And Doing So May Be Impossible</strong></h3><p>As part of its deal with SoftBank, OpenAI must convert its bizarre non-profit structure into a for-profit entity by December 2025, or it’ll lose $10 billion from its promised funding.&nbsp;</p><p>Furthermore, in the event that OpenAI fails to convert to a for-profit by October 2026,<a href="https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=yvhGAx&amp;ref=wheresyoured.at"> <u>investors in its previous $6.6 billion round can claw back their investment</u></a>, with it converting into a loan with an attached interest rate. Naturally, this represents a nightmare scenario for the company, as it’ll increase both its costs and its outgoings.</p><p>This is a complex situation that almost warrants its own newsletter, but the long and short of it is that OpenAI would have to effectively dissolve itself, <a href="https://www.upcounsel.com/converting-non-profit-to-for-profit?ref=wheresyoured.at#:~:text=Converting%20a%20nonprofit%20to%20a,a%20new%20for%2Dprofit%20entity."><u>start the process of forming an entirely new entity</u></a>, and distribute its assets to other nonprofits (or sell/license them to the for-profit company at fair market rates). It would require valuing OpenAI's assets, which in and of itself would be a difficult task, as well as getting past the necessary state regulators, the IRS, state revenue agencies, and<a href="https://www.inc.com/reuters/legal-battle-between-musk-and-openai-heads-to-trial-in-2026/91172454?ref=wheresyoured.at"> <u>the upcoming trial with Elon Musk only adds further problems</u></a>.</p><p>I’ve simplified things here, and that’s because (as I said) this stuff is complex. Suffice to say, this isn’t as simple as liquidating a company and starting afresh, or submitting a couple of legal filings. It’s a long, fraught process and one that will be — and has been — subject to legal challenges, both from OpenAI’s business rivals, as well as from civil society organizations in California.</p><p>Based on discussions with experts in the field and my own research, I simply do not know how OpenAI pulls this off <em>by October 2026,</em> let alone by the end of the year.</p><h2 id="openai-has-become-a-systemic-risk-to-the-tech-industry"><strong>OpenAI Has Become A Systemic Risk To The Tech Industry</strong></h2><p>OpenAI has become a load-bearing company for the tech industry, both as a narrative —<a href="https://www.wheresyoured.at/wheres-the-money/"> <u>as previously discussed, ChatGPT is the only Large Language Model company with any meaningful userbase</u></a> — and as a financial entity.&nbsp;</p><p>Its ability to meet its obligations and its future expansion plans are critical to the future health — or, in some cases, survival — of multiple large companies, and that's before the after-effects that will affect its customers as a result of any financial collapse.&nbsp;</p><p>The parallels to the 2007-2008 financial crisis are startling. Lehman Brothers wasn’t the largest investment bank in the world (although it was certainly big), just like OpenAI isn’t the largest tech company (though, again, it’s certainly large in terms of market cap and expenditure). Lehman Brothers’ collapse sparked a contagion that would later spread throughout the global financial services industry, and consequently, the global economy.&nbsp;</p><p>I can see OpenAI’s failure having a similar systemic effect. While there is a vast difference between OpenAI’s involvement in people’s lives compared to the millions of subprime loans issued to real people, the stock market’s dependence on the value of the Magnificent 7 stocks (Apple, Microsoft, Amazon, Alphabet, NVIDIA and Tesla), and in turn the Magnificent 7’s reliance on the stability of the AI boom narrative still threatens material harm to millions of people, and that’s before the ensuing layoffs.&nbsp;</p><p>And as I’ve said before, this entire narrative is based off of OpenAI’s success, because OpenAI <em>is</em> the generative AI industry.&nbsp;</p><p>I want to lay out the direct result of any kind of financial crisis at OpenAI, because I don't think anybody is taking this seriously.</p><h3 id="oracle-will-lose-at-least-1-billion-if-openai-doesnt-fulfil-its-obligations"><strong>Oracle Will Lose At Least $1 Billion If OpenAI Doesn't Fulfil Its Obligations</strong></h3><p><a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Per The Information</u></a>, Oracle, which has taken responsibility for organizing the construction of the Stargate data centers with unproven data center builder Crusoe, "...may need to raise more capital to fund its data center ambitions."</p><p>Oracle has signed a 15-year lease with Crusoe, and, to quote The Information, "...is on the hook for $1 billion in payments to that firm."</p><p>To further quote The Information:</p><blockquote>...while that’s a standard deal length, the unprecedented size of the facility Oracle is building for just one customer makes it riskier than a standard cloud data center used by lots of interchangeable customers with more predictable needs, according to half a dozen people familiar with these types of deals.</blockquote><p>In simpler terms, Oracle is building a giant data center for one customer — OpenAI — and has taken on the financial burden associated with it. If OpenAI fails to expand, or lacks the capital to actually pay for its share of the Stargate project, Oracle is on the hook for at least a billion dollars, and, based on The Information's reporting, is also on the hook to buy the GPUs for the site.</p><blockquote>Even before the Stargate announcement, Oracle and OpenAI had agreed to expand their Abilene deal from two to eight data center buildings, which can hold 400,000 Nvidia Blackwell GPUs, adding tens of billions of dollars to the total cost of the facility.</blockquote><p>In reality, this development will likely cost tens of billions of dollars, $19 billion of which is due from OpenAI, which does not have the money until it receives its second tranche of funding in December 2025, which is contingent partially on its ability to convert into a for-profit entity, which, as mentioned, is a difficult and unlikely proposition.</p><p>It's unclear how many of the Blackwell GPUs that Oracle has had to purchase in advance, but in the event of any kind of financial collapse at OpenAI, Oracle would likely <strong>take a loss of at least a billion dollars, if not several billion dollars.</strong></p><h3 id="coreweaves-expansion-is-likely-driven-entirely-by-openai-and-it-cannot-survive-without-openai-fulfilling-its-obligations-and-may-not-anyway"><strong>CoreWeave's Expansion Is Likely Driven Entirely By OpenAI, And It Cannot Survive Without OpenAI Fulfilling Its Obligations (And May Not Anyway)</strong></h3><p><a href="https://www.wheresyoured.at/core-incompetency/"><u>I have written a lot about publicly-traded AI compute firm CoreWeave</u></a>, and it would be my greatest pleasure to never mention it again.</p><p>Nevertheless, I have to.</p><p>The Financial Times revealed a few weeks ago that<a href="https://www.ft.com/content/163c6927-2032-4346-857e-8e3787e4babc?ref=wheresyoured.at"> <u>CoreWeave's debt payments could balloon to over $2.4 billion a year by the end of 2025</u></a>, far outstripping its cash reserves, and<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported that its cash burn would increase to $15 billion in 2025</u></a>.</p><p>As per its IPO filings, 62% of CoreWeave's 2024 revenue (a little under $2 billion, with losses of $863 million) was Microsoft compute, and based on conversations with sources, a good amount of this was Microsoft running compute for OpenAI.</p><p>Starting October 2025,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>OpenAI will start paying Coreweave as part of its five-year-long $12 billion contract</u></a>, picking up the option that Microsoft declined.<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Starting%20from%20October%202025"> <u>This is also when</u></a> CoreWeave will have to start making payments on<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Problem%20Loan%20Number%202%3A%20DDTL%202.0"> <u>its massive, multi-billion dollar DDTL 2.0 loan</u></a>, which likely makes these payments critical to CoreWeave's future.</p><p>This deal also suggests that OpenAI will become CoreWeave's largest customer. Microsoft had previously committed to spending $10 billion on CoreWeave's services "<a href="https://www.datacenterdynamics.com/en/news/microsoft-to-invest-10bn-in-coreweave-by-end-of-decade/?ref=wheresyoured.at"><u>by the end of the decade</u></a>," but CEO Satya Nadella added a few months later on a podcast that its relationship with CoreWeave was a "<a href="https://www.youtube.com/watch?v=9NtsnzRFJ_o&amp;ref=wheresyoured.at"><u>one-time thing</u></a>." Assuming Microsoft keeps spending at its previous rate — something that isn't guaranteed — it would still be only half of OpenAI's potential revenue.</p><p>CoreWeave's expansion, at this point, is entirely driven by OpenAI. 77% of its 2024 revenue came from two customers — Microsoft being the largest, and using CoreWeave as an auxiliary supplier of compute for OpenAI. As a result, the future expansion efforts —<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Per%20its%20S,its%20current%20commitments."> <u>the theoretical 1.3 gigawatts of contracted (translation: does not exist yet) compute</u></a> — are largely (if not entirely) for the benefit of OpenAI.</p><p><strong>In the event that OpenAI cannot fulfil its obligations, CoreWeave will collapse.</strong> It is that simple.&nbsp;</p><h3 id="nvidia-relies-on-coreweave-for-more-than-6-of-its-revenue-and-coreweaves-future-creditworthiness-to-continue-receiving-it-%E2%80%94-much-of-which-is-dependent-on-openai"><strong>NVIDIA Relies On CoreWeave For More Than 6% Of Its Revenue, And CoreWeave's Future Creditworthiness To Continue Receiving It — Much Of Which Is Dependent On OpenAI</strong></h3><p>I’m basing this on a comment I received from Gil Luria, Managing Director and Head of Technology Research at analyst D.A. Davidson &amp; Co:</p><blockquote>Since CRWV bought 200,000 GPUs last year and those systems are around $40,000 we believe CRWV spent $8 billion on NVDA last year. That represents more than 6% of NVDA’s revenue last year.&nbsp;</blockquote><p>CoreWeave receives preferential access to NVIDIA's GPUs, and makes up billions of dollars of its revenue.<a href="https://www.ft.com/content/41bfacb8-4d1e-4f25-bc60-75bf557f1f21?ref=wheresyoured.at"> <u>CoreWeave then takes those GPUs and raises debt using them as collateral</u></a>, then proceeds to buy more of those GPUs from NVIDIA. NVIDIA was the anchor for CoreWeave's IPO, and CEO Michael Intrator said that the IPO "wouldn't have closed" without NVIDIA buying $250 million worth of shares.<a href="https://www.theinformation.com/articles/project-osprey-how-nvidia-seeded-coreweaves-rise?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>NVIDIA invested $100 million in the early days of CoreWeave</u></a>, and, for reasons I cannot understand, also agreed to spend $1.3 billion over four years to, and I quote The Information, "rent its own chips from CoreWeave."</p><p><a href="https://www.wheresyoured.at/core-incompetency/#:~:text=potentially%20fatal%20%E2%80%94%20vulnerability.-,Sidenote,-%3A%20On%20the%20subject"><u>Buried in CoreWeave's S-1 — the document every company publishes before going public —&nbsp; was a warning about counterparty credit risk</u></a>, which is when one party provides services or goods to another with specific repayment terms, and the other party not meeting their side of the deal. While this was written as a theoretical (as it could, in theoretically, come from any company to which CoreWeave acts as a creditor) it only named one company: OpenAI.&nbsp;</p><p>As discussed previously, CoreWeave is saying that, should a customer — any customer, but really, it means OpenAI — fail to pay its bills for infrastructure built on their behalf, or for services rendered, it could have a material risk to the business.</p><blockquote><strong>Aside:</strong><a href="https://www.theinformation.com/articles/google-advanced-talks-rent-nvidia-ai-servers-coreweave?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported that Google is in "advanced talks" to rent GPUs from CoreWeave</u></a>. It also, when compared to Microsoft and OpenAI's deals with CoreWeave, noted that "...Google's potential deal with CoreWeave is "significantly smaller than those commitments, according to one of the people briefed on it, but could potentially expand in future years."</blockquote><p>CoreWeave's continued ability to do business hinges heavily on its ability to raise further debt (<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Two%20%E2%80%94%20CoreWeave%20Has%20Taken%20On%20A%20Fatal%20Amount%20of%20Debt"><u>which I have previously called into question</u></a>), and its ability to raise further debt is,<a href="https://www.ft.com/content/163c6927-2032-4346-857e-8e3787e4babc?ref=wheresyoured.at"> <u>to quote the Financial Times</u></a>, "secured against its more than 250,000 Nvidia chips and its contracts with customers, such as Microsoft." Any future debt that CoreWeave raises would be based upon its contract with OpenAI (you know, the counterparty credit risk threat that represents a disproportionate share of its revenue) and whatever GPUs it still has to collateralize.</p><p>As a result, a chunk of NVIDIA's future revenue is dependent on OpenAI's ability to fulfil its obligations to CoreWeave, both in its ability to pay them and their timeliness in doing so. If OpenAI fails, then CoreWeave fails, which then hurts NVIDIA.&nbsp;</p><p>Contagion.&nbsp;</p><h3 id="openais-expansion-is-dependent-on-two-unproven-startups-who-are-also-dependent-on-openai-to-live"><strong>OpenAI's Expansion Is Dependent On Two Unproven Startups, Who Are Also Dependent on OpenAI To Live</strong></h3><p>With Microsoft's data center pullback and OpenAI's intent to become independent from Redmond, future data center expansion is based on two partners supporting CoreWeave and Oracle: Crusoe and Core Scientific, neither of which appear to have ever built an AI data center.</p><p>I also must explain how <em>difficult</em> building a data center is, and how said difficulty increases when you're building an AI-focused data center. For example,<a href="https://www.theinformation.com/articles/nvidia-customers-worry-about-snag-with-new-ai-chip-servers?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>NVIDIA had to delay the launch of its Blackwell GPUs because of how finicky the associated infrastructure</u></a> (the accompanying servers and cooling them) is. <em>For customers that already had experience handling GPUs, and therefore likely know how to manage the extreme temperatures created by them.</em></p><p><em>As another reminder,</em> OpenAI is on the hook for $19 billion of funding behind Stargate, money that neither it nor SoftBank has right now.</p><p>Imagine if you didn't have any experience, and effectively had to learn from scratch? How do you think that would go?</p><p>We're about to find out!</p><h3 id="crusoestargateabilene-texas"><strong>Crusoe - Stargate - Abilene Texas</strong></h3><p><strong>Crusoe </strong>is a former cryptocurrency mining company that<a href="https://techcrunch.com/2024/11/21/crusoe-a-rumored-openai-data-center-supplier-has-secured-686m-in-new-funds-filing-shows/?ref=wheresyoured.at"> <u>has now raised hundreds of millions of dollars</u></a> to build data centers for AI companies, starting with<a href="https://www.theinformation.com/briefings/crusoe-in-talks-to-raise-several-billion-dollars-for-oracle-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>a $3.4 billion data center financing deal with asset manager Blue Owl Capital</u></a>. This (yet-to-be-completed) data center has now been leased by Oracle, which will, allegedly, fill it full of GPUs for OpenAI.</p><p>Despite calling itself "the industry’s first vertically integrated AI infrastructure provider," with the company using <a href="https://www.datacenterdynamics.com/en/news/crusoe-to-deploy-gas-flare-data-centers-in-utah/?ref=wheresyoured.at"><u>flared gas (a waste byproduct of oil production) to power IT infrastructure</u></a>, Crusoe does not appear to have built an AI data center, and is now being tasked with<a href="https://crusoe.ai/blog/crusoe-expands-ai-data-center-campus-in-abilene-to-1-2-gigawatts/?ref=wheresyoured.at"> <u>building a 1.2 Gigawatt data center campus for OpenAI</u></a>.</p><p>Crusoe is the sole developer and operator of the Abilene site, meaning, according to<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information</u></a>, "...is in charge of contracting with construction contractors and data center customers, as well as running the data center after it is built."</p><p>Oracle, it seems, will be responsible for<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>filling said data center with GPUs and the associated hardware</u></a>.</p><p>Nevertheless, the project appears to be behind schedule.</p><p>The Information reported in October 2024 that Abeline was meant to have "...<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"><u>50,000 of NVIDIA's [Blackwell] AI chips...in the first quarter of [2025</u></a>]," and also suggested that the site was projected to have 100,000 Blackwell chips by the end of 2025.</p><p>Here in reality,<a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"> <u>a report from Bloomberg in March 2025</u></a> (that I cited previously) said that OpenAI and Oracle were expected to have <em>16,000 GPUs</em> available <em>by the Summer of 2025, </em>with "...OpenAI and oracle are expected to deploy 64,000 NVIDIA GB200s at the Stargate data center...by the end of 2026."</p><p>As discussed above, OpenAI <em>needs this capacity</em>.<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>According to The Information</u></a>, OpenAI expects Stargate to handle three-quarters of its compute by 2030, and these delays call into question at the very least whether this schedule is reasonable, if not whether Stargate, as a project, is actually possible.</p><h3 id="core-scientificcoreweavedenton-texas"><strong>Core Scientific - CoreWeave - Denton Texas</strong></h3><p>I've written a great deal about CoreWeave in the past,<a href="https://www.wheresyoured.at/optimistic-cowardice/"> <u>and specifically about its buildout partner Core Scientific</u></a>, a cryptocurrency mining company (yes, <em>another one</em>) that has exactly one customer for AI data centers — CoreWeave.</p><p>A few notes:</p><ul><li>Core Scientific was bankrupt last year.</li><li>Core Scientific has never built an AI data center, and its cryptocurrency mining operations were built around ASICs — specialist computers for mining Bitcoin —<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Needham%20analysts%20wrote%20in%20a%20report%20in%20May%20that%20almost%20all%20infrastructure%20that%20miners%20currently%20have%20would%20%E2%80%9Cneed%20to%20be%20bulldozed%20and%20built%20from%20the%20ground%20up%20to%20accommodate%20HPC%2C%E2%80%9D%20or%20high%2Dperformance%20computing.%C2%A0"> <u>which led an analyst to tell CNBC</u></a> that said data centers would "<a href="https://www.cnbc.com/2024/08/06/bitcoin-miner-core-scientific-expands-coreweave-deal-to-6point7-billion.html?ref=wheresyoured.at#:~:text=Needham%20analysts%20wrote%20in%20a%20report%20in%20May%20that%20almost%20all%20infrastructure%20that%20miners%20currently%20have%20would%20%E2%80%9Cneed%20to%20be%20bulldozed%20and%20built%20from%20the%20ground%20up%20to%20accommodate%20HPC%2C%E2%80%9D%20or%20high%2Dperformance%20computing."><u>need to be bulldozed and built up from the ground up</u></a>" to accommodate AI compute.</li><li>Core Scientific does not appear to have any meaningful AI compute of any kind. Its AI/HPC (high-performance computing) revenue represents a tiny, tiny percentage of its overall revenue, which still comes primarily from mining crypto, both for itself and for third-parties.&nbsp;</li><li><a href="https://investors.corescientific.com/news-events/press-releases/detail/110/core-scientific-and-coreweave-announce-1-2-billion-expansion-at-denton-tx-site?ref=wheresyoured.at"><u>CoreWeave's entire 1.3 Gigawatt buildout appears to be being handled by Core Scientific</u></a>.</li></ul><p>Core Scientific is also, it seems, taking on $1.14 billion of capital expenditures to build out these data centers,<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Core%20Scientific%2C%20according%20to%20its%2010%2DK%20form%3A"> <u>with CoreWeave promising to reimburse $899.3 million of these costs</u></a>.</p><p>It's also unclear how Core Scientific intends to do this. While it’s taken on a good amount of debt in the past —<a href="https://investors.corescientific.com/news-events/press-releases/detail/102/core-scientific-prices-upsized-550-million-convertible-senior-notes-offering?ref=wheresyoured.at"> <u>$550 million in a convertible note toward the end of 2024</u></a> — this would be more debt than it’s ever taken on.</p><p>It also, as with Crusoe, does not appear to have any experience building AI data centers, except unlike Crusoe, Core Scientific is a barely-functioning recently-bankrupted bitcoin miner pretending to be a data center company.</p><p>How important is CoreWeave to OpenAI exactly?<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at#:~:text=%E2%80%9CCoreWeave%20has%20been,very%2C%20very%20quickly.%E2%80%9D"> <u>From Semafor</u></a>:</p><blockquote>“CoreWeave has been one of our earliest and largest compute partners,” OpenAI chief Sam Altman said in CoreWeave’s roadshow <a href="https://www.netroadshow.com/custom/IPO/CoreWeave/retail/disclaimer.html?ref=wheresyoured.at"><u>video</u></a>, adding that CoreWeave’s computing power “led to the creation of some of the models that we’re best known for.”<p>“Coreweave figured out how to innovate on hardware, to innovate on data center construction, and to deliver results very, very quickly.”</p></blockquote><p>But will it survive long term?</p><p>Going back to the point of contagion: If OpenAI fails, and CoreWeave fails, so too does Core Scientific. And I don’t fancy Crusoe’s chances, either. At least Crusoe isn’t public.</p><h3 id="an-open-question-does-microsoft-book-openais-compute-as-revenue"><strong>An Open Question: Does Microsoft Book OpenAI's Compute As Revenue?</strong></h3><p>Up until fairly recently, Microsoft has been the entire infrastructural backbone of OpenAI, but recently (to free OpenAI up to work with Oracle)<a href="https://techcrunch.com/2025/01/21/microsoft-is-no-longer-openais-exclusive-cloud-provider/?ref=wheresyoured.at"> <u>released it from its exclusive cloud compute deal</u></a>. Nevertheless,<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"> <u>per The Information</u></a>, OpenAI still intends to spend $13 billion on compute on Microsoft Azure this year.</p><p>What's confusing, however, is whether any of this is booked as <em>revenue.</em> Microsoft claimed earlier in this year that it surpassed $13 billion in annual recurring revenue — by which it means its last month multiplied by 12 —<a href="https://www.marketwatch.com/livecoverage/microsoft-earnings-stock-results-azure-cloud-ai-deepseek/card/microsoft-says-ai-revenue-has-surpassed-13-billion-annual-run-rate-4d7JEBh564bN1pCGbGI6?ref=wheresyoured.at"> <u>from artificial intelligence</u></a>.<a href="https://www.theinformation.com/articles/openai-projections-imply-losses-tripling-to-14-billion-in-2026?ref=wheresyoured.at&amp;rc=kz8jh3"> <u>OpenAI's compute costs in 2024 were $5 billion</u></a>, at a<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=OpenAI%20pays%20just%20over%2025%25%20of%20the%20cost%20of%20Azure%E2%80%99s%20GPU%20compute%20as%20part%20of%20its%20deal%20with%20Microsoft%20%E2%80%94%20around%20%241.30%2Dper%2DGPU%2Dper%2Dhour%20versus%20the%20regular%20Azure%20cost%20of%20%243.40%20to%20%244."> <u>discounted Azure rate</u></a>, which, on an annualized basis, would be around $416 million in revenue a month for Microsoft.</p><p>It isn't, however, clear whether Microsoft counts OpenAI's compute spend as revenue.</p><p>Microsoft's earnings do not include an "artificial intelligence" section, but<a href="https://www.microsoft.com/en-us/investor/segment-information?ref=wheresyoured.at"> <u>three separate segments</u></a>:</p><ul><li>Productivity and Business Processes, which includes things like Microsoft 365, LinkedIn, Dynamics 365 and other business processing software.</li><li>More Personal Computing, which includes Windows and Gaming Products</li><li>Intelligent Cloud, Including server products and cloud services like Azure, which is likely where OpenAI's compute is included.</li></ul><p>As a result, it's hard to say specifically where OpenAI's revenue sits, but based on an analysis of Microsoft's Intelligent Cloud segment from FY23 Q1 (note, financial years don’t always correspond with the calendar year,<a href="https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q2/press-release-webcast?os=httpwww.szxlp.xyz&amp;ref=app"> <u>so we just finished FY25 Q2 in January</u></a>) through to its most recent earnings, and found that there was a spike in revenue from FY23 Q1 to FY24 Q1.&nbsp;</p><p>In FY23 Q1 (which ended on <a href="https://www.microsoft.com/en-us/investor/earnings/fy-2023-q1/press-release-webcast?ref=wheresyoured.at"><u>September 30, 2022</u></a>, a month before ChatGPT's launch),&nbsp; the segment made $20.3 billion. The following year, in FY24 Q1, it made $24.3 billion — a 19.7% year-over-year (or roughly $4 billion) increase.</p><p>This could represent the massive increase in training and inference costs associated with hosting ChatGPT,<a href="https://www.microsoft.com/en-us/investor/earnings/fy-2024-q4/press-release-webcast?ref=wheresyoured.at"> <u>peaking at $28.5 billion in revenue in FY24 Q4</u></a> — before dropping dramatically to $24.1 billion in<a href="https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/press-release-webcast?ref=wheresyoured.at"> <u>FY25 Q1</u></a> and raising a little to $25.5 billion in<a href="https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q2/press-release-webcast?os=httpwww.szxlp.xyz&amp;ref=app"> <u>FY25 Q2</u></a>.</p><p>OpenAI spent 2023 training its GPT-4o model before transitioning to its massive, expensive "Orion" model which would eventually become GPT 4.5, as well as its video generation model "Sora."<a href="https://www.wsj.com/tech/ai/openai-gpt5-orion-delays-639e7693?ref=wheresyoured.at"> <u>According to the Wall Street Journal</u></a>, training GPT 4.5 involved at least one training run costing "around half a billion dollars in computing costs alone."</p><p>These are huge sums, but it’s worth noting a couple of things. First, Microsoft licenses OpenAI’s models to third parties, so some of this revenue could be from other companies using GPT on Azure. And there’s also other companies running their own models on Azure. We’ve seen a lot of companies launch AI products, and not all of them are based on LLMs.</p><p>Muddling things further, Microsoft provides OpenAI access to Azure cloud services at a discounted rate. And so, there’s a giant question mark over OpenAI’s contribution to the various spikes in revenue for Microsoft’s Intelligent Cloud segment, or whether other third-parties played a significant role.&nbsp;</p><p>Furthermore, Microsoft’s investment in OpenAI isn’t entirely in cold, hard cash. Rather, it has provided the company with credits to be redeemed on Azure services. I’m not entirely sure how this would be represented on accounting terms, and if anyone can shed light on this, please get in touch.&nbsp;</p><p>Would it be noted as revenue, or something else? OpenAI isn’t paying Microsoft, but rather doing the tech equivalent of redeeming some airmiles, or spending a gift card.&nbsp;</p><p>Additionally, while equity is often treated as income for tax purposes — as is the case when an employee receives RSUs as part of their compensation package — under the existing OpenAI structure, Microsoft isn’t a shareholder but rather the owner of profit-sharing units. This is a distinction worth noting.&nbsp;&nbsp;</p><p>These profit-sharing units are treated as analogous to equity, at least in terms of OpenAI’s ability to raise capital, but in practice they aren’t the same thing. They don’t represent ownership in the company as directly as, for example, a normal share unit would. They lack the liquidity of a share, and the upside they provide — namely, dividends — is purely theoretical.&nbsp;</p><p>Another key difference: when a company goes bankrupt and enters liquidation, shareholders can potentially receive a share of the proceeds (after other creditors, employees, etc are paid). While that often doesn’t happen (as in, the liabilities far exceed the assets of the company), it’s at least theoretically possible. Given that profit-sharing units aren’t actually shares, where does that leave Microsoft?</p><p>This stuff is confusing, and I’m not ashamed to say that complicated accounting questions like these are far beyond my understanding. If anyone can shed some light, drop me an email, or a message on Twitter or BlueSky, or post on the Better Offline subreddit.&nbsp;</p><h2 id="the-future-of-generative-ai-rests-on-openai-and-openais-future-rests-on-near-impossible-financial-requirements"><strong>The Future of Generative AI Rests On OpenAI, And OpenAI's Future Rests On Near-Impossible Financial Requirements</strong></h2><p>I have done my best to write this piece in as objective a tone as possible, regardless of my feelings about the generative AI bubble and its associated boosters.</p><p>OpenAI,<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=Is%20Generative%20AI%20A%20Real%20Industry%3F"> <u>as I've written before</u></a>, is effectively the entire generative AI industry, with its nearest competitor being less than five percent of its 500 million weekly active users.</p><p>Its future is dependent — and this is not an opinion, but objective fact — on effectively infinite resources.</p><h3 id="financial-resources"><strong>Financial Resources</strong></h3><p>If it required $40 billion to continue operations this year, it is reasonable to believe it will need at least another $40 billion next year, and based on its internal projections, will need at least that every single other year until 2030, when it claims, somehow, it will be profitable "with the completion of the Stargate data center."</p><h3 id="compute-resources-and-expansion"><strong>Compute Resources and Expansion</strong></h3><p>OpenAI requires more compute resources than anyone has ever needed, and will continue to do so in perpetuity. Building these resources is now dependent on two partners — Core Scientific and Crusoe — that have never built a data center, as Microsoft has materially pulled back on data center development, which have (as well as the aforementioned pullback on 2GW of data centers)<a href="https://www.linkedin.com/posts/noelle-walsh-b29356108_microsoftcloud-datacenters-activity-7315439628562423808-W67e/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAACNp-u0B8oyS6pLtatitYCwLv1mvyLXiCvk"> <u>"slowed or paused" some of its "early stage" data center projects</u></a>. This shift is directly linked to Microsoft’s relationship with OpenAI, withTD Cowen's recent analyst report saying that data center pullbacks were, and I quote its March 26 2025 data center channel checks letter, "...driven by the decision to not support incremental OpenAI training workloads."</p><p>In simpler terms, OpenAI needs more compute at a time when its lead backer,<a href="https://www.datacenterdynamics.com/en/news/microsoft-bought-twice-as-many-nvidia-hopper-gpus-as-other-big-tech-companies-report/?ref=wheresyoured.at"> <u>which has the most GPUs in the world</u></a>, has specifically walked away from building it.</p><p>Even in my most optimistic frame of mind, it isn't realistic to believe that Crusoe or Core Scientific can build the data centers necessary for OpenAI's expansion.</p><p>Even if SoftBank and OpenAI had the money to invest in Stargate <em>today</em>, dollars do not change the fabric of reality. Data centers take time to build, requiring concrete, wood, steel and other materials to be manufactured and placed, and that's after the permitting required to get these deals done. Even if that succeeds, getting the power necessary is a challenge unto itself, to the point that even Oracle, an established and storied cloud compute company,<a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>to quote The Information</u></a>, "...has less experience than its larger rivals in dealing with utilities to secure power and working with powerful and demanding cloud customers whose plans change frequently."</p><p>A partner like Crusoe or Core Scientific simply doesn't have the muscle memory or domain expertise that Microsoft has when it comes to building and operating data centers. As a result, it's hard to imagine even in the <em>best case scenario</em> that they're able to match the hunger for compute that OpenAI has.</p><p>Now, I want to be clear — I believe OpenAI will still continue to use Microsoft's compute, and even expand further into whatever remaining compute Microsoft may have. However, there is now a hard limit on how much of it there's going to be, both literally (in what's physically available) and in what Microsoft itself will actually OpenAI them to use, especially given how unprofitable GPU compute might be.</p><h2 id="how-does-this-end"><strong>How Does This End?</strong></h2><p>Last week, a truly offensive piece of fan fiction — framed as a "report" —<a href="https://ai-2027.com/?ref=wheresyoured.at"> <u>called AI 2027 went viral</u></a>, garnering press coverage with<a href="https://www.dwarkesh.com/p/scott-daniel?ref=wheresyoured.at"> <u>the Dwarkesh Podcast</u></a> and<a href="https://www.nytimes.com/2025/04/03/technology/ai-futures-project-ai-2027.html?ref=wheresyoured.at"> <u>gormless, child-like wonder from the New York Times' Kevin Roose</u></a>. Its predictions vaguely suggest a theoretical company called OpenBrain will invent a self-teaching agent of some sort.</p><p>It's bullshit, but it captured the hearts and minds of AI boosters because it vaguely suggests that somehow Large Language Models and their associated technology will become something entirely different.</p><p>I don't like making predictions like these because the future — especially in our current political climate — is so chaotic, but I will say that I do not see, and I say this with complete objectivity, how any of this continues.</p><p>I want to be <strong>extremely blunt</strong> with the following points, as I feel like both members of the media and tech analysts have failed to express how ridiculous things have become. I will be repeating myself, but it's necessary, as I <strong>need you to understand how untenable things are.</strong></p><ul><li>SoftBank is putting itself in dire straits <em>simply to fund OpenAI once. </em>This deal threatens its credit rating, with SoftBank having to take on what will be multiple loans <strong>to fund OpenAI's $40 billion round.<u> OpenAI will need at least another $40 billion in the next year.</u></strong><ul><li>This is before you consider the other $19 billion that SoftBank has agreed to contribute to the Stargate data center project, money that it does not currently have available.</li></ul></li><li>OpenAI has promised $19 billion to the Stargate data center project, money it <strong>does not have</strong> and <strong>cannot get without SoftBank's funds.</strong><ul><li><strong><u>Again, neither SoftBank nor OpenAI has the money for Stargate right now.</u></strong></li></ul></li><li>OpenAI <em>needs Stargate to get built to grow much further.</em></li></ul><p>I see no way in which OpenAI can continue to raise money at this rate, <em>even if OpenAI somehow actually receives the $40 billion, which will require it becoming a for-profit entity. </em>While it could theoretically stretch that $40 billion to last multiple years,<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>projections say it’ll burn $320 billion in the next five years</u></a>.</p><p>Or, more likely, I can’t see a realistic way in which OpenAI gets the resources it needs to survive. It’ll need a streak of unlikely good fortune, the kind of which you only ever hear about in Greek epic poems:&nbsp;</p><ul><li>SoftBank somehow gets the resources (and loses the constraints) required to bankroll it indefinitely.&nbsp;</li><li>The world’s wealthiest entities — those sovereign wealth funds mentioned earlier, the Saudis and so on&nbsp; — pick up the slack each year until OpenAI reaches productivity (assuming it does).</li><li>It has enough of those mega-wealthy benefactors to provide the $320bn it needs before it reaches profitability.</li><li>Crusoe and CoreScientific turn out to be really good at building AI infrastructure — something they’ve never done before.&nbsp;</li><li>Microsoft walks-back its walk-back on building new AI infrastructure and recommits to the tens of billions of dollars of capex spending it previously floated.&nbsp;</li><li>Stargate construction happens faster than expected, and there are no supply chain issues (in terms of labor, building materials, GPUs, and so on).</li></ul><p>If those things happen, I’ll obviously find myself eating crow. But I’m not worried.&nbsp;</p><p>In the present conditions, OpenAI is on course to run out of money or compute capacity, and it's unclear which will happen first.</p><h2 id="its-time-to-wake-up"><strong>It's Time To Wake Up</strong></h2><p>Even in a hysterical bubble where everybody is agreeing that this is the future, OpenAI currently requires more money and more compute than is reasonable to acquire. <em>Nobody</em> has ever raised as much as OpenAI needs to, and based on the sheer amount of difficulty that SoftBank is having in raising the funds to meet <em>the lower tranche ($10bn) of its commitment, </em>it may simply not be possible for this company to continue.</p><p>Even with <em>extremely</em> preferential payment terms — months-long deferred payments, for example — at some point somebody is going to need to get paid.</p><p>I will give Sam Altman credit. He's found many partners to shoulder the burden of the rotten economics of OpenAI, with Microsoft, Oracle, Crusoe and CoreWeave handling the up-front costs of building the infrastructure, SoftBank finding the investors for its monstrous round, and the tech media mostly handling his marketing for him.</p><p>He is, however, over-leveraged. OpenAI has never been forced to stand on its own two feet or focus on efficiency, and I believe the constant enabling of its ugly, nonsensical burnrate has doomed this company. OpenAI has acted like it’ll always have more money and compute, and that people will always believe its bullshit, mostly because up until recently <em>everybody has.</em></p><p>OpenAI cannot "make things cheaper" at this point, because the money has always been there to make things more expensive, as has the compute to make larger language models that burn billions of dollars a year. This company is not built to reduce its footprint in any way, nor is it built for a future in which it wouldn't have access to, as I've said before, infinite resources.</p><p>Worse still, investors and the media have run cover for the fact that these models don't really do much more than they did a year ago and for<a href="https://www.wheresyoured.at/godot-isnt-making-it/"> <u>the overall diminishing returns of Large Language Models</u></a>.</p><p>I have had many people <em>attack</em> my work about OpenAI, but none have provided any real counterpoint to<a href="https://www.wheresyoured.at/to-serve-altman/"> <u>the underlying economic argument I've made since July of last year</u></a> that OpenAI is unsustainable. This is likely because there really isn't one, other than "OpenAI will continue to raise more money than anybody has ever raised in history, in perpetuity, and will somehow turn from the least-profitable company of all time to a profitable one."</p><p>This isn’t a rational argument. It’s a religious one. It’s a call for faith.&nbsp;</p><p>And I see no greater pale horse of the apocalypse than Microsoft's material pullback on data centers. While the argument might be that Microsoft wants OpenAI to have an independent future, that's laughable when you consider Microsoft's deeply monopolistic tendencies — and, for that matter, it owns a massive proportion of OpenAI’s pseudo-equity. At one point, Microsoft’s portion was valued at 49 percent. And while additional fundraising has likely diluted Microsoft’s stake, it still “owns” a massive proportion of what is (at least) the most valuable private startup of all time.</p><p>And we’re supposed to believe that Microsoft’s pullback — which limits OpenAI’s access to the infrastructure it needs to train and run its models, and thus (as mentioned) represents an existential threat to the company — is because of some paternal desire to see OpenAI leave the childhood bedroom, spread its wings, and enter the real world? Behave.&nbsp;</p><p>More likely, Microsoft got what it needed out of OpenAI, which has reached the limit of the models it can develop, and which Microsoft already retains the IP of. There’s probably no reason to make any further significant investments, though they allegedly may be part of the initial $10 billion tranche of OpenAI’s next round.</p><p>It's also important to note that absolutely nobody <em>other than NVIDIA </em>is making any money from generative AI. CoreWeave loses billions of dollars, OpenAI loses billions of dollars, Anthropic loses billions of dollars, and I can't find a single company providing generative AI-powered software that's making a profit. The only companies even <em>close</em> to doing so are consultancies providing services to train and create data for models like Turing and Scale AI — and<a href="https://www.bloomberg.com/news/articles/2025-04-02/scale-ai-expects-to-more-than-double-sales-to-2-billion-in-2025?ref=wheresyoured.at"> <u>Scale isn't even profitable</u></a>.</p><p>The knock-on effects of OpenAI's collapse will be wide-ranging. Neither CoreWeave nor Crusoe will have tenants for their massive, unsustainable operations, and Oracle will have nobody to sell the compute it’s leased from Crusoe for the next 15 years. CoreWeave will likely collapse under the weight of its abominable debt, which will lead to a 7%+ revenue drop for NVIDIA at a time when revenue growth has already begun to slow.</p><p>On a philosophical level, OpenAI's health is what keeps this industry alive.<a href="https://www.wheresyoured.at/wheres-the-money/"> <u>OpenAI has the only meaningful userbase in generative AI</u></a>, and this entire hype-cycle has been driven by its success, meaning any deterioration (or collapse) of OpenAI will tell the market what I've been saying for over a year: that generative AI is not the next hyper-growth market, and its underlying economics do not make sense.</p><p>I am not writing this to be "right" or "be a hater."</p><p>If something changes, and I am wrong somehow, I will write exactly how, and why, and what mistakes I made to come to the conclusions I have in this piece.</p><p>I do not believe that my peers in the media will do the same when this collapses, but I promise you that they will be held accountable, because all of this abominable waste could have been avoided.</p><p>Large Language Models are not, on their own, the problem. They're tools, capable of some outcomes, doing some things, but the problem, ultimately, are the extrapolations made about their abilities, and the unnecessary drive to make them larger, even if said largeness never amounted to much.</p><p>Everything that I'm describing is the result of a tech industry — including media and analysts — that refuses to do business with reality, trafficking in ideas and ideology, celebrating victories that have yet to take place, applauding those who have yet to create the things they're talking about, cheering on men lying about what's possible so that they can continue to burn billions of dollars and increase their wealth and influence.</p><p>I understand why others might not have written this piece. What I am describing is a systemic failure, one at a scale hereto unseen, one that has involved so many rich and powerful and influential people agreeing to ignore reality, and that’ll have crushing impacts for the wider tech ecosystem when it happens.</p><p>Don't say I didn't warn you.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists: Protein IL-17 fights infection, acts on the brain, inducing anxiety (107 pts)]]></title>
            <link>https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html</link>
            <guid>43682686</guid>
            <pubDate>Mon, 14 Apr 2025 15:54:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html">https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html</a>, See on <a href="https://news.ycombinator.com/item?id=43682686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/anxiety.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/anxiety.jpg" data-sub-html="Credit: Andrew Neel from Pexels">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/anxiety.jpg" alt="anxiety" title="Credit: Andrew Neel from Pexels" width="800" height="530">
             <figcaption>
                Credit: Andrew Neel from Pexels
            </figcaption>        </figure>
    </div><p>Immune molecules called cytokines play important roles in the body's defense against infection, helping to control inflammation and coordinating the responses of other immune cells. A growing body of evidence suggests that some of these molecules also influence the brain, leading to behavioral changes during illness.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>Two new studies from MIT and Harvard Medical School, focusing on a cytokine called IL-17, now add to that evidence. The researchers found that IL-17 acts on two distinct brain regions—the amygdala and the somatosensory cortex—to exert two divergent effects. In the amygdala, IL-17 can elicit feelings of anxiety, while in the cortex it promotes sociable behavior.</p>
<p>These findings suggest that the immune and nervous systems are tightly interconnected, says Gloria Choi, an associate professor of brain and cognitive sciences, a member of MIT's Picower Institute for Learning and Memory, and one of the senior authors of the studies.</p>
<p>"If you're sick, there's so many more things that are happening to your internal states, your mood, and your behavioral states, and that's not simply you being fatigued physically. It has something to do with the brain," she says.</p>
<p>Jun Huh, an associate professor of immunology at Harvard Medical School, is also a senior author of both studies, which appear in <i>Cell</i>. One of the papers was led by Picower Institute Research Scientist Byeongjun Lee and former Picower Institute research scientist Jeong-Tae Kwon, and the other was led by Harvard Medical School postdoc Yunjin Lee and Picower Institute postdoc Tomoe Ishikawa.</p>
<h2>Behavioral effects</h2>
<p>Choi and Huh became interested in IL-17 several years ago, when they found it was involved in a phenomenon known as the fever effect. Large-scale studies of autistic children have found that for many of them, their behavioral symptoms temporarily diminish when they have a fever.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>In a <a href="https://medicalxpress.com/news/2019-12-infections-autism-symptoms.html">2019 study</a> in mice, Choi and Huh showed that in some cases of infection, IL-17 is released and suppresses a small region of the brain's cortex known as S1DZ. Overactivation of neurons in this region can lead to autism-like behavioral symptoms in mice, including repetitive behaviors and reduced sociability.</p>
<p>"This molecule became a link that connects immune system activation, manifested as a fever, to changes in <a href="https://medicalxpress.com/tags/brain+function/" rel="tag">brain function</a> and changes in the animals' behavior," Choi says.</p>
<p>IL-17 comes in six different forms, and there are five different receptors that can bind to it.</p>
<p>In their two new papers, the researchers set out to map which of these receptors are expressed in different parts of the brain. This mapping revealed that a pair of receptors known as IL-17RA and IL-17RB is found in the cortex, including in the S1DZ region that the researchers had previously identified. The receptors are located in a population of neurons that receive proprioceptive input and are involved in controlling behavior.</p>
<p>When a type of IL-17 known as IL-17E binds to these receptors, the neurons become less excitable, which leads to the behavioral effects seen in the 2019 study.</p>
<p>"IL-17E, which we've shown to be necessary for behavioral mitigation, actually does act almost exactly like a neuromodulator in that it will immediately reduce these neurons' excitability," Choi says.</p>
<p>"So, there is an immune molecule that's acting as a neuromodulator in the brain, and its main function is to regulate excitability of neurons."</p>
<p>Choi hypothesizes that IL-17 may have originally evolved as a neuromodulator, and later on was appropriated by the immune system to play a role in promoting inflammation.</p>
<p>That idea is consistent with previous work showing that in the worm C. elegans, IL-17 has no role in the immune system but instead acts on neurons. Among its effects in worms, IL-17 promotes aggregation, a form of social behavior. Additionally, in mammals, IL-17E is actually made by neurons in the cortex, including S1DZ.</p>
<p>"There's a possibility that a couple of forms of IL-17 perhaps evolved first and foremost to act as a neuromodulator in the brain, and maybe later were hijacked by the immune system also to act as immune modulators," Choi says.</p>

                                                                                                                                            <h2>Provoking anxiety</h2>
<p>In the other <i>Cell</i> paper, the researchers explored another brain location where they found IL-17 receptors—the amygdala. This almond-shaped structure plays an important role in processing emotions, including fear and anxiety.</p>
<p>That study revealed that in a region known as the basolateral amygdala (BLA), the IL-17RA and IL-17RE receptors, which work as a pair, are expressed in a discrete population of neurons. When these receptors bind to IL-17A and IL-17C, the neurons become more excitable, leading to an increase in anxiety.</p>
<p>The researchers also found that, counterintuitively, if animals are treated with antibodies that block IL-17 receptors, it actually increases the amount of IL-17C circulating in the body. This finding may help to explain unexpected outcomes observed in a clinical trial of a drug targeting the IL-17-RA receptor for psoriasis treatment, particularly regarding its potential adverse effects on mental health.</p>
<p>"We hypothesize that there's a possibility that the IL-17 ligand that is upregulated in this patient cohort might act on the brain to induce suicide ideation, while in animals there is an anxiogenic phenotype," Choi says.</p>
<p>During infections, this anxiety may be a beneficial response, keeping the sick individual away from others to whom the infection could spread, Choi hypothesizes.</p>
<p>"Other than its main function of fighting pathogens, one of the ways that the immune system works is to control the host behavior, to protect the host itself and also protect the community the host belongs to," she says. "One of the ways the immune system is doing that is to use cytokines, secreted factors, to go to the brain as communication tools."</p>
<p>The researchers found that the same BLA neurons that have receptors for IL-17 also have receptors for IL-10, a cytokine that suppresses inflammation. This molecule counteracts the excitability generated by IL-17, giving the body a way to shut off anxiety once it's no longer useful.</p>

                                                                                                                                                                                                                                                                                                    <h2>Distinctive behaviors</h2>
<p>Together, the two studies suggest that the immune system, and even a single family of cytokines, can exert a variety of effects in the brain.</p>
<p>"We have now different combinations of IL-17 receptors being expressed in different populations of neurons, in two different brain regions, that regulate very distinct behaviors. One is actually somewhat positive and enhances social behaviors, and another is somewhat negative and induces anxiogenic phenotypes," Choi says.</p>
<p>Her lab is now working on additional mapping of IL-17 receptor locations, as well as the IL-17 molecules that bind to them, focusing on the S1DZ region. Eventually, a better understanding of these neuro-immune interactions may help researchers develop new treatments for neurological conditions such as autism or depression.</p>
<p>"The fact that these molecules are made by the immune system gives us a novel approach to influence brain function as a means of therapeutics," Choi says. "Instead of thinking about directly going for the brain, can we think about doing something to the immune system?"</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Inflammatory and anti-inflammatory cytokines bidirectionally modulate amygdala circuits regulating anxiety, <i>Cell</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.cell.2025.03.005" target="_blank">DOI: 10.1016/j.cell.2025.03.005</a>. <a href="https://www.cell.com/cell/fulltext/S0092-8674(25)00278-8" target="_blank">www.cell.com/cell/fulltext/S0092-8674(25)00278-8</a>
</p><p>Brain-wide mapping of immune receptors uncovers a neuro-modulatory role of interleukin-17E and the receptor IL-17RB., <i>Cell</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.cell.2025.03.006" target="_blank">DOI: 10.1016/j.cell.2025.03.006</a>. <a href="https://www.cell.com/cell/fulltext/S0092-8674(25)00279-X" target="_blank">www.cell.com/cell/fulltext/S0092-8674(25)00279-X</a></p>

																								
																								<div>
													<p><strong>Journal information:</strong>
																											<a href="https://medicalxpress.com/journals/cell/"><cite>Cell</cite></a></p><a href="http://www.cell.com/" target="_blank" rel="nofollow">
															<svg>
																<use href="https://medx.b-cdn.net/tmpl/v6/img/svg/sprite.svg#icon_open" x="0" y="0"></use>
															</svg>
														</a> 
																									</div>
																							</div>
                                        											
																					
                                                                                                                            <p>
                                                <i>This story is republished courtesy of MIT News (<a href="http://web.mit.edu/newsoffice/" target="_blank">web.mit.edu/newsoffice/</a>), a popular site that covers news about MIT research, innovation and teaching.</i>
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Scientists discover the protein IL-17 that fights infection also acts on the brain, inducing anxiety or sociability (2025, April 7)
                                                 retrieved 14 April 2025
                                                 from https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Zero-codegen, no-compile TypeScript type inference from Protobufs (125 pts)]]></title>
            <link>https://github.com/nathanhleung/protobuf-ts-types</link>
            <guid>43682547</guid>
            <pubDate>Mon, 14 Apr 2025 15:41:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nathanhleung/protobuf-ts-types">https://github.com/nathanhleung/protobuf-ts-types</a>, See on <a href="https://news.ycombinator.com/item?id=43682547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">protobuf-ts-types</h2><a id="user-content-protobuf-ts-types" aria-label="Permalink: protobuf-ts-types" href="#protobuf-ts-types"></a></p>
<blockquote>
<p dir="auto">Zero-codegen, no-compile TypeScript <code>type</code> inference from protobuf <code>message</code>s.</p>
</blockquote>
<p dir="auto"><code>protobuf-ts-types</code> lets you define language-agnostic <code>message</code> types in <code>proto</code> format, then infers TypeScript types from them with no additional codegen.</p>
<p dir="auto"><a href="https://github.dev/nathanhleung/protobuf-ts-types/blob/main/examples/basic/index.ts" rel="nofollow">Try on github.dev</a> | <a href="https://codesandbox.io/p/github/nathanhleung/protobuf-ts-types/main?import=true&amp;embed=1&amp;file=%2Fexamples%2Fbasic%2Findex.ts" rel="nofollow">View on CodeSandbox</a></p>
<div dir="auto"><p dir="auto">Warning</p><p dir="auto">Proof of concept, not production ready. See <a href="#limitations">Limitations</a> below for more details.</p>
</div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nathanhleung/protobuf-ts-types/blob/main/screenshot.png"><img src="https://github.com/nathanhleung/protobuf-ts-types/raw/main/screenshot.png" width="400px" alt="Screenshot"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it Works" href="#how-it-works"></a></p>
<p dir="auto">In short, aggressive use of TypeScript's <a href="https://www.typescriptlang.org/docs/handbook/2/template-literal-types.html" rel="nofollow">template literal types</a>. Annotated example from the source:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Pass the proto string you want to infer `message` names from as a generic parameter
type MessageNames<Proto extends string> =
  // Infer `message` parts using template literal type
  WrapWithNewlines<Proto> extends `${string}${Whitespace}message${Whitespace}${infer MessageName}${OptionalWhitespace}{${string}}${infer Rest}`
    ? // Recursively infer remaining message names
      [MessageName, ...MessageNames<Rest>]
    : [];"><pre><span>// Pass the proto string you want to infer `message` names from as a generic parameter</span>
<span>type</span> <span>MessageNames</span><span>&lt;</span><span>Proto</span> <span>extends</span> <span>string</span><span>&gt;</span> <span>=</span>
  <span>// Infer `message` parts using template literal type</span>
  <span>WrapWithNewlines</span><span>&lt;</span><span>Proto</span><span>&gt;</span> <span>extends</span> `${<span>string</span><span>}</span>${<span>Whitespace</span><span>}</span>message${<span>Whitespace</span><span>}</span>${infer <span>MessageName</span><span>}</span>${<span>OptionalWhitespace</span><span>}</span>{${<span>string</span><span>}</span>}${infer <span>Rest</span><span>}</span>`
    ? <span>// Recursively infer remaining message names</span>
      <span>[</span><span>MessageName</span><span>,</span> ...<span>MessageNames</span><span>&lt;</span><span>Rest</span><span>&gt;</span><span>]</span>
    : <span>[</span><span>]</span><span>;</span></pre></div>
<p dir="auto">See more in <a href="https://github.com/nathanhleung/protobuf-ts-types/blob/main/src/proto.ts"><code>src/proto.ts</code></a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">First, install the package.</p>
<div data-snippet-clipboard-copy-content="npm install https://github.com/nathanhleung/protobuf-ts-types"><pre><code>npm install https://github.com/nathanhleung/protobuf-ts-types
</code></pre></div>
<p dir="auto">Then, use it in TypeScript.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { pbt } from &quot;protobuf-ts-types&quot;;

const proto = `
    syntax = &quot;proto3&quot;;

    message Person {
      string name = 1;
      int32 id = 2;
      bool is_ceo = 3;
      optional string description = 4;
    }

    message Group {
        string name = 1;
        repeated Person people = 2;
    }
`;

// `Proto` is a mapping of message names to message types, inferred from the
// `proto` source string above.
type Proto = pbt.infer<typeof proto>;

type Person = Proto[&quot;Person&quot;];
type Person2 = pbt.infer<typeof proto, &quot;Person&quot;>;

// `Person` and `Person2` are the same type:
// ```
// {
//     name: string;
//     id: number;
//     is_ceo: boolean;
//     description?: string;
// }
// ```

type Group = pbt.infer<typeof proto, &quot;Group&quot;>;

function greetPerson(person: Person) {
  console.log(`Hello, ${person.name}!`);

  if (person.description) {
    console.log(`${person.description}`);
  } else {
    console.log(&quot;(no description)&quot;);
  }
}

function greetGroup(group: Group) {
  console.log(`=========${&quot;=&quot;.repeat(group.name.length)}===`);
  console.log(`= Hello, ${group.name}! =`);
  console.log(`=========${&quot;=&quot;.repeat(group.name.length)}===`);

  for (const person of group.people) {
    greetPerson(person);
    console.log();
  }
}

// If the structure of the `Group` or any of the individual `Person`s does not
// match the type, TypeScript will show an error.
greetGroup({
  name: &quot;Hooli&quot;,
  people: [
    {
      name: &quot;Gavin Belson&quot;,
      id: 0,
      is_ceo: true,
      description: &quot;CEO of Hooli&quot;,
    },
    {
      name: &quot;Richard Hendricks&quot;,
      id: 1,
      is_ceo: true,
      description: &quot;CEO of Pied Piper&quot;,
    },
    {
      name: &quot;Dinesh Chugtai&quot;,
      id: 2,
      is_ceo: false,
      description: &quot;Software Engineer&quot;,
    },
    {
      name: &quot;Jared Dunn&quot;,
      id: 3,
      is_ceo: false,
    },
  ],
});

// Output:
// ```
// =================
// = Hello, Hooli! =
// =================
// Hello, Gavin Belson!
// CEO of Hooli

// Hello, Richard Hendricks!
// CEO of Pied Piper

// Hello, Dinesh Chugtai!
// Software Engineer

// Hello, Jared Dunn!
// (no description)
// ```"><pre><span>import</span> <span>{</span> <span>pbt</span> <span>}</span> <span>from</span> <span>"protobuf-ts-types"</span><span>;</span>

<span>const</span> <span>proto</span> <span>=</span> <span>`</span>
<span>    syntax = "proto3";</span>
<span></span>
<span>    message Person {</span>
<span>      string name = 1;</span>
<span>      int32 id = 2;</span>
<span>      bool is_ceo = 3;</span>
<span>      optional string description = 4;</span>
<span>    }</span>
<span></span>
<span>    message Group {</span>
<span>        string name = 1;</span>
<span>        repeated Person people = 2;</span>
<span>    }</span>
<span>`</span><span>;</span>

<span>// `Proto` is a mapping of message names to message types, inferred from the</span>
<span>// `proto` source string above.</span>
<span>type</span> <span>Proto</span> <span>=</span> <span>pbt</span><span>.</span><span>infer</span><span>&lt;</span><span>typeof</span> <span>proto</span><span>&gt;</span><span>;</span>

<span>type</span> <span>Person</span> <span>=</span> <span>Proto</span><span>[</span><span>"Person"</span><span>]</span><span>;</span>
<span>type</span> <span>Person2</span> <span>=</span> <span>pbt</span><span>.</span><span>infer</span><span>&lt;</span><span>typeof</span> <span>proto</span><span>,</span> <span>"Person"</span><span>&gt;</span><span>;</span>

<span>// `Person` and `Person2` are the same type:</span>
<span>// ```</span>
<span>// {</span>
<span>//     name: string;</span>
<span>//     id: number;</span>
<span>//     is_ceo: boolean;</span>
<span>//     description?: string;</span>
<span>// }</span>
<span>// ```</span>

<span>type</span> <span>Group</span> <span>=</span> <span>pbt</span><span>.</span><span>infer</span><span>&lt;</span><span>typeof</span> <span>proto</span><span>,</span> <span>"Group"</span><span>&gt;</span><span>;</span>

<span>function</span> <span>greetPerson</span><span>(</span><span>person</span>: <span>Person</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`Hello, <span><span>${</span><span>person</span><span>.</span><span>name</span><span>}</span></span>!`</span><span>)</span><span>;</span>

  <span>if</span> <span>(</span><span>person</span><span>.</span><span>description</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>`<span><span>${</span><span>person</span><span>.</span><span>description</span><span>}</span></span>`</span><span>)</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"(no description)"</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>function</span> <span>greetGroup</span><span>(</span><span>group</span>: <span>Group</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`=========<span><span>${</span><span>"="</span><span>.</span><span>repeat</span><span>(</span><span>group</span><span>.</span><span>name</span><span>.</span><span>length</span><span>)</span><span>}</span></span>===`</span><span>)</span><span>;</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`= Hello, <span><span>${</span><span>group</span><span>.</span><span>name</span><span>}</span></span>! =`</span><span>)</span><span>;</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>`=========<span><span>${</span><span>"="</span><span>.</span><span>repeat</span><span>(</span><span>group</span><span>.</span><span>name</span><span>.</span><span>length</span><span>)</span><span>}</span></span>===`</span><span>)</span><span>;</span>

  <span>for</span> <span>(</span><span>const</span> <span>person</span> <span>of</span> <span>group</span><span>.</span><span>people</span><span>)</span> <span>{</span>
    <span>greetPerson</span><span>(</span><span>person</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>// If the structure of the `Group` or any of the individual `Person`s does not</span>
<span>// match the type, TypeScript will show an error.</span>
<span>greetGroup</span><span>(</span><span>{</span>
  <span>name</span>: <span>"Hooli"</span><span>,</span>
  <span>people</span>: <span>[</span>
    <span>{</span>
      <span>name</span>: <span>"Gavin Belson"</span><span>,</span>
      <span>id</span>: <span>0</span><span>,</span>
      <span>is_ceo</span>: <span>true</span><span>,</span>
      <span>description</span>: <span>"CEO of Hooli"</span><span>,</span>
    <span>}</span><span>,</span>
    <span>{</span>
      <span>name</span>: <span>"Richard Hendricks"</span><span>,</span>
      <span>id</span>: <span>1</span><span>,</span>
      <span>is_ceo</span>: <span>true</span><span>,</span>
      <span>description</span>: <span>"CEO of Pied Piper"</span><span>,</span>
    <span>}</span><span>,</span>
    <span>{</span>
      <span>name</span>: <span>"Dinesh Chugtai"</span><span>,</span>
      <span>id</span>: <span>2</span><span>,</span>
      <span>is_ceo</span>: <span>false</span><span>,</span>
      <span>description</span>: <span>"Software Engineer"</span><span>,</span>
    <span>}</span><span>,</span>
    <span>{</span>
      <span>name</span>: <span>"Jared Dunn"</span><span>,</span>
      <span>id</span>: <span>3</span><span>,</span>
      <span>is_ceo</span>: <span>false</span><span>,</span>
    <span>}</span><span>,</span>
  <span>]</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// Output:</span>
<span>// ```</span>
<span>// =================</span>
<span>// = Hello, Hooli! =</span>
<span>// =================</span>
<span>// Hello, Gavin Belson!</span>
<span>// CEO of Hooli</span>

<span>// Hello, Richard Hendricks!</span>
<span>// CEO of Pied Piper</span>

<span>// Hello, Dinesh Chugtai!</span>
<span>// Software Engineer</span>

<span>// Hello, Jared Dunn!</span>
<span>// (no description)</span>
<span>// ```</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations</h2><a id="user-content-limitations" aria-label="Permalink: Limitations" href="#limitations"></a></p>
<ul dir="auto">
<li>If not using inline (i.e., literals in TypeScript) proto <code>string</code>s <code>as const</code>, probably requires a <a href="https://github.com/nonara/ts-patch"><code>ts-patch</code></a> compiler patch to import <code>.proto</code> files until <a data-error-text="Failed to load title" data-id="779392318" data-permission-text="Title is private" data-url="https://github.com/microsoft/TypeScript/issues/42219" data-hovercard-type="issue" data-hovercard-url="/microsoft/TypeScript/issues/42219/hovercard" href="https://github.com/microsoft/TypeScript/issues/42219">microsoft/TypeScript#42219</a> is resolved</li>
<li><code>service</code>s and <code>rpc</code>s are not supported (only <code>message</code>s)</li>
<li><code>oneof</code> and <code>map</code> fields are not supported</li>
<li><code>import</code>s are not supported (for now, concatenate)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>pbt</code></h3><a id="user-content-pbt" aria-label="Permalink: pbt" href="#pbt"></a></p>
<p dir="auto">Top-level exported namespace.</p>
<div data-snippet-clipboard-copy-content="import { pbt } from &quot;protobuf-ts-types&quot;;"><pre><code>import { pbt } from "protobuf-ts-types";
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>pbt.infer&lt;Proto extends string, MessageName extends string = ""&gt;</code></h3><a id="user-content-pbtinferproto-extends-string-messagename-extends-string--" aria-label="Permalink: pbt.infer<Proto extends string, MessageName extends string = &quot;&quot;>" href="#pbtinferproto-extends-string-messagename-extends-string--"></a></p>
<p dir="auto">Given a proto source string, infers the types of the <code>message</code>s in the source.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Returns</h4><a id="user-content-returns" aria-label="Permalink: Returns" href="#returns"></a></p>
<ul dir="auto">
<li>If <code>MessageName</code> is an empty string, the returned type is a mapping from message names to message types.</li>
<li>If <code>MessageName</code> is a known <code>message</code>, the returned type is the inferred type of the given <code>MessageName</code>.</li>
<li>If <code>MessageName</code> is not a known <code>message</code>, the returned type is <code>never</code>.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Path to Open-Sourcing the DeepSeek Inference Engine (488 pts)]]></title>
            <link>https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine</link>
            <guid>43682088</guid>
            <pubDate>Mon, 14 Apr 2025 15:03:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine">https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine</a>, See on <a href="https://news.ycombinator.com/item?id=43682088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">The Path to Open-Sourcing the DeepSeek Inference Engine</h2><a id="user-content-the-path-to-open-sourcing-the-deepseek-inference-engine" aria-label="Permalink: The Path to Open-Sourcing the DeepSeek Inference Engine" href="#the-path-to-open-sourcing-the-deepseek-inference-engine"></a></p>
<p dir="auto">A few weeks ago,
during <a href="https://github.com/deepseek-ai/open-infra-index?tab=readme-ov-file#202502-open-source-week">Open Source Week</a>,
we open-sourced several libraries.
The response from the community has been incredibly positive - sparking inspiring collaborations, productive
discussions, and valuable bug fixes.
Encouraged by this, we’ve decided to take another step forward: contributing our internal inference engine back to the
open-source community.</p>
<p dir="auto">We are deeply grateful for the open-source ecosystem, without which our progress toward AGI would not be possible.
Our training framework relies on <a href="https://github.com/pytorch/pytorch">PyTorch</a>, and our inference engine is built
upon <a href="https://github.com/vllm-project/vllm">vLLM</a>,
both of which have been instrumental in accelerating the training and deployment of DeepSeek models.</p>
<p dir="auto">Given the growing demand for deploying models like <a href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3</a>
and <a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1</a>, we want to give back to the community as much as we can.
While we initially considered open-sourcing our full internal inference engine, we identified several challenges:</p>
<ul dir="auto">
<li><strong>Codebase Divergence</strong>: Our engine is based on an early fork of vLLM from over a year ago. Although structurally
similar, we’ve heavily customized it for DeepSeek models, making it difficult to extend for broader use cases.</li>
<li><strong>Infrastructure Dependencies</strong>: The engine is tightly coupled with our internal infrastructure, including cluster
management tools, making it impractical for public deployment without significant modifications.</li>
<li><strong>Limited Maintenance Bandwidth</strong>: As a small research team focused on developing better models, we lack bandwidth to
maintain a large open-source project.</li>
</ul>
<p dir="auto">Considering these challenges, we’ve decided to collaborate with existing open-source projects as more sustainable alternatives.</p>
<p dir="auto">Moving forward, we will work closely with existing open-source projects to:</p>
<ul dir="auto">
<li><strong>Extract Standalone Features</strong>: Modularize and contribute reusable components as independent libraries.</li>
<li><strong>Share Optimizations</strong>: Contribute design improvements and implementation details directly.</li>
</ul>
<p dir="auto">We are profoundly grateful for the open-source movement - from operating systems and programming languages to machine
learning frameworks and inference engines. It’s an honor to contribute to this thriving ecosystem and to see our models
and code embraced by the community. Together, let’s push the boundaries of AGI and ensure its benefits serve all of
humanity.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto"><strong>To clarify, this article outlines our approach to open-sourcing of our DeepSeek-Inference-Engine codebase only.
Regarding future model releases, we maintain an open and collaborative stance towards both the open-source community
and hardware partners.
We commit to proactively synchronizing inference-related engineering efforts prior to new model launches, with the
goal of enabling the community to achieve state-of-the-art (SOTA) support from Day-0. Our ultimate aim is to foster a
synchronized ecosystem where cutting-edge AI capabilities can be seamlessly implemented across diverse hardware
platforms upon official model releases.</strong></p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite File Format Viewer (233 pts)]]></title>
            <link>https://sqlite-internal.pages.dev</link>
            <guid>43682006</guid>
            <pubDate>Mon, 14 Apr 2025 14:55:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite-internal.pages.dev">https://sqlite-internal.pages.dev</a>, See on <a href="https://news.ycombinator.com/item?id=43682006">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How to Bike Across the Country (195 pts)]]></title>
            <link>https://www.brooks.team/posts/how-to-bike-across-the-country/</link>
            <guid>43681936</guid>
            <pubDate>Mon, 14 Apr 2025 14:49:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brooks.team/posts/how-to-bike-across-the-country/">https://www.brooks.team/posts/how-to-bike-across-the-country/</a>, See on <a href="https://news.ycombinator.com/item?id=43681936">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  
  <p>Loading...</p>

  
  
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tariff: A Python package that imposes tariffs on Python imports (120 pts)]]></title>
            <link>https://pypi.org/project/tariff/</link>
            <guid>43681752</guid>
            <pubDate>Mon, 14 Apr 2025 14:32:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pypi.org/project/tariff/">https://pypi.org/project/tariff/</a>, See on <a href="https://news.ycombinator.com/item?id=43681752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="description" data-project-tabs-target="content" role="tabpanel" aria-labelledby="description-tab mobile-description-tab" tabindex="-1">
          <h2>Project description</h2>
          <div>
            
<p>The GREATEST, most TREMENDOUS Python package that makes importing great again!</p>
<h2>About</h2>
<p>TARIFF is a fantastic tool that lets you impose import tariffs on Python packages. We're going to bring manufacturing BACK to your codebase by making foreign imports more EXPENSIVE!</p>
<h2>Installation</h2>
<pre lang="bash">pip<span> </span>install<span> </span>tariff
</pre>
<h2>Usage</h2>
<pre lang="python3"><span>import</span><span> </span><span>tariff</span>

<span># Set your tariff rates (package_name: percentage)</span>
<span>tariff</span><span>.</span><span>set</span><span>({</span>
    <span>"numpy"</span><span>:</span> <span>50</span><span>,</span>     <span># 50% tariff on numpy</span>
    <span>"pandas"</span><span>:</span> <span>200</span><span>,</span>   <span># 200% tariff on pandas</span>
    <span>"requests"</span><span>:</span> <span>150</span>  <span># 150% tariff on requests</span>
<span>})</span>

<span># Now when you import these packages, they'll be TARIFFED!</span>
<span>import</span><span> </span><span>numpy</span>   <span># This will be 50% slower</span>
<span>import</span><span> </span><span>pandas</span>  <span># This will be 200% slower</span>
</pre>
<h2>How It Works</h2>
<p>When you import a package that has a tariff:</p>
<ol>
<li>TARIFF measures how long the original import takes</li>
<li>TARIFF makes the import take longer based on your tariff percentage</li>
<li>TARIFF announces the tariff with a TREMENDOUS message</li>
</ol>
<h2>Example Output</h2>
<pre><code>JUST IMPOSED a 50% TARIFF on numpy! Original import took 45000 us, now takes 67500 us. American packages are WINNING AGAIN! #MIPA
</code></pre>
<h2>Why TARIFF?</h2>
<p>Because foreign packages have been STEALING our CPU cycles for TOO LONG! It's time to put AMERICA FIRST and make importing FAIR and BALANCED again!</p>
<h2>License</h2>
<p>This is a parody package. Use at your own risk. MAKE IMPORTING GREAT AGAIN!</p>

          </div>
        </div><div id="files" data-project-tabs-target="content" role="tabpanel" aria-labelledby="files-tab mobile-files-tab" tabindex="-1">
            <h2>Download files</h2>
            <p>Download the file for your platform. If you're not sure which to choose, learn more about <a href="https://packaging.python.org/tutorials/installing-packages/" title="External link" target="_blank" rel="noopener">installing packages</a>.</p>

            <h3>
Source Distribution            </h3>

                  


            <h3>
Built Distribution            </h3>

                

          </div><div id="tariff-1.0.0.tar.gz" data-project-tabs-target="content" role="tabpanel" aria-labelledby="file-tab mobile-file-tab" tabindex="-1">
  <h2>File details</h2>
  <p>Details for the file <code>tariff-1.0.0.tar.gz</code>.</p>

  <h3>File metadata</h3>
  <div>
    <ul>
      <li>
        Download URL: <a href="https://files.pythonhosted.org/packages/6e/86/8a6d8b6c88cbfa42a7f20d7a0bf166ec621e4b0d4f89b2910a539452d587/tariff-1.0.0.tar.gz">
          tariff-1.0.0.tar.gz
        </a>
      </li>
      <li>Upload date: <time datetime="2025-04-10T19:33:18+0000" data-controller="localized-time" data-localized-time-relative="true" data-localized-time-show-time="false">
  Apr 10, 2025
</time></li>
      <li>Size: 4.0 kB</li>
      <li>Tags: Source</li>
      <li>
Uploaded using Trusted Publishing? No      </li>
      <li>Uploaded via: twine/6.1.0 CPython/3.10.16</li>
    </ul>
  </div>

  <h3>File hashes</h3>
  <div>
    <table>
      <caption>Hashes for tariff-1.0.0.tar.gz</caption>
      <thead>
        <tr>
          <th scope="col">Algorithm</th>
          <th scope="col">Hash digest</th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr data-controller="clipboard">
          <th scope="row">SHA256</th>
          <td><code data-clipboard-target="source">24a8d49034398a7820d6f9eb1d345476f0d0bfcb67f75ce266284943208596cd</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">MD5</th>
          <td><code data-clipboard-target="source">46117ae6651d1a90855555f1cb629b38</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">BLAKE2b-256</th>
          <td><code data-clipboard-target="source">6e868a6d8b6c88cbfa42a7f20d7a0bf166ec621e4b0d4f89b2910a539452d587</code></td>
          <td>
            
          </td>
        </tr>
      </tbody>
    </table>
    <p>
<a href="https://pip.pypa.io/en/stable/topics/secure-installs/#hash-checking-mode" title="External link" target="_blank" rel="noopener">See more details on using hashes here.</a>    </p>
  </div>

</div><div id="tariff-1.0.0-py3-none-any.whl" data-project-tabs-target="content" role="tabpanel" aria-labelledby="file-tab mobile-file-tab" tabindex="-1">
  <h2>File details</h2>
  <p>Details for the file <code>tariff-1.0.0-py3-none-any.whl</code>.</p>

  <h3>File metadata</h3>
  <div>
    <ul>
      <li>
        Download URL: <a href="https://files.pythonhosted.org/packages/8e/ae/6f57db1138cfce911d19113e8d931a739858e0116ca3a2a3e391748cb5ff/tariff-1.0.0-py3-none-any.whl">
          tariff-1.0.0-py3-none-any.whl
        </a>
      </li>
      <li>Upload date: <time datetime="2025-04-10T19:33:17+0000" data-controller="localized-time" data-localized-time-relative="true" data-localized-time-show-time="false">
  Apr 10, 2025
</time></li>
      <li>Size: 4.5 kB</li>
      <li>Tags: Python 3</li>
      <li>
Uploaded using Trusted Publishing? No      </li>
      <li>Uploaded via: twine/6.1.0 CPython/3.10.16</li>
    </ul>
  </div>

  <h3>File hashes</h3>
  <div>
    <table>
      <caption>Hashes for tariff-1.0.0-py3-none-any.whl</caption>
      <thead>
        <tr>
          <th scope="col">Algorithm</th>
          <th scope="col">Hash digest</th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr data-controller="clipboard">
          <th scope="row">SHA256</th>
          <td><code data-clipboard-target="source">20d738a789f96146ae49de4fffc000ea9942bd4335f0cdc336d2c824e6aa063b</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">MD5</th>
          <td><code data-clipboard-target="source">eb211c83b4fd4814b8a15f0a92ed3dab</code></td>
          <td>
            
          </td>
        </tr>
        <tr data-controller="clipboard">
          <th scope="row">BLAKE2b-256</th>
          <td><code data-clipboard-target="source">8eae6f57db1138cfce911d19113e8d931a739858e0116ca3a2a3e391748cb5ff</code></td>
          <td>
            
          </td>
        </tr>
      </tbody>
    </table>
    <p>
<a href="https://pip.pypa.io/en/stable/topics/secure-installs/#hash-checking-mode" title="External link" target="_blank" rel="noopener">See more details on using hashes here.</a>    </p>
  </div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A hackable AI assistant using a single SQLite table and a handful of cron jobs (568 pts)]]></title>
            <link>https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs</link>
            <guid>43681287</guid>
            <pubDate>Mon, 14 Apr 2025 13:52:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs">https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs</a>, See on <a href="https://news.ycombinator.com/item?id=43681287">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>There’s a lot of hype these days around patterns for building with AI. Agents, memory, RAG, assistants—so many buzzwords! But the reality is, <strong>you don’t need fancy techniques or libraries to build useful personal tools with LLMs.</strong></p>

<p>In this short post, I’ll show you how I built a useful AI assistant for my family using a dead simple architecture: a single SQLite table of memories, and a handful of cron jobs for ingesting memories and sending updates, all hosted on <a href="https://www.val.town/">Val.town</a>. The whole thing is so simple that you can easily copy and extend it yourself.</p>

<h2 id="meet-stevens">Meet Stevens</h2>

<p>The assistant is called Stevens, named after the butler in the great Ishiguro novel <a href="https://en.wikipedia.org/wiki/The_Remains_of_the_Day">Remains of the Day</a>. Every morning it sends a brief to me and my wife via Telegram, including our calendar schedules for the day, a preview of the weather forecast, any postal mail or packages we’re expected to receive, and any reminders we’ve asked it to keep track of. All written up nice and formally, just like you’d expect from a proper butler.</p>

<p>Here’s an example. (I’ll use fake data throughout this post, beacuse our actual updates contain private information.)</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/telegram.png?1744560139" alt=""></p>

<p>Beyond the daily brief, we can communicate with Stevens on-demand—we can forward an email with some important info, or just leave a reminder or ask a question via Telegram chat.</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/coffee.png?1744560139" alt=""></p>

<p>That’s Stevens. It’s rudimentary, but already more useful to me than Siri!</p>

<h2 id="behind-the-scenes">Behind the scenes</h2>

<p>Let’s break down the simple architecture behind Stevens. The whole thing is hosted on <a href="https://www.val.town/">Val.town</a>, a lovely platform that offers SQLite storage, HTTP request handling, scheduled cron jobs, and inbound/outbound email: a perfect set of capabilities for this project.</p>

<p>First, how does Stevens know what goes in the morning brief? The key is the butler’s notebook, a log of everything that Stevens knows. There’s an admin view where we can see the notebook contents—let’s peek and see what’s in there:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/notebook.png?1744560139" alt=""></p>

<p>You can see some of the entries that fed into the morning brief above—for example, the parent-teacher conference has a log entry.</p>

<p>In addition to some text, entries can have a <em>date</em> when they are expected to be relevant.  There are also entries with no date that serve as general background info, and are always included. You can see these particular background memories came from a Telegram chat, because Stevens does an intake interview via Telegram when you first get started:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/background.png?1744560139" alt=""></p>

<p><strong>With this notebook in hand, sending the morning brief is easy</strong>: just run a cron job which makes a call to the Claude API to write the update, and then sends the text to a Telegram thread. As context for the model, we include any log entries dated for the coming week, as well as the undated background entries.</p>

<p>Under the hood, the “notebook” is just a single SQLite table with a few columns. Here’s a more boring view of things:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/db.png?1744560139" alt=""></p>

<p>But wait: how did the various log entries get there in the first place? In the admin view, we can watch Stevens buzzing around entering things into the log from various sources:</p>

<video width="100%" controls="">
  <source src="https://www.geoffreylitt.com/images/article_images/stevens/cron.mp4" type="video/mp4">
</video>

<p>This is just some data importers populating the table:</p>

<ul>
<li>An hourly data pull from the Google Calendar API</li>
<li>An hourly check of the local weather forecast using a weather API</li>
<li>I forward <a href="https://www.usps.com/manage/informed-delivery.htm">USPS Informed Delivery</a> containing scans of our postal mail, and Stevens OCRs them using Claude</li>
<li>Inbound Telegram and email messages can also result in log entries</li>
<li>Every week, some “fun facts” get added into the log, as a way of adding some color to future daily updates.</li>
</ul>

<p><strong>This system is easily extensible with new importers.</strong> An importer is just any process that adds/edits memories in the log. The memory contents can be any arbitrary text, since they’ll just be fed back into an LLM later anyways.</p>

<h2 id="reflections">Reflections</h2>

<p>A few quick reflections on this project:</p>

<p><strong>It’s very useful for personal AI tools to have access to broader context from other information sources.</strong> Awareness of things like my calendar and the weather forecast turns a dumb chatbot into a useful assistant. ChatGPT recently added memory of past conversations, but there’s lots of information not stored within that silo. I’ve <a href="https://x.com/geoffreylitt/status/1810442615264796864">written before</a> about how the endgame for AI-driven personal software isn’t more app silos, it’s small tools operating on a shared pool of context about our lives.</p>

<p><strong>“Memory” can start simple.</strong> In this case, the use cases of the assistant are limited, and its information is inherently time-bounded, so it’s fairly easy to query for the relevant context to give to the LLM. It also helps that some modern models have long context windows. As the available information grows in size, RAG and <a href="https://x.com/sjwhitmore/status/1910439061615239520">fancier</a> <a href="https://arxiv.org/abs/2304.03442">approaches</a> to memory may be needed, but you can start simple.</p>

<p><strong>Vibe coding enables sillier projects.</strong> Initially, Stevens spoke with a dry tone, like you might expect from a generic Apple or Google product. But it turned out it was just more <em>fun</em> to have the assistant speak like a formal butler. This was trivial to do, just a couple lines in a prompt. Similarly, I decided to make the admin dashboard views feel like a video game, because why not? I generated the image assets in ChatGPT, and vibe coded the whole UI in Cursor + Claude 3.7 Sonnet; it took a tiny bit of extra effort in exchange for a lot more fun.</p>

<h2 id="try-it-yourself">Try it yourself</h2>

<p>Stevens isn’t a product you can run out of the box, it’s just a personal project I made for myself.</p>

<p>But if you’re curious, you can check out the code and fork the project <a href="https://www.val.town/x/geoffreylitt/stevensDemo">here</a>. You should be able to apply this basic pattern—a single memories table and an extensible constellation of cron jobs—to do lots of other useful things.</p>

<p>I recommend editing the code using your AI editor of choice with the <a href="https://github.com/pomdtr/vt">Valtown CLI</a> to sync to local filesystem.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>