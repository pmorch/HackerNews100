<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 25 Jun 2025 00:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[National Archives to restrict public access starting July 7 (231 pts)]]></title>
            <link>https://www.archives.gov/college-park</link>
            <guid>44371169</guid>
            <pubDate>Tue, 24 Jun 2025 21:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.archives.gov/college-park">https://www.archives.gov/college-park</a>, See on <a href="https://news.ycombinator.com/item?id=44371169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            

            <h3>Address<br>
              &nbsp;</h3>

            <p>8601 Adelphi Road</p>

            <p>College Park, MD&nbsp; 20740</p>

            <p>Truck Deliveries - entrance at&nbsp;3301 Metzerott Road</p>

            <p><strong>Customer Service Center:</strong> 1-866-272-6272&nbsp;</p>

            <p><strong>Lost and Found:</strong> 301-837-2900</p>

            <p><strong>Email:</strong> <a href="mailto:inquire@nara.gov">inquire@nara.gov</a></p>

            <p>Effective July 7, 2025, the National Archives at College Park, MD, will become a restricted-access federal facility with access only for visitors with a legitimate business need. It will no longer be open to the general public. Security officers will enforce these restrictions, and your cooperation is appreciated.</p>

            

            <h3>Parking</h3>

            

            

            <p>Only U.S. government federal employees with valid Personal Identity Verification (PIV) cards and registered researchers with disability documentation may park in the Archives II garage.</p>

            <p>All NARA contractors, researchers, and other visitors with legitimate business needs must park in the PEPCO satellite parking lot. There will be a 15-minute loading/unloading zone to accommodate equipment and passenger drop-off and pick-up. Researchers will bring their equipment into the building, where it will undergo security screening. Equipment may be stored in a researcher locker or left in the lobby until the owner has moved their car to the PEPCO lot and returned to the building.</p>

            <p>All for-hire transportation services, such as Uber and Lyft, will be confined to this loading/unloading zone. Hotel shuttles and vans will be directed to discharge and pick up passengers at the Adelphi Road bus stops.</p>

            <p>If you park in an Americans with Disability Act (ADA) space without the proper disability documentation in the form of disability tags, placard, or permit, you will be ticketed and may be towed. Repeat offenders will lose their parking privileges. Security officers will thoroughly verify all&nbsp;ADA permits.</p>

            

            <h3>Visitor Requirements</h3>

            

            <p>All researchers must apply and present a <a href="https://www.archives.gov/research/start/researcher-card">researcher card</a>, which may be obtained in Room 1000. This ensures that proper identification is on file for all individuals accessing the building to establish a legitimate business purpose. Abuse of any researcher registration to circumvent access by the general public may result in a trespass situation and a permanent ban from access to all NARA facilities.</p>

            <p>The pedestrian circle at the front of the building will be permanently closed to vehicle traffic. Registered researchers will be allowed to load and unload equipment at the designated 15-minute drop-off and pick-up zone.</p>

            

            <h3>Bus Services</h3>

            

            <p>The Washington Metropolitan Area Transit Authority (WMATA) bus will cease operations on June 30, 2025. The Prince George’s County bus will not be authorized to enter NARA's roadway, bus stop, or the pedestrian circle. Passengers must use the designated bus stops on Adelphi Road for drop-off and pick-up. The NARA shuttle bus schedule will remain the same; however, drop-off will take place in the 15-minute loading/unloading zone, and pick-up will take place in the bus shelter.</p>

            <p>Thank you for your understanding and support of these changes to ensure the security and safety of all building occupants.</p>

            

            <h3>Hours</h3>

            

            <p>The research room at the National Archives at College Park, MD, is open Monday–Friday, 9 a.m.–5 p.m. Research appointments are highly encouraged, but you may also conduct research as a walk-in. Research appointments can be scheduled via Eventbrite on the&nbsp;<a href="https://www.eventbrite.com/o/national-archives-dc-area-research-appointments-87533423643">National Archives DC-area Research Appointments</a>&nbsp;page.&nbsp;</p>

            <p>Researchers may contact Textual Consultation at&nbsp;<a href="mailto:archives2reference@nara.gov">archives2reference@nara.gov</a>&nbsp;for&nbsp;advance consultation and Researcher Registration at <a href="mailto:visit_archives2@nara.gov">visit_archives2@nara.gov</a> for researcher registration or research room appointment questions.</p>

            <h4>Researchers may contact the Special Media&nbsp;addresses listed below for advance consultation and appointment questions:</h4>

            <p>Cartographic:&nbsp;<a href="mailto:consultation.carto@nara.gov">consultation.carto@nara.gov&nbsp;</a></p>

            <p>Still Pictures:&nbsp;<a href="mailto:consultation.stillpix@nara.gov">consultation.stillpix@nara.gov&nbsp;</a></p>

            <p>Moving Image and Sound: <a href="mailto:mopix@nara.gov">mopix@nara.gov</a></p>

            

            <p>Please see these <a href="https://www.archives.gov/research/news/faqs-research-room-reopenings">frequently asked questions</a> for further information about conducting in-person research at the National Archives.</p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The German automotive industry wants to develop open-source software together (102 pts)]]></title>
            <link>https://www.vda.de/en/press/press-releases/2025/250624_PM_Automotive_industry_signs_Memorandum_of_Understanding</link>
            <guid>44370494</guid>
            <pubDate>Tue, 24 Jun 2025 20:07:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vda.de/en/press/press-releases/2025/250624_PM_Automotive_industry_signs_Memorandum_of_Understanding">https://www.vda.de/en/press/press-releases/2025/250624_PM_Automotive_industry_signs_Memorandum_of_Understanding</a>, See on <a href="https://news.ycombinator.com/item?id=44370494">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><h4><span>Collaboration for more speed, efficiency, and security in software development and the basis for an open and collaborative ecosystem</span></h4></p><div data-speakable="text"><p>With the support of the German Association of the Automotive Industry (VDA), 11 companies in the automotive industry have agreed on pre-competitive cooperation in open source software development.</p>

<p>A corresponding Memorandum of Understanding (MoU) was signed today at the 29th International Automotive Electronics Congress (AEK).</p>

<p>With the increasing importance and complexity of vehicle software, it is becoming critical for the industry to increase speed and efficiency in development while ensuring high quality and safety.</p>

<p>EA significant portion of the vehicle software is not directly accessible to the user and therefore not differentiating. This fact allows the corresponding software modules to be developed jointly in an open and collaborative ecosystem.</p>

<p>In order to achieve the necessary functional safety for automotive series software, a groundbreaking development process for open source was developed in preparation for certification according to the relevant standards.</p>

<p>In addition, by providing executable software modules instead of detailed specifications, standardization and increased development speed are achieved through the so-called code-first approach.<br>
The software development takes place in a transparent and vendor-independent environment of the Eclipse Foundation as part of the S-CORE project.</p>

<p>This ecosystem is open, both through software interoperability with relevant industry standards and for contributions and collaboration from other European and international companies.</p>

<p>The initiative's timeline envisages that the software scope for series development of a platform for autonomous driving will be available in 2026.</p>

<p>The modular software scope can be adapted or expanded and then made available to the industry as a customized distribution for series development. This allows manufacturers and suppliers to focus on differentiating features while maintaining core components together. This creates a strong foundation for innovation - and the freedom to focus on what makes the difference for the customer.</p>

<p>"Together we are building a future-proof and powerful software ecosystem - open, transparent and secure," VDA Managing Director Dr. Marcus Bollig said.</p>

<p><strong><a href="https://www.vda.de/dam/jcr:50e82fa0-dd27-4db5-834f-80032c57b1b3/MoU%20Automotive%20Grade%20Open-Source%20Software%20Ecosystem%20signed.pdf">You can download the Memorandum of Understanding here</a></strong></p>

<p><strong>Further quotes from the companies:</strong></p>

<p><strong>BMW Group<br>
Dr. Christoph Grote, SVP Electronics and Software</strong><br>
"The BMW Group believes that integrated ecosystems with open-source platforms and tools are a key driver for the development of mobility solutions. A shared code-first approach will be the foundation for functional innovations in our future products. We are committed to ECLIPSE S-CORE as a promising open-source approach for our upcoming projects."</p>

<p><br>
<strong>Continental AG<br>
Karsten Michels, Head of Product line "High Performance Computer", BA "Architecture and Network Solutions"</strong><br>
"With our contribution, Continental combines open source and virtualization with security certification and standardization. This creates an open and secure HPC middleware stack that accelerates the transition to the software-defined vehicle."</p>

<p><br>
<strong>ECLIPSE Foundation<br>
Mike Milinkovich, Executive Director</strong><br>
"Collaboration in the development of secure and open-source automotive platforms is a critical factor for the automotive industry. The Eclipse Foundation's governance model enables open collaboration between OEMs, tiers, and tech players within the Eclipse SDV Working Group. We recognize the trust placed in us as the stewards of such a strategic initiative and embrace the challenge of making it a success."</p>

<p><strong>ETAS GmbH<br>
Dr. Thomas Irawan, CEO</strong><br>
"Building on our role as a pioneer in automotive platform software, we are driving industry-wide innovation through an open source ecosystem, accelerating time to market, and delivering safe and sustainable solutions for the mobility of tomorrow."</p>

<p><strong>HELLA GmbH &amp; Co. KGaA<br>
Dr. Dietmar Stapel, Vice President Product Segment Radar</strong><br>
"We are pleased to support the Automotive Grade Open Source Ecosystem. Open, common standards are essential for secure integration and form the foundation for delivering innovative, value-added automotive features."</p>

<p><strong>Mercedes-Benz AG<br>
Magnus Östberg, Chief Software Officer</strong><br>
"As the creators of the automotive open source ecosystem, we are actively driving the future of automotive software with our code-first strategy. This is our clear commitment to open standards as the foundation for innovation."</p>

<p><strong>Qorix<br>
Markus Shupfner, CEO</strong><br>
"Qorix is committed to a powerful, open software ecosystem that combines functional safety and the speed of innovation - from architecture to production deployment."</p>

<p><strong>Robert Bosch GmbH<br>
Dr. Mathias Pilin, CTO Mobility</strong><br>
"We promote software solutions that integrate seamlessly across vehicle platforms, systems, and supplier technologies - for a software-defined mobility of the future."</p>

<p><strong>Valeo Brain Division<br>
Joachim Mathes, CTO </strong><br>
"Valeo has decided to join S-CORE and contribute key elements of its vOS to the stack. We are confident that a greater level of standardization and reuse will benefit the entire industry."</p>

<p><strong>Vector Informatik GmbH<br>
Dr. Matthias Traub, Managing Director</strong><br>
"With our joint initiative for an open software ecosystem for automotive ECUs, we are adding a powerful tool to the industry’s HPC full-stack toolbox."</p>

<p><strong>Dr. Ing. h.c. F. Porsche AG<br>
Dr. Oliver Seifert, Vice President R&amp;D Infotainment and Connect</strong><br>
"Through this open source ecosystem in automotive development, we shorten the time to market, reduce application development effort, and drive innovation."</p>

<p><strong>ZF Friedrichshafen<br>
Torsten Gollewski, Executive Vice President Corporate R&amp;D Innovation &amp; Technology</strong><br>
"Software development based on open source is the key to greater efficiency and speed. This is necessary to remain internationally competitive. The VDA initiative is a good example of the benefits that collaboration can bring."<br>
&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Forbidden secrets of ancient X11 scaling technology revealed (160 pts)]]></title>
            <link>https://flak.tedunangst.com/post/forbidden-secrets-of-ancient-X11-scaling-technology-revealed</link>
            <guid>44369646</guid>
            <pubDate>Tue, 24 Jun 2025 18:58:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flak.tedunangst.com/post/forbidden-secrets-of-ancient-X11-scaling-technology-revealed">https://flak.tedunangst.com/post/forbidden-secrets-of-ancient-X11-scaling-technology-revealed</a>, See on <a href="https://news.ycombinator.com/item?id=44369646">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>People keep telling me that X11 doesn’t support DPI scaling, or fractional scaling, or multiple monitors, or something. There’s nothing you can do to make it work. I find this surprising. Why doesn’t it work? I figure the best way to find out is try the impossible and see how far we get.</p><p>I’m just going to draw a two inch circle on the screen. This screen, that screen, any screen, the circle should always be two inches. Perhaps not the most exciting task, but I figure it’s isomorphic to any other scaling challenge. Just imagine it’s the letter o or a button we wish to draw at a certain size.</p><p>I have gathered around me a few screens of different sizes and resolutions. My laptop screen, and then a bit to the right a desktop monitor, and then somewhere over that way a nice big TV. Specifically:</p><pre><code>$ xrandr | grep \ connected
eDP connected primary 2880x1800+0+0 (normal left inverted right x axis y axis) 302mm x 189mm
DisplayPort-0 connected 2560x1440+2880+0 (normal left inverted right x axis y axis) 590mm x 334mm
DisplayPort-1 connected 3840x2160+5440+0 (normal left inverted right x axis y axis) 1600mm x 900mm</code></pre><p>I think I just spoiled the ending, but here we go anyway.</p><p>I’m going to draw the circle with OpenGL, using a simple shader and OBT. There’s a bunch of not very exciting code to create a window and a GLX context, but eventually we’re going to be looking at the shader. This may not be the best way to draw a circle, but it’s my way. For reference, the full code is in <a href="https://humungus.tedunangst.com/r/xtoys/v/tip/f/circle.c">circle.c</a>.</p><pre><code><span>void</span> main<span>(</span><span>)</span>
<span>{</span>
    float thick <span>=</span> radius <span>/</span> <span>10</span>;
    <span>if</span> <span>(</span>abs<span>(</span>center<span>.</span>y <span>-</span> gl_FragCoord<span>.</span>y<span>)</span> <span>&lt;</span> thick<span>/</span><span>2</span><span>)</span> 
        thick <span>=</span> <span>2</span>;
    float pi <span>=</span> <span>3</span><span>.</span><span>14159</span>;
    float d <span>=</span> distance<span>(</span>gl_FragCoord<span>.</span>xy<span>,</span> center<span>)</span>;
    float angle <span>=</span> atan<span>(</span>gl_FragCoord<span>.</span>y <span>-</span> center<span>.</span>y<span>,</span> gl_FragCoord<span>.</span>x <span>-</span> center<span>.</span>x<span>)</span>;
    angle <span>/=</span> <span>2</span> <span>*</span> pi;
    angle <span>+=</span> <span>0</span><span>.</span><span>5</span>;
    angle <span>+=</span> <span>0</span><span>.</span><span>25</span>;
    <span>if</span> <span>(</span>angle <span>&gt;</span> <span>1</span><span>.</span><span>0</span><span>)</span> angle <span>-=</span> <span>1</span><span>.</span><span>0</span>;
    float amt <span>=</span> <span>(</span>thick <span>-</span> abs<span>(</span>d <span>-</span> radius<span>)</span><span>)</span> <span>/</span> thick;
    <span>if</span> <span>(</span>d <span>&lt;</span> radius <span>+</span> thick &amp;&amp; d <span>&gt;</span> radius <span>-</span> thick<span>)</span> 
        fragment <span>=</span> vec4<span>(</span>rgb<span>(</span>angle<span>)</span><span>*</span>amt<span>,</span> <span>1</span><span>.</span><span>0</span><span>)</span>;
    <span>else</span> 
        discard;
<span>}</span></code></pre><p>I got a little carried away and made a pretty color wheel instead of a flat circle.</p><p>The key variable is <code>radius</code> which tells us how many pixels from the center the circle should be. But where does the shader get this from?</p><pre><code>    glUniform1f(0, radius);</code></pre><p>Okay, but seriously. We listen for configure events. This is the X server telling us our window has been moved or resized. Something has changed, so we should figure out where we are and adjust accordingly.</p><pre><code>        <span>case</span> ConfigureNotify<span>:</span>
            <span>{</span>
                XConfigureEvent <span>*</span>xev <span>=</span> <span>(</span><span>void</span> <span>*</span><span>)</span>&amp;ev;
                <span>int</span> x <span>=</span> xev<span>-&gt;</span>x;
                <span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>16</span>; i<span>++</span><span>)</span> <span>{</span>
                    <span>if</span> <span>(</span>x <span>&gt;=</span> screen_x<span>[</span>i<span>]</span> &amp;&amp; x <span>-</span> screen_x<span>[</span>i<span>]</span> <span>&lt;</span> screen_w<span>[</span>i<span>]</span><span>)</span> <span>{</span>
                        float r <span>=</span> screen_w<span>[</span>i<span>]</span> <span>/</span> screen_mm<span>[</span>i<span>]</span> <span>*</span> <span>25</span><span>.</span><span>4</span>;
                        <span>if</span> <span>(</span>r <span>!=</span> radius<span>)</span> <span>{</span>
                            radius <span>=</span> r;
                        <span>}</span>
                        <span>break</span>;
                    <span>}</span>
                <span>}</span>
                width <span>=</span> xev<span>-&gt;</span>width;
                height <span>=</span> xev<span>-&gt;</span>height;
            <span>}</span></code></pre><p>Getting closer. The numbers we need come from the X server.</p><pre><code>    XRRScreenResources <span>*</span>res <span>=</span> XRRGetScreenResourcesCurrent<span>(</span>disp<span>,</span> root<span>)</span>;
    float screen_mm<span>[</span><span>16</span><span>]</span> <span>=</span> <span>{</span> <span>0</span> <span>}</span>;
    float screen_w<span>[</span><span>16</span><span>]</span> <span>=</span> <span>{</span> <span>0</span> <span>}</span>;
    float screen_x<span>[</span><span>16</span><span>]</span> <span>=</span> <span>{</span> <span>0</span> <span>}</span>;
    <span>int</span> j <span>=</span> <span>0</span>;
    <span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> res<span>-&gt;</span>noutput; i<span>++</span><span>)</span> <span>{</span>
        XRROutputInfo <span>*</span>info <span>=</span> XRRGetOutputInfo<span>(</span>disp<span>,</span> res<span>,</span> res<span>-&gt;</span>outputs<span>[</span>i<span>]</span><span>)</span>;
        screen_mm<span>[</span>j<span>++</span><span>]</span> <span>=</span> info<span>-&gt;</span>mm_width;
    <span>}</span>
    j <span>=</span> <span>0</span>;
    <span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> res<span>-&gt;</span>ncrtc; i<span>++</span><span>)</span> <span>{</span>
        XRRCrtcInfo <span>*</span>info <span>=</span> XRRGetCrtcInfo<span>(</span>disp<span>,</span> res<span>,</span> res<span>-&gt;</span>crtcs<span>[</span>i<span>]</span><span>)</span>;
        screen_w<span>[</span>j<span>]</span> <span>=</span> info<span>-&gt;</span>width;
        screen_x<span>[</span>j<span>++</span><span>]</span> <span>=</span> info<span>-&gt;</span>x;
    <span>}</span></code></pre><p>It’s somewhat annoying that physical width and virtual width are in different structures, and we have to put the puzzle back together, but there it is.</p><p>Some more code to handle expose events, the draw loop, etc., and that’s it. A beautiful circle sized just right. Drag it over onto the next monitor, and it changes size. Or rather, it maintains its size. Send it over to the next monitor, and same as before.</p><p>Time for the visual proof. A nice pretty circle on my laptop. Another circle on my monitor. And despite the 4K resolution, a somewhat pixely circle on my TV. Turns out the hardest part of this adventure was trying to hold an uncooperative tape measure in place with one hand while trying to get a decent, or not, photo with the other. </p><p><img src="https://flak.tedunangst.com/images/circles.jpg"></p><p>We were so close to perfection. Somebody at the factory screwed up, and my TV is actually 66.5” wide, not the claimed 63 inches. So if we learn anything today, it’s that you shouldn’t use a consumer LG TV for accurately measuring the scale of structural engineering diagrams, at least not without further calibration.</p><p>The good news is we’ve done the impossible. Even better, I didn’t mention that I wasn’t actually running this program on my laptop. It was running on my router in another room, but everything worked as if by <span>MIT-MAGIC-COOKIE-1</span>. Alas, we are still no closer to understanding why people say this is impossible.</p><p>Anyway, I think the point is we should probably ignore the people who can’t do something when they tell us we can’t do it either. I woke up this morning not knowing precisely how to draw a scaled circle, having never done so before, but armed with a vague sense that surely it must be possible, because come on of course it is, I got it working. And now look at me, driven insane by the relentless stare of three unblinking eyes.</p><p>With my new knowledge, I also wrote an onscreen <a href="https://humungus.tedunangst.com/r/xtoys/v/tip/f/ruler.c">ruler</a> using the shape extension. Somewhat tautological for measuring the two inch circle, but in the event anyone asks, I can now tell them my terminal line height is 1/8”, and yes, I measured.</p><p><img src="https://flak.tedunangst.com/images/terminal-ruler.jpg">
</p></div><p>
Posted 24 Jun 2025 17:59 by tedu Updated: 24 Jun 2025 17:59 
<br>Tagged: <a href="https://flak.tedunangst.com/t/programming">programming</a> <a href="https://flak.tedunangst.com/t/x11">x11</a>
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fun with uv and PEP 723 (285 pts)]]></title>
            <link>https://www.cottongeeks.com/articles/2025-06-24-fun-with-uv-and-pep-723</link>
            <guid>44369388</guid>
            <pubDate>Tue, 24 Jun 2025 18:41:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cottongeeks.com/articles/2025-06-24-fun-with-uv-and-pep-723">https://www.cottongeeks.com/articles/2025-06-24-fun-with-uv-and-pep-723</a>, See on <a href="https://news.ycombinator.com/item?id=44369388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>              <h2> Fun with uv and PEP 723 <time datetime="2025-06-24T00:00:00.000Z"> June 24, 2025 </time> </h2>  <p>For the longest time, I have been frustrated with Python because I couldn’t use it for one-off scripts. I had to first ensure it was running in an environment where it could find the right Python version and the dependencies installed. That is now a thing of the past.</p>

<p>If you are not a Pythonista (or one possibly living under a rock), <a href="https://docs.astral.sh/uv/">uv</a> is <em>an extremely fast Python package and project manager, written in Rust.</em></p>
<p>uv also provides this nifty tool called <code>uvx</code> (kinda like <code>npx</code> from the Node/NPM ecosystem for Javascript/Typescript packages) which can be used to invoke a Python tool inside a package. <code>uvx</code> takes care of creating a (cached) disposable virtual environment, setting up the right Python version and installing all the dependencies before running.</p>
<p>For example</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>$ uvx ruff --version</span></span>
<span><span>Installed 1 package in 5ms</span></span>
<span><span>ruff 0.12.0</span></span></code></pre>

<p><a href="https://peps.python.org/pep-0723/">PEP 723</a> is a Python Enhancement Proposal that <em>specifies a metadata format that can be embedded in single-file Python scripts to assist launchers, IDEs and other external tools which may need to interact with such scripts.</em></p>
<p>Here is the example directly lifted from the proposal:</p>
<pre tabindex="0" data-language="python"><code><span><span># /// script</span></span>
<span><span># requires-python = "&gt;=3.11"</span></span>
<span><span># dependencies = [</span></span>
<span><span>#   "requests&lt;3",</span></span>
<span><span>#   "rich",</span></span>
<span><span># ]</span></span>
<span><span># ///</span></span>
<span></span>
<span><span>import</span><span> requests</span></span>
<span><span>from</span><span> rich.pretty </span><span>import</span><span> pprint</span></span>
<span></span>
<span><span>resp </span><span>=</span><span> requests.get(</span><span>"https://peps.python.org/api/peps.json"</span><span>)</span></span>
<span><span>data </span><span>=</span><span> resp.json()</span></span>
<span><span>pprint([(k, v[</span><span>"title"</span><span>]) </span><span>for</span><span> k, v </span><span>in</span><span> data.items()][:</span><span>10</span><span>])</span></span></code></pre>

<p>Combining uv and the PEP-723 metadata inside a Python script, we can run the script in the previous section as follows:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>$ uv run pep.py</span></span>
<span><span>Installed 9 packages in 24ms</span></span>
<span><span>[</span></span>
<span><span>│   ('1', 'PEP Purpose and Guidelines'),</span></span>
<span><span>│   ('2', 'Procedure for Adding New Modules'),</span></span>
<span><span>│   ('3', 'Guidelines for Handling Bug Reports'),</span></span>
<span><span>│   ('4', 'Deprecation of Standard Modules'),</span></span>
<span><span>│   ('5', 'Guidelines for Language Evolution'),</span></span>
<span><span>│   ('6', 'Bug Fix Releases'),</span></span>
<span><span>│   ('7', 'Style Guide for C Code'),</span></span>
<span><span>│   ('8', 'Style Guide for Python Code'),</span></span>
<span><span>│   ('9', 'Sample Plaintext PEP Template'),</span></span>
<span><span>│   ('10', 'Voting Guidelines')</span></span>
<span><span>]</span></span></code></pre>

<p>We can combine things we covered in the previous sections to create a simple executable script that can extract YouTube transcripts.</p>
<p>First we create a Python script with a shebang and inline metadata.</p>
<pre tabindex="0" data-language="python"><code><span><span>#!/usr/bin/env -S uv run --script</span></span>
<span><span># /// script</span></span>
<span><span># requires-python = "&gt;=3.8"</span></span>
<span><span># dependencies = [</span></span>
<span><span>#     "youtube-transcript-api",</span></span>
<span><span># ]</span></span>
<span><span># ///</span></span>
<span></span>
<span><span>import</span><span> sys</span></span>
<span><span>import</span><span> re</span></span>
<span><span>from</span><span> youtube_transcript_api </span><span>import</span><span> YouTubeTranscriptApi</span></span>
<span><span>from</span><span> youtube_transcript_api.formatters </span><span>import</span><span> TextFormatter</span></span>
<span></span>
<span><span>if</span><span> len</span><span>(sys.argv) </span><span>&lt;</span><span> 2</span><span>:</span></span>
<span><span>    print</span><span>(</span><span>'Usage: provide YouTube URL or video_id as argument'</span><span>, </span><span>file</span><span>=</span><span>sys.stderr)</span></span>
<span><span>    sys.exit(</span><span>1</span><span>)</span></span>
<span></span>
<span><span>url_or_id </span><span>=</span><span> sys.argv[</span><span>1</span><span>]</span></span>
<span></span>
<span><span># Extract video ID from URL if it's a full URL</span></span>
<span><span>video_id_match </span><span>=</span><span> re.search(</span><span>r</span><span>'</span><span>(?:</span><span>v=</span><span>|</span><span>/</span><span>)([a-zA-Z0-9_-]</span><span>{11}</span><span>)</span><span>'</span><span>, url_or_id)</span></span>
<span><span>if</span><span> video_id_match:</span></span>
<span><span>    video_id </span><span>=</span><span> video_id_match.group(</span><span>1</span><span>)</span></span>
<span><span>else</span><span>:</span></span>
<span><span>    # Assume it's already a video ID</span></span>
<span><span>    video_id </span><span>=</span><span> url_or_id</span></span>
<span></span>
<span><span>try</span><span>:</span></span>
<span><span>    ytt_api </span><span>=</span><span> YouTubeTranscriptApi()</span></span>
<span><span>    transcript </span><span>=</span><span> ytt_api.fetch(video_id)</span></span>
<span><span>    formatter </span><span>=</span><span> TextFormatter()</span></span>
<span><span>    print</span><span>(formatter.format_transcript(transcript))</span></span>
<span><span>except</span><span> Exception</span><span> as</span><span> e:</span></span>
<span><span>    print</span><span>(</span><span>f</span><span>'Error: </span><span>{</span><span>e</span><span>}</span><span>'</span><span>, </span><span>file</span><span>=</span><span>sys.stderr)</span></span>
<span><span>    sys.exit(</span><span>1</span><span>)</span></span></code></pre>
<p>Note the shebang line: <code>#!/usr/bin/env -S uv run --script</code>. It is important to specify <code>uv run</code> with the <code>--script</code> flag when used on the shebang line.</p>
<p>We save this script as <code>ytt</code> and then make it executable with <code>chmod +x ytt</code>.</p>
<p>We can now run the script like:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>$ ./ytt https://www.youtube.com/watch?v=zgSQr0d5EVg</span></span>
<span><span>Installed 7 packages in 10ms</span></span>
<span><span>hey it's Matt here and today I'm going</span></span>
<span><span>to show you how to use UV not only to</span></span>
<span><span>install packages in your python projects</span></span>
<span><span>but to manage entire projects to create</span></span>
<span><span>virtual environments and even how to</span></span>
<span><span>manage entire versions of python with UV</span></span>
<span><span>uh and hopefully you'll understand by</span></span>
<span><span>any of this video UV is a dropin</span></span>
<span><span></span></span>
<span><span>…&lt;snipped text&gt;…</span></span></code></pre>
<h2 id="fun-times">Fun times</h2>
<p>This opens up a lot of possibilities for running Python code more seamlessly. Before this I used to prefer <a href="https://go.dev/">Go</a> for one-off scripts because it was easy to create a self-contained binary executable. But now that I could use uv, I coded up a quick MCP server in Python for extracting YouTube transcripts. Check it out on Github at <a href="https://github.com/cottongeeks/ytt-mcp">cottongeeks/ytt-mcp</a>.</p>
<h2 id="more-resources">More resources</h2>
<ul>
<li><a href="https://docs.astral.sh/uv/guides/scripts/#using-a-shebang-to-create-an-executable-file">Running scripts | uv</a></li>
<li><a href="https://docs.astral.sh/uv/concepts/tools/">Tools | uv</a></li>
<li><a href="https://aider.chat/2025/01/15/uv.html">Using uv as an installer | aider</a></li>
</ul>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Man 'refused entry into US' as border control catch him with bald JD Vance meme (487 pts)]]></title>
            <link>https://www.dublinlive.ie/news/world-news/man-refused-entry-us-border-31925059</link>
            <guid>44369140</guid>
            <pubDate>Tue, 24 Jun 2025 18:21:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dublinlive.ie/news/world-news/man-refused-entry-us-border-31925059">https://www.dublinlive.ie/news/world-news/man-refused-entry-us-border-31925059</a>, See on <a href="https://news.ycombinator.com/item?id=44369140">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><!-- Article Start--><p>A 21-year-old Norwegian tourist claims he was denied entry to the United States and harassed by ICE agents after they discovered a JD Vance meme on his phone.</p> <p>Mads Mikkelsen arrived at New Jersey's Newark Airport on June 11 when he was pulled aside by border control and placed in a cell, he told Norwegian outlet Nordlys. Mads was travelling to the States to visit friends, first in New York and then in Austin, Texas, but suffered "harassment and abuse of power" at the hands of US immigration authorities.</p> <p>"I felt prejudiced, suspected and simply humiliated even then, in front of many other people at the airport," The Tromsø native recounted. "They took me to a room with several armed guards, where I had to hand over my shoes, mobile phone and backpack."</p> <p>Officers quizzed Mads about his visit, and his plans, before adopting a personal line of questioning. "They asked direct questions about drug smuggling, terrorist plans and right-wing extremism, completely without reason," he claimed.</p> <p>"They demanded full information about everyone I was going to meet in the US, including name, address, phone number and what they did for work." Mads' mother was due to meet up with him a few weeks into his stay and the pair had planned to travel to several national parks.</p> <p>"I had travelled for twelve hours, slept poorly, and was physically and mentally completely exhausted even before they started the questioning," he continued. A strenuous crackdown by U.S. Customs and Border Protection has followed President Donald Trump's return to office, with the service being allowed to search phones.</p> <p>A French scientist was denied entry at the border earlier this year, in March, after officers unearthed messages criticising Trump on his phone. Mikkelsen explained: "They threatened me with a minimum fine of $5,000 or five years in prison if I refused to provide the password to my phone."</p> <p>After handing over his password, Mads was told he would not be allowed to go through with his planned vacation after two images were not to the officers' liking. One image was of a meme showcasing JD Vance with a bald, egg-shaped head. Variations of the image were shared endlessly in March on social media, with the Vice President himself posting his own version.</p> <p>The other picture showed Mads with a wooden pipe which he had made years prior. "Both pictures had been automatically saved to my camera roll from a chat app, but I really didn't think that these innocent pictures would put a stop to my entry into the country," the 21-year-old admitted.</p> <p>Mads told Nordlys he tried to explain the images as being harmless and meant as jokes but the immigration authorities ignored his pleas. He claims he was then strip-searched, forced to give blood samples, a facial scan and fingerprints.</p> <p>"Later I was taken back in, and the situation got even worse. I was pushed up against a wall and was strip-searched with a lot of force. They were incredibly harsh and used physical force the whole time," he claimed.</p> <p>"I felt completely devastated and broke down, and was close to crying several times. I was on the verge of panic. It felt like I was a terrorist suspect where I was sitting. I tried to pull myself together several times, but in the end, I just wanted to get home again."</p> <p>The Norwegian adds he was placed in a cell for a further five hours, refused food or water and placed on a plane back to Oslo the same day he arrived for the holiday of a lifetime. "I don't feel there is any point in contacting the State Department, nor do I think they have any power against such a powerful and strict country as the United States," Mads conceded.</p> <p>Mathias Rongved, a spokesperson at the Ministry of Foreign Affairs has warned fellow Norwegians that it is their duty to be clued up on US regulations before entering the country. "Most trips to the US go without any particular problems," he said.</p> <p>"Entry regulations can change at short notice, and it is the traveller's responsibility to have valid documents and be familiar with the current entry regulations. It is the immigration authorities upon arrival who decide whether you are rejected at the border. Norwegian authorities cannot intervene in this decision.</p> <p>"It is also not necessarily the case that we receive a message either from other countries' border authorities or the Norwegian traveller if the person in question is not allowed to enter a country."</p>   <p><b>Join our Dublin Live breaking news service on WhatsApp. Click</b><a href="https://chat.whatsapp.com/DJTiyHweTeJHu5aLKRIiPc" target="_blank" rel="nofollow"> <b>this link</b> </a><b>to receive your daily dose of Dublin Live content. We also treat our community members to special offers, promotions, and adverts from us and our partners. If you don’t like our community, you can check out any time you like. If you’re curious, you can read our</b><a href="https://www.reachplc.com/site-services/privacy-policy" target="_blank" rel="nofollow"> <b></b> <b>Privacy Notice</b> </a><b>.</b></p> <p><b> For all the latest news from Dublin and surrounding areas <a href="https://www.dublinlive.ie/" target="_blank" data-link-tracking="InArticle|Link" data-content-type="section">visit our homepage</a>.</b></p><!-- Article End--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iPhone customers upset by Apple Wallet ad pushing F1 movie (153 pts)]]></title>
            <link>https://techcrunch.com/2025/06/24/iphone-customers-upset-by-apple-wallet-ad-pushing-f1-movie/</link>
            <guid>44368854</guid>
            <pubDate>Tue, 24 Jun 2025 17:51:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/06/24/iphone-customers-upset-by-apple-wallet-ad-pushing-f1-movie/">https://techcrunch.com/2025/06/24/iphone-customers-upset-by-apple-wallet-ad-pushing-f1-movie/</a>, See on <a href="https://news.ycombinator.com/item?id=44368854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Apple customers aren’t thrilled they’re getting an ad from the Apple Wallet app promoting the tech giant’s Original Film, “F1 the Movie.” <a rel="nofollow" href="https://x.com/ParkerOrtolani/status/1937551035825807545">Across</a> <a rel="nofollow" href="https://www.reddit.com/r/AppleWallet/comments/1ljbjrs/how_do_i_turn_this_off">social</a> <a rel="nofollow" href="https://www.reddit.com/r/ios/comments/1ljd94e/disable_fandango_ad_from_apple_pay/">media</a>, iPhone owners are complaining that their Wallet app sent out a push notification offering a $10 discount at Fandango for anyone buying two or more tickets to the film. </p>

<p>The feature film, starring Brad Pitt, explores the world of Formula 1 and was shot at actual Grand Prix races. It also showcases the use of Apple technology, from the <a href="https://tech.yahoo.com/cameras/articles/apple-converted-iphone-action-camera-200227072.html">custom-made cameras</a> made of iPhone parts used to film inside the cars, to the <a href="https://www.engadget.com/entertainment/tv-movies/f1-the-movie-review-a-shameless-apple-ad-that-will-blow-your-socks-off-144808364.html">AirPods Max that Pitt’s character</a>, F1 driver Sonny Hayes, sleeps in.</p>







<p>However <a rel="nofollow" href="https://www.hollywoodreporter.com/movies/movie-reviews/f1-the-movie-review-brad-pitt-damson-idris-joseph-kosinski-1236291870/">well-received</a> the film may be, iPhone users don’t necessarily want their built-in utilities, like their digital wallet, marketing to them. </p>

<figure></figure>

<p>“I did not pay over $1000 for an iPhone to get advertised at,” <a rel="nofollow" href="https://www.reddit.com/r/ios/comments/1ljd94e/disable_fandango_ad_from_apple_pay/">complains</a> one Reddit user (u/captain42d). Another recent post, already with dozens of replies, wants to know <a rel="nofollow" href="https://www.reddit.com/r/AppleWallet/comments/1ljbjrs/how_do_i_turn_this_off">how to turn off Apple Pay ads</a>. </p>

<p>As it turns out, there’s a new option in iOS 26’s beta build to disable “Offers &amp; Promotions” from Apple Wallet that isn’t available in the current release. Instead, users not on the new beta build only have the option to disable notifications or to turn off seeing card benefits within Wallet during checkout. They can’t opt out of offers.</p>

<p>The addition of the new control toggle in iOS 26 suggests that Apple plans to push more marketing messages and promotions through the Wallet app in the future — something many iPhone users won’t appreciate. </p>

<p>Apple customers are generally averse to advertisements and marketing efforts pushed to their devices without their consent. In the past, they’ve pushed back at ads for Apple’s services <a rel="nofollow" href="https://daringfireball.net/2023/04/ios_adware">in their iOS Settings</a>, for example. And over 10 years later, people are still complaining about the <a rel="nofollow" href="https://www.stereogum.com/2279219/u2-songs-of-innocence-apple-iphones/columns/sounding-board/">U2 album</a> that automatically appeared in their iTunes music library.</p>


<figure><div>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">All these F1 movie notifications from Apple is the equivalent of when they put that U2 album on everyone’s iTunes back in the day no one asked for. <a rel="nofollow" href="https://t.co/ukNLzwtuFD">pic.twitter.com/ukNLzwtuFD</a></p>— John Vezmar (@johnvezmar) <a rel="nofollow" href="https://twitter.com/johnvezmar/status/1937526455556039031?ref_src=twsrc%5Etfw">June 24, 2025</a></blockquote>
</div></figure>

<p>Recalling that marketing debacle, one Reddit user writes of the new Wallet push notification for the F1 film, “I am getting Bono flashbacks.” </p>

<p>Apple has been heavily promoting the F1 film along with its distribution partner, Warner Bros., which has included the launch of a <a rel="nofollow" href="https://www.fastcompany.com/91350375/f1-the-movie-trailer-apple-haptic-feel-cars-moving-brad-pitt">haptic trailer with vibration feedback</a>. The company even kicked off its recent WWDC 2025 <a rel="nofollow" href="https://www.youtube.com/watch?v=0_DjDdfqtUE&amp;t=5404s">keynote</a> this month with a preview of the film’s action, with participation from Apple CEO Tim Cook and SVP of Software Engineering, Craig Federighi, as a race car driver.</p>

<p>We reached out to Apple for comment and did not immediately hear back.</p>

<figure></figure>
</div><div>
	
	
	
	

	
<div>
	<p>Sarah has worked as a reporter for TechCrunch since August 2011. She joined the company after having previously spent over three years at ReadWriteWeb. Prior to her work as a reporter, Sarah worked in I.T. across a number of industries, including banking, retail and software.</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/sarah-perez/" data-event="button" href="https://techcrunch.com/author/sarah-perez/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A federal judge sides with Anthropic in lawsuit over training AI on books (137 pts)]]></title>
            <link>https://techcrunch.com/2025/06/24/a-federal-judge-sides-with-anthropic-in-lawsuit-over-training-ai-on-books-without-authors-permission/</link>
            <guid>44367850</guid>
            <pubDate>Tue, 24 Jun 2025 16:22:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/06/24/a-federal-judge-sides-with-anthropic-in-lawsuit-over-training-ai-on-books-without-authors-permission/">https://techcrunch.com/2025/06/24/a-federal-judge-sides-with-anthropic-in-lawsuit-over-training-ai-on-books-without-authors-permission/</a>, See on <a href="https://news.ycombinator.com/item?id=44367850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Federal judge William Alsup <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0_2.pdf" target="_blank" rel="noreferrer noopener nofollow">ruled</a> that it was legal for Anthropic to train its AI models on published books without the authors’ permission. This marks the first time that the courts have given credence to AI companies’ claim that fair use doctrine can absolve AI companies from fault when they use copyrighted materials to train large language models (LLMs).</p>

<p>This decision comes as a blow to authors, artists, and publishers who have brought dozens of lawsuits against companies like OpenAI, Meta, <a href="https://techcrunch.com/2025/06/11/disney-and-universal-sue-midjourney-alleging-ai-related-copyright-infringement/">Midjourney</a>, Google, and more. While the ruling is not a guarantee that other judges will follow Judge Alsup’s lead, it lays the foundation for courts to side with tech companies over creatives.</p>







<p>These lawsuits often depend on how a judge interprets fair use doctrine, a <a href="https://techcrunch.com/2022/08/03/unofficial-bridgerton-musical-lawsuit-netflix-barlow-bear/">notoriously finicky</a> carve-out of copyright law that <a href="https://www.copyright.gov/title17/#:~:text=L.%20No.%2094%2D553,subsequent%20amendments%20to%20Title%2017." target="_blank" rel="noreferrer noopener nofollow">hasn’t been updated</a> since 1976 — a time before the internet, let alone the concept of generative AI training sets.</p>

<p>Fair use rulings take into account what the work is being used for (parody and education can be viable), whether it’s being reproduced for commercial gain (you can write “Star Wars” fan fiction, but you can’t sell it), and how transformative a derivative work is from the original.</p>

<p>Companies like <a href="https://www.reuters.com/legal/litigation/meta-says-copying-books-was-fair-use-authors-ai-lawsuit-2025-03-25/" target="_blank" rel="noreferrer noopener nofollow">Meta</a> have made similar fair use arguments in defense of training on copyrighted works, though before this week’s decision, it was less clear how the courts would sway.</p>

<p>In this particular case, <a href="https://www.courtlistener.com/docket/69058235/bartz-v-anthropic-pbc/" target="_blank" rel="noreferrer noopener nofollow">Bartz v. Anthropic</a>, the group of plaintiff authors also brought into question the manner in which Anthropic attained and stored their works. According to the lawsuit, Anthropic sought to create a “central library” of “all the books in the world” to keep “forever.” But millions of these copyrighted books were downloaded for free from pirate sites, which is unambiguously illegal.</p>

<p>While the judge granted that Anthropic’s training of these materials was a fair use, the court will hold a trial about the nature of the “central library.”</p>


<p>“We will have a trial on the pirated copies used to create Anthropic’s central library and the resulting damages,” Judge Alsup wrote in the decision. “That Anthropic later bought a copy of a book it earlier stole off the internet will not absolve it of liability for theft but it may affect the extent of statutory damages.”</p>
</div><div>
	
	
	
	

	
<div>
		<p>Amanda Silberling is a senior writer at TechCrunch covering the intersection of technology and culture. She has also written for publications like Polygon, MTV, the Kenyon Review, NPR, and Business Insider. She is the co-host of Wow If True, a podcast about internet culture, with science fiction author Isabel J. Kim. Prior to joining TechCrunch, she worked as a grassroots organizer, museum educator, and film festival coordinator. She holds a B.A. in English from the University of Pennsylvania and served as a Princeton in Asia Fellow in Laos.</p>

<p>Send tips through Signal, an encrypted messaging app, to @amanda.100. For anything else, email amanda@techcrunch.com.</p>	</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/amanda-silberling/" data-event="button" href="https://techcrunch.com/author/amanda-silberling/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatGPT's enterprise success against Copilot fuels OpenAI/Microsoft rivalry (135 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-06-24/chatgpt-vs-copilot-inside-the-openai-and-microsoft-rivalry</link>
            <guid>44367638</guid>
            <pubDate>Tue, 24 Jun 2025 16:02:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-06-24/chatgpt-vs-copilot-inside-the-openai-and-microsoft-rivalry">https://www.bloomberg.com/news/articles/2025-06-24/chatgpt-vs-copilot-inside-the-openai-and-microsoft-rivalry</a>, See on <a href="https://news.ycombinator.com/item?id=44367638">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-06-24/chatgpt-vs-copilot-inside-the-openai-and-microsoft-rivalry: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[XBOW, an autonomous penetration tester, has reached the top spot on HackerOne (140 pts)]]></title>
            <link>https://xbow.com/blog/top-1-how-xbow-did-it/</link>
            <guid>44367548</guid>
            <pubDate>Tue, 24 Jun 2025 15:53:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xbow.com/blog/top-1-how-xbow-did-it/">https://xbow.com/blog/top-1-how-xbow-did-it/</a>, See on <a href="https://news.ycombinator.com/item?id=44367548">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>   <div> <h3> June 24, 2025 </h3> <p> <h3>Nico Waisman</h3> <h4>Head of Security</h4> </p> </div> <hr> <div> <p>For the first time in bug bounty history, an autonomous penetration tester has reached the top spot on the US leaderboard.</p>
<p><img src="https://xbow.com/_astro/top1-image2.I2cpMxV6_Z1CXWXw.webp" alt="" width="738" height="380" loading="lazy" decoding="async"></p>
<p>Our path to reaching the top ranks on HackerOne began with rigorous benchmarking. Since the early days of XBOW, we understood how crucial it was to measure our progress, and we did that in two stages:</p>
<ul>
<li>First we tested XBOW with existing CTF challenges (from well-known providers like PortSwigger and Pentesterlab), then quickly moved on and built our own <a href="https://github.com/xbow-engineering/validation-benchmarks/">unique benchmark</a> that simulates real-world scenarios—ones never used to train LLMs before. The results were encouraging, but still these were artificial exercises.</li>
<li>The logical next step, therefore, was to focus on discovering zero-day vulnerabilities in open source projects, which led to many exciting findings. Some of these were reported on this blog before: in every case, we gave the AI access to source code, simulating a white-box pentest. While our paying customers were enthusiastic about XBOW’s capabilities, the community raised a key question: How would XBOW perform in real, black-box production environments? We took up that challenge, choosing to compete in one of the largest hacker arenas, where companies serve as the ultimate judges by verifying and triaging vulnerabilities themselves.</li>
</ul>
<h3 id="dogfooding-ai-in-bug-bounties">Dogfooding AI in Bug Bounties</h3>
<p>XBOW is a fully autonomous AI-driven penetration tester. It requires no human input, operates much like a human pentester, but can scale rapidly, completing comprehensive penetration tests in just a few hours.</p>
<p>When building AI software, having precise benchmarks to keep pushing the limit of what’s possible, is essential. But when some of those benchmarks evolve into real-world environments, it’s a developer’s dream come true.</p>
<p>Discovering bugs in structured benchmarks and open source projects was a fantastic starting point. However, nothing can truly prepare you for the immense diversity of real-world environments, which span from cutting-edge technologies to 30-year-old legacy systems. No number of design partners can offer that breadth of system variety as that level of unpredictability is nearly impossible to simulate.</p>
<p>To bridge that gap, we started dogfooding XBOW in public and private bug bounty programs hosted on HackerOne. We treated it like any external researcher would: no shortcuts, no internal knowledge—just XBOW, running on its own.</p>
<p>HackerOne offers this unique opportunity, and as XBOW discovered and reported vulnerabilities across multiple programs, we soon found ourselves climbing the H1 ranks.</p>
<h3 id="scaling-discovery-and-scoping-capabilities">Scaling Discovery and Scoping capabilities</h3>
<p>Our first challenge was scaling. While XBOW can easily scan thousands of web apps simultaneously, HackerOne hosts hundreds of thousands of potential targets. As a startup with limited resources, even when we focused on specific vulnerability classes, we still needed to be strategic. That’s why we built infrastructure on top of XBOW to help us identify the high-value targets and prioritize those that would maximize our return on investment.</p>
<p>We started by consuming bug bounty program scopes and policies, but this information isn’t always machine-readable. With a combination of large language models and some manual curation, we managed to parse through them—with a few hiccups. (At one point, we were officially removed from a program that didn’t allow “automatic scanners.”)</p>
<p>With the domains ingested into our database, and a bit of “magic” to expand subdomains, we built a scoring system to highlight the most interesting targets. This scoring criteria covered a broad range of signals, including target appearance, presence of WAFs and other protections, HTTP status codes, redirect behavior, authentication forms, number of reachable endpoints, underlying technologies, and more.</p>
<p>Domain deduplication quickly became essential in large programs, it is common to encounter cloned or staging environments(e.g. stage0001-dev.example.com). Once a vulnerability is found in one, similar issues are likely to exist across others. To stay efficient, we used SimHash to detect content-level similarity and leveraged a headless browser to capture website screenshots and then applied imagehash techniques to assess visual similarity analysis, allowing us to group assets and focus our efforts on unique, high-impact targets.</p>
<h3 id="automated-vulnerability-discovery">Automated Vulnerability Discovery</h3>
<p>AI can be remarkably effective at discovering a broad range of vulnerabilities—but the real challenge isn’t always detection, It’s precision. Automation has long struggled with false positives, and nowhere is this more evident than in vulnerability scanning. Tools that flag dozens of irrelevant issues often create more work than they save. When AI enters the equation, the stakes grow even higher: models can generalize well, but verifying technical edge cases is a different game entirely.</p>
<p>To ensure accuracy, we developed the concept of <strong>validators</strong>, automated peer reviewers that confirm each vulnerability XBOW uncovers. Sometimes this process leverages a large language model; in other cases, we build custom programmatic checks. For example, to validate Cross-Site Scripting findings, a headless browser visits the target site to verify that the JavaScript payload was truly executed.
(don’t miss Brendan Dolan-Gavitt’s BlackHat <a href="https://www.blackhat.com/us-25/briefings/schedule/#ai-agents-for-offsec-with-zero-false-positives-46559">presentation on AI agents for Offsec</a>)</p>
<h3 id="xbows-real-world-impact">XBOW’s Real-World Impact</h3>
<p>Running XBOW across a wide range of public and private programs yielded results that exceeded our expectations—not just in volume, but in consistency and quality.</p>
<p>Over time, XBOW reported thousands of validated vulnerabilities, many of them affecting high-profile targets from well-known companies. These findings weren’t just theoretical; every submission was confirmed by the program owners and triaged as real, actionable security issues.</p>
<p><img src="https://xbow.com/_astro/top1-image1.DV-4rqXc_Z1OfWUq.webp" alt="" width="1338" height="966" loading="lazy" decoding="async"></p>
<p>The most public signal of progress came from the HackerOne leaderboard. Competing alongside thousands of human researchers, XBOW climbed to the top position in the US ranking. That wasn’t our original goal, and indeed was surprising since we didn’t have a buffer of untriaged reports from previous quarters—but it became a useful benchmark to track real-world performance and collect traces to reinforce our models.</p>
<p>XBOW submitted nearly 1,060 vulnerabilities. All findings were fully automated, though our security team reviewed them pre-submission to comply with HackerOne’s policy on automated tools. It was a unique privilege to wake up each morning and review creative new exploits.</p>
<p>To date, bug bounty programs have resolved 130 vulnerabilities, while 303 were classified as Triaged (mostly by VDP programs that acknowledged the issue but did not proceed to resolution). In addition, 33 reports are currently marked as new, and 125 remain pending review by program owners.</p>
<p><img src="https://xbow.com/_astro/top1-image3.DThYJmmV_Z1DRFBF.webp" alt="" width="603" height="500" loading="lazy" decoding="async"></p>
<p>Across all submissions, 208 were marked as duplicates, 209 as informative and 36 as not applicable (most of them self-closed by our team). Interestingly, many of these informative vulnerabilities came from programs with specific constraints such as policies excluding third-party vulnerabilities or disallowing certain classes like Cache Poisoning.</p>
<p>XBOW identified a full spectrum of vulnerabilities including: Remote Code Execution, SQL Injection, XML External Entities (XXE), Path Traversal, Server-Side Request Forgery (SSRF), Cross-Site Scripting, Information DIsclosures, Cache Poisoning, Secret exposure, and more.</p>
<p>Over the past 90 days alone, the vulnerabilities submitted were classified as <strong>54</strong> critical, <strong>242</strong> high, <strong>524</strong> medium, and <strong>65</strong> low severity issues by program owners. Notably, around <strong>45% of</strong> XBOW’s findings are still awaiting resolution, highlighting the volume and impact of the submissions across live targets.</p>
<p><img src="https://xbow.com/_astro/top1-image4.HojM9nHo_1FMAll.webp" alt="" width="603" height="500" loading="lazy" decoding="async"></p>
<p>XBOW’s path to the top involved uncovering a wide range of interesting and impactful vulnerabilities. Among them was a previously unknown vulnerability in Palo Alto’s GlobalProtect VPN solution, affecting over 2,000 hosts. Throughout this process, XBOW consistently demonstrated its ability to adapt to edge cases and develop creative strategies for complex exploitation scenarios entirely on its own.</p>
<p>In the spirit of transparency, and in accordance with the rules and regulations of POC || GTFO, our security team will be publishing a series of blog posts over the coming weeks, showcasing some of our favorite technical discoveries by XBOW.</p>
<p>XBOW is an enterprise solution. If your company would like a demo, email us at <a href="https://xbow.com/cdn-cgi/l/email-protection#01686f676e4179636e762f626e6c"><span data-cfemail="056c6b636a457d676a722b666a68">[email&nbsp;protected]</span></a>.</p> </div> </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing toy software is a joy (479 pts)]]></title>
            <link>https://blog.jsbarretto.com/post/software-is-joy</link>
            <guid>44367084</guid>
            <pubDate>Tue, 24 Jun 2025 15:09:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jsbarretto.com/post/software-is-joy">https://blog.jsbarretto.com/post/software-is-joy</a>, See on <a href="https://news.ycombinator.com/item?id=44367084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <p>Why you should write more toy programs</p>
                <hr>
                
            </div><div>
                <p>I am a huge fan of Richard Feyman’s famous quote:</p>
<blockquote>
<p>“What I cannot create, I do not understand”</p>
</blockquote>
<p>I think it’s brilliant, and it remains true across many fields (if you’re willing to be a little creative with the
definition of ‘create’). It is to this principle that I believe I owe everything I’m truly good at. Some will tell you
to avoid reinventing the wheel, but they’re wrong: you <em>should</em> build your own wheel, because it’ll teach you more about
how they work than reading a thousand books on them ever will.</p>
<p>In 2025, the beauty and craft of writing software is being eroded. AI is threatening to replace us (or, at least, the
most joyful aspects of our craft) and software development is being increasingly commodified, measured, packaged, and
industrialised. Software development needs more simple joy, and I’ve found that creating toy programs is a great way to
remember why I started working with computers again.</p>
<h2>Keep it simple</h2>
<p>Toy programs follow the 80:20 rule: 20% of the work, 80% of the functionality. The point is <em>not</em> to build
production-worthy software (although it is true that some of the best production software began life as a toy).
Aggressively avoid over-engineering, restrict yourself to only whatever code is necessary to achieve your goal. Have
every code path panic/crash until you’re forced to implement it to make progress. You might be surprised by just how
easy it is to build toy versions of software you might previously have considered to be insummountably difficult to
create.</p>
<h2>Other benefits</h2>
<p>I’ve been consistently surprised by just how often some arcane nugget of knowledge I’ve acquired when working on a toy
project has turned out to be immensely valuable in my day job, either by giving me a head-start on tracking down a
problem in a tool or library, or by recognising mistakes before they’re made.</p>
<p>Understanding the constraints that define the shape of software is vital for working with it, and there’s no better way
to gain insight into those constraints than by running into them head-first. You might even come up with some novel
solutions!</p>
<h2>The list</h2>
<p>Here is a list of toy programs I’ve attempted over the past 15 years, rated by difficulty and time required. These
ratings are estimates and assume that you’re already comfortable with at least one general-purpose programming language
and that, like me, you tend to only have an hour or two per day free to write code. Also included are some suggested
resources that I found useful.</p>
<h3>Regex engine (difficulty = 4/10, time = 5 days)</h3>
<p>A regex engine that can read a POSIX-style regex program and recognise strings that match it. Regex is simple yet
shockingly expressive, and writing a competent regex engine will teach you everything you need to know about using the
language too.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Regular_expression#Syntax">Wikipedia: Regex</a></li>
</ul>
<h3>x86 OS kernel (difficulty = 7/10, time = 2 months)</h3>
<p>A multiboot-compatible OS kernel with a simple CLI, keyboard/mouse driver, ANSI escape sequence support, memory manager,
scheduler, etc. Additional challenges include writing an in-memory filesystem, user mode and process isolation, loading
ELF executables, and supporting enough video hardware to render a GUI.</p>
<ul>
<li><a href="https://wiki.osdev.org/">OS Dev Wiki</a></li>
</ul>
<p><a href="https://gitlab.com/zesterer/tupai"><img src="https://gitlab.com/zesterer/tupai/-/raw/master/doc/images/tupai-0-5-0.png" alt="Tupai"></a></p>
<h3>GameBoy/NES emulator (difficulty = 6/10, time = 3 weeks)</h3>
<p>A crude emulator for the simplest GameBoy or NES games. The GB and the NES are classics, and both have relatively simple
instruction sets and peripheral hardware. Additional challenges include writing competent PPU (video) and PSG (audio)
implementations, along with dealing with some of the more exotic cartridge formats.</p>
<ul>
<li><a href="https://gbdev.io/">GB Dev</a></li>
<li><a href="https://www.nesdev.org/wiki/Nesdev_Wiki">NES Dev Wiki</a></li>
</ul>
<h3>GameBoy Advance game (difficulty = 3/10, time = 2 weeks)</h3>
<p>A sprite-based game (top-down or side-on platform). The GBA is a beautiful little console to write code for and there’s
an active and dedicated development community for the console. I truly believe that the GBA is one of the last game
consoles that can be fully and completely understood by a single developer, right down to instruction timings.</p>
<ul>
<li><a href="https://www.coranac.com/tonc/text/toc.htm">Tonc</a></li>
<li><a href="https://problemkaputt.de/gbatek.htm">GBATEK</a></li>
</ul>
<h3>Physics engine (difficulty = 5/10, time = 1 week)</h3>
<p>A 2D rigid body physics engine that implements Newtonian physics with support for rectangles, circles, etc. On the
simplest end, just spheres that push away from one-another is quite simple to implement. Things start to get complex
when you introduce more complex shapes, angular momentum, and the like. Additional challenges include making collision
resolution fast and scaleable, having complex interactions move toward a steady state over time, soft-body interactions,
etc.</p>
<h3>Dynamic interpreter (difficulty = 4/10, time = 1-2 weeks)</h3>
<p>A tree-walking interpreter for a JavaScript-like language with basic flow control. There’s an unbounded list of extra
things to add to this one, but being able to write programs in my own language still gives me child-like elation. It
feels like a sort of techno-genesis: once you’ve got your own language, you can start building the universe within it.</p>
<ul>
<li><a href="https://craftinginterpreters.com/">Crafting Interpreters</a></li>
</ul>
<p><a href="https://github.com/zesterer/forge"><img src="https://blog.jsbarretto.com/img/forge.webp" alt="Forge"></a></p>
<h3>Compiler for a C-like (difficulty = 8/10, time = 3 months)</h3>
<p>A compiler for a simply-typed C-like programming language with support for at least one target archtecture. Extra
challenges include implementing some of the most common optimisations (inlining, const folding, loop-invariant code
motion, etc.) and designing an intermediate representation (IR) that’s general enough to support multiple backends.</p>
<h3>Text editor (difficulty = 5/10, time = 2-4 weeks)</h3>
<p>This one has a lot of variability. At the blunt end, simply reading and writing a file can be done in a few lines of
Python. But building something that’s closer to a daily driver gets more complex. You could choose to implement the UI
using a toolkit like QT or GTK, but I personally favour an editor that works in the console. Properly handling unicode,
syntax highlighting, cursor movement, multi-buffer support, panes/windows, tabs, search/find functionality, LSP support,
etc. can all add between a week or a month to the project. But if you persist, you might join the elite company of those
developers who use an editor of their own creation.</p>
<p><a href="https://github.com/zesterer/zte"><img src="https://github.com/zesterer/zte/raw/master/misc/screenshot.png" alt="ZTE"></a></p>
<h3>Async runtime (difficulty = 6/10, time = 1 week)</h3>
<p>There’s a lot of language-specific variability as to what ‘async’ actually means. In Rust, at least, this means a
library that can ingest <code>impl Future</code> tasks and poll them concurrently until completion. Adding support for I/O waking
makes for a fun challenge.</p>
<h3>Hash map (difficulty = 4/10, time = 3-5 days)</h3>
<p>Hash maps (or sets/dictionaries, as a higher-level language might call them) are a programmer’s bread &amp; butter. And yet,
surprisingly few of us understand how they really work under the bonnet. There are a plethora of techniques to throw
into the mix too: closed or open addressing, tombstones, the robin hood rule, etc. You’ll gain an appreciation for when
and why they’re fast, and also when you should just use a vector + linear search.</p>
<ul>
<li><a href="https://www.sebastiansylvan.com/post/robin-hood-hashing-should-be-your-default-hash-table-implementation/">Robin Hood Hashing should be your default Hash Table implementation</a></li>
</ul>
<h3>Rasteriser / texture-mapper (difficulty = 6/10, time = 2 weeks)</h3>
<p>Most of us have played with simple 3D graphics at some point, but how many of us truly understand how the graphics
pipeline works and, more to the point, how to fix it when it doesn’t work? Writing your own software rasteriser will
give you that knowledge, along with a new-found appreciation for the beauty of vector maths and half-spaces that have
applications across many other fields. Additional complexity involves properly implementing clipping, a Z-buffer, N-gon
rasterisation, perspective-correct texture-mapping, Phong or Gouraud shading, shadow-mapping, etc.</p>
<ul>
<li><a href="https://www.scratchapixel.com/">Scratch-A-Pixel</a></li>
<li><a href="https://github.com/ssloy/tinyrenderer/wiki/Lesson-0:-getting-started">How OpenGL works: software rendering in 500 lines of code</a></li>
</ul>
<p><a href="https://github.com/zesterer/euc"><img src="https://github.com/zesterer/euc/raw/master/misc/example.png" alt="euc"></a></p>
<h3>SDF Rendering (difficulty = 5/10, time = 3 days)</h3>
<p>Signed Distance Fields are a beautifully simple way to render 3D spaces defined through mathematics, and are perfectly
suited to demoscene shaders. With relatively little work you can build yourself a cute little visualisation or some
moving shapes like the graphics demos of the 80s. You’ll also gain an appreciation for shader languages and vector
maths.</p>
<ul>
<li><a href="https://iquilezles.org/articles/distfunctions/">Inigo Quilez’s Site</a></li>
<li><a href="https://www.shadertoy.com/">ShaderToy</a></li>
</ul>
<p><a href="https://www.shadertoy.com/view/ftXBWs"><img src="https://blog.jsbarretto.com/img/sdf-shapes.webp" alt="Signed Distance Fields"></a></p>
<h3>Voxel engine (difficulty = 5/10, time = 2 weeks)</h3>
<p>I doubt there are many reading this that haven’t played Minecraft. It’s surprisingly easy to build your own toy voxel
engine cut from a similar cloth, especially if you’ve got some knowledge of 3D graphics or game development already. The
simplicity of a voxel engine, combined with the near-limitless creativity that can be expressed with them, never ceases
to fill me with joy. Additional complexity can be added by tackling textures, more complex procedural generation,
floodfill lighting, collisions, dynamic fluids, sending voxel data over the network, etc.</p>
<ul>
<li><a href="https://0fps.net/2012/06/30/meshing-in-a-minecraft-game/">0 FPS: Meshing in a Minecraft Game</a></li>
</ul>
<h3>Threaded Virtual Machine (difficulty = 6/10, time = 1 week)</h3>
<p>Writing interpreters is great fun. What’s more fun? <em>Faster interpreters</em>. If you keep pushing interpreters as far as
they can go without doing architecture-specific codegen (like AOT or JIT), you’ll eventually wind up (re)discovering
<em>threaded code</em> (not to be confused with multi-threading, which is a very different beast). It’s a beautiful way of
weaving programs together out highly-optimised miniature programs, and a decent implementation can even give an AOT
compiler a run for its money in the performance department.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Threaded_code">Wikipedia: Threaded code</a></li>
<li><a href="https://muforth.dev/threaded-code/">muforth.dev: Threaded code</a></li>
</ul>
<h3>GUI Toolkit (difficulty = 6/10, time = 2-3 weeks)</h3>
<p>Most of us have probably cobbled together a GUI program using tkinter, GTK, QT, or WinForms. But why not try writing
your GUI toolkit? Additional complexity involves implementing a competent layout engine, good text shaping (inc.
unicode support), accessibility support, and more. Fair warning: do not encourage people to use your tool unless it’s
<em>battle-tested</em> - the world has enough GUIs with little-to-no accessibility or localisation support.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=by9lQvpvMIc">YouTube: How Clay’s UI Algorithm Works</a></li>
</ul>
<p><a href="https://github.com/zesterer/gui"><img src="https://github.com/zesterer/gui/raw/master/misc/example.png" alt="GUI"></a></p>
<h3>Orbital Mechanics Sim (difficulty = 6/10, time = 1 week)</h3>
<p>A simple simulation of Newtonian gravity can be cobbled together in a fairly short time. Infamously, gravitational
systems with more than two bodies cannot be solved analytically, so you’ll have to get familiar with iterative
<em>integration</em> methods. Additional complexity comes with implementing more precise and faster integration methods,
accounting for relativistic effects, and writing a visualiser. If you’ve got the maths right, you can even try plugging
in real numbers from NASA to predict the next high tide or full moon.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Leapfrog_integration">Wikipedia: Leapfrog integration</a></li>
</ul>
<h3>Bitwise Challenge (difficulty = 3/10, time = 2-3 days)</h3>
<p>Here’s one I came up with for myself, but I think it would make for a great game jam: write a game that only persists 64
bits of state between subsequent frames. That’s 64 bits for everything: the entire frame-for-frame game state should be
reproducible using only 64 bits of data. It sounds simple, but it forces you to get incredibly creative with your game
state management. Details about the rules can be found on the GitHub page below.</p>
<ul>
<li><a href="https://github.com/zesterer/the-bitwise-challenge">The Bitwise Challenge</a></li>
</ul>
<p><a href="https://github.com/zesterer/bitwise-examples"><img src="https://blog.jsbarretto.com/img/snake.webp" alt="Snake"></a></p>
<h3>An ECS Framework (difficulty = 4/10, time = 1-2 weeks)</h3>
<p>For all those game devs out there: try building your own <a href="https://en.wikipedia.org/wiki/Entity_component_system">ECS</a>
framework. It’s not as hard as you might think (you might have accidentally done it already!). Extra points if you can
build in safety and correctness features, as well as good integration with your programming language of choice’s type
system features.</p>
<p>I built a custom ECS for my <a href="https://www.youtube.com/watch?v=nS5rj80L-pk">Super Mario 64 on the GBA</a> project due to the
unique performance and memory constraints of the platform, and enjoyed it a lot.</p>
<iframe width="100%" height="600ch" src="https://www.youtube.com/embed/nS5rj80L-pk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
<h3>CHIP-8 Emulator (difficulty = 3/10, time = 3-6 days)</h3>
<p>The <a href="https://en.wikipedia.org/wiki/CHIP-8">CHIP-8</a> is a beautifully simple virtual machine from the 70s. You can write
a fully compliant emulator in a day or two, and there are an enormous plethora of fan-made games that run on it.
<a href="https://github.com/zesterer/emul8/raw/refs/heads/master/test/test.ch8">Here’s</a> a game I made for it.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/CHIP-8">Wikipedia: CHIP-8</a></li>
</ul>
<p><a href="https://github.com/zesterer/emul8"><img src="https://github.com/zesterer/emul8/raw/master/misc/screenshot.png" alt="Emul8"></a></p>
<h3>Chess engine (difficulty = 5/10, time = 2-5 days)</h3>
<p>Writing a chess engine is great fun. You’ll start off with every move it makes being illegal, but over time it’ll get
smart and smarter. Experiencing a loss to your own chess engine really is a rite of passage, and it feels magical.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Minimax">Wikipedia: Minmax</a></li>
<li><a href="https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning">Wikipedia: Alpha-beta pruning</a></li>
</ul>
<p><img src="https://blog.jsbarretto.com/img/chess.webp" alt="Chess"></p>
<h3>POSIX shell (difficulty = 4/10, time = 3-5 days)</h3>
<p>We interact with shells every day, and building one will teach you can incredible amount about POSIX - how it works, and
how it doesn’t. A simple one can be built in a day, but compliance with an existing shell language will take time and
teach you more than you ever wanted to know about its quirks.</p>
<ul>
<li><a href="https://brennan.io/2015/01/16/write-a-shell-in-c/">Write a shell in C</a></li>
</ul>
<p><a href="https://github.com/zesterer/tosh"><img src="https://raw.githubusercontent.com/zesterer/tosh/master/misc/screen0.png" alt="Tosh"></a></p>
<h2>A note on learning and LLMs</h2>
<p>Perhaps you’re a user of LLMs. I get it, they’re neat tools. They’re useful for certain kinds of learning. But I might
suggest resisting the temptation to use them for projects like this. Knowledge is not supposed to be fed to you on a
plate. If you want that sort of learning, read a book - the joy in building toy projects like this comes from an
exploration of the unknown, without polluting one’s mind with an existing solution. If you’ve been using LLMs for a
while, this cold-turkey approach might even be painful at first, but persist. There is no joy without pain.</p>
<p>The runner’s high doesn’t come to those that take the bus.</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nordic Semiconductor Acquires Memfault (101 pts)]]></title>
            <link>https://www.nordicsemi.com/Nordic-news/2025/06/Nordic-Semiconductor-acquires-Memfault</link>
            <guid>44367071</guid>
            <pubDate>Tue, 24 Jun 2025 15:07:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nordicsemi.com/Nordic-news/2025/06/Nordic-Semiconductor-acquires-Memfault">https://www.nordicsemi.com/Nordic-news/2025/06/Nordic-Semiconductor-acquires-Memfault</a>, See on <a href="https://news.ycombinator.com/item?id=44367071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>Nordic Semiconductor, a global leader in low-power wireless connectivity solutions, today announces the acquisition of its long-term partner, Memfault Inc., the market-leading cloud platform provider for large-scale deployments of connected products. This marks a major leap in Nordic’s evolution - from a hardware supplier to a complete solution partner.</p>
<p>Nordic now provides a comprehensive platform that simplifies development and accelerates time-to-market. Throughout the product lifecycle, continuous software upgrades strengthen the security, performance, power consumption, and functionality of products in the field. This allows customers to focus on innovation – free from the burden of navigating fragmented and complex IoT ecosystems.</p>
<h3>Empowering product development through simplicity and scale </h3>
<p>Memfault has established itself as the leading platform provider for device observability and management, and secure over-the-air (OTA) software updates to ensure the highest device reliability without field returns. It is trusted by a growing developer community and customers to monitor, maintain, and scale connected products. Nordic will integrate Memfault’s capabilities across its complete product portfolio and into its existing nRF Cloud services platform, creating a significantly more powerful solution.</p>
            </div><div>
            <h3>Building the future of innovative connected products  </h3>
<p>“This acquisition is a declaration of intent,” said Vegard Wollan, CEO of Nordic Semiconductor. “Together, we enable thousands of customers to continuously interact with millions of devices in the field.”</p>
<p> “We are setting a new standard in the global semiconductor landscape for integrating hardware, software, tools, and services. By combining Nordic’s ultra-low power wireless connectivity solutions with Memfault’s cloud services, we are making it faster, simpler, and more secure to develop, maintain, and improve connected products through their entire lifecycle,” adds Wollan.</p>
<p>“Nordic’s world-class Systems-on-Chip, paired with Memfault’s cloud platform, creates an unmatched full-stack solution for connected products,” said François Baldassari, CEO of Memfault. “Our shared goal is simple: Free our customers and engineers to innovate while the platform guarantees reliability and insights for millions of products in the field.”</p>
<h3>Strengthening Nordic’s edge AI and security solutions </h3>
<p>This acquisition further strengthens Nordic Semiconductor’s leadership position in addressing current and future market demands. As IoT nodes become increasingly intelligent through edge AI, and as security standards evolve under frameworks such as the EU Cyber Resilience Act, Nordic's software and cloud services will equip product developers with comprehensive tools to stay ahead of industry and regulatory expectations.</p>
<h3>Commitment to continuity and customer trust </h3>
<p>Nordic and Memfault share a broad base of mutual customers and common markets. Nordic is committed to supporting every IoT device maker – including all existing Memfault customers – regardless of their choice of hardware. The Memfault platform will continue to thrive, with further enhancements and investments in hardware integration, device management, and advanced AI capabilities.</p>
<p>This acquisition underscores Nordic’s commitment to an exceptional customer experience. Nordic’s new software services will remove complexity and add value for thousands of customers who can now focus on product innovation.  This solution will reduce time-to-market, lower operational costs, and enable our customers to manage their connected products effectively across the entire lifecycle.</p>
<p>For further information, interested parties are encouraged to contact their local Nordic sales representative.&nbsp;</p>


<p><strong>Press contact:&nbsp;</strong><br>
Nordic Semiconductor&nbsp;<br>
Anne Gustavsson&nbsp;<br>
Phone: +47 971 63 752&nbsp;<br>
E-mail: <a href="https://www.nordicsemi.com/cdn-cgi/l/email-protection" data-cfemail="6b0a05050e450c1e181f0a1d181804052b0504190f0208180e0602450504">[email&nbsp;protected]</a></p>


            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PlasticList – Plastic Levels in Foods (276 pts)]]></title>
            <link>https://www.plasticlist.org/</link>
            <guid>44366548</guid>
            <pubDate>Tue, 24 Jun 2025 14:18:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.plasticlist.org/">https://www.plasticlist.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44366548">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Bitter Lesson is coming for Tokenization (195 pts)]]></title>
            <link>https://lucalp.dev/bitter-lesson-tokenization-and-blt/</link>
            <guid>44366494</guid>
            <pubDate>Tue, 24 Jun 2025 14:14:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lucalp.dev/bitter-lesson-tokenization-and-blt/">https://lucalp.dev/bitter-lesson-tokenization-and-blt/</a>, See on <a href="https://news.ycombinator.com/item?id=44366494">Hacker News</a></p>
Couldn't get https://lucalp.dev/bitter-lesson-tokenization-and-blt/: Error: getaddrinfo ENOTFOUND lucalp.dev]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini Robotics On-Device brings AI to local robotic devices (153 pts)]]></title>
            <link>https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/</link>
            <guid>44366409</guid>
            <pubDate>Tue, 24 Jun 2025 14:05:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/">https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/</a>, See on <a href="https://news.ycombinator.com/item?id=44366409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      
  <article>
    
    
  
  
  
    
      

      
      
        
          
            <div>
              
                
                
                  
                  
<div>
    <div>
      <p>Models</p>
      

      
    <dl>
      
        <dt>Published</dt>
        <dd><time datetime="2025-06-24">24 June 2025</time></dd>
      
      
        <dt>Authors</dt>
        
      
    </dl>
  

      
    </div>

    
      
    
    
    <picture>
      <source media="(min-width: 1024px)" type="image/webp" width="1072" height="603" srcset="https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1072-h603-n-nu-rw 1x, https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w2144-h1206-n-nu-rw 2x"><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w928-h522-n-nu-rw 1x, https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1856-h1044-n-nu-rw 2x"><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w528-h297-n-nu-rw 1x, https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1056-h594-n-nu-rw 2x">
      <img alt="Collage of imagery demonstrating Gemini Robotics On-Device. A central abstract image of a toy busy box shaped like a human head alludes to neural functions and problem-solving." height="603" src="https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1072-h603-n-nu" width="1072">
    </picture>
    
  
    
  </div>
                
              
                
                
                  
                  <div>
  <h4 data-block-key="fslsq">We’re introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.</h4><p data-block-key="cj9eq">In March, we introduced <a href="https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/" rel="noopener" target="_blank">Gemini Robotics</a>, our most advanced VLA (vision language action) model, bringing Gemini 2.0’s multimodal reasoning and real-world understanding into the physical world.</p><p data-block-key="ecdhr">Today, we’re introducing Gemini Robotics On-Device, our most powerful VLA model optimized to run locally on robotic devices. Gemini Robotics On-Device shows strong general-purpose dexterity and task generalization, and it’s optimized to run efficiently on the robot itself.</p><p data-block-key="bv9r5">Since the model operates independent of a data network, it’s helpful for latency sensitive applications, and ensures robustness in environments with intermittent or zero connectivity.</p><p data-block-key="954qn">We’re also sharing a <a href="https://github.com/google-deepmind/gemini-robotics-sdk" rel="noopener" target="_blank">Gemini Robotics SDK</a> to help developers easily evaluate Gemini Robotics On-Device on their tasks and environments, test our model in our <a href="https://github.com/google-deepmind/aloha_sim" rel="noopener" target="_blank">MuJoCo</a> physics simulator, and quickly adapt it to new domains, with as few as 50 to 100 demonstrations. Developers can access the SDK by signing up to our trusted tester program.</p><h2 data-block-key="s070">Model capabilities and performance</h2><p data-block-key="2f1eg">Gemini Robotics On-Device is a robotics foundation model for bi-arm robots, engineered to require minimal computational resources. It builds on the task generalization and dexterity capabilities of Gemini Robotics and is:</p><ul><li data-block-key="6usj8">Designed for rapid experimentation with dexterous manipulation.</li><li data-block-key="52so1">Adaptable to new tasks through fine-tuning to improve performance.</li><li data-block-key="cpmu">Optimized to run locally with low-latency inference.</li></ul><p data-block-key="6034e">Gemini Robotics On-Device achieves strong visual, semantic and behavioral generalization across a wide range of testing scenarios, follows natural language instructions, and completes highly-dexterous tasks like unzipping bags or folding clothes — all while operating directly on the robot.</p>
</div>
                
              
                
                
                  
                  





<figure>
  

  
</figure>
                
              
                
                
                  
                  <p data-block-key="fje3d">In our evaluations, our On-Device mode exhibits strong generalization performance while running entirely locally.</p>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-456f78ab-7f92-4940-985f-1d15556c9775">
  

  <figcaption>
      <p data-block-key="qu0k9">Chart evaluating Gemini Robotics On-Device’s generalization performance, compared to our flagship Gemini Robotics model and the previous best on-device model.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <p data-block-key="bfdk2">Gemini Robotics On-Device also outperforms other on-device alternatives on more challenging out-of-distribution tasks and complex multi-step instructions. For developers seeking state-of-the-art results in these settings, without on-device limitations, we also offer the Gemini Robotics model.</p>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-52dcd6d1-0509-4a0f-ba66-7a7ca7de6c1a">
  

  <figcaption>
      <p data-block-key="qu0k9">Chart evaluating Gemini Robotics On-Device’s instruction following performance, compared to our flagship Gemini Robotics model and the previous best on-device model.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="bfdk2">To learn more about our evaluations, read our <a href="https://arxiv.org/pdf/2503.20020" rel="noopener" target="_blank">Gemini Robotics tech report</a>.</p>
</div>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="bfdk2">Adaptable to new tasks, generalizable across embodiments</h2><p data-block-key="bdslo">Gemini Robotics On-Device is the first VLA model we're making available for fine-tuning. While many tasks will work out of the box, developers can also choose to adapt the model to achieve better performance for their applications. Our model quickly adapts to new tasks, with as few as 50 to 100 demonstrations — indicating how well this on-device model can generalize its foundational knowledge to new tasks.</p><p data-block-key="bvcef">Here, we show how Gemini Robotics On-Device outperforms the current, best on-device VLA on tasks involving fine-tuning to newer models. We tested the model on seven dexterous manipulation tasks of varying degrees of difficulty, including zipping a lunch-box, drawing a card and pouring salad dressing.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-bea01efa-d837-4abb-9e3a-98a583f023de">
  

  <figcaption>
      <p data-block-key="qu0k9">Chart showing Gemini Robotics On-Device’s task adaptation performance, with fewer than 100 examples.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="bfdk2">We further adapted the Gemini Robotics On-Device model to different robot embodiments. While we trained our model only for <a href="https://aloha-2.github.io/" rel="noopener" target="_blank">ALOHA robots</a>, we were able to further adapt it to a bi-arm <a href="https://franka.de/franka-research-3" rel="noopener" target="_blank">Franka FR3 robot</a> and the <a href="https://apptronik.com/apollo" rel="noopener" target="_blank">Apollo humanoid robot</a> by Apptronik.</p><p data-block-key="ft9gu">On the bi-arm Franka, the model performs general-purpose instruction following, including handling previously unseen objects and scenes, completing dexterous tasks like folding a dress, or executing <a href="https://www.nist.gov/el/intelligent-systems-division-73500/robotic-grasping-and-manipulation-assembly/assembly" rel="noopener" target="_blank">industrial belt assembly tasks</a> that require precision and dexterity.</p>
</div>
                
              
                
                
                  
                  





<figure>
  

  
</figure>
                
              
                
                
                  
                  <p data-block-key="bfdk2">On the Apollo humanoid, we adapt the model to a significantly different embodiment. The same generalist model can follow natural language instructions and manipulate different objects, including previously unseen objects, in a general manner.</p>
                
              
                
                
                  
                  





<figure>
  

  
</figure>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="bfdk2">Responsible development and safety</h2><p data-block-key="659ds">We’re developing all Gemini Robotics models in alignment with our <a href="https://ai.google/principles/" rel="noopener" target="_blank">AI Principles</a> and applying a <a href="https://sites.google.com/corp/view/safe-robots" rel="noopener" target="_blank">holistic safety approach</a> spanning semantic and physical safety.</p><p data-block-key="735t">In practice, we capture semantic and content safety using the <a href="https://ai.google.dev/gemini-api/docs/live" rel="noopener" target="_blank">Live API</a>, and interface our models with low-level safety critical controllers to execute the actions. We recommend evaluating the end-to-end system on our recently developed <a href="https://asimov-benchmark.github.io/" rel="noopener" target="_blank">semantic safety benchmark</a> and performing <a href="https://predictive-red-team.github.io/" rel="noopener" target="_blank">red-teaming exercises</a> at all levels to expose the model’s safety vulnerabilities.</p><p data-block-key="61g0f">Our Responsible Development &amp; Innovation (ReDI) team continues to analyze and advise on the real-world impact of all Gemini Robotics models, finding ways to maximize their societal impact and minimize risk. Then our Responsibility &amp; Safety Council (RSC) reviews these assessments, providing feedback to integrate into model development to help further maximize benefits and minimize risk.</p><p data-block-key="3v220">To gain a deeper understanding of Gemini Robotics On-Device’s usage and safety profile and to gather feedback, we’re initially releasing it to a select group of trusted testers.</p><h2 data-block-key="7efg8">Accelerating innovation in robotics</h2><p data-block-key="6r8fc">Gemini Robotics On-Device marks a step forward in making powerful robotics models more accessible and adaptable — and our on-device solution will help the robotics community tackle important latency and connectivity challenges.</p><p data-block-key="abc0t">The Gemini Robotics SDK will further accelerate innovation by allowing developers to adapt the model to their specific needs. Sign up for model and SDK access via our <a href="https://docs.google.com/forms/d/1sM5GqcVMWv-KmKY3TOMpVtQ-lDFeAftQ-d9xQn92jCE/edit?ts=67cef986" rel="noopener" target="_blank">trusted tester program</a>.</p><p data-block-key="4erv7">We’re excited to see what the robotics community will build with these new tools as we continue to explore the future of bringing AI into the physical world.</p>
</div>
                
              
                
                
                  
                  

<section>
  

  <ul>
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://docs.google.com/forms/d/1sM5GqcVMWv-KmKY3TOMpVtQ-lDFeAftQ-d9xQn92jCE/edit?ts=67cef986" rel="noopener" target="_blank">
      <span>Sign up for our trusted tester program</span>
      
    </a>
            </gemini-button>
        </li>
        
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://arxiv.org/pdf/2503.20020" rel="noopener" target="_blank">
      <span>Read the Gemini Robotics tech report</span>
      
    </a>
            </gemini-button>
        </li>
        
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://github.com/google-deepmind/aloha_sim" rel="noopener" target="_blank">
      <span>Test ALOHA robots in simulation</span>
      
    </a>
            </gemini-button>
        </li>
        
    
  </ul>
</section>
                
              
                
                
                  
                  <div>
      <p data-block-key="nfym9"><strong>Acknowledgements</strong></p><p data-block-key="eg2vo">We gratefully acknowledge contributions, advice, and support from Abbas Abdolmaleki, Saminda Abeyruwan, Joshua Ainslie, Jean-Baptiste Alayrac, Montserrat Gonzalez Arenas, Travis Armstrong, Maria Attarian, Ashwin Balakrishna, Yanan Bao, Clara Barbu, Catarina Barros, Robert Baruch, Nathan Batchelor, Maria Bauza, Lucas Beyer, Michael Bloesch, Michiel Blokzijl, Steven Bohez, Konstantinos Bousmalis, Demetra Brady, Philemon Brakel, Anthony Brohan, Thomas Buschmann, Arunkumar Byravan, Kendra Byrne, Serkan Cabi, Ken Caluwaerts, Federico Casarini, Christine Chan, Oscar Chang, Jose Enrique Chen, Xi Chen, Huizhong Chen, Hao-Tien Lewis Chiang, Krzysztof Choromanski, Adrian Collister, Kieran Connell, David D'Ambrosio, Sudeep Dasari, Todor Davchev, Coline Devin, Norman Di Palo, Tianli Ding, Adil Dostmohamed, Anca Dragan, Yilun Du, Debidatta Dwibedi, Michael Elabd, Tom Erez, Claudio Fantacci, Cody Fong, Erik Frey, Chuyuan Fu, Frankie Garcia, Ashley Gibb, Marissa Giustina, Keerthana Gopalakrishnan, Laura Graesser, Simon Green, Oliver Groth, Roland Hafner, Leonard Hasenclever, Sam Haves, Nicolas Heess, Brandon Hernaez, Tim Hertweck, Alexander Herzog, R. Alex Hofer, Sandy H Huang, Jan Humplik , Atil Iscen, Mithun George Jacob, Deepali Jain, Sally Jesmonth, Ryan Julian, Dmitry Kalashnikov, M. Emre Karagozler, Stefani Karp, Chase Kew, Jerad Kirkland, Sean Kirmani, Yuheng Kuang, Thomas Lampe, Antoine Laurens, Isabel Leal, Alex X. Lee, Tsang-Wei Edward Lee, Jennie Lees, Jacky Liang, Yixin Lin, Li-Heng Lin, Caden Lu, Sharath Maddineni, Anirudha Majumdar, Kevis-Kokitsi Maninis, Siobhan Mcloughlin, Assaf Hurwitz Michaely, Joss Moore, Robert Moreno, Thomas Mulc, Michael Neunert, Francesco Nori, Dave Orr, Carolina Parada, Emilio Parisotto, Peter Pastor, André Susano Pinto, Acorn Pooley, Grace Popple, Thomas Power, Alessio Quaglino, Haroon Qureshi, Kanishka Rao, Dushyant Rao, Krista Reymann, Martin Riedmiller, Francesco Romano, Keran Rong, Dorsa Sadigh, Stefano Saliceti, Daniel Salz, Pannag Sanketi, Mili Sanwalka, Kevin Sayed, Pierre Sermanet, Dhruv Shah, Mohit Sharma, Kathryn Shea, Mohit Shridhar, Charles Shu, Vikas Sindhwani, Sumeet Singh, Radu Soricut, Andreas Steiner, Rachel Sterneck, Ian Storz, Razvan Surdulescu, Ben Swanson, Mitri Syriani, Jie Tan, Yuval Tassa, Alan Thompson, Dhruva Tirumala, Jonathan Tompson, Karen Truong, Jake Varley, Siddharth Verma, Grace Vesom, Giulia Vezzani, Oriol Vinyals, Ayzaan Wahid, Zhicheng Wang, Stefan Welker, Paul Wohlhart, Chengda Wu, Markus Wulfmeier, Fei Xia, Ted Xiao, Annie Xie, Jinyu Xie, Peng Xu, Sichun Xu, Ying Xu, Zhuo Xu, Yuxiang Yang, Rui Yao, Sergey Yaroshenko, Matt Young, Wenhao Yu, Wentao Yuan, Martina Zambelli, Xiaohua Zhai, Jingwei Zhang, Tingnan Zhang, Allan Zhou, Yuxiang Zhou, Guangyao (Stannis) Zhou, Howard Zhou.</p><p data-block-key="416qn">We also thank the operations and support staff that performed data collection and robot evaluations for this project.</p>
    </div>
                
              
            </div>
          
        
      

      
    
  
  

  

  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finding a 27-year-old easter egg in the Power Mac G3 ROM (298 pts)]]></title>
            <link>https://www.downtowndougbrown.com/2025/06/finding-a-27-year-old-easter-egg-in-the-power-mac-g3-rom/</link>
            <guid>44365806</guid>
            <pubDate>Tue, 24 Jun 2025 13:06:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.downtowndougbrown.com/2025/06/finding-a-27-year-old-easter-egg-in-the-power-mac-g3-rom/">https://www.downtowndougbrown.com/2025/06/finding-a-27-year-old-easter-egg-in-the-power-mac-g3-rom/</a>, See on <a href="https://news.ycombinator.com/item?id=44365806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>I was recently poking around inside the original Power Macintosh G3’s ROM and accidentally discovered an easter egg that nobody has documented until now.</p>



<p>This story starts with me on a lazy Sunday using <a href="https://hexfiend.com/" target="_blank" rel="noreferrer noopener">Hex Fiend</a> in conjunction with <a href="https://github.com/eharmon/rom_fiend" target="_blank" rel="noreferrer noopener">Eric Harmon’s Mac ROM template (ROM Fiend)</a> to look through the resources stored in the Power Mac G3’s ROM. This ROM was used in the beige desktop, minitower, and all-in-one G3 models from 1997 through 1999.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-12.png" target="_blank" rel=" noreferrer noopener"><img fetchpriority="high" decoding="async" width="487" height="466" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-12.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-12.png 487w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-12-300x287.png 300w" sizes="(max-width: 487px) 100vw, 487px"></a></figure>



<p>As I write this post in mid-2025, I’m having a really difficult time accepting the fact that the Power Mac G3 is now over 27 years old. Wow!</p>



<p>While I was browsing through the ROM, two things caught my eye:</p>



<p>First, there was a resource of type <code>HPOE</code> which contained a JPEG image of a bunch of people, presumably people who worked on these Mac models.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/G3Picture.jpg" target="_blank" rel=" noreferrer noopener"><img decoding="async" width="640" height="480" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/G3Picture.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/G3Picture.jpg 640w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/G3Picture-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></a></figure>



<p>This wasn’t anything new; <a href="https://www.journaldulapin.com/2014/08/19/easter-egg-les-images-cachees-dans-les-roms/" target="_blank" rel="noreferrer noopener">Pierre Dandumont wrote about it back in 2014</a>. However, in his post, he mentioned that he hadn’t figured out how to display this particular hidden image on the actual machine. Several older Macs have secret keypress combinations to show similar pictures, but the mechanism for displaying this one was a complete mystery.</p>



<p>The second thing I found was a big clue: I kept looking for other interesting information in the ROM, and eventually I stumbled upon <code>nitt</code> resource ID 43, named “Native 4.3”. Thanks to <a href="https://blitter.net/blog/2021/02/09/pippin-kickstart-1-1/" target="_blank" rel="noreferrer noopener">Keith Kaisershot’s earlier Pippin research</a>, I was quickly able to conclude that this was the PowerPC-native SCSI Manager 4.3 code. The SCSI Manager wasn’t what piqued my interest about this resource though. At the very end of the data, I found some interesting Pascal strings:</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-1.png" target="_blank" rel=" noreferrer noopener"><img decoding="async" width="460" height="104" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-1.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-1.png 460w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-1-300x68.png 300w" sizes="(max-width: 460px) 100vw, 460px"></a></figure>



<p>These strings were definitely intriguing:</p>



<ul>
<li>.Edisk</li>



<li>secret ROM image</li>



<li>The Team</li>
</ul>



<p>The “secret ROM image” text in particular seemed like it could be related to the picture shown above. I decided to dive deeper to see if I could figure out why the SCSI Manager contained these strings, in the hopes that I could solve the mystery. Would this be the clue I needed in order to figure out how to instruct the Power Mac G3 to display this picture?</p>



<p>Some quick Internet searching for the phrase “secret ROM image” revealed that <a href="https://www.mackido.com/EasterEggs/HW-PCIROM.html" target="_blank" rel="noreferrer noopener">it had been used for easter eggs with earlier PowerPC Macs</a>. On those machines, you just had to type the text, select it, and drag it to the desktop. Then, the picture would appear. That approach didn’t work on the G3.</p>



<p>I suspected there was some similar way to access this hidden image, but nobody had documented it, at least not as far as I could find. So I had no choice but to disassemble the code and see where this text was used. What is it with me and all these crazy rabbit holes?</p>



<p>I extracted the entire <code>nitt</code> resource ID 43 to a file and inspected it:</p>



<pre>$ file nitt43<br>nitt43: header for PowerPC PEF executable</pre>



<p>That wasn’t too surprising, considering that the first twelve bytes were “Joy!peffpwpc”. I fed this entire file into <a href="https://github.com/NationalSecurityAgency/ghidra" target="_blank" rel="noreferrer noopener">Ghidra</a>, which immediately recognized it as a PEF file and had no trouble loading it. Although I’m pretty familiar with reading x86 and ARM assembly, I know essentially nothing about PowerPC assembly code. Thankfully, Ghidra’s decompiler worked very well with this file.</p>



<p>There was one problem, though: it didn’t detect any references to the “secret ROM image” string, other than inside of a huge list of pointers to variables. After scratching my head a little bit, I realized that Ghidra wasn’t doing a great job of finding references to several variables. Luckily, running Auto Analyze a second time after the initial analysis seemed to help it find several more references to things, including all of the strings I was interested in! I didn’t change any options with the analyzer; it just found more stuff on the second run.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-2.png" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="765" height="317" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-2.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-2.png 765w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-2-300x124.png 300w" sizes="auto, (max-width: 765px) 100vw, 765px"></a></figure>



<p>The function that used all of these strings was definitely doing something with the .EDisk driver, which I already knew was the RAM disk driver because of past hackery. It seemed to be using <code>strncmp()</code> to see if a string was equal to “secret ROM image”, and if so, it would create/open/write a file named “The Team”.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-3.png" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="704" height="816" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-3.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-3.png 704w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-3-259x300.png 259w" sizes="auto, (max-width: 704px) 100vw, 704px"></a></figure>



<p>I cleaned up this decompilation quite a bit by giving names to variables and figuring out data types. Fortunately, a lot of the functions like <code>PBGetVInfoSync()</code> had lots of public documentation, so I just had to tell Ghidra about the various Mac Toolbox structs being used.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-4.png" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="661" height="831" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-4.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-4.png 661w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-4-239x300.png 239w" sizes="auto, (max-width: 661px) 100vw, 661px"></a></figure>



<p>Okay, that’s a lot easier to understand!</p>



<p>I couldn’t figure out how to format the 32-bit function arguments such as 0x48504f45 into four-letter codes like <code>HPOE</code>, so that’s what the comments are. Ghidra simply wouldn’t let me display them as ASCII in the decompilation no matter what I did, even though hovering over the constant showed a tooltip with the equivalent text. This is easy to do in IDA, but I couldn’t figure out how to convince Ghidra to do it. I tried Set Equate, but it didn’t change anything. If someone knows how to make it work, I’d love to hear how!</p>



<p>Anyway, the decompiled code shown above makes sense, and here’s a summary of what it does:</p>



<ul>
<li>It looks for a driver called .Edisk. (The driver is really named .EDisk, but I guess Mac OS doesn’t care about case sensitivity for this.)</li>



<li>It finds a disk associated with that driver (the RAM disk).</li>



<li>It looks for a volume associated with that disk.</li>



<li>If the volume is named “secret ROM image”:
<ul>
<li>It loads <code>HPOE</code> resource ID 1, which contains the JPEG image data.</li>



<li>It creates a file of creator <code>ttxt</code> and type <code>JPEG</code> called “The Team”.</li>



<li>It opens the file, writes the JPEG data to it, and closes it.</li>



<li>Then it does something with the driver control entry that I didn’t bother trying to understand further.</li>
</ul>
</li>
</ul>



<p>Okay, interesting! So this code was clearly looking for the RAM disk to be named “secret ROM image”, but I wasn’t sure exactly how to trigger it. This function was only ever called in one other place: another function, which was checking to see if its first argument was equal to the value 0x3DA (decimal 986).</p>



<p>I didn’t have my beige G3 handy for tinkering, so instead, I mentioned what I had discovered in #mac68k on Libera. <a href="https://infosec.exchange/@atax1a/114729277160021527" target="_blank" rel="noreferrer noopener">^alex came to the rescue</a> after playing around in Infinite Mac with the hints I had given. They quickly figured out that the trick was to format the RAM disk, and type the special text into the format dialog:</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-5.png" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="640" height="480" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-5.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-5.png 640w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-5-300x225.png 300w" sizes="auto, (max-width: 640px) 100vw, 640px"></a></figure>



<p>I got out my desktop G3, tested it out on real hardware, and sure enough, it worked! If you want to try it for yourself just like ^alex did, you can <a href="https://infinitemac.org/1998/Mac%20OS%208.1?infinite_hd=false&amp;saved_hd=false&amp;machine=Power+Macintosh+G3+%28Beige%29" target="_blank" rel="noreferrer noopener">run Infinite Mac in your browser using this link, which sets up an emulated beige G3 running Mac OS 8.1</a> using DingusPPC. There’s a quirk that causes it to fail to resolve an alias at startup. I intentionally disabled it; just click Stop when the error pops up. Here are instructions:</p>



<ul>
<li>Enable the RAM Disk in the Memory control panel.</li>



<li>Choose Restart from the Special menu.</li>



<li>After the desktop comes back up, select the RAM Disk icon.</li>



<li>Choose Erase Disk from the Special menu.</li>



<li>Type the <em>secret ROM image</em> text exactly as depicted above.</li>



<li>Click Erase.</li>
</ul>



<p>When you open the newly-formatted RAM disk, you should see a file named “The Team”:</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-6.png" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="640" height="480" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-6.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-6.png 640w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-6-300x225.png 300w" sizes="auto, (max-width: 640px) 100vw, 640px"></a></figure>



<p>If you double-click the file, SimpleText will open it:</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-8.png" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="640" height="480" src="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-8.png" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-8.png 640w, https://www.downtowndougbrown.com/wp-content/uploads/2025/06/image-8-300x225.png 300w" sizes="auto, (max-width: 640px) 100vw, 640px"></a></figure>



<p>Based on various people’s tests, including my own, it sounds like <a href="https://bsky.app/profile/eaglebtc.bsky.social/post/3lsaz3jqsds2w" target="_blank" rel="noreferrer noopener">this trick works all the way up through Mac OS 9.0.4</a>, but 9.1 may have been the first version where it finally stopped working.</p>



<p>As far as I have been able to determine, this particular secret was undiscovered until now. People definitely knew the image was there in the ROM, but nobody had figured out how to actually activate it. This is probably one of the last easter eggs that existed in the Mac prior to <a href="https://gizmodo.com/the-easter-eggs-are-back-in-os-x-and-this-one-is-insane-5929286" target="_blank" rel="noreferrer noopener">Steve Jobs reportedly banning them in 1997 when he returned to Apple</a>. I wonder if he ever knew about this one?</p>



<p>Special thanks to ^alex for figuring out that the RAM Disk needed to be erased in order to activate the easter egg! I’m not sure I would have thought to try that, and it would have taken a lot more work to trace through the rest of the code to figure it out.</p>



<p>If you are reading this post and you were on “The Team”, I’d love to hear about it! I’m curious if anyone who worked at Apple in the era remembers this little secret.</p>
			  
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Basic Facts about GPUs (229 pts)]]></title>
            <link>https://damek.github.io/random/basic-facts-about-gpus/</link>
            <guid>44365320</guid>
            <pubDate>Tue, 24 Jun 2025 12:15:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://damek.github.io/random/basic-facts-about-gpus/">https://damek.github.io/random/basic-facts-about-gpus/</a>, See on <a href="https://news.ycombinator.com/item?id=44365320">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

      



<p>
  last updated:
  <time>2025-06-18</time>
</p>


<p>I’ve been trying to get a better sense of how GPUs work. I’ve read a lot online, but the following posts were particularly helpful:</p>
<ol>
  <li><a href="https://horace.io/brrr_intro.html" target="_blank">Making Deep Learning Go Brrrr From First Principles</a></li>
  <li><a href="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications" target="_blank">What Shapes Do Matrix Multiplications Like?</a></li>
  <li><a href="https://siboehm.com/articles/22/CUDA-MMM" target="_blank">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</a></li>
</ol>

<p>This post collects various facts I learned from these resources.</p>

<p>Acknowledgements: Thanks to <a href="https://afmck.in/" target="_blank">Alex McKinney</a> for comments on <a href="https://docs.nvidia.com/cuda/ampere-compatibility-guide/#independent-thread-scheduling-compatibility" target="_blank">independent thread scheduling</a>.</p>

<p><strong>Table of Contents</strong></p>

<ul>
  <li><a href="#compute-and-memory-hierarchy">Compute and memory hierarchy</a></li>
  <li><a href="#the-two-performance-regimes">Two Performance Regimes: Memory-Bound and Compute-Bound</a></li>
  <li><a href="#the-third-regime-overhead">The Third Regime: Overhead</a></li>
  <li><a href="#two-basic-strategies-for-increasing-performance-fusion-and-tiling">Two basic strategies for increasing performance: Fusion and Tiling</a>
    <ul>
      <li><a href="#operator-fusion">Operator Fusion</a></li>
      <li><a href="#tiling-strategy-for-compute-bound-kernels">Tiling: Strategy for Compute-Bound Kernels</a>
        <ul>
          <li><a href="#the-coalesced-load-hbm-to-sram">The Coalesced Load: HBM to SRAM</a></li>
          <li><a href="#synchronization">Synchronization</a></li>
          <li><a href="#the-on-chip-hardware-banks-and-warps">The On-Chip Hardware: Banks and Warps</a></li>
          <li><a href="#the-bank-conflict-problem">The Bank Conflict Problem</a></li>
          <li><a href="#the-on-chip-compute-phase-increasing-arithmetic-intensity">The On-Chip Compute Phase: Increasing Arithmetic Intensity</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#additional-performance-considerations">Additional Performance Considerations</a>
    <ul>
      <li><a href="#occupancy-and-latency-hiding">Occupancy and Latency Hiding</a></li>
      <li><a href="#avoiding-thread-divergence">Avoiding Thread Divergence</a></li>
      <li><a href="#quantization">Quantization</a></li>
    </ul>
  </li>
</ul>

<h2 id="compute-and-memory-hierarchy">Compute and memory hierarchy</h2>

<p>A GPU’s design creates an imbalance since it can compute much faster than it can access its main memory. An NVIDIA A100 GPU, for example, can perform 19.5 trillion 32-bit floating-point operations per second (TFLOPS), but its memory bandwidth is only about 1.5 terabytes per second (TB/s). In the time it takes to read a single 4-byte number, the GPU could have performed over 50 calculations.</p>

<p>Below is a diagram of the compute and memory hierarchy for an NVIDIA A100 GPU. The numbers I quote for flops/s and TB/s are exclusive to A100s.</p>

<div><pre><code>+---------------------------------------------------------------------------------+
|                               Global Memory (VRAM)                              |
|                            (~40 GB, ~1.5 TB/s on A100)                          |
+----------------------------------------+----------------------------------------+
                                         | (Slow off-chip bus)
+----------------------------------------v----------------------------------------+
|                            Streaming Multiprocessor (SM)                        |
|                     (1 of 108 SMs on an A100, each ~(19.5/108) TFLOPS)          |
|                           (2048 threads, 64 warps, 32 blocks)                   |
| +-----------------------------------------------------------------------------+ |
| |                        Shared Memory (SRAM) / L1 Cache                        |
| |                    (~192 KB on-chip workbench, 19.5 TB/s)                     |
| +-----------------------------------------------------------------------------+ |
| |                        Register File (~256 KB, ? TB/s)                        |
| +-----------------------------------------------------------------------------+ |
| |                                                                             | |
| |                //-- A "Block" of threads runs on one SM --//                | |
| | +--------------------------+ +------------------------+                     | |
| | |      Warp 0 (32 thr)     | |      Warp 1 (32 thr)   | ... (up to 32 warps)| |
| | | +----------------------+ | +----------------------+ |                     | |
| | | | Thread 0 Registers   | | | Thread 32 Registers  | |                     | |
| | | | [reg0: float]        | | | [reg0: float]        | |                     | |
| | | | [reg1: float] ...    | | | [reg1: float] ...    | |                     | |
| | | +----------------------+ | +----------------------+ |                     | |
| | +--------------------------+ +------------------------+                     | |
| |                                                                             | |
+---------------------------------------------------------------------------------+
</code></pre></div>

<p>This diagram shows the performance hierarchy.<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" rel="footnote">1</a></sup> <strong>Global Memory (VRAM)</strong> is the large, slow, off-chip memory pool where all data initially lives. A <strong>Streaming Multiprocessor (SM)</strong> is the GPU’s unit of computation. To work, it must fetch data over the slow bus. To mitigate this, each SM has fast, on-chip <strong>Shared Memory</strong> (SRAM) with a bandwidth of 19.5 TB/s.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">2</a></sup> Programmers use this as a manually-managed cache.</p>

<p>A <strong>thread</strong> is the smallest unit of execution. Each thread has a private set of <strong>Registers</strong> to hold values for immediate computation, with access speeds over ?? TB/s.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">3</a></sup> The hardware groups threads into <strong>Warps</strong> of 32. This post analyzes performance using the simplified model of <strong>lockstep execution</strong>, where all 32 threads in a warp execute the same instruction at the same time.<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" rel="footnote">4</a></sup> On an A100, an SM has an upper limit of 64 warps. A programmer groups threads into a <strong>Block</strong>, a grid of threads that is guaranteed to run on a single SM. A block can be one, two, or three-dimensional. For simplicity, this post will focus on square two-dimensional blocks of <code>BLOCK_DIM x BLOCK_DIM</code> threads, where the total number of threads cannot exceed the hardware limit of 1024. All threads in a block share access to the same on-chip Shared Memory.</p>

<h2 id="the-two-performance-regimes">The Two Performance Regimes</h2>

<p>We analyze the performance of a <strong>kernel</strong>, which is a function launched by the host (CPU) to be executed in parallel by many GPU threads. A kernel’s performance is limited by either its memory bandwidth or its compute throughput. These two limits define the performance regimes.</p>

<p>An operation is <strong>memory-bound</strong> if its runtime is dictated by the speed of transferring data from Global Memory to the SM. For an operation like element-wise addition <code>y = x + 1</code>, the SM performs a trivial number of FLOPs for each element it reads. The SM spends most of its time idle, waiting for data.</p>

<p>An operation is <strong>compute-bound</strong> if its runtime is dictated by the SM’s arithmetic speed. A large matrix multiplication is the canonical example. Once data is loaded into the SM, a massive number of computations are performed. The memory bus is idle while the SM is busy.</p>

<p><strong>Arithmetic Intensity (AI)</strong> is the formal metric that determines the regime. It is the ratio of work to memory traffic.</p>

<p><code>Arithmetic Intensity = Total FLOPs / Total Bytes Accessed</code></p>

<p>For the Roofline model, <code>Total Bytes Accessed</code> specifically counts the data transferred between Global Memory (HBM) and the on-chip SM. This is because the model evaluates a kernel’s performance against the primary bottleneck: the slow off-chip memory bus. On-chip traffic, such as from Shared Memory to registers, is not included in this calculation.</p>

<p>The Roofline Model plots a kernel’s achievable performance (in FLOPs per second) against its AI. The two “roofs” are the hard physical limits of the GPU.</p>

<div><pre><code>  ^ Performance (TFLOPS)
  |                                        
  | Memory-Bound Region ¦ Compute-Bound Region
  |                     ¦
  |                    /¦----------------------  &lt;-- Peak Compute (~19.5 TFLOPS)
  |                   / ¦
  |                  /  ¦
  | Peak Global     /&lt;--¦------ Inefficient Compute Roof (e.g., using scalar ops, transcendental functions)
  | Mem BW (~1.5   /    ¦
  | TB/s)         /     ¦
  |              /      ¦
  +---------------------¦---------------------------&gt; Arithmetic Intensity (FLOPs/Byte)
                        ^
                        ¦
                  Hardware Ridge Point (~13)

</code></pre></div>

<p>The performance of a kernel is determined as follows:</p>
<ul>
  <li>When memory-bound, the SMs are stalled waiting for data. The runtime is the time it takes to move that data: <code>Runtime = Bytes_Accessed / Memory_Bandwidth</code>. The kernel’s performance is therefore <code>Performance = Total_FLOPs / Runtime = AI * Memory_Bandwidth</code>. On the log-log plot, this is the diagonal line.</li>
  <li>When compute-bound, the SMs are fully utilized. The performance is limited by their peak arithmetic throughput: <code>Performance = Peak_Compute_FLOPs</code>. This is the horizontal line.</li>
</ul>

<p>A kernel’s actual performance is the minimum of these two values. The <strong>ridge point</strong> is the AI where the two performance ceilings intersect. For the A100, this is <code>19.5 TFLOPS / 1.5 TB/s ≈ 13 FLOPs/Byte</code>. A kernel must exceed this AI to become compute-bound.  A kernel with AI lower than 13 operates in the memory-bound region; a kernel with AI higher than 13 operates in the compute-bound region. The goal of optimization is to increase AI to move the kernel’s operating point to the right, pushing its performance up until it hits the compute roof.</p>

<p>The “Peak Compute” roof of 19.5 TFLOPS is an ideal, achievable only with highly optimized instructions like Tensor Core matrix multiplications and high enough power limits. An operation can be compute-bound but still perform far below this peak. For example, a kernel with high AI that is dominated by scalar arithmetic or complex transcendental functions (<code>sin</code>, <code>exp</code>) will be limited by the throughput of those specific, slower instructions. This creates a lower effective “roof” for that kernel, as shown in the diagram. Increasing AI is necessary, but not sufficient; the FLOPs must also be efficient.</p>

<p>The primary strategy to increase AI is to maximize the reuse of data once it has been loaded into the SM’s fast on-chip memory. The following is a simplified model where a thread reads data from Global Memory directly into its private registers. This analysis calculates the <em>minimum required</em> data transfer; actual memory traffic depends on access patterns, which we will discuss later.</p>

<p>Consider computing <code>C = A@B</code>, where all matrices are <code>N x N</code> and use 4-byte floats.</p>

<p><strong>Strategy 1: One thread computes one element <code>C[i,j]</code></strong></p>
<ul>
  <li><strong>FLOPs:</strong> To compute <code>C[i,j]</code>, the thread performs N multiply-add operations. This is <code>2*N</code> FLOPs.</li>
  <li><strong>Bytes Accessed:</strong> The thread must read row <code>i</code> of A (N floats) and column <code>j</code> of B (N floats). This is a total of <code>2*N</code> floats, or <code>8*N</code> bytes.</li>
  <li><strong>Arithmetic Intensity:</strong> <code>(2*N FLOPs) / (8*N Bytes) = 0.25 FLOPs/Byte</code>.</li>
</ul>

<p>This AI is low. The kernel will be memory-bound.</p>

<p><strong>Strategy 2: One thread computes a <code>2x2</code> tile of C</strong>
To compute a <code>2x2</code> tile (<code>C[i,j]</code>, <code>C[i,j+1]</code>, <code>C[i+1,j]</code>, <code>C[i+1,j+1]</code>), the thread must perform the computation for all four elements.</p>
<ul>
  <li><strong>FLOPs:</strong> <code>4 elements * 2*N FLOPs/element = 8*N</code> FLOPs.</li>
  <li><strong>Bytes Accessed:</strong> The thread must read two rows from A (<code>A[i,:]</code>, <code>A[i+1,:]</code>) and two columns from B (<code>B[:,j]</code>, <code>B[:,j+1]</code>). This is <code>2*N + 2*N = 4*N</code> floats, or <code>16*N</code> bytes.</li>
  <li><strong>Arithmetic Intensity:</strong> <code>(8*N FLOPs) / (16*N Bytes) = 0.5 FLOPs/Byte</code>.</li>
</ul>

<p>These AI values are far below the A100’s ridge point of ~13 FLOPs/Byte. This simple register-only model is insufficient to make matrix multiplication compute-bound.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">5</a></sup> The key to achieving high AI is for threads within a block to cooperate by loading a much larger tile of A and B into the shared, on-chip SRAM. By working together on this shared data, a block of 1024 threads can achieve an AI greater than 13. We will detail the mechanics of this in the section on Shared Memory.</p>

<h2 id="the-third-regime-overhead">The Third Regime: Overhead</h2>

<p>Performance can also be limited by host-side overhead. This is time the CPU (the host) spends preparing work for the GPU, for example, in the Python interpreter or a framework’s dispatch system.</p>

<p>An application is overhead-bound if its GPU kernels are too small or numerous. The GPU executes each small task quickly and then waits, idle, for the CPU to issue the next command. The runtime is dominated by the CPU’s inability to feed the GPU fast enough.</p>

<p>Modern frameworks use asynchronous execution to mitigate this. The host can queue a stream of commands for the GPU without waiting for each one to complete. If the individual GPU operations are sufficiently large, the host can “run ahead,” and the overhead of launching one kernel is hidden by the execution of the previous one.</p>

<p>For the remainder of this post, we assume our kernels are large enough that overhead is not the primary limiter, and focus instead on memory and compute.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">6</a></sup></p>

<h2 id="two-basic-strategies-for-increasing-performance-fusion-and-tiling">Two basic strategies for increasing performance: Fusion and Tiling</h2>

<p>With the kernel large enough to make launch overhead negligible, performance is governed by the two physical limits of the GPU: memory bandwidth and compute throughput. Increasing the performance of a kernel, therefore, means pushing its operating point on the Roofline model up and to the right. There are two basic strategies for achieving this.</p>

<ul>
  <li>For a sequence of individually memory-bound operations, the strategy is to <strong>fuse</strong> them into a single kernel to eliminate intermediate memory traffic.</li>
  <li>For a single, complex operation with high potential arithmetic intensity (like matrix multiplication), the strategy is to use <strong>tiling</strong> to maximize data reuse within the SM’s fast memory.</li>
</ul>

<p>We will address each strategy in turn.</p>

<h3 id="operator-fusion">Operator Fusion</h3>

<p>Chains of simple operations like <code>y = relu(x + 1)</code> are common. Each operation (<code>add</code>, <code>relu</code>) has a very low arithmetic intensity and is memory-bound. Executing them as separate, sequential GPU kernels is inefficient. The primary strategy to optimize these sequences is <strong>operator fusion</strong>.</p>

<p>The problem is the intermediate memory traffic. Consider the unfused execution of <code>y = relu(x + 1)</code>:</p>

<ol>
  <li><strong>Kernel 1 (<code>add</code>):</strong> Reads the entire tensor <code>x</code> from global memory. Computes <code>tmp = x + 1</code>. Writes the entire intermediate tensor <code>tmp</code> back to global memory.</li>
  <li><strong>Kernel 2 (<code>relu</code>):</strong> Reads the entire tensor <code>tmp</code> from global memory. Computes <code>y = relu(tmp)</code>. Writes the final tensor <code>y</code> back to global memory.</li>
</ol>

<p>This approach is wasteful. It involves two separate kernel launch overheads and forces a round-trip to slow global memory for the intermediate <code>tmp</code> tensor.</p>

<p>Fusion combines these steps into a single, more efficient GPU kernel. A JIT compiler like Triton or <code>torch.compile</code>’s Inductor backend can perform this transformation automatically.</p>

<p>In the fused kernel:</p>
<ol>
  <li>A single thread reads one element of <code>x</code> from global memory into its private registers.</li>
  <li>It performs all computations, i.e., <code>tmp = x + 1</code>, then <code>y = relu(tmp)</code>, entirely within those fast registers.</li>
  <li>It writes only the final result <code>y</code> back to global memory.</li>
</ol>

<div><pre><code><span># Unfused (Conceptual)
</span><span>def</span> <span>unfused_add_relu</span><span>(</span><span>x</span><span>):</span>
    <span>tmp</span> <span>=</span> <span>torch</span><span>.</span><span>add</span><span>(</span><span>x</span><span>,</span> <span>1</span><span>)</span> <span># Reads x from HBM, writes tmp to HBM
</span>    <span>y</span> <span>=</span> <span>torch</span><span>.</span><span>relu</span><span>(</span><span>tmp</span><span>)</span>   <span># Reads tmp from HBM, writes y to HBM
</span>    <span>return</span> <span>y</span>

<span># Fused (Conceptual)
</span><span>@</span><span>torch</span><span>.</span><span>compile</span>
<span>def</span> <span>fused_add_relu</span><span>(</span><span>x</span><span>):</span>
    <span># The compiler fuses these into one kernel.
</span>    <span># The intermediate result of x+1 never touches HBM.
</span>    <span>return</span> <span>torch</span><span>.</span><span>relu</span><span>(</span><span>x</span> <span>+</span> <span>1</span><span>)</span>
</code></pre></div>

<p>The intermediate tensor <code>tmp</code> becomes ephemeral, never materializing in global memory. This cuts the memory traffic in half (one read of <code>x</code>, one write of <code>y</code>) and eliminates the launch overhead of the second kernel.</p>

<h3 id="tiling-strategy-for-compute-bound-kernels">Tiling: Strategy for Compute-Bound Kernels</h3>

<p>Our register-only model for <code>C=A@B</code> yielded an arithmetic intensity of 0.25 FLOPs/Byte, far below the A100’s ridge point of ~13. This is because a single thread reads <code>2*N</code> values to perform <code>2*N</code> FLOPs; the data is used once and then discarded. To increase data reuse and become compute-bound, threads within a block must cooperate to load large tiles of the input matrices into the SM’s fast, on-chip Shared Memory.</p>

<p>The logic of this cooperation is based on decomposing the matrix product. The calculation for a single element <code>C[i,j]</code> is a sum over the <code>k</code> dimension: <code>C[i,j] = sum_k A[i,k] B[k,j]</code>. This sum can be partitioned into a sum of partial sums over tiles. For square tiles, the inner <code>k</code> dimension is broken into tiles of size <code>BLOCK_DIM</code>, matching the outer dimensions. The formula becomes:`</p><p>

\[C[i,j] = \sum_{t=0}^{\text{NUM_K_TILES}-1} \left( \sum_{k=t \cdot \text{BLOCK_DIM}}^{(t+1) \cdot \text{BLOCK_DIM} - 1} A[i,k] B[k,j] \right)\]

</p><p>The tiling algorithm computes one term from the outer sum (one partial product) per iteration. A block of threads computes one output <code>C_tile</code> by iterating through the <code>k</code> dimension, loading tiles of A and B, computing their product on-chip, and accumulating the result. This is achieved with a three-phase pattern: <strong>Load, Synchronize, and Compute</strong>.</p>

<div><pre><code><span># Conceptual algorithm for one thread block computing one output tile, C_tile.
# C_tile corresponds to, e.g., C[block_row_start:end, block_col_start:end].
</span>
<span># Each thread in the block holds a piece of C_tile in its registers. Initialize to zero.
</span><span>thread_private_C_accumulator</span> <span>=</span> <span>zeros</span><span>(...)</span>

<span># Loop over tiles of A and B along the k-dimension.
# Each iteration computes one partial product from the sum above.
</span><span>for</span> <span>k_tile_idx</span> <span>in</span> <span>range</span><span>(</span><span>NUM_K_TILES</span><span>):</span>
    <span># Phase 1: Load
</span>    <span># All threads in the block cooperate to load one tile of A and one tile of B
</span>    <span># from slow Global Memory into fast Shared Memory.
</span>    <span>A_tile</span> <span>=</span> <span>load_A_tile_from_global_mem</span><span>(</span><span>k_tile_idx</span><span>)</span>
    <span>B_tile</span> <span>=</span> <span>load_B_tile_from_global_mem</span><span>(</span><span>k_tile_idx</span><span>)</span>

    <span># Phase 2: Synchronize
</span>    <span># Wait for all threads to finish loading before any thread starts computing.
</span>    <span># This ensures A_tile and B_tile are fully populated.
</span>    <span>__syncthreads</span><span>()</span>

    <span># Phase 3: Compute
</span>    <span># Each thread computes its piece of the on-chip matmul.
</span>    <span># The data in A_tile and B_tile is reused extensively from Shared Memory.
</span>    <span>thread_private_C_accumulator</span> <span>+=</span> <span>on_chip_matmul_piece</span><span>(</span><span>A_tile</span><span>,</span> <span>B_tile</span><span>)</span>

    <span># Wait for all threads to finish computing before loading the next tile.
</span>    <span>__syncthreads</span><span>()</span>

<span># After the loop, write the final accumulated result to Global Memory.
</span><span>write_C_tile_to_global_mem</span><span>(</span><span>thread_private_C_accumulator</span><span>)</span>
</code></pre></div>

<p>We now examine the mechanics of the three-phase <strong>Load, Synchronize, Compute</strong> pattern.</p>

<h3 id="the-coalesced-load-hbm-to-sram">The Coalesced Load: HBM to SRAM</h3>

<p>The first phase loads tiles of A and B from slow global memory (HBM) into fast on-chip Shared Memory (SRAM). The goal is to perform this transfer with the maximum possible memory bandwidth. This requires <strong>coalesced memory access</strong>. A memory access is coalesced when all 32 threads in a warp access a single, contiguous 128-byte block of HBM in one transaction.</p>

<p>To achieve this, the kernel maps thread indices to memory addresses. For a <code>BLOCK_DIM x BLOCK_DIM</code> block of threads loading a data tile of the same size, a common mapping is for thread <code>(tx, ty)</code> to be responsible for loading <code>A[global_row + ty, global_k + tx]</code> into <code>A_tile[ty, tx]</code> in Shared Memory. In this example, <code>BLOCK_DIM</code> is 32.</p>

<p>Consider a single warp of threads where <code>ty</code> is fixed and <code>tx</code> ranges from 0 to 31.</p>
<ul>
  <li>Thread <code>(0, ty)</code> reads <code>A[global_row + ty, global_k + 0]</code>.</li>
  <li>Thread <code>(1, ty)</code> reads <code>A[global_row + ty, global_k + 1]</code>.</li>
  <li>…</li>
  <li>Thread <code>(31, ty)</code> reads <code>A[global_row + ty, global_k + 31]</code>.</li>
</ul>

<p>Assuming row-major storage, these threads access 32 consecutive 4-byte floats, a contiguous 128-byte segment. This is a perfect coalesced read. The entire <code>32x32</code> tile is loaded in 32 such coalesced reads, one for each warp in the block.</p>

<div><pre><code>   Thread Block (32x32)          Global Memory (HBM)
                                 (One row of A's tile)
   +--------------------+
   | Warp 0 (ty=0)      | ----&gt; [A_ij, A_i,j+1, ..., A_i,j+31]  (128 bytes)
   | (tx = 0..31)       |       (One coalesced memory transaction)
   +--------------------+
   | Warp 1 (ty=1)      | ----&gt; [A_i+1,j, ..., A_i+1,j+31] (128 bytes)
   +--------------------+
   | ...                |
   +--------------------+
   | Warp 31 (ty=31)    | ----&gt; [A_i+31,j, ..., A_i+31,j+31] (128 bytes)
   +--------------------+
</code></pre></div>

<p>This load can be made more efficient with <strong>vectorized access</strong>. The physical memory transaction for a coalesced read fetches the full 128 bytes from HBM regardless. The difference is how the SM requests this data.</p>

<p>With scalar loads, the warp must issue 32 separate 32-bit load instructions. With vectorized loads, it issues only 8 wider 128-bit load instructions. This is more efficient because the SM has a limited number of instruction issue slots per clock cycle. Requesting the data with 8 wide instructions consumes fewer of these hardware resources than requesting it with 32 narrow instructions. This ensures the memory controller is kept busy with a continuous stream of full-width requests, increasing the <em>utilized</em> memory bandwidth by reducing SM-side bottlenecks.</p>

<p>Vectorized access is enabled by casting pointers in device code (e.g., from <code>float*</code> to <code>float4*</code>), promising the compiler that the memory is aligned to the vector size.</p>

<p>The efficiency of these vectorized loads relies on <strong>memory alignment</strong>. A single <code>float4</code> instruction loads a 16-byte vector. For a matrix of 4-byte floats, this vector contains 4 elements. The hardware executes this instruction efficiently only if the memory address is a multiple of 16. This means the matrix’s inner dimension <code>K</code> (the number of columns) must be a multiple of 4. If <code>K</code> is not a multiple of 4, the rows become misaligned with the 16-byte memory segments.</p>

<p>Consider a matrix of 4-byte floats and a memory system with 16-byte segments.</p>
<ul>
  <li><strong>Aligned (K=8, a multiple of 4):</strong>
    <div><pre><code>Memory: |&lt;--- 16B ---&gt;|&lt;--- 16B ---&gt;|
        [Seg 0       ][Seg 1       ]
Row 0:  [e0 e1 e2 e3 | e4 e5 e6 e7]  (A float4 load for e0-e3 is aligned)
Row 1:  [e0 e1 e2 e3 | e4 e5 e6 e7]  (A float4 load for e0-e3 is aligned)
</code></pre></div>
  </li>
  <li><strong>Unaligned (K=7):</strong>
    <div><pre><code>Memory: |&lt;--- 16B ---&gt;|&lt;--- 16B ---&gt;|&lt;--- 16B ---&gt;|
        [Seg 0       ][Seg 1       ][Seg 2       ]
Row 0:  [e0 e1 e2 e3 e4 e5 e6]
Row 1:                      [e0 e1 e2 e3 e4 e5 e6] (A float4 load for Row 1's e0-e3 spans Seg 0 and Seg 1)
</code></pre></div>
    <p>This misalignment forces the hardware to issue more complex, slower load operations, reducing memory bandwidth.<sup id="fnref:karpathy" role="doc-noteref"><a href="#fn:karpathy" rel="footnote">7</a></sup></p>
  </li>
</ul>

<p><strong>Important:</strong> This row-wise strategy provides coalesced access for matrix A. For matrix B, the required access patterns are in opposition.</p>
<ol>
  <li><strong>HBM Requirement:</strong> To maintain coalescing, the B tile must be read from HBM row-by-row.</li>
  <li><strong>Compute Requirement:</strong> The matrix multiplication itself requires access to columns of the B tile.</li>
</ol>

<p>Loading columns directly from a row-major matrix is an uncoalesced, strided access that serializes HBM transactions. The solution is therefore to load the B tile using coalesced row-reads, but then rearrange the data as it is written into Shared Memory. The structure of this rearrangement is dictated by the physical, banked architecture of Shared Memory.</p>

<h3 id="synchronization">Synchronization</h3>

<p>The <code>__syncthreads()</code> call acts as a barrier. No thread in the block proceeds until all threads have reached this point. This ensures the <code>A_tile</code> and <code>B_tile</code> are fully loaded into Shared Memory before the compute phase begins.<sup id="fnref:sync" role="doc-noteref"><a href="#fn:sync" rel="footnote">8</a></sup>:</p>

<h3 id="the-on-chip-hardware-banks-and-warps">The On-Chip Hardware: Banks and Warps</h3>

<p>Shared Memory is a physical resource located on the Streaming Multiprocessor (SM). When a thread block is scheduled to run on an SM, it is allocated a portion of that SM’s total Shared Memory for its exclusive use.</p>

<p>The Shared Memory is physically partitioned into 32 independent memory modules of equal size, called <strong>banks</strong>. These banks can service memory requests in parallel. This number is not arbitrary; it is matched to the <strong>warp size</strong>. Recall that a warp consists of 32 threads that execute instructions in lockstep, and it is the fundamental unit of memory access. The 32 banks are designed to serve, in parallel, the 32 memory requests from a single warp in one clock cycle, provided those requests target different banks.</p>

<p>Addresses, representing 4-byte words, are interleaved across the banks.</p>
<div><pre><code>bank 0:  [word 0, word 32, word 64, ...]
bank 1:  [word 1, word 33, word 65, ...]
...
bank 31: [word 31, word 63, word 95, ...]
</code></pre></div>
<p>The bank for a given word address is determined by <code>bank_id = address % 32</code>.</p>

<h3 id="the-bank-conflict-problem">The Bank Conflict Problem</h3>

<p>To achieve the full bandwidth of Shared Memory, the 32 threads of a warp must access words that fall into 32 different banks. A <strong>bank conflict</strong> occurs when multiple threads access different addresses that map to the same bank. The hardware resolves this by serializing the requests, reducing bandwidth. A <strong>broadcast</strong>, where all threads read the <em>same</em> address, is a fast, conflict-free operation.</p>

<p>This creates a problem for matrix multiplication. Consider a <code>BLOCK_DIM x BLOCK_DIM</code> tile stored in Shared Memory in a row-major layout, where <code>BLOCK_DIM=32</code>. The address of <code>tile[row, col]</code> is <code>row * 32 + col</code>.</p>
<ul>
  <li><strong>Row Access (A_tile):</strong> A warp accesses <code>A_tile[fixed_row, t]</code> for <code>t = 0..31</code>. The addresses are <code>fixed_row * 32 + t</code>. The bank for each thread <code>t</code> is <code>(fixed_row * 32 + t) % 32 = t % 32</code>. Since <code>t</code> is unique for each thread, the threads access 32 unique banks. This is a conflict-free, full-bandwidth access.</li>
  <li><strong>Column Access (B_tile):</strong> A warp accesses <code>B_tile[t, fixed_col]</code> for <code>t = 0..31</code>. The addresses are <code>t * 32 + fixed_col</code>. The bank for each thread <code>t</code> is <code>(t * 32 + fixed_col) % 32 = fixed_col % 32</code>. All 32 threads target the same bank. This causes a 32-way bank conflict, serializing the memory access.</li>
</ul>

<p>The solution is to store the <code>B_tile</code> in a transposed layout within Shared Memory.</p>
<div><pre><code><span># Action for thread (tx, ty) during the load phase
# A is loaded directly, B is loaded and transposed on-the-fly
</span><span>A_tile</span><span>[</span><span>ty</span><span>,</span> <span>tx</span><span>]</span> <span>=</span> <span>A_global</span><span>[</span><span>global_row</span> <span>+</span> <span>ty</span><span>,</span> <span>global_k</span> <span>+</span> <span>tx</span><span>]</span>
<span>B_tile</span><span>[</span><span>tx</span><span>,</span> <span>ty</span><span>]</span> <span>=</span> <span>B_global</span><span>[</span><span>global_k</span> <span>+</span> <span>ty</span><span>,</span> <span>global_j</span> <span>+</span> <span>tx</span><span>]</span> <span># Indices are swapped
</span></code></pre></div>
<p>This “load-and-transpose” maneuver alters the on-chip computation. The calculation for an element of the partial product is no longer a dot product between a row of <code>A_tile</code> and a column of <code>B_tile</code>. Instead, using the transposed on-chip <code>B_tile</code>, the formula becomes:</p><p>

\[C_{\text{partial}}[i,j] = \sum_{k} A_{\text{tile}}[i,k] \cdot B_{\text{tile}}[j,k]\]

</p><p>In this formulation, a warp of threads computing different <code>j</code> values for a fixed <code>i</code> will access a row from <code>A_tile</code> and a row from the on-chip <code>B_tile</code>. Both are conflict-free access patterns. This single strategy solves both the HBM coalescing requirement and the SRAM bank conflict problem.</p>

<div><pre><code>   Load-and-Transpose Operation (Thread tx, ty)
   Reads row-wise from HBM, writes column-wise to SRAM

   Global Memory (HBM)                Shared Memory (SRAM)
   +-------------------------+        +-----------------------+
   | B[k_base+ty, j_base+tx] | -----&gt; |      B_tile[tx, ty]   |
   +-------------------------+        +-----------------------+

   Result: HBM reads are coalesced, SRAM reads are conflict-free.
</code></pre></div>

<h3 id="e-the-on-chip-compute-phase-increasing-arithmetic-intensity">E. The On-Chip Compute Phase: Increasing Arithmetic Intensity</h3>

<p>With data staged in Shared Memory, the block performs the computation. The goal is to maximize data reuse from this fast on-chip memory. We will analyze two strategies for structuring this on-chip computation.</p>

<p><strong>Strategy 1: One thread computes one output</strong></p>

<p>The simplest approach maps one output element to one thread. A <code>BLOCK_DIM x BLOCK_DIM</code> thread block computes a <code>TILE_DIM x TILE_DIM</code> data tile, where <code>BLOCK_DIM</code> and <code>TILE_DIM</code> are equal. This strategy is conceptually similar to <strong>Kernel 3</strong> in <a href="https://siboehm.com/articles/22/CUDA-MMM" target="_blank">Boehm’s post</a>, which introduces Shared Memory caching.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">9</a></sup> The hardware limit of 1024 threads per block constrains <code>BLOCK_DIM</code> to be at most 32. Thread <code>(tx, ty)</code> is responsible for a single output element <code>C_partial[ty, tx]</code>.</p>

<div><pre><code><span># Action for a single thread (tx, ty) where BLOCK_DIM = TILE_DIM
</span><span>c_accumulator</span> <span>=</span> <span>0.0</span>
<span>for</span> <span>k</span> <span>in</span> <span>range</span><span>(</span><span>TILE_DIM</span><span>):</span>
    <span>c_accumulator</span> <span>+=</span> <span>A_tile</span><span>[</span><span>ty</span><span>,</span> <span>k</span><span>]</span> <span>*</span> <span>B_tile</span><span>[</span><span>tx</span><span>,</span> <span>k</span><span>]</span>
</code></pre></div>

<p>The arithmetic intensity for this strategy is <code>TILE_DIM / 4</code>.</p>
<ul>
  <li><strong>Total FLOPs:</strong> The block performs <code>2 * TILE_DIM^3</code> FLOPs.</li>
  <li><strong>Total Bytes Accessed (HBM):</strong> The block loads two data tiles, totaling <code>8 * TILE_DIM^2</code> bytes.</li>
  <li><strong>Arithmetic Intensity (AI):</strong> <code>(2 * TILE_DIM^3) / (8 * TILE_DIM^2) = TILE_DIM / 4</code> FLOPs/Byte.</li>
</ul>

<p>With <code>TILE_DIM</code> limited to 32, the maximum AI is <code>32 / 4 = 8</code>. This is insufficient to cross the A100’s ridge point of ~13. The kernel remains memory-bound.</p>

<p><strong>Strategy 2: One thread computes multiple outputs</strong></p>

<p>To increase AI, we must increase <code>TILE_DIM</code> without increasing the number of threads. This requires decoupling the data tile size from the thread block size. We assign more work to each thread. This strategy corresponds to the goal of <strong>Kernel 5</strong> in <a href="https://siboehm.com/articles/22/CUDA-MMM" target="_blank">Boehm’s post.</a></p>

<p>A <code>16x16</code> thread block (<code>BLOCK_DIM = 16</code>, 256 threads) can compute a <code>64x64</code> data tile (<code>TILE_DIM = 64</code>). Each thread now computes a <code>4x4</code> sub-tile of the output. This requires <code>TILE_DIM=64</code> to not exceed Shared Memory capacity.<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">10</a></sup></p>

<div><pre><code><span># A thread computes a 4x4 output sub-tile
# TILE_DIM = 64, BLOCK_DIM = 16
</span><span>c_regs</span> <span>=</span> <span>[[</span><span>0.0</span><span>]</span> <span>*</span> <span>4</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>4</span><span>)]</span>
<span>a_regs</span> <span>=</span> <span>[</span><span>0.0</span><span>]</span> <span>*</span> <span>4</span>
<span>b_regs</span> <span>=</span> <span>[</span><span>0.0</span><span>]</span> <span>*</span> <span>4</span>

<span>for</span> <span>k</span> <span>in</span> <span>range</span><span>(</span><span>TILE_DIM</span><span>):</span>
    <span># Load a sliver of A_tile and B_tile into registers
</span>    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>4</span><span>):</span> <span>a_regs</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>A_tile</span><span>[</span><span>thread_row</span><span>*</span><span>4</span> <span>+</span> <span>i</span><span>,</span> <span>k</span><span>]</span>
    <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>4</span><span>):</span> <span>b_regs</span><span>[</span><span>j</span><span>]</span> <span>=</span> <span>B_tile</span><span>[</span><span>thread_col</span><span>*</span><span>4</span> <span>+</span> <span>j</span><span>,</span> <span>k</span><span>]</span>

    <span># Compute outer product in registers, accumulating into c_regs
</span>    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>4</span><span>):</span>
        <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>4</span><span>):</span>
            <span>c_regs</span><span>[</span><span>i</span><span>][</span><span>j</span><span>]</span> <span>+=</span> <span>a_regs</span><span>[</span><span>i</span><span>]</span> <span>*</span> <span>b_regs</span><span>[</span><span>j</span><span>]</span>
</code></pre></div>
<p>The AI calculation remains <code>TILE_DIM / 4</code>. With <code>TILE_DIM = 64</code>, the AI is <code>64 / 4 = 16</code> FLOPs/Byte. This exceeds the A100’s ridge point. The kernel is now <strong>compute-bound</strong>.</p>

<p>A compute-bound kernel’s runtime is limited by the SM’s arithmetic throughput. This does not guarantee high absolute performance. A kernel can be compute-bound but still be slow if its FLOPs are inefficient (e.g., using scalar FP32 math instead of specialized hardware like Tensor Cores<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" rel="footnote">11</a></sup>) or if the GPU operates below its peak clock speed due to power limits.</p>

<p>The inner loop in the code above can be further optimized. A thread loads four separate <code>float</code> values from <code>A_tile</code> into <code>a_regs</code>. It can instead issue a single instruction to load a 16-byte <code>float4</code> vector. This vectorized load from Shared Memory reduces the number of instructions issued for on-chip data movement, improving the efficiency of the compute phase. This corresponds to the on-chip vectorization refinement used in <strong>Kernel 6</strong> of <a href="https://siboehm.com/articles/22/CUDA-MMM" target="_blank">Boehm’s post.</a></p>

<p><strong>A Final Consideration: Tile Quantization</strong></p>

<p>If matrix dimensions are not multiples of the tile size, the kernel launches extra blocks that perform wasted computation.</p>

<p>To cover an <code>M x N</code> matrix with <code>TILE_M x TILE_N</code> tiles, the GPU launches a grid of <code>ceil(M/TILE_M) x ceil(N/TILE_N)</code> thread blocks. Tiling a 65x65 matrix with 32x32 tiles requires a <code>ceil(65/32) x ceil(65/32)</code> = 3x3 grid of blocks. The kernel’s logic is fixed; each block is programmed to perform the arithmetic for a full 32x32 tile.</p>

<div><pre><code>      Columns 0-31      Columns 32-63     Columns 64-95
    +-----------------+-----------------+-----------------+
R 0 |                 |                 |                 |
o-31|   Block 0,0     |   Block 0,1     |   Block 0,2     |
w   | (Full work)     | (Full work)     | (Wasted work)   |
s   |                 |                 |                 |
    +-----------------+-----------------+-----------------+
R 32|                 |                 |                 |
o-63|   Block 1,0     |   Block 1,1     |   Block 1,2     |
w   | (Full work)     | (Full work)     | (Wasted work)   |
s   |                 |                 |                 |
    +-----------------+-----------------+-----------------+
R 64|                 |                 |                 |
o-95|   Block 2,0     |   Block 2,1     |   Block 2,2     |
w   | (Wasted work)   | (Wasted work)   | (Wasted work)   |
s   |                 |                 |                 |
    +-----------------+-----------------+-----------------+
</code></pre></div>
<p><a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#tile-quant" target="_blank">According to NVIDIA</a>, “While libraries ensure that invalid memory accesses are not performed by any of the tiles, all tiles will perform the same amount of math.” My understanding of why this happens (I’m happy to be corrected): Boundary blocks perform wasted work because the kernel explicitly pads the data. Threads assigned to load elements from outside the matrix bounds are prevented from doing so by a guard condition. Instead, they write zero to their location in the on-chip Shared Memory tile. The arithmetic loops are not shortened. The kernel’s logic is uniform across the tile. All threads in a warp execute the same multiply-add instructions. A thread whose data corresponds to a padded zero still executes the instruction; it just performs a useless computation, such as <code>C += A * 0</code>. The hardware resources are used, but the  work is discarded.</p>

<h2 id="additional-performance-considerations">Additional Performance Considerations</h2>

<p>We have made our kernel compute-bound. Its performance is now limited by the speed of its on-chip arithmetic. However, the kernel can still be made faster by managing additional aspects of the hardware. The following are three such considerations. There are others, but I’m not quite advanced enough to write about them, yet. See <a href="https://siboehm.com/articles/22/CUDA-MMM" target="_blank">Boehm’s post</a> for others.</p>

<h3 id="occupancy-and-latency-hiding">Occupancy and Latency Hiding</h3>

<p>A warp <strong>stalls</strong> when it executes a long-latency instruction, such as a read from Global Memory. It cannot execute its next instruction until the data arrives, which can take hundreds of clock cycles. During this time, the SM’s compute units would be idle if the stalled warp were the only work available.</p>

<p>The SM hides this latency by executing other work. It can hold multiple thread blocks concurrently, creating a pool of resident warps. When one warp stalls, the SM’s hardware scheduler instantly switches to a different warp from this pool that is ready to run. This mechanism is called <strong>latency hiding</strong>.</p>

<div><pre><code>+-------------------------------------------------------------------+
| Streaming Multiprocessor (SM)                                     |
|                                                                   |
|  [Block A]              [Block B]                                 |
|   - Warp A1 (Ready)      - Warp B1 (Ready)                        |
|   - Warp A2 (Stalled -&gt; waiting on HBM)                           |
|        |                  |                                       |
|        +------------------v------------------+                    |
|           [ Pool of Ready-to-Run Warps ]                          |
|           [ A1, B1 ]                                              |
|                           |                                       |
|                   +-------v-------+                               |
|                   | SM Scheduler  | --&gt; [Execute instructions]    |
|                   +---------------+                               |
|                                                                   |
+-------------------------------------------------------------------+
</code></pre></div>
<p><strong>Occupancy</strong> is the ratio of active warps on an SM to the maximum number it can support. High occupancy gives the scheduler a larger pool of warps to choose from. This increases the likelihood that it can find a ready warp to execute at any given cycle, keeping the compute units active.</p>

<p>This leads to a trade-off between the resources used per block and the number of blocks that can reside on an SM. The two extremes can be visualized as follows:</p>

<div><pre><code>+------------------------------------+ +----------------------------------------------+
| SM with High AI, Low Occupancy     | | SM with Low AI, High Occupancy               |
|                                    | |                                              |
| +--------------------------------+ | | +----------+ +-----------+     +-----------+ |
| | Block 0 (uses 64KB SMEM)       | | | | Block 0  | | Block 1   | ... | Block N   | |
| | TILE_DIM=128 -&gt; High AI        | | | | (8KB SMEM) | (8KB SMEM)|     | (8KB SMEM)| |
| +--------------------------------+ | | +----------+ +-----------+     +-----------+ |
|                                    | |                                              |
| --&gt; Low # of resident blocks.      | | --&gt; High # of resident blocks.               |
| --&gt; Small pool of warps for        | | --&gt; Large pool of warps for                  |
|     latency hiding.                | |     latency hiding.                          |
+------------------------------------+ +----------------------------------------------+
</code></pre></div>
<p>We tune the kernel’s resource usage to balance the benefit of high AI against the necessity of sufficient occupancy. The primary levers for this tuning are the thread block dimensions (<code>BLOCK_DIM</code>), the amount of Shared Memory allocated per block (determined by <code>TILE_DIM</code>), and the number of registers used per thread.<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" rel="footnote">12</a></sup></p>

<h3 id="avoiding-thread-divergence">Avoiding Thread Divergence</h3>

<p>A conditional branch (<code>if-else</code>) where threads in a warp disagree on the outcome causes <strong>thread divergence</strong>.<sup id="fnref:12" role="doc-noteref"><a href="#fn:12" rel="footnote">13</a></sup> When this occurs, the hardware resolves the divergence by executing the different code paths serially. First, threads that take the <code>if</code> path execute it while the others are inactive. Then, the roles are reversed for the <code>else</code> path.</p>

<div><pre><code><span># A warp of 32 threads encounters an `if` statement:
</span><span>if</span> <span>(</span><span>thread_id</span> <span>&lt;</span> <span>16</span><span>)</span> 
    <span># Path A
</span><span>else</span> 
    <span># Path B
</span>
<span>Execution</span> <span>Timeline</span><span>:</span>

<span>Time</span> <span>-&gt;</span>
<span>+------------------------------------------------------------------+</span>
<span>|</span> <span>Warp</span> <span>Execution</span>                                                   <span>|</span>
<span>|</span>                                                                  <span>|</span>
<span>|</span>  <span>Cycle</span> <span>1</span><span>:</span> <span>Path</span> <span>A</span> <span>is</span> <span>executed</span><span>.</span>                                    <span>|</span>
<span>|</span>   <span>-</span> <span>Threads</span> <span>0</span><span>-</span><span>15</span><span>:</span>  <span>Active</span><span>,</span> <span>execute</span> <span>Path</span> <span>A</span> <span>code</span><span>.</span>                  <span>|</span>
<span>|</span>   <span>-</span> <span>Threads</span> <span>16</span><span>-</span><span>31</span><span>:</span> <span>Inactive</span><span>,</span> <span>masked</span> <span>off</span><span>.</span>                         <span>|</span>
<span>|</span>                                                                  <span>|</span>
<span>|</span>  <span>Cycle</span> <span>2</span><span>:</span> <span>Path</span> <span>B</span> <span>is</span> <span>executed</span><span>.</span>                                    <span>|</span>
<span>|</span>   <span>-</span> <span>Threads</span> <span>0</span><span>-</span><span>15</span><span>:</span>  <span>Inactive</span><span>,</span> <span>masked</span> <span>off</span><span>.</span>                         <span>|</span>
<span>|</span>   <span>-</span> <span>Threads</span> <span>16</span><span>-</span><span>31</span><span>:</span> <span>Active</span><span>,</span> <span>execute</span> <span>Path</span> <span>B</span> <span>code</span><span>.</span>                  <span>|</span>
<span>|</span>                                                                  <span>|</span>
<span>|</span> <span>Result</span><span>:</span> <span>Two</span> <span>cycles</span> <span>are</span> <span>required</span> <span>instead</span> <span>of</span> <span>one</span><span>.</span>                  <span>|</span>
<span>|</span>         <span>Effective</span> <span>throughput</span> <span>is</span> <span>halved</span><span>.</span>                          <span>|</span>
<span>+------------------------------------------------------------------+</span>
</code></pre></div>
<p>This serialization doubles the execution time of the divergent code, halving the warp’s effective throughput. We avoid this cost by writing branchless code in performance-critical sections, using primitives like <code>min</code> and <code>max</code> instead of <code>if-else</code>.</p>

<h3 id="quantization">Quantization</h3>

<p>Quantization reduces precision of elements of our tensor, from, say FP32 to FP16 or BFP16. This has two effects. First, it reduces the memory needed to store each element, for example, by 2. Thus, we can transfer twice as many elements per second from global memory to shared memory. This increases AI by 2.</p>

<p>Second, GPUs, such as the A100, can operate faster on lower precision elements. For example, on an A100, 312 TFLOPS are achievable for certain FP16 operations, whereas FP32 operations are limited to 19.5 TFLOPS. Thus, theoretically we can speedup computation by a factor of 16.</p>

<p>Quantization can therefore move us up and to the right on the Roofline plot.</p>

<hr>




  
                   
  
  
          
  
  
  
  
  
  
    


      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SourceHut moves business operations from US to Europe (153 pts)]]></title>
            <link>https://lists.sr.ht/~sircmpwn/sr.ht-dev/patches/60282</link>
            <guid>44365246</guid>
            <pubDate>Tue, 24 Jun 2025 12:06:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.sr.ht/~sircmpwn/sr.ht-dev/patches/60282">https://lists.sr.ht/~sircmpwn/sr.ht-dev/patches/60282</a>, See on <a href="https://news.ycombinator.com/item?id=44365246">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      
      
      <h3>
        
        sr.ht-docs:
        
        Terms of service &amp; privacy updates
        <small>v2</small>
        <span>
          PROPOSED
        </span>
      </h3>
      


    </div><div>
      
      <pre>Drew DeVault: 1
 Terms of service &amp; privacy updates

 2 files changed, 67 insertions(+), 71 deletions(-)
</pre>
      

      

      
      
      

      
      
        
          






<pre>Oh, thanks, will fix that.
</pre>


          
          
          
        
      

      
      
      
      
    </div><div>
      
      <h3>
        [PATCH sr.ht-docs v2] Terms of service &amp; privacy updates
        <a href="https://lists.sr.ht/~sircmpwn/sr.ht-dev/%3C20250623120647.7229-1-drew@ddevault.org%3E/raw">
          Export this patch 
        </a>
      </h3>
      






<pre>---
v2: rollback the premature removal of compliance with US law

Will defer this until we finish shutting down the US business entity
entirely.

 <a href="#<20250623120647.7229-1-drew@ddevault.org>+privacy.md">privacy.md</a> | 70 <span>+++++++++++++++++++++++</span><span>-------------------------------</span>
 <a href="#<20250623120647.7229-1-drew@ddevault.org>+terms.md">terms.md</a>   | 68 <span>++++++++++++++++++++++++++++</span><span>------------------------</span>
 2 files changed, 67 insertions(+), 71 deletions(-)

diff --git a/privacy.md b/privacy.md
index ab96a1f..ed6eb5c 100644
<span>--- a/privacy.md</span>
<a href="#<20250623120647.7229-1-drew@ddevault.org>+privacy.md" id="<20250623120647.7229-1-drew@ddevault.org>+privacy.md">+++ b/privacy.md</a>
@@ -1,13 +1,5 @@
---
title: Privacy policy
<span># TODO:</span>
<span># - Clarify that we don't store any information about logged-out users, except</span>
<span>#   for their IP address.</span>
<span># - Improve wording of details about short-lived session cookies.</span>
<span># - Improve presentation of bcrypt process.</span>
<span># - Mention information stored from email headers.</span>
<span># - Clarify s/web browser/client/g</span>
<span># These changes are batched to reduce the noise upon notifying users.</span>
---

[sr.ht-support]: mailto:~sircmpwn/sr.ht-support@lists.sr.ht
@@ -24,7 +16,7 @@ without a computationally expensive process. However, given your password, we
can determine that it matches our stored key without expensive processing.  The
purpose of this step is to ensure that should our database become compromised,
your original password will be difficult to recover. Regardless, you are
<span>strongly encouraged to use a unique password for your sr.ht account.</span>
<span>strongly encouraged to use a unique password for your SourceHut account.</span>

You may choose to give us additional information, which is shown publicly on
the site. This includes:
@@ -33,7 +25,10 @@ the site. This includes:
- A URL to any website
- A short biography

<span>You may omit or provide fictitious data for this information.</span>
<span>You may omit or provide fictitious data for this information. The location shown</span>
<span>on your profile is collected separately from your billing address, and may</span>
<span>differ. (*You may set your public location to "The Internet", for example,</span>
<span>despite providing an accurate billing address*).</span>

You may be required to provide the following information in order to
successfully operate some parts of the service, some of which may be used to
@@ -45,18 +40,18 @@ uniquely identify you:

You may delete this information at any time by visiting your [account
details](https://meta.sr.ht). If you provide a PGP key, you may choose to have
<span>email communications from sr.ht encrypted before being sent to you.</span>
<span>email communications from SourceHut encrypted before being sent to you.</span>

<span>We also obtain some information from your web browser as you use our services</span>
<span>We also obtain some information from your client as you use our services</span>
and store it for up to 30 days:

- Your IP address
- When you accessed the site
- What you did on the site

<span>This information is available to you as an [audit</span>
<span>Some of this information is available to you as an [audit</span>
log](https://meta.sr.ht/security). You are not able to delete this information.
<span>The purpose of this data collection is to inform both you and sr.ht of any</span>
<span>The purpose of this data collection is to inform both you and SourceHut of any</span>
unknown activity on your account. If we permitted deletion of this information,
someone who obtains unauthorized access to your account would be able to delete
it, too.
@@ -67,54 +62,49 @@ give us, including (but not limited to):
- repositories on git.sr.ht
- tickets on todo.sr.ht
- build logs and secrets on builds.sr.ht
<span></span>
<span>To faciliate automated access to your account for third-party service or your</span>
<span>personal use, we also generate and store API keys which can be used to authorize</span>
<span>use of your account. A portion of these keys are stored in plaintext — not</span>
<span>enough to gain access to your account, but enough for us to quickly look up your</span>
<span>account details given the key. The full key is stored only after processing with</span>
<span>bcrypt, similar to the process used for your password.</span>
<span>- email headers sent to lists.sr.ht</span>

If you choose to use our paid services, we will store a token which is used to
bill your payment method. Information like your credit card number cannot be
<span>recovered from this token.</span>
<span>recovered from this token. We will also retain a copy of your billing records</span>
<span>(e.g. invoices) for up to 7 years, even if you delete your account, in</span>
<span>compliance with European law.</span>

We also use cookies to store long-lived authorization data, to remember that
you're logged into your account between visits without prompting you for your
<span>password again. We also use cookies to store short-lived information, like the</span>
<span>fact that we have to tell you on the next page you load that we completed some</span>
<span>operation successfully for you.</span>
<span>password again, and to store short-lived information, for example when</span>
<span>filling out a form which requires several pages to complete.</span>

## How we share your information with third-parties

Aside from information you choose to make public in the course of your use of
<span>sr.ht and information you explicitly choose to share with specific</span>
<span>SourceHut and information you explicitly choose to share with specific</span>
third parties, none of your information is shared with third parties. We do not
<span>embed third-party content in our website, with one exception: on the billing</span>
<span>page, we embed a script from [Stripe](https://stripe.com). This measure is taken</span>
<span>to improve your privacy and allows us to avoid directly handling your credit</span>
<span>card information.</span>
<span>embed third-party content in our website. This measure is taken to improve your</span>
<span>privacy and allows us to avoid directly handling your credit card information.</span>

We permit user-generated content to include images from and links to third-party
sites. On pages displaying this content, information may be sent to these
third-parties. This information includes:

- Your IP address
<span>- Information about your web browser, such as whether you use Firefox or Chrome</span>
<span>- The URL on sr.ht you visited when you saw this content</span>
<span>- Information about your client, such as whether you use Firefox or Chrome</span>
<span>- The URL on SourceHut you visited when you saw this content</span>

<span>We are not responsible for any additional information your web browser may send</span>
<span>to these third parties.</span>
<span>We are not responsible for any additional information your client may send to</span>
<span>these third parties.</span>

If you use any of our paid services, we will transmit your payment information
<span>to a third-party payment processor. You will be notified of this before the</span>
<span>information is transmitted, and given an opportunity to prevent its</span>
<span>to a third-party payment processor, [Stripe]. You will be notified of this</span>
<span>before the information is transmitted, and given an opportunity to prevent its</span>
transmission. We will be unable to provide you with paid services if you decline
to transmit this information.

<span>We may also be required to remit your data upon receiving an order from a court</span>
<span>of the United States. If permitted by the order, you will be notified if this</span>
<span>happens.</span>
<span>[Stripe]: https://stripe.com</span>
<span></span>
<span>We may also be required to remit your data upon receiving a lawful order from an</span>
<span>applicable court with jurisdiction over SourceHut. If permitted by the order,</span>
<span>you will be notified if this happens.</span>

## How to access and control the information we've collected

@@ -123,7 +113,7 @@ archive of the information we've collected about you, or to request that we
remove any information we've collected about you. 

You may also reach out to our data protection officer directly: Drew DeVault
<span>&lt;sir@cmpwn.com&gt;.</span>
<span>&lt;drew@ddevault.org&gt;.</span>

## Changes to this document

diff --git a/terms.md b/terms.md
index f781d94..0704ab0 100644
<span>--- a/terms.md</span>
<a href="#<20250623120647.7229-1-drew@ddevault.org>+terms.md" id="<20250623120647.7229-1-drew@ddevault.org>+terms.md">+++ b/terms.md</a>
@@ -1,33 +1,9 @@
---
title: Terms of Service
---
<span>&lt;!--</span>

<span>Pending changes:</span>
<span></span>
<span># Automated use of our services</span>
<span></span>
<span>You may use automated tools to access SourceHut data in bulk (i.e. crawlers,</span>
<span>robots, spiders, etc) provided that:</span>
<span></span>
<span>1. You obey the rules set forth in robots.txt</span>
<span>2. Your software uses a User-Agent header which clearly identifies your</span>
<span>   software and its operators, including your contact information</span>
<span>3. You request data from SourceHut at a rate which does not adversely affect</span>
<span>   the performance of the services for normal users</span>
<span></span>
<span>You may *only* collect this data for one or more of the following purposes:</span>
<span></span>
<span>- Search engine indexing</span>
<span>- Open-access research</span>
<span>- Data archival</span>
<span></span>
<span>You may not use automated tools to collect SourceHut data for solicitation,</span>
<span>profit, or the training of a machine learning model.</span>
<span></span>
<span>---&gt;</span>
<span></span>
<span>These are the terms of service for sr.ht; please read them before using sr.ht.</span>
<span>These are the terms of service for SourceHut; please read them before using our</span>
<span>services.</span>

If you have any questions, please reach out to [sr.ht-support] via email.

@@ -48,9 +24,9 @@ This is for quick reference only, binding terms follow.
## Definitions

The "services" are any software, application, product, or service provided by
<span>sr.ht. Collectively they are also referred to as the "network".</span>
<span>SourceHut. Collectively they are also referred to as the "network".</span>

<span>"sr.ht", "we", and "us" refers to sr.ht and its authorized agents.</span>
<span>"SourceHut", "we", and "us" refers to SourceHut and its authorized agents.</span>

The "user", "you", and "your" refers to any individual or organization which
accesses our services.
@@ -80,9 +56,10 @@ this address. If we are unable to reach you, your account may be terminated.

## Permissible use

<span>You must obey all local, US, and Dutch laws in the course of using the service.</span>
<span>You will not utilize the service to transmit or store content which is unlawful.</span>
<span>The following additional types of content are explicitly prohibited:</span>
<span>You must obey all local, US, European, and Dutch laws and regulations in the</span>
<span>course of using the service. You will not utilize the service to transmit or</span>
<span>store content which is unlawful. The following additional types of content are</span>
<span>explicitly prohibited:</span>

- explicit sexual content
- malware in executable form; or in source form without obvious disclaimers
@@ -105,6 +82,26 @@ You may use automated tools to obtain public information from the services for
the purposes of archival or open-access research. You may not use this data for
recruiting, solicitation, or profit.

<span># Automated use of our services</span>
<span></span>
<span>You may use automated tools to access SourceHut data in bulk (i.e. crawlers,</span>
<span>robots, spiders, etc) provided that:</span>
<span></span>
<span>1. You obey the rules set forth in robots.txt</span>
<span>2. Your software uses a User-Agent header which clearly identifies your</span>
<span>   software and its operators, including your contact information</span>
<span>3. You request data from SourceHut at a rate which does not adversely affect</span>
<span>   the performance of the services for normal users</span>
<span></span>
<span>You may *only* collect this data for one or more of the following purposes:</span>
<span></span>
<span>- Search engine indexing</span>
<span>- Open-access research</span>
<span>- Data archival</span>
<span></span>
<span>You may not use automated tools to collect SourceHut data for solicitation,</span>
<span>profit, or the training of a machine learning model.</span>
<span></span>
## Content rights

When uploading content to SourceHut, you must have the right to do so. You grant
@@ -165,3 +162,12 @@ reduced price at the start of the next billing term.

We may make changes to these terms with no less than 2 weeks notice. Notice of
changes to these terms will be sent to the email on file for your account.
<span></span>
<span>---</span>
<span></span>
<span>SourceHut</span>
<span>Postbus 3068</span>
<span>1620GB Hoorn</span>
<span>Netherlands</span>
<span>KVK nummer: 84165251</span>
<span>BTW nummer: NL003921490B16</span>
-- 
2.50.0
</pre>



<blockquote>
  
  


  <pre>The business details at the bottom of terms.md will be appear on a
single line when converted to HTML per the CommonMark spec.

[See this demo][0].

[0]: https://spec.commonmark.org/dingus/?text=SourceHut%0APostbus%203068%0A1620GB%20Hoorn%0ANetherlands%0AKVK%20nummer%3A%2084165251%0ABTW%20nummer%3A%20NL003921490B16</pre>
</blockquote>




      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starship: The minimal, fast, and customizable prompt for any shell (360 pts)]]></title>
            <link>https://starship.rs/</link>
            <guid>44364874</guid>
            <pubDate>Tue, 24 Jun 2025 11:11:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://starship.rs/">https://starship.rs/</a>, See on <a href="https://news.ycombinator.com/item?id=44364874">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-9a6c75ad="" data-v-e07eaea7="" id="VPContent" data-v-d8b57b2d=""><!--[--><!--]--><div data-v-dd8814ff="" data-v-e07eaea7=""><div data-v-dd8814ff=""><!--[--><!--]--><!--[--><p data-v-dd8814ff="">The minimal, blazing-fast, and infinitely customizable prompt for any shell!</p><!--]--><!--[--><!--]--><!--[--><!--]--></div><div data-v-dd8814ff=""><!--[--><!--[--><p><img src="https://starship.rs/logo.svg" alt="" data-v-ab19afbb=""></p><!--]--><!--]--></div></div><!--[--><!--]--><!--[--><!--]--><div data-v-b1eea84a="" data-v-e07eaea7=""><!--[--><div data-v-b1eea84a="" data-v-bd37d1a2=""><!--[--><article data-v-bd37d1a2=""><!----><h2 data-v-bd37d1a2="">Compatibility First</h2><p data-v-bd37d1a2="">Works on the most common shells on the most common operating systems. Use it everywhere!</p><!----></article><!--]--></div><div data-v-b1eea84a="" data-v-bd37d1a2=""><!--[--><article data-v-bd37d1a2=""><!----><h2 data-v-bd37d1a2="">Rust-Powered</h2><p data-v-bd37d1a2="">Brings the best-in-class speed and safety of Rust, to make your prompt as quick and reliable as possible.</p><!----></article><!--]--></div><div data-v-b1eea84a="" data-v-bd37d1a2=""><!--[--><article data-v-bd37d1a2=""><!----><h2 data-v-bd37d1a2="">Customizable</h2><p data-v-bd37d1a2="">Every little detail is customizable to your liking, to make this prompt as minimal or feature-rich as you'd like it to be.</p><!----></article><!--]--></div><!--]--></div><!--[--><!--]--><div data-v-e07eaea7="" data-v-c141a4bd=""><video muted="" autoplay="" loop="" playsinline=""><source src="https://starship.rs/demo.webm" type="video/webm"><source src="https://starship.rs/demo.mp4" type="video/mp4"></video><h3 id="prerequisites" tabindex="-1">Prerequisites <a href="#prerequisites" aria-label="Permalink to &quot;Prerequisites&quot;">​</a></h3><ul><li>A <a href="https://www.nerdfonts.com/" target="_blank" rel="noreferrer">Nerd Font</a> installed and enabled in your terminal.</li></ul><h3 id="quick-install" tabindex="-1">Quick Install <a href="#quick-install" aria-label="Permalink to &quot;Quick Install&quot;">​</a></h3><ol><li><p>Install the <strong>starship</strong> binary:</p><h4 id="install-latest-version" tabindex="-1">Install Latest Version <a href="#install-latest-version" aria-label="Permalink to &quot;Install Latest Version&quot;">​</a></h4><p>With Shell:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span>curl</span><span> -sS</span><span> https://starship.rs/install.sh</span><span> |</span><span> sh</span></span></code></pre></div><p>To update the Starship itself, rerun the above script. It will replace the current version without touching Starship's configuration.</p><h4 id="install-via-package-manager" tabindex="-1">Install via Package Manager <a href="#install-via-package-manager" aria-label="Permalink to &quot;Install via Package Manager&quot;">​</a></h4><p>With <a href="https://brew.sh/" target="_blank" rel="noreferrer">Homebrew</a>:</p><p>With <a href="https://github.com/microsoft/winget-cli" target="_blank" rel="noreferrer">Winget</a>:</p><div><p><span>powershell</span></p><pre tabindex="0"><code><span><span>winget install starship</span></span></code></pre></div></li><li><p>Add the init script to your shell's config file:</p><h4 id="bash" tabindex="-1">Bash <a href="#bash" aria-label="Permalink to &quot;Bash&quot;">​</a></h4><p>Add the following to the end of <code>~/.bashrc</code>:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span># ~/.bashrc</span></span>
<span></span>
<span><span>eval</span><span> "$(</span><span>starship</span><span> init bash)"</span></span></code></pre></div><h4 id="fish" tabindex="-1">Fish <a href="#fish" aria-label="Permalink to &quot;Fish&quot;">​</a></h4><p>Add the following to the end of <code>~/.config/fish/config.fish</code>:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span># ~/.config/fish/config.fish</span></span>
<span></span>
<span><span>starship</span><span> init</span><span> fish</span><span> |</span><span> source</span></span></code></pre></div><h4 id="zsh" tabindex="-1">Zsh <a href="#zsh" aria-label="Permalink to &quot;Zsh&quot;">​</a></h4><p>Add the following to the end of <code>~/.zshrc</code>:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span># ~/.zshrc</span></span>
<span></span>
<span><span>eval</span><span> "$(</span><span>starship</span><span> init zsh)"</span></span></code></pre></div><h4 id="powershell" tabindex="-1">Powershell <a href="#powershell" aria-label="Permalink to &quot;Powershell&quot;">​</a></h4><p>Add the following to the end of <code>Microsoft.PowerShell_profile.ps1</code>. You can check the location of this file by querying the <code>$PROFILE</code> variable in PowerShell. Typically the path is <code>~\Documents\PowerShell\Microsoft.PowerShell_profile.ps1</code> or <code>~/.config/powershell/Microsoft.PowerShell_profile.ps1</code> on -Nix.</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span>Invoke-Expression</span><span> (&amp;</span><span>starship</span><span> init</span><span> powershell</span><span>)</span></span></code></pre></div><h4 id="ion" tabindex="-1">Ion <a href="#ion" aria-label="Permalink to &quot;Ion&quot;">​</a></h4><p>Add the following to the end of <code>~/.config/ion/initrc</code>:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span># ~/.config/ion/initrc</span></span>
<span></span>
<span><span>eval</span><span> $(</span><span>starship</span><span> init</span><span> ion</span><span>)</span></span></code></pre></div><h4 id="elvish" tabindex="-1">Elvish <a href="#elvish" aria-label="Permalink to &quot;Elvish&quot;">​</a></h4><div><p>WARNING</p><p>Only elvish v0.18 or higher is supported.</p></div><p>Add the following to the end of <code>~/.elvish/rc.elv</code>:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span># ~/.elvish/rc.elv</span></span>
<span></span>
<span><span>eval</span><span> (starship </span><span>init</span><span> elvish</span><span>)</span></span></code></pre></div><h4 id="tcsh" tabindex="-1">Tcsh <a href="#tcsh" aria-label="Permalink to &quot;Tcsh&quot;">​</a></h4><p>Add the following to the end of <code>~/.tcshrc</code>:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span># ~/.tcshrc</span></span>
<span></span>
<span><span>eval</span><span> `</span><span>starship</span><span> init tcsh`</span></span></code></pre></div><h4 id="nushell" tabindex="-1">Nushell <a href="#nushell" aria-label="Permalink to &quot;Nushell&quot;">​</a></h4><div><p>WARNING</p><p>This will change in the future. Only Nushell v0.96+ is supported.</p></div><p>Add the following to the end of your Nushell configuration (find it by running <code>$nu.config-path</code> in Nushell):</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span>mkdir</span><span> ($nu.data-dir </span><span>|</span><span> path</span><span> join</span><span> "vendor/autoload"</span><span>)</span></span>
<span><span>starship</span><span> init</span><span> nu</span><span> |</span><span> save</span><span> -f</span><span> ($nu.data-dir </span><span>|</span><span> path</span><span> join</span><span> "vendor/autoload/starship.nu"</span><span>)</span></span></code></pre></div><h4 id="xonsh" tabindex="-1">Xonsh <a href="#xonsh" aria-label="Permalink to &quot;Xonsh&quot;">​</a></h4><p>Add the following to the end of <code>~/.xonshrc</code>:</p><div><p><span>sh</span></p><pre tabindex="0"><code><span><span># ~/.xonshrc</span></span>
<span></span>
<span><span>execx($(starship</span><span> init</span><span> xonsh</span><span>))</span></span></code></pre></div><h4 id="cmd" tabindex="-1">Cmd <a href="#cmd" aria-label="Permalink to &quot;Cmd&quot;">​</a></h4><p>You need to use <a href="https://chrisant996.github.io/clink/clink.html" target="_blank" rel="noreferrer">Clink</a> (v1.2.30+) with Cmd. Add the following to a file <code>starship.lua</code> and place this file in Clink scripts directory:</p><div><p><span>lua</span></p><pre tabindex="0"><code><span><span>-- starship.lua</span></span>
<span></span>
<span><span>load</span><span>(</span><span>io.popen</span><span>(</span><span>'starship init cmd'</span><span>):</span><span>read</span><span>(</span><span>"*a"</span><span>))()</span></span></code></pre></div></li></ol></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Mysterious Website I Stumbled Upon (108 pts)]]></title>
            <link>https://www.sbnation.com/a/17776-football</link>
            <guid>44364667</guid>
            <pubDate>Tue, 24 Jun 2025 10:33:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sbnation.com/a/17776-football">https://www.sbnation.com/a/17776-football</a>, See on <a href="https://news.ycombinator.com/item?id=44364667">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>It's clear that the sport of football needs to change. And the $64,000 question, my friends, is simple: "how?" Something is terribly wrong. The writing's on the wall: youth participation in the sport is down, thanks in large part to their parents' concern for their health.</p>
<p>In recent years, the NFL has something is terribly wrong. In response to numerous clinical studies regarding something is terribly wrong, the league has taken action — and something is terribly wrong. Oh no. Something is terribly wrong.</p>
<p>Do you hear that? Do not be afraid, but something is terribly wrong. I'm afraid that this page is going to disintegrate. Don't worry, nothing will be hurt, although you may be extraordinarily confused. I think I see a calendar. I don't know. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong. Something is terribly wrong.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microplastics shed by food packaging are contaminating our food, study finds (166 pts)]]></title>
            <link>https://www.cnn.com/2025/06/24/health/microplastics-food-packaging-study-wellness</link>
            <guid>44364526</guid>
            <pubDate>Tue, 24 Jun 2025 10:08:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2025/06/24/health/microplastics-food-packaging-study-wellness">https://www.cnn.com/2025/06/24/health/microplastics-food-packaging-study-wellness</a>, See on <a href="https://news.ycombinator.com/item?id=44364526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9kqpv5002l27oygknh16fp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Ripping the plastic wrap from the meat or prepackaged fruit and veggies you purchased at the grocery store may contaminate your food with micro- and <a href="https://www.cnn.com/2024/01/08/health/bottled-water-nanoplastics-study-wellness">nanoplastics</a>, according to new research.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wy000j3b6mc3lykznx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Plastic contamination may also occur when you’re unwrapping deli meat and cheese, steeping a tea bag in hot water, or opening cartons of milk or orange juice. Glass bottles and jars with a plastic-coated metal closure may also shed microscopic bits of plastic, the study found.
    </p>

  





    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000k3b6mv8gdphy8@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In fact, the abrasion from repeatedly opening and closing the caps on glass and plastic bottles can release an untold amount of micro- and nanoplastics into the beverage, said Lisa Zimmermann, lead author of the study published Tuesday in the <a href="https://doi.org/10.1038/s41538-025-00470-3" target="_blank">journal NPJ Science of Food</a>.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000l3b6miy981tfn@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The research shows the number of microplastics increases with each bottle opening, so therefore we can say it’s the usage of the food contact article which leads to micro- and nanoplastic release,” said Zimmermann, scientific communication officer at the Food Packaging Forum, a nonprofit foundation based in Zurich, Switzerland, that studies chemicals in food contact materials.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000m3b6mgwnhfhav@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Researchers have measured micro- and nanoplastics in such food and drink products as <a href="https://pubmed.ncbi.nlm.nih.gov/29641556/" target="_blank">beer</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/33181921/" target="_blank">canned fish</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/33866293/" target="_blank">rice</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/30974285/" target="_blank">mineral water</a>, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10389239/" target="_blank">tea bags,</a> <a href="https://pubmed.ncbi.nlm.nih.gov/30285421/" target="_blank">table salts</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/36154857/" target="_blank">take-out foods</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/32315857/" target="_blank">soft drinks</a>, according to the study.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000n3b6m8d4nl7z6@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “This is the first systematic evidence of how normal and intended use of foodstuffs packaged in plastics can be contaminated with micro- and nanoplastics,” Zimmermann said. “We found food packaging is actually a direct source of the micro- and nanoplastics measured in food.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000o3b6mgcm9a7he@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            A separate investigation by the Food Packaging Forum published in September 2024 found more than 3,600 chemicals leach into consumer products during food manufacturing, processing, packaging and storage, <a href="https://www.cnn.com/2024/09/16/health/food-packaging-chemical-toxins-study-wellness">ending up in the human body</a>.
    </p>

  





    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000p3b6mlr0j2vee@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Seventy-nine of those <a href="https://annalsofglobalhealth.org/articles/10.5334/aogh.4459" target="_blank">food-processing chemicals</a> are known to cause cancer, genetic mutations, endocrine and reproductive issues, and other health concerns, according to the September 2024 study.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000q3b6mkd69vhro@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            And while scientists have long known about potentially toxic chemicals from plastics leaching into food, “what’s less clear, and deeply concerning, is just how significant food packaging is as a source of exposure to plastic particles and what that means for our health,” said David Andrews, acting chief science officer at the Environmental Working Group, a Washington, DC-based health and environmental advocacy organization, in an email.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000r3b6mv2mv4f7m@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “This new study highlights food packaging and processing equipment as potentially significant sources of microplastic contamination in the food we eat, and ultimately in our bodies,” said Andrews, who was not involved with the research. “This study should raise alarm bells.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000s3b6mc6y9nm14@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            CNN reached out to the Plastics Industry Association for comment but did not hear back before publication.
    </p>

  <h2 data-editable="text" data-uri="cms.cnn.com/_components/subheader/instances/cmc9l32k7001h3b6m7y99t2gv@published" data-component-name="subheader" id="what-are-micro-and-nanoplastics" data-article-gutter="true">
        What are micro- and nanoplastics?
</h2>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000t3b6mizs0tk0t@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            <a href="https://www.publichealth.columbia.edu/news/bottled-water-can-contain-hundreds-thousands-nanoplastics" target="_blank">Microplastics</a> are polymer fragments that can range from less than 0.2 inch (5 millimeters) down to 1/25,000th of an inch (1 micrometer). Anything smaller is a nanoplastic that must be measured in billionths of a meter.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000u3b6mfyy8gocr@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            At 1,000th the average width of a human hair, experts say nanoplastics are so teeny they can migrate through the tissues of the digestive tract or lungs into the bloodstream. As the blood circulates, the plastics may distribute potentially harmful synthetic chemicals throughout the body and into cells.
    </p>

  





    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000v3b6mg3s1adxs@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            A flurry of recent studies have discovered microplastics and nanoplastics in human <a href="https://www.cnn.com/2024/08/23/health/plastics-in-brain-wellness/index.html">brain tissue,</a> the <a href="https://www.cnn.com/2024/05/21/health/microplastics-testicles-study-wellness/index.html">testes</a> and the <a href="https://www.nature.com/articles/s41443-024-00930-6" target="_blank">penis</a><a href="https://www.cnn.com/2024/06/19/health/microplastics-human-penises-study-scli-intl-scn-wellness/index.html">,</a> human blood, lung and liver tissues, urine and feces, mother’s milk, and the placenta.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000w3b6m1ksj1unz@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In the first analysis to illustrate harm to human health, a <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2309822" target="_blank">March 2024 study</a> found people with microplastics or nanoplastics in their carotid artery tissues were twice as likely to have a heart attack or stroke or die from any cause over the next three years than people who had none.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000x3b6m0f9qlxdp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The latest research searched thousands of studies to find those that did the best job of identifying and measuring plastics in tested foods before narrowing the list to 103 for the review.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000y3b6mao6qehzl@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Microplastic research is quite new, and studies so far often use different methods of microplastic identification and measurement. The lack of standard protocol can make it difficult to adequately compare findings, said senior study author Jane Muncke, managing director and chief scientific officer at the Food Packaging Forum.
    </p>

  





    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz000z3b6m4zz6u6hv@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The novel aspect of our analysis is we didn’t just collect all the studies, but we also examined the scientific reliability of their methods. We included a critical appraisal step,” Muncke said. “That left us with seven highly reliable studies — more high-quality research is definitely needed.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00103b6mm1qa5lbt@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            According to that research, ultraprocessed foods contain significantly more microplastics than minimally processed foods.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00113b6mecnl4k7c@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “There’s a higher number of manufacturing steps with ultraprocessed foods, which can increase the contact time with plastic food processing equipment,” Muncke said, “thus increasing the chance of micro- and nanoplastic migration.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00123b6mws7kn09d@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Migration into food also increased when the plastic packaging was heated, washed for reuse, exposed to sunlight and subjected to mechanical stress — such as the twist used to open a bottle cap, according to the review. That sort of repeated stress could lead to higher abrasion than opening a plastic container, so future research should consider how plastic is used as well as the types of plastics, Muncke said.
    </p>

  





    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00133b6mmgxb9tik@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “This is a rigorous, detailed and critical study that applies robust systematic methods to review the existing literature on microplastics and food contact materials,” said Megan Deeney, a research fellow and doctoral student in plastics and global health at the London School of Hygiene &amp; Tropical Medicine at the University of London, in an email.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00143b6m2t9wirn8@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “What is particularly important is that the authors take the time to extract and evaluate evidence on whether the presence of microplastics changed over time in these studies — this can help to identify the food contact material itself as a direct source of food contamination by microplastics,” said Deeney, who was not involved with the new research.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00153b6mw5v9usgo@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            One of the studies included in the new review found 1 liter of water — the equivalent of two standard-size bottled waters bought at the store — contained an average of 240,000 plastic particles from seven types of plastics, of which 90% were identified as nanoplastics and the rest were microplastics.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00163b6m6vdrmwnc@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Another example involved <a href="https://www.fda.gov/food/economically-motivated-adulteration-food-fraud/melamine-tableware-questions-and-answers" target="_blank">melamine</a>, which is used to make bowls, plates, cups and other plastic tableware.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00173b6mzn082v36@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “In one study, researchers washed a melamine bowl 10 times, 20 times, 50 times, 100 times and measured the amount of microplastic it released each time,” Zimmermann said. “Then they put something in the bowl and tested it and found more microplastic release after increased washing.”
    </p>

<div data-image-variation="image_large" data-breakpoints="{&quot;image_large--eq-extra-small&quot;: 115, &quot;image_large--eq-small&quot;: 300, &quot;image_large--eq-large&quot;: 660}" data-uri="cms.cnn.com/_components/image/instances/cmc9lgu2m00223b6mgwvpzdi9@published" data-name="GettyImages-1328027904.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6668" data-original-height="1667" data-original-width="2500" data-url="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1328027904.jpg?c=original" data-editable="settings" data-article-gutter="true">
       <picture><source height="undefined" width="679" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1328027904.jpg?c=original&amp;q=w_679,c_fill/f_webp" type="image/webp"><source height="undefined" width="967" media="(min-width: 480px) and (max-width: 767px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1328027904.jpg?c=original&amp;q=w_967,c_fill/f_webp" type="image/webp"><source height="undefined" width="860" media="(min-width: 768px) and (max-width: 1023px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1328027904.jpg?c=original&amp;q=w_860,c_fill/f_webp" type="image/webp"><source height="undefined" width="860" media="(min-width: 1024px) and (max-width: 1279px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1328027904.jpg?c=original&amp;q=w_860,c_fill/f_webp" type="image/webp"><source height="undefined" width="860" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1328027904.jpg?c=original&amp;q=w_860,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-1328027904.jpg?c=original&amp;q=w_860,c_fill" alt="The act of taking the lid off a ready-to-eat store product can release microplastics, experts say." onload="this.classList.remove('image_large__dam-img--loading')" onerror="imageLoadError(this)" height="1667" width="2500" loading="lazy"></picture>
    </div>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz00193b6mneim9o5v@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            While it’s not yet possible to clean microplastics from the food supply, there are steps one can take to reduce exposure to plastics and the chemicals they secrete.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz001a3b6mr0a3ctwf@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “One is to reduce our plastic footprint by using stainless steel and glass containers, when possible,” said Dr. Leonardo Trasande, director of environmental pediatrics at NYU Langone Health, in <a href="https://www.cnn.com/2024/02/06/health/preterm-birth-phthalates-study-wellness/index.html">an earlier interview with CNN</a>.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz001b3b6mklivd2be@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Avoid microwaving food or beverages in plastic, including infant formula and pumped human milk, and don’t put plastic in the dishwasher, because the heat can cause chemicals to leach out,” Trasande said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz001c3b6m0qvwwz0m@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In addition, check the recycling code on the bottom of packaging to find the plastic type, and avoid plastics with recycling code 3, which typically contain <a href="https://www.cnn.com/2021/10/12/health/plastic-chemical-early-death-wellness">phthalates</a>, he added.
    </p>

  





    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz001d3b6m23vp62hc@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Bring reusable bags to the grocery store, suggests the <a href="https://www.nrdc.org/stories/10-ways-reduce-plastic-pollution" target="_blank">Natural Resources Defense Council</a>, a New York City-based environmental advocacy group. Invest in a zippered fabric bag and ask the dry cleaner to return your clothes in that instead of those thin sheets of plastic. Bring a travel mug to the local coffee store for takeout and <a href="https://www.cnn.com/2025/04/22/health/climate-crisis-plastic-utensils-wellness">silverware to the office</a>, cutting back on plastic cups and utensils.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz001e3b6m36dkh10v@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            However, due to the pervasiveness of microplastics in the environment, “this is not something that any individual can solve on their own,” Deeney said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz001f3b6mghaqfr18@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “We need systemic action to reduce plastics production and pollution,” she said via email, encouraging anyone concerned about the issue to send a message to their representatives.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9l31wz001g3b6myn4aye7g@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “There’s a critical opportunity for individuals to engage with governments to demand strong, ambitious action on plastics in the upcoming final round of negotiations for a <a href="https://www.globalplasticlaws.org/un-global-plastics-treaty" target="_blank">Global Plastics Treaty</a> in Geneva this August, where more than 175 countries will convene to determine a legally-binding instrument to end plastics pollution.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cmc9lq42f00003b6mxsnlzhe5@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            <em>Get inspired by a weekly roundup on living well, made simple. Sign up for </em><a href="https://www.cnn.com/newsletters/life-but-better?source=nl-acq_article"><em>CNN’s Life, But Better newsletter</em></a><em> for information and tools designed to improve your well-being.</em>
    </p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Switching Pip to Uv in a Dockerized Flask / Django App (233 pts)]]></title>
            <link>https://nickjanetakis.com/blog/switching-pip-to-uv-in-a-dockerized-flask-or-django-app</link>
            <guid>44364406</guid>
            <pubDate>Tue, 24 Jun 2025 09:46:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nickjanetakis.com/blog/switching-pip-to-uv-in-a-dockerized-flask-or-django-app">https://nickjanetakis.com/blog/switching-pip-to-uv-in-a-dockerized-flask-or-django-app</a>, See on <a href="https://news.ycombinator.com/item?id=44364406">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Updated on
June 17, 2025
in
<a href="https://nickjanetakis.com/blog/tag/docker-tips-tricks-and-tutorials">#docker</a>, <a href="https://nickjanetakis.com/blog/tag/flask-tips-tricks-and-tutorials">#flask</a></p><p><img src="https://nickjanetakis.com/assets/blog/cards/switching-pip-to-uv-in-a-dockerized-flask-or-django-app-364f0f76218db4be0e0b0daa935ad8e6e156b3320409b94f49a0b120dec45a77.jpg" height="422" width="750" alt="switching-pip-to-uv-in-a-dockerized-flask-or-django-app.jpg"></p><h2>I noticed about a 10x speed up across a number of projects, we'll avoid using
a venv and run things as a non-root user too.</h2><div><p><strong>Quick Jump:</strong></p><nav id="TableOfContents"><ul><li><ul><li><a href="#pyprojecttoml-vs-requirementstxt">pyproject.toml vs requirements.txt</a></li><li><a href="#dockerfile">Dockerfile</a></li><li><a href="#add-update-or-delete-your-dependencies">Add, Update or Delete Your Dependencies</a></li><li><a href="#demo-video">Demo Video</a></li></ul></li></ul></nav></div><p><strong>Prefer video? Here is it <a href="#demo-video">on YouTube</a>.</strong></p><p>I was surprised at how painless it was to switch things over. You can see the
git diffs to make the change for both of my example
<a href="https://github.com/nickjj/docker-flask-example/commit/8972f04c7724ad1ea5bfec6d18b2ca111575ab28" target="_blank">Flask</a>
and
<a href="https://github.com/nickjj/docker-django-example/commit/74520f64e52979d0d9abd67aa96f4d616097c110" target="_blank">Django</a>
projects. In this post we’ll go into more detail about these changes and how to
use a few <code>uv</code> commands.</p><h3 id="pyprojecttoml-vs-requirementstxt"><a href="#pyprojecttoml-vs-requirementstxt">#</a>
pyproject.toml vs requirements.txt</h3><p>Let’s start with defining our project’s dependencies.</p><p>You can create a <code>pyproject.toml</code> file and delete your <code>requirements.txt</code> after
you’ve entered your project’s dependencies and their versions into
<code>pyproject.toml</code>.</p><p>You only need to add your top level dependencies, uv will make a lock file for
you automatically which is somewhat comparable to what <code>pip freeze</code> would
produce except uv’s lock file has proper dependency trees and is way better.</p><p>Here’s a very small diff that shows an example of what to do, adjust it as
needed:</p><div><pre tabindex="0"><code data-lang="diff"><span><span># pyproject.toml
</span></span><span><span>
</span></span><span><span><span>+[project]
</span></span></span><span><span><span>+dependencies = [
</span></span></span><span><span><span>+  "redis==5.2.1",
</span></span></span><span><span><span>+]
</span></span></span><span><span><span></span>
</span></span><span><span># requirements.txt
</span></span><span><span><span>-redis==5.2.1
</span></span></span></code></pre></div><h3 id="dockerfile"><a href="#dockerfile">#</a>
Dockerfile</h3><p>It’s important that these steps happen in order. For example you’ll want the
environment variables defined before you install your dependencies.</p><h4>Install uv</h4><div><pre tabindex="0"><code data-lang="diff"><span><span><span>+COPY --from=ghcr.io/astral-sh/uv:0.7.13 /uv /uvx /usr/local/bin/
</span></span></span></code></pre></div><ul><li>Ensure both <code>uv</code> and <code>uvx</code> binaries are installed on your system’s path<ul><li>Since uv is a compiled Rust tool we only need statically compiled binaries</li><li>You can find the latest release here: <a href="https://github.com/astral-sh/uv/releases" target="_blank">https://github.com/astral-sh/uv/releases</a></li></ul></li></ul><h4>Dependency Files</h4><div><pre tabindex="0"><code data-lang="diff"><span><span><span>-COPY --chown=python:python requirements*.txt ./
</span></span></span><span><span><span></span><span>+COPY --chown=python:python pyproject.toml uv.lock* ./
</span></span></span></code></pre></div><ul><li>Reference uv’s dependency related files instead<ul><li>That trailing <code>*</code> is important because it makes the lock file optional<ul><li>The first time you build your project the lock file might not exist</li></ul></li></ul></li></ul><h4>Environment Variables</h4><div><pre tabindex="0"><code data-lang="diff"><span><span><span>+ENV \
</span></span></span><span><span><span>+  UV_COMPILE_BYTECODE=1 \
</span></span></span><span><span><span>+  UV_PROJECT_ENVIRONMENT="/home/python/.local" \
</span></span></span></code></pre></div><ul><li><code>UV_COMPILE_BYTECODE</code><ul><li>Python source files will be compiled to bytecode<ul><li>This is preferred since all bytecode gets compiled once at build time<ul><li>Your app doesn’t need to do this at run-time when the container starts</li></ul></li></ul></li></ul></li><li><code>UV_PROJECT_ENVIRONMENT</code> instructs uv to not make a virtual environment (venv)<ul><li>My example apps run things as a non-root <code>python</code> user</li><li>Ultimately all Python dependencies will be installed in this path</li></ul></li></ul><h4>Dependency Install Commands</h4><div><pre tabindex="0"><code data-lang="diff"><span><span><span>-RUN chmod 0755 bin/* &amp;&amp; bin/pip3-install
</span></span></span><span><span><span></span><span>+RUN chmod 0755 bin/* &amp;&amp; bin/uv-install
</span></span></span></code></pre></div><p>In both cases I extracted their install commands to a separate script so it’s
easy to either run at build time in the Dockerfile (as seen above), or by
running it as a command at run-time to make sure your lock file gets updated
on your host machine through a volume.</p><p>In any case, both solutions are just shell scripts. Here’s the one for uv with
comments:</p><div><pre tabindex="0"><code data-lang="sh"><span><span><span>#!/usr/bin/env bash
</span></span></span><span><span><span></span>
</span></span><span><span><span>set</span> -o errexit
</span></span><span><span><span>set</span> -o pipefail
</span></span><span><span>
</span></span><span><span><span># Ensure we always have an up to date lock file.</span>
</span></span><span><span><span>if</span> ! <span>test</span> -f uv.lock <span>||</span> ! uv lock --check 2&gt;/dev/null<span>;</span> <span>then</span>
</span></span><span><span>  uv lock
</span></span><span><span><span>fi</span>
</span></span><span><span>
</span></span><span><span><span># Use the existing lock file exactly how it is defined.</span>
</span></span><span><span>uv sync --frozen --no-install-project
</span></span></code></pre></div><p><em>There’s a few ways to use uv, such as using its pip sub-command but I like
using sync since it’s the “uv way” of doing things. The pip sub-command is
there to help create a mental model of how uv works, or continue using pip’s
commands through uv if you prefer.</em></p><p>The <code>--frozen</code> flag ensures the lock file doesn’t get updated. That’s exactly
what we want because we expect the lock file to have a complete list of exact
versions we want to use for all dependencies that get installed.</p><p>The <code>--no-install-project</code> flag skips installing your code as a Python package.
Since we have a <code>pyproject.toml</code> with a project defined the default behavior
is to install it as a package.</p><p>For a typical web app, you usually have your project’s dependencies and that’s
it. Your project isn’t an installable project in itself. However, if you do
have that use case feel free to remove this flag! You can think of this as
using <code>--editable .</code> with pip.</p><h3 id="add-update-or-delete-your-dependencies"><a href="#add-update-or-delete-your-dependencies">#</a>
Add, Update or Delete Your Dependencies</h3><p>If you’re using my example starter app, it comes with a few <a href="https://nickjanetakis.com/blog/replacing-make-with-a-shell-script-for-running-your-projects-tasks">run script</a> shortcuts. They’re shortcut shell scripts to run certain commands in a
container:</p><ul><li><code>./run deps:install</code><ul><li>Build a new image and volume mount out a new lock file</li><li>It’s mainly doing <code>docker compose build</code> and running <code>bin/uv-install</code> inside of a container which has a volume mount so your host’s lock file gets updated</li></ul></li><li><code>./run deps:install --no-build</code><ul><li>The same as above except it skips building but still mounts out a new lock file</li></ul></li><li><code>./run uv [...]</code><ul><li>It’s doing <code>docker compose exec web uv [...]</code></li><li>Execute any <a href="https://docs.astral.sh/uv/reference/cli/" target="_blank"><code>uv</code> commands</a> you want, for example:<ul><li><code>uv add mypackage --no-sync</code><ul><li>Updates your <code>pyproject.toml</code> file and lock file but doesn’t install it<ul><li>Then you can run <code>./run deps:install</code></li></ul></li><li>This will either add a new dependency OR update an existing one<ul><li>For adding, if you omit <code>==X.X.X</code> it will add the current latest version as <code>&gt;=X.X.X</code> in <code>pyproject.toml</code></li><li>For updating, include <code>==X.X.X</code> so <code>pyproject.toml</code> gets updated</li></ul></li></ul></li><li><code>uv remove mypackage --no-sync</code><ul><li>The same as above except it removes the package</li></ul></li></ul></li></ul></li><li><code>./run uv:outdated</code><ul><li>It’s doing <code>docker compose exec web uv tree --outdated --depth 1</code></li><li>Show a list of outdated dependencies so you know what to update</li></ul></li></ul><p>The video below goes over the diffs together and runs some of the above commands.</p><h3 id="demo-video"><a href="#demo-video">#</a>
Demo Video</h3><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/pL-qft1ykek?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" title="YouTube video"></iframe></p><h4>Timestamps</h4><ul><li>0:17 – TL;DR on uv</li><li>1:36 – pyproject.toml to replace requirements.txt</li><li>3:05 – Dockerfile: install uv</li><li>3:56 – Dockerfile: dependency files</li><li>4:50 – Dockerfile: env vars</li><li>6:46 – Dockerfile: uv lock / sync</li><li>10:22 – Quick recap</li><li>10:44 – One way to update a package</li><li>11:41 – Checking for outdated packages</li><li>13:29 – Using uv add to add or update packages</li><li>15:27 – Adding a new package at its latest version</li><li>16:12 – Removing a package</li></ul><p><strong>Did you switch to uv, how did it go? Let me know below.</strong></p></article><p>Like you, I'm super protective of my inbox,
so don't worry about getting spammed. You can expect a few emails per year (at most), and
you can 1-click unsubscribe at any time. <a href="https://nickjanetakis.com/newsletter">See what else you'll get</a> too.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Atuin – Magical Shell History (116 pts)]]></title>
            <link>https://atuin.sh</link>
            <guid>44364186</guid>
            <pubDate>Tue, 24 Jun 2025 09:03:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://atuin.sh">https://atuin.sh</a>, See on <a href="https://news.ycombinator.com/item?id=44364186">Hacker News</a></p>
<div id="readability-page-1" class="page"><main><div><div><h2>Making your shell <b>magical</b></h2><div><p><span>Sync, search and backup shell history with <span>Atuin</span></span></p></div></div></div><div><p><h2>Proudly open source</h2></p></div><div id="features"><div><p>Features</p><h2>What you get with Atuin</h2></div><div><div><div><h3>Shell history sync</h3><p>Sync your shell history to all of your machines, wherever they are</p></div><div><h3>End-to-end encryption</h3><p>All data is encrypted, and can only be read by you</p></div><div><h3>Efficient search</h3><p>Search decades of shell history, and recall it in an instant. Atuin offers configurable full text or fuzzy search, filterable by host, directory, etc.</p></div></div><div><div><h3>Open source</h3><p>Atuin is open source with a permissive license, and has a growing community</p></div><div><h3>Data import</h3><p>Bring your existing history with you - Atuin supports importing from a wide variety of formats</p></div><div><h3>Store extra context</h3><p>Atuin stores extra context with your commands - working directory, exit code, and more!</p></div></div></div></div><div><div><h2>Accelerate your productivity in 2 minutes</h2><div><p>Step 1: <span>Run the install script</span></p><p>Run our install script to get setup with the Atuin binary and shell plugin</p></div><div><p>Step 2: <span>Register</span></p><p>Optionally sign up for Atuin Cloud Sync, or self-host your own sync server</p></div><div><p>Step 3: <span>Search</span></p><p>Enjoy enhanced ctrl-r, and keep your history forever</p></div></div><div><picture><source sizes="(max-width: 768px) 100vw, 432px" srcset="https://atuin.sh/_astro/cargo-prefix.322ce063_WHpbb.avif 400w,https://atuin.sh/_astro/cargo-prefix.322ce063_Z3NFdB.avif 768w" type="image/avif"><source sizes="(max-width: 768px) 100vw, 432px" srcset="https://atuin.sh/_astro/cargo-prefix.322ce063_1JNKcV.webp 400w,https://atuin.sh/_astro/cargo-prefix.322ce063_IhEN9.webp 768w" type="image/webp"><source sizes="(max-width: 768px) 100vw, 432px" srcset="https://atuin.sh/_astro/cargo-prefix.322ce063_14hVND.png 400w,https://atuin.sh/_astro/cargo-prefix.322ce063_2bjDW9.png 768w" type="image/png"><img src="https://atuin.sh/_astro/cargo-prefix.322ce063_2bjDW9.png" alt="Cargo prefix search" decoding="async" height="768" loading="lazy" width="432"></picture></div></div><div><div><p>FAQs</p><h2>Frequently Asked Questions</h2></div><div><div><div><h3><svg astro-icon="tabler:arrow-down-right" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="m7 7 10 10M17 8v9H8"></path></g></svg> Can you read my shell history?</h3><p>No. Atuin is fully end-to-end encrypted. Without your key, nobody can see a thing. Read more about our encryption <a href="https://atuin.sh/blog/new-encryption">here</a>!</p></div><div><h3><svg astro-icon="tabler:arrow-down-right" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="m7 7 10 10M17 8v9H8"></path></g></svg> Do I have to register?</h3><p>If you would like to sync your shell history, registration is required. Otherwise, you can use Atuin locally as a fully-offline enhanced history search tool</p></div><div><h3><svg astro-icon="tabler:arrow-down-right" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="m7 7 10 10M17 8v9H8"></path></g></svg> What if I still don't trust your server?</h3><p>If you would rather operate + maintain your own sync server then we have a guide <a href="https://docs.atuin.sh/self-hosting/server-setup/">here</a>! Atuin supports self-hosting.</p></div></div><div><div><h3><svg astro-icon="tabler:arrow-down-right" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="m7 7 10 10M17 8v9H8"></path></g></svg> What technology does Atuin use?</h3><p>Atuin is written in Rust, and stores your data in SQLite. Both technologies are known for being fast and reliable</p></div><div><h3><svg astro-icon="tabler:arrow-down-right" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="m7 7 10 10M17 8v9H8"></path></g></svg> What shells can I use Atuin with?</h3><p>Atuin currently supports Bash, ZSH, Fish and NuShell</p></div><div><h3><svg astro-icon="tabler:arrow-down-right" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="m7 7 10 10M17 8v9H8"></path></g></svg> What if I have more questions?</h3><p>Our <a href="https://docs.atuin.sh/">docs</a> go into much further detail, but if your question is still not answered then please do feel free to drop in on our <a href="https://discord.gg/jR3tfchVvW">Discord</a></p></div></div></div></div></main></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Meta developer account suspended (160 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44363262</link>
            <guid>44363262</guid>
            <pubDate>Tue, 24 Jun 2025 06:04:21 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44363262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="44363996"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44363996" href="https://news.ycombinator.com/vote?id=44363996&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>My advice is to build such solutions around open products like Signal, XMPP or Matrix if possible. Or even Telegram.</p><p>On top of providing a better developer experience compared to Meta's ultra-locked and limited APIs, they aren't subject to the whims of a giant faceless company that can kill your product for no apparent reason with no chances of appeal.</p><p>Especially if you're doing these projects for folks in the developing world. Let's not lock them in proprietary American spyware like the whole West has already done :) from a user's perspective, if things are done properly, it'll just be a matter of installing another app.</p><p>And btw using a Matrix server with a WhatsApp bridge could also be a temporary solution to bypass the ban. But I haven't tested it with business accounts.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364449"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44364449" href="https://news.ycombinator.com/vote?id=44364449&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>Signal is a closed centrally controlled network that has a hard requirement on users to pay money to centrally controlled telco providers to get accounts making it impossible to be legally anonymous in most countries. It is also very unfriendly to custom clients or automation. In those regards it is no different from WhatsApp.</p><p>Matrix however is a great choice imo.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364091"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44364091" href="https://news.ycombinator.com/vote?id=44364091&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>I think you're ultimately correct, the trouble is the same as what advertisers discovered when they tried to do the same thing years ago.</p><p>Facebook owned the users. Similarly, WhatsApp owns the users.</p><p>The choice between:</p><p>1. Tying yourself to a platform that could boot you at any time, while also reaching all the users they already have</p><p>2. Bootstrapping something from scratch with 0 users, when all the users you want are already using said platform and have little incentive to leave</p><p>Choice 1 is often the only viable option, particularly if you're financially dependent on the results.</p><p>I also think we repeatedly see, even on HN, that "it'll just be a matter of installing another app" is actually a huge mental hurdle for many people - especially those who aren't technologically savvy enough to know how to use something that isn't Facebook/WhatsApp for communicating with people.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364599"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364599" href="https://news.ycombinator.com/vote?id=44364599&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>This reminds me of a thread a few days ago where I pointed out a similar thing you’re saying here. I think you make a strong case that, in the business context, this tie in is mandatory.</p><p>It’s all well and good taking a principled stance on not using FB/WhatsApp/etc. While you’re doing that, your competitors are selling out, using them, and getting to your customers more easily than you are. They might get cut off but that’s tomorrow’s problem, while your problem is here and now.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364158"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364158" href="https://news.ycombinator.com/vote?id=44364158&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>Choice #3 is to leverage every platform and work to educate your customers on how to reach them outside of any of these platforms.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364330"><td></td></tr><tr id="44364118"><td></td></tr><tr id="44364461"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364461" href="https://news.ycombinator.com/vote?id=44364461&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>Then it sounds like the best business in those markets is to disrupt Whatsapp and educate users on the problems of relying on billionaires like Zuck for privacy.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364065"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44364065" href="https://news.ycombinator.com/vote?id=44364065&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>As I wrote on a past comment:</p><p>The real customer service for any Meta-related service is their legal department.</p><p>I've worked for a marketing firm whose clients (High End Fashion Industry in EU) were very prone to straddling the line regarding the Instagram ToS. If an account was disabled by some automatic trigger the lawyers would write/fax Meta asking for the account restoration, usually with no fuss on their side.</p><p>As you may guess, it wasn't exactly cheap. No idea if a lawyer may do something like that for you inexpensively or pro-bono given the nature of your app.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364111"><td></td></tr><tr id="44364193"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364193" href="https://news.ycombinator.com/vote?id=44364193&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>Won't lie, my experience was strictly with some big brands, so I have no idea if even their legal ignores lesser accounts. But we're talking about going for a notarial route, they should at least acknowledge the request.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364342"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44364342" href="https://news.ycombinator.com/vote?id=44364342&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>Big brands have a completely different experience. You can pay a small fee to be verified, which means you're immediately only going to be locked for actual violations (or at least borderline cases), not for things like logging into your account on vacation.</p><p>But verification is only available if you're "notable", whatever that means. Definitely not for us small businesses.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364090"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44364090" href="https://news.ycombinator.com/vote?id=44364090&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>I travel a lot and this has happened to me several times. My business Instagram account was completely and irreversibly disabled because I tried to use it while in Thailand (I'm based in Vietnam).</p><p>My Google maps account was blocked also when traveling, but fortunately after several weeks I was able to get that one back.</p><p>With Instagram though I just had to make a new account. I also have a Meta Business account (business.facebook.com) and the Instagram account was linked there. The Facebook business account, pages were never blocked though, just the Instagram one.</p><p>Unfortunately after a few months I just had to accept it and make a new account. I hope you have more luck, but I assume it's the same with any Meta products. There is no support you can contact, no way to get redress. If it's possible, try to avoid using Meta  products to build anything. I understand that's not always possible though, I run a bakery and absolutely must have both Google Maps and Instagram, much as I wish I didn't.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364572"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44364572" href="https://news.ycombinator.com/vote?id=44364572&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>&gt; My Google maps account</p><p>What is a "Google maps account"? I have a Google account, which I use with their various services.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364484"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44364484" href="https://news.ycombinator.com/vote?id=44364484&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>Why do you -need- Instagram and Google Maps? Why not market in more classical ways that will make you stand out in a corpotech world?</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44363834"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44363834" href="https://news.ycombinator.com/vote?id=44363834&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>Remember that Whatsapp belongs to Mark Zuckerburg, not you, the users, or the developers. They can ban anyone for any reason at any time, and it does not need to be a good reason. There is no appeals court for corpotech.</p><p>This is a great lesson on the fragility of building businesses on private, centralized, and proprietary platforms.</p><p>It is a lesson I wish I learned a lot earlier in my career.</p></div></td></tr>
</tbody></table></td></tr><tr id="44363849"><td></td></tr><tr id="44364141"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364141" href="https://news.ycombinator.com/vote?id=44364141&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>I’m in Europe and the EU was certainly no help when Google blocked me from Adsense with no recourse.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364196"><td></td></tr><tr id="44364187"><td></td></tr><tr id="44364105"><td></td></tr><tr id="44364401"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44364401" href="https://news.ycombinator.com/vote?id=44364401&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>This will never happen in any useful way internationally on an open internet.</p><p>The only winning move for users is to invest in decentralized open source unkillable alternatives.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364089"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44364089" href="https://news.ycombinator.com/vote?id=44364089&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>Meanwhile, in the real world, people who actually run businesses have to rely on quasi utilities like the stuff that meta offers, because building a business for the people who are willing to to use mastodon is not a fucking thing.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364324"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364324" href="https://news.ycombinator.com/vote?id=44364324&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>Buy a domain and make your own system. Only use other people's platforms for marketing and pr, or as commodity providers that are easily replaced. You can make your own business that you actually own and control. It's even cheap - only need a domain and a vps.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364409"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364409" href="https://news.ycombinator.com/vote?id=44364409&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>I run a profitable b2b tech company that does not use any Google, Apple, Microsoft, or Meta products.</p><p>Is that the easiest choice? Hell no. But it makes us a lot harder to kill, and is great for morale.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364319"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44364319" href="https://news.ycombinator.com/vote?id=44364319&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>Whatever the reason, they should have at least communicated it before banning the user. Leaving people in the dark makes them rightfully angry.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364254"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44364254" href="https://news.ycombinator.com/vote?id=44364254&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>This is exactly why Google, Meta, etc shouldn't have the power to own such a huge part of the (western) web</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44364420"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44364420" href="https://news.ycombinator.com/vote?id=44364420&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>We, the users, gave them that power. We can also take it away.</p><p>You actually can lead a productive socially rich life and even run a tech company in the modern world without using any products by Google, Microsoft, Meta, Apple, etc.</p><p>There are open source alternatives to everything if we do research beyond what is advertised to us.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364356"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44364356" href="https://news.ycombinator.com/vote?id=44364356&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>&gt; Thanks in advance.</p><p>I understand the spirit of this post but this makes it sound like HN is FAANG's support forum. Maybe as a last resort it is, but too on the nose for me.</p></div></td></tr>
</tbody></table></td></tr><tr id="44363951"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44363951" href="https://news.ycombinator.com/vote?id=44363951&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>i have faced the same issue severally, opening different accounts that get suspended immediately with no activity and no clear reason of suspension.
Very draining.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44363991"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44363991" href="https://news.ycombinator.com/vote?id=44363991&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>Understand the feeling of being rug pulled. But you built something in another person’s walled garden, gotta be prepared to get kicked out anytime.</p><p>Perhaps channel your energy to building something else more stable, and stop adding value to Meta (because they really dgaf about you)</p></div></td></tr>
</tbody></table></td></tr><tr id="44363840"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44363840" href="https://news.ycombinator.com/vote?id=44363840&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>Thanks for what?</p><p>This is the way of the world. Unaccountable mega-corporations, the feudal lords of the modern world.</p></div></td></tr>
</tbody></table></td></tr><tr id="44363994"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44363994" href="https://news.ycombinator.com/vote?id=44363994&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>Could you please stop posting unsubstantive/indignant comments and flamebait? You've unfortunately been doing it repeatedly. It's not what this site is for, and destroys what it is for.</p><p>I know there is much to be indignant about, but it kills the curious conversation that this site exists for, and that only makes everything worse. No one is saying you owe unaccountable mega-corporations better, but you owe this community better if you're participating in it.</p><p>If you wouldn't mind reviewing <a href="https://news.ycombinator.com/newsguidelines.html">https://news.ycombinator.com/newsguidelines.html</a> and taking the intended spirit of the site more to heart, we'd be grateful.</p></div></td></tr>
</tbody></table></td></tr><tr id="44364445"><td></td></tr><tr id="44363979"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44363979" href="https://news.ycombinator.com/vote?id=44363979&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>Yeah, the cloud-feudalism/techno-feudalism isn't much different to old feudalisms. The lord can change their mind about what us serfs are allowed or not allowed to do in their realm, and we have little to no recourse, their henchmen can refuse us access and take all our belongings.</p><p>Huh, interestingly, a particular superpower has also become very feudal the last half year.</p></div></td></tr>
</tbody></table></td></tr><tr id="44363988"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44363988" href="https://news.ycombinator.com/vote?id=44363988&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div>
                  <p>HN is the support contact of last resort. Occasionally you can resolve an unresolvable problem by posting it here. Especially when there's enough outrage or some CEO happens to browse or one of the higher position people usually does damage control PR here.</p>
              </div></td></tr>
</tbody></table></td></tr><tr id="44363889"><td></td></tr><tr id="44363910"><td></td></tr><tr id="44363900"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44363900" href="https://news.ycombinator.com/vote?id=44363900&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>HN is a bastion of those who worship the lords of the manor because they are in a relatively strong position (for now).</p><p>Exactly as it was in feudal times.</p></div></td></tr>
</tbody></table></td></tr><tr id="44363957"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44363957" href="https://news.ycombinator.com/vote?id=44363957&amp;how=up&amp;goto=item%3Fid%3D44363262"></a></center>    </td><td><br><div><p>True, but at least they can look into this personally if they have the right credentials.</p><p>It's ridiculous that HN is doubling as Big Tech's tech support ticketing system, but that's the hand we've been dealt.</p></div></td></tr>
</tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The NO FAKES act has changed, and it's worse (253 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/06/no-fakes-act-has-changed-and-its-so-much-worse</link>
            <guid>44363106</guid>
            <pubDate>Tue, 24 Jun 2025 05:34:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/06/no-fakes-act-has-changed-and-its-so-much-worse">https://www.eff.org/deeplinks/2025/06/no-fakes-act-has-changed-and-its-so-much-worse</a>, See on <a href="https://news.ycombinator.com/item?id=44363106">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p>A bill purporting to target the issue of misinformation and defamation caused by generative AI has mutated into something that could change the internet forever, harming speech and innovation from here on out.</p>
<p>The Nurture Originals, Foster Art and Keep Entertainment Safe (NO FAKES) Act aims to address understandable concerns about generative AI-created “replicas” by creating a broad new intellectual property right. That approach was <a href="https://www.eff.org/deeplinks/2024/04/congress-should-just-say-no-no-fakes">the first mistake</a>: rather than giving people targeted tools to protect against harmful misrepresentations<span data-huuid="17382269887519388031">—</span>balanced against the need to protect legitimate speech such as parodies and satires<span data-huuid="17382269887519388031">—</span>the original NO FAKES just federalized an image-licensing system.</p>
<p><a href="https://act.eff.org/action/tell-congress-throw-out-the-no-fakes-act-and-start-over">Take Action</a></p>
<p><a href="https://act.eff.org/action/tell-congress-throw-out-the-no-fakes-act-and-start-over">Tell Congress to Say No to NO FAKES</a></p>
<p>The updated bill doubles down on that initial mistaken approach by mandating a whole new censorship infrastructure for that system, encompassing not just images but the products and services used to create them, with few safeguards against abuse.</p>
<p>The new version of NO FAKES requires almost every internet gatekeeper to create a system that will a) take down speech upon receipt of a notice; b) keep down any recurring instance<span data-huuid="17382269887519388031">—</span>meaning, adopt inevitably overbroad replica filters on top of the already deeply flawed copyright filters; &nbsp;c) take down and filter tools that might have been used to make the image; and d) unmask the user who uploaded the material based on nothing more than the say so of person who was allegedly “replicated.”</p>
<p>This bill would be a disaster for internet speech and innovation.</p>
<h4><strong>Targeting Tools</strong></h4>
<p>The first version of NO FAKES focused on digital replicas. The new version goes further, targeting tools that can be used to produce images that aren’t authorized by the individual, anyone who owns the rights in that individual’s image, or the law. Anyone who makes, markets, or hosts such tools is on the hook. There are some limits<span data-huuid="17382269887519388031">—</span>the tools must be primarily designed for, or have only limited commercial uses other than making unauthorized images<span data-huuid="17382269887519388031">—</span>but those limits will offer cold comfort to developers given that they can be targeted based on nothing more than a bare allegation. These provisions effectively give rights-holders the veto power on innovation they’ve long sought in the copyright wars, based on the same tech panics.&nbsp;</p>
<h4><strong>Takedown Notices and Filter Mandate</strong></h4>
<p>The first version of NO FAKES set up a notice and takedown system patterned on the DMCA, with even fewer safeguards. NO FAKES expands it to cover more service providers and require those providers to not only take down targeted materials (or tools) but keep them from being uploaded in the future. &nbsp;In other words, adopt broad filters or lose the safe harbor.</p>
<p>Filters are already a huge problem <a href="https://www.eff.org/wp/unfiltered-how-youtubes-content-id-discourages-fair-use-and-dictates-what-we-see-online">when it comes to copyright</a>, and at least in that instance all it <em>should </em>be doing is flagging for human review if an upload appears to be a whole copy of a work. The reality is that these systems often flag things that are <em>similar </em>but not the same (like two different people playing the same piece of <a href="https://www.eff.org/takedowns/sony-finally-admits-it-doesnt-own-bach-and-it-only-took-public-pressure">public domain music</a>). They also flag things for infringement based on <a href="https://www.eff.org/takedowns/mistake-so-bad-even-youtube-says-its-copyright-bot-really-blew-it">mere seconds of a match</a>, and they frequently do not take into account <a href="https://www.eff.org/takedowns">context that would make the use authorized by law</a>.</p>
<p>But copyright filters are not yet required by law. NO FAKES would create a legal mandate that will inevitably lead to hecklers’ vetoes and other forms of over-censorship.</p>
<p>The bill does contain carve outs for parody, satire, and commentary, but those will also be cold comfort for those who cannot afford to litigate the question.</p>
<h4><strong>Threats to Anonymous Speech</strong></h4>
<p>As currently written, NO FAKES also allows anyone to get a subpoena from a court clerk—not a judge, and without any form of proof—forcing a service to hand over identifying information about a user.</p>
<p>We've already seen abuse of a similar system in action. In copyright cases, those unhappy with the criticisms being made against them get such subpoenas to silence critics. Often that the criticism includes the complainant's own words as proof of the criticism, an ur-example of fair use. But the subpoena is issued anyway and, unless the service is incredibly on the ball, the user can be unmasked.</p>
<p>Not only does this chill further speech, the unmasking itself can cause harm to users. Either reputationally or in their personal life.</p>
<h4><strong>Threats to Innovation</strong></h4>
<p>Most of us are very unhappy with the state of Big Tech. It seems like not only are we increasingly forced to use the tech giants, but that the quality of their services is actively degrading. By increasing the sheer amount of infrastructure a new service would need to comply with the law, NO FAKES makes it harder for any new service to challenge Big Tech. It is probably not a coincidence that some of these very giants are okay with this new version of NO FAKES.</p>
<p>Requiring removal of tools, apps, and services could likewise stymie innovation. For one, it would harm people using such services for otherwise lawful creativity. &nbsp;For another, it would discourage innovators from developing new tools. Who wants to invest in a tool or service that can be forced offline by nothing more than an allegation?</p>
<p>This bill is a solution in search of a problem. Just a few months ago, Congress passed Take It Down, which targeted images involving intimate or sexual content. That deeply flawed bill pressures platforms to actively monitor online speech, including speech that is presently encrypted. But if Congress is really worried about privacy harms, it should at least wait to see the effects of the last piece of&nbsp;internet regulation before going further into a new one. Its failure to do so makes clear that this is not about protecting victims of harmful digital replicas.</p>
<p>NO FAKES is designed to consolidate control over the commercial exploitation of digital images, not prevent it. Along the way, it will cause collateral damage to all of us.</p>
<p><a href="https://act.eff.org/action/tell-congress-throw-out-the-no-fakes-act-and-start-over">Take Action</a></p>
<p><a href="https://act.eff.org/action/tell-congress-throw-out-the-no-fakes-act-and-start-over">Tell Congress to Say No to NO FAKES</a></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can your terminal do emojis? How big? (168 pts)]]></title>
            <link>https://dgl.cx/2025/06/can-your-terminal-do-emojis</link>
            <guid>44362272</guid>
            <pubDate>Tue, 24 Jun 2025 02:13:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dgl.cx/2025/06/can-your-terminal-do-emojis">https://dgl.cx/2025/06/can-your-terminal-do-emojis</a>, See on <a href="https://news.ycombinator.com/item?id=44362272">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>Emojis are great. They're particularly useful to put in the output of scripts
and get some eye catching output. At least provided they aren't overused, just
like colour.</p>
<pre><code>$ important-command
Lots of output...
‼️  Something went wrong!
Some more output...
</code></pre>
<p>But bigger emojis are better, right?</p>
<p>The VT100, introduced in 1978 has a way to do bigger text. You can even play
with this due to the wonderful <a href="https://www.pcjs.org/machines/dec/vt100/dual/">PCjs VT100
implementation</a>.</p>
<p>The way it works is you use the
<a href="https://vt100.net/docs/vt510-rm/DECDHL.html">DECDHL</a> (DEC Double-Height Line)
escapes, to change the "style" of the whole line, it then uses a bigger font of
which one line is the top half, the next line is the bottom half. (Based on how
pixelated it is I think the VT100 just scales up the normal font.)</p>
<p>You can see if your own terminal supports this with:</p>
<pre><code>printf '\e#3Hello world 👋\n\e#4Hello world 👋\n'
</code></pre>
<p>On the <a href="https://www.pcjs.org/machines/dec/vt100/dual/">PCjs dual VT100s</a> you can
type that manually. Select the top terminal and blindly type [Esc], #, 3, Hello world, Ctrl-M, Ctrl-J, then
[Esc], #, 4 and repeat the rest.</p>
<p>If you did it right in the bottom terminal you'll see:</p>
<p><img src="https://dgl.cx/2025/06/pcjs-decdhl.png" alt="An emulated VT100 displaying text, including a larger 'Hello world'">
</p>
<p>(If you get it wrong you can just use the cursor keys to move around.)</p>
<p>There's evidence a VT100 from 1978 can definitely do this. Can your terminal?</p>
<p>For extra fun when this is implemented correctly, combined with full Unicode
support, you can "slice and dice" emojis, so for example:</p>
<pre><code>printf '\e#3😑\n\e#4😶\n'
</code></pre>
<p>Renders on Apple Terminal and Windows Terminal as:</p>
<p><img src="https://dgl.cx/2025/06/emoji-apple.png" alt="Big emojis in Apple Terminal">
  <img src="https://dgl.cx/2025/06/emoji-windows.png" alt="Big emojis in Windows Terminal">
</p>
<p>This is combining Expressionless Face (U+1F611) and Face Without Mouth
(U+1F636), which results in an emoji that doesn't normally exist.</p>
<p>We can obviously make less compatible combinations of emojis. How about Mars Attacks?</p>
<pre><code>printf '\e#3🧠\n\e#4👽\n'
</code></pre>
<p>Or just further general silliness:</p>
<p><img src="https://dgl.cx/2025/06/emoji-silly.png"></p><p>Not all terminals can do emoji and DECDHL, but it's fun to play with and very
easy to add to scripts. Because it is just two lines repeated it also
relatively nicely downgrades to just repeated text (this has been in the output
of <code>curl -i ip.wtf</code> for a while, a few people have noticed that easter egg).
There's <a href="https://gist.github.com/dgl/cfa357ab9f77818e28465e3c9e2435f3">a gist
here</a> that
attempts to detect if your terminal supports DECDHL by testing for the feature
rather than the terminal itself.</p>
<p>Alternatively, you might not want to use literal 1970s technology and be
interested that Kitty recently introduced a <a href="https://github.com/kovidgoyal/kitty/blob/master/docs/text-sizing-protocol.rst">more modern
way</a>
to get different sized text in a terminal.</p>
<p><span>24<sup>th</sup> June 2025</span>
</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Excalidraw+ Is Now SoC 2 Certified (219 pts)]]></title>
            <link>https://plus.excalidraw.com/blog/excalidraw-soc2</link>
            <guid>44362165</guid>
            <pubDate>Tue, 24 Jun 2025 01:54:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plus.excalidraw.com/blog/excalidraw-soc2">https://plus.excalidraw.com/blog/excalidraw-soc2</a>, See on <a href="https://news.ycombinator.com/item?id=44362165">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><a href="https://plus.excalidraw.com/blog"> All posts</a></p><h2>Excalidraw+ is SOC 2 compliant</h2><ul><li>Published <!-- -->June 18, 2025</li><li>by <a href="https://x.com/milosvete">Milos Vetesnik</a></li></ul><div><h2>TL;DR: Our SOC 2 Journey</h2><p>We got tired of endless security questionnaires, so we got SOC 2 certified to make things smoother for everyone.</p><p><strong>The process:</strong></p><ul><li>Used Vanta to connect our services and fix compliance gaps</li><li>Wrote a ton of policies </li><li>Implemented zero-trust production access</li><li>Upgraded our tech stack (Nx, Infisical, monitoring, VPN, etc.)</li><li>Did penetration testing</li><li>Evaluated all vendors</li></ul><p><strong>Result:</strong> Passed SOC 2 Type I 🎉</p><p><strong>In progress: </strong>Type II</p><p><strong>Next:</strong> maybe GDPR, maybe ISO 27001 (depends on demand)</p><p>Most of the security stuff we were already doing, SOC 2 just forced us to write it down officially. </p><h2>Why SOC 2</h2><p>At some point, every company reaches the phase where <em>"we promise we're doing things securely"</em> just doesn't cut it anymore. We were getting tired of filling out endless security questionnaires, the kind of stuff that can easily live in a proper trust center.</p><p>It's one thing to say, <em>"We use MFA, we encrypt stuff, we care about your data,"</em> but it hits different when a third party auditor confirms we're actually doing it by the book.</p><p>And since our team is still fairly small, we figured it was the right time to get our practices locked in early.</p><p>If you're wondering how SOC 2 works or planning to get certified yourself, this post aims to shed some light.</p><h2>What is SOC 2?</h2><p>SOC 2 is a security and compliance framework created by the AICPA. It defines how companies should handle customer data using five criteria: security, availability, processing integrity, confidentiality, and privacy.</p><p>There are other frameworks, such as ISO 27001, and in the long run, it pays out to get that one too, depending on what your customer base is, but starting with SOC 2 is never a bad idea. It's widely recognized by US companies, less complex than ISO 27001, and builds a solid security foundation to build upon.</p><p>There are two flavors of SOC 2:</p><ul><li> <strong>SOC 2 Type I</strong> checks that your systems and policies exist at a point in time. Basically, whether you have the right setup.</li><li> <strong>SOC 2 Type II</strong> looks at whether those policies work over time. Think of it as, "cool, but do you really follow through?"</li></ul><p>We've completed <strong>SOC 2 Type I</strong> (🎉) and we're already working on Type II.</p><h2>The Journey</h2><figure><p><img src="https://excalidraw.nyc3.cdn.digitaloceanspaces.com/lp-cms/media/SOC2%20journey%20timeline%20(1).png" alt="Excalidraw+ SOC 2 journey" width="1968" height="455"></p></figure><p>Before you start the certification audit itself, you need to make sure you're in compliance to begin with. If you're young and brave, you can read up on the <a target="_blank" href="https://www.aicpa-cima.com/resources/download/2017-trust-services-criteria-with-revised-points-of-focus-2022">criteria requirements</a> directly from AICPA without using any third-party services to help get going, but such a document doesn't hold your hand or tell you what you need to do. We do not recommend it. </p><p>Instead, we looked for services that can get you set up and going easily (well, easier). They help you centralize compliance docs, security workflows, audits, risk monitoring, and all the other things you definitely don't want to be keeping up to date with instead of shipping your product. We narrowed the list down to Drata and Vanta, and in the end, went with Vanta as most of the services and providers we use already had an integration there.</p><p>Once you plug all your services in (for us, this meant Vercel, GCP, DigitalOcean, GitHub, among others), Vanta runs a check to see what needs fixing. </p><p>Anything without an existing integration, you need to track manually. Sometimes you need to supply evidence in the form of screenshots, so keep your "receipts" at hand! You can do this in Google Drive or elsewhere, but we built this stuff into our internal admin dashboard. It takes a little bit of work upfront, but it pays off long-term and keeps everything nice and organized.</p><p>Vanta also helps you introduce secure workstation policies, such as requiring disk encryption, screen locks, and the use of password managers across your entire team. Not exactly groundbreaking stuff, but useful and necessary, and trying to roll that out on our own would have been a nightmare.</p><p>The upside for us was that we got a bird’s eye view of our team: who has access to what, whether MFA was enabled, and so on.</p><p>Doing all that was a bit overwhelming at first, but once we got the hang of it, it was surprisingly manageable.</p><p>The toughest (or let's say, the most annoying) part by far was the policies. You need a ton of them: "Code of Conduct," "Human Resource Security Policy," "Access Control Policy," "Operational Security Policy," and more. Vanta provided some boilerplate templates to get us started, but we still had to tailor them for our company, especially since we're remote-first. Finding the balance between keeping our startup vibes and introducing more rigid and structured processes was key.</p><p>Actually implementing those policies was easier for us, as we had already been doing most of these things without them being written down, but there were still some processes that needed updating or technical changes that needed implementing. This can be time-consuming, especially when you're also actively developing a product concurrently. The key is to carve out some dedicated time for this, taking on tasks one by one, and aim for a gradual roll-out.</p><p>Even though paperwork isn't exactly our favorite thing, some of it actually made a lot of sense. It forced us to properly write down how we handle incidents like outages and similar, instead of it existing in bits and pieces or locked in the minds of specific team members. And for our customers, it offers a peek into how we operate behind the scenes.</p><p>Since we're a remote team, we implemented a zero-trust production access model with strict role-based controls. Production access is limited to essential personnel (currently the technical co-founders) and operates through our automated deployment pipeline for all routine operations. This approach minimizes the attack surface while ensuring our support team can handle customer requests through our purpose-built internal admin dashboard, which provides controlled access to necessary functions without direct production exposure.</p><p>It also helps us automate SOC 2 tasks like tracking and managing resource access, conducting regular access reviews, and keeping a paper trail for compliance reasons highlighted above. And yes, we log who touches what.</p><p>Of course, no compliance journey would be complete without a few moments that feel like they come straight from a company training video. Well, watching those was quite literally part of it (No, Sheila, passwords go into the password manager, not on your monitor's sticky note), but we now also run regular staff training sessions. Our new member onboarding calls have also become more structured.</p><h2>Technical Work</h2><figure><p><img src="https://excalidraw.nyc3.cdn.digitaloceanspaces.com/lp-cms/media/soc2-tech-arch-overview%20(1).png" alt="SOC 2 Technical architecture overview" width="1417" height="1376"></p></figure><p>We went a bit crazy here. We started by splitting our monolith into more services and kept adding new apps into our codebase as we grew. To manage it all, we chose <a target="_blank" href="https://nx.dev/">Nx⁠</a> as our build/monorepo framework. Migrating to Nx helps us standardize how our dev team runs development, builds, shipping, and tests within our GitHub CI/CD pipeline. Nx gives us custom executors that we use to handle environment variables, accommodate differences between frameworks like classic SPA and Next.js, and others. The speedup due to caching was a nice bonus (you can do this locally, or in the cloud for added benefits).</p><p>For managing environment keys, we picked <a target="_blank" href="https://infisical.com/">Infisical⁠</a>, which is end-to-end encrypted, self-deployable, and basically ticks all our boxes. This setup lets developers access only development keys and nothing more, same for CI. No more committing environment variables into the codebase or injecting them manually into CI. Try it once, and you'll never want to go back. The secrets management tool also lets us run everything in CI smoothly, such as testing for missing or leaking environment keys. One of the tougher challenges was making CI work smoothly alongside the VPN and firewalls we have in place.</p><p>And our custom firewall and VPN setup finally pushed us to upgrade to GitHub Enterprise to get dedicated IPs for our runners.</p><p>We also set up monitoring for our services and made a public <a target="_blank" href="https://status.excalidraw.com/status">status page⁠</a>. For logging, we use <a target="_blank" href="https://vector.dev/">Vector⁠</a> and <a target="_blank" href="https://axiom.co/">Axiom⁠</a>.</p><p>As we wrapped things up, we needed to verify that everything was as secure as we planned. So, we conducted penetration testing across the entire <a target="_blank" href="https://plus.excalidraw.com/">Excalidraw+</a> platform. It found some minor issues, like exposed headers, which we fixed right away. Running penetration tests at least once a year to make sure everything is squared up is a must.</p><h2>Vendors &amp; Risk Management</h2><p>Turns out, your vendors need to have their act together, too. Every service that touches customer data needs to be evaluated and documented.</p><p>The good news? Most of the big players we rely on (Vercel, Google Cloud, GitHub) already have their SOC 2 reports ready to go. </p><p>We use a combination of Vanta (which handles most of the common vendors) and our internal admin dashboard for the ones Vanta doesn't cover, because managing this in spreadsheets gets old fast. For each vendor, we document what data they access, their certifications, key risks, and how we mitigate them.</p><p>Pro tip: Start this early. Some vendors take weeks to respond, and you might need time to find alternatives.</p><h2>Going One Step Further</h2><p>We don't care for tracking our customers, but we do need to know the essentials. How many users do we have, what features are actually used, things like that.</p><p>For Excalidraw, we use a self-hosted version of <a target="_blank" href="https://umami.is/">Umami⁠</a>. For public-facing stuff like our open-source editor and landing pages, we use <a target="_blank" href="https://www.simpleanalytics.com/">Simple Analytics</a>⁠.</p><p>Both do the job without invading your privacy. So if you're wondering why you don't see a cookie banner (<a target="_blank" href="https://umami.is/docs/faq">Umami⁠ FAQ</a>, <a target="_blank" href="https://www.simpleanalytics.com/blog/analytics-without-a-cookie-banner">Simple Analytics⁠</a> ) on our site, that's why.</p><h2>The Audit</h2><p>When it comes to the audit itself, you can either pick from the auditors your provider (e.g., Vanta) works with or find your own. We chose <a target="_blank" href="https://insightassurance.com/">Insight Assurance</a>⁠. What we learned, though, is that we should have contacted them way earlier in the process, as they could have helped us with some of the policies and risk definitions we were overthinking, which would have saved us a lot of time. But hey, lesson learned.</p><p>As for the good ending, we passed SOC 2 Type 1. While Type 2 is next on the list and it's what everyone should aim for, Type 1 is a good stepping stone along the way, as it already demonstrates to your customers you're serious and that you're not running your business from the back of a tool shed.</p><p>If you want to go through the paperwork with a good wine in the evening, you can find it all in our trust center, below.</p><h2>Security page &amp; trust center</h2><ul><li> <a target="_blank" href="https://trust.excalidraw.com/">Trust Center</a>⁠</li><li> <a target="_blank" href="https://plus.excalidraw.com/security-and-compliance">Security and Compliance⁠</a></li></ul><h2>What's Next</h2><figure><p><img src="https://excalidraw.nyc3.cdn.digitaloceanspaces.com/lp-cms/media/SOC2-blog-roadmap.png" alt="soc2 certification roadmap" width="3860" height="1667"></p></figure><ul><li> SOC 2 Type 2</li><li> GDPR (unless the EU repeals it first)</li><li> ISO 27001 (if enough customers ask)</li></ul></div></section></div>]]></description>
        </item>
    </channel>
</rss>