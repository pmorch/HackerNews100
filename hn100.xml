<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 20 Oct 2024 03:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[QUIC Is Not Quick Enough over Fast Internet (162 pts)]]></title>
            <link>https://arxiv.org/abs/2310.09423</link>
            <guid>41890784</guid>
            <pubDate>Sat, 19 Oct 2024 21:04:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.09423">https://arxiv.org/abs/2310.09423</a>, See on <a href="https://news.ycombinator.com/item?id=41890784">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2310.09423">View PDF</a>
    <a href="https://arxiv.org/html/2310.09423v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>QUIC is expected to be a game-changer in improving web application performance. In this paper, we conduct a systematic examination of QUIC's performance over high-speed networks. We find that over fast Internet, the UDP+QUIC+HTTP/3 stack suffers a data rate reduction of up to 45.2% compared to the TCP+TLS+HTTP/2 counterpart. Moreover, the performance gap between QUIC and HTTP/2 grows as the underlying bandwidth increases. We observe this issue on lightweight data transfer clients and major web browsers (Chrome, Edge, Firefox, Opera), on different hosts (desktop, mobile), and over diverse networks (wired broadband, cellular). It affects not only file transfers, but also various applications such as video streaming (up to 9.8% video bitrate reduction) and web browsing. Through rigorous packet trace analysis and kernel- and user-space profiling, we identify the root cause to be high receiver-side processing overhead, in particular, excessive data packets and QUIC's user-space ACKs. We make concrete recommendations for mitigating the observed performance issues.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Xumiao Zhang [<a href="https://arxiv.org/show-email/cd546dba/2310.09423">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2310.09423v1">[v1]</a></strong>
        Fri, 13 Oct 2023 22:05:13 UTC (201 KB)<br>
    <strong>[v2]</strong>
        Mon, 30 Sep 2024 22:56:00 UTC (238 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ribbonfarm Is Retiring (116 pts)]]></title>
            <link>https://www.ribbonfarm.com/2024/10/10/ribbonfarm-is-retiring/</link>
            <guid>41889876</guid>
            <pubDate>Sat, 19 Oct 2024 19:06:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ribbonfarm.com/2024/10/10/ribbonfarm-is-retiring/">https://www.ribbonfarm.com/2024/10/10/ribbonfarm-is-retiring/</a>, See on <a href="https://news.ycombinator.com/item?id=41889876">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>After several years of keeping it going in semi-retired, keep-the-lights-on (KTLO) mode, I’ve decided to officially fully retire this blog. The ribbonfarm.com domain and all links will remain active, but there will be no new content after November 13th, 2024, which happens to be my 50th birthday. There will be one final roundup post before then, and perhaps a shortish epitaph post. And the main page will switch to a static landing page. But after that date, this will effectively be a museum site.</p>



<p>I’m not <em>personally </em>retiring of course (I neither want to, nor can I afford to), but this WordPress blog is. Sometime in the next few months, I’ll figure out how to move it to a lower-cost archival hosting model, probably as a static non-WordPress site, simplify the design as befits a retiree, and put up some sort of museum-like landing page with self-guided tour maps, a little museum shop selling books, directions to the service entrance for AI scraper-bots, and so on. If you get your updates via the Mailchimp newsletter, that will be shutting down sometime in the next few weeks. So if you’d like to continue hearing from me, sign up for my <a href="https://studio.ribbonfarm.com/">substack</a> (fair warning: It’s not a blog, and both the contents and style are distinctly different from what you’ve been used to here).</p>



<p>But in the meantime, in what is going to be the last significant post on here, let’s look back on what has been a 17-year journey.</p>



<p>It’s been 17 eventful years, and this blog has been my home online through some very interesting times, both for me personally and for the world, but it feels like the time is finally <em>just </em>right for it to retreat gracefully to the shadows. Not too early, not too late.</p>



<p>There is no specific reason to retire the blog right now. While the recent minor civil war in the WordPress ecosystem (if you don’t know about it, you probably don’t need to) felt like the portent I was unconsciously waiting for, this decision has been brewing for a couple of years now. </p>



<p>***</p>



<p>I do think that the end really <em>is </em>here for the blogosphere though. This time it really <em>is</em> different. I’ve weathered many ups and downs in the blogosphere over my 17 years in it, but now it feels like the end of the blogging era. And what has emerged to take its place is not the blogosphere (and really shouldn’t try to be), even though parts of it have tried to claim the word.</p>



<p>I don’t think there is any single heir to the blog, or to the public social media landscape it dominated, anymore than there was a single heir to the Roman empire when it collapsed. And this is as things should be. Emerging media should emerge into their own identities, not attempt to perpetuate the legacies of sundowning media, or fight over baggage. And of course, many architectural elements of the blog will live on in newer media, just as many patterns we live with today originated in the Roman empire. Chronological feeds, and RSS-like protocols are part of our collective technological vocabulary. So at least in a technological sense, nothing is dying <em>per se</em>. But in a cultural sense, we are definitely witnessing the end of an era.</p>



<p>But there’s no denying that the legacy we’re talking about is a powerful one that will cast a long shadow. The cultural reign of the blog, roughly 2000-20 or so, coincided with the second full chapter of the internet. Far more than aggregators, photo-sharing services, or social feeds, the blog <em>was </em>“Web 2.0.” Blogs didn’t produce the <em>most </em>Web 2.0 bytes, but they produced the most <em>significant </em>ones.</p>



<p>Perhaps it’s my blogocentric conceit, but it feels like the active lifespan of ribbonfarm in particular, 2007-24, coincides rather neatly with a very well-defined chapter in the grand narrative of civilization itself, with the Global Financial Crisis (GFC) and the 2024 US Presidential election serving as neat bookends. Whatever the outcome of the election, when this blog officially retires on November 13, we’ll be in some sort of new era. An era blogs helped usher in, but won’t be a part of. </p>



<p>Conceit or not, it’s hard for me to see the story of ribbonfarm as merely <em>my </em>story, or even merely the marginal story of the few dozens of contributors, or of the little subculture of a few hundreds that coalesced around it for the better part of a decade. The story of ribbonfarm has been, in a small one-of-a-million threads way, the story of civilization itself, through the 2007-24 period.</p>



<p>That thought feels nice, in the way I imagine carving my initials onto an ancient monument might feel nice. <em>VENKAT WAS HERE.</em> Actually, <a href="https://www.ribbonfarm.com/2017/06/13/ten-years-of-refactoring/">I kinda did that</a>, with a friend’s help.</p>



<p>I’d argue that the blogosphere, and the public social media landscape, represented the spirit of this civilizational chapter in a much truer way than old media. Through this period, old media strongholds seemed increasingly like grand and sad old ruins of the past, falling into ever-greater dereliction. While they still exerted a certain baleful influence over the cultural landscape, there was something dead about the gaze of old media on the new world. But public social media… it was <em>alive. </em>Its gaze on the new world was not just lively, it was <em>constitutive</em>. It helped <em>make </em>the world it observed. It was where the real action was. Even the dying old media types knew it, as they increasingly turned to new media not just for informational sustenance, self-disruption ideas, and talent, but for what we might call a sort of life-energy. Journalists didn’t just trawl the old Twitter for stories to print on dead trees. They tapped into it like it was a life-giving elixir they needed to stay spiritually alive. The came for the leads and personalities, stayed for the <em>elan vital.</em> They’ll deny it furiously if you ask of course. They’re a stuffy lot. Nice, but stuffy. And snobby. They’ll pretend it was access to the corridors of power that was keeping them alive all this time. It wasn’t. It was us.</p>



<p>For a couple of decades, public social media, with blogs serving as a sort of network of fortresses scattered across that feudal landscape, was where the <em>world</em> happened. A public, grand sort of world. It wreaked havoc too of course, but a grand sort of havoc. The maturing <a href="https://studio.ribbonfarm.com/p/the-extended-internet-universe">cozyweb</a> phase we’re in right now, while it has its own intimate charms, to be found in the warren of discords, slacks, and group DMs we all inhabit these days, lacks the raw grandeur of the public social media era.</p>



<p>Here on ribbonfarm, the era unfolded as a three-act story. The core 2012-2019 period, when <a href="https://www.ribbonfarm.com/refactor-camp/">Refactor Camp</a> was an active event, is a good proxy for the “subcultural” phase of ribbonfarm. During those years, I had the social energy both to curate a lot of writing by others, and events of various sorts. I also tweeted up a storm. But perhaps more importantly, the zeitgeist itself had the right kind of energy to respond in a lively way to such curation. The periods before and after, 2007-12, and 2019-24 were more personal eras, defined by my own interests.</p>



<p>If you’ve been a long-time reader, you know that this three-act story corresponds roughly to my rather grandiose scheme of “Ages” for periodizing the ribbonfarm archives. The three ages of ribbonfarm (the Rust Age (2007-12), the Snowflake Age (2013-18), and the Charnel Age (2019-24)) constitute a story that’s perhaps 10% about me personally, perhaps 20% about the various intersecting milieus that gave rise to the short-lived subculture of the second act, and 70% about the world at large. </p>



<p>Throughout the life of this blog, an old world was dying, and a new world was struggling to be born. And this blog channeled the energy of that ongoing transformation for lulz and profit. Gramsci would have approved.</p>



<p>I have joked to friends, building on a very clever Drew Austin (an early ribbonfarm contributor) observation, that the entire three-age ribbonfarm story was a product of low interest rates. This blog was sponsored by ZIRP. The future historians who dive into these archives for archaeological research will likely be economic rather than cultural historians, trying to reconstruct the play-by-play impact of ZIRP. Many of the big hits of this blog, such as The Premium Mediocre Life of Maya Millennial, and The Locust Economy (a forgotten hit from 2013) had ZIRPy subtexts.</p>



<p>This is not an entirely flippant observation. The blog in its heyday was a product of open-source software, cheap hosting, and perhaps most importantly, essentially free global distribution. First through RSS, then through Twitter. This free distribution was in turn an artifact of cheap venture capital. It began to collapse when interest rates began to rise, forcing distribution deals with devils upon all of us, which only the most desperate and ambitious were willing to take. The rest of us began retreating to the cozyweb rather than pay up to the protection rackeeters who began taking over public distribution channels starting around 2017, culminating in Musk’s acquisition of Twitter in 2022. </p>



<p>***</p>



<p>The young cozyweb era currently taking shape and replacing public social media is equally a product of higher interest rates and paid distribution, but is at least not a distribution-channel protection racket. </p>



<p>I coined the term <em><a href="https://studio.ribbonfarm.com/p/the-extended-internet-universe">cozyweb</a></em> in 2019 (appropriately enough in my substack, rather than here), which is around when it was born. It was perhaps my last major meme. Equally appropriately, that essay has ended up part of a rather <a href="https://darkforest.metalabel.com/dfc?variantId=1">cozy little book from a cozy little publishing startup</a>.</p>



<p>The cozyweb anchors an era that’s threatening to be as long-lived as the public social media era, so it might last till 2035 or so. In fact, I don’t think we’ll see really low/zero/negative interest rates again in my lifetime. Which means we may not see anything like the blogosphere or the public social media era either. </p>



<p>It’s worth noting that the cozyweb is <em>already </em>5 years old. Maybe I should start a new periodization. I need a label for my own first age in the cozyweb, 2019-24. I ported over my old Breaking Smart list into what is now my main substack in 2019, started and finished the short-run Art of Gig newsletter as another substack, helped found the cozy Yak Collective Discord community,  got myself a 5-year Roam subscription, and (much to the dismay of some of you), went crypto-bro (crypto is a very cozyweb type part of the internet).</p>



<p>There have been structural signs of all this of course, and many of my tactical moves over the past few years, which I thought of in the moment as random acts of creative experimentation, were in hindsight preparations for an exit from both the blogosphere and the public social media landscape.</p>



<p>A few examples.</p>



<p>For example, in 2019, I deliberately shifted gears to writing what I’ve called blogchains, over stand-alone posts. These eschew theatricality and engagement farming, and adopt an intimate rhetorical style better suited to the cozyweb. They do not work well with blogs either structurally or thematically. They are really closer cousins to a much older medium: The monograph.</p>



<p>As another example, in 2020, I consciously stopped trying to write “viral hit” type posts, and even bent over backwards to try and write anti-viral posts. The <a href="https://www.ribbonfarm.com/2020/01/16/the-internet-of-beefs/">Internet of Beefs</a>, which I wrote in January 2020, was not just my last viral post, it was my last viral-<em>intent</em> post. I also kinda consciously intended it to serve as a sort of epitaph for the public social media era, which by that time I had come to see as being in irreversible decline. </p>



<p>Events since then have only strongly confirmed those early premonitions. Virality as such, is mostly dead as a cultural phenomenon in long-form writing. When it occurs these days, it feels somehow deadening and cheap. </p>



<p>The cozyweb zeitgeist favors a deeper, quieter sort of writerly ambition, with classier, more high-minded aspirations. Where the viral blog post of the last decade was something of a loud public-park pop-music performance, good 2024 longform feels more like chamber music performed for exclusive invite-only audiences. One under-appreciated reason for Substack’s success at taking over some of the blogosphere’s role is that it’s conducive to this chamber-music style of writing. One of my current operating theories is that this style is in fact the culturally load-bearing part of Substack, even though most of the attention is on high-profile refugees from old media. The proprietors of the platform don’t quite appreciate the chamber music scenes they harbor, which is one of the reasons I’m not convinced the platform will last.</p>



<p>I don’t read any of the old-media refugee substacks, but I do read a lot of chamber-music style substacks. And one of the reasons I don’t quite feel at home on Substack is that while I like reading the chamber-music style stuff, I don’t really do it well myself. I’m too much of a careless shitposter, and the chamber music style calls for a certain earnestness of approach. It calls for a certain amount of self-conscious gravitas (which can easily turn into humorless self-importance, the main failure mode on Substack; one that gives it decided LinkedIn overtones). </p>



<p>This sense of anxiously performed gravitas is perhaps the governing vibe of Substack. They’re sincerely trying to make <em>meaning </em>over there. We here in the blogosphere were just having fun watching the world burn for a couple of fiery decades. A kind of psychotic, nihilistic humor was the governing vibe of the blogosphere at its best.  So far I haven’t seen anything like it on Substack. I miss it of course, but one must move on with the times.</p>



<p>On Substack, the mere <em>prospect</em> of making money reliably (something the blogosphere was spectacularly shitty at, and remains so in its dotage) seems to get people to adopt a more respectable demeanor, and second-guess the shitposting instincts that would have served them well in the blogosphere at its peak. The blogosphere didn’t so much move to Substack as get gentrified by it, much as they’d like you to believe it did. And many of us transplanted bloggers got a shave and haircut, put on a suit, and went to work there, shoulder-to-shoulder with the old media types we once maintained ritual rivalries with, but are now increasingly indistinguishable from. </p>



<p>The rest of them, that is. Not me of course. I’m only wearing the Substack Suit ironically. Why can’t anyone see I’m only wearing the Substack Suit ironically!</p>



<p>But kidding aside, this is fine (and not in a burning-house dog gif sense). Mediums should grow into their own true natures. And if the message of the Substack medium (and subscription newsletters generally… there’s a handful of other contenders) is one of earnestness and gravitas, so be it. Let it get <em>good </em>at it, just as the blogosphere got good at shitposting. <em>Really </em>good.</p>



<p>Perhaps the most revealing example. Sometime around late 2021, thanks to my interests shifting steadily towards what I might call <em>studious </em>interests in things like storytelling, fermi estimation, and tinkering in my pandemic-born lab, my posting here began taking on the tenor of a semi-private notebook. Ribbonfarm began to resemble my private Roam notebooks more than its own past as a slovenly, loud, meme-making, virality-chasing, content junkyard. And it’s no accident that the notebook/digital garden type of medium began to emerge around 2019. A vast amount of good writing these days is happening <em>entirely </em>in private. A tiny fraction is shared (Sarah Constantin, a long-time friend of this blog, <a href="https://roamresearch.com/#/app/srcpublic/page/dUOCm_0cT">has a public Roam</a> for example), and a slightly larger fraction (including a lot of my own Roam content) is likely intended for eventual public sharing in some form. But much of the notebooking universe will remain private forever. It is interesting that a kind of semi-public notebooking is how my blogging story is wrapping up. A kind of semi-public notebooking is a good description of the <em>original </em>vibe of blogs, circa 2002-09. </p>



<p>But we’ve moved on to a deeper kind of notebooking now (deeper in the sense of much more richly and densely hyperlinked internally). A much deeper kind than blogs can sustain. Deep notebooking and content gardening too, aren’t blogging — and shouldn’t try to be. That would be selling <em>that</em> new medium short.</p>



<p>Fourth and final example: I quit actively posting on Twitter when Musk took over. Not directly related to the ribbonfarm story, but a key adjacent subplot. In the moment, it felt like a tactical reaction to the (political and cultural) writing that was clearly on the wall, and I’m glad I quit when I did. But in hindsight, the Muskening was not an independent story. It was just another chapter in the larger story of the rise and fall of the blogosphere and public social media.</p>



<p>Anyhow, where to next?</p>



<p>***</p>



<p>Much of the appropriate subset of my nonfiction writing, of course, has already migrated to my <a href="https://studio.ribbonfarm.com/">substack</a>, which is already five years old (time flies, huh?), but still doesn’t quite feel like home, and I suspect never will. At least not in the way this blog has felt.</p>



<p>Mostly what I write there has to do with technology trends and serialized book-length projects. There’s not much left here that’s suitable for substacking. It’s mostly stuff that does not look good when it puts on a suit, so I probably won’t try to put it there.</p>



<p>These remaining active threads on this blog — narrative theory, fiction experiments, mediocrity musings, outtakes from my lab tinkering — don’t fit Substack and have never quite fit the blog medium either. They need transplanting to media where they can flourish. Lab tinkering really belongs in video, and in cozy conversations with small groups of co-conspirators, such as I’ve been able to find via the <a href="https://yakcollective.org/">Yak Collective</a> (also already 4 years old). Fiction <em>really </em>does not like the reverse-chronological tendency of the blog, and wants to create its own escaped reality, complete with its own temporality, in pre-temporal media spaces. I’m not yet sure where to take my fiction experiments. I suspect I’ll be parking ongoing efforts either in Roam or in novella-length ebook drafts. A few non-fiction threads — narrative theory, mediocrity — will likely eventually turn into monograph-style ebooks/books. They’re kinda done, really. They just need a round of editing and packaging.</p>



<p>That leaves a few loose ends which don’t really belong anywhere in the future at all. They feel like increasingly fussy footnotes, not just to my own archives here, but to the blogging era itself. The impulse to post here now feels like an archival impulse. An impulse to tend to the needs of a gradually settling and cooling past, rather than the needs of a restless and warming future. Garbage collector janitorial work in a memory palace where the temperature is dropping slowly to cold-storage levels. </p>



<p>I’ll be redirecting the energy fueling the memory-curation impulse towards gradually putting together a decent collection of book-length volumes from the archives. And perhaps a fine-tuned LLM that can serve as a ghostly era-bound after-image of myself too. And maybe a glossary and a set of footnotes too, why not. With my twitter archives (also sitting around) thrown in for good measure. They belong spiritually with this blog.</p>



<p>I look forward to chatting with the Ghost of Ribbonfarm+vgr-on-twitter in the metaverse, whenever that option is available and cheap enough to exercise. For now, I’m starting out on this memory curation project by working on a book of key posts spanning the entire life of the blog. A selection I hope will tell at least my subplot of the larger story this blog belongs to. Taxidermy-ing the twitter archives (particularly the threads, not so much the conversations) into a suitably mummified form is a tougher challenge I haven’t yet figured out.</p>



<p>But the memory curation is, to be frank, a backburner priority. Retiring this blog is a poignant moment for me, but I’m fundamentally a future-oriented guy.</p>



<p>These half-assed retirement plans still leave an important function of this blog unaccounted for: As the default outlet for all my random impulses for nearly two decades. What I’ve called my <a href="https://www.ribbonfarm.com/2023/03/01/salt-seeking/">salt-seeking</a> tendencies. Without this blog serving as a sort of /etc folder, I will be sort of cognitively homeless after November 13, since such impulses are probably my most primal ones. It might sound silly, but “where will I put my random 2x2s now” is a real and serious question for me. </p>



<p>I have no idea where I’m going to put my random hare-brained theories, 2x2s, crappy maps, bad cartoons, and so on. Substack and post-Twitter protocol media don’t feel right. Neither does a private notebook. There’s a decidedly social element to that kind of /etc salt-seeking thinking. It thrives best when embedded in global and public distributional media as shitposts, ready to trigger Cunningham’s Law dynamics (“the easiest way to get the right answer is to post a wrong answer”). It struggles along in freshwater publishing media like books and newsletters. And it wilts entirely in private media like notebooks. A bathtub is no place for ideas that yearn for the ocean. There’s no fun or dopamine in making a 2×2 if you can’t immediately share it, as publicly as possible. If you have to put it in a suit to send out via substack, or limit it to niche cozy media, or pay Elon to put it out in the post-apocalyptic sewage stream that is “public” social media, it doesn’t feel quite right.</p>



<p>I’m sure having no outlet for this core part of my thinking will drive me nuts, but that’s a good problem to have. You have to harbor a certain inner restlessness if you want to be a good homeless nomad. Maybe I’ll start putting certain thoughts down on paper, and tossing them into the ocean in plastic bottles. Luckily I live by the Pacific Ocean, the biggest tank of saltwater around. And I’m told they just cleaned up the garbage gyre, so we can start making a new one, and killing a whole new generation of turtles.</p>



<p>Speaking of nomadism, a curious inversion is underway in my life. I’ve been digitally at home here on ribbonfarm for 17 years, but a nomad in my physical life, having lived in 23 apartments in 10 cities over the last 27 years. If my cunning plans work out, that will flip. I’ll be digitally homeless once more (as I was 2000-2007), but hopefully manage to buy a <s>house</s> mansion within the next year if this damn housing market thaws soon. Ideally in the Seattle area. We’ll see.</p>



<p>As I said, I’ll post a final roundup sometime in the next month, and perhaps some sort of final epitaph post on the 13th itself (rather appropriately, I’ll be in Thailand that week, a country that will likely go down in history as a sort of blogger Mecca during the heyday of public social media, when blogosaurs ruled the Earth).</p>



<p>In the meantime, thanks for coming along with me on this long journey, and hope to see you at <a href="https://studio.ribbonfarm.com/">my rental apartment on Substack</a>. I’m somewhat active in the Notes section there, and also on Farcaster. I’m on Bluesky too, but not very active there (something isn’t quite working for me there).</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Svelte 5 Released (271 pts)]]></title>
            <link>https://www.npmjs.com/package/svelte</link>
            <guid>41889674</guid>
            <pubDate>Sat, 19 Oct 2024 18:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npmjs.com/package/svelte">https://www.npmjs.com/package/svelte</a>, See on <a href="https://news.ycombinator.com/item?id=41889674">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div id="readme"><p><a href="https://svelte.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/859edad6e38e149fe3782b13564f3f88c64d731fbc47c3a2fe4556b34eb8f00d/68747470733a2f2f7376656c74656a732e6769746875622e696f2f6173736574732f62616e6e65722e706e67" alt="Cybernetically enhanced web apps: Svelte" data-canonical-src="https://sveltejs.github.io/assets/banner.png"></a></p>
<p><a href="https://www.npmjs.com/package/svelte" rel="nofollow"><img src="https://camo.githubusercontent.com/aa233b2ce5693c2189f6570b03a4fe9c0afdeb4ded145cb67c98e1a790297832/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f7376656c74652e737667" alt="npm version" data-canonical-src="https://img.shields.io/npm/v/svelte.svg"></a> <a href="https://github.com/sveltejs/svelte/blob/HEAD/packages/svelte/LICENSE.md"><img src="https://camo.githubusercontent.com/3fedb1706708c94fa3d5afa55f4021f54f2d3233d346a0ba1bc4d7995e68c692/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f6c2f7376656c74652e737667" alt="license" data-canonical-src="https://img.shields.io/npm/l/svelte.svg"></a> <a href="https://svelte.dev/chat" rel="nofollow"><img src="https://camo.githubusercontent.com/c2c90158c480032a45adcec99107f21ec25c717ce49e05fadff5a3af57d41270/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3435373931323037373237373835353736343f6c6162656c3d63686174266c6f676f3d646973636f7264" alt="Chat" data-canonical-src="https://img.shields.io/discord/457912077277855764?label=chat&amp;logo=discord"></a></p>
<div><h2>What is Svelte?</h2></div>
<p>Svelte is a new way to build web applications. It's a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.</p>
<p>Learn more at the <a href="https://svelte.dev/" rel="nofollow">Svelte website</a>, or stop by the <a href="https://svelte.dev/chat" rel="nofollow">Discord chatroom</a>.</p>
<div><h2>Getting started</h2></div>
<p>You can play around with Svelte in the <a href="https://learn.svelte.dev/" rel="nofollow">tutorial</a>, <a href="https://svelte.dev/examples" rel="nofollow">examples</a>, and <a href="https://svelte.dev/repl" rel="nofollow">REPL</a>.</p>
<p>When you're ready to build a full-fledge application, we recommend using <a href="https://kit.svelte.dev/" rel="nofollow">SvelteKit</a>:</p>
<div><pre>npm create svelte@latest my-app
<span>cd</span> my-app
npm install
npm run dev</pre></div>
<p>See <a href="https://kit.svelte.dev/docs" rel="nofollow">the SvelteKit documentation</a> to learn more.</p>
<div><h2>Changelog</h2></div>
<p><a href="https://github.com/sveltejs/svelte/blob/master/packages/svelte/CHANGELOG.md">The Changelog for this package is available on GitHub</a>.</p>
<div><h2>Supporting Svelte</h2></div>
<p>Svelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you'd like to support their efforts, please consider:</p>
<ul>
<li>
<a href="https://opencollective.com/svelte" rel="nofollow">Becoming a backer on Open Collective</a>.</li>
</ul>
<p>Funds donated via Open Collective will be used for compensating expenses related to Svelte's development.</p>
</div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dwarf Fortress – Boatmurdered Part #1 – Intro (2006) (125 pts)]]></title>
            <link>https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/</link>
            <guid>41889543</guid>
            <pubDate>Sat, 19 Oct 2024 18:19:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/">https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/</a>, See on <a href="https://news.ycombinator.com/item?id=41889543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
	<h3><strong>Part 1:</strong> Intro by Evilslug</h3><p>
	
What follows is a succession-style Let's Play of the game Dwarf Fortress.  In it, we chronicle the rise and fall of the epic Dwarven fortress, Boatmurdered.  (Actually, it's pretty much all fall.)  Each ruler was given a single year of gametime in which to manage the fortress, then they gave the reigns over to the next player in line.  I have added the occasional editor's note to clarify things, but mostly I stay out of the way.  The madness surrounding Boatmurdered is quite apparent on its own, I feel.</p><p>

<b>Official List of Madmen...er..."Rulers".</b></p><p>

TouretteDog<br>
mariguana (aka.  megor grendel)<br>
Keyboard Fox (aka.  Furry, Kalo)<br>
Locus<br>
StarkRavingMad<br>
Bremen<br>
Sankis <br>
Astronautonomicon<br>
Unknowing<br>
Cross Quantum<br>
Major Failure<br>
Mystic Mongol<br>
Doctor Zero<br>
Guerilla Medic</p><p>

All eras of Boatmurdered history are highly noteworthy and interesting.  Things very quickly progressed from somewhat casual daily elephant deaths to retired rulers rampaging and beating people to death (while burning alive).  The heavy downward slide that would come to define Boatmurdered seems to have begun during StarkRavingMad's rule, with the utterly epic "Elephant War".  Historians seem to agree that the insanity surrounding Boatmurdered began to increase almost exponentially from that point forward.</p><p>

<b>The "WTF is Dwarf Fortress?" Crash-Course.</b></p><p>

The thread to follow generally assumes you have a tiny bit of knowledge about the game being played.  In hopes of making it an easy read for those unfamiliar, I've condensed the most important factors from the general info threads and wiki into this brief introduction.  You don't need to know a thing about the game to genuinely enjoy the playthrough, but a tiny bit of knowledge does help.  Here's the tl;dr guide, first.

</p><div><p><img src="https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/dwarfguide.gif" alt=""></p><p>

Left to right:  Elephant, Dwarf, Miasma Cloud (the purple cloud of stench that comes from rotting bodies).</p><p>

For a bit better outline of the game, read on.  Impatient types and those who already know Dwarf Fortress well, please skip straight to the first update.  The initial update outlines the rules by which this game was played (there aren't many, hah!).  The second update is where we generate the world and actually get the ball rolling.</p><p>

====</p><p>

<b>What kind of game is Dwarf fortress?</b></p><p>

In a nutshell, Dwarf Fortress is best described as a 2-D base building game in the theme of Dungeon Keeper.  The concept is simple, the graphics are simple; but the depth of the game is fairly awesome.  (Even more amazing when you realize it is all the product of a single man gaming company.)</p><p>

The dwarves you "control" are somewhat autonomous.  They have likes, dislikes, and needs.  While you can assign them specific duties and set basic orders, they have minds of their own and will act according to how they feel.  You can give them a job, but that doesn't always mean they'll do it right away.  Injuries to all animals and dwarves are tracked, down to internal organs and body parts.  Dwarves have moods that are affected by the things around them.  They can decide to throw a party for their friends, or they might stress out under strain and suddenly kill each other with little to no warning.  Female dwarves occasionally get pregnant and, if they are exposed to trauma (say a goblin siege); they very well might miscarry.  Sad thoughts caused by things of that nature can lead dwarves to tantrums or even suicide.</p><p>

You begin with 7 dwarves and scarce few supplies at the face of a mountain.  Your only objective is to survive the elements while building yourself as cool a fortress as you possibly can before you inevitably die.  Simple enough, yes?</p><p>

The game is displayed in a pseudo-ASCII style, which uses letters for objects in the game world, similar to Nethack.  I hear you groaning, but you'll quickly catch the hang of things.  The players provide excellent explanation of what is going on in each screenshot.  I've included a general key to some common items, below; should you find yourself needing one.</p><p>

In the following shot, a bunch of dwarves are charging off to be trampled by elephants outside the fortress.  The cliff face bisects the picture, with the outdoors on the left and the cliff interior on the right:

</p></div><div><p><img src="https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/chargedetail.png" alt=""></p><p>

1:  This section with the '=' symbols marks a stockpile.  It's where dwarves store various crafts, barrels (not pictured...denoted by a % with a yellow background), and food.</p><p>

2:  This symbol represents a cage for trapping creatures.  You'll see these a lot.</p><p>

3:  This is a pile of rocks which come from digging away the mountain.  You'll see them all over.  They can be crafted into all manner of useful items.</p><p>

4:  The matrix looking green crap is the ground.  On the inside, to the right of box 10, you'll see the symbols are white, instead.  Smoothed stone floors in the fort are represented by + symbols.  Some people use a variegated tileset, which results in what you see here.  Others will have ground that displays as all periods.  You eventually get used to both and can easily pick out what is where on any map.</p><p>

5:  Dwarves are shown as these guys here, or as smiley faces.  Different colors indicate different professions.  These guys are all military recruits, charging off stupidly to their deaths.</p><p>

6:  The E is an elephant.  They murder dwarves in wonderful fashion.  Get used to them.  Above and below him, the brackets are discarded armor or clothing.  The grey blocks to his right represent exposed walls of un-mined rock.  The blocks with the cross on them represent stone doors.  The small 2's that fill the room behind the two doors are the bones of animals or dwarves.</p><p>

7:  The ^ symbol denotes a trap.  The parallel lines below the traps represent a smoothed wall.  Below these lines, you see the grey wall of the bone room, which is not smoothed.  Different colored symbols in grey rock walls just represent types of exposed mineral, gems, or ore veins.</p><p>

8:  This is a pile of dead dwarves, an Elephant, and a cloud of Miasma.  Those are the three most prevalent features in Boatmurdered.  Miasma is the purple blotch that shows up when corpses begin to rot.  It makes your dwarves angry, which usually leads to hilarity.</p><p>

9:  The two green asterisks are gems.  These have been mined out of a wall, already; and are awaiting storage.</p><p>

10:  These are siege engines.  In this case, two ballistas aimed at the hallway with all the dead dwarves.</p><p>

11:  The black spaces with symbols like these are areas of the mountain that have yet to be mined.</p><p>

In other images, you'll often see a yellow X somewhere and a command list on the right side of the screen.  The text on that screen generally refers to whatever is under the yellow X to its left.</p><p>

====</p><p>

If you need further details, you can find them here:</p><p>

Quick links<br>
<a href="http://www.bay12games.com/dwarves/" target="_blank" rel="nofollow">http://www.bay12games.com/dwarves/</a> - official site</p><p>

<a href="http://dwarf.lendemaindeveille.com/index.php/Main_Page" target="_blank" rel="nofollow">http://dwarf.lendemaindeveille.com/index.php/Main_Page</a> - wiki (tutorials here)</p><p>

<a href="http://forums.somethingawful.com/showthread.php?s=&amp;threadid=2377482" target="_blank" rel="nofollow">SA Dwarf Fortress Megathread</a> - the big DF Q&amp;A thread in Games.</p><p>

The shots in the thread are generally pretty self-explanatory, so get to the thread and enjoy.  And by the way...In the words of the great ruler, StarkRavingMad:</p><p>

<b>Welcome to fucking Boatmurdered!</b></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI engineers claim new algorithm reduces AI power consumption by 95% (186 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-engineers-build-new-algorithm-for-ai-processing-replace-complex-floating-point-multiplication-with-integer-addition</link>
            <guid>41889414</guid>
            <pubDate>Sat, 19 Oct 2024 18:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-engineers-build-new-algorithm-for-ai-processing-replace-complex-floating-point-multiplication-with-integer-addition">https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-engineers-build-new-algorithm-for-ai-processing-replace-complex-floating-point-multiplication-with-integer-addition</a>, See on <a href="https://news.ycombinator.com/item?id=41889414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-320-80.jpg" alt="addition sign floating on hand" srcset="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi.jpg" data-pin-nopin="true" fetchpriority="high" crossorigin="anonymous">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Shutterstock)</span>
</figcaption>
</div>

<div id="article-body">
<p>Engineers from BitEnergy AI, a firm specializing in AI inference technology, has developed a means of artificial intelligence processing that replaces floating-point multiplication (FPM) with integer addition.&nbsp;</p><p>The new method, called Linear-Complexity Multiplication (L-Mul), comes close to the results of FPM while using the simpler algorithm. But despite that, it’s still able to maintain the high accuracy and precision that FPM is known for. As <a data-analytics-id="inline-link" href="https://techxplore.com/news/2024-10-integer-addition-algorithm-energy-ai.html" data-url="https://techxplore.com/news/2024-10-integer-addition-algorithm-energy-ai.html" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">TechXplore reports</a>, this method reduces the power consumption of AI systems, potentially up to 95%, making it a crucial development for our AI future.</p><p>Since this is a new process, popular and readily available hardware on the market, like Nvidia’s upcoming Blackwell GPUs, aren't designed to handle this algorithm. So, even if BitEnergy AI’s algorithm is confirmed to perform at the same level as FPM, we still need systems that could handle it. This might give a few AI companies pause, especially after they just invested millions, or even billions, of dollars in AI hardware. Nevertheless, the massive 95% reduction in power consumption would probably make the biggest tech companies jump ship, especially if AI chip makers build application-specific integrated circuits (ASICs) that will take advantage of the algorithm.</p><p>Power is now the primary constraint on AI development, with all data center GPUs sold last year alone <a data-analytics-id="inline-link" href="https://www.tomshardware.com/desktops/servers/a-single-modern-ai-gpu-consumes-up-to-37-mwh-of-power-per-year-gpus-sold-last-year-alone-consume-more-power-than-13-million-households" data-before-rewrite-localise="https://www.tomshardware.com/desktops/servers/a-single-modern-ai-gpu-consumes-up-to-37-mwh-of-power-per-year-gpus-sold-last-year-alone-consume-more-power-than-13-million-households">consuming more power than one million homes</a> in a year. Even <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/google" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/google">Google</a> put its climate target in the backseat because of AI’s power demands, with <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/google-reveals-48-increase-in-greenhouse-gas-emissions-from-2019-largely-driven-by-data-center-energy-demands" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/google-reveals-48-increase-in-greenhouse-gas-emissions-from-2019-largely-driven-by-data-center-energy-demands">its greenhouse gas emissions increasing by 48%</a> from 2019, instead of declining year-on-year, as expected. The company’s former CEO even suggested opening the floodgates for power production by <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/former-google-ceo-says-climate-goals-are-not-meetable-so-we-might-as-well-drop-climate-conservation-unshackle-ai-companies-so-ai-can-solve-global-warming" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/artificial-intelligence/former-google-ceo-says-climate-goals-are-not-meetable-so-we-might-as-well-drop-climate-conservation-unshackle-ai-companies-so-ai-can-solve-global-warming">dropping climate goals</a> and using more advanced AI to solve the global warming problem.</p><p>But if AI processing can be more power efficient, then it seems that we can still get advanced AI technologies without sacrificing the planet. Aside from that, this 95% drop in energy use would also reduce the burden that these massive data centers put on the national grid, reducing the need to build more energy plants to power our future quickly.</p><p>While most of us are amazed by the additional power that new AI chips bring every generation, true advancement only comes when these processors are more powerful and more efficient. So, if L-Mul works as advertised, then humanity could have its AI cake and eat it, too.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-EDyKodJvgq4KhLWiwh7i8j"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>
<div id="slice-container-authorBio-EDyKodJvgq4KhLWiwh7i8j"><p>Jowi Morales is a tech enthusiast with years of experience working in the industry. He’s been writing with several tech publications since 2021, where he’s been interested in tech hardware and consumer electronics.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Love being interrupted when my monitor asks me to accept user agreements (309 pts)]]></title>
            <link>https://twitter.com/snwy_me/status/1847396175961641176</link>
            <guid>41889140</guid>
            <pubDate>Sat, 19 Oct 2024 17:27:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/snwy_me/status/1847396175961641176">https://twitter.com/snwy_me/status/1847396175961641176</a>, See on <a href="https://news.ycombinator.com/item?id=41889140">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A Distributed Systems Reading List (2014) (158 pts)]]></title>
            <link>https://dancres.github.io/Pages/</link>
            <guid>41889076</guid>
            <pubDate>Sat, 19 Oct 2024 17:17:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dancres.github.io/Pages/">https://dancres.github.io/Pages/</a>, See on <a href="https://news.ycombinator.com/item?id=41889076">Hacker News</a></p>
<div id="readability-page-1" class="page">


<h2>Introduction
</h2>

<p>I often argue that the toughest thing about distributed systems is changing the way you think.  The below is a collection of material I've found useful for motivating these changes.
</p>

<h2>Thought Provokers</h2>

<p>Ramblings that make you think about the way you design.  Not everything can be solved with big servers, databases and transactions.</p>

<ul>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.411">Harvest,
  Yield and Scalable Tolerant Systems</a><a> - Real world applications of
  CAP from Brewer et al</a></li><a>
</a><li><a></a><a href="https://mvdirona.com/jrh/talksAndPapers/JamesRH_Lisa.pdf">On Designing and Deploying Internet Scale Services</a> - James Hamilton</li>
<li><a href="https://web.archive.org/web/20181006111158/http://www.addsimplicity.com/adding_simplicity_an_engi/2006/12/the_perils_of_g.html">The Perils of Good Abstractions</a>
	- Building the perfect API/interface is difficult</li>
	
<li><a href="https://web.archive.org/web/20180821164750/http://www.addsimplicity.com/adding_simplicity_an_engi/2007/05/chaotic_perspec.html">Chaotic Perspectives</a>
	- Large scale systems are everything developers dislike - unpredictable, unordered and parallel</li>

<li><a href="http://cidrdb.org/cidr2005/papers/P12.pdf">Data on the Outside versus Data on the Inside</a> - Pat Helland</li>
<li><a href="https://channel9.msdn.com/Shows/ARCast.TV/ARCastTV-Pat-Helland-on-Memories-Guesses-and-Apologies">Memories, Guesses and Apologies</a> - Pat Helland</li>
<li><a href="https://web.archive.org/web/20190719121913/https://blogs.msdn.microsoft.com/pathelland/2007/05/20/soa-and-newtons-universe/">SOA and Newton's Universe</a> - Pat Helland</li>
<li><a href="https://arxiv.org/abs/0909.1788">Building on Quicksand</a> - Pat Helland</li>
<li><a href="https://www.artima.com/weblogs/viewpost.jsp?thread=4247">Why Distributed Computing?</a> - Jim Waldo</li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7628">A Note on Distributed Computing</a> - Waldo, Wollrath et al</li>
<li><a href="https://web.archive.org/web/20190319154842/https://plus.google.com/112678702228711889851/posts/eVeouesvaVX">Stevey's Google Platforms Rant</a> - Yegge's SOA platform experience</li>
</ul>

<h2>Latency</h2>

<ul>
<li><a href="https://web.archive.org/web/20181004043647/http://www.addsimplicity.com/adding_simplicity_an_engi/2007/02/latency_exists_.html">Latency Exists, Cope!</a>
	- Commentary on coping with latency and it's architectural impacts</li>
<li><a href="https://www.igvita.com/2012/07/19/latency-the-new-web-performance-bottleneck/">Latency - the new web performance bottleneck</a> - not at all new (see <a href="http://dl.acm.org/citation.cfm?id=1022596">Patterson</a>), but noteworthy</li>
<li><a href="https://research.google/pubs/pub40801/">The Tail At Scale</a> - the latencychallenges inherent of dealing with latency in large scale systems</li>	
</ul>

<h2>Amazon</h2>

<p>Somewhat about the technology but more interesting is the culture and organization they've created to work with it.</p>

<ul>
<li><a href="https://queue.acm.org/detail.cfm?id=1142065">A Conversation with Werner Vogels</a> - Coverage of Amazon's transition to a service-based architecture</li>

<li><a href="https://queue.acm.org/detail.cfm?id=1388773">Discipline and Focus</a> - Additional coverage of Amazon's transition to a service-based architecture</li>

<li><a href="https://web.archive.org/web/20130729204944id_/http://itc.conversationsnetwork.org/shows/detail1634.html">Vogels on Scalability</a></li>

<li><a href="http://searchwebservices.techtarget.com/originalContent/0,289142,sid26_gci1195702,00.html">SOA creates order out of chaos @ Amazon</a></li>
</ul>

<h2>Google</h2>

<p>Current "rocket science" in distributed systems.</p>

<ul>
<li><a href="https://research.google/pubs/pub62/">MapReduce</a></li>

<li><a href="https://research.google/pubs/pub27897/">Chubby Lock Manager</a></li>

<li><a href="https://research.google/pubs/pub51/">Google File System</a></li>

<li><a href="https://research.google/pubs/pub27898/">BigTable</a></li>

<li><a href="https://www.usenix.org/legacy/event/worlds06/tech/prelim_papers/perl/perl.pdf">Data Management for Internet-Scale Single-Sign-On</a></li>
<li><a href="https://research.google/pubs/pub36632/">Dremel: Interactive Analysis of Web-Scale Datasets</a></li>
<li><a href="https://research.google/pubs/pub36726/">Large-scale Incremental Processing Using Distributed Transactions and Notifications</a></li>
<li><a href="http://cidrdb.org/cidr2011/Papers/CIDR11_Paper32.pdf">Megastore: Providing Scalable, Highly Available Storage for Interactive Services</a> - Smart design for low latency Paxos implementation across datacentres.</li>
<li><a href="https://research.google/pubs/pub39966/">Spanner</a> - Google's scalable, multi-version, globally-distributed, and synchronously-replicated database.</li>
<li><a href="https://research.google/pubs/pub41318/">Photon</a> -  Fault-tolerant and Scalable Joining of Continuous Data Streams. Joins are tough especially with time-skew, high availability and distribution.</li>
<li><a href="https://research.google/pubs/pub42851/">Mesa: Geo-Replicated, Near Real-Time, Scalable Data Warehousing</a> - Data warehousing system that stores critical measurement data related to Google's Internet advertising business.</li>
</ul>

<h2>Consistency Models</h2>

<p>Key to building systems that suit their environments is finding the right tradeoff between consistency and availability.</p>

<ul>
<li><a href="https://web.archive.org/web/20190629112250/https://www.glassbeam.com/sites/all/themes/glassbeam/images/blog/10.1.1.67.6951.pdf">CAP Conjecture</a> - Consistency, Availability, Parition Tolerance cannot all be satisfied at once</li>
<li><a href="https://www.cs.utexas.edu/users/dahlin/papers/cac-tr.pdf">Consistency, Availability, and Convergence</a> - Proves the upper bound for consistency possible in a typical system</li>
<li><a href="https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed">CAP Twelve Years Later: How the "Rules" Have Changed</a> - Eric Brewer expands on the original tradeoff description</li>
<li><a href="https://www.infoq.com/news/2008/01/consistency-vs-availability">Consistency and Availability</a> - Vogels</li>
<li><a href="https://www.allthingsdistributed.com/2007/12/eventually_consistent.html">Eventual Consistency</a> - Vogels</li>
<li><a href="https://web.archive.org/web/20180821165044/http://www.addsimplicity.com/adding_simplicity_an_engi/2006/12/avoiding_two_ph.html">Avoiding Two-Phase Commit</a>
	- Two phase commit avoidance approaches</li>
	
<li><a href="https://web.archive.org/web/20180821164931/http://www.addsimplicity.com/adding_simplicity_an_engi/2006/12/2pc_or_not_2pc_.html">2PC or not 2PC, Wherefore Art Thou XA?</a>
	- Two phase commit isn't a silver bullet</li>
<li><a href="https://docs.microsoft.com/en-us/archive/blogs/pathelland/link-to-quotlife-beyond-distributed-transactions-an-apostates-opinion">Life Beyond Distributed Transactions</a>
	- Helland</li>
<li><a href="https://queue.acm.org/detail.cfm?id=1988603">If you have
	too much data, then 'good enough' is good enough</a> - NoSQL,
	Future of data theory - Pat Helland</li>
<li><a href="https://www.enterpriseintegrationpatterns.com/docs/IEEE_Software_Design_2PC.pdf">Starbucks doesn't do two phase commit</a> - Asynchronous mechanisms at work</li>
<li><a href="https://codahale.com/you-cant-sacrifice-partition-tolerance/">You Can't Sacrifice Partition Tolerance</a> - Additional CAP commentary</li>
<li><a href="https://www.hpl.hp.com/techreports/2002/HPL-2002-33.pdf">Optimistic Replication</a> - Relaxed consistency approaches for data replication</li>
</ul>

<h2>Theory</h2>

<p>Papers that describe various important elements of distributed systems design.</p>

<ul>
<li><a href="https://arxiv.org/pdf/cs/0403019.pdf">Distributed Computing Economics</a> - Jim Gray</li>
<li><a href="https://www.microsoft.com/en-us/research/publication/rules-of-thumb-in-data-engineering/">Rules of Thumb in Data Engineering</a> - Jim Gray and Prashant Shenoy</li>
<li><a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">Fallacies of Distributed Computing</a> - Peter Deutsch</li>
<li><a href="https://doi.acm.org/10.1145/3149.214121">Impossibility of distributed consensus with one faulty process</a> - also known as FLP [access requires account and/or payment, a free version can be found <a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf">here</a>]</li>
<li><a href="https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/p225-chandra.pdf">Unreliable Failure Detectors for Reliable Distributed Systems.</a> A method for handling the challenges of FLP</li>
<li><a href="https://lamport.azurewebsites.net/pubs/time-clocks.pdf">Lamport Clocks</a> - How do you establish a global view of time when each computer's clock is independent</li>
<li><a href="https://lamport.azurewebsites.net/pubs/byz.pdf">The Byzantine Generals Problem</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.469">Lazy Replication: Exploiting the Semantics of Distributed Services</a></li>
<li><a href="https://www.usenix.org/legacy/event/hotdep10/tech/full_papers/Kapritsos.pdf">Scalable Agreement - Towards Ordering as a Service</a></li>
<li><a href="https://arxiv.org/pdf/1307.3207v1.pdf">Scalable Eventually Consistent Counters over Unreliable Networks</a> - Scalable counting is tough in an unreliable world</li>
</ul>

<h2>Languages and Tools</h2>

<p>Issues of distributed systems construction with specific technologies.</p>

<ul>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.9417&amp;rep=rep1&amp;type=pdf">Programming Distributed Erlang Applications: Pitfalls and Recipes</a> - Building reliable distributed applications isn't as simple as merely choosing Erlang and OTP.</li>
</ul>

	
<h2>Infrastructure</h2>
<ul>
<li><a href="https://queue.acm.org/detail.cfm?id=1773943">Principles of Robust Timing over the Internet</a> - Managing clocks is essential for even basics such as debugging</li>
</ul>

<h2>Storage</h2>
<ul>
<li><a href="https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf">Consistent Hashing and Random Trees</a></li>
<li><a href="https://www.allthingsdistributed.com/2007/10/amazons_dynamo.html">Amazon's Dynamo Storage Service</a></li>
</ul>

<h2>Paxos Consensus</h2>

<p>Understanding this algorithm is the challenge.  I would suggest reading "Paxos Made Simple" before the other papers and again afterward.</p>

<ul>
<li><a href="https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf">The Part-Time Parliament</a> - Leslie Lamport</li>
<li><a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">Paxos Made Simple</a> - Leslie Lamport</li>
<li><a href="https://static.googleusercontent.com/media/research.google.com/en/us/archive/paxos_made_live.pdf">Paxos Made Live - An Engineering Perspective</a> - Chandra et al</li>
<li><a href="https://groups.csail.mit.edu/tds/paxos.html">Revisiting the Paxos Algorithm</a> - Lynch et al</li>
<li><a href="http://bwl-website.s3-website.us-east-2.amazonaws.com/58-Consensus/Acrobat.pdf">How to build a highly available system with consensus</a> - Butler Lampson</li>
<li><a href="https://www.microsoft.com/en-us/research/publication/reconfiguring-a-state-machine/">Reconfiguring a State Machine</a> - Lamport et al - changing cluster membership</li>
<li><a href="https://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.4762">Implementing Fault-Tolerant Services Using the State Machine Approach: a Tutorial</a> - Fred Schneider</li>
</ul>

<h2>Other Consensus Papers</h2>

<ul>
<li><a href="https://www.usenix.org/legacy/event/osdi08/tech/full_papers/mao/mao_html/">Mencius: Building Efficient Replicated State Machines for WANs</a> - consensus algorithm for wide-area network</li>
<li><a href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm</a> - The extended version of the RAFT paper, an alternative to PAXOS.</li>
</ul>

<h2>Gossip Protocols (Epidemic Behaviours)</h2>

<ul>
<li><a href="https://infoscience.epfl.ch/record/109302?ln=en">How robust are gossip-based communication protocols?</a></li>
<li><a href="https://www.cs.cornell.edu/home/rvr/papers/astrolabe.pdf">Astrolabe: A Robust and Scalable Technology For Distributed Systems Monitoring, Management, and Data Mining</a></li>
<li><a href="https://www.allthingsdistributed.com/historical/archives/000456.html">Epidemic Computing at Cornell</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.4000%22">Fighting Fire With Fire: Using Randomized Gossip To Combat Stochastic Scalability Limits</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.7959">Bi-Modal Multicast</a></li>
<li><a href="https://dl.acm.org/toc/sigops/2007/41/5">ACM SIGOPS Operating Systems Review - Gossip-based computer networking</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.9737">SWIM: Scalable Weakly-consistent Infection-style Process Group Membership Protocol</a></li>
</ul>

<h2>P2P</h2>

<ul>
<li><a href="https://pdos.csail.mit.edu/papers/ton:chord/paper-ton.pdf">Chord</a>: A Scalable Peer-to-peer Lookup Protocol for Internet Applications</li>
<li><a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">Kademlia</a>: A Peer-to-peer Information System Based on the XOR Metric</li>
<li><a href="https://rowstron.azurewebsites.net/PAST/pastry.pdf">Pastry</a>: Scalable, decentralized object location and routing for large-scale peer-to-peer systems</li>
<li><a href="http://research.microsoft.com/en-us/um/people/antr/PAST/hotos.pdf">PAST</a>: A large-scale, persistent peer-to-peer storage utility - storage system atop Pastry</li>
<li><a href="https://rowstron.azurewebsites.net/PAST/jsac.pdf">SCRIBE</a>: A large-scale and decentralised application-level multicast infrastructure - wide area messaging atop Pastry</li>
</ul>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Data Version Control (119 pts)]]></title>
            <link>https://dvc.org/</link>
            <guid>41888937</guid>
            <pubDate>Sat, 19 Oct 2024 16:56:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dvc.org/">https://dvc.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41888937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="-1" id="___gatsby"><main><div><div><p><strong>DataChain Open-Source Release</strong></p><p>A New Way to Manage your Unstructured Data</p></div><p><a href="https://github.com/iterative/datachain" rel="noopener noreferrer" target="_blank">Star us on GitHub<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 40 40"><path fill="currentColor" fill-rule="evenodd" d="M19.999 5C11.717 5 5 11.716 5 20c0 6.628 4.298 12.25 10.258 14.233.75.138 1.024-.325 1.024-.723 0-.355-.013-1.3-.02-2.55-4.172.905-5.053-2.012-5.053-2.012-.682-1.733-1.666-2.194-1.666-2.194-1.362-.93.104-.912.104-.912 1.505.106 2.297 1.546 2.297 1.546 1.338 2.292 3.511 1.63 4.366 1.246.136-.968.524-1.63.952-2.004-3.33-.379-6.833-1.666-6.833-7.414 0-1.637.585-2.977 1.545-4.025-.155-.38-.67-1.905.147-3.97 0 0 1.259-.403 4.124 1.538 1.196-.333 2.48-.5 3.755-.506 1.275.007 2.558.173 3.756.506 2.863-1.941 4.12-1.538 4.12-1.538.819 2.065.304 3.59.15 3.97.962 1.048 1.542 2.388 1.542 4.025 0 5.763-3.508 7.03-6.848 7.402.537.463 1.017 1.378 1.017 2.778 0 2.004-.018 3.622-.018 4.114 0 .402.27.868 1.031.722C30.706 32.244 35 26.626 35 20c0-8.284-6.717-15-15.001-15"></path></svg></a></p></div><div><div><p>Free and open source, forever.</p></div><p>Manage and version images, audio, video, and text files in storage and organize your ML modeling process into a reproducible workflow.</p></div><div><div><div><p><img src="https://dvc.org/img/logos/datachain-black.svg" alt="DVC Logo"></p><div><h2>GenAI DataChain</h2><a href="https://github.com/iterative/datachain" rel="noopener noreferrer" target="_blank"><p><span>---</span><img src="https://dvc.org/img/landing/github.svg" alt="Github Logo"></p></a></div></div><div><p><img src="https://dvc.org/img/logos/dvc.svg" alt="DVC Logo"></p><div><h2>Data and model versioning</h2><a href="https://github.com/iterative/dvc" rel="noopener noreferrer" target="_blank"><p>13.6K<img src="https://dvc.org/img/landing/github.svg" alt="Github Logo"></p></a></div></div></div><div><div data-gatsby-image-wrapper=""><picture><source type="image/avif" srcset="https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/fecd9/Hero%20Visualization.avif 714w,https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/5887a/Hero%20Visualization.avif 1428w,https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/568f1/Hero%20Visualization.avif 2856w" sizes="(min-width: 2856px) 2856px, 100vw"><source type="image/webp" srcset="https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/10990/Hero%20Visualization.webp 714w,https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/5ad4f/Hero%20Visualization.webp 1428w,https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/05bdf/Hero%20Visualization.webp 2856w" sizes="(min-width: 2856px) 2856px, 100vw"><img data-gatsby-image-ssr="" data-main-image="" sizes="(min-width: 2856px) 2856px, 100vw" decoding="async" loading="eager" src="https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/e0432/Hero%20Visualization.svg" srcset="https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/7a82a/Hero%20Visualization.svg 714w,https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/faa69/Hero%20Visualization.svg 1428w,https://dvc.org/static/fc45be68b6d7ea2eae90eda3ff00ba1e/e0432/Hero%20Visualization.svg 2856w" alt="Visualization"></picture></div><p><strong>Explore</strong> and <strong>enrich</strong> annotated datasets with custom embeddings, auto-labeling, and bias removal at billion-file scale — without modifying your data.</p><div><p><strong>Connect</strong> to versioned data sources and code with pipelines, <strong>track</strong> experiments,</p><!-- --> <p><strong>register</strong> models — all based on GitOps principles.</p></div></div></div><div id="get-started-datachain"><h2>Get Started with</h2><p><img src="https://dvc.org/img/logos/datachain-black.svg" alt="Datachain Logo"></p></div><div><h2>DataChain and DVC: Better Together</h2><p>Build the datasets you need without modifying your data sources. Create pipelines that connect your versioned datasets, code, and models together for effective experiment tracking the GitOps way.</p></div><div id="get-started-dvc"><h2>Get Started with</h2><p><img src="https://dvc.org/img/logos/dvc.svg" alt="DVC Logo"></p></div><div><p><h2>Empowering thousands of users and customers from startups to Fortune 500 companies</h2></p></div><div id="subscribe"><p><img src="data:image/svg+xml;base64,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" alt=""></p><div><p>Subscribe for updates. We won't spam you.</p></div><p><img src="data:image/svg+xml;base64,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" alt=""></p></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Have McKinsey and its consulting rivals got too big? (151 pts)]]></title>
            <link>https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</link>
            <guid>41888061</guid>
            <pubDate>Sat, 19 Oct 2024 14:46:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big">https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</a>, See on <a href="https://news.ycombinator.com/item?id=41888061">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><span><a href="https://www.economist.com/business" data-analytics="sidebar:section"><span>Business</span></a></span><span> | <!-- -->The lost art of self-management</span></p><h2>The golden age for CEO whisperers may be coming to an end</h2></section><div><div><p><time datetime="2024-03-25T22:03:59.042Z"> <!-- -->Mar 25th 2024</time></p></div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">A</span><small>N ANONYMOUS MEMO</small> briefly circled the web in March. The authors, who claimed to be former partners at McKinsey, rebuked the illustrious strategy consultancy for its pursuit in recent years of “unchecked and unmanaged growth”, and chastised its leadership for, of all things, a “lack of strategic focus”. With humility typical of McKinseyites, they warned that “an organisation of genuine greatness” was at risk of being lost.</p></section><p>This article appeared in the Business section of the print edition under the headline “The lost art of self-management”</p><div data-tracking-id="content-well-chapter-list"><h2><a href="https://www.economist.com/business">Business</a> <span>March 30th 2024</span></h2><ul><li><a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big"><span>Have McKinsey and its consulting rivals got too big?</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/making-accounting-sexy-again"><span>Making accounting sexy again</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/a-marketing-victory-for-nike-is-a-business-win-for-adidas"><span>A marketing victory for Nike is a business win for Adidas</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/the-pros-and-cons-of-corporate-uniforms"><span>The pros and cons of corporate uniforms</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/regulators-are-forcing-big-tech-to-rethink-its-ai-strategy"><span>Regulators are forcing big tech to rethink its AI strategy</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/dave-calhoun-bows-out-as-chief-executive-of-boeing"><span>Dave Calhoun bows out as chief executive of Boeing</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/meet-the-digital-david-taking-on-the-google-goliath"><span>Meet the digital David taking on the Google Goliath</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the March 30th 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-03-30" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div><div><p><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Have%20McKinsey%20and%20its%20consulting%20rivals%20got%20too%20big%3F&amp;publicationDate=2024-03-25&amp;contentID=%2Fcontent%2Fh2uo27nddgkvs01g3l6va42ufik5tavk&amp;type=A&amp;orderBeanReset=TRUE" target="_blank" rel="noreferrer" data-analytics="end_of_article:reuse_this_content"><span>Reuse this content</span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Send: Open-source fork of Firefox Send (174 pts)]]></title>
            <link>https://send.vis.ee/</link>
            <guid>41887378</guid>
            <pubDate>Sat, 19 Oct 2024 12:17:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://send.vis.ee/">https://send.vis.ee/</a>, See on <a href="https://news.ycombinator.com/item?id=41887378">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[S3 as a Git remote and LFS server (114 pts)]]></title>
            <link>https://github.com/awslabs/git-remote-s3</link>
            <guid>41887004</guid>
            <pubDate>Sat, 19 Oct 2024 10:37:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/awslabs/git-remote-s3">https://github.com/awslabs/git-remote-s3</a>, See on <a href="https://news.ycombinator.com/item?id=41887004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">git-remote-s3</h2><a id="user-content-git-remote-s3" aria-label="Permalink: git-remote-s3" href="#git-remote-s3"></a></p>
<p dir="auto">This library enables to use Amazon S3 as a git remote and LFS server.</p>
<p dir="auto">It provides an implementation of a <a href="https://git-scm.com/docs/gitremote-helpers" rel="nofollow">git remote helper</a> to use S3 as a serverless Git server.</p>
<p dir="auto">It also provide an implementation of the <a href="https://github.com/git-lfs/git-lfs/blob/main/docs/custom-transfers.md">git-lfs custom transfer</a> to enable pushing LFS managed files to the same S3 bucket used as remote.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><code>git-remote-s3</code> is a Python script and works with any Python version &gt;= 3.9.</p>
<p dir="auto">Run:</p>
<div data-snippet-clipboard-copy-content="pip install git-remote-s3"><pre><code>pip install git-remote-s3
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prerequisites</h2><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<p dir="auto">Before you can use <code>git-remote-s3</code>, you must:</p>
<ul dir="auto">
<li>
<p dir="auto">Complete initial configuration:</p>
<ul dir="auto">
<li>Creating an AWS account</li>
<li>Configuring an IAM user or role</li>
</ul>
</li>
<li>
<p dir="auto">Create an AWS S3 bucket (or have one already) in your AWS account.</p>
</li>
<li>
<p dir="auto">Attach a minimal policy to that user/role that allows the to the S3 bucket:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;Sid&quot;: &quot;S3Access&quot;,
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Action&quot;: [&quot;s3:PutObject&quot;, &quot;s3:GetObject&quot;, &quot;s3:ListBucket&quot;],
  &quot;Resource&quot;: [&quot;arn:aws:s3:::<BUCKET>&quot;, &quot;arn:aws:s3:::*/*&quot;]
}"><pre>{
  <span>"Sid"</span>: <span><span>"</span>S3Access<span>"</span></span>,
  <span>"Effect"</span>: <span><span>"</span>Allow<span>"</span></span>,
  <span>"Action"</span>: [<span><span>"</span>s3:PutObject<span>"</span></span>, <span><span>"</span>s3:GetObject<span>"</span></span>, <span><span>"</span>s3:ListBucket<span>"</span></span>],
  <span>"Resource"</span>: [<span><span>"</span>arn:aws:s3:::&lt;BUCKET&gt;<span>"</span></span>, <span><span>"</span>arn:aws:s3:::*/*<span>"</span></span>]
}</pre></div>
</li>
<li>
<p dir="auto">Optional (but recommended) - use <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html" rel="nofollow">SSE-KMS Bucket keys to encrypt the content of the bucket</a>, ensure the user/role create previously has the permission to access and use the key.</p>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;Sid&quot;: &quot;KMSAccess&quot;,
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Action&quot;: [&quot;kms:Decrypt&quot;, &quot;kms:GenerateDataKey&quot;],
  &quot;Resource&quot;: [&quot;arn:aws:kms:<REGION>:<ACCOUNT>:key/<KEY_ID>&quot;]
}"><pre>{
  <span>"Sid"</span>: <span><span>"</span>KMSAccess<span>"</span></span>,
  <span>"Effect"</span>: <span><span>"</span>Allow<span>"</span></span>,
  <span>"Action"</span>: [<span><span>"</span>kms:Decrypt<span>"</span></span>, <span><span>"</span>kms:GenerateDataKey<span>"</span></span>],
  <span>"Resource"</span>: [<span><span>"</span>arn:aws:kms:&lt;REGION&gt;:&lt;ACCOUNT&gt;:key/&lt;KEY_ID&gt;<span>"</span></span>]
}</pre></div>
<ul dir="auto">
<li>Install Python and its package manager, pip, if they are not already installed. To download and install the latest version of Python, <a href="https://www.python.org/" rel="nofollow">visit the Python website</a>.</li>
<li>Install Git on your Linux, macOS, Windows, or Unix computer.</li>
<li>Install the latest version of the AWS CLI on your Linux, macOS, Windows, or Unix computer. You can find instructions <a href="https://docs.aws.amazon.com/cli/latest/userguide/installing.html" rel="nofollow">here</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data encryption</h3><a id="user-content-data-encryption" aria-label="Permalink: Data encryption" href="#data-encryption"></a></p>
<p dir="auto">All data is encrypted at rest and in transit by default. To add an additional layer of security you can use customer managed KMS keys to encrypt the data at rest on the S3 bucket. We recommend to use <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html" rel="nofollow">Bucket keys</a> to minimize the KMS costs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Access control</h3><a id="user-content-access-control" aria-label="Permalink: Access control" href="#access-control"></a></p>
<p dir="auto">Access control to the remote is ensured via IAM permissions, and can be controlled at:</p>
<ul dir="auto">
<li>bucket level</li>
<li>prefix level (you can use prefixes to store multiple repos in the same S3 bucket thus minimizing the setup effort)</li>
<li>KMS key level</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use S3 remotes</h2><a id="user-content-use-s3-remotes" aria-label="Permalink: Use S3 remotes" href="#use-s3-remotes"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Create a new repo</h2><a id="user-content-create-a-new-repo" aria-label="Permalink: Create a new repo" href="#create-a-new-repo"></a></p>
<p dir="auto">S3 remotes are identified by the prefix <code>s3://</code> and at the bare minimum specify the name of the bucket. You can also provide a key prefix as in <code>s3://my-git-bucket/my-repo</code> and a profile <code>s3://my-profile@my-git-bucket/myrepo</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir my-repo
cd my-repo
git init
git remote add origin s3://my-git-bucket/my-repo"><pre>mkdir my-repo
<span>cd</span> my-repo
git init
git remote add origin s3://my-git-bucket/my-repo</pre></div>
<p dir="auto">You can then add a file, commit and push the changes to the remote:</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &quot;Hello&quot; > hello.txt
git add -A
git commit -a -m &quot;hello&quot;
git push --set-upstream origin main"><pre><span>echo</span> <span><span>"</span>Hello<span>"</span></span> <span>&gt;</span> hello.txt
git add -A
git commit -a -m <span><span>"</span>hello<span>"</span></span>
git push --set-upstream origin main</pre></div>
<p dir="auto">The remote HEAD is set to track the branch that has been pushed first to the remote repo. To change the remote HEAD branch, delete the HEAD object <code>s3://&lt;bucket&gt;/&lt;prefix&gt;/HEAD</code> and then run <code>git-remote-s3 doctor s3://&lt;bucket&gt;/&lt;prefix&gt;</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Clone a repo</h2><a id="user-content-clone-a-repo" aria-label="Permalink: Clone a repo" href="#clone-a-repo"></a></p>
<p dir="auto">To clone the repo to another folder just use the normal git syntax using the s3 URI as remote:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone s3://my-git-bucket/my-repo my-repo-clone"><pre>git clone s3://my-git-bucket/my-repo my-repo-clone</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Branches, etc.</h2><a id="user-content-branches-etc" aria-label="Permalink: Branches, etc." href="#branches-etc"></a></p>
<p dir="auto">Creating branches and pushing them works as normal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd my-repo
git checkout -b new_branch
touch new_file.txt
git add -A
git commit -a -m &quot;new file&quot;
git push origin new_branch"><pre><span>cd</span> my-repo
git checkout -b new_branch
touch new_file.txt
git add -A
git commit -a -m <span><span>"</span>new file<span>"</span></span>
git push origin new_branch</pre></div>
<p dir="auto">All git operations that do not rely on communication with the server should work as usual (eg <code>git merge</code>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">LFS</h2><a id="user-content-lfs" aria-label="Permalink: LFS" href="#lfs"></a></p>
<p dir="auto">To use LFS you need to first install git-lfs. You can refer to the [official documentation]((<a href="https://git-lfs.com/" rel="nofollow">https://git-lfs.com/</a>) on how to do this on your system.</p>
<p dir="auto">Next, you need enable the S3 integration by running the following command in the repo folder:</p>

<p dir="auto">which is a short cut for:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git config --add lfs.customtransfer.lfs-s3-py.path lfs-s3-py
git config --add lfs.standalonetransferagent lfs-s3-py"><pre>git config --add lfs.customtransfer.lfs-s3-py.path lfs-s3-py
git config --add lfs.standalonetransferagent lfs-s3-py</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example use</h2><a id="user-content-example-use" aria-label="Permalink: Example use" href="#example-use"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Creating the repo and pushing</h3><a id="user-content-creating-the-repo-and-pushing" aria-label="Permalink: Creating the repo and pushing" href="#creating-the-repo-and-pushing"></a></p>
<p dir="auto">Let's assume we want to store TIFF file in LFS.</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir lfs-repo
cd lfs-repo
git init
git lfs install
lfs-s3-py install
git lfs track &quot;*.tiff&quot;
git add .gitattributes
<put file.tiff in the repo>
git add file.tiff
git commit -a -m &quot;my first tiff file&quot;
git remote add origin s3://my-git-bucket/lfs-repo
git push --set-upstream origin main"><pre>mkdir lfs-repo
<span>cd</span> lfs-repo
git init
git lfs install
lfs-s3-py install
git lfs track <span><span>"</span>*.tiff<span>"</span></span>
git add .gitattributes
<span>&lt;</span>put file.tiff <span>in</span> the repo<span>&gt;</span>
git add file.tiff
git commit -a -m <span><span>"</span>my first tiff file<span>"</span></span>
git remote add origin s3://my-git-bucket/lfs-repo
git push --set-upstream origin main</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notes about specific behaviors of Amazon S3 remotes</h2><a id="user-content-notes-about-specific-behaviors-of-amazon-s3-remotes" aria-label="Permalink: Notes about specific behaviors of Amazon S3 remotes" href="#notes-about-specific-behaviors-of-amazon-s3-remotes"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Arbitrary Amazon S3 URIs</h3><a id="user-content-arbitrary-amazon-s3-uris" aria-label="Permalink: Arbitrary Amazon S3 URIs" href="#arbitrary-amazon-s3-uris"></a></p>
<p dir="auto">An Amazon S3 URI for an valid bucket and an arbitrary prefix which does not contain the right structure under it, is considered valid.</p>
<p dir="auto"><code>git ls-remote</code> returns an empty list and <code>git clone</code> clones an empty repository for which the S3 URI is set as remote origin.</p>
<div data-snippet-clipboard-copy-content="% git clone s3://my-git-bucket/this-is-a-new-repo
Cloning into 'this-is-a-new-repo'...
warning: You appear to have cloned an empty repository.
% cd this-is-a-new-repo
% git remote -v
origin  s3://my-git-bucket/this-is-a-new-repo (fetch)
origin  s3://my-git-bucket/this-is-a-new-repo (push)"><pre><code>% git clone s3://my-git-bucket/this-is-a-new-repo
Cloning into 'this-is-a-new-repo'...
warning: You appear to have cloned an empty repository.
% cd this-is-a-new-repo
% git remote -v
origin  s3://my-git-bucket/this-is-a-new-repo (fetch)
origin  s3://my-git-bucket/this-is-a-new-repo (push)
</code></pre></div>
<p dir="auto"><strong>Tip</strong>: This behavior can be used to quickly create a new git repo.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Concurrent writes</h2><a id="user-content-concurrent-writes" aria-label="Permalink: Concurrent writes" href="#concurrent-writes"></a></p>
<p dir="auto">Due to the distributed nature of <code>git</code>, there might be cases (albeit rare) where 2 or more <code>git push</code> are executed at the same time by different user with their own modification of the same branch.</p>
<p dir="auto">The git command executes the push in 2 steps:</p>
<ol dir="auto">
<li>first it checks if the remote reference is the correct ancestor for the commit being pushed</li>
<li>if that is correct it invokes the <code>git-remote-s3</code> command which writes the bundle to the S3 bucket at the <code>refs/heads/&lt;branch&gt;</code> path</li>
</ol>
<p dir="auto">In case two (or more) <code>git push</code> command are executed at the same time from different clients, at step 1 the same valid ref is fetched, hence both clients proceed with step 2, resulting in multiple bundles being stored in S3.</p>
<p dir="auto">The branch has now multiple head references, and any subsequent <code>git push</code> fails with the error:</p>
<div data-snippet-clipboard-copy-content="error: dst refspec refs/heads/<branch>> matches more than one
error: failed to push some refs to 's3://<bucket>/<prefix>'"><pre><code>error: dst refspec refs/heads/&lt;branch&gt;&gt; matches more than one
error: failed to push some refs to 's3://&lt;bucket&gt;/&lt;prefix&gt;'
</code></pre></div>
<p dir="auto">To fix this issue, run the <code>git-remote-s3 doctor &lt;s3-uri&gt;</code> command. By default it will create a new branch for every bundle that should not be retained. The user can then checkout the branch locally and merge it to the original branch. If you want instead to remove the bundle, specify <code>--delete-bundle</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Clone the repo</h3><a id="user-content-clone-the-repo" aria-label="Permalink: Clone the repo" href="#clone-the-repo"></a></p>
<p dir="auto">When cloning a repo using the S3 remote for LFS, <code>git-lfs</code> can't know how to fetch the files since we have yet to add the configuration.</p>
<p dir="auto">It involves 2 extra steps.</p>
<div dir="auto" data-snippet-clipboard-copy-content="% git clone s3://my-git-bucket/lfs-repo lfs-repo-clone
Error downloading object: file.tiff (54238cf): Smudge error: Error downloading file.tiff (54238cfaaaa42dda05da0e12bf8ee3156763fa35296085ccdef63b13a87837c5): batch request: ssh: Could not resolve hostname s3: Name or service not known: exit status 255
..."><pre>% git clone s3://my-git-bucket/lfs-repo lfs-repo-clone
Error downloading object: file.tiff (54238cf): Smudge error: Error downloading file.tiff (54238cfaaaa42dda05da0e12bf8ee3156763fa35296085ccdef63b13a87837c5): batch request: ssh: Could not resolve hostname s3: Name or service not known: <span>exit</span> status 255
...</pre></div>
<p dir="auto">To fix:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd lfs-repo-clone
lfs-s3-py install
git reset --hard main"><pre><span>cd</span> lfs-repo-clone
lfs-s3-py install
git reset --hard main</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Manage the Amazon S3 remote</h2><a id="user-content-manage-the-amazon-s3-remote" aria-label="Permalink: Manage the Amazon S3 remote" href="#manage-the-amazon-s3-remote"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Delete branches</h2><a id="user-content-delete-branches" aria-label="Permalink: Delete branches" href="#delete-branches"></a></p>
<p dir="auto">To remove remote branches that are not used anymore you can use the <code>git-s3 delete-branch &lt;s3uri&gt; -b &lt;branch_name&gt;</code> command. This command deletes the bundle object(s) from Amazon S3 under the branch path.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Protected branches</h2><a id="user-content-protected-branches" aria-label="Permalink: Protected branches" href="#protected-branches"></a></p>
<p dir="auto">To protect/unprotect a branch run <code>git s3 protect &lt;remote&gt; &lt;branch-name&gt;</code> respectively <code>git s3 unprotect &lt;remote&gt; &lt;branch-name&gt;</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Under the hood</h2><a id="user-content-under-the-hood" aria-label="Permalink: Under the hood" href="#under-the-hood"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How S3 remote work</h2><a id="user-content-how-s3-remote-work" aria-label="Permalink: How S3 remote work" href="#how-s3-remote-work"></a></p>
<p dir="auto">Bundles are stored in the S3 bucket as <code>&lt;prefix&gt;/&lt;ref&gt;/&lt;sha&gt;.bundle</code>.</p>
<p dir="auto">When listing remote ref (eg explicitly via <code>git ls-remote</code>) we list all the keys present under the given .</p>
<p dir="auto">When pushing a new ref (eg a commit), we get the sha of the ref, we bundle the ref via <code>git bundle create &lt;sha&gt;.bundle &lt;ref&gt;</code> and store it to S3 according the schema above.</p>
<p dir="auto">If the push is successful, the code removes the previous bundle associated to the ref.</p>
<p dir="auto">If two user concurrently push a commit based on the same current branch head to the remote both bundles would be written to the repo and the current bundle removed. No data is lost, but no further push will be possible until all bundles but one are removed.
For this you can use the <code>git s3 doctor &lt;remote&gt;</code> command.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How LFS work</h2><a id="user-content-how-lfs-work" aria-label="Permalink: How LFS work" href="#how-lfs-work"></a></p>
<p dir="auto">The LFS integration stores the file in the bucket defined by the remote URI, under a key <code>&lt;prefix&gt;/lfs/&lt;oid&gt;</code>, where oid is the unique identifier assigned by git-lfs to the file.</p>
<p dir="auto">If an object with the same key already exists, git-lfs-s3 does not upload it again.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Debugging</h2><a id="user-content-debugging" aria-label="Permalink: Debugging" href="#debugging"></a></p>
<p dir="auto">Use <code>--verbose</code> flag to print some debug information when performing git operations. Logs will be put to stderr.</p>
<p dir="auto">For LFS operations you can enable and disable debug logging via <code>git-lfs-s3 enable-debug</code> and <code>git-lfs-s3 disable-debug</code> respectively. Logs are put in <code>.git/lfs/tmp/git-lfs-s3.log</code> in the repo.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">The git S3 integration was inspired by the work of Bryan Gahagan on <a href="https://github.com/bgahagan/git-remote-s3">git-remote-s3</a>.</p>
<p dir="auto">The LFS implementation benefitted from <a href="https://github.com/nicolas-graves/lfs-s3">lfs-s3</a> by <a href="https://github.com/nicolas-graves">@nicolas-graves</a>. If you do not need to use the git-remote-s3 transport you are should use that project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The long road to lazy preemption in the Linux CPU scheduler (203 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</link>
            <guid>41886256</guid>
            <pubDate>Sat, 19 Oct 2024 07:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/">https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</a>, See on <a href="https://news.ycombinator.com/item?id=41886256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
The kernel's CPU scheduler currently offers several preemption modes that
implement a range of tradeoffs between system throughput and response time.
Back in September 2023, a <a href="https://lwn.net/Articles/944686/">discussion
on scheduling</a> led to the concept of "lazy preemption", which could
simplify scheduling in the kernel while providing better results.  Things
went quiet for a while, but lazy preemption has returned in the form of <a href="https://lwn.net/ml/all/20241007074609.447006177@infradead.org">this patch series</a>
from Peter Zijlstra.  While the concept appears to work well, there is
still a fair amount of work to be done.
</p><h4>Some review</h4>
<p>
Current kernels have four different modes that regulate when one task can
be preempted in favor of another.  <tt>PREEMPT_NONE</tt>, the simplest
mode, only allows preemption to happen when the running task has exhausted
its time slice.  <tt>PREEMPT_VOLUNTARY</tt> adds a large number of points
within the kernel where preemption can happen if needed.
<tt>PREEMPT_FULL</tt> allows preemption at almost any point except places
in the kernel that prevent it, such as when a spinlock is held.  Finally,
<tt>PREEMPT_RT</tt> prioritizes preemption over most other things, even
making most spinlock-holding code preemptible.
</p><p>
A higher level of preemption enables the system to respond more quickly to
events; whether an event is the movement of a mouse or an "imminent
meltdown" signal from a nuclear reactor, faster response tends to be more
gratifying.  But a higher level of preemption can hurt the overall
throughput of the system; workloads with a lot of long-running,
CPU-intensive tasks tend to benefit from being disturbed as little as
possible.  More frequent preemption can also lead to higher lock
contention.  That is why the different modes exist; the optimal preemption
mode will vary for different workloads.
</p><p>
Most distributions ship kernels built with the <tt>PREEMPT_DYNAMIC</tt>
pseudo-mode, which allows any of the first three modes to be selected at
boot time, with <tt>PREEMPT_VOLUNTARY</tt> being the default.  On systems
with debugfs mounted, the current mode can be read from
<tt>/sys/kernel/debug/sched/preempt</tt>.
</p><p>
<tt>PREEMPT_NONE</tt> and <tt>PREEMPT_VOLUNTARY</tt> do not allow the
arbitrary preemption of code running in the kernel; there are times when
that can lead to excessive latency even in systems where minimal latency is
not prioritized.  This problem is the result of places in the kernel where
a large amount of work can be done; if that work is allowed to run
unchecked, it can disrupt the scheduling of the system as a whole.  To get
around this problem, long-running loops have been sprinkled with calls to
<tt>cond_resched()</tt>, each of which is an additional voluntary
preemption point that is active even in the <tt>PREEMPT_NONE</tt> mode.
There are hundreds of these calls in the kernel.
</p><p>
There are some problems with this approach.  <tt>cond_resched()</tt> is a
form of heuristic that only works in the places where a developer has
thought to put it.  Some calls are surely unnecessary, while there will be
other places in the kernel that could benefit from <tt>cond_resched()</tt>
calls, but do not have them.  The use of <tt>cond_resched()</tt>, at its
core, takes a decision that should be confined to the scheduling code and
spreads it throughout the kernel.  It is, in short, a bit of a hack that
mostly works, but which could be done better.
</p><h4>Doing better</h4>
<p>
The tracking of whether a given task can be preempted at any moment is a
complicated affair that must take into account several variables; see <a href="https://lwn.net/Articles/945422/">this article</a> and <a href="https://lwn.net/Articles/831678/">this article</a> for details.  One of those
variables is a simple flag, <tt>TIF_NEED_RESCHED</tt>, that indicates the
presence of a higher-priority task that is waiting for access to the CPU.
Events such as waking a high-priority task can cause that flag to be set in
whatever task is currently running.  In the absence of this flag, there is
no need for the kernel to consider preempting the current task.
</p><p>
There are various points where the kernel can notice that flag and cause
the currently running task to be preempted.  The scheduler's timer tick is
one example; any time a task returns to user space from a system call is
another.  The completion of an interrupt handler is yet another, but that
check, which can cause preemption to happen any time that interrupts are
enabled, is only enabled in <tt>PREEMPT_FULL</tt> kernels.  A call to
<tt>cond_resched()</tt> will also check that flag and, if it is set, call
into the scheduler to yield the CPU to the other task.
</p><p>
The lazy-preemption patches are simple at their core; they add another
flag, <tt>TIF_NEED_RESCHED_LAZY</tt>, that indicates a need for
rescheduling at some point, but not necessarily right away.  In the lazy
preemption mode (<tt>PREEMPT_LAZY</tt>), most events will set the new flag
rather than <tt>TIF_NEED_RESCHED</tt>.  At points like the return to user
space from the kernel, either flag will lead to a call into the scheduler.
At the voluntary preemption points and in the return-from interrupt path,
though, only <tt>TIF_NEED_RESCHED</tt> is checked.
</p><p>
The result of this change is that, in lazy-preemption mode, most events in
the kernel will not cause the current task to be preempted.  That task
<i>should</i> be preempted eventually, though.  To make that happen, the
kernel's timer-tick handler will check whether
<tt>TIF_NEED_RESCHED_LAZY</tt> is set; if so, <tt>TIF_NEED_RESCHED</tt>
will also be set, possibly causing the running task to be preempted.  Tasks
will generally end up running for something close to their full time slice
unless they give up the CPU voluntarily, which should lead to good
throughput. 
</p><p>
With these changes, the lazy-preemption mode can, like
<tt>PREEMPT_FULL</tt>, run with kernel preemption enabled at (almost) all
times.  Preemption <i>can</i> happen any time that the preemption counter
says that it should.  That allows long-running kernel code to be preempted
whenever other conditions do not prevent it.  It also allows preemption to
happen quickly in those cases where it is truly needed.  For example, 
should a realtime task become runnable, as the result of
handling an interrupt, for example, the <tt>TIF_NEED_RESCHED</tt> flag will
be set, leading to an almost immediate preemption.  There will be no need
to wait for the timer tick in such cases.
</p><p>
Preemption will <i>not</i> happen, though, if only
<tt>TIF_NEED_RESCHED_LAZY</tt> is set, which will be the case much of the
time. So a <tt>PREEMPT_LAZY</tt> kernel will be far less likely to preempt
a running task than a <tt>PREEMPT_FULL</tt> kernel.
</p><h4>Removing <tt>cond_resched()</tt> — eventually</h4>
<p>
The end goal of this work is to have a scheduler with only two non-realtime
modes: <tt>PREEMPT_LAZY</tt> and <tt>PREEMPT_FULL</tt>.  The lazy mode will
occupy a place between <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt>, replacing both of them.  It will, however, not
need the voluntary preemption points that were added for the two modes it
replaces.  Since preemption can now happen almost anywhere, there is no
longer a need to enable it in specific spots.
</p><p>
For now, though, the <tt>cond_resched()</tt> calls remain; if nothing else,
they are required for as long as the <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt> modes exist.  Those calls also help to ensure
that problems are not introduced while lazy preemption is being stabilized.
</p><p>
In the current patch set, <tt>cond_resched()</tt> only checks
<tt>TIF_NEED_RESCHED</tt>, meaning that preemption will be deferred in many
situations where it will happen immediately from <tt>cond_resched()</tt> in
<tt>PREEMPT_VOLUNTARY</tt> or <tt>PREEMPT_NONE</tt> mode.
Steve Rostedt <a href="https://lwn.net/ml/all/20241009100133.2569e2a7@gandalf.local.home">questioned</a>
this change, asking whether <tt>cond_resched()</tt> should retain its older
meaning, at least for the <tt>PREEMPT_VOLUNTARY</tt> case.  Even though
<tt>PREEMPT_VOLUNTARY</tt> is slated for eventual removal, he thought,
keeping the older behavior could help to ease the transition.
</p><p>
Thomas Gleixner
<a href="https://lwn.net/ml/all/87h69lqbk0.ffs@tglx">answered</a> that only checking
<tt>TIF_NEED_RESCHED</tt> is the correct choice, since it will help in the
process of removing the <tt>cond_resched()</tt> calls entirely:
</p><blockquote>
	That forces us to look at all of them and figure out whether they
	need to be extended to include the lazy bit or not. Those which do
	not need it can be eliminated when LAZY is in effect because that
	will preempt on the next possible preemption point once the
	non-lazy bit is set in the tick.
</blockquote>
<p>
He added that he expects "<q>less than 5%</q>" of the
<tt>cond_resched()</tt> calls need to check <tt>TIF_NEED_RESCHED_LAZY</tt>
and, thus, will need to remain even after the transition to
<tt>PREEMPT_LAZY</tt> is complete.
</p><p>
Before then, though, there are hundreds of <tt>cond_resched()</tt> calls
that need to be checked and, for most of them at least, removed.  Many
other details have to be dealt with as well; <a href="https://lwn.net/ml/all/20241009165411.3426937-1-ankur.a.arora@oracle.com">this patch
set</a> from Ankur Arora addresses a few of them.  There is
also, of course, the need for extensive performance testing; Mike Galbraith
has made <a href="https://lwn.net/ml/all/579b7ea34ef6e2f7c955abdfc0929fe1af36faef.camel@gmx.de">an
early start</a> on that work, showing that throughput with lazy preemption
falls just short of that with <tt>PREEMPT_VOLUNTARY</tt>.
</p><p>
It all adds up to a lot to be done still, but the end result
of the lazy-preemption work should be a kernel that is a bit smaller and
simpler while delivering predictable latencies without the need to
sprinkle scheduler-related calls throughout the code.  That seems like a
better solution, but getting there is going to take some time.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Preemption">Preemption</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Scheduler">Scheduler</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
    </channel>
</rss>