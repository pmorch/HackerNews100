<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 07 Jul 2024 12:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Malloc broke Serenity's JPGLoader, or: how to win the lottery (2021) (113 pts)]]></title>
            <link>https://sin-ack.github.io/posts/jpg-loader-bork/</link>
            <guid>40896102</guid>
            <pubDate>Sun, 07 Jul 2024 08:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sin-ack.github.io/posts/jpg-loader-bork/">https://sin-ack.github.io/posts/jpg-loader-bork/</a>, See on <a href="https://news.ycombinator.com/item?id=40896102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I got the chance to investigate an interesting bug in
<a href="https://serenityos.org/">SerenityOS</a> this week. It was related to the decoding
of JPG images in the operating system. For some reason, when a JPG image is
viewed, it comes out like this:</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/lenna-broken.png" alt="Lenna,
showing up with incorrect colors."><figcaption>
            <p>Lenna,
showing up with incorrect colors.</p>
        </figcaption>
</figure>

<p>Weird, huh? Also seems like a simple confusion of RGB vs. BGR. And sure enough,
making the following change on <code>JPGLoader.cpp</code>:</p>
<div><pre tabindex="0"><code data-lang="diff"><span><span><span>-   const Color color { (u8)block.y[pixel_index], (u8)block.cb[pixel_index], (u8)block.cr[pixel_index] };
</span></span></span><span><span><span></span><span>+   const Color color { (u8)block.cr[pixel_index], (u8)block.cb[pixel_index], (u8)block.y[pixel_index] };
</span></span></span><span><span><span></span>    context.bitmap-&gt;set_pixel(x, y, color);
</span></span></code></pre></div><p>makes the image show up correctly. Case closed!</p>
<p>…not. Why did this even break in the first place?</p>
<p>The last non-reverted change
to <code>JPGLoader.cpp</code> is reported by Git to be over a month ago:</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/commitlog.png" alt="Commit log
at the time of JPGLoader being broken."><figcaption>
            <p>Commit log
at the time of JPGLoader being broken.</p>
        </figcaption>
</figure>

<p>And I remembered very well that JPG images worked just fine about a week or two
ago, as I had set a JPG image as my background and would’ve noticed if it looked
wrong.</p>
<p>Well, time to bisect! I didn’t know when to start, so I picked the last 1000
commits (where images showed up correctly), and started bisecting.</p>
<h2 id="bisect-hell">Bisect hell</h2>
<p>Please skip to the next section if you’d like to avoid C++ whining.</p>
<p>SerenityOS, being an operating system project that focuses on doing its own
thing, also has its own standard library called AK (which stands for
<span title="Andreas Kling">Agnostic Kit</span>).
This library is analogous to
C++’s STL, but is more readable due to not having to support a myriad of
different operating systems and not having to contort oneself to conform to
<a href="https://www.gnu.org/prep/standards/">hideous coding standards</a>.</p>
<p>One of the nice things about having the standard library in the same repository
as its users is that making changes is very easy as the change propagates to
everyone who pulls from master. However, this is a double edged sword when it
comes to C++; because <em>everyone</em> includes the standard library (even if you
don’t include it, your includes will), and because C++’s template system means
that everything that’s templated has to include the definitions in the header as
well, this means that <em>anytime</em> someone touches AK in a commit, the <em>entire</em>
operating system has to be rebuilt (~3400 files at the time of writing).
<code>ccache</code>, while being useful in many situations, cannot handle this case.
Additionally, due to the breakneck pace of the SerenityOS project, someone ends
up touching AK at least once every 100 commits or so.</p>
<p>As a result, during the 1000 commits I ended up bisecting for, I had to build
SerenityOS from scratch about 4-5 times on a 2011 laptop with Sandy Bridge
Mobile. While this isn’t the fault of the project, I’m still mad.</p>
<h2 id="bisect-results">Bisect results</h2>
<p>So, after bisecting 1000 commits, rebuilding the OS from scratch several times
and pulling my hair out because I didn’t understand how bisect worked, I
<em>finally</em> found the commit that broke JPG images. Drumroll please…</p>
<pre tabindex="0"><code>f89e8fb71a4893911ee5125f34bd5bbb99327d33
Author:     Gunnar Beutner
AuthorDate: Sat May 15 10:06:41 2021 +0200

AK+LibC: Implement malloc_good_size() and use it for Vector/HashTable

This implements the macOS API malloc_good_size() which returns the
true allocation size for a given requested allocation size. This
allows us to make use of all the available memory in a malloc chunk.

For example, for a malloc request of 35 bytes our malloc would
internally use a chunk of size 64, however the remaining 29 bytes
would be unused.

Knowing the true allocation size allows us to request more usable
memory that would otherwise be wasted and make that available for
Vector, HashTable and potentially other callers in the future.
</code></pre><p>Uh, sorry, what?</p>
<p>But it was. Building the commit right before this one showed the image
correctly:</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/lenna-beforebroken.png" alt="Lenna, before it was broken."><figcaption>
            <p>Lenna, before it was broken.</p>
        </figcaption>
</figure>

<p>Initial discussion with other developers made me think that either <code>JPGLoader</code>
or something else up the chain is depending on the capacity of a <code>Vector</code> and
writing directly into it when it really shouldn’t. So I began hunting down
possible causes.</p>
<h2 id="a-surprising-discovery">A surprising discovery</h2>
<p>The commit seemed to touch the two main container types: <code>HashTable</code> (which
<code>HashMap</code> depends on) and <code>Vector</code>. Both are used in the <code>JPGLoader</code> code, and
either could be the cause of the problem here.</p>
<p>I picked <code>HashTable</code> at random, removed the offending line:</p>
<div><pre tabindex="0"><code data-lang="diff"><span><span>         new_capacity = max(new_capacity, static_cast&lt;size_t&gt;(4));
</span></span><span><span><span>-        new_capacity = kmalloc_good_size(new_capacity * sizeof(Bucket)) / sizeof(Bucket);
</span></span></span><span><span><span></span>
</span></span><span><span>         auto* old_buckets = m_buckets;
</span></span></code></pre></div><p>and rebuilt the system, while joking around in chat about how this can’t
possibly be the problem.</p>
<p>…but then it fixed the issue.</p>
<p>What? How? Why does the <code>HashTable</code> capacity being different matter?! <code>HashTable</code>
isn’t even a contiguous stream of data you can write to, so you shouldn’t even
be able to assume its capacity!</p>
<p>Before I present the full story to you, I’ll have give a brief background on how
<code>JPGLoader</code> used to work.</p>
<h2 id="non-deterministic-serial-component-iteration">Non-deterministic serial component iteration</h2>
<p>That’s really the most appropriate title I can give this section.</p>
<p><code>JPGLoader</code> previously would read information about a JPG component from the
“Start of Frame” section of the JPG file into a struct called <code>Component</code>, and
then store that in a <code>HashTable</code>. Of course, the order in a JPG file for each
component should always be <code>Y</code>, <code>Cb</code> and <code>Cr</code>, so the <code>Component</code> struct would
idiosyncratically carry a <code>serial_id</code>, which was the position of the <code>Component</code>
within the file. The reason the <code>Component</code>s were in a hash table was that they
would then be checked against the component ordering in a “Start of Scan”
section to make sure all the components in the SOS section are in the expected
order. Why this code was written this way instead of just checking against the
ID by linearly iterating over the <code>Component</code>s, I have no idea.</p>
<p>Anyway, these components would then be iterated over during the different
decoding stages of <code>JPGLoader</code>, during which the component information would be
used to perform transforms on macroblocks.</p>
<h2 id="getting-close">Getting close</h2>
<p>When I added some debug prints to see how the components were read, I saw this
in the commit with the broken colors:</p>
<pre tabindex="0"><code>ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 2
ImageDecoder(33:33): Looking at component 1
ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 2
ImageDecoder(33:33): Looking at component 1
...
</code></pre><p>And when I checked out the previous commit, I saw this:</p>
<pre tabindex="0"><code>ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 1
ImageDecoder(33:33): Looking at component 2
ImageDecoder(33:33): Looking at component 0
ImageDecoder(33:33): Looking at component 1
ImageDecoder(33:33): Looking at component 2
...
</code></pre><p>The final piece of the puzzle: During the discussion of this bug with
<a href="https://twitter.com/the_semicolon_">CxByte</a> at my wit’s end, we ended up
manually messing with the order of the components to see what would happen, and
got this message:</p>
<pre tabindex="0"><code>ImageDecoder(32:32): Huffman stream exhausted. This could be an error!
ImageDecoder(32:32): Failed to build Macroblock 3277
</code></pre><p>…ah. Of course. It’s a stream.</p>
<h2 id="the-bug">The bug</h2>
<p>So, here’s a quick rundown of the bug:</p>
<ul>
<li>Someone used a <code>HashTable</code> to store objects that should be ordered, then
iterated over it using the basic <code>HashTable</code> iterator</li>
<li>The hash of the component IDs in the JPG files were passed into <code>int_hash</code>
for hash table bucket selection</li>
<li>Not only did they get <em>just the right value</em> to be in order, they got
inserted into a HashTable with <em>just the right amount</em> of buckets to be in
the correct order</li>
<li>This caused the Huffman stream to be read in the correct order for each
component, thereby masking the bug</li>
<li>This bug was masked since <code>JPGLoader</code>’s inception by sheer luck until someone
messed with the size of the <code>HashTable</code></li>
</ul>
<h2 id="the-fix">The fix</h2>
<p>And finally, at the end of about 10 hours of debugging, <a href="https://github.com/SerenityOS/Serenity/commit/a10ad24c760bfe713f1493e49dff7da16d14bf39">here is the
commit</a>
that fixed this monster of a bug:</p>
<pre tabindex="0"><code>a10ad24c760bfe713f1493e49dff7da16d14bf39
Author:     sin-ack
AuthorDate: Mon May 31 15:22:04 2021 +0000
Commit:     Linus Groh
CommitDate: Mon May 31 17:26:11 2021 +0100

LibGfx: Make JPGLoader iterate components deterministically

JPGLoader used to store component information in a HashTable, indexed
by the ID assigned by the JPEG file.  This was fine for most purposes,
however after f89e8fb7 this was revealed to be a flawed implementation
which causes non-deterministic iteration over components.

This issue was previously masked by a perfect storm of int_hash being
stable for the integer values 0, 1 and 2; and AK::HashTable having just
the right amount of buckets for the components to be ordered correctly
after being hashed with int_hash. However, after f89e8fb7,
malloc_good_size was used for determining the amount of space for
allocation; this caused the ordering of the components to change, and
images started showing up with the red and blue channels reversed. The
issue was finally determined to be inconsistent ordering after randomly
changing the order of the components caused Huffman decoding to fail.

This was the result of about 10 hours of hair-pulling and repeatedly
doing full rebuilds due to bisecting between commits that touched AK.
Gunnar, I like you, but please don't make me go through this again. :^)

Credits to Andrew Kaster, bgianf, CxByte and Gunnar for the debugging
help.
</code></pre><h2 id="final-thoughts">Final thoughts</h2>
<p>Sometimes the simplest problems might point at big mistakes within. I could’ve
probably fixed this by just swapping the order of the arguments right then and
there, and it would’ve worked; until someone else came along and changed the
order again. Thankfully, now we will be able to look at tubas with correct
colors in peace.</p>
<figure><img src="https://sin-ack.github.io/images/serenity-jpgloader/tuba.png" alt="A tuba with the
correct colors. Source: music123.com"><figcaption>
            <p>A tuba with the
correct colors. Source: music123.com</p>
        </figcaption>
</figure>

<h2 id="thanks">Thanks</h2>
<p>Thanks to CxByte, Gunnar, Andrew and Brian for their help with debugging this,
and their helpful tips. Gunnar in particular was the one who uncovered this bug,
and despite my satirical jab in the commit message helped uncover this very
interesting bug, so he’s the one who made this post possible.</p>
<p>Also, thanks to the person who introduced this bug (the commit log gets a little
fuzzy, so I’m not quite sure who did) and hope he buys a lottery ticket. :^)</p>
<p>And thank you for reading. I’ll probably post sometime in the future, but work’s
been keeping me busy. But maybe I’ll find another bug to suck me into a rabbit
hole. Stay tuned!</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: BeaconDB – An Alternative to Mozilla Location Services (116 pts)]]></title>
            <link>https://beacondb.net/</link>
            <guid>40895672</guid>
            <pubDate>Sun, 07 Jul 2024 06:25:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://beacondb.net/">https://beacondb.net/</a>, See on <a href="https://news.ycombinator.com/item?id=40895672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <ul> <li><b>ethically sourced</b>: opt-in only data collection</li> <li><b>privacy friendly</b>: published information is obfuscated to protect transmitters and contributors</li> <li> <b>abuse resistant</b>: updating existing data requires information
          only available in physical range of a beacon
</li> </ul> <h2>contribute</h2> <p>
beaconDB has recently started to accept submissions. to add coverage for your area you
        can use the following apps on your phone:
</p> <ul> <li> <a href="https://github.com/mjaakko/NeoStumbler">NeoStumbler</a>:
          supports cell towers, wifi networks and bluetooth devices
<ul> <li> <a href="https://f-droid.org/packages/xyz.malkki.neostumbler.fdroid/">download on F-Droid</a> </li> <li>
in the Settings tab, set the endpoint to <code>https://beacondb.net</code> </li> </ul> </li> <li> <a href="https://github.com/zamojski/TowerCollector">Tower Collector</a>: only supports cell towers
<ul> <li> <a href="https://f-droid.org/packages/info.zamojski.soft.towercollector/">download on F-Droid</a>
or
<a href="https://play.google.com/store/apps/details?id=info.zamojski.soft.towercollector">Google Play</a> </li> <li>
in Upload Preferences, enable support for custom MLS services and
              set the address to <code>https://beacondb.net/v2/geosubmit</code> </li> </ul> </li> </ul> <p>
data you submit will be aggregated and shared under a public domain
        license. for more information on how your data is handled, see the
<a href="https://beacondb.net/privacy">privacy notice</a>.
</p> <h2>usage</h2> <p> <b>
beaconDB is experimental and should not be used by critical services
</b> </p> <p>
if you own an Android phone running the latest preview version of <a href="https://microg.org/">microG</a>, you can easily give beaconDB a spin without needing to install
        anything. in microG Settings on the Location page, pressing the three
        dots in the top right lets you set a custom service URL. you can set
        this to <code>https://beacondb.net/</code> to give beaconDB a try.
</p> <p>
as beaconDB is starting from scratch there is likely no wifi coverage
        for your area. if beaconDB can't estimate your location using wifi, it
        will fallback to an approximate cell tower location sourced from MLS'
        final data dump. note that submissions will take at least 5 minutes to
        become available in the beaconDB API.
</p> <h2>developers</h2> <p>
beaconDB hosts an endpoint at
<code>https://beacondb.net/v1/geolocate</code> which is compatible with <a href="https://ichnaea.readthedocs.io/en/latest/api/geolocate.html">Ichnaea's request format</a>. if your software has a large amount of users, please don't use this
        as a default location service. beaconDB infrastructure is not yet
        capable of handling a large amount of requests.
</p> <p>
data dumps are currently not available as I'm still researching the
        measures I need to take to protect the privacy of both contributors and
        AP owners.
</p> <hr> <ul> <li>
source code <a href="https://codeberg.org/beacondb/beacondb">on Codeberg</a> </li> <li>
chat <a href="https://matrix.to/#/#_oftc_#beacondb:matrix.org">on Matrix</a>
and <a href="irc://irc.oftc.net/#beacondb">IRC</a> </li> <li> <a href="https://codeberg.org/beacondb/beacondb/issues">bug tracker</a> </li> <li><a href="https://beacondb.net/privacy">privacy notice</a></li> <li>made by <a href="https://joel.net.au/">Joel Koen</a></li> </ul> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Where are the good resources for learning audio processing? (130 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40892812</link>
            <guid>40892812</guid>
            <pubDate>Sat, 06 Jul 2024 19:59:48 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40892812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40893374"><td></td></tr>
                <tr id="40894238"><td></td></tr>
                <tr id="40894341"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40894341" href="https://news.ycombinator.com/vote?id=40894341&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>That doesn't look terse to me, though it does require familiarity with the subject.</p><p>"The last expression can be interpreted as the Fourier superposition of the sinusoidal harmonics of [expression], i.e., an inverse Fourier series sum. In other words, [expression] is the amplitude of the k-th harmonic in the Fourier-series expansion of the periodic signal x_m(t)."</p><p>Many of the concepts are hyperlinked for reference. With the required familiarity, I would much rather read this than something that took seven pages to get to the point - say by assuming that the reader is unfamiliar with a premise out of an abundance of caution.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40893967"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40893967" href="https://news.ycombinator.com/vote?id=40893967&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Second anything from CCRMA, the inventors of FM synthesis and still the one top programs in the country/world.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40894254"><td></td></tr>
                <tr id="40894481"><td></td></tr>
                        <tr id="40894570"><td></td></tr>
            <tr id="40893962"><td></td></tr>
                  <tr id="40893889"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40893889" href="https://news.ycombinator.com/vote?id=40893889&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>Hey - one of the industry standard time stretching library is "elastique" by Zynaptiq (licensed, not open source). Used  by Ableton, FL Studio etc.</p><p>If you want to peak into some source code - you can look into Rubberband library:</p><p><a href="https://breakfastquay.com/rubberband/" rel="nofollow">https://breakfastquay.com/rubberband/</a></p><p>Rubberband is one of the time stretching/pitch shifting algorithms used in Reaper.  You can download reaper trial and listen to the results with different parameters to see how you can tweak the code and if that gets any results you're happy with:</p><p><a href="https://www.reaper.fm/" rel="nofollow">https://www.reaper.fm/</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894189"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894189" href="https://news.ycombinator.com/vote?id=40894189&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>I find [1] a good reference. A con is the examples are in matlab, but it's clear enough between the text and matlab code to write your own implementation.</p><p>Also [2] is a decent book for overall dsp concepts.</p><p>[1] DAFX - Digital Audio Effects (Second Edition) Edited by Udo Zölzer
<a href="https://dafx.de/DAFX_Book_Page_2nd_edition/index.html" rel="nofollow">https://dafx.de/DAFX_Book_Page_2nd_edition/index.html</a></p><p>[2] Understanding Digital Signal Processing, Richard Lyons</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40894433"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40894433" href="https://news.ycombinator.com/vote?id=40894433&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>lyons is a good intro but maybe a bit handwavey at times (although my copy is an edition from the 90s).</p><p>consider maybe backing it up with one of the textbooks like oppenheim (the classic) or manolakis (one that i think i remember liking).</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894318"><td></td></tr>
                  <tr id="40893936"><td></td></tr>
                <tr id="40894272"><td></td></tr>
            <tr id="40894440"><td></td></tr>
                  <tr id="40895345"><td></td></tr>
            <tr id="40893704"><td></td></tr>
                <tr id="40893743"><td></td></tr>
                  <tr id="40894894"><td></td></tr>
            <tr id="40894639"><td></td></tr>
            <tr id="40893555"><td></td></tr>
            <tr id="40893694"><td></td></tr>
            <tr id="40894583"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894583" href="https://news.ycombinator.com/vote?id=40894583&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>The Will Pirkle books have a lot of good info and code to get you started:</p><p><a href="https://www.willpirkle.com/" rel="nofollow">https://www.willpirkle.com</a></p><p>Audio programming is a lot of fun but it's the most challenging domain I've ever worked in. You have to be very careful with what you do on the audio thread. No locks, no memory allocation etc. Messing this up can result in some really ugly audio artifacts.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40893918"><td></td></tr>
            <tr id="40893955"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40893955" href="https://news.ycombinator.com/vote?id=40893955&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div><p>Audio is half art, half science. That's why I'd try to find someone with experience.</p><p>Back in university, I heard lectures on FFT and its applications to audio signal processing. So open access university courses would be the second place I'd look. The approach I always try first is to ask people I know if they can recommend a conference/meetup. For example, the annual JUCE events appear to be chock full with VST plugin developers. There's also private schools like SAE where you (or your employer) can pay for you to have an hour with one of their lecturers to ask questions.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894978"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894978" href="https://news.ycombinator.com/vote?id=40894978&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Gnu Radio can easily handle audio I/O as well as it does IQ signals from SDR front ends. It's cross platform and you just build flow graphs, which then can be executed.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40893859"><td></td></tr>
            <tr id="40894552"><td></td></tr>
            <tr id="40894554"><td></td></tr>
            <tr id="40893476"><td></td></tr>
            <tr id="40894034"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40894034" href="https://news.ycombinator.com/vote?id=40894034&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>I would pick up a microcontroller dev board that has a mic built in (Eg one of the STM32 discoveries). Also get a "codec" dev board. (Or alternatively, use the MCU's onboarod DAC). Get it to receive audio, process it using DSP, then output it, and/or save to memory. This will really force you to understand it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40894221"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40894221" href="https://news.ycombinator.com/vote?id=40894221&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Why not just use a regular laptop for this? There’s a ton of low level sound processing libraries for every OS.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40894664"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40894664" href="https://news.ycombinator.com/vote?id=40894664&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Bad advice. I have no idea how using a microcontroller would help someone understand pitchshifting algorithms.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40893834"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40893834" href="https://news.ycombinator.com/vote?id=40893834&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Use LabView as a calculation engine to do experiments. The advantage is you get system-like diagrams.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40895055"><td></td></tr>
                <tr id="40895577"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40895577" href="https://news.ycombinator.com/vote?id=40895577&amp;how=up&amp;goto=item%3Fid%3D40892812"></a></center>    </td><td><br><div>
                  <p>Chris @ airwindows is super nice to release all his plugins and source code for free. But the code quality is really bad. That doesn't matter if you're using a plugin in the production of a song and it works well. But for learning dsp, it's a bad resource.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to think in writing (244 pts)]]></title>
            <link>https://www.henrikkarlsson.xyz/p/writing-to-think</link>
            <guid>40892298</guid>
            <pubDate>Sat, 06 Jul 2024 18:44:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.henrikkarlsson.xyz/p/writing-to-think">https://www.henrikkarlsson.xyz/p/writing-to-think</a>, See on <a href="https://news.ycombinator.com/item?id=40892298">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png" width="750" height="587" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d8bec767-3242-4428-a281-0cdc3182ff75_750x587.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:587,&quot;width&quot;:750,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8bec767-3242-4428-a281-0cdc3182ff75_750x587.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><blockquote><p><em>The reason I've spent so long establishing this rather obvious point [that writing helps you refine your thinking] is that it leads to another that many people will find shocking. If writing down your ideas always makes them more precise and more complete, then no one who hasn't written about a topic has fully formed ideas about it. And someone who never writes has no fully formed ideas about anything nontrivial.</em></p><p><em>It feels to them as if they do, especially if they're not in the habit of critically examining their own thinking. Ideas can feel complete. It's only when you try to put them into words that you discover they're not. So if you never subject your ideas to that test, you'll not only never have fully formed ideas, but also never realize it.</em></p><p>—Paul Graham</p></blockquote><p>When I sit down to write, the meadow is still sunk in darkness, and above it, satellites pass by, one after the other. My thoughts are flighty and shapeless; they morph as I approach them. But when I type, it is as if I pin my thoughts to the table. I can examine them.</p><p><span>But it is hard to do it right. Not all writing helps me </span><em>think</em><span>. Most kinds of writing are rather weak, or even counterproductive, in this regard. You have to approach it in the right way.</span></p><p>Until last fall, I had not seen anyone properly articulate the mental moves that make writing a powerful tool for thought. Writing advice is usually focused on more superficial parts of the craft. Whatever I knew about thinking on the page, I had picked up through trial and error and conversations with other writers.</p><p><span>But then I read Imre Lakatos’s </span><em><a href="https://dl1.cuni.cz/pluginfile.php/730446/mod_resource/content/2/Imre%20Lakatos%3B%20Proofs%20and%20Refutations.pdf" rel="">Proofs and Refutations</a></em><span>. It is not, at first glance, a book about writing. It is a book of mathematical philosophy. By a Hungarian Stalinist, no less. But it is, if you read it sideways, a profound exploration of the act of writing. This shouldn’t be a surprise. Mathematics is, after all, a subset of writing—it is a way of crafting a language that helps you express and improve thoughts. The main difference, compared to prose writers and poets, is that mathematicians are more rigorous, precise. Because of this precision, reading Lakatos gave me a clearer and more precise understanding of what I do, or strive to do, as I sit down each morning and wrestle with my thoughts.&nbsp;</span></p><p>What follows is a series of meditations about thinking through writing provoked by, but not faithful to, Lakatos’s book. I’ve divided it into two parts. The first part covers the basic mental models that are useful to most people (if you write a diary, for example, and want to get clarity about things in your life). The next part goes into more complex patterns of thinking which I suspect is mostly useful if you do research or engage in some other kind of deep creative work.</p><p>A warning. If you aim to write and publish stuff, this essay might tie you up in knots. It is about thinking, not about crafting beauty or finishing things in a finite time.</p><blockquote><p><em><span>There is a crack, a crack in everything</span><br><span>That’s how the light gets in.</span><br><span>—</span></em><span>Leonard Cohen, “Anthem”</span></p></blockquote><p><span>In </span><a href="https://www.dwarkeshpatel.com/p/patrick-collison" rel="">a recent interview with Dwarkesh</a><span>, Patrick Collison explained the value of writing using a metaphor I enjoyed:</span></p><blockquote><p><span>Bruno Latour spoke about how he thinks the printing revolution, like Gutenberg’s, partially caused the scientific revolution by </span><em>making knowledge more rigid.</em><span> Before, if some observation didn’t match some claim, you could always shrug and be like: “Well, the person who transcribed that thing made a mistake.” So </span><em>by making things more rigid, it’s easier to break them. </em><span>[Emphasis mine.]&nbsp;</span></p></blockquote><p><span>Good thinking is about pushing past your current understanding and reaching the thought behind the thought. This often requires breaking old ideas, which is much easier to do when the ideas are as rigid as they get on the page. In a fluid medium like thought or conversation, you can always go, “Well, I didn’t mean it like </span><em>that</em><span>” or rely on the fact that your short-term memory is too limited for you to notice the contradiction between what you are saying now and what you said 12 minutes ago.</span></p><p>When I write, I get to observe the transition from this fluid mode of thinking to the rigid. As I type, I’m often in a fluid mode—writing at the speed of thought. I feel confident about what I’m saying. But as soon as I stop, the thoughts solidify, rigid on the page, and, as I read what I’ve written, I see cracks spreading through my ideas. What seemed right in my head fell to pieces on the page.</p><p><span>Seeing your ideas crumble can be a frustrating experience, but </span><em>it is the point</em><span> if you are writing to think. You want it to break. It is in the cracks the light shines in.</span></p><p>When I write, I push myself to make definite positive claims. Ambiguity allows thought to remain fluid on the page, floating into a different meaning when put under pressure. This makes it harder to push your thinking deeper. By making clear and sharp claims, I reveal my understanding so that I—or the person I’m writing to—can see the state of my knowledge and direct their feedback to the point where it will help my thinking improve.</p><p>This is valuable to do even in areas where you know way too little to “warrant” an opinion. I met a Japanese linguist in the harbor yesterday and talked about the relationship between the Chinese and the Japanese writing systems. This is a topic I had thought about for about twenty seconds before this. “So,” I said after two minutes, “this is a stupid question, but is the relationship between China and Japan like that between Ancient Greece and the Roman Empire?” This is, as it turns out, not a good analogy. But by spelling out my naive understanding, I gave the linguist a good area to work on when he laid out a richer model of the flow of cultural influence in East Asia.</p><p><span>In the terminology of mathematics, what I did here (and in my writing) was to “make a conjecture,” a qualified guess based on limited information. A hypothesis. The mathematician Alexander Grothendieck, whom Johanna and I </span><a href="https://www.henrikkarlsson.xyz/p/good-ideas" rel="">have written about elsewhere</a><span>, would always summarize his first impression of a new situation with a conjecture, proclaiming with irrepressible enthusiasm, “It must be true!” Ten seconds later, someone would come up with a counterexample that proved him wrong. But being right wasn’t the point: getting a better understanding was. And he would immediately throw out a new conjecture. (Holden Karnofsky has a blog post about using this technique to </span><a href="https://www.cold-takes.com/learning-by-writing/" rel="">learn through writing</a><span>.)</span></p><p>Forcing the diffuse ideas and impressions in your head into a definite statement is an art form. You have to grab hold of what is floating and make it rigid and sharp. It can feel almost embarrassing–revealing your ignorance with as much vulnerability as possible.</p><p><span>And it is only the first step. Once you have made your thoughts definite, clear, concrete, sharp, and rigid, you also want to </span><em>unfold </em><span>them.</span></p><p><span>By unfolding I mean “interrogating the conclusion to come up with an explanation of why it </span><em>could </em><span>be true.” What premises and reasoning chains leads to this conclusion? The explanation isn’t meant to prove that your conclusion was right. It is just a way of unpacking it.</span></p><p>By unfolding a claim into an explanation, you spread it on a “wider front” (to borrow a metaphor from Lakatos), so that the criticism has more targets.</p><p><span>I used this tactic in the food store yesterday. Maud, our six-year-old, told me we had to get a pink miniature plastic teapot. I couldn’t come up with a compassionate counterargument, so I said, “Why do you think a plastic teapot is so great?” And she said, “Because it is </span><em>so</em><span> beautiful. And I need one in plastic so it doesn’t break. I would use it all the time.” This brought a smile to my face. See—trying to prove her point, she had given me three times as many claims to attack!</span></p><p>Since the goal is to find flaws in our guesses (so that we can change our minds, refine our mental models and our language, and be more right) unfolding a claim through an explanation is progress. Even if the explanation is wrong.</p><blockquote><p><span>You are interested only in proofs which ‘prove’ what they have set out to prove. I am interested in proofs even if they do not accomplish their intended task. Columbus did not reach India but he discovered something interesting.</span><br><span>—Lakatos</span></p></blockquote><p><span>Let me take another example. Before Maud was born, Johanna and I worked as teachers in Sweden. The first conclusion we drew from that experience was that we didn’t want to submit our kids to what we had observed. This way of formulating it (“Not </span><em>that</em><span>”) is a bit vague as it only defines where not to look for the solution. It is useful to also attempt a positive formulation. If I were to reconstruct the positive version of our conclusion back then, it was something like, “We need to find (or start) a school where our daughter can pursue her interests at her pace.”</span></p><p>There are several subtle problems with this conclusion. But the point is—these problems didn’t come into view until we had unfolded and probed our original position.&nbsp;</p><p>The way we unfolded and improved our conclusion back then was more haphazard than it would have been today. We just talked about it aimlessly, read randomly, and made small notes. This cost us time and caused confusion. These days, I would instead unfold a conclusion like this as a series of bullet points where I spell out the intuition behind my claim in a series of premises. In the case of Maud’s education, this would have looked something like this (note that this is not my current understanding but a reconstruction of what I thought eight years ago):</p><ul><li><p>People have an intrinsic motivation to learn and it is important to not undermine that, which schools do&nbsp;</p></li><li><p>It is better to go deep on a few topics that you are passionate about rather than have a superficial understanding of a broad range of subjects you care little about</p></li><li><p>But you need to attend a school so you get socialized</p></li><li><p>Hence, we need to find a school that allows self-directed learning</p></li></ul><p>Once I unfold my understanding in writing, I often see holes right away. I start correcting myself and discarding ideas already while typing. I cut ideas that are obviously flawed. I rewrite what feels ambiguous to make it sharper–more precise, concrete, unhedged, and true to my understanding.</p><p>The flaws I see immediately, however, are only the more superficial flaws. The deeper patterns take a longer time to emerge—because they are further from my established thoughts and so are harder to articulate.</p><p>Often, they occur first as subtle emotional cues. As I reread a passage, I notice a slight tension across my chest or my eyes fog over. For some reason, it doesn’t feel right. There is something wrong here.&nbsp;</p><p>These subtle feelings are easy to dismiss (“Eh, words are slippery, I mean something slightly different . . . there is no reason to obsess about this”). But in my experience, it is these subtler problems that tend to open a path beyond my current understanding. I learned this from my wife, Johanna, who will often sit with a draft for several hours, not writing or editing, but simply articulating why something feels off to her. Our best essays have come out of the things she surfaced during those sessions.</p><p>For this reason, I suspect that many of my friends who write and publish rapidly are shortchanging themselves. They generate texts filled with hidden doors and move on before they’ve opened them.&nbsp;</p><p>I tend to go through my list of premises and assumptions and ask follow-up questions to myself, to further unfold my conclusion. To continue the example from above, I would take one of the premises and unfold it like this:</p><ul><li><p>But you need a school so you get socialized</p><ul><li><p><em>Curious: why?</em></p></li><li><p>Kids will get depressed and struggle to navigate workplaces, and so on, if they haven’t been exposed to society</p><ul><li><p><em>Where can I read more about this? Are there any good studies?</em></p></li></ul></li><li><p>Being in something like a school is important because humans are social animals. We pick up most of our skills and norms and so on by being immersed in a peer group</p><ul><li><p><em>And what follows from this?</em></p></li><li><p><em>If we are shaped by our peer group, what would the ideal peer group look like?</em></p></li></ul></li></ul></li></ul><p><span>The emotional tone of these questions is, in my head, lovingly curious; I’m not trying to</span><em> </em><span>put myself down. I’m trying not to kill ideas. I want to help them evolve and spill forth more insight. Often this dialogue ends with me changing my mind about several premises and coming to a different conclusion, but the original idea remains the seed—no less valuable for having been proven wrong. It takes creativity and boldness to leap out and form a conclusion, and the part that criticizes must understand how dependent it is on the part that throws ideas at the wall. It is often easier to criticize than it is to synthesize a new position.</span></p><p>The sun is above the horizon now, the satellites hid behind a thin layer of orange and pink. A hare raises on his hind legs in the middle of the meadow looking around. I tap the glass and watch his ears turn my way.</p><p>Now that I have spelled out my position and fixed the obvious flaws, I start probing myself more seriously to see if I can get the argument to break down.</p><p><span>If one of the premises I have unfolded is a factual claim, I’ll spend a few minutes skimming research in the area to see how well my position holds up. “Oh, it turns out that most homeschooled kids do </span><em>not</em><span> have any problems with socialization!” I realized when doing this in relation to Maud’s education. (Though it didn’t take me a few minutes, it took me years in this case. Partly because we were unsystematic, partly because homeschooling is illegal and taboo in Sweden and this had worked itself into my body so that I felt revulsion each time I probed that assumption.) In this case, looking at studies and statistics helped remove several needless assumptions. We changed our conclusion (we left Sweden and now homeschool Maud and her sister).</span></p><p><span>But often the type of problem I like to think about is too personal and messy and qualitative to be resolved cleanly through a statistically significant study. What I do in these situations instead is to consider </span><em>counterexamples</em><span>.</span></p><p><span>I like to visualize concrete situations when I make an argument (in the notes for this essay, for example, I continually compare what I say against past writing projects). This makes it easier for me to think clearly. I am tied back into a lived reality, which is rigid, and do not float off into theory, where I have a solid track record of fooling myself. When I have a concrete situation in mind, I can ask myself, “What is a situation where the opposite happened? Why was that?” I can list the characteristics of the situation that inform my conclusion and then systematically look for cases that have other characteristics. In “</span><a href="https://www.henrikkarlsson.xyz/p/childhoods" rel="">Childhoods of exceptional people</a><span>,” for example, I wrote about parenting from the perspective of concrete biographies. The sample was unsystematic. But once I had extracted what I thought were the common patterns, I asked myself, “So whom does this </span><em>not</em><span> apply to?” Then I added the people that came to mind to the sample and ended up with a distribution that was good enough for my purposes.</span></p><p>Counterexamples are useful in two ways. Either you find a counterexample that a) proves one of the premises wrong but b) does not change your mind about the conclusion. Lakatos calls this a local (and non-global) counterexample. This means there is something wrong with your unfolding. Perhaps you need to change that part of the explanation? Or perhaps you can simply drop it, making the mental model simpler and more general? Local counterexamples help you improve your explanation and get a better understanding.&nbsp;</p><p><span>There is a scene in the last season of </span><em>Breaking Bad</em><span> that illustrates this. The main character, whatever his name was, is a teacher that starts a meth lab. This can be thought of as his conclusion (“I should get into the meth business”) and when asked to defend this decision he unfolds the claim by saying, “I need to support my family.” This is false. There are better ways for him to do that (he has an old friend who offers him money). That is a local counterexample. In the final season, he admits to himself: “I did it because it made me feel alive.” This doesn’t change his conclusion (he does not change his mind about the meth) but it gives him a deeper and more correct understanding of himself.</span></p><p><span>Other times, the counterexample you find undermines the whole idea—a </span><em>global counterexample</em><span>. You unfold your conclusion and discover that one of the premises does not hold up, and there is no way to patch it. The fracture spreads right up to the conclusion. Now—this is what we have been longing for—there is a big hole of confusion where before there was a mental model. It is time to replace it with something more subtle and deep that incorporates the critique.</span></p><p>How to do this, and do it in the most interesting way possible, is the topic of the next part (which I have no idea when I’ll finish).</p><p><em>If you liked this, you might enjoy this one too:</em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why privacy is important, and having "nothing to hide" is irrelevant (2016) (181 pts)]]></title>
            <link>https://robindoherty.com/2016/01/06/nothing-to-hide.html</link>
            <guid>40892259</guid>
            <pubDate>Sat, 06 Jul 2024 18:38:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://robindoherty.com/2016/01/06/nothing-to-hide.html">https://robindoherty.com/2016/01/06/nothing-to-hide.html</a>, See on <a href="https://news.ycombinator.com/item?id=40892259">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            <p>
              The governments of
              <a href="https://robindoherty.com/2015/10/07/your-digital-privacy-ends-this-time-next-week.html">Australia</a>,
              <a href="https://lawfareblog.com/german-bundestag-passes-new-data-retention-law">Germany</a>, the
              <a href="http://www.theguardian.com/world/2015/nov/05/mass-snooping-and-more-the-measures-in-theresa-mays-bill">UK</a>
              and the
              <a href="https://medium.com/@RonWyden/this-bill-won-t-protect-you-from-hackers-6aff1d250f67">US</a>
              are destroying your privacy. Some people don’t see the problem…
            </p>

            <h4 id="i-have-nothing-to-hide-so-why-should-i-care">
              “I have nothing to hide, so why should I care?”
            </h4>

            <p>
              It doesn’t matter if <em>you</em> have <em>“nothing to hide”</em>.
              Privacy is a right granted to individuals that underpins the
              freedoms of expression, association and assembly; all of which are
              essential for a free, democratic society.
            </p>

            <p>
              The statement from
              <a href="http://www.smh.com.au/digital-life/digital-life-news/metadata-retention-those-with-nothing-to-hide-have-nothing-to-fear-says-australian-federal-police-assistant-commissioner-tim-morris-20150222-13ljzi.html">some</a>
              <a href="https://www.youtube.com/watch?v=lWam4EWI48M">politicians</a>
              that “if you have nothing to hide then you have nothing to fear”
              purposefully misframes the whole debate.
            </p>

            <p>This affects all of us. We must care.</p>

            <blockquote>
              <p>
                Arguing that you don’t care about the right to privacy because
                you have nothing to hide is no different than saying you don’t
                care about free speech because you have nothing to say.
              </p>
            </blockquote>

            <p><em>– Edward Snowden</em></p>

            <h2 id="privacy-and-freedom">Privacy and freedom</h2>

            <p>Loss of privacy leads to loss of freedom.</p>

            <p>
              Your
              <a href="https://en.wikipedia.org/wiki/Freedom_of_expression">freedom of expression</a>
              is threatened by the surveillance of your internet usage – thought
              patterns and intentions can be extrapolated from your website
              visits (rightly or wrongly), and the knowledge that you are being
              surveilled can make you less likely to research a particular
              topic. You lose that perspective, and your thought can be pushed
              in one direction as a result. Similarly, when the things you write
              online, or communicate privately to others, are surveilled, and
              you <a href="#self-censorship">self-censor</a> as a result, the
              rest of us lose your perspective, and the development of further
              ideas is stifled.
            </p>

            <p>
              Your
              <a href="https://en.wikipedia.org/wiki/Freedom_of_association">freedom of association</a>
              is threatened by the surveillance of your communications online
              and by phone, and your
              <a href="https://en.wikipedia.org/wiki/Freedom_of_assembly">freedom of assembly</a>
              is threatened by the tracking of your location by your mobile
              phone. Can we afford to risk the benefits of free association, the
              social change brought by activists and campaigners, or the right
              to protest?
            </p>

            <p>
              These freedoms are being eroded, right now. The effects will
              worsen over time, as each failure to exercise our freedom builds
              upon the last, and as more people experience the
              <a href="#personal-chilling">chilling effects</a>.
            </p>

            <h3 id="aggregation"><a name="aggregation"></a>Aggregation</h3>

            <p>
              Bits of information that you might not feel the need to hide can
              be <em>aggregated</em> into a telling profile, which might include
              things that you actually do want to conceal.
            </p>

            <p>
              In the case of data retention in Australia, we have given away our
              rights to privacy, and now share a constant stream of:
            </p>

            <ul>
              <li><strong>where</strong> we go,</li>
              <li><strong>who</strong> we contact and when,</li>
              <li>and <strong>what we do</strong> on the internet.</li>
            </ul>

            <p>
              With just a small portion of this
              <a href="http://www.abc.net.au/news/2015-08-16/metadata-retention-privacy-phone-will-ockenden/6694152">data</a>, off-the-shelf software and their own spare time, ABC News
              readers found
              <a href="http://www.abc.net.au/news/2015-08-24/metadata-what-you-found-will-ockenden/6703626">Will Ockenden’s home, workplace and parents’ home</a>.
            </p>

            <p>
              The intrusion becomes all the more spectacular when you consider
              the data across a whole population, the
              <a href="https://www.rt.com/usa/snowden-leak-black-budget-176/">massive budgets</a>
              of the
              <a href="https://www.privacyinternational.org/node/51">Five Eyes</a>
              intelligence agencies, and the constant progress of artificial
              intelligence and big data analytics.
            </p>

            <p>
              Your interactions with the world around you can reveal your
              political and religious beliefs, your desires, sympathies and
              convictions, and things about yourself that you
              <a href="http://www.businessinsider.com.au/the-incredible-story-of-how-target-exposed-a-teen-girls-pregnancy-2012-2">aren’t even aware of</a>
              (and they might be wrong too).
            </p>

            <p>
              Given enough data and time, your behaviour might even be
              <a href="http://qz.com/527008/an-algorithm-can-predict-human-behavior-better-than-humans/">predicted</a>.
            </p>

            <h3 id="personal-chilling-effects">
              <a name="personal-chilling"></a>Personal chilling effects
            </h3>

            <p>
              When you understand the fullness of the picture that mass
              surveillance paints of you, you begin to change your behaviour –
              you avoid exercising certain freedoms.
            </p>

            <p>You might think twice about:</p>

            <ul>
              <li>
                <p>
                  <strong>contacting</strong> or meeting people (exercising your
                  freedom of association) who you think might become “persons of
                  interest” to the state, or that you think the algorithms might
                  determine as such in the future, since you know that your
                  association with them is retained for <em>at least</em> two
                  years and may be analysed,
                </p>
              </li>
              <li>
                <p>
                  <strong>congregating</strong> in the same location as a group
                  of those people (exercising your freedom of assembly). Would
                  you attend a protest march calling for action on climate
                  change, knowing that you would forever be linked to what the
                  Australian government calls a
                  <a href="http://www.theguardian.com/australia-news/2015/sep/10/green-lawfare-voters-feel-coalition-is-trying-to-silence-environment-groups">“vigilantist” movement of “economic saboteurs”</a>?
                </p>
              </li>
              <li>
                <p>
                  <strong>participating</strong> in any activity that might make
                  you look bad in the data – even if you know that you are
                  innocent. This could mean avoiding writing about a particular
                  topic online, or visiting a particular website, or buying a
                  particular book – exercising your freedom of expression.
                </p>
              </li>
            </ul>

            <h3 id="societal-chilling-effects">
              <a name="societal-chilling"></a>Societal chilling effects
            </h3>

            <p>
              The combined result of these second thoughts across the population
              is a chilling effect on many of the activities that are key to a
              well-functioning democracy – activism, journalism, and political
              dissent, among others.
            </p>

            <p>
              We all benefit from progress that occurs when activists,
              journalists and society as a whole are able to freely engage in
              political discourse and dissent. Many of the positive changes of
              the last century were only possible because of these freedoms. For
              example, the
              <a href="https://en.wikipedia.org/wiki/Australian_referendum,_1967_(Aboriginals)">1967 referendum</a>
              on including indigenous Australians in the census, and allowing
              the federal government to make laws specifically benefiting
              indigenous races, was only made possible by sustained activism
              throughout the 1950s and 60s.
            </p>

            <p>
              Unfortunately, we are already <a name="self-censorship"></a><strong>self-censoring</strong>.
              <a href="https://www.pen.org/sites/default/files/Chilling%20Effects_PEN%20American.pdf">A 2013 survey of US writers</a>
              found that after the revelations of the NSA’s mass surveillance
              regime, 1 in 6 had avoided writing on a topic they thought would
              subject them to surveillance, and a further 1 in 6 had seriously
              considered doing so.
            </p>

            <blockquote>
              <p>
                Ask yourself: at every point in history, who suffers the most
                from unjustified surveillance? It is not the privileged, but the
                vulnerable. Surveillance is not about safety, it’s about power.
                It’s about control.
              </p>
            </blockquote>

            <p><em>– Edward Snowden</em></p>

            <h3 id="misuse--misappropriation">
              <a name="misappropriation"></a>Misuse &amp; misappropriation
            </h3>

            <p>
              By creating databases and systems of easy access to such a great
              volume of personally revealing information, we increase the scope
              of mass surveillance, and therefore the scope for infringements
              upon our human rights.
            </p>

            <p>
              East Germany is the most extreme example of a surveillance state
              in history. The Stasi – its infamous security agency – employed
              90,000 spies and had a network of at least 174,000 informants. The
              Stasi kept meticulous files on hundreds of thousands of innocent
              citizens and used this information to psychologically harrass,
              blackmail and discredit people who became dissenters. But that was
              before the internet. Reflecting on the NSA’s current systems of
              mass surveillance, a former Stasi lieutenant colonel
              <a href="http://www.mcclatchydc.com/news/nation-world/national/article24750439.html">said</a>:
              <strong>“for us, this would have been a dream come true”</strong>.
            </p>

            <p>
              Even aside from the risk of systematic state misbehaviour, in
              Australia we know that the
              <a href="https://robindoherty.com/2015/10/07/your-digital-privacy-ends-this-time-next-week.html#snoopers">2500 snoopers</a>
              who have unrestricted access to your data are subject to
              <a href="http://www.watoday.com.au/wa-news/wa-policeman-charged-over-disclosing-ben-cousins-secrets-to-journalist-girlfriend-20150423-1mrjhd.html">“professional curiosity”</a>,
              <a href="http://www.couriermail.com.au/news/queensland/police-under-fire-for-probing-phone-records-of-their-own-in-8216disturbing8217-breach-of-officers8217-privacy/story-fnihsrf2-1226706966590">fallible morals</a>, and are only human, so will make mistakes and become victims of
              social engineering, blackmail or bribery.
            </p>

            <p>
              This is most dangerous for the most vulnerable people. For
              example, if you have an angry or violent ex-partner, you could be
              put in mortal danger by them getting their hands on this much
              detail about your life.
            </p>

            <h4 id="risk-taking">Risk taking</h4>

            <p>
              Our “digital lives” are an accurate reflection of our actual
              lives. Our phone records expose where we go and who we talk to,
              and our internet usage can expose almost everything about
              ourselves and what we care about.
            </p>

            <p>
              Even if we trust the motives of our current governments, and every
              person with authorised access to our data, we are taking an
              incredible risk. The systems of surveillance that we entrench now
              may be misappropriated and misused at any time by future
              governments, foreign intelligence agencies, double agents, and
              opportunistic hackers.
            </p>

            <p>The more data we have, the more devastating its potential.</p>

            <h3 id="gradual-erosion">
              <a name="gradual-erosion"></a>Gradual erosion
            </h3>

            <p>
              Each system of surveillance and intrusion that we introduce erodes
              our privacy and pushes us one step further away from a free
              society.
            </p>

            <p>
              While you may not have noticed the impact yet, your privacy has
              already been eroded. If we continue along our current path,
              building more powers into our systems of surveillance, what was
              once your private life will be whittled away to nothing, and the
              freedoms that we have taken for granted will cease to exist.
            </p>

            <p>
              As technology advances, we are presented with a choice – will it
              to continue to offer an overall benefit to society, or will we
              allow it to be used as a tool for total intrusion into our lives?
            </p>

            <blockquote>
              <p>
                Privacy is rarely lost in one fell swoop. It is usually eroded
                over time, little bits dissolving almost imperceptibly until we
                finally begin to notice how much is gone.
              </p>
            </blockquote>

            <p>
              <em>–
                <a href="https://web.archive.org/web/20151116013709/http://chronicle.com/article/Why-Privacy-Matters-Even-if/127461/">Why Privacy Matters Even if You Have ‘Nothing to Hide’</a>, Daniel J. Solove</em>
            </p>

            <h2 id="what-next">What next?</h2>

            <p>
              The governments of Australia, New Zealand, Canada, the US and
              others are poised to take a big step in the wrong direction with
              the Trans-Pacific Partnership (TPP). The EFF
              <a href="https://www.eff.org/deeplinks/2015/12/how-tpp-will-affect-you-and-your-digital-rights">explains</a>
              why the TPP is a huge threat to your privacy and other rights.
            </p>

            <ul>
              <li>
                <p>
                  <strong>Take action</strong> – if you are a technologist, join
                  Hack for Privacy and fight back against mass surveillance –
                  <a href="https://hackforprivacy.org/">hackforprivacy.org</a>.
                </p>
              </li>
              <li>
                <p>
                  <strong>Spread the privacy mindset</strong> – we must foster
                  understanding of this issue in order to protect ourselves from
                  harmful laws and fight against future invasions of privacy.
                  Please help spread the knowledge, discuss this article with a
                  friend, tweet it, share it, etc.
                </p>
              </li>
              <li>
                <p>
                  <strong>Protect yourself</strong> – protect your own data from
                  mass surveillance. This
                  <a href="http://www.theguardian.com/commentisfree/2013/sep/05/government-betrayed-internet-nsa-spying">increases the cost</a>
                  of mass surveillance and helps others too. Read
                  <a href="https://robindoherty.com/2015/10/07/your-digital-privacy-ends-this-time-next-week.html">my advice on protecting your data from retention in
                    Australia</a>, the EFF’s
                  <a href="https://ssd.eff.org/">Surveillance Self-Defense Guide</a>, and
                  <a href="http://www.tcij.org/node/1016">Information Security for Journalists</a>.
                </p>
              </li>
            </ul>

            <hr>

            <p>
              <em>Translations of this article are available in:
                <a href="http://www.seanhall.it/blog/2016/01/14/perche-la-privacy-e-importante-e-non-avere-nulla-da-nascondere-e-irrilevante">Italian</a>
                and
                <a href="https://robindoherty.com/de/2016/02/01/nichts-zu-verbergen.html">German</a>.</em>
            </p>

            <hr>

            
          </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Bash Dungeon – An educational dungeon crawler in the shell (125 pts)]]></title>
            <link>https://github.com/wolandark/bash-dungeon</link>
            <guid>40891643</guid>
            <pubDate>Sat, 06 Jul 2024 16:59:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/wolandark/bash-dungeon">https://github.com/wolandark/bash-dungeon</a>, See on <a href="https://news.ycombinator.com/item?id=40891643">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Bash Dungeon</h2><a id="user-content-bash-dungeon" aria-label="Permalink: Bash Dungeon" href="#bash-dungeon"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/107309764/307185316-7846dd64-fac7-489b-8730-d369149420fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMzc3MDEsIm5iZiI6MTcyMDMzNzQwMSwicGF0aCI6Ii8xMDczMDk3NjQvMzA3MTg1MzE2LTc4NDZkZDY0LWZhYzctNDg5Yi04NzMwLWQzNjkxNDk0MjBmZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcwN1QwNzMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYzllNzZhNTY1ZGFhOWFjMTUzZmEwYjNiMTIyYTFkM2FhNDU0ZDQzMGY4NGRhNjUzNTk5ODdlN2IwYmNmOWMwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.nixFPQKcs_ktYqJb2MpcuVSUlvcIG12FdTO7VXZLMsE"><img src="https://private-user-images.githubusercontent.com/107309764/307185316-7846dd64-fac7-489b-8730-d369149420fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMzc3MDEsIm5iZiI6MTcyMDMzNzQwMSwicGF0aCI6Ii8xMDczMDk3NjQvMzA3MTg1MzE2LTc4NDZkZDY0LWZhYzctNDg5Yi04NzMwLWQzNjkxNDk0MjBmZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcwN1QwNzMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYzllNzZhNTY1ZGFhOWFjMTUzZmEwYjNiMTIyYTFkM2FhNDU0ZDQzMGY4NGRhNjUzNTk5ODdlN2IwYmNmOWMwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.nixFPQKcs_ktYqJb2MpcuVSUlvcIG12FdTO7VXZLMsE"></a>
</p>
<p dir="auto">A dungeon crawler game in bash where the dungeons are directories.<br> Inspired by <a href="https://github.com/wheybags/DungeonsAndDirectories">Dungeons And Directories</a> and <a href="https://gitlab.com/slackermedia/bashcrawl" rel="nofollow">Bash Crawl</a>.<br></p>
<p dir="auto"><em>This game is intended to teach new users how to use their shell in a fun and interactive way.<br></em></p>
<p dir="auto"><strong>Right now its a work in progress ...</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Play in GitPod</h2><a id="user-content-play-in-gitpod" aria-label="Permalink: Play in GitPod" href="#play-in-gitpod"></a></p>
<p dir="auto">Sign up for a free gitpod account and click the link below<br>
<a href="https://wolandark-bashdungeon-wr1fmhxhnti.ws-us108.gitpod.io/" rel="nofollow">Bash Dungeon GitPod</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Play in docker</h2><a id="user-content-play-in-docker" aria-label="Permalink: Play in docker" href="#play-in-docker"></a></p>
<p dir="auto">You must have docker installed.<br>
Then:</p>
<div data-snippet-clipboard-copy-content="docker pull wolandark/bash-dungeon
docker run -it wolandark/bash-dungeon"><pre><code>docker pull wolandark/bash-dungeon
docker run -it wolandark/bash-dungeon
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Play Locally</h2><a id="user-content-play-locally" aria-label="Permalink: Play Locally" href="#play-locally"></a></p>
<p dir="auto">clone the repository and cd into it<br>
<code>cd Enter</code> the dungeon <br>
<code>cat</code> your first parchment and follow the instructions. <br></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Instructions</h2><a id="user-content-instructions" aria-label="Permalink: Instructions" href="#instructions"></a></p>
<p dir="auto"><code>cd</code>, <code>ls</code> and <code>cat</code> are all you need to know to start playing.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Your very first moves</h2><a id="user-content-your-very-first-moves" aria-label="Permalink: Your very first moves" href="#your-very-first-moves"></a></p>
<p dir="auto"><code>cd bash-dungeon</code> <br>
<code>ls</code> <br>
<code>cd Enter</code><br>
<code>ls</code><br>
<code>cat parchment</code><br></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fabric is an open-source framework for augmenting humans using AI (128 pts)]]></title>
            <link>https://github.com/danielmiessler/fabric</link>
            <guid>40891507</guid>
            <pubDate>Sat, 06 Jul 2024 16:40:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/danielmiessler/fabric">https://github.com/danielmiessler/fabric</a>, See on <a href="https://news.ycombinator.com/item?id=40891507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/danielmiessler/fabric/blob/main/images/fabric-logo-gif.gif"><img src="https://github.com/danielmiessler/fabric/raw/main/images/fabric-logo-gif.gif" alt="fabriclogo" width="400" height="400" data-animated-image=""></a></p><p dir="auto"><h2 tabindex="-1" dir="auto"><code>fabric</code></h2><a id="user-content-fabric" aria-label="Permalink: fabric" href="#fabric"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/95c90b94555d8bdc331ab2a8e6e02c0f7f276f5abd07653f65430eeafe7043fd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d697373696f6e2d68756d616e5f666c6f7572697368696e675f7669615f41495f6175676d656e746174696f6e2d707572706c65"><img src="https://camo.githubusercontent.com/95c90b94555d8bdc331ab2a8e6e02c0f7f276f5abd07653f65430eeafe7043fd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d697373696f6e2d68756d616e5f666c6f7572697368696e675f7669615f41495f6175676d656e746174696f6e2d707572706c65" alt="Static Badge" data-canonical-src="https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple"></a>
<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3b4f6dec3108f06d7d3c2e86e95ab65258b27ec4499bf81caf2c115e61755cb6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c616e6775616765732f746f702f64616e69656c6d696573736c65722f666162726963"><img src="https://camo.githubusercontent.com/3b4f6dec3108f06d7d3c2e86e95ab65258b27ec4499bf81caf2c115e61755cb6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c616e6775616765732f746f702f64616e69656c6d696573736c65722f666162726963" alt="GitHub top language" data-canonical-src="https://img.shields.io/github/languages/top/danielmiessler/fabric"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/022b2bfa795bf900c9cc003a4dfba27ec4a559f3a3776a35ab8f18930a88ceb7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f64616e69656c6d696573736c65722f666162726963"><img src="https://camo.githubusercontent.com/022b2bfa795bf900c9cc003a4dfba27ec4a559f3a3776a35ab8f18930a88ceb7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f64616e69656c6d696573736c65722f666162726963" alt="GitHub last commit" data-canonical-src="https://img.shields.io/github/last-commit/danielmiessler/fabric"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/b59ba4ef5c86bc79e9e3e9039f1b96a4db59e7f96a7ba04abfc6548ae88c461b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d677265656e2e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-green.svg"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>fabric</code> is an open-source framework for augmenting humans using AI.</h4><a id="user-content-fabric-is-an-open-source-framework-for-augmenting-humans-using-ai" aria-label="Permalink: fabric is an open-source framework for augmenting humans using AI." href="#fabric-is-an-open-source-framework-for-augmenting-humans-using-ai"></a></p>

<p dir="auto"><a href="#introduction-video-by-network-chuck">Introduction Video</a> •
<a href="#what-and-why">What and Why</a> •
<a href="#philosophy">Philosophy</a> •
<a href="#quickstart">Quickstart</a> •
<a href="#structure">Structure</a> •
<a href="#examples">Examples</a> •
<a href="#custom-patterns">Custom Patterns</a> •
<a href="#helper-apps">Helper Apps</a> •
<a href="#examples">Examples</a> •
<a href="#meta">Meta</a></p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Navigation</h2><a id="user-content-navigation" aria-label="Permalink: Navigation" href="#navigation"></a></p>
<ul dir="auto">
<li><a href="#introduction-video-by-network-chuck">Introduction Videos</a></li>
<li><a href="#what-and-why">What and Why</a></li>
<li><a href="#philosophy">Philosophy</a>
<ul dir="auto">
<li><a href="#breaking-problems-into-components">Breaking problems into components</a></li>
<li><a href="#too-many-prompts">Too many prompts</a></li>
<li><a href="#our-approach-to-prompting">The Fabric approach to prompting</a></li>
</ul>
</li>
<li><a href="#quickstart">Quickstart</a>
<ul dir="auto">
<li><a href="#setting-up-the-fabric-commands">Setting up the fabric commands</a></li>
<li><a href="#using-the-fabric-client">Using the fabric client</a></li>
<li><a href="#just-use-the-patterns">Just use the Patterns</a></li>
<li><a href="#create-your-own-fabric-mill">Create your own Fabric Mill</a></li>
</ul>
</li>
<li><a href="#updating">Updating</a></li>
<li><a href="#structure">Structure</a>
<ul dir="auto">
<li><a href="#components">Components</a></li>
<li><a href="#cli-native">CLI-native</a></li>
<li><a href="#directly-calling-patterns">Directly calling Patterns</a></li>
</ul>
</li>
<li><a href="#examples">Examples</a></li>
<li><a href="#custom-patterns">Custom Patterns</a></li>
<li><a href="#helper-apps">Helper Apps</a></li>
<li><a href="#meta">Meta</a>
<ul dir="auto">
<li><a href="#primary-contributors">Primary contributors</a></li>
</ul>
</li>
</ul>
<br>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">May 23, 2024 — We will be switching Fabric to Go in a few weeks to avoid all the installation issues with Python. The Go version will be dead-simple to install and will be even faster. Plus easier to update. We already have it working thanks to the heroic efforts of @xssdoctor, and we're just working on testing now! Stay tuned for more info on the release date!</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction video by Network Chuck!</h2><a id="user-content-introduction-video-by-network-chuck" aria-label="Permalink: Introduction video by Network Chuck!" href="#introduction-video-by-network-chuck"></a></p>
<p dir="auto">This is a <strong>brilliant</strong> video by Network Chuck that goes over why he's started using Fabric for all things AI. He talks about the spirit of the project, how to install it, and how he uses it, and he just generally articulates the spirit of what we're doing here SO WELL. Thanks to Chuck for this!</p>
<p><a href="https://youtu.be/UbDyjIIGaxQ" rel="nofollow"><img width="1000" alt="image" src="https://private-user-images.githubusercontent.com/50654/335734878-a6a61885-7bb1-48d7-8ea9-777ebb2fdb94.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMzU3MzQ4NzgtYTZhNjE4ODUtN2JiMS00OGQ3LThlYTktNzc3ZWJiMmZkYjk0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTZmMDFlMWI2MTc0MzQ1Yjc5ZmRiZWYyMjM1OTE5NmM0NGI4ZWE5MjNkMjFjOWIzN2YyNTg2NzIzYjhlYzhkOTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.TqLfUylTseJrvnO7L31TCuTLUGr8gfvMzCo6zxtKxuA" secured-asset-link=""></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What and why</h2><a id="user-content-what-and-why" aria-label="Permalink: What and why" href="#what-and-why"></a></p>
<p dir="auto">Since the start of 2023 and GenAI we've seen a massive number of AI applications for accomplishing tasks. It's powerful, but <em>it's not easy to integrate this functionality into our lives.</em></p>
<div dir="auto">
<p dir="auto"><h4 tabindex="-1" dir="auto">In other words, AI doesn't have a capabilities problem—it has an <em>integration</em> problem.</h4><a id="user-content-in-other-words-ai-doesnt-have-a-capabilities-problemit-has-an-integration-problem" aria-label="Permalink: In other words, AI doesn't have a capabilities problem—it has an integration problem." href="#in-other-words-ai-doesnt-have-a-capabilities-problemit-has-an-integration-problem"></a></p>
</div>
<p dir="auto">Fabric was created to address this by enabling everyone to granularly apply AI to everyday challenges.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Philosophy</h2><a id="user-content-philosophy" aria-label="Permalink: Philosophy" href="#philosophy"></a></p>
<blockquote>
<p dir="auto">AI isn't a thing; it's a <em>magnifier</em> of a thing. And that thing is <strong>human creativity</strong>.</p>
</blockquote>
<p dir="auto">We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the <strong>human</strong> problems we want to solve.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Breaking problems into components</h3><a id="user-content-breaking-problems-into-components" aria-label="Permalink: Breaking problems into components" href="#breaking-problems-into-components"></a></p>
<p dir="auto">Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/50654/302028537-31997394-85a9-40c2-879b-b347e4701f06.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDIwMjg1MzctMzE5OTczOTQtODVhOS00MGMyLTg3OWItYjM0N2U0NzAxZjA2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBmZDYxYzU1Y2U4ZTg3YWUzYTc2ZTYwOTAxOTM3MDEwZjY5ZmEwNDA2ZjhlMWQ2NzczZTIwMDg0YTNmYjNiYjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lxyu2ttUHl-2yOVYxy12wVHXDdq6moeYr6dsFC-D2PQ"><img width="2000" alt="augmented_challenges" src="https://private-user-images.githubusercontent.com/50654/302028537-31997394-85a9-40c2-879b-b347e4701f06.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDIwMjg1MzctMzE5OTczOTQtODVhOS00MGMyLTg3OWItYjM0N2U0NzAxZjA2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBmZDYxYzU1Y2U4ZTg3YWUzYTc2ZTYwOTAxOTM3MDEwZjY5ZmEwNDA2ZjhlMWQ2NzczZTIwMDg0YTNmYjNiYjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.lxyu2ttUHl-2yOVYxy12wVHXDdq6moeYr6dsFC-D2PQ"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto">Too many prompts</h3><a id="user-content-too-many-prompts" aria-label="Permalink: Too many prompts" href="#too-many-prompts"></a></p>
<p dir="auto">Prompts are good for this, but the biggest challenge I faced in 2023——which still exists today—is <strong>the sheer number of AI prompts out there</strong>. We all have prompts that are useful, but it's hard to discover new ones, know if they are good or not, <em>and manage different versions of the ones we like</em>.</p>
<p dir="auto">One of <code>fabric</code>'s primary features is helping people collect and integrate prompts, which we call <em>Patterns</em>, into various parts of their lives.</p>
<p dir="auto">Fabric has Patterns for all sorts of life and work activities, including:</p>
<ul dir="auto">
<li>Extracting the most interesting parts of YouTube videos and podcasts.</li>
<li>Writing an essay in your own voice with just an idea as an input.</li>
<li>Summarizing opaque academic papers.</li>
<li>Creating perfectly matched AI art prompts for a piece of writing.</li>
<li>Rating the quality of content to see if you want to read/watch the whole thing.</li>
<li>Getting summaries of long, boring content.</li>
<li>Explaining code to you.</li>
<li>Turning bad documentation into usable documentation.</li>
<li>Creating social media posts from any content input.</li>
<li>And a million more…</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Our approach to prompting</h3><a id="user-content-our-approach-to-prompting" aria-label="Permalink: Our approach to prompting" href="#our-approach-to-prompting"></a></p>
<p dir="auto">Fabric <em>Patterns</em> are different than most prompts you'll see.</p>
<ul dir="auto">
<li><strong>First, we use <code>Markdown</code> to help ensure maximum readability and editability</strong>. This not only helps the creator make a good one, but also anyone who wants to deeply understand what it does. <em>Importantly, this also includes the AI you're sending it to!</em></li>
</ul>
<p dir="auto">Here's an example of a Fabric Pattern</p>
<div dir="auto" data-snippet-clipboard-copy-content="https://github.com/danielmiessler/fabric/blob/main/patterns/extract_wisdom/system.md"><pre>https://github.com/danielmiessler/fabric/blob/main/patterns/extract_wisdom/system.md</pre></div>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/50654/302031520-b910c551-9263-405f-9735-71ca69bbab6d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDIwMzE1MjAtYjkxMGM1NTEtOTI2My00MDVmLTk3MzUtNzFjYTY5YmJhYjZkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE1M2NmMjQxNjkwNjU3MTJkM2ZlNjE4NTAxYjA5NTQ0OTI2YjNkODQxYWFiYjVmMjc3NTMwYjU2ZWI0ODI2MWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.wp2gWG1CTI_IptujQoT50HGDud0xQ_LoAEsJRkFCGTw"><img width="1461" alt="pattern-example" src="https://private-user-images.githubusercontent.com/50654/302031520-b910c551-9263-405f-9735-71ca69bbab6d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDIwMzE1MjAtYjkxMGM1NTEtOTI2My00MDVmLTk3MzUtNzFjYTY5YmJhYjZkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE1M2NmMjQxNjkwNjU3MTJkM2ZlNjE4NTAxYjA5NTQ0OTI2YjNkODQxYWFiYjVmMjc3NTMwYjU2ZWI0ODI2MWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.wp2gWG1CTI_IptujQoT50HGDud0xQ_LoAEsJRkFCGTw"></a>
<ul dir="auto">
<li>
<p dir="auto"><strong>Next, we are extremely clear in our instructions</strong>, and we use the Markdown structure to emphasize what we want the AI to do, and in what order.</p>
</li>
<li>
<p dir="auto"><strong>And finally, we tend to use the System section of the prompt almost exclusively</strong>. In over a year of being heads-down with this stuff, we've just seen more efficacy from doing that. If that changes, or we're shown data that says otherwise, we will adjust.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">The most feature-rich way to use Fabric is to use the <code>fabric</code> client, which can be found under <a href="https://github.com/danielmiessler/fabric/tree/main/installer/client"><code>/client</code></a> directory in this repository.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Required Python Version</h3><a id="user-content-required-python-version" aria-label="Permalink: Required Python Version" href="#required-python-version"></a></p>
<p dir="auto">Ensure you have at least python3.10 installed on your operating system. Otherwise, when you attempt to run the pip install commands, the project will fail to build due to certain dependencies.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setting up the fabric commands</h3><a id="user-content-setting-up-the-fabric-commands" aria-label="Permalink: Setting up the fabric commands" href="#setting-up-the-fabric-commands"></a></p>
<p dir="auto">Follow these steps to get all fabric-related apps installed and configured.</p>
<ol dir="auto">
<li>Navigate to where you want the Fabric project to live on your system in a semi-permanent place on your computer.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Find a home for Fabric
cd /where/you/keep/code"><pre><span><span>#</span> Find a home for Fabric</span>
<span>cd</span> /where/you/keep/code</pre></div>
<ol start="2" dir="auto">
<li>Clone the project to your computer.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone Fabric to your computer
git clone https://github.com/danielmiessler/fabric.git"><pre><span><span>#</span> Clone Fabric to your computer</span>
git clone https://github.com/danielmiessler/fabric.git</pre></div>
<ol start="3" dir="auto">
<li>Enter Fabric's main directory.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Enter the project folder (where you cloned it)
cd fabric"><pre><span><span>#</span> Enter the project folder (where you cloned it)</span>
<span>cd</span> fabric</pre></div>
<ol start="4" dir="auto">
<li>Install pipx:</li>
</ol>
<p dir="auto">macOS:</p>

<p dir="auto">Linux:</p>

<p dir="auto">Windows:</p>
<p dir="auto">Use WSL and follow the Linux instructions.</p>
<ol start="5" dir="auto">
<li>Install fabric:</li>
</ol>

<ol start="6" dir="auto">
<li>Run setup:</li>
</ol>

<ol start="7" dir="auto">
<li>
<p dir="auto">Restart your shell to reload everything.</p>
</li>
<li>
<p dir="auto">Now you are up and running! You can test by running the help.</p>
</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Making sure the paths are set up correctly
fabric --help"><pre><span><span>#</span> Making sure the paths are set up correctly</span>
fabric --help</pre></div>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">If you're using the <code>server</code> functions, <code>fabric-api</code> and <code>fabric-webui</code> need to be run in distinct terminal windows.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Updating</h2><a id="user-content-updating" aria-label="Permalink: Updating" href="#updating"></a></p>
<p dir="auto">To update Fabric, run the following commands.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# From the fabric directory
pipx install . --force
fabric --update"><pre><span><span>#</span> From the fabric directory</span>
pipx install <span>.</span> --force
fabric --update</pre></div>
<p dir="auto">Then restart your shell.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using the <code>fabric</code> client</h3><a id="user-content-using-the-fabric-client" aria-label="Permalink: Using the fabric client" href="#using-the-fabric-client"></a></p>
<p dir="auto">If you want to use it with OpenAI API-compatible inference servers, such as <a href="https://github.com/lm-sys/FastChat">FastChat</a>, <a href="http://helmholtz-blablador.fz-juelich.de/" rel="nofollow">Helmholtz Blablador</a>, <a href="https://lmstudio.ai/" rel="nofollow">LM Studio</a> and others, simply export the following environment variables:</p>
<ul dir="auto">
<li><code>export OPENAI_BASE_URL=https://YOUR-SERVER:8000/v1/</code></li>
<li><code>export DEFAULT_MODEL="YOUR_MODEL"</code></li>
</ul>
<p dir="auto">And if your server needs authentication tokens, as Blablador does, you export the token the same way you would with OpenAI:</p>
<ul dir="auto">
<li><code>export OPENAI_API_KEY="YOUR TOKEN"</code></li>
</ul>
<p dir="auto">Once you have it all set up, here's how to use it:</p>
<ol dir="auto">
<li>Check out the options
<code>fabric -h</code></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="usage: fabric -h
usage: fabric [-h] [--text TEXT] [--copy] [--agents] [--output [OUTPUT]] [--session [SESSION]] [--gui] [--stream] [--list] [--temp TEMP] [--top_p TOP_P] [--frequency_penalty FREQUENCY_PENALTY]
              [--presence_penalty PRESENCE_PENALTY] [--update] [--pattern PATTERN] [--setup] [--changeDefaultModel CHANGEDEFAULTMODEL] [--model MODEL] [--listmodels]
              [--remoteOllamaServer REMOTEOLLAMASERVER] [--context]

An open-source framework for augmenting humans using AI.

options:
  -h, --help            show this help message and exit
  --text TEXT, -t TEXT  Text to extract summary from
  --copy, -C            Copy the response to the clipboard
  --agents, -a          Use praisonAI to create an AI agent and then use it. ex: 'write me a movie script'
  --output [OUTPUT], -o [OUTPUT]
                        Save the response to a file
  --session [SESSION], -S [SESSION]
                        Continue your previous conversation. Default is your previous conversation
  --gui                 Use the GUI (Node and npm need to be installed)
  --stream, -s          Use this option if you want to see the results in realtime. NOTE: You will not be able to pipe the output into another command.
  --list, -l            List available patterns
  --temp TEMP           sets the temperature for the model. Default is 0
  --top_p TOP_P         set the top_p for the model. Default is 1
  --frequency_penalty FREQUENCY_PENALTY
                        sets the frequency penalty for the model. Default is 0.1
  --presence_penalty PRESENCE_PENALTY
                        sets the presence penalty for the model. Default is 0.1
  --update, -u          Update patterns.
  --pattern PATTERN, -p PATTERN
                        The pattern (prompt) to use
  --setup               Set up your fabric instance
  --changeDefaultModel CHANGEDEFAULTMODEL
                        Change the default model. For a list of available models, use the --listmodels flag.
  --model MODEL, -m MODEL
                        Select the model to use
  --listmodels          List all available models
  --remoteOllamaServer REMOTEOLLAMASERVER
                        The URL of the remote ollamaserver to use. ONLY USE THIS if you are using a local ollama server in a non-default location or port
  --context, -c         Use Context file (context.md) to add context to your pattern"><pre>usage: fabric -h
usage: fabric [-h] [--text TEXT] [--copy] [--agents] [--output [OUTPUT]] [--session [SESSION]] [--gui] [--stream] [--list] [--temp TEMP] [--top_p TOP_P] [--frequency_penalty FREQUENCY_PENALTY]
              [--presence_penalty PRESENCE_PENALTY] [--update] [--pattern PATTERN] [--setup] [--changeDefaultModel CHANGEDEFAULTMODEL] [--model MODEL] [--listmodels]
              [--remoteOllamaServer REMOTEOLLAMASERVER] [--context]

An open-source framework <span>for</span> augmenting humans using AI.

options:
  <span>-h</span>, --help            show this <span>help</span> message and <span>exit</span>
  --text TEXT, <span>-t</span> TEXT  Text to extract summary from
  --copy, -C            Copy the response to the clipboard
  --agents, <span>-a</span>          Use praisonAI to create an AI agent and <span>then</span> use it. ex: <span><span>'</span>write me a movie script<span>'</span></span>
  --output [OUTPUT], <span>-o</span> [OUTPUT]
                        Save the response to a file
  --session [SESSION], <span>-S</span> [SESSION]
                        Continue your previous conversation. Default is your previous conversation
  --gui                 Use the GUI (Node and npm need to be installed)
  --stream, <span>-s</span>          Use this option <span>if</span> you want to see the results <span>in</span> realtime. NOTE: You will not be able to pipe the output into another command.
  --list, -l            List available patterns
  --temp TEMP           sets the temperature <span>for</span> the model. Default is 0
  --top_p TOP_P         <span>set</span> the top_p <span>for</span> the model. Default is 1
  --frequency_penalty FREQUENCY_PENALTY
                        sets the frequency penalty <span>for</span> the model. Default is 0.1
  --presence_penalty PRESENCE_PENALTY
                        sets the presence penalty <span>for</span> the model. Default is 0.1
  --update, -u          Update patterns.
  --pattern PATTERN, -p PATTERN
                        The pattern (prompt) to use
  --setup               Set up your fabric instance
  --changeDefaultModel CHANGEDEFAULTMODEL
                        Change the default model. For a list of available models, use the --listmodels flag.
  --model MODEL, -m MODEL
                        Select the model to use
  --listmodels          List all available models
  --remoteOllamaServer REMOTEOLLAMASERVER
                        The URL of the remote ollamaserver to use. ONLY USE THIS <span>if</span> you are using a <span>local</span> ollama server <span>in</span> a non-default location or port
  --context, -c         Use Context file (context.md) to add context to your pattern</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example commands</h4><a id="user-content-example-commands" aria-label="Permalink: Example commands" href="#example-commands"></a></p>
<p dir="auto">The client, by default, runs Fabric patterns without needing a server (the Patterns were downloaded during setup). This means the client connects directly to OpenAI using the input given and the Fabric pattern used.</p>
<ol dir="auto">
<li>Run the <code>summarize</code> Pattern based on input from <code>stdin</code>. In this case, the body of an article.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="pbpaste | fabric --pattern summarize"><pre>pbpaste <span>|</span> fabric --pattern summarize</pre></div>
<ol start="2" dir="auto">
<li>Run the <code>analyze_claims</code> Pattern with the <code>--stream</code> option to get immediate and streaming results.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="pbpaste | fabric --stream --pattern analyze_claims"><pre>pbpaste <span>|</span> fabric --stream --pattern analyze_claims</pre></div>
<ol start="3" dir="auto">
<li>Run the <code>extract_wisdom</code> Pattern with the <code>--stream</code> option to get immediate and streaming results from any Youtube video (much like in the original introduction video).</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="yt --transcript https://youtube.com/watch?v=uXs-zPc63kM | fabric --stream --pattern extract_wisdom"><pre>yt --transcript https://youtube.com/watch<span>?</span>v=uXs-zPc63kM <span>|</span> fabric --stream --pattern extract_wisdom</pre></div>
<ol start="4" dir="auto">
<li><strong>new</strong> All of the patterns have been added as aliases to your bash (or zsh) config file</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="pbpaste | analyze_claims --stream"><pre>pbpaste <span>|</span> analyze_claims --stream</pre></div>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">More examples coming in the next few days, including a demo video!</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Just use the Patterns</h3><a id="user-content-just-use-the-patterns" aria-label="Permalink: Just use the Patterns" href="#just-use-the-patterns"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/50654/301807224-9186a044-652b-4673-89f7-71cf066f32d8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDE4MDcyMjQtOTE4NmEwNDQtNjUyYi00NjczLTg5ZjctNzFjZjA2NmYzMmQ4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWIyYzQ0NWFlNWZkMmM3MmIxZmQ2OTEyYTMxZTgxMjI2ZjczYTc4ODE3YzUxOTZhZmU5MzFmNTEyOTMwMjM2ZDImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0._CUfFxYf4hYIZTQqpqBdbb18DNU16YH-gv_4RiO8iGs"><img width="1173" alt="fabric-patterns-screenshot" src="https://private-user-images.githubusercontent.com/50654/301807224-9186a044-652b-4673-89f7-71cf066f32d8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDE4MDcyMjQtOTE4NmEwNDQtNjUyYi00NjczLTg5ZjctNzFjZjA2NmYzMmQ4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWIyYzQ0NWFlNWZkMmM3MmIxZmQ2OTEyYTMxZTgxMjI2ZjczYTc4ODE3YzUxOTZhZmU5MzFmNTEyOTMwMjM2ZDImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0._CUfFxYf4hYIZTQqpqBdbb18DNU16YH-gv_4RiO8iGs"></a>

<p dir="auto">If you're not looking to do anything fancy, and you just want a lot of great prompts, you can navigate to the <a href="https://github.com/danielmiessler/fabric/tree/main/patterns"><code>/patterns</code></a> directory and start exploring!</p>
<p dir="auto">We hope that if you used nothing else from Fabric, the Patterns by themselves will make the project useful.</p>
<p dir="auto">You can use any of the Patterns you see there in any AI application that you have, whether that's ChatGPT or some other app or website. Our plan and prediction is that people will soon be sharing many more than those we've published, and they will be way better than ours.</p>
<p dir="auto">The wisdom of crowds for the win.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Create your own Fabric Mill</h3><a id="user-content-create-your-own-fabric-mill" aria-label="Permalink: Create your own Fabric Mill" href="#create-your-own-fabric-mill"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/50654/301727604-ec3bd9b5-d285-483d-9003-7a8e6d842584.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDE3Mjc2MDQtZWMzYmQ5YjUtZDI4NS00ODNkLTkwMDMtN2E4ZTZkODQyNTg0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE3ZWY2M2U5YmY0ZGJjYzQ5NDE4ZTk4OGM2MzAxYmMzMTY2OTQ3ZGY0Y2Q1MjMxZWFjNDkwNzY2ZTZlY2I1OWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5Nr762Iy8EjhyWT1Xf2UXLBicZlj5G1oFXWnj-USryE"><img width="2000" alt="fabric_mill_architecture" src="https://private-user-images.githubusercontent.com/50654/301727604-ec3bd9b5-d285-483d-9003-7a8e6d842584.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjAzMjY5MDEsIm5iZiI6MTcyMDMyNjYwMSwicGF0aCI6Ii81MDY1NC8zMDE3Mjc2MDQtZWMzYmQ5YjUtZDI4NS00ODNkLTkwMDMtN2E4ZTZkODQyNTg0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA3VDA0MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE3ZWY2M2U5YmY0ZGJjYzQ5NDE4ZTk4OGM2MzAxYmMzMTY2OTQ3ZGY0Y2Q1MjMxZWFjNDkwNzY2ZTZlY2I1OWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5Nr762Iy8EjhyWT1Xf2UXLBicZlj5G1oFXWnj-USryE"></a>

<p dir="auto">But we go beyond just providing Patterns. We provide code for you to build your very own Fabric server and personal AI infrastructure!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Structure</h2><a id="user-content-structure" aria-label="Permalink: Structure" href="#structure"></a></p>
<p dir="auto">Fabric is themed off of, well… <em>fabric</em>—as in…woven materials. So, think blankets, quilts, patterns, etc. Here's the concept and structure:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Components</h3><a id="user-content-components" aria-label="Permalink: Components" href="#components"></a></p>
<p dir="auto">The Fabric ecosystem has three primary components, all named within this textile theme.</p>
<ul dir="auto">
<li>The <strong>Mill</strong> is the (optional) server that makes <strong>Patterns</strong> available.</li>
<li><strong>Patterns</strong> are the actual granular AI use cases (prompts).</li>
<li><strong>Stitches</strong> are chained together <em>Patterns</em> that create advanced functionality (see below).</li>
<li><strong>Looms</strong> are the client-side apps that call a specific <strong>Pattern</strong> hosted by a <strong>Mill</strong>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI-native</h3><a id="user-content-cli-native" aria-label="Permalink: CLI-native" href="#cli-native"></a></p>
<p dir="auto">One of the coolest parts of the project is that it's <strong>command-line native</strong>!</p>
<p dir="auto">Each Pattern you see in the <code>/patterns</code> directory can be used in any AI application you use, but you can also set up your own server using the <code>/server</code> code and then call APIs directly!</p>
<p dir="auto">Once you're set-up, you can do things like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Take any idea from `stdin` and send it to the `/write_essay` API!
echo &quot;An idea that coding is like speaking with rules.&quot; | write_essay"><pre><span><span>#</span> Take any idea from `stdin` and send it to the `/write_essay` API!</span>
<span>echo</span> <span><span>"</span>An idea that coding is like speaking with rules.<span>"</span></span> <span>|</span> write_essay</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Directly calling Patterns</h3><a id="user-content-directly-calling-patterns" aria-label="Permalink: Directly calling Patterns" href="#directly-calling-patterns"></a></p>
<p dir="auto">One key feature of <code>fabric</code> and its Markdown-based format is the ability to <em>directly reference</em> (and edit) individual <a href="#components">Patterns</a> directly—on their own—without any surrounding code.</p>
<p dir="auto">As an example, here's how to call <em>the direct location</em> of the <code>extract_wisdom</code> pattern.</p>
<div dir="auto" data-snippet-clipboard-copy-content="https://github.com/danielmiessler/fabric/blob/main/patterns/extract_wisdom/system.md"><pre>https://github.com/danielmiessler/fabric/blob/main/patterns/extract_wisdom/system.md</pre></div>
<p dir="auto">This means you can cleanly, and directly reference any pattern for use in a web-based AI app, your own code, or wherever!</p>
<p dir="auto">Even better, you can also have your <a href="#components">Mill</a> functionality directly call <em>system</em> and <em>user</em> prompts from <code>fabric</code>, meaning you can have your personal AI ecosystem automatically kept up to date with the latest version of your favorite <a href="#components">Patterns</a>.</p>
<p dir="auto">Here's what that looks like in code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="https://github.com/danielmiessler/fabric/blob/main/server/fabric_api_server.py"><pre>https://github.com/danielmiessler/fabric/blob/main/server/fabric_api_server.py</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# /extwis
@app.route(&quot;/extwis&quot;, methods=[&quot;POST&quot;])
@auth_required  # Require authentication
def extwis():
    data = request.get_json()

    # Warn if there's no input
    if &quot;input&quot; not in data:
        return jsonify({&quot;error&quot;: &quot;Missing input parameter&quot;}), 400

    # Get data from client
    input_data = data[&quot;input&quot;]

    # Set the system and user URLs
    system_url = &quot;https://raw.githubusercontent.com/danielmiessler/fabric/main/patterns/extract_wisdom/system.md&quot;
    user_url = &quot;https://raw.githubusercontent.com/danielmiessler/fabric/main/patterns/extract_wisdom/user.md&quot;

    # Fetch the prompt content
    system_content = fetch_content_from_url(system_url)
    user_file_content = fetch_content_from_url(user_url)

    # Build the API call
    system_message = {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_content}
    user_message = {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_file_content + &quot;\n&quot; + input_data}
    messages = [system_message, user_message]
    try:
        response = openai.chat.completions.create(
            model=&quot;gpt-4-1106-preview&quot;,
            messages=messages,
            temperature=0.0,
            top_p=1,
            frequency_penalty=0.1,
            presence_penalty=0.1,
        )
        assistant_message = response.choices[0].message.content
        return jsonify({&quot;response&quot;: assistant_message})
    except Exception as e:
        return jsonify({&quot;error&quot;: str(e)}), 500"><pre><span># /extwis</span>
<span>@<span>app</span>.<span>route</span>(<span>"/extwis"</span>, <span>methods</span><span>=</span>[<span>"POST"</span>])</span>
<span>@<span>auth_required</span>  <span># Require authentication</span></span>
<span>def</span> <span>extwis</span>():
    <span>data</span> <span>=</span> <span>request</span>.<span>get_json</span>()

    <span># Warn if there's no input</span>
    <span>if</span> <span>"input"</span> <span>not</span> <span>in</span> <span>data</span>:
        <span>return</span> <span>jsonify</span>({<span>"error"</span>: <span>"Missing input parameter"</span>}), <span>400</span>

    <span># Get data from client</span>
    <span>input_data</span> <span>=</span> <span>data</span>[<span>"input"</span>]

    <span># Set the system and user URLs</span>
    <span>system_url</span> <span>=</span> <span>"https://raw.githubusercontent.com/danielmiessler/fabric/main/patterns/extract_wisdom/system.md"</span>
    <span>user_url</span> <span>=</span> <span>"https://raw.githubusercontent.com/danielmiessler/fabric/main/patterns/extract_wisdom/user.md"</span>

    <span># Fetch the prompt content</span>
    <span>system_content</span> <span>=</span> <span>fetch_content_from_url</span>(<span>system_url</span>)
    <span>user_file_content</span> <span>=</span> <span>fetch_content_from_url</span>(<span>user_url</span>)

    <span># Build the API call</span>
    <span>system_message</span> <span>=</span> {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>system_content</span>}
    <span>user_message</span> <span>=</span> {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>user_file_content</span> <span>+</span> <span>"<span>\n</span>"</span> <span>+</span> <span>input_data</span>}
    <span>messages</span> <span>=</span> [<span>system_message</span>, <span>user_message</span>]
    <span>try</span>:
        <span>response</span> <span>=</span> <span>openai</span>.<span>chat</span>.<span>completions</span>.<span>create</span>(
            <span>model</span><span>=</span><span>"gpt-4-1106-preview"</span>,
            <span>messages</span><span>=</span><span>messages</span>,
            <span>temperature</span><span>=</span><span>0.0</span>,
            <span>top_p</span><span>=</span><span>1</span>,
            <span>frequency_penalty</span><span>=</span><span>0.1</span>,
            <span>presence_penalty</span><span>=</span><span>0.1</span>,
        )
        <span>assistant_message</span> <span>=</span> <span>response</span>.<span>choices</span>[<span>0</span>].<span>message</span>.<span>content</span>
        <span>return</span> <span>jsonify</span>({<span>"response"</span>: <span>assistant_message</span>})
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span>:
        <span>return</span> <span>jsonify</span>({<span>"error"</span>: <span>str</span>(<span>e</span>)}), <span>500</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Here's an abridged output example from the <a href="https://github.com/danielmiessler/fabric/blob/main/patterns/extract_wisdom/system.md"><code>extract_wisdom</code></a> pattern (limited to only 10 items per section).</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Paste in the transcript of a YouTube video of Riva Tez on David Perrel's podcast
pbpaste | extract_wisdom"><pre><span><span>#</span> Paste in the transcript of a YouTube video of Riva Tez on David Perrel's podcast</span>
pbpaste <span>|</span> extract_wisdom</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="## SUMMARY:

The content features a conversation between two individuals discussing various topics, including the decline of Western culture, the importance of beauty and subtlety in life, the impact of technology and AI, the resonance of Rilke's poetry, the value of deep reading and revisiting texts, the captivating nature of Ayn Rand's writing, the role of philosophy in understanding the world, and the influence of drugs on society. They also touch upon creativity, attention spans, and the importance of introspection.

## IDEAS:

1. Western culture is perceived to be declining due to a loss of values and an embrace of mediocrity.
2. Mass media and technology have contributed to shorter attention spans and a need for constant stimulation.
3. Rilke's poetry resonates due to its focus on beauty and ecstasy in everyday objects.
4. Subtlety is often overlooked in modern society due to sensory overload.
5. The role of technology in shaping music and performance art is significant.
6. Reading habits have shifted from deep, repetitive reading to consuming large quantities of new material.
7. Revisiting influential books as one ages can lead to new insights based on accumulated wisdom and experiences.
8. Fiction can vividly illustrate philosophical concepts through characters and narratives.
9. Many influential thinkers have backgrounds in philosophy, highlighting its importance in shaping reasoning skills.
10. Philosophy is seen as a bridge between theology and science, asking questions that both fields seek to answer.

## QUOTES:

1. &quot;You can't necessarily think yourself into the answers. You have to create space for the answers to come to you.&quot;
2. &quot;The West is dying and we are killing her.&quot;
3. &quot;The American Dream has been replaced by mass-packaged mediocrity porn, encouraging us to revel like happy pigs in our own meekness.&quot;
4. &quot;There's just not that many people who have the courage to reach beyond consensus and go explore new ideas.&quot;
5. &quot;I'll start watching Netflix when I've read the whole of human history.&quot;
6. &quot;Rilke saw beauty in everything... He sees it's in one little thing, a representation of all things that are beautiful.&quot;
7. &quot;Vanilla is a very subtle flavor... it speaks to sort of the sensory overload of the modern age.&quot;
8. &quot;When you memorize chapters [of the Bible], it takes a few months, but you really understand how things are structured.&quot;
9. &quot;As you get older, if there's books that moved you when you were younger, it's worth going back and rereading them.&quot;
10. &quot;She [Ayn Rand] took complicated philosophy and embodied it in a way that anybody could resonate with.&quot;

## HABITS:

1. Avoiding mainstream media consumption for deeper engagement with historical texts and personal research.
2. Regularly revisiting influential books from youth to gain new insights with age.
3. Engaging in deep reading practices rather than skimming or speed-reading material.
4. Memorizing entire chapters or passages from significant texts for better understanding.
5. Disengaging from social media and fast-paced news cycles for more focused thought processes.
6. Walking long distances as a form of meditation and reflection.
7. Creating space for thoughts to solidify through introspection and stillness.
8. Embracing emotions such as grief or anger fully rather than suppressing them.
9. Seeking out varied experiences across different careers and lifestyles.
10. Prioritizing curiosity-driven research without specific goals or constraints.

## FACTS:

1. The West is perceived as declining due to cultural shifts away from traditional values.
2. Attention spans have shortened due to technological advancements and media consumption habits.
3. Rilke's poetry emphasizes finding beauty in everyday objects through detailed observation.
4. Modern society often overlooks subtlety due to sensory overload from various stimuli.
5. Reading habits have evolved from deep engagement with texts to consuming large quantities quickly.
6. Revisiting influential books can lead to new insights based on accumulated life experiences.
7. Fiction can effectively illustrate philosophical concepts through character development and narrative arcs.
8. Philosophy plays a significant role in shaping reasoning skills and understanding complex ideas.
9. Creativity may be stifled by cultural nihilism and protectionist attitudes within society.
10. Short-term thinking undermines efforts to create lasting works of beauty or significance.

## REFERENCES:

1. Rainer Maria Rilke's poetry
2. Netflix
3. Underworld concert
4. Katy Perry's theatrical performances
5. Taylor Swift's performances
6. Bible study
7. Atlas Shrugged by Ayn Rand
8. Robert Pirsig's writings
9. Bertrand Russell's definition of philosophy
10. Nietzsche's walks"><pre><span>## <span>SUMMARY:</span></span>

The content features a conversation between two individuals discussing various topics, including the decline of Western culture, the importance of beauty and subtlety in life, the impact of technology and AI, the resonance of Rilke's poetry, the value of deep reading and revisiting texts, the captivating nature of Ayn Rand's writing, the role of philosophy in understanding the world, and the influence of drugs on society. They also touch upon creativity, attention spans, and the importance of introspection.

<span>## <span>IDEAS:</span></span>

<span>1</span><span>.</span> Western culture is perceived to be declining due to a loss of values and an embrace of mediocrity.
<span>2</span><span>.</span> Mass media and technology have contributed to shorter attention spans and a need for constant stimulation.
<span>3</span><span>.</span> Rilke's poetry resonates due to its focus on beauty and ecstasy in everyday objects.
<span>4</span><span>.</span> Subtlety is often overlooked in modern society due to sensory overload.
<span>5</span><span>.</span> The role of technology in shaping music and performance art is significant.
<span>6</span><span>.</span> Reading habits have shifted from deep, repetitive reading to consuming large quantities of new material.
<span>7</span><span>.</span> Revisiting influential books as one ages can lead to new insights based on accumulated wisdom and experiences.
<span>8</span><span>.</span> Fiction can vividly illustrate philosophical concepts through characters and narratives.
<span>9</span><span>.</span> Many influential thinkers have backgrounds in philosophy, highlighting its importance in shaping reasoning skills.
<span>10</span><span>.</span> Philosophy is seen as a bridge between theology and science, asking questions that both fields seek to answer.

<span>## <span>QUOTES:</span></span>

<span>1</span><span>.</span> "You can't necessarily think yourself into the answers. You have to create space for the answers to come to you."
<span>2</span><span>.</span> "The West is dying and we are killing her."
<span>3</span><span>.</span> "The American Dream has been replaced by mass-packaged mediocrity porn, encouraging us to revel like happy pigs in our own meekness."
<span>4</span><span>.</span> "There's just not that many people who have the courage to reach beyond consensus and go explore new ideas."
<span>5</span><span>.</span> "I'll start watching Netflix when I've read the whole of human history."
<span>6</span><span>.</span> "Rilke saw beauty in everything... He sees it's in one little thing, a representation of all things that are beautiful."
<span>7</span><span>.</span> "Vanilla is a very subtle flavor... it speaks to sort of the sensory overload of the modern age."
<span>8</span><span>.</span> "When you memorize chapters <span>[</span>of the Bible<span>]</span>, it takes a few months, but you really understand how things are structured."
<span>9</span><span>.</span> "As you get older, if there's books that moved you when you were younger, it's worth going back and rereading them."
<span>10</span><span>.</span> "She <span>[</span>Ayn Rand<span>]</span> took complicated philosophy and embodied it in a way that anybody could resonate with."

<span>## <span>HABITS:</span></span>

<span>1</span><span>.</span> Avoiding mainstream media consumption for deeper engagement with historical texts and personal research.
<span>2</span><span>.</span> Regularly revisiting influential books from youth to gain new insights with age.
<span>3</span><span>.</span> Engaging in deep reading practices rather than skimming or speed-reading material.
<span>4</span><span>.</span> Memorizing entire chapters or passages from significant texts for better understanding.
<span>5</span><span>.</span> Disengaging from social media and fast-paced news cycles for more focused thought processes.
<span>6</span><span>.</span> Walking long distances as a form of meditation and reflection.
<span>7</span><span>.</span> Creating space for thoughts to solidify through introspection and stillness.
<span>8</span><span>.</span> Embracing emotions such as grief or anger fully rather than suppressing them.
<span>9</span><span>.</span> Seeking out varied experiences across different careers and lifestyles.
<span>10</span><span>.</span> Prioritizing curiosity-driven research without specific goals or constraints.

<span>## <span>FACTS:</span></span>

<span>1</span><span>.</span> The West is perceived as declining due to cultural shifts away from traditional values.
<span>2</span><span>.</span> Attention spans have shortened due to technological advancements and media consumption habits.
<span>3</span><span>.</span> Rilke's poetry emphasizes finding beauty in everyday objects through detailed observation.
<span>4</span><span>.</span> Modern society often overlooks subtlety due to sensory overload from various stimuli.
<span>5</span><span>.</span> Reading habits have evolved from deep engagement with texts to consuming large quantities quickly.
<span>6</span><span>.</span> Revisiting influential books can lead to new insights based on accumulated life experiences.
<span>7</span><span>.</span> Fiction can effectively illustrate philosophical concepts through character development and narrative arcs.
<span>8</span><span>.</span> Philosophy plays a significant role in shaping reasoning skills and understanding complex ideas.
<span>9</span><span>.</span> Creativity may be stifled by cultural nihilism and protectionist attitudes within society.
<span>10</span><span>.</span> Short-term thinking undermines efforts to create lasting works of beauty or significance.

<span>## <span>REFERENCES:</span></span>

<span>1</span><span>.</span> Rainer Maria Rilke's poetry
<span>2</span><span>.</span> Netflix
<span>3</span><span>.</span> Underworld concert
<span>4</span><span>.</span> Katy Perry's theatrical performances
<span>5</span><span>.</span> Taylor Swift's performances
<span>6</span><span>.</span> Bible study
<span>7</span><span>.</span> Atlas Shrugged by Ayn Rand
<span>8</span><span>.</span> Robert Pirsig's writings
<span>9</span><span>.</span> Bertrand Russell's definition of philosophy
<span>10</span><span>.</span> Nietzsche's walks</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Custom Patterns</h2><a id="user-content-custom-patterns" aria-label="Permalink: Custom Patterns" href="#custom-patterns"></a></p>
<p dir="auto">You can also use Custom Patterns with Fabric, meaning Patterns you keep locally and don't upload to Fabric.</p>
<p dir="auto">One possible place to store them is <code>~/.config/custom-fabric-patterns</code>.</p>
<p dir="auto">Then when you want to use them, simply copy them into <code>~/.config/fabric/patterns</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cp -a ~/.config/custom-fabric-patterns/* ~/.config/fabric/patterns/"><pre>cp -a <span>~</span>/.config/custom-fabric-patterns/<span>*</span> <span>~</span>/.config/fabric/patterns/</pre></div>
<p dir="auto">Now you can run them with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pbpaste | fabric -p your_custom_pattern"><pre>pbpaste <span>|</span> fabric -p your_custom_pattern</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Agents</h2><a id="user-content-agents" aria-label="Permalink: Agents" href="#agents"></a></p>
<p dir="auto">NEW FEATURE! We have incorporated <a href="https://github.com/MervinPraison/PraisonAI">PraisonAI</a> into Fabric. This feature creates AI agents and then uses them to perform a task.</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &quot;Search for recent articles about the future of AI and write me a 500-word essay on the findings&quot; | fabric --agents"><pre><span>echo</span> <span><span>"</span>Search for recent articles about the future of AI and write me a 500-word essay on the findings<span>"</span></span> <span>|</span> fabric --agents</pre></div>
<p dir="auto">This feature works with all OpenAI and Ollama models but does NOT work with Claude. You can specify your model with the -m flag.</p>
<p dir="auto">For more information about this amazing project, please visit <a href="https://github.com/MervinPraison/PraisonAI">https://github.com/MervinPraison/PraisonAI</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Helper Apps</h2><a id="user-content-helper-apps" aria-label="Permalink: Helper Apps" href="#helper-apps"></a></p>
<p dir="auto">These are helper tools to work with Fabric. Examples include things like getting transcripts from media files, getting metadata about media, etc.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">yt (YouTube)</h2><a id="user-content-yt-youtube" aria-label="Permalink: yt (YouTube)" href="#yt-youtube"></a></p>
<p dir="auto"><code>yt</code> is a command that uses the YouTube API to pull transcripts, pull user comments, get video duration, and other functions. It's primary function is to get a transcript from a video that can then be stitched (piped) into other Fabric Patterns.</p>
<div dir="auto" data-snippet-clipboard-copy-content="usage: yt [-h] [--duration] [--transcript] [url]

vm (video meta) extracts metadata about a video, such as the transcript and the video's duration. By Daniel Miessler.

positional arguments:
  url           YouTube video URL

options:
  -h, --help    Show this help message and exit
  --duration    Output only the duration
  --transcript  Output only the transcript
  --comments    Output only the user comments"><pre>usage: yt [-h] [--duration] [--transcript] [url]

vm (video meta) extracts metadata about a video, such as the transcript and the video<span><span>'</span>s duration. By Daniel Miessler.</span>
<span></span>
<span>positional arguments:</span>
<span>  url           YouTube video URL</span>
<span></span>
<span>options:</span>
<span>  -h, --help    Show this help message and exit</span>
<span>  --duration    Output only the duration</span>
<span>  --transcript  Output only the transcript</span>
<span>  --comments    Output only the user comments</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">ts (Audio transcriptions)</h2><a id="user-content-ts-audio-transcriptions" aria-label="Permalink: ts (Audio transcriptions)" href="#ts-audio-transcriptions"></a></p>
<p dir="auto">'ts' is a command that uses the OpenAI Whisper API to transcribe audio files. Due to the context window, this tool uses pydub to split the files into 10 minute segments. for more information on pydub, please refer <a href="https://github.com/jiaaro/pydub">https://github.com/jiaaro/pydub</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="
mac:
brew install ffmpeg

linux:
apt install ffmpeg

windows:
download instructions https://www.ffmpeg.org/download.html"><pre>mac:
brew install ffmpeg

linux:
apt install ffmpeg

windows:
download instructions https://www.ffmpeg.org/download.html</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="ts -h
usage: ts [-h] audio_file

Transcribe an audio file.

positional arguments:
  audio_file  The path to the audio file to be transcribed.

options:
  -h, --help  show this help message and exit"><pre>ts -h
usage: ts [-h] audio_file

Transcribe an audio file.

positional arguments:
  audio_file  The path to the audio file to be transcribed.

options:
  -h, --help  show this <span>help</span> message and <span>exit</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Save</h2><a id="user-content-save" aria-label="Permalink: Save" href="#save"></a></p>
<p dir="auto"><code>save</code> is a "tee-like" utility to pipeline saving of content, while keeping the output stream intact. Can optionally generate "frontmatter" for PKM utilities like Obsidian via the
"FABRIC_FRONTMATTER" environment variable</p>
<p dir="auto">If you'd like to default variables, set them in <code>~/.config/fabric/.env</code>. <code>FABRIC_OUTPUT_PATH</code> needs to be set so <code>save</code> where to write. <code>FABRIC_FRONTMATTER_TAGS</code> is optional, but useful for tracking how tags have entered your PKM, if that's important to you.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">usage</h3><a id="user-content-usage" aria-label="Permalink: usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="usage: save [-h] [-t, TAG] [-n] [-s] [stub]

save: a &quot;tee-like&quot; utility to pipeline saving of content, while keeping the output stream intact. Can optionally generate &quot;frontmatter&quot; for PKM utilities like Obsidian via the
&quot;FABRIC_FRONTMATTER&quot; environment variable

positional arguments:
  stub                stub to describe your content. Use quotes if you have spaces. Resulting format is YYYY-MM-DD-stub.md by default

options:
  -h, --help          show this help message and exit
  -t, TAG, --tag TAG  add an additional frontmatter tag. Use this argument multiple timesfor multiple tags
  -n, --nofabric      don't use the fabric tags, only use tags from --tag
  -s, --silent        don't use STDOUT for output, only save to the file"><pre>usage: save [-h] [-t, TAG] [-n] [-s] [stub]

save: a <span><span>"</span>tee-like<span>"</span></span> utility to pipeline saving of content, <span>while</span> keeping the output stream intact. Can optionally generate <span><span>"</span>frontmatter<span>"</span></span> <span>for</span> PKM utilities like Obsidian via the
<span><span>"</span>FABRIC_FRONTMATTER<span>"</span></span> environment variable

positional arguments:
  stub                stub to describe your content. Use quotes <span>if</span> you have spaces. Resulting format is YYYY-MM-DD-stub.md by default

options:
  -h, --help          show this <span>help</span> message and <span>exit</span>
  -t, TAG, --tag TAG  add an additional frontmatter tag. Use this argument multiple timesfor multiple tags
  -n, --nofabric      don<span><span>'</span>t use the fabric tags, only use tags from --tag</span>
<span>  -s, --silent        don<span>'</span></span>t use STDOUT <span>for</span> output, only save to the file</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="echo test | save --tag extra-tag stub-for-name
test

$ cat ~/obsidian/Fabric/2024-03-02-stub-for-name.md
---
generation_date: 2024-03-02 10:43
tags: fabric-extraction stub-for-name extra-tag
---
test"><pre><span>echo</span> <span>test</span> <span>|</span> save --tag extra-tag stub-for-name
<span>test</span>

$ cat <span>~</span>/obsidian/Fabric/2024-03-02-stub-for-name.md
---
generation_date: 2024-03-02 10:43
tags: fabric-extraction stub-for-name extra-tag
---
<span>test</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Meta</h2><a id="user-content-meta" aria-label="Permalink: Meta" href="#meta"></a></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Special thanks to the following people for their inspiration and contributions!</p>
</div>
<ul dir="auto">
<li><em>Caleb Sima</em> for pushing me over the edge of whether to make this a public project or not.</li>
<li><em>Joel Parish</em> for super useful input on the project's Github directory structure.</li>
<li><em>Jonathan Dunn</em> for spectacular work on the soon-to-be-released universal client.</li>
<li><em>Joseph Thacker</em> for the idea of a <code>-c</code> context flag that adds pre-created context in the <code>./config/fabric/</code> directory to all Pattern queries.</li>
<li><em>Jason Haddix</em> for the idea of a stitch (chained Pattern) to filter content using a local model before sending on to a cloud model, i.e., cleaning customer data using <code>llama2</code> before sending on to <code>gpt-4</code> for analysis.</li>
<li><em>Dani Goland</em> for enhancing the Fabric Server (Mill) infrastructure by migrating to FastAPI, breaking the server into discrete pieces, and Dockerizing the entire thing.</li>
<li><em>Andre Guerra</em> for simplifying installation by getting us onto Poetry for virtual environment and dependency management.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Primary contributors</h3><a id="user-content-primary-contributors" aria-label="Permalink: Primary contributors" href="#primary-contributors"></a></p>
<p dir="auto"><a href="https://github.com/danielmiessler"><img src="https://avatars.githubusercontent.com/u/50654?v=4" title="Daniel Miessler" width="50" height="50"></a>
<a href="https://github.com/xssdoctor"><img src="https://avatars.githubusercontent.com/u/9218431?v=4" title="Jonathan Dunn" width="50" height="50"></a>
<a href="https://github.com/sbehrens"><img src="https://avatars.githubusercontent.com/u/688589?v=4" title="Scott Behrens" width="50" height="50"></a>
<a href="https://github.com/agu3rra"><img src="https://avatars.githubusercontent.com/u/10410523?v=4" title="Andre Guerra" width="50" height="50"></a></p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kivy – a cross platform Python UI framework (175 pts)]]></title>
            <link>https://kivy.org</link>
            <guid>40891446</guid>
            <pubDate>Sat, 06 Jul 2024 16:27:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kivy.org">https://kivy.org</a>, See on <a href="https://news.ycombinator.com/item?id=40891446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p><b>Kivy</b> is released under the <b>MIT License</b>, is
          <b>100%</b> free to use, and is professionally developed, backed and
          maintained.</p><p>
          <b>Companies</b> and <b>individuals</b> are using Kivy for their
          projects <b>every day</b>.
        </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First anode-free sodium solid-state battery (325 pts)]]></title>
            <link>https://pme.uchicago.edu/news/uchicago-prof-shirley-mengs-laboratory-energy-storage-and-conversion-creates-worlds-first</link>
            <guid>40891252</guid>
            <pubDate>Sat, 06 Jul 2024 16:01:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pme.uchicago.edu/news/uchicago-prof-shirley-mengs-laboratory-energy-storage-and-conversion-creates-worlds-first">https://pme.uchicago.edu/news/uchicago-prof-shirley-mengs-laboratory-energy-storage-and-conversion-creates-worlds-first</a>, See on <a href="https://news.ycombinator.com/item?id=40891252">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="app">
  <header>
    <uc-skip-nav text="Skip to main content"></uc-skip-nav>
            


        
<uc-masthead :nav-data="{
  &quot;items&quot;:
    [{&quot;section&quot;:&quot;About&quot;,&quot;link&quot;:&quot;/about&quot;,&quot;target&quot;:&quot;_self&quot;,&quot;text&quot;:&quot;The Pritzker School of Molecular Engineering integrates science and engineering to address global challenges from the molecular level up.&quot;,&quot;groups&quot;:null,&quot;links&quot;:[{&quot;title&quot;:&quot;A Welcome from Dean Mason&quot;,&quot;url&quot;:&quot;/about/welcome-dean-mason&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Mission and Vision&quot;,&quot;url&quot;:&quot;/about/mission-and-vision&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;How We\u0027re Organized \u2014 by Themes&quot;,&quot;url&quot;:&quot;https://pme.uchicago.edu/research/themes&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Our Degree Programs&quot;,&quot;url&quot;:&quot;/academics&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Equity, Diversity, &amp; Inclusion&quot;,&quot;url&quot;:&quot;/equity-diversity-inclusion&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Leadership&quot;,&quot;url&quot;:&quot;/about/leadership&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Faculty Accolades&quot;,&quot;url&quot;:&quot;/about/faculty-accolades&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;PME Facilities&quot;,&quot;url&quot;:&quot;/about/facilities&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Argonne National Laboratory Facilities&quot;,&quot;url&quot;:&quot;https://www.anl.gov/national-scientific-user-facilities&quot;,&quot;target&quot;:&quot;_blank&quot;},{&quot;title&quot;:&quot;Partners&quot;,&quot;url&quot;:&quot;/about/partners&quot;,&quot;target&quot;:&quot;_self&quot;}]},{&quot;section&quot;:&quot;Research&quot;,&quot;link&quot;:&quot;/research/themes&quot;,&quot;target&quot;:&quot;_self&quot;,&quot;text&quot;:&quot;PME is organized  into problem-solving interdisciplinary themes focused on some of humanity\u0027s biggest challenges. Unlike traditional schools with departments, we work together to drive impact.&quot;,&quot;groups&quot;:[{&quot;group&quot;:&quot;Themes&quot;,&quot;links&quot;:[{&quot;title&quot;:&quot;Immunoengineering&quot;,&quot;url&quot;:&quot;/themes/immunoengineering&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Materials Systems for Sustainability and Health&quot;,&quot;url&quot;:&quot;/themes/materials-systems-sustainability-and-health&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Quantum Engineering&quot;,&quot;url&quot;:&quot;https://pme.uchicago.edu/quantum-uchicago&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Arts, Sciences, and Technology&quot;,&quot;url&quot;:&quot;/themes/arts-sciences-and-technology&quot;,&quot;target&quot;:&quot;&quot;}]},{&quot;group&quot;:&quot;Other Areas of Focus&quot;,&quot;links&quot;:[{&quot;title&quot;:&quot;Artificial Intelligence&quot;,&quot;url&quot;:&quot;/ai-pme&quot;,&quot;target&quot;:&quot;&quot;}]}],&quot;links&quot;:[]},{&quot;section&quot;:&quot;Academics&quot;,&quot;link&quot;:&quot;/academics&quot;,&quot;target&quot;:&quot;_self&quot;,&quot;text&quot;:&quot;At the Pritzker School of Molecular Engineering, we are scientists, engineers, and above all, global-problem solvers.&quot;,&quot;groups&quot;:null,&quot;links&quot;:[{&quot;title&quot;:&quot;PhD Programs&quot;,&quot;url&quot;:&quot;/academics/phd-programs&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Master\u0027s Program&quot;,&quot;url&quot;:&quot;/academics/masters-of-engineering&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Undergraduate Program&quot;,&quot;url&quot;:&quot;/academics/undergraduate-program-molecular-engineering&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Non-degree Visiting Student Research&quot;,&quot;url&quot;:&quot;/academics/non-degree-visiting-student-research&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Dean of Students Office&quot;,&quot;url&quot;:&quot;/current-phd-students/pme-dean-students-office&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Educational Outreach&quot;,&quot;url&quot;:&quot;/academics/educational-outreach&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Postdoctoral Researchers&quot;,&quot;url&quot;:&quot;/academics/postdoctoral-researchers&quot;,&quot;target&quot;:&quot;&quot;}]},{&quot;section&quot;:&quot;People&quot;,&quot;link&quot;:&quot;/people&quot;,&quot;target&quot;:&quot;&quot;,&quot;text&quot;:&quot;We select our community purposefully, bringing together individuals committed to finding solutions to pressing world issues.&quot;,&quot;groups&quot;:null,&quot;links&quot;:[{&quot;title&quot;:&quot;Meet the Dean&quot;,&quot;url&quot;:&quot;https://pme.uchicago.edu/faculty/nadya-mason&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Leadership&quot;,&quot;url&quot;:&quot;/about/leadership&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;CASE members&quot;,&quot;url&quot;:&quot;/people/case-directory&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Faculty&quot;,&quot;url&quot;:&quot;/people/faculty-directory&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Fellows&quot;,&quot;url&quot;:&quot;/people/fellows-directory&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;NSF\u2019s ChemMatCARS&quot;,&quot;url&quot;:&quot;/people/nsfs-chemmatcars-directory&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Senior Instructional Professors&quot;,&quot;url&quot;:&quot;/people/senior-instructional-professors-sip-directory&quot;,&quot;target&quot;:&quot;_self&quot;},{&quot;title&quot;:&quot;Staff&quot;,&quot;url&quot;:&quot;/people/staff-directory&quot;,&quot;target&quot;:&quot;_self&quot;}]},{&quot;section&quot;:&quot;Lab Groups&quot;,&quot;link&quot;:&quot;/lab-groups-directory&quot;,&quot;target&quot;:&quot;&quot;,&quot;text&quot;:&quot;&quot;,&quot;groups&quot;:null,&quot;links&quot;:[]},{&quot;section&quot;:&quot;News&quot;,&quot;link&quot;:&quot;/news&quot;,&quot;target&quot;:&quot;&quot;,&quot;text&quot;:&quot;&quot;,&quot;groups&quot;:null,&quot;links&quot;:[]},{&quot;section&quot;:&quot;Events&quot;,&quot;link&quot;:&quot;/events&quot;,&quot;target&quot;:&quot;&quot;,&quot;text&quot;:&quot;Stay up to date with the latest events at the University of Chicago\u0027s Pritzker School of Molecular Engineering&quot;,&quot;groups&quot;:null,&quot;links&quot;:[]},{&quot;section&quot;:&quot;Give&quot;,&quot;link&quot;:&quot;/make-gift&quot;,&quot;target&quot;:&quot;&quot;,&quot;text&quot;:&quot;&quot;,&quot;groups&quot;:null,&quot;links&quot;:[]},{&quot;section&quot;:&quot;Apply Now&quot;,&quot;link&quot;:&quot;https://pme.uchicago.edu/academics/apply-now&quot;,&quot;target&quot;:&quot;_self&quot;,&quot;text&quot;:&quot;&quot;,&quot;groups&quot;:null,&quot;links&quot;:[]}],
  &quot;switcher&quot;: [
    {&quot;type&quot;:&quot;prospect&quot;,&quot;links&quot;:[{&quot;title&quot;:&quot;Current Students&quot;,&quot;url&quot;:&quot;/current-students&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Industry&quot;,&quot;url&quot;:&quot;https://pme.uchicago.edu/industry&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Publications&quot;,&quot;url&quot;:&quot;/publications&quot;,&quot;target&quot;:&quot;&quot;},{&quot;title&quot;:&quot;Intranet&quot;,&quot;url&quot;:&quot;https://uchicagoedu.sharepoint.com/sites/PME&quot;,&quot;target&quot;:&quot;_blank&quot;}]}
  ],
  &quot;site_logo&quot;: &quot;/sites/default/files/2021-06/pme_logo_color_rgb_v3.png&quot;,
  &quot;site_logo_alt&quot;: &quot;Pritzker School of Molecular Engineering&quot;
}">
</uc-masthead>

    
  </header>
  <main>
      





<section>
  <article>
    

        

<header>
      
  
<a href="https://pme.uchicago.edu/taxonomy/term/26/edit">
  News
</a>


    
  
      <p>
  <time datetime="2024-07-03T12:00:00Z">July 3, 2024</time>

</p>
  </header>

          
    
          
    
    <uc-share-links></uc-share-links>

          
    
    
    
    
                        <div>
            <p>UChicago Pritzker Molecular Engineering <a href="https://pme.uchicago.edu/faculty/y-shirley-meng">Prof. Y. Shirley Meng’s</a> <a href="https://lescmeng.ai/">Laboratory for Energy Storage and Conversion</a> has created the world’s first anode-free sodium solid-state battery.</p>
<p>With this research, the LESC – a collaboration between the UChicago Pritzker School of Molecular Engineering and the <a href="https://ne.ucsd.edu/">University of California San Diego’s Aiiso Yufeng Li Family Department of Chemical and Nano Engineering</a> – has brought the reality of inexpensive, fast-charging, high-capacity batteries for electric vehicles and grid storage closer than ever.</p>
<p>“Although there have been previous sodium, solid-state, and anode-free batteries, no one has been able to successfully combine these three ideas until now,” said UC San Diego PhD candidate Grayson Deysher, first author of a new paper outlining the team’s work.</p>
<p>The paper, <a href="https://www.nature.com/articles/s41560-024-01569-9">published today in <em>Nature Energy</em></a>, demonstrates a new sodium battery architecture with stable cycling for several hundred cycles. By removing the anode and using inexpensive, abundant sodium instead of lithium, this new form of battery will be more affordable and environmentally friendly to produce. Through its innovative solid-state design, the battery also will be safe and powerful.</p>
<p>This work is both an advance in the science and a necessary step to fill the battery scaling gap needed to transition the world economy off of fossil fuels.</p>
<p>“To keep the United States running for one hour, we must produce one terawatt hour of energy,” Meng said. “To accomplish our mission of decarbonizing our economy, we need several hundred terawatt hours of batteries. We need more batteries, and we need them fast.”</p>
<p><strong>Sustainability and sodium</strong></p>
<p>The lithium commonly used for batteries isn’t that common. It makes up about 20 parts per million of the Earth’s crust, compared to sodium, which makes up 20,000 parts per million.</p>
<p>This scarcity, combined with the surge in demand for the lithium-ion batteries for laptops, phones and EVs, have sent prices skyrocketing, putting the needed batteries further out of reach.</p>

          </div>
        
                  
                                <div>
            <p>Lithium deposits are also concentrated. The “Lithium Triangle” of Chile, Argentina and Bolivia holds more than 75% of the world’s lithium supply, with other deposits in Australia, North Carolina and Nevada. This benefits some nations over others in the decarbonization needed to fight climate change.</p>
<p>“Global action requires working together to access critically important materials,” Meng said.</p>
<p>Lithium extraction is also environmentally damaging, whether from the industrial acids used to break down mining ore or the more common brine extraction that pumps massive amounts of water to the surface to dry.</p>
<p>Sodium, common in ocean water and soda ash mining, is an inherently more environmentally friendly battery material. The LESC research has made it a powerful one as well.</p>
<p><strong>Innovative architecture</strong></p>
<p>To create a sodium battery with the energy density of a lithium battery, the team needed to invent a new sodium battery architecture.</p>
<p>Traditional batteries have an anode to store the ions while a battery is charging. While the battery is in use, the ions flow from the anode through an electrolyte to a current collector (cathode), powering devices and cars along the way.</p>
<p>Anode-free batteries remove the anode and store the ions on an electrochemical deposition of alkali metal directly on the current collector. This approach enables higher cell voltage, lower cell cost, and increased energy density, but brings its own challenges.</p>
<p>“In any anode-free battery there needs to be good contact between the electrolyte and the current collector,” Deysher said. “This is typically very easy when using a liquid electrolyte, as the liquid can flow everywhere and wet every surface. A solid electrolyte cannot do this.”</p>
<p>However, those liquid electrolytes create a buildup called solid electrolyte interphase while steadily consuming the active materials, reducing the battery’s usefulness over time.</p>
<p><strong>A solid that flows</strong></p>
<p>The team took a novel, innovative approach to this problem. Rather than using an electrolyte that surrounds the current collector, they created a current collector that surrounds the electrolyte.</p>
<p>They created their current collector out of aluminum powder, a solid that can flow like a liquid.</p>

          </div>
        
                  
                                <div>
            <p>During battery assembly the powder was densified under high pressure to form a solid current collector while maintaining a liquid-like contact with the electrolyte, enabling the low-cost and high-efficiency cycling that can push this game-changing technology forward.</p>
<p>“Sodium solid-state batteries are usually seen as a far-off-in-the-future technology, but we hope that this paper can invigorate more push into the sodium area by demonstrating that it can indeed work well, even better than the lithium version in some cases,” Deysher said.</p>
<p>The ultimate goal? Meng envisions an energy future with a variety of clean, inexpensive battery options that store renewable energy, scaled to fit society’s needs.</p>
<p>Meng and Deysher have filed a patent application for their work through UC San Diego’s Office of Innovation and Commercialization.</p>
<p><em>Citation: “Design principles for enabling an anode-free sodium all-solid-state battery,” Deysher et al, </em>Nature Energy, <em>July 3, 2024. DOI: </em><a href="https://www.nature.com/articles/s41560-024-01569-9"><em>10.1038/s41560-024-01569-9</em></a></p>
<p><em>Funding: Funding to support this work was provided by the National Science Foundation through the Partnerships for Innovation (PFI) grant no. 2044465</em></p>

          </div>
        
              
    


        <uc-share-links></uc-share-links>
    
  </article>
</section>







  </main>
  





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teaching general problem-solving skills is not a substitute for teaching math [pdf] (215 pts)]]></title>
            <link>https://www.ams.org/notices/201010/rtx101001303p.pdf</link>
            <guid>40890847</guid>
            <pubDate>Sat, 06 Jul 2024 15:07:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ams.org/notices/201010/rtx101001303p.pdf">https://www.ams.org/notices/201010/rtx101001303p.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40890847">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Anxious Generation – How Safetyism and Social Media Are Damaging the Kids (117 pts)]]></title>
            <link>https://matija.eu/posts/anxious-generation-safetyism-social-media/</link>
            <guid>40890534</guid>
            <pubDate>Sat, 06 Jul 2024 14:02:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matija.eu/posts/anxious-generation-safetyism-social-media/">https://matija.eu/posts/anxious-generation-safetyism-social-media/</a>, See on <a href="https://news.ycombinator.com/item?id=40890534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I just finished reading this book the other day. Written by Jonathan Haidt, <a href="https://www.amazon.com/Anxious-Generation-Rewiring-Childhood-Epidemic/dp/0593655036">"Anxious Generation"</a> deals with a concept he calls the "Great Rewiring." Essentially, he proposes that two forces at play nowadays have led (and continue to lead) an entire generation to significantly higher rates of mental illnesses.</p>
<p>One of these forces is unfettered access to social media. He draws a distinct line between the generic overuse of computers or the internet and the use of social media. The former began back in the 90s (or maybe even the 80s), but no dramatic increases in mental illness occurred back then. In those days, you'd be spending too much time in front of your screen, and the worst that could happen was you'd worsen your eyesight, end up somewhat socially inept, or even get a job in the industry once you grew up. He highlights that this was mostly observed among boys rather than girls, and the effects weren't as negative.</p>
<p>Nowadays, this is no longer the case. It's actually girls who bear the brunt of the effect, and the impact is far from harmless. He convincingly connects the dots between the social validation loop masterfully (ab)used by all modern social media, the early age that social media starts being used (early teens), and the statistics that show the incidence of mental illnesses just as platforms like Instagram started their growth in the 2010s.</p>
<p>The mind gets stuck in a loop where it continuously seeks validation and requires us to put up an almost perfect appearance for others. There's no way this is healthy for a young mind to go through. He even shows research indicating that school-aged kids might actually be taking a toll in cognitive performance due to this. A study done on kids taking exams shows there's an actual difference between taking the test without your phone in the room, with your phone in your pocket, and with your phone on the table right in front of you. You can guess which produces the best results and which produces the worst, as their minds are frankly always on standby, wondering what's going on in their social network.</p>
<p>In addition to social media use, he also talks about the other big issue that leads to his Great Rewiring: helicopter parenting.</p>
<p>The net effect of this is that kids have far more extended boundaries set on them (except on their phones!). For example, nowadays, parents expect their children to be free to go and do groceries alone or play outside without adult supervision only at around the age of 10 to 12 (if not even higher). Gen X, in his research, remembers this as having happened for them around ages 6, 7, or 8. On one hand, I feel like this claim rings true; on the other, I'm also wondering if there might be a case of some <a href="https://en.m.wikipedia.org/wiki/Rosy_retrospection">rosy retrospection</a> or wishful thinking.</p>
<p>Far from stopping there, he mentions other significant societal efforts that are thwarting children's growth, such as having playgrounds where kids don't exhibit any risk of harming themselves. Instead of preparing the kids and making them capable of (literally in this case) tackling obstacles, we're removing obstacles and coddling them.</p>
<p>Kids also become overprotected in other ways, such as not hearing other views or not being able to handle opposing views. No wonder academia is nowadays the exact opposite of free speech and the scientific method.</p>
<p>The trend of not keeping tabs on what kids are doing <em>online</em> (as opposed to offline, where the boundaries are much stricter) leads to what he deems a phone-based childhood. The kids are growing up playing with their phones rather than playing outside with other kids, learning the ropes of, well—life.</p>
<p>He suggests solving these regressions by reverting some societal safetyisms. He comes up with what he calls a "Ladder from Childhood to Adulthood" and presents checkpoints of what type of behavior one ought to expect their child to exhibit. For example, at six, the child should have a certain level of household responsibility. At eight, they might not require adult supervision to play outside, and maybe they get a dumbphone to stay in touch. Within this framework, the use of social media should come only at age 16, unlike the current state where it's supposedly age 13+ but in reality, this is not enforced at all.</p>
<p>Apart from these two major angles of the Great Rewiring, he also touches on the spiritual aspects (albeit he's an atheist), but that's not that important. He's somewhat activist about all of this, so he has a website dedicated to it all <a href="https://www.anxiousgeneration.com/">over here</a> (not just a book commercial).</p>
<p>All in all, it's a fairly interesting book, and I'll probably take a look at some of his other writings.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>