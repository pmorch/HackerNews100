<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 30 Jul 2024 05:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Four billion years in four minutes – Simulating worlds on the GPU (132 pts)]]></title>
            <link>https://davidar.io/post/sim-glsl</link>
            <guid>41104721</guid>
            <pubDate>Mon, 29 Jul 2024 23:33:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://davidar.io/post/sim-glsl">https://davidar.io/post/sim-glsl</a>, See on <a href="https://news.ycombinator.com/item?id=41104721">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<section id="abstract">
<h6>Abstract</h6>
<p>This post delves into the implementation of my <a href="https://www.shadertoy.com/view/XttcWn">procedural earth simulation</a>, written entirely in GLSL fragment shaders. It simulates the complete history of an earth-like planet in a few minutes, with the simulation updating at 60 frames per second.</p>
</section>
<figure>
<p><iframe src="https://player.vimeo.com/video/283607168" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<figcaption>A video recording of the <a href="https://www.shadertoy.com/view/XttcWn">final shader</a>.</figcaption>
</figure>
<h2>Protoplanet</h2>
<blockquote>
<p>This story begins four and a half billion years ago, with a lump of molten rock...
</p></blockquote>
<figure>

</figure>
<p>The early earth was a <a href="https://en.wikipedia.org/wiki/Protoplanet">protoplanet</a>, red hot and heavily cratered by asteroid impacts. As my earth simulation is <em>entirely procedurally generated</em>, with no pre-rendered textures, the first task is to generate a map of this terrain. To calculate the <code>height</code> of the terrain at a given <code>lat</code>itude and <code>lon</code>gitude, first translate to 3D cartesian coordinates:
</p><pre><code>
vec3 p = 1.5 * vec3(
    sin(lon*PI/180.) * cos(lat*PI/180.),
    sin(lat*PI/180.),
    cos(lon*PI/180.) * cos(lat*PI/180.));
</code></pre>
<p>Now, as asteroids come in a variety of sizes, so do the resulting craters. To accommodate this, the shader iterates over five levels of detail, layering craters of decreasing size over each other. To make the craters have a realistic rugged appearance, this is mixed with some <a href="https://iquilezles.untergrund.net/www/articles/fbm/fbm.htm">fractional Brownian motion</a> noise, and scaled so that the largest craters have the most impact on the terrain.
</p><pre><code>
float height = 0.;
for (float i = 0.; i &lt; 5.; i++) {
    float c = craters(0.4 * pow(2.2, i) * p);
    float noise = 0.4 * exp(-3. * c) * FBM(10. * p);
    float w = clamp(3. * pow(0.4, i), 0., 1.);
    height += w * (c + noise);
}
height = pow(height, 3.);
</code></pre>
<p>The craters themselves are generated on a 3D grid, from which a sphere is carved out for the surface terrain. To avoid visible regularity, the crater centres are given a pseudo-random offset from the grid points, using a <a href="https://www.shadertoy.com/view/4djSRW">hash function</a>. To calculate influence of a crater at a given location, take a weighted average of the craters belonging to the nearby grid points, with weights exponentially decreasing with distance from the centre. The crater rims are generated by a simple sine curve.
</p><pre><code>
float craters(vec3 x) {
    vec3 p = floor(x);
    vec3 f = fract(x);
    float va = 0.;
    float wt = 0.;
    for (int i = -2; i &lt;= 2; i++)
     for (int j = -2; j &lt;= 2; j++)
      for (int k = -2; k &lt;= 2; k++) {
        vec3 g = vec3(i,j,k);
        vec3 o = 0.8 * hash33(p + g);
        float d = distance(f - g, o);
        float w = exp(-4. * d);
        va += w * sin(2.*PI * sqrt(d));
        wt += w;
    }
    return abs(va / wt);
}
</code></pre>
<p>The final procedurally generated heightmap looks like this:
</p><figure>
<img src="https://davidar.io/img/protoplanet.jpg">
</figure>
<p>Although relatively simple, after filling the low-lying regions with water, this procedural terrain resembles what scientists believe the early earth actually looked like:
</p><figure>
<img src="https://davidar.io/img/hadeanearth.jpg">
<figcaption>Artistic impression of the early earth, by <a href="https://sservi.nasa.gov/articles/new-nasa-research-shows-giant-asteroids-battered-early-earth/">NASA</a>.</figcaption>
</figure>
<blockquote>
<p>Water contained within was vaporised by the heat, which escaped and began circulating through the early atmosphere forming around the planet. As time progressed and the rock cooled, the water vapour began to condense into oceans. The flow of liquid water across the surface carved valleys in the terrain, leaving an accumulation of sediment in its wake.
</p></blockquote>
<h2>Tectonic plates</h2>
<p>The formation of mountains, ocean trenches, and familiar continental landforms requires a model of tectonic movement. The simulation randomly generates seed locations for plates, with an initial velocity. These plates grow in size over time with a simple aggregation model, which randomly selects neighbouring points and adds them to a plate if they have not already been assigned to another plate. All of the pixels within a plate store the velocity of the plate's movement. The aggregation model is similar to that of a diffusion-limited aggregation (but without the diffusion):
</p><figure>

</figure>
<p>Continuous movement of the plates is difficult, as it would require plate boundaries to account for movements measured in fractions of a pixel. To avoid this, the plates are instead moved at discrete time-steps, by a whole pixel either horizontally or vertically. These times are randomised for each plate such that the average velocity is maintained at the set speed and direction, and also so that it is unlikely that neighbouring plates will move simultaneously.
</p><p>Plate collisions occur when some boundary pixels of one plate move onto a location previously occupied by pixels belonging to another plate. This causes <a href="https://en.wikipedia.org/wiki/Subduction">subduction</a>, which is modelled by simply slightly increasing the elevation of the terrain at the locations of the collision. Although this only occurs at the pixels along the boundary of a plate, the impact is gradually spread to neighbouring pixels through a simple thermal erosion model, which pushes the elevation of a pixel in the direction of the average of its neighbours.
</p><p>Altogether this provides a decent simulation of the formation of continents with mountain ranges (which will be further improved with the introduction of hydraulic erosion in the next section):
</p><figure>

</figure>
<h2>Hydraulic erosion</h2>
<p>The rugged appearance of natural terrain is largely driven by the formation of river basins, which erode landscapes in a familiar branching pattern. A variety of water flow simulations are readily available for this task, but a difficulty here is that the resolution of the terrain map is quite low for an entire planet. Therefore, the model will have to be able to simulate rivers which are no more than a single pixel wide. <a href="https://arxiv.org/abs/1803.02977">Barnes (2018)</a> proposes a simple model which achieves just this.
</p><p>Simply put, each pixel examines its eight neighbours, to determine which direction has the greatest decrease in elevation (adjusted for the fact that the diagonal neighbours are further away). This direction of greatest slope is where water flowing out of this pixel will travel. Water is initially distributed amongst cells by rainfall, which is then transported between neighbouring pixels at each time-step.
</p><p>Erosion is driven by a <a href="https://en.wikipedia.org/wiki/Stream_power_law">stream power law</a>:
</p><pre><code>
elevation -= 0.05 * pow(water, 0.8) * pow(slope, 2.);
</code></pre>
<p>Here we have the <code>elevation</code> and amount of <code>water</code> located at the current cell, along with the <code>slope</code> in the direction the water is travelling. The decrease in elevation is capped so that it doesn't become lower than the location the water is flowing to.
</p><p>The interaction between the water flow and erosion results in the natural formation of river basins in the terrain:
</p><figure>

</figure>
<p>By colouring connected waterways (with the colour determined by the location of the river's mouth), it's possible to produce striking visualisations reminiscent of <a href="https://imgur.com/gallery/WaEbi">real river basin maps</a>:
</p><figure>
<img src="https://davidar.io/img/basin.png">
<figcaption>Simulated river basins. <a href="https://www.shadertoy.com/view/XsVBDz">Original shader</a>.</figcaption>
</figure>
<figure>
<img src="https://i.imgur.com/ZXLEvU3.jpg">
<figcaption>River basins of USA, by <a href="https://www.grasshoppergeography.com/"></a>Grasshopper Geography.</figcaption>
</figure>
<h2>Global climate</h2>
<p>Simulating the climate system of an entire planet is a daunting task, but luckily it turns out that it can be approximated relatively easily. The driving force behind everything in my climate simulation is a procedurally generated map of the <a href="https://en.wikipedia.org/wiki/Atmospheric_pressure#Mean_sea-level_pressure">mean sea-level pressure (MSLP)</a>.
</p><p>According to <a href="https://web.archive.org/web/20130619132254/http://jc.tech-galaxy.com/bricka/climate_cookbook.html">the Climate Cookbook</a>, the main ingredients in creating a MSLP map are where the landforms are located amidst the ocean, and the impact of latitude. In fact, if you take data from a real MSLP map of the Earth, separate out locations according to whether they are land or ocean, and plot the MSLP against latitude, you end up with two sinusoidal curves for the land and ocean with slightly different shapes.
</p><p>By fitting the parameters appropriately, I came up with a crude model of the annual mean pressure (here the <code>lat</code>itude is measured in degrees):
</p><pre><code>
if (land) {
    mslp = 1012.5 - 6. * cos(lat*PI/45.);
} else { // ocean
    mslp = 1014.5 - 20. * cos(lat*PI/30.);
}
</code></pre>
<p>Of course, this isn't quite enough to generate a realistic MSLP map, as generating values for the land and ocean separately results in sharp discontinuities at the boundaries between them. In reality, MSLP smoothly varies across the transition from ocean to land, due to the local diffusion of gas pressure. This diffusion process can be approximated quite well by simply applying a <a href="https://en.wikipedia.org/wiki/Gaussian_blur">Gaussian blur</a> to the MSLP map (with a standard deviation of 10--15 degrees).
</p><p>To allow for the climate to change along with the seasons, it's necessary to also model the difference in MSLP between January and July. Once again, terrestrial data suggests this follows a sinusoidal pattern. By fitting parameters and applying a Gaussian blur, this can be combined with the annual MSLP map to generate dynamic climate patterns which vary throughout the year.
</p><pre><code>
if (land) {
    delta = 15. * sin(lat*PI/90.);
} else { // ocean
    delta = 20. * sin(lat*PI/35.) * abs(lat)/90.;
}
</code></pre>
<p>Now, with the MSLP in hand, it is possible to generate wind currents and temperatures. In reality it's the temperate which generates the pressure, but correlation is correlation. This requires a little more fiddling to generate realistic values (<code>season</code> oscillates between -1 and 1 throughout the year):
</p><pre><code>
float temp = 40. * tanh(2.2 * exp(-0.5 * pow((lat + 5. * season)/30., 2.)))
             - 15. - (mslp - 1012.) / 1.8 + 1.5 * land - 4. * elevation;
</code></pre>
<p>Wind tends to move from high-pressure to low, but at a global scale we also need to account for the <a href="https://en.wikipedia.org/wiki/Coriolis_force">Coriolis force</a>, which is responsible for causing winds to circulate <em>around</em> pressure zones (<code>grad</code> is the MSLP gradient vector):
</p><pre><code>
vec2 coriolis = 15. * sin(lat*PI/180.) * vec2(-grad.y, grad.x);
vec2 velocity = coriolis - grad;
</code></pre>
<p>Although a relatively crude simulation, this generates remarkably <a href="https://gist.github.com/davidar/229193b04bdb0dd8cba20dc31592625a">realistic</a> wind circulation patterns. If you look closely, you may notice a number of natural phenomena being replicated, including the reversal of winds over India during the monsoon season:
</p><figure>

</figure>
<p>As a final detail, precipitation can be simulated by advecting water vapour from the ocean, through the wind vector field, and onto the land:
</p><figure>

</figure>
<p>The advection is implemented in a similar manner to fluid simulations:
</p><figure>

</figure>
<h2>Life</h2>
<p>The climate influences the distribution of life on a planet. Rainfall patterns and temperature variation dictate rates of plant growth. As the seasons change, herbivores migrate to regions with enough vegetation to sustain them. And, as they follow the vegetation, predators follow them. All of these dynamics can be captured by a <a href="https://en.wikipedia.org/wiki/Lotka-Volterra_equations">Lotka--Volterra</a> diffusion model:
</p><pre><code>
float dx = plant_growth - c.y;
float dy = reproduction * c.x - predation * c.z - 1.;
float dz = predation * c.y - 1.;
float dt = 0.1;
c.xyz += dt * c.xyz * vec3(dx, dy, dz);
</code></pre>
<p>The <code>xyz</code> elements of <code>c</code> represent the populations of vegetation, herbivores, and predators respectively. On a large scale, the dynamics of animal populations generate interesting patterns:
</p><figure>

</figure>
<p>In real life, these kinds of patterns are most easily seen with microbe populations in a petri dish, but the same laws govern large animal populations across the globe.
</p><figure>
<img src="https://davidar.io/img/spiralmold.jpg">
<figcaption><a href="http://www.evsc.net/projects/reaction-diffusion-2">Spiral waves in colonies of mold</a>.</figcaption>
</figure>
<h2>Humanity</h2>
<blockquote>
<p>Concluding the prelude on the early earth, the pace slows to a cycle between day and night, terrain becoming fixed as tectonic movements become imperceptible. Soon the night reveals unprecedented patterns of light, as humanity proceeds to colonise the surface of the planet.
</p><p>This rapid expansion brings its own set of changes, as humans begin to burn large amounts of fossil fuels to power their settlements. Carbon that had lain dormant for millions of years is released into the atmosphere, and dispersed around the planet.
</p><p>Over several hundred years, humans burn through all available fossil fuel resources, releasing five trillion tonnes of carbon into the atmosphere. This strengthens the greenhouse effect, <a href="https://www.nature.com/articles/nclimate3036">raising the global average temperature by almost 10 degrees Celsius</a>. Large regions of land around the equator are rendered uninhabitable by extreme temperatures, resulting in the disappearance of humanity from a significant portion of the planet.
</p></blockquote>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SAM 2: Segment Anything in Images and Videos (329 pts)]]></title>
            <link>https://github.com/facebookresearch/segment-anything-2</link>
            <guid>41104523</guid>
            <pubDate>Mon, 29 Jul 2024 22:52:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/facebookresearch/segment-anything-2">https://github.com/facebookresearch/segment-anything-2</a>, See on <a href="https://news.ycombinator.com/item?id=41104523">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">SAM 2: Segment Anything in Images and Videos</h2><a id="user-content-sam-2-segment-anything-in-images-and-videos" aria-label="Permalink: SAM 2: Segment Anything in Images and Videos" href="#sam-2-segment-anything-in-images-and-videos"></a></p>
<p dir="auto"><strong><a href="https://ai.meta.com/research/" rel="nofollow">AI at Meta, FAIR</a></strong></p>
<p dir="auto"><a href="https://nikhilaravi.com/" rel="nofollow">Nikhila Ravi</a>, <a href="https://gabeur.github.io/" rel="nofollow">Valentin Gabeur</a>, <a href="https://scholar.google.com/citations?user=E8DVVYQAAAAJ&amp;hl=en" rel="nofollow">Yuan-Ting Hu</a>, <a href="https://ronghanghu.com/" rel="nofollow">Ronghang Hu</a>, <a href="https://scholar.google.com/citations?user=4LWx24UAAAAJ&amp;hl=en" rel="nofollow">Chaitanya Ryali</a>, <a href="https://scholar.google.com/citations?user=VeTSl0wAAAAJ&amp;hl=en" rel="nofollow">Tengyu Ma</a>, <a href="https://hkhedr.com/" rel="nofollow">Haitham Khedr</a>, <a href="https://scholar.google.de/citations?user=Tpt57v0AAAAJ&amp;hl=en" rel="nofollow">Roman Rädle</a>, <a href="https://scholar.google.com/citations?hl=fr&amp;user=n-SnMhoAAAAJ" rel="nofollow">Chloe Rolland</a>, <a href="https://scholar.google.com/citations?user=c8IpF9gAAAAJ&amp;hl=en" rel="nofollow">Laura Gustafson</a>, <a href="https://ericmintun.github.io/" rel="nofollow">Eric Mintun</a>, <a href="https://junting.github.io/" rel="nofollow">Junting Pan</a>, <a href="https://scholar.google.co.in/citations?user=m34oaWEAAAAJ&amp;hl=en" rel="nofollow">Kalyan Vasudev Alwala</a>, <a href="https://www.nicolascarion.com/" rel="nofollow">Nicolas Carion</a>, <a href="https://chaoyuan.org/" rel="nofollow">Chao-Yuan Wu</a>, <a href="https://www.rossgirshick.info/" rel="nofollow">Ross Girshick</a>, <a href="https://pdollar.github.io/" rel="nofollow">Piotr Dollár</a>, <a href="https://feichtenhofer.github.io/" rel="nofollow">Christoph Feichtenhofer</a></p>
<p dir="auto">[<a href="https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/" rel="nofollow"><code>Paper</code></a>] [<a href="https://ai.meta.com/sam2" rel="nofollow"><code>Project</code></a>] [<a href="https://sam2.metademolab.com/" rel="nofollow"><code>Demo</code></a>] [<a href="https://ai.meta.com/datasets/segment-anything-video" rel="nofollow"><code>Dataset</code></a>] [<a href="https://ai.meta.com/blog/segment-anything-2" rel="nofollow"><code>Blog</code></a>] [<a href="#citing-sam-2"><code>BibTeX</code></a>]</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/segment-anything-2/blob/main/assets/model_diagram.png?raw=true"><img src="https://github.com/facebookresearch/segment-anything-2/raw/main/assets/model_diagram.png?raw=true" alt="SAM 2 architecture"></a></p>
<p dir="auto"><strong>Segment Anything Model 2 (SAM 2)</strong> is a foundation model towards solving promptable visual segmentation in images and videos. We extend SAM to video by considering images as a video with a single frame. The model design is a simple transformer architecture with streaming memory for real-time video processing. We build a model in the loop data engine, which improves model and data via user interaction, to collect <a href="https://ai.meta.com/datasets/segment-anything-video" rel="nofollow"><strong>our SA-V dataset</strong></a>, the largest video segmentation dataset to date. SAM 2 trained on our data provides strong performance across a wide range of tasks and visual domains.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/segment-anything-2/blob/main/assets/sa_v_dataset.jpg?raw=true"><img src="https://github.com/facebookresearch/segment-anything-2/raw/main/assets/sa_v_dataset.jpg?raw=true" alt="SA-V dataset"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Please install SAM 2 on a GPU machine using:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:facebookresearch/segment-anything-2.git

cd segment-anything-2; pip install -e ."><pre>git clone git@github.com:facebookresearch/segment-anything-2.git

<span>cd</span> segment-anything-2<span>;</span> pip install -e <span>.</span></pre></div>
<p dir="auto">To use the SAM 2 predictor and run the example notebooks, <code>jupyter</code> and <code>matplotlib</code> are required and can be installed by:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Download Checkpoints</h3><a id="user-content-download-checkpoints" aria-label="Permalink: Download Checkpoints" href="#download-checkpoints"></a></p>
<p dir="auto">First, we need to download a model checkpoint. All the model checkpoints can be downloaded by running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd checkpoints
./download_ckpts.sh"><pre><span>cd</span> checkpoints
./download_ckpts.sh</pre></div>
<p dir="auto">or individually from:</p>
<ul dir="auto">
<li><a href="https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt" rel="nofollow">sam2_hiera_tiny.pt</a></li>
<li><a href="https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt" rel="nofollow">sam2_hiera_small.pt</a></li>
<li><a href="https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt" rel="nofollow">sam2_hiera_base_plus.pt</a></li>
<li><a href="https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt" rel="nofollow">sam2_hiera_large.pt</a></li>
</ul>
<p dir="auto">Then SAM 2 can be used in a few lines as follows for image and video prediction.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Image prediction</h3><a id="user-content-image-prediction" aria-label="Permalink: Image prediction" href="#image-prediction"></a></p>
<p dir="auto">SAM 2 has all the capabilities of <a href="https://github.com/facebookresearch/segment-anything">SAM</a> on static images, and we provide image prediction APIs that closely resemble SAM for image use cases. The <code>SAM2ImagePredictor</code> class has an easy interface for image prompting.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import torch
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

checkpoint = &quot;./checkpoints/sam2_hiera_large.pt&quot;
model_cfg = &quot;sam2_hiera_l.yaml&quot;
predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))

with torch.inference_mode(), torch.autocast(&quot;cuda&quot;, dtype=torch.bfloat16):
    predictor.set_image(<your_image>)
    masks, _, _ = predictor.predict(<input_prompts>)"><pre><span>import</span> <span>torch</span>
<span>from</span> <span>sam2</span>.<span>build_sam</span> <span>import</span> <span>build_sam2</span>
<span>from</span> <span>sam2</span>.<span>sam2_image_predictor</span> <span>import</span> <span>SAM2ImagePredictor</span>

<span>checkpoint</span> <span>=</span> <span>"./checkpoints/sam2_hiera_large.pt"</span>
<span>model_cfg</span> <span>=</span> <span>"sam2_hiera_l.yaml"</span>
<span>predictor</span> <span>=</span> <span>SAM2ImagePredictor</span>(<span>build_sam2</span>(<span>model_cfg</span>, <span>checkpoint</span>))

<span>with</span> <span>torch</span>.<span>inference_mode</span>(), <span>torch</span>.<span>autocast</span>(<span>"cuda"</span>, <span>dtype</span><span>=</span><span>torch</span>.<span>bfloat16</span>):
    <span>predictor</span>.<span>set_image</span>(<span>&lt;</span><span>your_image</span><span>&gt;</span>)
    <span>masks</span>, <span>_</span>, <span>_</span> <span>=</span> <span>predictor</span>.<span>predict</span>(<span>&lt;</span><span>input_prompts</span><span>&gt;</span>)</pre></div>
<p dir="auto">Please refer to the examples in <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/notebooks/image_predictor_example.ipynb">image_predictor_example.ipynb</a> for static image use cases.</p>
<p dir="auto">SAM 2 also supports automatic mask generation on images just like SAM. Please see <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/notebooks/automatic_mask_generator_example.ipynb">automatic_mask_generator_example.ipynb</a> for automatic mask generation in images.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Video prediction</h3><a id="user-content-video-prediction" aria-label="Permalink: Video prediction" href="#video-prediction"></a></p>
<p dir="auto">For promptable segmentation and tracking in videos, we provide a video predictor with APIs for example to add prompts and propagate masklets throughout a video. SAM 2 supports video inference on multiple objects and uses an inference state to keep track of the interactions in each video.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import torch
from sam2.build_sam import build_sam2_video_predictor

checkpoint = &quot;./checkpoints/sam2_hiera_large.pt&quot;
model_cfg = &quot;sam2_hiera_l.yaml&quot;
predictor = build_sam2_video_predictor(model_cfg, checkpoint)

with torch.inference_mode(), torch.autocast(&quot;cuda&quot;, dtype=torch.bfloat16):
    state = predictor.init_state(<your_video>)

    # add new prompts and instantly get the output on the same frame
    frame_idx, object_ids, masks = predictor.add_new_points(state, <your prompts>):

    # propagate the prompts to get masklets throughout the video
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ..."><pre><span>import</span> <span>torch</span>
<span>from</span> <span>sam2</span>.<span>build_sam</span> <span>import</span> <span>build_sam2_video_predictor</span>

<span>checkpoint</span> <span>=</span> <span>"./checkpoints/sam2_hiera_large.pt"</span>
<span>model_cfg</span> <span>=</span> <span>"sam2_hiera_l.yaml"</span>
<span>predictor</span> <span>=</span> <span>build_sam2_video_predictor</span>(<span>model_cfg</span>, <span>checkpoint</span>)

<span>with</span> <span>torch</span>.<span>inference_mode</span>(), <span>torch</span>.<span>autocast</span>(<span>"cuda"</span>, <span>dtype</span><span>=</span><span>torch</span>.<span>bfloat16</span>):
    <span>state</span> <span>=</span> <span>predictor</span>.<span>init_state</span>(<span>&lt;</span><span>your_video</span><span>&gt;</span>)

    <span># add new prompts and instantly get the output on the same frame</span>
    <span>frame_idx</span>, <span>object_ids</span>, <span>masks</span> <span>=</span> <span>predictor</span>.<span>add_new_points</span>(<span>state</span>, <span>&lt;</span><span>your</span> <span>prompts</span><span>&gt;</span>):

    <span># propagate the prompts to get masklets throughout the video</span>
    <span>for</span> <span>frame_idx</span>, <span>object_ids</span>, <span>masks</span> <span>in</span> <span>predictor</span>.<span>propagate_in_video</span>(<span>state</span>):
        ...</pre></div>
<p dir="auto">Please refer to the examples in <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/notebooks/video_predictor_example.ipynb">video_predictor_example.ipynb</a> for details on how to add prompts, make refinements, and track multiple objects in videos.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Description</h2><a id="user-content-model-description" aria-label="Permalink: Model Description" href="#model-description"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><strong>Model</strong></th>
<th><strong>Size (M)</strong></th>
<th><strong>Speed (FPS)</strong></th>
<th><strong>SA-V test (J&amp;F)</strong></th>
<th><strong>MOSE val (J&amp;F)</strong></th>
<th><strong>LVOS v2 (J&amp;F)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>sam2_hiera_tiny</td>
<td>38.9</td>
<td>47.2</td>
<td>75.0</td>
<td>70.9</td>
<td>75.3</td>
</tr>
<tr>
<td>sam2_hiera_small</td>
<td>46</td>
<td>43.3 (53.0 compiled*)</td>
<td>74.9</td>
<td>71.5</td>
<td>76.4</td>
</tr>
<tr>
<td>sam2_hiera_base_plus</td>
<td>80.8</td>
<td>34.8 (43.8 compiled*)</td>
<td>74.7</td>
<td>72.8</td>
<td>75.8</td>
</tr>
<tr>
<td>sam2_hiera_large</td>
<td>224.4</td>
<td>24.2 (30.2 compiled*)</td>
<td>76.0</td>
<td>74.6</td>
<td>79.8</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">* Compile the model by setting <code>compile_image_encoder: True</code> in the config.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Segment Aything Video Dataset</h2><a id="user-content-segment-aything-video-dataset" aria-label="Permalink: Segment Aything Video Dataset" href="#segment-aything-video-dataset"></a></p>
<p dir="auto">See <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/sav_dataset/README.md">sav_dataset/README.md</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The models are licensed under the <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/LICENSE">Apache 2.0 license</a>. Please refer to our research paper for more details on the models.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/CONTRIBUTING.md">contributing</a> and the <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/CODE_OF_CONDUCT.md">code of conduct</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<p dir="auto">The SAM 2 project was made possible with the help of many contributors (alphabetical):</p>
<p dir="auto">Karen Bergan, Daniel Bolya, Alex Bosenberg, Kai Brown, Vispi Cassod, Christopher Chedeau, Ida Cheng, Luc Dahlin, Shoubhik Debnath, Rene Martinez Doehner, Grant Gardner, Sahir Gomez, Rishi Godugu, Baishan Guo, Caleb Ho, Andrew Huang, Somya Jain, Bob Kamma, Amanda Kallet, Jake Kinney, Alexander Kirillov, Shiva Koduvayur, Devansh Kukreja, Robert Kuo, Aohan Lin, Parth Malani, Jitendra Malik, Mallika Malhotra, Miguel Martin, Alexander Miller, Sasha Mitts, William Ngan, George Orlin, Joelle Pineau, Kate Saenko, Rodrick Shepard, Azita Shokrpour, David Soofian, Jonathan Torres, Jenny Truong, Sagar Vaze, Meng Wang, Claudette Ward, Pengchuan Zhang.</p>
<p dir="auto">Third-party code: we use a GPU-based connected component algorithm adapted from <a href="https://github.com/zsef123/Connected_components_PyTorch"><code>cc_torch</code></a> (with its license in <a href="https://github.com/facebookresearch/segment-anything-2/blob/main/LICENSE_cctorch"><code>LICENSE_cctorch</code></a>) as an optional post-processing step for the mask predictions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citing SAM 2</h2><a id="user-content-citing-sam-2" aria-label="Permalink: Citing SAM 2" href="#citing-sam-2"></a></p>
<p dir="auto">If you use SAM 2 or the SA-V dataset in your research, please use the following BibTeX entry.</p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\&quot;a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint},
  year={2024}
}"><pre><span>@article</span>{<span>ravi2024sam2</span>,
  <span>title</span>=<span><span>{</span>SAM 2: Segment Anything in Images and Videos<span>}</span></span>,
  <span>author</span>=<span><span>{</span>Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph<span>}</span></span>,
  <span>journal</span>=<span><span>{</span>arXiv preprint<span>}</span></span>,
  <span>year</span>=<span><span>{</span>2024<span>}</span></span>
}</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FastHTML – Modern web applications in pure Python (242 pts)]]></title>
            <link>https://fastht.ml/</link>
            <guid>41104305</guid>
            <pubDate>Mon, 29 Jul 2024 22:18:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fastht.ml/">https://fastht.ml/</a>, See on <a href="https://news.ycombinator.com/item?id=41104305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<header>
  <nav>
    <a href="#">
      <img src="https://fastht.ml/assets/logo.svg" alt="FastHTML" width="105" height="24">
    </a>
    <a href="https://docs.fastht.ml/" target="_blank" rel="noopener noreferrer">Read docs</a>
  </nav>
</header>

<div>
      <h2>Modern web applications in pure Python</h2>
      <p>Built on solid web foundations, not the latest fads - with
FastHTML you can get started on anything from simple dashboards to
scalable web applications in minutes.</p>
    </div>
  <div>
      <div>
        <h2>This home page is a FastHTML app.</h2>
        <p>Click the buttons below to see four small, live components in action.</p>
      </div>
      
      
      
      
      <ul role="tablist" id="tab-list">
        <li role="tab" aria-selected="true">
          
        </li>
        <li role="tab" aria-selected="false">
          
        </li>
        <li role="tab" aria-selected="false">
          
        </li>
        <li role="tab" aria-selected="false">
          
        </li>
        
      </ul>
    </div>
  <section>
<div>
    <p>GET STARTED IN MINUTES</p>
    <h2>The fastest way to create a real web application.</h2>
    <p>With FastHTML you create good-looking modern web applications in pure Python and deploy them in minutes.</p>
  </div>

<div>
  <div>
    <h3>Get started fast</h3>
    <p>A single Python file is all that's needed to create any app you can think of. Or bring in any Python or JS library you like.</p>
  </div>
  <div>
    <h3>Flexibility</h3>
    <p>FastHTML provides full access to HTTP, HTML, JS, and CSS, bringing the foundations of the web to you. There's no limits to what you can build.</p>
  </div>
  <div>
    <h3>Speed &amp; scale</h3>
    <p>FastHTML applications are fast and scalable. They're also easy to deploy, since you can use any hosting service that supports Python.</p>
  </div>
</div>
  </section>
  <section id="stacked-cards-section">
    <div>
          <p>TECH STACK</p>
          <h2>FastHTML scales up and scales down.</h2>
          <p>
Read more about our 
            <a href="https://about.fastht.ml/vision" target="_blank" rel="noopener noreferrer">design philosophy here</a>
, or click a button below:
          </p>
        </div>
    <div id="stacked-cards">
        <div>
            <h3>Build on solid foundations</h3>
            <p>FastHTML stands on the shoulders of giants:</p>
            
          </div>
        <div>
            <h3>Use tools you already know</h3>
            <p>FastHTML embraces the familiar:</p>
            
          </div>
        <div>
            <h3>Deploy anywhere</h3>
            <p>FastHTML runs anywhere Python does, including 1-click deploy to:</p>
            
          </div>
      </div>
  </section>
  <section>
<div>
  <p>SAMPLES</p>
  <h2>See FastHTML in action</h2>
  <p>FastHTML can be used for everything from collaborative games to multi-modal UI. We've selected small self-contained examples for you to learn from.</p>
</div>



<a href="https://github.com/AnswerDotAI/fasthtml-example/tree/main">Discover all</a>
  </section>
  <div>
      <div>
        <p>FAQ</p>
        <h2>Questions? Answers.</h2>
        <p>Your top FastHTML questions clarified.</p>
      </div>
      <div>
        <div>
          <p>
          <label for="collapsible-3">
            <p>What kinds of applications can be written with this?</p>
            <img src="https://fastht.ml/assets/icons/plus-icon.svg" alt="Expand">
            <img src="https://fastht.ml/assets/icons/minus-icon.svg" alt="Collapse">
          </label></p><p>It's good for: general purpose web applications (i.e anything you'd build with React, Django, NexJS, etc); quick dashboards, prototypes, and in-company apps (e.g. like what you might use gradio/streamlit/etc for); Analytics/models/dashboards interactive reports; Custom blogs and content-heavy sites where you also want some interactive/dynamic content.</p>
        </div>
        <div>
          <p>
          <label for="collapsible-4">
            <p>Where can I deploy my FastHTML to? What's needed?</p>
            <img src="https://fastht.ml/assets/icons/plus-icon.svg" alt="Expand">
            <img src="https://fastht.ml/assets/icons/minus-icon.svg" alt="Collapse">
          </label></p><p>You can deploy a FastHTML app to any service or server that supports Python. We have guides and helpers for Railway.app, Vercel, Hugging Face Spaces, Replit, and PythonAnywhere. You can also use any VPS or server, or any on-premise machine with Python installed. All major operating systems are supported.</p>
        </div>
        <div>
          <p>
          <label for="collapsible-5">
            <p>How does FastHTML relate to FastAPI?</p>
            <img src="https://fastht.ml/assets/icons/plus-icon.svg" alt="Expand">
            <img src="https://fastht.ml/assets/icons/minus-icon.svg" alt="Collapse">
          </label></p><p>FastAPI is one of the inspirations for FastHTML. We are fans of its developer experience and tried to make FastHTML extremely familiar for FastAPI users. FastAPI is designed for creating APIs, whereas FastHTML is designed for creating HTML (i.e "Hypermedia applications"). Anything you could create with FastAPI (plus a JS frontend), you could also create with FastHTML, and vice versa -- if you prefer mainly writing JS, you might prefer FastAPI, since you can move a lot of client-side logic into the JS. If you prefer mainly writing Python, you'll probably want to use FastHTML, since you can often avoid using JS entirely.</p>
        </div>
        <div>
          <p>
          <label for="collapsible-6">
            <p>Is this only for multi-page "old style" web apps, or can FastHTML be used for modern SPA apps too?</p>
            <img src="https://fastht.ml/assets/icons/plus-icon.svg" alt="Expand">
            <img src="https://fastht.ml/assets/icons/minus-icon.svg" alt="Collapse">
          </label></p><p>FastHTML is specifically designed to make writing modern SPA apps as fast and easy as possible, whilst also ensuring the apps you write are scalable and performant. By default, FastHTML routes return lightweight "partials" that update the DOM directly, rather than doing a full page refresh.</p>
        </div>
        <div>
          <p>
          <label for="collapsible-7">
            <p>What is HTMX, and what's it go to do with FastHTML?</p>
            <img src="https://fastht.ml/assets/icons/plus-icon.svg" alt="Expand">
            <img src="https://fastht.ml/assets/icons/minus-icon.svg" alt="Collapse">
          </label></p><p>HTMX is best thought of as filling in the missing bits of a web browser -- in fact, web browser manufacturers are considering incorporating similar features directly into future browsers. It is a small javascript library that with a single line of HTML lets you respond to any event from any part of a web page by modifying the DOM in any way you like, all directly from Python. Whilst you don't have to use it with FastHTML, it will dramatically increase the amount of stuff you can do!</p>
        </div>
        <div>
          <p>
          <label for="collapsible-8">
            <p>Do I need to know JS? Can I use it if I want, with FastHTML?</p>
            <img src="https://fastht.ml/assets/icons/plus-icon.svg" alt="Expand">
            <img src="https://fastht.ml/assets/icons/minus-icon.svg" alt="Collapse">
          </label></p><p>No, and yes! You can write nearly any standard web app with just Python. However, using a bit of JS can be helpful -- for instance, nearly any existing JS lib can be incorporated into a FastHTML app, and you can sprinkle bits of JS into your pages anywhere you like.</p>
        </div>
        <div>
          <p>
          <label for="collapsible-9">
            <p>Are FastHTML apps slower than React, Next.JS, etc?</p>
            <img src="https://fastht.ml/assets/icons/plus-icon.svg" alt="Expand">
            <img src="https://fastht.ml/assets/icons/minus-icon.svg" alt="Collapse">
          </label></p><p>It depends. Apps using FastHTML and HTMX are often faster than JS-based approaches using big libraries, since they can be very lightweight.</p>
        </div>
      </div>
    </div>
  <div>
        <p>LOVE IS IN THE AIR</p>
        <h2>What the experts say</h2>
        <p>Top web programmers tell us that they love working with FastHTML.</p>
      </div>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Running One-man SaaS for 9 Years (471 pts)]]></title>
            <link>https://blog.healthchecks.io/2024/07/running-one-man-saas-9-years-in/</link>
            <guid>41104293</guid>
            <pubDate>Mon, 29 Jul 2024 22:15:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.healthchecks.io/2024/07/running-one-man-saas-9-years-in/">https://blog.healthchecks.io/2024/07/running-one-man-saas-9-years-in/</a>, See on <a href="https://news.ycombinator.com/item?id=41104293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<main id="main">
<article id="post-1520" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div itemprop="text">
<p>Healthchecks.io launched in July 2015, which means this year we turn 9. Time flies!</p>
<p>Previous status updates:</p>
<ul>
<li>In 2018, <a href="https://blog.healthchecks.io/2018/08/my-one-person-saas-side-project-celebrates-its-third-birthday/">My One-person SaaS Side Project Celebrates its Third Birthday</a></li>
<li>In 2021, <a href="https://blog.healthchecks.io/2021/07/healthchecks-turns-6-status-update/">Healthchecks Turns 6, Status Update</a></li>
</ul>
<h3>Money</h3>
<p>Healthchecks.io currently has 652 paying customers, and the monthly recurring revenue is 14043 USD. MRR graph:</p>
<figure><img fetchpriority="high" decoding="async" width="1024" height="393" src="https://blog.healthchecks.io/wp-content/uploads/2024/07/mrr-1024x393.png" alt=""></figure>
<p>Side note: to minimize the number of data sub-processors, I am not using revenue analytics services. I used a script and a spreadsheet to make the MRR graph!</p>
<p>I’m happy to see MRR gradually go up, but I’m not optimizing for it. Healthchecks.io is sustainable as-is, and so I’m optimizing for enjoyment and life/work balance.</p>
<p>More stats (user count, check count, pings/day) are available on the <a href="https://healthchecks.io/about/">Healthchecks.io About page</a>.</p>
<h3>Still a one-man business?</h3>
<p>Yes, Healthchecks.io is still a one-man business. Until 2022, I was part-time contracting. Since January 2022 Healthchecks.io has been my only source of income, but I work on it part-time.</p>
<p>At least for the time being I’m not looking to expand the team. A large part of why I’m a “solopreneur” is because I do not want to manage or be managed. A cofounder or employee would mean regular meetings to discuss what’s done, and what’s to be done. It would be awesome to find someone who just magically does great work without needing any attention. Just brief monthly summaries of high-quality contributions, better than I could have done. But I don’t think I can find someone like that, and I also don’t think I could afford them.</p>
<h3>Growth Goals</h3>
<p>I’m not planning to tighten the limits of the free plans. I started Healthchecks in 2015 because I thought the existing services (Dead Man’s Snitch and Cronitor) were overpriced. I started with “I think this can be done better and cheaper”, and I’m sticking with it.</p>
<p>For the same reason, I’m also not planning to raise pricing for paid plans.</p>
<p>I’m choosing not to pursue enterprise customers who ask about PO billing, payments by wire transfer, custom agreements, and signing up to vendor portals. “But you are leaving money on the table!” – yes, it is a conscious decision. In my situation, the extra money will not make a meaningful difference, but the additional burden will make me more busy and grumpy.</p>
<p>Feature-wise, I am happy with the current scope and feature set of Healthchecks. I am <em>not</em> planning to expand the scope and add e.g. active uptime monitoring, hosted status pages, or APM features.</p>
<p>Healthchecks the product is <a href="https://hachyderm.io/@danderson/112766460393943288">hobbit software</a> and Healthchecks.io the business is a lifestyle business.</p>
<h3>Hosting Setup</h3>
<p>The hosting setup is mostly the same as in <a href="https://blog.healthchecks.io/2022/02/healthchecks-io-hosting-setup-2022-edition/">2022</a>. Just a few updates:</p>
<ul>
<li>Web servers upgraded to Hetzner’s AX42 (AMD 8700GE, 8 cores). On the old machines, saw a few nonsensical Python exceptions. A kernel update and a reboot didn’t fix it. Rather than messing with hardware troubleshooting, I upgraded to newer, faster, and more efficient machines.</li>
<li>Database servers upgraded to Hetzner’s EX101 (Intel 13900, 8+16 cores). I was setting up new database replicas after <a href="https://status.healthchecks.io/en/incidents/m7Qv7s8KCsVdMVjGvMbpJb/">an outage and failover event</a> and took the opportunity to upgrade hardware.</li>
<li>Healthchecks.io <a href="https://blog.healthchecks.io/2023/08/notes-on-self-hosted-transactional-email/">now sends its own email using maddy</a>.</li>
<li>Healthchecks.io <a href="https://blog.healthchecks.io/2022/04/we-moved-some-data-to-s3/">now stores ping body data in S3-compatible object storage</a>. This keeps the PostgreSQL database size down but adds reliance on an external service.</li>
</ul>
<p>That’s it for now, thank you for reading! Here’s to another 9 years, and in the closing here’s a complimentary picture of me trying to fit through pull-up bars, and my kids, Nora and Alberts, cheering:</p>
<figure><img decoding="async" width="1024" height="768" src="https://blog.healthchecks.io/wp-content/uploads/2024/07/pull_up_bars-1024x768.jpg" alt=""></figure>
<p>Happy monitoring,<br>Pēteris,<br>Healthchecks.io</p>
</div>
</article>
	</main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to save $13.27 on your SaaS bill (131 pts)]]></title>
            <link>https://dgerrells.com/blog/how-to-save-13-27-on-your-saas-bill</link>
            <guid>41104243</guid>
            <pubDate>Mon, 29 Jul 2024 22:09:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dgerrells.com/blog/how-to-save-13-27-on-your-saas-bill">https://dgerrells.com/blog/how-to-save-13-27-on-your-saas-bill</a>, See on <a href="https://news.ycombinator.com/item?id=41104243">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://dgerrells.com/images/vercelanal.jpg" alt="vercel example analytics dashboard showing great stats"></p>
<p>I decided to try out Vercel's analytics product on a newly minted pro plan, it included some 25k events.</p>
<p>You see, I had to start paying Vercel $ as more than 20 people visited my website. I had been using massive png images on a few high traffic pages which ate up my free outbound data. This is because the default format of taking a snippet on a Mac is a png. It is also because I didn't want to pay Vercel to make all 12 of my website's images go fast. I figured it wouldn't matter. I don't get much traffic.</p>
<blockquote>
<p>Fast forward 4 years.</p>
</blockquote>
<p>Well it did matter. And here I sit looking the fool as I humbly type my CC info into Vercel's payment form. How did I solve the issue? Did I integrate Vercel's images? Did I use an alternative cdn? No, I just converted the 2 worst offenders to jpgs and rewarded myself with another sip of coffee for a job well done. Clearly a decision the past me from four years ago would approve of.</p>
<p>I read Vercel's analytics marketing and pricing pages. 25k events are included with pro and $14 per 100k after. Seems pricey but I can cancel if I use up my quota. All good. Let's implement it.</p>
<p>I have used google, datadog, segment, and a few other client side offerings and came with expectations. It should be easy to implement and Vercel delivered. It took two lines of code since this is an older vercel project that used both the app and page routers.</p>
<pre><code>&lt;Analytics /&gt;
</code></pre>
<p>With a push to production it is live. Nice. I think it took all of 60 seconds. The dashboard view is decent. It has about what I am looking for. Popular urls, total visiters, browsers, country, all good stuff. There is some additional depth I'd like to see but it lives behind a prestigious super pro analytics tier that costs even more. That is ok though. The traffic is barely eating into the 25k quota though so I am happy. Good stuff.</p>
<h2>1 week later</h2>
<p><img src="https://dgerrells.com/images/usagewarningvercel.jpg" alt="vercel warning about too much usage"></p><p>You can guess where this went. No, not a big bill. Only $28. Surely though. Surely!!! There has to be a better way. And no, I am not thinking of the latest trending analytics sAAs vendor nor the resident OSS tool's managed cloud offering from the project's maintainers.</p>
<p>I live on the edge, the edge of the network, the browser, the bleeding edge. Everything must be serverless, multi-region, edge delivered, eventually consistent, strongly typed, ACID compliant, point in time recovery, buzzword buzzword, and buzzword bazzword. In the noise, if one listens closely, an echo can be heard. Old backend engineers from long long ago in the before time whisper of sacrilege. They use words like "htmx", "monolith", and "OOP". Usually I ignore the whispers like we do but one word kept coming up. It stayed with me. Day after day. Month after month. Taunting me. "sqlite".</p>
<p>We have been spoiled by the Vercel's of the world, the heroku's too, and even dare I say, the Salesforces. My infra game is weak. I thought it would be a fun challenge and good practice to try and save a few $ on my Vercy bill by building an analytics api from scratch using a new stack. A stack so bleeding edge that the edge lords have only just now heard of it.</p>
<h2>the squeeh stack</h2>
<p>The Squeeh stack is a new stack I just created 15 seconds ago. What is the Squeeh stack you ask? Well I am glad you asked. Any app which uses sqlite for data counts as a <code>Squeeh Stack</code><span>tm</span>.</p>
<ul>
<li>flask + sqlite + psql? <strong>squeeh stack!</strong></li>
<li>node + sqlite + hono + cloudflare? <strong>squeeh stack!!!</strong></li>
<li>unity + sqlite? <strong>squeeh snack!</strong></li>
<li>swift + tim apple + sqlite? <strong>yup also squeeh stack!</strong></li>
</ul>
<p>Sqlite may be the worst possible option for an analytics service but I keep hearing people saying it is fast. I have never used it though. People on the internet are generally a trustworthy bunch so I am going to trust them and use it. I am going to use bun and hono as the api layer. Bun because it has a delicious looking mascot and Hono because I saw this video where a guy said Hono and it made me laugh. I don't know why. I had never heard of Hono until then.</p>
<p>It didn't take long to get an api setup locally. A simple schema with a <code>db.ts</code> script creates the table. I am skipping migrations and other data best practices. No daily backups, snapshots, point in time recovery. Capturing the data is more important at this point.</p>
<pre><code>app.post(<span>"/analytics"</span>, <span>async</span> (c) =&gt; {
  <span>try</span> {
    <span>const</span> data = <span>await</span> c.req.json();
    insertLog(data);
    <span>return</span> c.json({ message: <span>"Event logged"</span> }, <span>201</span>);
  } <span>catch</span> (error) {
    <span>console</span>.error(<span>"Error logging analytics:"</span>, error);
    <span>return</span> c.json({ error: <span>"Internal Server Error"</span> }, <span>500</span>);
  }
});
</code></pre>
<p>It is time to get a gut check on how much sqlite could handle before continuing. It isn't that I don't trust the internet but you know, better to check now.</p>
<p>Gypity gave a pretty simple load test script using <code>hey</code>. I removed the useless comments and ran it.</p>
<pre><code>URL="http://localhost:3000/analytics"
DURATION="30s"
CONCURRENT_REQUESTS=10
TOTAL_REQUESTS=10000

DATA='{
  "time": "2024-07-23T15:12:20.53Z",
  "status_code": 200,
  "status_text": "OK",
  "host": "example.com",
  "request_path": "/some/path",
  "request_id": "abc123",
  "request_user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
  "level": "Info",
  "environment": "production",
  "location": "New York, USA",
  "ip_address": "203.0.113.1"
}'

hey -m POST -d "$DATA" -H "Content-Type: application/json" -c $CONCURRENT_REQUESTS -n $TOTAL_REQUESTS $URL
</code></pre>
<p>The first test ran fine.</p>
<pre><code>Summary:
  Total:        0.4716 secs
  Slowest:      0.0220 secs
  Fastest:      0.0000 secs
  Average:      0.0005 secs
  Requests/sec: 21204.8583

  Total data:   260000 bytes
  Size/request: 26 bytes
  ---------------------
</code></pre>
<p>I have no idea if that is a good result. Better bump it up to 1m requests and see how it does. I will also start another process running some reads against the same file to see what happens there.</p>
<p>And I get some locks and a few dozen failed requests. Adding the <code>WAL</code> pragma seems to fix the locking issue.</p>
<p><code>db.exec("PRAGMA journal_mode = WAL;");</code></p>
<p>Now that I am thoroughly distracted from the original goal time to fixate on making this number go up. I could buy a more powerful computer but batching the inserts would be cheaper. I wrote a function to do this for me.</p>
<pre><code><span>const</span> insertAnalytics = db.prepare(<span>`
  INSERT INTO analytics (
    data
  ) VALUES (many question marks)
`</span>);

<span>const</span> transact = db.transaction(<span>(<span>logs</span>) =&gt;</span> {
  <span>for</span> (<span>const</span> log <span>of</span> logs) {
    insertAnalytics.run(...orderSpecificLogFields);
  }
  <span>return</span> logs.length;
});
</code></pre>
<p>To gather the events before a batch I kept it stupid simple.</p>
<pre><code><span>let</span> activeLogBuffer: <span>any</span>[] = [];
<span>let</span> isActiveWrite = <span>false</span>;

<span><span>function</span> <span>backgroundPersist</span>(<span></span>) </span>{
  <span>if</span> (activeLogBuffer.length === <span>0</span> || isActiveWrite) <span>return</span>;
  <span>try</span> {
    <span>const</span> tempLogs = activeLogBuffer;
    activeLogBuffer = [];
    isActiveWrite = <span>true</span>;
    <span>const</span> count = transact(tempLogs);
    <span>console</span>.log(<span>`inserted <span>${count}</span> events`</span>);
  } <span>catch</span> (e) {
    <span>console</span>.error(<span>"batch insert error events dropped"</span>, e);
  }
  isActiveWrite = <span>false</span>;
}

<span>setInterval</span>(backgroundPersist, <span>20</span>);

app.post(<span>"/analytics"</span>, <span>async</span> (c) =&gt; {
  <span>try</span> {
    <span>const</span> data = <span>await</span> c.req.json();
    activeLogBuffer.push(data);
    <span>return</span> c.json({ message: <span>"Event logged"</span> }, <span>201</span>);
  } <span>catch</span> (error) {
    <span>console</span>.error(<span>"Error logging analytics:"</span>, error);
    <span>return</span> c.json({ error: <span>"Internal Server Error"</span> }, <span>500</span>);
  }
});
</code></pre>
<p>This is great as I can also return a response before the event persists which will prevent blocking until the write completes. I think it is a great idea to take a cue from frontend land and optimistically return an "Event logged" response even though the event has not yet been logged. Let's load test 100k with a few random read queries in another process.</p>
<pre><code>Summary:
  Total:        2.0621 secs
  Slowest:      0.0093 secs
  Fastest:      0.0000 secs
  Average:      0.0002 secs
  Requests/sec: 48495.3401

  Total data:   2600000 bytes
  Size/request: 26 bytes
</code></pre>
<p>And what about 1m with 20 concurrent requests.</p>
<pre><code>Summary:
  Total:        19.8167 secs
  Slowest:      0.0111 secs
  Fastest:      0.0000 secs
  Average:      0.0004 secs
  Requests/sec: 50462.3789

  Total data:   26000000 bytes
  Size/request: 26 bytes
</code></pre>
<p>There is a pragma to keep the db in-memory but it didn't seem to make a difference. I also read about how I could include more records per prepared statement which should help a bit more. I have been distracted long enough. This works fine.</p>
<p>Time to deploy it.</p>
<h2>how to get kicked off the ocean</h2>
<p>The api service is stupid simple, getting that api inside a docker container was not. I made the rookie mistake of having skill issues with docker. I tried to a get fancy docker compose file going and I did but it took way too long. I picked DigitalOcean for a VPS host and my expectations were high. While it is possible to have a docklet spin up based on an image pulled from a registry when an action is fired like a merge request, it is also involved. It is even more involved to get a zero downtime deployment going without dipping into more complicated orchestration.</p>
<p>I ended up ditching docker and running everything bare metal. I ssh'd into my VPS and got to work dusting off my admin skills. As I made config changes I built a bash script which should do everything needed to spin up the service on a new machine. Install all the dep, configure nginx with lets encrypt, etc. This took me a long time to do. It's not hard, just more skill issues. This made deploying changes much easier down the road.</p>
<p>After confirming I could access the remote api I figured I should load test it. I ran the same script and only hit some 250 req/s. I knew something was off though as the cpu and memory barely moved. I ran it again and it started to just hang. The VPS wasn't doing anything. The bun process was still running with no issues. I thought maybe I didn't provision enough compute so I bumped up to double the ram and a better processor. I ran the load test again and hit 2k req/s before hanging. The cpu and memory ticked up ever so slightly but then dropped down.</p>
<p>It turns out digital ocean blocked my ip. I can no longer directly ssh in. I have to use the console window from digital ocean's dashboard. To confirm this I had a friend run my same load test and he too was blocked from accessing that particular ip. Hilarious and it does work. I don't know how well but nothing like throwing some live traffic at it.</p>
<h2>a poor mans analytics</h2>
<p>The api will sit behind a function on Vercel. There isn't any auth on the endpoint so I'd rather obfuscate it a bit. I am also going to try and include a bit more information and implement some simple session tracking so I can get a better idea of unique users. Ip address could be used but I want something which will be more reliable. Cookies come to mind but I think an id in <code>localstorage</code> is better. This is the schema I needed to populate.</p>
<pre><code>db.exec(<span>`
  CREATE TABLE IF NOT EXISTS analytics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    type TEXT,
    time TEXT,
    status_code INTEGER,
    status_text TEXT,
    host TEXT,
    request_path TEXT,
    request_id TEXT,
    request_user_agent TEXT,
    session_id TEXT,
    os TEXT,
    browser TEXT,
    country TEXT,
    level TEXT,
    environment TEXT,
    location TEXT,
    ip_address TEXT,
    content TEXT,
    referrer TEXT
  )
`</span>);
</code></pre>
<p>Storing a few derived fields from the user agent will make grouping by them much easier. Most of the fields are pretty simple to populate but location/country were trickier. I know that geo information can be included based on ip. To do this you have to setup a local ip lookup db which must be updated every month based on a vendor who kinda has a monopoly in the space. The lookup process can add some overhead. Vercel is suppose to populate the <code>geo</code> field on edge requests. I don't know why but my website doesn't run in the edge runtime. I decided to skip the geo lookup step. I can always add an ip lookup later on and run a backfill.</p>
<p>Here is the Vercel function.</p>
<pre><code><span>import</span> { UAParser } <span>from</span> <span>"ua-parser-js"</span>;

<span>const</span> url = process.env.ANALYTICS_API_URL || <span>"fallback"</span>;

<span>export</span> <span>async</span> <span><span>function</span> <span>POST</span>(<span>req</span>) </span>{
  <span>const</span> data = {
    ...requestData,
    <span>//set other data from headers etc</span>
  };

  <span>try</span> {
    <span>const</span> response = <span>await</span> fetch(url, {
      method: <span>"POST"</span>,
      headers: {
        <span>"Content-Type"</span>: <span>"application/json"</span>,
      },
      body: <span>JSON</span>.stringify(data),
    });

    <span>const</span> result = <span>await</span> response.json();
    <span>return</span> <span>new</span> Response(<span>JSON</span>.stringify(result), {
      status: <span>201</span>,
      headers: {
        <span>"Content-Type"</span>: <span>"application/json"</span>,
      },
    });
  } <span>catch</span> (error) {
    <span>// handle errors</span>
  }
}
</code></pre>
<p>I did want some idea of a country breakdown so I pulled it off the language settings in the browser.</p>
<p>And here is the react hook for that.</p>
<pre><code><span>import</span> { usePathname } <span>from</span> <span>"next/navigation"</span>;
<span>import</span> { useEffect } <span>from</span> <span>"react"</span>;

<span><span>function</span> <span>getSessionId</span>(<span></span>) </span>{
  <span>let</span> sessionId = <span>localStorage</span>.getItem(<span>"sessionId"</span>);
  <span>if</span> (!sessionId) {
    sessionId = <span>`session-<span>${crypto.randomUUID()}</span>`</span>;
    <span>localStorage</span>.setItem(<span>"sessionId"</span>, sessionId);
  }

  <span>return</span> sessionId;
}

<span>export</span> <span>const</span> useAnalytics = <span>() =&gt;</span> {
  <span>const</span> pathname = usePathname();

  useEffect(<span>() =&gt;</span> {
    <span>const</span> logAnalytics = <span>async</span> () =&gt; {
      <span>const</span> country = navigator.language.split(<span>"-"</span>)?.[<span>1</span>] || <span>"Unknown"</span>;
      <span>const</span> data = {
        status_code: <span>200</span>,
        status_text: <span>"OK"</span>,
        request_path: <span>window</span>.location.pathname,
        session_id: getSessionId(),
        referrer: <span>document</span>.referrer,
        <span>type</span>: <span>"page-view"</span>,
        country,
      };

      <span>try</span> {
        <span>await</span> fetch(<span>"/api/analytics"</span>, {
          method: <span>"POST"</span>,
          headers: {
            <span>"Content-Type"</span>: <span>"application/json"</span>,
          },
          body: <span>JSON</span>.stringify(data),
        });
      } <span>catch</span> (error) {
        <span>console</span>.error(<span>"Error logging analytics:"</span>, error);
      }
    };

    logAnalytics();
  }, [pathname]);

  <span>return</span> <span>null</span>;
};
</code></pre>
<p>While this does work and will get the job done. I added support for <code>navigator.sendBeacon</code>, <code>page-leave</code>, and <code>page-return</code> events. It was tricky to get cross browser support since I listen for multiple sources of a "session end" event and didn't want to double count. A <code>useRef</code> can solve this. If <code>navigator.sendBeacon</code> is not supported, a <code>fetch</code> request is used as a fallback.</p>
<pre><code><span>const</span> pathname = usePathname();
<span>const</span> hasFiredExitEventRef = useRef&lt;<span>boolean</span>&gt;(<span>false</span>);

useEffect(<span>() =&gt;</span> {
  logAnalytics(<span>"page-view"</span>);

  <span>const</span> handleVisibilityChange = <span>(<span>e: <span>any</span></span>) =&gt;</span> {
    <span>if</span> (<span>document</span>.visibilityState === <span>"visible"</span>) {
      logAnalytics(<span>"page-return"</span>);
      hasFiredExitEventRef.current = <span>false</span>;
      <span>return</span>;
    }

    <span>if</span> (hasFiredExitEventRef.current) <span>return</span>;

    <span>if</span> (<span>document</span>.visibilityState === <span>"hidden"</span>) {
      logAnalytics(<span>"page-leave"</span>);
      hasFiredExitEventRef.current = <span>true</span>;
      <span>return</span>;
    }

    <span>if</span> (e.type === <span>"pagehide"</span>) {
      logAnalytics(<span>"page-leave"</span>);
      hasFiredExitEventRef.current = <span>true</span>;
    }
  };

  <span>document</span>.addEventListener(<span>"visibilitychange"</span>, handleVisibilityChange);
  <span>window</span>.addEventListener(<span>"pagehide"</span>, handleVisibilityChange);

  <span>return</span> <span>() =&gt;</span> {
    <span>document</span>.removeEventListener(<span>"visibilitychange"</span>, handleVisibilityChange);
    <span>window</span>.removeEventListener(<span>"pagehide"</span>, handleVisibilityChange);
  };
}, [pathname]);
</code></pre>
<p>Naturally this hook must live only on the client so I will perform what I call "client component boxing" a common pattern in the new RSC world.</p>
<pre><code><span>"use client"</span>;
<span>import</span> { useAnalytics } <span>from</span> <span>"./useAnalytics"</span>;

<span>export</span> <span><span>function</span> <span>Analytics</span>(<span></span>) </span>{
  useAnalytics();
  <span>return</span> <span>null</span>;
}
</code></pre>
<p>Tell me this pattern isn't hilarious without it being hilarious. Adding it to the app is as easy as Vercel's so DX is the same.</p>
<pre><code><span>import</span> { Analytics } <span>from</span> <span>"./components/Analytics"</span>;
<span>import</span> { Analytics <span>as</span> VercelStyle } <span>from</span> <span>"@vercel/analytics/react"</span>;

<span>export</span> <span>default</span> <span>async</span> <span><span>function</span> <span>RootLayout</span>(<span>{
  children,
}: {
  children: React.ReactNode;
}</span>) </span>{
  <span>return</span> (
    &lt;html lang=<span>"en"</span>&gt;
      &lt;body&gt;
        {children}
        &lt;Analytics /&gt;
        &lt;VercelStyle /&gt;
      &lt;/body&gt;
    &lt;/html&gt;
  );
}
</code></pre>
<p>Vercel will stay running as I need a baseline to compare against. I almost pushed to main, as is the way, but decided to test it out in a branch instead. Usually everything I write works the first time as is tradition but I had a sneaky suspicion i didn't really know what I was doing. I deployed to a preview branch and started clicking around. I ran a query against the db file on my VPS and it was working. First try? Wow! That uhh...usually doesn't happen.</p>
<p>Rewarding myself with another sip of coffee I pushed it off to production.</p>
<h2>500 is the new green</h2>
<p>The next day I see a wall of red with sprinklings of green. 500s. Streams and streams of them. This is fine. I ssh into the vps and of course the bun process isn't running. There are no spikes in cpu, disk, memory, the service just stopped. But why?</p>
<p>I don't know but the solution was obvious. Find the root cause? No. Add orchestration with self healing hyper nano pods? Closer. It was <code>systemd</code>. I'd love to say I started at <code>systmed</code> but I actually noodled about with some node tooling first. The fact I forgot <code>systemd</code> existed is how I knew it was the right choice. It is even more embarrassing that gypity was the one who suggested it.</p>
<p>I settled on this config file. I updated the setup script to include registering this on the system.</p>
<pre><code>[Unit]
<span>Description</span>=Monolith<span> Server
</span><span>After</span>=network.target

[Service]
<span>ExecStart</span>=/root/.bun/bin/bun /root/squeeh-stack/app/src/index.ts
<span>WorkingDirectory</span>=/root/squeeh-stack/app
<span>StandardOutput</span>=append:/var/log/monolith-server/out.log
<span>StandardError</span>=append:/var/log/monolith-server/err.log
<span>Restart</span>=always
<span>User</span>=notRoot
<span>Environment</span>=NODE_ENV=production
<span>Type</span>=simple
<span>RestartSec</span>=3

[Install]
<span>WantedBy</span>=multi-user.target
</code></pre>
<p>I spun a bit trying to get this to work right. I thought I had a config wrong as the process kept crashing and restarting until it exhausted the default restart count. It turns out the db changed but I forgot to recreate it. Logs are great.</p>
<p>The red 500s are now all green. Overtime you can see when bun crashes and restarts. I am open to ideas on why this happens but my guess is because bun isn't written in rust.</p>
<p><img src="https://dgerrells.com/images/regularservicedeath.jpg" alt="digital ocean droplet chart with reg drops in usage"></p><p>You thought that was funny right? Because bun is written in zig and rust is clearly superior in every way. Well it wasn't bun, it was Hono the whole time. I looked in the <code>systemd</code> logs after a day and noticed that Hono's static router was crashing on some weird uri error.</p>
<pre><code><span>return</span> <span>async</span> (c, next) =&gt; {
<span>if</span> (c.finalized) {
<span>await</span> next (); <span>return</span>;
<span>let</span> filename = options.path ?? <span>decodeURI</span>(c.reg•path) ;
URIError: URI error
stack<span> -&gt;</span>&gt;&gt;
</code></pre>
<p>I don't know why I added a static router but when I removed it, not only did it stop crashing, it decreased the baseline cpu usage significantly. While it would be easy to say, "bad hono, no, that's a bad Hono!". It is possible I was doing something wrong, either way, this chart makes me happy.</p>
<p><img src="https://dgerrells.com/images/badhonobad.jpg" alt="chart showing better perf after fixing hono"></p><p>Ok, time for some analytics.</p>
<h2>analytics 101</h2>
<p>I wrote out the analytics features based on what Vercel has. I figured the bare minimum would be to match what they offer. I added a few more and send it off to gyptiy to write a bash script which would create a markdown file with this info. I wanted it to also email me but I knew I was already pushing it. It wasn't a usable result. Instead, I asked it to give me a js function which returns the query results.</p>
<pre><code>prompt

schema

metrics

unique visitors based on session id<span> group </span>by page, referrer, country, os, <span>and</span> browser
total unique visitors based on session id
total<span> page </span>views
unique visters change trend since last date range<span>
page </span>views change trend since last date range
average time spend on website
bounce rate <span>for</span> top 20 pages.
</code></pre>
<p>It got a little more than half right. A better ratio than the liveliness of my analytics service. I added an endpoint to return some json with metrics I could look at.</p>
<pre><code>app.get(<span>"/analytics/metrics"</span>, <span>async</span> (c) =&gt; {
  <span>try</span> {
    <span>const</span> metrics = <span>await</span> getAnalyticsMetrics(db);
    <span>return</span> c.json(metrics);
  } <span>catch</span> (error) {
    <span>console</span>.error(<span>"Error logging analytics:"</span>, error);
    <span>return</span> c.json({ error: <span>"Internal Server Error"</span> }, <span>500</span>);
  }
});
</code></pre>
<p>And it works.</p>
<p><img src="https://dgerrells.com/images/prettymetrics.jpg" alt="json metrics"></p><p>I keep reeding about how great gypity is at building UI products from the internet. I gave it my analytics json file and it spit out some react charts using <code>rechart</code>. I don't know rechart but the code looked simple enough. I plugged it in to nextjs and get an error I have never seen before.</p>
<p><img src="https://dgerrells.com/images/weirdoldreact.jpg" alt="old react error"></p><p>Research found that it is an error from back in the long ago times of class based react components. And sure enough the <code>rechart</code> library has class components. I "client component boxed" the <code>rechart</code> component and the error went away but the code didn't work either. Looks like rechart doesn't like RSC.</p>
<p>I asked gypity to try again and it picked <code>nivo</code> this time. I have heard of <code>nivo</code> it has pretty charts but I have never used it. Gyptiy wrote well over 1k lines of code for this one. I plugged the code in and got an error I was familiar with.</p>
<p><img src="https://dgerrells.com/images/nextjsclientcontextonly.jpg" alt="nextjs hates context in src"></p><p>It seems a context is used by the charts and RSC don't like those. Clearly <code>nivo</code> is an old and unsuitable library if it doesn't support RSC. I would add the latest <code>shaddy</code> chart library but I don't have tailwind setup. Instead I will drop the charts and opt for a simpler approach. More pure and soulful. Plain old html tables with css frosting.</p>
<p>This is the result.</p>
<p><img src="https://dgerrells.com/images/rigged-up-analytics.jpg" alt="super simple analytics dashboard"></p><p>I hate it but also find it endearing in an ugly duckling kind of way. I do have other data I could display like daily/weekly trends and could allow drilling down to individual sessions.</p>
<p>This is fine for now...</p>
<h3>dashboard round two</h3>
<p>It wasn't fine at all. That dashboard sucked. I changed some styles and flavor a bit and trimmed down superfluous information. I picked apart Vercel's dashboard design beyond the layout for inspiration. It is subtle in how simple it is to use. I like a bit more information thrown in my face personally but it got me thinking.</p>
<p>I tried to use ye'old gyptiy, sonnyte, and <code>v0</code> to make a chart component for me. None were up to the task. Everything either didn't work or looked terrible. No libraries allowed here.</p>
<p>I hacked together a chart component with the following api.</p>
<pre><code>&lt;BoxChart
  title=<span>"Your a wizard harry"</span>
  data={[
    {
      <span>label</span>: <span>"date"</span>,
      <span>value</span>: <span>42</span>,
    },
  ]}
  height={<span>300</span>}
/&gt;
</code></pre>
<p>It is put together with a bunch of divs and some flex box glue. It kinda works on mobile too but needs more polish.</p>
<p>Here is the new dashboard featuring the chart.</p>
<iframe src="https://www.youtube.com/embed/UQuLrQ7Sj_0" frameborder="false" credentialless="true" width="100%" height="430px" sandbox="allow-scripts allow-popups allow-top-navigation-by-user-activation allow-forms allow-same-origin allow-storage-access-by-user-activation allow-popups-to-escape-sandbox"></iframe>
<p>I like it. Here is a chart with live version with some data.</p>
<div><h6>big data energy</h6><div><p>Jul 29 9:20 PM</p><p>Jul 29 6:20 PM</p><p>Jul 29 4:20 PM</p><p>Jul 29 1:20 PM</p><p>Jul 29 10:20 AM</p><p>Jul 29 7:20 AM</p><p>Jul 29 5:20 AM</p><p>Jul 29 2:20 AM</p></div></div>
<p>With that out of the way it is time to look at the baseline.</p>
<h2>squeeh-stack vs Vercel</h2>
<p>The data when compared to Vercel is a pretty close match. My analytics seem to over count a bit compared to Vercel which could be how uniqueness is determined. I also don't filter out testing nor bot data. I did notice that Vercel's tracking gets blocked by default even with shields down on Brave where as mine is not. The data analytics people may bulk at the potential of over counting here but I just consider it a feature. Nothing helps juice up a company's valuation like inflated metrics.</p>
<p>Looking at language seems to give a good baseline when compared to Vercel's analytics which uses the ip. It is pretty close to accurate although someone in Dublin will show up as GB. I did find out that Vercel does populate the geo info. Some docs said to look at the <code>geo</code> object on the request where as in reality it is in a header.</p>
<pre><code><span>const</span> country = headers.get(<span>"x-vercel-ip-country"</span>) || <span>"Unknown"</span>;
<span>const</span> city = headers.get(<span>"x-vercel-ip-city"</span>) || <span>"Unknown"</span>;
<span>const</span> location = <span>`<span>${country}</span>, <span>${city}</span>`</span>;
</code></pre>
<p>With the current traffic this would run fine on a $6/m VPS. Data is enough to cover well over 100m events maybe even a billion depending on sqlite. I can add volumes for data backup for a few bucks more depending on size. I left the VPS over provisioned at a higher tier and came out to a $13.27 savings compared to my current Vercel Analytics spend. It took about 2 days to build this and reap those sweet sweet savings. CPU/Memory/etc is low. When load testing bun peaked at around 50mb. Pretty fat when compared to others but still significantly cheaper.</p>
<p>There is freedom to add additional analytics and queries since I have direct access to the service and data. For example I am able to get a bounce rate approximation. With a little more work I can get an average visit duration among others. I imagine Vercel has more features but behind a higher paywall.</p>
<p>An engineer who doesn't suffer from infra skill issues could spin up a much more robust and stable analytics service in a fraction of the time. However, for each additional "robustness" feature added, the cost and complexity will go up too. If I wanted zero downtime deployments, that means orchestration with additional provisioning. If I wanted data guarantees, that'd add even more.</p>
<p>I am going to keep running this along side Vercel to see how it does and will iterate on it overtime. Who knows, maybe I'll spin up a sAAs product which is nothing more than a droplet wrapper with a sqlite database slapped in. I better slap AI in the domain to make sure people know I mean business.</p>
<p>shush, I know of <a href="https://turso.tech/">turso</a>. They look amazing.</p>
<h2>fin.</h2>
<p>This was fun and outside my comfort zone. I want to do more to see what a squeeh stack can handle. I have ideas.</p>
<p>Cheers!</p>
<p><span><p>One final note. I know that Vercel is wrapping Tinybird behind the scenes.
Just imagine replacing all usages of "Vercel" with Tinybird.</p></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CrowdStrike's impact on aviation (295 pts)]]></title>
            <link>https://heavymeta.org/2024/07/28/crowdstrikes-impact-on-aviation.html</link>
            <guid>41103101</guid>
            <pubDate>Mon, 29 Jul 2024 19:41:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://heavymeta.org/2024/07/28/crowdstrikes-impact-on-aviation.html">https://heavymeta.org/2024/07/28/crowdstrikes-impact-on-aviation.html</a>, See on <a href="https://news.ycombinator.com/item?id=41103101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Just after midnight Eastern Time on July 19, 2024, the enterprise cybersecurity
company CrowdStrike YOLOed a software update to millions of Windows machines. Or
as they put it:</p>

<blockquote>
  <p>On July 19, 2024 at 04:09 UTC, as part of ongoing operations, CrowdStrike
released a sensor configuration update to Windows systems.</p>
</blockquote>

<p>That sensor configuration update caused the largest IT outage in history.</p>

<p><a href="https://twitter.com/Pinboard/status/1814361862890307692"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/pinboard-largest-it-outage-so-far-s.webp 1x,                     https://heavymeta.org/images/pinboard-largest-it-outage-so-far.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/pinboard-largest-it-outage-so-far.webp 1x,                     https://heavymeta.org/images/pinboard-largest-it-outage-so-far.webp 2x">
    <img src="https://heavymeta.org/images/pinboard-largest-it-outage-so-far-s.webp" alt="Screenshot of a @pinboard tweet: 'Largest IT outage in history *so far*!'">
  </picture></a></p>

<p>Overnight, about <a href="https://www.bbc.com/news/articles/cpe3zgznwjno">8.5 million
computers</a> blue screened,
affecting hospitals, banks, 911 systems–as the New York Times put it, “It is
more apt to ask what was not affected.” The answer is Linux, Macs, and phones.</p>

<p>The outage highlighted a different kind of digital divide. On one side, gmail,
Facebook, and Twitter kept running, letting us post photos of blue screens
located on the other side: the Windows machines responsible for actually doing
things in the world like making appointments, opening accounts, and dispatching
police.</p>

<p>They also run airlines.</p>

<p>Here’s a visualization of the chaos that CrowdStrike caused for airlines from
the <a href="https://www.nytimes.com/2024/07/19/technology/microsoft-crowdstrike-outage-what-happened.html">New York
Times</a>:</p>

<p><a href="https://heavymeta.org/images/nytimes-crowdstrike-airport-delays.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/nytimes-crowdstrike-airport-delays-s.webp 1x,                     https://heavymeta.org/images/nytimes-crowdstrike-airport-delays.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/nytimes-crowdstrike-airport-delays.webp 1x,                     https://heavymeta.org/images/nytimes-crowdstrike-airport-delays.webp 2x">
    <img src="https://heavymeta.org/images/nytimes-crowdstrike-airport-delays-s.webp" alt="Chart from the New York Times: How the airlines cancellations rippled around the world (and across time zones). Share of canceled flights at 25 airports on Friday">
  </picture></a></p>

<p>Airline cancellations is a good metric, but I want to look directly at air
traffic: How many planes were in the air? How many planes should have been in
the air?</p>

<p>At about noon UTC, 8 hours after the CrowdStrike update hit, someone posted a
video to Twitter that they made with FlightRadar24 showing air traffic over the
United States. It was described as a 12-hour timelapse of American Airlines,
Delta, and United plane traffic that showed the nationwide ground stop of the
three airlines due to CrowdStrike.</p>

<p>Here’s the video:</p>

<video controls="">
  <source src="https://heavymeta.org/images/fr24-20240718.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

<p>It’s not a good visualization of the impact because there’s no basis for
comparison. It clearly shows fewer planes flying at night, but that happens
every day. Was that night different from any other night? There’s no way to
tell. In Bellingcat’s <a href="https://www.bellingcat.com/resources/2024/04/25/oshit-seven-deadly-sins-of-bad-open-source-research/">“OSHIT: Seven Deadly Sins of Bad Open Source
Research”</a>,
sin #4 is “Lacking Context for Occurrences, Common or Otherwise”. In this post
I’ll show the effects CrowdStrike had on air traffic, with enough context to
make the significance clear.</p>

<h2 id="impact-on-us-aviation">Impact on U.S. Aviation</h2>

<p>CrowdStrike hit on July 19. This chart shows the number of aircraft that took
off in the United States, hour by hour, on that day. It also shows the same
numbers for July 12, the previous Friday. The same day one week previously seems
to be a good basis for comparison–both days are Fridays, and there aren’t any
major holidays on either day. I also plotted the stats for July 18, the day
before CrowdStrike, but it was very similar so I’ll continue to compare to the
previous week.</p>

<p>Note that the chart is for all of aviation in the United States, including fire
fighting aircraft, police, military, and general aviation as well as commercial
aviation.</p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-all.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-all-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-all.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-all.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-all.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-all-s.webp" alt="CrowdStrike US all flights chart">
  </picture></a></p>

<p>From about 0600 to 1300 there seems to have been a small decrease in the number
of flights, and then a small increase in the rest of the day. Looking at the
cumulative statistics starting from 0400, when the CrowdStrike update was
pushed, flights were up 2.6% compared to the same period on the previous Friday.</p>

<p>This chart shows the percentage change in flights, comparing each hour on July
19 to the matching hour of the previous Friday as the baseline:</p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-all-pct.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-all-pct-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-all-pct.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-all-pct.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-all-pct.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-all-pct-s.webp" alt="CrowdStrike US all flights percent change chart">
  </picture></a></p>

<p>This chart brings CrowdStrike’s effects into greater relief. The hour with the
largest percent decrease was from 0800 to 0900, which had only 261 flights
compared to the previous Friday’s 378 flights, a 31% reduction.</p>

<h2 id="airline-statistics">Airline Statistics</h2>

<p>Now let’s look at the statistics for the top 4 U.S. airlines: Delta, United,
American, and Southwest.</p>

<h3 id="delta-air-lines">Delta Air Lines</h3>

<p>Change during CrowdStrike: -1087 flights (-46%)</p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-dal.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-dal-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-dal.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-dal.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-dal.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-dal-s.webp" alt="CrowdStrike US DAL chart">
  </picture></a></p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-dal-pct.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-dal-pct-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-dal-pct.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-dal-pct.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-dal-pct.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-dal-pct-s.webp" alt="CrowdStrike US DAL percent chart"></picture></a></p>

<h3 id="united-airlines">United Airlines</h3>

<p>Change during CrowdStrike: -596 flights (-36%)</p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-ual.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-ual-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-ual.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-ual.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-ual.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-ual-s.webp" alt="CrowdStrike US UAL chart">
  </picture></a></p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-ual-pct.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-ual-pct-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-ual-pct.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-ual-pct.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-ual-pct.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-ual-pct-s.webp" alt="CrowdStrike US UAL percent chart">
  </picture></a></p>

<h3 id="american-airlines">American Airlines</h3>

<p>Change during CrowdStrike: -376 flights (-16%)</p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-aal.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-aal-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-aal.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-aal.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-aal.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-aal-s.webp" alt="CrowdStrike US AAL chart">
  </picture></a></p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-aal-pct.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-aal-pct-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-aal-pct.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-aal-pct.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-aal-pct.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-aal-pct-s.webp" alt="CrowdStrike US AAL percent chart"></picture></a></p>

<h3 id="southwest-airlines">Southwest Airlines</h3>

<p>Change during CrowdStrike: +101 flights (+3%)</p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-swa.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-swa-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-swa.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-swa.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-swa.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-swa-s.webp" alt="CrowdStrike US SWA chart">
  </picture></a></p>

<p><a href="https://heavymeta.org/images/crowdstrike-us-swa-pct.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-swa-pct-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-swa-pct.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-swa-pct.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-swa-pct.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-swa-pct-s.webp" alt="CrowdStrike US SWA percent chart">
  </picture></a></p>

<h3 id="airlines-summary">Airlines Summary</h3>

<p>Delta was hardest hit, then United, and to a significantly smaller degree
American. Southwest didn’t seem to be affected at all.</p>

<!-- [![foo](/images/crowdstrike-us-airlines-pct-chg-s.webp)](/images/crowdstrike-us-airlines-pct-chg.webp) -->

<p><a href="https://heavymeta.org/images/crowdstrike-us-airlines-pct-chg.webp"><picture>
    <source media="(max-width: 640px)" srcset="https://heavymeta.org/images/crowdstrike-us-airlines-pct-chg-s.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-airlines-pct-chg.webp 2x">
    <source media="(min-width: 641px)" srcset="https://heavymeta.org/images/crowdstrike-us-airlines-pct-chg.webp 1x,                     https://heavymeta.org/images/crowdstrike-us-airlines-pct-chg.webp 2x">
    <img src="https://heavymeta.org/images/crowdstrike-us-airlines-pct-chg-s.webp" alt="CrowdStrike US airlines percent change chart">
  </picture></a></p>

<p>Apparently <a href="https://www.techradar.com/pro/security/southwest-airlines-avoided-crowdstrike-microsoft-outage-because-its-still-running-windows-31-fourth-largest-us-airline-remained-free-of-bsod-errors-because-its-os-hasnt-been-updated-in-decades">Southwest Airlines’ ingenious strategy of never upgrading from
Windows
3.1</a>
allowed it to remain unscathed. <a href="https://www.osnews.com/story/140301/no-southwest-airlines-is-not-still-using-windows-3-1/">This seems to be
false</a>,
BTW. <a href="https://abcnews.go.com/Travel/wireStory/airlines-except-recovering-crowdstrike-tech-outage-feds-noticed-112167272">This ABC News
article</a>
says that Southwest wasn’t affected because they don’t use CrowdStrike.]</p>

<p>Delta Air Lines took an extended time to recover, canceling thousands of flights
in the days following the CrowdStrike update. Why were other airlines able to
get back to normal so much faster than Delta? A <a href="https://abcnews.go.com/Business/delta-days-restore-normal-service-after-crowdstrike-outage/story?id=112299966">terrible article from ABC
News</a>
said this:</p>

<blockquote>
  <p>The reason for the prolonged recovery from the outage was because the
CrowdStrike update disruption required a manual fix at each individual
computer system, experts told ABC News. While each fix can be completed in no
more than 10 minutes, the vast number of Delta’s digital terminals required
significant manpower to address, expert said.</p>
</blockquote>

<p>I’m reminded of sin #4 again–How is this different from any other airline? ABC
News has no idea. A <a href="https://www.reddit.com/r/delta/comments/1edtfbh/comment/lf9konn/">random redditor gave an unsourced
explanation</a>
that might be wrong but at least attempts to answer the question “Why Delta so
bad?” (DR = disaster recovery):</p>

<blockquote>
  <p>These “experts” are completely wrong. The core issue was Delta did NOT have a
proper DR plan ready and did NOT have a proper IT business continuity plan
ready. UA, AA, and F9 recovered so fast because they had plans on stand-by and
engaged them immediately. After the SWA IT problem, UA and AA put in robust DR
plans staged everywhere from the server farms, to cloud solutions, to end-user
stations at airports. They had plans on how to recover systems. DL outsources
a lot of their IT. UA and AA engaged those plans quickly. They did not hold
back paying OT for staff. UA and AA have just as much reliance on Windows as
Delta. AA was recovered by end of data Friday and resumed normal operations
Saturday. UA was about 12 hours behind them having it resolved by Saturday
morning resuming normal schedules Saturday afternoon. The ONUS is 100% on DL
C+ level in their IT decisions.</p>
</blockquote>

<h2 id="data-and-analysis">Data and Analysis</h2>

<p>I took raw ADS-B data from <a href="https://adsbexchange.com/">ADS-B Exchange</a> and
processed it through my custom code to detect aircraft takeoffs. I’m assuming
that a takeoff is roughly equivalent to a flight, which isn’t actually true but
is close enough for these purposes. It tends to undercount the number of
aircraft flying, e.g. in the case where an aircraft took off from a field
outside of ADS-B Exchange’s coverage, but it does so in a systematic way that
still allows for valid comparisons between time periods. That is, the absolute
numbers of flights may be too low, but the percent changes in numbers are
accurate.</p>

<p>I counted takeoffs instead of counting flying aircraft because I already had
code to detect takeoffs and didn’t want to write new code–this was just a quick
weekend project.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Attribution is dying, clicks are dying (203 pts)]]></title>
            <link>https://sparktoro.com/blog/attribution-is-dying-clicks-are-dying-marketing-is-going-back-to-the-20th-century/</link>
            <guid>41101948</guid>
            <pubDate>Mon, 29 Jul 2024 17:09:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sparktoro.com/blog/attribution-is-dying-clicks-are-dying-marketing-is-going-back-to-the-20th-century/">https://sparktoro.com/blog/attribution-is-dying-clicks-are-dying-marketing-is-going-back-to-the-20th-century/</a>, See on <a href="https://news.ycombinator.com/item?id=41101948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Welcome to another edition of 5-Minute Whiteboards. And folks, we’ve got a doozy of a topic. Yes, I’m being intentionally provocative. But it’s because things really have changed in the last decade, yet too many of us are still asked to invest in marketing as though it’s 2014.</p>
<p>In just seven minutes, I’m going to try to change your mind about how marketing works in 2024 (and doesn’t), and the hard conversation we need to have with the C-suite, clients, team members, and those who believe every sale can be perfectly attributed to all the marketing channels and tactics that contributed. I’m also trying out a “digital” whiteboard format that’s likely to be my go to for the next few episodes (it’s easier to read, and the graphics can be embedded/shared with less friction). Let me know what you think of this format in the comments 😉</p>

<h2>The Way We’ve Done Digital Marketing for 20 Years is Ending</h2>
<p>Well, marketing friends, we gotta have a serious talk. Because the way we’ve done marketing for the last twenty years is ending. I’m serious. I believe that Rand in 2010 would have told you that digital marketing was all about being able to track every view and every click, so that when conversions happened, we could perfectly attribute them, is wrong today. Back then, we could say: <em>“Oh, this piece of content, this advertisement, this PR investment, this word-of-mouth effort is worthwhile because it turned into this trackable, perfectly attributable series of events in our analytics.”</em></p>
<p>It doesn’t work this way anymore.</p>
<p>That’s because clicks are dying and attribution is dying. There’s only one way forward.</p>
<h2>What’s Killing Clicks?</h2>
<p>“Tell me, Rand, what killed all these clicks?”</p>
<p>I’m going to tell you every one of the major search, social, and content platforms has an incentive to keep you there. LinkedIn wants to keep you on LinkedIn. Twitter wants to keep you on Twitter.</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2022\/07\/zero-click-content-chart-pink-1024x731.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-large is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:null,&quot;imgStyles&quot;:&quot;width:700px&quot;,&quot;targetWidth&quot;:&quot;none&quot;,&quot;targetHeight&quot;:&quot;none&quot;,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2022/07/zero-click-content-chart-pink-1024x731.png" alt=""></figure></div>
<p>So does Facebook, so does Reddit, so does YouTube, so does Instagram, so does TikTok, every one of these. So, they all bias to algorithms that penalize links and reward native content—zero-click content.</p>
<h2>What’s Killing Attribution?</h2>
<p>Attribution was killed by a variety of things: Apple’s cookie changes absolutely had a big effect when they pulled back on third party cookies inside safari that took a huge hit. Anti tracking and privacy laws in California, Canada, New York, and the EU, and many of those cookie permissions and do-not-track protocols have rolled out globally.</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2024\/07\/what-killed-attribution.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-9185&quot;,&quot;imgStyles&quot;:&quot;width:600px&quot;,&quot;targetWidth&quot;:800,&quot;targetHeight&quot;:801,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img fetchpriority="high" decoding="async" width="800" height="801" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/what-killed-attribution.png" alt="" srcset="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/what-killed-attribution.png 800w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/what-killed-attribution-300x300.png 300w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/what-killed-attribution-150x150.png 150w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/what-killed-attribution-768x769.png 768w" sizes="(max-width: 800px) 100vw, 800px"></figure></div>
<p>Then there’s the massive adoption of ad blockers. We’re talking about <a href="https://www.ghostery.com/blog/privacy-report-advertisers-and-adblockers">a third to half of all Internet users using an ad blocker</a> on one or more of their devices. And and ad blockers don’t just block ads, they block all of the tracking that we do as well.</p>
<p>Multi device journeys mean that tracking someone, even with fancy browser fingerprinting (illegal in many parts of the world, but still technically allowed in the US), is rendered impossible unless they log in with the same credentials on all those devices.</p>
<p>The adoption of mobile and tablet devices, and the domination of apps that happen inside of them further hides attribution data. All of that in-app activity, those hours that people spend inside their apps on their phone/tablet cannot be perfectly attributed back to the same visits that they make on the web except when it is through the same ad/login tracking system. That means only a few big companies (mostly Google, Apple, and Meta) have access to that data.</p>
<p>And then there’s the zero click problem.</p>
<p>As an Internet user, I don’t click on things the way I used to. You don’t click on things. We, as a collective Internet, stopped clicking. Part of that was the platforms training us not to click. And part of that is our own predilection for consuming content in native formats on apps and websites.</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2023\/04\/dark-traffic-major-social-networks-1024x635.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-large is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:null,&quot;imgStyles&quot;:&quot;width:750px&quot;,&quot;targetWidth&quot;:&quot;none&quot;,&quot;targetHeight&quot;:&quot;none&quot;,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2023/04/dark-traffic-major-social-networks-1024x635.png" alt=""></figure></div>
<p>Last, but not least, there’s dark traffic. We studied this in-depth at SparkToro last year, noting that <a href="https://sparktoro.com/blog/new-research-dark-social-falsely-attributes-significant-percentages-of-web-traffic-as-direct/">more than half of the major social networks hide some or all</a> of their referral data.</p>
<h2>Show Me the Receipts</h2>
<p>We have the data to back up these assertions about the decline of both clicks and attribution. This isn’t just conjecture. I can prove it to you. We did a study in January of this year with Datos looking at <a href="https://sparktoro.com/blog/who-sends-traffic-on-the-web-and-how-much-new-research-from-datos-sparktoro/">who sends traffic on the web</a>, and it is overwhelmingly search.</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2024\/03\/Datos-SparkToro-Referral-Study-Share-2024-1024x818.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-large is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:null,&quot;imgStyles&quot;:&quot;width:800px&quot;,&quot;targetWidth&quot;:&quot;none&quot;,&quot;targetHeight&quot;:&quot;none&quot;,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2024/03/Datos-SparkToro-Referral-Study-Share-2024-1024x818.png" alt=""></figure></div>
<p>Google, Microsoft/Bing, and DuckDuckGo account for ~70% of all traffic referrals, every click that’s sent out. But, where people are spending time is NOT 70% search. That is not where 70% of visits go.</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2024\/03\/Share-of-Visits-to-Categories-Datos-Jan-2023-24.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-large is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:null,&quot;imgStyles&quot;:&quot;width:800px&quot;,&quot;targetWidth&quot;:&quot;none&quot;,&quot;targetHeight&quot;:&quot;none&quot;,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2024/03/Share-of-Visits-to-Categories-Datos-Jan-2023-24.png" alt=""></figure></div>
<p>In fact, search is only ~10% of all visits (and yes that includes AI search players like Perplexity). Ten percent. We spend time in social and productivity tools like our email, on news websites, buying things in e-commerce, on video and audio platforms.</p>
<p>If you try to prove acquisition via traffic referral data you will become Google’s fool. Here’s why: Everything we consume in social, news, productivity (like our emails), video and audio (YouTube and podcasts), and specific sectors like financial sites, travel sits, health sites, etc. leads us to potential searches. It exposes us to ideas, brands, problems… things we need to research.</p>
<p>If see something about a brand of risotto on a recipe website that looks interesting, it’s rare that I directly have a link to click. And often if I do, I still don’t bother! Because I’m used to zero-click consumption. Instead, later on, I might search in Google for that type of risotto.</p>
<p>When I go to Google and search… who gets the credit?</p>
<p>Google does. </p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2024\/07\/acquisition-via-referral-will-make-you-googles-fool.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-9187&quot;,&quot;imgStyles&quot;:&quot;width:800px&quot;,&quot;targetWidth&quot;:917,&quot;targetHeight&quot;:915,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" width="917" height="915" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquisition-via-referral-will-make-you-googles-fool.png" alt="" srcset="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquisition-via-referral-will-make-you-googles-fool.png 917w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquisition-via-referral-will-make-you-googles-fool-300x300.png 300w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquisition-via-referral-will-make-you-googles-fool-150x150.png 150w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquisition-via-referral-will-make-you-googles-fool-768x766.png 768w" sizes="(max-width: 917px) 100vw, 917px"></figure></div>
<h2>What’s the Solution to the Zero-Click, Impossible-to-Attribute World of Marketing in 2024?</h2>
<p>The way forward is to go where your audience is being influenced.</p>
<p>For example, let’s say I want to find the best rice for making risotto. I might search Google to solve that problem. But I might also watch videos on TikTok or Instagram. I could turn to my favorite recipe blog. I might ask the chefs at my favorite Italian restaurant.</p>
<p>Millions of people make risotto around the world every week. But, only 0.1% of them are searching Google for “best rice to make risotto.” If we wanna know how to influence those millions of people, we need to uncover ALL the sources that influence them. We need to know all the ways they’re nudged to buy one particular brand or kind of rice or another. We want the websites risotto searchers visit. We wanna know the social networks and social accounts that they use and follow. We want to know the podcasts and the Youtube channels and the subreddits that they visit.</p>
<p>Even if we’re exclusively thinking about a Google search for the “best rice for risotto,” I worry. I worry that an old school SEO looks at the potential click through rate and says this isn’t a keyword worth targeting.</p>
<p>Right? It’s not worth ranking for because Google’s showing an instant answer. There’s no clicks. But, there is a behavior-biasing result.</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2024\/07\/go-where-audience-is.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-large&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-9189&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1400,&quot;targetHeight&quot;:692,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="506" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/go-where-audience-is-1024x506.png" alt="" srcset="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/go-where-audience-is-1024x506.png 1024w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/go-where-audience-is-300x148.png 300w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/go-where-audience-is-768x380.png 768w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/go-where-audience-is.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>
<p>If you’rein the grocery store and search for “best kind of rice for risotto,” you’re probably going to buy arborio. Because Google’s big, bold answer at the top of the search result is Arborio. (Guess what: as an avid maker of risotto, and someone who’s been perfecting the dish for years, I can promise you that arborio is not the best kind of rice for risotto. You should be buying Carnaroli if you can).</p>
<p>The problem with doing marketing work to change this result and nudge Google to show Carnaroli (or even better, your particular brand of Carnaroli) is that even if you succeed, it lacks attribution. You can’t prove to your boss that by taking over that ranking you’ve provided any value to the company. Because not only are most of the searches going to end without a click, even those that DO send traffic won’t tell you what keyword referred them. Google killed that ability to see keyword data almost ten years ago.</p>
<h2>Success Comes By Reaching People Through the Right Sources of Influence</h2>
<p>There’s a brand of aged carnaroli rice, which which is excellent for risotto, and highly regarded by professional chefs and home cooks, too. It’s what I almost always use, and over the last few years, I’m obsessed with this stuff. It’s called <a href="https://acquerello.it/eng/">Acquerello</a>.</p>
<p>Acquerello was virtually unknown in the United States ten years ago. But in the last decade, they’ve massively grown their US sales by investing in tactics that cannot be perfectly attributed, no matter how sophisticated the AI-powered, econometrics/MMM software you’re using might be.</p>
<p>Acquerello recognized that to get into the major US publications, they needed an affiliate program, so they started selling through Amazon (even though it wasn’t a great brand positioning match). Then their PR team pitched folks like the editors at Bon Appetit (below).</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/images.sparktoro.com\/blog\/wp-content\/uploads\/2024\/07\/acquerello-for-risotto.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-9190&quot;,&quot;imgStyles&quot;:&quot;width:700px&quot;,&quot;targetWidth&quot;:917,&quot;targetHeight&quot;:917,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="917" height="917" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquerello-for-risotto.png" alt="" srcset="https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquerello-for-risotto.png 917w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquerello-for-risotto-300x300.png 300w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquerello-for-risotto-150x150.png 150w, https://images.sparktoro.com/blog/wp-content/uploads/2024/07/acquerello-for-risotto-768x768.png 768w" sizes="(max-width: 917px) 100vw, 917px"></figure></div>
<p>Acquerello started nudging chefs all over Italy, where tourists often experienced great risotto for the first time, to include their brand name on their menus, and put their rice packaging on visible shelves in the restaurants. They started a huge word-of-mouth campaign with Italian restaurants and chefs in major US cities. They sponsored events in other European and North American countries. They worked with specialty retailers in the US to carry their product. They expanded their online sales distribution.</p>
<p>Every one of these things positively contributed to Acquerello’s success. But, almost none of them can be attributed to a particular sale. Tragically, most of the very smart, savvy, sophisticated American tech CEOs and CFOs I know, who grew up on attribution models to direct their spend, would veto every single thing Acquerello did because they couldn’t PROVE that it led to increased sales.</p>
<p><em>“Correlation, not causation means we might be throwing our money away,”</em> they’d say.</p>
<p>What I’m suggesting to you is that digital marketing in 2024 is a lot like marketing in 1964. It is getting the right message that appeals to the right people in the right places and at the right time to the right audience.</p>
<p>And I’m urging you to invest in it and to optimize for it using <a href="https://sparktoro.com/blog/how-to-measure-hard-to-measure-marketing-channels/">lift-based measurement and not attribution</a>.</p>
<p>Because attribution fundamentally don’t work anymore. When you make marketing investments based, instead, on knowing who your audience is and where/how you can influence them, you can massively improve your results.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do Penguins Have Knees? (2019) (106 pts)]]></title>
            <link>https://www.penguinsinternational.org/do-penguins-have-knees-and-other-frequently-asked-questions/</link>
            <guid>41101502</guid>
            <pubDate>Mon, 29 Jul 2024 16:10:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.penguinsinternational.org/do-penguins-have-knees-and-other-frequently-asked-questions/">https://www.penguinsinternational.org/do-penguins-have-knees-and-other-frequently-asked-questions/</a>, See on <a href="https://news.ycombinator.com/item?id=41101502">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
<article id="post-2500">
<div data-hide-featured-media="1">
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0" id="fws_66a8328a72d1b" data-column-margin="default" data-midnight="dark">
<div>
<p>
<h2><strong>Do Penguins Have Knees?…and other frequently asked questions</strong></h2>
</p>
</div>
<div>
<p><span>by Autumn L. Syracuse, Educator I</span></p>
</div>
</div>
<div id="fws_66a8328a7358a" data-column-margin="default" data-midnight="dark">
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0">
<p><span>“Do penguins have knees?” and “So what is a penguin?” are two of the most common questions I hear regarding our penguin colony on display at the Aquarium of Niagara (</span><a href="http://www.aquariumofniagara.org/" target="_blank" rel="noopener"><span>www.aquariumofniagara.org</span></a><span>). Before we talk about penguin anatomy, let’s discuss what a penguin is exactly, first. It’s hard to imagine that these chunky bipeds that don’t fly — but swim — are indeed birds. Ostriches, emus, and rheas are pretty easy to identify as birds with their fluffy plumage of feathers. So why does it seem odd to include penguins in this group of flightless birds? Are all birds descended from one common ancestor? </span></p>
<p><span>Birds are: warm-blooded, air breathing, egg-laying, covered in feathers, and possess a bill. Now let’s take a look at penguins: They check all the boxes! “But </span><i><span>why</span></i><span> are they birds? They are so funny looking!” Although outwardly different from most other birds, penguins still possess many characteristics of other avian species. Let’s get down to the </span><i><span>bones</span></i><span> of it. </span></p>
</div>
<div data-max-width="100%" data-max-width-mobile="default" data-shadow="none" data-animation="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-delay="0">
<p><img fetchpriority="high" decoding="async" data-delay="0" height="350" width="520" data-animation="none" data-nectar-img-src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1.jpg" src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1.jpg" alt="Penguin knees" data-nectar-img-srcset="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1.jpg 520w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1-300x202.jpg 300w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1-400x269.jpg 400w" sizes="(max-width: 520px) 100vw, 520px" srcset="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1.jpg 520w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1-300x202.jpg 300w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen1-400x269.jpg 400w">
</p>
</div>
</div>
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0" id="fws_66a8328a740b0" data-column-margin="default" data-midnight="dark">
<h2><b>Okay, so do penguins have knees?</b></h2>
<p><span>A penguin’s skeletal structure is laid out in the same general pattern as other birds. One obvious characteristic of a bird skeleton is the keel, or sternum. This is designed to be very wide and flat, but lays perpendicular to the ribs. This large bone helps to attach the flight muscles and tendons, which is very important in both form and function to flight. And since penguins “fly” through the water, which is denser, they too need to rely on the keel and flight muscles for propulsion.&nbsp;</span></p>
<p><span>Another important adaptation that varies from other flighted (volant) birds is the density of their bones. Most birds we see flying in our yards and neighborhoods have skeletons with bones that are hollow. This creates a skeleton that is extremely lightweight, allowing the birds to be able to lift off into flight. Penguins would not benefit from bones of this same density. Penguins need to be able to dive underwater to hunt for their fish, and hollow bones would make them too buoyant. To help with this, penguin bones are solid and heavy, helping to give them more weight in order to dive deep.</span></p>
</div>
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0" id="fws_66a8328a743a8" data-column-margin="default" data-midnight="dark">
<h2><b>Penguin knees are tucked up inside their body</b></h2>
<p><span>Penguins are designed to be streamlined and hydrodynamic, so having long legs would add extra drag. Having short legs with webbed feet to act like rudders, helps to give them that torpedo-like figure. If we compare bird anatomy with humans, we would see something a bit peculiar. By taking a look at the side-by-side image in Figure 1, you can see how their leg bones compare to ours. What most people mistake for knees are actually the ankles of the birds. This gives the illusion that bird knees bend opposite of ours. The knees are actually tucked up inside the body cavity of the bird! So how does this look inside of a penguin? In the images below, you can see boxes surrounding the penguins’ knees.&nbsp;</span></p>
</div>
<div id="fws_66a8328a7463a" data-column-margin="default" data-midnight="dark">
<div data-max-width="100%" data-max-width-mobile="default" data-shadow="none" data-animation="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-delay="0">
<p><img decoding="async" data-delay="0" height="419" width="512" data-animation="none" data-nectar-img-src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen2.jpg" src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen2.jpg" alt="Penguin knees" data-nectar-img-srcset="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen2.jpg 512w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen2-300x246.jpg 300w" sizes="(max-width: 512px) 100vw, 512px" srcset="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen2.jpg 512w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen2-300x246.jpg 300w">
</p>
</div>
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0">
<div data-max-width="100%" data-max-width-mobile="default" data-shadow="none" data-animation="none">
<p><img decoding="async" data-delay="0" height="295" width="242" data-animation="none" data-nectar-img-src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen3.png" src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen3.png" alt="Penguin knees">
</p>
</div>
<div>
<p>
<h5><b>Colored boxes highlighting the location of penguin </b><b>knees.https://www.neaq.org/blog/do-penguins-have-knees/</b></h5>
</p>
</div>
</div>
</div>
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0" id="fws_66a8328a75445" data-column-margin="default" data-midnight="dark">
<p><span>Imagine yourself wearing an oversized shirt, and pulling it over your knees so that only your ankles and feet are showing. Now imagine you’re trying to walk forward in this position. I bet you’d waddle too! This design gives the penguin an advantage in the water to help them swim quickly to catch food or avoid predators. On land, they tend to be slower and clumsy, which makes them more prone to predators. For Antarctic penguins, they rarely encounter predators on land, so having larger bodies isn’t detrimental. For other species in temperate or tropical climates, the water tends to be a bit safer place.</span></p>
<p><span>Originally, penguins were classified in the same group as other flightless birds (Ratites). After multiple studies, it was discovered that penguins evolved from flying birds, which were separate from the ancestors of other flightless birds. Mitochondrial DNA has further suggested their relationship to other seafaring flighted birds such as albatross, frigatebirds, and loons. In 2006, more genomic testing suggested that birds of the </span><i><span>Ciconiiformes</span></i><span> order (storks, gannets, plovers, and boobies) were their closest living relatives (Watanabe et al. 2006).&nbsp;</span></p>
</div>
<div id="fws_66a8328a75701" data-column-margin="default" data-midnight="dark">
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0">
<div data-max-width="100%" data-max-width-mobile="default" data-shadow="none" data-animation="none">
<p><img decoding="async" data-delay="0" height="660" width="660" data-animation="none" data-nectar-img-src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4.jpg" src="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4.jpg" alt="Waimanu" data-nectar-img-srcset="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4.jpg 660w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-300x300.jpg 300w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-150x150.jpg 150w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-600x600.jpg 600w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-100x100.jpg 100w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-140x140.jpg 140w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-500x500.jpg 500w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-350x350.jpg 350w" sizes="(max-width: 660px) 100vw, 660px" srcset="https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4.jpg 660w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-300x300.jpg 300w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-150x150.jpg 150w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-600x600.jpg 600w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-100x100.jpg 100w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-140x140.jpg 140w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-500x500.jpg 500w, https://www.penguinsinternational.org/wp-content/uploads/2019/07/pen4-350x350.jpg 350w">
</p>
</div>
<div>
<p>
<h5><b>Paleontologist Ewan Fordyce with a model replica of a </b><b><i>Waimanu</i></b><b> penguin.&nbsp; </b><b>https://teara.govt.nz/en/photograph/9803/oldest-penguin</b></h5>
</p>
</div>
</div>
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0">
<p><span>It is still uncertain as to what other bird species may be related to penguins. But from finding and examining their fossilized bones, we have an idea of what they were like nearly 60 million years ago. Known by the genus name </span><i><span>Waimanu</span></i><span>, these ancient penguins may hold the record for the oldest evidence of bird lineage. Scientists believe that the extinction event that wiped out the dinosaurs during the Cretaceous period, also eliminated almost all bird species. After this catastrophe, it is believed that modern day penguins evolved from the few species that had survived, evolving quickly over a short amount of time—in relation to Earth’s history (Fordyce and Ksepka, 2012).</span></p>
<p><span>“So what kind of animal are they?” All of the evidence points to birds, but it still leaves questions unanswered. After learning of this fossil evidence, it leaves me with this question: “Are penguins birds? Or are birds penguins?” When we take a look at other body systems and explore their behavior, things become more “black and white.”</span></p>
</div>
</div>

<div id="fws_66a8328a762be" data-column-margin="default" data-midnight="dark">
<div data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-animation="" data-delay="0">
<p>
<h3><span><b>Like our penguin blogs? Sign up for our newsletter to get them right in your inbox!</b></span></h3>
</p>
</div>
<div data-max-width="100%" data-max-width-mobile="default" data-shadow="none" data-animation="" data-padding-pos="top-bottom" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-delay="0">
<p><img decoding="async" data-delay="0" height="128" width="130" data-animation="fade-in" data-nectar-img-src="https://www.penguinsinternational.org/wp-content/uploads/2020/03/IMG_6441-2-1.jpg" src="https://www.penguinsinternational.org/wp-content/uploads/2020/03/IMG_6441-2-1.jpg" alt="King Penguins">
</p>
</div>



</div>

</div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Cloudflare overcharging us for their images service? (180 pts)]]></title>
            <link>http://jpetazzo.github.io/2024/07/26/cloudflare-images-overcharge-billing/</link>
            <guid>41100958</guid>
            <pubDate>Mon, 29 Jul 2024 14:55:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://jpetazzo.github.io/2024/07/26/cloudflare-images-overcharge-billing/">http://jpetazzo.github.io/2024/07/26/cloudflare-images-overcharge-billing/</a>, See on <a href="https://news.ycombinator.com/item?id=41100958">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I recently went down a very deep rabbit hole to understand why, some months, Cloudflare was charging us 3x what we were expecting for their Cloudflare Images service. I’m posting this write-up because back then, a quick search didn’t turn anything up; and Cloudflare support has totally ghosted us for more than 8 months now.</p>

<h2 id="context-and-scale">Context and scale</h2>

<p>Let’s get something out of the way first: this is not going to be a story about millions, or even thousands, of dollars. Merely hundreds. My partner <a href="https://www.linkedin.com/in/ajbowen/">AJ</a> runs a website called <a href="https://www.ephemerasearch.com/">EphemeraSearch</a> which is an archive of old mail, a treasure trove for folks doing history or genealogy research. It’s not making much money (yet!) but storing millions of postcards <em>does</em> incur significant hosting costs, so we’re trying to be thrifty, since these costs come directly out of our own pockets (we don’t have external investors, at least not yet).</p>

<p>The website itself was initially on Heroku, then moved to a self-hosted Kubernetes cluster (after a brief transition through AWS EKS, which turned to be awfully expensive, despite leveraging spot instances, very tight autoscaling, and the famously treacherous startup credits). Many third-party services are used whenever it makes sense; for instance, the search currently relies on Algolia.</p>

<p>Image hosting was initially using Cloudinary, but we knew from day one that it was only a temporary solution, as their pricing was prohibitive for us in the long run. We moved to Cloudflare Images because it seemed affordable enough at our scale (even though we’ll almost certainly replace it later, too) and there is no question that Cloudflare is an excellent CDN.</p>

<h2 id="the-problem">The problem</h2>

<p>The service was working well, but after a few months, we noticed something off with our Cloudflare Images bills. At that point, we had a couple of million images, and less than a million image views per month. According to their <a href="https://developers.cloudflare.com/images/pricing/">pricing</a> page, we should have been paying each month:</p>

<ul>
  <li>$100 for image storage ($5 per 100,000 images stored, x 20)</li>
  <li>$10 for image delivery ($1 per 100,000 images served, x 10)</li>
</ul>

<p>Instead, when summing our Cloudflare charges (as reflected on our credit card statements), we reached more than $400 some months.</p>

<p>What was going on?!?</p>

<h2 id="it-should-be-easy-right">It should be easy, right</h2>

<p>You might wonder, dear reader, “Why did you have to sum credit card charges to know your monthly bills? Don’t you get invoices that would basically give you that information?”</p>

<p>Of course, the first thing we did was look at the invoices that we were getting. Despite the relatively simple billing models for storage and delivery, the invoices are more confusing than they should be, because the two dimensions of billing work differently.</p>

<p><strong>Image delivery</strong> is a classic pay-for-what-you-use thing. It’s $1 per 100,000 images served, <em>post-paid</em>. In other words, at the end of the month, Cloudflare counts how many images they’ve served, divides by 100,000, rounds up, and that’s how much you pay in dollars.</p>

<p><strong>Image storage</strong>, however, is prepaid, and you decide how many increments of 100,000 images you’d like to purchase. When you’re close to running out, your account dashboard will show a warning message:</p>

<blockquote>
  <p>Your account has 2% of its storage capacity remaining. Please add storage capacity to your account.</p>
</blockquote>

<p>When you add storage capacity to your account, here is what happens.</p>

<p>First, you pre-pay immediately (and your credit card is charged) for the whole capacity that you’re using, prorated to the remaining number of days in your billing cycle. In other words, if your new storage capacity is 1 million images, and you have 10 days left in your billing cycle, you immediately pay $16.67:</p>

<ul>
  <li>1 million images = 10 increments of 100,000 images at $5 each = $50</li>
  <li>10 days remaining in a cycle of 30, so 50x10/30 = $16.67</li>
</ul>

<p>Then, you get credited on your next bill with your <em>previous</em> storage capacity, prorated by the same amount - that’s the time during which you will <em>not</em> use that capacity. In other words, if you upgraded from, say, 800,000 images when you have 10 days left to your current billing cycle, you get a credit of $13.33:</p>

<ul>
  <li>800,000 images = 8 increments of 100,000 images at $5 each = $40</li>
  <li>10 days remaining in a cycle of 30, so 40x10/30 = $13.33</li>
</ul>

<p>And finally, you receive a new invoice; meaning that in some months, instead of one invoice, you get multiple invoices with prorated charges. Fair enough.</p>

<p>At the end of the day (or rather, of the billing cycle), if we went from a capacity of say 800,000 to 900,000 and then again to 1,000,000, it looks like we should pay a prorated cost depending on how many days we provisioned each capacity. In any case, it should never cost more than 1,000,000 images, right?</p>

<p><em>Wrong.</em></p>

<p>As mentioned at the beginning of this post, in some months, instead of $110, our credit card charges were over $400, and we couldn’t understand why.</p>

<p><em>And neither could the Cloudflare support team.</em></p>

<h2 id="involving-support">Involving support</h2>

<p>We contacted Cloudflare support in November 2023:</p>

<blockquote>
  <p>I’m currently subscribed to Cloudflare Images with a capacity of 2,200,000 images. I’ve been adding many images in the last few months and am regularly adding capacity as needed. It’s my understanding that each upgrade should be prorated.
2.2m images should cost $110/mo. However, when I look at the charges for the month of October, they add up to almost $400!
September also exceeds $116 even though I had way less capacity then.</p>
</blockquote>

<p>Cloudflare replied:</p>

<blockquote>
  <p>[…] we’ve raised this issue with our Images team […]</p>
</blockquote>

<p>Then when we pinged them again some time later:</p>

<blockquote>
  <p>[…] We are experiencing an unprecedented demand for our service, which is causing delays for our customers.
I’ve submitted a request to our Engineering Team, so that we can thoroughly explain what happened, and if there was any mistake reagarding your Images service.</p>
</blockquote>

<p>And after pinging them one month later:</p>

<blockquote>
  <p>Please note that we are still working with the Engineering Team on this issue.</p>
</blockquote>

<p>Then after 3 more months without an answer:</p>

<blockquote>
  <p>Thank you for waiting. Please accept our apologies for the delay in responding to you. We are experiencing an unprecedented demand for our service, which is causing delays for our customers.
Our Engineering team continues to analyze your case and develop a solution for your issue. We have been conducting weekly reviews of it for the past eight weeks. Rest assured, we are diligently working to resolve this matter.</p>
</blockquote>

<p>After pinging them the Nth time, they pointed us to this <a href="https://www.cloudflarestatus.com/incidents/wsjmr28lwxw3">incident</a> which was indeed billing-related, but had absolutely nothing to do with our issue, alas.</p>

<p>We assume that our request was blindly lumped into the ongoing billing issue (even though our request dated from November 2023, and the billing issue ran through March-May 2024).</p>

<p>Last time we pinged support again, they had migrated support to Salesforce, so the original ticket seemed to be forgotten.</p>

<p><em>Great.</em></p>

<h2 id="re-analyzing-the-situation">Re-analyzing the situation</h2>

<p>Making sense of the invoices was not trivial, because each invoice will potentially mention:</p>

<ul>
  <li>itemized charges,</li>
  <li>an “available balance”,</li>
  <li>a “previous balance”,</li>
  <li>a “starting balance”,</li>
  <li>a list of payments and credits.</li>
</ul>

<p>That’s a lot of different balances, with quite confusing names. To make sense of it, we ended up painstakingly entering all the transactions (meaning charges, payments, credits) into a spreadsheet, to try and see which balance actually corresponded to what, and to try to understand if and how we had been overcharged. That took a few hours of data entry, but eventually, it gave us the following graph:</p>

<p><img src="http://jpetazzo.github.io/assets/cloudflare-images-charges.png" alt="Graph of our charges, payments, credits, and running balance"></p>

<p>And that’s finally what helped us to understand what was going on.</p>

<h2 id="the-explanation">The explanation</h2>

<p>When you change your provisioned image storage on Cloudflare Images, you pay for the new capacity upfront: your credit card gets charged immediately. Sure, it’s prorated by the time remaining on your billing cycle, but the money goes out <em>immediately</em>. You get a credit for the old capacity that you won’t use, but that credit will only show up on your next monthly bill.</p>

<p>Consider the extreme case where you would, at the beginning of your billing cycle, increase your capacity 5 times: each time, you pay for that capacity upfront; and you get a credit for the previous capacity but that credit only materializes the following month. On the next bill, you will see a very high negative balance (indicating that Cloudflare owes you a bunch of money) and your credit card will be charged less (or even not at all) that month, so things will eventually balance out. But in the meantime, you’re accruing these credit card charges.</p>

<p>In the end, this means that Cloudflare was indeed overcharging us, but only temporarily: if enough time passes during which we <em>do not</em> change our image storage capacity, the balance should eventually go down until Cloudflare doesn’t owe us money anymore.</p>

<p>The problem is that “changing capacity” is precisely the whole point of the hecking cloud. “Pay for what you use”. The first time I racked a machine in a datacenter in the 90s, I think we had at least a yearly commitment. In the 2000s it was fairly common to rent servers by the month, and by 2010 multiple cloud providers would let you rent machines by the hour, and then by the minute.</p>

<p>I don’t know why Cloudflare decided to have this extremely weird mix of post-paid, cloud-like billing (for image delivery) and prepaid, not-cloudlike-at-all billing (for image storage), but here we are.</p>

<h2 id="is-cloudflare-images-any-good">Is Cloudflare Images any good?</h2>

<p>We’re happy with the quality of the Cloudflare Images service, but our needs are very modest, and it’s definitely overpriced for our use-case.</p>

<p>If you need to store and serve <em>big</em> images (thousands of pixels in each dimension) and to resize them efficiently, Cloudflare Images might be interesting for you, because the pricing is exclusively based on the number of images, not their size. In our case, our images are typically in the 100KB-1MB range, and we only need a small number of variants for each of them.</p>

<p>It’s likely that we will replace Cloudflare Images in the long run. Looking at storage costs alone, S3 would be 4 times less expensive <em>for our use-case</em>. And when we scale our image collection 10x, other solutions (like a couple of replicated, dedicated servers with 20 TB SATA disks) become 20x cheaper.</p>

<h2 id="conclusions-and-thoughts">Conclusions and thoughts</h2>

<p>Many “indie” projects can easily fit on very cheap infrastructure and services, sometimes well within the free tier of some generous hosting providers.</p>

<p>In our case, however, the current scale of our collection (a few terabytes at the moment, and constantly growing) compared to the very low revenue (a trickle of sales commissions whenever someone ends up buying on eBay a postcard that they found through <a href="https://www.ephemerasearch.com/">EphemeraSearch</a>) means that we have to be very efficient with our (personal) funds.</p>

<p>In the IT industry, we often talk about “buy vs. build”. Over time, as we gain more experience and understand the complexity of the things we build, we often prefer to buy a quality service rather than cobble together a crappy version of our own, arguing that the time spent building it would better be invested somewhere else. In our situation, however, the bargain turns out a bit differently: now that this is <em>my</em> money, do I want to pay $1000/month for a service, or build it myself and run it on a $100/month server? How much time do I need to build and run that service; and can I reliably make $900/month by e.g. selling consulting services to cover that cost instead?</p>

<p>Preserving historical artifacts is not, unfortunately, something that investors or the capitalist system in general tend to favor. Let’s hope that this changes in the future, but in the meantime, follow us for more thrifty and scrappy hosting tips ! 😁💸</p>

<p><em>This post was reviewed by <a href="https://www.linkedin.com/in/ajbowen/">AJ Bowen</a>. Any remaining typo or mistake is mine. We want to clarify that we think that Cloudflare Images is a great service, but that its pricing model (specifically, the prepaid aspect that has to be manually adjusted) is utterly borked. We hope our findings will be helpful to others!</em></p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An Open Course on LLMs, Led by Practitioners (105 pts)]]></title>
            <link>https://hamel.dev/blog/posts/course/</link>
            <guid>41100951</guid>
            <pubDate>Mon, 29 Jul 2024 14:54:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hamel.dev/blog/posts/course/">https://hamel.dev/blog/posts/course/</a>, See on <a href="https://news.ycombinator.com/item?id=41100951">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<p>Today, we are releasing <a href="https://parlance-labs.com/education/">Mastering LLMs</a>, a set of workshops and talks from practitioners on topics like evals, retrieval-augmented-generation (RAG), fine-tuning and more. This course is unique because it is:</p>
<ul>
<li>Taught by 25+ industry veterans who are experts in information retrieval, machine learning, recommendation systems, MLOps and data science. We discuss how this prior art can be applied to LLMs to give you a meaningful advantage.</li>
<li>Focused on applied topics that are relevant to people building AI products.</li>
<li><ins>
<strong>Free and open to everyone</strong>
</ins>
.</li>
</ul>
<p>We have organized and annotated the talks from our popular paid course.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> This is a survey course for technical ICs (including engineers and data scientists) who have some experience with LLMs and need guidance on how to improve AI products.</p>
<div>
<figure>
<p><a href="https://parlance-labs.com/education/" target="_blank"><img src="https://hamel.dev/blog/posts/course/course.png" alt="Speakers include Jeremy Howard, Sophia Yang, Simon Willison, JJ Allaire, Wing Lian, Mark Saroufim, Jane Xu, Jason Liu, Emmanuel Ameisen, Hailey Schoelkopf, Johno Whitaker, Zach Mueller, John Berryman, Ben Clavié, Abhishek Thakur, Kyle Corbitt, Ankur Goyal, Freddy Boulton, Jo Bergum, Eugene Yan, Shreya Shankar, Charles Frye, Hamel Husain, Dan Becker and more"></a></p>
<figcaption><em>Speakers include Jeremy Howard, Sophia Yang, Simon Willison, JJ Allaire, Wing Lian, Mark Saroufim, Jane Xu, Jason Liu, Emmanuel Ameisen, Hailey Schoelkopf, Johno Whitaker, Zach Mueller, John Berryman, Ben Clavié, Abhishek Thakur, Kyle Corbitt, Ankur Goyal, Freddy Boulton, Jo Bergum, Eugene Yan, Shreya Shankar, Charles Frye, Hamel Husain, Dan Becker and more</em></figcaption>
</figure>
</div>
<section id="getting-the-most-value-from-the-course">
<h2 data-anchor-id="getting-the-most-value-from-the-course">Getting The Most Value From The Course</h2>
<section id="prerequisites">
<h3 data-anchor-id="prerequisites">Prerequisites</h3>
<p>The course assumes basic familiarity with LLMs. If you do not have any experience, we recommend watching <a href="https://www.youtube.com/watch?v=jkrNMKz9pWU">A Hacker’s Guide to LLMs</a>. We also recommend the tutorial <a href="https://www.philschmid.de/instruction-tune-llama-2">Instruction Tuning llama2</a> if you are interested in fine-tuning <a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
</section>
<section id="navigating-the-material">
<h3 data-anchor-id="navigating-the-material">Navigating The Material</h3>
<p>The course has over 40 hours of content. To help you navigate this, we provide:</p>
<ul>
<li><strong>Organization by subject area</strong>: evals, RAG, fine-tuning, building applications and prompt engineering.</li>
<li><strong>Chapter summaries:</strong> quickly peruse topics in each talk and skip ahead</li>
<li><strong>Notes, slides, and resources</strong>: these are resources used in the talk, as well as resources to learn more. Many times we have detailed notes as well!</li>
</ul>
<p>To get started, <a href="https://parlance-labs.com/education">navigate to this page</a> and explore topics that interest you. Feel free to skip sections that aren’t relevant to you. We’ve organized the talks within each subject to enhance your learning experience. Be sure to review the chapter summaries, notes, and resources, which are designed to help you focus on the most relevant content and dive deeper when needed. This is a survey course, which means we focus on introducing topics rather than diving deeply into code. To solidify your understanding, we recommend applying what you learn to a personal project.</p>
</section>
<section id="what-students-are-saying">
<h3>What Students Are Saying</h3>
<p>Here are some testimonials from students who have taken the course<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a>:</p>
<div>
<div>
<div>
<p><img src="https://hamel.dev/blog/posts/course/sanyam.jpeg"></p>
<section id="sanyam-bhutani-partner-engineer-meta">
<h2 data-anchor-id="sanyam-bhutani-partner-engineer-meta"><em>Sanyam Bhutani, Partner Engineer @ Meta</em></h2>
<section id="there-was-a-magical-time-in-2017-when-fastai-changed-the-deep-learning-world.-this-course-does-the-same-by-extending-very-applied-knowledge-to-llms-best-in-class-teachers-teach-you-their-knowledge-with-no-fluff">
<h3 data-anchor-id="there-was-a-magical-time-in-2017-when-fastai-changed-the-deep-learning-world.-this-course-does-the-same-by-extending-very-applied-knowledge-to-llms-best-in-class-teachers-teach-you-their-knowledge-with-no-fluff">There was a magical time in 2017 when fastai changed the deep learning world. This course does the same by extending very applied knowledge to LLMs Best in class teachers teach you their knowledge with no fluff</h3>
</section>
</section>
</div>
<div>
<p><img src="https://hamel.dev/blog/posts/course/laurian.jpeg"></p>
<section id="laurian-full-stack-computational-linguist">
<h2 data-anchor-id="laurian-full-stack-computational-linguist"><em>Laurian, Full Stack Computational Linguist</em></h2>
<section id="this-course-was-legendary-still-is-and-the-community-on-discord-is-amazing.-ive-been-through-these-lessons-twice-and-i-have-to-do-it-again-as-there-are-so-many-nuances-you-will-get-once-you-actually-have-those-problems-on-your-own-deployment.">
<h3 data-anchor-id="this-course-was-legendary-still-is-and-the-community-on-discord-is-amazing.-ive-been-through-these-lessons-twice-and-i-have-to-do-it-again-as-there-are-so-many-nuances-you-will-get-once-you-actually-have-those-problems-on-your-own-deployment.">This course was legendary, still is, and the community on Discord is amazing. I’ve been through these lessons twice and I have to do it again as there are so many nuances you will get once you actually have those problems on your own deployment.!</h3>
</section>
</section>
</div>
<div>
<p><img src="https://hamel.dev/blog/posts/course/andre.png"></p>
<section id="andre-cto">
<h2 data-anchor-id="andre-cto"><em>Andre, CTO</em></h2>
<section id="amazing-an-opinionated-view-of-llms-from-tools-to-fine-tuning.-excellent-speakers-giving-some-of-the-best-lectures-and-advice-out-there-a-lot-of-real-life-experiences-and-tips-you-cant-find-anywhere-on-the-web-packed-into-this-amazing-courseworkshopconference-thanks-dan-and-hamel-for-making-this-happen">
<h3 data-anchor-id="amazing-an-opinionated-view-of-llms-from-tools-to-fine-tuning.-excellent-speakers-giving-some-of-the-best-lectures-and-advice-out-there-a-lot-of-real-life-experiences-and-tips-you-cant-find-anywhere-on-the-web-packed-into-this-amazing-courseworkshopconference-thanks-dan-and-hamel-for-making-this-happen">Amazing! An opinionated view of LLMs, from tools to fine-tuning. Excellent speakers, giving some of the best lectures and advice out there! A lot of real-life experiences and tips you can’t find anywhere on the web packed into this amazing course/workshop/conference! Thanks Dan and Hamel for making this happen!</h3>
</section>
</section>
</div>
<div>
<p><img src="https://hamel.dev/blog/posts/course/marcus.png"></p>
<section id="marcus-software-engineer">
<h2 data-anchor-id="marcus-software-engineer"><em>Marcus, Software Engineer</em></h2>
<section id="the-mastering-llms-conference-answered-several-key-questions-i-had-about-when-to-fine-tune-base-models-building-evaluation-suits-and-when-to-use-rag.-the-sessions-provided-a-valuable-overview-of-the-technical-challenges-and-considerations-involved-in-building-and-deploying-custom-llms.">
<h3 data-anchor-id="the-mastering-llms-conference-answered-several-key-questions-i-had-about-when-to-fine-tune-base-models-building-evaluation-suits-and-when-to-use-rag.-the-sessions-provided-a-valuable-overview-of-the-technical-challenges-and-considerations-involved-in-building-and-deploying-custom-llms.">The Mastering LLMs conference answered several key questions I had about when to fine-tune base models, building evaluation suits and when to use RAG. The sessions provided a valuable overview of the technical challenges and considerations involved in building and deploying custom LLMs.</h3>
</section>
</section>
</div>
<div>
<p><img src="https://hamel.dev/blog/posts/course/ali.png"></p>
<section id="ali-principal-founder-scty">
<h2 data-anchor-id="ali-principal-founder-scty"><em>Ali, Principal &amp; Founder, SCTY</em></h2>
<section id="the-course-that-became-a-conference-filled-with-a-lineup-of-renowned-practitioners-whose-expertise-and-contributions-to-the-field-was-only-exceeded-by-their-generosity-of-spirit.">
<h3 data-anchor-id="the-course-that-became-a-conference-filled-with-a-lineup-of-renowned-practitioners-whose-expertise-and-contributions-to-the-field-was-only-exceeded-by-their-generosity-of-spirit.">The course that became a conference, filled with a lineup of renowned practitioners whose expertise (and contributions to the field) was only exceeded by their generosity of spirit.</h3>
</section>
</section>
</div>
<div>
<p><img src="https://hamel.dev/blog/posts/course/lukas.png"></p>
<section id="lukas-software-engineer">
<h2 data-anchor-id="lukas-software-engineer"><em>Lukas, Software Engineer</em></h2>
<section id="the-sheer-amount-of-diverse-speakers-that-cover-the-same-topics-from-different-approaches-both-praising-andor-degrading-certain-workflows-makes-this-extremely-valuable.-especially-when-a-lot-of-information-online-is-produced-by-those-who-are-building-a-commercial-product-behind-naturally-is-biased-towards-a-fine-tune-a-rag-an-open-source-llm-an-open-ai-llm-etc.-it-is-rather-extra-ordinary-to-have-a-variety-of-opinions-packed-like-this.-thank-you">
<h3 data-anchor-id="the-sheer-amount-of-diverse-speakers-that-cover-the-same-topics-from-different-approaches-both-praising-andor-degrading-certain-workflows-makes-this-extremely-valuable.-especially-when-a-lot-of-information-online-is-produced-by-those-who-are-building-a-commercial-product-behind-naturally-is-biased-towards-a-fine-tune-a-rag-an-open-source-llm-an-open-ai-llm-etc.-it-is-rather-extra-ordinary-to-have-a-variety-of-opinions-packed-like-this.-thank-you">The sheer amount of diverse speakers that cover the same topics from different approaches, both praising and/or degrading certain workflows makes this extremely valuable. Especially when a lot of information online, is produced by those, who are building a commercial product behind, naturally is biased towards a fine tune, a RAG, an open source LLM, an open ai LLM etc. It is rather extra ordinary to have a variety of opinions packed like this. Thank you!</h3>
</section>
</section>
</div>
</div>

<center>
<a href="https://parlance-labs.com/education" target="_blank">Course Website</a>
</center>
</div>
</section>
</section>
<section id="stay-connected">
<h2 data-anchor-id="stay-connected">Stay Connected</h2>
<p>I’m continuously learning about LLMs, and enjoy sharing my findings and thoughts. If you’re interested in this journey, consider subscribing.</p>
<p>What to expect:</p>
<ul>
<li>Occasional emails with my latest insights on LLMs</li>
<li>Early access to new content</li>
<li>No spam, just honest thoughts and discoveries</li>
</ul>



</section>


<section id="quarto-appendix" role="doc-endnotes"><h2>Footnotes</h2>

<ol>
<li id="fn1"><p>https://maven.com/parlance-labs/fine-tuning. We had more than 2,000 students in our first cohort. The students who paid for the original course had early access to the material, office hours, generous compute credits, and a lively Discord community.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>We find that instruction tuning a model to be a very useful educational experience even if you never intend to fine-tune, because it familiarizes you with topics such as (1) working with open weights models (2) generating synthetic data (3) managing prompts (4) fine-tuning (5) and generating predictions.<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>These testimonials are taken from https://maven.com/parlance-labs/fine-tuning.<a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yark: YouTube Archiver with Offline UI (110 pts)]]></title>
            <link>https://github.com/Owez/yark</link>
            <guid>41100820</guid>
            <pubDate>Mon, 29 Jul 2024 14:37:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Owez/yark">https://github.com/Owez/yark</a>, See on <a href="https://news.ycombinator.com/item?id=41100820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Yark</h2><a id="user-content-yark" aria-label="Permalink: Yark" href="#yark"></a></p>
<p dir="auto">YouTube archiving made simple.</p>




<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install Yark, simply download <a href="https://www.python.org/downloads/" rel="nofollow">Python 3.9+</a> and <a href="https://ffmpeg.org/" rel="nofollow">FFmpeg</a> (optional), then run the following:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Managing your Archive</h2><a id="user-content-managing-your-archive" aria-label="Permalink: Managing your Archive" href="#managing-your-archive"></a></p>
<p dir="auto">Once you've installed Yark, think of a name for your archive (e.g., "foobar") and copy the target's url:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ yark new foobar https://www.youtube.com/channel/UCSMdm6bUYIBN0KfS2CVuEPA"><pre>$ yark new foobar https://www.youtube.com/channel/UCSMdm6bUYIBN0KfS2CVuEPA</pre></div>
<p dir="auto">Now that you've created the archive, you can tell Yark to download all videos and metadata using the refresh command:</p>

<p dir="auto">Once everything has been downloaded, Yark will automatically give you a status report of what's changed since the last refresh:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/Owez/yark/1.2-support/examples/images/cli_dark.png"><img src="https://raw.githubusercontent.com/Owez/yark/1.2-support/examples/images/cli_dark.png" alt="Report Demo" title="Report Demo" width="600"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Viewing your Archive</h2><a id="user-content-viewing-your-archive" aria-label="Permalink: Viewing your Archive" href="#viewing-your-archive"></a></p>
<p dir="auto">Viewing you archive is easy, just type <code>view</code> with your archives name:</p>

<p dir="auto">This will pop up an offline website in your browser letting you watch all videos 🚀</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/Owez/yark/1.2-support/examples/images/viewer_light.png"><img src="https://raw.githubusercontent.com/Owez/yark/1.2-support/examples/images/viewer_light.png" alt="Viewer Demo" title="Viewer Demo" width="650"></a></p>
<p dir="auto">Under each video is a rich history report filled with timelines and graphs, as well as a noting feature which lets you add timestamped and permalinked comments 👐</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/Owez/yark/1.2-support/examples/images/viewer_stats_light.png"><img src="https://raw.githubusercontent.com/Owez/yark/1.2-support/examples/images/viewer_stats_light.png" alt="Viewer Demo – Stats" title="Viewer Demo – Stats" width="650"></a></p>
<p dir="auto">Light and dark modes are both available and automatically apply based on the system's theme.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Details</h2><a id="user-content-details" aria-label="Permalink: Details" href="#details"></a></p>
<p dir="auto">Here are some things to keep in mind when using Yark; the good and the bad:</p>
<ul dir="auto">
<li>Don't create a new archive again if you just want to update it, Yark accumulates all new metadata for you via timestamps</li>
<li>Feel free to suggest new features via the issues tab on this repository</li>
<li>Scheduling isn't a feature just yet, please use <a href="https://en.wikipedia.org/wiki/Cron" rel="nofollow"><code>cron</code></a> or something similar!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Archive Format</h2><a id="user-content-archive-format" aria-label="Permalink: Archive Format" href="#archive-format"></a></p>
<p dir="auto">The archive format itself is simple and consists of a directory-based structure with a core metadata file and all thumbnail/video data in their own directories as typical files:</p>
<ul dir="auto">
<li><code>[name]/</code> – Your self-contained archive
<ul dir="auto">
<li><code>yark.json</code> – Archive file with all metadata</li>
<li><code>yark.bak</code> – Backup archive file to protect against data damage</li>
<li><code>videos/</code> – Directory containing all known videos
<ul dir="auto">
<li><code>[id].*</code> – Files containing video data for YouTube videos</li>
</ul>
</li>
<li><code>thumbnails/</code> – Directory containing all known thumbnails
<ul dir="auto">
<li><code>[hash].png</code> – Files containing thumbnails with its hash</li>
</ul>
</li>
</ul>
</li>
</ul>
<p dir="auto">It's best to take a few minutes to familiarize yourself with your archive by looking at files which look interesting to you in it, everything is quite readable.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Roame (YC S23) – Flight search engine for your credit card points (161 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41100094</link>
            <guid>41100094</guid>
            <pubDate>Mon, 29 Jul 2024 12:56:23 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41100094">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="41100094">
      <td><span></span></td>      <td><center><a id="up_41100094" href="https://news.ycombinator.com/vote?id=41100094&amp;how=up&amp;goto=item%3Fid%3D41100094"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=41100094">Launch HN: Roame (YC S23) – Flight search engine for your credit card points</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_41100094">111 points</span> by <a href="https://news.ycombinator.com/user?id=zman0225">zman0225</a> <span title="2024-07-29T12:56:23"><a href="https://news.ycombinator.com/item?id=41100094">7 hours ago</a></span> <span id="unv_41100094"></span> | <a href="https://news.ycombinator.com/hide?id=41100094&amp;goto=item%3Fid%3D41100094">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Roame%20(YC%20S23)%20%E2%80%93%20Flight%20search%20engine%20for%20your%20credit%20card%20points&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=41100094&amp;auth=a3795de04d7848fb177399aef603812f2be35bbc">favorite</a> | <a href="https://news.ycombinator.com/item?id=41100094">70&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hi HN! We're Tim and Zi from Roame (<a href="https://roame.travel/">https://roame.travel</a>). Roame is a flight search engine that lets you find and redeem business class flights using points and miles, rather than exorbitant amounts of cash. Here's a demo video: <a href="https://www.youtube.com/watch?v=fixXuyhofgo" rel="nofollow">https://www.youtube.com/watch?v=fixXuyhofgo</a>
We have been flying around the world in first and business class using points for years—Tim for more than a decade and Zi more recently. A little over a year ago, we were trying to find cheap round-trip tickets in first or business class to Asia and back using points. We had tons of points across Chase, American Express, and Citi, but finding a good redemption is always a pain.</p><p>We had flexibility with points currency, destinations, and dates. Our only requirement was securing two round-trip flight redemptions in first or business class on the same flight. This flexibility came at a cost: we spent over 30 hours across two weeks manually searching dates and routes on the websites of 10-20 airline transfer partners.</p><p>Ultimately, we did find two Japan Airlines first class tickets from Los Angeles to Tokyo for 70,000 points each, returning to New York for 80,000 points each. These flights typically cost between $20,000 to $30,000 roundtrip in cash, but using points, we effectively paid only ~$2,000.</p><p>The first class experience was unforgettable, but we didn't want to repeat the tedious search process. So, we decided to build a tool to save time in the future.</p><p>I know all this about points might sound a bit like magic, but booking cheap business class flights using points is achievable for the average person. Here's how it works:
Credit card sign-up offers range from 50,000 to 150,000 points. These points are either tied to credit card currencies (Chase Ultimate Rewards, American Express Membership Rewards) or specific airlines (Delta Skymiles, United MileagePlus). The most valuable and versatile points are tied to credit card currencies because they can be transferred to various travel partners. This flexibility allows you to choose the best value before transferring points. If you only have points with one airline program, you're limited to their redemptions.</p><p>While most people redeem their credit card points through the Chase or American Express travel portals at about 1-1.5 cents per point, transferring to an airline partner can yield 3-8 cents per point for business class or 12-20 cents per point for first class.</p><p>The best value for points often comes from non-US airlines like Air Canada, Air France/KLM, Avianca, and British Airways. For example, you can redeem 50,000 points for an Air France business class flight from San Francisco to Paris, which would otherwise cost around $4,000. That's an 8 cents per point value, significantly higher than using the credit card travel portal.</p><p>However, the challenges are: 1) most people don't know their credit card points can transfer to airline partners, 2) they don't consider non-US airlines, and 3) manually searching each airline website is time-consuming.</p><p>Our tool simplifies this process: Enter your origin airport, destination airport, date, fare class, and number of travelers. After you click search, our tool searches up to 16 different airline loyalty programs in real time and displays the results, including flight information, points cost, and redemption instructions.</p><p>The real-time search is free and offers access to 60 days of SkyView, a cached database of the top 6,500 most popular routes categorized by regions (state, country, continent) across two months. The paid version extends access to the full 365 calendar and allows searches up to two months at a time, with email alerts. SkyView is perfect for showing you what is currently available or was previously possible for all your award redemption needs.</p><p>We're continuously adding more features and would love to hear your ideas, experiences, and feedback! Thank you in advance!</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Movable tree CRDTs and Loro's implementation (252 pts)]]></title>
            <link>https://loro.dev/blog/movable-tree</link>
            <guid>41099901</guid>
            <pubDate>Mon, 29 Jul 2024 12:24:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loro.dev/blog/movable-tree">https://loro.dev/blog/movable-tree</a>, See on <a href="https://news.ycombinator.com/item?id=41099901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><main>
<!-- -->

<p><img loading="lazy" width="1792" height="1024" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmovable-tree-cover.f2c64ff7.png&amp;w=1920&amp;q=75 1x, https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmovable-tree-cover.f2c64ff7.png&amp;w=3840&amp;q=75 2x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmovable-tree-cover.f2c64ff7.png&amp;w=3840&amp;q=75"></p>
<p>This article introduces the implementation difficulties and challenges of Movable Tree CRDTs when collaboration, and how Loro implements it and sorts child nodes. The algorithm has high performance and can be used in production.</p>
<h2>Background<a href="#background" id="background" aria-label="Permalink for this section"></a></h2>
<p>In distributed systems and collaborative software, managing hierarchical relationships is difficult and complex. Challenges arise in resolving conflicts and meeting user expectations when working with the data structure that models movement by combining deletion and insertion. For instance, if a node is concurrently moved to different parents in replicas, it may lead to the unintended creation of duplicate nodes with the same content. Because the node is deleted twice and created under two parents.</p>
<p>Currently, many software solutions offer different levels of support and functionality for managing hierarchical data structures in distributed environments. The key variation among these solutions lies in their approaches to handling potential conflicts.</p>
<h3>Conflicts in Movable Trees<a href="#conflicts-in-movable-trees" id="conflicts-in-movable-trees" aria-label="Permalink for this section"></a></h3>
<p>A movable tree has 3 primary operations: creation, deletion, and movement. Consider a scenario where two peers independently execute various operations on their respective replicas of the same movable tree. Synchronizing these operations can lead to potential conflicts, such as:</p>
<ul>
<li>The same node was deleted and moved</li>
<li>The same node was moved under different nodes</li>
<li>Different nodes were moved, resulting in a cycle</li>
<li>The ancestor node is deleted while the descendant node is moved</li>
</ul>
<h4>Deletion and Movement of the Same Node<a href="#deletion-and-movement-of-the-same-node" id="deletion-and-movement-of-the-same-node" aria-label="Permalink for this section"></a></h4>
<p><img alt="Deletion and Movement of the Same Node" loading="lazy" width="3054" height="1394" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmove-delete-dark.17378273.png&amp;w=3840&amp;q=75 1x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmove-delete-dark.17378273.png&amp;w=3840&amp;q=75"></p>
<p>This situation is relatively easy to resolve. It can be addressed by applying one of the operations while ignoring the other based on the timestamp in the distributed system or the application's specific requirements. Either approach yields an acceptable outcome.</p>
<h4>Moving the Same Node Under Different Parents<a href="#moving-the-same-node-under-different-parents" id="moving-the-same-node-under-different-parents" aria-label="Permalink for this section"></a></h4>
<p><img alt="Moving the Same Node Under Different Parents" loading="lazy" width="3070" height="1398" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmove-same-node-dark.fc82da02.png&amp;w=3840&amp;q=75 1x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmove-same-node-dark.fc82da02.png&amp;w=3840&amp;q=75"></p>
<p>Merging concurrent movement operations of the same node is slightly more complex. Different approaches can be adopted depending on the application:</p>
<ul>
<li>Delete the node and create copies of nodes under different parent nodes. Subsequent operations then treat these nodes independently. This approach is acceptable when node uniqueness is not critical.</li>
<li>Allow the node have two edges pointing to different parents. However, this approach breaks the fundamental tree structure and is generally not considered acceptable.</li>
<li>Sort all operations, then apply them one by one. The order can be determined by timestamps in a distributed system. Providing the system maintains a consistent operation sequence, it ensures uniform results across all peers.</li>
</ul>
<h4>Movement of Different Nodes Resulting in a Cycle<a href="#movement-of-different-nodes-resulting-in-a-cycle" id="movement-of-different-nodes-resulting-in-a-cycle" aria-label="Permalink for this section"></a></h4>
<p><img alt="cycle" loading="lazy" width="3024" height="1442" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcycle-dark.267300d7.png&amp;w=3840&amp;q=75 1x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcycle-dark.267300d7.png&amp;w=3840&amp;q=75"></p>
<p>Concurrent movement operations that cause cycles make the conflict resolution of movable trees complex. Matthew Weidner listed several solutions to resolve cycles in his <a href="https://mattweidner.com/2023/09/26/crdt-survey-2.html#forests-and-trees" target="_blank" rel="noreferrer">blog<span> (opens in a new tab)</span></a>.</p>
<blockquote>
<ol>
<li>Error. Some desktop file sync apps do this in practice (<a href="https://doi.org/10.1109/TPDS.2021.3118603" target="_blank" rel="noreferrer">Martin Kleppmann et al. (2022)<span> (opens in a new tab)</span></a> give an example).</li>
<li>Render the cycle nodes (and their descendants) in a special “time-out” zone. They will stay there until some user manually fixes the cycle.</li>
<li>Use a server to process move ops. When the server receives an op, if it would create a cycle in the server’s own state, the server rejects it and tells users to do likewise. This is&nbsp;<a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/#syncing-trees-of-objects" target="_blank" rel="noreferrer">what Figma does<span> (opens in a new tab)</span></a>. Users can still process move ops optimistically, but they are tentative until confirmed by the server. (Optimistic updates can cause temporary cycles for users; in that case, Figma uses strategy (2): it hides the cycle nodes.)</li>
<li>Similar, but use a&nbsp;<a href="https://mattweidner.com/2023/09/26/crdt-survey-2.html#topological-sort" target="_blank" rel="noreferrer">topological sort<span> (opens in a new tab)</span></a>&nbsp;(below) instead of a server’s receipt order. When processing ops in the sort order, if an op would create a cycle, skip it&nbsp;<a href="https://doi.org/10.1109/TPDS.2021.3118603" target="_blank" rel="noreferrer">(Martin Kleppmann et al. 2022)<span> (opens in a new tab)</span></a>.</li>
<li>For forests: Within each cycle, let&nbsp;<code dir="ltr">B.parent = A</code>&nbsp;be the edge whose&nbsp;<code dir="ltr">set</code>&nbsp;operation has the largest LWW timestamp. At render time, “hide” that edge, instead rendering&nbsp;<code dir="ltr">B.parent = "none"</code>, but don’t change the actual CRDT state. This hides one of the concurrent edges that created the cycle.
• To prevent future surprises, users’ apps should follow the rule: before performing any operation that would create or destroy a cycle involving a hidden edge, first “affirm” that hidden edge, by performing an op that sets&nbsp;<code dir="ltr">B.parent = "none"</code>.</li>
<li>For trees: Similar, except instead of rendering&nbsp;<code dir="ltr">B.parent = "none"</code>, render the previous parent for&nbsp;<code dir="ltr">B</code>&nbsp;- as if the bad operation never happened. More generally, you might have to backtrack several operations. Both&nbsp;<a href="http://dx.doi.org/10.1145/3209280.3229110" target="_blank" rel="noreferrer">Hall et al. (2018)<span> (opens in a new tab)</span></a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2103.04828" target="_blank" rel="noreferrer">Nair et al. (2022)<span> (opens in a new tab)</span></a>&nbsp;describe strategies along these lines.</li>
</ol>
</blockquote>
<h4>Ancestor Node Deletion and Descendant Node Movement<a href="#ancestor-node-deletion-and-descendant-node-movement" id="ancestor-node-deletion-and-descendant-node-movement" aria-label="Permalink for this section"></a></h4>
<p><img alt="Ancestor Node Deletion and Descendant Node Movement" loading="lazy" width="2064" height="1136" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmove_chlid_delete_parent_dark.4422d913.png&amp;w=3840&amp;q=75 1x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmove_chlid_delete_parent_dark.4422d913.png&amp;w=3840&amp;q=75"></p>
<p>The most easily overlooked scenario is moving descendant nodes when deleting an ancestor node. If all descendant nodes of the ancestor are deleted directly, users may easily misunderstand that their data has been lost.</p>
<h3>How Popular Applications Handle Conflicts<a href="#how-popular-applications-handle-conflicts" id="how-popular-applications-handle-conflicts" aria-label="Permalink for this section"></a></h3>
<p>Dropbox is a file data synchronization software. Initially, Dropbox treated file movement as a two-step process: deletion from the original location followed by creation at a new location. However, this method risked data loss, especially if a power outage or system crash occurred between the delete and create operations.</p>
<p>Today, when multiple people move the same file concurrently and attempt to save their changes, Dropbox detects a conflict. In this scenario, it typically saves one version of the original file and creates a new <a href="https://help.dropbox.com/organize/conflicted-copy" target="_blank" rel="noreferrer">"conflicted copy"<span> (opens in a new tab)</span></a> for the changes made by one of the users.</p>
<p><img alt="Solution for conflicts when moving files with Dropbox" loading="lazy" width="852" height="311" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdropbox_move.467b7931.gif&amp;w=1080&amp;q=75 1x, https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdropbox_move.467b7931.gif&amp;w=1920&amp;q=75 2x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdropbox_move.467b7931.gif&amp;w=1920&amp;q=75"></p>
<p>The image shows the conflict that occurs when A is moved to the B folder and B
is moved to the A folder concurrently.</p>
<p>Figma is a real-time collaborative prototyping tool. They consider tree structures as the most complex part of the collaborative system, as detailed in their <a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/#syncing-trees-of-objects" target="_blank" rel="noreferrer">blog post about multiplayer technology<span> (opens in a new tab)</span></a>. To maintain consistency, each element in Figma has a "parent" attribute. The centralized server plays a crucial role in ensuring the integrity of these structures. It monitors updates from various users and checks if any operation would result in a cycle. If a potential cycle is detected, the server rejects the operation.</p>
<p>However, due to network delays and similar issues, there can be instances where updates from users temporarily create a cycle before the server has the chance to reject them. Figma acknowledges that this situation is uncommon. Their <a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/#syncing-trees-of-objects" target="_blank" rel="noreferrer">solution<span> (opens in a new tab)</span></a> is straightforward yet effective: they temporarily preserve this state and hide the elements involved in the cycle. This approach lasts until the server formally rejects the operation, ensuring both the stability of the system and a seamless user experience.</p>
<p><img alt="An animation that demonstrates how Figma resolves conflicts." loading="lazy" width="1248" height="824" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffigma-tree.8521d43a.gif&amp;w=1920&amp;q=75 1x, https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffigma-tree.8521d43a.gif&amp;w=3840&amp;q=75 2x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffigma-tree.8521d43a.gif&amp;w=3840&amp;q=75"></p>
<div><p>An animation that demonstrates how
<a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/#syncing-trees-of-objects" target="_blank" rel="noreferrer">Figma<span> (opens in a new tab)</span></a>
resolves conflicts.</p></div>
<h2>Movable Tree CRDTs<a href="#movable-tree-crdts" id="movable-tree-crdts" aria-label="Permalink for this section"></a></h2>
<p>The applications mentioned above use movable trees and resolve conflicts based on centralized solutions. Another alternative approach to collaborative tree structures is using Conflict-free Replicated Data Types (CRDTs). While initial CRDT-based algorithms were challenging to implement and incurred significant storage overhead as noted in prior research, such as <a href="https://arxiv.org/pdf/1201.1784.pdf" target="_blank" rel="noreferrer">Abstract unordered and
ordered trees CRDT<span> (opens in a new tab)</span></a> or <a href="https://arxiv.org/pdf/1207.5990.pdf" target="_blank" rel="noreferrer">File system on CRDT<span> (opens in a new tab)</span></a>, but continual optimization and improvement have made several CRDT-based tree synchronization algorithms suitable for certain production environments. This article highlights two innovative CRDT-based approaches for movable trees. The first is presented by Martin Kleppmann et al. in their work <strong><em><a href="https://martin.kleppmann.com/2021/10/07/crdt-tree-move-operation.html" target="_blank" rel="noreferrer">A highly-available move operation for replicated trees<span> (opens in a new tab)</span></a></em></strong> and the second by Evan Wallace in his <strong><em><a href="https://madebyevan.com/algos/crdt-mutable-tree-hierarchy/" target="_blank" rel="noreferrer">CRDT: Mutable Tree Hierarchy<span> (opens in a new tab)</span></a></em></strong>.</p>
<h3>A highly-available move operation for replicated trees<a href="#a-highly-available-move-operation-for-replicated-trees" id="a-highly-available-move-operation-for-replicated-trees" aria-label="Permalink for this section"></a></h3>
<p>This paper unifies the three operations used in trees (creating, deleting, and moving nodes) into a move operation. The move operation is defined as a four-tuple <code dir="ltr">Move t p m c</code>, where <code dir="ltr">t</code> is the operation's unique and ordered timestamp such as <a href="https://en.wikipedia.org/wiki/Lamport_timestamp" target="_blank" rel="noreferrer"><code dir="ltr">Lamport timestamp</code><span> (opens in a new tab)</span></a>, <code dir="ltr">p</code> is the parent node ID, <code dir="ltr">m</code> is the metadata associated with the node, and <code dir="ltr">c</code> is the child node ID.</p>
<p>If all nodes of the tree do not contain <code dir="ltr">c</code>, this is a <strong>creation</strong> operation that creates a child node <code dir="ltr">c</code> under parent node <code dir="ltr">p</code>. Otherwise, it is a <strong>move</strong> operation that moves <code dir="ltr">c</code> from its original parent to the new parent <code dir="ltr">p</code>. Additionally, node deletion is elegantly handled by introducing a designated <code dir="ltr">TRASH</code> node; moving a node to <code dir="ltr">TRASH</code> implies its deletion, with all descendants of <code dir="ltr">TRASH</code> considered deleted. But they remain in memory to prevent concurrent editing from moving them to other nodes. In order to handle the previously mentioned situation of deleting ancestor nodes and moving descendant nodes concurrently.</p>
<p>In the three potential conflicts mentioned earlier, since deletion is also defined as a move operation, <strong>deleting and moving the same node</strong> is transformed into two move operations, leaving only two remaining problems:</p>
<ul>
<li><strong>Moving the same node under different parents</strong></li>
<li><strong>Moving different nodes, creating a cycle</strong></li>
</ul>
<p>Logical timestamps are added so that all operations can be linearly ordered, thus the first conflict can be avoided as they can be expressed as two operations in sequence rather than concurrently for the same node. Therefore, in modeling a Tree using only move operations, the only exceptional case in concurrent editing would be creating a cycle, and operations causing a cycle are termed <strong>unsafe operations</strong>.</p>
<p>This algorithm sorts all move operations according to their timestamps. It can then sequentially apply each operation. Before applying, the algorithm detects cycles to determine whether an operation is safe. If the operation creates a cycle, we ignore the unsafe operation to ensure the correct structure of the tree.</p>
<p>Based on the above approach, the consistency problem of movable trees becomes the following two questions:</p>
<ol>
<li>How to introduce global order to operations</li>
<li>How to apply a remote operation that should be inserted in the middle of an existing sorted sequence of operations</li>
</ol>
<h4>Globally Ordered Logical Timestamps<a href="#globally-ordered-logical-timestamps" id="globally-ordered-logical-timestamps" aria-label="Permalink for this section"></a></h4>
<p><a href="https://en.wikipedia.org/wiki/Lamport_timestamp" target="_blank" rel="noreferrer">Lamport Timestamp<span> (opens in a new tab)</span></a> can determine the causal order of events in a distributed system. Here's how they work: each peer starts with a counter initialized to <code dir="ltr">0</code>. When a local event occurs, the counter is increased by <code dir="ltr">1</code>, and this value becomes the event's Lamport Timestamp. When peer <code dir="ltr">A</code> sends a message to peer <code dir="ltr">B</code>, <code dir="ltr">A</code> attaches its Lamport Timestamp to the message. Upon receiving the message, peer <code dir="ltr">B</code> compares its current logical clock value with the timestamp in the message and updates its logical clock to the larger value.</p>
<p>To globally sort events, we first look at the Lamport Timestamps: smaller numbers mean earlier events. If two events have the same timestamp, we use the unique ID of the peer serves as a tiebreaker.</p>
<h4>Apply a Remote Operation<a href="#apply-a-remote-operation" id="apply-a-remote-operation" aria-label="Permalink for this section"></a></h4>
<p>An op's safety depends on the tree's state when applied, avoiding cycles. Insertion requires evaluating the state formed by all preceding ops. For remote updates, we may need to:</p>
<ol>
<li>Undo recent ops</li>
<li>Insert the new op</li>
<li>Reapply undone ops</li>
</ol>
<p>This ensures proper integration of new ops into the existing sequence.</p>
<h5>Undo Recent Ops<a href="#undo-recent-ops" id="undo-recent-ops" aria-label="Permalink for this section"></a></h5>
<p>Since we've modeled all operations on the tree as move operations, undoing a move operation involves either moving the node back to its old parent or undoing the operation that created this node. To enable quick undoing, we cache and record the <strong>old parent</strong> of the node before applying each move operation.</p>
<h5>Apply the Remote Op<a href="#apply-the-remote-op" id="apply-the-remote-op" aria-label="Permalink for this section"></a></h5>
<p>Upon encountering an unsafe operation, disregarding its effects prevents the creation of a cycle. Nevertheless, it's essential to record the operation, as the safety of an operation is determined <strong>dynamically</strong>. For instance, if we receive and sort an update that deletes another node causing the cycle prior to this operation, the operation that was initially unsafe becomes safe. Additionally, we need to mark this unsafe operation as ineffective, since during undo operations, it's necessary to query the <strong>old parent</strong> node, which is the target parent of the last effective operation in the sequence targeting this node.</p>
<h5>Reapply Undone Ops<a href="#reapply-undone-ops" id="reapply-undone-ops" aria-label="Permalink for this section"></a></h5>
<p>Cycles only occur when receiving updates from other peers, so the undo-do-redo process is also needed at this time. When receiving a new op:</p>

<ul>
<li>If the new operation depends on an op that has not been encountered locally, indicating that some inter-version updates are still missing, it is necessary to temporarily cache the new op and wait to apply it until the missing updates are received.</li>
<li>Compare the new operation with all existing operations. If the <code dir="ltr">opId</code> of the new operation is greater than that of all existing operations, it can be directly applied. If the new operation is safe, record the parent node of the target node as the old parent node, then apply the move operation to change the current state. If it is not safe, mark this operation as ineffective and ignore the operation's impact.</li>
<li>If the new opId is sorted in the middle of the existing sequence, it is necessary to pop the operations that are sorted later from the sequence one by one, and undo the impact of this operation, which means moving back to the child of the old parent node, until the new operation can be applied. After applying the new operation, reapply the undone nodes in sequence order, ensuring that all operations are applied in order.</li>
</ul>
<p>The following animated GIF demonstrates the process executed by <code dir="ltr">Peer1</code>:</p>
<ol>
<li>Received <code dir="ltr">Peer0</code> creating node <code dir="ltr">A</code> with the <code dir="ltr">root</code> node as its parent.</li>
<li>Received <code dir="ltr">Peer0</code> creating node <code dir="ltr">B</code> with <code dir="ltr">A</code> as its parent.</li>
<li>Created node <code dir="ltr">C</code> with <code dir="ltr">A</code> as its parent and synchronized it with <code dir="ltr">Peer0</code>.</li>
<li>Moved <code dir="ltr">C</code> to have <code dir="ltr">B</code> as its parent.</li>
<li>Received <code dir="ltr">Peer0</code>'s moving <code dir="ltr">B</code> to have <code dir="ltr">C</code> as its parent.</li>
</ol>
<p><img loading="lazy" width="1440" height="810" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fundo-do-redo.213bb232.gif&amp;w=1920&amp;q=75 1x, https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fundo-do-redo.213bb232.gif&amp;w=3840&amp;q=75 2x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fundo-do-redo.213bb232.gif&amp;w=3840&amp;q=75"></p>
<p>The queue at the top right of the animation represents the order of local operations and newly received updates. The interpretation of each element in each <code dir="ltr">Block</code> is as follows:</p>
<p><img loading="lazy" width="891" height="465" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fexplain.ba7477d6.png&amp;w=1080&amp;q=75 1x, https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fexplain.ba7477d6.png&amp;w=1920&amp;q=75 2x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fexplain.ba7477d6.png&amp;w=1920&amp;q=75"></p>
<p>A particular part of this process to note is the two operations with <code dir="ltr">lamport timestamps</code> of <code dir="ltr">0:3</code> and <code dir="ltr">1:3</code>. Initially, the <code dir="ltr">1:3</code> operation moving <code dir="ltr">C</code> to <code dir="ltr">B</code> was created and applied locally, followed by receiving <code dir="ltr">Peer0</code>'s <code dir="ltr">0:3</code> operation moving <code dir="ltr">B</code> to <code dir="ltr">C</code>. In <code dir="ltr">lamport timestamp</code> order, <code dir="ltr">0:3</code> is less than <code dir="ltr">1:3</code> but greater than <code dir="ltr">1:2</code> (with peer as the tiebreaker when counters are equal). To apply the new op, the <code dir="ltr">1:3</code> operation is undone first, moving <code dir="ltr">C</code> back to its old parent <code dir="ltr">A</code>, then <code dir="ltr">0:3</code> moving <code dir="ltr">B</code> to <code dir="ltr">C</code> is applied. After that, <code dir="ltr">1:3</code> is redone, attempting to move <code dir="ltr">C</code> to <code dir="ltr">B</code> again (the old parent remains <code dir="ltr">A</code>, omitted in the animation). However, a cycle is detected during this attempt, preventing the operation from taking effect, and the state of the tree remains unchanged. This completes an <code dir="ltr">undo-do-redo</code> process.</p>
<h3>CRDT: Mutable Tree Hierarchy<a href="#crdt-mutable-tree-hierarchy" id="crdt-mutable-tree-hierarchy" aria-label="Permalink for this section"></a></h3>
<p>Evan Wallace has developed an innovative algorithm that enables each node to track all its historical parent nodes, attaching a counter to each recorded parent. The count value of a new parent node is 1 higher than that of all the node's historical parents, indicating the update sequence of the node's parents. The parent with the highest count is considered the current parent node.</p>
<p>During synchronization, this parent node information is also synced. If a cycle occurs, a heuristic algorithm reattaches the nodes causing the cycle back to the nearest historical parent node that won't cause a cycle and is connected to the root node, thus updating the parent node record. This process is repeated until all nodes causing cycles are reattached to the tree, achieving all replica synchronization of the tree structure. The demo in <a href="https://madebyevan.com/algos/crdt-mutable-tree-hierarchy/" target="_blank" rel="noreferrer">Evan's blog<span> (opens in a new tab)</span></a> clearly illustrates this process.</p>
<p>As Evan summarized at the end of the article, this algorithm does not require the expensive <code dir="ltr">undo-do-redo</code> process. However, each time a remote move is received, the algorithm needs to determine if all nodes are connected to the root node and reattach the nodes causing cycles back to the tree, which can perform poorly when there are too many nodes.</p>
<p>I established a <a href="https://github.com/Leeeon233/movable-tree-crdt" target="_blank" rel="noreferrer">benchmark<span> (opens in a new tab)</span></a> to compare the performance of the movable tree algorithms.</p>
<h2>Movable Tree CRDTs implementation in Loro<a href="#movable-tree-crdts-implementation-in-loro" id="movable-tree-crdts-implementation-in-loro" aria-label="Permalink for this section"></a></h2>
<p>Loro implements the algorithm proposed by Martin Kleppmann et al., <strong><em><a href="https://martin.kleppmann.com/2021/10/07/crdt-tree-move-operation.html" target="_blank" rel="noreferrer">A highly-available move operation for replicated trees<span> (opens in a new tab)</span></a></em></strong>. On one hand, this algorithm has high performance in most real world scenarios. On the other hand, the core <code dir="ltr">undo-do-redo</code> process of the algorithm is highly similar to how REG (Replayable Event Graph) applies remote updates in Loro. Introduction about <strong>REG</strong> can be found in our previous <a href="https://www.loro.dev/blog/loro-richtext#brief-introduction-to-replayable-event-graph" target="_blank" rel="noreferrer">blog<span> (opens in a new tab)</span></a>.</p>
<p>Movable tree has been introduced in detail, but there is still another problem of tree structure that has not been solved. For movable tree, in some real use cases, we still need the capability to sort child nodes. This is necessary for outline notes or layer management in graphic design softwares. Users need to adjust node order and sync it to other collaborators or devices.</p>
<p>We integrated the <code dir="ltr">Fractional Index</code> algorithm into Loro and combined it with the movable tree, making the child nodes of the movable tree sortable.</p>
<p>There are many introductions to <code dir="ltr">Fractional Index</code> on the web, You can read more about <code dir="ltr">Fractional Index</code> in the <a href="https://www.figma.com/blog/realtime-editing-of-ordered-sequences" target="_blank" rel="noreferrer">Figma blog<span> (opens in a new tab)</span></a> or <a href="https://madebyevan.com/algos/crdt-fractional-indexing/" target="_blank" rel="noreferrer">Evan blog<span> (opens in a new tab)</span></a>. In simple terms, <code dir="ltr">Fractional Index</code> assigns a sortable value to each object, and if a new insertion occurs between two objects, the <code dir="ltr">Fractional Index</code> of the new object will be between the left and right values. What we want to speak about more here is how to deal with potential conflicts brought by <code dir="ltr">Fractional Index</code> in CRDTs systems.</p>
<h3>Potential Conflicts in Child Node Sorting<a href="#potential-conflicts-in-child-node-sorting" id="potential-conflicts-in-child-node-sorting" aria-label="Permalink for this section"></a></h3>
<p>As our applications are in a distributive condition, when multiple peers insert new nodes in the same position, the same <code dir="ltr">Fractional Index</code> would be assigned to these differing content but same position nodes. When updates from the remote are applied to local, conflicts arise as the same <code dir="ltr">Fractional Index</code> is encountered.</p>
<p>In Loro, we retain these identical <code dir="ltr">Fractional Index</code> and use <code dir="ltr">PeerID</code> (unique ID of every Peer) as the tie-breaker for the relative order judgment of the same <code dir="ltr">Fractional Index</code>.</p>
<p><img loading="lazy" width="1096" height="465" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FFI-and-PeerID-dark.82febfcc.png&amp;w=1200&amp;q=75 1x, https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FFI-and-PeerID-dark.82febfcc.png&amp;w=3840&amp;q=75 2x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FFI-and-PeerID-dark.82febfcc.png&amp;w=3840&amp;q=75"></p>
<p>Although this solved the sorting problem among the same <code dir="ltr">Fractional Index</code> nodes from different peers, it impacted the generation of new <code dir="ltr">Fractional Index</code> as we cannot generate a new <code dir="ltr">Fractional Index</code> between two same ones. We use two methods to solve this problem:</p>
<ol>
<li>The first method, as stated in Evan's blog, we could add a certain amount of jitter to each generated <code dir="ltr">Fractional Index</code>, (for the ease of explanation, all examples below take decimal fraction as the <code dir="ltr">Fractional Index</code>) for example, when generating a new <code dir="ltr">Fractional Index</code> between 0 and 1, it should have been 0.5, but through random jitters, it could be <code dir="ltr">0.52712</code>, <code dir="ltr">0.58312</code>, <code dir="ltr">0.52834</code>, etc., thus significantly reducing the chance of same <code dir="ltr">Fractional Index</code> appearing.</li>
<li>If the situation arises where the same <code dir="ltr">Fractional Index</code> is present on both sides, we can handle this problem by resetting these <code dir="ltr">Fractional Index</code>. For example, if we need to insert a new node between <code dir="ltr">0.7@A</code> and <code dir="ltr">0.7@B</code> (which indicates <code dir="ltr">Fractional Index</code> @ <code dir="ltr">PeerID</code>), instead of generating a new <code dir="ltr">Fractional Index</code> between 0.7 and 0.7, we could assign two new <code dir="ltr">Fractional Index</code> respectively for the new node and the <code dir="ltr">0.7@B</code> node between 0.7 and 1, which could be understood as an extra move operations.</li>
</ol>
<p><img loading="lazy" width="2592" height="1354" decoding="async" data-nimg="1" srcset="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsame-FI-dark.79d4bd5a.png&amp;w=3840&amp;q=75 1x" src="https://loro.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsame-FI-dark.79d4bd5a.png&amp;w=3840&amp;q=75"></p>
<h3>Implementation and Encoding Size<a href="#implementation-and-encoding-size" id="implementation-and-encoding-size" aria-label="Permalink for this section"></a></h3>
<p>Introducing <code dir="ltr">Fractional Index</code> brings the advantage of node sequence. What about encoding size?</p>
<p>Loro uses <a href="https://github.com/drifting-in-space/fractional_index" target="_blank" rel="noreferrer">drifting-in-space<span> (opens in a new tab)</span></a> <code dir="ltr">Fractional Index</code> implementation based on <code dir="ltr">Vec&lt;u8&gt;</code>, which is base 256. In other words, you need to continuously insert 128 values forward or backward from the default value to increase the byte size of the <code dir="ltr">Fractional Index</code> by 1. The worst storage overhead case, such as inserting new values alternately each time. For example, the initial sequence is <code dir="ltr">ab</code>, insert <code dir="ltr">c</code> between <code dir="ltr">a</code> and <code dir="ltr">b</code>, then insert <code dir="ltr">d</code> between <code dir="ltr">c</code> and <code dir="ltr">b</code>, then <code dir="ltr">e</code> between <code dir="ltr">c</code> and <code dir="ltr">d</code>, like:</p>

<p>a new operation would cause an additional byte to be needed. But such a situation is very rare.</p>
<p>Considering that potential conflicts wouldn't appear frequently in most applications, Loro simply extended the implementation, the original implementation produced new <code dir="ltr">Fractional Index</code> in <code dir="ltr">Vec&lt;u8&gt;</code> by only increasing or decreasing 1 in certain index to achieve relative sorting. The simple jitter solution was added, by appending random bytes in length of jitter value to <code dir="ltr">Fractional Index</code>. To enable jitter in js, you can use <code dir="ltr">doc.setFractionalIndexJitter(number)</code> with a positive value. But this will increase the encoding size slightly, but each <code dir="ltr">Fractional Index</code> only adds <code dir="ltr">jitter</code> bytes. If you want to generate <code dir="ltr">Fractional Index</code> at the same position with 99% probability without conflict, the relationship between <code dir="ltr">jitter</code> settings and the maximum number of concurrent edits <code dir="ltr">n</code> will be:</p>
<table><thead><tr><th><p>jitter</p></th><th><p>max num of concurrent edits</p></th></tr></thead><tbody><tr><td><p>1</p></td><td><p>3</p></td></tr><tr><td><p>2</p></td><td><p>37</p></td></tr><tr><td><p>3</p></td><td><p>582</p></td></tr></tbody></table>
<p>When there are numerous <code dir="ltr">Fractional Indexes</code>, there will be many common prefixes after being sorted, when Loro encodes these <code dir="ltr">Fractional Indexes</code>, prefix optimization would be implemented. Each <code dir="ltr">Fractional Index</code> only saves the amount of same prefix bits and remaining bytes with the previous one, which further downsizes the overall encoding size.</p>
<h3>Related work<a href="#related-work" id="related-work" aria-label="Permalink for this section"></a></h3>
<p>Other than using Fractional Index, there are other movable list CRDT that can make sibling nodes of the tree in order. One of these algorithms is Martin Kleppmann's <a href="https://martin.kleppmann.com/2020/04/27/papoc-list-move.html" target="_blank" rel="noreferrer">Moving Elements in List CRDTs<span> (opens in a new tab)</span></a>, which has been used in Loro's <a href="https://www.loro.dev/docs/tutorial/list" target="_blank" rel="noreferrer">Movable List<span> (opens in a new tab)</span></a>.</p>
<p>In comparison, the implementation of <code dir="ltr">Fractional Index</code> solution is simpler, and no stable position representation is provided for child nodes when modeling nodes in a tree, otherwise, the overall tree structure would be too complex. However, the <code dir="ltr">Fractional Index</code> has the problem of <a href="https://vlcn.io/blog/fractional-indexing#interleaving" target="_blank" rel="noreferrer">interleaving<span> (opens in a new tab)</span></a>, but this is acceptable when some only need relative order and do not require strict sequential semantics, such as figma layer items, multi-level bookmarks, etc.</p>
<h2>Benchmark<a href="#benchmark" id="benchmark" aria-label="Permalink for this section"></a></h2>
<p>We conducted performance benchmarks on the Movable Tree implementation by Loro, including scenarios of random node movement, switching to historical versions, and performance under extreme conditions with significantly deep tree structures. The results indicate that it is capable of supporting real-time collaboration and enabling seamless historical version checkouts.</p>

<div><p>Test environment: M2 Max CPU, you can find the bench code
<a href="https://github.com/loro-dev/loro/blob/main/crates/loro-internal/benches/tree.rs" target="_blank" rel="noreferrer">here<span> (opens in a new tab)</span></a>.</p></div>
<h2>Usage<a href="#usage" id="usage" aria-label="Permalink for this section"></a></h2>

<h3>Demo<a href="#demo" id="demo" aria-label="Permalink for this section"></a></h3>
<p>We developed a simulated Todo app with data synchronization among multiple peers using Loro, including the use of <code dir="ltr">Movable Tree</code> to represent subtask relationships, <code dir="ltr">Map</code> to represent various attributes of tasks, and <code dir="ltr">Text</code> to represent task titles, etc. In addition to basic creation, moving, modification, and deletion, we also implemented version switching based on Loro. You can drag the scrollbar to switch between all the historical versions that have been operated on.</p>

<h2>Summary<a href="#summary" id="summary" aria-label="Permalink for this section"></a></h2>
<p>This article discusses why implementing Movable Tree CRDTs is difficult, and presents two innovative algorithms for movable trees.</p>
<p>For implementation, Loro has integrated <strong><em><a href="https://martin.kleppmann.com/2021/10/07/crdt-tree-move-operation.html" target="_blank" rel="noreferrer">A highly-available move operation for replicated trees<span> (opens in a new tab)</span></a></em></strong> to implement the hierarchical movement of the Tree, and integrated the <code dir="ltr">Fractional Index</code> implementation by <a href="https://github.com/drifting-in-space/fractional_index" target="_blank" rel="noreferrer">drifting-in-space<span> (opens in a new tab)</span></a> to achieve the movement between child nodes. This can meet the needs of various application scenarios.</p>
<p>If you are developing collaborative applications or are interested in CRDT algorithms, you are welcome to join <a href="https://discord.gg/tUsBSVfqzf" target="_blank" rel="noreferrer">our community<span> (opens in a new tab)</span></a>.</p></main></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The weird and wonderful world of DNS LOC records (105 pts)]]></title>
            <link>https://blog.cloudflare.com/the-weird-and-wonderful-world-of-dns-loc-records</link>
            <guid>41099567</guid>
            <pubDate>Mon, 29 Jul 2024 11:26:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/the-weird-and-wonderful-world-of-dns-loc-records">https://blog.cloudflare.com/the-weird-and-wonderful-world-of-dns-loc-records</a>, See on <a href="https://news.ycombinator.com/item?id=41099567">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>2014-04-01</p><section><p>5 min read</p><div><!--kg-card-begin: markdown--><p>A cornerstone of CloudFlare's infrastructure is our ability to serve DNS requests quickly and <a href="https://blog.cloudflare.com/deep-inside-a-dns-amplification-ddos-attack">handle DNS attacks</a>. To do both those things we wrote our own authoritative DNS server called <a href="https://blog.cloudflare.com/the-story-of-a-little-dns-easter-egg">RRDNS</a> in Go. Because of it we've been able to fight off DNS attacks, and be consistenly one of the <a href="https://blog.cloudflare.com/cloudflare-fastest-free-dns-among-fastest-dns">fastest</a> DNS providers on the web.</p>
<p>Implementing an authoritative DNS server is a large task. That's in part because DNS is a very old standard (<a href="http://www.ietf.org/rfc/rfc1035.txt">RFC 1035</a> dates to 1987), in part because as DNS has developed it has grown into a more and more complex system, and in part because what's written in the RFCs and what happens in the real-world aren't always the same thing.</p>
<p>One little used type of DNS record is the LOC (or location). It allows you to specify a physical location. CloudFlare handles millions of DNS records; of those just 743 are LOCs. Nevertheless, it's possible to set up a LOC record in the CloudFlare DNS editor.</p>
<p><img alt="Trinity" src="https://blog.cloudflare.com/content/images/480px-Trinity_Site_Obelisk_National_Historic_Landmark.jpg"></p>
<p>My site <a href="http://geekatlas.com/">geekatlas.com</a> has a LOC record as an Easter Egg. Here's how it's configured in the CloudFlare DNS settings:</p>
<p><img alt="LOC Example" src="https://blog.cloudflare.com/content/images/Screen_Shot_2014-03-27_at_11.34.24.png"></p>
<p>When you operate at CloudFlare scale the little-used nooks and crannies turn out to be important. And even though there are only 743 LOC records in our entire database, at least one customer contacted support to find out why their LOC record wasn't being served.</p>
<p>And that sent me into the RRDNS source code to find out why.</p>
<p>The answer was simple. Although RRDNS had code for receiving requests for LOC records, creating response packets containing LOC data, there was a missing link. The CloudFlare DNS server stores the LOC record as a string (such as the <code>33 40 31 N 106 28 29 W 10m</code> above) and no one had written the code to parse that and turn it into the internal format. Oops.</p>
<p>The textual LOC format and the binary, on-the-wire, format are described in <a href="https://tools.ietf.org/rfc/rfc1876.txt">RFC 1876</a> and it's one of many RFCs that updated the original 1987 standard. RFC 1876 is from 1996.</p>
<p>The textual format is fairly simple. Here's what the RFC says:</p>
<pre>The LOC record is expressed in a primary file in the following format:

owner TTL class LOC ( d1 [m1 [s1]] {"N"|"S"} d2 [m2 [s2]]
                           {"E"|"W"} alt["m"] [siz["m"] [hp["m"]
                           [vp["m"]]]] )

where:

   d1:     [0 .. 90]            (degrees latitude)
   d2:     [0 .. 180]           (degrees longitude)
   m1, m2: [0 .. 59]            (minutes latitude/longitude)
   s1, s2: [0 .. 59.999]        (seconds latitude/longitude)
   alt:    [-100000.00 .. 42849672.95] BY .01 (altitude in meters)
   siz, hp, vp: [0 .. 90000000.00] (size/precision in meters)

If omitted, minutes and seconds default to zero, size defaults to 1m,
horizontal precision defaults to 10000m, and vertical precision
defaults to 10m.  These defaults are chosen to represent typical
ZIP/postal code area sizes, since it is often easy to find
approximate geographical location by ZIP/postal code.
</pre>
<p>So, there are required latitude, longitude and altitude and three optional values for the size of the location and precision information. Pretty simple.</p>
<p>Then there's the on-the-wire format. Unlike a TXT record the LOC record data is parsed and turned into a fixed size binary format. Back to RFC 1876:</p>
<pre>   MSB                                           LSB
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
  0|        VERSION        |         SIZE          |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
  2|       HORIZ PRE       |       VERT PRE        |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
  4|                   LATITUDE                    |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
  6|                   LATITUDE                    |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
  8|                   LONGITUDE                   |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
 10|                   LONGITUDE                   |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
 12|                   ALTITUDE                    |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
 14|                   ALTITUDE                    |
   +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
</pre>
<p>So, 32 bits of latitude, longitude and altitude and then three 8 bit values for the size and precision. The latitude and longitude values have a pretty simple encoding that treats the 32 bits as an unsigned integer:</p>
<pre>The latitude of the center of the sphere described by the SIZE field, expressed as a 32-bit integer, most significant octet first (network standard byte order), in thousandths of a second of arc.  2^31 represents the equator; numbers above that are north latitude.
</pre>
<p>And the altitude can be below sea-level but still unsigned:</p>
<pre>The altitude of the center of the sphere described by the SIZE field, expressed as a 32-bit integer, most significant octet first (network standard byte order), in centimeters, from a base of 100,000m below the [WGS 84] reference spheroid used by GPS.
</pre>
<p>But the 8 bit values use a very special encoding that allows a wide range of approximate values to be packed into 8 bits and also be human-readable when dumped out in hex!</p>
<pre>The diameter of a sphere enclosing the described entity, in centimeters, expressed as a pair of four-bit unsigned integers, each ranging from zero to nine, with the most significant four bits representing the base and the second number representing the power of ten by which to multiply the base.  This allows sizes from 0e0 (&lt;1cm) to 9e9 (90,000km) to be expressed.  This representation was chosen such that the hexadecimal representation can be read by eye; 0x15 = 1e5.
</pre>
<p>For example, the value <code>0x12</code> means <code>1 * 10^2</code> or 100cm. <code>0x99</code> means <code>9 * 10^9</code> or 90,000,000m. The smallest value that can be represented is 1cm (it's <code>0x10</code>). So, in just 8 bits there's a range values from 1cm to larger than the diameter of Jupiter.</p>
<p>To fix this I wrote a parser for the LOC text record type (and associated tests). It can be found <a href="https://gist.github.com/jgrahamc/9807839">here</a>.</p>
<p>We've now rolled out the the fix and all the existing LOC records are being served by RRDNS. For example, my <code>geekatlas.com</code> LOC record can be queried like this:</p>
<pre>$ dig geekatlas.com LOC
; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; geekatlas.com LOC
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 2997
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:    
;geekatlas.com.         IN  LOC

;; ANSWER SECTION:
geekatlas.com.      299 IN  LOC 33 40 31.000 N 106 28 29.000 W 10.00m 1m 10000m 10m

;; Query time: 104 msec
;; SERVER: 192.168.14.1#53(192.168.14.1)
;; WHEN: Tue Apr  1 14:13:48 2014
;; MSG SIZE  rcvd: 59
</pre><p>m</p><!--kg-card-end: markdown--></div></section><div><p>We protect <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, help customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerate any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">ward off DDoS attacks</a>, keep <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/rrdns">RRDNS</a><a href="https://blog.cloudflare.com/tag/dns">DNS</a><a href="https://blog.cloudflare.com/tag/reliability">Reliability</a><a href="https://blog.cloudflare.com/tag/attacks">Attacks</a><a href="https://blog.cloudflare.com/tag/go">Go</a></article></div><div data-testid="related-posts-section"><p>Related posts</p><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-04-12T14:00:12.000+01:00">April 12, 2024  1:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/foundation-dns-launch"><h2>Improving authoritative DNS with the official release of Foundation DNS</h2></a><p data-testid="related-posts-article-excerpt">We are launching Foundation DNS – our new enterprise-grade authoritative DNS offering. As our new enterprise authoritative DNS offering, Foundation DNS was designed to enhance the reliability, security, flexibility, and analytics of our authoritative DNS service<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-03-07T14:00:36.000+00:00">March 07, 2024  2:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/advanced-dns-protection"><h2>Advanced DNS Protection: mitigating sophisticated DNS DDoS attacks</h2></a><p data-testid="related-posts-article-excerpt">We're proud to introduce the Advanced DNS Protection system, a robust defense mechanism designed to protect against the most sophisticated DNS-based DDoS attacks<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-02-29T14:00:57.000+00:00">February 29, 2024  2:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/remediating-new-dnssec-resource-exhaustion-vulnerabilities"><h2>Remediating new DNSSEC resource exhaustion vulnerabilities</h2></a><p data-testid="related-posts-article-excerpt">Cloudflare recently fixed two critical DNSSEC vulnerabilities: CVE-2023-50387 and CVE-2023-50868. Both of these vulnerabilities can exhaust computational resources of validating DNS resolvers. These vulnerabilities do not affect our Authoritative DNS or DNS firewall products<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-01-09T14:00:25.000+00:00">January 09, 2024  2:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/ddos-threat-report-2023-q4"><h2>DDoS threat report for 2023 Q4</h2></a><p data-testid="related-posts-article-excerpt">Welcome to the sixteenth edition of Cloudflare’s DDoS Threat Report. This edition covers DDoS trends and key findings for the fourth and final quarter of the year 2023, complete with a review of major trends throughout the year<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li><li></li></ul></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Tea-tasting, a Python package for the statistical analysis of A/B tests (131 pts)]]></title>
            <link>https://e10v.me/tea-tasting-analysis-of-experiments/</link>
            <guid>41099028</guid>
            <pubDate>Mon, 29 Jul 2024 09:10:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://e10v.me/tea-tasting-analysis-of-experiments/">https://e10v.me/tea-tasting-analysis-of-experiments/</a>, See on <a href="https://news.ycombinator.com/item?id=41099028">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p><small>Jul 29, 2024</small> <small><a href="https://e10v.me/tags/a-b-testing/">a/b testing</a></small> <small><a href="https://e10v.me/tags/statistics/">statistics</a></small> <small><a href="https://e10v.me/tags/tea-tasting/">tea-tasting</a></small> <small><a href="https://e10v.me/tags/python/">python</a></small></p><h2 id="intro">Intro&nbsp;<a aria-label="Anchor link for: intro" href="#intro">#</a></h2><p>I developed <strong>tea-tasting</strong>, a Python package for the statistical analysis of A/B tests featuring:</p><ul><li>Student's t-test, Bootstrap, variance reduction with CUPED, power analysis, and other statistical methods and approaches out of the box.</li><li>Support for a wide range of data backends, such as BigQuery, ClickHouse, PostgreSQL/GreenPlum, Snowflake, Spark, Pandas, and 20+ other backends supported by&nbsp;<a href="https://ibis-project.org/" rel="noopener" target="_blank">Ibis</a>.</li><li>Extensible API: define custom metrics and use statistical tests of your choice.</li><li>Convenient API for reducing manual work, and a framework for minimizing errors.</li><li>Detailed documentation.</li></ul><p>In this blog post, I explore each of these advantages of using <strong>tea-tasting</strong> in the analysis of experiments.</p><p>If you are eager to try it, check the <a href="https://tea-tasting.e10v.me/" rel="noopener" target="_blank">documentation</a>.</p><h2 id="statistical-methods">Statistical methods&nbsp;<a aria-label="Anchor link for: statistical-methods" href="#statistical-methods">#</a></h2><p><strong>tea-tasting</strong> includes statistical methods and techniques that cover most of what you might need in the analysis of experiments.</p><p>Analyze metric averages and proportions with the Student's t-test and the Z-test. Or use Bootstrap to analyze any other statistic of your choice. And there is a predefined method for the analysis of quantiles using Bootstrap. <strong>tea-tasting</strong>&nbsp;also detects mismatches in the sample ratios of different variants of an A/B test.</p><p><strong>tea-tasting</strong> applies <a href="https://alexdeng.github.io/public/files/kdd2018-dm.pdf" rel="noopener" target="_blank">delta method</a> for the analysis of ratios of averages. For example, average number of orders per average number of sessions, assuming that session is not a randomization unit.</p><p>Use pre-experiment data, metric forecasts, or other covariates to reduce variance and increase the sensitivity of an experiment. This approach is also known as <a href="https://exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf" rel="noopener" target="_blank">CUPED</a> or <a href="https://doordash.engineering/2020/06/08/improving-experimental-power-through-control-using-predictions-as-covariate-cupac/" rel="noopener" target="_blank">CUPAC</a>.</p><p>The calculation of confidence intervals for <em>percentage</em> change in Student's t-test and Z-test can be tricky. Just taking confidence interval for <em>absolute</em> change and dividing it by control average will produce a biased result. <strong>tea-tasting</strong> applies <a href="https://alexdeng.github.io/public/files/kdd2018-dm.pdf" rel="noopener" target="_blank">delta method</a> to calculate the correct interval.</p><p>Analyze statistical power for Student's t-test and Z-test. There are three possible options:</p><ul><li>Calculate the effect size, given statistical power and the total number of observations.</li><li>Calculate the total number of observations, given statistical power and the effect size.</li><li>Calculate statistical power, given the effect size and the total number of observations.</li></ul><p>Learn more in the detailed&nbsp;<a href="https://tea-tasting.e10v.me/user-guide/" rel="noopener" target="_blank">user guide</a>.</p><p>The roadmap includes:</p><ul><li>A/A tests and simulations to analyze power of any statistical test.</li><li>More statistical tests: <ul><li>Asymptotic and exact tests for frequency data.</li><li>Mann–Whitney U test.</li></ul></li></ul><p>You can define a <a href="https://tea-tasting.e10v.me/custom-metrics/" rel="noopener" target="_blank">custom metric</a> with a statistical test of your choice.</p><h2 id="data-backends">Data backends&nbsp;<a aria-label="Anchor link for: data-backends" href="#data-backends">#</a></h2><p>There are many different databases and engines for storing and processing experimental data. And in most cases it's not efficient to pull the detailed experimental data into a Python environment. Many statistical tests, such as the Student's t-test or the Z-test, require only aggregated data for analysis.</p><p>For example, if the raw experimental data are stored in ClickHouse, it's faster and more efficient to calculate counts, averages, variances, and covariances directly in ClickHouse rather than fetching granular data and performing aggregations in a Python environment.</p><p>Querying all the required statistics manually can be a daunting and error-prone task. For example, analysis of ratio metrics and variance reduction with CUPED require not only number of rows and variance, but also covariances. But don't worry—<strong>tea-tasting</strong>&nbsp;does all this work for you.</p><p><strong>tea-tasting</strong> accepts data either as a Pandas DataFrame or an Ibis Table.&nbsp;<a href="https://ibis-project.org/" rel="noopener" target="_blank">Ibis</a>&nbsp;is a Python package which serves as a DataFrame API to various data backends. It supports 20+ backends including BigQuery, ClickHouse, PostgreSQL/GreenPlum, Snowflake, and Spark. You can write an SQL query,&nbsp;<a href="https://ibis-project.org/how-to/extending/sql#backend.sql" rel="noopener" target="_blank">wrap</a>&nbsp;it as an Ibis Table, and pass it to&nbsp;<strong>tea-tasting</strong>.</p><p>Keep in mind that&nbsp;<strong>tea-tasting</strong>&nbsp;assumes that:</p><ul><li>Data is grouped by randomization units, such as individual users.</li><li>There is a column indicating variant of the A/B test (typically labeled as A, B, etc.).</li><li>All necessary columns for metric calculations (like the number of orders, revenue, etc.) are included in the table.</li></ul><p>Some statistical methods, like Bootstrap, require granular data for the analysis. In this case,&nbsp;<strong>tea-tasting</strong>&nbsp;fetches the detailed data as well.</p><p>Learn more in the guide on <a href="https://tea-tasting.e10v.me/data-backends/" rel="noopener" target="_blank">data backends</a>.</p><h2 id="convenient-api">Convenient API&nbsp;<a aria-label="Anchor link for: convenient-api" href="#convenient-api">#</a></h2><p>You can perform all the tasks listed above using just NumPy, SciPy, and Ibis. In fact, <strong>tea-tasting</strong> uses these packages under the hood. What <strong>tea-tasting</strong> offers on top is a convenient higher-level API.</p><p>It's easier to show than to describe. Here is the basic example:</p><pre data-lang="python"><code data-lang="python"><span>import </span><span>tea_tasting </span><span>as </span><span>tt
</span><span>
</span><span>
</span><span>data = tt.</span><span>make_users_data</span><span>(</span><span>seed</span><span>=</span><span>42</span><span>)
</span><span>
</span><span>experiment = tt.</span><span>Experiment</span><span>(
</span><span>    </span><span>sessions_per_user</span><span>=tt.</span><span>Mean</span><span>("</span><span>sessions</span><span>"),
</span><span>    </span><span>orders_per_session</span><span>=tt.</span><span>RatioOfMeans</span><span>("</span><span>orders</span><span>", "</span><span>sessions</span><span>"),
</span><span>    </span><span>orders_per_user</span><span>=tt.</span><span>Mean</span><span>("</span><span>orders</span><span>"),
</span><span>    </span><span>revenue_per_user</span><span>=tt.</span><span>Mean</span><span>("</span><span>revenue</span><span>"),
</span><span>)
</span><span>
</span><span>result = experiment.</span><span>analyze</span><span>(data)
</span><span>print</span><span>(result)
</span><span>#&gt;             metric control treatment rel_effect_size rel_effect_size_ci pvalue
</span><span>#&gt;  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674
</span><span>#&gt; orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762
</span><span>#&gt;    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118
</span><span>#&gt;   revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123
</span></code></pre><p>The two-stage approach, with separate parametrization and inference, is common in statistical modeling. This separation helps in making the code more modular and easier to understand.</p><p><strong>tea-tasting</strong> performs calculations that can be tricky and error-prone:</p><ul><li>Analysis of ratio metrics with delta method.</li><li>Variance reduction with CUPED/CUPAC&nbsp;(also in combination with the delta method for ratio metrics).</li><li>Calculation of confidence intervals for both absolute and percentage change.</li><li>Analysis of statistical power.</li></ul><p>It also provides a framework for representing experimental data to avoid errors. Grouping the data by randomization units and including all units in the dataset is important for correct analysis.</p><p>In addition, <strong>tea-tasting</strong> provides some convenience methods and functions, such as pretty formatting of the result and a context manager for metric parameters.</p><h2 id="documentation">Documentation&nbsp;<a aria-label="Anchor link for: documentation" href="#documentation">#</a></h2><p>Last but not least: documentation. I believe that good documentation is crucial for tool adoption. That's why I wrote several user guides and an API reference.</p><p>I recommend starting with the example of basic usage in the <a href="https://tea-tasting.e10v.me/user-guide/" rel="noopener" target="_blank">user guide</a>. Then you can explore specific topics, such as variance reduction or power analysis, in the same guide.</p><p>See the guide on <a href="https://tea-tasting.e10v.me/data-backends/" rel="noopener" target="_blank">data backends</a> to learn how to use a data backend of your choice with <strong>tea-tasting</strong>.</p><p>See the guide on <a href="https://tea-tasting.e10v.me/custom-metrics/" rel="noopener" target="_blank">custom metrics</a> if you want to perform statistical test that is not included in <strong>tea-tasting</strong>.</p><p>Use the <a href="https://tea-tasting.e10v.me/api/" rel="noopener" target="_blank">API reference</a> to explore all parameters and detailed information about the functions, classes, and methods available in <strong>tea-tasting</strong>.</p><h2 id="conclusions">Conclusions&nbsp;<a aria-label="Anchor link for: conclusions" href="#conclusions">#</a></h2><p>There are a variety of statistical methods that can be applied in the analysis of an experiment. But only a handful of them are actually used in most cases.</p><p>On the other hand, there are methods specific to the analysis of A/B tests that are not included in the general purpose statistical packages like SciPy.</p><p><strong>tea-tasting</strong> functionality includes the most important statistical tests, as well as methods specific to the analysis of A/B tests.</p><p><strong>tea-tasting</strong> provides a convenient API that helps to reduce the time spent on analysis and minimize the probability of error.</p><p>In addition, <strong>tea-tasting</strong> optimizes computational efficiency by calculating the statistics in the data backend of your choice, where the data are stored.</p><p>With the detailed <a href="https://tea-tasting.e10v.me/" rel="noopener" target="_blank">documentation</a>, you can quickly learn how to use <strong>tea-tasting</strong> for the analysis of your experiments.</p><h2 id="p-s-package-name">P.S. Package name&nbsp;<a aria-label="Anchor link for: p-s-package-name" href="#p-s-package-name">#</a></h2><p>The package name "tea-tasting" is a play on words that refers to two subjects:</p><ul><li><a href="https://en.wikipedia.org/wiki/Lady_tasting_tea" rel="noopener" target="_blank">Lady tasting tea</a> is a famous experiment which was devised by Ronald Fisher. In this experiment, Fisher developed the null hypothesis significance testing framework to analyze a lady's claim that she could discern whether the tea or the milk was added first to the cup.</li><li>"tea-tasting" phonetically resembles "t-testing" or Student's t-test, a statistical test developed by William Gosset.</li></ul><p>© Evgeny Ivanov 2024</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MeTube: Self-hosted YouTube downloader (257 pts)]]></title>
            <link>https://github.com/alexta69/metube</link>
            <guid>41098974</guid>
            <pubDate>Mon, 29 Jul 2024 08:59:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alexta69/metube">https://github.com/alexta69/metube</a>, See on <a href="https://news.ycombinator.com/item?id=41098974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">MeTube</h2><a id="user-content-metube" aria-label="Permalink: MeTube" href="#metube"></a></p>
<blockquote>
<p dir="auto"><strong><em>NOTE:</em></strong>  32-bit ARM builds have been retired (a full year after <a href="https://www.linuxserver.io/blog/a-farewell-to-arm-hf" rel="nofollow">other major players</a>), as new Node versions don't support them, and continued security updates and dependencies require new Node versions. Please migrate to a 64-bit OS to continue receiving MeTube upgrades.</p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alexta69/metube/actions/workflows/main.yml/badge.svg"><img src="https://github.com/alexta69/metube/actions/workflows/main.yml/badge.svg" alt="Build Status"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6708f289d99a1b880e35d3f4050b19fb27031c6adc1dab32e625809a32191670/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f616c6578746136392f6d65747562652e737667"><img src="https://camo.githubusercontent.com/6708f289d99a1b880e35d3f4050b19fb27031c6adc1dab32e625809a32191670/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f616c6578746136392f6d65747562652e737667" alt="Docker Pulls" data-canonical-src="https://img.shields.io/docker/pulls/alexta69/metube.svg"></a></p>
<p dir="auto">Web GUI for youtube-dl (using the <a href="https://github.com/yt-dlp/yt-dlp">yt-dlp</a> fork) with playlist support. Allows you to download videos from YouTube and <a href="https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md">dozens of other sites</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alexta69/metube/raw/master/screenshot.gif"><img src="https://github.com/alexta69/metube/raw/master/screenshot.gif" alt="screenshot1" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run using Docker</h2><a id="user-content-run-using-docker" aria-label="Permalink: Run using Docker" href="#run-using-docker"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -d -p 8081:8081 -v /path/to/downloads:/downloads ghcr.io/alexta69/metube"><pre>docker run -d -p 8081:8081 -v /path/to/downloads:/downloads ghcr.io/alexta69/metube</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run using docker-compose</h2><a id="user-content-run-using-docker-compose" aria-label="Permalink: Run using docker-compose" href="#run-using-docker-compose"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="version: &quot;3&quot;
services:
  metube:
    image: ghcr.io/alexta69/metube
    container_name: metube
    restart: unless-stopped
    ports:
      - &quot;8081:8081&quot;
    volumes:
      - /path/to/downloads:/downloads"><pre><span>version</span>: <span><span>"</span>3<span>"</span></span>
<span>services</span>:
  <span>metube</span>:
    <span>image</span>: <span>ghcr.io/alexta69/metube</span>
    <span>container_name</span>: <span>metube</span>
    <span>restart</span>: <span>unless-stopped</span>
    <span>ports</span>:
      - <span><span>"</span>8081:8081<span>"</span></span>
    <span>volumes</span>:
      - <span>/path/to/downloads:/downloads</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration via environment variables</h2><a id="user-content-configuration-via-environment-variables" aria-label="Permalink: Configuration via environment variables" href="#configuration-via-environment-variables"></a></p>
<p dir="auto">Certain values can be set via environment variables, using the <code>-e</code> parameter on the docker command line, or the <code>environment:</code> section in docker-compose.</p>
<ul dir="auto">
<li><strong>UID</strong>: user under which MeTube will run. Defaults to <code>1000</code>.</li>
<li><strong>GID</strong>: group under which MeTube will run. Defaults to <code>1000</code>.</li>
<li><strong>UMASK</strong>: umask value used by MeTube. Defaults to <code>022</code>.</li>
<li><strong>DEFAULT_THEME</strong>: default theme to use for the ui, can be set to <code>light</code>, <code>dark</code> or <code>auto</code>. Defaults to <code>auto</code>.</li>
<li><strong>DOWNLOAD_DIR</strong>: path to where the downloads will be saved. Defaults to <code>/downloads</code> in the docker image, and <code>.</code> otherwise.</li>
<li><strong>AUDIO_DOWNLOAD_DIR</strong>: path to where audio-only downloads will be saved, if you wish to separate them from the video downloads. Defaults to the value of <code>DOWNLOAD_DIR</code>.</li>
<li><strong>DOWNLOAD_DIRS_INDEXABLE</strong>: if <code>true</code>, the download dirs (<strong>DOWNLOAD_DIR</strong> and <strong>AUDIO_DOWNLOAD_DIR</strong>) are indexable on the webserver. Defaults to <code>false</code>.</li>
<li><strong>CUSTOM_DIRS</strong>: whether to enable downloading videos into custom directories within the <strong>DOWNLOAD_DIR</strong> (or <strong>AUDIO_DOWNLOAD_DIR</strong>). When enabled, a drop-down appears next to the Add button to specify the download directory. Defaults to <code>true</code>.</li>
<li><strong>CREATE_CUSTOM_DIRS</strong>: whether to support automatically creating directories within the <strong>DOWNLOAD_DIR</strong> (or <strong>AUDIO_DOWNLOAD_DIR</strong>) if they do not exist. When enabled, the download directory selector becomes supports free-text input, and the specified directory will be created recursively. Defaults to <code>true</code>.</li>
<li><strong>STATE_DIR</strong>: path to where the queue persistence files will be saved. Defaults to <code>/downloads/.metube</code> in the docker image, and <code>.</code> otherwise.</li>
<li><strong>TEMP_DIR</strong>: path where intermediary download files will be saved. Defaults to <code>/downloads</code> in the docker image, and <code>.</code> otherwise.
<ul dir="auto">
<li>Set this to an SSD or RAM filesystem (e.g., <code>tmpfs</code>) for better performance</li>
<li><strong>Note</strong>: Using a RAM filesystem may prevent downloads from being resumed</li>
</ul>
</li>
<li><strong>DELETE_FILE_ON_TRASHCAN</strong>: if <code>true</code>, downloaded files are deleted on the server, when they are trashed from the "Completed" section of the UI. Defaults to <code>false</code>.</li>
<li><strong>URL_PREFIX</strong>: base path for the web server (for use when hosting behind a reverse proxy). Defaults to <code>/</code>.</li>
<li><strong>PUBLIC_HOST_URL</strong>: base URL for the download links shown in the UI for completed files. By default MeTube serves them under its own URL. If your download directory is accessible on another URL and you want the download links to be based there, use this variable to set it.</li>
<li><strong>PUBLIC_HOST_AUDIO_URL</strong>: same as PUBLIC_HOST_URL but for audio downloads.</li>
<li><strong>OUTPUT_TEMPLATE</strong>: the template for the filenames of the downloaded videos, formatted according to <a href="https://github.com/yt-dlp/yt-dlp/blob/master/README.md#output-template">this spec</a>. Defaults to <code>%(title)s.%(ext)s</code>.</li>
<li><strong>OUTPUT_TEMPLATE_CHAPTER</strong>: the template for the filenames of the downloaded videos, when split into chapters via postprocessors. Defaults to <code>%(title)s - %(section_number)s %(section_title)s.%(ext)s</code>.</li>
<li><strong>YTDL_OPTIONS</strong>: Additional options to pass to youtube-dl, in JSON format. <a href="https://github.com/yt-dlp/yt-dlp/blob/master/yt_dlp/YoutubeDL.py#L183">See available options here</a>. They roughly correspond to command-line options, though some do not have exact equivalents here, for example <code>--recode-video</code> has to be specified via <code>postprocessors</code>. Also note that dashes are replaced with underscores.</li>
<li><strong>YTDL_OPTIONS_FILE</strong>: A path to a JSON file that will be loaded and used for populating <code>YTDL_OPTIONS</code> above. Please note that if both <code>YTDL_OPTIONS_FILE</code> and <code>YTDL_OPTIONS</code> are specified, the options in <code>YTDL_OPTIONS</code> take precedence.</li>
</ul>
<p dir="auto">The following example value for <code>YTDL_OPTIONS</code> embeds English subtitles and chapter markers (for videos that have them), and also changes the permissions on the downloaded video and sets the file modification timestamp to the date of when it was downloaded:</p>
<div dir="auto" data-snippet-clipboard-copy-content="    environment:
      - 'YTDL_OPTIONS={&quot;writesubtitles&quot;:true,&quot;subtitleslangs&quot;:[&quot;en&quot;,&quot;-live_chat&quot;],&quot;updatetime&quot;:false,&quot;postprocessors&quot;:[{&quot;key&quot;:&quot;Exec&quot;,&quot;exec_cmd&quot;:&quot;chmod 0664&quot;,&quot;when&quot;:&quot;after_move&quot;},{&quot;key&quot;:&quot;FFmpegEmbedSubtitle&quot;,&quot;already_have_subtitle&quot;:false},{&quot;key&quot;:&quot;FFmpegMetadata&quot;,&quot;add_chapters&quot;:true}]}'"><pre>    <span>environment</span>:
      - <span><span>'</span>YTDL_OPTIONS={"writesubtitles":true,"subtitleslangs":["en","-live_chat"],"updatetime":false,"postprocessors":[{"key":"Exec","exec_cmd":"chmod 0664","when":"after_move"},{"key":"FFmpegEmbedSubtitle","already_have_subtitle":false},{"key":"FFmpegMetadata","add_chapters":true}]}<span>'</span></span></pre></div>
<p dir="auto">The following example value for <code>OUTPUT_TEMPLATE</code> sets:</p>
<ul dir="auto">
<li>playlist name and author, if present</li>
<li>playlist number and count, if present (zero-padded, if needed)</li>
<li>video author, title and release date in YYYY-MM-DD format, falling back to <em>UNKNOWN_...</em> if missing</li>
<li>sanitises everything for valid UNIX filename</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="    environment:
      - 'OUTPUT_TEMPLATE=%(playlist_title&amp;Playlist |)S%(playlist_title|)S%(playlist_uploader&amp; by |)S%(playlist_uploader|)S%(playlist_autonumber&amp; - |)S%(playlist_autonumber|)S%(playlist_count&amp; of |)S%(playlist_count|)S%(playlist_autonumber&amp; - |)S%(uploader,creator|UNKNOWN_AUTHOR)S - %(title|UNKNOWN_TITLE)S - %(release_date>%Y-%m-%d,upload_date>%Y-%m-%d|UNKNOWN_DATE)S.%(ext)s'"><pre>    <span>environment</span>:
      - <span><span>'</span>OUTPUT_TEMPLATE=%(playlist_title&amp;Playlist |)S%(playlist_title|)S%(playlist_uploader&amp; by |)S%(playlist_uploader|)S%(playlist_autonumber&amp; - |)S%(playlist_autonumber|)S%(playlist_count&amp; of |)S%(playlist_count|)S%(playlist_autonumber&amp; - |)S%(uploader,creator|UNKNOWN_AUTHOR)S - %(title|UNKNOWN_TITLE)S - %(release_date&gt;%Y-%m-%d,upload_date&gt;%Y-%m-%d|UNKNOWN_DATE)S.%(ext)s<span>'</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using browser cookies</h2><a id="user-content-using-browser-cookies" aria-label="Permalink: Using browser cookies" href="#using-browser-cookies"></a></p>
<p dir="auto">In case you need to use your browser's cookies with MeTube, for example to download restricted or private videos:</p>
<ul dir="auto">
<li>Add the following to your docker-compose.yml:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="    volumes:
      - /path/to/cookies:/cookies
    environment:
      - YTDL_OPTIONS={&quot;cookiefile&quot;:&quot;/cookies/cookies.txt&quot;}"><pre>    <span>volumes</span>:
      - <span>/path/to/cookies:/cookies</span>
    <span>environment</span>:
      - <span>YTDL_OPTIONS={"cookiefile":"/cookies/cookies.txt"}</span></pre></div>
<ul dir="auto">
<li>Install in your browser an extension to extract cookies:
<ul dir="auto">
<li><a href="https://addons.mozilla.org/en-US/firefox/addon/export-cookies-txt/" rel="nofollow">Firefox</a></li>
<li><a href="https://chrome.google.com/webstore/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc" rel="nofollow">Chrome</a></li>
</ul>
</li>
<li>Extract the cookies you need with the extension and rename the file <code>cookies.txt</code></li>
<li>Drop the file in the folder you configured in the docker-compose.yml above</li>
<li>Restart the container</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Browser extensions</h2><a id="user-content-browser-extensions" aria-label="Permalink: Browser extensions" href="#browser-extensions"></a></p>
<p dir="auto">Browser extensions allow right-clicking videos and sending them directly to MeTube. Please note that if you're on an HTTPS page, your MeTube instance must be behind an HTTPS reverse proxy (see below) for the extensions to work.</p>
<p dir="auto"><strong>Chrome:</strong> contributed by <a href="https://github.com/rpsl">Rpsl</a>. You can install it from <a href="https://chrome.google.com/webstore/detail/metube-downloader/fbmkmdnlhacefjljljlbhkodfmfkijdh" rel="nofollow">Google Chrome Webstore</a> or use developer mode and install <a href="https://github.com/Rpsl/metube-browser-extension">from sources</a>.</p>
<p dir="auto"><strong>Firefox:</strong> contributed by <a href="https://github.com/nanocortex">nanocortex</a>. You can install it from <a href="https://addons.mozilla.org/en-US/firefox/addon/metube-downloader" rel="nofollow">Firefox Addons</a> or get sources from <a href="https://github.com/nanocortex/metube-firefox-addon">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">iOS Shortcut</h2><a id="user-content-ios-shortcut" aria-label="Permalink: iOS Shortcut" href="#ios-shortcut"></a></p>
<p dir="auto"><a href="https://github.com/rithask">rithask</a> has created an iOS shortcut to send the URL to MeTube from Safari. Initially, you'll need to enter the server address and port, but after that, it will be saved and you can just run the shortcut from the share menu in Safari. The address should include the protocol (http/https) and the port, if it's not the default 80/443. For example: <code>https://metube.example.com</code> or <code>http://192.168.1.1:8081</code>. The shortcut can be found <a href="https://www.icloud.com/shortcuts/f1548df15b734418a77a709103bc1dd5" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">iOS Compatibility</h2><a id="user-content-ios-compatibility" aria-label="Permalink: iOS Compatibility" href="#ios-compatibility"></a></p>
<p dir="auto">iOS has strict requirements for video files, requiring h264 or h265 video codec and aac audio codec in MP4 container. This can sometimes be a lower quality than the best quality available. To accommodate iOS requirements, when downloading a MP4 format you can choose "Best (iOS)" to get the best quality formats as compatible as possible with iOS requirements.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bookmarklet</h2><a id="user-content-bookmarklet" aria-label="Permalink: Bookmarklet" href="#bookmarklet"></a></p>
<p dir="auto"><a href="https://github.com/kushfest">kushfest</a> has created a Chrome bookmarklet for sending the currently open webpage to MeTube. Please note that if you're on an HTTPS page, your MeTube instance must be behind an HTTPS reverse proxy (see below) for the bookmarklet to work.</p>
<p dir="auto">GitHub doesn't allow embedding JavaScript as a link, so the bookmarklet has to be created manually by copying the following code to a new bookmark you create on your bookmarks bar. Change the hostname in the URL below to point to your MeTube instance.</p>
<div dir="auto" data-snippet-clipboard-copy-content="javascript:!function(){xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.withCredentials=true;xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function(){if(xhr.status==200){alert(&quot;Sent to metube!&quot;)}else{alert(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}}();"><pre>javascript:<span>!</span><span>function</span><span>(</span><span>)</span><span>{</span><span>xhr</span><span>=</span><span>new</span> <span>XMLHttpRequest</span><span>(</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>open</span><span>(</span><span>"POST"</span><span>,</span><span>"https://metube.domain.com/add"</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>withCredentials</span><span>=</span><span>true</span><span>;</span><span>xhr</span><span>.</span><span>send</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span>"url"</span>:<span>document</span><span>.</span><span>location</span><span>.</span><span>href</span><span>,</span><span>"quality"</span>:<span>"best"</span><span>}</span><span>)</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>onload</span><span>=</span><span>function</span><span>(</span><span>)</span><span>{</span><span>if</span><span>(</span><span>xhr</span><span>.</span><span>status</span><span>==</span><span>200</span><span>)</span><span>{</span><span>alert</span><span>(</span><span>"Sent to metube!"</span><span>)</span><span>}</span><span>else</span><span>{</span><span>alert</span><span>(</span><span>"Send to metube failed. Check the javascript console for clues."</span><span>)</span><span>}</span><span>}</span><span>}</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><a href="https://github.com/shoonya75">shoonya75</a> has contributed a Firefox version:</p>
<div dir="auto" data-snippet-clipboard-copy-content="javascript:(function(){xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function(){if(xhr.status==200){alert(&quot;Sent to metube!&quot;)}else{alert(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}})();"><pre>javascript:<span>(</span><span>function</span><span>(</span><span>)</span><span>{</span><span>xhr</span><span>=</span><span>new</span> <span>XMLHttpRequest</span><span>(</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>open</span><span>(</span><span>"POST"</span><span>,</span><span>"https://metube.domain.com/add"</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>send</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span>"url"</span>:<span>document</span><span>.</span><span>location</span><span>.</span><span>href</span><span>,</span><span>"quality"</span>:<span>"best"</span><span>}</span><span>)</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>onload</span><span>=</span><span>function</span><span>(</span><span>)</span><span>{</span><span>if</span><span>(</span><span>xhr</span><span>.</span><span>status</span><span>==</span><span>200</span><span>)</span><span>{</span><span>alert</span><span>(</span><span>"Sent to metube!"</span><span>)</span><span>}</span><span>else</span><span>{</span><span>alert</span><span>(</span><span>"Send to metube failed. Check the javascript console for clues."</span><span>)</span><span>}</span><span>}</span><span>}</span><span>)</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The above bookmarklets use <code>alert()</code> as a success/failure notification. The following will show a toast message instead:</p>
<p dir="auto">Chrome:</p>
<div dir="auto" data-snippet-clipboard-copy-content="javascript:!function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement('span');text.innerHTML=msg;var ts = text.style;ts.all = 'revert';ts.color = '#000';ts.fontFamily = 'Verdana, sans-serif';ts.fontSize = '15px';ts.backgroundColor = 'white';ts.padding = '15px';ts.border = '1px solid gainsboro';ts.boxShadow = '3px 3px 10px';ts.zIndex = '100';document.body.appendChild(text);ts.position = 'absolute'; ts.top = 50 + sc + 'px'; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + 'px'; setTimeout(function () { text.style.visibility = &quot;hidden&quot;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function() { if(xhr.status==200){notify(&quot;Sent to metube!&quot;)}else {notify(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}}();"><pre>javascript:<span>!</span><span>function</span><span>(</span><span>)</span><span>{</span><span>function</span> <span>notify</span><span>(</span><span>msg</span><span>)</span> <span>{</span><span>var</span> <span>sc</span> <span>=</span> <span>document</span><span>.</span><span>scrollingElement</span><span>.</span><span>scrollTop</span><span>;</span> <span>var</span> <span>text</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'span'</span><span>)</span><span>;</span><span>text</span><span>.</span><span>innerHTML</span><span>=</span><span>msg</span><span>;</span><span>var</span> <span>ts</span> <span>=</span> <span>text</span><span>.</span><span>style</span><span>;</span><span>ts</span><span>.</span><span>all</span> <span>=</span> <span>'revert'</span><span>;</span><span>ts</span><span>.</span><span>color</span> <span>=</span> <span>'#000'</span><span>;</span><span>ts</span><span>.</span><span>fontFamily</span> <span>=</span> <span>'Verdana, sans-serif'</span><span>;</span><span>ts</span><span>.</span><span>fontSize</span> <span>=</span> <span>'15px'</span><span>;</span><span>ts</span><span>.</span><span>backgroundColor</span> <span>=</span> <span>'white'</span><span>;</span><span>ts</span><span>.</span><span>padding</span> <span>=</span> <span>'15px'</span><span>;</span><span>ts</span><span>.</span><span>border</span> <span>=</span> <span>'1px solid gainsboro'</span><span>;</span><span>ts</span><span>.</span><span>boxShadow</span> <span>=</span> <span>'3px 3px 10px'</span><span>;</span><span>ts</span><span>.</span><span>zIndex</span> <span>=</span> <span>'100'</span><span>;</span><span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>text</span><span>)</span><span>;</span><span>ts</span><span>.</span><span>position</span> <span>=</span> <span>'absolute'</span><span>;</span> <span>ts</span><span>.</span><span>top</span> <span>=</span> <span>50</span> <span>+</span> <span>sc</span> <span>+</span> <span>'px'</span><span>;</span> <span>ts</span><span>.</span><span>left</span> <span>=</span> <span>(</span><span>window</span><span>.</span><span>innerWidth</span> <span>/</span> <span>2</span><span>)</span><span>-</span><span>(</span><span>text</span><span>.</span><span>offsetWidth</span> <span>/</span> <span>2</span><span>)</span> <span>+</span> <span>'px'</span><span>;</span> <span>setTimeout</span><span>(</span><span>function</span> <span>(</span><span>)</span> <span>{</span> <span>text</span><span>.</span><span>style</span><span>.</span><span>visibility</span> <span>=</span> <span>"hidden"</span><span>;</span> <span>}</span><span>,</span> <span>1500</span><span>)</span><span>;</span><span>}</span><span>xhr</span><span>=</span><span>new</span> <span>XMLHttpRequest</span><span>(</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>open</span><span>(</span><span>"POST"</span><span>,</span><span>"https://metube.domain.com/add"</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>send</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span>"url"</span>:<span>document</span><span>.</span><span>location</span><span>.</span><span>href</span><span>,</span><span>"quality"</span>:<span>"best"</span><span>}</span><span>)</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>onload</span><span>=</span><span>function</span><span>(</span><span>)</span> <span>{</span> <span>if</span><span>(</span><span>xhr</span><span>.</span><span>status</span><span>==</span><span>200</span><span>)</span><span>{</span><span>notify</span><span>(</span><span>"Sent to metube!"</span><span>)</span><span>}</span><span>else</span> <span>{</span><span>notify</span><span>(</span><span>"Send to metube failed. Check the javascript console for clues."</span><span>)</span><span>}</span><span>}</span><span>}</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Firefox:</p>
<div dir="auto" data-snippet-clipboard-copy-content="javascript:(function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement('span');text.innerHTML=msg;var ts = text.style;ts.all = 'revert';ts.color = '#000';ts.fontFamily = 'Verdana, sans-serif';ts.fontSize = '15px';ts.backgroundColor = 'white';ts.padding = '15px';ts.border = '1px solid gainsboro';ts.boxShadow = '3px 3px 10px';ts.zIndex = '100';document.body.appendChild(text);ts.position = 'absolute'; ts.top = 50 + sc + 'px'; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + 'px'; setTimeout(function () { text.style.visibility = &quot;hidden&quot;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function() { if(xhr.status==200){notify(&quot;Sent to metube!&quot;)}else {notify(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}})();"><pre>javascript:<span>(</span><span>function</span><span>(</span><span>)</span><span>{</span><span>function</span> <span>notify</span><span>(</span><span>msg</span><span>)</span> <span>{</span><span>var</span> <span>sc</span> <span>=</span> <span>document</span><span>.</span><span>scrollingElement</span><span>.</span><span>scrollTop</span><span>;</span> <span>var</span> <span>text</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'span'</span><span>)</span><span>;</span><span>text</span><span>.</span><span>innerHTML</span><span>=</span><span>msg</span><span>;</span><span>var</span> <span>ts</span> <span>=</span> <span>text</span><span>.</span><span>style</span><span>;</span><span>ts</span><span>.</span><span>all</span> <span>=</span> <span>'revert'</span><span>;</span><span>ts</span><span>.</span><span>color</span> <span>=</span> <span>'#000'</span><span>;</span><span>ts</span><span>.</span><span>fontFamily</span> <span>=</span> <span>'Verdana, sans-serif'</span><span>;</span><span>ts</span><span>.</span><span>fontSize</span> <span>=</span> <span>'15px'</span><span>;</span><span>ts</span><span>.</span><span>backgroundColor</span> <span>=</span> <span>'white'</span><span>;</span><span>ts</span><span>.</span><span>padding</span> <span>=</span> <span>'15px'</span><span>;</span><span>ts</span><span>.</span><span>border</span> <span>=</span> <span>'1px solid gainsboro'</span><span>;</span><span>ts</span><span>.</span><span>boxShadow</span> <span>=</span> <span>'3px 3px 10px'</span><span>;</span><span>ts</span><span>.</span><span>zIndex</span> <span>=</span> <span>'100'</span><span>;</span><span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>text</span><span>)</span><span>;</span><span>ts</span><span>.</span><span>position</span> <span>=</span> <span>'absolute'</span><span>;</span> <span>ts</span><span>.</span><span>top</span> <span>=</span> <span>50</span> <span>+</span> <span>sc</span> <span>+</span> <span>'px'</span><span>;</span> <span>ts</span><span>.</span><span>left</span> <span>=</span> <span>(</span><span>window</span><span>.</span><span>innerWidth</span> <span>/</span> <span>2</span><span>)</span><span>-</span><span>(</span><span>text</span><span>.</span><span>offsetWidth</span> <span>/</span> <span>2</span><span>)</span> <span>+</span> <span>'px'</span><span>;</span> <span>setTimeout</span><span>(</span><span>function</span> <span>(</span><span>)</span> <span>{</span> <span>text</span><span>.</span><span>style</span><span>.</span><span>visibility</span> <span>=</span> <span>"hidden"</span><span>;</span> <span>}</span><span>,</span> <span>1500</span><span>)</span><span>;</span><span>}</span><span>xhr</span><span>=</span><span>new</span> <span>XMLHttpRequest</span><span>(</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>open</span><span>(</span><span>"POST"</span><span>,</span><span>"https://metube.domain.com/add"</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>send</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span>"url"</span>:<span>document</span><span>.</span><span>location</span><span>.</span><span>href</span><span>,</span><span>"quality"</span>:<span>"best"</span><span>}</span><span>)</span><span>)</span><span>;</span><span>xhr</span><span>.</span><span>onload</span><span>=</span><span>function</span><span>(</span><span>)</span> <span>{</span> <span>if</span><span>(</span><span>xhr</span><span>.</span><span>status</span><span>==</span><span>200</span><span>)</span><span>{</span><span>notify</span><span>(</span><span>"Sent to metube!"</span><span>)</span><span>}</span><span>else</span> <span>{</span><span>notify</span><span>(</span><span>"Send to metube failed. Check the javascript console for clues."</span><span>)</span><span>}</span><span>}</span><span>}</span><span>)</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running behind a reverse proxy</h2><a id="user-content-running-behind-a-reverse-proxy" aria-label="Permalink: Running behind a reverse proxy" href="#running-behind-a-reverse-proxy"></a></p>
<p dir="auto">It's advisable to run MeTube behind a reverse proxy, if authentication and/or HTTPS support are required.</p>
<p dir="auto">When running behind a reverse proxy which remaps the URL (i.e. serves MeTube under a subdirectory and not under root), don't forget to set the URL_PREFIX environment variable to the correct value.</p>
<p dir="auto">If you're using the <a href="https://docs.linuxserver.io/general/swag" rel="nofollow">linuxserver/swag</a> image for your reverse proxying needs (which I can heartily recommend), it already includes ready snippets for proxying MeTube both in <a href="https://github.com/linuxserver/reverse-proxy-confs/blob/master/metube.subfolder.conf.sample">subfolder</a> and <a href="https://github.com/linuxserver/reverse-proxy-confs/blob/master/metube.subdomain.conf.sample">subdomain</a> modes under the <code>nginx/proxy-confs</code> directory in the configuration volume. It also includes Authelia which can be used for authentication.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">NGINX</h3><a id="user-content-nginx" aria-label="Permalink: NGINX" href="#nginx"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="location /metube/ {
        proxy_pass http://metube:8081;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection &quot;upgrade&quot;;
        proxy_set_header Host $host;
}"><pre><span>location</span> <span>/metube/ </span>{
        <span>proxy_pass</span> http://metube:8081;
        <span>proxy_http_version</span> <span>1.1</span>;
        <span>proxy_set_header</span> Upgrade <span>$http_upgrade</span>;
        <span>proxy_set_header</span> Connection <span>"upgrade"</span>;
        <span>proxy_set_header</span> Host <span>$host</span>;
}</pre></div>
<p dir="auto">Note: the extra <code>proxy_set_header</code> directives are there to make WebSocket work.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Apache</h3><a id="user-content-apache" aria-label="Permalink: Apache" href="#apache"></a></p>
<p dir="auto">Contributed by <a href="https://github.com/PIE-yt">PIE-yt</a>. Source <a href="https://gist.github.com/PIE-yt/29e7116588379032427f5bd446b2cac4">here</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# For putting in your Apache sites site.conf
# Serves MeTube under a /metube/ subdir (http://yourdomain.com/metube/)
<Location /metube/>
    ProxyPass http://localhost:8081/ retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/
</Location>

<Location /metube/socket.io>
    RewriteEngine On
    RewriteCond %{QUERY_STRING} transport=websocket    [NC]
    RewriteRule /(.*) ws://localhost:8081/socket.io/$1 [P,L]
    ProxyPass http://localhost:8081/socket.io retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/socket.io
</Location>"><pre><span><span>#</span> For putting in your Apache sites site.conf</span>
<span><span>#</span> Serves MeTube under a /metube/ subdir (http://yourdomain.com/metube/)</span>
&lt;<span>Location</span> /metube/&gt;
    <span>ProxyPass</span> http://localhost:8081/ retry=0 timeout=30
    <span>ProxyPassReverse</span> http://localhost:8081/
&lt;/<span>Location</span>&gt;

&lt;<span>Location</span> /metube/socket.io&gt;
    <span>RewriteEngine</span> On
    <span>RewriteCond</span> <span>%{QUERY_STRING}</span> <span>transport=websocket</span>    <span>[NC]</span>
    <span>RewriteRule</span> <span>/(.*)</span> <span>ws://localhost:8081/socket.io/$1</span> <span>[P,L]</span>
    <span>ProxyPass</span> http://localhost:8081/socket.io retry=0 timeout=30
    <span>ProxyPassReverse</span> http://localhost:8081/socket.io
&lt;/<span>Location</span>&gt;</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Caddy</h3><a id="user-content-caddy" aria-label="Permalink: Caddy" href="#caddy"></a></p>
<p dir="auto">The following example Caddyfile gets a reverse proxy going behind <a href="https://caddyserver.com/" rel="nofollow">caddy</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="example.com {
  route /metube/* {
    uri strip_prefix metube
    reverse_proxy metube:8081
  }
}"><pre><span>example.com</span> {
<span>  route</span> <span>/metube/*</span> {
<span>    uri</span> strip_prefix metube
<span>    reverse_proxy</span> metube<span>:8081</span>
  }
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Updating yt-dlp</h2><a id="user-content-updating-yt-dlp" aria-label="Permalink: Updating yt-dlp" href="#updating-yt-dlp"></a></p>
<p dir="auto">The engine which powers the actual video downloads in MeTube is <a href="https://github.com/yt-dlp/yt-dlp">yt-dlp</a>. Since video sites regularly change their layouts, frequent updates of yt-dlp are required to keep up.</p>
<p dir="auto">There's an automatic nightly build of MeTube which looks for a new version of yt-dlp, and if one exists, the build pulls it and publishes an updated docker image. Therefore, in order to keep up with the changes, it's recommended that you update your MeTube container regularly with the latest image.</p>
<p dir="auto">I recommend installing and setting up <a href="https://github.com/containrrr/watchtower">watchtower</a> for this purpose.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting and submitting issues</h2><a id="user-content-troubleshooting-and-submitting-issues" aria-label="Permalink: Troubleshooting and submitting issues" href="#troubleshooting-and-submitting-issues"></a></p>
<p dir="auto">Before asking a question or submitting an issue for MeTube, please remember that MeTube is only a UI for <a href="https://github.com/yt-dlp/yt-dlp">yt-dlp</a>. Any issues you might be experiencing with authentication to video websites, postprocessing, permissions, other <code>YTDL_OPTIONS</code> configurations which seem not to work, or anything else that concerns the workings of the underlying yt-dlp library, need not be opened on the MeTube project. In order to debug and troubleshoot them, it's advised to try using the yt-dlp binary directly first, bypassing the UI, and once that is working, importing the options that worked for you into <code>YTDL_OPTIONS</code>.</p>
<p dir="auto">In order to test with the yt-dlp command directly, you can either download it and run it locally, or for a better simulation of its actual conditions, you can run it within the MeTube container itself. Assuming your MeTube container is called <code>metube</code>, run the following on your Docker host to get a shell inside the container:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker exec -ti metube sh
cd /downloads"><pre>docker <span>exec</span> -ti metube sh
<span>cd</span> /downloads</pre></div>
<p dir="auto">Once there, you can use the yt-dlp command freely.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building and running locally</h2><a id="user-content-building-and-running-locally" aria-label="Permalink: Building and running locally" href="#building-and-running-locally"></a></p>
<p dir="auto">Make sure you have node.js and Python 3.11 installed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd metube/ui
# install Angular and build the UI
npm install
node_modules/.bin/ng build
# install python dependencies
cd ..
pip3 install pipenv
pipenv install
# run
pipenv run python3 app/main.py"><pre><span>cd</span> metube/ui
<span><span>#</span> install Angular and build the UI</span>
npm install
node_modules/.bin/ng build
<span><span>#</span> install python dependencies</span>
<span>cd</span> ..
pip3 install pipenv
pipenv install
<span><span>#</span> run</span>
pipenv run python3 app/main.py</pre></div>
<p dir="auto">A Docker image can be built locally (it will build the UI too):</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Development notes</h2><a id="user-content-development-notes" aria-label="Permalink: Development notes" href="#development-notes"></a></p>
<ul dir="auto">
<li>The above works on Windows and macOS as well as Linux.</li>
<li>If you're running the server in VSCode, your downloads will go to your user's Downloads folder (this is configured via the environment in .vscode/launch.json).</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Children should be allowed to get bored, expert says (2013) (144 pts)]]></title>
            <link>https://www.bbc.com/news/education-21895704</link>
            <guid>41098488</guid>
            <pubDate>Mon, 29 Jul 2024 07:17:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/education-21895704">https://www.bbc.com/news/education-21895704</a>, See on <a href="https://news.ycombinator.com/item?id=41098488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p><b>Children should be allowed to get bored so they can develop their innate ability to be creative, an education expert says.</b></p><p>Dr Teresa Belton told the BBC cultural expectations that children should be constantly active could hamper the development of their imagination</p><p>She quizzed author Meera Syal and artist Grayson Perry about how boredom had aided their creativity as children.</p><p>Syal said boredom made her write, while Perry said it was a "creative state".</p><p>The senior researcher at the University of East Anglia's School of Education and Lifelong Learning interviewed a number of authors, artists and scientists in her exploration of the effects of boredom.</p><p>She heard Syal's memories of the small mining village, with few distractions, where she grew up.</p><p>Dr Belton said: "Lack of things to do spurred her to talk to people she would not otherwise have engaged with and to try activities she would not, under other circumstances, have experienced, such as talking to elderly neighbours and learning to bake cakes.</p><p>"Boredom is often associated with solitude and Syal spent hours of her early life staring out of the window across fields and woods, watching the changing weather and seasons.</p><p>"But importantly boredom made her write. She kept a diary from a young age, filling it with observations, short stories, poems, and diatribe. And she attributes these early beginnings to becoming a writer late in life."</p></div><div data-component="text-block"><p>The comedienne turned writer said: "Enforced solitude alone with a blank page is a wonderful spur."</p><p>While Perry said boredom was also beneficial for adults: "As I get older, I appreciate reflection and boredom. Boredom is a very creative state."</p><p>And neuroscientist and expert on brain deterioration Prof Susan Greenfield, who also spoke to the academic, recalled a childhood in a family with little money and no siblings until she was 13.</p><p>"She happily entertained herself with making up stories, drawing pictures of her stories and going to the library."</p><p>Dr Belton, who is an expert in the impact of emotions on behaviour and learning, said boredom could be an "uncomfortable feeling" and that society had "developed an expectation of being constantly occupied and constantly stimulated".</p><p>But she warned that being creative "involves being able to develop internal stimulus".</p><p>"Nature abhors a vacuum and we try to fill it," she said. "Some young people who do not have the interior resources or the responses to deal with that boredom creatively then sometimes end up smashing up bus shelters or taking cars out for a joyride."</p></div><div data-component="text-block"><p>The academic, who has previously studied the impact of television and videos on children's writing, said: "When children have nothing to do now, they immediately switch on the TV, the computer, the phone or some kind of screen. The time they spend on these things has increased. </p><p>"But children need to have stand-and-stare time, time imagining and pursuing their own thinking processes or assimilating their experiences through play or just observing the world around them."</p><p>It is this sort of thing that stimulates the imagination, she said, while the screen "tends to short circuit that process and the development of creative capacity".</p><p>Syal adds: "You begin to write because there is nothing to prove, nothing to lose, nothing else to do.</p><p>"It's very freeing being creative for no other reason other than you freewheel and fill time."</p><p>Dr Belton concluded: "For the sake of creativity perhaps we need to slow down and stay offline from time to time."</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Understanding the design of the the Super Nintendo video system (216 pts)]]></title>
            <link>https://fabiensanglard.net/snes_video/index.html</link>
            <guid>41098141</guid>
            <pubDate>Mon, 29 Jul 2024 05:36:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fabiensanglard.net/snes_video/index.html">https://fabiensanglard.net/snes_video/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=41098141">Hacker News</a></p>
<div id="readability-page-1" class="page"><br><center>
    

</center><p>
July 29, 2024</p>
<p>Designing the Super Nintendo Video System</p><hr>




<p>Last time, I explored the <a href="https://fabiensanglard.net/snes_carts">inside of the Super Nintendo cartridges</a>. Today I am going through  its video system.</p>

<p>I put myself in the shoes of a Nintendo engineer working in Masayuki Uemura (上村雅之)'s team<a name="back_1" href="#footnote_1"><sup>[1]</sup></a><a name="back_2" href="#footnote_2"><sup>[2]</sup></a> by studying what was available in 1989, namely a TV set, to understand what decisions had to be made while designing the SNES video system.</p>

<p>Here is the summary of what I learned. Perhaps you will enjoy tagging along.</p>



<p>What is inside an early 90s TV?</p><hr><p>The screen upon which the SNES outputs video is a standard TV set. Usually it is used to watch Captain Tsubasa, Cobra, Astro Boy, Captain Herlock, Saint Seiya, or Dragon Ball.</p>

<p>There is an antenna on the roof of the house which catches the analog TV broadcast (NTSC), a cable bringing the signal to a tuner, and finally the part where the image is displayed, called a cathode ray tube (CRT).</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/tv.svg" width="178.47072mm" height="68.211235mm">

<p>More importantly for the topic at hand, there are auxiliary (AUX) inputs. A basic TV set would have a composite connector (in yellow) which carries a video signal. The auxiliary stereo audio signals are carried over dedicated jacks (in white and red on my ugly drawing).</p>

<p>How a CRT works</p><hr><p>The CRT is a super line drawing machine. At the time, they were rated at 15kHz which means they could draw in the vicinity of 15,000 lines per second.</p>

<p>Inside the CRT is a gun with three electron cannons. The cannons always shoot straight in front of them, and two sets of magnets (one vertical and one horizontal) route them up/down and left/right.
</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/shadow_mask.svg" width="10.246995in" height="5.2401996in">
<p>In the drawing above, I colored the rays from the cannons but only so the reader can follow. Electrons have no color. There is a mask in front of the phosphor strips to make sure the electrons from each cannon land in the appropriate color strip.</p>
 
<p>There are no pixels in the world of CRTs. A slot is <b>not a pixel</b>. The drawing below zoom into a scanline where various parts of slots are hit. The one guarantee is that electrons from a cannon always land in the correct color strip.</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/triad_slots.svg" width="210.54335mm" height="27.952505mm">

<p>A HD TV has smaller slots, better able to render the color signal. In the drawing below, the same line is rendered horizontally with more fidelity thanks to the higher density of slots.</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/triad_slots_hd.svg" width="210.54335mm" height="27.952505mm">


<p>How a CRT is controlled</p><hr><p>A CRT consumes five signals, carried over four wires. There is one wire for each of the Red, Green, and Blue signals. They are directly connected to the cannons of the gun. The higher the signal, the more electrons are shot and the more bright the phosphor strips are. No signal on all three wires means no electrons being shot, resulting in black being displayed on that line.</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/rgb_wires.svg" width="210.30133mm" height="30.451578mm">
<p>The white wire in the drawing above carries the synchronization signals. There are two, named Horizontal Sync (HSYNC) and Vertical Sync (VSYNC). The two signals use the same wire so it is called Composite Sync (CSYNC).</p>

<p>With my PC programming background, I was used to "Wait for VSYNC" which carried the false idea the CRT emitted it. That is wrong. A CRT emits nothing, it only consumes signals and tries to synchronize the cannon with them.</p>

<p>How a CRT draws an image</p><hr><p>The CRT draws a line (a.k.a raster) from left to right. When it receives a HSYNC event, it "returns" to the left of the screen (X=0). When it receives a VSYNC event, it goes back to the top of the screen (Y=0). 
</p>

<p>Observant readers will see a problem with these events. There is no way to go down. The system driving the CRT can issue as many HSYNC and VSYNC as it wants, the same line at the top of the screen will end up being drawn over and over.
</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/one_line.svg" width="208.88399mm" height="82.920204mm">

<p>The key to understand CRTs</p><hr><p>The key to understanding CRTs is to assimilate that the cannon moves towards the right of the screen with a <b>downward slope</b><a name="back_3" href="#footnote_3"><sup>[3]</sup></a>. Upon HSYNC, the CRT returns to X = 0 but because the cannon will have aimed downward, the next line will be drawn below the previous one.</p>


<img loading="lazy" src="https://fabiensanglard.net/snes_video/p_scan.svg" width="208.88399mm" height="82.920204mm">
<p>This opens the door to cool tricks. The drawing above shows a signal where VSYNC is issued at the same time as the last HSYNC. The lines are always drawn at the same location on the screen. But look below what happens if a VSYNC is issued between two HSYNC.</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/i_scan.svg" width="208.88399mm" height="82.920204mm">
<p>Because it only drew half a line at the bottom, the CRT starts drawing the next line at the top of the screen at the same X position. The next set of lines will be interlaced with the previous set.</p>

<p>Lines sets are called "fields". The mode where fields are drawn at the same location is called "progressive" scan ("p"). The mode where fields are interlaced is abbreviated "i". In i mode, the tradeoff is that the vertical resolution is doubled but the refresh rate of each line is halved.</p> 

<p>NTSC issues two fields at 30-ish Hz. Therefore all CRTs provisioned enough space between lines for interlacing. When drawing in progressive, scanline spacing is visible. It results in black space between lines<a name="back_4" href="#footnote_4"><sup>[4]</sup></a> which are characteristic of CRT rasterization.</p>

<img loading="lazy" src="https://fabiensanglard.net/snes_video/zelda3.webp" width="1154" height="866"><span><i><small>
Visible scanlines gaps. Photo source: <a href="https://www.retrogameboards.com/t/scanline-screenshot-thread-because-240p-is-all-the-ps-i-need-56k-warning/71/83?page=5">retrogameboards.com</a></small></i></span>

<p>What is inside a line?</p><hr><p>The CRT is numeric when it comes to drawing lines but analog when it comes to what is inside a line<a name="back_5" href="#footnote_5"><sup>[5]</sup></a>. As seen in the drawing, the three cannons are directly connected to the three RGB wires. A system is free to change the color signal as much as it wants (hence use any horizontal resolution). The only limit is signal propagation and the slot mask density.
</p>

 

<p>Dealing with what exists</p><hr><p>While the SNES designers could issue what they wanted on the wires, they still had to make sure the CRT would be able to deal with it. Since the hardware is designed to display a NTSC signal, whatever they decided on had to be close to these specifications<a name="back_6" href="#footnote_6"><sup>[6]</sup></a><a name="back_7" href="#footnote_7"><sup>[7]</sup></a>.
</p>

<ul>
  <li>4:3 aspect ratio</li>
  <li>Number of lines: 262.5 per field</li>
  <li>Number of dots on a line: 341.25</li>
  <li>Field frequency: 59.94Hz</li>
</ul>

<p>59.94Hz is such a weird number. Isn't the power grid running at 60Hz and TVs used that AC frequency directly? Black and White NTSC used to be 60Hz. When broadcast engineers had to find a way to add color to the NTSC signal without breaking backward compatibility they decided to reduce frequency by 0.1% to avoid artifacts<a name="back_8" href="#footnote_8"><sup>[8]</sup></a><a name="back_9" href="#footnote_9"><sup>[9]</sup></a>.</p>



<p>Being a Nintendo engineer</p><hr> 
<p>Now that we know how a CRT works, it is time to play at being a Nintendo engineer and craft a video system.</p>

<p>The first choice to make it how many lines we want. NTSC uses 262.5 lines per field but the half-line is to interlace fields. We can use 262 to make it progressive. With a target framerate of 59.94, that should require 15,734.26 lines per second which is within 4% of the 15KHz rating.
</p>

<p>The CRT screen has an aspect ratio of 4:3. If we use 350 dots horizontally, we will match exactly that aspect ratio and there will be no distortion when the console image is converted into scanlines.</p>
 
<p>262 lines at 59.94Hz, each with 350 dots means we need a dot clock pulsing at 262 * 350 * 59.94 = 5,496,498Hz. We can craft an ASIC which counts dot ticks. Every 350 ticks it issues a HSYNC. Every 350*262 = 91,700 ticks, it issues a VSYNC<a name="back_10" href="#footnote_10"><sup>[10]</sup></a>. I guess we are done?</p>







<p>We are not done. We are just getting started</p><hr>
<p>There are two issues with this naive design.</p>

<ol>
<li>It requires a dot clock of 5,496,498Hz we don't have. The SNES cost constraints prevent the video system from getting its own oscillator. There is a Master oscillator which sub-systems must use via dividers<a name="back_11" href="#footnote_11"><sup>[11]</sup></a>.
</li>

<li>You can't draw color all the time. This is called overscan. And it deserves its own section.</li>
</ol>



<p>Introducing overscan</p><hr>

<p>When the gun position is reset horizontally or vertically, it continues to shoot electrons. If it was to keep on shooting, it would create visible artifacts.</p>

<p>Another thing to consider is that TVs tend to over-scan their screen area<a name="back_12" href="#footnote_12"><sup>[12]</sup></a>, which means the picture on the screen is a little larger than the display. How much the TV over-scans varies from TV to TV. This happens to hide wobbling.</p>

<p>When the gun vertical position is reset to Y=0 (after VSYNC), it is going to undulate up and down for a while. You only get straight lines after a few µs. The same problem happens horizontally after HSYNC.</p>




<p>The solution to all these problems is to "stop" the CRT cannon a little bit after VSYNC and after HSYNC. These time spans during which no electrons are shot are called respectively VBLANK and HBLANK.</p>

<div><p>All gaming systems of that era used blanking. Here is a summary of the SNES competitors.</p><table>

<tbody><tr>  
  <th>Machine</th>
  <th>Year</th>
  <th>Lines</th>
  <th>VBLANK lines</th>
  <th>Visible lines</th>
  <th>Lines per second</th>
  <th>Framerate</th>
</tr>
  <tr>
  <td>Capcom arcade CPS-1</td>
  <td>1989</td>
  <td>262</td>
  <td>38</td>
  <td>224</td>
  <td>15,622</td>
  <td>59.6294<a name="back_13" href="#footnote_13"><sup>[13]</sup></a></td>
</tr>  
<tr>
  <td>Sega Genesis</td>
  <td>1989</td>
  <td>262</td>
  <td>38</td>
  <td>224</td>
  <td>15,700</td>
  <td>59.9227<a name="back_14" href="#footnote_14"><sup>[14]</sup></a></td>
</tr>  
<tr>
  <td>Neo-Geo AES<a name="back_15" href="#footnote_15"><sup>[15]</sup></a></td>
  <td>1990</td>
  <td>264</td>
  <td>40</td>
  <td>224</td>
  <td>15,734</td>
  <td>59.18&nbsp;&nbsp;<a name="back_16" href="#footnote_16"><sup>[16]</sup></a></td>
</tr>  
</tbody></table>
</div>






<p>Picking the SNES vertical resolution</p><hr><img loading="lazy" src="https://fabiensanglard.net/snes_video/super-mario.png" width="256" height="262">
<p>If we look closely at the recap table above, we see that all the competing systems, namely the Megadrive, the Neo-Geo, and Capcom's CPS-1 used 224 visible lines.</p>

<p>
They probably did not pick that number at random. 224 is a number evenly divisible by 16 (224/16 = 14) which means it plays nicely with the graphic rendering pipeline tilemaps.</p>

<p>My best guess is that Nintendo did not want to reinvent the wheel. They did not need higher resolution but better graphics. What made the system stand apart was its PPUs.</p>

<div><p>In the end, they went the safe way and split their 262 lines per frame into 224 visible + 38 blanks (as the drawing on the right shows).</p></div> 

<div>




<div><p>Arcade games could afford to be as peculiar as they wanted on a per-title basis. 
The designers of R-Type at Irem were unsatisfied with the default ”standard” 224 active lines of a CRT.</p><p>

They calibrated their M72-System registers to draw 284 lines, 512 dots, and used an 8 Mhz dot-clock. Leaving 128 dots to HBLANK and 28 lines to VBLANK resulted in an active resolution of 384x256 which was higher than other arcade titles at the time.</p><p>
The trade-off was a vertical refresh rate of 55.017605 Hz which was visually less pleasing and dangerously 10% off from the CRT recommended values. This refresh rate is difficult to replicate for ”modern” emulators but what an impressive feat for a 1987 system!</p><p>



<img loading="lazy" src="https://fabiensanglard.net/snes_video/rtype.png" width="384" height="256"><span><i><small>
R-Type (1984) has a whopping 256 visible lines (photo credit: <a href="https://en.wikipedia.org/wiki/R-Type">wikipedia</a>)!</small></i></span></p></div>

<p>Picking the SNES horizontal resolution</p><hr><p>So far we have picked a number of lines per frame (262). We also know we won't be able to pick a dotclock. We have to use the Master clock (21.47727MHz) and use a divider to end up close to NTSC dotclock. That leaves us with using a 21.47727 Mhz / 4 = 5.3693175 MHz dot clock.</p>

<p>Lines, dots, dot clock and refresh rate are inter-connected via the framerate equation.</p>

<center>
<p>refresh rate = <span>
    <span>lines * dots</span>
    <span>/</span>
    <span>dot clock</span>
</span></p>
</center>

<p>Given that our target refresh rate is 59.94Hz, we don't have much of a choice for the number of dots per line.</p>

<center>
<p>dots = <span>
  <span>5369317.5 (dot clock)</span>
    <span>/</span>
    <span>262 (lines) * 59.94 (rate)</span>
</span> ≃ 342 </p>
</center>

<p>Except that for gory reasons involving carrier artifact when using composite outputs, Nintendo engineers had to use 341 dot per lines instead of 342. This leaves the SNES with a framerate of:</p>

<center>
<p>refresh rate = <span>
    <span>5369317.5</span>
    <span>/</span>
    <span>(341 * 262)</span>
</span> = <b>60.098Hz</b></p>
</center>

<p>60.098Hz is not NTSC's 59.94 Hz but since, as seen previously with R-Type, CRTs have tolerance it works. If you enjoyed this part, Nerdy pleasure has plenty more<a name="back_17" href="#footnote_17"><sup>[17]</sup></a></p>



<p>Picking the SNES horizontal Overscan</p><hr>
<p><img loading="lazy" src="https://fabiensanglard.net/snes_video/super-mario-overscan-res.png" width="342" height="262"></p><p>Of these 341 dots, all of them are not usable for the same wobbling, artifact hiding, and TV overscan  reasons. The SNES needs an horizontal overscan during which it issues a blank signal.</p>

<p>The constraints are:
  </p><ul>
    <li>Result in an aspect ratio close to 4:3. This would mean 224*(4/3) = 298 visible dots.</li>
    <li>Play nice with the graphic pipeline tilemaps which uses 16x16 tiles. That leaves values 304 (16x19), 288 (16x18), 272 (16x17), 256 (16x16), 240 (16*15), and so on. The best value, the one resulting in next to no distortion on the screen would be 304 dots.</li>
  </ul>

<p>A third constraint was to allow enough time for the PPU to populate its sprite line buffer during HBLANK. My guess is that up to 128 sprites was a lot of data to retrieve and the PPU needed more than the 7µs granted by 37 dots of HBLANK if 304 visible dots was to be picked as horizontal resolution.</p>

<p>In the end, Nintendo decided on <b>256 visible dots</b> per line with <b>85 dots of HBLANK</b>. This means the PPU has 16µs to retrieve sprite data during HBLANK. This also means the aspect ratio was not 4:3 but 8:7 which results in slight distortion when the CRT displayed what the PPU generated.</p>


<p>High vertical Resolution mode: Interlacing</p><hr>
<p>So far we have designed the SNES video system with only progressive mode in mind.

</p><pre>Overscan resolution: 341x262
Visible resolution:  256x224
Framerate:           60.098Hz
</pre>

<p>Even though this is what 99% of games ended up using, the SNES also had high-resolution modes. I can double its resolution vertically and/or horizontally.</p>


<p>Doubling the resolution vertically to 448 lines is easy. We can just change the counter to issue a VSYNC half a line after the latest HSYNC to interlace frames. That means drawing 262.5 lines per frame but each line is now refreshed at only 60.098/2=30.049Hz. It will cause flickering and it won't be very pleasant but the vertical resolution will be higher<a name="back_18" href="#footnote_18"><sup>[18]</sup></a>.</p>


<p>High horizontal Resolution mode: The hack</p><hr>
<p>Doubling the horizontal resolution however is much more difficult since the console doesn't have the dotclock for it.</p>

<p>The hack is that the SNES shifts every second field horizontally a bit, so the dots of the field end up between the dots of the previous field. You end up with something running at half the framerate and massive color bleeding. Quite a few titles used it, mainly for menu screens as detailed in <a href="https://problemkaputt.de/fullsnes.txt">fullsnes.txt</a>.</p>


 <pre>Hires Software
  Air Strike Patrol (mission overview)       (whatever mode? with Interlace)
  Bishoujo Wrestler Retsuden (some text)     (512x448, BgMode5+Interlace)
  Ball Bullet Gun (in lower screen half)     (512x224, BgMode5)
  Battle Cross (in game) (but isn't hires?)  (512x224, BgMode1+PseudoH)(Bug?)
  BS Radical Dreamers (user name input only) (512x224, BgMode5)
  Chrono Trigger (crash into Lavos sequence) (whatever mode? with Interlace)
  Donkey Kong Country 1 (Nintendo logo)      (512x224, BgMode5)
  G.O.D. (intro &amp; lower screen half)         (512x224, BgMode5)
  Jurassic Park (score text)                 (512x224, BgMode1+PseudoH+Math)
  Kirby's Dream Land 3 (leaves in 1st door)  (512x224, BgMode1+PseudoH)
  Lufia 2 (credits screen at end of game)    (whatever mode?)
  Moryo Senki Madara 2 (text)                (512x224, BgMode5)
  Power Drive (in intro)                     (512x448, BgMode5+Interlace)
  Ranma 1/2: Chounai Gekitou Hen             (256x448, BgMode1+InterlaceBug)
  RPM Racing (in intro and in game)          (512x448, BgMode5+Interlace)
  Rudra no Hihou (RnH/Treasure of the Rudras)(512x224, BgMode5)
  Seiken Densetsu 2 (Secret of Mana) (setup) (512x224, BgMode5)
  Seiken Densetsu 3                          (512x224, BgMode5)
  Shock Issue 1 &amp; 2 (homebrew eZine)         (512x224, BgMode5)
  SNES Test Program (by Nintendo) (Character Test includes BgMode5/BgMode6)
  Super Play Action Football (text)          (512x224, BgMode5)
  World Cup Striker (intro/menu)             (512x224, BgMode5)

Notes: Ranma is actually only 256x224 (but does accidentally have interlace enabled,
which causes some totally useless flickering).


</pre>


<p>PAL vs NTSC</p><hr><p>We are still not done. In Europe, TVs don't use NTSC but PAL and the French even use SECAM. The framerate expected is exactly 50Hz and there are 312.5 lines per field.</p>

<p>That is actually a simple problem to solve. These versions of the SNES ship with a Master clock running at 17.7344750MHz. The same divider gives a dot clock of 5.32034250MHz. The overscan resolution is 312 lines by 341 dots. The visible resolution is 224 lines by 256 dots. And the framerate is 50.00697891Hz.
</p>

<p>The problem is that only 224 lines of graphics is going to result in big black bands above and below the active zone. This is solved via an "Overscan mode" which increased the number of visible lines to 240 (that is 16 lines which is one tile tall).</p>

<p>What a blessing for game developers willing to port a game to the European market you may say. In practice, "overscan mode" was never used. Most titles were tailor made for 224 lines so the developers did not know what to put in these 16 extra lines. In total, only twelve titles ever used it<a name="back_19" href="#footnote_19"><sup>[19]</sup></a>. Nintendo still managed to do something awesome with their flagship title Super Mario World by increasing the vertical view range.</p>




<p>Note that both NTSC and PAL screen use the same 4:3 aspect ratio so the PAL image is a little bit more compressed vertically than the NTSC one.</p>



<p>Besides the annoying black band, the game code was also rarely revised to account for the VSYNC which occurred at 50.00697891Hz instead of 60.098Hz. This resulted in game running 17% slower than intended. European gaming was a real dumpster fire. But luckily without the internet we did not know about it.</p>

<p>Outputs</p><hr><p>So far we have only considered the "pure" signals needed to drive a CRT. However, few TVs set allowed to directly feed the CRT. Most sets only had a yellow composite jack input in the back while some high-end models had S-Video inputs. </p>

<p>The SNES does something pretty cool to handle this diversity. It converts the CRT signals to both composite and S-Video<a name="back_20" href="#footnote_20"><sup>[20]</sup></a>.</p>


<p><img loading="lazy" src="https://fabiensanglard.net/snes_video/multi-out.svg" width="244.45126mm" height="65.154602mm"></p><p>The AV connector</p><hr><p><img loading="lazy" src="https://fabiensanglard.net/snes_video/av.svg" width="88mm" height="55mm"></p><p>None of the signals are discarded. Thanks to the design of its AV output, gamers get a la carte access to the pure "RGB/CSync" signal, the "Composite" signal, and the S-Video.</p>

<pre>
1. Red                7. Luminance (S-Video)
2. Green              8. Chrominance (S-Video)
3. C-Sync             9. Composite Video
4. Blue              10. +5V DC
5. Ground            11. Left Audio 
6. Ground            12. Right Audio
</pre>

<p>European TVs, especially those in France, came with SCART connectors (a.k.a Prise peritel). This allowed them to craft cables feeding the CRT directly<a name="back_21" href="#footnote_21"><sup>[21]</sup></a>.</p>


<p><img loading="lazy" src="https://fabiensanglard.net/snes_video/scart.webp" width="974" height="553"></p><p>That way we could enjoy our 17% slower, black-banded games at the highest level of visual fidelity.</p>
<p>References</p><hr><p id="paperbox"><table><tbody><tr><td><a name="footnote_1"></a><a href="#back_1">^</a></td><td> [ 1]</td><td><a href="https://www.youtube.com/watch?v=FlOAd81a1aI">Inside 1990 Nintendo Headquarters in Kyoto</a></td></tr><tr><td><a name="footnote_2"></a><a href="#back_2">^</a></td><td> [ 2]</td><td><a href="https://www.youtube.com/watch?v=zt2i51CZZ5M">Nintendo Headquarters in 1993</a></td></tr><tr><td><a name="footnote_3"></a><a href="#back_3">^</a></td><td> [ 3]</td><td><a href="https://www.analog.com/en/resources/technical-articles/basics-of-analog-video.html">Video Basics</a></td></tr><tr><td><a name="footnote_4"></a><a href="#back_4">^</a></td><td> [ 4]</td><td><a href="https://www.youtube.com/watch?v=3GJUM6pCpew">Why is TV 29.97 frames per second?</a></td></tr><tr><td><a name="footnote_5"></a><a href="#back_5">^</a></td><td> [ 5]</td><td><a href="https://www.youtube.com/watch?v=puksg4iD3RY">How Games Used to Look: Why Retro Gaming on a CRT Looks WAY Different</a></td></tr><tr><td><a name="footnote_6"></a><a href="#back_6">^</a></td><td> [ 6]</td><td><a href="https://fabiensanglard.net/snes_video/NTSCspecifications.pdf">NTSC specs by jsgil</a></td></tr><tr><td><a name="footnote_7"></a><a href="#back_7">^</a></td><td> [ 7]</td><td><a href="https://forums.nesdev.org/viewtopic.php?t=7265">NTSC specs</a></td></tr><tr><td><a name="footnote_8"></a><a href="#back_8">^</a></td><td> [ 8]</td><td><a href="https://en.wikipedia.org/wiki/NTSC#:~:text=Resolution%20and%20refresh%20rate">NTSC (wikipedia)</a></td></tr><tr><td><a name="footnote_9"></a><a href="#back_9">^</a></td><td> [ 9]</td><td><a href="https://www.youtube.com/watch?v=CBFlhj2UMEk">Tektronix explains analog video color, 1979</a></td></tr><tr><td><a name="footnote_10"></a><a href="#back_10">^</a></td><td> [10]</td><td><a href="https://digilent.com/reference/learn/programmable-logic/tutorials/vga-display-congroller/start">VGA Display Controller</a></td></tr><tr><td><a name="footnote_11"></a><a href="#back_11">^</a></td><td> [11]</td><td><a href="https://fabiensanglard.net/snes_video/snes_hearts">The hearts of the Super Nintendo</a></td></tr><tr><td><a name="footnote_12"></a><a href="#back_12">^</a></td><td> [12]</td><td><a href="http://scanline.ca/overscan/">Overscan and broadcast television</a></td></tr><tr><td><a name="footnote_13"></a><a href="#back_13">^</a></td><td> [13]</td><td><a href="https://gamicus.fandom.com/wiki/CP_System#cite_note-cps1drv-7">CPS-1 Framerate</a></td></tr><tr><td><a name="footnote_14"></a><a href="#back_14">^</a></td><td> [14]</td><td><a href="https://assets.analogue.co/pdf/cb0e551939f5a31cbe617382f3178d47/Analogue+Mega+Sg+User+Manual+1.3.pdf">Analogue Mega Sg User Manual</a></td></tr><tr><td><a name="footnote_15"></a><a href="#back_15">^</a></td><td> [15]</td><td><a href="https://www.reddit.com/r/gamecollecting/comments/pe8ex/neo_geo_mvsaes_guide/">Neo Geo MVS/AES Guide</a></td></tr><tr><td><a name="footnote_16"></a><a href="#back_16">^</a></td><td> [16]</td><td><a href="https://wiki.neogeodev.org/index.php?title=Framerate">Neo Geo framerate</a></td></tr><tr><td><a name="footnote_17"></a><a href="#back_17">^</a></td><td> [17]</td><td><a href="https://nerdlypleasures.blogspot.com/2017/01/classic-systems-true-framerate.html">Classic Systems - The True Framerate</a></td></tr><tr><td><a name="footnote_18"></a><a href="#back_18">^</a></td><td> [18]</td><td><a href="https://nerdlypleasures.blogspot.com/2017/10/the-rise-of-interlacing-in-video-game.html">The Rise of Interlacing in Video Game Consoles</a></td></tr><tr><td><a name="footnote_19"></a><a href="#back_19">^</a></td><td> [19]</td><td><a href="https://snes.nesdev.org/wiki/Uncommon_graphics_mode_games#:~:text=The%20launch%20PAL%20release%20did%20not%20use%20overscan%2C%20but%20a%20later%20PAL%20revision%20did.">SNES games using Overscan (239 lines)</a></td></tr><tr><td><a name="footnote_20"></a><a href="#back_20">^</a></td><td> [20]</td><td><a href="https://fabiensanglard.net/snes_video/snes_schematic.pdf">SNES schematic</a></td></tr><tr><td><a name="footnote_21"></a><a href="#back_21">^</a></td><td> [21]</td><td><a href="https://fabiensanglard.net/snes_video/nintendo-snes-pal-manual.pdf">SNES Pal manual</a></td></tr></tbody></table></p> <hr>
 <center>*</center></div></div>]]></description>
        </item>
    </channel>
</rss>