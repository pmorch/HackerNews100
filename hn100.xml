<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 29 Dec 2024 13:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[We've not been trained for this: life after the Newag DRM disclosure [video] (169 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure</link>
            <guid>42538914</guid>
            <pubDate>Sun, 29 Dec 2024 09:48:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure">https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure</a>, See on <a href="https://news.ycombinator.com/item?id=42538914">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[38C3: Illegal Instructions (207 pts)]]></title>
            <link>https://media.ccc.de/c/38c3</link>
            <guid>42537631</guid>
            <pubDate>Sun, 29 Dec 2024 04:54:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/c/38c3">https://media.ccc.de/c/38c3</a>, See on <a href="https://news.ycombinator.com/item?id=42537631">Hacker News</a></p>
Couldn't get https://media.ccc.de/c/38c3: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[WebGL Fluid Simulation (158 pts)]]></title>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid>42537567</guid>
            <pubDate>Sun, 29 Dec 2024 04:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paveldogreat.github.io/WebGL-Fluid-Simulation/">https://paveldogreat.github.io/WebGL-Fluid-Simulation/</a>, See on <a href="https://news.ycombinator.com/item?id=42537567">Hacker News</a></p>
Couldn't get https://paveldogreat.github.io/WebGL-Fluid-Simulation/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Jeju Air accident in South Korea kills at least 47 (200 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</link>
            <guid>42536647</guid>
            <pubDate>Sun, 29 Dec 2024 01:40:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap">https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</a>, See on <a href="https://news.ycombinator.com/item?id=42536647">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[38C3: Blinkencity, radio controlling street lamps and power plants [video] (120 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants</link>
            <guid>42535622</guid>
            <pubDate>Sat, 28 Dec 2024 23:02:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants">https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants</a>, See on <a href="https://news.ycombinator.com/item?id=42535622">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Fish 4.0: The Fish of Theseus (646 pts)]]></title>
            <link>https://fishshell.com/blog/rustport/</link>
            <guid>42535217</guid>
            <pubDate>Sat, 28 Dec 2024 22:07:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fishshell.com/blog/rustport/">https://fishshell.com/blog/rustport/</a>, See on <a href="https://news.ycombinator.com/item?id=42535217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>About two years ago, our head maintainer @ridiculousfish opened what quickly became our most-read pull request:</p>

<ul>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/9512">#9512 - Rewrite it in Rust</a></li>
</ul>

<p>Truth be told, we did not quite expect that to be as popular as it was.
It was written as a bit of an in-joke for the fish developers first, and not really as a press release to be shared far and wide.
We didn’t post it anywhere, but other people did, and we got a lot of reactions.</p>

<p>Observant readers will note that the PR was a proposal to rewrite the entirety of fish in Rust, from C++.</p>

<p>Fish is no stranger to language changes - it was ported from pure C to C++ earlier in its life,
but this was a much bigger project, porting to a much more different language that didn’t even exist when fish was started in 2007.</p>

<p>Now that we’ve released the beta of fish 4.0, containing 0% C++ and almost 100% pure Rust, let’s look back to see what we’ve learned, what went well, what could have gone better and what we can do now.</p>

<p>We’re writing this so others can learn from our experience, but it is <em>our</em> experience and not an exhaustive study.
We hope that you’ll be able to follow along even if you have never written any rust, but
experience with a roughly C++-shaped language should help.</p>

<h2 id="why-are-we-doing-this-again">Why are we doing this again?</h2>

<p>We’ve experienced some pain with C++. In short:</p>

<ul>
  <li>tools and compiler/platform differences</li>
  <li>ergonomics and (thread) safety</li>
  <li>community</li>
</ul>

<p>Frankly, the tooling around the language isn’t good, and we had to take on some additional pain in order to support our users.
We want to provide up-to-date fish packages for systems that aren’t up-to-date, like LTS Linux and older macOS.
But there is no ‘rustup’ for C++, no standard way to install recent C++ compilers on these operating systems.
This means adopting recent C++ standards would complicate the lives of packagers and would-be contributors<sup id="fnref:Contributions"><a href="#fn:Contributions" rel="footnote" role="doc-noteref">1</a></sup>.
For example, we started using C++11 in 2016, and yet we still needed to upgrade the compilers on our build machines until 2020.</p>

<p>Fish also uses threads for its award-winning (<em>note to editor</em>: find an actual award) autosuggestions and syntax highlighting,
and one long-term project is to add concurrency to the language.</p>

<p>Here’s a dirty secret: while external commands run in parallel, fish’s execution of internal commands (builtins and functions) is currently serial and can’t be backgrounded. Lifting this limitation will enable features like asynchronous prompts or non-blocking completions, as well as performance gains.</p>

<p>POSIX shells use subshells to get around this, but subshells are a leaky abstraction that can bite you in the behind when you least expect it.
For instance, you can’t set variables from inside a pipe (except on some shells, but only in the last part of the pipe, maybe, if you have enabled the correct option).
We would like to avoid that, and so the heavy hand of forking off a process isn’t appealing.</p>

<p>We prototyped true multithreaded execution in C++, but it just didn’t work out. For example, it was too easy to accidentally share objects across threads, with only post-hoc tools like Thread Sanitizer to prevent it.</p>

<p>The ergonomics of C++ are also simply not good - header files are annoying, templates are complicated, you can easily cause a compile error that throws <em>pages</em> of overloads in the standard library at you. Many functions are unsafe to use. C++ string handling is very verbose with
easily confusable overloads of many methods, making it attractive to drop down to C-style char pointers, which are quite unsafe.</p>

<p>And the standard prioritizes performance over ergonomics. Consider for instance string_view, which provides a non-owning slice of a string. This is an extremely modern, well-liked feature that C++ programmers often claim is a great reason to switch to C++17. And it is extremely easy to run into use-after-free bugs with it, because the ergonomics weren’t a priority.</p>

<p>One good case study of the deficiencies of C++-in-practice is a C library: curses. This is a venerable library to access terminal features, and we use it to access the terminfo database, which describes differences in terminal features and behavior.</p>

<p>This not only caused us grief by being unsafe to use in weird ways - the “cur_term” pointer (or sometimes macro!) can be NULL, and it is dereferenced in surprising places, but also caused a surprisingly high number of issues when building from source. This was either because there are multiple implementations of it with differences as useless as “this function takes a char on system X but an int on system Y”, but also because users kept coming to us with new and exciting(ly terrible) ways to package and install it. The dependency system is the system package manager.</p>

<p>Finally, subjectively, C++ isn’t drawing in the crowds. We have never had a lot of C++ contributors. Over the 11 years fish used C++, only 17 people have at least 10 commits to the C++ code. We also don’t know a lot of people who would love to work on a C++ codebase in their free time.</p>

<p>Some parting thoughts we can give the C++ community: We would like to see improvements to ergonomics and safety of the language and the tools prioritized over performance, and we would like to see efforts to make C++ compilers easier to upgrade on real systems.</p>

<h2 id="why-rust">Why Rust?</h2>

<p>We need to get one thing out of the way: Rust is cool. It’s fun.</p>

<p>It’s tempting to try to sweep this under the rug because it feels gauche to say, but it’s actually important for a number of reasons.</p>

<p>For one, fish is a hobby project, and that means we want it to be fun for us. Nobody is being paid to work on fish, so we <em>need</em> it to be fun.
Being fun and interesting also attracts contributors.</p>

<p>Rust also has great tooling. The tools have really paid a lot of attention to use, and the compiler errors are terrific. Not even “compared to C++”, they just actually rule. And as we have tried to pay attention to our own error messages (fish has a bespoke error for if it thinks a file you told it to run has Windows line endings),
we like it.</p>

<p>And it is <em>easy</em> to get that tooling installed - <code>rustup</code> is magic, and allows people to get started quickly, with minimal fuss or root permissions.
When the answer to “how to upgrade C++ compiler” is “find a repository (with root permissions), compile it yourself, install some <em>other</em> repository or a docker image”,
it is amazing how the Rust answer can just be “use rustup”.</p>

<p>Rust has great ergonomics - the difference between C++’s pointers (which can always be NULL) and Rust’s Options are apparent very quickly even to those of us who had never used it before. We did have a backport of C++’s optional, and liked using it, but it was never as integrated as Rust’s Options were.</p>

<p>Having an explicit <code>use</code> system where you know exactly which function comes from which module is a great improvement over <code>#include</code>.</p>

<p>Rust makes it nice to add dependencies. We don’t want to go overboard with it, but we do want to change our history format from our homegrown “I can’t believe it’s not YAML” to something specified that other tools can actually read, and Rust makes it easy to add support for YAML/JSON/KDL.</p>

<p>But the killer feature of Rust, from fish-shell’s perspective, is Send and Sync, statically enforcing rules around threading. “Fearless concurrency” is too strong - you can still blow your leg off with fork or signal handlers - but Send and Sync will be the key to unlocking fully multithreaded execution, with confidence in its correctness.</p>

<p>We did not do a comprehensive survey of other languages. We were confident Rust was up to the task and either already knew it or wanted to learn it, so we picked it.</p>

<h2 id="platform-support">Platform Support</h2>

<p>A lot of hay has also been made online about Rust’s platform support (e.g. <a href="https://lwn.net/Articles/998115/">in the git project</a>). We don’t see a big problem here - all of our big platforms (macOS, Linux, the BSDs) are supported, as are Opensolaris/Illumos and Haiku. We have never heard of anyone trying to run fish on NonStop.</p>

<p>Architecture support is even less of a problem - going by <a href="https://popcon.debian.org/">Debian’s popcon</a>, 99.9995% (the actual result, not an exaggeration) of machines run an architecture that has Rust packages in Debian. Given that fish is <a href="https://qa.debian.org/popcon.php?package=fish">installed on 1.92% of Debian systems</a>, we would project two (2) or three (3) machines of the quarter million responses to have fish on an unsupported architecture <sup id="fnref:stats"><a href="#fn:stats" rel="footnote" role="doc-noteref">2</a></sup>.</p>

<p>Unlike what some online have assumed, a native Windows port was not a reason for switching to Rust as it was never in the cards. Fish is, at heart, a UNIX shell that relies not only on UNIX APIs but also their semantics, and exposes them in the scripting language. What would <code>test -x</code> say on Windows, which has no executable bit? These are issues that <em>could</em> be solved with a lot of work, but we’re unix nerds making a unix shell, not one for Windows.</p>

<p>The one platform we care about a bit that it does not currently seem to have enough support for is Cygwin, which is sad, but we have to make a cut somewhere.</p>

<h2 id="the-story-of-the-port">The Story Of The Port</h2>

<p>We had decided we were gonna do a “Fish <a href="https://en.wikipedia.org/wiki/Ship_of_Theseus">Of Theseus</a>” port - we would move over, component by component, until no C++ was left.
And at every stage of that process, it would remain a working fish.</p>

<p>This was a necessity - if we didn’t, we would not have a working program for months, which is not only demoralizing but would also have precluded us from
using most of our test suite - which is end-to-end tests that run a script or fake a terminal interaction. We would also not have been able to do another C++ release,
putting some cool improvements into the hands of our users.</p>

<p>Had we chosen to disappear into a hole we might not have finished at all, and we would have to re-do a bunch of work once it became testable.
We also mostly kept the structure of the C++ code intact - if a function is in the “env” subsystem, it would stay there. Resisting the temptation to
clean up allowed us to compare the before and after to find places where we had mistranslated something.</p>

<p>So we used <a href="https://google.github.io/autocxx/">autocxx</a> to generate bindings between C++ and Rust code, allowing us to port one component at a time.</p>

<p>We started<sup id="fnref:technically"><a href="#fn:technically" rel="footnote" role="doc-noteref">3</a></sup> by porting the builtins. These are essentially little self-contained programs, with their own arguments, streams, exit code, etc.
That means it’s easy to port them separately from the rest of the shell once you have a way to call a Rust builtin from C++, which we had as part of the initial pull request.</p>

<p>Where they connected to the main shell, we used one of three approaches:</p>

<ol>
  <li>Add some FFI glue to the C++ to make it callable from Rust, port the caller and leave the callee for later</li>
  <li>Move the callee to Rust and, if necessary, make it callable from C++</li>
  <li>Write a Rust version of the callee and call it from the ported caller, but leave the C++ version around</li>
</ol>

<p>For instance, almost every builtin needs to parse its options. We have our own implementation of getopt, that we reimplemented in Rust in the initial PR,
but the C++ version stuck around until it had no more callers remaining. Otherwise we would have had to write a C++-to-Rust bridge and adjust the C++ callers to use it.</p>

<p>Or the <code>builtin</code> builtin (the builtin called <code>builtin</code>) needs access to the names of all builtins to print them for <code>builtin --get-names</code>. In that case we bridged some access to what amounts to a constant vector of strings in the C++, and eventually moved it over once the users were in Rust.</p>

<p>That’s how it went for a while, but we finally hit the more entangled systems, where porting larger chunks felt more productive,
since that reduced the amount of tricky FFI code to be written only to be thrown away. These were ported in solo efforts.
This includes the input/output “reader”, which is, unsurprisingly, one of fish’s biggest parts, ending up at about 13000 lines of Rust.</p>

<p>During the port, we hit a bunch of snags with (auto)cxx. Sometimes it would just not understand a particular C++ construct, and we spent a lot of time trying to figure out ways to please it. As an example, we introduced a struct on the C++ side that wrapped C++’s <code>vector</code>, because for some reason autocxx liked to complain about <code>vector&lt;wstring&gt;</code>. We had to fork it to add support for wstring/wchar, which is understandable because using wchar is a horrible decision - we only do it because it’s a historical mistake.</p>

<p>Similarly, we had to wrap some C++ variables in <code>unique_ptr</code> and similar to make the ownership rules understandable to (auto)cxx, or copy values that didn’t strictly need to be copied. This caused the performance during the port to go down quite a bit, but we regained all of it in most spots, and even beat the C++ version in some.</p>

<p>We also patched autocxx to remove the requirement to use <code>unsafe</code> to invoke any C++ API, because that would have obscured uses of <code>unsafe</code> that wouldn’t disappear just by porting the callee. We were building something temporary, so sometimes it is okay to do something a little underhanded.
If you used this for a permanent bridge between Rust and C++ in a few parts of your code, the <code>unsafe</code> markers might be useful, but in our case they were noise.</p>

<p>Because autocxx generated a lot of code, some tools also were less helpful than they’d usually be. rust-analyzer for instance was extremely slow.</p>

<p>So, even though our codebase was fairly amenable to being moved to Rust because we didn’t use exceptions or a lot of templates, autocxx isn’t the easiest to work with.
It is absolutely magical that it works at all, and it enabled us to do this port, but it has a hard task to perform and isn’t perfect at it.</p>

<h3 id="the-timeline">The Timeline</h3>

<ul>
  <li>
    <p>The initial PR was opened on 28th January 2023, merged on 19th February 2023</p>
  </li>
  <li>
    <p>fish 3.7.0, another release in the C++ branch to flush out some accumulated improvements, was released in January 2024</p>
  </li>
  <li>
    <p>The last C++ code was removed in January 2024 (and some additional test code was ported from C++ to C 12th of June 2024)</p>
  </li>
  <li>
    <p>The first beta was released 17th of December 2024</p>
  </li>
</ul>

<p>The initial PR had a timeline of “handwaving, half a year”. It was clear to all of us that it might very well be entirely off, and we’re not
disappointed that it was. Frankly, 14 months was still a pretty good pace, especially considering that we made a C++ release in-between, so it did not throw off our usual release cadence.</p>

<p>Most of the work was done by 7 people (going by those with at least 10 commits to “.rs” files), but we got a lot of help from interested community members.</p>

<p>The delay after that was down to a few reasons:</p>

<ol>
  <li>The “second 90%” - testing that everything worked. We flushed out a lot of bugs in this time, and if we made a release at that time it would have been a bad one.</li>
  <li>Having something to release that’s visible to users - there’s no point in making a release that does the same thing in new code, you need it to do different things.
So we held off until we had something.</li>
  <li>Simple availability - sometimes, some of us took time off.</li>
</ol>

<p>So if you are trying to draw any conclusions from this, consider the context: A group of people working on a thing in their free time,
diverting some effort to work on something else, <em>and</em> deciding that after the work is finished it actually isn’t.</p>

<h2 id="the-gripes">The Gripes</h2>

<p>It won’t surprise anyone who has spent any time on this world of ours that Rust is not, in fact, perfect. We have some gripes with it.</p>

<p>Chief among them is how Rust handles portability. While it offers many abstractions over systems, allowing you to target a variety of systems with the same code,
when it comes to <em>adapting</em> your code to systems at a lower-level, it’s all based on enumerating systems by hand, using checks like <code>#[cfg(any(target_os = "freebsd", target_os = "netbsd", target_os = "openbsd"))]</code>.</p>

<p>This is an imperfect solution, allowing you to miss systems and ignoring version differences entirely. From what we can tell, if FreeBSD 12 gains a function that we want to use, libc would add it, but calling it would then fail on FreeBSD 11 without a good way to check, at the moment.</p>

<p>But listing targets in our code is also fundamentally duplicating work that the libc crate (in our case) has already done. If you want to call libc::X, which is only defined on systems A, B and C, you need to put in that check for A, B and C yourself and if libc adds system D you need to add it as well. Instead of doing that, we are using our own <a href="https://github.com/mqudsi/rsconf">rsconf</a> crate to do compile-time feature detection in build.rs.</p>

<p>Most of this would be solved if Rust had some form of saying “compile this if that function exists” - <code>#[cfg(has_fn = "fstatat")]</code>. With that, the libc crate could do whatever checks it wants and fish would just follow what it did, and we could remove a lot of the use for rsconf. It would not really help support older distributions that lack some features, tho. That could be solved by something like the <a href="https://github.com/rust-lang/rfcs/pull/3036">min_target_API_version</a> cfg.</p>

<p>While we’re on portability, the tools also sometimes fail to consider other targets - clippy may warn about a conversion being useless when it isn’t on another system, it is often better to use <code>if cfg!(...)</code> instead of <code>#[cfg(...)]</code> because code behind the latter is eliminated very early, so it may be entirely wrong and only shows up when building on the affected system.</p>

<p>We’ve also had issues with localization - a lot of the usual Rust relies on format strings that are checked at compile-time, but unfortunately they aren’t translatable.
We ported printf from musl, which we required for our own <code>printf</code> builtin anyway, which allows us to reuse our preexisting format strings at runtime.</p>

<h3 id="the-mistakes">The Mistakes</h3>

<p>We’ve hit some false starts, dead ends and other kinds of mistakes. For instance we originally used a fancy macro to allow us to write our strings as <code>"foo"L</code>, but that did not end up carrying its weight and we removed it in favor of a regular <code>L!("foo")</code> macro call.</p>

<p>We were confused by a deprecation warning in the libc crate, which explains that “time_t” will be switched to 64-bit on musl in the future.
We initially tried to work around it, adding a lot of wrappers to try to stay agnostic on that size, but only later figured out that it does not affect us,
as we do not pass a time_t we get from one C library to another. (https://github.com/fish-shell/fish-shell/issues/10634)</p>

<p>Some bugs appeared because we missed subtleties of the original code.
Often this turned into a crash because we used asserts or assert’s modern cousin “.unwrap()”. This was often the easiest way to translate the C++,
and sometimes it simply turned out to be not accurate, and had to be replaced with different error handling.</p>

<p>But overall most of these were, once found, pretty shallow - “it panics here, why would it do that? oh, this can be an Err? Okay, what leads to that? Ah, okay, let’s handle that in this way”.</p>

<p>We’ve also caused some friction by turning on link-time-optimization combined with having release builds as the default in CMake (currently needed to run the full test suite),
which makes it easy to accidentally have very long build time.</p>

<h2 id="the-good">The Good</h2>

<p>A lot of the benefits of porting to Rust will appear over time, but some are already here.</p>

<p>Remember our issues with (n)curses? We will no longer have any, because we no longer use curses. Instead we switched to <a href="https://github.com/meh/rust-terminfo">a Rust crate</a> that gives us just what we need, which is access to terminfo and expanding its sequences. This removes some awkward global state, and means those building from source no longer need to ensure that curses is installed “correctly” on their system - cargo just downloads a crate and builds it.</p>

<p>We do still read terminfo, which means users need to install that, but that can be done at runtime, is preinstalled on all mainstream systems <em>and</em> if it can’t be found we just use an included copy of the xterm-256color definitions<sup id="fnref:terminfo"><a href="#fn:terminfo" rel="footnote" role="doc-noteref">4</a></sup>.</p>

<p>We have also managed to create “self-installable” fish packages that include all the functions, completions and other asset files in the fish binary to be written out at runtime.
That allowed us to create statically linked versions of fish (for linux this uses musl, because glibc has unavoidable crashes!), so for the first time we have <em>one file</em> you can download and run on <em>any linux</em> (the only requirement being that the architecture matches!).</p>

<p>This is a pretty big boon for people who want to use fish but sometimes ssh to servers, where they might not have root access to install a package. So they can just <code>scp</code> a single file and it’s available.</p>

<p>This might be possible with C23’s <code>#embed</code>, but Rust allowed us to do it now and, overall, pretty easily.</p>

<h2 id="the-sad">The Sad</h2>

<p>The one goal of the port we did not succeed in was removing CMake.</p>

<p>That’s because, while <code>cargo</code> is great at <em>building</em> things, it is very simplistic at <em>installing</em> them. Cargo wants everything in a few neat binaries,
and that isn’t our use case. Fish has about 1200 .fish scripts (961 completions, 217 associated functions), as well as about 130 pages of documentation (as html and man pages),
and the web-config tool and the man page generator (both written in python).</p>

<p>It also has a test suite that is light on unit tests but heavy on end-to-end script and interactive tests. The scripted tests run through our own littlecheck tool,
which runs a script and compares its output to embedded comments. The interactive tests are driven by pexpect, which fakes terminal interaction and checks that the right thing happens when you press buttons.</p>

<p>We kept cmake, in a simplified form, for these tasks, but let it hand over the responsibility of <em>building</em> to cargo.</p>

<p>It would be possible to switch all that to a simpler task runner like Just or even plain old makefiles, but since we already have this system we’re keeping it for now.
The upside is that the build process hasn’t really changed for packagers.</p>

<p>We’re also losing Cygwin as a supported platform for the time being, because there is no Rust target for Cygwin and so no way to build binaries targeting it.
We hope that this situation changes in future, but we had also hoped it would improve during the almost two years of the port.
For now, the only way to run fish on Windows is to use WSL.</p>

<h2 id="the-present--the-future">The Present &amp; The Future</h2>

<p>We’ve succeeded. This was a gigantic project and <em>we made it</em>. The sheer scale of this is perhaps best expressed in numbers:</p>

<ul>
  <li>1155 files changed, 110247 insertions(+), 88941 deletions(-) (excluding translations)</li>
  <li>2604 commits by over 200 authors</li>
  <li>498 issues</li>
  <li>Almost 2 years of work</li>
  <li>57K Lines of C++ to 75K Lines of Rust <sup id="fnref:formatting"><a href="#fn:formatting" rel="footnote" role="doc-noteref">5</a></sup> (plus 400 lines of C <sup id="fnref:ccode"><a href="#fn:ccode" rel="footnote" role="doc-noteref">6</a></sup>)</li>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/10564">C++–</a></li>
</ul>

<p>The beta works very well. Performance is usually slightly better in terms of time taken, memory use has a slightly higher floor but a lower ceiling - it will use 8M instead of 7M at rest, but e.g. globbing a big directory won’t make it go up as much. These things can all be improved, of course, but for a first result it is encouraging.</p>

<p>Fish is still a bit of an odd duck…fish as a Rust program. It has some bits that smell like C spirit, directly using the C API and e.g. passing around file descriptors instead of File objects. It still uses UTF-32 strings - which is why we are using a fork of the pcre2 crate because we couldn’t convince the pcre2-crate maintainer to add UTF-32 support. We hope to find a nicer solution here, but it wasn’t necessary for the first release.</p>

<p>The port wasn’t without challenges, and it did not all go <em>entirely</em> as planned. But overall, it went pretty dang well. We’re now left with a codebase that we like a lot more, that has already gained some features that would have been much more annoying to add with C++,
with more on the way, and we did it while creating a separate 3.7 release that also included some cool stuff.</p>

<p>And we had fun doing it.</p>

<hr>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel's $475M error: the silicon behind the Pentium division bug (254 pts)]]></title>
            <link>https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</link>
            <guid>42535071</guid>
            <pubDate>Sat, 28 Dec 2024 21:48:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html">https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</a>, See on <a href="https://news.ycombinator.com/item?id=42535071">Hacker News</a></p>
Couldn't get https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Family of OpenAI whistleblower Suchir Balaji demand FBI investigate death (251 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</link>
            <guid>42535057</guid>
            <pubDate>Sat, 28 Dec 2024 21:46:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji">https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</a>, See on <a href="https://news.ycombinator.com/item?id=42535057">Hacker News</a></p>
Couldn't get https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Anki AI Utils (147 pts)]]></title>
            <link>https://github.com/thiswillbeyourgithub/AnkiAIUtils</link>
            <guid>42534931</guid>
            <pubDate>Sat, 28 Dec 2024 21:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/thiswillbeyourgithub/AnkiAIUtils">https://github.com/thiswillbeyourgithub/AnkiAIUtils</a>, See on <a href="https://news.ycombinator.com/item?id=42534931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Anki AI Utils</h2><a id="user-content-anki-ai-utils" aria-label="Permalink: Anki AI Utils" href="#anki-ai-utils"></a></p>
<p dir="auto">A powerful suite of AI-powered tools to enhance your <a href="https://en.wikipedia.org/wiki/Anki_(software)" rel="nofollow">Anki</a> flashcard learning experience by automatically improving cards you struggle with, tested through medical school. For example think of it like this: every time you fail a card you get a ChatGPT explanation, a Dall-E illustration, mnemonics, etc but supporting your own mnemonics.</p>
<p dir="auto"><strong>Check out my other Anki and AI related projects on my <a href="https://github.com/thiswillbeyourgithub">GitHub profile</a>!</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Simple example</h3><a id="user-content-simple-example" aria-label="Permalink: Simple example" href="#simple-example"></a></p>
<p dir="auto"><strong>Those scripts make it so that every failed note will automatically have new fields containing explanations, mnemonics, and illustrations.</strong> This is done in a way that respects <strong>your own mnemonics</strong>, can even use the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">major system</a>, and has <strong>many</strong> more features.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Developer's note / call for help</h2><a id="user-content-developers-note--call-for-help" aria-label="Permalink: Developer's note / call for help" href="#developers-note--call-for-help"></a></p>
<p dir="auto">This collection of scripts is the culmination of my efforts to contributes the AI features I wish existed when I started medical school. All scripts should be working but I released them hastily after documenting them heavily with the help of <a href="https://aider.chat/" rel="nofollow">aider</a>. It is possible that some aspects of the documentation is slightly off or imprecise. It is also possible that some of the scripts where slighly broken during the release process. In any case, <strong>by releasing this project made with love and care my hope is to motivate others to package it into addons.</strong> I have too little time to learn how to package those scripts into addons and make the appropriate GUI so any help is absolutely welcome.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Adaptive Learning</strong>: Uses <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> to dynamically match your cards with the most relevant examples from your training datasets. The more examples you add, the better it gets!</p>
</li>
<li>
<p dir="auto"><strong>Personalized Memory Hooks</strong>: Reuses consistent mnemonics from your custom collection, building a personalized memory system. Includes a dedicated tool to help create and manage your mnemonic library.</p>
</li>
<li>
<p dir="auto"><strong>Automation Ready</strong>: Run programmatically - for example, use cron to automatically enhance cards you struggled with yesterday, making them easier to remember through images, mnemonics, and explanations.</p>
</li>
<li>
<p dir="auto"><strong>Universal Compatibility</strong>: Modifies Anki notes directly in-place, working seamlessly across all Anki clients (Windows, Mac, Linux, Android, iOS). Extensive logging ensures you can track changes and rollback if needed.</p>
</li>
<li>
<p dir="auto"><strong>Provider Agnostic</strong>: Supports all LLM providers and models through LiteLLM, letting you choose the best option for your needs.</p>
</li>
<li>
<p dir="auto"><strong>Infinitely Extensible</strong>: Add as many examples as you want to your training datasets - the semantic filtering automatically picks the most relevant ones for each card.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools</h2><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator" aria-label="Permalink: Illustrator" href="#illustrator"></a></p>
<p dir="auto">Creates custom mnemonic images for your cards using AI image generation. It:</p>
<ul dir="auto">
<li>Analyzes card content to identify key concepts</li>
<li>Generates creative visual memory hooks</li>
<li>Preserves a history of generated images</li>
<li>Supports both DALL-E2, DALL-E3 and Stable Diffusion</li>
<li>Automatically formats images for optimal display (centered, proper sizing)</li>
<li>Handles multiple images per card with consistent layout</li>
</ul>
<p dir="auto">Perfect for visual learners or complex topics that benefit from imagery.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, I had this French flashcard:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever.png" alt=""></a></p>
<details>
<summary>Click here if you can't read French</summary>
<p dir="auto">Here's the note content translated to English:</p>
<div data-snippet-clipboard-copy-content="Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total"><pre><code>Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total
</code></pre></div>
</details>
<p dir="auto"><code>illustrator.py</code> generated to me this image:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever_generated.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever_generated.png" alt=""></a></p>
<p dir="auto">As well as this text content to understand its thought process: (Note that this part is always in English no matter the original language)</p>
<div data-snippet-clipboard-copy-content="Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]"><pre><code>Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]
</code></pre></div>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator" aria-label="Permalink: Reformulator" href="#reformulator"></a></p>
<p dir="auto">An intelligent tool that rephrases your flashcards while preserving their core meaning and structure. It helps when:</p>
<ul dir="auto">
<li>Cards are poorly worded or unclear</li>
<li>You want to vary the phrasing to strengthen recall</li>
<li>Cards need to be more concise or natural sounding</li>
<li>Your preferred card format has evolved over time</li>
</ul>
<p dir="auto">The tool uses LLMs to reformulate content while carefully preserving cloze deletions and media. This is especially valuable for long-term Anki users - for example, during medical school, your idea of what makes a "perfect" flashcard often evolves after a few semesters. The Reformulator lets you easily update all your older cards to match your current preferred format and style.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, given this poorly worded flashcard:</p>
<div data-snippet-clipboard-copy-content="bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}"><pre><code>bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}
</code></pre></div>
<p dir="auto">The reformulator would improve it to:</p>
<div data-snippet-clipboard-copy-content="What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}"><pre><code>What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}
</code></pre></div>
<p dir="auto">Note how the reformulation:</p>
<ul dir="auto">
<li>Makes the question grammatically complete and clear</li>
<li>Structures it as a proper question</li>
<li>Makes the answer self-contained by repeating key context</li>
<li>Preserves the exact medical terminology</li>
<li>Maintains the cloze deletion format</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator"></a></p>
<p dir="auto">Generates memorable mnemonics tailored to your cards by:</p>
<ul dir="auto">
<li>Creating multiple mnemonic options per card</li>
<li>Using proven memory techniques like the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a></li>
<li>Incorporating your existing memory anchors</li>
<li>Preserving context and accuracy</li>
</ul>
<p dir="auto">Helps create lasting memory connections, especially for numbers and sequences.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiMnemonics field:</p>
<hr>
<ol dir="auto">
<li>'Heureux Hephaistos fébrile tend sa banane unique près du feu'<br>* <b>Heureux </b> Âge supérieur à 1 an  Heureux évoque la maturité et donc un âge déjà avancé, supérieur à 1 an <br>* <b>Hephaistos fébrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  Hephaistos évoque la fièvre du fait de son rôle de forgeron et fébrile réitère ce concept <br>* <b>tend sa banane unique </b> 1 unique crise par épisode fébrile donné  banane unique évoque une seule occurrence, ici la crise unique par épisode fébrile <br>* <b>près du feu </b> Moins de 3 épisodes au total  feu évoque la fièvre et sa proximité suggère une limite, ici moins de 3 épisodes en tout <p>2.  'Un enfant trébuche dans le feu, danse symétriquement, a un seul coup et moins de trois feux'<br>* <b>Un enfant trébuche </b> Âge supérieur à 1 an  l'idée d'un enfant qui commence juste à marcher évoque l'âge juste après un an <br>* <b>dans le feu, </b> Survenue de la crise avec une fièvre supérieure à 38°C  le feu évoque la chaleur, donc la fièvre <br>* <b>danse symétriquement, </b> Manifestations motrices symétriques  danser évoque le mouvement, et symétriquement évoque les deux côtés du corps bougeant de la même manière <br>* <b>a un seul coup </b> 1 unique crise par épisode fébrile donné  un seul coup évoque l'unicité de la crise pendant l'épisode fébrile <br>* <b>et moins de trois feux </b> Moins de 3 épisodes au total  moins de trois feux évoque le nombre total d'épisodes, utilisant l'analogie avec la fièvre comme feu </p><p>3.  'Un enfant febrile symetrique forge une unique bulle dans la prairie'<br>* <b>Un enfant </b> Âge supérieur à 1 an  enfant indique que le sujet concerne un jeune individu, donc plus d'un an <br>* <b>febrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  fébrile se lie à la notion de fièvre <br>* <b>symetrique </b> Manifestations motrices symétriques  directement lié à symétrique <br>* <b>forge </b> durant moins de 15 minutes et sans déficit  forger évoque une action courte et intense, comme la crise qui dure moins de 15 minutes sans laisser de séquelles <br>* <b>une unique </b> 1 unique crise par épisode fébrile donné  unique précise le nombre de crises <br>* <b>bulle </b> Moins de 3 épisodes au total  une bulle évoque quelque chose de rare et limité, semblable à moins de 3 épisodes au total <br>* <b>dans la prairie </b> hyperthermique  la prairie évoque un espace ouvert et naturel, hyperthermique évoque la chaleur comme celle du soleil sur une prairie </p><p>[DATE:09/04/2024 VERSION:2.1 MODEL:openai/gpt-4-0125-preview]</p></li>
</ol>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Explainer</h3><a id="user-content-explainer" aria-label="Permalink: Explainer" href="#explainer"></a></p>
<p dir="auto">Provides clear, detailed explanations when you struggle with cards by:</p>
<ul dir="auto">
<li>Breaking down complex concepts</li>
<li>Highlighting key relationships</li>
<li>Adding helpful context</li>
<li>Using analogies and examples</li>
</ul>
<p dir="auto">Particularly useful for understanding why you got a card wrong and filling knowledge gaps.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiExplainer field (I translated it french to English for universal documentation):</p>
<hr>
<ul dir="auto">
<li><b>EXPLANATION</b> A simple febrile seizure is characterized by its uniqueness and brevity during a febrile episode, which helps distinguish it from complex seizures or other neurological disorders.<br>* <b>MECHANISM</b> Fever can lower the seizure threshold in certain children, which explains why an elevation in body temperature can trigger a seizure in predisposed individuals.<p>[DATE:09/04/2024 VERSION:1.7 LLMMODEL:openai/gpt-4-0125-preview]</p></li>
</ul>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Helper</h3><a id="user-content-mnemonics-helper" aria-label="Permalink: Mnemonics Helper" href="#mnemonics-helper"></a></p>
<p dir="auto">A lightweight interactive CLI tool for quick mnemonic generation that:</p>
<ul dir="auto">
<li>Takes a concept and finds semantically similar existing mnemonics</li>
<li>Generates multiple new mnemonic options using LLMs</li>
<li>Lets you choose from generated options with vim-style navigation</li>
<li>Automatically saves selected mnemonics for future reference</li>
<li>Works independently of Anki, perfect for brainstorming sessions</li>
</ul>
<p dir="auto">Unlike the Mnemonics Creator which processes Anki cards in batch, this tool provides an interactive interface for generating mnemonics one concept at a time. Those new mnemonics can automatically be added to a dataset file that can readily be used by the other tools. This allows rapidly tailoring the scripts to your own imagination.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are the core benefits of those tools?</h3><a id="user-content-what-are-the-core-benefits-of-those-tools" aria-label="Permalink: What are the core benefits of those tools?" href="#what-are-the-core-benefits-of-those-tools"></a></p>
<p dir="auto">Basically if you run these tools each evening on cards you failed that day it will steadily improve your deck quality and learning effectiveness:</p>
<ul dir="auto">
<li>Automatically enhance cards you struggle with</li>
<li>Save time on manual card improvements</li>
<li>Create stronger memory connections</li>
<li>Track improvements with detailed history</li>
<li>Preserve card structure while enhancing content</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What is the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a>?</h3><a id="user-content-what-is-the-major-system" aria-label="Permalink: What is the Major System?" href="#what-is-the-major-system"></a></p>
<p dir="auto">The Major System is a powerful memory technique that converts numbers into consonant sounds, which can then be turned into memorable words. For example:</p>
<ul dir="auto">
<li>0 = S sound (as in "sea")</li>
<li>1 = T sound (as in "tea")</li>
<li>2 = N sound (as in "new")</li>
<li>etc.</li>
</ul>
<p dir="auto">This makes it easier to remember numbers by turning them into words. For example, "92" could become "pen" (P=9, N=2).</p>
<p dir="auto">You can read more about it <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">on wikipedia</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are Memory Anchors?</h3><a id="user-content-what-are-memory-anchors" aria-label="Permalink: What are Memory Anchors?" href="#what-are-memory-anchors"></a></p>
<p dir="auto">Memory anchors are existing associations you already know well that can be used to create new memories. For example, if you already strongly associate "Napoleon" with "France", you can use Napoleon as an anchor when learning new facts about French history.</p>
<p dir="auto">The tools can use your personal set of memory anchors to generate mnemonics that build on your existing knowledge.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Which LLM providers are supported?</h3><a id="user-content-which-llm-providers-are-supported" aria-label="Permalink: Which LLM providers are supported?" href="#which-llm-providers-are-supported"></a></p>
<p dir="auto">The tools use <a href="https://docs.litellm.ai/docs/" rel="nofollow">LiteLLM</a> which provides a unified interface to virtually any LLM provider including:</p>
<ul dir="auto">
<li>OpenAI</li>
<li>Anthropic</li>
<li>Google</li>
<li>OpenRouter</li>
<li>Azure</li>
<li>AWS Bedrock</li>
<li>Local models</li>
<li>And many more</li>
</ul>
<p dir="auto">Just specify the model in LiteLLM format (e.g. "openai/gpt-4" or "anthropic/claude-3-opus") and it will handle the rest.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What languages are supported?</h3><a id="user-content-what-languages-are-supported" aria-label="Permalink: What languages are supported?" href="#what-languages-are-supported"></a></p>
<p dir="auto">The tools work in any language supported by the LLM you choose to use. Since these scripts support virtually all LLM providers through LiteLLM, you can use any model that works well with your language. For example:</p>
<ul dir="auto">
<li>OpenAI's models support 100+ languages</li>
<li>Anthropic's Claude supports 100+ languages</li>
<li>You can use local models specifically trained for your language</li>
<li>etc.</li>
</ul>
<p dir="auto">The tools will preserve all language-specific formatting, including:</p>
<ul dir="auto">
<li>Right-to-left text</li>
<li>Special characters and diacritics</li>
<li>Language-specific punctuation</li>
<li>etc.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How do the Mnemonics Work?</h3><a id="user-content-how-do-the-mnemonics-work" aria-label="Permalink: How do the Mnemonics Work?" href="#how-do-the-mnemonics-work"></a></p>
<p dir="auto">The mnemonics tools use several proven memory techniques:</p>
<ul dir="auto">
<li><a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a> for numbers</li>
<li>Vivid imagery and visualization</li>
<li>Personal memory anchors</li>
<li>Phonetic similarities</li>
<li>Humor and absurdity</li>
<li>Story-based connections</li>
</ul>
<p dir="auto">This creates memorable associations that help strengthen recall while preserving accuracy.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Where can I find example datasets for each tool?</h3><a id="user-content-where-can-i-find-example-datasets-for-each-tool" aria-label="Permalink: Where can I find example datasets for each tool?" href="#where-can-i-find-example-datasets-for-each-tool"></a></p>
<p dir="auto">The <code>examples/</code> folder contains training datasets and example files for each tool. While these were originally written in French and hastily translated to English, they provide good templates for creating your own datasets. Check the Example Files section below for details on each file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the future of this project?</h3><a id="user-content-whats-the-future-of-this-project" aria-label="Permalink: What's the future of this project?" href="#whats-the-future-of-this-project"></a></p>
<p dir="auto">This toolkit was developed and battle-tested while studying tens of thousands of Anki cards during medical school. It proved invaluable for maintaining and enhancing a large flashcard collection during intense study periods.</p>
<p dir="auto">However, as research commitments have grown, I now have limited time to transform these scripts into a more user-friendly package. The tools work well but need:</p>
<ul dir="auto">
<li>Packaging as a proper Anki addon</li>
<li>Installation via PyPI</li>
<li>Code deduplication and cleanup</li>
<li>Better documentation</li>
</ul>
<p dir="auto">I'm actively looking for contributors of all skill levels to help make these tools more accessible to the wider Anki community. Whether you're a seasoned developer or just getting started, all contributions are welcome! I can provide guidance and direction based on extensive experience with the codebase, while you help with the technical aspects of packaging and distribution.</p>
<p dir="auto">Check out the detailed roadmap below to see what needs improving. If you're interested in helping transform these battle-tested scripts into a polished Anki addon, please don't hesitate to reach out - I'm always happy to chat and help you get started!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why is there code duplication across the tools?</h3><a id="user-content-why-is-there-code-duplication-across-the-tools" aria-label="Permalink: Why is there code duplication across the tools?" href="#why-is-there-code-duplication-across-the-tools"></a></p>
<p dir="auto">This project evolved organically alongside my Python skills while solving real needs during medical school. Each tool was developed independently when needed, prioritizing functionality over code elegance. While they all work reliably, there's significant opportunity to unify their codebases around a common API.</p>
<p dir="auto">I can provide detailed guidance on refactoring and consolidating the code, but lack the time to implement these changes myself. Check the roadmap below if you're interested in helping streamline the codebase while preserving its battle-tested functionality.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">When Should I Use Each Tool?</h3><a id="user-content-when-should-i-use-each-tool" aria-label="Permalink: When Should I Use Each Tool?" href="#when-should-i-use-each-tool"></a></p>
<ul dir="auto">
<li><strong>Mnemonics Creator</strong>: Best for memorizing numbers, sequences, lists, and abstract concepts</li>
<li><strong>Illustrator</strong>: Ideal for visual learners and complex topics that benefit from imagery</li>
<li><strong>Reformulator</strong>: Use when card wording is unclear or you want variety in phrasing. Don't worry about running it on well-formatted cards - the LLM is trained to recognize and preserve cards that already follow best practices, avoiding unnecessary changes that could disrupt your learning</li>
<li><strong>Explainer</strong>: Great for understanding why you got a card wrong and filling knowledge gaps</li>
<li><strong>Mnemonics Helper</strong>: Simple script to quickly ask an LLM to come up with new mnemonics by taking into accountsthe <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> of the new subject vs your previous mnemonics.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What happens if I run a script multiple times on the same card?</h3><a id="user-content-what-happens-if-i-run-a-script-multiple-times-on-the-same-card" aria-label="Permalink: What happens if I run a script multiple times on the same card?" href="#what-happens-if-i-run-a-script-multiple-times-on-the-same-card"></a></p>
<p dir="auto">For most tools (Mnemonics Creator, Illustrator, Explainer), the previous content will be preserved in a collapsible HTML section using the <code>&lt;details&gt;</code> and <code>&lt;summary&gt;</code> tags. The new content appears above this section. This makes it easy to:</p>
<ul dir="auto">
<li>See the latest generated content first</li>
<li>Access previous versions by expanding the collapsible sections</li>
<li>Track how the card evolved over time</li>
</ul>
<p dir="auto">The Reformulator works differently - it replaces the content of the original field directly, but saves all previous versions and metadata in a separate <code>AnkiReformulator</code> field. This preserves the card's readability while maintaining a complete history.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How can I track which cards were modified?</h3><a id="user-content-how-can-i-track-which-cards-were-modified" aria-label="Permalink: How can I track which cards were modified?" href="#how-can-i-track-which-cards-were-modified"></a></p>
<p dir="auto">Each tool meticulously tracks modifications through tags and metadata to ensure transparency and reversibility. For example, when a tool processes a card, it adds a dated tag like <code>AnkiIllustrator::done::02/07/2023</code>. This makes it easy to:</p>
<ul dir="auto">
<li>Quickly identify which cards were modified by each tool</li>
<li>Track when modifications were made</li>
<li>Find cards that haven't been processed yet</li>
<li>Rollback changes if needed (especially with the Reformulator)</li>
</ul>
<p dir="auto">You can use these tags in the Anki browser to assess how many cards could benefit from each tool and review the modifications made. Note that notes for which a script failed will have a tag added to it. For example <code>AnkiI ::failed</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How much does it cost to run these tools?</h3><a id="user-content-how-much-does-it-cost-to-run-these-tools" aria-label="Permalink: How much does it cost to run these tools?" href="#how-much-does-it-cost-to-run-these-tools"></a></p>
<p dir="auto">The cost depends on your usage patterns and which features you enable:</p>
<ul dir="auto">
<li>Start small with a few cards to get comfortable with each tool</li>
<li>Built-in safeguards prevent accidental overspending:
<ul dir="auto">
<li>Maximum cards per run can be limited</li>
<li>Cost tracking per script is stored in the database</li>
<li>Failed API calls don't count towards your quota</li>
<li>You can set hard spending limits</li>
</ul>
</li>
<li>Typical costs per card:
<ul dir="auto">
<li>Reformulator: ~$0.02-0.04 (text only)</li>
<li>Mnemonics: ~$0.02-0.04 (text only)</li>
<li>Explainer: ~$0.03-0.06 (more complex reasoning)</li>
<li>Illustrator: ~$0.02 + image cost ($0.04-0.12 per image)</li>
</ul>
</li>
</ul>
<p dir="auto">The database tracks total spending per script, making it easy to budget and monitor costs. You can also use cheaper models for initial testing before scaling up to more capable ones.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Can I use these tools on mobile?</h3><a id="user-content-can-i-use-these-tools-on-mobile" aria-label="Permalink: Can I use these tools on mobile?" href="#can-i-use-these-tools-on-mobile"></a></p>
<p dir="auto">While you need to run the scripts themselves from a computer (not your phone), all changes are made directly to your Anki notes. This means:</p>
<ul dir="auto">
<li>Run the scripts from your computer/server</li>
<li>Sync Anki on your computer</li>
<li>The improved cards will appear on AnkiMobile/AnkiDroid after syncing</li>
<li>All generated content (reformulations, mnemonics, images, etc.) works perfectly on mobile</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Files</h3><a id="user-content-example-files" aria-label="Permalink: Example Files" href="#example-files"></a></p>
<p dir="auto">The <code>examples/</code> folder contains example files to help you get started. Note that these examples were originally written in French (except for system prompts) and were quickly translated to English - some examples may not make perfect sense but should still demonstrate the basic usage:</p>
<ul dir="auto">
<li><code>anki_ai_utils_tmux_launcher.sh</code>: A tmux-based launcher script I used every morning to automatically process cards I struggled with the previous day</li>
<li><code>anchors.json</code>: Example memory anchors mapping file</li>
<li><code>dataset_anchors.txt</code>: Training examples for memory anchor processing</li>
<li><code>explainer_dataset.txt</code>: Examples for the Explainer tool</li>
<li><code>illustrator_dataset.txt</code>: Training data for image generation</li>
<li><code>illustrator_sanitize_dataset.txt</code>: Examples for sanitizing image prompts</li>
<li><code>mnemonics_dataset.txt</code>: Training data for mnemonic generation</li>
<li><code>reformulator_dataset.txt</code>: Examples for card reformulation</li>
<li><code>string_formatting.py</code>: Handles cloze deletions and text formatting</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the format of dataset files?</h3><a id="user-content-whats-the-format-of-dataset-files" aria-label="Permalink: What's the format of dataset files?" href="#whats-the-format-of-dataset-files"></a></p>
<p dir="auto">Dataset files (like <code>explainer_dataset.txt</code>, <code>reformulator_dataset.txt</code>, etc.) are simple text files where messages are separated by <code>----</code>. The first message is assumed to be a system prompt, followed by alternating user and assistant messages. This format mirrors a typical LLM conversation flow while remaining easy to read and edit.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Reformulator</h4><a id="user-content-reformulator-1" aria-label="Permalink: Reformulator" href="#reformulator-1"></a></p>
<p dir="auto">The Reformulator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python reformulator.py \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/reformulator_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --main_field_index 0 \
    --llm &quot;openai/gpt-4&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --max_token 4000 \
    --llm_temp 0"><pre>python reformulator.py \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/reformulator_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --main_field_index 0 \
    --llm <span><span>"</span>openai/gpt-4<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --max_token 4000 \
    --llm_temp 0</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for reformulation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>main_field_index</code>: Index of the field to reformulate (0 for first field)</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>max_token</code>: Maximum tokens per query</li>
<li><code>llm_temp</code>: LLM temperature (0 for consistent output)</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if already reformulated</li>
<li><code>--print_db_then_exit</code>: Display database contents and exit</li>
<li><code>--parallel</code>: Number of parallel processes (default 4)</li>
<li><code>--exclude_media</code>: Skip cards containing media</li>
<li><code>--mode</code>: Either 'reformulate' or 'reset' to restore original content. Note that the 'reset' feature is not absolutely guaranteed to work, but if things go wrong there are tons of logs on purpose to make sure you don't lose anything.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics</h4><a id="user-content-mnemonics" aria-label="Permalink: Mnemonics" href="#mnemonics"></a></p>
<p dir="auto">The Mnemonics Creator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/mnemonics_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --n_mnemonic 1"><pre>python mnemonics.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/mnemonics_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --n_mnemonic 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for mnemonic generation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>n_mnemonic</code>: Number of mnemonics to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have mnemonics</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics Creator CLI</h4><a id="user-content-mnemonics-creator-cli" aria-label="Permalink: Mnemonics Creator CLI" href="#mnemonics-creator-cli"></a></p>
<p dir="auto">The Mnemonics Creator CLI provides an interactive interface for generating mnemonics:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embed_model &quot;openai/text-embedding-3-small&quot;"><pre>python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embed_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span></pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>top_k</code>: Number of similar existing mnemonics to use as examples (default: 100)</li>
<li><code>n_gen</code>: Number of new mnemonics to generate per query (default: 10)</li>
<li><code>model</code>: LLM model to use in litellm format</li>
<li><code>embed_model</code>: Model for semantic similarity search</li>
<li><code>query</code>: Optional initial query to process</li>
<li><code>gui</code>: Enable GUI interface (not yet implemented)</li>
</ul>
<p dir="auto">The CLI provides an interactive interface where you can:</p>
<ul dir="auto">
<li>Enter concepts to generate mnemonics for</li>
<li>See similar existing mnemonics as context</li>
<li>Choose from multiple generated options</li>
<li>Navigate with vim-style keys (j/k) or numbers</li>
<li>Save selected mnemonics to your collection</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Explainer</h4><a id="user-content-explainer-1" aria-label="Permalink: Explainer" href="#explainer-1"></a></p>
<p dir="auto">The Explainer can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python explainer.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/explainer_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --llm_max_token 3000"><pre>python explainer.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/explainer_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --llm_max_token 3000</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for generating explanations</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>llm_max_token</code>: Maximum tokens per query</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have explanations</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Illustrator</h4><a id="user-content-illustrator-1" aria-label="Permalink: Illustrator" href="#illustrator-1"></a></p>
<p dir="auto">The Illustrator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python illustrator.py \
    --field_names &quot;front,back&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/illustrator_dataset.txt&quot; \
    --dataset_sanitize_path &quot;data/illustrator_sanitize.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --n_image 1"><pre>python illustrator.py \
    --field_names <span><span>"</span>front,back<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/illustrator_dataset.txt<span>"</span></span> \
    --dataset_sanitize_path <span><span>"</span>data/illustrator_sanitize.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --n_image 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for image generation</li>
<li><code>dataset_sanitize_path</code>: Examples for sanitizing unsafe prompts</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>n_image</code>: Number of images to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have illustrations</li>
<li><code>--disable_notif</code>: Disable ntfy.sh notifications</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Roadmap</h3><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><i>This TODO list is maintained automatically by <a href="https://github.com/thiswillbeyourgithub/MdXLogseqTODOSync">MdXLogseqTODOSync</a></i></p>

<ul dir="auto">
<li>turn those scripts into addons</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Applies to all tools</h3><a id="user-content-applies-to-all-tools" aria-label="Permalink: Applies to all tools" href="#applies-to-all-tools"></a></p>
</li>
<li>use beartype everywhere</li>
<li>add an arg to include tags or not in the LLM context for a given note, as otherwise the LLM can get confused by some acronyms
<ul dir="auto">
<li>but with a regex arg to keep only the tags that match the regex. This way we can keep only a portion of them for the LLM</li>
</ul>
</li>
<li>store all inference in a compressed sqlite db instead of a json. It gets too large</li>
<li>add check that we indeed removed all the done tags</li>
<li>actually there's no need to store the "Done" tags because all important info is stored in the field</li>
<li>use xml formatting for the examples
<ul dir="auto">
<li>make use of  tags too</li>
</ul>
</li>
<li>make it installable with a setup.py on pypi</li>
<li>add images to illustrate the benefits of using each</li>
<li>do a unique class that could be used to unify all those codes
<ul dir="auto">
<li>arguments:
<ul dir="auto">
<li>name (to differentiate each children: for example "illustrator")</li>
<li>string_format (can be overloaded)</li>
<li>in the init, check that indeed there is a version attribute</li>
</ul>
</li>
</ul>
</li>
<li>use toml instead of json, it allows setting comments too</li>
<li>tell user how much time each answer took</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator-1" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator-1"></a></p>
<ul dir="auto">
<li>Add keybindings
<ul dir="auto">
<li>binding e to edit a proposition</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator-2" aria-label="Permalink: Illustrator" href="#illustrator-2"></a></p>
</li>
<li>use an llm to extract numbers
<ul dir="auto">
<li>ask it to do quick transformations like turn 48h into 2 days, modify units, etc,</li>
</ul>
</li>
<li>add support for note containing media like audio, images etc</li>
<li>add a mode without actually creating images. This could be used like a mnemonics after all.</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator-2" aria-label="Permalink: Reformulator" href="#reformulator-2"></a></p>
</li>
<li>Add 5 to 10 example for the LLM of how to manage media like iimages etc then add support for them</li>
<li>make it work with specific fstring template for field replacement. Otherwise it can only reformulate a single field
<ul dir="auto">
<li>better: add an arg to specify the single output field, and an arg to specify a comma separated list of input fields</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">explainer</h3><a id="user-content-explainer-2" aria-label="Permalink: explainer" href="#explainer-2"></a></p>
</li>
<li>compute all embeddings at the start, making it faster</li>
<li>it's actually quite terrible. Use one LLM call to ask for which follow up questions to ask, then another LLM call to answer each using async
<ul dir="auto">
<li>save each new question answer as a <details> tag to make it easy to access on phones by touching the field</details></li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ankimnemonics</h3><a id="user-content-ankimnemonics" aria-label="Permalink: Ankimnemonics" href="#ankimnemonics"></a></p>
</li>
<li>comment out the mnemonics that dont respect the rule of adding the subject first</li>
<li>understand why it sometimes hangs during a run</li>
<li>make it distinguish 'has to appear in plain' vs 'has to appear as mnemonic'?</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">AnkiAiFilter</h3><a id="user-content-ankiaifilter" aria-label="Permalink: AnkiAiFilter" href="#ankiaifilter"></a></p>
</li>
<li>use an eval llm like in <a href="https://wdoc.readthedocs.io/en/latest/" rel="nofollow">wdoc</a> to better filer an anki query
<ul dir="auto">
<li>actually wdoc can already be used for that! Maybe it should be converted into an addon?</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tagger (In project)</h2><a id="user-content-tagger-in-project" aria-label="Permalink: Tagger (In project)" href="#tagger-in-project"></a></p>
</li>
<li>always prepend tags by ankitagger: but customizable</li>
<li>always sort those tags by alphabetical order</li>
<li>add modes:
<ul dir="auto">
<li>mode "predefined": the user gives a list of tags and the LLM finds which to apply to each note given a query
<ul dir="auto">
<li>loop over each note and ask it to generate tags</li>
</ul>
</li>
</ul>
</li>
<li>arg for image support if media found
<ul dir="auto">
<li>if the card contains an image, it should be hashed, then a cached call to a func that asks a vision model to describe the type of image, then use the embedding of this answer to suggest the appropriate tags to suggest to the LLM for classification</li>
</ul>
</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">This project makes heavy use of <a href="https://git.foosoft.net/alex/anki-connect" rel="nofollow">AnkiConnect</a> to interact with Anki.</p>
</details>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU law mandating universal chargers for devices comes into force (229 pts)]]></title>
            <link>https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</link>
            <guid>42534851</guid>
            <pubDate>Sat, 28 Dec 2024 21:20:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force">https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</a>, See on <a href="https://news.ycombinator.com/item?id=42534851">Hacker News</a></p>
Couldn't get https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Photos phones home on iOS 18 and macOS 15 (812 pts)]]></title>
            <link>https://lapcatsoftware.com/articles/2024/12/3.html</link>
            <guid>42533685</guid>
            <pubDate>Sat, 28 Dec 2024 19:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lapcatsoftware.com/articles/2024/12/3.html">https://lapcatsoftware.com/articles/2024/12/3.html</a>, See on <a href="https://news.ycombinator.com/item?id=42533685">Hacker News</a></p>
Couldn't get https://lapcatsoftware.com/articles/2024/12/3.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Google's Results Are Infested, Open AI Is Using Their Playbook from the 2000s (417 pts)]]></title>
            <link>https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</link>
            <guid>42532441</guid>
            <pubDate>Sat, 28 Dec 2024 17:06:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook">https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</a>, See on <a href="https://news.ycombinator.com/item?id=42532441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You know when you go on a picnic, sometimes there's a fly that decides to join you.</p>
<p>You wave your hand to shoo it away from the tasty lunch you're about to enjoy and think nothing more of it.</p>
<p>But it returns, only for you to swipe again, and that tinge of frustration starts to bloom. It returns, and now your lunch is no longer the focus, but this annoying fly whose buzzing is now an obstacle to a perfectly nice picnic.</p>
<h2>The 2000s were a picnic</h2>
<p>When Google came onto the scene, I credit its success to the tried and true paradigm that makes companies successful: <strong>simple and easy to use</strong>.</p>
<p>Yahoo was dominant back then, and it tried to put everyone and everything in front of you. Then we learned about the paralysis of choice. Too many choices, the mental fatigue weighed in, and the product became difficult to use.</p>
<p><img src="https://chuckwnelson.com/images/yahoo-vs-google.jpg" alt="Yahoo vs Google"></p>
<p>Enter Google, and it was <strong>Feeling Lucky</strong>. Just a search input, logo, and some minor text. The next step was clear. And the search results were a simple list. Sequential to avoid mental fatigue, and just enough description to make an informed choice.</p>
<p><img src="https://chuckwnelson.com/images/google-serp.jpg" alt="Trustworthy Google"></p>
<p>Then a fly came buzzing to the picnic.</p>
<h2>Enter the buzz</h2>
<p>Google added advertising. Their first iteration was clearly marked and outside the search list. Trust in the organic results mattered to Google, and it would be off-brand to show you could pay to be at the top of that list.</p>
<p>And even these ads weren't that bad. What made Google successful was showing ads you wanted to see. I'm searching for a bottle of wine, and ads for bottles of wine were shown to me. This is okay because it's not interrupting the picnic. Google's success is from active intent advertising.</p>
<p>But then ads were placed over search results, still clearly marked, but pushing down organic results. Buzz.</p>
<p>Then the SEO industry got its footing. Organic results are now optimized advertorials, or aggregation websites like Yelp and Pinterest, which have their own ad models.</p>
<p>It's a layer cake of ads all the way down the list.</p>
<p>Google lost its credibility.</p>
<h2>Google is infested with these little annoyances</h2>
<p>Enter 2024 with AI. The top 20% of search results are a wall of text from AI, then a Google product such as maps or shopping listings (with ads), then search ads, then YouTube videos, then search results (hidden ads), then some sprinkling of what you are looking for.</p>
<p>I don't want to watch a 10-minute video for a quick answer.</p>
<p>No longer can you flip back and forth from search results quickly to find the answer.</p>
<p>You need a machete to cut through the visual noise in order to find even a website that may have your lunch.</p>
<p>We are back to Yahoo in the 2000s, choice paralysis, visual clutter, and no trust in the results I do see.</p>
<p>I'm no longer feeling lucky.</p>
<p><img src="https://chuckwnelson.com/images/google-serp-today.jpg" alt="Google Search Results Today"></p>
<h2>OpenAI's search is becoming Google in the 2000s, if it can remain trustworthy.</h2>
<p>Open AI's ChatGPT search results have entered the scene. It's not perfect, but it's not Google.</p>
<p>The visual clutter is not there because it's a conversation, not a list. It's one answer instead of 10.</p>
<p>It's active intent searching, the thing that made Google successful. Plus, it's conversational. We are trained monkeys to be able to keep asking questions, with the context of the information that came before. It's simple because we are use to it.</p>
<p><strong>Active intent conversations</strong> is just a overly fancy way to say "recommendations." Just like a friend would recommend a restaurant to you based on what you ask for. But we trust our friends.</p>
<p><img src="https://chuckwnelson.com/images/openai-serp.jpg" alt="Open AI Search Results"></p>
<p>Does ChatGPT Search have trust? Open AI isn't monetizing its search just yet, but AI has its own issues with hallucinations.</p>
<p>If Open AI can build its brand and its trust with the consumer, it can dethrone the king.</p>
<p>They know this is important as well. Their website is littered with media quotes stating <a href="https://openai.com/index/introducing-chatgpt-search/">ChatGPT's search</a> links to trustworthy sources, and bringing premium journalism.</p>
<p>This is the fork in the road. There are entire industries waiting to see the direction this goes in. If Open AI goes the way of Google with tons of choices and mental fatigue, it can still be successful, but will be battling to be king of the hill.</p>
<p>But if it can keep it simple <strong>and trustworthy</strong>, it can own the most valuable digital real estate as the sidekick with the single answer.</p>
<p>Google is losing trust with all these buzzing results, and its answer is to throw more spaghetti at the wall to see what sticks. But this just attracts more problems.</p>
<p>In order for Google to keep its crown, it needs to remember what it was in the 2000s and a bit of luck.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. homelessness jumps to record high amid affordable housing shortage (109 pts)]]></title>
            <link>https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</link>
            <guid>42532311</guid>
            <pubDate>Sat, 28 Dec 2024 16:54:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants">https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</a>, See on <a href="https://news.ycombinator.com/item?id=42532311">Hacker News</a></p>
Couldn't get https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[My history with Forth and stack machines (2010) (103 pts)]]></title>
            <link>https://yosefk.com/blog/my-history-with-forth-stack-machines.html</link>
            <guid>42532157</guid>
            <pubDate>Sat, 28 Dec 2024 16:34:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yosefk.com/blog/my-history-with-forth-stack-machines.html">https://yosefk.com/blog/my-history-with-forth-stack-machines.html</a>, See on <a href="https://news.ycombinator.com/item?id=42532157">Hacker News</a></p>
Couldn't get https://yosefk.com/blog/my-history-with-forth-stack-machines.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Are you unable to find employment? (261 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42531830</link>
            <guid>42531830</guid>
            <pubDate>Sat, 28 Dec 2024 15:48:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42531830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="42531830">
      <td><span></span></td>      <td><center><a id="up_42531830" href="https://news.ycombinator.com/vote?id=42531830&amp;how=up&amp;goto=item%3Fid%3D42531830"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=42531830">Ask HN: Are you unable to find employment?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_42531830">117 points</span> by <a href="https://news.ycombinator.com/user?id=w4ffl35">w4ffl35</a> <span title="2024-12-28T15:48:02 1735400882"><a href="https://news.ycombinator.com/item?id=42531830">3 hours ago</a></span> <span id="unv_42531830"></span> | <a href="https://news.ycombinator.com/hide?id=42531830&amp;goto=item%3Fid%3D42531830">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Are%20you%20unable%20to%20find%20employment%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=42531830&amp;auth=53e534d335780effb0dc1b295eec39a0de8d5081">favorite</a> | <a href="https://news.ycombinator.com/item?id=42531830">136&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I am seeing many anecdotal experiences shared online on various platforms stating that it is difficult to find employment in tech. I myself have had a difficult time landing an interview over the last year despite having two decades of experience.</p><p>I am attempting to gain some insight into the issue. My situation is somewhat unique in that I am self-taught without a CS degree. I'm a very experienced, diligent worker, etc, but an algorithm doesn't care about this and so getting through the filters is difficult.</p><p>However I see many discussions being posted (primarily on X) stating that it is nearly impossible for people with CS degrees (especially white males) to get an interview let alone a job. There have been mass layoffs, less money being invested etc. 
Many people have claimed AI is taking jobs, or that there aren't as many jobs available, yet at the same time, Elon Musk and others claim there is an engineer shortage and we must increase the number of H-1B visas in order to fill this gap. When I apply to a position on linkedin I can see that even the most Jr positions have over 100 applicants.</p><p>I know that X can be slanted, and really anything posted online must be taken with a grain of salt - but I'm seeing many people claiming to be in the same situation as myself, and most of them claim to be white males.</p><p>Furthermore, in the last two years I experienced two layoffs. In both situations it was white males let go in favor of Indian and KZ foreigners. Again - this is anecdotal and could be a coincidence, but its awfully telling that Vivek and Elon are calling American tech workers uncultured, lazy and stupid in the wake of these experiences and those that I've read about online.</p><p>I don't want to start a war here on hackernews, but I'm looking for people's personal experiences. Do they match up? Are you having a hard time finding employment? Have you been fired in favor of foreign workers? Is this racism / ageism / sexism at play or is that being overblown by political actors?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Automated My Job Application Process (450 pts)]]></title>
            <link>https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</link>
            <guid>42531695</guid>
            <pubDate>Sat, 28 Dec 2024 15:26:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1">https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</a>, See on <a href="https://news.ycombinator.com/item?id=42531695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>Look, I'll be honest - job hunting sucks.</p>
<p>It's this soul-crushing cycle of copying and pasting the same information over and over again, tweaking your resume for the 100th time, and writing cover letters that make you sound desperate without actually sounding desperate.</p>
<p>But here's the thing: repetitive tasks + structured process = perfect automation candidate.</p>
<p>So I did what any sane developer would do - I built a system to automate the whole damn thing. By the end, I had sent out 250 job applications in 20 minutes. (The irony? I got a job offer before I even finished building it. More on that later.)</p>
<p>Let me walk you through how I did it.</p>
<h2 id="heading-the-job-application-process-is-broken">The Job Application Process is Broken</h2>
<p>Think about it - every job application follows the same basic pattern:</p>
<ol>
<li><p>Find job posting</p>
</li>
<li><p>Check if you're qualified</p>
</li>
<li><p>Research company (let's be real, most people skip this)</p>
</li>
<li><p>Submit resume + cover letter</p>
</li>
<li><p>Wait... and wait... and wait...</p>
</li>
</ol>
<p>It's like a really boring video game where you do the same quest over and over, hoping for different results.</p>
<h2 id="heading-building-the-proof-of-concept">Building the Proof of Concept</h2>
<p>I started by writing some quick Python scripts to test if this crazy idea could work. Here's how I broke it down:</p>
<h3 id="heading-step-1-getting-the-job-listings-the-manual-part">Step 1: Getting the Job Listings (The Manual Part)</h3>
<p>First challenge: getting job listings at scale. I tried web scraping but quickly realized something: job boards are like snowflakes - each one is uniquely annoying to scrape.</p>
<p>I tested dumping entire web pages into an LLM to clean the data, but:</p>
<ul>
<li><p>It was expensive as hell</p>
</li>
<li><p>I didn't want the AI hallucinating job requirements (imagine explaining that in an interview)</p>
</li>
</ul>
<p>So I went old school - manual HTML copying. Yes, it's primitive. Yes, it works. Sometimes the simplest solution is the best solution.</p>
<h3 id="heading-step-2-cleaning-the-raw-html">Step 2: Cleaning the Raw HTML</h3>
<p>The raw HTML was a mess, but I needed structured data like this:</p>
<pre><code>{
    <span>"job_link"</span>: <span>"https://example.com/job/12345"</span>,
    <span>"job_id"</span>: <span>"12345"</span>,
    <span>"job_role"</span>: <span>"software developer"</span>,
    <span>"employer"</span>: <span>"Tech Corp Inc"</span>,
    <span>"location"</span>: <span>"San Francisco, CA"</span>,
    <span>"work_arrangement"</span>: <span>"Remote"</span>,
    <span>"salary"</span>: <span>"$150,000"</span>
}
</code></pre>
<p>Pro tip: You can just show ChatGPT a sample of your HTML and the output format you want, and it'll write the parsing script for you. Work smarter, not harder.</p>
<h3 id="heading-step-3-getting-the-full-job-details">Step 3: Getting the Full Job Details</h3>
<p>This part was straightforward but required some finesse. For each job listing, I made a GET request to fetch the full description. Each request returns raw HTML that still has all the website scaffolding - navigation bars, popups, footer junk, the works.</p>
<p>I wrote a simple HTML parser to strip out everything except the actual job description. Sometimes you'll hit extra hurdles - like having to click a button to reveal the recruiter's email or company details. The good news? Since you're working with one job board at a time, you only need to figure out these patterns once.</p>
<p>Pro tip: Always add delays between requests. I set mine to 2-3 seconds. Sure, it makes the process slower, but it's better than getting your IP banned. Don't be that person who DDOSes job boards - I added delays between requests because I'm not a monster.</p>
<h3 id="heading-step-4-converting-raw-html-to-structured-data">Step 4: Converting Raw HTML to Structured Data</h3>
<p>This is where it gets interesting. Job postings are like people - they all have the same basic parts but the organization is chaos. Some list skills at the top, others bury them in paragraphs of corporate speak.</p>
<p>Enter the LLM prompt that saved my sanity:</p>
<pre><code><span>const</span> prompt = <span>`Please analyze these HTML contents from a job posting and extract information into a structured JSON format.

[... HTML content ...]

Format the response as valid JSON object with these exact keys:
- contact_email
- application_instructions
- job_posting_text (in markdown)
- job_posting_link
- additional_info (salary, location, etc.)
- job_title
- job_company
- job_department
- job_location
- job_skills
- job_instructions (how to apply)

optional keys

- hiring_manager_name
- 
- job_portal
`</span>
</code></pre>
<h3 id="heading-step-5-generating-cover-letters-that-dont-suck">Step 5: Generating Cover Letters That Don't Suck</h3>
<p>The secret to good cover letters? Context. I fed my resume into the LLM along with the job details. This way, the AI could match my experience with their requirements. Suddenly, those "I'm excited about this opportunity" letters actually had substance.</p>
<p>Here's the prompt that made it happen:</p>
<pre><code><span>const</span> prompt = <span>`Please help me write a professional job application email based on the following information:

=== MY RESUME ===
<span>${resumeMarkdown}</span>

=== JOB DETAILS ===
Job Title: <span>${job_title}</span>
Company: <span>${job_company}</span>
Department: <span>${job_department || <span>''</span>}</span>
Location: <span>${job_location || <span>''</span>}</span>
Job Description: <span>${job_posting_text }</span>
Required Skills: <span>${job_skills?.join(<span>', '</span>) || <span>''</span>}</span>
Application Instructions: <span>${job_instructions || <span>''</span>}</span>

Additional Context:
- Hiring Manager Name: <span>${hiring_manager_name || <span>''</span>}</span>
- Referral Source: <span>${referral_source || <span>'Job board'</span>}</span>
- Application Portal: <span>${job_portal || <span>''</span>}</span>

Instructions:
1. Create an email that is ready to send without any placeholders or edits needed
2. If any critical information is missing (like company name or job title), respond with an error message instead of generating incomplete content
3. Skip any optional fields if they're empty rather than including placeholder text
4. Use natural sentence structure instead of obvious template language
5. Include specific details from both the resume and job description to show genuine interest and fit
6. Any links or contact information should be properly formatted and ready to use

Format the response as a JSON object with these keys:
{
  "status": "success" or "error",
  "error_message": "Only present if status is error, explaining what critical information is missing",
  "email": {
    "subject": "The email subject line",
    "body_html": "The email body in HTML format with proper formatting",
    "body_text": "The plain text version of the email",
    "metadata": {
      "key_points_addressed": ["list of main points addressed"],
      "skills_highlighted": ["list of skills mentioned"],
      "resume_matches": ["specific experiences/skills from resume that match job requirements"],
      "missing_recommended_info": ["optional fields that were missing but would strengthen the application if available"],
      "tone_analysis": "brief analysis of the email's tone"
    }
  }
}

Critical required fields (will return error if missing):
- Job title
- Company name
- Job description
- Resume content

Recommended but optional fields:
- Hiring manager name
- Department
- Location
- Application instructions
- Referral source
- Required skills list

Please ensure all HTML in body_html is properly escaped for JSON and uses only basic formatting tags (p, br, b, i, ul, li) to ensure maximum email client compatibility.
`</span>
</code></pre>
<p>The prompt does a few clever things:</p>
<ol>
<li><p>Forces structured output - no wishy-washy responses</p>
</li>
<li><p>Tracks which of your skills match the job requirements</p>
</li>
<li><p>Identifies any missing info that could strengthen the application</p>
</li>
<li><p>Generates both HTML and plain text versions (because some job portals hate formatting)</p>
</li>
</ol>
<p>And here's the kicker - it fails fast if critical info is missing. No more generic "I saw your job posting" emails. Either the cover letter has substance, or it doesn't get sent. Period.</p>
<p>(I start all all my prompts with ‘please’, so that when AI eventually takes over, they would consider me friendly 😁)</p>
<h3 id="heading-step-6-sending-the-emails-the-moment-of-truth">Step 6: Sending the Emails (The Moment of Truth)</h3>
<p>Last step - actually sending these beautifully crafted applications. Sounds simple, right? Just hook up an email service and blast away?</p>
<p>Not so fast. I needed a way to:</p>
<ul>
<li><p>Send professional-looking emails</p>
</li>
<li><p>Track what was actually sent</p>
</li>
<li><p>Monitor responses (can't ghost the recruiters)</p>
</li>
<li><p>Not get flagged as spam (crucial!)</p>
</li>
</ul>
<p>For testing, I sent all emails to a test account first. Pro tip: when you do send to actual recruiters, BCC yourself. Nothing worse than wondering "did that email actually go through?"</p>
<p>At this stage of the POC, I just used a simple email provider like Mailgun. Quick, dirty, but effective. Don't worry - in Part 2, I'll tell you about the rabbit hole I went down trying to build a full email management system. (Spoiler: it involves rejected AWS applications and a failed attempt at running my own email server. Good times.)</p>
<h2 id="heading-the-results">The Results</h2>
<p>The proof of concept worked better than expected. I could take a job board, extract listings, parse them, and generate personalized applications - all with a few Python scripts.</p>
<p>But this was just the beginning. The real challenge? Turning these scripts into a proper application that could:</p>
<ul>
<li><p>Handle multiple job boards</p>
</li>
<li><p>Track applications</p>
</li>
<li><p>Manage email responses</p>
</li>
<li><p>Not get me blacklisted from every HR system in existence</p>
</li>
</ul>
<p>In Part 2, I'll show you how I built the actual application, complete with all the technical decisions, trade-offs, and "what was I thinking" moments.</p>
<p>Stay tuned - it gets even better.</p>
<hr>
<p><em>Want to know when Part 2 drops? Follow me on</em> <a target="_blank" href="https://x.com/DavidDodda_"><em>Twitter</em></a> <em>or</em> <a target="_blank" href="https://www.linkedin.com/in/arundavidreddy/"><em>LinkedIn</em></a><em>. And yes, I'll eventually tell you how I got a job offer before finishing this project. It's a good story.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EmacsConf 2024 Notes (290 pts)]]></title>
            <link>https://sachachua.com/blog/2024/12/emacsconf-2024-notes/</link>
            <guid>42531217</guid>
            <pubDate>Sat, 28 Dec 2024 14:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sachachua.com/blog/2024/12/emacsconf-2024-notes/">https://sachachua.com/blog/2024/12/emacsconf-2024-notes/</a>, See on <a href="https://news.ycombinator.com/item?id=42531217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
    <nav><a href="https://sachachua.com/blog/2024/12/emacs-tv/">emacs.tv »</a></nav><article id="index0">
<header>
Posted: <time>Dec 27, 2024</time> - Modified: <time>Dec 28, 2024</time>| <span><a href="https://sachachua.com/blog/category/emacs">emacs</a>, <a href="https://sachachua.com/blog/category/emacsconf">emacsconf</a></span>
</header>
<div>
<p>
<span><span>[2024-12-28 Sat]</span></span>: Added talk and Q&amp;A count, added note about BBB max simultaneous users, added note about BBB, added thanks
</p>

<p>
<a href="https://emacsconf.org/2024/talks">The videos have been uploaded</a>, thank-you notes
have been sent, and the kiddo has decided to play
a little Minecraft on her own, so now I get to
write some quick notes on <a href="https://emacsconf.org/2024">EmacsConf 2024</a>.
</p>


<div id="outline-container-emacsconf-2024-notes-stats">
<h2 id="emacsconf-2024-notes-stats">Stats</h2>
<div id="text-emacsconf-2024-notes-stats">
<table>


<colgroup>
<col>

<col>
</colgroup>
<tbody>
<tr>
<td>Talks</td>
<td>31</td>
</tr>

<tr>
<td>Hours</td>
<td>10.7</td>
</tr>

<tr>
<td>Q&amp;A web conferences</td>
<td>21</td>
</tr>

<tr>
<td>Hours</td>
<td>7.8</td>
</tr>
</tbody>
</table>


<ul>
<li>Saturday:
<ul>
<li>gen: 177 peak + 14 peak lowres</li>
<li>dev: 226 peak + 79 peak lowres</li>
</ul></li>
<li>Sunday:
<ul>
<li>gen: 89 peak + 10 peak lowres</li>
</ul></li>
</ul>

<p>
Server configuration:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<tbody>
<tr>
<td>meet</td>
<td>16GB 8core dedicated</td>
<td>peak 409% CPU (100% is 1 CPU), average 69.4%</td>
</tr>

<tr>
<td>front</td>
<td>32GB 8core shared</td>
<td>peak 70.66% CPU (100% is 1 CPU)</td>
</tr>

<tr>
<td>live</td>
<td>64GB 16core shared</td>
<td>peak 552% CPU (100% is 1 CPU) average 144%</td>
</tr>

<tr>
<td>res</td>
<td>46GB 12core</td>
<td>peak 81.54% total CPU (100% is 12 CPUs); each OBS ~250%), mem 7GB used</td>
</tr>

<tr>
<td>media</td>
<td>3GB 1core</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>

<p>
YouTube livestream stats:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">Shift</th>
<th scope="col">Peak</th>
<th scope="col">Avg</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gen Sat AM</td>
<td>46</td>
<td>28</td>
</tr>

<tr>
<td>Gen Sat PM</td>
<td>24</td>
<td>16</td>
</tr>

<tr>
<td>Dev Sat AM</td>
<td>15</td>
<td>7</td>
</tr>

<tr>
<td>Dev Sat PM</td>
<td>20</td>
<td>12</td>
</tr>

<tr>
<td>Gen Sun AM</td>
<td>28</td>
<td>17</td>
</tr>

<tr>
<td>Gen Sun PM</td>
<td>26</td>
<td>18</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-timeline">
<h2 id="emacsconf-2024-notes-timeline">Timeline</h2>
<div id="text-emacsconf-2024-notes-timeline">
<table>


<colgroup>
<col>

<col>
</colgroup>
<tbody>
<tr>
<td>Call for proposals</td>
<td><span><span>[2024-06-30 Sun]</span></span></td>
</tr>

<tr>
<td>CFP deadline</td>
<td><span><span>[2024-09-20 Fri]</span></span></td>
</tr>

<tr>
<td>Speaker notifications</td>
<td><span><span>[2024-09-27 Fri]</span></span></td>
</tr>

<tr>
<td>Publish schedule</td>
<td><span><span>[2024-10-25 Fri]</span></span></td>
</tr>

<tr>
<td>Video target date</td>
<td><span><span>[2024-11-08 Fri]</span></span></td>
</tr>

<tr>
<td>EmacsConf</td>
<td><span><span>[2024-12-07 Sat]</span></span>-<span><span>[2024-12-07 Sat]</span></span></td>
</tr>
</tbody>
</table>

<p>
We did early acceptances again this year. That was
nice. I wasn't sure about committing longer
periods of time early in the scheduling process,
so I usually tried to nudge people to plan a
20-minute video with the option of possibly doing
more, and I okayed longer talks once we figured
out what the schedule looked like.
</p>

<p>
There were 82 days between the call for proposals
and the CFP deadline, another 49 days from that to
the video target date, and 29 days between the
video target date and EmacsConf. It felt like
there was a good amount of time for proposals and
videos. Six videos came in before or on the target
date. The rest trickled in afterwards, which was
fine because we wanted to keep things low-pressure
for the speakers. We had enough capacity to
process and caption the videos as they came in.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-data">
<h2 id="emacsconf-2024-notes-data">Data</h2>
<div id="text-emacsconf-2024-notes-data">
<p>
We continued to use an Org file to store the talk information.
It would be great to add some validation functions:
</p>

<ul>
<li>Check permissions and ownership for files</li>
<li>Check case sensitivity for Q&amp;A type detection</li>
<li>Check BBB redirect pages to make sure they exist</li>
<li>Check transcripts for ` because that messes up formatting;
consider escaping for the wiki</li>
<li>Check files are public and readable</li>
<li>Check captioned by comment vs caption status vs captioner</li>
</ul>

<p>
Speakers uploaded their files via <a href="https://github.com/psi-4ward/psitransfer">PsiTransfer</a>
again. I didn't get around to setting up the FTP
server. I should probably rename
ftp-upload.emacsconf.org to upload.emacsconf.org
so that people don't get confused.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-communication">
<h2 id="emacsconf-2024-notes-communication">Communication</h2>
<div id="text-emacsconf-2024-notes-communication">
<p>
As usual, we announced the EmacsConf call for
proposals on <a href="https://lists.gnu.org/archive/html/emacs-tangents/2024-06/msg00004.html">emacs-tangents</a>, <a href="https://sachachua.com/blog/2024/07/2024-07-01-emacs-news/">Emacs News</a>,
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a>, <a href="https://lists.gnu.org/archive/html/emacsconf-org/2024-06/msg00000.html">emacsconf-org</a>,
<a href="https://reddit.com/r/emacs">https://reddit.com/r/emacs</a>. <a href="https://systemcrafters.net/live-streams/july-12-2024/">System Crafters</a>,
<a href="https://irreal.org/blog/?p=12280">Irreal</a>, and <a href="https://emacs-apac.gitlab.io/announcements/november-2024/">Emacs APAC</a>, mentioned it, and people
also posted about EmacsConf on <a href="https://mastodon.social/tags/emacsconf">Mastodon</a>, <a href="https://x.com/search?q=%23emacsconf&amp;src=typed_query&amp;f=live">X</a>,
<a href="https://bsky.app/hashtag/emacsconf">BlueSky</a>, and <a href="https://www.facebook.com/story.php?story_fbid=538504738701826&amp;id=100076269125316&amp;_rdr">Facebook</a>. <a href="https://toot.si/@len/113392360015917614">@len@toot.si suggested</a>
submitting EmacsConf to <a href="https://foss.events/">https://foss.events</a>, so I
did. There was some other <a href="https://www.reddit.com/r/emacs/comments/1h5c778/which_emacsconf_2024_talks_have_your_attention/">EmacsConf-related
discussions</a> in r/emacs. <a href="https://200ok.ch/posts/2024-09-16_announcing_emacsconf__official_swiss_satellite.html">200ok and Ardeo</a> organized
an in-person meetup in Switzerland, and <a href="https://dogodki.kompot.si/events/00a6f9ee-9087-400d-9d9b-d51b98561424">emacs.si got together in Ljubljana</a>.
</p>

<p>
For communicating with speakers and volunteers, I
used lots of mail merge
(<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-mail.el">emacsconf-mail.el</a>). Most of the
templates only needed a little tweaking from last
year's code. I added a function to help me
double-check delivery, since the batches that I
tried to send via async sometimes ran into errors.
</p>

<p>
Next time, I think it could be interesting to add
more blog posts and Mastodon toots.
</p>

<p>
Also, maybe it would be good to get in touch with podcasts like
</p>

<ul>
<li><a href="https://systemcrafters.net/">System Crafters</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLbFVcOQ-YH_LRP687N0YeN78YZmBp5wqF">This Week in Linux</a></li>
<li><a href="https://linuxunplugged.com/">Linux Unplugged</a></li>
<li><a href="http://asknoahshow.com/">Ask Noah</a></li>
<li><a href="https://linuxafterdark.net/">Linux After Dark</a></li>
<li><a href="https://anonradio.net/">Lispy Gopher Show</a></li>
</ul>

<p>
to give a heads up on EmacsConf before it
happens and also let them know when videos are
available.
</p>

<p>
We continued to use <a href="https://www.mumble.info/">Mumble</a> for backstage coordination. It worked out well.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-schedule">
<h2 id="emacsconf-2024-notes-schedule">Schedule</h2>
<div id="text-emacsconf-2024-notes-schedule">
<p>
The schedule worked out to two days of talks, with
two tracks on the first day, and about 15-20
minutes between each talk. We were able to adapt
to late submissions, last-minute cancellations,
and last-minute switches from Q&amp;A to live.
</p>

<p>
We added an open mic session on Sunday to fill in
the time from a last-minute cancellation. That
worked out nicely and it might be a good idea to
schedule in that time next year. It was also good
to move some of the usual closing remarks earlier.
We were able to wrap up in a timely manner, which
was great for some hosts and participants because
they didn't have to stay up so late.
</p>

<p>
Sunday was single-track, so it was nice and
relaxed. I was a little worried that people might
get bored if the current talk wasn't relevant to
their interests, but everyone managed just fine. I
probably should have remembered that Emacs people
are good at turning extra time into more
configuration tweaks.
</p>

<p>
Most of the scheduling was determined by people's
time constraints, so I didn't worry too much about
making the talks flow logically. I accidentally
forgot to note down one speaker's time
constraints, but he caught it when we e-mailed the
draft schedule and I was able to move things
around for a better time for him.
</p>

<p>
There was a tiny bit of technical confusion
because the automated schedule publishing on res
had case-sensitive matching (<code>case-fold-search</code>
was set to <code>nil</code>), so if a talk was set to "Live"
Q&amp;A, it didn't announce it as a live talk because
it was looking for <code>live</code>. Whoops. I've added that
configuration setting to my
<code>emacsconf-stream-config.el</code>, so the ansible
scripts should get it next time.
</p>

<p>
I asked Leo and Corwin if they wanted to manually
control the talks this year. They opted to leave
it automatically managed by crontab so that they
wouldn't have to worry as much about timekeeping.
It worked reliably. Hooray for automation! The
only scheduling hiccup was because I turned off
the crontab so that we could do Saturday closing
remarks when we wanted to and I forgot to reenable
autopilot the next day. We noticed when the
opening remarks didn't start right on the dot, and
I got everything back on track.
</p>

<p>
Like last year, I scheduled the dev track to start
a little later than the gen track. That made for a
less frantic morning. Also, this year we scheduled
Sunday morning to start with more IRC Q&amp;A instead
of live Q&amp;A. We didn't notice any bandwidth issues
on Sunday morning this time.
</p>

<p>
It would be nice to have Javascript countdowns in
some kind of web interface to make it easier for
hosts, especially if we can update it with the
actual time the current video will end in MPV.
</p>

<p>
I can also update the <a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-stream.el">emacsconf-stream.el</a> code to
make it easier to automatically count down to the
next talk or to a specific talk.
</p>

<p>
We have Javascript showing local time on the
individual talk pages, but it would be nice to
localize the times on all the schedule/watch pages
too.
</p>

<p>
Most of my stuff (scheduling, publishing, etc.) is
handled by automation with just a little bit of
manual nudging every so often, so it might be
possible to organize an event that's more friendly
to Europe/APAC timezones.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-recorded-videos">
<h2 id="emacsconf-2024-notes-recorded-videos">Recorded videos</h2>
<div id="text-emacsconf-2024-notes-recorded-videos">
<p>
As usual, we strongly encouraged speakers to
record videos to lower everyone's stress levels
and allow for captioning by volunteers, so that's
what most speakers did. We were able to handle
a few last-minute submissions as well as a
live talk. Getting videos also meant we could
publish them as each talk went live, including
automatically putting the videos and transcripts
on the wiki.
</p>

<p>
We didn't have obvious video encoding cut-offs, so
re-encoding in a screen was a reliable way to
avoid interruptions this year. Also, no one
complained about tiny text or low resolution, so
the talk preparation instructions seem to be
working out.
</p>

<p>
Automatically normalizing the audio with
ffmpeg-normalize didn't work out, so Leo Vivier
did a last-minute scramble to normalize the audio
the day before the conference. Maybe that's
something that volunteers can help with during the
lead-up to the conference, or maybe I can finally
figure out how to fit that into my process. I
don't have much time or patience to listen to
things, but it would be nice to get that sorted
out early.
</p>

<p>
Next year we can try remixing the audio to mono.
One of the talks had some audio moving around,
which was a little distracting. Also, some people
listen to the talks in one ear, so it would be
good to drop things down to mono for them.
</p>

<p>
We think 60fps videos stressed the res server a
bit, resulting in dropped frames. Next year, we
can downsample those to 30fps and add a note to
the talk preparation instructions. The hosts also
suggested looking into setting up streaming from
each host's computer instead of using our shared
VNC sessions.
</p>

<p>
There was some colour smearing and weirdness when
we played some videos with mpv on res. Upgrading
MPV to v0.38 fixed it.
</p>

<p>
Some people requested dark mode (light text on
dark background), so maybe we can experiment with
recommending that next year.
</p>

<p>
I did a last-minute change to the shell scripts to
load resources from the cache directory instead of
the assets/stream directory, but I didn't get all
of the file references, so sometimes the test
videos played or the introductions didn't have
captions. On the plus side, I learned how to use
<code>j</code> in MPV to reload a subtitle file.
</p>

<p>
Sometimes we needed to play the videos manually.
If we get the hang of starting MPV in a screen or
tmux session, it might be easier for hosts to
check how much time is left, or to restart a video
at a specific point if needed. Leo said he'll work
on figuring out the configuration and the Lua
scripts.
</p>

<p>
I uploaded all the videos to YouTube and scheduled
them. That was nice because then I didn't have to
keep updating things during the conference. It
turns out that Toobnix also has a way to schedule
uploads. I just need to upload it as unlisted
first, and then choose Scheduled from the
visibility. I wonder if <a href="https://www.npmjs.com/package/%40peertube%2Fpeertube-cli">peertube-cli</a> can be
extended to schedule things. Anyway, since I
didn't know about that during the conference, I
just used <code>emacsconf-publish-upload-talk</code> function
to upload videos.
</p>

<p>
It was fun playing <a href="https://www.youtube.com/watch?v=urcL86UpqZc">Interview with an Emacs
Enthusiast in 2023 [Colorized] - YouTube</a> at lunch.
I put together some captions for it after the
conference, so maybe we can play it with captions
next year.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-recorded-introductions">
<h2 id="emacsconf-2024-notes-recorded-introductions">Recorded introductions</h2>
<div id="text-emacsconf-2024-notes-recorded-introductions">
<p>
We record introductions so that hosts don't have
to worry about how to say things on air. I should
probably send the intro check e-mail
earlier–maybe on the original video target date,
even if speakers haven't submitted their videos
yet. This will reduce the last-minute scramble to
correct intros.
</p>

<p>
When I switched the shell scripts to use the cache
directory, I forgot to get it to do the intros
from that directory as well, so some of the
uncorrected intros were played.
</p>

<p>
I forgot to copy the intro VTTs to the cache
directory. This should be handled by the
subed-record process for creating intros, so it'll
be all sorted out next year.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-captioning">
<h2 id="emacsconf-2024-notes-captioning">Captioning</h2>
<div id="text-emacsconf-2024-notes-captioning">
<p>
We used <a href="https://github.com/m-bain/whisperX">WhisperX</a> for speech-to-text this year. It
did a great job at preparing the first drafts of
captions that our wonderful army of volunteer
captioners could then edit. WhisperX's built-in
voice activity detection cut down a lot on the
hallucinations that <a href="https://github.com/openai/whisper">OpenAI Whisper</a> had during
periods of silence in last year's captions, and
there was only one instance of WhisperX missing a
chunk of text from a speaker that I needed to
manually fill in. I upgraded to a Lenovo P52 with
64GB RAM, so I was able to handle last-minute
caption processing on my computer. It might be
handy to have a smaller model ready for those
last-minute requests, or have something ready to
go for the commercial APIs.
</p>

<p>
The timestamps were a little bit off. It was
really helpful that speakers and volunteers used
the backstage area to check video quality. I used
<a href="https://www.readbeyond.it/aeneas/">Aeneas</a> to re-align the text, but Aeneas was also
confused by silences. I've added some code to
<a href="https://github.com/sachac/subed">subed</a> so that I can realign regions of subtitles
using Aeneas or WhisperX timestamps, and I also
wrote some code to <a href="https://sachachua.com/blog/2024/11/checking-caption-timing-by-skimming-with-emacs-lisp-or-js/">skim timestamps for easy
verification</a>.
</p>

<p>
Anush V experimented with using machine learning
for <a href="https://gitlab.com/jun8git/sub-seg">subtitle segmentation</a>, so that might be
something to explore going forward.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-bigbluebutton-web-conference">
<h2 id="emacsconf-2024-notes-bigbluebutton-web-conference">BigBlueButton web conference</h2>
<div id="text-emacsconf-2024-notes-bigbluebutton-web-conference">
<p>
This year we set up a new <a href="https://demo.bigbluebutton.org/">BigBlueButton</a> web conferencing server. The server with our previous BigBlueButton instance had been donated by a defunct nonprofit, so it finally got removed on October 27. After investigating whether Jitsi or Galene might be a good fit for EmacsConf, we decided to continue with BigBlueButton. There were some concerns about <a href="https://github.com/bigbluebutton/bbb-install/issues/261">non-free Mongo</a> for BBB versions &gt;= 2.3 and &lt; 3, so I installed BBB 3.0. This was hard to get working on a Docker on the existing res server. <a href="https://emacsconf.org/2024/organizers-notebook/#bbb">We decided</a> it was worth spinning up an additional Linode virtual private server. It turned out that BBB refused to run on anything smaller than 8GB/4core, so I scaled up to that during testing, scaled back down to 1GB/1core in between, and scaled up to 16GB/8core dedicated during the conference.
</p>

<p>
I'm still not 100% sure I set everything up
correctly or that everything was stable. Maybe
next year BBB 3.0 will be better-tested, someone
more sysad-y can doublecheck the setup, or we can
try <a href="https://galene.org/">Galene</a>.
</p>

<p>
One of the benefits of upgrading to BBB 3.0 was
that we could use the smart layout feature to drag
the webcam thumbnails to the side of the shared
screen. This made shared screens much easier to
read. I haven't automated this yet, but it was
easy enough for us to do via the shared VNC
session.
</p>

<p>
On the plus side, it was pretty straightforward to use the Rails console to create all the rooms. We used moderator access codes to give all the speakers moderator access. Mysteriously, superadmins didn't automatically have moderator access to all the rooms even if they were logged in, so we needed to add host access by hand so that they could start the recordings.
</p>

<p>
Since we self-hosted and were budgeting more for the full-scale node, I didn't feel comfortable scaling it up to production size until a few days before the conference. I sent the access codes with the check-in e-mails to give speakers time to try things out.
</p>

<p>
<a href="https://sachachua.com/blog/2023/12/emacsconf-backstage-figuring-out-our-maximum-number-of-simultaneous-bigbluebutton-users/">Compared to last year's stats</a>:
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">&nbsp;</th>
<th scope="col">2023</th>
<th scope="col">2024</th>
</tr>
</thead>
<tbody>
<tr>
<td>Max number of simultaneous users</td>
<td>62</td>
<td>107</td>
</tr>

<tr>
<td>Max number of simultaneous meetings</td>
<td>6</td>
<td>7</td>
</tr>

<tr>
<td>Max number of people in one meeting</td>
<td>27</td>
<td>25</td>
</tr>

<tr>
<td>Total unique people</td>
<td>84</td>
<td>102</td>
</tr>

<tr>
<td>Total unique talking</td>
<td>36</td>
<td>40</td>
</tr>
</tbody>
</table>

<p>
(Max number of simultaneous users wasn't deduplicated, since we need that number for server load planning)
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-tech-checks-and-hosting">
<h2 id="emacsconf-2024-notes-tech-checks-and-hosting">Tech checks and hosting</h2>
<div id="text-emacsconf-2024-notes-tech-checks-and-hosting">
<p>
FlowyCoder did a great job getting everyone
checked in, especially once I figured out the
right checklist to use. We used people's emergency
contact information a couple of times.
</p>

<p>
Corwin and Leo were able to jump in and out of the
different streams for hosting. Sometimes they were
both in the same Q&amp;A session, which made it more
conversational especially when they were covering
for technical issues. We had a couple of crashes
even though the tech checks went fine, so that was
weird. Maybe something's up with BBB 3.0 or how I
set it up.
</p>

<p>
Next time, we can consider asking speakers what
kind of facilitation style they like. A chatty
host? Someone who focuses on reading the questions
and then gets out of the way? Speakers reading
their own questions and the host focusing on
timekeeping/troubleshooting?
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-streaming">
<h2 id="emacsconf-2024-notes-streaming">Streaming</h2>
<div id="text-emacsconf-2024-notes-streaming">
<p>
I experimented with setting up the live0 streaming
node as a 64GB 32core dedicated CPU server, but
that was overkill, so we went back down to 64GB
16core and it still didn't approach the CPU
limits.
</p>

<p>
The 480p stream seemed stable, hooray! I had set
it up last year to automatically kick in as soon
as I started streaming to Icecast, and that worked
out. I think I changed a loop to be <code>while true</code>
instead of making it try 5 times, so that probably
helped.
</p>

<p>
I couldn't get Toobnix livestreaming to work this
year. On the plus side, that meant that I could
use OBS to directly stream to YouTube instead of
trying to set up multicasting. I set up one
YouTube livestreaming event for each shift and
added the RTMP keys to our shift checklists so
that I could update the settings before starting
the stream. That was pretty straightforward.
</p>

<p>
This year, I wrote a little randomizer function to
display things on the countdown screen. At first I
just dumped in
<a href="https://www.gnu.org/fun/jokes/gnuemacs.acro.exp.en.html">https://www.gnu.org/fun/jokes/gnuemacs.acro.exp.en.html</a>,
but some of those were not quite what I was
looking for. (… Probably should've read them all
first!) Then I added random packages from GNU ELPA
and NonGNU ELPA, and that was more fun. I might
add MELPA next time too. The code for dumping
random packages is probably worth putting into a
different blog post, since it's the sort of thing
people might like to add to their dashboards or
screensavers.
</p>

<p>
I ran into some C-s annoyances in screen even with
flow control turned off, so it might be a good
idea to switch to tmux instead of screen.
</p>

<p>
Next year, I think it might be a good idea to make
intro images for each talk. Then we can use that
as the opening slide in BigBlueButton (unless
they're already sharing something else) as well as
a video thumbnail.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-publishing">
<h2 id="emacsconf-2024-notes-publishing">Publishing</h2>
<div id="text-emacsconf-2024-notes-publishing">
<p>
The automated process for publishing talks and
transcripts to the wiki occasionally needed
nudging when someone else had committed a change
to the wiki. I thought I had a <code>git pull</code> in there
somewhere, but maybe I need to look at it some
more.
</p>

<p>
I forgot to switch the conference publishing phase
and enable the inclusion of Etherpads, but
fortunately Ihor noticed. I did some last-minute
hacking to add them in, and then I remembered the
variables I needed to set. Just need to add it to
our process documentation.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-etherpad">
<h2 id="emacsconf-2024-notes-etherpad">Etherpad</h2>
<div id="text-emacsconf-2024-notes-etherpad">
<p>
We used <a href="https://etherpad.org/">Etherpad</a> 1.9.7 to collect Q&amp;A again this
year. I didn't upgrade to Etherpad v2.x because I
couldn't figure out how to get it running within
the time I set aside for it, but maybe that's
something for next year.
</p>

<p>
I wrote some Elisp to copy the current ERC line
(unwrapped) for easier pasting into Etherpad. That
worked out really well, and it let me keep up with
copying questions from IRC to the pad in between
other bits of running around.
(<code>emacsconf-erc-copy</code> in
<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-erc.el">emacsconf-erc.el</a>)
</p>

<p>
Next year, I'll add pronouns and pronunciations to
the Etherpad template so that hosts can refer to
them easily.
</p>

<p>
If I rejig the template to move the next/previous
links so that notes can be added to the end, I
might be able to use the Etherpad API to add text
from IRC.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-irc">
<h2 id="emacsconf-2024-notes-irc">IRC</h2>
<div id="text-emacsconf-2024-notes-irc">
<p>
We remembered to give the libera.chat people a
heads-up before the conference, so we didn't run
into usage limits for <a href="https://chat.emacsconf.org/">https://chat.emacsconf.org</a>. Yay!
</p>

<p>
Aside from writing <code>emacsconf-erc-copy</code>
(<a href="https://git.emacsconf.org/emacsconf-el/tree/emacsconf-erc.el">emacsconf-erc.el</a>) to make it easier
to add text from IRC to the Etherpad, I didn't
tinker much with the IRC setup for this year. It
continued to be a solid platform for discussion.
</p>

<p>
I think a keyboard shortcut for inserting a talk's
URL could be handy and should be pretty easy to
add to my Embark keymap.
</p>
</div>
</div>

<div id="outline-container-emacsconf-2024-notes-budget-and-donations">
<h2 id="emacsconf-2024-notes-budget-and-donations">Budget and donations</h2>
<div id="text-emacsconf-2024-notes-budget-and-donations">
<p>
The total hosting cost for the conference was USD
42.92 + tax and the BBB testing in the lead-up to
the conference was USD 3.11 + tax, so a total of
USD 46.03+tax. The web node and the livestreaming
node are kept as 1GB nanodes the rest of the year
(USD 5 x 2 servers + tax, so USD 110). Very
manageable.
</p>

<p>
The Free Software Foundation also provided
<a href="https://media.emacsconf.org/">media.emacsconf.org</a> for serving media files. Ry P
provided res.emacsconf.org for OBS streaming over
VNC sessions.
</p>

<p>
Amin Bandali was away during the conference
weekend and no one else knew how to get the list
of donors and current donation stats from the FSF
Working Together program on short notice. Next
time, we can get that sorted out beforehand so
that we can thank donors properly.
</p>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-documentation-and-time">
<h2 id="emacsconf-2024-notes-documentation-and-time">Documentation and time</h2>
<div id="text-emacsconf-2024-notes-documentation-and-time">
<p>
I think my biggest challenge was having less time
to prepare for EmacsConf this year because the
kiddo wanted more of my attention. In many ways,
the automation that I'd been gradually building up
paid off. We were able to pull together EmacsConf
even though I had limited focus time.
</p>

<p>
Here's my Emacs-related time data (including Emacs
News and tweaking my config):
</p>

<table>


<colgroup>
<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">Year</th>
<th scope="col">Jan</th>
<th scope="col">Feb</th>
<th scope="col">March</th>
<th scope="col">April</th>
<th scope="col">May</th>
<th scope="col">June</th>
<th scope="col">July</th>
<th scope="col">Aug</th>
<th scope="col">Sept</th>
<th scope="col">Oct</th>
<th scope="col">Nov</th>
<th scope="col">Dec</th>
<th scope="col">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>23.4</td>
<td>15.9</td>
<td>16.2</td>
<td>11.2</td>
<td>4.4</td>
<td>11.5</td>
<td>6.5</td>
<td>13.3</td>
<td>36.6</td>
<td>86.6</td>
<td>93.2</td>
<td>113.0</td>
<td>432</td>
</tr>

<tr>
<td>2024</td>
<td>71.2</td>
<td>12.0</td>
<td>5.6</td>
<td>6.6</td>
<td>3.3</td>
<td>9.6</td>
<td>11.0</td>
<td>4.7</td>
<td>36.0</td>
<td>40.3</td>
<td>52.3</td>
<td>67.7</td>
<td>320</td>
</tr>
</tbody>
</table>

<p>
(and here's a <a href="https://sachachua.com/blog/2023/12/analyzing-my-emacs-time-over-the-last-11-years-or-so/">longer-term analysis going back to 2012</a>.)
</p>

<p>
I spent 92.6 hours total in October and November
2024 doing Emacs-related things, compared to 179.8
hours the previous year – so, around half the
time. Part of the 2023 total was related to
preparing my presentation for EmacsConf, so I was
much more familiar with my scripts then.
Apparently, there was still a lot more that I
needed to document. As I scrambled to get
EmacsConf sorted out, I captured quick tasks/notes
for the things I need to add to our organizers
notebook. Now I get to go through all those notes
in my inbox. Maybe next year will be even
smoother.
</p>

<p>
On the plus side, all the process-related
improvements meant that the other volunteers could
jump in pretty much whenever they wanted,
including during the conference itself. I didn't
want to impose firm commitments on people or bug
them too much by e-mail, so we kept things very
chill in terms of scheduling and planning. If
people were available, we had stuff people could
help with. If people were busy, that was fine, we
could manage. This was nice, especially when I
applied the same sort of chill approach to myself.
</p>

<p>
I'd like to eventually get to the point of being
able to mostly follow my checklists and notes from
the start of the conference planning process to
the end. I've been moving notes from year-specific
organizer notebooks to the main <a href="https://emacsconf.org/organizers-notebook/">organizers'
notebook</a>. I plan to keep that one as the main file
for notes and processes, and then to have specific
dates and notes in the yearly ones.
</p>
</div>
</div>
<div id="outline-container-orgf96c4c3">
<h2 id="orgf96c4c3">Thanks</h2>
<div id="text-orgf96c4c3">
<ul>
<li>Thank you to all the speakers, volunteers, and participants, and to all those other people in our lives who make it possible through time and support.</li>
<li>Thanks to Leo Vivier and Corwin Brust for hosting the sessions, and to FlowyCoder for checking people in.</li>
<li>Thanks to our proposal review volunteers James Howell, JC Helary, and others for helping with the early acceptance process.</li>
<li>Thanks to our captioning volunteers: Mark Lewin, Rodrigo Morales, Anush, annona, and James Howell, and some speakers who captioned their own talks.</li>
<li>Thanks to Leo Vivier for fiddling with the audio to get things nicely synced.</li>
<li>Thanks to volunteers who kept the mailing lists free from spam.</li>
<li>Thanks to Bhavin Gandhi, Christopher Howard, Joseph Turner, and screwlisp for quality-checking.</li>
<li>Thanks to shoshin for the music.</li>
<li>Thanks to Amin Bandali for help with infrastructure and communication.</li>
<li>Thanks to Ry P for the server that we're using for OBS streaming and for processing videos.</li>
<li>Thanks to the Free Software Foundation for Emacs itself, the mailing lists, the media.emacsconf.org server, and handling donations on our behalf through the FSF Working Together program. <a href="https://www.fsf.org/working-together/fund">https://www.fsf.org/working-together/fund</a></li>
<li>Thanks to the many users and contributers and project teams that create all the awesome free software we use, especially: BigBlueButton, Etherpad, Icecast, OBS, TheLounge, libera.chat, ffmpeg, OpenAI Whisper, WhisperX, the aeneas forced alignment tool, PsiTransfer, subed, and many, many other tools and services we used to prepare and host this years conference</li>
<li>Thanks to everyone!</li>
</ul>
</div>
</div>
<div id="outline-container-emacsconf-2024-notes-overall">
<h2 id="emacsconf-2024-notes-overall">Overall</h2>
<div id="text-emacsconf-2024-notes-overall">
<p>
Good experience. Lots of fun. I'd love to do it
again next year. EmacsConf feels like a nice, cozy
get-together where people share the cool things
they've been working on and thinking about. People had fun!
They said:
</p>

<ul>
<li>"emacsconf is absolutely knocking it out of the park when it comes to conference logistics"</li>
<li>"I think this conference has defined the terms for a successful online conference."</li>
<li>"EmacsConf is one of the big highlights of my year every year. Thank you a ton for running this 😊"</li>
</ul>

<p>
It's one of the highlights of my year too. =) Looking forward to the next one!
</p>

<p>
In the meantime, y'all can stay connected via <a href="https://sachachua.com/blog/category/emacs-news/">Emacs News</a>, <a href="https://emacs-berlin.org/">meetups (online and in person)</a>, <a href="https://planet.emacslife.com/">Planet Emacslife</a>, and now <a href="https://emacs.tv/">emacs.tv</a>. Enjoy!
</p>

<p>
p.s. I'd love to learn from other people's conference blog posts, EmacsConf or otherwise. I'm particularly interested in virtual conferences and how we can tinker with them to make them even better. I'm having a hard time finding posts; please feel free to send me links to ones you've liked or written!</p>
</div>
</div>

</div>

</article><nav><a href="https://sachachua.com/blog/2024/12/emacs-tv/">emacs.tv »</a></nav>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So You Want to Write Java in Neovim (148 pts)]]></title>
            <link>https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/</link>
            <guid>42530991</guid>
            <pubDate>Sat, 28 Dec 2024 13:41:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/">https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/</a>, See on <a href="https://news.ycombinator.com/item?id=42530991">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
        

        

        <section>
            <p>Note: I plan on keeping this post updated if I need to add more content or change something</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-test.png" alt="alt text"></p>
<p>I have been doing Java in Neovim for quite a while at work, and it’s been a very pleasant experience. As Neovim usage grows (especially amongst the younger crowd), I want to share how I do it.</p>
<p>I think historically it's been considered a painful experience, but with guidance, it can be very straightforward!</p>
<p>I’ll preface this by saying that if Neovim isn’t your primary editor, you should first try an IDE specifically for Java (they should all have a Vim plugin):</p>
<ul>
<li>Eclipse</li>
<li>IntelliJ</li>
<li>Apache Netbeans</li>
</ul>
<p>If Neovim is your primary editor, you probably hate opening *insert IDE that turns you into snail* for a specific language, and so did I.</p>
<h2 id="lsp">LSP</h2>
<p>Java has one LSP option for Neovim, and that’s JDTLS (Java Development Tools Language Server) by Eclipse. You should read the project README for a high-level overview on it (including features): <a href="https://github.com/eclipse-jdtls/eclipse.jdt.ls">JDTLS GitHub</a></p>
<p>It’s a great LSP for Java, and I think it’s all you need to work with Java projects. My personal workflow usually involves one tmux window with a project open and another window handling the compiling, testing etc</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-k.png" alt="alt text"></p>
<p>To use JDTLS in Neovim, there are two plugins you can choose from, and which you decide on depends on your preferences.</p>
<h2 id="you-use-a-distro">YOU USE A DISTRO</h2>
<p>If you're happy accepting out-of-the-box, all-in-one setups, then <a href="https://github.com/nvim-java/nvim-java">nvim-java</a> might be for you.
It attempts to be a comprehensive solution with popular defaults, and be hassle-free when it comes to LSP, debugging, testing setups.
It’s not completely flexible, so if you need more control, you should try the next option.</p>
<h2 id="you-read-the-friendly-manual">YOU READ THE FRIENDLY MANUAL</h2>
<p>I expect the majority to fit here, and <a href="https://github.com/mfussenegger/nvim-jdtls">nvim-jdtls</a> is the go-to Java plugin for LSP support in Neovim. You have full access to configure JDTLS, and I highly recommend reading through the available options.</p>
<p>Just remember to install <strong>JDTLS</strong> via <strong>Mason</strong>.</p>
<p>Sometimes you will need to provide a reference JAR that the LSP can hook into loading. I downloaded a Lombok JAR and added it at the JDTLS install path (you will see this in my nvim-jdtls config below), and I at least know this had to be done for Playwright under 'referencedLibraries'.</p>
<h2 id="debugging">DEBUGGING</h2>
<p>Debugging can be done inside Neovim, but again, keep in mind that you <em>may</em> have a better experience in a Java-focused IDE.</p>
<p>I recommend installing <a href="https://github.com/mfussenegger/nvim-dap">nvim-dap</a> and <a href="https://github.com/rcarriga/nvim-dap-ui">nvim-dap-ui</a>.</p>
<p>You will need to install <a href="https://github.com/microsoft/java-debug">java-debug-adapter</a> from Mason OR download it and reference it in the lsp config (for nvim-jdtls only).</p>
<p><img src="https://ptrtojoel.dev/posts/so-you-want-to-write-java-in-neovim/neovim-dap.png" alt="alt text"></p>
<h2 id="testing">TESTING</h2>
<p>Working with tests inside Neovim is also possible, follows a similar setup to the above.</p>
<p>You will need to install <a href="https://github.com/microsoft/vscode-java-test">java-test</a> from Mason OR download it and reference it in the lsp config (for nvim-jdtls only).</p>
<h2 id="my-setup">MY SETUP</h2>
<p>I will show what I have as a point of reference:</p>
<p>I imagine you are also using treesitter, lspzero etc.</p>
<p><strong>JDTLS</strong></p>
<pre data-lang="lua"><code data-lang="lua"><span>local </span><span>java_cmds </span><span>= </span><span>vim</span><span>.api.</span><span>nvim_create_augroup</span><span>('</span><span>java_cmds</span><span>', { </span><span>clear </span><span>= </span><span>true </span><span>})
</span><span>local </span><span>cache_vars </span><span>= {}
</span><span>
</span><span>local </span><span>root_files </span><span>= {
</span><span>    '</span><span>.git</span><span>',
</span><span>    '</span><span>mvnw</span><span>',
</span><span>    '</span><span>gradlew</span><span>',
</span><span>    '</span><span>pom.xml</span><span>',
</span><span>    '</span><span>build.gradle</span><span>',
</span><span>    '</span><span>build.sbt</span><span>'
</span><span>}
</span><span>
</span><span>local </span><span>features </span><span>= {
</span><span>    </span><span>-- change this to `true` to enable codelens
</span><span>    </span><span>codelens </span><span>= </span><span>true</span><span>,
</span><span>
</span><span>    </span><span>-- change this to `true` if you have `nvim-dap`,
</span><span>    </span><span>-- `java-test` and `java-debug-adapter` installed
</span><span>    </span><span>debugger </span><span>= </span><span>true</span><span>,
</span><span>}
</span><span>
</span><span>local function </span><span>get_jdtls_paths</span><span>()
</span><span>    </span><span>if </span><span>cache_vars</span><span>.paths </span><span>then
</span><span>        </span><span>return </span><span>cache_vars</span><span>.paths
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>local </span><span>path </span><span>= {}
</span><span>
</span><span>    </span><span>path</span><span>.data_dir = </span><span>vim</span><span>.fn.</span><span>stdpath</span><span>('</span><span>cache</span><span>') .. '</span><span>/nvim-jdtls</span><span>'
</span><span>
</span><span>    </span><span>local </span><span>jdtls_install </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>jdtls</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>path</span><span>.java_agent = </span><span>jdtls_install </span><span>.. '</span><span>/lombok.jar</span><span>'
</span><span>    </span><span>path</span><span>.launcher_jar = </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>jdtls_install </span><span>.. '</span><span>/plugins/org.eclipse.equinox.launcher_*.jar</span><span>')
</span><span>
</span><span>    </span><span>if </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>mac</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_mac</span><span>'
</span><span>    </span><span>elseif </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>unix</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_linux</span><span>'
</span><span>    </span><span>elseif </span><span>vim</span><span>.fn.</span><span>has</span><span>('</span><span>win32</span><span>') == </span><span>1 </span><span>then
</span><span>        </span><span>path</span><span>.platform_config = </span><span>jdtls_install </span><span>.. '</span><span>/config_win</span><span>'
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>path</span><span>.bundles = {}
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Include java-test bundle if present
</span><span>    </span><span>---
</span><span>    </span><span>local </span><span>java_test_path </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>java-test</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>java_test_bundle </span><span>= </span><span>vim</span><span>.</span><span>split</span><span>(
</span><span>        </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>java_test_path </span><span>.. '</span><span>/extension/server/*.jar</span><span>'),
</span><span>        '</span><span>\n</span><span>'
</span><span>    )
</span><span>
</span><span>    </span><span>if </span><span>java_test_bundle</span><span>[</span><span>1</span><span>] ~= '' </span><span>then
</span><span>        </span><span>vim</span><span>.</span><span>list_extend</span><span>(</span><span>path</span><span>.bundles, </span><span>java_test_bundle</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Include java-debug-adapter bundle if present
</span><span>    </span><span>---
</span><span>    </span><span>local </span><span>java_debug_path </span><span>= </span><span>require</span><span>('</span><span>mason-registry</span><span>')
</span><span>        .</span><span>get_package</span><span>('</span><span>java-debug-adapter</span><span>')
</span><span>        :</span><span>get_install_path</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>java_debug_bundle </span><span>= </span><span>vim</span><span>.</span><span>split</span><span>(
</span><span>        </span><span>vim</span><span>.fn.</span><span>glob</span><span>(</span><span>java_debug_path </span><span>.. '</span><span>/extension/server/com.microsoft.java.debug.plugin-*.jar</span><span>'),
</span><span>        '</span><span>\n</span><span>'
</span><span>    )
</span><span>
</span><span>    </span><span>if </span><span>java_debug_bundle</span><span>[</span><span>1</span><span>] ~= '' </span><span>then
</span><span>        </span><span>vim</span><span>.</span><span>list_extend</span><span>(</span><span>path</span><span>.bundles, </span><span>java_debug_bundle</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>---
</span><span>    </span><span>-- Useful if you're starting jdtls with a Java version that's
</span><span>    </span><span>-- different from the one the project uses.
</span><span>    </span><span>---
</span><span>    </span><span>path</span><span>.runtimes = {
</span><span>        </span><span>-- Note: the field `name` must be a valid `ExecutionEnvironment`,
</span><span>        </span><span>-- you can find the list here:
</span><span>        </span><span>-- https://github.com/eclipse/eclipse.jdt.ls/wiki/Running-the-JAVA-LS-server-from-the-command-line#initialize-request
</span><span>        </span><span>--
</span><span>        </span><span>-- This example assume you are using sdkman: https://sdkman.io
</span><span>        {
</span><span>            </span><span>name </span><span>= '</span><span>JavaSE-21</span><span>',
</span><span>            </span><span>path </span><span>= </span><span>vim</span><span>.fn.</span><span>expand</span><span>('</span><span>~/.sdkman/candidates/java/21.0.2-tem</span><span>'),
</span><span>        },
</span><span>        {
</span><span>            </span><span>name </span><span>= '</span><span>JavaSE-23</span><span>',
</span><span>            </span><span>path </span><span>= </span><span>vim</span><span>.fn.</span><span>expand</span><span>('</span><span>~/.sdkman/candidates/java/23-tem</span><span>'),
</span><span>        }
</span><span>
</span><span>    }
</span><span>
</span><span>    </span><span>cache_vars</span><span>.paths = </span><span>path
</span><span>
</span><span>    </span><span>return </span><span>path
</span><span>end
</span><span>
</span><span>local function </span><span>enable_codelens</span><span>(bufnr)
</span><span>    </span><span>pcall</span><span>(</span><span>vim</span><span>.lsp.codelens.refresh)
</span><span>
</span><span>    </span><span>vim</span><span>.api.</span><span>nvim_create_autocmd</span><span>('</span><span>BufWritePost</span><span>', {
</span><span>        </span><span>buffer </span><span>= </span><span>bufnr</span><span>,
</span><span>        </span><span>group </span><span>= </span><span>java_cmds</span><span>,
</span><span>        </span><span>desc </span><span>= '</span><span>refresh codelens</span><span>',
</span><span>        </span><span>callback </span><span>= </span><span>function</span><span>()
</span><span>            </span><span>pcall</span><span>(</span><span>vim</span><span>.lsp.codelens.refresh)
</span><span>        </span><span>end</span><span>,
</span><span>    })
</span><span>end
</span><span>
</span><span>local function </span><span>enable_debugger</span><span>(bufnr)
</span><span>    </span><span>require</span><span>('</span><span>jdtls</span><span>').</span><span>setup_dap</span><span>({ </span><span>hotcodereplace </span><span>= '</span><span>auto</span><span>' })
</span><span>    </span><span>require</span><span>('</span><span>jdtls.dap</span><span>').</span><span>setup_dap_main_class_configs</span><span>()
</span><span>
</span><span>    </span><span>local </span><span>opts </span><span>= { </span><span>buffer </span><span>= </span><span>bufnr </span><span>}
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;df</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').test_class()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;dn</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').test_nearest_method()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>end
</span><span>
</span><span>local function </span><span>jdtls_on_attach</span><span>(client, bufnr)
</span><span>    </span><span>--vim.lsp.inlay_hint(bufnr, true)
</span><span>    </span><span>if </span><span>features</span><span>.debugger </span><span>then
</span><span>        </span><span>enable_debugger</span><span>(</span><span>bufnr</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>if </span><span>features</span><span>.codelens </span><span>then
</span><span>        </span><span>enable_codelens</span><span>(</span><span>bufnr</span><span>)
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>-- The following mappings are based on the suggested usage of nvim-jdtls
</span><span>    </span><span>-- https://github.com/mfussenegger/nvim-jdtls#usage
</span><span>
</span><span>    </span><span>local </span><span>opts </span><span>= { </span><span>buffer </span><span>= </span><span>bufnr </span><span>}
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;A-o&gt;</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').organize_imports()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>crv</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').extract_variable()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crv</span><span>', "</span><span>&lt;esc&gt;&lt;cmd&gt;lua require('jdtls').extract_variable(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>crc</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').extract_constant()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crc</span><span>', "</span><span>&lt;esc&gt;&lt;cmd&gt;lua require('jdtls').extract_constant(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>x</span><span>', '</span><span>crm</span><span>', "</span><span>&lt;esc&gt;&lt;Cmd&gt;lua require('jdtls').extract_method(true)&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>    </span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;leader&gt;pjp</span><span>', "</span><span>&lt;cmd&gt;lua require('jdtls').javap()&lt;cr&gt;</span><span>", </span><span>opts</span><span>)
</span><span>end
</span><span>
</span><span>local function </span><span>jdtls_setup</span><span>(event)
</span><span>    </span><span>local </span><span>jdtls </span><span>= </span><span>require</span><span>('</span><span>jdtls</span><span>')
</span><span>    </span><span>local </span><span>extendedClientCapabilities </span><span>= </span><span>jdtls</span><span>.extendedClientCapabilities;
</span><span>    </span><span>extendedClientCapabilities</span><span>.onCompletionItemSelectedCommand = "</span><span>editor.action.triggerParameterHints</span><span>"
</span><span>
</span><span>    </span><span>local </span><span>path </span><span>= </span><span>get_jdtls_paths</span><span>()
</span><span>    </span><span>local </span><span>data_dir </span><span>= </span><span>path</span><span>.data_dir .. '</span><span>/</span><span>' .. </span><span>vim</span><span>.fn.</span><span>fnamemodify</span><span>(</span><span>vim</span><span>.fn.</span><span>getcwd</span><span>(), '</span><span>:p:h:t</span><span>')
</span><span>
</span><span>    </span><span>if </span><span>cache_vars</span><span>.capabilities == </span><span>nil </span><span>then
</span><span>        </span><span>jdtls</span><span>.extendedClientCapabilities.resolveAdditionalTextEditsSupport = </span><span>true
</span><span>
</span><span>        </span><span>local </span><span>ok_cmp</span><span>, </span><span>cmp_lsp </span><span>= </span><span>pcall</span><span>(</span><span>require</span><span>, '</span><span>cmp_nvim_lsp</span><span>')
</span><span>        </span><span>cache_vars</span><span>.capabilities = </span><span>vim</span><span>.</span><span>tbl_deep_extend</span><span>(
</span><span>            '</span><span>force</span><span>',
</span><span>            </span><span>vim</span><span>.lsp.protocol.</span><span>make_client_capabilities</span><span>(),
</span><span>            </span><span>ok_cmp </span><span>and </span><span>cmp_lsp</span><span>.</span><span>default_capabilities</span><span>() or {}
</span><span>        )
</span><span>    </span><span>end
</span><span>
</span><span>    </span><span>-- The command that starts the language server
</span><span>    </span><span>-- See: https://github.com/eclipse/eclipse.jdt.ls#running-from-the-command-line
</span><span>    </span><span>local </span><span>cmd </span><span>= {
</span><span>        '</span><span>java</span><span>',
</span><span>
</span><span>        '</span><span>-Declipse.application=org.eclipse.jdt.ls.core.id1</span><span>',
</span><span>        '</span><span>-Dosgi.bundles.defaultStartLevel=4</span><span>',
</span><span>        '</span><span>-Declipse.product=org.eclipse.jdt.ls.core.product</span><span>',
</span><span>        '</span><span>-Dlog.protocol=true</span><span>',
</span><span>        '</span><span>-Dlog.level=ALL</span><span>',
</span><span>        '</span><span>-javaagent:</span><span>' .. </span><span>path</span><span>.java_agent,
</span><span>        '</span><span>-Xms1g</span><span>',
</span><span>        '</span><span>--add-modules=ALL-SYSTEM</span><span>',
</span><span>        '</span><span>--add-opens</span><span>',
</span><span>        '</span><span>java.base/java.util=ALL-UNNAMED</span><span>',
</span><span>        '</span><span>--add-opens</span><span>',
</span><span>        '</span><span>java.base/java.lang=ALL-UNNAMED</span><span>',
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-jar</span><span>',
</span><span>        </span><span>path</span><span>.launcher_jar,
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-configuration</span><span>',
</span><span>        </span><span>path</span><span>.platform_config,
</span><span>
</span><span>        </span><span>-- 💀
</span><span>        '</span><span>-data</span><span>',
</span><span>        </span><span>data_dir</span><span>,
</span><span>    }
</span><span>
</span><span>    </span><span>local </span><span>lsp_settings </span><span>= {
</span><span>        </span><span>java </span><span>= {
</span><span>            </span><span>-- jdt = {
</span><span>            </span><span>--   ls = {
</span><span>            </span><span>--     vmargs = "-XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xmx1G -Xms100m"
</span><span>            </span><span>--   }
</span><span>            </span><span>-- },
</span><span>            </span><span>project </span><span>= {
</span><span>                </span><span>referencedLibraries </span><span>= {
</span><span>                    </span><span>-- add any library jars here for the lsp to pick them up
</span><span>                },
</span><span>            },
</span><span>            </span><span>eclipse </span><span>= {
</span><span>                </span><span>downloadSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>configuration </span><span>= {
</span><span>                </span><span>updateBuildConfiguration </span><span>= '</span><span>interactive</span><span>',
</span><span>                </span><span>runtimes </span><span>= </span><span>path</span><span>.runtimes,
</span><span>            },
</span><span>            </span><span>maven </span><span>= {
</span><span>                </span><span>downloadSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>implementationsCodeLens </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>referencesCodeLens </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>references </span><span>= {
</span><span>                </span><span>includeDecompiledSources </span><span>= </span><span>true</span><span>,
</span><span>            },
</span><span>            </span><span>inlayHints </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>                </span><span>--parameterNames = {
</span><span>                </span><span>--   enabled = 'all' -- literals, all, none
</span><span>                </span><span>--}
</span><span>            },
</span><span>            </span><span>format </span><span>= {
</span><span>                </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>                </span><span>-- settings = {
</span><span>                </span><span>--   profile = 'asdf'
</span><span>                </span><span>-- },
</span><span>            }
</span><span>        },
</span><span>        </span><span>signatureHelp </span><span>= {
</span><span>            </span><span>enabled </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>        </span><span>completion </span><span>= {
</span><span>            </span><span>favoriteStaticMembers </span><span>= {
</span><span>                '</span><span>org.hamcrest.MatcherAssert.assertThat</span><span>',
</span><span>                '</span><span>org.hamcrest.Matchers.*</span><span>',
</span><span>                '</span><span>org.hamcrest.CoreMatchers.*</span><span>',
</span><span>                '</span><span>org.junit.jupiter.api.Assertions.*</span><span>',
</span><span>                '</span><span>java.util.Objects.requireNonNull</span><span>',
</span><span>                '</span><span>java.util.Objects.requireNonNullElse</span><span>',
</span><span>                '</span><span>org.mockito.Mockito.*</span><span>',
</span><span>            },
</span><span>        },
</span><span>        </span><span>contentProvider </span><span>= {
</span><span>            </span><span>preferred </span><span>= '</span><span>fernflower</span><span>',
</span><span>        },
</span><span>        </span><span>extendedClientCapabilities </span><span>= </span><span>jdtls</span><span>.extendedClientCapabilities,
</span><span>        </span><span>sources </span><span>= {
</span><span>            </span><span>organizeImports </span><span>= {
</span><span>                </span><span>starThreshold </span><span>= </span><span>9999</span><span>,
</span><span>                </span><span>staticStarThreshold </span><span>= </span><span>9999</span><span>,
</span><span>            }
</span><span>        },
</span><span>        </span><span>codeGeneration </span><span>= {
</span><span>            </span><span>toString </span><span>= {
</span><span>                </span><span>template </span><span>= '</span><span>${object.className}{${member.name()}=${member.value}, ${otherMembers}}</span><span>',
</span><span>            },
</span><span>            </span><span>useBlocks </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>    }
</span><span>
</span><span>    </span><span>-- This starts a new client &amp; server,
</span><span>    </span><span>-- or attaches to an existing client &amp; server depending on the `root_dir`.
</span><span>    </span><span>jdtls</span><span>.</span><span>start_or_attach</span><span>({
</span><span>        </span><span>cmd </span><span>= </span><span>cmd</span><span>,
</span><span>        </span><span>settings </span><span>= </span><span>lsp_settings</span><span>,
</span><span>        </span><span>on_attach </span><span>= </span><span>jdtls_on_attach</span><span>,
</span><span>        </span><span>capabilities </span><span>= </span><span>cache_vars</span><span>.capabilities,
</span><span>        </span><span>root_dir </span><span>= </span><span>jdtls</span><span>.setup.</span><span>find_root</span><span>(</span><span>root_files</span><span>),
</span><span>        </span><span>flags </span><span>= {
</span><span>            </span><span>allow_incremental_sync </span><span>= </span><span>true</span><span>,
</span><span>        },
</span><span>        </span><span>init_options </span><span>= {
</span><span>            </span><span>bundles </span><span>= </span><span>path</span><span>.bundles,
</span><span>            </span><span>extendedClientCapabilities </span><span>= </span><span>extendedClientCapabilities</span><span>,
</span><span>        },
</span><span>    })
</span><span>end
</span><span>
</span><span>vim</span><span>.api.</span><span>nvim_create_autocmd</span><span>('</span><span>FileType</span><span>', {
</span><span>    </span><span>group </span><span>= </span><span>java_cmds</span><span>,
</span><span>    </span><span>pattern </span><span>= { '</span><span>java</span><span>' },
</span><span>    </span><span>desc </span><span>= '</span><span>Setup jdtls</span><span>',
</span><span>    </span><span>callback </span><span>= </span><span>jdtls_setup</span><span>,
</span><span>})
</span></code></pre>
<p><strong>DAP</strong></p>
<pre data-lang="lua"><code data-lang="lua"><span>local </span><span>dap </span><span>= </span><span>require</span><span>('</span><span>dap</span><span>')
</span><span>
</span><span>dap</span><span>.configurations.java = {
</span><span>    {
</span><span>        </span><span>type </span><span>= '</span><span>java</span><span>',
</span><span>        </span><span>request </span><span>= '</span><span>launch</span><span>',
</span><span>        </span><span>name </span><span>= '</span><span>Launch Java Program</span><span>'
</span><span>    },
</span><span>}
</span><span>
</span><span>vim</span><span>.fn.</span><span>sign_define</span><span>('</span><span>DapBreakpoint</span><span>',
</span><span>    {
</span><span>        </span><span>text </span><span>= '</span><span>🔴</span><span>',
</span><span>        </span><span>texthl </span><span>= '</span><span>DapBreakpointSymbol</span><span>',
</span><span>        </span><span>linehl </span><span>= '</span><span>DapBreakpoint</span><span>',
</span><span>        </span><span>numhl </span><span>= '</span><span>DapBreakpoint</span><span>'
</span><span>    })
</span><span>vim</span><span>.fn.</span><span>sign_define</span><span>('</span><span>DapStopped</span><span>',
</span><span>    {
</span><span>        </span><span>texthl </span><span>= '</span><span>DapStoppedSymbol</span><span>',
</span><span>        </span><span>linehl </span><span>= '</span><span>CursorLine</span><span>',
</span><span>        </span><span>numhl </span><span>= '</span><span>DapBreakpoint</span><span>'
</span><span>    })
</span><span>
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F5&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>continue</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F10&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_over</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F11&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_into</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;F12&gt;</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>step_out</span><span>() </span><span>end</span><span>)
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;Leader&gt;b</span><span>', </span><span>function</span><span>() </span><span>require</span><span>('</span><span>dap</span><span>').</span><span>toggle_breakpoint</span><span>() </span><span>end</span><span>)
</span><span>
</span><span>local </span><span>dapui </span><span>= </span><span>require</span><span>('</span><span>dapui</span><span>')
</span><span>dapui</span><span>.</span><span>setup</span><span>()
</span><span>
</span><span>dap</span><span>.listeners.before.attach.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>dapui</span><span>.</span><span>open</span><span>()
</span><span>end
</span><span>dap</span><span>.listeners.before.launch.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>dapui</span><span>.</span><span>open</span><span>()
</span><span>end
</span><span>dap</span><span>.listeners.before.event_terminated.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>--dapui.close()
</span><span>end
</span><span>dap</span><span>.listeners.before.event_exited.</span><span>dapui_config </span><span>= </span><span>function</span><span>()
</span><span>    </span><span>--dapui.close()
</span><span>end
</span><span>
</span><span>vim</span><span>.keymap.</span><span>set</span><span>('</span><span>n</span><span>', '</span><span>&lt;Leader&gt;du</span><span>', </span><span>function</span><span>() </span><span>dapui</span><span>.</span><span>toggle</span><span>() </span><span>end</span><span>)
</span><span>
</span></code></pre>
<p>I hope this helps you get started working with Java in Neovim!</p>

        </section>

        

    </article>
</div></div>]]></description>
        </item>
    </channel>
</rss>