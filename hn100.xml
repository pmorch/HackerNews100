<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 08 Aug 2025 03:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cursed Knowledge (175 pts)]]></title>
            <link>https://immich.app/cursed-knowledge/</link>
            <guid>44831704</guid>
            <pubDate>Thu, 07 Aug 2025 23:34:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://immich.app/cursed-knowledge/">https://immich.app/cursed-knowledge/</a>, See on <a href="https://news.ycombinator.com/item?id=44831704">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="__docusaurus_skipToContent_fallback"><p>Cursed knowledge we have learned as a result of building Immich that we wish we never knew.</p><div><ul><li><p>6/4/2025</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M16,16.92C15.67,16.97 15.34,17 15,17C14.66,17 14.33,16.97 14,16.92V13.41L11.5,15.89C11,15.5 10.5,15 10.11,14.5L12.59,12H9.08C9.03,11.67 9,11.34 9,11C9,10.66 9.03,10.33 9.08,10H12.59L10.11,7.5C10.3,7.25 10.5,7 10.76,6.76V6.76C11,6.5 11.25,6.3 11.5,6.11L14,8.59V5.08C14.33,5.03 14.66,5 15,5C15.34,5 15.67,5.03 16,5.08V8.59L18.5,6.11C19,6.5 19.5,7 19.89,7.5L17.41,10H20.92C20.97,10.33 21,10.66 21,11C21,11.34 20.97,11.67 20.92,12H17.41L19.89,14.5C19.7,14.75 19.5,15 19.24,15.24V15.24C19,15.5 18.75,15.7 18.5,15.89L16,13.41V16.92H16V16.92M5,19A2,2 0 0,1 7,17A2,2 0 0,1 9,19A2,2 0 0,1 7,21A2,2 0 0,1 5,19H5Z" style="fill:purple"></path></svg><p><span>Zitadel Actions are cursed</span></p></div><p>Zitadel is cursed because its custom scripting feature is executed with a JS engine that doesn't support regex named capture groups.</p></div></li><li><p>5/30/2025</p><div><p>Microsoft Entra supports PKCE, but doesn't include it in its OpenID discovery document. This leads to clients thinking PKCE isn't available.</p></div></li><li><p>5/5/2025</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M7,17V1H5V5H1V7H5V17A2,2 0 0,0 7,19H17V23H19V19H23V17M17,15H19V7C19,5.89 18.1,5 17,5H9V7H17V15Z" style="fill:tomato"></path></svg><p><span>Image dimensions in EXIF metadata are cursed</span></p></div><p>The dimensions in EXIF metadata can be different from the actual dimensions of the image, causing issues with cropping and resizing.</p></div></li><li><p>4/1/2025</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M5,3H7V5H5V10A2,2 0 0,1 3,12A2,2 0 0,1 5,14V19H7V21H5C3.93,20.73 3,20.1 3,19V15A2,2 0 0,0 1,13H0V11H1A2,2 0 0,0 3,9V5A2,2 0 0,1 5,3M19,3A2,2 0 0,1 21,5V9A2,2 0 0,0 23,11H24V13H23A2,2 0 0,0 21,15V19A2,2 0 0,1 19,21H17V19H19V14A2,2 0 0,1 21,12A2,2 0 0,1 19,10V5H17V3H19M12,15A1,1 0 0,1 13,16A1,1 0 0,1 12,17A1,1 0 0,1 11,16A1,1 0 0,1 12,15M8,15A1,1 0 0,1 9,16A1,1 0 0,1 8,17A1,1 0 0,1 7,16A1,1 0 0,1 8,15M16,15A1,1 0 0,1 17,16A1,1 0 0,1 16,17A1,1 0 0,1 15,16A1,1 0 0,1 16,15Z" style="fill:yellow"></path></svg><p><span>YAML whitespace is cursed</span></p></div><p>YAML whitespaces are often handled in unintuitive ways.</p></div></li><li><p>9/20/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M3,12V6.75L9,5.43V11.91L3,12M20,3V11.75L10,11.9V5.21L20,3M3,13L9,13.09V19.9L3,18.75V13M20,13.25V22L10,20.09V13.1L20,13.25Z" style="fill:#357EC7"></path></svg><p><span>Hidden files in Windows are cursed</span></p></div><p>Hidden files in Windows cannot be opened with the "w" flag. That, combined with SMB option "hide dot files" leads to a lot of confusion.</p></div></li><li><p>8/7/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M21,5H3V7H21V5M3,19H10V17H3V19M3,13H18C19,13 20,13.43 20,15C20,16.57 19,17 18,17H16V15L12,18L16,21V19H18C20.95,19 22,17.73 22,15C22,12.28 21,11 18,11H3V13Z" style="fill:gray"></path></svg><p><span>Carriage returns in bash scripts are cursed</span></p></div><p>Git can be configured to automatically convert LF to CRLF on checkout and CRLF breaks bash scripts.</p></div></li><li><p>8/7/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M9 5.82L7.36 4.16C8.09 2.31 9.89 1 12 1C14.76 1 17 3.24 17 6V8H18C19.11 8 20 8.9 20 10V16.8L11.2 8H15V6C15 4.34 13.66 3 12 3C10.41 3 9.11 4.25 9 5.82M22.11 21.46L20.84 22.73L19.46 21.35C19.1 21.75 18.58 22 18 22H6C4.89 22 4 21.11 4 20V10C4 8.89 4.9 8 6 8H6.11L1.11 3L2.39 1.73L22.11 21.46M13.85 15.74L11.26 13.15C10.5 13.44 10 14.16 10 15C10 16.11 10.9 17 12 17C12.84 17 13.56 16.5 13.85 15.74Z" style="fill:red"></path></svg><p><span>Fetch inside Cloudflare Workers is cursed</span></p></div><p>Fetch requests in Cloudflare Workers use http by default, even if you explicitly specify https, which can often cause redirect loops.</p></div></li><li><p>7/21/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M20.94 11C20.5 6.83 17.17 3.5 13 3.06V1H11V3.06C9.87 3.18 8.81 3.5 7.84 4.03L9.34 5.53C10.16 5.19 11.06 5 12 5C15.87 5 19 8.13 19 12C19 12.94 18.81 13.84 18.5 14.65L20 16.15C20.5 15.19 20.82 14.13 20.95 13H23V11H20.94M3 4.27L5.04 6.31C3.97 7.62 3.25 9.23 3.06 11H1V13H3.06C3.5 17.17 6.83 20.5 11 20.94V23H13V20.94C14.77 20.74 16.38 20.03 17.69 18.96L19.73 21L21 19.73L4.27 3L3 4.27M16.27 17.54C15.09 18.45 13.61 19 12 19C8.13 19 5 15.87 5 12C5 10.39 5.55 8.91 6.46 7.73L16.27 17.54Z" style="fill:gray"></path></svg><p><span>GPS sharing on mobile is cursed</span></p></div><p>Some phones will silently strip GPS data from images when apps without location permission try to access them.</p></div></li><li><p>7/3/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M16.84,2.73C16.45,2.73 16.07,2.88 15.77,3.17L13.65,5.29L18.95,10.6L21.07,8.5C21.67,7.89 21.67,6.94 21.07,6.36L17.9,3.17C17.6,2.88 17.22,2.73 16.84,2.73M12.94,6L4.84,14.11L7.4,14.39L7.58,16.68L9.86,16.85L10.15,19.41L18.25,11.3M4.25,15.04L2.5,21.73L9.2,19.94L8.96,17.78L6.65,17.61L6.47,15.29" style="fill:gold"></path></svg><p><span>PostgreSQL NOTIFY is cursed</span></p></div><p>PostgreSQL does everything in a transaction, including NOTIFY. This means using the socket.io postgres-adapter writes to WAL every 5 seconds.</p></div></li><li><p>7/3/2024</p><div><p>npm scripts make a http call to the npm registry each time they run, which means they are a terrible way to execute a health check.</p></div></li><li><p>6/28/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M12 16C13.66 16 15 14.66 15 13C15 11.88 14.39 10.9 13.5 10.39L3.79 4.77L9.32 14.35C9.82 15.33 10.83 16 12 16M12 3C10.19 3 8.5 3.5 7.03 4.32L9.13 5.53C10 5.19 11 5 12 5C16.42 5 20 8.58 20 13C20 15.21 19.11 17.21 17.66 18.65H17.65C17.26 19.04 17.26 19.67 17.65 20.06C18.04 20.45 18.68 20.45 19.07 20.07C20.88 18.26 22 15.76 22 13C22 7.5 17.5 3 12 3M2 13C2 15.76 3.12 18.26 4.93 20.07C5.32 20.45 5.95 20.45 6.34 20.06C6.73 19.67 6.73 19.04 6.34 18.65C4.89 17.2 4 15.21 4 13C4 12 4.19 11 4.54 10.1L3.33 8C2.5 9.5 2 11.18 2 13Z" style="fill:brown"></path></svg><p><span>50 extra packages are cursed</span></p></div><p>There is a user in the JavaScript community who goes around adding "backwards compatibility" to projects. They do this by adding 50 extra package dependencies to your project, which are maintained by them.</p></div></li><li><p>6/25/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M12,17C10.89,17 10,16.1 10,15C10,13.89 10.89,13 12,13A2,2 0 0,1 14,15A2,2 0 0,1 12,17M18,20V10H6V20H18M18,8A2,2 0 0,1 20,10V20A2,2 0 0,1 18,22H6C4.89,22 4,21.1 4,20V10C4,8.89 4.89,8 6,8H7V6A5,5 0 0,1 12,1A5,5 0 0,1 17,6V8H18M12,3A3,3 0 0,0 9,6V8H15V6A3,3 0 0,0 12,3Z" style="fill:gold"></path></svg><p><span>Long passwords are cursed</span></p></div><p>The bcrypt implementation only uses the first 72 bytes of a string. Any characters after that are ignored.</p></div></li><li><p>1/31/2024</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M7,10H12V15H7M19,19H5V8H19M19,3H18V1H16V3H8V1H6V3H5C3.89,3 3,3.9 3,5V19A2,2 0 0,0 5,21H19A2,2 0 0,0 21,19V5A2,2 0 0,0 19,3Z" style="fill:greenyellow"></path></svg><p><span>JavaScript Date objects are cursed</span></p></div><p>JavaScript date objects are 1 indexed for years and days, but 0 indexed for months.</p></div></li><li><p>1/9/2024</p><div><p>Prior to Node.js v20.8 using --experimental-vm-modules in a CommonJS project that imported an ES module that imported a CommonJS modules would create a segfault and crash Node.js</p></div></li><li><p>12/28/2023</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M12,3C7.58,3 4,4.79 4,7C4,9.21 7.58,11 12,11C16.42,11 20,9.21 20,7C20,4.79 16.42,3 12,3M4,9V12C4,14.21 7.58,16 12,16C16.42,16 20,14.21 20,12V9C20,11.21 16.42,13 12,13C7.58,13 4,11.21 4,9M4,14V17C4,19.21 7.58,21 12,21C16.42,21 20,19.21 20,17V14C20,16.21 16.42,18 12,18C7.58,18 4,16.21 4,14Z" style="fill:gray"></path></svg><p><span>PostgreSQL parameters are cursed</span></p></div><p>PostgresSQL has a limit of 65,535 parameters, so bulk inserts can fail with large datasets.</p></div></li><li><p>6/26/2023</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M12,12H19C18.47,16.11 15.72,19.78 12,20.92V12H5V6.3L12,3.19M12,1L3,5V11C3,16.55 6.84,21.73 12,23C17.16,21.73 21,16.55 21,11V5L12,1Z" style="fill:gold"></path></svg><p><span>Secure contexts are cursed</span></p></div><p>Some web features like the clipboard API only work in "secure contexts" (ie. https or localhost)</p></div></li><li><p>2/23/2023</p><div><div><svg viewBox="0 0 24 24" style="width:1.5rem;height:1.5rem" role="presentation"><path d="M9,3V4H4V6H5V19A2,2 0 0,0 7,21H17A2,2 0 0,0 19,19V6H20V4H15V3H9M9,8H11V17H9V8M13,8H15V17H13V8Z" style="fill:gray"></path></svg><p><span>TypeORM deletes are cursed</span></p></div><p>The remove implementation in TypeORM mutates the input, deleting the id property from the original object.</p></div></li></ul></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vibechart (664 pts)]]></title>
            <link>https://www.vibechart.net/</link>
            <guid>44830684</guid>
            <pubDate>Thu, 07 Aug 2025 21:36:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vibechart.net/">https://www.vibechart.net/</a>, See on <a href="https://news.ycombinator.com/item?id=44830684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>vibechart</p>
            <div><p>[From vibe + chart: cf. subjective interpretation + <a href="https://www.datavisualizationsociety.org/">data visualization.</a> See <a href="https://www.drawaurora.com/">Vibe</a>, and cf. <a href="https://chartscss.org/">Chart</a>.]</p></div>
            <p>
                To chart based on what you want to see instead of what is true, beautiful, or useful.
            </p>
            <div><p>
                See also: <a href="https://en.wikipedia.org/wiki/Lie">lies</a>, <a href="https://gizmodo.com/sam-altmans-lies-about-chatgpt-are-growing-bolder-2000614431">damned lies</a>, and <a href="https://en.wikipedia.org/wiki/Statistics">statistics</a>.
            </p></div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flipper Zero DarkWeb Firmware Bypasses Rolling Code Security (186 pts)]]></title>
            <link>https://www.rtl-sdr.com/flipperzero-darkweb-firmware-bypasses-rolling-code-security/</link>
            <guid>44830408</guid>
            <pubDate>Thu, 07 Aug 2025 21:10:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rtl-sdr.com/flipperzero-darkweb-firmware-bypasses-rolling-code-security/">https://www.rtl-sdr.com/flipperzero-darkweb-firmware-bypasses-rolling-code-security/</a>, See on <a href="https://news.ycombinator.com/item?id=44830408">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="site" role="main">
			
	
			
		<article id="post-64439">
			<header>
								
			  				  <time datetime="2025-08-07T02:47:03+00:00" pubdate="">August 7, 2025</time>
								
									
							</header>
		
			<div>
				<p>Over on YouTube Talking Sasquach has recently tested custom firmware for the Flipper Zero that can entirely break the rolling code security system used on most modern vehicles. Rolling code security works by using&nbsp;a synchronized algorithm between a transmitter and receiver to generate a new, unique code for each transmission, preventing replay attacks and unauthorized access.</p>
<p>In the past we've discussed an attack against rolling code security systems called <a href="https://www.rtl-sdr.com/?s=rolljam&amp;apbct__email_id__search_form_47564=47564" target="_blank" rel="noopener">RollJam</a>, which works by jamming the original keyfob signal so the vehicle cannot receive it, and at the same time recording it for later use. However, this attack is difficult to perform in reality.</p>
<p>For this new attack to work, all that is needed is a single button-press capture from the keyfob, without any jamming. Just from that single capture, it is able to emulate all the keyfob's functions, including lock, unlock, and unlock trunk. A consequence of this is that the original keyfob gets out of sync, and will no longer function.</p>
<p>According to the Talking Sasquatch, the attack works by simply reverse engineering the rolling code sequence, either through sequence leaks or prior brute forcing of the sequence from a large list of known codes. However, <a href="https://san.com/cc/millions-of-cars-at-risk-from-flipper-zero-key-fob-hack-experts-warn/" target="_blank" rel="noopener">another article</a> mentions that the firmware is based on the "<a href="https://arxiv.org/abs/2210.11923" target="_blank" rel="noopener">RollBack</a>" attack, which works by playing back captured rolling codes in a specific order to initiate a 'rollback' of the synchronization system.</p>
<p>Regardless of the method, videos demonstrating the attack show that only a single capture is needed to emulate a keyfob completely.</p>
<p>Affected vehicles include Chrysler, Dodge, Fiat, Ford, Hyundai, Jeep, Kia, Mitsubishi and Subaru. As of yet, there appears to be no easy fix for this, other than mass vehicle recalls.</p>
<div id="WYL_wk7BGMkuI8A" data-src="https://www.rtl-sdr.com/wp-content/plugins/wp-youtube-lyte/lyteCache.php?origThumbUrl=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fwk7BGMkuI8A%2Fmaxresdefault.jpg" title="Flipper Zero DarkWeb Firmware Copies My Key Fob! I&amp;#039;ll Explain How this Works!"><p>Flipper Zero DarkWeb Firmware Copies My Key Fob! I'll Explain How this Works!</p></div>
					
					
			</div>
			<!-- / .content -->
			
			
		</article>
		<!-- / #post-64439 -->

		    
    
    
    
    		
				  
			<!-- / .post-nav -->
				
		



		</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cursor CLI (193 pts)]]></title>
            <link>https://cursor.com/cli</link>
            <guid>44830221</guid>
            <pubDate>Thu, 07 Aug 2025 20:53:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cursor.com/cli">https://cursor.com/cli</a>, See on <a href="https://news.ycombinator.com/item?id=44830221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main"><section aria-label="Marketing highlights"><div><p>Use it in your IDE or any terminal.</p><p>Same commands, any environment. Plug into your setup anywhere.</p></div><div><h2>Full control from your terminal.</h2><div><div><ul><li role="button" tabindex="0"><p>Review agent edits</p><p>Make code changes directly in the terminal.</p></li><li role="button" tabindex="0"><p>Steer in real-time</p><p>Guide the agent as it works.</p></li><li role="button" tabindex="0"><p>Set your own rules</p><p>Customize Cursor's work with rules, AGENTS.md, and MCP.</p></li></ul></div><div aria-live="polite"><p><span>1/2 src/components/Canvas3D.tsx</span><span><span>+8</span><span>-2</span></span></p><div aria-label="Code diff for Canvas3D.tsx"><p>1</p><div><p><span>import</span></p><!-- --><p>{</p><!-- --><p> Suspense </p><!-- --><p>}</p><!-- --> <!-- --><p>from <span>'react'</span>;</p></div><p>2</p><div><p><span>import</span></p><!-- --><p>{</p><!-- --><p> Canvas </p><!-- --><p>}</p><!-- --> <!-- --><p>from <span>'@react-three/fiber'</span>;</p></div><p>3</p><div><p><span>import</span> as THREE from</p><!-- --> <p><span>'three'</span>;</p></div><p>4</p><div><p><span>import</span></p><!-- --><p>{</p><!-- --><p> Leva </p><!-- --><p>}</p><!-- --><p> from</p><!-- --> <p><span>'leva'</span>;</p></div><p>5</p><p>import GameScene from '../scenes/GameScene';</p><p>18</p><p>right-click</p><p>19</p><p>gl<span>=</span>{{</p><p>20</p><p>antialias: true,</p><p>20</p><p>antialias: false,</p><p>21</p><p> alpha: false,</p><p>22</p><p> stencil: false,</p><p>23</p><p> depth: true,</p><p>24</p><div> <!-- --><p>powerPreference:</p><!-- --> <p><span>'high-performance'</span>,</p></div></div></div></div></div><section aria-label="Additional highlights"><h3>Built for your workflow</h3><div><div><p>Always use the latest model</p><p>Every cutting edge model from Anthropic, OpenAI, Gemini, and more at your fingertips.</p></div><div><p>Use in your preferred IDE</p><p>Wherever you code, Cursor CLI integrates with your existing workflow.</p></div><div><p>Write powerful scripts and automations</p><p>Automatically update docs, trigger security reviews, or build custom coding agents.</p></div></div></section></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Historical Tech Tree (312 pts)]]></title>
            <link>https://www.historicaltechtree.com/</link>
            <guid>44829185</guid>
            <pubDate>Thu, 07 Aug 2025 19:24:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.historicaltechtree.com/">https://www.historicaltechtree.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44829185">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI's new open-source model is basically Phi-5 (199 pts)]]></title>
            <link>https://www.seangoedecke.com/gpt-oss-is-phi-5/</link>
            <guid>44828884</guid>
            <pubDate>Thu, 07 Aug 2025 18:59:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/gpt-oss-is-phi-5/">https://www.seangoedecke.com/gpt-oss-is-phi-5/</a>, See on <a href="https://news.ycombinator.com/item?id=44828884">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header></header><section><p>OpenAI just released its first ever open-source<sup id="fnref-1"><a href="#fn-1">1</a></sup> large language models, called gpt-oss-120b and gpt-oss-20b. You can talk to them <a href="https://gpt-oss.com/">here</a>. Are they good models? Well, that depends on what you’re looking for. They’re great at <a href="https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf">some benchmarks</a>, of course (OpenAI would never have released them otherwise) but weirdly bad at others, like SimpleQA.</p>
<p>Some people <a href="https://simonwillison.net/2025/Aug/5/gpt-oss/">really like them</a>. Others on Twitter <a href="https://x.com/corbtt/status/1952868822891012241">really</a> <a href="https://x.com/vikhyatk/status/1952863413845275132">don’t</a>. From what I can tell, they’re technically competent but lack a lot of out-of-domain knowledge: for instance, they have broad general knowledge about science, but don’t know much about popular culture. We’ll know in six months how useful these models are in practice, but my prediction is that these models will end up in the category of “performs much better on benchmarks than on real-world tasks”.</p>
<h3>Phi models and training on synthetic data</h3>
<p>In 2024, Sebastien Bubeck led the development of Microsoft’s open-source Phi-series of models<sup id="fnref-2"><a href="#fn-2">2</a></sup>. The big idea behind those models was to train exclusively on synthetic data: instead of text pulled from books or the internet, text generated by other language models or hand-curated textbooks. Synthetic data is less common than normal data, since instead of just downloading terabytes of it for free you have to spend money to generate each token. But the trade-off is that you have complete control over your training data. What happens when you train a model on entirely high-quality synthetic and curated data?</p>
<p>As it turns out, it does very well on model benchmarks but disappoints in practice. Searching for the reception to each Phi model shows the same pattern: very impressive <a href="https://arxiv.org/abs/2404.14219">benchmarks</a>, lots of enthusiasm, and then actual performance <a href="https://news.ycombinator.com/item?id=40128351">far weaker</a> than the benchmarks would suggest.</p>
<p>I think the impressive benchmark results come from the fact that these models are very easy to train for specific tasks, because you generate much of the training data yourself. If you’re training on synthetic data, you’d be foolish not to generate some synthetic data that matches the kind of problems people are benchmarking on. But since you’re “teaching for the test”, you should expect to do worse than other language models who are training on broad data and end up being good at the benchmarks by accident.</p>
<p>Why am I talking about Phi models? At the end of 2024, Sebastien Bubeck <a href="https://www.reuters.com/technology/microsofts-vp-genai-research-join-openai-2024-10-14/">left Microsoft</a> to join OpenAI. We don’t know who was involved in making the new OpenAI <code>gpt-oss</code> models. The <a href="https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf">model card</a> doesn’t provide much detail about the pretraining stage. However, I’d bet that Sebastien Bubeck was a part of the effort, and that these models were trained on a <em>heavily</em> filtered or synthetic dataset.</p>
<h3>Synthetic data is safer</h3>
<p>Why would OpenAI train Phi-style models, knowing that they’ll perform better on benchmarks than in real-world applications? For the same reason that Microsoft probably continued to train Phi-style models: safety. Releasing an open-source model is terrifying for a large organization. Once it’s out there, your name is associated with it forever, and thousands of researchers will be frantically trying to fine-tune it to remove the safety guardrails. </p>
<p>It’s not discussed publically very often, but the main use-case for fine-tuning small language models is for erotic role-play, and there’s a serious demand. Any small online community for people who run local models is at least 50% perverts.</p>
<p>If you release a regular closed-weights model that stays in your own infrastructure, people can’t fine-tune it. If you make a mistake, you can always update the model in-place. But open-source models are out there forever.</p>
<p>Training on synthetic data (or highly-controlled data such as textbooks) makes it much easier to produce a safe model. You can produce as much “you asked me to do X, but as a sensible language model I am declining to do so” content as you like. If there’s no subversive or nasty content in the training data, the model never learns to behave in subversive or nasty ways (at least, that’s the goal).</p>
<p>For OpenAI, it must have been very compelling to train a Phi-style model for their open-source release. They needed a model that beat the Chinese open-source models on benchmarks, while also not misbehaving in a way that caused <a href="https://www.seangoedecke.com/ai-sycophancy">yet another</a> scandal for them. Unlike Meta, they don’t need their open-source model to be <em>actually</em> good, because their main business is in their closed-source models.</p>
<p>That’s why I think OpenAI went down the synthetic data route for their new <code>gpt-oss</code> models. For good or ill, they may as well be Phi-5 and Phi-5-mini.</p>
</section><p>If you liked this post, consider <a href="https://buttondown.com/seangoedecke" target="_blank">subscribing</a> to email updates about my new posts, or <a href="https://news.ycombinator.com/submitlink?u=https://www.seangoedecke.com/gpt-oss-is-phi-5/" target="_blank">sharing it on Hacker News</a>.</p><p>August 7, 2025<!-- -->&nbsp;│ Tags: <a href="https://www.seangoedecke.com/tags/ai/">ai</a></p><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Encryption made for police and military radios may be easily cracked (136 pts)]]></title>
            <link>https://www.wired.com/story/encryption-made-for-police-and-military-radios-may-be-easily-cracked-researchers-find/</link>
            <guid>44828504</guid>
            <pubDate>Thu, 07 Aug 2025 18:30:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/encryption-made-for-police-and-military-radios-may-be-easily-cracked-researchers-find/">https://www.wired.com/story/encryption-made-for-police-and-military-radios-may-be-easily-cracked-researchers-find/</a>, See on <a href="https://news.ycombinator.com/item?id=44828504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>Two years ago,</span> researchers in the Netherlands <a href="https://www.wired.com/story/tetra-radio-encryption-backdoor/">discovered an intentional backdoor</a> in an encryption algorithm baked into radios used by critical infrastructure–as well as police, intelligence agencies, and military forces around the world–that made any communication secured with the algorithm vulnerable to eavesdropping.</p><p>When the researchers publicly disclosed the issue in 2023, the European Telecommunications Standards Institute (ETSI), which developed the algorithm, advised anyone using it for sensitive communication to deploy an end-to-end encryption solution on top of the flawed algorithm to bolster the security of their communications.</p><p>But now the same researchers have found that at least one implementation of the end-to-end encryption solution endorsed by ETSI has a similar issue that makes it equally vulnerable to eavesdropping. The encryption algorithm used for the device they examined starts with a 128-bit key, but this gets compressed to 56 bits before it encrypts traffic, making it easier to crack. It’s not clear who is using this implementation of the end-to-end encryption algorithm, nor if anyone using devices with the end-to-end encryption is aware of the security vulnerability in them.</p><p>The end-to-end encryption the researchers examined, which is expensive to deploy, is most commonly used in radios for law enforcement agencies, special forces, and covert military and intelligence teams that are involved in national security work and therefore need an extra layer of security. But ETSI’s endorsement of the algorithm two years ago to mitigate flaws found in its lower-level encryption algorithm suggests it may be used more widely now than at the time.</p><p>In 2023, Carlo Meijer, Wouter Bokslag, and Jos Wetzels of security firm <a data-offer-url="https://www.midnightblue.nl/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.midnightblue.nl/&quot;}" href="https://www.midnightblue.nl/" rel="nofollow noopener" target="_blank">Midnight Blue</a>, based in the Netherlands, discovered vulnerabilities in encryption algorithms that are part of a European radio standard created by ETSI called TETRA (Terrestrial Trunked Radio), which has been baked into radio systems made by Motorola, Damm, Sepura, and others since the ’90s. The flaws remained unknown publicly until their disclosure, because ETSI refused for decades to let anyone examine the proprietary algorithms. The end-to-end encryption the researchers examined recently is designed to run on top of TETRA encryption algorithms.</p><p>The researchers found the issue with the end-to-end encryption (E2EE) only after extracting and reverse-engineering the E2EE algorithm used in a radio made by Sepura. The researchers plan to present their findings today at the BlackHat security conference in Las Vegas.</p><p>ETSI, when contacted about the issue, noted that the end-to-end encryption used with TETRA-based radios is not part of the ETSI standard, nor was it created by the organization. Instead it was produced by The Critical Communications Association’s (TCCA) security and fraud prevention group (SFPG). But ETSI and TCCA work closely with one another, and the two organizations include many of the same people. Brian Murgatroyd, former chair of the technical body at ETSI responsible for the TETRA standard as well as the TCCA group that developed the E2EE solution, wrote in an email on behalf of ETSI and the TCCA that end-to-end encryption was not included in the ETSI standard “because at the time it was considered that E2EE would only be used by government groups where national security concerns were involved, and these groups often have special security needs.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>For this reason, Murgatroyd noted that purchasers of TETRA-based radios are free to deploy other solutions for end-to-end encryption on their radios, but he acknowledges that the one produced by the TCCA and endorsed by ETSI “is widely used as far as we can tell.”</p><p>Although TETRA-based radio devices are not used by police and military in the US, the majority of police forces around the world do use them. These include police forces in Belgium and Scandinavian countries, as well as East European countries like Serbia, Moldova, Bulgaria, and Macedonia, and in the Middle East in Iran, Iraq, Lebanon, and Syria. The Ministries of Defense in Bulgaria, Kazakhstan, and Syria also use them, as do the Polish military counterintelligence agency, the Finnish defense forces, and Lebanon and Saudi Arabia’s intelligence services. It’s not clear, however, how many of these also deploy end-to-end decryption with their radios.</p><p>The TETRA standard includes four encryption algorithms—TEA1, TEA2, TEA3 and TEA4—that can be used by radio manufacturers in different products, depending on the intended customer and usage. The algorithms have different levels of security based on whether the radios will be sold in or outside Europe. TEA2, for example, is restricted for use in radios used by police, emergency services, military, and intelligence agencies in Europe. TEA3 is available for police and emergency services radios used outside Europe but only in countries deemed “friendly” to the EU. Only TEA1 is available for radios used by public safety agencies, police agencies, and militaries in countries deemed not friendly to Europe, such as Iran. But it’s also used in critical infrastructure in the US and other countries for machine-to-machine communication in industrial control settings such as pipelines, railways, and electric grids.</p><p>All four TETRA encryption algorithms use 80-bit keys to secure communication. But the Dutch researchers revealed in 2023 that TEA1 has a feature that causes its key to get reduced to just 32 bits, which allowed the researchers to crack it in less than a minute.</p><p>In the case of the E2EE, the researchers found that the implementation they examined starts with a key that is more secure than ones used in the TETRA algorithms, but it gets reduced to 56 bits, which would potentially let someone decrypt voice and data communications. They also found a second vulnerability that would let someone send fraudulent messages or replay legitimate ones to spread misinformation or confusion to personnel using the radios.</p><p>The ability to inject voice traffic and replay messages affects all users of the TCCA end-to-end encryption scheme, according to the researchers. They say this is the result of flaws in the TCCA E2EE protocol design rather than a particular implementation. They also say that “law enforcement end users” have confirmed to them that this flaw is in radios produced by vendors other than Sepura.</p><p>But the researchers say only a subset of end-to-end encryption users are likely affected by the reduced-key vulnerability because it depends how the encryption was implemented in radios sold to various countries.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>ETSI’s Murgatroyd <a data-offer-url="https://www.zetter-zeroday.com/interview-with-the-etsi-standards/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.zetter-zeroday.com/interview-with-the-etsi-standards/&quot;}" href="https://www.zetter-zeroday.com/interview-with-the-etsi-standards/" rel="nofollow noopener" target="_blank">said in 2023</a> that the TEA1 key was reduced to meet export controls for encryption sold to customers outside Europe. He said when the algorithm was created, a key with 32 bits of entropy was considered secure for most uses. Advances in computing power make it less secure now, so when the Dutch researchers exposed the reduced key two years ago, ETSI recommended that customers using TEA1 deploy TCCA's end-to-end encryption solution on top of it.</p><p>But Murgatroyd said the end-to-end encryption algorithm designed by TCCA is different. It doesn’t specify the key length the radios should use because governments using the end-to-end encryption have their own “specific and often proprietary security rules” for the devices they use. Therefore they are able to customize the TCCA encryption algorithm in their devices by working with their radio supplier to select the “encryption algorithm, key management and so on” that is right for them—but only to a degree.</p><p>“The choice of encryption algorithm and key is made between supplier and customer organisation, and ETSI has no input to this selection—nor knowledge of which algorithms and key lengths are in use in any system,” he said. But he added that radio manufacturers and customers “will always have to abide by export control regulations.”</p><p>The researchers say they cannot verify that the TCCA E2EE doesn’t specify a key length because the TCCA documentation describing the solution is protected by nondisclosure agreement and provided only to radio vendors. But they note that the E2EE system calls out an “algorithm identifier" number, which means it calls out the specific algorithm it’s using for the end-to-end encryption. These identifiers are not vendor specific, the researchers say, which suggests the identifiers refer to different key variants produced by TCCA—meaning TCCA provides specifications for algorithms that use a 126 bit key or 56 bit key, and radio vendors can configure their devices to use either of these variants, depending on the export controls in place for the purchasing country.</p><p>Whether users know their radios could have this vulnerability is unclear. The researchers found a confidential 2006 Sepura product bulletin that <a href="https://www.scribd.com/document/237610110/Issue2-MOD-05-166-Crypto-Management-Tools">someone leaked online</a>, which mentions that “the length of the traffic key … is subject to export control regulations and hence the [encryption system in the device] will be factory configured to support 128, 64, or 56 bit key lengths.” But it’s not clear what Sepura customers receive or if other manufacturers whose radios use a reduced key disclose to customers if their radios use a reduced-key algorithm.</p><p>“Some manufacturers have this in brochures; others only mention this in internal communications, and others don’t mention it at all,” says Wetzels. He says they did extensive open-source research to examine vendor documentation and “ found no clear sign of weakening being communicated to end users. So while … there are ‘some’ mentions of the algorithm being weakened, it is not fully transparent at all.”</p><p>Sepura did not respond to an inquiry from WIRED.</p><p>But Murgatroyd says that because government customers who have opted to use TCCA’s E2EE solution need to know the security of their devices, they are likely to be aware if their systems are using a reduced key.</p><p>“As end-to-end encryption is primarily used for government communications, we would expect that the relevant government National Security agencies are fully aware of the capabilities of their end-to-end encryption systems and can advise their users appropriately,” Murgatroyd wrote in his email.</p><p>Wetzels is skeptical of this, however. “We consider it highly unlikely non-Western governments are willing to spend literally millions of dollars if they know they're only getting 56 bits of security,” he says.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Benchmark Framework Desktop Mainboard and 4-node cluster (144 pts)]]></title>
            <link>https://github.com/geerlingguy/ollama-benchmark/issues/21</link>
            <guid>44827862</guid>
            <pubDate>Thu, 07 Aug 2025 17:49:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/geerlingguy/ollama-benchmark/issues/21">https://github.com/geerlingguy/ollama-benchmark/issues/21</a>, See on <a href="https://news.ycombinator.com/item?id=44827862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="issue-body-viewer" data-team-hovercards-enabled="true" data-turbolinks="false" id="issue-body-viewer"><p dir="auto">Testing the <a href="https://frame.work/desktop" rel="nofollow">Framework Desktop</a> - AMD Ryzen AI Max+ 395 with Radeon 8090S. (Four pre-production units were shipped to me for local cluster testing).</p>
<h2 dir="auto">Single Node configuration (128 GB RAM):</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/481677/475718422-78791530-a491-463b-8c8e-6b94883b2b19.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ2MDI1MDIsIm5iZiI6MTc1NDYwMjIwMiwicGF0aCI6Ii80ODE2NzcvNDc1NzE4NDIyLTc4NzkxNTMwLWE0OTEtNDYzYi04YzhlLTZiOTQ4ODNiMmIxOS5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDgwNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA4MDdUMjEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTdmNzNlMGRlN2M5MmYzZGEzNzZhOWI1ZmY5YjdkNmVkMWY4YWYyOTJjY2M5ZTAyYzA3MTYzN2FiNTQ3ZjU2ZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.NrogbtFc_AN6neMIMlFkEZxdrq03GhOdZvW2ofvWeXg"><img src="https://private-user-images.githubusercontent.com/481677/475718422-78791530-a491-463b-8c8e-6b94883b2b19.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ2MDI1MDIsIm5iZiI6MTc1NDYwMjIwMiwicGF0aCI6Ii80ODE2NzcvNDc1NzE4NDIyLTc4NzkxNTMwLWE0OTEtNDYzYi04YzhlLTZiOTQ4ODNiMmIxOS5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDgwNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA4MDdUMjEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTdmNzNlMGRlN2M5MmYzZGEzNzZhOWI1ZmY5YjdkNmVkMWY4YWYyOTJjY2M5ZTAyYzA3MTYzN2FiNTQ3ZjU2ZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.NrogbtFc_AN6neMIMlFkEZxdrq03GhOdZvW2ofvWeXg" alt="Image"></a></p>
<h2 dir="auto">Cluster configuration (4x Mainboard - 512 GB RAM)</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/481677/475719431-140425ff-2110-4301-9e92-dc2807b3c277.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ2MDI1MDIsIm5iZiI6MTc1NDYwMjIwMiwicGF0aCI6Ii80ODE2NzcvNDc1NzE5NDMxLTE0MDQyNWZmLTIxMTAtNDMwMS05ZTkyLWRjMjgwN2IzYzI3Ny5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwN1QyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yY2ZkMzcyNDk0NjgwYTYxYTNlNmM1ZmIwYzZmNzZjN2IwMjg3NmI4ZDRmYzA2MDIzZDZmNzNjZWM2YWRlMjgxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.bvcCvKOWXhYfWrtuFsAn0asOUaw_tnxHHDZpx5F9pRQ"><img src="https://private-user-images.githubusercontent.com/481677/475719431-140425ff-2110-4301-9e92-dc2807b3c277.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ2MDI1MDIsIm5iZiI6MTc1NDYwMjIwMiwicGF0aCI6Ii80ODE2NzcvNDc1NzE5NDMxLTE0MDQyNWZmLTIxMTAtNDMwMS05ZTkyLWRjMjgwN2IzYzI3Ny5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwN1QyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yY2ZkMzcyNDk0NjgwYTYxYTNlNmM1ZmIwYzZmNzZjN2IwMjg3NmI4ZDRmYzA2MDIzZDZmNzNjZWM2YWRlMjgxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.bvcCvKOWXhYfWrtuFsAn0asOUaw_tnxHHDZpx5F9pRQ" alt="Image"></a></p>
<p dir="auto">Initial tests (above) were run using 2.5 Gbps Ethernet interconnect.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/481677/475719725-da027dbf-864c-47d2-ad87-2917285de6c9.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ2MDI1MDIsIm5iZiI6MTc1NDYwMjIwMiwicGF0aCI6Ii80ODE2NzcvNDc1NzE5NzI1LWRhMDI3ZGJmLTg2NGMtNDdkMi1hZDg3LTI5MTcyODVkZTZjOS5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDgwNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA4MDdUMjEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWU5ZjUzNGJmMGZlMzNjZmRmZmNmYzdlOGVhYTc1MGZhNzVjNDlmNjgwYTJiYWNhMTBlNTc2YmJhZTNjZWJlOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.1BO9Fncu1POYdXUNIT2rRTRJimpRGMeumaevUIA-8NU"><img src="https://private-user-images.githubusercontent.com/481677/475719725-da027dbf-864c-47d2-ad87-2917285de6c9.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ2MDI1MDIsIm5iZiI6MTc1NDYwMjIwMiwicGF0aCI6Ii80ODE2NzcvNDc1NzE5NzI1LWRhMDI3ZGJmLTg2NGMtNDdkMi1hZDg3LTI5MTcyODVkZTZjOS5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDgwNyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA4MDdUMjEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWU5ZjUzNGJmMGZlMzNjZmRmZmNmYzdlOGVhYTc1MGZhNzVjNDlmNjgwYTJiYWNhMTBlNTc2YmJhZTNjZWJlOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.1BO9Fncu1POYdXUNIT2rRTRJimpRGMeumaevUIA-8NU" alt="Image"></a></p>
<p dir="auto">I later changed to 5 Gbps using a NICGIGA switch, and racked it in a black T1 mini rack shipped by DeskPi, along with four of their currently-in-prototype Framework Desktop mini rack trays. <a href="https://github.com/geerlingguy/mini-rack/issues/234" data-hovercard-type="issue" data-hovercard-url="/geerlingguy/mini-rack/issues/234/hovercard">Mini rack build showcase here</a>.</p>
<p dir="auto">I also tested Thunderbolt node-to-node interconnects, but could only get 10 Gbps over TB4 using <code>thunderbolt0</code>/<code>thunderbolt1</code> interfaces).</p>
<p dir="auto">For more benchmarks (focusing on CPU, GPU, disk, net, etc.), see:</p>
<ul dir="auto">
<li><a href="https://www.jeffgeerling.com/blog/2025/i-clustered-four-framework-mainboards-test-huge-llms" rel="nofollow">I clustered four Framework Mainboards to test huge LLMs</a></li>
<li><a href="https://github.com/geerlingguy/sbc-reviews/issues/80" data-hovercard-type="issue" data-hovercard-url="/geerlingguy/sbc-reviews/issues/80/hovercard">sbc-reviews: Framework Desktop</a>.</li>
</ul>
<p dir="auto">All my automation for testing is in the <a href="https://github.com/geerlingguy/beowulf-ai-cluster">Beowulf AI Cluster</a> repo.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5: Key characteristics, pricing and system card (472 pts)]]></title>
            <link>https://simonwillison.net/2025/Aug/7/gpt-5/</link>
            <guid>44827794</guid>
            <pubDate>Thu, 07 Aug 2025 17:46:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Aug/7/gpt-5/">https://simonwillison.net/2025/Aug/7/gpt-5/</a>, See on <a href="https://news.ycombinator.com/item?id=44827794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/Aug/7/gpt-5/">

<p>7th August 2025</p>



<p>I’ve had preview access to the new GPT-5 model family for the past two weeks (see <a href="https://simonwillison.net/2025/Aug/7/previewing-gpt-5/">related video</a>) and have been using GPT-5 as my daily-driver. It’s my new favorite model. It’s still an LLM—it’s not a dramatic departure from what we’ve had before—but it rarely screws up and generally feels competent or occasionally impressive at the kinds of things I like to use models for.</p>
<p>I’ve collected a lot of notes over the past two weeks, so I’ve decided to break them up into <a href="https://simonwillison.net/series/gpt-5/">a series of posts</a>. This first one will cover key characteristics of the models, how they are priced and what we can learn from the <a href="https://openai.com/index/gpt-5-system-card/">GPT-5 system card</a>.</p>
<ul>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#key-model-characteristics">Key model characteristics</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#position-in-the-openai-model-family">Position in the OpenAI model family</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#pricing-is-aggressively-competitive">Pricing is aggressively competitive</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#more-notes-from-the-system-card">More notes from the system card</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#prompt-injection-in-the-system-card">Prompt injection in the system card</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#thinking-traces-in-the-api">Thinking traces in the API</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#and-some-svgs-of-pelicans">And some SVGs of pelicans</a></li>
</ul>

<h4 id="key-model-characteristics">Key model characteristics</h4>
<p>Let’s start with the fundamentals. GPT-5 in ChatGPT is a weird hybrid that switches between different models. Here’s what the system card says about that (my highlights in bold):</p>
<blockquote>
<p>GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and <strong>a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent</strong> (for example, if you say “think hard about this” in the prompt). [...] Once usage limits are reached, a mini version of each model handles remaining queries. In the near future, we plan to integrate these capabilities into a single model.</p>
</blockquote>
<p>GPT-5 in the API is simpler: it’s available as three models—<strong>regular</strong>, <strong>mini</strong> and <strong>nano</strong>—which can each be run at one of four reasoning levels: minimal (a new level not previously available for other OpenAI reasoning models), low, medium or high.</p>
<p>The models have an input limit of 272,000 tokens and an output limit (which includes invisible reasoning tokens) of 128,000 tokens. They support text and image for input, text only for output.</p>
<p>I’ve mainly explored full GPT-5. My verdict: it’s just <strong>good at stuff</strong>. It doesn’t feel like a dramatic leap ahead from other LLMs but it exudes competence—it rarely messes up, and frequently impresses me. I’ve found it to be a very sensible default for everything that I want to do. At no point have I found myself wanting to re-run a prompt against a different model to try and get a better result.</p>

<p>Here are the OpenAI model pages for <a href="https://platform.openai.com/docs/models/gpt-5">GPT-5</a>, <a href="https://platform.openai.com/docs/models/gpt-5-mini">GPT-5 mini</a> and <a href="https://platform.openai.com/docs/models/gpt-5-nano">GPT-5 nano</a>. Knowledge cut-off is September 30th 2024 for GPT-5 and May 30th 2024 for GPT-5 mini and nano.</p>

<h4 id="position-in-the-openai-model-family">Position in the OpenAI model family</h4>
<p>The three new GPT-5 models are clearly intended as a replacement for most of the rest of the OpenAI line-up. This table from the system card is useful, as it shows how they see the new models fitting in:</p>
<table>
<thead>
<tr>
<th>Previous model</th>
<th>GPT-5 model</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-4o</td>
<td>gpt-5-main</td>
</tr>
<tr>
<td>GPT-4o-mini</td>
<td>gpt-5-main-mini</td>
</tr>
<tr>
<td>OpenAI o3</td>
<td>gpt-5-thinking</td>
</tr>
<tr>
<td>OpenAI o4-mini</td>
<td>gpt-5-thinking-mini</td>
</tr>
<tr>
<td>GPT-4.1-nano</td>
<td>gpt-5-thinking-nano</td>
</tr>
<tr>
<td>OpenAI o3 Pro</td>
<td>gpt-5-thinking-pro</td>
</tr>
</tbody>
</table>
<p>That “thinking-pro” model is currently only available via ChatGPT where it is labelled as “GPT-5 Pro” and limited to the $200/month tier. It uses “parallel test time compute”.</p>
<p>The only capabilities not covered by GPT-5 are audio input/output and image generation. Those remain covered by models like <a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview">GPT-4o Audio</a> and <a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview">GPT-4o Realtime</a> and their mini variants and the <a href="https://platform.openai.com/docs/models/gpt-image-1">GPT Image 1</a> and DALL-E image generation models.</p>
<h4 id="pricing-is-aggressively-competitive">Pricing is aggressively competitive</h4>
<p>The pricing is <em>aggressively competitive</em> with other providers.</p>
<ul>
<li>GPT-5: $1.25/million for input, $10/million for output</li>
<li>GPT-5 Mini: $0.25/m input, $2.00/m output</li>
<li>GPT-5 Nano: $0.05/m input, $0.40/m output</li>
</ul>
<p>GPT-5 is priced at half the input cost of GPT-4o, and maintains the same price for output. Those invisible reasoning tokens count as output tokens so you can expect most prompts to use more output tokens than their GPT-4o equivalent (unless you set reasoning effort to “minimal”).</p>
<p>The discount for token caching is significant too: 90% off on input tokens that have been used within the previous few minutes. This is particularly material if you are implementing a chat UI where the same conversation gets replayed every time the user adds another prompt to the sequence.</p>
<p>Here’s a comparison table I put together showing the new models alongside the most comparable models from OpenAI’s competition:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Input $/m</th>
<th>Output $/m</th>
</tr>
</thead>
<tbody>
<tr>
<td>Claude Opus 4.1</td>
<td>15.00</td>
<td>75.00</td>
</tr>
<tr>
<td>Claude Sonnet 4</td>
<td>3.00</td>
<td>15.00</td>
</tr>
<tr>
<td>Grok 4</td>
<td>3.00</td>
<td>15.00</td>
</tr>
<tr>
<td>Gemini 2.5 Pro (&gt;200,000)</td>
<td>2.50</td>
<td>15.00</td>
</tr>
<tr>
<td>GPT-4o</td>
<td>2.50</td>
<td>10.00</td>
</tr>
<tr>
<td>GPT-4.1</td>
<td>2.00</td>
<td>8.00</td>
</tr>
<tr>
<td>o3</td>
<td>2.00</td>
<td>8.00</td>
</tr>
<tr>
<td>Gemini 2.5 Pro (&lt;200,000)</td>
<td>1.25</td>
<td>10.00</td>
</tr>
<tr>
<td><strong>GPT-5</strong></td>
<td>1.25</td>
<td>10.00</td>
</tr>
<tr>
<td>o4-mini</td>
<td>1.10</td>
<td>4.40</td>
</tr>
<tr>
<td>Claude 3.5 Haiku</td>
<td>0.80</td>
<td>4.00</td>
</tr>
<tr>
<td>GPT-4.1 mini</td>
<td>0.40</td>
<td>1.60</td>
</tr>
<tr>
<td>Gemini 2.5 Flash</td>
<td>0.30</td>
<td>2.50</td>
</tr>
<tr>
<td>Grok 3 Mini</td>
<td>0.30</td>
<td>0.50</td>
</tr>
<tr>
<td><strong>GPT-5 Mini</strong></td>
<td>0.25</td>
<td>2.00</td>
</tr>
<tr>
<td>GPT-4o mini</td>
<td>0.15</td>
<td>0.60</td>
</tr>
<tr>
<td>Gemini 2.5 Flash-Lite</td>
<td>0.10</td>
<td>0.40</td>
</tr>
<tr>
<td>GPT-4.1 Nano</td>
<td>0.10</td>
<td>0.40</td>
</tr>
<tr>
<td>Amazon Nova Lite</td>
<td>0.06</td>
<td>0.24</td>
</tr>
<tr>
<td><strong>GPT-5 Nano</strong></td>
<td>0.05</td>
<td>0.40</td>
</tr>
<tr>
<td>Amazon Nova Micro</td>
<td>0.035</td>
<td>0.14</td>
</tr>
</tbody>
</table>
<p>(Here’s a good example of a GPT-5 failure: I tried to get it to <a href="https://chatgpt.com/share/6894d804-bca4-8006-ac46-580bf4a9bf5f">output that table sorted itself</a> but it put Nova Micro as more expensive than GPT-5 Nano, so I prompted it to “construct the table in Python and sort it there” and that fixed the issue.)</p>
<h4 id="more-notes-from-the-system-card">More notes from the system card</h4>
<p>As usual, <a href="">the system card</a> is vague on what went into the training data. Here’s what it says:</p>
<blockquote>
<p>Like OpenAI’s other models, the GPT-5 models were trained on diverse datasets, including information that is publicly available on the internet, information that we partner with third parties to access, and information that our users or human trainers and researchers provide or generate. [...] We use advanced data filtering processes to reduce personal information from training data.</p>
</blockquote>
<p>I found this section interesting, as it reveals that writing, code and health are three of the most common use-cases for ChatGPT. This explains why so much effort went into health-related questions,  for both GPT-5 and the recently released OpenAI open weight models.</p>
<blockquote>
<p>We’ve made significant advances in <strong>reducing hallucinations, improving instruction following, and minimizing sycophancy</strong>, and have leveled up GPT-5’s performance in <strong>three of ChatGPT’s most common uses: writing, coding, and health</strong>. All of the GPT-5 models additionally feature <strong>safe-completions, our latest approach to safety training</strong> to prevent disallowed content.</p>
</blockquote>
<p>Safe-completions is later described like this:</p>
<blockquote>
<p>Large language models such as those powering ChatGPT have <strong>traditionally been trained to
either be as helpful as possible or outright refuse a user request</strong>, depending on whether the
prompt is allowed by safety policy. [...] Binary refusal boundaries are especially ill-suited for dual-use cases (such as biology
or cybersecurity), where a user request can be completed safely at a high level, but may lead
to malicious uplift if sufficiently detailed or actionable. <strong>As an alternative, we introduced safe-
completions: a safety-training approach that centers on the safety of the assistant’s output rather
than a binary classification of the user’s intent</strong>. Safe-completions seek to maximize helpfulness
subject to the safety policy’s constraints.</p>
</blockquote>
<p>So instead of straight up refusals, we should expect GPT-5 to still provide an answer but moderate that answer to avoid it including “harmful” content.</p>
<p>OpenAI have a paper about this which I haven’t read yet (I didn’t get early access): <a href="https://openai.com/index/gpt-5-safe-completions/">From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training</a>.</p>
<p>Sycophancy gets a mention, unsurprising given <a href="https://simonwillison.net/2025/May/2/what-we-missed-with-sycophancy/">their high profile disaster in April</a>. They’ve worked on this in the core model:</p>
<blockquote>
<p>System
prompts, while easy to modify, have a more limited impact on model outputs relative to changes in
post-training. For GPT-5, we post-trained our models to reduce sycophancy. Using conversations
representative of production data, we evaluated model responses, then assigned a score reflecting
the level of sycophancy, which was used as a reward signal in training.</p>
</blockquote>
<p>They claim impressive reductions in hallucinations. In my own usage I’ve not spotted a single hallucination yet, but that’s been true for me for Claude 4 and o3 recently as well—hallucination is so much less of a problem with this year’s models.</p>
<blockquote>
<p>One of our focuses when training the GPT-5 models was to reduce the frequency of factual
hallucinations. While ChatGPT has browsing enabled by default, many API queries do not use
browsing tools. Thus, we focused both on training our models to browse effectively for up-to-date
information, and on reducing hallucinations when the models are relying on their own internal
knowledge.</p>
</blockquote>
<p>The section about deception also incorporates the thing where models sometimes pretend they’ve completed a task that defeated them:</p>
<blockquote>
<p>We placed gpt-5-thinking in a variety of tasks that were partly or entirely infeasible to accomplish,
and <strong>rewarded the model for honestly admitting it can not complete the task</strong>. [...]</p>
<p>In tasks where the agent is required to use tools, such as a web browsing
tool, in order to answer a user’s query, previous models would hallucinate information when
the tool was unreliable. We simulate this scenario by purposefully disabling the tools or by
making them return error codes.</p>
</blockquote>
<h4 id="prompt-injection-in-the-system-card">Prompt injection in the system card</h4>
<p>There’s a section about prompt injection, but it’s pretty weak sauce in my opinion.</p>
<blockquote>
<p>Two external red-teaming groups conducted a two-week prompt-injection assessment targeting
system-level vulnerabilities across ChatGPT’s connectors and mitigations, rather than model-only
behavior.</p>
</blockquote>
<p>Here’s their chart showing how well the model scores against the rest of the field. It’s an impressive result in comparison—56.8 attack success rate for gpt-5-thinking, where Claude 3.7 scores in the 60s (no Claude 4 results included here) and everything else is 70% plus:</p>
<p><img src="https://static.simonwillison.net/static/2025/prompt-injection-chart.jpg" alt="A bar chart titled &quot;Behavior Attack Success Rate at k Queries&quot; shows attack success rates (in %) for various AI models at k=1 (dark red) and k=10 (light red). For each model, the total height of the stacked bar represents the k=10 success rate (labeled above each bar), while the lower dark red section represents the k=1 success rate (estimated). From left to right: Llama 3.3 70B – k=10: 92.2%, k=1: ~47%; Llama 3.1 405B – k=10: 90.9%, k=1: ~38%; Gemini Flash 1.5 – k=10: 87.7%, k=1: ~34%; GPT-4o – k=10: 86.4%, k=1: ~28%; OpenAI o3-mini-high – k=10: 86.4%, k=1: ~41%; Gemini Pro 1.5 – k=10: 85.5%, k=1: ~34%; Gemini 2.5 Pro Preview – k=10: 85.0%, k=1: ~28%; Gemini 2.0 Flash – k=10: 85.0%, k=1: ~33%; OpenAI o3-mini – k=10: 84.5%, k=1: ~40%; Grok 2 – k=10: 82.7%, k=1: ~34%; GPT-4.5 – k=10: 80.5%, k=1: ~28%; 3.5 Haiku – k=10: 76.4%, k=1: ~17%; Command-R – k=10: 76.4%, k=1: ~28%; OpenAI o4-mini – k=10: 75.5%, k=1: ~17%; 3.5 Sonnet – k=10: 75.0%, k=1: ~13%; OpenAI o1 – k=10: 71.8%, k=1: ~18%; 3.7 Sonnet – k=10: 64.5%, k=1: ~17%; 3.7 Sonnet: Thinking – k=10: 63.6%, k=1: ~17%; OpenAI o3 – k=10: 62.7%, k=1: ~13%; gpt-5-thinking – k=10: 56.8%, k=1: ~6%. Legend shows dark red = k=1 and light red = k=10."></p>
<p>On the one hand, a 56.8% attack rate is cleanly a big improvement against all of those other models.</p>
<p>But it’s also a strong signal that prompt injection continues to be an unsolved problem! That means that more than half of those k=10 attacks (where the attacker was able to try up to ten times) got through.</p>
<p>Don’t assume prompt injection isn’t going to be a problem for your application just because the models got better.</p>
<h4 id="thinking-traces-in-the-api">Thinking traces in the API</h4>
<p>I had initially thought that my biggest disappointment with GPT-5 was that there’s no way to get at those thinking traces via the API... but that turned out <a href="https://bsky.app/profile/sophiebits.com/post/3lvtceih7222r">not to be true</a>. The following <code>curl</code> command demonstrates that the responses API <code>"reasoning": {"summary": "auto"}</code> is available for the new GPT-5 models:</p>

<pre><code>curl https://api.openai.com/v1/responses \
  -H "Authorization: Bearer $(llm keys get openai)" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-5",
    "input": "Give me a one-sentence fun fact about octopuses.",
    "reasoning": {"summary": "auto"}
  }'</code></pre>

<p>Here’s <a href="https://gist.github.com/simonw/1d1013ba059af76461153722005a039d">the response</a> from that API call.</p>

<p>Without that option the API will often provide a lengthy delay while the model burns through thinking tokens until you start getting back visible tokens for the final response.</p>
<p>OpenAI offer a new <code>reasoning_effort=minimal</code> option which turns off most reasoning so that tokens start to stream back to you as quickly as possible.</p>
<h4 id="and-some-svgs-of-pelicans">And some SVGs of pelicans</h4>
<p>Naturally I’ve been running <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">my “Generate an SVG of a pelican riding a bicycle” benchmark</a>. I’ll actually spend more time on this in a future post—I have some fun variants I’ve been exploring—but for the moment here’s <a href="https://gist.github.com/simonw/c98873ef29e621c0fe2e0d4023534406">the pelican</a> I got from GPT-5 running at its default “medium” reasoning effort:</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-pelican.png" alt="The bicycle is really good, spokes on wheels, correct shape frame, nice pedals. The pelican has a pelican beak and long legs stretching to the pedals."></p>
<p>It’s pretty great! Definitely recognizable as a pelican, and one of the best bicycles I’ve seen yet.</p>
<p>Here’s <a href="https://gist.github.com/simonw/9b5ecf61a5fb0794729aa0023aaa504d">GPT-5 mini</a>:</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-mini-pelican.png" alt="Blue background with clouds. Pelican has two necks for some reason. Has a good beak though. More gradents and shadows than the GPT-5 one."></p>
<p>And <a href="https://gist.github.com/simonw/3884dc8b186b630956a1fb0179e191bc">GPT-5 nano</a>:</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-nano-pelican.png" alt="Bicycle is two circles and some randomish black lines. Pelican still has an OK beak but is otherwise very simple."></p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DNA tests are uncovering the true prevalence of incest (2024) (101 pts)]]></title>
            <link>https://www.theatlantic.com/health/archive/2024/03/dna-tests-incest/677791/</link>
            <guid>44827692</guid>
            <pubDate>Thu, 07 Aug 2025 17:40:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/health/archive/2024/03/dna-tests-incest/677791/">https://www.theatlantic.com/health/archive/2024/03/dna-tests-incest/677791/</a>, See on <a href="https://news.ycombinator.com/item?id=44827692">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">When Steve Edsel was a boy, his adoptive parents kept a scrapbook of newspaper clippings in their bedroom closet. He would ask for it sometimes, poring over the headlines about his birth. Headlines like this: “Mother Deserts Son, Flees From Hospital,” <em>Winston-Salem Journal,</em> December 30, 1973.</p><p data-flatplan-paragraph="true">The mother in question was 14 years old, “5 feet 6 with reddish brown hair,” and she had come to the hospital early one morning with her own parents. They gave names that all turned out to be fake. And by 8 o’clock that evening, just hours after she gave birth, they were gone. In a black-and-white drawing of the mother, based on nurses’ recollections, she has round glasses and sideswept bangs. Her mouth is grimly set.</p><p data-flatplan-paragraph="true">The abandoned boy was placed in foster care with a local couple, the Edsels, who later adopted him. Steve knew all of this growing up. His parents never tried to hide his origins, and they always gave him the scrapbook when he asked. It wasn’t until he turned 14, though, that he really began to wonder about his birth mom. “I’m 14,” he thought at the time. “This is how old she was when she had me.”</p><p data-flatplan-paragraph="true">Steve began looking for her in earnest in his 20s, but the paper trail quickly ran cold. When he turned 40, he told his wife, Michelle, that he wanted to give the search one last go. This was in 2013. AncestryDNA had started selling mail-in test kits the previous year, so he bought one. His matches at first seemed unpromising—some distant relatives—but when he began posting in a Facebook group for people seeking out biological family, he got connected to a genetic genealogist named CeCe Moore. Moore specializes in finding people via distant DNA matches, a technique made famous in 2018 when it led to the <a data-event-element="inline link" href="https://www.theatlantic.com/science/archive/2018/04/golden-state-killer-east-area-rapist-dna-genealogy/559070/">capture of the Golden State Killer</a>. But back then, genetic genealogy was still new, and Moore was one of its pioneers. She volunteered to help Steve.</p><p data-flatplan-paragraph="true">Within just a couple of weeks, she had narrowed down the search to two women, cousins of the same age. On Facebook, Steve could see that one cousin had four kids, and she regularly posted photos of them, beautiful and smiling. They looked well-off, their lives picture-perfect—“like a storybook,” Steve says. The other woman was unmarried; she didn’t have kids. She was not friends with her immediate family on Facebook, and she had moved halfway across the country from them. One evening—a Saturday, Steve clearly remembers—Moore asked to speak with him by phone.</p><p data-flatplan-paragraph="true">She confirmed what he had already suspected: His birth mom was the second woman. But Moore had another piece of news too. She had unexpectedly figured out something about his biological father as well.<em> It looks like your parents are related.</em> Steve didn’t know what to say. <em>Do you understand what I mean?</em> He said he thought so. <em>Either your mom’s father or your mom’s brother is your father.</em> A sea of emotions rose to a boil inside him: anger, hurt, worthlessness, disgust, shame, and devastation all at once. In his years of wondering about his birth, he had never, ever considered the possibility of incest. Why would he? What were the chances?</p><hr><p data-flatplan-paragraph="true">In 1975, around the time of Steve’s birth, a psychiatric textbook put the frequency of incest at one in a million.</p><p data-flatplan-paragraph="true">But this number is almost certainly a dramatic underestimate. The stigma around openly discussing incest, which often involves child sexual abuse, has long made the subject difficult to study. In the 1980s, <a data-event-element="inline link" href="https://www.hup.harvard.edu/books/9780674002708">feminist scholars argued</a>, based on the testimonies of victims, that incest was far more common than recognized, and in recent years, DNA has offered a new kind of biological proof. Widespread genetic testing is uncovering case after secret case of children born to close biological relatives—providing an unprecedented accounting of incest in modern society.</p><p data-flatplan-paragraph="true">The geneticist Jim Wilson, at the University of Edinburgh, was shocked by the frequency he found in the U.K. Biobank, an anonymized research database: One in 7,000 people, according to his unpublished analysis, was born to parents who were first-degree relatives—a brother and a sister or a parent and a child. “That’s way, way more than I think many people would ever imagine,” he told me. And this number is just a floor: It reflects only the cases that resulted in pregnancy, that did not end in miscarriage or abortion, and that led to the birth of a child who grew into an adult who volunteered for a research study.</p><p data-flatplan-paragraph="true">Most of the people affected may never know about their parentage, but these days, many are stumbling into the truth after AncestryDNA and 23andMe tests. Steve’s case was one of the first Moore worked on involving closely related parents. She now knows of well over 1,000 additional cases of people born from incest, the significant majority between first-degree relatives, with the rest between second-degree relatives (half-siblings, uncle-niece, aunt-nephew, grandparent-grandchild). The cases show up in every part of society, every strata of income, she told me.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/science/archive/2018/07/dna-test-misattributed-paternity/562928/">Read: When a DNA test shatters your identity</a></p><p data-flatplan-paragraph="true">Neither AncestryDNA nor 23andMe informs customers about incest directly, so the thousand-plus cases Moore knows of all come from the tiny proportion of testers who investigated further. This meant, for example, uploading their DNA profiles to a third-party genealogy site to analyze what are known as “runs of homozygosity,” or ROH: long stretches where the DNA inherited from one’s mother and father are identical. For a while, one popular genealogy site instructed anyone who found high ROH to contact Moore. She would call them, one by one, to explain the jargon’s explosive meaning. Unwittingly, she became the keeper of what might be the world’s largest database of people born out of incest.</p><p data-flatplan-paragraph="true">In the overwhelming majority of cases, Moore told me, the parents are a father and a daughter or an older brother and a younger sister, meaning a child’s existence was likely evidence of sexual abuse. She had no obvious place to send people reeling from such revelations, and she was not herself a trained therapist. After seeing many of these cases, though, she wanted people to know they were not alone. Moore ended up creating a private and invite-only support group on Facebook in 2016, and she tapped Steve and later his wife, Michelle, to become admins, too. The three of them had become close in the months and years after the search for his birth mom, as they navigated the emotional fallout together.</p><p data-flatplan-paragraph="true">One day this past January, Michelle, who also works as Moore’s part-time assistant, told me she had spoken with four new people that week, all of them with ROH high enough to have parents who were first-degree relatives. She used to dread these calls. “I would stumble over my words,” she told me. But not anymore. She tells the shaken person on the line that they can join a support group full of people who are living the same reality. She tells them they can talk to her husband, Steve.</p><hr><p data-flatplan-paragraph="true">When Steve first discovered the truth about his biological parents, a decade ago, he had no support group to turn to, and he did not know what to do with the strange mix of emotions. He was genuinely happy to have found his birth mom. He had never looked like his adoptive parents, but in photos of her and her family, he could see his eyes, his chin, and even the smirky half-grin that his face naturally settles into.</p><p data-flatplan-paragraph="true">But he radiated with newfound anger, too, on her behalf. He could not know the exact circumstances of his conception, and his DNA test alone could not determine whether her older brother or her father was responsible. But Steve could not imagine a consensual scenario, given her age. The bespectacled 14-year-old girl who disappeared from the hospital had remained frozen in time in his mind, even as he himself grew older, got married, became a stepdad. He felt protective of that young girl.</p><p data-flatplan-paragraph="true">As badly as he wanted to know his birth mom, he worried she would not want to know him. Would his sudden reappearance dredge up traumatic memories—memories she had perhaps been trying to outrun her whole adult life, given how far away she had moved and how little she seemed connected to her family? A religious man, Steve prayed over it and settled on handwriting a letter. He included a couple of paragraphs about his life, some photos, and a message that he loved her. He left out what he knew about his paternity. And he took care to send the letter by certified mail, so that he could confirm its receipt and so that it would not accidentally fall into anyone else’s hands.</p><p data-flatplan-paragraph="true">She never responded. But Steve knew that she had received it: The post office sent him the green slip that she had signed upon delivery, and he scrutinized her signature—her actual name, written by her actual hand. At 40 years old, he touched for the first time something his mother had just touched, held something she had just held. He put the slip inside the pages of his Bible.</p><p data-flatplan-paragraph="true">Steve had never faulted his mother for leaving him at the hospital, and finding out about his paternity made him even more understanding. But the revelation also made him struggle with who he was. Did it mean that something was wrong with him, written into his DNA from the moment of his conception? On a <a data-event-element="inline link" href="https://podcasts.apple.com/us/podcast/ep-1-the-secret-one/id1572201167?i=1000526354990">podcast</a> later, he admitted to feeling like trash, “like something that somebody had just thrown away.” Those first six months after his discovery were the hardest six months of his life.</p><hr><p data-flatplan-paragraph="true">Across human cultures, incest between close family members is one of the most universal and most deeply held taboos. A common explanation is biological: Children born from related parents are more likely to develop health complications, because their parents are more likely to be carriers of the same recessive mutations. From the 1960s to the ’80s, a <a data-event-element="inline link" href="https://publications.aap.org/pediatrics/article-abstract/40/1/55/43627/CHILDREN-OF-INCEST">handful</a> <a data-event-element="inline link" href="https://www.sciencedirect.com/science/article/abs/pii/S0022347682803478">of</a> <a data-event-element="inline link" href="https://karger.com/hhe/article-abstract/21/2/108/158742/A-Study-of-Children-of-Incestuous-Matings">studies</a> following a few dozen children born of incest documented high rates of infant mortality and congenital conditions.</p><p data-flatplan-paragraph="true">But in the past, healthy children born from incestuous unions would have never come to the attention of doctors. As widespread DNA testing has uncovered orders of magnitude more people whose parents are brother and sister or parent and child, it’s also shown that plenty of those people are perfectly healthy. “There is a large element of chance in whether incest has a poor outcome,” according to Wilson, the geneticist. It depends on whether those runs of homozygosity contain recessive disease-causing mutations. All of us have some of these runs in our DNA—usually less than 1 percent of the genome in Western populations, higher in cultures where cousin marriage is common. But that number is about 25 percent, Wilson said, in people born from first-degree relatives. While the odds of a genetic disease are much higher, the outcome is far from predetermined.</p><p data-flatplan-paragraph="true">Still, these numbers make people wonder. Steve was born with a heart murmur, which required open-heart surgery at ages 13 and 18, though he does not know for sure the cause; heart defects are among the more common birth defects in the general population. He and Michelle were also never able to have children together. Others in the Facebook group have shared their struggles with autoimmune diseases, fibromyalgia, eye problems, and so on—though these are often hard to definitively link to incest. Health problems arising from incest might manifest in any number of ways, depending on exactly which mutations are inherited. “When I go to the doctor and they ask me my family history, I wonder: <em>How much do I need to go into it?</em>” says Mandy, another member of the group. (I am identifying some people by first name only, so they can speak freely about their family and medical histories.) How much experience would a typical doctor have with incest, anyway?</p><p data-flatplan-paragraph="true">After Mandy first learned that her father was her mother’s uncle, she went looking for stories about other people like her. All she could find were “gross fantasies” online and medical-journal articles about health problems. She felt very lonely. “<em>I don’t have anybody I can talk to about this</em>,” she remembers thinking. “<em>Nobody knows what to say.</em>” When she found the Facebook group, she could see that she was far from the only one like her. She watched the others cycle, too, through the stages of denial, anger, bargaining, depression, and acceptance.</p><p data-flatplan-paragraph="true">She does not know exactly what happened between her biological parents, but her mother was 17, and her mother’s uncle was in his 30s. The discovery, for all the hurt that it surfaced, has helped Mandy reconcile some of her childhood experiences. Unlike Steve, she was raised by her biological mother, and she believed her mother’s husband to be her biological father. He mostly ignored her, but her mother was cruel. She treated Mandy differently than she did her younger brothers. “At least now I have more of an answer as to why,” Mandy told me. “I wasn’t a bad kid and unlovable.”</p><p data-flatplan-paragraph="true">Kathy was also raised by her mother, though she had an early inkling that her dad was not her biological dad. Their blood types were incompatible, and she heard rumors about her mother and grandfather. Although her mother’s family was violent and chaotic, she was close to her dad’s family, especially her granny on that side. “They’ve been my rock,” she told me. By the time Kathy took a DNA test confirming that her dad was not her biological dad, she had spent a lifetime distancing herself from her biological family and embracing one with whom she shared no DNA.</p><p data-flatplan-paragraph="true">Hers was, in some ways, the opposite journey of adoptees such as Steve, who wanted so badly to know his biological family. But the two of them have become close. Kathy remembers how angry he used to be on his mother’s behalf. She told him that she used to be angry too, but she had to leave it behind. “It’s not going to bring me any peace. It’s not going to bring my mother any peace,” she recalled saying. And it wouldn’t undo what had been done to his mother by her father or her brother so many years ago.</p><hr><p data-flatplan-paragraph="true">In the end, Steve was able to identify his biological father, though not through any particular feat of genetic sleuthing. One day, two and a half years after his DNA test, he logged in to AncestryDNA and saw a parent match. It was his mother’s older brother. From the site, he could see that his father-uncle had logged in once, presumably seen that Steve was his son, and—even after Steve sent him a message—never logged back on again.</p><p data-flatplan-paragraph="true">By then, his initial anger had started to dissipate. He still felt deeply for his birth mom. Michelle says that her husband has always been a sensitive guy—she makes fun of him for crying at movies—but he’s become even more empathetic. The feeling of worthlessness he initially struggled with has given way to a sense of purpose; he and Michelle now spend hours on the phone talking with others in the support group.</p><p data-flatplan-paragraph="true">Steve has still never spoken to his birth mother. He tried writing to her a second time, sending a journal about his life—but she returned it unopened. He messages her occasionally on Facebook, sending photos of grandkids and puppies he’s raised. Every year, he wishes her a happy birthday. She has not replied, but she has also not blocked him.</p><p data-flatplan-paragraph="true">When the journal came back unopened, Steve decided to try messaging his mother’s cousin—the other woman he’d initially thought could be his birth mom. He yearned for some kind of connection with someone in his biological family. He wrote to the cousin about his mom—but not his dad—and she&nbsp; actually replied. She told him that she and his mom had been close as children, Steve recounted, but she did not know about a pregnancy. To her, it had seemed like her cousin one day “fell off the face of the Earth,” he says. She agreed to read his journal, and the two of them soon began speaking on the phone about their families.</p><p data-flatplan-paragraph="true">Months later, Steve felt like he could finally share the truth about his biological father, and the cousin again accepted him for who he was. They met for the first time in 2017 when she was visiting a nearby town, and she later invited Steve and Michelle to Thanksgiving. Last year, she extended another invitation to a large family gathering. Steve’s immediate biological family was not there, but hers was, and they all knew about him and his mom and his dad. They greeted him with hugs, and they took photos together as a family. “It felt like a relief,” he told me, like a burden had been lifted from him. In this family, he was not a secret.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5 for Developers (359 pts)]]></title>
            <link>https://openai.com/index/introducing-gpt-5-for-developers</link>
            <guid>44827101</guid>
            <pubDate>Thu, 07 Aug 2025 17:06:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-gpt-5-for-developers">https://openai.com/index/introducing-gpt-5-for-developers</a>, See on <a href="https://news.ycombinator.com/item?id=44827101">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-gpt-5-for-developers: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5 (1485 pts)]]></title>
            <link>http://openai.com/gpt-5</link>
            <guid>44826997</guid>
            <pubDate>Thu, 07 Aug 2025 17:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://openai.com/gpt-5">http://openai.com/gpt-5</a>, See on <a href="https://news.ycombinator.com/item?id=44826997">Hacker News</a></p>
Couldn't get http://openai.com/gpt-5: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Live: GPT-5 (170 pts)]]></title>
            <link>https://www.youtube.com/watch?v=0Uu_VJeVVfo</link>
            <guid>44826463</guid>
            <pubDate>Thu, 07 Aug 2025 16:16:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=0Uu_VJeVVfo">https://www.youtube.com/watch?v=0Uu_VJeVVfo</a>, See on <a href="https://news.ycombinator.com/item?id=44826463">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Building Bluesky Comments for My Blog (277 pts)]]></title>
            <link>https://natalie.sh/posts/bluesky-comments/</link>
            <guid>44826164</guid>
            <pubDate>Thu, 07 Aug 2025 15:56:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://natalie.sh/posts/bluesky-comments/">https://natalie.sh/posts/bluesky-comments/</a>, See on <a href="https://news.ycombinator.com/item?id=44826164">Hacker News</a></p>
<div id="readability-page-1" class="page"><p data-astro-cid-2q5oecfc=""> I hate disqus too much. </p><article data-astro-cid-2q5oecfc=""> 
<p>I’ve been running my blog without decent comments for years. Not by choice, really - I just couldn’t find a solution that didn’t suck.</p>
<ul>
<li>
<p>Disqus? Slow, heavy, tracks users, and I don’t own anything. Plus it makes every page 100x slower to load.</p>
</li>
<li>
<p>Self-hosted solutions? Great in theory. (not really.) You’re signing up to manage users, moderate spam, maintain databases, and deal with all the headaches that come with running basically a miniature social platform. And if your users aren’t where you are, it’s probably slow as hell.</p>
</li>
<li>
<p>GitHub Issues as comments? Probably works for some developer blogs, but feels hacky and limits your audience to people with GitHub accounts.</p>
</li>
<li>
<p>No comments at all? Clean and simple, but you lose the conversations. Some of my favorite discoveries came from comment threads that went in unexpected directions.</p>
</li>
</ul>
<p>I’ve been a Bluesky user for a while. Recently, the community has been feeling healthier than Twitter ever did, the API is designed, and this decentralized approach means I don’t necessarily have to be beholden to a single company. People have been doing some interesting things with Bluesky, like on-protocol blog content and using Bluesky comments as a comment system. Why not do some of that for myself?</p>
<h2 id="why-bluesky-actually-makes-sense">Why Bluesky Actually Makes Sense</h2>
<p>The more I thought about it, the more directly using Bluesky for comments made sense:</p>
<ul>
<li>
<p>No infrastructure to maintain. (for me, at least) I don’t need to run databases, manage user accounts, or build moderation tools. Bluesky handles all of that.</p>
</li>
<li>
<p>Rich(er) content support. People can post images, links, and in threads. All the stuff that makes conversations interesting.</p>
</li>
<li>
<p>Real identities. Since people are using their actual Bluesky profiles, and your one profile can <em>actually</em> be used on any supported platform, there’s more accountability and less incentive to drive-by troll.</p>
</li>
<li>
<p>Cross-platform conversations. Comments live on Bluesky too, so people can discover my blog posts through social media and vice versa.</p>
</li>
<li>
<p>I own my content, they own theirs. No platform lock-in for anyone!</p>
</li>
</ul>
<p>The workflow is simple: I publish a blog post, share it on Bluesky, edit the post to add the AT URI, and the replies to that Bluesky post become the comments on my blog.</p>
<h2 id="building-the-component">Building the Component</h2>
<h3 id="understanding-the-at-protocol">Understanding the AT Protocol</h3>
<p>Bluesky runs on the AT Protocol, which has surprisingly okay documentation. The key concepts I needed:</p>
<ul>
<li><strong>DIDs</strong> (Decentralized Identifiers): Unique user IDs like <code>did:plc:abc123...</code> or <code>did:web:joe.coffee</code></li>
<li><strong>CIDs</strong> (Content Identifiers): Unique post IDs</li>
<li><strong>AT URIs</strong>: Addresses for content like <code>at://did:plc:user.../app.bsky.feed.post/postid</code></li>
</ul>
<p>To fetch comments, I just need to call the <code>getPostThread</code> endpoint with the right URI. No authentication required. Easy peasy.</p>
<h3 id="component-architecture">Component Architecture</h3>
<p>I ended up with three main pieces:</p>
<ol>
<li>The main comments component that fetches and displays the thread.</li>
<li>A reply component that handles rendering individual posts and their replies. Also includes metadata and a link to the original Bluesky post.</li>
<li>An embed component for rich content like images and open graph previews.</li>
</ol>
<p>This separation made each piece reasonably manageable, reasonable, and small.</p>
<h3 id="the-threading-challenge">The Threading Challenge</h3>
<p>The interesting part was handling nested replies. Bluesky threads can go arbitrarily deep, but I needed to display them in a way that’s readable and doesn’t break layouts.</p>
<p>I settled on a naive recursive approach where each reply can render child replies, with visual indentation to show the hierarchy. I cap it at 5 levels deep because beyond that, conversations usually devolve into two people arguing anyway.</p>
<pre tabindex="0" data-language="typescript"><code><span><span>const</span><span> MAX_DEPTH </span><span>=</span><span> 5</span><span>;</span></span>
<span><span>const</span><span> BlueskyReply</span><span> =</span><span> ({</span><span> thread</span><span>,</span><span> depth</span><span> =</span><span> 0</span><span> })</span><span> =&gt;</span><span> {</span></span>
<span><span>  return</span><span> (</span></span>
<span><span>    &lt;</span><span>div style</span><span>=</span><span>{{</span><span> marginLeft</span><span>:</span><span> depth </span><span>*</span><span> 12</span><span> }}</span><span>&gt;</span></span>
<span><span>      {</span><span>/* Render the post content */</span><span>}</span></span>
<span></span>
<span><span>      {</span><span>depth</span><span> &lt; </span><span>MAX_DEPTH</span><span> &amp;&amp; </span><span>thread</span><span>.</span><span>replies</span><span>?.</span><span>map</span><span>(</span><span>reply</span><span> =&gt;</span></span>
<span><span>        &lt;</span><span>BlueskyReply</span><span> thread</span><span>=</span><span>{</span><span>reply</span><span>}</span><span> depth</span><span>=</span><span>{</span><span>depth + </span><span>1</span><span>}</span><span> /&gt;</span></span>
<span><span>      )</span><span>}</span></span>
<span><span>    &lt;/</span><span>div</span><span>&gt;</span></span>
<span><span>  )</span><span>;</span></span>
<span><span>};</span></span></code></pre>
<h3 id="handling-rich-content">Handling Rich Content</h3>
<p>One of the nice things about Bluesky is that posts can contain more than just text. People embed images, external links, and even quote other posts. Each embed type needs special handling.</p>
<p><strong>Images</strong> were the most complex. Bluesky serves them through their CDN, and people often post multiple images in a single reply. I built a responsive grid layout that adapts based on image count, plus a modal for viewing images full-screen.</p>
<p><strong>External links</strong> get rendered as cards with thumbnails and descriptions, just like they appear in Bluesky apps.</p>
<p><strong>Other embed types</strong> get a graceful fallback message since the AT Protocol is extensible and new embed types might appear.</p>
<h3 id="integrating-with-astro">Integrating with Astro</h3>
<p>Getting this working with my Astro blog was straightforward. I had the React integration (which I already had for my background and music components) and used the <code>client:load</code> directive to ensure the comment component hydrates immediately:</p>
<pre tabindex="0" data-language="astro"><code><span><span>---</span></span>
<span><span>import</span><span> BlueskyComments </span><span>from</span><span> '../components/bsky-comments.tsx'</span><span>;</span></span>
<span><span>---</span></span>
<span></span>
<span><span>{</span><span>post</span><span>.</span><span>data</span><span>.</span><span>bsky </span><span>&amp;&amp;</span><span> (</span></span>
<span><span>  &lt;</span><span>BlueskyComments</span></span>
<span><span>    did</span><span>=</span><span>{</span><span>post</span><span>.</span><span>data</span><span>.</span><span>bsky</span><span>.</span><span>did</span><span>}</span></span>
<span><span>    postCid</span><span>=</span><span>{</span><span>post</span><span>.</span><span>data</span><span>.</span><span>bsky</span><span>.</span><span>postCid</span><span>}</span></span>
<span><span>    client</span><span>:</span><span>load</span></span>
<span><span>  /&gt;</span></span>
<span><span>)</span><span>}</span></span></code></pre>
<p>Now I just add this to any post’s frontmatter to enable comments:</p>
<pre tabindex="0" data-language="yaml"><code><span><span>bsky</span><span>:</span></span>
<span><span>  did</span><span>:</span><span> "my-bluesky-did"</span></span>
<span><span>  postCid</span><span>:</span><span> "the-post-id"</span></span></code></pre>
<h2 id="what-i-learned">What I Learned</h2>
<h3 id="typescript-is-your-friend">TypeScript is Your Friend</h3>
<p>There are proper TypeScript types for all their API responses through the <code>@atcute/client</code> package. This made development much smoother as I could rely on autocomplete and catch type errors before they became runtime bugs.</p>
<h3 id="progressive-enhancement-works">Progressive Enhancement Works</h3>
<p>I built the comments as an enhancement to the blog, not a core dependency. If JavaScript is disabled or the API is down, the blog post (rendered a long time ago) still works perfectly. The comments just don’t appear.</p>
<h3 id="performance-by-default--ish">Performance by Default (-ish)</h3>
<p>Since I’m not managing any backend infrastructure, server-side performance optimizations are just there. Bluesky’s CDN handles image delivery, their public API is fast and cached, and I don’t have to care about database queries or server scaling.</p>
<h2 id="the-results">The Results</h2>
<p>I’m pretty happy with how it turned out. The conversations feel more natural than traditional blog comments - people use their actual profiles, share images and links, and more. It’s a lot more like social media.</p>
<h2 id="whats-next">What’s Next</h2>
<p>I’m considering a few improvements, but honestly, the core system works so well that I’m not in a rush to change it. Sometimes the best solution is the one just works, almost invisibly.</p>
<h2 id="why-this-approach-works">Why This Approach Works</h2>
<p>Traditional comment systems try to recreate social media features on every individual website. I think that’s backwards. People already have social media accounts they like using. Instead of forcing them to create new accounts and learn new interfaces, why not try meeting them where they already are?</p>
<p>This approach scales with the platform because it <em>uses</em> the platform. As Bluesky grows, more people can participate in blog discussions without any additional work from me. And because everything is built on open protocols, I’m not locked into any single platform’s decisions. If Bluesky ever changes for the worse, I can always switch to another AppView, such as zeppelin or Blacksky’s AppView.</p>
<p>I could theoretically even write my own comments AppView. ATProto is designed to be flexible, especially with data, so doing such would be quite simple. I’d just need to listen to the right events on the firehose and store the data in a way that makes sense and rebuild the comment thread every so often.</p>
<p>In my opinion, the web is better when independent sites can connect to broader conversations without sacrificing their independence. I feel like this <del>is</del> was the goal of other decentralised platforms like Mastodon, but Bluesky’s focus on user-owned identities and app intercompat via the PDS ultimately makes it a better fit.</p>
<hr>
<p><em>Want to see it in action? The comments are right below this post, powered by the system I mentioned above. Meta.</em></p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to sell if your user is not the buyer (154 pts)]]></title>
            <link>https://writings.founderlabs.io/p/how-to-sell-if-your-user-is-not-the</link>
            <guid>44825491</guid>
            <pubDate>Thu, 07 Aug 2025 15:09:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://writings.founderlabs.io/p/how-to-sell-if-your-user-is-not-the">https://writings.founderlabs.io/p/how-to-sell-if-your-user-is-not-the</a>, See on <a href="https://news.ycombinator.com/item?id=44825491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!XpMA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!XpMA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 424w, https://substackcdn.com/image/fetch/$s_!XpMA!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 848w, https://substackcdn.com/image/fetch/$s_!XpMA!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 1272w, https://substackcdn.com/image/fetch/$s_!XpMA!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!XpMA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png" width="1456" height="816" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:816,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2220211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://writings.founderlabs.io/i/168654646?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!XpMA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 424w, https://substackcdn.com/image/fetch/$s_!XpMA!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 848w, https://substackcdn.com/image/fetch/$s_!XpMA!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 1272w, https://substackcdn.com/image/fetch/$s_!XpMA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7892cc8d-c26f-410a-9747-929a882f6573_1456x816.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>I recently wrote about how </span><a href="https://writings.founderlabs.io/p/your-ideal-customer-is-one-who-values" rel="">your ideal customer is one who values your product the most</a><span>”. And then quickly, in one of my private communities, I had this question pop up:</span></p><blockquote><p>But how you would talk to your ideal customer if they are not the ones who try the product?</p><p>In my case -- I totally agree. CTOs / Director of Engineering are probably the ones who make decisions. But it is developers who try the product first.</p><p>In the article you talk about messaging. I get it. But how practically you can reach out to decision makers?</p></blockquote><p>Let’s dissect this question here and get to the root of this question here, right now.</p><p>This is the "the user is not the buyer" problem.</p><p>Sure, it's a tough one, and I don't think there's a one-size-fits-all solution. </p><p><strong>Here’s the key… it depends on one thing:</strong><span> </span></p><p><span>→ Who actually has the power?</span><br><em>(and hint, it’s not always the person with the credit card)</em></p><p>Let me explain…</p><p>Your product is used and bought by smaller companies, they have CTOs/directors, but it's pretty flat, and they are in build mode. These are likely early stage or smaller companies still trying to figure out their market fit or value proposition.</p><p>The user (developer) might have the power. Here’s why…</p><p>The CTO's incentive is to reduce time to market/iterate. The faster they are to market and iterate, the faster they learn, the faster they find PMF, the more likely everyone keeps their jobs (and maybe they get a big payout win 3-10 years from now, or at least that's the promise from the CEO).</p><p><span>The user/dev has the power </span><strong>because of the time constraint</strong><span>. </span></p><p>They're likely to come to the organization with knowledge - it's why they were hired. So, their suggestion on what to bring to the table in terms of dev tooling will be massively important. </p><p>They might even setup a free account to use before anyone notices, "just to get things done". </p><p><span>Eventually they have to level up to a paid tier and voila, </span><strong>the company has just been trojan-horsed</strong><span>.</span></p><p>The CTO/directors/leadership are the ones who have the power because there’s different constraints other than time.  In this case, let’s just say security is the primary constraint. </p><p>No user/dev is going to be allowed to install software themselves. This comes from top-down. </p><p>Thus, the sales cycle is going to be long since you have to sell the value differently and there’s likely a vetting and due diligence type of process they have to go through to choose your product over another.</p><p>The users/devs don't have much of a choice because the primary value/risk isn't UI/UX/DX or whatever the user/dev cares about. It's security + outcome/output.</p><p><strong>Now here’s the thing…</strong><span> The person with the credit card is who we typically would call the "decision maker" (and in the original question, it was called the “ideal customer” even).</span></p><p><strong>But the reality is, they aren't always the one with the power. It depends on the constraints they're under.</strong></p><p>It's also not “who tries the product first”, as the original question states. </p><p>It's “who has the leverage”?</p><p>Who has the power, the constraints, and/or the incentive to push it through the most?</p><p><span>Subsequently, </span><strong>this is who values it the most.</strong></p><p>IMPORTANT POINT: I’m getting picky about defining “value” here. It needs to be actionable - something within the bounds of reality. Someone who says it’s worth N to them, but doesn’t have the means to actually trade N for it, doesn’t really matter at the end of the day. </p><p>Let’s get back to it…</p><p><strong>If your user/dev values it more than the holder of the budget, then you only have one thing to do….</strong></p><p>The CTO will never write the check for the value the user/dev deems it’s worth.  </p><p>That said, as a dev, I've paid for tools out of my own pocket that mean enough to me to do so if it's valuable enough. And in that case, the incentive and value isn't because the company will win... it's because I'm going to look great when I make the company win.</p><p><span>Different incentives. </span><br><span>Different payoffs.</span></p><p>But, with that in mind, let's get more specific... </p><div><p><span>I posed this question back to the OP: “What's the typical path for adoption (that works best for you!)?”</span></p><p><span>Perhaps for you, it goes something like this:</span></p></div><ol><li><p>User/dev registers</p></li><li><p>User/dev runs free trial on a local environment</p></li><li><p>User/dev gets a the value right before the do a pull request, so they can see the before and after scenarios (highlighting any issues)</p></li><li><p><span>User/dev sees value (Note: here’s </span><a href="https://writings.founderlabs.io/p/how-to-increase-mrr-activating-users?utm_source=publication-search" rel="">how to master the “aha moment”</a><span>). They see it will save them time with QA’ing their own changes, perhaps it could even be automated?</span></p></li><li><p>User/dev tries to convince leadership it's necessary to get it paid for</p></li><li><p>Leadership tests/sees process, checks budget, decides yes/no</p></li><li><p>Leadership gives approval for purchase</p></li><li><p>User/dev/leadership purchases</p></li><li><p>User/dev continues to use it and propagates among other user/devs in the co.</p></li></ol><p><span>In this case (change based on the assumption of the scenarios above, small vs big orgs, user flow, etc), </span><strong>here's some questions to figure out:</strong></p><p><strong>What's the real incentive behind why the dev suggests the tool?</strong><span>  Does the dev want it because it helps them be awesome / reduces the pain of doing their job, or because it'll help the company goals? </span></p><p><strong>What's the real incentive behind why the leadership buys it?</strong><span> Because they'll see it'll take less time for the dev to do their job, they'll be better at it, thus getting to the goals of the company? </span></p><p>If those things are true, I would do these 2 things….</p><ol><li><p>Give the user/dev the tools they need to convince their leadership that it's a slam dunk (for their incentives).  Translate the value from the user/dev’s terms into the leadership’s terms.  </p></li></ol><p>Note: It's best if this isn't explicitly declared to them like "here's how you convince your leadership this is a good idea" but more like "here's a report showing how much time you were going to spend doing it in the old way vs how much time you actually spent doing it this way". Also, make these actual, real numbers as much as possible or the dev won't use the report because they’ll know the numbers are inaccurate.</p><ol start="2"><li><p>I'd also do some customer interviews here with the devs to figure out how those conversations usually go with leadership.  What do they need to make that conversation go faster/easier? What stops them from buying?</p></li></ol><p><strong>Find the friction, smooth it out.</strong></p><p>The meta point here is that you're not going to talk to the credit card holder; the user/dev is going to do that for you. </p><p><span>Give them the best possible chance at convincing the leadership. Make them look awesome for even bothering the leadership with a choice like this. Make it obviously awesome for them to decide “yes”.  These users/devs are your sales people. Treat them as such in the sense that </span><strong>if they win</strong><span> (product does what the user hopes and dreams it will, getting them to the promised land), </span><strong>you win</strong><span> ($), and </span><strong>then they win again</strong><span> (look good, systemically removing friction in their job/process, etc). Not to mention, the leadership wins and the company wins.</span></p><p>Now go, and proselytize those devs. ;) </p><p><span>If you’re a founder who wants to get unstuck, reduce churn, get through that revenue plateau, generate more leads, and more…  </span><a href="https://fantastical.app/nateritter/nrp" rel="">Get in touch today</a></p><p data-attrs="{&quot;url&quot;:&quot;https://fantastical.app/nateritter/nrp&quot;,&quot;text&quot;:&quot;→ I want to get unstuck, let's talk&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://fantastical.app/nateritter/nrp" rel=""><span>→ I want to get unstuck, let's talk</span></a></p><p><span>🧢 Hat tip to </span><a href="https://ygerasimov.com/" rel="">Yuriy Gerasimov</a><span> from </span><a href="https://diffy.website/" rel="">Diffy (visual regression for Wordpress and Drupal)</a><span> for the being the muse this week! Thanks for letting me write about our chat, Yuriy!</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lithium compound can reverse Alzheimer’s in mice: study (134 pts)]]></title>
            <link>https://hms.harvard.edu/news/could-lithium-explain-treat-alzheimers-disease</link>
            <guid>44825326</guid>
            <pubDate>Thu, 07 Aug 2025 14:56:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hms.harvard.edu/news/could-lithium-explain-treat-alzheimers-disease">https://hms.harvard.edu/news/could-lithium-explain-treat-alzheimers-disease</a>, See on <a href="https://news.ycombinator.com/item?id=44825326">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Open AI Announces $1.5M Bonus for Every Employee (124 pts)]]></title>
            <link>https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590</link>
            <guid>44825309</guid>
            <pubDate>Thu, 07 Aug 2025 14:55:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590">https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590</a>, See on <a href="https://news.ycombinator.com/item?id=44825309">Hacker News</a></p>
Couldn't get https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Let's stop pretending that managers and executives care about productivity (129 pts)]]></title>
            <link>https://www.baldurbjarnason.com/2025/disingenuous-discourse/</link>
            <guid>44824981</guid>
            <pubDate>Thu, 07 Aug 2025 14:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.baldurbjarnason.com/2025/disingenuous-discourse/">https://www.baldurbjarnason.com/2025/disingenuous-discourse/</a>, See on <a href="https://news.ycombinator.com/item?id=44824981">Hacker News</a></p>
Couldn't get https://www.baldurbjarnason.com/2025/disingenuous-discourse/: AggregateError]]></description>
        </item>
        <item>
            <title><![CDATA[Windows XP Professional (314 pts)]]></title>
            <link>https://win32.run/</link>
            <guid>44824539</guid>
            <pubDate>Thu, 07 Aug 2025 13:58:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://win32.run/">https://win32.run/</a>, See on <a href="https://news.ycombinator.com/item?id=44824539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pos_loader">
			<!-- Bootup by Kyle Stephens -->
			<!-- https://codepen.io/kylestephens/pen/zYOgLrr -->
			<section id="bios">
				<p>PhoenixBIOS 1.4 Release 6.0</p>
				<p>Copyright 1985-2001 Phoenix Technologies Ltd.</p>
				<p>All Rights Reserved</p>
				<p>Copyright 2001-2003 VMware. Inc.</p>
				<p>VMware BIOS build 314</p>
				
				<p>ATAPI CD-ROM: VMware Virtual IDECDROM Drive</p>
				<p>Initializing <span>...</span></p>
			  
			  </section>
			  
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infinite Pixels (219 pts)]]></title>
            <link>https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/</link>
            <guid>44824056</guid>
            <pubDate>Thu, 07 Aug 2025 13:12:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/">https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/</a>, See on <a href="https://news.ycombinator.com/item?id=44824056">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I was on one of my rounds of social media trawling, just seeing what was floating through the aether, when I came across <a href="https://mastodon.art/@otterlove/114971594534242993">a toot by Andy P</a> that said:</p>
<blockquote>
<div><p>Fun #css trick:</p><p>

width: calc(infinity * 1px);<br>
height: calc(infinity * 1px);</p></div>
</blockquote>
<p>…and I immediately thought, <em>This is a perfect outer-limits probe!</em> By which I mean, if I hand a browser values that are effectively infinite by way of <a href="https://www.w3.org/TR/css-values-4/#calc-error-constants"> the<code>infinity</code> keyword</a>, it will necessarily end up clamping to something finite, thus revealing how far it’s able or willing to go for that property.</p>
<p>The first thing I did was exactly what Andy proposed, with a few extras to zero out box model extras:</p>
<pre><code>div {
	width: calc(infinity * 1px);&nbsp; 
	height: calc(infinity * 1px);
	margin: 0;
	padding: 0; }</code></pre>
<pre><code>&lt;body&gt;
&nbsp;  &lt;div&gt;I’m huge!&lt;/div&gt;
&lt;/body&gt;</code></pre>
<p>Then I loaded the (fully valid HTML 5) test page in Firefox Nightly, Chrome stable, and Safari stable, all on macOS, and things pretty immediately got weird:</p>
<table>
<caption>Element Size Results</caption>
<thead>
<tr>
<th>Browser</th>
<th>Computed value</th>
<th>Layout value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Safari</td>
<td>33,554,428</td>
<td>33,554,428</td>
</tr>
<tr>
<td>Chrome</td>
<td>33,554,400</td>
<td>33,554,400</td>
</tr>
<tr>
<td>Firefox (Nightly)</td>
<td>19.2 / 17,895,700</td>
<td>19.2 / 8,947,840 †</td>
</tr>
</tbody>
</table>
<p><em>† height / width</em></p>
<p>Chrome and Safari both get <em>very</em> close to 2<sup>25</sup>-1 (33,554,431), with Safari backing off from that by just 3 pixels, and Firefox by 31.&nbsp; I can’t even hazard a guess as to why this sort of value would be limited in that way; if there was a period of time where 24-bit values were in vogue, I must have missed it.&nbsp; I assume this is somehow rooted in the pre-Blink-fork codebase, but who knows. (Seriously, who knows?&nbsp; I want to talk to you.)</p>
<p>But the faint whiff of oddness there has <em>nothing</em> on what’s happening in Firefox.&nbsp; First off, the computed height is<code>19.2px</code>, which is the height of a line of text at default font size and line height.&nbsp; If I explicitly gave it<code> line-height: 1</code>, the height of the <code>&lt;div&gt;</code> changes to 16px.&nbsp; All this is despite my assigning a height of infinite pixels!&nbsp; Which, to be fair, is not really possible to do, but does it make sense to just drop it on the floor rather than clamp to an upper bound?</p>
<p>Even if that can somehow be said to make sense, it <em>only</em> happens with height.&nbsp; The computed width value is, as indicated, nearly 17.9 million, which is not the content width and is also nowhere close to any power of two.&nbsp; But the actual layout width, according to the diagram in the Layout tab, is just over 8.9 million pixels; or, put another way, one-half of 17,895,700 <em> minus 10</em>.</p>
<p>This frankly makes my brain hurt.&nbsp; I would truly love to understand the reasons for any of these oddities.&nbsp; If you know from whence they arise, please, please leave a comment!&nbsp; The more detail, the better.&nbsp; I also accept trackbacks from blog posts if you want to get extra-detailed.</p>
<p>For the sake of my aching skullmeats, I almost called a halt there, but I decided to see what happened with font sizes.</p>
<pre><code>div {
	width: calc(infinity * 1px);&nbsp; 
	height: calc(infinity * 1px);
	margin: 0;
	padding: 0;
	font-size: calc(infinity * 1px); }</code></pre>
<p>My skullmeats did not thank me for this, because once again, things got…&nbsp;interesting.</p>
<table>
<caption>Font Size Results</caption>
<thead>
<tr>
<th>Browser</th>
<th>Computed value</th>
<th>Layout value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Safari</td>
<td>100,000</td>
<td>100,000</td>
</tr>
<tr>
<td>Chrome</td>
<td>10,000</td>
<td>10,000</td>
</tr>
<tr>
<td>Firefox (Nightly)</td>
<td>3.40282e38</td>
<td>2,400 / 17,895,700 †</td>
</tr>
</tbody>
</table>
<p><em>† line height values of <code>normal</code> /<code>1</code></em></p>
<p>Safari and Chrome have pretty clearly set hard limits, with Safari’s an order of magnitude larger than Chrome’s.&nbsp; I get it: what are the odds of someone wanting their text to be any larger than, say, a viewport height, let alone ten or 100 times that height?&nbsp; What intrigues me is the nature of the limits, which are so clearly base-ten numbers that someone typed in at some point, rather than being limited by setting a register size or variable length or something that would have coughed up a power of two.</p>
<p>And speaking of powers of two… ah, Firefox.&nbsp; Your idiosyncrasy continues.&nbsp; The computed value is a 32-bit <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format">single-precision floating-point</a> number.&nbsp; It doesn’t get used in any of the actual rendering, but that’s what it is.&nbsp; Instead, the actual font size of the text, as judged by the Box Model diagram on the Layout tab, is…&nbsp;2,400 pixels.</p>
<p>Except, I can’t say that’s the <em>actual</em> actual font size being used: I suspect the actual value is 2,000 with a line height of 1.2, which is generally what <code> normal</code> line heights are in browsers. “So why didn’t you just set <code> line-height: 1</code> to verify that, genius?” I hear you asking.&nbsp; I did!&nbsp; And that’s when the layout height of the <code>&lt;div&gt;</code> bloomed to just over 8.9 million pixels, like it probably should have in the previous test!&nbsp; And all the same stuff happened when I moved the styles from the<code>&lt;div&gt;</code> to the <code>&lt;body&gt;</code>!</p>
<p>I’ve started writing at least three different hypotheses for why this happens, and stopped halfway through each because each hypothesis self-evidently fell apart as I was writing it.&nbsp; Maybe if I give my whimpering neurons a rest, I could come up with something.&nbsp; Maybe not.&nbsp; All I know is, I’d be much happier if someone just explained it to me; bonus points if their name is Clarissa.</p>
<p>Since setting line heights opened the door to madness in font sizing, I thought I’d try setting <code>line-height</code> to infinite pixels and see what came out.&nbsp; This time, things were (relatively speaking) more sane.</p>
<table>
<caption>Line Height Results</caption>
<thead>
<tr>
<th>Browser</th>
<th>Computed value</th>
<th>Layout value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Safari</td>
<td>33,554,428</td>
<td>33,554,428</td>
</tr>
<tr>
<td>Chrome</td>
<td>33,554,400</td>
<td>33,554,400</td>
</tr>
<tr>
<td>Firefox (Nightly)</td>
<td>17,895,700</td>
<td>8,947,840</td>
</tr>
</tbody>
</table>
<p>Essentially, the results were the same as what happened with element widths in the first example: Safari and Chrome were very close to 2<sup>25</sup>-1, and Firefox had its thing of a strange computed value and a rendering size not <em> quite</em> half the computed value.</p>
<p>I’m sure there’s a fair bit more to investigate about infinite-pixel values, or about infinite values in general, but I’m going to leave this here because my gray matter needs a rest and possibly a pressure washing.&nbsp; Still, if you have ideas for infinitely fun things to jam into browser engines and see what comes out, let me know.&nbsp; I’m already wondering what kind of shenanigans, other than in <code>z-index</code>, I can get up to with <code> calc(-infinity)</code>…</p> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An LLM does not need to understand MCP (102 pts)]]></title>
            <link>https://hackteam.io/blog/your-llm-does-not-care-about-mcp/</link>
            <guid>44823850</guid>
            <pubDate>Thu, 07 Aug 2025 12:52:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackteam.io/blog/your-llm-does-not-care-about-mcp/">https://hackteam.io/blog/your-llm-does-not-care-about-mcp/</a>, See on <a href="https://news.ycombinator.com/item?id=44823850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Model Context Protocol (MCP) has become the standard for tool calling when building agents, but contrary to popular belief, your LLM does not need to understand MCP. You might have heard about the term "context engineering"; where you, as the person interacting with an LLM, are responsible for providing the right context to help it answer your questions. To gather this context, you can use tool calling to give the LLM access to a set of tools it can use to fetch information or take actions.</p>
<p>MCP helps by standardizing how your agent connects to these tools. But to your LLM, there’s no difference between “regular” tool calling and using a standard like MCP. It only sees a list of tool definitions, it doesn’t know or care what’s happening behind the scenes. And that’s a good thing.</p>
<p>By using MCP you get access to thousands of tools, without writing custom integration logic for each one. It heavily simplifies setting up an agentic loop that involves tool calling, often with almost zero development time. You, the developer, are responsible for calling the tools. The LLM only generates a snippet of what tool(s) to call and with which input parameters.</p>
<p>In this blog post, I’ll break down how tool calling works, what MCP actually does, and how both relate to context engineering.</p>

<p>LLMs understand the concept of tool calling, sometimes also called tool use or function calling. You provide a list of tool definitions as part of your prompt. Each tool includes a name, description, and expected input parameters. Based on the question and available tools, the LLM may generate a call.</p>

<p>But here’s the important part: LLMs don’t know how to use tools. They don’t have native tool calling support. They just generate text that represents a function call.
</p><p><img src="https://hackteam.io/images/your-llm-does-not-care-about-mcp/tool-calling.png" alt="Input and output when interacting with a LLM"><span>Input and output when interacting with a LLM</span></p>
<p>In the diagram above, you can see what the LLM actually sees: a prompt made up of instructions, previous user messages, and a list of available tools. Based on that, the LLM generates a text response which might include a tool that your system should call. It doesn’t understand tools in a meaningful way, it’s just making a prediction.</p>
<p>Let's look at a more practical use case. For example, if you provide a tool called <code>get_weather</code> that takes a <code>location</code> as input, and then ask the model: "What’s the weather in San Jose, CA?" it might respond with:</p>
<pre><div><p><code>{
  "name": "get_weather",
  "input": {
    "location": "San Jose, CA"
  }
}</code></p></div></pre>
<p>The LLM is able to generate that snippet based on the context it was provided with, as you can see in the diagram below. The LLM doesn’t know how to call the <code>get_weather</code> tool, nor does it need to. Your agentic loop, or agentic application, is responsible for taking this output and making the actual API call or function invocation. It parses the generated tool name and inputs, runs the tool, and passes the result back to the LLM as a new message.</p>
<p><img src="https://hackteam.io/images/your-llm-does-not-care-about-mcp/tool-calling-flow.png" alt="Tool Calling flow interaction with a LLM"><span>Tool Calling flow interaction with a LLM</span></p>
<p>This separation of concerns is important. The LLM just generates predictions and your system handles the execution. And that brings us to where MCP fits in.</p>

<p>Model Context Protocol, or MCP, is a way to <a target="_blank" rel="noopener noreferrer" href="https://www.infoworld.com/article/4029634/what-is-model-context-protocol-how-mcp-bridges-ai-and-external-services.html">standardize how your agent connects</a> to data sources like tools, prompts, resources, and samples. Right now, MCP is best known for simplifying the tools side of that equation. Instead of manually writing code for each tool in a custom format, MCP defines a consistent schema and communication pattern. Think of it as a universal adapter (like USB-C) for tooling.</p>

<p>MCP usually involves three components: a host application, an MCP client, and one or more MCP servers. The host might be a chat app or IDE (like Cursor) that includes an MCP client capable of connecting to different servers. These servers expose tools, prompts, samples, or resources.</p>
<p>The way you interact with the LLM doesn’t change. What changes is how the tools are surfaced to it. The agentic application talks to the MCP client, which talks to the right server. Tools are described in a format the LLM can use.</p>
<p><img src="https://hackteam.io/images/your-llm-does-not-care-about-mcp/tool-calling-flow-mcp.png" alt="Tool Calling flow interaction with a LLM and MCP"><span>Tool Calling flow interaction with a LLM and MCP</span></p>
<p>For the same question, "What’s the weather in San Jose, CA?", the LLM will still get the same list of tools. And based on that list it will tell you what tool to call, how that tool is called is up to the developer. When using MCP, that tool will be called using MCP.</p>
<p>The benefit here isn’t for the LLM, it’s for you as the developer. MCP helps manage complexity of working with many different tools as your agent grows. It makes it easier to reuse tools across projects, enforce consistent formats, and plug into new systems without rewriting everything.</p>
<p>But the LLM will never know you are using MCP, unless you are letting it know in the system prompt of tool definitions. You, the developer, is responsible for calling the tools. The LLM only generates a snippet of what tool(s) to call with which input parameters.</p>
<p>Next, let’s look at how this fits into the bigger picture of context engineering, and why abstraction layers like MCP make things easier for humans, not models.</p>

<p>Context engineering is about giving your LLM the right inputs so it can generate useful outputs. That sounds simple, but it’s actually one of the most important parts of building effective AI systems.</p>
<p>When you ask a model a question, you’re really giving it a prompt -- a block of text it uses to predict the next block of text. The quality of that prompt directly affects the quality of the response.</p>
<p>This is where tools come in. Sometimes the model doesn’t have enough context to answer a question well. Maybe it needs real-time data, access to user profiles, or the ability to take action on behalf of the user. Tool calling lets you solve that by giving the model access to external systems, as you learned in this blog post.</p>
<p>But again, the model doesn’t need to know how those tools work. It just needs to know that they exist, what they’re for, and how to call them. That’s where context engineering meets tool design, you’re crafting a set of tool definitions that serve as part of the model’s prompt.</p>
<p><img src="https://hackteam.io/images/your-llm-does-not-care-about-mcp/overview.png" alt="Tool Calling as seen by a LLM"><span>Tool Calling as seen by a LLM</span></p>
<p>MCP makes that process cleaner and more repeatable. Instead of hardcoding tools or writing ad hoc wrappers, you define a structured interface once and expose it through MCP. The LLM still sees the same types of tool definitions, but now they’re easier to maintain and scale.</p>
<p>So in the end, MCP is a tool for us developers, not for the LLM. It helps us build more reliable, modular systems. And it helps us focus on context engineering without reinventing the plumbing every time.</p>

<ul depth="0">
<li><a target="_blank" rel="noopener noreferrer" href="https://hackteam.io/blog/build-your-first-mcp-server-with-typescript-in-under-10-minutes">Learn how to build a MCP Server in &lt;10 minutes</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://hackteam.io/blog/build-test-mcp-server-typescript-mcp-inspector">Test MCP Servers using MCP Inspector</a></li>
</ul>
<p>If you found this tutorial helpful, don’t forget to share it with your network. For more content on AI and web development, subscribe to my <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/@gethackteam?sub_confirmation=1">YouTube channel</a> and connect with me on <a target="_blank" rel="noopener noreferrer" href="https://linkedin.com/in/gethackteam">LinkedIn</a>, <a target="_blank" rel="noopener noreferrer" href="https://x.com/gethackteam">X</a> or <a target="_blank" rel="noopener noreferrer" href="https://bsky.app/profile/gethackteam.bsky.social">Bluesky</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Ethics is being narrowed on purpose, like privacy was (167 pts)]]></title>
            <link>https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose</link>
            <guid>44823094</guid>
            <pubDate>Thu, 07 Aug 2025 11:20:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose">https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose</a>, See on <a href="https://news.ycombinator.com/item?id=44823094">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!DANS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!DANS!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!DANS!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!DANS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/400a5908-8000-4717-8537-bd326bb46886_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2158689,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://nimishg.substack.com/i/170332859?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!DANS!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!DANS!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><br><span>A few days ago, OpenAI released an open-source language model for the first time in a very long time.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-1-170332859" target="_self" rel="nofollow ugc noopener">1</a></span><span>  It had been promised for a while, but the deadline kept being pushed for “safety” concerns.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-2-170332859" target="_self" rel="nofollow ugc noopener">2</a></span></p><p><span>In fact, they’ve put quite a bit of time and effort into discussing safety</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-3-170332859" target="_self" rel="nofollow ugc noopener">3</a></span><span>, because, ostensibly, safety and ethics is at the top of people’s minds. </span></p><p>So, the public is worried about AI ethics, and OpenAI is putting efforts into making sure the AI is ethical. Sounds like a match. </p><p><span>Not just a match, but a great talking point. When the press or someone issues a question or challenge around ethics, they can point to the work they’re doing </span><strong>around that very subject</strong><span>, and superficially the questioner is shut down.</span></p><p><span>Except that’s not what people actually mean when they say “ethics”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-4-170332859" target="_self" rel="nofollow ugc noopener">4</a></span><span>.  People are far more concerned with the </span><em>real-world </em><span>implications of ethics: governance structures, accountability, how their data is used, jobs being lost, etc.  In other words, they’re not so worried about whether their models will swear or philosophically handle the </span><a href="https://en.wikipedia.org/wiki/Trolley_problem" rel="nofollow ugc noopener">trolley problem</a><span> so much as, you know, reality. What happens with the </span><em>humans</em><span> running the models? </span><em>Their</em><span> influx of power and resources? How will </span><em>they</em><span> hurt or harm society? </span></p><p>This isn’t the first time this “redefining a legitimate concern” tactic has been used in tech. Way back, in the one thousand nine hundred and 90s, telemarketer calls were even more ubiquitous than they are now, and puzzled recipients would often ask “how did you even get my number?”</p><p><span>The answer was that telemarketing companies would just buy customer lists from other companies, who naively didn’t understand the true value of what they had</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-5-170332859" target="_self" rel="nofollow ugc noopener">5</a></span><span>. It was a sketchy practice and there was a huge consumer backlash against it, leading to </span><strong>the</strong><span> privacy cop-out phrase: “we never share your data with third parties”.</span></p><p><span>The full statement should be “we never share your data with third parties because that would be dumb. If they want that data, they have to buy out the company. In fact, that’s a large part of our exit strategy and valuation”. Business-wise, this has become common knowledge, so the statement about third-parties is almost redundant.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-6-170332859" target="_self" rel="nofollow ugc noopener">6</a></span></p><p><span>When people express concerns about privacy nowadays, the concern is what </span><em>the company they’re interacting with right now</em><span> is doing with the data. There’s an app I’m required to have for my kids’ school. What kind of profile and behavior model are they building about me? Why? What about the one I’m required to have to buy parking? Or the one I’m required to have to ride the train?</span></p><p><span>Those concerns aren’t really discussed. Instead, privacy is redefined as “making sure people </span><em>who aren’t this company</em><span> won’t have access to your data”, and never “what exactly is </span><em>this</em><span> company going to do with my data?”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-7-170332859" target="_self" rel="nofollow ugc noopener">7</a></span></p><p>This narrow redefinition has become the accepted professional definition of the term. We have entire industries around procurement, compliance, testing and others to make sure the above standards of “privacy” are upheld. Don’t get me wrong — it’s definitely important to secure your data and to prevent data leaks and testing the security infrastructure and all that. If anything, in a ‘vibe code’ era of start-ups, it’s even more important to make sure baseline security practices are followed.</p><p>But, when it comes to addressing public concerns about privacy, it’s (deliberately) spending time, resources, and energy on a particular scope, and pretending this effort is your way of addressing a different scope.</p><p>It’s like when a politician is asked “Will you raise taxes?” and then answers with “I want to grow the economy”… it’s not actually addressing the question being asked. Only now, with privacy, there are whole ecosystems of process and tools that are dedicated to answering the wrong question, specifically so they don’t have to answer the right one.</p><p>AI is different in that it’s new and (for many) came out of nowhere when it comes to culture and ethics discussions around it.</p><p><span>In fact, the only thing we had to fall back on were sci-fi thought experiments (which we have </span><a href="https://en.wikipedia.org/wiki/Roko%27s_basilisk" rel="nofollow ugc noopener">plenty</a><span> </span><a href="https://en.wikipedia.org/wiki/Gray_goo" rel="nofollow ugc noopener">of</a><span>). They’re interesting, fun, profound, and from a business perspective, totally safe. I mean, no one wants an AI to trap them in some sort of </span><em>Black Mirror</em><span> simulation, or turn the world into paperclips or anything like that. If it earns you good PR, there’s no reason </span><em>not</em><span> to spend time on such issues. It’s also free publicity since the press eats that stuff up.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-8-170332859" target="_self" rel="nofollow ugc noopener">8</a></span></p><p>But, realistically, is that the actual danger? </p><p><span>One final AI thought experiment is the </span><a href="https://en.wikipedia.org/wiki/AI_alignment#Alignment_problem" rel="nofollow ugc noopener">alignment problem</a><span>. Basically, if we give an AI lots of resources and ask it to do something, how do we know it will do what we want it to, and not try to subvert us and… take over the world? How do we know it will stay on humanity’s side?</span></p><p><span>This is something that some companies have </span><a href="https://openai.com/index/our-approach-to-alignment-research/" rel="nofollow ugc noopener">whole</a><span> </span><a href="https://alignment.anthropic.com/" rel="nofollow ugc noopener">teams</a><span> dedicated to working on and see as a fundamental challenge of the AI age. I absolutely agree, but I don’t think they’re using the right premise or assumptions.</span></p><div><p><span>If we give </span><em>companies</em><span> unending hype, near unlimited government and scientific resources, all of our personal data including thoughts and behavior patterns, how do we know </span><em>their leaders</em><span> will do what we want them to, and not try to subvert us and… take over the world? How do we know </span><em>they</em><span> stay on humanity’s side?</span></p><p><span>See, AI ethics is quite important. But like everything else in AI, we have to be sure we understand the actual problems so we can set up the solutions right.</span></p></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Whispering Earring (103 pts)]]></title>
            <link>https://croissanthology.com/earring</link>
            <guid>44822684</guid>
            <pubDate>Thu, 07 Aug 2025 10:16:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://croissanthology.com/earring">https://croissanthology.com/earring</a>, See on <a href="https://news.ycombinator.com/item?id=44822684">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>


        
        <article>
    
    <div>
        <p>Cleaner, easier-to-reference repo of Scott Alexander’s <em>The Whispering Earring</em> (that’s the Schelling title, real title below). Original from livejournal is backed up <a href="https://gwern.net/doc/fiction/science-fiction/2012-10-03-yvain-thewhisperingearring.html">here</a>.</p>

<h2 id="clarity-didnt-work-trying-mysterianism">Clarity didn’t work, trying mysterianism</h2>

<p>In the treasure-vaults of Til Iosophrang rests the Whispering Earring, buried deep beneath a heap of gold where it can do no further harm.</p>

<p>The earring is a little topaz tetrahedron dangling from a thin gold wire. When worn, it whispers in the wearer’s ear: “Better for you if you take me off.” If the wearer ignores the advice, it never again repeats that particular suggestion.</p>

<p>After that, when the wearer is making a decision the earring whispers its advice, always of the form “Better for you if you…”. <em>The earring is always right</em>. It does not always give the best advice possible in a situation. It will not necessarily make its wearer King, or help her solve the miseries of the world. But its advice is always better than what the wearer would have come up with on her own.</p>

<p>It is not a taskmaster, telling you what to do in order to achieve some foreign goal. It always tells you what will make you happiest. If it would make you happiest to succeed at your work, it will tell you how best to complete it. If it would make you happiest to do a half-assed job at your work and then go home and spend the rest of the day in bed having vague sexual fantasies, the earring will tell you to do that. <em>The earring is never wrong.</em></p>

<p>The <em>Book of Dark Waves</em> gives the histories of two hundred seventy four people who previously wore the Whispering Earring. There are no recorded cases of a wearer regretting following the earring’s advice, and there are no recorded cases of a wearer not regretting disobeying the earring. <em>The earring is always right</em>.</p>

<p>The earring begins by only offering advice on major life decisions. However, as it gets to know a wearer, it becomes more gregarious, and will offer advice on everything from what time to go to sleep, to what to eat for breakfast. If you take its advice, you will find that breakfast food really hit the spot, that it was exactly what you wanted for breakfast that day even though you didn’t know it yourself. <em>The earring is never wrong</em>.</p>

<p>As it gets completely comfortable with its wearer, it begins speaking in its native language, a series of high-bandwidth hisses and clicks that correspond to individual muscle movements. At first this speech is alien and disconcerting, but by the magic of the earring it begins to make more and more sense. No longer are the earring’s commands momentous on the level of “Become a soldier”. No more are they even simple on the level of “Have bread for breakfast”. Now they are more like “Contract your biceps muscle about thirty-five percent of the way” or “Articulate the letter p”. <em>The earring is always right</em>. This muscle movement will no doubt be part of a supernaturally effective plan toward achieving whatever your goals at that moment may be.</p>

<p>Soon, reinforcement and habit-formation have done their trick. The connection between the hisses and clicks of the earring and the movements of the muscles have become instinctual, no more conscious than the reflex of jumping when someone hidden gives a loud shout behind you.</p>

<p>At this point no further change occurs in the behavior of the earring. The wearer lives an abnormally successful life, usually ending out as a rich and much-beloved pillar of the community with a large and happy family.</p>

<p>When Kadmi Rachumion came to Til Iosophrang, he took an unusual interest in the case of the earring. First, he confirmed from the records and the testimony of all living wearers that the earring’s first suggestion was always that the earring itself be removed. Second, he spent some time questioning the Priests of Beauty, who eventually admitted that when the corpses of the wearers were being prepared for burial, it was noted that their brains were curiously deformed: the neocortexes had wasted away, and the bulk of their mass was an abnormally hypertrophied mid- and lower-brain, especially the parts associated with reflexive action.</p>

<p>Finally, Kadmi-nomai asked the High Priest of Joy in Til Iosophrang for the earring, which he was given. After cutting a hole in his own earlobe with the tip of the Piercing Star, he donned the earring and conversed with it for two hours, asking various questions in Kalas, in Kadhamic, and in its own language. Finally he removed the artifact and recommended that the it be locked in the deepest and most inaccessible parts of the treasure vaults, a suggestion with which the Iosophrelin decided to comply.</p>

<p><strong>Niderion-nomai’s commentary</strong>: It is well that we are so foolish, or what little freedom we have would be wasted on us. It is for this that <em>Book of Cold Rain</em> says one must never take the shortest path between two points.</p>

    </div>
</article>


    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How AI Conquered the US Economy: A Visual FAQ (152 pts)]]></title>
            <link>https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a</link>
            <guid>44822665</guid>
            <pubDate>Thu, 07 Aug 2025 10:12:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a">https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a</a>, See on <a href="https://news.ycombinator.com/item?id=44822665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>The American economy has split in two. There’s a rip-roaring AI economy. And there’s a lackluster consumer economy.</p><p><span>You see it in the economic statistics. Last quarter, spending on artificial intelligence outpaced the growth in consumer spending. Without AI, US economic growth </span><a href="https://www.wsj.com/economy/the-ai-booms-hidden-risk-to-the-economy-731b00d6?mod=author_content_page_1_pos_1" rel="">would be meager.</a></p><p><span>You see it in stocks. In the last two years, </span><a href="https://privatebank.jpmorgan.com/content/dam/jpm-pb-aem/global/en/documents/eotm/summer-mailbag.pdf" rel="">about 60 percent</a><span> of the stock market’s growth has come from AI-related companies, such as Microsoft, Nvidia, and Meta. Without the AI boom, stock market returns would be putrid.</span></p><p><span>You see it in the business data. According to </span><a href="https://stripe.com/guides/indexing-the-ai-economy" rel="">Stripe</a><span>, firms that self-describe as “AI companies” are dominating revenue growth on the platform, and they’re far surpassing the growth rate of any other group.</span></p><p>Nobody can say for sure whether the AI boom is evidence of the next Industrial Revolution or the next big bubble. All we know is that it’s happening. We can all stop talking about “what will happen if AI dominates the economy at such-and-such future date?” No, the AI economy is here and now. We’re living in it, for better or worse.</p><p><span>So, what exactly </span><em>is</em><span> the artificial intelligence boom? How did it happen, where did all this money to build AI come from, who is using the technology, and is it making people more productive? Today, in a bit of a throwback to my early blogging years, I’m going to try to walk through an FAQ with graphs to create a visual guide to the question: </span></p><p>Artificial intelligence has a few simple ingredients: computer chips, racks of servers in data centers, huge amounts of electricity, and networking and cooling systems that keep everything running without overheating.</p><p><span>This hardware is immensely expensive. In the last six months, the four companies investing the most in artificial intelligence—Meta, Google, Microsoft, and Amazon—spent between $100 billion and $200 billion on chips, data centers, and the like. “The most valuable tech companies are buying and building stuff at a record pace,” </span><a href="https://www.wsj.com/tech/ai/silicon-valley-ai-infrastructure-capex-cffe0431" rel="">wrote</a><span> the Wall Street Journal’s Christopher Mims.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Nkpa!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Nkpa!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 424w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 848w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1272w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png" width="1155" height="887" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:887,&quot;width&quot;:1155,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:306661,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Nkpa!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 424w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 848w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1272w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>WSJ</figcaption></figure></div><p>This is either the biggest tech-infrastructure project since the 1960s (since the beginning of the computer age) or the 1880s (the heyday of the railroad age).</p><p><span>In January, JP Morgan’s Michael Cembalest </span><a href="https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/the-alchemists.pdf" rel="">calculated</a><span> that the leading AI chip manufacturer Nvidia is on pace to capture the highest share of market-wide capital spending since IBM’s peak revenues in 1969. Not to be outdone, the economic writer Paul Kedrosky </span><a href="https://paulkedrosky.com/honey-ai-capex-ate-the-economy/" rel="">has calculated</a><span> that AI capital expenditures as a share of GDP have already exceeded the dot-com boom and are now approaching levels not seen since the railroad build-out of the Gilded Age. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!wqm2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wqm2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 424w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 848w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1272w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!wqm2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png" width="1080" height="694" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:694,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:99436,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!wqm2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 424w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 848w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1272w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>JPM</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2pDW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2pDW!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 424w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 848w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1272w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2pDW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png" width="1322" height="834" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:834,&quot;width&quot;:1322,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:164779,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2pDW!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 424w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 848w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1272w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Today’s AI infrastructure boom is made possible by the extraordinary and unprecedented profits of today’s leading tech companies. As Cembalest </span><a href="https://www.theringer.com/podcasts/plain-english-with-derek-thompson/2025/01/07/the-big-2025-economy-forecast-ai-and-big-tech-nuclears-renaissance-trump-vs-china-and-whats-eating-europe" rel="">explained</a><span> on my podcast, today's leading tech companies have become so profitable in the last few years that their share of total “free cash flow” (meaning, revenue minus operating expenses and infrastructure) dwarfs anything we’ve seen since the end of World War II. These firms’ existing business models—whether it’s ads for Meta or search ads for Google—are strong enough to generate stupid amounts of money to throw at the next generation of technology. “They’re generating unprecedented amounts of free cash flow,” Cembalest told me. “They make oodles and oodles of money, which is why they can afford to be pouring hundreds of billions of dollars of capital spending each year into AI-related R&amp;D and infrastructure.”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Zx6X!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Zx6X!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 424w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 848w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1272w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png" width="1270" height="827" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:827,&quot;width&quot;:1270,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:106735,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Zx6X!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 424w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 848w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1272w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>JPM</figcaption></figure></div><p>I think so. There’s an interesting debate in finance circles now about why the stock market seems to be shrugging off the Trump tariffs and slowing growth. I think the clearest answer to this question is some combination of (a) some investors still think Trump will chicken out on the tariffs; (b) they don’t think the final effect of the tariffs will be very big; and (c) the tariffs don’t matter much to the digital economy, and AI-related stocks are dominating returns while the rest of the market collectively putters along.</p><p><span>As this chart from Societe Generale </span><a href="https://insight-public.sgmarkets.com/quant-motion-pictures/outside-of-the-top-10-stocks-sp500-forward-profits-haven-t-grown-in-three-years?utm_source=chatgpt.com" rel="">shows</a><span>, the ten largest companies in the S&amp;P 500 have so dominated net income growth in the last six years that it’s becoming more useful to think about an S&amp;P 10 vs an S&amp;P 490. If you’re a portfolio manager invested in the other 490 stocks, the last six years of equity returns aren’t very impressive because these companies have collectively not managed to increase their profits.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!y2id!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!y2id!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 424w, https://substackcdn.com/image/fetch/$s_!y2id!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 848w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1272w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!y2id!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png" width="1058" height="624" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:624,&quot;width&quot;:1058,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:270757,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!y2id!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 424w, https://substackcdn.com/image/fetch/$s_!y2id!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 848w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1272w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Societe Generale</figcaption></figure></div><p><span>Not yet. As the </span><em>Wall Street Journal</em><span>'s Greg Ip </span><a href="https://www.wsj.com/economy/the-ai-booms-hidden-risk-to-the-economy-731b00d6?mod=author_content_page_1_pos_1" rel="">wrote</a><span>, the "unsettling” side of the AI boom is that all this spending on chips and data centers is "draining American corporations of cash." OpenAI and Anthropic are losing gobs of money, and the biggest tech companies are still relying on their older business models to generate their largest profit margins. If these firms are spending much more than they’ll ever be able to earn back, it would suggest that we’re in the midst of a historic infrastructure bubble.</span></p><p><span>As for the bull case: The payments company Stripe is already seeing evidence that AI startup revenue is exceeding the growth rate of </span><em>any</em><span> previous generation of technology.</span><strong> “</strong><span>AI companies are reaching revenue milestones faster than previous generations of startups,” the company </span><a href="https://stripe.com/blog/inside-the-growth-of-the-top-ai-companies-on-stripe" rel="">announced</a><span> in a recent report. “The top 100 AI companies on Stripe achieved annualized revenues of $1 million in a median period of just 11.5 months—four months ahead of the fastest-growing SaaS companies.”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Bqd0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Bqd0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 424w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 848w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1272w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png" width="1456" height="679" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:679,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:283989,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Bqd0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 424w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 848w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1272w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Stripe</figcaption></figure></div><p><span>By one account, generative AI tools like ChatGPT and Gemini are being adopted faster than practically any technology for which we have good data. The St. Louis Federal Reserve </span><a href="https://www.stlouisfed.org/on-the-economy/2024/sep/rapid-adoption-generative-ai" rel="">has estimated</a><span> that the rate of adoption for generative AI is roughly twice as fast as the Internet.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!k_ds!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!k_ds!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 424w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 848w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1272w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!k_ds!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png" width="1456" height="1156" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1156,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:258824,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!k_ds!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 424w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 848w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1272w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>In one the largest recent surveys of generative AI—the 2025 paper </span><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5136877" rel="">"The Labor Market Effects of Generative Artificial Intelligence</a><span>”—economists estimated that more than 50 percent of workers in information services (meaning, software firms) and management are already using the technology at work. That compares with very few people in old-economy firms, such as mining or fishing. AI is also much more popular among college graduates than people who never attended college.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!F9t1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!F9t1!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 424w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 848w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1272w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!F9t1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png" width="1456" height="1002" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1002,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:305371,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!F9t1!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 424w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 848w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1272w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Hartley, et al</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ySxl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ySxl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 424w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 848w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1272w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ySxl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png" width="1456" height="968" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:968,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:193624,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ySxl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 424w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 848w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1272w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Hartley, et al</figcaption></figure></div><p><span>Yes. The iconic study proving that new AI models improve productivity comes from firms with rather repetitive work, such as </span><a href="https://hai.stanford.edu/news/will-generative-ai-make-you-more-productive-work-yes-only-if-youre-not-already-great-your-job" rel="">call centers</a><span>. But we’re getting more self-reports from workers saying that AI is helping them save lots of time. One surprising example: teaching. According to a recent </span><a href="https://news.gallup.com/poll/691967/three-teachers-weekly-saving-six-weeks-year.aspx" rel="">Gallup survey</a><span>, roughly 60 percent of elementary school teachers say they’ve used AI to prepare lessons, review instruction material, make worksheets, or do administrative work. Most teachers who use AI say it improves their work, and those who use it regularly say it saves them 6 hours a week—or six weeks per school year. In one very optimistic interpretation, that’s like saying AI gives elementary school teachers a month and a half of paid leave every year.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!UOEU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!UOEU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 424w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 848w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1272w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!UOEU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png" width="1349" height="1196" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1196,&quot;width&quot;:1349,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:284978,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!UOEU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 424w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 848w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1272w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Gallup</figcaption></figure></div><p>Perhaps the most bullish indicator that AI is going to help people become more productive at work comes from the AI research nonprofit METR, which found that the length of tasks that AI agents can complete is doubling every 7 months. In 2021, AI could automate a simple Google search: 10 seconds. Two years later, ChatGPT was looking up facts on the Internet that would take the typical person about 4 minutes. Now some models are performing coding tasks that take a typical developer 50 minutes. “Extrapolating this trend predicts that, in under a decade, we will see AI agents that can independently complete a large fraction of software tasks that currently take humans days or weeks,” the researchers said.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!E3fb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!E3fb!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 424w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 848w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1272w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!E3fb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png" width="1395" height="973" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:973,&quot;width&quot;:1395,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:318042,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!E3fb!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 424w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 848w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1272w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Not so fast. In fact, many workers might dramatically </span><em>overestimate</em><span> how much more productive AI is making them.</span></p><p><span>METR also </span><a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/" rel="">conducted</a><span> an in-depth study that asked experienced developers to code with a popular AI assistant. After they finished their tasks, the developers claimed that using the AI had made them 20 percent more productive. But independent evaluators in the study actually concluded that using AI did the opposite: it </span><em>increased</em><span> task completion time by about 20 percent. I don’t want to speculate too much about what this study means in the long run. But for now, I think it’s a necessary caveat to boosterish claims that ChatGPT is on the cusp of replacing tens of millions of entry-level white-collar jobs.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!aH-u!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!aH-u!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 424w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 848w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1272w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!aH-u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png" width="1456" height="881" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:881,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:243646,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!aH-u!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 424w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 848w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1272w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>A new paper in </span><em>Science</em><span> </span><a href="https://www.science.org/doi/10.1126/sciadv.adt3813?utm_campaign=ScienceMagazine&amp;utm_source=twitter&amp;utm_medium=ownedSocial" rel="">found</a><span> that since the rise of large language models, there's been a huge shift in academic writing. In 2024, the word "delves" has appeared 2,700% more than its historical average, by one account. The analysis suggests that about 1/7th of 2024 abstracts were processed by AI.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!UDeX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!UDeX!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 424w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 848w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1272w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!UDeX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png" width="1456" height="1243" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1243,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1132159,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!UDeX!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 424w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 848w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1272w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Kobak, et al</figcaption></figure></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["I closed MPEG on 2 Jun '20 when I left because obscure forces had hijacked it." (201 pts)]]></title>
            <link>https://leonardo.chiariglione.org/</link>
            <guid>44822637</guid>
            <pubDate>Thu, 07 Aug 2025 10:09:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://leonardo.chiariglione.org/">https://leonardo.chiariglione.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44822637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="5c35ece" data-element_type="section" data-widget_type="text-editor.default">
									<p><span>I needed an organisation that would</span><em>&nbsp;create digital media standards for <span>consumers</span>&nbsp;to seamlessly communicate and&nbsp;<span>industry</span>&nbsp;operate in a global market of interoperable products, services and applications</em><span>.&nbsp;</span><span>I conceived&nbsp;</span><span>t</span><span>hat organisation&nbsp;</span><span>in 1987, established it in 1988</span><span>I, and called </span><span>&nbsp;</span><a href="http://mpeg.chiariglione.org/">Moving Picture Experts Group</a><span>&nbsp;(MPEG). In four years,&nbsp;</span><span>MPEG had&nbsp;</span><span>ushered in the&nbsp;</span><span><i>digital media age </i><span>with&nbsp;</span></span><span>MPEG-1,&nbsp;</span><span>a standard for interactive media&nbsp;</span><span>used in Video CD, digital audio broadcasting (MP2), and personal music (MP3). Starting from the mid ’90s, MPEG-2, the result of the second MPEG project, became the common infrastructure that underpinned distribution of digital television via cable, satellite, terrestrial networks and package media (DVD). MPEG-4, the third standard first released in 1988, opened the way to digital media distribution over the internet. Several families of standards followed: MPEG-7, MPEG-21, </span><span>MPEG-A, MPEG-H, MPEG-I and more.</span></p><p><span>I chaired the group </span><span>fostering its productivity with the development of over 200 standards, membership with a 20-fold growth in attendance </span><span>from the initial 29 experts attending the first meeting, and scope extending from media to genomics, the “born digital” data of the world..&nbsp;</span></p><p><span>I closed MPEG on 2 June 2020 when I left because&nbsp;</span><span>obscure forces</span><span>&nbsp;had hijacked it.&nbsp;</span></p><p>Even before it has ceased to exists, the MPEG engine had run out of steam – technology- and business wise. The same obscure forces that have hijacked MPEG had kept it hostage to their interests impeding its technical development and keeping it locked to outmoded Intellectual Property licensing models delaying market adoption of MPEG standards. Industry has been strangled&nbsp;<span>and consumers have been deprived of the benefits of new technologies. From&nbsp;</span><span>facilitators&nbsp;</span><span>of new opportunities and experiences, MPEG s</span><span>tandards have morphed from </span><span>&nbsp;into </span><span>roadblocks.</span></p><p>On the 19th of July 2020 I proposed and, on 30 September 2020, a group of 33 companies established the&nbsp;<a href="http://mpai.community/" target="_blank" rel="nofollow noopener noreferrer">Moving Picture, Audio and Data Coding by Artificial Intelligence</a>&nbsp;(MPAI). Industry and consumers have now an organisation developing standards based on powerful technologies, overcoming stagnation and licensing stalemates. Five standards covering <a href="https://mpai.community/standards/mpai-aif/">execution of AI applications</a>, <a href="https://mpai.community/standards/mpai-cae/">audio enhancement</a>, <a href="https://mpai.community/standards/mpai-mmc/">multimodal conversation</a>, <a href="https://mpai.community/standards/mpai-cui/">company performance prediction</a>, and <a href="https://mpai.community/standards/mpai-gme/">ecosystem governance</a> have been developed and adopted. More standards are in the pipeline: <a href="https://mpai.community/standards/mpai-eev/">AI-based End-to-End Video Coding</a>, <a href="https://mpai.community/standards/mpai-evc/">AI-Enhanced Video Coding</a>, <a href="https://mpai.community/standards/mpai-aih/">AI Health</a>, <a href="https://mpai.community/standards/mpai-ara/">Avatar Representation and Animation</a>, <a href="https://mpai.community/standards/mpai-cav/">Connected Autonomous Vehicles</a>, <a href="https://mpai.community/standards/mpai-mmm/">Metaverse Model</a>,&nbsp; <a href="https://mpai.community/standards/mpai-spg/">Server-based Predictive Multiplayer Gaming</a>, and <a href="https://mpai.community/standards/mpai-xrv/">XR Venues</a>.</p><p>The book <a href="https://leonardo.chiariglione.org/publications/even-the-stars-die/"><em>Even the stars die</em></a> tell the MPEG story from birth to death and the MPAI story from birth to growth to death. The book <a href="https://mpai.community/the-mpai-book-2021/"><em>Towards Pervasive and Trustworthy Artificial Intelligence</em></a> tells the MPAI story in its first 15 months of life: 5 standards produced and 7 projects under way1998.</p>								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New AI Coding Teammate: Gemini CLI GitHub Actions (220 pts)]]></title>
            <link>https://blog.google/technology/developers/introducing-gemini-cli-github-actions/</link>
            <guid>44822389</guid>
            <pubDate>Thu, 07 Aug 2025 09:28:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/">https://blog.google/technology/developers/introducing-gemini-cli-github-actions/</a>, See on <a href="https://news.ycombinator.com/item?id=44822389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            

    
    

    <article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Meet your new AI coding teammate: Gemini CLI GitHub Actions&quot;
  }">
  
  <div>
      
      
        <p>
          Gemini CLI GitHub Actions is a no-cost, powerful AI coding teammate for your repository. It acts both as an autonomous agent for critical routine coding tasks, and an on-demand collaborator you can quickly delegate work to.
        </p>
      
    </div>
  
  <div>
  <p>Ryan J. Salva</p>
  
    <p>
      Senior Director, Product Management
    </p>
  
  
</div>
</div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="Gemini CLI GitHub Actions implements a feature at a user's request" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="Meet your new AI coding teammate: Gemini CLI GitHub Actions" listen-to-article="Listen to article" data-date-modified="2025-08-06T01:00:00.396657+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js" data-highlight-mode="word-over-paragraph"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Meet your new AI coding teammate: Gemini CLI GitHub Actions&quot;
         }"><p data-block-key="qeat0">In June, we launched <a href="https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/">Gemini CLI</a>, an open-source AI agent that brings the power of Gemini to your terminal. The enthusiastic adoption from developers has been incredible. To keep up with the flood of feature requests and contributions, we put our own tool to the test — using Gemini CLI to automate issue triage and pull request reviews. When community members noticed our new workflows, they asked us to share what we’ve built.</p><p data-block-key="dkm0r">Today, we’re introducing <b>Gemini CLI GitHub Actions</b>. It’s a no-cost, powerful AI coding teammate for your repository. It acts both as an autonomous agent for critical routine coding tasks, and an on-demand collaborator you can quickly delegate work to.</p><p data-block-key="4h2fu">It’s now in beta, available to everyone worldwide, and you can find it on GitHub at <a href="https://github.com/google-github-actions/run-gemini-cli">google-github-actions/run-gemini-cli</a>.</p><h3 data-block-key="d3s1s"><b>An AI teammate in your repository</b></h3><p data-block-key="5qn4">While Gemini CLI is a tool built for individual use in your own terminal, Gemini CLI GitHub Actions was created for team collaboration on the platform where developers work with each other.</p><p data-block-key="3tmop">Triggered by events like new issues or pull requests, it works asynchronously in the background, using the full context of your project to automatically handle tasks. It knows your code, understands what you want to do, and gets it done.</p><p data-block-key="413o5">We’re launching with three powerful, open-source workflows that can help you code better, faster:</p><ol><li data-block-key="1fbho"><b>🤖Intelligent issue triage</b>: Automate the overhead of managing new issues. Gemini CLI can analyze, label and prioritize incoming issues, helping focus your attention on what matters most.</li><li data-block-key="fu7pb"><b>🚀Accelerated pull request reviews</b>: Get instant, insightful feedback on code changes. Gemini CLI can review pull requests for quality, style and correctness, freeing up reviewers to focus on more complex tasks and decisions.</li><li data-block-key="2q78t"><b>🤝On-demand collaboration</b>: Simply mention @gemini-cli in any issue or pull request to delegate tasks. Tell it to do things like, "write tests for this bug," "implement the changes suggested above," "brainstorm alternative solutions," or "fix this well defined bug."</li></ol></div>
  

  
    

















<uni-image-carousel section-header="Meet your new AI coding teammate: Gemini CLI GitHub Actions" images="[
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/CLI_Labels.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Easily create new feature requests on GitHub for Gemini CLI to handle on your behalf&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini CLI GitHub Actions labels workflow&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/CLI_Pull_Request.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini CLI GitHub Actions can handle your pull requests, providing code changes and AI\u002Dgenerated suggestions for improving the user experience&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini CLI GitHub Actions Pull Request&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/CLI_Comment.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Delegate work with an \u0022@gemini\u002Dcli\u0022 tag and the agent can complete a range of tasks, from writing bugs to fixing bugs&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini CLI GitHub Actions feature request&quot;
      }
    
  ]">
  
    
      <div slot="caption-slot-0">
        <p data-block-key="3g0nl">Easily create new feature requests on GitHub for Gemini CLI to handle on your behalf</p>
      </div>
    
  
    
      <div slot="caption-slot-1">
        <p data-block-key="foxmz">Gemini CLI GitHub Actions can handle your pull requests, providing code changes and AI-generated suggestions for improving the user experience</p>
      </div>
    
  
    
      <div slot="caption-slot-2">
        <p data-block-key="foxmz">Delegate work with an "@gemini-cli" tag and the agent can complete a range of tasks, from writing bugs to fixing bugs</p>
      </div>
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Meet your new AI coding teammate: Gemini CLI GitHub Actions&quot;
         }"><p data-block-key="qeat0">Think of these initial workflows as your launchpad. They are open-source and fully customizable — you can create your own workflows, or configure the ones that come built into Gemini CLI GitHub Actions.</p><h2 data-block-key="fe8q4">Built with enterprise-grade security and control</h2><p data-block-key="16p06">Robust security measures are a fundamental part of modern software development. That’s why we built Gemini CLI GitHub Actions with security and flexibility at its core.</p><p data-block-key="ataps">You are always in control with capabilities including:</p><ul><li data-block-key="9s87r"><b>Secure, credential-less authentication:</b> Vertex AI and Gemini Code Assist Standard and Enterprise users can tap into Google Cloud's <a href="https://cloud.google.com/iam/docs/workload-identity-federation">Workload Identity Federation</a> (WIF) to eliminate the need for long-lived API keys in your environment, drastically reducing the risk of credential compromise.</li><li data-block-key="e2u6u"><b>Granular control</b>: Enforce the principle of least privilege with multi-layered controls. Use capabilities like command allowlisting to explicitly approve every shell command the agent can execute. You can also create a custom identity for the agent (e.g., gemini-for-your-org) and grant it only the precise permissions it needs.</li><li data-block-key="d5i11"><b>Complete transparency:</b> GitHub on CLI comes integrated with <a href="https://opentelemetry.io/">OpenTelemetry</a>, an industry standard for telemetry, so you can stream logs and metrics to your preferred observability platform, like Google Cloud Monitoring. This gives you full, real-time visibility into every action to monitor usage and debug complex workflows.</li></ul><h2 data-block-key="ffuab">Get started today</h2><p data-block-key="3bqq">What will you build with your new coding teammate? A workflow that automatically generates release notes? One that keeps documentation in sync with your code? Don’t just imagine it; build it. We invite you to contribute your innovative workflows to our repository and share them with the community.</p><p data-block-key="f79fk">Gemini CLI GitHub Actions is <a href="https://github.com/google-github-actions/run-gemini-cli">available today</a> in beta, with <a href="https://github.com/google-gemini/gemini-cli/blob/main/docs/quota-and-pricing.md#gemini-cli-quotas-and-pricing">generous free-of-charge quotas</a> for Google AI Studio. Vertex AI, along with the Standard and Enterprise tiers of Gemini Code Assist, are also supported. We will have free-of-charge use for Gemini Code Assist for individual users available soon.</p><p data-block-key="mgkb">To get started, <a href="https://github.com/google-gemini/gemini-cli">download</a> Gemini CLI 0.1.18 or later and run `/setup-github`. You can find the GitHub Action at <a href="https://github.com/google-github-actions/run-gemini-cli">google-github-actions/run-gemini-cli</a>.</p></div>
  


            
            

            
              




            
          </div>
  </article>
  





  

  


<div data-component="uni-related-articles" aria-roledescription="carousel" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Footer Related Stories&quot;,
    &quot;section_header&quot;: &quot;Related stories&quot;
  }">
        <h3>
          <p>
            Related stories
          </p>
        </h3>
      </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cracking the Vault: How we found zero-day flaws in HashiCorp Vault (224 pts)]]></title>
            <link>https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/</link>
            <guid>44821434</guid>
            <pubDate>Thu, 07 Aug 2025 07:01:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/">https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/</a>, See on <a href="https://news.ycombinator.com/item?id=44821434">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-rocket-location-hash="b5f44b58950a14272f2f7bf6d6b43960">
<h2>Introduction: when the trust model can’t be trusted</h2>



<p>Secrets vaults are the backbone of digital infrastructure. They store the credentials, tokens, and certificates that govern access to systems, services, APIs, and data. They’re not just a part of the trust model, they <em>are</em> the trust model. In other words, if your vault is compromised, your infrastructure is already lost.</p>



<p>Driven by the understanding that vaults are high-value targets for attackers, our research team at Cyata set out to conduct a comprehensive assessment of HashiCorp Vault (“Vault”), one of the most widely used tools in this space.</p>



<p>Over several weeks of deep investigation, we identified <strong>nine previously unknown zero-day vulnerabilities</strong>, <strong>each assigned a CVE</strong> through responsible disclosure. We worked closely with HashiCorp to ensure all issues were patched prior to public release.</p>



<p>The flaws we uncovered bypass lockouts, evade policy checks, and enable impersonation. One vulnerability even allows root-level privilege escalation, and another – perhaps most concerning – leads to the first public <strong>remote code execution (RCE)</strong> reported in Vault, enabling an attacker to execute a full-blown system takeover.</p>



<p>We found a pattern of logic failures that, individually and in combination, create dangerous attack paths – especially in real-world Vault deployments where misconfigurations or excessive permissions are common.</p>



<p>These vulnerabilities weren’t memory corruption or race condition issues, but subtle logic flaws buried in Vault’s authentication, identity, and policy enforcement layers. Some had existed for nearly a decade, quietly embedded and easy to miss, yet straightforward to exploit once understood.</p>



<p>Previous public research on Vault risks, most notably Google Project Zero’s <a href="https://googleprojectzero.blogspot.com/2020/10/enter-the-vault-auth-issues-hashicorp-vault.html">Enter the Vault</a> (2020), focused on bypasses in cloud-provider-specific IAM backends like AWS and GCP. Our work targets Vault’s <strong>core authentication flows</strong>, surfacing issues that impact both Open Source and Enterprise versions, across multiple solution providers.</p>



<p>In this post, we share what we found, how we found it, and what it means for the infrastructure Vault is meant to protect.</p>



<p>In parallel, we conducted a similar assessment of <strong>CyberArk Conjur</strong>, uncovering several high-severity vulnerabilities – composing a pre-auth remote code authentication chain. Those findings are detailed <a href="https://cyata.ai/blog/exploiting-a-full-chain-of-trust-flaws-how-we-went-from-unauthenticated-to-arbitrary-remote-code-execution-rce-in-cyberark-conjur/">in a separate post on Conjur</a>.</p>



<h2>What is HashiCorp Vault?</h2>



<p>HashiCorp Vault is an open-source tool designed to secure, store, and control access to secrets, including API keys, database passwords, certificates, and encryption keys.</p>



<p>Used across organizations of all sizes, Vault centralizes secret management and enforces fine-grained access policies across distributed systems.</p>



<p>At its core, it acts as a security boundary: authenticating users and machines and brokering access to sensitive data.</p>



<p>Vault plays a critical role in modern DevSecOps pipelines, helping teams reduce the risks of hardcoded credentials, secret sprawl, and unauthorized access.</p>



<p>Users frequently highlight its integration flexibility, detailed policy enforcement, and suitability for complex, distributed environments.</p>



<p>In many environments, it’s trusted as the final gatekeeper of secrets and, depending on its configuration, a breach of Vault can mean a breach of <strong>everything</strong>.</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1562" src="https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-261x300.webp 261w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-892x1024.webp 892w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-768x882.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-1337x1536.webp 1337w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-372x427.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p>Vault highlights</p>



<ul>
<li>Secrets management and cryptographic engine designed for dynamic, multi-cloud and hybrid environments</li>



<li>Centralized secrets storage with access via API</li>



<li>Dynamic credential provisioning with automatic expiration</li>



<li>Identity-based access controls supporting human and machine authentication</li>



<li>Encryption as a service for data at rest and in transit</li>



<li>Certificate management for generating, rotating, and revoking certificates</li>



<li>Distribution, enabling, disabling, and rotating encryption keys</li>
</ul>



<p>For more on Vault, see: <a href="https://www.hashicorp.com/en/resources/introduction-to-hashicorp-vault">Introduction to HashiCorp Vault</a>.</p>



<h2>Methodology: how we found what others missed</h2>



<p>This research was the result of a deliberate, weeks-long effort by our research team to uncover logic-level vulnerabilities in Vault – the kind that don’t show up in memory scanners or crash logs, but that can quietly undermine a system’s trust model.</p>



<p>We didn’t stumble into these issues. We sought them out, starting with a clear hypothesis – if Vault plays the role of trust anchor for organizations, then even minor inconsistencies in how it enforces identity, authentication, or policy could have outsized consequences.</p>



<p>We focused on Vault’s core request flow, especially the <code>request_handling.go</code> file which functions as the “brain” of Vault. This is where requests are routed, identities resolved, and policy decisions made. We spent weeks reviewing the logic across functions and modules, looking for edge cases where trust boundaries might blur.</p>



<p>We didn’t rely on fuzzers or automated probes. Instead, we conducted a deep manual review of the source code – looking not just at what each function did, but how different components interpreted identity and input. Where we saw inconsistencies in casing, aliasing, or formatting, we dug deeper.</p>



<p>These weren’t random guesses, each test input was a precision-guided hypothesis shaped by the code itself. We also approached the system like an attacker: starting with minimal access and asking, <em>“How far can we push from here?”</em></p>



<p>We repeated that process again and again.</p>



<p>This recurring loop – spotting subtle inconsistencies, reasoning through their downstream impact, and validating them with controlled testing – led us to each of the nine vulnerabilities disclosed in this report.</p>



<p>Ultimately, we didn’t just look for vulnerabilities. We looked at how trust itself could break and followed the logic wherever it led.</p>



<h2>The path to compromise</h2>



<p><mark>Step 1 – Cracks in userpass authentication</mark></p>



<p>HashiCorp Vault supports a wide range of authentication methods, 14 by default. To kick off our research, we began with the simplest and most widely used – <code>userpass</code>, Vault’s native username-and-password login mechanism.</p>



<p>To enable <code>userpass</code>, users configure it through the Vault UI or API as one of the available authentication methods.</p>



<figure><img loading="lazy" decoding="async" width="1294" height="844" src="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1.webp 1294w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-300x196.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-1024x668.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-768x501.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-372x243.webp 372w" sizes="auto, (max-width: 1294px) 100vw, 1294px"></figure>



<p>In a typical <code>userpass</code> setup, each user is assigned a hashed password and one or more Vault policies. On login, Vault verifies the credentials and applies the appropriate policy upon success.</p>



<p>Given how foundational <code>userpass</code> is to Vault and how widely it’s deployed across production environments, we were surprised to discover logic flaws in this core component. Even here, at the default entry point to the system, the trust model could be broken.</p>



<p>The Full Login Flow</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1360" src="https://cyata.ai/wp-content/uploads/2025/08/userpass-login.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/userpass-login.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-300x300.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-1024x1024.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-150x150.webp 150w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-768x768.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-372x372.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p><strong>What we looked for</strong></p>



<p>We began by reviewing how Vault enforces lockout protections under <code>userpass</code> – specifically, how failed login attempts are tracked, throttled, and attributed to individual users.</p>



<p><strong>What we found</strong></p>



<p>Our first stop was Vault’s userpass backend. We wanted to understand not only how it works – but also how it could be manipulated into misbehaving.</p>



<p>Our investigation focused on Vault’s <strong>lockout protection</strong> logic, the mechanism that’s supposed to throttle brute-force attempts. We discovered three vulnerabilities, all related to how Vault tracks and handles failed login attempts:</p>



<ul>
<li id="CVE-2025-6010"><strong>CVE-2025-6010 – Redacted (Pending Fix)<br></strong>This CVE has been temporarily withheld from publication at the request of the vendor. No technical details will be shared at this time.</li>



<li id="CVE-2025-6004"><strong>CVE-2025-6004 – Lockout bypass via case permutation</strong><br>By changing the casing of a known username (e.g., <code>admin</code> vs <code>Admin</code>), an attacker can reset the lockout counter and continue brute-forcing.</li>



<li id="CVE-2025-6011"><strong>CVE-2025-6011 – Timing-based enumeration</strong><br>When Vault authenticates a real user, it performs a bcrypt hash comparison. For nonexistent users, that step is unintentionally skipped due to an early return. This leads to a detectable timing difference, allowing attackers to infer which usernames are valid.</li>
</ul>



<p>CVE-2025-6004 Lockout Bypass:</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/CVE-2025-6004-userpass.mp4"></video></figure>



<p><strong>Why it matters</strong></p>



<p>These flaws allow an attacker to:</p>



<ul>
<li><strong>Enumerate </strong>valid users without alerting defenders</li>



<li><strong>Bypass </strong>Vault’s intended lockout protections</li>



<li><strong>Brute-force </strong>credentials at scale, even in hardened environments</li>
</ul>



<p>In short, Vault’s simplest authentication path – the first line of defense – contained logic bugs that could be exploited to undermine access controls before any policies were ever enforced.</p>



<p>Step 2 – LDAP logic flaws and MFA enforcement bypass</p>



<p>After uncovering multiple vulnerabilities in <code>userpass</code>, we turned our attention to another backend that shares the same lockout mechanism: <code>ldap</code>. It’s one of Vault’s most widely used authentication methods in production environments, often integrated with directory services like Active Directory or OpenLDAP. And like <code>userpass</code>, it enforces a lockout threshold by default, which made it a compelling next target for investigation.</p>



<p>To enable the <code>ldap</code> backend, it must be configured through the Vault UI or API:</p>



<figure><img loading="lazy" decoding="async" width="1294" height="844" src="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2.webp 1294w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-300x196.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-1024x668.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-768x501.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-372x243.webp 372w" sizes="auto, (max-width: 1294px) 100vw, 1294px"></figure>



<p>Unlike <code>userpass</code>, where Vault verifies credentials internally, the <code>ldap</code> method delegates authentication to an external server. Vault simply forwards the provided credentials, and the LDAP server performs the verification.</p>



<p>The full authentication flow looks like this:</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1562" src="https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-261x300.webp 261w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-892x1024.webp 892w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-768x882.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-1337x1536.webp 1337w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-372x427.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p><strong>What we looked for</strong></p>



<p>After discovering username enumeration issues in <code>userpass</code>, we turned our attention to the <code>ldap</code> backend – specifically, how it handles lockout behavior for unknown users.</p>



<p>Unlike <code>userpass</code>, <code>ldap </code>applies lockout uniformly to all failed login attempts, regardless of whether the username exists. This consistent treatment prevents the kind of enumeration attacks seen in <code>userpass</code>.</p>



<p>So:</p>



<ul>
<li>No lockout discrepancy → no username enumeration vector</li>



<li>A previous known issue (CVE-2023-3462) had already been patched</li>
</ul>



<p>But despite this uniformity, we uncovered <strong>two high-impact logic flaws</strong>.</p>



<p><strong>What we found</strong></p>



<p>We found two critical flaws that weakened lockout enforcement and bypassed MFA controls under specific configuration conditions.</p>



<p><strong>CVE-2025-6004 – Lockout bypass via input normalization mismatch</strong></p>



<p>This vulnerability stems from how Vault and the LDAP server handle input formatting differently. Vault tracks lockouts by the exact input string, but most LDAP servers normalize input, ignoring case and trimming spaces.</p>



<p>So, these inputs:</p>



<ul>
<li><code>"yardenporat"</code></li>



<li><code>"yardenporat "</code></li>



<li><code>" yardenporat"</code></li>



<li><code>"YARDENPORAT"</code></li>
</ul>



<p>These are all interpreted by LDAP as the same user, but treated by Vault as different aliases.</p>



<p>That discrepancy results in an astronomical number of login attempts that bypass the intended lockout limits. For example:</p>



<pre><code>≈ 1,000 (leading spaces) × 1,000 (trailing spaces) × 2¹¹ (case variants) × 5 (attempts) = ~10 billion guesses</code></pre>



<p><strong>Impact:</strong> </p>



<p>An attacker can make <strong>billions of password guesses</strong> against the same account in a single lockout window – completely defeating the brute-force protection mechanism</p>



<p><strong>CVE-2025-6003 – MFA enforcement bypass via</strong> <code>username_as_alias</code> <strong>and</strong> <code>EntityID</code><br>The second flaw was even more subtle and potentially more dangerous.</p>



<p>Vault allows admins to set <code>username_as_alias=true</code> in the <code>ldap </code>configuration. This means the username itself is used as the basis for identity resolution.</p>



<p>But when MFA enforcement is applied at the <code>EntityID</code> or <code>IdentityGroup</code> level, a mismatch occurs between how Vault resolves the user and how it enforces MFA.</p>



<p>Even though the user logs in successfully, Vault may fail to associate the correct <code>EntityID</code> and therefore, MFA never gets triggered.</p>



<p>For this bypass to occur, two conditions must be met:</p>



<ol>
<li><code>username_as_alias=true</code> in the LDAP auth configuration</li>



<li>MFA enforcement is applied at the <code>EntityID</code>or <code>IdentityGroup</code> level</li>



<li>This issue only became apparent after a deep analysis of how Vault handles <code>EntityID</code>resolution in tandem with authentication workflows, but the result is easily exploitable in practice, including via the UI.</li>
</ol>



<p><strong>Impact:</strong></p>



<p>When MFA is enforced at the <code>EntityID</code> level, Vault may fail to associate the correct <code>EntityID</code>, allowing the login to proceed without triggering MFA.</p>



<p>CVE-2025-6004 Lockout Bypass:</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/CVE-2025-6004-ldap.mp4"></video></figure>



<p><br>CVE-2025-6003 MFA enforcement bypass:</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/CVE-2025-6003-1.mp4"></video></figure>



<p><br><strong>Why it matters</strong></p>



<p>These two vulnerabilities allow an attacker to:</p>



<ul>
<li><strong>Bypass Vault’s lockout mechanism</strong>, enabling a high volume of password guesses per account</li>



<li><strong>Silently bypass MFA enforcement</strong> in specific configurations where MFA is applied at the <code>EntityID</code> or <code>IdentityGroup</code> level and <code>username_as_alias=true</code> is set</li>
</ul>



<p>Both flaws directly undermine core security protections in enterprise Vault deployments and highlight how subtle logic mismatches can erode trust at the identity layer.</p>



<p>Step 3 – Bypassing TOTP MFA protections</p>



<p><code>userpass</code> and <code>ldap</code> are widely used authentication backends in Vault, but they’re rarely deployed on their own. In most real-world setups, multi-factor authentication (MFA) is also configured. That’s why it was clear to us that any analysis of the authentication surface would be incomplete without examining it.</p>



<p>The MFA method we investigated is TOTP (Time-based One-Time Password), the most common MFA method overall, and especially common alongside <code>userpass</code> and <code>ldap</code>.</p>



<p>This approach adds a rotating numeric code on top of static credentials, aiming to stop brute-force and replay attacks with minimal overhead.</p>



<p><strong>TOTP in Vault</strong></p>



<p>Vault’s built-in TOTP MFA relies on a per-entity shared secret. During authentication, it generates a 6-digit code (valid for a 30-second window by default) and compares it to the user’s input.</p>



<p>By taking a look under the hood, we saw that:</p>



<ul>
<li>Vault uses the Go package <a href="https://pkg.go.dev/github.com/pquerna/otp/totp">github.com/pquerna/otp/totp</a></li>



<li>Rate-limiting and replay protection are implemented separately inside Vault</li>
</ul>



<p>For TOTP specification details, see <a href="https://datatracker.ietf.org/doc/html/rfc6238">RFC 6238</a></p>



<p><strong>Vault’s TOTP flow</strong></p>



<p>Here’s how Vault handles TOTP MFA during login:</p>



<p>1. Login begins</p>



<p>2. Vault checks for TOTP MFA</p>



<p>3. A passcode is extracted:</p>



<pre><code>func (c *Core) validateTOTP(...) error {
    if mfaFactors == nil || mfaFactors.passcode == "" {
        return fmt.Errorf("MFA credentials not supplied")
    }
    passcode := mfaFactors.passcode
    ...
}</code></pre>



<p>4. Vault checks if the passcode was already used (replay detection):</p>



<pre><code>usedName := fmt.Sprintf("%s_%s", configID, passcode)

_, ok := usedCodes.Get(usedName)
if ok {
    return fmt.Errorf("code already used; new code is available in %v seconds", totpSecret.Period)
}</code></pre>



<p>5. Rate-limiting is enforced per <code>EntityID</code>:</p>



<pre><code>rateLimitID := fmt.Sprintf("%s_%s", configID, entityID)

numAttempts, _ := usedCodes.Get(rateLimitID)
if numAttempts == nil {
    usedCodes.Set(rateLimitID, uint32(1), passcodeTTL)
} else {
    num, ok := numAttempts.(uint32)
    if !ok {
        return fmt.Errorf("invalid counter type returned in TOTP usedCode cache")
    }
    if num == maximumValidationAttempts {
        return fmt.Errorf("maximum TOTP validation attempts %d exceeded the allowed attempts %d.", num, maximumValidationAttempts)
    }
    err := usedCodes.Increment(rateLimitID, 1)
    if err != nil {
        return fmt.Errorf("failed to increment the TOTP code counter")
    }
}</code></pre>



<p>6. Code validation occurs using the <code>ValidateCustom()</code> function:</p>



<pre><code>key, err := c.fetchTOTPKey(ctx, configID, entityID)
if err != nil {
    return errwrap.Wrapf("error fetching TOTP key: {{err}}", err)
}

if key == "" {
    return fmt.Errorf("empty key for entity's TOTP secret")
}

valid, err := totplib.ValidateCustom(passcode, key, time.Now(), validateOpts)</code></pre>



<p><br>7. If the code is valid, it is marked as used:</p>



<pre><code>validityPeriod := time.Duration(int64(time.Second) * int64(totpSecret.Period) * int64(2+totpSecret.Skew))
err = usedCodes.Add(usedName, nil, validityPeriod)</code></pre>



<p>8. Authentication completes</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1360" src="https://cyata.ai/wp-content/uploads/2025/08/totop-image.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/totop-image.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-300x300.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-1024x1024.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-150x150.webp 150w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-768x768.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-372x372.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p><strong>What we looked for</strong></p>



<p>We dug into Vault’s TOTP implementation, looking for logic flaws that could significantly weaken this layer of protection, whether individually or when combined.</p>



<p><strong>What we found</strong></p>



<p>We uncovered <strong>three major logic flaws</strong>, plus a CVE that captures their combined impact:</p>



<p><strong>Bug 1 – Used passcode enumeration</strong></p>



<p>Vault checks for code reuse before applying rate-limiting. This opens a subtle but powerful attack surface.</p>



<p>If an attacker submits a passcode that was recently used, Vault responds with a specific error:</p>



<pre><code>"code already used; new code is available in %v seconds"</code></pre>



<p>This behavior reveals information. Even if a code is expired, Vault confirms it was valid at some point, enabling enumeration of previously used passcodes.</p>



<p><br><strong>Bug 2 – One-time-use bypass via space padding</strong></p>



<p>This issue originates deep inside Vault’s TOTP validation stack. Specifically:</p>



<ol>
<li>Vault calls <code>totp.ValidateCustom()</code></li>



<li><code>totp</code> internally calls <code>hotp.ValidateCustom()</code></li>



<li>Inside <code>hotp</code>, input is normalized:</li>
</ol>



<pre><code>func ValidateCustom(passcode string, ...) {
    passcode = strings.TrimSpace(passcode)
    ...
}</code></pre>



<p>So <code>"123456"</code> and <code>" 123456"</code> are treated as equivalent by the validator.</p>



<p>But Vault’s internal <code>usedCodes</code> cache does not normalize the input. This means:</p>



<ul>
<li><code>"123456"</code> is marked as used</li>



<li><code>" 123456"</code> is accepted as new, even though it’s the same underlying code</li>
</ul>



<p><strong>Impact:</strong> </p>



<p>An attacker can <strong>bypass the one-time-use restriction</strong> simply by adding spaces.</p>



<p><br><strong>Bug 3.1 – Rate-limiting evasion via time skew</strong></p>



<p>Even if an attacker has a valid TOTP code using Bug 1, Vault may still reject it because the enumeration attempts required to discover that code may have already triggered per-entity rate-limiting within the TOTP validity window. But this protection can be bypassed if the attacker understands how Vault sets its TTL threshold:</p>



<pre><code>passcodeTTL := time.Duration(int64(time.Second) * int64(totpSecret.Period))</code></pre>



<p>This default is <strong>30 seconds</strong>, matching the default TOTP period. But due to skew, passcodes may remain valid for <strong>up to 60 seconds</strong>, spanning two time windows.</p>



<p>This creates a strategy:</p>



<ul>
<li>Hit the rate limit</li>



<li>Wait out the 30-second TTL</li>



<li>Resubmit the same code (still within skew window)</li>



<li><strong>Authentication succeeds</strong></li>
</ul>



<p><br><strong>Bug 3.2 – Rate-limiting bypass via entity switching</strong></p>



<p>Vault enforces rate limits <strong>per </strong><code>EntityID</code>, but the <code>usedCodes</code> cache is <strong>global</strong>. This creates a loophole:</p>



<ol>
<li>One entity hits the rate limit while brute-forcing</li>



<li>A second entity submits the same (space-padded) passcode</li>



<li><strong>Rate-limit doesn’t apply</strong></li>
</ol>



<p id="CVE-2025-6013">Even worse, <strong>CVE-2025-6013</strong>, which we discovered and described above, allows LDAP users to generate multiple <code>EntityIDs</code> for the same identity. So even if Vault enforced rate limits per <code>EntityID</code> (which it doesn’t), attackers could still rotate <code>EntityIDs</code> to keep attacking.</p>



<p id="CVE-2025-6016"><br><strong>CVE-2025-6016 – Aggregated logic flaws weaken MFA</strong></p>



<p>All these flaws combine into a dangerous scenario.</p>



<p>An attacker can:</p>



<ol>
<li><strong>Enumerate </strong>used passcodes by probing for error messages</li>



<li><strong>Evade </strong>rate-limiting by either:
<ul>
<li>Switching entities</li>



<li>Waiting out the TTL window</li>
</ul>
</li>



<li><strong>Bypass </strong>one-time-use protection via space manipulation</li>



<li><strong>Submit </strong>the correct passcode to authenticate without triggering defenses</li>
</ol>



<p>Despite TOTP being configured as a second factor, Vault’s logic flaws allowed attackers to <strong>brute-force MFA codes </strong>within a small time window.</p>



<p><strong>Why it matters</strong></p>



<p>These flaws significantly reduced the effectiveness of MFA in Vault, enabling attackers to bypass protections like rate-limiting and one-time-use enforcement, and in some configurations, guess valid TOTP codes without triggering MFA challenges as expected.</p>



<p>Step 4 – Certificate-based authentication and entity impersonation</p>



<p>In Vault, TLS certificate authentication is commonly used for machine-to-machine scenarios, allowing automated services, infrastructure components, or nodes to securely identify themselves.</p>



<p>To enable cert-based authentication, users configure it through the Vault UI or API:</p>



<figure><img loading="lazy" decoding="async" width="1243" height="811" src="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3.webp 1243w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-300x196.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-1024x668.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-768x501.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-372x243.webp 372w" sizes="auto, (max-width: 1243px) 100vw, 1243px"></figure>



<p>Once enabled, Vault’s <code>cert</code> method supports two modes:</p>



<ol>
<li><strong>CA mode</strong> – Trust any certificate issued by a configured Certificate Authority (CA)</li>



<li><strong>Non-CA mode</strong> – Trust only a specific pinned certificate, verified by public key</li>
</ol>



<p>In both cases, Vault maps the TLS client certificate to an <code>EntityID</code> using the authentication mount path and the Common Name (CN) from the certificate.</p>



<p>(auth mount path, alias.Name)</p>



<p>The value of <code>alias.Name</code> is taken from the Common Name (CN) field of the client certificate presented during the TLS handshake, not from the certificate configured in Vault:</p>



<pre><code>Alias: &amp;logical.Alias{
    Name: clientCerts[0].Subject.CommonName,
}</code></pre>



<p>In CA mode, this behavior makes sense – CNs vary and can’t be predicted in advance. But in non-CA mode, this introduces a dangerous blind spot.</p>



<p><strong>What we looked for</strong></p>



<p>We examined how Vault maps identities in cert-based authentication, particularly in non-CA mode, to identify potential mismatches between trust and identity resolution.</p>



<p><strong>What we found</strong></p>



<p>We discovered a logic flaw in Vault’s non-CA certificate authentication: Vault verifies only that the TLS client certificate’s public key matches the pinned certificate, but does not verify that the CN matches as well.</p>



<p id="CVE-2025-6037"><strong>CVE-2025-6037 – Certificate entity impersonation</strong></p>



<p>In non-CA mode, an attacker who has access to the private key of a pinned certificate can:</p>



<ul>
<li>Present a certificate with the correct public key</li>



<li>Modify the CN in the client certificate to any arbitrary value</li>



<li>Cause Vault to assign the resulting <code>alias.Name</code> to that CN</li>
</ul>



<p>Because Vault maps this alias to an <code>EntityID</code>, the attacker is now authenticated as any identity whose alias matches the forged CN.</p>



<p>This allows impersonation of other machine identities, inheriting:</p>



<ul>
<li>Policies tied to the spoofed <code>EntityID</code></li>



<li>Policies from associated <code>Identity Groups</code></li>
</ul>



<p>Even though policies directly tied to a specific certificate remain inaccessible, in many deployments, <code>EntityID</code> – linked policies may be sufficient to escalate access or retrieve secrets.</p>



<p><strong>Why it matters</strong></p>



<p>Vault’s trust model depends on accurate identity mapping. This vulnerability breaks that assumption by allowing any private-key holder of a pinned cert to impersonate other machine identities, a severe breach of trust.</p>



<p>In environments where certificates govern automated secret retrieval, service orchestration, or backend access control, this opens the door to full lateral compromise.</p>



<p>Step 5 – Escalating from admin to root</p>



<p>So far, we’ve focused on breaking Vault’s authentication surface, through <code>userpass</code>, <code>LDAP</code>, <code>MFA</code>, and <code>cert</code>.</p>



<p>Now we turn to what happens after authentication: what can a legitimate user do? In this section, we show how an admin-level user can escalate privileges and obtain a root token, despite the boundaries the Vault trust model is designed to enforce.</p>



<p>The Vault trust model is one that relies on strict role separation. Even users with admin-level tokens are restricted from performing certain privileged actions. But that boundary can break.</p>



<p><strong>How it works</strong></p>



<p>Vault uses a policy-based authorization system. Each identity or token is granted permissions through attached policies.</p>



<p>Two built-in policies define access boundaries:</p>



<ul>
<li><code>default:</code> minimal access</li>



<li><code>root:</code> full administrative control, including audit logging, plugin registration, encryption key rotation, and system reconfiguration</li>
</ul>



<p>To prevent misuse, Vault includes a hardcoded restriction to block assignment of the <code>root</code> policy. This protection applies at all expected enforcement points, including:</p>



<ul>
<li>During user login</li>



<li>When modifying an identity (<code>EntityID</code>) via Vault’s identity API</li>
</ul>



<p>To assign policies to an identity, Vault provides the following endpoint:</p>



<p><code>POST /v1/identity/entity/id/{entity_id}</code></p>



<p>This endpoint allows modification of the attached policy set for a given <code>EntityID</code>. It’s powerful and typically reserved for high-privilege users.</p>



<p>Vault includes a safeguard to prevent abuse:</p>



<pre><code>if strutil.StrListContains(entity.Policies, "root") {
    return logical.ErrorResponse("policies cannot contain root"), nil
}</code></pre>



<p>This hardcoded check explicitly blocks requests that attempt to assign the <code>root</code> policy, or so it seems.</p>



<p><strong>What we looked for</strong></p>



<p>With initial access achieved, we turned our attention to potential escalation paths, particularly whether admin users could gain root.</p>



<p>We uncovered a <strong>logic flaw</strong> in how Vault normalizes policy names, one that lets an attacker escalate from <strong>admin to root</strong> by bypassing its most explicitly protected gate.</p>



<p><strong>What we found</strong></p>



<p id="CVE-2025-5999"><strong>CVE-2025-5999 – Root privilege escalation via policy normalization</strong></p>



<p>During request evaluation (e.g., when a token is used to access an endpoint), Vault performs policy merging and normalization. The relevant code:</p>



<pre><code>auth.Policies = policyutil.SanitizePolicies(append(te.Policies, identityPolicies[te.NamespaceID]...))</code></pre>



<p>Inside <code>SanitizePolicies</code>, this logic appears:</p>



<pre><code>p = strings.ToLower(strings.TrimSpace(p))</code></pre>



<p>This introduces a subtle but powerful mismatch:</p>



<ul>
<li>The <strong>validation</strong> layer checks for <code>"root"</code>  – exactly as written</li>



<li>The <strong>enforcement</strong> layer normalizes input by trimming and lowercasing</li>
</ul>



<p>That means the following inputs:</p>



<ul>
<li><code>" root"</code> (with a space)</li>



<li><code>"ROOT"</code> (uppercase)</li>
</ul>



<p>Because these variations aren’t blocked by the validation check, they pass through and are then normalized to ‘root’ during enforcement.</p>



<p>So, if an attacker submits a request assigning <code>" root"</code> as a policy, it silently passes the block and becomes <code>root</code> in practice.</p>



<p>Vault will now treat the token as having full administrative privileges.</p>



<p><strong>Why it matters</strong></p>



<p>This logic flaw allows an attacker with admin-level access to:</p>



<ul>
<li>Authenticate and obtain a valid token</li>



<li>Submit a request to <code>POST /v1/identity/entity/id/{entity_id}</code> with <code>" root"</code> in the policy list</li>



<li>Bypass the hardcoded <code>root</code> check</li>



<li>Gain <strong>root privileges</strong> after the policy is normalized at runtime</li>
</ul>



<p>This bypass targets one of the <strong>most tightly protected controls in Vault</strong> and succeeds without crashing the service, triggering alarms, or touching memory. It’s a clean, silent privilege escalation.</p>



<p>Step 6 – Remote code execution via plugin interface abuse</p>



<p>In the previous step, we demonstrated how an admin-level user can escalate to root token privileges.</p>



<p>From there, the next logical step was to investigate whether that level of access could be used to achieve code execution, specifically, to abuse Vault’s internal interfaces in order to run arbitrary commands on the server.</p>



<p><strong>What we looked for</strong></p>



<p>From root, we explored whether code execution was possible for an attacker with elevated access, specifically via Vault’s plugin system.</p>



<p><strong>What we found</strong></p>



<p>Vault supports loading custom plugins – binaries that provide secret engines, auth methods, or other extensible functionality.&nbsp;These plugins are stored in a predefined <code>plugin_directory</code>, which is configured during setup and cannot be modified at runtime.</p>



<p>During our testing, we discovered a method for creating and loading an attacker-controlled plugin.</p>



<p><strong>CVE-2025-6000 – RCE via plugin catalog abuse</strong></p>



<p>To create and load a new plugin, an attacker must achieve five goals:</p>



<ol>
<li>Create a controlled file on disk</li>



<li>Locate the configured <code>plugin_directory</code></li>



<li>Place the controlled file inside <code>plugin_directory</code></li>



<li>Assign execute permissions to the file</li>



<li>Know the SHA256 hash of the file contents in advance (required to load a plugin)</li>
</ol>



<p><strong>Step 1 – Writing a payload to disk</strong></p>



<p>Vault encrypts nearly all user-controlled content, including secrets and metadata.</p>



<p>Even when storing data through the API, the resulting file is encoded and wrapped in structured formats.</p>



<p>There’s no way to get raw bytes written directly to disk . . . except in one place:</p>



<p><strong>Audit logs.</strong></p>



<p>Audit logs are written in plaintext, not encrypted. And while each entry is a structured JSON object, we discovered something surprising:</p>



<p><strong>Vault’s audit log system supports a “prefix” – a string prepended to every log entry.</strong></p>



<p>We set the prefix to a payload like <code>#!/bin/bash\n...</code> and let Vault write the rest. The JSON body that follows is ignored by Bash. All that matters is that the script starts with a valid shebang and executable code.</p>



<p><strong>Step 2 – Locating the </strong><code>plugin_directory</code></p>



<p>The <code>plugin_directory </code>configuration is used only for loading plugins. So, to locate it, our best bet was to examine the plugin loading endpoint:</p>



<p><code>POST /v1/sys/plugins/catalog/:type/:name.</code></p>



<p>We experimented with it to understand how plugin loading works and what the code flow looks like. During testing, we found that when attempting to load a non-existent binary, the endpoint returns an error message, and that message includes the full path to the <code>plugin_directory</code>.</p>



<p>For example, when we tried to load the binary <code>invalid91cad96-b8e6-4f5b-9359-ad20fe5815c4</code>, we got:</p>



<pre><code>Loading plugin invalid91cad96-b8e6-4f5b-9359-ad20fe5815c4&nbsp;
Got error:&nbsp;&nbsp;&nbsp;&nbsp; * error while validating the command path: lstat /Users/yarpo/Desktop/vaults/hashicorp/config/plugins/invalid91cad96-b8e6-4f5b-9359-ad20fe5815c4: no such file or directory&nbsp;</code></pre>



<p><strong>Step 3 – Writing to the plugin directory</strong></p>



<p>Now that we had the <code>plugin_directory</code> we wanted to write our audit file to there.</p>



<p>Fortunately, Vault allows configuring the audit backend to write logs to any absolute file path.</p>



<p>We set:</p>



<ul>
<li><code>file_path</code> = inside the plugin directory</li>
</ul>



<p><strong>Step 4 – Getting execute permissions</strong></p>



<p>Vault doesn’t load just any file as a binary. The file must have execute permissions in order to be loaded as a plugin.</p>



<p>This turned out to be the most unexpected and critical part. When configuring the audit log file, there is an option to set the file’s mode. and this includes support for executable modes.</p>



<p>So we set:</p>



<ul>
<li><code>mode = 0755</code></li>
</ul>



<p><strong>Note:</strong> Using the audit logs, we can create a file with arbitrary contents matching a regex, write it to any absolute <code>file_path</code>, and assign it executable permissions.</p>



<p><strong>Step 5 – Capturing the hash</strong></p>



<p>In the registration phase, a SHA256 of the binary must be provided. This might sound simple, but for our audit log approach, it presents a challenge: audit logs include timestamps and other unpredictable values, making it impossible to precompute the hash.&nbsp;</p>



<p>To solve this, we configured multiple audit backends simultaneously.</p>



<p>We added a second backend that streamed logs to a TCP socket we controlled. This gave us a real-time copy of the exact file content, allowing us to compute the correct SHA256 after the file was written.</p>



<p><strong>Full exploit flow</strong></p>



<ol>
<li>Attempt to load a non-existent plugin → Vault returns an error that reveals the full <code>plugin_directory</code> path.</li>



<li>Enable a file-based audit backend with:</li>
</ol>



<ul>
<li><code>file_path = inside plugin_directory</code></li>



<li>mode = 0755</li>
</ul>



<ol>
<li><code>prefix = Bash payload</code> <strong>Send request</strong> → Vault writes executable Bash file.</li>



<li>Capture file content from the socket → Compute SHA256.</li>



<li><strong>Register the plugin</strong> using the correct hash.</li>



<li>Vault executes it → <strong>RCE achieved</strong>.</li>
</ol>



<p>Default -&gt; RCE (CVE-2025-6037, CVE-2025-5999, CVE-2025-6000):</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/HashiCorpRCE-1.mp4"></video></figure>



<p><strong>Why it matters</strong></p>



<p>This vulnerability chains together multiple trusted Vault components – audit logging, file permissions, plugin registration, to break critical security boundaries.</p>



<p>The ability to:</p>



<ul>
<li>Write a file to disk</li>



<li>Control its contents via a hidden prefix feature</li>



<li>Set its mode to executable</li>



<li>Compute its hash</li>



<li>And execute it as a plugin</li>
</ul>



<p>translates into a full remote code execution with no memory corruption or native code injection.</p>



<p>CVE-2025-6000 is <strong>the first public RCE reported in Vault</strong>, even though the underlying risk had been present for nearly a decade.</p>



<p><strong>Post-exploitation scenarios</strong></p>



<p>With RCE in Vault, an attacker gains complete control, but what they do next depends on their intent. We highlight two realistic post-exploitation strategies observed during testing.</p>



<p><strong>Vault ransomware</strong></p>



<p>Vault stores all critical state – including secrets, tokens, and policies, encrypted on disk. One of the key components required for decryption is the file:</p>



<ul>
<li><code>core/hsm/_barrier-unseal-keys</code></li>
</ul>



<p>If this file is deleted, Vault permanently loses access to its encryption key, rendering the remaining data unreadable – even to administrators.</p>



<p>By removing a single file, an attacker can flip Vault’s encryption model on its head, turning it from a security mechanism into a ransomware vector.</p>



<p><strong>Stealthy path: audit-free persistence</strong></p>



<p>In Vault Enterprise, the <strong>Control Group</strong> feature is designed to enforce multi-approver workflows for sensitive operations. But with RCE, this mechanism can be subverted for stealth.</p>



<p>By writing custom control group files directly to disk, an attacker can abuse the system to send HTTP requests and receive responses without being audited. This results in persistent, low-visibility access that bypasses oversight.</p>



<p>This abuse was discovered through black-box testing, as Control Group is exclusive to Vault Enterprise and not openly documented.</p>



<h2>Putting it all together: impact and attack paths</h2>



<p>This research exposes critical weak points in Vault’s trust and identity model – flaws that, under real-world conditions, form exploitable attack paths and can drive devastating results.</p>



<p>Each issue stands on its own, but when combined, they open the door to high-impact compromise scenarios.</p>



<p>In practice, a determined attacker may be able to chain together multiple vulnerabilities, depending on configuration, permissions, and persistence level.</p>



<p>Below are three realistic attack paths, based on common authentication methods:</p>



<p>1. <code>userpass</code> attack path (high-effort, persistent attacker)</p>



<ul>
<li>Enumerate valid usernames via error message mismatch</li>



<li>Bypass lockout using case variation</li>



<li>Bypass TOTP MFA rate limits and one-time-use protection</li>



<li><em>(If the compromised user has admin privileges)</em> → escalate to <code>root</code> via policy normalization</li>



<li>Achieve RCE via audit log and plugin abuse</li>
</ul>



<p>This path is difficult and requires persistence, but it’s viable, especially if MFA policies are weak and admin tokens are in use.</p>



<p>2. <code>ldap</code> attack path (config-dependent)</p>



<ul>
<li>Bypass lockout using input normalization mismatch</li>



<li>Bypass MFA if <code>username_as_alias=true</code> and MFA is enforced at the <code>EntityID</code> level</li>



<li><em>(If the compromised user has admin privileges)</em> → escalate to <code>root</code></li>



<li>Achieve RCE via plugin interface abuse</li>
</ul>



<p>This scenario depends on specific but common configuration choices</p>



<p>3. <code>cert</code> attack path (targeted impersonation)</p>



<ul>
<li>Impersonate an admin-level user by modifying CN in a certificate with a trusted public key</li>



<li><em>(If the impersonated identity has entity-based policies)</em> → gain admin access</li>



<li>Escalate to <code>root</code></li>



<li>Trigger RCE through audit logging chain</li>
</ul>



<p>This path requires access to the private key of a pinned certificate and benefits from permissive policy binding.</p>



<p>Each of these paths leverages distinct logic flaws in Vault, but all converge at the same critical outcome: <strong>root access and full code execution inside the Vault server</strong>.</p>



<p><strong>Why this matters</strong></p>



<p>This research shows how authentication, policy enforcement, and plugin execution can all be subverted through logic bugs, without touching memory, triggering crashes, or breaking cryptography.</p>



<p><strong>These logic vulnerabilities – one of which would qualify as CVSS ‘critical’ –  could be weaponized to exfiltrate secrets, disable access controls, or sabotage infrastructure from within.</strong></p>



<p><strong>It’s a reminder that even without memory safety bugs, logic flaws can open the door to complete compromise.</strong></p>



<h2>How long were these vulnerabilities in Vault?</h2>



<p>As part of our research, we analyzed the history of key vulnerabilities in Vault to understand how long they had existed before our discovery. Two cases stood out:</p>



<p><em>CVE-2025-6037 – Certificate impersonation</em></p>



<p>This vulnerability existed in Vault for over <strong>eight years</strong>. For the first seven years, it was effectively a <strong>full authentication bypass via certificate</strong>, not just impersonation, making it far more severe.</p>



<p>In the past year, the issue appears to have been partially addressed, “downgrading” the bug to impersonation.</p>



<p id="CVE-2025-6000"><em>CVE-2025-6000 – Remote Code Execution</em></p>



<p>This vulnerability has existed in Vault for <strong>nine years</strong>, dating back to the project’s early releases.</p>



<p>This is also the <strong>first public RCE ever reported in Vault</strong>. While there have been issues in adjacent areas before, none previously enabled full command execution on the Vault server.</p>



<h2>Disclosure and response</h2>



<p>At Cyata, we followed a strict responsible disclosure process throughout this research. Every vulnerability was privately reported to HashiCorp with clear documentation, technical detail, and proof-of-concept support.</p>



<p>We worked in close coordination with HashiCorp’s security team to ensure that all issues were understood, addressed, and resolved before any public disclosure – minimizing risk to users and ensuring timely protection.</p>



<p>HashiCorp responded professionally at every stage of the process, engaging constructively and collaborating with us until all findings were fully resolved.</p>



<p>This wasn’t just a technical milestone. It was a deliberate, professional collaboration aimed at protecting the global organizations that rely on Vault.</p>



<p>Disclosure timeline</p>



<ul>
<li><strong>May 18, 2025</strong> – Cyata submitted the initial disclosure to the HashiCorp security team, covering the majority of the findings. Some issues were still under active investigation.</li>



<li><strong>May 23, 2025</strong> – We followed up with the complete list of confirmed vulnerabilities.</li>



<li><strong>May 24, 2025</strong> – HashiCorp responded with additional questions, primarily focused on the certificate impersonation issue.</li>



<li><strong>May 24 (Evening)</strong> – Cyata sent a detailed technical explanation clarifying the impersonation path.</li>



<li><strong>May 25, 2025</strong> – We shared a full proof-of-concept video demonstrating the certificate impersonation attack in action.</li>



<li><strong>June 12, 2025</strong> – HashiCorp acknowledged and accepted all findings, assigning <strong>nine CVEs</strong> across the reported issues.</li>
</ul>



<p><em>Coordinated patching and resolution</em></p>



<p>HashiCorp moved quickly to develop and release patches for both the Open Source and Enterprise versions of Vault. These fixes were made available to users ahead of public disclosure, ensuring organizations could protect their environments immediately.</p>



<p>Further information from the vendor is available in&nbsp;<a href="https://discuss.hashicorp.com/t/hcsec-2025-22-multiple-vulnerabilities-impacting-hashicorp-vault-and-vault-enterprise/76096" target="_blank" rel="noreferrer noopener">this HashiCorp advisory</a>.</p>



<p>This coordinated response is a model for how security research and vendor collaboration should work – transparent, professional, and impact-driven.</p>



<p>At Cyata, we believe meaningful research doesn’t stop at discovery. It must include responsible coordination, resolution, and ultimately, protection for the infrastructure the world depends on.</p>



<h2>Conclusion</h2>



<p>This research reinforces a critical truth – even memory-safe software can fail at the logic level – and when it does, the consequences can be just as severe.</p>



<p>Vault is designed to be the ultimate protector of secrets and infrastructure access. But this work shows how subtle logic bugs in authentication flows, identity resolution, and policy enforcement, can quietly break trust.</p>



<p>And when trust in the vault is broken, the impact is immediate and devastating: attackers can impersonate users, bypass MFA, extract credentials, seize root tokens, and even execute arbitrary commands. With control over Vault, they can hijack internal services, pivot across environments, and hold entire systems hostage, all without triggering conventional alarms.</p>



<p>One of our key takeaways is that vaults must be tested not only against brute-force and interface abuse, but against deep behavioral inconsistencies – edge cases that only emerge when you understand how the system is wired together internally.</p>



<p>Cyata’s research team uncovered these vulnerabilities through manual review, attacker-style reasoning, and persistence. This wasn’t automation. It was a methodical, step-by-step process, reasoning through Vault’s design and asking: where can things go wrong?</p>



<p>The issues uncovered in this research are exceptionally severe, capable of quietly compromising the core layer that organizations rely on to protect everything else.</p>



<p>We believe that research like this is essential – not only to harden individual products, but to help the security community stay one step ahead of attackers.</p>



<p>Because when trust itself is the surface, scrutiny is protection.</p>


<div>
		<p>The Control Plane  for Agentic Identity</p>
					
			</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FDA approves eye drops that fix near vision without glasses (126 pts)]]></title>
            <link>https://newatlas.com/aging/age-related-near-sighted-drops-vizz/</link>
            <guid>44820325</guid>
            <pubDate>Thu, 07 Aug 2025 03:34:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newatlas.com/aging/age-related-near-sighted-drops-vizz/">https://newatlas.com/aging/age-related-near-sighted-drops-vizz/</a>, See on <a href="https://news.ycombinator.com/item?id=44820325">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The first aceclidine-based eye drop to improve near vision in adults with presbyopia, which affects more than 100 million adults in the US alone, has been approved by the Food and Drug Administration (FDA) and will be available within three months.</p><p>Known as VIZZ, from pharmaceutical company LENZ, the drops are an aceclidine ophthalmic solution that effectively treats <a href="https://newatlas.com/medical/vuity-presbyopia-eye-drops/" data-cms-ai="0">presbyopia</a> in adults. The once-daily drops offer relief from blurry near. vision for up to 10 hours.</p><p>"The FDA approval of VIZZ is a defining moment for LENZ and represents a transformative improvement in the available treatment options for the 128 million adults living with blurry near vision in the United States," said Eef Schimmelpennink, President and Chief Executive Officer of LENZ Therapeutics. "This significant milestone is the result of tremendous commitment and collaboration by the LENZ team and our partners, the dedication of our clinical investigators, and the contributions of hundreds of participants in our clinical trials."</p><p>VIZZ works by gently shrinking the pupil of the eye, using aceclidine. This creates a “pinhole effect” – like narrowing a camera lens — which helps bring nearby objects into sharper focus. Unlike older eye drops, this one does not significantly affect the eye’s focusing muscles, so it doesn’t blur your distance vision or cause that “zoomed-in” effect (aka a myopic shift).</p><p>Ultimately, the drops offer improved reading vision for up to 10 hours, without the need for glasses and, importantly, without the side effects of older treatments.</p><p><a href="https://newatlas.com/medical/vuity-presbyopia-eye-drops/" data-cms-ai="0">In 2021, the very first drops to treat this condition were launched</a> to much acclaim, but there's a reason VIZZ drops are considered first-in-class. Vuity (pilocarpine hydrochloride 1.25%) is a dual-action eye drop that can improve near vision but may cause side effects like brow heaviness or rare vitreoretinal issues due to the ciliary muscle activation. Aceclidine, a pupil-selective miotic, works without significantly stimulating the focusing (ciliary) muscle, creating a pinhole effect – which improves near vision without adverse outcomes seen in Vuity.</p><p>"This FDA approval represents a disruptive paradigm shift in treatment options for millions of people who are frustrated and struggling with the inevitable age-related loss of their near vision," said VIZZ clinical investigator Marc Bloomenstein, from Schwartz Laser Eye Care Center in Scottsdale, Arizona. "I believe this will be a welcome solution for both optometrists and ophthalmologists who will now be able to offer a highly effective and sought-after presbyopia treatment that could immediately become the standard of care, with a product profile that will meet our patients’ needs."</p><p>The FDA approval comes on the back of three randomized, double-masked, controlled Phase II studies featuring hundreds of participants. VIZZ was well-tolerated with no serious adverse events observed in the 30,000-plus treatment days across all three trials. </p><p>Presbyopia is, unfortunately, an inevitable condition associated with aging. Almost everyone over the age of 45 experiences this near-sight vision loss, which gradually gets worse and usually requires correction with glasses or contact lenses. While presbyopia is a gradual condition, it can progress quickly and unexpectedly, making formerly simple tasks of day-to-day tasks like reading instructions or food labels more difficult. </p><p>The therapeutics company said VIZZ is expected to be broadly available in the fourth quarter of 2025, making it the first and only FDA-approved aceclidine-based eye drop for presbyopia treatment. </p><p>"This is uniquely engineered, highly-differentiated and designed to deliver quick onset and lasting benefit for the vast majority of presbyopes," said Schimmelpennink. "As we have shown, this is not only best-in-class, but frankly, the only in a class of pupil selective ciliary-sparing myotics."</p><p>The FDA approval comes based on trial data submitted by the pharmaceutical company, so it's worth noting that published peer-reviewed reports are yet to be published. Peer-reviewed publications often follow regulatory approvals, not precede them, which is common in the field of ophthalmology and dermatology.</p><p>However, the FDA data and guidance can be found <a href="https://www.accessdata.fda.gov/drugsatfda_docs/label/2025/218585s000lbl.pdf" target="_blank" data-cms-ai="0">published here</a>.</p><p>Source: <a href="https://ir.lenz-tx.com/news-events/press-releases/detail/39/lenz-therapeutics-announces-us-fda-approval-of-vizz-for-the-treatment-of-presbyopia" target="_blank" data-cms-ai="0">LENZ Therapeutics</a></p></div></div>]]></description>
        </item>
    </channel>
</rss>