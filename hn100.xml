<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 30 Jan 2024 13:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Everyone hates the electronic medical record (163 pts)]]></title>
            <link>https://logicmag.io/policy/why-everyone-hates-the-electronic-medical-record/</link>
            <guid>39186252</guid>
            <pubDate>Tue, 30 Jan 2024 03:59:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://logicmag.io/policy/why-everyone-hates-the-electronic-medical-record/">https://logicmag.io/policy/why-everyone-hates-the-electronic-medical-record/</a>, See on <a href="https://news.ycombinator.com/item?id=39186252">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><i>They tell you that injustice is part of some grand plan. And that’s what keeps you from rising against it.&nbsp;</i></p>
<p><i>—Shehan Karunatilaka,</i> The Seven Moons of Maali Almeida </p>
<p>Patient R was in a hurry. I signed into my computer—or tried to. Recently, IT had us update to a new 14-digit password. Once in, I signed (different password) into the electronic medical record. I had already ordered routine lab tests, but R had new info. I pulled up a menu to add on an additional HIV viral load to capture early infection, which the standard antibody test might miss. R went to the lab to get his blood drawn</p>
<p>My last order did not print to the onsite laboratory. An observant nurse had seen the order and no tube. The patient had left without the viral load being drawn. I called the patient: could he come back?&nbsp;</p>
<p>&nbsp;Healthcare workers do not like the electronic health record (EHR), where they spend more time than with patients. <a href="https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers"><u>Doctors hate it</u></a>, as do <a href="https://pubmed.ncbi.nlm.nih.gov/30220361/"><u>nurse practitioners</u></a>, <a href="https://pubmed.ncbi.nlm.nih.gov/26340247/"><u>nurses</u></a>, <a href="https://www.pharmacypracticenews.com/Pharmacy-Technology-Report/Article/09-23/GROSS-Gives-Input-on-Troublesome-Tech-Issues/71315"><u>pharmacists</u></a>, and <a href="https://rehabpub.com/clinic-management/software/emr-fatigue-3-ways-the-wrong-system-contributes-to-pt-burnout/#:~:text=%E2%80%9CThe%20finding%20that%20the%20odds,burnout%2C%E2%80%9D%20Mayo%20Clinic%20wrote."><u>physical therapists</u></a>. The National Academies of Science, Engineering and Medicine reports the EHR is a <a href="https://www.ncbi.nlm.nih.gov/books/NBK552608/"><u>major contributor</u></a> to clinician burnout. Patient experience is <a href="https://www.kff.org/other/poll-finding/data-note-publics-experiences-with-electronic-health-records/"><u>mixed</u></a>, though the public is <a href="https://www.pewtrusts.org/en/research-and-analysis/issue-briefs/2021/07/most-americans-want-to-share-and-access-more-digital-health-data"><u>still concerned</u></a> about privacy, errors, interoperability and access to their own records.</p>
<p>The EHR promised a lot: better accuracy, streamlined care, and patient-accessible records. In February 2009, the Obama administration <a href="https://www.healthcapital.com/hcc/newsletter/6_09/HITECH.pdf"><u>passed</u></a> the HITECH Act on this promise, investing $36 billion to scale up health information technology. No more deciphering bad handwriting for critical info. Efficiency and cost-savings could get more people into care. We imagined cancer and rare disease registries to research treatments. We wanted portable records accessible in an emergency. We wanted to rapidly identify the spread of highly contagious respiratory illnesses and other public health crises.</p>
<p>Why had the lofty ambition of health information, backed by enormous resources, failed so spectacularly?&nbsp;</p>

<p><b>A history</b>
</p>
<p>Medicine narrates the beginning of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9599146/#:~:text=The%20book%2C%20a%20compilation%20of,including%20physicians'%20recommendations%2C%20descriptions%20of"><u>medical records</u></a> with the 2500 year-old Hippocratic corpus. These books included <a href="https://lithub.com/what-the-worlds-first-medical-records-tell-us-about-ancient-life/"><u>individual patients’</u></a> courses, bearing witness, observing patterns and preserving a teaching library for future generations. This fused with a pedagogical approach that continued with the Romans, evolving into the medical advances of the Islamic Golden Age. Physician and philosopher Ibn Sina left hundreds of medical texts, as did Maimonides, the rabbi and physician in North Africa, that shaped medicine for centuries. Each of these collections had a version of: “Treat the patient, not the disease.”</p>
<p>While medieval Islamic <a href="https://www.nlm.nih.gov/exhibition/islamic_medical/islamic_12.html"><u>hospitals</u></a> operated in the contemporary sense, European hospitals were <a href="https://bookshop.org/p/books/god-s-hotel-a-doctor-a-hospital-and-a-pilgrimage-to-the-heart-of-medicine-victoria-sweet/16598072?ean=9781594486548"><u>God’s hotel</u></a>, almshouses operated by nuns for the ill and poor. The Church <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1694293/"><u>excluded</u></a> women who were usually keepers of those traditions, absorbing the knowledge while <a href="https://www.akpress.org/calibanandthewitch.html"><u>burning</u></a> its practitioners. This effectively consolidated the Church’s authority. The same strategy was deployed in the Church’s colonial reach, extracting knowledge from other civilizations, while subjugating and erasing people. Colonization and military campaigns through the 18th and 19th century also brought back insight from battlefield surgery to the growing cities of Paris, Vienna and Berlin. The almshouses became academic medical centers. The records still held knowledge and teaching: junior surgeons kept detailed notes on patients, passing these notes to the next generation.&nbsp;</p>
<p>The 19th and 20th centuries’ rapid industrialization, urbanization, militarization, colonization, with its related bureaucratic expansion is—well beyond this brief history. Let’s say, it takes a lot of paperwork to run <a href="https://link.springer.com/chapter/10.1007/978-3-658-34003-2_2"><u>empire</u></a> and <a href="https://plato.stanford.edu/entries/weber/"><u>industry</u></a>. A class of administrators grew to meet this need. State regulations also increased, requiring annual reports of hospital admissions, outcomes and expenditures, which meant increased standardization.</p>

<p>Dawn of the Flexner Report&nbsp;
</p>
<p>While medical administration proliferated, so did instruments (stethoscopes, ophthalmoscopes, thermometers) that could “perceive more deeply.” This changed what constituted <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3116347/"><u>medical information</u></a>, shifting focus from interview (emphasis on patient’s testimony) to physical exam (emphasis on the clinician’s observations). The charge was led by the “French School,” especially Jean-Nicolas Corvisart, Napoleon’s personal physician. Later, German physicians argued that we ought to center lab technology, further removing the patient’s authority. Lab findings were more “pure”: a <i>truthier truth.&nbsp;&nbsp;</i></p>
<p>These trends reached apotheosis in the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3178858/"><u>1910 Flexner Report</u></a>, which shapes US medical education to this day. Abraham Flexner was neither a scientist nor a physician. He was an educator, whose early <a href="https://www.loc.gov/item/08030713/">work</a> criticized rigid curricula and over-emphasis on research. This attracted notice from the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3178858/"><u>Hopkins Circle</u></a> (described by a Yale medical professor as a “particularly American…aristocracy of excellence…not defined by one’s origins or wealth, although wealth permitted the group’s recommendations to be successful.”) The group had just recruited William Osler, the Canadian physician fond of pithy aphorisms like “varicose veins are the result of improper selection of grandparents.” Osler continued an ancient framework: “The good physician treats the disease; the great physician treats the patient who has the disease.”&nbsp;</p>
<p>The <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3178858/"><u>Flexner Report</u></a> diverged from Flexner’s earlier work, calling to <i>increase </i>standardization and scientific research in medical education. If Osler carried the tradition of centering the patient, this report was the German academic clinic, where the patient was second to professor. Funding from Carnegie and Rockefeller foundations enabled rapid implementation of this “lab-centered” model. Of 160 MD-conferring institutions in 1904, only 66 stood by 1935. Only two of five Black medical schools remained. The report advised to continue segregation (with ongoing <a href="https://daily.jstor.org/the-1910-report-that-unintentionally-disadvantaged-minority-doctors/"><u>ramifications</u></a>) and limiting physician numbers (scarcity was good business). This reversed the decision to admit women. Meanwhile Harry S. Plummer (a Mayo Clinic founder) urged medical records to mimic business and economic reports, with more graphs, diagrams and lab data.&nbsp;</p>
<p>Fusing scientific methods with clinical care (and funding) did yield powerful 20th century medical “blockbusters”: insulin, surgical techniques, antibiotics, chemotherapy. More data also necessitated more data management, requiring more labor. The electronic record emerged in the 1960s. It required tediously converting paper data into punch cards, but enabled large-scale medical research, economic analysis and administration.&nbsp;
</p>
<p>Patient R could not return. Despite concerning symptoms and possible exposure, he wasn’t concerned with HIV testing. He could not get a psychiatry appointment in the 4 months since moving here and needed meds. The team conferred: we could run the viral test if I canceled another less critical test. Each order I canceled, and each order I entered, printed multiple pages to the lab. The tech gathered, sorted and manually entered revisions into the lab company’s separate computer system. What would have been, years ago, a brief list written on a paper carried to the lab, had become a more baffling and arduous procedure.&nbsp;&nbsp;
</p>
<h6><b>Hope for Change: Scaling the EHR</b></h6>
<p>In 2008, a young president promising hope steps into a global financial meltdown. Barack Obama was a former law professor at the University of Chicago, where he met the behavioral economists Cass Sunstein. That year, Sunstein, with Richard Thaler (eventual Nobel-laureate) published the book <i>Nudge</i>, arguing for a policy framework based on behavioral economics. Instead of heavy-handed regulations, governments should shape the “choice architecture” that individuals face, to favor more rational choices (defined by the economists). Examples: change an “opt out” choice into “opt in” (dispense plastic utensils with takeout only if asked); or rearranging visual layouts (display water more prominently than soda). Sunstein called this “libertarian paternalism.” Instead of resource-intense interventions risking fraught political negotiations, nudging offered politically-neutral, no-cost, minimalist interventions, based on science.&nbsp;</p>
<p>This is a very appealing promise! Obama embraced a <a href="https://newrepublic.com/article/61724/nudge-ocracy"><u>lineage</u></a> of liberal technocrats, confident of a “third way” to preserve free markets <i>and</i> address social needs. Obama brought on Sunstein and Thaler, eventually opening a “Nudge Unit,” helmed by a neuroscientist. Policy would now be informed by psychology, behavioral economics and other “decision sciences.”&nbsp;</p>
<p>Meanwhile, Obama wanted a massive government stimulus to stabilize the economy. This stimulus needed targets. He proposed one such target: “every doctor’s office and hospital in this country is using cutting-edge technology and electronic medical records so that we can cut red tape, prevent medical mistakes and help save billions of dollars each year.” This was a ready-to-go (if underfunded) Bush project. In 2009, the HITECH Act injected vast amounts of money into scaling health information technology.&nbsp;&nbsp;</p>
<p>And they kind of did it! In 2008,<a href="https://www.healthit.gov/data/quickstats/national-trends-hospital-and-physician-adoption-electronic-health-records"><u> only 9%</u></a> of hospitals used an EHR. By 2011, 50% had implemented EHR. Now 96% of hospitals use a federally-certified EHR system. Obama’s vision had accelerated a new era.&nbsp;</p>
<p>So why was everyone complaining? In 2018, Atul Gawande published a piece in <i>The New Yorker </i>called “<a href="https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers"><u>Why Doctors Hate Their Computers</u></a>.” He described what physicians experienced daily with the newly installed EHR at Harvard’s hospitals: redundancy, complexity, wasted time. A hospital administrator responded that this doctor dissatisfaction was irrelevant, the EHR was <i>for</i> patients.&nbsp;</p>
<p>The patients were also experiencing trouble, not least of which was that their clinicians spent visits squinting at screens. KFF Health News <a href="https://kffhealthnews.org/news/death-by-a-thousand-clicks/"><u>reported</u></a> (a decade and $36 billion after the HiTECH Act) a long trail of EHR-related errors resulting in death and serious injury. Medication lists did not update with changed prescriptions. Glitches linked one patient’s medical note to another’s file. Lawsuits were filed for failure to flag critical test results to medical teams, delaying time-sensitive treatment. A central premise of HITECH had been accessible records for patients and families. The administration’s own vice president Joe Biden could not transfer his son’s cancer treatment records from one hospital to another.&nbsp;</p>

<p><img src="https://images.ctfassets.net/e529ilab8frl/5S778EbGJErosGOp3BIsHU/8a0c5408052c27c6089accd913d6937f/tyelonol_options_1_.PNG" alt="tylenol options"></p><p><b>The rushed implementation&nbsp;</b></p>

<p>The goal of a stimulus is to push cash into the economy as quickly as possible. This is not the same goal as building a sensible and sustainable digital infrastructure. With threats and subsidies, the federal government pressured EHR vendors to rapidly meet government certification, then pressured the clinics/hospitals to purchase and implement the product. Rusty Frantz, the CEO of NextGen, confessed to <a href="https://www.fiercehealthcare.com/tech/death-by-1-000-clicks-where-electronic-health-records-went-wrong"><u>KFF</u></a> that “the software wasn’t implemented in a way that supported care, it was installed in a way that supported stimulus.”&nbsp;</p>
<p>Achieving speed is perhaps why, among other shortcuts, software made for billing was commandeered into the more complex EHR functions. In contrast, the Veteran Administration’s (VA) EHR VistA, created in 1983, had developers work directly with clinical staff to prioritize intuitive workflow; it has consistently <a href="https://www.healthcareitnews.com/news/everybody-hates-vista-not-its-users#:~:text=For%20starters%2C%20annual%20Medscape%20EHR,off%2Dthe%2Dshelf%20vendors.&amp;text=VistA%20developers%20who%20wrote%20its,ideal%20system%20would%20look%20like."><u>outranked</u></a> all other EHRs in user satisfaction. Speed is also why interoperability was not prioritized. Consider as a counterexample the global system of ATMs, developed in the 1980s. Achieving interoperability required standardized network elements. This in turn required international political negotiations to agree on shared technical specifications. The American EHR is instead a patchwork of disconnected proprietary systems created by over 700 vendors, what the KFF report called “an electronic bridge to nowhere.” Medical staff, patients and families instead resort to older technology (CD-ROMs, fax, notebooks) to move critical information.&nbsp;</p>
<p>David Blumenthal, a HITECH architect, acknowledged that, in retrospect, it may have been more effective to build interoperability at the start. Then-chief technology officer Aneesh Chopra argued that rushing was necessary, a move-fast-break-things situation to be refined later. So now 96% of the nation’s hospitals are locked into a disjointed, shoddy infrastructure.&nbsp;</p>
<h6><b>Perverse business incentives</b>
</h6>
<p>Healthcare isn’t structured around patient needs; it is a business that prioritizes profit. EHR vendors rushed to claim stimulus money and market share. Economists call this rational, but also <a href="https://en.wikipedia.org/wiki/Perverse_incentive"><u>perverse</u></a>. It has paid off: despite lawsuits, fraud accusations and prosecutions for rushed, error-prone products, EHR is now a $28 billion industry and growing. Financial incentives also shape hospitals and private practices, who lose revenue when patients go to other institutions; there is no financial reward to sharing medical charts, nor the proprietary data entangled in it. Then there is liability. Thousands of patient deaths, injuries and near misses are attributed EHR errors, but this is only what is known. EHR vendors implemented “gag clauses,” on buyers, preventing disclosures of safety issues. Medical institutions allegedly withheld records to cover mistakes as well.</p>
<p>Surely this is fixable? Gawande listed experiments his hospital tried to improve the EHR: time-intensive tailoring of the interface and developing an ecosystem of apps (the hospital and EHR vendor resisted both). The hospital also hired scribes to free up doctors’ time. The American Medical Association has a <a href="https://www.ama-assn.org/practice-management/ama-steps-forward/practice-innovation-strategies-ehr-improvements"><u>toolkit</u></a> of ideas like delegating inbox duties and “getting rid of stupid stuff” (<a href="https://www.nejm.org/doi/full/10.1056/NEJMp1809698"><u>GROSS</u></a>). The most recent solution for interoperability has been the cloud. This replaces the high cost of in-house operations with a subscription. Large hospital systems have begun migrating records into <a href="https://www.healthcareitnews.com/news/mount-sinai-moves-more-epic-workloads-azure-cloud"><u>Microsoft</u></a> and <a href="https://www.fiercehealthcare.com/health-tech/google-epic-ink-deal-migrate-hospital-ehrs-cloud-ramp-use-ai-analytics"><u>Google</u></a><u> subscriptions</u>. These are the companies with the scale, experience, security and analytic capacity to support the massive edifice of medical records. This degree of consolidation raises <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6745146/"><u>another set of</u></a> <a href="https://www.sciencedirect.com/science/article/pii/S2772442523000576"><u>concerns</u></a> about privacy, security and data ownership within an industry already <a href="https://www.statnews.com/2023/07/17/ai-regulation-google-health-epic/"><u>fighting federal </u></a>patient protections, with a <a href="https://www.amnesty.org/en/latest/news/2023/05/us-big-tech-must-be-regulated-to-protect-human-rights-despite-us-supreme-court-decision/"><u>spotty human rights record</u></a>.&nbsp;&nbsp;</p>
<p><b>The Technocratic Veneer on Institutional Problems</b></p>
<p><i>Technology does not bypass labor, it re-organizes it</i>&nbsp;
</p>
<p>By 2017, Obama despaired, “there are still just mountains of paperwork…and the doctors still have to input stuff, and the nurses are spending all their time on all this administrative work...”</p>
<p>There is an illusion that technology automates work—instead it <a href="https://hbr.org/2021/11/automation-doesnt-just-create-or-destroy-jobs-it-transforms-them#:~:text=Technology%20does%20not%20purge%20the,automation's%20better%20days%20%E2%80%94%20were%20shortchanged"><u>only changes it</u></a>. Someone must still tediously punch the cards and maintain them. The hype around novel technology <a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html"><u>inflates its capacity</u></a>, obscuring how it requires an old capitalist foundation: cheap labor. Automation is often used as a threat to <a href="https://www.smithsonianmag.com/history/what-the-luddites-really-fought-against-264412/"><u>drive down wages</u></a> rather than improve conditions. Digitizing healthcare can create well-paid programmers and administrators. It <i>also</i> relies on outsourcing cheaper, invisible, <a href="https://www.amnesty.org/en/latest/news/2016/01/child-labour-behind-smart-phone-and-electric-car-batteries/"><u>less regulated</u></a> labor: mining raw materials, manufacturing, shipping, precarious contractors, and vast armies of <a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html"><u>human intelligence</u></a> to train artificial intelligence. The maps of those labor markets often overlap significantly with the map of former colonies.</p>
<p>Technology is frequently touted as a method for eliminating bureaucracy, yet it just as easily <a href="https://www.sciencedirect.com/science/article/abs/pii/S0016328721001956"><u>enables</u></a> its expansion. <a href="https://www.athenahealth.com/knowledge-hub/practice-management/expert-forum-rise-and-rise-healthcare-administrator"><u>Between 1975-2010</u></a>, the number of physicians grew 150%, same as population; healthcare administrators grew 3200%. Despite that expansion, the EHR still re-routes hidden administrative work back to direct-service labor like physicians, nurses, and pharmacists. Hours once spent with patients are now spent on <a href="https://www.mayoclinicproceedings.org/article/S0025-6196(16)30215-4/fulltext"><u>clerical labor</u></a>. One physician told KFF, “I have yet to see the CEO who, while running a board meeting, takes minutes, and certainly I’ve never heard of a judge who, during the trial, would also be the court stenographer. But in medicine … we’ve asked the physician to move from writing in pen to [entering a computer] record, and it’s a pretty complicated interface.”</p>
<p>This is not mere data entry. Digitizing health records demands significant cognitive labor to<i> translate</i> clinical information. A hospital’s daily 137 terabytes of medical information (messy, unstructured narratives and images, in fluid categories evolved over millennia) must be converted into highly-structured data legible to the EHR. The promise of <a href="https://www.nature.com/articles/s41746-022-00742-2"><u>machine learning and AI</u></a> is premised on this extra labor, taken from patient care and workers’ personal time (physicians take home an average 1-2 hours of extra uncompensated charting). “It’s no secret that healthcare is a data-driven business,” <u>notes</u> a health IT trade magazine. Providers interpret clinical realities into forms that can train “<a href="https://www.sciencedirect.com/science/article/pii/S1532046419302564"><u>data-hungry</u></a>” proprietary algorithms. Rather than decreasing clinician workload, the EHR extracts it.&nbsp;</p>
<p>I go back to my computer to examine why my test order did not go through. I type “HIV” into an order box, which pulls dozens of options. Some are distinct tests (viral load, antibody, genotype) requiring knowledge to choose appropriately. Others are the same orders but for other clinics sharing the EHR: labs for a Texas site pull up for a patient in St. Louis. I skip the search and navigate to a menu of tests exclusive to our site. This brings up two identically-named lab menus in the same column. Expanding one menu sends the lab order to “external interface.” There is a second button: “outside collection.” But to properly order the test, I needed to have clicked the third button, “external interface-outside collection.”&nbsp;</p>
<p>I have worked in many settings. My clinic’s EHR non-sequiturs are not unique. Most institutions are eager to respond to feedback. The order menus now default to the correct button. To improve the EHR I am usually advised to personalize a menu toolbar, generate templates (“dot phrases”) and streamline the interface. If ambitious, I could join a committee to, over weeks, remove duplicate menus. Or, if I want to make it home, I can jerry-rig yet another work-around for the hundreds of inevitable idiosyncrasies.</p>
<p>A front-end investment of time promises eventual efficiency. Seems reasonable! Each EHR, however, is specific to each site, even with the same software. Providers commonly round at multiple hospitals, clinics, nursing facilities, even under one employer, sometimes in the same building. Each facility’s Epic (the dominant EHR) has a distinct interface. Painstakingly built menus, phrases and unique shortcuts developed in one context cannot transfer to another. Orders have different names and codes. Muscle memory is useless. (In contrast, the VA’s 1983 VistA designers, knowing clinicians rotate through services, focused on only two goals: patient care and rapid adaptability). It is time-consuming and none of this is actual patient care.</p>
<p>Adapting the EHR to be more useful is Sisyphean. So is navigating the sheer volume of signal it produces. An ICU clinician receives 7000 passive alerts a day, making it difficult to discern critical signals from noise. American <a href="https://www.beckershospitalreview.com/ehrs/u-s-physicians-notes-4x-as-long-as-those-of-physicians-overseas-3-things-to-know.html"><u>medical notes</u></a> are twice as long as a decade ago, many times longer than notes across the globe, from repetitive cut-and-pastes. The next person must sort through all this to find what’s relevant.&nbsp;</p>
<p>This is no Hippocratic corpus. We have traveled far from the attentive observations meant to bear witness and teach future healers. For most of our workday, we treat neither patient nor disease.&nbsp;</p>
<p>If we resist or slip, the EHR is ready-made<a href="https://pubmed.ncbi.nlm.nih.gov/30821896/"><u> surveillance</u></a>, with swift consequences. In December 2020, deep in a COVID-19 winter surge, I covered my colleague’s patients on a weekend. I ended the 15-hour day by charting, billing and tying loose ends. The next week I received an email, threatening to suspend my privileges. The message opened sternly: “Timely and accurate completion of medical records is essential for quality of care and an important step for patient safety.”&nbsp;</p>
<p>Reader, of course I panicked. Physician-writer Emily Silverman <a href="https://www.nytimes.com/2019/11/01/health/epic-electronic-health-records.html"><u>wrote</u></a>, sure, healthcare workers are “motivated by compassion and a love of medical science, but also a desire for external validation.” Like most people, we do not like to be monitored and berated. Eventually, I found that the system had auto-flagged a pended note draft for a patient I never saw. I create such drafts to abstract info from each chart before rounding. The patient did well and went home before I saw them. There was no patient safety at stake. The EHR sent a polite reminder (among dozens) to my inbox, which I missed. Why would I sign into <i>that </i>hospital’s Epic, when I was now overwhelmed with work in <i>another </i>hospital’s Epic? Amid a global health emergency requiring all hands-on deck, in a hospital that had just run out of ventilators, decked in posters saluting its heroes, I stopped everything to clear my inbox.</p>
<p><i>It is not only the technology increasing labor&nbsp;</i></p>
<p>The EHR and its administrative burden contributes to burnout. There is <i>also</i> more clinical work. Increasing corporatization of medicine and staff shortages have increased the <a href="https://www.ncbi.nlm.nih.gov/books/NBK2657/"><u>volume of patient care</u></a> for each healthcare worker, <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/jan.15690"><u>accelerated</u></a> since the pandemic. In Gawande’s <a href="https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers"><u>report</u></a>, the hospital hired human scribes to document, freeing the doctor’s time to focus on patients. The doctors remained burnt out because the hospital then gave them even more patients. Even when unions are strong, such as with California nurses, hospitals cut non-unionized ancillary staff, effectively increasing the work.&nbsp;</p>
<p>This trend is accelerated by the incursion of private equity, which has<a href="https://kffhealthnews.org/news/article/private-equity-takeover-health-care-cities-specialties"><u> rapidly expanded</u></a> in healthcare. Private equity now has large market shares in anesthesiology, obstetrics, dentistry, radiology, nursing homes, and even <a href="https://kffhealthnews.org/news/article/hospices-private-equity-firms-end-of-life-care/"><u>lucrative end-of-life care</u></a>. Private equity’s central goal is short-term profit, not healthcare. This is achieved through aggressive “efficiencies:” loopholes to increase billing, cutting services, increasing invasive procedures, cutting staff, and employing staff with less training than previously required. This model has generated large profits, while the “perverse incentives” create <a href="https://jamanetwork.com/journals/jama-health-forum/fullarticle/2795946"><u>worse care</u></a>, higher cost, and detriment to workforce infrastructure.&nbsp;</p>
<p>The Obama era’s faith in technological overhaul did not fix a fractured healthcare system that, like all profit-driven enterprises, squeezes labor before margins.&nbsp;</p>
<p><i>Technology matters less than the social determinants for health</i>
</p>
<p>In Akshay Pendyal’s <a href="https://compactmag.com/article/the-soft-tyranny-of-modern-medicine"><u>excellent essay</u></a> about the insidious role of Nudge theory in medicine, he identifies the specific outrageousness of transmuting social failures into individual responsibilities. Rather than address the material insecurity of a patient with congestive heart failure (compelling her to do grueling work in an Amazon warehouse) nudge theory offers “one-weird-trick” suggestions like pill boxes that buzz medication reminders. “Such efforts,” Pendyal remarks, “seem futile at best—and at worst, bordering on cruel.” Nudging misdirects attention from institutions, social structures, and resource distribution, towards correcting individual behavior. We nudge the patient’s obesity, addictions, and noncompliance with doctor’s orders. This focus contradicts a century of medicine’s own rigorous research that medical “blockbuster” treatments matter, but not as much as the <a href="https://health.gov/healthypeople/priority-areas/social-determinants-health"><u>systemic determinants of health</u></a>: housing, material security, safety from violence, community support, public infrastructure and environmental stewardship, that shape things like access to clean water.&nbsp;</p>
<p>Digitizing medical information is useful; but it does not address problems that require redistributing resources, nor bring the people most impacted by policy to the table. That change requires politics. If it’s “perverse incentives”all around, perhaps, as economist Kenneth Arrow argued in 1963, markets <a href="https://web.stanford.edu/~jay/health_class/Readings/Lecture01/arrow.pdf"><u>don’t work</u></a> in this setting.&nbsp;</p>
<p>Effective politically-neutral, no-cost, minimalist interventions are rare. As to based-on-science: nudging and behavioral economics repeatedly evoke <i>science </i>to claim it is beyond politics<i>. </i>Sunstein himself, when running the Office of Information and Regulatory Affairs (where he bragged that he had issued fewer regulations than the Reagan, Bush, Clinton, and W. Bush administrations) insisted on the organization’s apolitical stance because it was scientific, even as it regularly met with lobbyists.&nbsp;</p>
<p>Pendyal observed at a Nudge in Healthcare symposium, the repeated attempts to ground behavior economics, however tenuously, in neurobiology. Like the clinician’s gaze and lab data usurping the patient’s testimony, behavioral economics claims the “truthier truth.” Perhaps this insistence is necessary because the science in question is not good. Behavioral economics and its adjacent fields are undergoing a <a href="https://www.newyorker.com/magazine/2023/10/09/they-studied-dishonesty-was-their-work-a-lie"><u>crisis of replication</u></a>—in which some of the field’s splashiest are accused of, at best, “p-hacking” (massaging the data until something pops out) and at worst, <a href="https://www.ft.com/content/846cc7a5-12ee-4a44-830e-11ad00f224f9"><u>blatant fabrication.</u></a> The ease with which bad science dominated policy may just be the most recent iteration of Max Weber’s observations: these frameworks are less natural science and more rationalizing the ruling class’s methods of disciplining the laboring class.&nbsp;</p>
<p>In Sunstein’s <i>Nudge</i>, you’re stalled by misleading logic before getting to scientific methodology. Sunstein cites highway signs reminding drivers to “click it or ticket!” as a nudge example. However, that “nudge” works because the government deployed command-and-control regulations: requiring auto-manufacturers to include seat belts and people to use them, under threat of fine. Robert Kuttner wryly <a href="https://harpers.org/archive/2014/12/obamas-obama/"><u>noted</u></a> that behavioral economics was initially a <i>critique</i> of neoclassical economics’ “rational” agent. The early rigorous experiments of Kahneman, Thaler and others demonstrated that human beings deviate from this model of “rationality”. In Sunstein’s hands, criticism of economics’ failure to grasp true human behavior becomes instead: a criticism of humans for failing to meet the premises of economics. The markets are working exactly as they ought to, it is the humans that must be corrected.&nbsp;</p>
<p>Those corrections are <a href="https://monoskop.org/images/9/92/Foucault_Michel_The_Birth_of_the_Clinic_1976.pdf"><u>exacted</u></a> on individual bodies, in workplaces, education, prisons, and the clinic: workers are surveilled; medical education is reshaped in the vision of Carnegie and Rockefeller; racial hierarchy is <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9495470/"><u>naturalized</u></a>, including by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10589311/"><u>large language models</u></a>; disabled “unproductive” bodies are crushed; gender roles (and associated care labor) are enforced by withholding reproductive and transgender care.&nbsp;</p>
<p>So why had the lofty ambition of health information failed so spectacularly? It did not fail entirely. It failed us, the workers, patients and public, but it is not <i>for</i> us. Bad EHR technology dominates because it serves enterprise first. Sunstein’s arguments are illogical, disconnected, and founded on preposterous data, but it serves the Obama administration’s <a href="https://newrepublic.com/article/61724/nudge-ocracy"><u>ideology</u></a>. If weak science and bad technology emerge from the marketplace of ideas, it is because the highest bidder is the ruling class. Political will is exerted, but veiled with “science” to insist those in power know what’s best. Meanwhile, individualism means the consequences always fall to those they rule. From the Hopkins Circle to the Chicago School of Economics to the Silicon Valley libertarians: mechanisms of control are cloaked in what social theorist Marco D’eramo <a href="https://newleftreview.org/sidecar/posts/scientific-capitalism"><u>described</u></a> as the “neo-feudalism of a cognitive aristocracy, whereby alleged superiority of knowledge or competence entitles a select few to rule over the ignorant masses.”&nbsp;&nbsp;</p>
<p>Perhaps part of the rage of the rank-and-file healthcare worker crushed by the EHR, is partly because we thought maybe <i>we</i> were among the cognitive aristocracy. Alongside the scientists, social workers, artists, and <a href="https://logicmag.io/clouds/agile-and-the-long-crisis-of-software/"><u>engineers</u></a> of the <a href="https://www.dissentmagazine.org/online_articles/on-the-origins-of-the-professional-managerial-class-an-interview-with-barbara-ehrenreich/"><u>professional managerial class</u></a>, our knowledge and competence was supposed to protect our autonomy, even as our work was deployed to control others. “What has happened to the professional middle class has long since happened to the blue-collar working class,”<a href="https://rosalux.nyc/wp-content/uploads/2021/09/ehrenreich_death_of_a_yuppie_dream90.pdf"><u> observed</u></a> Barbara and John Ehrenreich, “Those of us who have college and higher degrees have proved to be no more indispensable, as a group, to the American capitalist enterprise than those who honed their skills on assembly lines or in warehouses or foundries.”</p>
<p>R’s HIV testing was negative. He remains ill. Because he does not have HIV, we are not funded to find out why. We printed lists of other clinics with long waiting lists. In any case, he had to focus on fighting to keep his housing. Anthropologist David Graeber wrote, “we were constantly being told that work is a virtue in itself—it shapes character or somesuch—but nobody believed that. Most of us felt work was best avoided, that is, unless it benefited others. But of work that did, whether it meant building bridges or emptying bedpans, you could be rightly proud. And there was something else we were definitely proud of: that we were the kind of people who took care of each other.” We, the physicians, nurse practitioners, nurses, medical assistants, case managers, lab technicians could only do what we could do for R, before turning to the long line of other patients. In the end, our inboxes were clear.</p>
<hr>
<p>Medicine did not start with Hippocrates, despite how medicine tells it. Even our ancient cousins the <a href="https://theconversation.com/neanderthals-cared-for-each-other-and-survived-into-old-age-new-research-93110"><u>Neanderthals cared</u></a> for their sick. Healing traditions are fundamental to human survival. Science is the careful observation of patterns, experimentation, and sharing knowledge. Technology, Ursula Le Guin has <a href="https://sentiers.media/notes/rant-about-technology/"><u>argued</u></a>, is how a tool-making species interacts with its material world. Which is to say, these things belong to all of us. There have always been other ways to do things.</p>
<hr>
<p>What does radically improved healthcare look like? Mark Olin Wright once described <a href="https://jacobin.com/2015/12/erik-olin-wright-real-utopias-anticapitalism-democracy/"><u>4 types of anticapitalists</u></a>. Using that framework, we imagine a different healthcare on his four strategies of change.&nbsp;</p>
<p>1. <i>Smashing the existing system.</i> When an existing system is completely intolerable, the ruptures of political revolution show glimpses of radical possibilities. There is no call to smash the healthcare system, but the COVID-19 pandemic may have been the rupture no one asked for. Despite scientific prowess and resources, the pandemic strained the American healthcare system revealing its deep fissures, failures, hypocrisies, and instabilities. The devastating US death rate, inequality and rush to re-open commerce laid bare the state’s priorities. The frightening collapse of even sophisticated health-care infrastructure (such as in <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(19)30344-7/fulltext"><u>Venezuela</u></a>) is not theoretical. Medication, supply, and staff shortages, as well as instability from private equity profiteering, stress the system. Arguably, there is already regional collapse in the rural United States, such as in <a href="https://www.hhs.gov/about/news/2023/05/19/hhs-announces-over-65-million-address-maternal-health-crisis-invest-new-approaches-care.html"><u>obstetrics and maternal health</u></a>. Building on the ashes, however, requires more.&nbsp;</p>
<p>2. <i>Taming the current system</i>. This approach mitigates harm, though not with the non-solutions of nudging or technocratic veneers. Instead, it would require robust, meaningful prioritization of patients, labor, and community. It would mean securing the material infrastructure (housing, racial equity, clean water) that most shape the conditions of human health. This requires political organization, but it has been<a href="https://m.ufcw1500.org/get-educated/what-unions-have-done-for-you"><u> done before</u></a> and is <a href="https://www.nytimes.com/2023/10/08/business/economy/labor-strikes.html"><u>building power</u></a> now. It would require solidarity – physicians would have to stop identifying with capital or the cognitive aristocracy. It requires solidarity among formally-educated colleagues (pharmacists, mid-level practitioners, nurses) <i>and</i> technicians, food prep, custodial, transportation, and home health aids. Healthcare workers would have to join with other <a href="https://www.seiu.org/"><u>service and care workers</u></a> and unpaid care labor who make health possible. It would require coordinating with disability rights activists, community organizers and patient advocates.&nbsp;</p>
<p>3. <i>Escaping the system.</i> It can appear that the system is too large and overwhelming to change, in which case it is tempting to leave it entirely. There are multiple flavors of this:&nbsp; alternative medicine, concierge medicine, and Goop-flavored consumerism. Not everyone can escape of course—individuals or families perhaps, if they have the luck of no serious illness, injury, or disability requiring interdependence, or enough resources to buy the support. As insidious and exclusive as escaping can be, there is still something here. What is at the heart of what a “wellness spa” provides? Leisure, gentle touch, warm water and pleasure. Why should this not be part of what everyone deserves?&nbsp;</p>
<p>4. <i>Erosion. </i>There are always cracks, in which one can build small experiments of alternative care systems. These do not promote the escape of individuals, but of collective care. This is creating and expanding viable alternatives in the ruptures of an intolerable system. In the policed streets of Oakland, the Black Panthers organized not only self-defense squads but also Survival programs. They provided free breakfast for kids, transportation for disabled persons and <a href="https://hyphenmagazine.com/magazine/issue-25-generation-spring-2012/panthers-patients-asian-health-services"><u>free health clinics</u></a>. So too did founders of Clinica de la Raza, Asian Health Services, and Food Not Bombs. The Panthers were threatening enough that J. Edgar Hoover tried to take them out. The threat also pushed Lyndon B Johnson to co-opt those mutual aid programs into the War on Poverty, building a network of federally qualified health centers, which now provides not-for-profit care for over 30 million people.&nbsp;</p>
<p>Would the Panthers have made more radical changes if not suppressed? Yes, but their legacy of radical self-organization demonstrated the viability (and threat) of organizing. So did the <a href="https://www.gmhc.org/history/"><u>Gay Men's Health Crisis</u></a> providing care during the HIV crisis and ACT-UP’s direct action <a href="https://www.npr.org/sections/health-shots/2019/02/09/689924838/how-to-demand-a-medical-breakthrough-lessons-from-the-aids-fight"><u>demanding scientific</u></a> and public health attention. Harm reduction, now a pillar of public health, began as the <a href="https://rumahcemara.or.id/wp-content/uploads/2022/10/Harm-Reduction-as-Anarchist-Practice.pdf"><u>anarchic practice</u></a> of injection drug users risking arrest to distribute clean syringes to avoid infections. Erosion is far more common than institutional technocrats, who savvily adopt and claim the interventions as their own, would admit.&nbsp;</p>

        </div><p>D. Muthulingam is a writer and infectious disease physician in St. Louis, working on an essay collection about infections, migrations, and speculative storytelling.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pub400.com – Your public IBM I 7.5 server (103 pts)]]></title>
            <link>https://pub400.com/</link>
            <guid>39185933</guid>
            <pubDate>Tue, 30 Jan 2024 03:03:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pub400.com/">https://pub400.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39185933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="100%">
 <tbody><tr>
 <td>

<div>
 <header>
 <h2>Welcome to PUB400</h2>
 </header>
 <div>
 <ul>
 <li>A free and public Server running <a href="http://en.wikipedia.org/wiki/IBM_i" target="_WIKI">IBM i 7.5</a> for everyone</li>
 <li>You can create your own user profile, you have 500MB of disk storage and two private libraries</li>
 <li>You can program in CL, RPG, SQL, COBOL, train your skills and start learning about the best server operating system ever :)</li>
 <li>Create your own programming projects, you can even use node.js or other web technologies (contact us for http settings)</li>
 <li>An average of 25 new users per day! Great IBM i community!</li>
 </ul>
 </div>
</div>
</td>

<td>
&nbsp;
</td>
<td>
 <div>
 <header>
 <h2>PUB400 community rules</h2>
 </header>
 <div>
 <ul>
 <li>Anyone can create a user profile (see below)<br>Do not create multiple users or try to run commercial environments</li>
 <li>There will be a hard restriction on number of connections from a single IP</li>
 <li>There will be a hard setting on excluding other users from a user library</li>
 <li>There will be no regular backup, and there will be no guarantee that this system is online if you need it</li>
 <li>This system is a playground. But it will not be a place to make business without the efforts...</li>
 </ul>
 </div>
 </div>
</td>
</tr>
</tbody></div><p>
PUB400.COM serves  the IBM i community for almost 23 years, starting
in year 2000 as a little test system.
Now it is serving more than 40.000 Users worldwide as a learning and testing environment to get in touch with the
most advanced business operating system "IBM i" (named "AS/400" and "iSeries" before).
IBM i is <i>the leading</i> integrative platform for managing and running business oriented workload
combining legacy software with modern open source techniques. It's just up to you - IBM i will handle it.
</p><p>
<b>NOTE:</b>&nbsp;Love PUB400? Nominate Holger Scherer (hs at rzkh.de)
a Community Champion at
<a href="https://www.ibm.com/community/ibm-champion-nominate/" target="_VOTE">IBM Champions</a>
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing withdraws bid for safety exemption for Boeing 737 MAX 7 (206 pts)]]></title>
            <link>https://www.reuters.com/business/aerospace-defense/boeing-withdraws-bid-safety-exemption-boeing-737-max-7-2024-01-30/</link>
            <guid>39185895</guid>
            <pubDate>Tue, 30 Jan 2024 02:57:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/business/aerospace-defense/boeing-withdraws-bid-safety-exemption-boeing-737-max-7-2024-01-30/">https://www.reuters.com/business/aerospace-defense/boeing-withdraws-bid-safety-exemption-boeing-737-max-7-2024-01-30/</a>, See on <a href="https://news.ycombinator.com/item?id=39185895">Hacker News</a></p>
Couldn't get https://www.reuters.com/business/aerospace-defense/boeing-withdraws-bid-safety-exemption-boeing-737-max-7-2024-01-30/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Dracula Theme for Hacker News (121 pts)]]></title>
            <link>https://draculatheme.com/hacker-news</link>
            <guid>39185403</guid>
            <pubDate>Tue, 30 Jan 2024 01:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://draculatheme.com/hacker-news">https://draculatheme.com/hacker-news</a>, See on <a href="https://news.ycombinator.com/item?id=39185403">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img alt="Dracula Icon" fetchpriority="high" width="192" height="192" decoding="async" data-nimg="1" src="https://draculatheme.com/icons/used/pack-8/021-satellite.svg"></p><div><p><span>Dracula Theme for Hacker News</span></p></div></div><div><div><p><img alt="hacker-news - Theme Preview" loading="lazy" width="500" height="500" decoding="async" data-nimg="1" srcset="https://draculatheme.com/_next/image?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdracula%2Fhacker-news%2Fmaster%2Fscreenshot.png&amp;w=640&amp;q=100 1x, https://draculatheme.com/_next/image?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdracula%2Fhacker-news%2Fmaster%2Fscreenshot.png&amp;w=1080&amp;q=100 2x" src="https://draculatheme.com/_next/image?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdracula%2Fhacker-news%2Fmaster%2Fscreenshot.png&amp;w=1080&amp;q=100"></p><div><h3><a href="https://news.ycombinator.com/">Hacker News</a></h3>
<h4>Install using browser extesion</h4>
<ul>
<li>
<p>Install Stylus for <a href="https://chrome.google.com/webstore/detail/stylus/clngdbkpkpeebahjckkjfobafhncgmne">Chrome</a>, <a href="https://addons.mozilla.org/pt-BR/firefox/addon/styl-us/">Firefox</a> or <a href="https://addons.opera.com/pt-br/extensions/details/stylus/">Opera</a></p>
</li>
<li>
<p><a href="https://github.com/dracula/hacker-news/raw/main/dracula.user.css">Click here to intall Dracula for Hacker News</a></p>
</li>
<li>
<p>Once installed, it will replace the default theme for Dracula!</p>
</li>
</ul>
<h4>Install using Git</h4>
<p>If you are a git user, you can install the theme and keep up to date by cloning the repo:</p>
<pre><code>git clone https://github.com/dracula/hacker-news.git
</code></pre>
<h4>Install manually</h4>
<p>You can find a link to the css that you'll need to manually inject on Stylus <a href="https://github.com/dracula/hacker-news/blob/main/dracula.user.css">here</a>.</p></div></div><div id="newsletter"><article><p><span>Join the dark side</span><span>Be the first to know about new products, special releases, and much more.</span></p><span><em>7,449</em> people enjoy it!</span><p>Subscribe to the<!-- --> <a target="_blank" href="https://draculatheme.com/rss.xml"><span>RSS Feed</span></a>.</p></article></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers have found a faster way to do integer linear programming (365 pts)]]></title>
            <link>https://www.quantamagazine.org/researchers-approach-new-speed-limit-for-seminal-problem-20240129/</link>
            <guid>39185198</guid>
            <pubDate>Tue, 30 Jan 2024 01:19:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/researchers-approach-new-speed-limit-for-seminal-problem-20240129/">https://www.quantamagazine.org/researchers-approach-new-speed-limit-for-seminal-problem-20240129/</a>, See on <a href="https://news.ycombinator.com/item?id=39185198">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>That’s not to say it’s easy work. It wasn’t until 1983 that the mathematician <a href="https://www.universiteitleiden.nl/en/staffmembers/hendrik-lenstra#tab-1">Hendrik Lenstra</a> <a href="https://www.jstor.org/stable/3689168">proved</a> that the general problem was even solvable, providing the first algorithm that could do it. Lenstra thought about ILP geometrically. First, he turned the inequalities at the heart of ILP into a convex shape, such as any regular polygon. This shape represents the constraints of the individual problem you’re solving, whether it’s couch production or airline scheduling, so the shape’s interior corresponds to all possible values that could solve the inequalities, and thus the problem. Lenstra called this shape the convex body. The problem’s dimension influences the dimension of this shape: With two variables it takes the form of a flat polygon; in three dimensions it is a <a href="https://www.quantamagazine.org/digital-alchemist-sharon-glotzer-seeks-rules-of-emergence-20170308/">Platonic solid</a>, and so on.</p>
<p>Lenstra next imagined all the integers as an infinite set of grid points, known in mathematics as a lattice. A two-dimensional version looks like a sea of dots, and in three dimensions it looks like the points where steel beams in a building connect. The dimension of the lattice also depends on the dimension of a given problem.</p>
<p>To solve a given ILP problem, Lenstra showed that you just look for where the possible solutions meet the set of integers: at the intersection of the convex body and the lattice. And he came up with an algorithm that could search this space exhaustively — but to be effective, it sometimes had to break the problem up into pieces of smaller dimensions, adding many steps to the runtime.</p>

<p>In the following years, several researchers explored how to make this algorithm run faster. In 1988, Ravi Kannan and László Lovász introduced a concept called the covering radius, <a href="https://link.springer.com/article/10.1007/s00037-005-0193-y">borrowed</a> from the study of <a href="https://www.quantamagazine.org/tag/error-correction">error-correcting codes</a>, to help the convex body and lattice intersect more efficiently. Roughly, the covering radius makes sure that the convex body always contains at least one integer point, no matter where you place it on the lattice. As a result, the size of the covering radius also determines how efficiently you can solve the ILP problem.</p>
<p>So it all came down to determining the size of the ideal covering radius. Unfortunately, this proved to be a hard problem on its own, and the best Kannan and Lovász could do was narrow down a possible value by searching for upper and lower bounds. They showed that the upper bound — the maximum size of the covering radius — scaled up linearly with the dimension<em>.</em> This was pretty fast, but not enough to significantly speed up the ILP runtime. Over the next 30 years, other researchers could only do slightly better.</p>
<p>What ultimately helped Reis and Rothvoss break through was an unrelated mathematical result that focused purely on lattices. In 2016, Oded Regev and Stephens-Davidowitz <a href="https://arxiv.org/abs/1611.05979">showed</a>, in effect, how many lattice points could fit within a specific shape. Reis and Rothvoss applied this to other shapes, which allowed them to better estimate the number of lattice points contained in an ILP covering radius, lowering the upper bound. “The latest breakthrough came with the realization that you can actually do other kinds of shapes,” Regev said.</p>
<p>This new tightened upper bound was a vast improvement, allowing Reis and Rothvoss to achieve a dramatic speedup of the overall ILP algorithm. Their work brings the runtime to (log <em>n</em>)<em><sup>O</sup></em><sup>(<em>n</em>)</sup>, where <em>n</em> is the number of variables and <em>O(n)</em>means it scales linearly with <em>n</em>. (This expression is considered “almost” the same as the run time of the binary problem.)</p>

<p>“It’s a triumph at the intersection of math, computer science and geometry,” said <a href="https://www.cwi.nl/en/people/daniel-dadush/">Daniel Dadush</a> of the national research institute CWI in the Netherlands, who helped pioneer the algorithm Reis and Rothvoss used to measure the ILP runtime.</p>
<p>For now, the new algorithm hasn’t actually been used to solve any logistical problems, since it would take too much work updating today’s programs to make use of it. But for Rothvoss, that’s beside the point. “It’s about the theoretical understanding of a problem that has fundamental applications,” he said.</p>
<p><span>As to whether the computational efficiency of ILP could be further improved, researchers are still hopeful that they’ll keep approaching the ideal runtime — but not anytime soon. “That would require a fundamentally new idea,” Vempala said.</span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to do things if you're not that smart and don't have any talent (214 pts)]]></title>
            <link>https://adaobi.substack.com/p/how-to-do-things-if-youre-not-that</link>
            <guid>39183968</guid>
            <pubDate>Mon, 29 Jan 2024 23:01:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adaobi.substack.com/p/how-to-do-things-if-youre-not-that">https://adaobi.substack.com/p/how-to-do-things-if-youre-not-that</a>, See on <a href="https://news.ycombinator.com/item?id=39183968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg" width="1456" height="2184" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2184,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Picasso's Blue Period - Wikipedia&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="Picasso's Blue Period - Wikipedia" title="Picasso's Blue Period - Wikipedia" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab0d438b-7d70-41cd-9506-07c3072b5ea2_3648x5472.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>This is a blog post aimed at people who want to do important work or make meaningful contributions to work, but feel they aren’t that smart and don’t have any talent.&nbsp;</p><ul><li><p><strong>Be audacious.</strong><span> Most people who are talented or smart are scared of doing things. I’m not sure why that is, but it’s more often than not the case. The ability to do scary things on their behalf is extremely powerful, both in terms of advancing the goal/project and also getting them to better utilize their talents.&nbsp;</span></p></li></ul><blockquote><p>For example, you will find that a lot of talented or intelligent people are scared of cold emailing or just do a really bad job at it. Offer to do this work for them, and by offer I mean just do it. Send the cold email, get the response and then tell them about it*. They will be really impressed and have an incentive to get the ball rolling on said project. They might end up so impressed that they also stretch the initial goal of the project!</p><p>A by-product of this skill is that you may start to feel like a little bit of an imposter because the work doesn’t feel hard, and therefore you’ll assume it is not valuable in the grand sheme of things. This is not true. By being audacious on these peoples behalf you will make them, and therefore the work you both do together, a reality. Talented and smart people tend to have the technical ability to do work, but often lack the courage or audacity to actually do it. Pushing them to make it a reality is a very big deal, so don’t underestimate that.</p></blockquote><ul><li><p><strong>Do grunt work. </strong><span>Most people do not like doing grunt work. More often than not people want to be doing “creative” work, such as discovering or creating new things. Fortunately for you, this is your opportunity to shine. Become someone who loves grunt work. Most times the work is not that complicated, it’s just laborious, repetitive, and not that intellectually challenging, but it is important. Learn to genuinely love it and do it for the team or project. People will appreciate you.</span></p></li></ul><ul><li><p><strong>Do the boring things. </strong><span>Similar to grunt work, there will always be boring work to do. Learn to love it &amp; do it! This is an especially good area to work in if you aren’t so smart or talented because people will show you more grace &amp; patience to get up to skill (purely because they don’t want to do it themselves).</span></p></li></ul><ul><li><p><strong>Learn undefined skills</strong><span>. Learn skills that have not yet been professionalized or established. A really good example of this is learning to code with AI.&nbsp;</span></p></li></ul><blockquote><p>For example, most people don’t actually know how to use AI to code up real products, especially if they don’t know how to code. There is no proven course or guide written to do this either so its even harder to do, which is what makes this a great opportunity for you to shine. If you teach yourself how to do so you are not only in a unique position to set the standard for other people to learn (write, write, write about what you have learnt!) but you also get to apply this skill set on behalf of super smart or talented people who most likely wouldn’t have done so due to lack of time, skepticism or both. Again, do and show the results, rather than seek permission first to avoid discouragement (if the stakes are low enough).</p></blockquote><ul><li><p><strong>Work hard. </strong><span>If you are not that smart or talented it’ll often take you more time on average to complete a task. And that’s okay. Just be aware of this and put in the extra time and effort to not only produce at a good pace but produce above standard. Again, most smart or talented people can produce above standard with much less effort than you. But sometimes they don’t do so because they don’t see a clear reward at the end. Try to counteract this and put in the extra effort. It might not always lead to a super fantastic outcome, but you significantly increase your chances of bumping into such an outcome if you do.</span></p></li></ul><ul><li><p><strong>Bring a sense of urgency &amp; move fast.</strong><span> If you think about it, most deadlines are arbitrary, and smart &amp; talented people know this. They will still work to the deadline but they may not feel a real sense of urgency to move faster. Try to counteract this energy. I’m not sure why but moving faster increases the likelihood that work will actually get done, and also opens you up (and therefore the team) up to a lot more opportunities along the way. Most likely because you are “prepared” when you meet luck, or something along those lines. Anyways.</span></p></li></ul><p>Tiny things you can do to bring a sense of urgency and move fast:</p><ul><li><p>Don’t let things be scheduled to be discussed in the next meeting. Push to get it sorted now, even if it is just a make-do v1 solution.</p></li><li><p>If you can get something done faster, or produce more per unit of time, then do it. Don’t look for a reason to do so first. Sometimes this is of no benefit, but often this sets you up to take advantage of an unknown opportunity (in the future) a lot quicker.</p></li><li><p>Keep things stupid simple &amp; focused. As I have mentioned before, smart and talented people often want to do creative work, that involves inventing or discovering. Because of that, they will naturally be driven to complex work and shiny new ideas. Your job, should you choose to accept, is to keep things simple and focused. To make sure you (they) are always moving one leg in front of the other so that shit is actually getting done at a fast pace. Otherwise, you will find that you have moved in every direction apart from forward, which leads to a lack of progress =&gt; lack of momentum =&gt; low motivation, and eventually death of the project.&nbsp;</p></li></ul><ul><li><p><strong>Improve things. </strong><span>Similar to boring work, a lot of times what it takes to improve things is just a lot of boring grunt work e.g. optimizing incubation times of an antibody, tweaking marketing email times, etc. Boring but impactful work. Learn to love it and then do it without asking. This doesn’t need to just be your own work, but the work of others too.</span></p></li></ul><ul><li><p><strong>Ask your naive questions.</strong><span> If you aren’t that smart or talented, you will find that you will have a lot of “noob” questions, that’s okay. In fact, it is kind of a superpower. Ask them! Especially if you are entering a new field, take note of these questions before you become entrenched in current knowledge. These questions may just probe you or your teammate to question dogma that may not be so true in your project’s case. More importantly, on occasion, you will bring forth questions that other people have but are too afraid to ask due to fear of being seen as not smart or talented. Sometimes the emperor has no clothes, so don’t be afraid to say something!</span></p></li></ul><blockquote><p>Now I will warn you, it is uncomfortable doing so. You may be made to feel silly for asking, and may even receive push back for asking. Don’t get defensive in these situations. If you have a simple, low stakes** way of testing out your hypothesis / answering your question then just do it and report the results later. Avoid asking permission.</p></blockquote><ul><li><p><strong>Simplify things. </strong><span>I have mentioned this skill a lot, but it’s a pretty awesome skill to have and one that you probably already have. Simplifying things does not only apply to communication. It could be a development process, operational process, the project itself, etc. There is usually always some sort of benefit that comes from being able to simplify things.</span></p></li></ul><ul><li><p><strong>Follow up. </strong><span>Most people are super sensitive to being seen as annoying, and that’s the primary reason they don’t follow up and therefore watch opportunities go down the drain. Super simple solution, follow up! Most people just forget to respond, haven’t prioritized your request, or something else along those lines. But don’t just follow up, make it easy for the other participant to act on this too. For example, if you are following up on a due-to-be-scheduled meeting with someone, offer multiple specific times (including “now”), offer to meet them where they are (if possible), and send them light talking points so that they know the meeting won’t be a waste of their time. This will make it a lot easier for them to want to accept and actually turn up.</span></p></li></ul><ul><li><p><strong>Show up during the hard times. </strong><span>Every piece of work experiences hard times, the same goes for people. Sometimes the project isn’t going to plan or something majorly bad is happening in your personal life. It’ll be tough but your job here is to simply keep going. It will be hard, and you will have legitimate reasons to take it easy, but try not to use them (within reason) and keep going. People remember and count on people who pushed through hard times to make things work. You will also surprise yourself at the end of it all and have proof that you can get through things of certain difficulty if push comes to shove.</span></p></li></ul><ul><li><p><strong>Figure out the first step. </strong><span>Most people can achieve more than they think they are capable of, but they often get intimated by ideas and just “don’t know where to start”. Make that your job and become very good at it. Learn how to figure out the first step of any idea and get the ball rolling. Often times you can usually find a cheap, low-stakes, simple way of getting started. The point is to build momentum. Momentum =&gt; morale =&gt; shit getting done! You may not have the technical skills to execute things super well, and that’s okay. That’s the job of the super smart and talented people. Your job is to get them off their asses and make them realize that progress is possible.</span></p></li></ul><ul><li><p><strong>Finish things. </strong><span>Probably the most important thing after being audacious. Most people don’t finish things. They either get distracted, don’t have the motivation to or get stuck. Learn to finish things, it’s a big deal. It’s proof of work and of your idea (actions speak louder than words and all that). To do so requires a combination of all the previously mentioned skills, and probably even more skills that I haven't mentioned. I don’t have that many practical tips to share here as it’s a skill I’m still developing. But once I feel I have more insight I will share it either here or in a separate blog post.&nbsp;&nbsp;</span></p></li></ul><p>*Do not make the mistake of seeking their permission first, they will say “no, let’s wait until x” (and x will never come), or they will find ways to demoralize you from doing so (it’s nothing personal)</p><p>** There is usually always a simple, low-stakes way of doing something.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The first human received an implant from Neuralink yesterday (126 pts)]]></title>
            <link>https://twitter.com/elonmusk/status/1752098683024220632</link>
            <guid>39183888</guid>
            <pubDate>Mon, 29 Jan 2024 22:52:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/elonmusk/status/1752098683024220632">https://twitter.com/elonmusk/status/1752098683024220632</a>, See on <a href="https://news.ycombinator.com/item?id=39183888">Hacker News</a></p>
Couldn't get https://twitter.com/elonmusk/status/1752098683024220632: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[An Introduction to the WARC File (161 pts)]]></title>
            <link>https://archive-it.org/post/the-stack-warc-file/</link>
            <guid>39183670</guid>
            <pubDate>Mon, 29 Jan 2024 22:31:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archive-it.org/post/the-stack-warc-file/">https://archive-it.org/post/the-stack-warc-file/</a>, See on <a href="https://news.ycombinator.com/item?id=39183670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wordpressEmbed" role="main">
        <article id="post-6009">
            
            <h3>April 1st, 2021</h3>
            
<p>by Karl-Rainer Blumenthal, Web Archivist for Archive-It</p>



<p><i>Want to know more about a tool in our web archiving toolbox? Your suggestions or questions for future <strong><a href="https://archive-it.org/blog/category/technology/">posts about Archive-It technology</a> </strong>are very welcome <a href="https://support.archive-it.org/hc/en-us/community/posts/360074355111-The-stack-A-new-blog-series-about-web-archiving-technology" target="_blank" rel="noreferrer noopener"><strong>here</strong></a>.</i></p>







<p>It’s a digital preservation mantra: lots of copies keeps stuff safe (LOCKSS). And web archiving is a useful example — when sites change or disappear from the web, web archivists around the world have copies at the ready to maintain access to vital information resources. The foundation of this promise is the WARC file, a global standard for containing all of the data that we need in order to make web archives possible.&nbsp;</p>



<p>But what do we know about that WARC? It has been developed much more slowly than the technologies that collect and replay its contents. (After more than ten years, its specification is still in version 1.1). This pace befits a long-term archival container for material that is exposed to such notoriously rapid change on the live web, so we might be excused for not thinking too much about the digital box into which we shelve all these materials.</p>



<p>But to preserve and manage them in the longest term, it helps to know what WARCs are and are <i>not</i>–what they can and cannot do for future users of web archives. For an introduction to this important digital preservation standard and a peek into its contents, watch the <i>Archive-It Advanced Training</i> series webinar or continue reading below:</p>







<p>
<!-- iframe plugin v.4.5 wordpress.org/plugins/iframe/ -->
<iframe src="//archive.org/embed/introduction-to-the-warc" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen="" height="315" width="560" scrolling="yes"></iframe>
</p>







<h2>What is a WARC file?</h2>



<p><strong>A WARC (Web ARChive) is a container file standard for storing web content in its original context, maintained by the International Internet Preservation Consortium (IIPC).</strong>&nbsp;</p>



<p>Let’s unpack what this means. A WARC is…</p>



<ol><li>a digital file that you can store on your own local or networked storage, like a PDF document or an MP3 audio file, complete its own <strong>.warc</strong> file extension and <strong>application/warc</strong> <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Media_type" target="_blank"><strong>mimetype</strong></a>.</li><li>a <i>container file</i> that houses <i>other</i> files. It concatenates several files into one digital object, like you’ve seen elsewhere from container formats like <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/ZIP_(file_format)" target="_blank"><strong>ZIP</strong></a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Gzip" target="_blank"><strong>GZIP</strong></a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Tar_(computing)" target="_blank"><strong>TAR</strong></a>, or <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/RAR_(file_format)" target="_blank"><strong>RAR</strong></a>. A WARC wraps around other files like the PDF and MP3 above, along with some additional information and formatting that we’ll cover below.</li><li>a container for files that are <i>native to the web</i>. WARCs are produced by crawlers, proxies, and other utilities that retrieve files from a live web server. They can contain the PDF and MP3 files described above, for instance, but also the HTML, JS, CSS, and other structural elements that web browsers need to read in order to represent site contents to human computer users.</li><li>a container that can also <i>contextualize</i> those contents. WARCs contain technical and provenance metadata about the collection and arrangement of their media so sites can be read and represented in live web browsing experiences like they were at the time of their collection.</li><li>a <i>standard</i> container format. The WARC file format standard was published by the International Organization for Standardization (ISO) committee on technical interoperability as <strong><a rel="noreferrer noopener" href="https://www.iso.org/standard/68004.html" target="_blank">ISO 28500</a></strong>. You might get other outputs from web scraping tools, but WARC is <i>the</i> generally agreed-upon way to contain web archives such that people and their software know how to interpret and read the contents today and into the future.</li><li>a standard maintained <i>by web archivists</i>. Keeping up the WARC file format standard is the responsibility of the<strong> <a href="https://archive-it.org/home/IIPC">International Internet Preservation Consortium (IIPC)</a></strong>. This coalition of practitioners does the ‘agreeing upon’ above, that keeps the WARC relevant and vital to how we collect and preserve web archives.</li></ol>







<h2>A (very!) brief history</h2>



<p>The WARC was preceded by the ARC file format, which the Internet Archive used to contain its collected web archives as far back as 1996. If your organization has ever used the <a href="https://archive-it.org/blog/post/waybackfill-service-announcement/"><strong>Waybackfill Service</strong></a> or if it started crawling with Archive-It before 2009, then you still have these files in your own collections to this day as well.&nbsp;</p>



<p><a href="https://wayback.archive-it.org/193/20050922044914/http://www.sdarts.org/folkarts/st__pierre.htm"><img decoding="async" src="https://archive-it.org/blog/files/2021/04/SD-Wayback.png" alt="Screenshot of a web capture made in the ARC format, from the South Dakota State Archives and State Library's 'State Agencies' collection"></a></p>



<p><i><a href="https://wayback.archive-it.org/193/20050922044914/http://www.sdarts.org/folkarts/st__pierre.htm">A capture</a> from one of the first ARC files created by an Archive-It partner, the South Dakota State Archives and State Library. <a href="https://artssouthdakota.org/folkarts/st__pierre.htm" target="_blank" rel="noopener">The original page</a> is now offline. </i></p>







<p>The ARC file was the Internet Archive’s original container file for web-native resources, so it conformed to the first three bullet points in the definition above. Reflecting the needs of web archivists around the world to preserve more context about their collected resources, the WARC standard was formalized in 2009 to include the very detailed kinds of technical metadata that we’ll explore below.&nbsp;&nbsp;</p>



<p>Much specificity and readability was added to the WARC standard for its 2017 upgrade to version 1.1. Thanks to the IIPC and the National Library of France (BnF), you can also access it outside of the ISO paywall now. IIPC maintains a version-controlled copy for markup <a rel="noreferrer noopener" href="https://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.1/" target="_blank"><strong>here on Github</strong></a> and BnF’s bibum file format index houses <strong><a rel="noreferrer noopener" href="http://bibnum.bnf.fr/WARC/" target="_blank">PDF and DOC copies here</a></strong>.&nbsp;</p>



<p>The WARC file format has since been added to the UK National Archives’ PRONOM registry as <a rel="noreferrer noopener" href="https://www.nationalarchives.gov.uk/pronom/fmt/289" target="_blank"><strong>fmt/289</strong></a> and to the Library of Congress’s list of described formats for sustainability <strong><a rel="noreferrer noopener" href="https://www.loc.gov/preservation/digital/formats/fdd/fdd000236.shtml" target="_blank">here</a></strong>.</p>







<h2>A look inside </h2>



<p>The WARC file includes metadata about its creation and contents, records of server requests and responses, and each server response’s full payload. In other words, the WARC file records everything that was done in order to record the transfer of information from a web server to its reader (like a web crawler or you at your browser). It includes the intended contents of that transfer too of course, but also some useful clues about how we can piece them back together later.</p>







<p><img decoding="async" src="https://archive-it.org/blog/files/2021/04/warc-schematic.png" alt="Diagram of WARC record types in the WARC file"></p>







<p>It does this in eight distinct pieces, each with its own meaning and metadata attributes. Each of these is called a <i>WARC record</i>. To get to know them, take any WARC from your collections or <strong><a rel="noreferrer noopener" href="https://archive.org/details/sample-warc-file" target="_blank">this sample file</a></strong> of <a rel="noreferrer noopener" href="https://web.archive.org/web/20200319185556/https://netpreserveblog.wordpress.com/2020/02/13/cdg-collection-novel-coronavirus/" target="_blank"><strong>an IIPC blog post</strong></a>, open it in your favorite text editor, and look for the following in the “WARC-Type” field, starting right at the top of the file:</p>







<p><img decoding="async" src="https://archive-it.org/blog/files/2021/04/warcinfo.png" alt="Screenshot of the warcinfo record at the beginning of a WARC file"></p>







<ul><li><strong>warcinfo</strong>: This record identifies the file as a WARC. It tells us a little bit about how and when it was created, who created it, and–in the case of Archive-It–the collection to which it belongs. It tells us precisely when this acquisition occurred, the software that was used to do so, and even the location and host machine that did the work, all of which is good provenance information for the future.<br>&nbsp;&nbsp;</li><li><strong>request</strong>: Archive-It’s collecting tools must request each webpage, downloadable document, etc., from its original, live web server. This request starts with a metadata header, which includes information about the request, the requester, and how to deliver the relevant contents to them. Under the header we see the precise request as the server received it, so that it’s documented and preserved.</li><li><strong>response</strong>: Subsequently, the live server’s response to this request is also written into the WARC as well. Again, it begins with header metadata to contextualize it individually; the header tells us that it is a unique response to a request for a specific document at a specific time, using a specific communication method. And again, the header is followed by the original content of that delivery–the original file or code from the web that we might want to reproduce in a web browser.</li></ul>







<p>With the above alone, we can use a rendering software (like Wayback) to request a document from the WARC, to get this same response that was generated at collection time, and to read the same HTML or load the same image in a web browser.&nbsp;</p>



<p>You will however also find two additional record types among most WARCs created by Archive-It, and which reflect some of the service’s helpful efficiencies:</p>



<ul><li><strong>revisit</strong>: This record describes the response to a request for material that has already been archived, which hasn’t changed, and which Archive-It subsequently de-duplicates. By matching known checksum values in a collection, our tools can instead write a reference to an existing response record and where to find it when necessary for replay.&nbsp;</li><li><strong>resource:</strong> This record is created by the web archiving process, to capture and describe material related to an archived resource, but which might not have a discrete URL of its own. Archive-It does this most often to capture two types of resources: the screenshots and thumbnails of web pages that <a href="https://archive-it.org/blog/post/the-stack-brozzler/"><strong>Brozzler</strong></a> creates automatically for future reference; and the videos that are retrieved by <a href="https://archive-it.org/blog/post/the-stack-youtube-dl-guide/"><strong>youtube-dl</strong></a> instead of either Brozzler or the “standard” Archive-It crawling stack.&nbsp;</li></ul>







<p>These are the building blocks of any web archive created with Archive-It’s tools. However, the WARC specification also allows for two types of records that are not known to be implemented anywhere at the time of writing, but which speak to the management and preservation of web archives:</p>



<ul><li><strong>conversion:</strong> This record holds space for the eventual migration of archived web materials into successor formats if and when that need arises. An HTML5 record could for instance appear here in order to augment or improve access to content that was collected in the deprecated Adobe Flash format.</li><li><strong>continuation</strong>: This record would enable a rendering software to read and represent an archived document across two separate records if need be. It is based on the premise that the process of writing a record’s content into a WARC file could be interrupted, and that the process could therefore be ‘continued’ in a subsequent record, just picking right up where it left off at the next line.&nbsp;&nbsp;</li></ul>







<p>And finally:</p>



<ul><li><strong>metadata:</strong> Many WARC files, including Archive-It’s, include a list of records at the bottom that can further describe the contents of the above records, so that we can better understand why they were created or what they looked like at that time. They can provide the most basic record of what we call the <a rel="noreferrer noopener" href="https://support.archive-it.org/hc/en-us/articles/360023045811" target="_blank"><strong>“scope”</strong></a> of an Archive-It web crawl on a record-by-record basis. For example, a metadata record for an embedded resource like an image or video might describe how the collecting tool identified it as “in-scope” and subsequently archived it.&nbsp;</li></ul>







<p>That’s the gist! But you can always read <strong><a rel="noreferrer noopener" href="https://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.1/" target="_blank">the IIPC’s extensive documentation</a></strong> for many more details and case studies of all of the above.</p>







<h2>What’s next?&nbsp;</h2>



<p>For many Archive-It partners, knowing that their holdings are contained and available in a standardized format is enough to feel confident about their futures. But the LOCKSS principle doesn’t end at web capture. Here at the Internet Archive we maintain multiple copies of all partners’ W/ARCs in case of any kind of data loss. Our <strong><a rel="noreferrer noopener" href="https://support.archive-it.org/hc/en-us/articles/208117536" target="_blank">Storage and Preservation Policy</a></strong> outlines how.&nbsp;</p>



<p>Still, many Archive-It partners <strong><a href="https://archive-it.org/blog/post/state-of-the-warc-2020/" target="_blank" rel="noreferrer noopener">download W/ARC files</a></strong> into local or third party storage for additional preservation and care. For a detailed example, check out partner Adriane Hanson’s <strong><a href="https://archive-it.org/blog/post/automated-preservation-workflow/">great blog post</a></strong> about the University of Georgia’s process for their own safekeeping. Now that you know what’s in the box too, I hope that this introduction can help you to gauge your need or interests in managing WARCs directly.</p>



<p>If you’ve read this far, then you’re already something of an advanced beginner when it comes to WARC files! Knowing what you know now, I’d be interested to hear how you would augment or improve the standard going forward. The WARC develops slowly, but it’s here to meet your web archiving needs.</p>




            
        </article>
        		<!-- .navigation -->
		        
        <!-- .entry-meta -->
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alzheimer’s cases tied to no-longer-used medical procedure (441 pts)]]></title>
            <link>https://www.statnews.com/2024/01/29/first-transmitted-alzheimers-disease-cases-growth-hormone-cadavers/</link>
            <guid>39183063</guid>
            <pubDate>Mon, 29 Jan 2024 21:39:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statnews.com/2024/01/29/first-transmitted-alzheimers-disease-cases-growth-hormone-cadavers/">https://www.statnews.com/2024/01/29/first-transmitted-alzheimers-disease-cases-growth-hormone-cadavers/</a>, See on <a href="https://news.ycombinator.com/item?id=39183063">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
	<p><span><span>L</span></span>ONDON — There was something odd about these Alzheimer’s cases.</p>
<p>Part of it was the patients’ presentations: Some didn’t have the classic symptoms of the condition. But it was also that the patients were in their 40s and 50s, even their 30s, far younger than people who normally develop the disease. They didn’t even have the known genetic mutations that can set people on the course for such early-onset Alzheimer’s.</p>
<p>But this small handful of patients did share a particular history. As children, they had received growth hormone taken from the brains of human cadavers, which used to be a treatment for a number of conditions that caused short stature. Now, decades later, they were showing signs of Alzheimer’s. In the interim, scientists had discovered that that type of hormone treatment they got could unwittingly transfer bits of protein into recipients’ brains. In some cases, it had induced a fatal brain disease called Creutzfeldt-Jakob disease, or CJD — a finding that led to the banning of the procedure 40 years ago.</p>
<p>It seemed that it wasn’t just the proteins behind CJD that could get transferred. As the scientific team treating the patients <a href="https://www.nature.com/articles/s41591-023-02729-2" target="_blank" rel="noopener">reported Monday</a> in the journal Nature Medicine, the hormone transplant seeded the beta-amyloid protein that’s a hallmark of Alzheimer’s in some recipients’ brains, which, decades later, propagated into disease-causing plaques. They are the first known cases of transmitted Alzheimer’s disease, likely a scientific anomaly yet a finding that adds another wrinkle <a href="https://www.statnews.com/2019/06/25/alzheimers-cabal-thwarted-progress-toward-cure/" rel="">to ongoing arguments about what truly causes Alzheimer’s</a>.</p>
<p>“It looks real that some of these people developed early-onset Alzheimer’s because of that [hormone treatment],” said Ben Wolozin, an expert on neurodegenerative diseases at Boston University’s medical school, who was not involved in the study.</p>
		
		
<p>Other outside scientists agreed that they found the findings legitimate, in particular because only people who had received cadaveric growth hormone prepared in a particular way — a method that doesn’t eliminate protein bits — went on to develop dementia.</p>
<p>Such incidents of illness are known as “iatrogenic,” meaning the result of a medical procedure. In conditions like iatrogenic CJD, the transmissible agents are known as prions — basically, misfolded pieces of protein that go on to cause disease, like a sort of infectious bug.</p>
<p>Researchers debate the definition of a prion and whether it could include amyloid. But regardless, the paper’s authors “provide tantalizing evidence that, under extraordinary circumstances, Alzheimer’s disease is transmissible by a prion-like mechanism,” Mathias Jucker of Germany’s University of Tübingen and Lary Walker of Emory University <a href="https://www.nature.com/articles/s41591-023-02768-9" target="_blank" rel="noopener">wrote in a commentary</a> also published Monday.</p>
<p>Both the study’s authors and outside researchers stressed Alzheimer’s is not some contagious disease that you could catch by caring for a relative, for example. Cases tied to cadaveric growth hormone treatment are also no longer possible; a synthetic hormone has been used instead for decades. The paper’s authors, who run a special prion disease research and treatment center in London, describe just five Alzheimer’s patients out of the more than 1,800 people who were known to have received cadaveric growth hormone in the U.K. from 1959 to 1985. Still, the researchers said the findings were a reminder of the continuing importance of practices like sterilizing neurosurgical instruments, which, in theory, could transfer prions if not properly cleaned between patients.</p>
<p>But in addition to being a scientific curiosity — and another example of the fallout of the use of cadaveric growth hormone — these cases could also stir up the decades-long, oft-contentious fight over the roots of Alzheimer’s.</p>
<p>“We think from a public health point of view, this is probably going to be a relatively small number of patients,” said John Collinge of the MRC Prion Unit at University College London, the senior author of the paper. “However, the implications of this paper we think are broader with respect to disease mechanisms — that it looks like what’s going on in Alzheimer’s disease is very similar in many respects to what happens in the human prion diseases like CJD, with the propagation of these abnormal aggregates of misfolded proteins and misshapen proteins.”</p>
<p>Many scientists believe that beta-amyloid plays a role in the development of Alzheimer’s, and therapies that can clear the protein from people’s brains have finally, after decades of failed attempts, <a href="https://www.statnews.com/2023/07/06/leqembi-alzheimers-fda-approval-eisai-biogen/" rel="">started showing</a> some <a href="https://www.statnews.com/2023/07/17/alzheimers-disease-donanemab-eli-lilly-detailed-data/" rel="">benefits for patients</a>. But most experts also think amyloid isn’t solely responsible. So in these cases, was there something else going on in addition to the amyloid transfer?</p>
<p>“It raises questions about whether amyloid alone is able to cause problems,” said Marc Dhenain, an Alzheimer’s expert at the French research center CEA, who was not involved in the new study.</p>
<p>Outside researchers said they were also left scratching their heads about some of the findings. They said there was limited information, with findings reported from just a few patients, and data like genetic sequencing and autopsy results available from just a sample of them.</p>
<p>They noted, however, that there didn’t seem to be much inflammation in the patients’ brains, another hallmark of Alzheimer’s that can be induced by amyloid. They also wondered why there was so little presence of another protein called tau in the people’s brains despite their cognitive losses, even though tau levels often correlate to cognitive decline. Some researchers speculated that the patients may have had some other genetic mutation that could increase their risk of Alzheimer’s. Two of the patients had intellectual disabilities, another risk factor.</p>
<p>“Can the pathology be transmitted? Yes, it can, and that’s important conceptually,” Wolozin said. “The question is, what’s driving disease? There are many weird things about these rare cases. What’s unclear from the images is, why would they develop such severe dementia that quickly?”</p>
		
		
<p>Globally, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3358170/" target="_blank" rel="noopener">more than 200 cases of iatrogenic CJD</a> have been documented in recipients of cadaveric human growth hormone, with the bulk of patients in France, the U.K., and the U.S. And for years, researchers have been gathering clues that there may be an iatrogenic form of Alzheimer’s as well. (The vast majority of Alzheimer’s cases are what’s known as sporadic, developing among older people. There are also some early-onset cases that are tied to inherited mutations.)</p>
<p>In 2015, the UCL prion researchers <a href="https://pubmed.ncbi.nlm.nih.gov/26354483/" target="_blank" rel="noopener">reported</a> finding lots of beta-amyloid in the brains of patients who died of iatrogenic CJD, including a buildup in the brain’s blood vessels, which is known as cerebral amyloid angiopathy and which is seen in most people with Alzheimer’s. It led them to hypothesize that the hormones the patient received had been contaminated not just with the CJD prions, but seeds of amyloid as well. It also made them wonder whether the patients, had CJD not killed them, would have gone on to develop Alzheimer’s.</p>
<p>The paper describes eight patients who were treated at the U.K.’s National Prion Clinic from 2017 to 2022, none of whom had CJD and only some of whom were found to have Alzheimer’s. They had received the hormone treatment as children for different causes of short stature: some had brain tumors, others had developmental conditions, others just lacked their own natural hormone.</p>
<p>Five of them had been diagnosed with Alzheimer’s or likely had Alzheimer’s disease, with their symptoms starting between the ages of 38 and 55. Among the other three patients, two had some cognitive impairments, while the third was asymptomatic.</p>
<p>The researchers noted that the presentation of iatrogenic CJD often differs from that of the more common sporadic cases, so it’s possible the transmitted Alzheimer’s cases would look somewhat distinct from typical cases.</p>
<p>Gargi Banerjee, the lead author of the paper, said the UCL researchers considered other possible causes of these patients’ Alzheimer’s. Given the age of the patients, these weren’t sporadic cases, which almost always develop only later in life. The patients didn’t have known genetic mutations that could cause early-onset dementia. The researchers also considered the underlying reasons why the patients had received the hormone in the first place — was it a result of their cancer treatment or congenital conditions? — but that wasn’t a likely explanation either.</p>
<p>“The thing about this group is thinking about them as a whole,” she said. “In the people who did have symptoms, they had various different illnesses, but the only combined fact was that they all had this particular type of growth hormone, this particular preparation in childhood. … There was no other unifying cause for this.”</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HP CEO Makes Up a Whole Lot of Bullshit to Defend Crippling Printers (103 pts)]]></title>
            <link>https://www.techdirt.com/2024/01/29/hp-ceo-makes-up-a-whole-lot-of-bullshit-to-defend-crippling-printers-that-use-cheaper-ink/</link>
            <guid>39183011</guid>
            <pubDate>Mon, 29 Jan 2024 21:36:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/01/29/hp-ceo-makes-up-a-whole-lot-of-bullshit-to-defend-crippling-printers-that-use-cheaper-ink/">https://www.techdirt.com/2024/01/29/hp-ceo-makes-up-a-whole-lot-of-bullshit-to-defend-crippling-printers-that-use-cheaper-ink/</a>, See on <a href="https://news.ycombinator.com/item?id=39183011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-430911">


<h3>from the <i>smart-consumers-are-bad-for-us</i> dept</h3>

<p>When last we checked in with Hewlett Packard (HP), the company <a href="https://www.techdirt.com/2024/01/11/hp-hit-with-yet-another-lawsuit-over-bricking-printers-that-use-third-party-ink-cartridges/">had just been sued</a> (for the second time) for crippling customer printers if owners attempt to use cheaper, third-party printer cartridges. It was just the latest in a long saga where printer manufacturers use DRM or dodgy software updates to wage all out war on consumer choice.</p>
<p>The company could have taken the opportunity for self reflection, acknowledge their error, and attempt to shore up a fraying relationship with customers. Instead, HP CEO Enrique Lores <a href="https://www.youtube.com/watch?v=QPRMyQSZGuY">went on CNBC</a> to not only double down, but to make up a whole bunch of new nonsense to justify their unpopular actions. </p>
<p>On the segment, Lores claims that HP is crippling the use of cheaper ink and toner cartridges because they’re simply worried they <a href="https://arstechnica.com/gadgets/2024/01/hp-ceo-blocking-third-party-ink-from-printers-fights-viruses/">will infect consumers with viruses</a>:</p>
<blockquote>
<p><em>“Last Thursday, HP CEO Enrique Lores addressed the company’s controversial practice of bricking printers when users load them with third-party ink. Speaking to&nbsp;<a href="https://www.youtube.com/watch?v=QPRMyQSZGuY">CNBC Television</a>, he said, “We have seen that you can embed viruses in the cartridges. Through the cartridge, [the virus can] go to the printer, [and then] from the printer, go to the network.”</em></p>
</blockquote>
<p>Ars Technica <a href="https://arstechnica.com/gadgets/2024/01/hp-ceo-blocking-third-party-ink-from-printers-fights-viruses/">talked to numerous security researchers</a> who laughed at the claim, noting that it’s never been meaningfully documented in the wild, and isn’t something consumers should be worried about. </p>
<p>Printer manufacturers have a long and proud history of hiding their anti-competitive price gouging under the pretense of user safety and security. In this case, HP cripples printer functionality using its “Dynamic Security System,” which stops HP printers from functioning if an ink cartridge without an HP chip or HP electronic circuitry is installed.</p>
<p>It’s clear to everybody that HP is simply being obnoxious and anti-competitive to goose quarterly revenues. But you really get a good sense of Lores’ distorted thinking later on in the CNBC article, where he calls savvy, cost-conscious consumers a “bad investment”: </p>
<blockquote>
<p><em>“This is something we announced a few years ago that our goal was to reduce the number of what we call unprofitable customers. Because every time a customer buys a printer, it’s an investment for us. We’re investing [in] that customer, and if this customer doesn’t print enough or doesn’t use our supplies, it’s a bad investment.”</em></p>
</blockquote>
<p>That kind of thinking teeters toward the psychotic. HP is being obnoxiously anti-competitive, hiding it behind claims of user security, then declaring consumers the enemy if they’re smart enough to see through the company’s bullshit and shop for cartridges intelligently.</p>
<p>Of course for publicly traded companies, it’s simply not enough to sell a quality product that people like. Wall Street’s unrelenting need for improved quarterly returns <em>at any cost </em>routinely turns big companies and their execs into self-sabotaging, anti-competitive jackasses sooner or later. Companies start to nickel-and-dime users, skimp on customer service, or cannibalize product quality to hit quarterly revenue goals. </p>
<p>It’s not clear if a handful of class action lawsuits will be enough to shift the company’s thinking back to reality, but being so obnoxious that you permanently pollute the HP brand reputation in the mind of an entire generation of future shoppers might just do the trick. </p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/drm/" rel="tag">drm</a>, <a href="https://www.techdirt.com/tag/enrique-lores/" rel="tag">Enrique Lores</a>, <a href="https://www.techdirt.com/tag/ink-cartridges/" rel="tag">ink cartridges</a>, <a href="https://www.techdirt.com/tag/printers/" rel="tag">printers</a>, <a href="https://www.techdirt.com/tag/security/" rel="tag">security</a>, <a href="https://www.techdirt.com/tag/third-party/" rel="tag">third party</a>, <a href="https://www.techdirt.com/tag/virus/" rel="tag">virus</a>
<br>
Companies: <a href="https://www.techdirt.com/company/hp/" rel="category tag">hp</a>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Tour of the Lisps (288 pts)]]></title>
            <link>https://www.fosskers.ca/en/blog/rounds-of-lisp</link>
            <guid>39182721</guid>
            <pubDate>Mon, 29 Jan 2024 21:15:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fosskers.ca/en/blog/rounds-of-lisp">https://www.fosskers.ca/en/blog/rounds-of-lisp</a>, See on <a href="https://news.ycombinator.com/item?id=39182721">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>2023 seems to have been the year where I "made the rounds" of a number of major Lisps. There were several elements that lead to this. Firstly must have been my exposure to Elixir in 2022, which introduced me to the idea of debugging live systems and "staying in your program". Secondly must have been my chief complaint of Rust; although it is a wonderful language and ecosystem in many ways, you can't say that it's beautiful, which my previous love Haskell very much was. Thirdly then must been the talk <a href="https://www.youtube.com/watch?v=8Ab3ArE8W3s&amp;pp=ygUnc3RvcCB3cml0aW5nIGRlYWQgcHJvZ3JhbXMgamFjayBkb25vdmFu">Stop Writing Dead Programs</a> by Jack Rusher, which opened my eyes to the prevalence of the write-compile-run development cycle and how we can escape from it. And last was my day-to-day usage of Emacs, whose configuration language is also a Lisp. Thanks Henrik.</p><p>Over the past year I published software in five Lisps: Guile, Common Lisp, Fennel, Clojure, and Emacs Lisp. Based on some questions I received from a Doom Emacs community member, I'll talk about each of these and reveal where I am now in my views and usage of Lisp languages.</p><h2 id="org8bd351">Questions</h2><h3 id="org92cbde">What was the purpose of doing the rounds?</h3><p>It happened organically, I didn't plan to do it.</p><p>I mostly switched away from Haskell to Rust during COVID, sometime during 2020. I had some time off, decided to learn both Go and Rust, and was happier with the latter as I found that I could very much "speak Haskell" in it while gaining <a href="https://www.fosskers.ca/en/blog/rust-software-dev">other modern benefits</a> like the Ownership system. Very little compromise for massive gain.</p><p>Yet I've always had a love for terser, elegant languages, and I've always had a soft spot for Lisps. I like Rust, but somehow it didn't feel like home. The purpose of the rounds was to once and for all find a language that could satisfy my needs as a working software developer, but also "tickle my fancy" in terms of day-to-day joy and match my values as a person.</p><h3 id="orgf72a8b">What draws you to a Lisp dialect?</h3><p>Beauty in programs is important. I generally believe that beautiful code is less likely to be buggy, since beauty and simplicity are related, simplicity is the dual of complexity, and complexity is the womb from which bugs emerge.</p><p>Lisps are beautiful. Code is generally quite terse thanks to its syntax. And something interesting happens with even a bit of serious Lisp experience: you stop seeing the parentheses. Not that they'd be a bother if you did; the parens allow "structural editing" which can speed up your editing. You're no longer bound to characters and lines, you can swap and move entire s-expressions freely. And besides, modern editor setups handle the parenthesis balancing for you. I spend no extra time herding parentheses, but I can see how this would have been an issue in the past.</p><p>So I'm clearly drawn to the aesthetics, as I was in my Haskell years. But what drew me to the particular Lisps I tried?</p><p><span>Guile</span> has Scheme's cleanliness and consistency. It's also a GNU language and installed by default on many systems, and there was a part of me that loved <i>the
freedom, man, yeah</i>. It was here that I discovered Transducers and fell in love, proceeding to port the paradigm to <a href="https://git.sr.ht/~fosskers/cl-transducers">Common Lisp</a>, <a href="https://git.sr.ht/~fosskers/transducers.fnl">Fennel</a>, and <a href="https://git.sr.ht/~fosskers/transducers.el">Emacs Lisp</a>. Guile though is hard to produce larger projects in if you aren't using Guix, since there exists no non-Guix-based dependency management.</p><p><span>Common Lisp</span> is the classic. It has its historical warts, but I found an active ecosystem and enthusiastic community. Best-in-class debuggability and interactivity for any language I've used. Have you ever wanted to debug external library code, but from within your program? While it's running? In prod across the network? Well you can. It's also a compiled language but allows hotswapping like Erlang, and has a static type system if you want it for API-hardening and performance tuning. It's definitely a power user's language. There are modern libraries for papering over some of the historical stdlib API oddities, although discovering these is sometimes difficult. There is also no "one Common Lisp", you need to <a href="https://github.com/CodyReichert/awesome-cl#implementations">pick an implementation</a> to work with. No LSP either, although existing editor integrations are of sufficently high quality and predate the notion of LSPs, so they aren't particularly missed.</p><p><a href="https://fennel-lang.org/">Fennel</a> is simple and clean. It compiles to Lua, shares its semantics, and can trivially use Lua libraries. The <a href="https://tic80.com/">TIC-80</a> supports it natively for retro game development, which I used to write <a href="https://tic80.com/play?cart=3375">Snake</a> and a port of the classic TI83 game <a href="https://fosskers.itch.io/falldown">Falldown</a>. It's tooling improves with time and you can produce static binaries with it, but direct vendoring is the recommended dependency management strategy. It also lacks Common Lisp's debuggability, given that it sits entirely within Lua's runtime.</p><p><span>Clojure</span> is what happens when a smart, experienced developer sits down for two years and thinks about what a programming language really needs to be to get work done in the real world. And Rich Hickey did an excellent job. Clojure is very clean, has best-in-class ergonomics, and best-in-class tooling. Great data structure literals. Its community is also very strong and <a href="https://www.clojuriststogether.org/">self-funds</a> many of the popular projects. Its heavy integration with the JVM turns a lot of people off (myself included), but there are <a href="https://github.com/babashka/babashka">alternate platforms</a> available, including an upcoming <a href="https://github.com/jank-lang/jank/">C++-based native implementation</a> which I've had my eye on for some time. Clojure can definitely be said to have "brought Lisp into the modern age", and I used it to power the <a href="https://git.sr.ht/~fosskers/faur">AUR data mirror</a> that <a href="https://github.com/fosskers/aura">Aura</a> uses. Unfortunately Clojure does have famously poor error messages, and while it has some of Common Lisp's prod-debuggability and hotswapping, I always miss having the Condition System.</p><p>And finally, the strength of <span>Emacs Lisp</span> is that it's always at hand. Best-in-class discoverability due to editor integration, and especially in combination with Org Mode it's easiest to whip out quick code samples. I write a lot of small script-like functionality in it, which is then always available without leaving the editor and is only one button press away from executing. It also has a very active <a href="https://melpa.org/#/">ecosystem</a> and community projects like <a href="https://github.com/doomemacs/doomemacs/">Doom Emacs</a>. Given how old it is though, senior even to Common Lisp, it has some historical cruft and lacks "obvious" things like first-class async. Makes for some really clean editor config, though!</p><p>As you can see, each dialect has its strengths but is not without drawbacks.</p><h3 id="org8270ce">What have you learned, big-picture-wise, from doing the rounds?</h3><p>Several things.</p><p>First, I learned that I had been obsessing over Order. In things being "just so", especially with regards to the type system. I've overhauled Aura enough times to know that I gain joy from pushing puzzle pieces into place, but that doesn't necessarily lead to a state of "being done" and freedom in the <a href="https://medium.com/@bre/the-cult-of-done-manifesto-724ca1c2ff13">Getting Stuff Done</a> sense. Type systems are great for maintainability, but especially through my exposure to Clojure-thinking and live, in-editor testing like:</p><div><pre><code><span id="1"><a href="#1"></a>(<span>comment</span></span>
<span id="2"><a href="#2"></a>  (clojure.str/join <span>"foo"</span> <span>"bar"</span>))</span></code></pre></div><p>and leaving a <code>repl.clj</code> or <code>repl.lisp</code> file around in every project filled with little utilities for live testing, I've come around to the idea that:</p><blockquote><p>It's okay to start dynamic and tighten down the API later with gradual-typing
mechanisms once the domain crystalizes.</p></blockquote><p>Some Lisps have such things, such as Common Lisp, Racket, and Clojure. Heck even Simon Peyton-Jones, the inventor of Haskell, has <a href="https://codersatwork.com/">gone on record</a> saying:</p><blockquote><p>...dynamic languages are still interesting and important. There are programs you
can write which can't be typed by a particular type system but which
nevertheless don't "go wrong" at runtime, which is the gold standard - don't
segfault, don't add integers to characters. They're just fine.</p><p>I think to try to specify all that a program should do, you get specifications
that are themselves so complicated that you're not longer confident that they
say what you intended.</p></blockquote><p>The harder it is to test things in-editor, the more you need top-down structure like type systems and unit tests. Lisp makes in-editor testing very easy.</p><p>Now second, I learned that I had never truly debugged before. The tools provided particularly by Common Lisp and to a slightly lesser degree Clojure allow me to <span>be inside my program</span> at all times. Why do print-line-debugging to find out what's happening at a location in code when you can just be inside your program and inspect everything live as it's running? I had never known that this existed as a paradigm. The write-compile-run cycle we usually suffer through in other languages is silly, and I do feel this pain in Rust.</p><p>Third, that Lisps are mostly not about writing macros. I have written perhaps two small ones. Functions do the job the vast majority of the time. No, I'd say "the center of Lisp", if it's anywhere, is the interactive REPL-based development. And that doesn't mean you should be typing things into a REPL prompt manually like a Neanderthal; modern setups have you type directly into your editor and <i>send</i> the code to the REPL, receiving the result as an in-editor overlay. It's quite pretty (see the <code>comment</code> example above).</p><p>And finally fourth, I got confirmation that Lisps are entirely usable in the modern day. Real, working, maintainable software can be written for basically <a href="https://store.steampowered.com/app/1261430/Kandria/">any domain</a>. And did you know salaries for Lisp languages <a href="https://survey.stackoverflow.co/2023/#salary-and-experience-by-language">seem to be quite high</a>?</p><h3 id="org2133ee">What's your current mental model of an "ideal Lisp"?</h3><p>It would be something like a fusion of Clojure and Common Lisp, but with stronger-yet-still-optional static typing features. Enums are great, traits/typeclasses are great, so let's have those when we want them. Maybe the latter isn't as necessary if you're doing generic-dispatch properly.</p><p>I like Functional Programming, and I'm not married to CLOS. Structs do the job just fine for me, but maybe I'm missing something.</p><p>I'd want the debuggability of Common Lisp for sure, and its ability to compile natively. Rich was both right and wrong about parens; I'm not offended by CL-style paren usage, for example in this <code>let</code>:</p><div><pre>(let* ((foo (bar 5))
       (baz (zoo foo)))
  #(foo baz))</pre></div><p>versus</p><div><pre><code><span id="1"><a href="#1"></a>(<span>let</span> [foo (bar <span>5</span>)</span>
<span id="2"><a href="#2"></a>      bar (zoo foo)]</span>
<span id="3"><a href="#3"></a>  [foo baz])</span></code></pre></div><p>Yet as seen in the second example, I <span>do</span> want special brackets for well-used collections like vectors, maps, and sets.</p><p>After that I'd be happy with good tooling and a talented community.</p><p>As an aside, it should be known that some folks have gone to great lengths to embed other languages inside Common Lisp, namely <a href="https://github.com/coalton-lang/coalton">Coalton</a>, a Haskell-like Lisp, and <a href="https://github.com/phantomics/april">April</a>, which is APL. These can be easily slotted into existing CL programs.</p><h3 id="org3c9725">Do you believe s-expressions are the be-all-end-all of Lisp syntax?</h3><p>Yes, because of structural editing and because Lisp isn't APL or <a href="https://www.uiua.org/">Uiua</a>. Something is lost when you still want to be a word-based language but insist on whitespace-only like Python or Haskell. Efforts to abandon parentheses for fear that they turn away theoretical new users are misguided. Mature people can see past such surface details. Growth for its own sake is not a virtue.</p><h3 id="org309a3e">How can newcomers get the most out of learning Lisp?</h3><ol><li>Start with a proper setup.</li><li>Embrace the REPL.</li><li>Immerse yourself.</li><li>Get help.</li></ol><p>Immersion is the best way to learn a human language; so too of programming. Configuring your <a href="https://github.com/doomemacs/doomemacs/">Editor</a> (another option: <a href="https://lem-project.github.io/">Lem</a>), your <a href="https://github.com/atlas-engineer/nyxt">Browser</a>, or your <a href="https://guix.gnu.org/">OS</a> in a Lisp is a good way to stay immersed.</p><p>You'll also want to build something real. Naturally as in any project, if you don't have a goal in mind you aren't going to get very far, so I'd also say that the next time you want to build something, just pick a Lisp to do it in.</p><p>Before that though, you'll want to make sure you have a proper setup. Get the <a href="https://github.com/joaotavora/sly">editor modes</a>, find the LSPs, download the dependency managers, grab the <a href="https://github.com/justinbarclay/parinfer-rust-mode">paren-balancers</a>.</p><p>If you want help, check out the Clojure Slack. They're very welcoming there. For Common Lisp, see my article on <a href="https://www.fosskers.ca/en/blog/common-lisp">Common Lisp resources</a>. Consider also joining the Doom Emacs Discord server or the Lisp Discord server. Also try to find meetups in your area. You might be surprised at how much is happening in this world.</p><p>If you just want to get your feet wet, consider <a href="https://exercism.org/">Exercism</a>.</p><p>Overall, I'd say start with Clojure, get a feel for the style, then swing over to Common Lisp to see what each is missing. If you've built something real in either, you should have gotten a feel for what the paradigm offers. I personally don't feel you necessarily need to slog through a giant 1000-page textbook to learn a Lisp. That includes the famous <a href="https://en.wikipedia.org/wiki/Structure_and_Interpretation_of_Computer_Programs">Structure and Interpretation of Computer
Programs</a>. At the end of the day, you just need to write code, and no amount of reading will ever be a substitute for that.</p><h2 id="orgca5e2f">Conclusion</h2><p>I find myself <a href="https://codeberg.org/fosskers/filepaths">writing Common Lisp</a> lately. I had a moment at work recently where odd behaviour in our Rust application code was likely due to a bug in a library, but I couldn't debug it <i>right there</i> to confirm the problem. What follows is a clone, patch, push, re-pin, retest, ok, merge, release, re-pin again... you get it. I noticed myself thinking "if this were Common Lisp this debug would have taken 30 seconds." So here I am, at least for my personal coding.</p><p>Both Common Lisp and Lisps in general are "chill cafés". The communities are small enough to find yourself a nice window seat, and projects are generally well-written. The folks themselves are self-selecting and I've had nothing but positive experiences.</p><p>Have I found my "one true language"? Well, no, because there isn't such a thing. No matter which tool we pick, we'll always <a href="https://www.fosskers.ca/en/blog/subsetting-your-life">have to choose an inner subset</a> of features to adopt, at least until "the next stage". And as nice as newer languages like Clojure and Rust are, these aren't Man's final programming languages. But I'm happy for now.</p><h2 id="orgc547d5">Feedback</h2><p>Here are my responses to some questions I got regarding the article.</p><blockquote><p>What about other Schemes like Chicken, Chez, Gambit, etc.? Like CL, the Scheme
implementation you pick can affect your day to day experience a lot.</p></blockquote><p>I had tried Chicken a bit in 2022 (I think). It seemed like a decent package, although I turned away nonetheless. Racket I had also tried in the past but moved on for similar reasons.</p><p>To me, the Schemes seem like good languages, but when doing software development the language itself <a href="https://www.fosskers.ca/en/blog/software-dev-langs">isn't all there is to it</a>.</p><blockquote><p>What about Clojure's Condition System library, Farolero?</p></blockquote><p><a href="https://github.com/IGJoshua/farolero">I have tried this</a>. It's a solid attempt at introducing as much of the Condition System as possible given the underlying platform's capabilities. Although, since it's not first-class, it isn't trivial to integrate across libraries. Probably decent for application development.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Boardzilla, a framework for making web-based board games (483 pts)]]></title>
            <link>https://www.boardzilla.io/</link>
            <guid>39180953</guid>
            <pubDate>Mon, 29 Jan 2024 19:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.boardzilla.io/">https://www.boardzilla.io/</a>, See on <a href="https://news.ycombinator.com/item?id=39180953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><img alt="Rawr!" src="https://www.boardzilla.io/boardzilla-logo.svg"></p><h2>Digital board games made easy.</h2><p><a href="https://discord.gg/bdjpdmuZpH">Join us on Discord</a></p></div><div><h2>Games</h2><div><a href="https://www.boardzilla.io/g/7-wonders-duel"><div><h2>7 Wonders Duel</h2><p>For 2 players</p></div></a><a href="https://www.boardzilla.io/g/cursed"><div><h2>Cursed</h2><p>For 1 player</p></div></a><a href="https://www.boardzilla.io/g/hex"><div><h2>Hex</h2><p>For 2 players</p></div></a><a href="https://www.boardzilla.io/g/powergrid"><div><h2>Power Grid</h2><p>For 2 to 4 players</p></div></a></div></div><div><h2>Boardzilla is a place for playing and developing board games all within your browser. Boardzilla makes it easy to express the game rules and provides players with a simple interface to the choices available to them.</h2><p><a href="https://www.boardzilla.io/why">Find out more</a></p></div><div><h2>Ready to make your own game?</h2><p><a href="https://docs.boardzilla.io/">Read the documentation</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Evergrande, once China's biggest property developer, ordered to liquidate (127 pts)]]></title>
            <link>https://www.wsj.com/articles/evergrande-faces-imminent-liquidation-after-talks-with-top-creditors-break-down-4af5f657</link>
            <guid>39180898</guid>
            <pubDate>Mon, 29 Jan 2024 19:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/articles/evergrande-faces-imminent-liquidation-after-talks-with-top-creditors-break-down-4af5f657">https://www.wsj.com/articles/evergrande-faces-imminent-liquidation-after-talks-with-top-creditors-break-down-4af5f657</a>, See on <a href="https://news.ycombinator.com/item?id=39180898">Hacker News</a></p>
Couldn't get https://www.wsj.com/articles/evergrande-faces-imminent-liquidation-after-talks-with-top-creditors-break-down-4af5f657: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[The Big Little Guide to Message Queues (2020) (161 pts)]]></title>
            <link>https://sudhir.io/the-big-little-guide-to-message-queues</link>
            <guid>39180891</guid>
            <pubDate>Mon, 29 Jan 2024 19:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sudhir.io/the-big-little-guide-to-message-queues">https://sudhir.io/the-big-little-guide-to-message-queues</a>, See on <a href="https://news.ycombinator.com/item?id=39180891">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>A guide to the fundamental concepts that underlie message queues, and how they apply to popular queueing systems available today.</p><p>Message Queues are now fairly prevalent—there are so many of them showing up so fast you'd think they were <a href="https://www.rabbitmq.com/">rabbits</a> with an unlimited supply of <a href="https://docs.celeryproject.org/en/stable/">celery</a>, resulting in an <a href="https://kafka.apache.org/">kafkaesque</a> situation where making a decision is like trying to catch a <a href="https://redis.io/topics/streams-intro">stream</a> in your hands. If only there were fewer <a href="https://aws.amazon.com/sns">simple</a> <a href="https://aws.amazon.com/sqs/">services</a> that could help with <a href="https://cloud.google.com/pubsub">publishing and subscribing</a>, it would be so much easier to make a <a href="https://zeromq.org/">zero-effort</a> choice 😕</p><p>Whether we use them by themselves as-is to move data between parts of our application, or as an integral part of the architecture (like event driven systems), message queues are here to stay. In a way, they've been here all along—just without as many names. But what are they? Why are they useful? And how do we use them effectively? Which implementation do we pick? Does it even matter which one we use? And do we need to learn each of them individually, or are there more general concepts that apply to all message queues?</p><p>In this guide, we'll talk about:</p><ul><li>What message queues are and their history.</li><li>Why they're useful and what mental models to use when reasoning about them.</li><li>Delivery guarantees that the queuing systems make (at-least-once, at-most-once, and exactly-once semantics).</li><li>Ordering and FIFO guarantees and how they effect sequencing, parallelism and performance.</li><li>Patterns for fan-out and fan-in: delivering one message to many systems or messages from many systems into one.</li><li>Notes on the pros and cons of many popular systems available today.</li></ul><h2>What are message queues?</h2><p>Message Queues are a way to transfer information between two systems. This information—a message—can be data, metadata, signals, or a combination of all three. The systems that are sending and receiving messages could be processes on the same computer, modules of the same application, services that might be running on different computers or technology stacks, or entirely different kinds of systems altogether—like transferring information from your software into an email or an SMS on the cellphone network.</p><p>The idea of a messaging system has been around a very long time, from the message boxes used for moving information between people or office departments (literally where the words <em>inbox</em> and <em>outbox</em> come from), to telegrams, to your local postal or courier service. The messaging systems in the physical world that come closest to what we have in computing are probably the <a href="https://en.wikipedia.org/wiki/Pneumatic_tube">pnuematic</a> <a href="https://www.google.com/search?q=pneumatic+tubes&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;biw=2560&amp;bih=1366">tubes</a> that moved messages through buildings and cities using compressed air until a few decades ago (and are still used in some places today).</p><p>The kinds of messages we transfer today might be a note that something technical happened, like CPU usage exceeding a limit; or a business event of interest, like a customer placing an order; or a signal, like a command that tells another service to do something. The contents of each message will be driven entirely by the architecture of your application and its purposes—so for the rest of this guide, we don't need to be concerned about what's inside a message—we're more concerned with how the message gets from the system where it originates (the <em>producer</em>, <em>source, publisher</em> or <em>sender</em>) to the system where's it's supposed to go (the <em>consumer</em>, <em>subscriber</em>, <em>destination</em> or <em>receiver</em>).</p><h2>And Why Do We Need Them?</h2><p>We need message queues because no system exists or works in isolation—all systems need to communicate with other systems in structured ways that they both can understand, and at a controlled speed that they both can handle. Any non-trivial process needs a way to move information between each stage of the process; any workflow needs a way to move the intermediate product between the stages of that workflow. Message queues are a great way to handle this movement. There are plenty of ways of getting these messages around using API calls, file systems, or many other abuses of the natural order of things; but all of these are ad-hoc implementations of the message queue that we sometimes refuse to acknowledge we need.</p><p>The simplest mental model for a message queue is a very long tube that you can roll a ball into. You write your message on a ball, roll it into the tube, and someone or something else receives it at the other end. There are a lot of interesting benefits with this model, some of which are:</p><ul><li>We don't need to worry about <em>who or what</em> is going to receive the message – that's one less responsibility for the sender to be concerned about.</li><li>We don't need to worry about <em>when</em> the receiver is going to pick up the message.</li><li>We can put <em>as many</em> messages as we want into the tube (let's assume we have a infinitely long tube) at whatever <em>speed</em> is comfortable to us.</li><li>The receiver will <em>never be impacted</em> by our actions—they will pull out as many messages as they want at whatever rate is comfortable to them.</li><li>Neither the sender nor the receiver are concerned with <em>how</em> the other works.</li><li>Neither the sender nor the receiver are concerned with the <em>capacity or load</em> of the other.</li><li>Neither system is concerned with <em>where</em> the other one is – they may or many not reside on the same computer, network, continent or even the same planet.</li></ul><p>Each of these advantages (and this isn't even an exhaustive list) has very important benefits in software development—what they all have in common is <em>decoupling</em>. One system is decoupled from the other in terms of responsibility, time, bandwidth, internal workings, load and geography. And decoupling is a very desirable part of any distributed or complex system—the more decoupled the parts of the system are, the easier it is to independently build, test, run, maintain and scale them.</p><p>Most systems interact with other outside or third-party systems as well—if we build a shopping site we might interact with a payment processor, and let’s say we attempt to directly communicate with the payment processor on each user click. If our system is under heavy load, we're also subjecting the other system to the same load. And vice versa—if our payment provider needs to send us millions of pieces of information about our past payment statuses, our system better be ready. The two systems are now <em>coupled</em>. The decisions and actions made by one system have a significant impact on the other, so the needs of both need to be taken into account while making every decision. Add enough other systems into the mix, like logistics or delivery systems, and we quickly have a paralysing mess that makes it difficult to decide anything at all. If one system goes down, the other systems have effectively gone down as well, for no fault of their own.</p><p>We’re also in trouble if we want to switch out any one of these systems for another one, like a new payment processor or delivery system. We’d have to make deep changes in multiple places in our application, and it’s even more difficult to build code to split our messages between multiple providers—we may want to use a ratio to load balance them or split them by geography; or dynamically switch between them based on each provider’s availability or cost.</p><p>Message queues offer the decoupling that solves a lot of these problems. If we set up a queue between two systems that need to communicate with each other, they can now go about their work without having to worry about each other at all—we put our messages aimed at any system into a queue, and we expect information from the other system to come to us through another queue as well. We now have clear points at which we can add rules or make the changes we require, without either system knowing or caring about what's different.</p><h3>So what's the catch?</h3><p>Are message queues the holy grail of computing, though? Do they solve all the world's problems? No, of course not. There are plenty of situations where we might not want to use them. And we certainly don't want to use a queue just because we have one easily available and think it might be fun. There are some systems that are really simple that just don't require it—a message queue is a way to reduce complexity of communicating systems, but two communicating systems will always be more complex than one system that doesn't have to communicate. If you have a system that’s simple enough to not require communication with any others, there simply isn't any reason to reach for a queue.</p><p>There are also systems that communicate with each other, but where the complexity added by that communication added is insignificant and not worth worrying about. Or more often the systems are already coupled, in the sense that they all need to work together to function. A really common example is an application server and a data service (in an <em>OLTP</em> system). There's not much point in decoupling them with a queue, because neither can do anything useful without the direct involvement of the other.</p><p>Then there's performance to consider as well—the whole point of decoupling two systems with regards to time and load is so that they can each process information at their own pace—but we certainly would <em>not</em> want this to happen in performance sensitive applications or real-time systems. A queue might help us process more work at the same time (the receiver might have many processes working in parallel on the messages you send) but will remove any guarantees we need about the exact time taken for each piece of work. If predictability is more important than throughput, we're better off without a queue.</p><p>Using a queue might increase the time taken to process each <em>individual</em> message, but will allow you process many more messages at the same time across different computers—so your total number of messages processed per minute or hour, or <em>throughput</em>, will increase.</p><p>If we do have multiple systems that need to communicate, and that communication needs to be <em>durable</em> (if we’ve put a message into a queue, we want to be sure that the messaging system isn’t going to ‘forget’ about it) and decoupled, a message queue is indispensable.</p><h2>Arguing Semantics</h2><p>There's simply no way to learn about message queues without reading and/or arguing about delivery guarantees and semantics, so we might as well get to that quickly. People who build message queues will claim that their system offers one of three delivery guarantees—that each message you put into the queue will be delivered:</p><ul><li><em>at-least</em> once.</li><li><em>at-most</em> once.</li><li><em>exactly</em> once.</li></ul><p>Which guarantees we're using will have a massive impact on the design and working of our system, so let's unpack each of them one by one.</p><h3>At-Least Once</h3><p>This is the most common delivery mechanism, and it's the simplest to reason about and implement. If I have a message for you, I will read it to you, and keep doing so again and again until you acknowledge it. That's it. In a system which works on an at-least-once basis, this means that when you receive a message from the queue and don't delete/acknowledge it, you will receive it again in the future, and will keep receiving it until you explicitly delete/acknowledge it.</p><p>The reason this is the most common guarantee is that it's simple and gets the job done 100% of the time—there's no edge case in which the message gets lost. Even if the receiver crashes before acknowledging the message, it will simply receive the same message again. The flip side is that you as the receiver need to plan on receiving the same message multiple times—even if you haven't necessarily experienced a crash. This is because offering at-least-once is the simplest way to protect the queueing service from missing out messages as well—if your acknowledgement doesn't reach the queueing system over the network, the message will be sent again. If there's a problem persisting your acknowledgement, the message will be sent again. If the queuing system restarts before it can properly keep track of what's been sent to you, the message will be sent again. This simple remedy of sending the message again in case of any problem on any side is what makes this guarantee so reliable.</p><p>But is message duplication/repetition a problem? That's really up to you and your application or use-case. If the message is a timestamp and a measurement, for example, there's no problem with receiving a million duplicates. But if you're moving money based on the messages, it definitely is a problem. In these cases you'll need to have a transactional (ACID) database at the receiving end, and maybe record the message ID in a unique index so that it can't be repeated. This is called using an <em>idempotency token</em> or _tombstone—_when you act on a message you store a unique permanent marker to keep track of your actions, often in the same database transaction as taking the action itself. The prevents you from repeating that action again even if the message is duplicated.</p><p>If you handle duplication, or if your messages are naturally resistant to duplication, your systems are said to be <em>idempotent</em>. This means you can safely handle receiving the same message multiple times, without corrupting your work. It also often means you can tolerate the sender sending the same message multiple times—remember that senders will usually operate on the at-least-once principle when sending messages as well. If senders are unable to record the fact that they've sent a particular message, they'll simply send it again. The senders are then responsible for making sure that they use the same tombstone or idempotency token if and when they re-send messages.</p><h3>At Most Once</h3><p>This is a pretty rare semantic, used for messages where duplication is so horribly explosive (or the message so utterly unimportant) that we'd prefer not to send the message at all, rather than send it twice. At-most-once once implies that the queuing system will attempt to deliver the message to you once, but that's it. If you receive and acknowledge the message all is well, but if you don't, or anything goes wrong, that message will be lost forever—either because the queuing system has taken great pains to record the delivery to you before attempting to send it (in case the message is horribly explosive), or has not even bothered to record the message at all, and is just passing it on like a router passes on a UDP packet.</p><p>This semantic usually comes into play for messaging systems that are either acting as stateless information routers; or in those cases where a repeat message is so destructive that an investigation or reconciliation is necessary in case there's any failure.</p><h3>Exactly Once</h3><p>This is the holy grail of messaging, and also the fountain of a lot of snake-oil. It implies that every message is guaranteed to be delivered and processed exactly once, no more and no less. Everyone who builds or uses distributed systems has a point in their lives where they think “how hard can this be?”, and then they either (1) learn why it's impossible, figure out idempotency, and use at-least-once, or (2) they try to build a half-assed “exactly-once” system and sell it for lots of money to those who haven't figured out (1) yet.</p><p>The impossibility of exactly-once delivery arises from two basic facts:</p><ul><li>senders and receivers are imperfect</li><li>networks are imperfect</li></ul><p>If you think about the problem deeply, there are a lot of things that can go wrong:</p><ul><li>a sender might be unable to record (they <em>forget</em>) that they've sent the message</li><li>the network call to send the message might fail</li><li>the messaging system’s database might not be able to record the message</li><li>the acknowledgement that the messaging system has recorded the message might not reach the sender over the network</li><li>the sender might not be able to record the acknowledgement that the messaging system has received the message</li></ul><p>Let's say all goes well while sending the message—when the messaging system tries to deliver the message to the receiver:</p><ul><li>the message might not reach the receiver over the network</li><li>the receiver might not be able to record the message in its database</li><li>the acknowledgement from the receiver might not reach the messaging system over the network</li><li>the messaging system’s database might not be able to record that the message has been delivered</li></ul><p>Given all the things that can go wrong, it's impossible for any messaging system to guarantee exactly-once delivery. Even if the messaging system is godlike in its perfection, most of the things that can go wrong are outside of it or in the interconnecting networks. Some systems do attempt to use the phrase “exactly once” anyway, usually because they claim their implementation will never have any of the messaging system problems mentioned above—but that doesn't mean the whole system is magically blessed with exactly-once semantics, even if the claims are actually true. It usually means that the queuing system has some form of ordering, locking, hashing, timers and idempotency tokens that will ensure it never re-delivers a messsage that's already been deleted/acknowledged—but this doesn't mean that the whole system including publisher + queue + subscriber has gained full exactly-once guarantees.</p><p>Most good messaging system engineers understand this and will <a href="https://www.lightbend.com/blog/how-akka-works-exactly-once-message-delivery">explain</a> to their users why this semantic is unworkable. The simpler and more reliable way to handle messages is go back to the basics and embrace at-least-once with idempotency measures at every point on the sending, receiving and queuing process: if at first you don't succeed, retry, retry, retry...</p><h2>Ordering vs Parallelism</h2><p>After delivery semantics, another common question on peoples’ minds is “why can’t we just process messages in parallel while also making sure we process them in order?”. Unfortunately this is another tradeoff imposed on us by the tyranny of logic. Doing work in a sequence and doing multiple pieces of work at the same time are always at conflict with each other. Most message queue systems will ask you to pick one—AWS SQS started by prioritising parallelism over strict ordering; but recently introduced a separate FIFO (first in, first out) queuing system as well, which maintains strict sequential ordering. Before making a choice between the two, let’s go over what the difference is and why there needs to be a difference at all.</p><p>Returning to our earlier metaphor for a queue—a long tube into which we roll messages written on a ball—we probably imagined the tube to be just a little wider than a single ball. There's really no way the balls could overtake or pass each other inside the tube, so the only way a receiver could get these messages out is one-by-one, in the order they were put in. This guarantees strict ordering, but places strong limitations on our receiver. There can <em>only be one</em> <em>agent</em> on the receiver side that's processing each message—if there was more than one, there would be no guarantee that the messages were processed in order. Because each new agent could processes each message independently, they could each finish and start on the next message at any time. If the are two agents, A &amp; B, and Agent A receives the first message and Agent B the second; Agent B could finish processing the second message and start on the third message even before Agent A is finished processing the first message. Though the messages were <em>received from the queue</em> strictly in the order that they were put in, if there are multiple receiving agents there’s no way to say the messages will <em>be processed in that order</em>.</p><p>The agents could use a <a href="https://redis.io/topics/distlock">distributed</a> <a href="https://www.postgresql.org/docs/current/explicit-locking.html#ADVISORY-LOCKS">lock</a> of some kind to co-ordinate with each other, but this is basically the same as having only one agent—the lock would only allow one agent to work at any given time. This also means that one agent crashing would result in a <em>deadlock</em> with no work being done.</p><p>One way for the messaging system to guarantee order would be for the tube to refuse to give out the next ball until and unless the last ball that was received has been destroyed (the last message has been deleted/acknowledged). This is what FIFO queues in general will do—they'll provide the next message only after the last one has been acknowledged or deleted—but this means that only one agent can possibly be working at a time, even if there are <em>N</em> agents waiting to receive messages from the queue.</p><p>Sometimes, this is exactly what we want. Some operations are easier to control effectively when we only have to deal with a single agent, like enforcing rules on financial transactions; respecting <a href="https://redis.io/commands/incr#pattern-rate-limiter">rate limits</a>; or generally processing messages whose formats have been designed assuming they would always be processed in order. But a lot of these “benefits” are not really coming from the decision to use FIFO ordering—any scenario where we have <em>N</em> receivers that must somehow co-ordinate their work with each other will benefit from the special case of <em>N = 1</em>. The key takeaway is that requiring a guaranteed order means we have to process messages sequentially on only one receiver at a time.</p><p>This restriction also places severe pressure on the queuing system, so you'll find that FIFO queues are often more expensive and have less capacity than their parallel counterparts. This is because the same logical limits apply to the internal implementation of queuing system as well—most work needs to be constrained to a single agent or server, and that system needs to be kept reliable. Any effort to add redundancy requires synchronous co-ordination between the master and the backup services in order to maintain the ordering guarantees. In AWS SQS, the FIFO queues are about 2X more expensive than the parallel queues, and are constrained to a few hundred messages per second when strict FIFO ordering is required.</p><p>So the only way to move forward with a FIFO message queue is to accept that the entire message processing architecture is going to have an intrinsic speed limit. Many systems will support <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagegroupid-property.html">group headings</a> inside the queue to denote what messages we want strict ordering on—we might say that all messages under the heading “payments” need to be FIFO, and all the messages under “orders” need to be FIFO, but they don't need to be FIFO with respect to each other. This allows some parallelisation inside the queue (like having two FIFO tubes instead of one), but we need to remember that the message bandwidth inside each group heading will still be limited.</p><h3>Parallel != Random</h3><p>Does that mean that the ordering in parallel queues is completely random? Sometimes, yes, but most often no. In SQS, the analogy is more that instead of having one tube from the sender to receiver, there are multiple tubes. They might also branch or join each other along the way. This doesn't mean that the order of the messages you roll in are intentionally randomised in any way—across a large number of messages you'd still expect that earlier messages are generally received before the later ones. This is more a <em>best-effort</em> ordering, where some effort is make to keep the ordering intact, but because it's already logically impossible, it's simply not a big priority for the system. This also allows a messaging system like SQS to scale up to nearly infinite capacity—because if you're rolling in a lot of messages the queueing system can simply add more tubes. And as you can imagine, this will support any number of receivers at the same time, and any number of senders as well. This simplicity is what allows SQS to scale to mind-boggling numbers, including a case where <a href="https://twitter.com/timbray/status/1246157403663388672">there was a queue</a> with over 250 billion messages waiting to be consumed, with the receiver reading and acknowledging over a million messages a second. And that’s just one queue operated by one customer.</p><p>Most problems that seem like they have a hard FIFO requirement can often lend themselves to parallelism and out-of-order delivery with a little bit of creativity. The sender adding a timestamp into the message is one way to help with this, like in the case where the messages are measurements where only the last one matters. In a more transactional system, the sender can often add a <a href="https://www.postgresql.org/docs/current/functions-sequence.html">monotonically increasing counter</a> into the messages. If that's impossible, we might be able to handle this based on the contents of the message—if we're messaging the percentage of a file downloaded, for example, seeing 41%, 42% and 43% always means that the current value is 43%—even if we see them out of order as 41%, 43% and 42%.</p><p>While it's often a bad idea to change our systems to accommodate the tools we use, designing our messages to allow for out-of-order delivery and idempotency makes the system more resilient in general, while also letting use more parallel messaging systems—often saving time, money and a lot of operational work.</p><h2>Fan Out / In</h2><p>When building a distributed system there's often a need to have the same message sent to multiple receivers—besides the usual receiver of the message, we also often want the same message sent to other places, like an archive, an audit log (for compliance and security checks) or an analyzer for our dashboards. If you're using an event driven architecture with many services, you might want to use a single <em>event bus</em> in your application, where all the messages posted into this event bus are automatically sent to all of your services. This is called a <em>fan-out</em> problem, where a message from one producer needs to reach many consumers.</p><p>The inverse problem, where a single receiver is tasked with reading the messages posted to multiple queues is also common—in the example we considered above, a receiver that was archiving all messages or creating an audit log would probably receive all the messages generated in an organisation, on every queue. It's also common in service architectures to have a function like notifications handled separately—so a notification system might need to receive messages about a new confirmed orders, failed payments, successful shipping and many more. This is a <em>fan-in</em> problem, where the messages from many producers need to reach the same consumer.</p><p>If all the producers are putting their messages directly into queues, this would be a really difficult problem to solve—we'd have to somehow intercept our queues, and reliably copy the messages into multiple queues. Building, configuring and maintaining this switchboard simply isn't worth the time or the effort—especially when we could just use <em>topics</em> instead.</p><p>One way to think about topics is that they're similar to the headings you'd see on a notice board at a school or an office. Producers post messages under a specific topic on a board, and everyone interested in that topic will see the message. The most common way messaging systems send the messages to interested receivers is an HTTP(S) request, sometimes also called a <em>webhook</em>. In a push-based system like a HTTP request, the message is pushed into the receiver whether it's ready or not. This re-introduces the coupling that we talked about earlier which we want to avoid—we don't want a situation where our receiver collapses under the crushing load of tens / hundreds / thousands / millions of webhooks over a short span of time. The answer here, again, is to just use a message queue to soak up the messages from the topics at whatever rate they're generated. The receivers can then process them at their own pace.</p><p>Automatically copying a message from one topic into one or more queues isn't strictly a message queue feature, but it is complementary—most full-featured messaging systems will offer a way to do this. Producers will still continue to put messages into a single place as usual, but this will be a topic, and internally the messages will be copied to multiple queues, each of which will be read by their respective receivers.</p><p>In AWS, the service that provides topic based messaging is the Simple Notification Service (<a href="https://aws.amazon.com/sns/">SNS</a>). Here you create a topic and publish messages into it—the API to publish a message into an SNS topic is very similar to that of publishing a message into an SQS queue, and most producers don't have to care about the difference. SNS then has options available to publish that message into any number of <em>subscribed</em> SQS queues (at no extra charge). Each of these subscribed SQS queues would then be processed by their respective receivers.</p><p>If you're working with a different system like Apache Kafka, you'll see similar concepts there as well - you'll have <em>topics</em> that you publish messages into, and any number of consumers can each read all the messages in a topic. Google's Pub/Sub system integrates topics and queues as well.</p><p>This combination of these scenarios is common enough that there's a simple well established pattern to handle it:</p><ul><li>Publish every message to one appropriate topic.</li><li>Create a queue for each receiver.</li><li>Link up each receiver's queue to the topics that the receiver is interested in.</li></ul><p>Since it's usually possible to subscribe a queue to any number of topics, there's no extra plumbing required at a receiver to process messages from multiple topics. And of course, it's possible to have any number of message queues subscribed to a single topic. This kind of setup supports both fan-out as well as fan-in, and keeps your architecture open to expansion and changes in the future.</p><h3>Poison Pills &amp; Dead Letters</h3><p>As morbid as that sounds, when setting up systems to talk to multiple other systems there are bound to be mistakes that happen. The usual problem is that a subscriber is hooked up to receive messages from a topic it knows nothing about in a message format it doesn't understand. What happens? Does the subscriber ignore the message? Or does it acknowledge/delete it? Wouldn't be wrong for it to ignore it, because the message would just keep coming back again and again in an at-least-once system? But isn't it worse to delete/acknowledge a message that we aren't handling? Before we reach for philosophy books made from trees fallen in the woods, we might want to configure a <em>dead letter queue</em> on our queue. This is a feature that many queue systems give us, where if the system sees a message being sent out for processing repeatedly, unsuccessfully each time, it'll move it out into a special queue called a <em>dead letter queue</em>. We'd want to hook this queue up to an alarm of some sort, so we'll quickly know something weird is going on.</p><p>A much worse scenario is one in which the message is explosive in some way—maybe it's formatted in XML instead of JSON, or contains user generated content carrying a malformed input attack that causes your parsing code to crash... your subscriber has just swallowed a <em>poison pill</em>. What happens when this pill reaches the subscriber is heavily dependent on your technology stack, so needless to say you want to think carefully about error handling and exceptions in the subscriber code. The good news is that if you've configured a <em>dead letter queue</em>, just failing silently can be a fine option. The poison pill will eventually show up in the <em>dead letter queue</em> and can be examined. Even if the poison message is crashing your subscriber, running an automated restart with a process manager is often enough to retry the message so many times that it moves it to the dead letter queue. You do need to make sure there are no security implications, though, and remember that this is an easy <a href="https://en.wikipedia.org/wiki/Denial-of-service_attack">DoS attack</a>.</p><p>Remember to always verify your incoming messages, both in terms of whether the message is structured the way you expect it to be, and if you're the intended recipient.</p><h2>The Q-List</h2><p>Here's a list of some of the more popular message queuing systems available right now, with a list of how the concepts we've seen so far apply to each of them. This isn't an exhaustive list of course, so let me know <a href="https://twitter.com/sudhirj">@sudhirj</a> if you think there are any that are missing or misrepresented.</p><h3>AWS SNS &amp; SQS</h3><p>AWS runs two services that integrate with each other to provide full message queuing functions. The <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html">SQS</a> service is a pure message queue—it allows you to create a queue, send a message, and receive a message. That's it. The <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_ReceiveMessage.html"><code>ReceiveMessage</code></a> API on on SQS queue is pull-only, so you'll need to call it whenever your receiver is ready to process a message. There's a <code>WaitTimeSeconds</code> option to block on the call wait for a message for up to 20 seconds, so an effective pattern is to poll the <code>ReceiveMessage</code> API in an infinite loop with the 20 second wait turned on.</p><p>The topics and fan-out / fan-in functions come with the integration of <a href="https://docs.aws.amazon.com/sns/latest/dg/sns-sqs-as-subscriber.html">SNS</a>, which works on the construct of a <em>topic</em>. This allows a message to be posted into a topic, as opposed to a queue. You can then subscribe any number of SQS queues into a topic, so messages published to the topic are copied to all subscribed queues quickly at no additional cost. You'll want to turn on &nbsp;the <a href="https://docs.aws.amazon.com/sns/latest/dg/sns-large-payload-raw-message-delivery.html"><em>raw message</em></a> option, which makes posting a message into an SNS topic effectively equivalent to posting it into an SQS queue—no transformations or packaging of any sort will be applied onto the message.</p><p>SQS &amp; SNS are both fully managed services, so there are no servers to maintain or software to install. You're charged based on the number of messages you send and receive, and AWS handles scaling to any load.</p><p>FIFO options are available on <a href="https://aws.amazon.com/blogs/aws/introducing-amazon-sns-fifo-first-in-first-out-pub-sub-messaging/">SNS</a> and <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html">SQS</a>, with different pricing and capacity guarantees. AWS uses the term <em>message group ID</em> to denote a group heading under which all messages are FIFO. Messages inside a group heading are delivered in order by not giving out the next message until the previous message is deleted.</p><h3>Google Pub/Sub</h3><p>Google provides the <a href="https://cloud.google.com/pubsub/docs/overview">Pub/Sub</a> service as part of their cloud platform to handle message queues and topics in an integrated service. The concept of topics exists as you'd expect it, while a queue is called a <em>subscription</em>. As expected, associating multiple subscriptions with a topic will copy the message to all associated subscriptions. Besides allowing subscribers to poll, or <em>pull</em>, messages from the subscription, Pub/Sub can also do a <a href="https://cloud.google.com/pubsub/docs/push"><em>webhook</em></a> style POST of the message to your server, letting you acknowledge it with a success return status code.</p><p>This is also a fully managed system, like AWS. You're charged based on the number of messages you send, and Google handles scaling the system to whatever capacity you need. It also has a few features that aren't available in the SNS+SQS combo, like allowing you to look into your historical record using timestamps and <a href="https://cloud.google.com/pubsub/docs/replay-overview">replay messages</a>.</p><p><a href="https://cloud.google.com/pubsub/docs/ordering">FIFO functionality</a> exists inside the context of an <em>ordering key</em>, which allows you to ensure that messages inside an ordering key are processed in sequence by not giving you the next message until the previous one has been acknowledged.</p><h3>AWS EventBridge</h3><p>A new offering from AWS, <a href="https://aws.amazon.com/eventbridge/">EventBridge</a> offers a fully managed <em>event bus</em>—this is a varition on the concept of queues and topics, where all messages are posted into a single bus with no visible topic separation. Instead, every message needs to be structured according to a standard format that has information about the message topic inside it. The bus will then read the message, and route it to whichever subscribers have expressed an interest in receiving the messages about that topic. The actual delivery mechanism from the bus to the subscriber can be an SQS queue, webhooks, or many other platform specific options. This makes it easy to manage the event bus as a separately configurable rule-based switchboard, while also allowing easy plugins for archival, auditing, monitoring, alerting, replay, etc.</p><h3>Redis Streams</h3><p>Redis has a relatively new <a href="https://redis.io/topics/streams-intro">Streams</a> feature that works great for message queues. It works by creating topics on the fly and adding messages to them with the <code>XADD</code> command. Reading the messages directly off the topic is possible with <code>XREAD</code>, so each subscriber can maintain its own state (the last read offset) to read through the messages. To avoid each subscriber having to maintain its current state, it makes more sense to create <em>consumer groups</em> using <code>XGROUP CREATE</code>, which are the equivalents of queues. Each message sent to a topic becomes available independently in each consumer group, which can then be subscribed to with <code>XREADGROUP</code>. Messages can be acknowledged with <code>XACK</code>.</p><p>The Redis Streams are automatically FIFO ordered using a timestamp that can either be auto-generated or manually set. This also means that messages can only be processed by one consumer agent at a time. To get around this limitation and work with many consumer agents in parallel, there's a separate non-streams-based pattern described in the documentation for <code>[RPOPLPUSH](https://redis.io/commands/rpoplpush#pattern-reliable-queue)</code>—basically <code>LPUSH</code> messages into a topic, and then <code>RPOPLPUSH</code> them into other lists, each representing a queue, or more accurately its work in progress. <code>LREM</code> works to delete/acknowledge the message.</p><p>Redis is an open source system that you can install and maintain yourself or find managed hosting for. Depending on how durable you need the system to be you might want to figure out the best <a href="https://redis.io/topics/persistence">persistence</a> mechanism to use.</p><h3>Apache Kafka</h3><p><a href="https://kafka.apache.org/documentation/">Kakfa</a> is a popular message broker that works on the concepts of <em>producers</em> publishing messages, called <em>events</em>, to <em>topics</em>. The events in a topic are split into <em>partitions</em>, using a partition key inside of the topic, and FIFO ordering is maintained inside every partition. Events can be streamed to <em>consumers</em> over a socket, or queried by the consumers for a more decoupled approach. For consumers that don't want to maintain state, the concept of a <em>consumer group</em> applies, same as Redis Streams. A <em>consumer group</em> is effectively a queue, where every event posted to a topic is available for processing in every associated <em>consumer group</em>.</p><p>Kafka is open source, but is a complicated to install and maintain, which makes it suitable for larger projects and teams. It scales based on how well you split your events in to partitions—the more partitions you have the more Kafka can distribute work, and each partition has only as much capacity as the server that's in charge of managing it. Managed hosting options are avaiable, but they tend to have high base costs compared to managed services like SNS+SQS, Pub/Sub or RabbitMQ.</p><h3>RabbitMQ</h3><p>RabbitMQ is a popular open source message broker that supports a variety of <a href="https://www.rabbitmq.com/protocols.html">protocols</a>, with <a href="https://www.rabbitmq.com/tutorials/tutorial-five-python.html">direct support</a> for the concepts of topics and queues. RabbitMQ operates under both <em>at-most-once</em> and <em>at-least-once</em> modes, with <em>at-most-once</em> being a fast memory based mode that occasionally writes messages to the disk if necessary (you can choose between pesisted or transient queues). If you want a more reliable, but slower, at-least-once system, you can use the operations described in the <a href="https://www.rabbitmq.com/reliability.html">reliability guide</a> to ask for <em>confirmations</em> when publishing messages, and require mandatory <em>acknowledgements</em> when reading them. Queues are FIFO by default, with the option to enforce sequential processing with acknowledgements.</p><h3>NSQ</h3><p>The first truly distributed message queue in this list, <a href="https://nsq.io/">NSQ</a> is interesting because it's built from the group up to be decentralized. There's no single point to connect to to publish or subscribe to messages—every NSQ node is effectively a full server and talks to every other node. The nodes allow you to publish messages to <em>topics</em>, and each topic can be linked to one or more <em>channels</em>—which are the equivalent of queues. Every message published to a topic is available in all its linked <em>channels</em>.</p><p>NSQ is <a href="https://nsq.io/overview/features_and_guarantees.html">defaults</a> to non-durable, at-least-once, un-ordered messaging, but has a few configuration options to tweak things. It's specially worth considering if your servers are highly networked with each other and you want a system without a single point of failure.</p><h3>NATS</h3><p><a href="https://docs.nats.io/">NATS</a> is a high performance distributed messaging system that's made for fast in-memory messaging. It supports topic based <a href="https://docs.nats.io/nats-concepts/pubsub">broadcast</a> (topics are called <em>subjects</em>), where all messages sent to the <em>subject</em> are sent to all subscriber agents; and <a href="https://docs.nats.io/nats-concepts/queue">distributed queues</a>, where each message in the queue is sent to any one subscriber agent. There isn't a built-in way to have topics linked to queues, but that should be possible to do programmatically.</p><p>NATS supports both <em>at-most-once</em> and <em>at-least-once</em> delivery, and by providing a <a href="https://docs.nats.io/nats-streaming-concepts/intro">streaming system</a> and an <a href="https://github.com/nats-io/jetstream">experimental persistence system</a>. It also has support for subscribing to multiple topics based on subject name patterns, which makes it easier to do fan-in and multi-tenancy.</p><p>NATS works great when you need a high throughput distributed system—it's also pretty easy to run, and supports complex network topology, like having regional clusters with connections between them.</p><h2>The Tail Message</h2><p>These are just a few of the options available right now, and still more are being developed as distributed computing develops and cloud providers grow. I've found that the important thing when evaluating or using queueing systems is to understand the semantics &amp; guarantees they offer. I do this by reading their architectural overviews to get rough idea of how they're implemented. Beneath the surface, the same concepts apply to all of them, just under different name and configuration options.</p><p>If you're running your workloads in a particular cloud provider, the default topic/queue system they offer will usually work fine, as long as you understand what semantics they're offering in each mode. If you're managing your own installation of a queue system, the same thing applies—except you need to be a lot more concerned about the limit imposed by the operating decisions you're making, like how many nodes you're running, failover configuration, drive space, etc.</p><p>Thanks for reading, reach out to me <a href="https://twitter.com/sudhirj">@sudhirj</a> or join the discussion on <a href="https://news.ycombinator.com/item?id=25591492">Hacker News</a> if you have questions or disagree with anything.</p><p>Special thanks to <a href="https://twitter.com/svethacvl">@svethacvl</a> for proofreading, and <a href="https://twitter.com/wallyqs">@wallyqs</a> for notes on NATS.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lessons from history's greatest R&D labs (138 pts)]]></title>
            <link>https://www.answer.ai/posts/2024-01-26-freaktakes-lessons.html</link>
            <guid>39180430</guid>
            <pubDate>Mon, 29 Jan 2024 18:42:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.answer.ai/posts/2024-01-26-freaktakes-lessons.html">https://www.answer.ai/posts/2024-01-26-freaktakes-lessons.html</a>, See on <a href="https://news.ycombinator.com/item?id=39180430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<blockquote>
<p><strong>Note from Jeremy</strong>: <em>There are few things more important to our civilization than understanding how to better do R&amp;D. Thankfully, Eric Gilliam has dedicated himself to studying this question. As a result, he’s become the foremost scholar and historian of 19th and 20th century R&amp;D labs. I thought I was fairly well informed when it comes to the history of these labs, but after talking to Eric, I quickly realised I’m a rank amateur by comparison! Eric’s knowledge of the history of modern research and development is unparalled, and I found his insights into why some organizations were dramatically more effective than others to be utterly compelling. Therefore, I asked him for his totally honest assessment of our plans for Answer.AI, based both on our written plans and a number of in-depth conversations we had together. Today we are publishing a guest post with his analysis, cross-posted from <a href="https://www.freaktakes.com/p/lessons-answerai-can-learn-from-historys">FreakTakes</a>, his blog.</em></p>
</blockquote>
<audio controls="">
  <source src="https://www.answer.ai/posts/2024-01-26-freaktakes-lessons.mp3" type="audio/mpeg">
  Your browser does not support the audio tag.
</audio>
<ul>
<li>This article is also available in AI-generated spoken audio format – play directly in the above player, or click the menu on the right to download the mp3 file. Skip to 3m20s to get past the intro section and jump to the main article.</li>
</ul>
<p>Jeremy Howard (former President and Chief Scientist of Kaggle) and Eric Ries (creator of The Lean Startup movement and Long Term Stock Exchange) have teamed up to found a new applied R&amp;D lab:&nbsp;<a href="https://www.answer.ai/">Answer.AI</a>. When speaking with Jeremy, he made it clear that many details of&nbsp;Answer.AI’s structure are still being worked out. Only announced a month ago, the org is still in its early development stages. But the founders have conviction on certain principles. The most prominent of them is one extremely relevant to my regular readers: The founders seem to be particularly inspired by Edison’s Menlo Park Lab and the early days of commercial electric research.</p>
<p>In the piece, I’ll briefly examine the (working) plans for the lab and do some historical analysis, detailing:</p>
<ol type="1">
<li>What the earliest electrical R&amp;D labs can teach Answer.AI</li>
<li>Useful rules-of-thumb from other historically great applied R&amp;D labs</li>
<li>Potential pitfalls to keep in mind as they move forward</li>
</ol>
<p>You can find more thorough historical evidence in my prior pieces for any of the lab details I mention, listed below:</p>
<ul>
<li><a href="https://worksinprogress.co/issue/thomas-edison-tinkerer/">Thomas Edison, tinkerer</a> published in <em>Works in Progress</em></li>
<li><a href="https://www.freaktakes.com/p/tales-of-edisons-lab">Tales of Edison’s Lab</a> (podcast)</li>
<li><a href="https://www.freaktakes.com/p/irving-langmuir-the-general-electric">Irving Langmuir, the General Electric Research Laboratory, and when applications lead to theory</a></li>
<li><a href="https://www.freaktakes.com/p/how-did-places-like-bell-labs-know">How did places like Bell Labs know how to ask the right questions?</a></li>
<li><a href="https://www.freaktakes.com/p/the-third-university-of-cambridge">“The Third University of Cambridge”: BBN and the Development of the ARPAnet</a></li>
<li><a href="https://www.freaktakes.com/p/an-interview-with-chuck-thorpe-on">An Interview with Chuck Thorpe on CMU: Operating an autonomous vehicle research powerhouse</a></li>
<li><a href="https://www.freaktakes.com/p/illiac-iv-and-the-connection-machine">ILLIAC IV and the Connection Machine</a></li>
<li><a href="https://www.freaktakes.com/p/a-progress-studies-history-of-early-001">A Progress Studies History of Early MIT — Part 2: An Industrial Research Powerhouse</a></li>
<li><a href="https://www.freaktakes.com/p/how-karl-compton-believed-a-research">How Karl Compton believed a research department should be run</a></li>
</ul>
<p>Each of the orgs listed has lessons to teach Answer.AI. But none are a perfect analog. So, as the piece progresses, I’ll explain which lessons I think most strongly apply to Answer.AI. With that, let’s get into it!</p>
<div>
<figure>
<p><img src="https://www.answer.ai/posts/the-boys.jpg" width="500"></p>
<figcaption>Edison and “the boys” preparing the First Practical Incandescent Lamp for Testing at Edison’s Menlo Park Lab. Illustration by Harry K. Flemming. Photo Courtesy of the Henry Ford Museum</figcaption>
</figure>
</div>
<section id="answer.ai-in-a-nutshell">
<h2 data-anchor-id="answer.ai-in-a-nutshell"><a href="http://answer.ai/">Answer.AI</a> in a Nutshell</h2>
<p>Jeremy’s blog post <a href="https://www.answer.ai/posts/2023-12-12-launch.html">announcing Answer.AI</a> makes it clear that the org is, to a large degree, inspired by the field of electricity’s path of progress in the 1800s. He believes the current state of the AI field is similar to the state of the electricity field between the work of Michael Faraday and Edison’s lighting projects. This was an era in which new electrical findings were being pieced together, but few had made any progress in turning the potential of electricity into great applications.</p>
<p>I don’t find this comparison crazy. So far, I don’t believe AI has come close to the level of breakthrough that electricity proved to be. Electricity brought the sunlight indoors for a negligible cost <em>and</em> powers so many of our modern conveniences— refrigeration, TVs, central heating, etc. That’s a high bar. <em>However</em>, given that human ingenuity created the breakthrough that was electricity and each of those applications, it is surely worth considering that AI <em>could</em> grow to be the most impactful field of them all. Whether AI does reach that level of promise, to me, is a question of human ingenuity. So, I have no issue with Jeremy comparing the AI field to the electrical field c.&nbsp;1830 to 1910.</p>
<p>With that elephant out of the way, let’s briefly examine what sets <a href="https://www.answer.ai/">Answer.AI</a> apart from AI labs like OpenAI and Anthropic. From a funding perspective, Answer.AI seems much, much cheaper. The founders have initially raised USD10 million. This stands in stark contrast to the gargantuan initial rounds of OpenAI and Anthropic. Also, Answer.AI’s research agenda is more application-centric. The following excerpt from Jeremy’s blog post highlights what he thinks differentiates the lab’s approach:</p>
<blockquote>
<p>At Answer.AI we are not working on building AGI. Instead, our interest is in effectively using the models that already exist. Figuring out what practically useful applications can be built on top of the foundation models that already exist is a huge undertaking, and I believe it is receiving insufficient attention.</p>
<p>My view is that the right way to build Answer.AI’s R&amp;D capabilities is by bringing together a very small number of curious, enthusiastic, technically brilliant generalists. Having huge teams of specialists creates an enormous amount of organizational friction and complexity. But with the help of modern AI tools I’ve seen that it’s possible for a single generalist with a strong understanding of the foundations to create effective solutions to challenging problems, using unfamiliar languages, tools, and libraries (indeed I’ve done this myself many times!) I think people will be very surprised to discover what a small team of nimble, creative, open-minded people can accomplish.</p>
<p>At Answer.AI we will be doing genuinely original research into questions such as how to best fine-tune smaller models to make them as practical as possible, and how to reduce the constraints that currently hold back people from using AI more widely. We’re interested in solving things that may be too small for the big labs to care about — but our view is that it’s the collection of these small things matter a great deal in practice.</p>
</blockquote>
<p>It would be unfair to say that an application-centric research agenda is necessarily less ambitious than AGI. Those biased toward basic research might say so, but I don’t think that opinion is very historically-informed. Edison himself was application-centric above all else. His deep belief in market signals is fascinating when juxtaposed with the market indifference of many great academic physicists. In the book <em><a href="https://amzn.to/3HoUUbW">From Know-How to Nowhere</a></em>, a history of American learning-by-doing, Elting Morison described the interesting nature of Edison’s motivations:</p>
<blockquote>
<p>If the means by which he [Edison] brought off his extraordinary efforts are not wholly clear, neither is the cause for his obsessive labors. No diver into nature’s deepest mysteries carrying next to nothing for the advancement of knowledge and even less for the world’s goods, he would become absorbed in making something work well enough to make money. The test in the marketplace was for him, apparently, the moment of truth for his experiments.</p>
</blockquote>
<p>Edison built his god-like reputation by dreaming in specific applications. He kept market, resource, and manufacturing constraints in mind from the earliest stages of his projects. Edison dreamed practical, realizable dreams. And when the limitations of component technologies stood in the way of his dreams, he often had the talent to invent new components or improve existing materials. Edison’s biggest dream, the light bulb, mandated that&nbsp; Edison solve a much broader set of problems. The following excerpts from my <a href="https://worksinprogress.co/issue/thomas-edison-tinkerer/">Works in Progress piece on Edison</a> paint a clear picture of his ambitious but practical dreams:</p>
<blockquote>
<p>After Edison’s bulb patent was approved in January 1880, he immediately filed another for a ‘System of Electrical Distribution’. Filing for these so close together was no coincidence. To Edison, it was never just a bulb project. It was a technical business venture on a possibly unprecedented scale. Edison wanted to light up homes all over the world, starting with lower Manhattan.</p>
<p>Bringing the project from dream to mass-market reality would require solving over a hundred technical problems. His was a new bulb that needed to be powered by a generator that did not yet exist at the start of the project, strung up in houses that had no electricity, connected via underground street wiring that was only hypothetical, and hooked up to a power station that had never existed before.</p>
<p>Yet, at the end of two years’ time, Edison would do it. And, just as importantly, the entire venture was profitable by the end of the project’s sixth year.</p>
</blockquote>
<p>Edison was clearly doing a different kind of dreaming than those who do basic research. His lighting work embodies what extreme ambition looks like in application-centric research. Answer.AI making this kind of ambitious, applied work their North Star is an extremely interesting goal.</p>
<p>This goal has the potential to give Answer.AI a comparative advantage in the growing space of for-profit AI labs. For example, the most ambitious aspects of OpenAI are considered to be in its research, not its work on applications. Answer.AI’s particular setup can also set it apart from AI startups and academic labs. New AI startups do some research on how to commercialize new AI models in new ways, but they generally have short runways. In this kind of environment, only specific types of research projects can be pursued. Academic labs — for many reasons covered elsewhere on my Substack (such as in the <a href="https://www.freaktakes.com/s/arpa-playbook">ARPA series</a>) — don’t have the right combination of incentives, experience, and staffing to build new technologies in most problem areas. The main incentive of the profession, in a simplified form, is producing many paper studies that get cited many times. Answer.AI has the chance to let its alternative focus lead it to areas under-explored by academics, companies with brief timelines to hit revenue benchmarks, and more AGI-focused R&amp;D labs.</p>
<p>Legally, Answer.AI is a company. But in practice, it might hover somewhere between a lab and a normal “profit-maximizing firm” — as was the case with Edison’s lab. The founders seem perfectly content to pursue high-risk projects that might lead to failures or lack of revenue for quite a while. In saying this, I do not mean to imply they are content to light money on fire doing research with no chance of a return. Rather, they hope to fund a body of research projects that ideally have positive ROI in the long term. They are just not overly concerned with short-term revenue creation.</p>
<p><em>(Making the pursuit of research agendas like this easier is actually one of the founding goals of Ries’ Long Term Stock Exchange — which I address later.)</em></p>
<p>There is apparently no pressure to produce a product that can hit software VC-style revenue goals within 12-24 months, or anything similar. This is good. Seeking to satisfy these types of metrics does not traditionally permit a company to act like a truly ambitious R&amp;D lab. I’m not saying it can’t happen — DeepMind seems to have made it work in its early years — but it does require pushing against investor pressure quite strongly. The VC money raised for Answer.AI has left the founders with enough voting shares that investors can’t veto founders’ decisions. Additionally, Howard says the company’s investors understand what they are trying to build is, first and foremost, a lab. This is a great step towards building an organization focused on building very useful, very new things rather than the most profitable thing possible — which often comes with bounded technical novelty.</p>
<p>Interestingly, Answer.AI will also keep a small headcount. Jeremy built Fastmail up to one million accounts with only three full-time employees. He hopes to keep the Answer.AI team exceptionally talented and “ruthlessly small” in a similar way; he believes keeping teams small is important to building new, technically complex things.</p>
<p>Now that I’ve outlined some important pieces of Answer.AI’s vision, I’ll dive into the historical analysis. In the first section, I detail lessons that Answer.AI can draw from both Edison’s Menlo Park laboratory and the Early GE Research Laboratory. In the following section, I’ll share useful lessons from other historically great industrial R&amp;D labs. Lastly, I’ll highlight the bureaucratic details that explain why the operational models of the great industrial R&amp;D labs have not been replicated often.</p>
</section>
<section id="learning-from-the-first-electrical-rd-labs">
<h2 data-anchor-id="learning-from-the-first-electrical-rd-labs">Learning from the First Electrical R&amp;D Labs</h2>
<p>I find it exciting that Edison’s Menlo Park lab is a North Star for Answer.AI. I covered Edison’s work in several pieces because I think evergreen lessons can be drawn from his work. <em>But</em> I think a more complete way to incorporate lessons from the 1870-1920 electrical space is to draw on the work of both Edison’s Menlo Park Lab <em>and</em> the young GE Research Lab. The latter operated as a more traditional industrial R&amp;D lab. GE Research’s history holds many lessons to help steer Answer.AI’s problem selection and work on its standard projects. However, <em>exceptionally ambitious</em> projects may draw more heavily on the lessons of Edison’s lab.</p>
<p><em>(As a note, while Edison General Electric was one of the two companies that merged to become GE — along with Thomson-Houston Electric — Edison had essentially nothing to do with the formation of the iconic GE Research Laboratory.)</em></p>
<p>Different types of projects characterized the work of the two electrical labs. When it came to electrical work, for years, Edison’s lab and mental efforts were focused on doing everything necessary to bring a single, revolutionary product to market. On the other hand, GE Research usually had many separate courses of research underway at once. These projects all sought to improve the science and production of existing lighting systems, but they were otherwise often unrelated to each other. Additionally, GE’s work could be categorized as more traditional “applied research.” The lab was not actively looking to create a field of technology from scratch as Edison did. GE Research’s projects were often novel and ambitious, but in a different way than Edison’s.</p>
<p>Later, I will explore the types of novelty the GE Research Lab pursued. First, I’ll give the reader a more fine-grained idea of how Edison’s lighting project actually operated.</p>
<section id="lessons-from-edisons-work-on-electricity">
<h3 data-anchor-id="lessons-from-edisons-work-on-electricity">Lessons from Edison’s Work on Electricity</h3>
<p>Edison’s lighting work provides great management lessons for those looking to direct a large chunk of a lab’s efforts toward a single, big idea.</p>
<p>Edison’s major contribution to the field of electricity was not inventing each of the components in his lighting system, but in turning a mass of disparate gadgets, scientific principles, and academic misconceptions into a world-changing system. The burden of doing “night science” — <a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1800-6">as Francois Jacob refers to it</a> — largely fell on Edison. In the late 1870s, nobody knew much about electricity yet. The existing academic literature had more holes than answers, and many of its so-called “answers” turned out to be wrong or misleading. From this shaky starting point, Edison proceeded. He combined his unique mix of attributes and experience to deliver a world-changing system. These included: knowledge of several adjacent scientific fields, deep knowledge in then-overlooked experimental areas, market knowledge, manufacturing knowledge, and the ability to adequately operate a small research team.</p>
<p>In large part, Edison created his lab as a way to scale himself. As a result, to understand how his lab operated, one needs to know how Edison himself carried out his explorations. Edison was one of the more stubborn experimentalists of all time. He spent most of his waking hours carrying out one experiment or another. While he did pore over scientific literature, for him, nothing was settled until he proved it for himself at the lab bench.</p>
<p>I write in my <em>Works in Progress</em> piece:</p>
<blockquote>
<p>Edison respected scientific theory, but he respected experience far more. In Edison’s era of academia as well as today’s, many professors had a certain preference for theory or ‘the literature’ over hands-on improvement. Because of this Edison did not care much for professors. He was even known to go on long diatribes, during which he had assistants open up textbooks, locate scientific statements that he knew to be untrue from experience, and quickly rig up lab demonstrations to disprove them. ‘Professor This or That will controvert [dispute with reasoning] you out of the books, and prove out of the books that it can’t be so, though you have it right in the hollow of your hand and could break his spectacles with it.’</p>
</blockquote>
<p>Contained in his head was a database of countless experiments and results that made it seem as if his “intuition” was far beyond his contemporaries. This left him with an unparalleled skillset and body of knowledge. If anyone could feel comfortable pursuing a project that others had previously failed at, it was Edison. Edison’s confidence in his skills was never more on display than when he chose to pursue his lighting work. Many in the scientific establishment knew electric bulb lighting was technically possible, but claimed they had proven that it could never be economical. Edison disagreed.</p>
<p>On top of Edison’s admirable approach to experimentation, he brought a high level of practicality to his process. He knew his inventions needed to make commercial sense in order to make it out of the lab. So, even in early courses of experimentation, he kept factors like manufacturability in mind. He wouldn’t commit much time to something that didn’t make commercial sense. With that being said, Edison wanted to change the world with his technologies more than he wanted to get rich. So, the practical factors he paid aggressive attention to were primarily treated as constraints. He did not optimize for profitability, but he knew his ideas needed to be profitable. Nobody who wanted to optimize for profit would have pursued lighting in the way Edison did. The technical risks were too great.</p>
<p>Edison was able to imagine an ambitious system that required many technical advances. It was so futuristic that maybe only he was capable of coming up with it. But just as impressively, he was able to do it profitably and on schedule. His dogged commitment to experimentation seems to be largely responsible for this. Edison and “the boys” constantly experimented on every piece of the process to improve and learn more about all the sub-systems in Edison’s grand system. They wanted to know how every piece of every sub-system performed in all conditions. I’ll share just two excerpts from my <em>Works in Progress</em> piece as examples.</p>
<p>The first is from Edmund Morris’ biography of Edison. It recounts how thoroughly Edison and his trusted aid, William Batchelor, were in carrying out round after round of filament experiments:</p>
<blockquote>
<p>For week after week the two men cut, planed, and carbonized filaments from every fibrous substance they could get — hickory, holly, maple, and rosewood splints; sassafras pith; monkey bast; ginger root; pomegranate peel; fragrant strips of eucalyptus and cinnamon bark; milkweed; palm fronds; spruce; tarred cotton; baywood; cedar; flax; coconut coir; jute boiled in maple syrup; manila hemp twined and papered and soaked in olive oil. Edison rejected more than six thousand specimens of varying integrity, as they all warped or split…</p>
<p>In the dog days, as heat beat down on straw hats and rattan parasols, the idea of bamboo suggested itself to him. Nothing in nature grew straighter and stronger than this pipelike grass, so easy to slice from the culm and to bend, with its silicous epidermis taking the strain of internal compression. It had the additional virtue, ideal for his purpose, of being highly resistant to the voltaic force. When he carbonized a few loops sliced off the outside edge of a fan, they registered 188 ohms cold, and one glowed as bright as 44 candles in vacuo.</p>
</blockquote>
<p>This approach went far beyond bulb filaments. The following excerpt describes the work of one of Edison’s lead mechanics in turning the Menlo Park yard into a 1/3 scale model of what they would later install in Lower Manhattan. I write:</p>
<blockquote>
<p>[Kruesi, Edison’s mechanic] along with a group of engineers and a team of six diggers, turned the excess land of the lab in Menlo Park, New Jersey…into a one-third-scale model of Edison’s first lighting district in lower Manhattan. This team tested and re-tested the electricity delivery system, digging up Menlo Park’s red clay to lay and re-lay an experimental conduit system. The team carried out countless tests to ensure that they found materials to efficiently carry the electric current while also keeping the delicate materials safe from water and ever-present New York City rats.</p>
</blockquote>
<p>The entire process was marked by the classic trial-and-error of the Edisonian process. The first subterranean conducting lines and electrical boxes the group laid were completely ruined by two weeks of rain — despite being coated with coal tar and protected with extra wood. While the diggers dug up the failed attempt so the damage could be examined, Kruesi and a young researcher…studied and tirelessly tested unbelievable numbers of chemical combinations — making full use of the laboratory library and chemical room — until, finally, a blend of ‘refined Trinidad asphaltum boiled in oxidized linseed oil with paraffin and a little beeswax’ was found that protected the electrical current from rain and rats. &gt;</p>
<p>Edison built his own style of dogged experimentation into the culture of his lab. Since the lab was meant to scale Edison, this makes perfect sense; he was a man with far more ideas than hands. So, he hired more hands. Edison did not search far and wide to hire the world’s best research minds, and many of those he employed did not even have scientific backgrounds. This didn’t matter much to Edison because most of them were employed to undertake courses of research that he had directed them to pursue. A couple of his Menlo Park employees had advanced scientific degrees, but far more did not. For the most part, the lab and its activities were steered by Edison and his ideas. As a result, the productivity of his lab followed wherever his attention went. After some time working on a project area, Edison would often grow antsy and wish to move on to the next thing — he craved novelty. The lab’s resources and extra hands would move with him. As we’ll see in the next section, this stands in stark contrast to how the GE Research Lab recruited and chose problems.</p>
<p>Menlo Park’s electrical activities provide a great management playbook for what it looks like to direct a lab’s efforts toward a single, major system. If Answer.AI does not want to go all-in on one thing, it can still find a way to apply this playbook to a certain focused team of employees while leaving the others to tinker around with exploration-stage ideas. In Edison’s less-focused experimentation periods, his lab served as more of an “invention factory,” doing this sort of fiddling. Additionally, Edison’s preference for application and commitment to experimentation over theory in a young area of science can surely provide Answer.AI some inspiration.</p>
<p>Of course, Edison did some things better than others. Edison’s most easily-spottable “deficiency” is that his lab was largely dependent on him. Without him and his big ideas, the lab would have probably ground to a halt. While Edison’s technical vision, practicality, and experimental approach are absolutely worthy of emulation, the lessons of GE Research should probably be added into the mix as well. GE operated as more of a prototypical industrial R&amp;D lab with an approach quite suited to the fact that the science of electricity was beginning to mature in the early 1900s.</p>
</section>
<section id="lessons-from-the-young-ge-research-laboratory">
<h3 data-anchor-id="lessons-from-the-young-ge-research-laboratory">Lessons from the Young GE Research Laboratory</h3>
<p>The young GE Research lab took a different approach to electricity research than Edison. The lab worked on many unrelated projects at once, recruited more talented researchers, and allowed these talented researchers more freedom to exert the scientific method on commercializable projects. The lab did not undertake projects that were as purposely futuristic as Edison did. Nobody from the lab earned nicknames like “the Wizard of Menlo” or “the Wizard of Recorded Sound.” But early GE Research was still responsible for a Nobel Prize and making the light bulb a much-improved, more cost-effective technology.</p>
<p>Elting Morison wrote the following on the lasting impact of GE Research’s early decades:</p>
<blockquote>
<p>There seems little doubt that…much that was done in Schenectady in electrical engineering and some parts of physics was both better done and more interesting than what was being done in those fields in any American university.</p>
</blockquote>
<p>In its heyday, even great researchers like Karl Compton hoped to shift their academic departments to operate more like GE Research.</p>
<p>While GE did simultaneously pursue diverse projects, there was a unifying thread holding all of the projects at GE Research together. Each project aimed to improve the quality and profitability of GE’s products and manufacturing. Under that unifying theme, all kinds of projects were encouraged. Much of the research was very applied, particularly in the early years when the lab was still proving itself.</p>
<p>William Coolidge was one of the lab’s most talented applied researchers in its early years. Coolidge joined the lab in 1905, part-time while teaching courses at MIT. Coolidge had the kind of toolkit typical of many MIT professors in that era. He had a far greater grasp of the science of physics and metallurgy than somebody like a blacksmith; he was simultaneously far closer to a blacksmith than one would ever expect a university researcher to be. With this differentiated toolkit, he did science in a way that was not typical of academics. In describing the process that led to his successes at GE, he claimed that he was, “guided in the main by experiment itself rather than by metallurgical knowledge.”</p>
<p>Willis Whitney, the founding Director of GE Research and former MIT professor, recruited Coolidge to build on findings Whitney himself had made. Whitney’s initial course of research had found an improved metalized carbonized cellulose filament for bulbs. Whitney’s results proved very profitable for the lab. It seemed reasonable that an actual metal filament could perform even better. Whitney thought Coolidge and his metal-working skills were well-suited to pursue the area further.</p>
<p>Coolidge expertly applied practical skills in concert with scientific knowledge to pursue the problem. Elting Morison described a small sample of Coolidge’s workflow:</p>
<blockquote>
<p>He suspended tungsten powder in an amalgam of bismuth, cadmium, and mercury. He then passed the resulting substance through tiny dies — drawing it — and obtained a silvery pliable wire. At that time, he thought he had reached ductility and the search was over. But when a current was passed through this wire the mercury, cadmium, and bismuth distilled out, leaving, unfortunately, a nonductile tungsten. But it also proved to be tungsten in the purest state he had yet produced.</p>
</blockquote>
<p>I continue in my FreakTakes piece, writing:</p>
<blockquote>
<p>He eventually iterated his way to a workable process where…the more pure tungsten was put through a specific combination of metal-working processes at a temperature that worked that produced rods of tungsten about 1 mm in diameter. These 1mm rods could then be drawn and re-drawn through rods of decreasing size until you were left with wires of tungsten .01 mm in diameter. When put in the vacuum-sealed bulb, electricity ran through the tungsten filaments and demonstrated an efficiency of 1 watt per candle — extending the life of a bulb up to 27x.</p>
<p>Within 5 years, 85% of all lamps would be made from tungsten. As the project went on, more and more research chemists and technical assistants grew to be involved in the wide-ranging steps and combinations involved in Coolidge’s experiments. But it worked. GE had the factories re-fit and deployed the new bulb. Coolidge moved on to other research.</p>
</blockquote>
<p>The success of Coolidge’s hybrid work style, not dissimilar to Edison’s, is surely a useful data point to Answer.AI. But GE Research also did work that went far beyond Coolidge’s technically adept, applied science. The lab was fantastic at making use of talented individuals who were very academic. Irving Langmuir was a prime example. I described his interests in my original piece:</p>
<blockquote>
<p>It should be noted…Langmuir did not even care about lightbulbs. Well, I guess that is not technically true. The bulb interested him because 1) he thought a metal like tungsten was cool because it could accept really high temperatures which opened up options to the scientist working with it and 2) these vacuum-sealed bulbs provided a pristine environment for controlled scientific investigations.</p>
</blockquote>
<p>To Langmuir, light bulbs were primarily a playground in which to do his science. But Willis Whitney knew how to take an individual like that and direct his energy towards productive ends. The lab deployed a principle that I call extending a “long leash within a narrow fence” to basic researchers like Langmuir.</p>
<p>The way the lab facilitated this was rather simple. On his first day, Langmuir was told to walk around the applied end of the lab and ask people about their projects. Whitney permitted him to undertake any course of investigation of any phenomenon he wanted, <em>but</em> it had to be directly related to an existing problem/limitation/constraint that the applied folks were working through. These applied folks were working on projects that rather directly plugged into GE’s operations, so there was minimal risk of Langmuir’s work not amounting to anything useful if he succeeded and found answers. With that assurance of applicability, Langmuir was given extensive timelines to find answers to open questions.</p>
<p>Langmuir’s first course of research focused on the constant bulb-blackening problem common to bulbs at the time. The problem was generally attributed to a bulb’s imperfect vacuum. Langmuir found this problem to be a great excuse to carry out a course of experimentation he found interesting. Morison described Langmuir’s thought process as follows:</p>
<blockquote>
<p>If residual gases — imperfect vacua — produced a bad effect — blackening — here was a fine opportunity to study the effects produced by different gases introduced one by one into the bulb. What he wanted to do, he told Whitney, was simply to plot the interactions of various gases exposed at low pressures to very high temperatures in the filament. Nobody knew very much about this phenomena and he wanted to look into it simply “to satisfy [his] own curiosity.”</p>
</blockquote>
<p>Langmuir carried out this course of research over three years. There were many gases and temperatures to test, which took time. But unforeseen results constantly took Langmuir off in different directions. Exploring these unforeseen results often entailed new courses of experiment altogether. With his long leash, Langmuir was able to figure out that imperfect vacua were not what caused bulb blackening at all. Rather, it was that tungsten vapor particles were finding their way onto the wall of the bulb. Temperature was the issue.</p>
<p>He also discovered that different gases markedly changed the rate of evaporation. One extreme example was nitrogen, which reduced the evaporation rate by 100-fold. <em>However</em>, adding nitrogen to the bulbs caused the electrical efficiency of the system to decrease drastically. So, the existing bulb design with nitrogen added was less cost-efficient than the normal bulbs. But Langmuir was undeterred. This was progress.</p>
<p>Existing fundamental research in this area led him to believe that this efficiency issue could be alleviated by increasing the diameter of the filament. Further experimentation proved this to work. He also found that coiling the filament in a certain way could mitigate the heat loss issue. The final result was a novel bulb that used an inert gas instead of a vacuum to reduce bulb blackening. Along with the coiled tungsten filament, this new bulb only required .5 watts per candle and lasted three times longer than any other bulb.</p>
<p>Once he passed the bulb project onto the engineering team at GE Research, Langmuir set his sights on an anomaly he had come across talking with the lab’s more applied staff. The bulbs in the lab had a design that depended on only a few milliamperes of current flowing across the space between one end of the filament and the other. Langmuir noted this anomaly in a letter to <em>Scientific Monthly</em>, writing:</p>
<blockquote>
<p>This fact seemed very peculiar to me, for the work of Richardson and others had indicated that at temperatures as high as those used in the tungsten-filament lamp, currents of many amperes should flow across the space. In other words, according to the then-accepted theory of the electron emission from hot filaments, a serious difficulty should have been encountered in the construction of tungsten-filament lamps. The fact that we did not meet any such difficulty therefore seemed to me a peculiar fact that should be investigated.</p>
</blockquote>
<p>In the brief course of exploration that followed from Langmuir, he discovered what is now known as the space-charge effect. This work combined with follow-on work from Coolidge to produce an entirely new kind of GE X-ray tube.</p>
<p>Under this “long leash within a narrow fence” guideline, Irving Langmuir would go on to be partially responsible for a handful of new and improved product lines at GE. Additionally, the knowledge he created with his tungsten filament work went far beyond padding GE’s balance sheet. Over the course of his project, he noted that the way tungsten vapor condensed did not gel with existing academic theory. His subsequent exploration of this phenomenon led Langmuir to be credited with founding the field of surface chemistry. Langmuir earned himself a Nobel Prize for his efforts.</p>
<p>There was a symbiosis in the GE lab between Langmuir types and the Coolidge types — the latter skillset being more standard in the lab. I imagine Answer.AI will have no shortage of Coolidge-like individuals: bright, Kaggle Grandmaster-type individuals who understand academic theory but whose specialty is in expertly applying their craft in dirty, practical situations. Someone like Jeremy Howard will likely have great intuition about how to utilize these individuals. The GE playbook — with its “long leash within a narrow fence” principles — can help Answer.AI think through how to deploy basic researchers in its operations</p>
<p>Langmuir’s career at the GE Research Lab provides a clear roadmap for how to optimally leverage a basic researcher’s energies in an applied context. Langmuir getting paid to investigate <em>any</em> anomalies would likely have satisfied his curiosity. However, it was his investigation of the <em>right</em> anomalies that made this a beneficial arrangement for GE Research.</p>
<p>In general, there is a time and place to apply insights from either Edison’s playbook or GE’s. The maturity of a given research field or technology area has a strong hand in dictating which set of principles is more applicable. Edison came first and had to shoulder the burden of developing an extensive technical system to power the “killer app” that was his bulb. GE Research had the benefit of working on an existing technology area with moderately developed science and existing user technology (thanks to Edison), but the technology still needed a lot of work to become reliable and economical.</p>
<p>A lab can simultaneously employ both playbooks. Even most of Edison’s projects were modest in relation to his lighting work. When inventing for existing fields, such as telephony, Edison contained his inventive streak to working within existing technical systems. He knew nobody would rebuild entirely new telephone infrastructure just because the young inventor had rigged up a moderately improved but completely different version. When adding to Bell’s telephone, he simply invented a carbon transmitter that could plug directly into the system. This device made voices come through much clearer. That was it: one gadget that cleanly plugged into the existing system. Technologies like these may not be as earth-shattering as Edison’s lighting system, but they were still enough to make him a world-famous inventor in his own time.</p>
<p>It was about impact. In optimizing impact, I thoroughly suspect Answer.AI to make great use of the playbooks of both of these small industrial research giants.</p>
</section>
</section>
<section id="learning-from-other-historically-great-industrial-rd-labs">
<h2 data-anchor-id="learning-from-other-historically-great-industrial-rd-labs">Learning From Other Historically Great Industrial R&amp;D Labs</h2>
<p>I’d now like to highlight applicable lessons from other research operations covered on my Substack. I’ll cover the orgs in no particular order.</p>
<section id="striking-the-balance-of-bbn-and-cmus-autonomous-vehicle-group">
<h4 data-anchor-id="striking-the-balance-of-bbn-and-cmus-autonomous-vehicle-group">Striking the Balance of BBN and CMU’s Autonomous Vehicle Group</h4>
<p>FreakTakes recently covered two historically great DARPA contractors who expertly balanced the competing pulls of project novelty and deployable technology. The first was Bolt, Beranek, and Newman (BBN), the contractor primarily responsible for the ARPAnet. The second was Carnegie Mellon’s autonomous vehicle groups.</p>
<p>BBN embodied what it meant to be a “middle ground between academia and the commercial world.” The firm was initially set up by MIT acoustics professors to pursue their contracting work more ambitiously. In its early decades, the firm gradually expanded its contracting efforts into the computing space, initially under the leadership of BBN VP J.C.R. Licklider. BBN soon became a common home for the best researchers in Cambridge, abandoning their academic positions to work for BBN. The firm’s growing reputation even earned the monicker the “third university of Cambridge.”</p>
<p>The firm’s revenue was primarily sourced from research contracts given out by orgs like DARPA, research grantmakers, and aerospace firms. BBN’s positioning was somewhat unique; when compared to industry, the firm emphasized novelty and cutting-edge technology work. This insistence on novelty helped the firm recruit individuals who felt a bit too talented to waste away working on derivative projects at Westinghouse. When compared to academia, BBN emphasized working on real technology that people would use in the near term. J.C.R. Licklider is just one prominent example of an individual who left a tenureship at MIT to work on more useful technology down the road at BBN. Leveraging this positioning, the firm was able to recruit the best talent.</p>
<p>BBN also provided its most talented individuals latitude to ply their minds broadly. Many projects at BBN showcased the extreme potential of small teams of talented individuals with broad technical knowledge. Only eight BBNers were primarily responsible for pushing the early ARPAnet into existence. The size of the team was no accident; Frank Heart, the engineering lead of the project, described why he preferred a team of this size in his <a href="https://conservancy.umn.edu/handle/11299/107349">oral history</a>:</p>
<blockquote>
<p>I tend to believe important things get done by small groups of people who all know all about the whole project. That is, in those days all the software people knew something about hardware, and all the hardware people programmed. It wasn’t a group of unconnected people. It was a set of people who all knew a lot about the whole project. I consider that pretty important in anything very big. So I suppose if you call it a management style, that would be something I’d state. I think also that they were a very, very unusually talented group. I think things tend to get done best by small groups of very, very good people — if you can possibly manage that. You can’t always manage it. So if you again want to call it a management style, it is to get the very, very best people and in small numbers, so they can all know what they’re all doing.</p>
</blockquote>
<p>Lockheed Skunk Works legend “Kelly” Johnson also held quite similar beliefs when putting together teams to build experimental aircraft. Particularly in the early stages of novel projects, there is a strong case for keeping things small, with specialists who understand the fields that touch theirs. To me, Jeremy’s belief in small teams seems well-validated by technical history.</p>
<p>BBN demonstrates the ideal case of a research firm that wholly embraces technical novelty. CMU can be thought of as the flipside of that coin: a university that wholly embraced systems-building and used firm-like management practices to do so. The highlight of CMU’s later-1900s systems work was its autonomous vehicle projects. The academic group staffed itself with researchers responsible for technical integration and management-style work to effectively carry out novel technological systems building.</p>
<p>Similar to BBN, CMU’s positioning was differentiated from both industry and academia. This fact became very clear as DARPA’s mid-1980s autonomous vehicle work progressed. CMU was seemingly the only contractor excited about technical novelty <em>and</em> systems integration. Martin Marietta — the defense prime in charge of DARPA’s Autonomous Land Vehicle — obsessed over ways to hit DARPA’s demo benchmarks while using unambitious, dated technologies. Simultaneously, the academic vision research groups cared more about using the camera data to write papers than helping directly contribute to building a functional driving system. CMU was the only contractor involved in the project who truly cared about building a novel, functional system. DARPA eventually recognized this and gave them ample funds to build successive generations of autonomous vehicles. The rest was history.</p>
<p>CMU carried out this work with a management structure that was more firm-like than most academic labs. For example, Chuck Thorpe did project management-style work for the team with firm-like incentives — he was a researcher promoted based on vehicle performance, not his h-index. While this was a firm-like position, the group also had academic-style positions. Its use of graduate students on the projects is one prominent example. Each student on the project had to own a piece of the project that was all their own and could be written up as a thesis.</p>
<p><em>(I explore how the team mitigated the risks of theses not panning out in <a href="https://www.freaktakes.com/p/an-interview-with-chuck-thorpe-on">my interview with Chuck Thorpe</a>.)</em></p>
<p>These academic incentives partially enabled the CMU team to continually innovate. Oftentimes these students’ theses perfectly plugged into existing systems, such as a thesis on reducing the processing time of an existing sensor’s data from 15 minutes to 90 seconds. But on the most extreme occasion, in 1988, this incentive structure led a grad student named Dean Pomerleau to successfully train a neural net to steer the vehicle. In that particular case, the requirement to allow each grad student to try something new changed the world.</p>
<p>Answer.AI similarly cares about deep technical novelty and building deployable technology. As such, Answer.AI could benefit from emulating BBN and CMU’s strategies to balance the two. The success of BBN and CMU should hopefully embolden Answer.AI’s founders to trust in the priorities they have set. This balance of goals is uncommon today, but orgs from history have expertly balanced the two to world-changing effect.</p>
<p>With that said, time elapsing without world-changing results might be unnerving. This ambiguity is partially what pushed academia to rely on near-term outcome variables that incentivize the incremental. Fear of wasting time and money is real. The Answer.AI founders would surely like some way to ensure that they are spending theirs on good problems. To deal with that, I think the Bell Labs’ approach to problem selection has a lot to add to the approaches I’ve already covered.</p>
</section>
<section id="the-bell-labs-approach-to-problem-selection">
<h4 data-anchor-id="the-bell-labs-approach-to-problem-selection">The Bell Labs Approach to Problem Selection</h4>
<p>Bell Labs’ management of researchers in its golden era is famous — and it should be. However, Bell researchers were not left to their own devices to pursue whatever they wished, despite what many think. Bell managed their researchers with an approach similar to the “long leash within a narrow fence” approach of GE — which one long-time Bell chemist called “circumscribed freedom.” The most effective tool it used to do this was its corp of excellent systems engineers.</p>
<p>Bell had an expansive product line with massive scale — even more so than GE. Even modest improvements from the research team could have outsized returns. This, of course, is not the case with Answer.AI. However, Bell’s use of systems engineers can still be extremely instructive to Answer.AI, even if Answer.AI may deploy them in different ways.</p>
<p>As I covered extensively on FreakTakes, Bell’s systems engineers often combined several knowledge bases to expose the <em>right</em> researchers to the problems that <em>most</em> needed solving. Within one mind systems engineers often combined STEM backgrounds, knowledge of the nitty-gritty details of Bell’s manufacturing, an understanding of Bell’s implementation problems, detailed knowledge of Ma Bell’s expenses, and familiarity with the researchers at Bell Labs.</p>
<p>Bell knew these systems engineers were a massive part of their secret sauce, ensuring Labs deployed its limited resources on the right kinds of problems with sufficient upside. I wrote in the conclusion of my Bell Labs piece:</p>
<blockquote>
<p>Finding&nbsp;<em>a problem</em>&nbsp;in these systems is not so hard for those familiar with the systems. That’s why many researchers and engineers do not feel the need to bring in help. But finding a set of&nbsp;<em>good problems</em>&nbsp;is not finding the&nbsp;<em>best problems</em>. Finding the best problems is a profession in and of itself. A systems engineer is worth it when, under the right scrutiny, it might turn out that the best problem is 10X as financially valuable, does 50X the social good, or is 2X as likely to work as just some run-of-the-mill good problem.</p>
</blockquote>
<p>My prior piece delves deeper into the specific problems towards which Bell’s systems engineers led Bell’s researchers. For now, suffice it to say that I think that any new applied science org that can dedicate an (ideally full-time) individual to doing the work of a systems engineer should strongly consider it.</p>
<p>Of course, these systems engineers would need somewhat clear marching orders on what sorts of technologies they should be exploring. Nowadays, many existing roles in industry and academia train individuals to equate revenue or potential citation count with impact. Answer.AI will not be satisfied with these metrics as proxies of impact, and they shouldn’t be. What to direct these systems engineers toward instead should surely be up to Jeremy and Eric.</p>
<p>As a firm that pursued novelty and was not attached to a large industrial operation, BBN might be an interesting source of inspiration. Several of its hallmark projects started with systems-engineer-style contributions. Three examples are DARPA PM Larry Roberts putting out the ARPAnet contract, J.C.R. Licklider’s visionary Libraries of the Future Project, and BBNer Jordan Baruch’s early-1960s pitch to the NIH on a system to build a computer system to facilitate modern hospital operations. All three project initiators had Bell systems-engineer-like exposure to the people and problems of their field — technical backgrounds, regularly spoke with the best academic researchers, knew modern industry’s issues, were able to project the costs and complications of potential projects, etc.</p>
<p>Few have used systems engineers as effectively as Bell Labs, with Bell-style goals, since the great lab was broken up. It would be amazing to see a lab like Answer.AI commit significant staff time to this purpose.</p>
</section>
<section id="the-cautionary-tale-of-thinking-machines-corporations-funding">
<h4 data-anchor-id="the-cautionary-tale-of-thinking-machines-corporations-funding">The Cautionary Tale of Thinking Machines Corporation’s Funding</h4>
<p>The case of the Thinking Machines Corporation (TMC) is not as directly instructive as the examples above, but TMC made one key mistake that makes it worth mentioning. TMC put itself in the unfortunate position of raising some of its funds from investors whose incentives were not aligned with theirs.</p>
<p>For those who don’t know, TMC was a complete failure as a commercial firm. As a result of its bankruptcy, many write the firm off as a holistic failure. But the firm did accomplish many of the technical goals it set out to achieve. Since the company was conceived with technological goals in mind, rather than a specific market, this was no small feat. The company was founded by Danny Hillis, a PhD from Marvin Minsky’s lab at MIT. Through TMC, he sought to build the machine he conceptualized in his graduate thesis: a truly parallel computer to improve the capacity of all scientists. The young company recruited the best researchers — including scoring Richard Feynman as its “intern” for several summers — and achieved many technical goals that helped pave the way for the modern field of parallel computing. Jeremy, who knows far more about the technical aspects of parallel computing than I do, sang TMC’s technical praises in our first conversation. He emphasized how shocking it was that TMC seemed to be the first to employ so many methods the field still uses today.</p>
<p>However, TMC’s high-powered team and great technical work were not enough to overcome their management follies. The firm spent money as if its financial standing was in line with its technical reputation, which it was not. In retrospect, some of these management decisions — such as a comically expensive long-term lease — could have been avoided without modifying the company’s general approach. However, on a deeper level, there was a dissonance between the company’s technical goals and the funding it raised.</p>
<p>TMC’s two major funders were DARPA’s computing office and private investors. The goals of Hillis and his top-flight technical staff were only aligned with DARPA’s goals. In looking to build the technically most ambitious parallel computer possible, DARPA funding was ideal. The DARPA computing office also felt that TMC’s work was progressing exceptionally well for most of its early years. However, the level of enthusiasm Hillis and the technical staff had for building a machine for science did not bleed into the most profitable areas — like deploying the machine on banking databases or managing logistics for Walmart. As time wore on, it seems that pressures were beginning to mount for TMC to pursue work more in line with those areas. It seems highly likely that TMC would have had to disappoint one of its funders sooner or later, even if it spent funds more wisely in its early years.</p>
<p>Had TMC just raised funds from DARPA and spent them much more modestly, the company might still exist today; it may have even earned a reputation beyond that of NVIDIA.</p>
</section>
</section>
<section id="copying-mid-20th-c.-industrial-rd-models-is-hard-for-incumbents">
<h2 data-anchor-id="copying-mid-20th-c.-industrial-rd-models-is-hard-for-incumbents">Copying mid-20th C. Industrial R&amp;D Models is Hard for Incumbents</h2>
<p>The middle 20th Century saw both the rise and fall of ambitious American industrial R&amp;D labs. It is not just nostalgia that makes modern researchers look back on these labs with fondness. Not long after these labs were formed, it was becoming clear to many top researchers that the model was special.</p>
<p>In 1927, Karl Compton wrote a prescient letter to <em>Science</em> that praised these labs. At the time of writing the letter, Compton was the head of Princeton’s Physics Department and a part-time GE contractor. His letter asserts that these organizations were doing some of the best science in the country, even though the top universities often had the best men. A portion of the letter, in which Compton praises the labs’ management of scientific projects, reads:</p>
<blockquote>
<p>This has been strikingly demonstrated in some of the big industrial research laboratories, from which the output has greatly exceeded the individual capacities of the research workers</p>
</blockquote>
<p>Compton believed there were <em>many</em> lessons that university departments should steal from these exceptional industrial labs. The first was the need to specialize when building a portfolio of researchers and projects. Why should every department attempt to loosely approximate the makeup of researchers and research questions in the field as a whole? No company would ever do such a thing. He believed that, “Such a policy dissipates effort, and if every institution followed it we should have the spectacle of a great many universities all very much alike and all with struggling, mediocre departments.”</p>
<p>On an organizational level, Compton believed the equilibrium of N autonomous professors with N separate budgets and a few grad students in their lab under their control was just not efficient for most projects. It would be silly for all departments to function that way. In the letter, Compton proposes what I’ve taken to calling a ‘Compton Model’ research department. This model is far more structured than a department of mostly autonomous professors doing ad-hoc research with their own separate funds. Compton describes it as follows:</p>
<blockquote>
<p>There is another direction in which more effective organization is possible within the universities themselves! Departments of a somewhat more flexible nature than those to which we are accustomed and which could, more than now, be built around one or two outstanding men in the department, could give these men an opportunity for organization and concentration of effort which is now rarely possible.</p>
</blockquote>
<p>Another way to describe this model is as a “fund department heads, not projects” model. The model allows one or two individuals to largely shape the research vision, hiring, project selection, capital purchasing, etc. of an entire department at once. In addition, it allows these individuals the latitude to replace salaries spent on additional professors or grad students with full-time engineers or discretionary capital expenses as needed.</p>
<p>The model makes perfect sense. However, it’s remarkably difficult to make happen at a real university. Compton couldn’t succeed in doing so when he took over as MIT President. The existing stakeholders and structures are just too hard to shift in this direction. Absent some special circumstance, most university administrators wouldn’t find the idea even worth considering. However, CMU’s President Cyert was able to build a department that loosely resembled a Compton Model department. And its results were exceptional! But this was the exception. Pivoting an existing department to run like a Compton Model department has proven infeasible in almost all cases.</p>
<p>The great, old models of managing labs didn’t disappear from industry because they lacked scientific merit. These labs largely began to disappear in the 1970s and 1980s. The 1970s saw a deep recession, which usually hurt R&amp;D budgets. In the 1980s, new corporate management trends surfaced that led to companies being managed more myopically than ever before or since. These, along with other non-scientific trends, were largely responsible for the labs going away when they did. With them, the operational know-how that had slowly been built up throughout the century dissipated. Now, to learn how these orgs operated, one must read oral histories or talk to now-retired engineers.</p>
<p>The first thing these retired engineers will often tell you is that we should bring the old models back! Bell’s long-time researchers had confidence in the Bell model even as a late-1900s court case ended Bell Labs as we know it. In the 1920s, Compton dreamt of copying much of the GE model to use within a university. One should not be afraid to put their time and resources behind bringing these models back. Great engineers largely maintained confidence in these models from their inception until they faded into the background.</p>
<p>Many in academia know it should operate more like BBN, CMU, or GE research. They just can’t change the structures to make it happen. Many R&amp;D leaders know that their company should think more in 10-20-year time horizons when planning research expenditures, but shareholders and shareholder-wary CEOs often do not find this view actionable. <strong>Answer.AI can be free from all this. The org can apply the great old models in a new era on new technology.</strong></p>
<p><em>(Ries being a cofounder of Answer.AI should be comforting. Ries has railed against the types of myopic management trends that make activities like maintaining an expansive industrial R&amp;D lab difficult for firms. He founded the young Long Term Stock Exchange, in part, to help mitigate issues like this.)</em></p>
</section>
<section id="conclusion-running-your-own-races">
<h2 data-anchor-id="conclusion-running-your-own-races">Conclusion: Running Your Own Races</h2>
<p>It’s up to Answer.AI’s two-headed management team to stick to the organization’s comparative advantages. There is no need to race academic CS researchers or corporate R&amp;D departments in races those two groups feel incentivized to run. Corporate R&amp;D, NSF-funded CS researchers, and AGI-focused labs all have areas in which they clearly will and won’t operate. And those areas don’t come close to covering 100% of the good ideas somebody should obviously be working on. <a href="https://www.answer.ai/">Answer.AI</a> is free to run its own races, uncontested.</p>
<p>Many will feel the org is using an untested model. However, Answer.AI’s founders — like me — believe that this model is proven, but has simply gone away for a while. So, shouldering this “organizational risk” that others are seemingly not willing to do, they have the chance to work on problems without much competition. If their USD10 million experiment works, it has the chance to spark a rush of emboldened researchers and engineers to found small research firms, leveraging the models of the once-great dragons of American industrial R&amp;D.</p>
<p>I wish Jeremy and Eric luck in the early stages of their mission. To any researchers and engineers — across all areas — reading this and wishing a BBN, CMU, TMC, or Answer.AI existed in your area, please reach out to me on <a href="https://twitter.com/eric_is_weird">Twitter</a>. I’d love to see if there’s anything I can do to help.</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An Air Force officer who spent $11M searching Earhart's plane may have found it (203 pts)]]></title>
            <link>https://www.businessinsider.com/sonar-image-pilot-amelia-earhart-plane-found-pacific-ocean-2024</link>
            <guid>39179031</guid>
            <pubDate>Mon, 29 Jan 2024 17:20:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/sonar-image-pilot-amelia-earhart-plane-found-pacific-ocean-2024">https://www.businessinsider.com/sonar-image-pilot-amelia-earhart-plane-found-pacific-ocean-2024</a>, See on <a href="https://news.ycombinator.com/item?id=39179031">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>Tony Romeo believes he's discovered Amelia Earhart's long-lost aircraft.</li><li>Romeo said he captured an image of an aircraft-shaped object on the floor of the Pacific Ocean.</li><li>Experts say the location seems roughly correct, but clearer images are needed.</li></ul><!-- Excluded mobile ad on desktop --><div id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-newsletter-title="Insider Today" data-acq-source="transportationinlinesignup">
                        
                        
                          <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            <div>
                                <p><img src="https://www.businessinsider.com/public/assets/rebrand/newsletter-bull.png" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'%3E%3C/svg%3E" data-src="/public/assets/rebrand/newsletter-bull.png">
                              
                              
                              
                              </p>    </div>
                        
                          
                        </div><p>A pilot and former US Air Force intelligence officer believes an image he captured using sonar on a high-tech unmanned submersible may have finally answered one of America's most baffling mysteries: What caused the disappearance of the iconic pilot <a target="_blank" href="https://www.businessinsider.com/how-did-amelia-earhart-die-2017-7" data-analytics-product-module="body_link" rel="">Amelia Earhart</a> at the height of her fame?</p><p>Tony Romeo is one of a long line of researchers and hobbyists to have taken up the search for Earhart's distinctive Lockheed 10-E Electra plane, which disappeared over the Pacific Ocean along with its famous pilot and its navigator, Fred Noonan, during an attempt to circumnavigate the globe in July of 1937.</p>
                          <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/65b5bfcd6c8f0a134f7a6c71&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:1552,&quot;aspectRatioH&quot;:1096}}" alt="Amelia Earhart, 40, stands next to a Lockheed Electra 10E, before her last flight in 1937." itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  Amelia Earhart, 40, standing next to a Lockheed Electra 10E, before her last flight in 1937 from Oakland, California.
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          AP Photo
                          
                          </span>
                              </span>
                          </figure>
                        <p>The mystery surrounding Earhart's disappearance has long puzzled researchers and spurred <a target="_blank" href="https://www.businessinsider.com/amelia-earhart-conspiracy-theories-2018-5" data-analytics-product-module="body_link" rel="">conspiracy theories</a> over the years, including the Japanese taking her prisoner and her being a government spy.</p><p>But Romeo, a former real-estate investor who sold commercial properties to raise the $11 million needed to begin funding the search, returned in December from a roughly 100-day voyage at sea with a sonar image that he believes shows the lost plane in the ocean's depths.</p><!-- Excluded mobile ad on desktop --><h2>A high-tech search at sea</h2><p>His expedition, which was carried out using a $9 million high-tech unmanned submersible "Hugin" drone manufactured by the Norwegian company <a target="_blank" href="https://markets.businessinsider.com/news/stocks/kongsberg-gets-nok-1-2-bln-order-from-lockheed-martin-1032649045" data-analytics-product-module="body_link" rel="">Kongsberg</a> and a research crew of 16, started last September in Tarawa, Kiribati, covering 5,200 square miles of the ocean floor, <a target="_blank" href="https://www.wsj.com/science/amelia-earhart-lost-plane-found-843e9e9c" data-analytics-product-module="body_link" rel=" nofollow">The Wall Street Journal</a> reported.</p><p>It was a dream Romeo had for years before making it a reality.</p><p>"This has been a story that's always intrigued me, and all the things in my life kind of collided at the right moment," Romeo, whose father and brothers are also pilots, told Business Insider. "I was getting out of real estate and looking for a new project so even though I really started about 18 months ago, this was something I've been thinking and researching for a long time."</p>
                          <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/65b5bfd3ac2de4f17ee52049&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:3000,&quot;aspectRatioH&quot;:1747}}" alt="Amelia Earhart's plane rising into the air after a 4,000-foot run at the start of the flight from Oakland, California, on March 17, 1937." itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  Amelia Earhart took off from the airport in her £10,000 Flying Laboratory for Honolulu on the first leg of her round-the-world flight.
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          AP Photo
                          
                          </span>
                              </span>
                          </figure>
                        <p>Roughly a month into the trip, the team captured a sonar image of the plane-shaped object about 100 miles from Howland Island — but didn't discover the image in the submersible's data until the 90th day of the voyage, making it impractical to turn back to get a closer look.</p><!-- Excluded mobile ad on desktop --><p>Experts have shown interest in the finding, with Dorothy Cochrane, a curator at the Smithsonian Institution's National Air and Space Museum, telling The Journal that the reported location where the image was taken was just about right, geographically, compared with where <a target="_blank" href="https://www.businessinsider.com/amelia-earhart-disappearance-explained-photo-national-archives-history-2017-7" data-analytics-product-module="body_link" rel="">Earhart's flight</a> is believed to have gone down.</p>
                          <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/65b5cabf6c8f0a134f7a6cc7&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:1474,&quot;aspectRatioH&quot;:1102}}" alt="A presumed flight path from the last leg of Earhart's journey" itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  A map of where Earhart's plane is believed to have gone missing along her presumed flight path.
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          Google Maps
                          
                          </span>
                              </span>
                          </figure>
                        <p>But others say they need clearer views and more details, such as the plane's serial number.</p><p>"Until you physically take a look at this, there's no way to say for sure what that is," Andrew Pietruszka, an underwater archaeologist at the Scripps Institution of Oceanography, told The Journal.</p><p>Romeo, who said the search might be "the most exciting thing I'll ever do in my life," added that he planned to return to the area to try to capture better images using autonomous or robotic submersibles equipped with cameras and sonar to get closer to the object, which rests more than 16,500 feet beneath the surface.</p><!-- Excluded mobile ad on desktop --><p>Romeo told BI that if it wasn't <a target="_blank" href="https://www.businessinsider.com/how-investigators-use-new-techniques-to-solve-amelia-earhart-mystery-2019-7" data-analytics-product-module="body_link" rel="">Earhart's plane</a>, the object he found could be a different missing aircraft lost in the Pacific or — less interestingly, perhaps — another manmade object that fell off a shipping container. But as of now, he's feeling confident he's made a groundbreaking discovery due to the distinctive shape of the fuselage, tail, and wings.</p>
                          <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/65b5c0c36c8f0a134f7a6c89&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:692,&quot;aspectRatioH&quot;:272}}" alt="A sonar image of an object underwater is displayed next to a diagram of Amelia Earhart's missing plane." itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  Romeo and his company, Deep Sea Vision, discovered an object of similar size and shape to Amelia Earhart's iconic plane deep in the Pacific Ocean.
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          Deep Sea Vision
                          
                          </span>
                              </span>
                          </figure>
                        <p>"The next step is confirmation —&nbsp;we've got to go back out with different sorts of sensors and really photograph it well and take a look at how the artifact is sitting on the seabed," Romeo told BI. "Once that step is done, lots of people will be involved. The Smithsonian, the family, there'll be some investors involved because it'll be an expensive operation, but then we're thinking: 'How do we lift the plane? How do we salvage it?'"</p><p>He added: "I don't think we're there yet. But I do think Americans want to see this in the Smithsonian; that's where it belongs. Not the bottom of the ocean."</p><h2>A decadeslong mystery</h2><p>Hopeful explorers have pumped millions of dollars into expeditions to find Earhart's lost plane over the years, but her last known location has made the searches difficult.</p><!-- Excluded mobile ad on desktop --><p>"It's very deep water, and the area that she could've possibly been in is huge," Tom Dettweiler, a sonar expert, told The Journal.</p><p>One team who searched for Earhart's aircraft in 2009 said on Twitter that following its 2,500-square-mile search near Howland Island, close to where Romeo conducted his search, it only knew where the aviator wasn't.</p><p>Earhart, who was the first woman to fly solo across the Atlantic and the US, was declared legally dead on January 5, 1939, two years after she vanished. But her legacy has lived on, and she continues to fascinate people worldwide.</p><p>"It was one of the great <a target="_blank" href="https://www.businessinsider.com/phenomena-science-cant-explain-2019-1" data-analytics-product-module="body_link" rel="">mysteries of the 20th century</a> and still now into the 21st century," Cochrane told The Journal. "We're all hopeful that the mystery will be solved."</p><!-- Excluded mobile ad on desktop --><h2>The dateline theory</h2><p>Romeo believes he's taken a massive step toward answering vital questions surrounding the famous pilot's disappearance after scouring decades of clues and potential leads to her location, including the "dateline theory."</p><p>The theory, which Romeo relied on partly to guide his search, suggests that when Earhart crossed over the international dateline during her 20-hour flight, her navigation system became inaccurate and misdirected her by about 60 miles, potentially leading to a tragic end.</p>
                          <figure data-type="img" data-e2e-name="image-figure-image" data-media-container="image" itemscope="" itemtype="https://schema.org/ImageObject">
                          
                          
                          
                            <p><img src="data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/%3E" data-content-type="image/jpeg" data-srcs="{&quot;https://i.insider.com/65b5bfd06c8f0a134f7a6c77&quot;:{&quot;contentType&quot;:&quot;image/jpeg&quot;,&quot;aspectRatioW&quot;:3000,&quot;aspectRatioH&quot;:2327}}" alt="Amelia Earhart wears a string of leis around her neck after landing in Honolulu, Hawaii." itemprop="contentUrl">
                        </p>
                          
                          <span>
                                <figcaption data-e2e-name="image-caption">
                                  Earhart after landing in Honolulu after a speedy flight from Oakland, California, in March 1936. 
                                </figcaption>
                                
                          <span data-e2e-name="image-source" itemprop="creditText">
                          
                          AP Photo
                          
                          </span>
                              </span>
                          </figure>
                        <p>Romeo said if he received confirmation that he'd found Earhart's plane, hopefully during another voyage planned for later this year, the company he created as part of the search would continue trying to solve other mysteries held in the ocean.</p><p>"There's lots of cool stuff in the Pacific —&nbsp;WWII aircraft and <a target="_blank" href="https://www.businessinsider.com/mh370-theories-dead-ends-unanswered-questions-ahead-of-major-new-report-2018-7" data-analytics-product-module="body_link" rel="">flight MH370</a> are still out there, and maybe we can make a run at that at some point," Romeo told BI. "I'm not announcing yet that we are, but I'd love to collaborate with other folks on other projects since we've got the state-of-the-art equipment. There's only a couple of these in the world, and finding these things out is in demand."</p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta AI releases Code Llama 70B (533 pts)]]></title>
            <link>https://twitter.com/AIatMeta/status/1752013879532782075</link>
            <guid>39178886</guid>
            <pubDate>Mon, 29 Jan 2024 17:11:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/AIatMeta/status/1752013879532782075">https://twitter.com/AIatMeta/status/1752013879532782075</a>, See on <a href="https://news.ycombinator.com/item?id=39178886">Hacker News</a></p>
Couldn't get https://twitter.com/AIatMeta/status/1752013879532782075: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Prediction markets have an elections problem (126 pts)]]></title>
            <link>https://asteriskmag.com/issues/05/prediction-markets-have-an-elections-problem-jeremiah-johnson</link>
            <guid>39178750</guid>
            <pubDate>Mon, 29 Jan 2024 17:02:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/05/prediction-markets-have-an-elections-problem-jeremiah-johnson">https://asteriskmag.com/issues/05/prediction-markets-have-an-elections-problem-jeremiah-johnson</a>, See on <a href="https://news.ycombinator.com/item?id=39178750">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<div data-mode="add-marker">
		<p><img id="marker" src="https://asteriskmag.com/assets/img/asterisk_mark.png" title="save highlight"></p><!-- <a href="https://asteriskmag.com/about/#highlights"><img id="help" src="https://asteriskmag.com/assets/img/asterisk_help.png" title="about highlights"></a> -->
		
	</div>

	<section>
				
		 			<h2>
				   
					<span>Jeremiah Johnson</span>
							</h2>
			</section>

	 
		<section id="rangyscope">
					<p>Weeks after it was clear that Donald Trump lost the 2020 election, you could still make pennies on the dollar betting Joe Biden would win. Why doesn’t smart money drive out dumb money in election markets?</p>
				<div>
											<div><p>Prediction markets are having a moment. The mainstream media is increasingly profiling them — see, for example, Bloomberg’s Matt Levine linking to a market on why Sam Altman was fired from OpenAI — and paying attention to what they have to say. Advocates claim that by providing a marketplace for bets on uncertain events, prediction markets give predictors a financial incentive to be correct. If you want a good estimate of what will happen, prediction markets filter signal from noise and cut past pundits with no skin in the game. Money talks and bullshit walks, and prediction markets force people to put that money where their mouth is.</p><p>Some of the largest and most notable prediction markets to date have been around elections. The only problem? Prediction markets simply aren’t very good at political predictions. Markets for major U.S. elections are some of the deepest prediction markets anywhere: billions of dollars bet, millions of daily trades, and huge amounts of press. In theory, the larger the market, the more accurate the predictions. But in the markets with the biggest spotlight, we see a lot of strange stuff. Predictions that don’t line up with common sense. Odds that seem to defy reality. Obviously noncredible market movements. To figure out why, we’ll have to explore the underlying mechanisms that make markets work, and why the typical user of political prediction markets may not behave in the ways we expect.</p><p><strong>***</strong></p><p>How do we know prediction markets struggle with politics in the first place? The best evidence comes from the 2020 election. Despite a deep pool of participants, markets for the presidential election showed clear signs of irrationality and biased outcomes.</p><p>The elections were held on November 3, 2020. By November 7, almost every major media and poll-watching organization had declared Joe Biden the winner in enough states to be elected president. And yet deep into December, prediction market contracts in states like Georgia, Michigan, Arizona, and Pennsylvania only listed Joe Biden at 90 cents (or a 90% chance to win)<sup>
    <!-- <a id="fnref-1" href="#fn-1"> -->
    <span id="fnref-1">
        1    </span>
    <!-- </a> -->
</sup>
 — long after those states had formally ratified Joe Biden as their winner. In a more normal scenario those markets would have shot to 99% or 100% once every media outlet called the relevant states for Biden, and then closed once those states formally certified Biden as the winner. That wasn’t the case.</p><p>Why did those particular prediction markets refuse to go to 100%? Were they dominated by irrational behavior, or was there some sensible explanation for why? In the aftermath of Biden’s victory, Donald Trump quickly declared that large-scale election fraud had taken place. He pursued a variety of legal challenges to the official results, and, if polls are accurate, convinced something like a third of the country that the official results were fraudulent. Although there was never any real evidence or rational case for mass-scale election fraud, perhaps the market believed that Trump’s legal challenges had a ~10% chance of succeeding and was pricing in that outcome. Call this the “rational chance of overturning” theory.</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/05/prediction-markets-have-an-elections-problem-jeremiah-johnson/aa088654a5-1706542289/asterisk-mag_alfonso-de-anda_web.png" alt="">
  </p>
    <p>
    Alfonso de Anda  </p>
  </figure>
</div>
											<div><p>Unfortunately, that theory falls flat in the face of other evidence. Consider the “Electoral College Margin of Victory” market for the presidential election on PredictIt, a prominent prediction market. This market was designed to predict the margin of victory in the Electoral College — Biden wins by 30–59 electors,<sup>
    <!-- <a id="fnref-2" href="#fn-2"> -->
    <span id="fnref-2">
        2    </span>
    <!-- </a> -->
</sup>
 Trump wins by 10–29 electors, etc. A rational theory pricing in a 10% chance that Trump’s legal challenges would succeed would see that 10% distributed among the likely outcomes, such as a narrow Trump victory by a small number of electoral votes. But instead, the majority of the bettors against Biden bet on the astonishing outcome of “Trump wins by 280+ electoral votes.” That, it should be clear, was impossible — it would require results to be overturned not just in states with tight races but also in Democratic bellwethers like California. The Trump campaign did not have active legal challenges in enough states to even consider this a possibility. And yet the bulk of prediction market betting on Trump was betting on a 280+ margin, with prices as high as 9 cents late in November.</p><p>Other signs of irrationality also existed in the 2020 election prediction markets. Sports betting sites are essentially a more legal form of real-money prediction markets, and sometimes venture into political betting. The sports book MyBookie listed Trump as a slight favorite to win the presidency overall, giving him implied odds of 53% to win re-election. But on that same site, Biden was a significant favorite in every swing state — 69% to win Wisconsin, 66% to win Pennsylvania, 60% to win Arizona. In a rational market, the national odds should reflect the aggregation of state-level odds, or else there would be free arbitrage available. But that arbitrage persisted — state odds were continuously out of tune with national odds.&nbsp;</p><p><strong>***</strong></p><p>While the 2020 election is one of the clearest examples of irrational behavior in political prediction markets, it’s far from the only example. Academic interest in prediction markets has increased since 2016, and that research has repeatedly found evidence of inefficiency and irrationality in political prediction markets. One study found that betting markets for the 2016 EU referendum in the U.K. were inefficient in absorbing new information.<sup>
    <!-- <a id="fnref-3" href="#fn-3"> -->
    <span id="fnref-3">
        3    </span>
    <!-- </a> -->
</sup>
 Other researchers<sup>
    <!-- <a id="fnref-4" href="#fn-4"> -->
    <span id="fnref-4">
        4    </span>
    <!-- </a> -->
</sup>
 have found that both the 2016 and 2020 U.S. presidential elections had large and persistent arbitrage opportunities in their prediction markets — a classic sign of inefficient markets. Prediction markets as a whole have a tendency to overstate the odds of low-probability events, a tendency known as “small odds bias.” But analysis shows that tendency is even more extreme in political prediction markets.<sup>
    <!-- <a id="fnref-5" href="#fn-5"> -->
    <span id="fnref-5">
        5    </span>
    <!-- </a> -->
</sup>
&nbsp;</p><p>Beyond the academic research on elections from 2016 and 2020, there’s also evidence from more recent elections that political prediction markets struggle to forecast events accurately when compared to expert forecasters. A proponent of prediction markets might be inclined to dismiss research for 2016, as prediction markets were still in their relative infancy. They may also equivocate about the strange 2020 markets, since Donald Trump’s claims of mass election fraud were a confounding factor and difficult to account for. But even in the 2022 U.S. midterm elections, with no Trump and fully modern prediction markets, prediction markets fared worse than expert forecasters.&nbsp;</p></div>
											<div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/05/prediction-markets-have-an-elections-problem-jeremiah-johnson/5cdf9db45b-1705682315/data_web_2.svg" alt="">
  </p>
    
  </figure>
</div>
											<p>In Figure 1, a variety of election prediction sites were graded on their accuracy based on a log-odds scoring method, where a higher score means a more accurate forecast.<sup>
    <!-- <a id="fnref-6" href="#fn-6"> -->
    <span id="fnref-6">
        6    </span>
    <!-- </a> -->
</sup>
 The election forecasts from FiveThirtyEight’s famed election model were more accurate than prediction markets from Manifold Markets, Polymarket, Election Betting Odds, and PredictIt. The only site to surpass<sup>
    <!-- <a id="fnref-7" href="#fn-7"> -->
    <span id="fnref-7">
        7    </span>
    <!-- </a> -->
</sup>
 FiveThirtyEight was Metaculus, which is not a prediction market — it aggregates expert predictions but without the buying or selling of shares that are the signature feature of markets. The two best predictors of the 2022 midterm results were the two sites least reliant on betting and market mechanisms and most reliant on specialist expertise. The loss to FiveThirtyEight is particularly embarrassing for prediction markets because FiveThirtyEight’s predictions were public and widely shared for months before the election. Prediction markets could have simply copied those odds, since they were proven to be well-calibrated.<sup>
    <!-- <a id="fnref-8" href="#fn-8"> -->
    <span id="fnref-8">
        8    </span>
    <!-- </a> -->
</sup>
 In deviating from the public predictions from FiveThirtyEight, prediction markets added negative value.</p>
											<div><p>***</p><p>By now, we’ve seen quite a lot of evidence that prediction markets struggle with major political predictions. But if prediction markets are inefficient and irrational when predicting political outcomes, why?</p><p>First, we need to talk about the technical factors that can cause prediction markets to malfunction. Even the most successful prediction markets today often suffer from these factors. They may have a low volume of betting or a limited pool of bettors. They may have high fees, or a cap on how much can be bet. For long-run predictions like political outcomes, the time value of money can distort odds.<sup>
    <!-- <a id="fnref-9" href="#fn-9"> -->
    <span id="fnref-9">
        9    </span>
    <!-- </a> -->
</sup>
 Questions about the legality of some prediction markets may scare away bettors; some markets allay that fear by using only fake money, but that introduces a new concern since fake money may not incentivize bettors as strongly as real money. And the markets that have the fewest troublesome technical factors — crypto markets and overseas sports betting sites — are the most logistically and legally challenging markets for everyday U.S.-based bettors to reach.</p><p>There’s some evidence that these technical factors are slightly more impactful on political markets than other markets. We know that small-odds bias is larger in political markets. There’s good reason to think that legal issues that prevent higher volumes of trading are more severe in political markets. Even as sports betting has seen a wave of legalization in the U.S. the Commodity Futures Trading Commission, which regulates derivative markets (under which event-based contract markets fall), denied prediction market Kalshi permission to offer real-money bets on political races.<sup>
    <!-- <a id="fnref-10" href="#fn-10"> -->
    <span id="fnref-10">
        10    </span>
    <!-- </a> -->
</sup>
 And some political prediction markets have higher fees to participate than more general betting sites.</p><p>But these technical factors alone can’t fully explain all the odd predictions and idiosyncratic behavior we see in political prediction markets, or why they’re worse than other types of prediction markets. Instead we’ll need to turn to psychology to understand why people place these bets in the first place.</p><p>Politics is one of the strongest sources of identity in modern society. Hundreds of millions of Americans strongly identify with political parties or labels like conservative, liberal, socialist, libertarian, Republican, or Democrat. They form groups and communities with others who keep the same beliefs. They discriminate against opposing party members in favor of their own.<sup>
    <!-- <a id="fnref-11" href="#fn-11"> -->
    <span id="fnref-11">
        11    </span>
    <!-- </a> -->
</sup>
 They have a common language with shared phrases, references, and inside jokes. They have beloved in-group heroes and hated out-group villains. It’s not a stretch to compare political loyalties to a religion — political identities can also have holy texts, promote saintlike figures, construct complex moral and ethical codes to live by, and enforce orthodoxy with the punishment of expulsion from the group. For millions of people, a political stance is not an abstract idea they have rationally considered and think is correct. It’s who they are as a person. And when you mix this sort of potent identity creation with prediction markets, outcomes get weird.</p><p>There’s an interesting piece of research from Temple University<sup>
    <!-- <a id="fnref-12" href="#fn-12"> -->
    <span id="fnref-12">
        12    </span>
    <!-- </a> -->
</sup>
 that tested sports fans on their ability to predict the outcome of games, while also noting which teams the participants were fans of and how strongly they considered themselves fans. They found that participants had lower prediction accuracy when predicting their favorite team’s games, because they strongly overestimated their team’s chances of winning. This effect was larger the more strongly the participant identified as a fan of a particular team.&nbsp;</p><p>In short, the more strongly someone identified as a fan of a team, the worse their predictions were. Fans in this context often either misevaluate their teams or just fail to evaluate their teams at all. Betting can be seen as a form of loyalty, as an expression of allegiance to the team rather than a rational attempt to maximize expected value. Other researchers have found that fans are often reluctant to bet against their teams even if the bet is free — their identity as a fan overwhelms any rational profit-seeking motive.<sup>
    <!-- <a id="fnref-13" href="#fn-13"> -->
    <span id="fnref-13">
        13    </span>
    <!-- </a> -->
</sup>
 If this effect can happen for teams in sports, it certainly can happen for the “teams” in politics, where group-identity forces are even stronger.&nbsp;</p><p>How can we tell that political loyalists on prediction markets are exhibiting this “betting as loyalty” behavior? This may sound like a flippant suggestion, but a single glance at the comments section for a major PredictIt political market should tell you all you need to know. You’re unlikely to find any sort of reasoned analysis, but you’ll find plenty of bitter partisan fights, memes, and culture-war yelling around which party and which candidates are currently ruining America.&nbsp;</p><p>To state the problem bluntly, there is an enormous amount of dumb money that surges into political prediction markets for major elections. The 2020 presidential election alone saw more than a billion dollars wagered at European sportsbooks, and major state and national political markets on PredictIt reached millions of bets per day leading up to election day. We know that this tidal wave of money is dumb money because we can see intense tribal behavior on these sites and research tells us that the more one identifies with a “team,” the worse one’s predictions for that team are. People will bet for candidates and parties not because they have an evidence-based analysis supporting their bet, but as an expression of identity.</p><p>Once you look at these bets as expressions of identity rather than rational bets, many of the irrational and puzzling behaviors we described earlier make more sense. This reasoning explains why the strongest overperformance comes from candidates with highly online, energetic fan bases such as Donald Trump, Andrew Yang, and Vivek Ramaswamy. It explains why the 2020 Trump betting clustered at a margin of victory of 280+ electoral votes rather than a realistic scenario like Trump winning by 10-29 electoral votes. The bettors involved weren’t doing any sort of detailed analysis or investigating the facts. They were expressing how much they believed in Trump, how much they supported him, and how loyal they were to him. Betting on an impossible outcome is how you show the most loyalty!</p><p>This also explains why state-level prediction markets disconnected from national-level prediction markets. Most state-level markets received an order of magnitude less attention and betting volume than national markets. Identity-based betting congregated in those highly visible national markets and tilted them heavily towards Donald Trump. Meanwhile, far fewer bettors filtered down to the state markets, allowing savvier bettors to dominate. And these state-level predictions, when aggregated, showed Joe Biden as the favorite.</p><p><strong>***</strong></p><p>Whenever we observe instances of markets failing, it’s useful to remember why markets usually work in the first place. We know that prediction markets offer a monetary incentive to make correct predictions. But too many people jump from that starting point directly to the conclusion that prediction markets must therefore arrive at correct and efficient outcomes.</p><p>Real-world markets are more complicated. They rely on all sorts of collective norms, enforcement mechanisms, and other characteristics in order to function. They can be thrown out of whack by frictions like fees or taxes, incomplete information, barriers to entry, psychological or cultural factors, and more. To simplify a complex topic potentially more than we should: Markets only work when smart money can drive out dumb money. Dumb money will always exist in some form, but the financial incentives for sharp traders to bet against less savvy traders are usually enough to allow markets to function well and arrive at efficient or near-efficient outcomes.&nbsp;</p><p>But smart money driving out dumb money isn’t an automatic process. There are a variety of reasons why it might not happen, including technical barriers to market entry, regulation, or cultural factors. Even in extremely deep, liquid, and mainstream financial markets the process isn’t automatic. The rise of meme stocks such as GameStop (GME) and Bed Bath &amp; Beyond (BBBY) show that if dumb money is large enough and enthusiastic enough, it’s difficult for smart money to overwhelm it and get a stock back to its “correct” price. BBBY stock maintained a market cap of around $60 million for months after the company filed for bankruptcy. Dumb-money demand for BBBY stock was so strong that BBBY actually got special permission to sell more stock — of an already bankrupt company! — and sold millions of dollars of it to willing buyers. The market cap remained at $62 million until the literal day the stock was delisted as their bankruptcy was finalized with zero value going to stockholders.</p><p>This process of smart money driving out dumb money is even harder in prediction markets. There’s strong evidence that prediction markets have a huge amount of unsophisticated, identity-based bettors. And there’s very little evidence of the opposite — financial juggernauts throwing around their weight. Where are the hedge funds making an easy buck? Billionaire financiers routinely make massive bets on stocks, bonds, and currencies — where are the billionaires taking huge positions on prediction markets? That kind of institutional smart money doesn’t exist in political prediction markets the way it does in traditional financial markets. With so much dumb money and so little smart money, is it any surprise that we get outcomes dictated by trolls instead of professional traders?</p><p>Prediction markets as a tool are still in their relative infancy. They show great promise, but the results from political prediction markets should give us pause. These markets are demonstrably inefficient, biased in predictable ways based on political identities, and can’t outperform expert analysis even when they have public access to that expert analysis. This isn’t a reason to abandon prediction markets. Like any tool, prediction markets can be used, abused, or misused, and one failure doesn’t doom the concept.&nbsp;</p><p>But it does show that we need to take seriously the structures that make markets work when designing prediction markets. We can see the same dynamics from previous political markets playing out in the markets for the 2024 presidential election — candidates like Robert Kennedy Jr., Vivek Ramaswamy, and Gavin Newsom (who hasn’t even declared he’s running) all have odds that seem unrealistically high. Prediction markets that deal with other highly charged subjects — for instance, a market on the outcome of a war, or a market on urban crime statistics — will likely be subject to some of the same factors that distort political prediction markets. Unless we make sure that market structures are providing the right incentives in the right way, we shouldn’t be surprised if prediction markets continue to struggle.</p></div>
										 
				</div>
		
	</section>
	 	<section>
		 		 <p><strong>Jeremiah Johnson</strong> is the founder of the Center for New Liberalism and host of The New Liberal Podcast. He writes at Infinite Scroll.</p>		 		 		 </section>
	 	<section>            
		<p>
			Published February 2024		</p>
		
		<p>Have something to say? Email us at <a href="mailto:letters@asteriskmag.com">letters@asteriskmag.com</a>.</p>		                        
	</section>	
	
	
	<!--end published content, not coming soon-->

	<!--tags-->
	 

	
	            
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oxide Computer releases distribution of illumos intended to power the Oxide Rack (401 pts)]]></title>
            <link>https://github.com/oxidecomputer/helios</link>
            <guid>39178521</guid>
            <pubDate>Mon, 29 Jan 2024 16:47:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/oxidecomputer/helios">https://github.com/oxidecomputer/helios</a>, See on <a href="https://news.ycombinator.com/item?id=39178521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:oxidecomputer/helios" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="xVGn1tBX4mVNIYMaWz1EV2b50WFWX9rY5oGgSfKDRKV06itPaiK5lIrHel7S_OaFuLHYTZ4e3KEF9iaYXO8ZDg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="oxidecomputer/helios" data-current-org="oxidecomputer" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=wEC4bs8ZuebuxYaGzi73AipCD8HuAyAQ0%2Bkn6jJHBmjlFkBCNeNikSnf4SO53sb2lwmxXKDKgLI%2F6wqhb2xzxrLYSwjUE3Y0Els04YUcGEAQBn310qRt2WDpUjVJQT3IBUquv8oiDoOkVhHCeX2ZKO%2FwKPljX4YQJL7OYcOn7sz%2BVgViDNBMm9TYLAiBQqbwdetEc7bza0xT%2BDH6NGq5OMz363h%2B7nZcmQQmR%2FYnP852T%2FceuTXLxhxYrhuhANrHIZhkWNKvbFdfZ6rZRihhdwPXYp24C0KyME62GPlPIjp%2FzzKokfUZAEE9jcJEKZKySJ4E9I6lhfOcPp2DiL8U95h2Grciz%2Bw0lBfu6jF5BS4Z0LQnFwu3E1LEFTkOP2ms%2FfwEyg46T%2BqSvJXmESU4nNFhWaL436a4UadivRSU8D6Glb5VIoXmoc0UVmR18k52w88iPYnGYkd23zJ1FggUNO6t3nRlbgvI9HQIT70gWaC5FvboagsWjVrMA3JJYKGPk%2BpxwuwhB%2F5Gq0oTweO1dbHc--6Qskg8QHWmNlcdi1--qaY8KMgjlltTsUE0w8urcA%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=oxidecomputer%2Fhelios" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/oxidecomputer/helios&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="954a652804e1eac88ae7a8241ce48cd1e8cb10a6092939703d95b074ab405d35" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Viewing Illegal Streams: No Cautions, Fines or Arrests Say GM Police (101 pts)]]></title>
            <link>https://torrentfreak.com/viewing-illegal-streams-no-cautions-fines-or-arrests-say-gm-police-240129/</link>
            <guid>39178122</guid>
            <pubDate>Mon, 29 Jan 2024 16:22:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/viewing-illegal-streams-no-cautions-fines-or-arrests-say-gm-police-240129/">https://torrentfreak.com/viewing-illegal-streams-no-cautions-fines-or-arrests-say-gm-police-240129/</a>, See on <a href="https://news.ycombinator.com/item?id=39178122">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>

<span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to TorrentFreak." href="https://torrentfreak.com/"><span property="name">Home</span></a><meta property="position" content="1"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Anti-Piracy category archives." href="https://torrentfreak.com/category/anti-piracy/"><span property="name">Anti-Piracy</span></a><meta property="position" content="2"></span> &gt; <span></span>
</p>
<p>
<span> </span>
After two UK regional police forces refused to supply information on the number of people cautioned, fined or arrested for simply <em>watching</em> illegal streams, this weekend it emerged that Greater Manchester Police received the same request and actually responded. For the years 2019, 2020, 2021, 2022 and 2023, the number of people cautioned, fined and/or arrested for simply watching illegal streams was.....zero.
</p>
</div><div>
<p><a href="https://torrentfreak.com/images/gm-police2.png"><img decoding="async" src="https://torrentfreak.com/images/gm-police2.png" alt="gm-police2" width="290" height="290" srcset="https://torrentfreak.com/images/gm-police2.png 320w, https://torrentfreak.com/images/gm-police2-300x300.png 300w, https://torrentfreak.com/images/gm-police2-150x150.png 150w" sizes="(max-width: 290px) 100vw, 290px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20290%20290'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/gm-police2.png 320w, https://torrentfreak.com/images/gm-police2-300x300.png 300w, https://torrentfreak.com/images/gm-police2-150x150.png 150w" data-lazy-src="https://torrentfreak.com/images/gm-police2.png"></a>Last Friday, we <a href="https://torrentfreak.com/police-website-offers-pirated-live-sports-streams-as-iptv-foia-requests-denied-240126/">reported</a> on two Freedom of Information Act requests directed at two regional police forces in the UK.</p>
<p>In almost identical requests, which appear to have been filed by the same person, Wiltshire Police and West Yorkshire Police were asked eight questions relating to enforcement measures taken against suppliers, distributors, and consumers of illegal streaming services. </p>
<p>Both police forces said that no information was readily accessible, adding that it would take so long to retrieve information manually that the estimated costs rendered both requests ineligible for disclosure under the Freedom of Information Act. That was disappointing.</p>
<p>A key component of an ongoing anti-piracy campaign in the UK includes sensitizing the public to the risk of being convicted for fraud offenses carrying prison sentences of up to 10 years. Not for getting involved in the supply or sale of pirate streams, but for simply <em><strong>watching them</strong></em>.</p>
<p>Certainly, legal theory doesn’t rule out the possibility, but in a campaign that relies almost entirely on fear, hard independent facts would’ve been a welcome addition.</p>
<h2>Information Accessible, Reasonably Priced</h2>
<p>During the weekend, we learned that the eight questions covering the five-year period 2019-2023, rejected by Wiltshire Police and West Yorkshire Police for being too costly to answer, were also sent to Greater Manchester Police (GMP). With just one exception (question 7 relating to the supply of illegal streams, <a href="https://torrentfreak.com/police-website-offers-pirated-live-sports-streams-as-iptv-foia-requests-denied-240126/">see earlier article</a>) GMP answered every question.</p>
<p>GMP reports that <em>two people</em> received a police caution for distributing or supplying illegal streaming services in 2021. During the same year, a total of <em>two people</em> were arrested for distributing or supplying illegal streaming services. </p>
<p>There’s insufficient information in the response to determine whether the two people arrested in 2021 were the same people who received cautions in 2021. In 2022, one person was arrested for distributing or supplying illegal streaming services.</p>
<h2>Distribution, Supply, &amp; Viewing</h2>
<p>Since GMP declined to answer question seven (which relates exclusively to the supply of illegal streams) but were happy respond to question six (which mentions both distribution and supply) it seems likely that all figures released here relate to distribution. </p>
<p>Overall then, a maximum of three arrests and two cautions in a five-year period doesn’t sound like a lot, even accounting for the possibility of additional arrests/cautions/fines relating to action under question 7.</p>
<p>Based on how many members of the public could be affected by the purported fraud prosecutions publicized in the media, we now turn to the most important disclosures by GMP with government figures for context.</p>
<p>The most recent data published by the Intellectual Property Office estimates that in 2022 alone, <a href="https://www.gov.uk/government/publications/online-copyright-infringement-tracker-survey-12th-wave/executive-summary-online-copyright-infringement-tracker-survey-12th-wave">3.9 million people</a> in the UK watched live sports via illegal streams. </p>
<center><a href="https://torrentfreak.com/images/3-9m-IPTV-live-sports.png"><img decoding="async" src="https://torrentfreak.com/images/3-9m-IPTV-live-sports.png" alt="3-9m IPTV live sports" width="670" height="353" srcset="https://torrentfreak.com/images/3-9m-IPTV-live-sports.png 710w, https://torrentfreak.com/images/3-9m-IPTV-live-sports-300x158.png 300w" sizes="(max-width: 670px) 100vw, 670px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20670%20353'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/3-9m-IPTV-live-sports.png 710w, https://torrentfreak.com/images/3-9m-IPTV-live-sports-300x158.png 300w" data-lazy-src="https://torrentfreak.com/images/3-9m-IPTV-live-sports.png"></a></center>
<p>How many of the 3.9 million live in GMP’s area is unknown but, with almost 500 square miles of mostly urban conurbation and a population of 2.8 million, it accounts for 5% of the overall UK population.</p>
<p>In its response to the FOIA request, Greater Manchester Police reveal that the number of people cautioned, fined and/or arrested for simply watching illegal streams in 2019, 2020, 2021, 2022, and 2023 combined, was…..zero. </p>
<h2>Inconvenient Facts Are Still Facts</h2>
<p>GMP’s disclosure doesn’t come as a surprise but seeing the zero figure in black and white confirms our suspicions. Had there been a single arrest anywhere in the UK, purely for watching illegal streams, no effort would’ve been spared to ensure everyone heard about it.</p>
<p>Whether similar disclosures will appear in the days and weeks ahead is unknown but thanks to GMP’s ability to accurately retrieve information, at least some facts have entered the public domain. If West Midlands Police or Leicestershire Police receive similar requests, their record retrieval skills shouldn’t disappoint.</p>
<p>For a six-week period early 2023, West Midlands Police were able to report that four crimes were linked to Prime Energy drink, <em>(<a href="https://foi.west-midlands.police.uk/wp-content/uploads/2023/03/ATTACHMENT_.pdf">pdf</a>)</em> including assault, harassment, criminal damage, and theft from a machine. None of the offenses related to the extortionate price of the drink, however.</p>
<p>In response to a FOIA request to disclose caller logs that featured terms including ‘UFO’, ‘Alien’, ‘UAP’ and ‘spaceship’, Leicestershire Police went to considerable lengths to protect caller privacy <em>(<a href="https://www.leics.police.uk/SysSiteAssets/foi-media/leicestershire/disclosure/disclosure_2023/08.-august/dl_2830_s402_ufo-reports-resonse-letter.pdf">pdf</a>)</em>. </p>
<p>After being provided with an example of appropriate redaction (<em>“Male caller named (REDACTED) reports seeing four flashing lights hovering above his property in (REDACTED) street before a female was beamed into the sky”</em>) the force published a spreadsheet. It lists 65 calls but no information that could identify any particular caller.</p>
<p>West Yorkshire Police received the same request <em>(<a href="https://www.westyorkshire.police.uk/freedom-of-information/august-2023-foi-1730542-23-ufo-sightings">pdf</a>)</em> and was able to confirm that the words ‘UFO’, ‘UAP’, ‘ALIEN’ or ‘SPACESHIP’ appeared in log text 1805 times.</p>
<p><em>GMP’s response to the FOIA request related to streaming is available <a href="https://www.gmp.police.uk/SysSiteAssets/foi-media/greater-manchester/disclosure-2024/january/foi.23.011815.n-illegal-streaming-of-sport-in-the-uk.pdf">here</a> (pdf)</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Phrasing – learn every language, to any level (118 pts)]]></title>
            <link>https://phrasing.app/playground</link>
            <guid>39177467</guid>
            <pubDate>Mon, 29 Jan 2024 15:38:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phrasing.app/playground">https://phrasing.app/playground</a>, See on <a href="https://news.ycombinator.com/item?id=39177467">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Apple Vision Pro’s missing apps (182 pts)]]></title>
            <link>https://stratechery.com/2024/the-apple-vision-pros-missing-apps/</link>
            <guid>39176899</guid>
            <pubDate>Mon, 29 Jan 2024 14:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stratechery.com/2024/the-apple-vision-pros-missing-apps/">https://stratechery.com/2024/the-apple-vision-pros-missing-apps/</a>, See on <a href="https://news.ycombinator.com/item?id=39176899">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-12205">
	<!-- .entry-header -->

	<div>
		<p>Om Malik has been observing, writing about, and investing in technology for going on three decades; that’s one reason I find his unabashed enthusiasm for the Apple Vision Pro to be notable. Malik wrote <a href="https://om.co/2024/01/08/vision-pro-is-coming/">on his blog</a>:</p>
<blockquote><p>
  Apple touts Vision Pro as a new canvas for productivity and a new way to play games. Maybe, maybe not. Just as the Apple Watch is primarily a health-related device that also does other things, including phone calls, text messages, and making payments. Similarly, the primary function for Vision Pro is ‘media’ — especially how we consume it on the go. Give it a few weeks, and more people will come to the same conclusion.</p>
<p>  In 2019,&nbsp;<a href="https://om.co/2019/01/13/so-what-can-apple-do-next/">I wrote an essay</a>&nbsp;about the future of television (screen):</p>
<blockquote><p>
    With that caveat, I think both, the big (TV) and biggest (movie theater) screens are going to go the way of the DVD. We could replace those with a singular, more personal screen — that will sit on our face. Yes, virtual reality headsets are essentially the television and theaters of the future. They aren’t good enough just yet — but can get better in the years to come as technologies to make the headsets improve.
  </p></blockquote>
<p>  Apple has made that headset. Apple Vision Pro has ultra-high-resolution displays that deliver more pixels than a 4K TV for each eye. This gives you a screen that feels 100 feet wide with support for HDR content. The audio experience is just spectacular. In time, Apple’s marketing machine will push the simple message — for $3,500, you get a full-blown replacement for a reference-quality home theater, which would typically cost ten times as much and require you to live in a McMansion.
</p></blockquote>
<p>Malik expounded on this point last week in a <a href="https://stratechery.com/2024/an-interview-with-om-malik-about-techs-history-and-future/">Stratechery Interview</a>:</p>
<blockquote><p>
  But the thing is you actually have to be mobile-native to actually appreciate something like this. So if you’ve grown up watching a 75-inch screen television, you probably would not really appreciate it as much. But if you are like me who’s been watching iPad for ten-plus years as my main video consumption device, this is the obvious next step. If you live in Asia, like you live in Taiwan, people don’t have big homes, they don’t have 85-inch screen televisions. Plus, you have six, seven, eight people living in the same house, they don’t get screen time to watch things so they watch everything on their phone. I think you see that behavior and you see this is going to be the iPod.
</p></blockquote>
<p>The iPod was a truly personal device, which was not only what people wanted, but also a great business: why sell one stereo to a household when you can sell an iPod to every individual? You can imagine Apple feeling the same about the long-term trajectory of the Vision Pro: why sell a TV that sits on the wall of the living room when you can sell every individual a TV of their own? You can be sure that Apple isn’t just marketing this device to people who live alone: the EyeSight feature only makes sense if you are wearing the Vision Pro around other people.</p>
<p>I already commented about the dystopian nature of this vision <a href="https://stratechery.com/2023/apple-vision/">when the Vision Pro was announced</a>; for now I’m interested in the business aspects of this vision, and the iPod is a good place to start.</p>
<h3>The iPod and the Music Labels</h3>
<p>The iPod story actually starts with the Mac, and Apple’s vision of a “Digital Hub.” The company released iMovie in 1999, iDVD and iTunes two years later, and iPhoto a year after that. The release order is interesting: Apple thought that home movies would be the big new market for PCs, but the emergence of Napster in 1999 made it clear that music was a much more interesting market (digital cameras, meanwhile, were only just becoming a thing). That laid the groundwork for the iPod, which was released in the fall of 2001. I documented this history in <a href="https://stratechery.com/2017/apple-and-the-oak-tree/">Apple and the Oak Tree</a> and noted:</p>
<blockquote><p>
  One of my favorite artifacts from the brief period between the introduction of iTunes and the release of the iPod was Apple’s “Rip. Mix. Burn.” advertising campaign.</p>
<p>  <a href="https://stratechery.com/2017/apple-and-the-oak-tree/"><img loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2017/08/rip-mix-burn.jpg?resize=600%2C283&amp;ssl=1" alt="Apple's Rip. Mix. Burn. iMac campaign" width="600" height="283" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2017/08/rip-mix-burn.jpg?w=600&amp;ssl=1 600w, https://i0.wp.com/stratechery.com/wp-content/uploads/2017/08/rip-mix-burn.jpg?resize=300%2C142&amp;ssl=1 300w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1"></a></p>
<p>  What is particularly amazing (that is, beyond the cringe-inducing television ad) is that Apple was arguably encouraging illegal behavior: it was likely legal to rip and probably legal to burn, presuming the CD that you made was for your own personal use. It certainly was not legal to share.
</p></blockquote>
<p>The iPod was predicated on the reality of file-sharing as well:</p>
<blockquote><p>
  And yet, as much as “Rip. Mix. Burn.” may have walked the line of legality, the reality of iTunes — and the iPod that followed — was well on the other side of that line. Apple knew better than anyone that the iPod’s tagline — 1,000 songs in your pocket — was predicated on users having 1,000 digital songs, not via the laborious procedure of ripping legally purchased CDs, but rather via Napster and its progeny. By the spring of 2003 Apple had introduced the iTunes Music Store, a seamless and legal way to download DRM-protected digital music, but particularly in those early days the value of the iTunes Music Store to Apple was not so much that it was a selling point to consumers, but rather a means by which Apple could play dumb about how it was that its burgeoning number of iPod customers came to fill up their music libraries.
</p></blockquote>
<p>That description of the iTunes Music Store is perhaps a touch cynical, but it is impossible to ignore the importance of music piracy in Apple’s original deal with the record labels. Apple was able to make a deal in part because it was offering the carrot of increased digital revenue, but it was certainly aided by the stick of piracy obliterating CD sales.</p>
<p><img loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-4.png?resize=640%2C390&amp;ssl=1" alt="The carrot and stick of the iTunes Music Store" width="640" height="390" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-4.png?w=1280&amp;ssl=1 1280w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-4.png?resize=300%2C183&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-4.png?resize=1024%2C623&amp;ssl=1 1024w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-4.png?resize=768%2C467&amp;ssl=1 768w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-4.png?resize=1035%2C630&amp;ssl=1 1035w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></p>
<p>Over the next few years the record labels would become increasingly resentful of Apple’s position in the market, but they certainly weren’t going anywhere; by 2008 iTunes was their biggest source of revenue, and it’s all but impossible for an ongoing business to give up revenue just because they think the arrangement under which they make that revenue is unfair.</p>
<h3>The App Store</h3>
<p>The iTunes Music Store does still exist, although its revenue contribution to the labels has long been eclipsed by streaming. It’s more important contribution to modern computing is that it provided the foundation for the App Store.</p>
<p>The App Store didn’t exist when Apple launched its iPhone in 2007; Apple provided a suite of apps that made the iPhone more capable than anything else on the market, and assumed the web would take care of the rest. Developers, though, wanted to build apps; in September 2007 <a href="https://github.com/chockenberry/mobile-twitterrific">Iconfactory released Twitterific</a>, a Twitter client that ran on jail-broken iPhone devices, and more apps followed. The following year Apple gave its eager developers what they wanted: an officially supported SDK and an App Store to distribute their apps, for free or for pay; in the case of the latter Apple would, just as it did with songs, keep 30% of the purchase price (and cover processing fees).</p>
<p>This period of the App Store didn’t require any sticks: the capability of the iPhone was carrot enough, and, over the next few years, as the iPhone exploded in popularity, the market opportunity afforded by the App Store proved even more attractive. A better analogy to what Apple provided was gas for the fire, particularly with the release of in-app purchase capabilities in 2009. Now developers could offer free versions of their apps and convert consumers down the line, or sell consumables, a very profitable approach for games.</p>
<p>That, though, is where App Store innovation stopped, at least for a while. By 2013, when I started Stratechery, I was wondering <a href="https://stratechery.com/2013/why-doesnt-apple-enable-sustainable-businesses-on-the-app-store/">Why Doesn’t Apple Enable Sustainable Businesses on the App Store?</a>, by which I meant trials, paid updates, and built-in subscription support. The latter (along with associated trials) finally showed up in 2016, but at that point developer frustration with the App Store had been growing right alongside Apple’s services revenues: productivity apps shared my concerns about sustainability, while “reader” apps like streaming services were frustrated that they couldn’t sign up new users in the app, or even point them to the web; game developers, meanwhile, hated giving away 30% of their revenue.</p>
<p>It’s fair to note that an unacknowledged driver of much of this frustration was surely the fact that the app market matured from the heady days of the early App Store. No one is particularly worried about restrictions or missing capabilities or revenue shares when there is a landgrab for new users’ homescreens; by the end of the decade, though, mature businesses were locked in a zero sum game for user attention and dollars. In that environment the money Apple was taking, despite the fact the lack of flexibility entailed in terms of business model, was much more of an irritant; still, it’s all but impossible for an ongoing business to give up revenue just because they think the arrangement under which they make that revenue is unfair.</p>
<h3>The Epic Case</h3>
<p>I keep saying “all but impossible” because Epic is the exception that proved the rule: in <a href="https://stratechery.com/2020/apple-epic-and-the-app-store/">August 2020</a> Epic updated Fortnite to include an alternative in-app purchase flow, was subsequently kicked out of the App Store by Apple, and proceeded to file an antitrust lawsuit against the iPhone maker. I documented this saga from beginning to end, including:</p>
<ul>
<li><a href="https://stratechery.com/2020/apple-epic-and-the-app-store/">Apple, Epic, and the App Store</a>, which provided a history of the App Store and Epic’s lawsuit at the time it was filed.</li>
<li><a href="https://stratechery.com/2021/app-store-arguments/">App Store Arguments</a>, which I wrote at the conclusion of the trial, explained why I expected Epic to lose, even as I hoped that Apple would voluntarily make pro-developer changes in the App Store.</li>
<li><a href="https://stratechery.com/2021/the-apple-v-epic-decision/">The Apple v. Epic Decision</a>, which reviewed the judge’s decision that favored Apple in 10 of the 11 counts.</li>
</ul>
<p>The 11th count that Epic prevailed on required Apple to allow developers to steer users to a website to make a purchase; while its implementation was delayed while both parties <a href="https://stratechery.com/2023/apple-epic-and-the-court-of-appeals-apples-federal-victory-epics-california-win/">filed appeals</a>, the lawsuit reached the end of the road last week when the Supreme Court denied certiorari. That meant that Apple had to allow steering, and the company did so in the most restrictive way possible: developers had to use an Apple-granted entitlement to put a link on one screen of their app, and pay Apple 27% of any conversions that happened on the developer’s website within 7 days of clicking said link.</p>
<p>Many developers were outraged, but the company’s tactics were <a href="https://stratechery.com/2024/the-supreme-court-declines-to-hear-apple-epic-apples-predictable-response/">exactly what I expected</a>:</p>
<blockquote><p>
  To that end, I wouldn’t be surprised if Apple does the same in this case: developers who steer users to their website may be required to provide auditable conversion numbers and give Apple 27%, and oh-by-the-way, they still have to include an in-app purchase flow (that costs 30% and includes payment processor fees and converts much better). In other words, nothing changes — unless it goes in the other direction: if Apple is going to go to the trouble to build out an auditing arm, then it could very well go after all of the revenue for everyone with an app in the App Store, whether they acquire a user through in-app purchase or not. The reason not to do so before was some combination of goodwill, questionable legality, and most importantly the sheer hassle of it all. At this point, though, it’s not clear if any of those will be deterrents going forward…</p>
<p>  Apple has shown, again and again and again, that it is only going to give up App Store revenue kicking-and-screaming; indeed, the company has actually gone the other way, particularly with its crackdown over the last few years on apps that only sold subscriptions on the web (and didn’t include an in-app purchase as well). This is who Apple is, at least when it comes to the App Store.
</p></blockquote>
<p>The crackdown I’m referring to was pure stick: <a href="https://stratechery.com/2020/xscale-and-arm-in-the-cloud-hey-versus-apple-apples-iap-campaign/">Apple refused to approve upgrades to SaaS apps</a> that had been in the App Store for years unless they added in-app purchase; developers <a href="https://twitter.com/benthompson/status/1273079296618201093">complained</a> but this time the reality of it being impossible for an ongoing business to give up revenue meant they didn’t have any choice but to do extra work so that Apple could have a cut.</p>
<h3>Vision Pro’s Missing Apps</h3>
<p>The Apple Vision Pro started pre-sales last week, but the biggest surprise came via two stories from Bloomberg. <a href="https://www.bloomberg.com/news/articles/2024-01-17/watching-netflix-on-apple-vision-pro-you-ll-have-to-use-the-web">First</a>:</p>
<blockquote><p>
  Netflix Inc. isn’t planning to launch an app for Apple Inc.’s upcoming Vision Pro headset, marking a high-profile snub of the new technology by the world’s biggest video subscription service. Rather than designing a Vision Pro app — or even just supporting its existing iPad app on the platform — Netflix is essentially taking a pass. The company, which competes with Apple in streaming, said in a statement that users interested in watching its content on the device can do so from the web.
</p></blockquote>
<p><a href="https://www.bloomberg.com/news/articles/2024-01-18/youtube-and-spotify-join-netflix-in-not-launching-apple-vision-pro-apps">Second</a>:</p>
<blockquote><p>
  Google’s YouTube and Spotify Technology SA, the world’s most popular video and music services, are joining Netflix Inc. in steering clear of Apple Inc.’s upcoming mixed-reality headset. YouTube said in a statement Thursday that it isn’t planning to launch a new app for the Apple Vision Pro, nor will it allow its longstanding iPad application to work on the device — at least, for now. YouTube, like Netflix, is recommending that customers use a web browser if they want to see its content: “YouTube users will be able to use YouTube in Safari on the Vision Pro at launch.” Spotify also isn’t currently planning a new app for visionOS — the Vision Pro’s operating system — and doesn’t expect to enable its iPad app to run on the device when it launches, according to a person familiar with matter. But the music service will still likely work from a web browser.
</p></blockquote>
<p>These are a big loss: Malik made the case about why the Vision Pro is the best TV ever, but it will launch without native access to the largest premium streaming service and the largest repository of online video period. I myself am very excited about the productivity use cases of the Vision Pro, which for me includes listening to music while I work; no Spotify makes that harder.</p>
<p>There are, to be sure, valid business reasons for all three services to have not built a native app; <a href="https://medium.com/@mingchikuo/apple-vision-pro-shipment-growth-may-be-below-market-expectations-apple-vision-pro%E5%87%BA%E8%B2%A8%E6%88%90%E9%95%B7%E5%8F%AF%E8%83%BD%E4%BD%8E%E6%96%BC%E5%B8%82%E5%A0%B4%E9%A0%90%E6%9C%9F-7a5eeb613ab0">the latest prediction from Apple supply chain analyst Ming-Chi Kuo</a> put first-year sales at around 500,000 units, which as a tiny percentage of these services’ user bases may not be worth the investment. Apple’s solution, though, is to simply use a pre-existing iPad app; that all three companies declined to do even that is notable. Nebula CEO Dave Wiskus observed <a href="https://twitter.com/dwiskus/status/1748354772531282213">on X</a>:</p>
<div>
<blockquote data-dnt="true">
<p lang="en" dir="ltr">2003: Steve Jobs brings the big five record labels together in a landmark deal to sell their songs digitally for $0.99 each on the iTunes Store.</p>
<p>2024: Apple can’t convince streaming video companies to check the “allow iPad app” box.</p>
<p>— Dave Wiskus (@dwiskus) <a href="https://twitter.com/dwiskus/status/1748354772531282213?ref_src=twsrc%5Etfw">January 19, 2024</a></p></blockquote>
</div>
<p>The Apple Vision Pro app shelves will not be bare in terms of video content; the company says in a <a href="https://www.apple.com/newsroom/2024/01/apple-previews-new-entertainment-experiences-launching-with-apple-vision-pro/">press release</a>:</p>
<blockquote><p>
  Users will also be able to download and stream TV shows, films, sports, and more with apps from top streaming services, including Disney+, ESPN, NBA, MLB, PGA Tour, Max, Discovery+, Amazon Prime Video, Paramount+, Peacock, Pluto TV, Tubi, Fubo, Crunchyroll, Red Bull TV, IMAX, TikTok, and the 2023 App Store Award-winning MUBI. Users can also watch popular online and streaming video using Safari and other browsers.
</p></blockquote>
<p>It’s not clear how many of these apps are truly native versus iPad apps with the Vision Pro check box, but the absence of Netflix and YouTube do stand out, and their absence is, without question, a total failure for Apple’s developer relations team.</p>
<p>The blame, though, likely goes to the App Store: Apple has been making Netflix in particular jump through hoops for years when it comes to precisely what language the service can or cannot present to customers who can’t sign up in the app, and also can’t be directed to the web. The current version’s language is fairly anondyne (although it has been <a href="https://149384716.v2.pressablecdn.com/wp-content/uploads/2024/01/vision-pro-apps-3.png">spicier in the past</a>):</p>
<p><img loading="lazy" decoding="async" src="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-2.png?resize=640%2C447&amp;ssl=1" alt="Netflix's language in its iOS app for new users" width="640" height="447" srcset="https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-2.png?w=1280&amp;ssl=1 1280w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-2.png?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-2.png?resize=1024%2C715&amp;ssl=1 1024w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-2.png?resize=768%2C536&amp;ssl=1 768w, https://i0.wp.com/stratechery.com/wp-content/uploads/2024/01/vision-pro-apps-2.png?resize=902%2C630&amp;ssl=1 902w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></p>
<p>Apple may be unhappy that Netflix viewers have to go to the Netflix website to watch the service on the Vision Pro (and thus can’t download shows for watching offline, like on a plane); Netflix might well point out that that going to the web is exactly what Apple makes Netflix customers do to sign up for the service.<sup id="rf1-12205"><a href="#fn1-12205" title="There is an exception for Netflix specifically: if you download a Netflix game <a href=&quot;https://stratechery.com/2023/netflix-earnings-netflixs-licensing-pitch-netflix-gaming-revisited/&quot;>you can sign up with in-app purchase</a>, which the company would almost certainly prefer not to offer but, thanks to Apple’s aforementioned crack-down on SaaS app sign-ups, requires." rel="footnote">1</a></sup></p>
<h3>Developers On Strike</h3>
<p>It’s certainly possible that I’m reading too much into these absences: maybe these three companies simply didn’t get enough Visions Pro to build a native app, and felt uncomfortable releasing their iPad versions without knowing how useful they would be. YouTube in particular, given that much of its usage is free, likely has less of a beef with Apple than Netflix or Spotify do, and it’s easy enough to believe that Google just isn’t a company that moves that fast these days.</p>
<p>Still, there’s no question that the biggest beneficiary of these companies being on the Vision Pro — and, correspondingly, the biggest loser from their absence — is Apple. The company is launching an audacious and ambitious new product, and there are major partners in its ecosystem that aren’t interested in helping.</p>
<p>This is the consequence of fashioning App Store policies as a stick: until there is a carrot of a massive user base, it’s hard to see why developers of any size would be particularly motivated to build experiences for the Vision Pro, which will make it that much more difficult to attract said massive user base. Apple was happy to remind users that, when it came to the iPhone, <a href="https://www.youtube.com/watch?v=szrsfeyLzyg">there’s an app for that</a>; in the case of the Vision Pro, there may not be: this is the one and only chance for developers to go on strike without suffering an Epic-like fate, and some of them are taking it.</p>
<p>For now, Apple appears to be so supply-constrained that it doesn’t matter; the company will likely sell as many units as it can make. I would guess that Apple’s strategy with regards to developer hold-outs will be to wait them out, trusting that it can sell enough devices that developers can’t go on strike forever. I certainly think this approach is more likely than offering any sort of concessions to developers, on any of its platforms.</p>
<h3>A Disney Double-Down?</h3>
<p>The other option may be an even greater investment in content by Apple itself. This could take the form of more Apple TV+ shows and sports deals like MLS, but the most interesting possibility is deepening its partnership with Disney. The entertainment giant is looking for a tech partner to invest in its ESPN streaming service, and the Vision Pro makes Apple a compelling candidate. From <a href="https://stratechery.com/2023/bob-iger-on-cnbc-the-end-of-linear-tv-espn-and-strategic-partnerships-and-apple/">an Update last summer</a>:</p>
<blockquote><p>
  What does seem notable was Iger’s call out of Apple’s headset; I can attest that the sports experience on the Vision Pro is extraordinary, and remember that Iger appeared on stage at the event to say that Disney would be working with Apple to bring content to the device; here is the sports portion of the video he played at WWDC:</p>

<p>  I have to say, one almost gets the impression that the Apple Vision sports-watching experience might have single-handedly convinced Iger to keep ESPN! What does seem likely is that Apple is probably Iger’s preferred partner, and there certainly is upside for Apple — probably more upside than any other tech company — primarily because of the Vision Pro. The single most important factor in the Vision Pro’s success will likely be how quickly entertainment is built for it, and as Cook noted while introducing Iger, “The Walt Disney Company is the world’s leader in entertainment.”
</p></blockquote>
<p>I heard from a lot of people after that Update who were very skeptical that any sort of deal would be struck, in large part because Apple is so difficult to partner with (the company seems continually surprised that not everyone negotiates like the record labels under siege from Napster). And, it should be noted, Disney is showing up on Day One for the Vision Pro launch; why partner if the content is already there?</p>
<p>And yet, Apple’s most potent response to ecosystem intransigence may be to double down: Disney with a war chest (via an Apple partnership) would be a far more formidable competitor to Netflix, and ESPN with a VR camera at every game it televises would, in my estimation, make the Vision Pro an essential purchase for every sports fan. I once argued that <a href="https://stratechery.com/2016/apple-should-buy-netflix/">Apple Should Buy Netflix</a> the last time the two companies were at odds, but the weakness in that argument is that simply having money another company needs isn’t a compelling enough case; when it comes to Disney the payoff is the Apple Vision Pro having that much more great content that much sooner, not only making the headset a success but also making it impossible for other streaming businesses to not serve their customers just because they think the arrangement under which they operate is unfair.</p>
<hr><ol><li id="fn1-12205"><p>There is an exception for Netflix specifically: if you download a Netflix game <a href="https://stratechery.com/2023/netflix-earnings-netflixs-licensing-pitch-netflix-gaming-revisited/">you can sign up with in-app purchase</a>, which the company would almost certainly prefer not to offer but, thanks to Apple’s aforementioned crack-down on SaaS app sign-ups, requires.&nbsp;<a href="#rf1-12205" title="Return to footnote 1.">↩</a></p></li></ol>
	</div><!-- .entry-content -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Walmart pays its truck drivers 6 figures (192 pts)]]></title>
            <link>https://www.freightwaves.com/news/how-walmart-uses-trucking-to-dominate-american-retail</link>
            <guid>39176877</guid>
            <pubDate>Mon, 29 Jan 2024 14:51:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.freightwaves.com/news/how-walmart-uses-trucking-to-dominate-american-retail">https://www.freightwaves.com/news/how-walmart-uses-trucking-to-dominate-american-retail</a>, See on <a href="https://news.ycombinator.com/item?id=39176877">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-504392">
	

	<div id="entry-content">
		
<p data-beyondwords-marker="8dd5baad-38cf-4842-849f-6e19e61393d3">One Walmart truck driver says he has 15 years left of working, and he intends to spend them hauling loads for Walmart. “Barring a lottery win or marrying a sugar mama, I don’t see myself going anywhere,” said the Texas-based driver, who asked not to have his name included as he is not authorized to speak on behalf of the company.</p>







<p data-beyondwords-marker="d9aacada-376e-4c45-81b8-93a8340b45df">Such loyalty to a single company is unusual in trucking, an industry notorious for massive turnover. And the Texas trucker isn’t alone in his dedication to Walmart. One of the best jobs you can get in trucking is at Walmart. <a href="https://corporate.walmart.com/news/2022/04/07/drive-in-opportunity-walmart-raises-driver-pay-and-launches-private-fleet-development-program">The uber-retailer says</a> truck drivers can make up to $110,000 in their first year at the company. That’s twice the nationwide median pay of a truck driver, and certainly above <a href="https://corporate.walmart.com/askwalmart/how-much-do-walmart-associates-make">the $17.50 an hour</a> that the average Walmart associate earns. Home time, paid vacation and good health insurance are also guaranteed for Walmart company drivers. These offerings are elusive in the trucking world.</p>







<p data-beyondwords-marker="e7df8d37-546e-42ca-950d-7b3224abffe0">It’s not out of the goodness of Walmart’s corporate heart that it pays truck drivers a truckload. Rather, truckers are key to Walmart’s retail dominance — and they have been from the start. Without a highly engaged trucking workforce, it’s not likely that the company would have flourished in the way it has. The Fortune 1 company prioritized supply chain long before it became a buzzword.</p>







<p data-beyondwords-marker="f5baf673-c5b8-444f-8626-f64bd53fca99">“At Walmart, we believe in offering our drivers a competitive compensation package to attract the best drivers in the industry,” a Walmart spokesperson told FreightWaves in an emailed statement.&nbsp;&nbsp;</p>



<figure data-beyondwords-marker="9af8cc1d-793c-4149-8477-f8e1c32431f9"><img decoding="async" width="1600" height="1059" src="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-2.jpeg" alt="" srcset="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-2.jpeg 1600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-2-600x397.jpeg 600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-2-1200x794.jpeg 1200w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-2-768x508.jpeg 768w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-2-1536x1017.jpeg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption><em>Walmart company drivers are historically some of the most elite in the industry. (Photo: Jim Allen/FreightWaves)</em></figcaption></figure>



<p data-beyondwords-marker="66a4f40e-3ab5-4981-a610-0944076f4876">Walmart employs some 14,000 drivers, which makes it comparable to some of the largest for-hire fleets in the U.S. It’s added 5,800 drivers to the company in the past five years alone.&nbsp;</p>







<p data-beyondwords-marker="61cc4cfe-b165-467e-913f-bfa6d31567d4">Recently, Walmart has shifted some of its strategies around recruiting those new drivers. In 2018, Walmart changed its truck driving recruitment program to allow more drivers to pass its program. A senior vice president at Walmart <a href="https://finance.yahoo.com/news/walmart-successfully-recruited-truck-drivers-122937062.html">told Yahoo! Finance</a> at the time it was because of a “shortage” of truck drivers. (Those who study the trucking industry <a href="https://www.bls.gov/opub/mlr/2019/article/is-the-us-labor-market-for-truck-drivers-broken.htm">dispute that such a shortage exists</a>, concluding that drivers leave the industry for jobs with better pay and hours.)</p>







<p data-beyondwords-marker="394e993e-0a74-4eae-8828-e86069f7cff4">Last year, Walmart announced another key pivot. The <a href="https://www.freightwaves.com/news/walmart-expands-in-house-driver-hiring-training-program">company said in January 2023</a>, building on a pilot it launched the <a href="https://corporate.walmart.com/news/2022/04/07/drive-in-opportunity-walmart-raises-driver-pay-and-launches-private-fleet-development-program">year before</a>, that it would allow Walmart associates living in participating locations to apply to a 12-week CDL program. For perhaps the first time, a Walmart company driver doesn’t need years of experience to get behind the wheel of its branded 18-wheelers. It may be that Walmart’s tack on trucking is changing.&nbsp;</p>







<h2 data-beyondwords-marker="8a201039-55d3-4ac3-87de-2de23e3a39bd" id="h-operating-in-the-boondocks-forced-walmart-to-become-a-distribution-whiz">Operating in the boondocks forced Walmart to become a distribution whiz</h2>







<p data-beyondwords-marker="fd3e035a-b533-434b-b7fa-ae25df3bbe1a">Decades before Walmart became the biggest company in the world — raking in $611 billion in revenue last year — its leadership team couldn’t find anyone to haul freight to its first stores. Walmart operated mostly in the boondocks, far from where most trucking companies wanted to go.</p>







<p data-beyondwords-marker="32a80ef4-869b-4c38-99d4-40f09f7ea116">“We couldn’t find anybody who wanted to run their trucks 60 or 70 miles out of the way into these little towns where we were operating,” Don Sonderquist, an early Walmart executive, explained in an interview <a href="https://theyoungtreps.com/wp-content/uploads/2021/03/sam_walton-made_in_america.pdf">published in 1992</a>. “We were totally ignored by the distributors and the jobbers. That’s not only how we came to build our own distribution system, it’s also how we got used to beating the heck out of everybody on prices.”</p>







<p data-beyondwords-marker="0463b21b-88a3-4dc7-b48c-9a0cf4930657">This forced founder Sam Walton to build up his own network of suppliers, too. Walmart elected to work directly with the brands it sells in-store, which still allows the company unusual control over the minutiae of the products of some very large companies, according to journalist Charles Fishman, the author of the 2006 book “The Wal-Mart Effect.”</p>







<figure data-beyondwords-marker="e922ebce-85d8-4182-8ce2-35e019f20b83"><img loading="lazy" decoding="async" width="1600" height="900" src="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-3.jpeg" alt="" srcset="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-3.jpeg 1600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-3-600x338.jpeg 600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-3-1200x675.jpeg 1200w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-3-768x432.jpeg 768w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-3-1536x864.jpeg 1536w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-3-390x220.jpeg 390w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption><em>Walmart employed 2.1 million associates, per its 2022 financial statement. It’s the largest private employer in the world. (Photo: Jim Allen/FreightWaves)</em></figcaption></figure>







<p data-beyondwords-marker="a982dd1c-d09e-4130-97c9-79493c2e9cfd">This hyperfocus on supply chain and distribution shaped key decisions from the top to the bottom of Walmart’s operations. That’s according to two people who have closely studied Walmart: Fishman and historian Nelson Lichtenstein, author of the 2006 book “Wal-Mart: The Face of Twenty-First-Century Capitalism” and professor at the University of California, Santa Barbara.</p>







<p data-beyondwords-marker="2613a98e-07de-460a-8a58-83f51e742567">When Walmart sought to open a new store, Fishman and Lichtenstein explained, it built the distribution center. Then, it built stores within a one-day drive of that distribution center. This might seem like an obvious strategy in 2024, but it was somewhat revolutionary in the mid-20th century. Kmart, for example, targeted the same blue-collar Americans that Walmart did. However, Kmart would simply plop stores into suburbs that had plenty of customers. Distribution was an afterthought.</p>







<p data-beyondwords-marker="1a716f30-0896-44fd-bae2-f564ecb135bb">“Walmart has become the largest company in human history by doing something that was already being done, better than anyone else did it,” Fishman said. “Logistics and transportation is one of the things that made Walmart, Walmart, and allowed them to outcompete.”</p>







<h2 data-beyondwords-marker="4056585e-82f7-45df-82fc-dd968c660a58" id="h-so-why-is-walmart-so-obsessed-with-its-truckers">So … why is Walmart so obsessed with its truckers?</h2>







<p data-beyondwords-marker="da760775-c730-4d4f-a7f7-ea2f405a0546">Kroger, Home Depot, Target and the like all operate huge supply chains and obviously manage to get their shelves robustly stocked — without the front-and-center obsession on supply chain. Walmart’s supply chain, though, is different for a few key reasons. Professor Brian Gibson, executive director of the Center for Supply Chain Innovation at Auburn University, laid it out:</p>







<ul data-beyondwords-marker="61760d03-5096-4296-99b9-3cd543dda28d">
<li data-beyondwords-marker="b9acc781-0284-4cb2-bd24-7f77a92a2618">Walmart is just, well, bigger than any other retailer. It has 4,616 stores, compared to fewer than 2,000 for Target, around 2,200 for Home Depot and 2,750 for Kroger. Walmart also has a larger average square footage per store, too.</li>
</ul>



<ul data-beyondwords-marker="3445c5f7-3db8-45e1-ac96-a4218f270c96">
<li data-beyondwords-marker="3889d350-1d62-40dc-81b5-7991c01b8bbc">Walmart has a mix of grocery and general merchandise, which adds complexity to its trucking network.</li>
</ul>



<ul data-beyondwords-marker="bdb10324-e7d4-4f44-a3dd-942287249a87">
<li data-beyondwords-marker="7cd90b3b-83cc-433d-8bec-42ba5fb396a8">As a result of its large, private fleet, Walmart has unusual clout among equipment manufacturers and other trucking service providers. It’s the type of status that’s usually reserved for companies that <em>only </em>do trucking.</li>
</ul>







<p data-beyondwords-marker="4130dfc0-bb57-4e73-91df-d7171aec82a7">“Walmart’s mission is to save people money so they can live better,” the Walmart spokesperson said in an emailed statement. “Managing our own distribution and trucking networks helps us better serve our customer and manage costs.”</p>







<figure data-beyondwords-marker="6c4c9632-6ab9-4de3-9fb2-43584f3b6c28"><img loading="lazy" decoding="async" width="1600" height="900" src="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image.jpeg" alt="" srcset="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image.jpeg 1600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-600x338.jpeg 600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1200x675.jpeg 1200w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-768x432.jpeg 768w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1536x864.jpeg 1536w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-390x220.jpeg 390w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption><em>Walmart employs around 14,000 truck drivers. The retailer hired nearly 6,000 in the last five years. (Photo: Jim Allen/FreightWaves)&nbsp;&nbsp;</em></figcaption></figure>







<p data-beyondwords-marker="023e0528-b7b7-4ccd-8924-aa803eb1d715">The importance of distribution is perhaps incredibly obvious. If stuff is not on the shelves, customers aren’t going to be buying that stuff. Customers would ultimately buy less during that visit and, if they get fed up by a consistent lack of stuff, eventually not at all. The stuff has to be moved safely and on time across the country. If paying top dollar makes that happen, then it’s sensible for Walmart to agree to do that.&nbsp;</p>







<p data-beyondwords-marker="830b6ace-7eb3-47b6-95fc-19c94f264a4f">“They wanted to pay them good money because it was the absolute core of their, of their business — to get this stuff from the distribution center to the store at precisely the right time with no screw-ups,” Lichtenstein said. “That was crucial.”</p>







<p data-beyondwords-marker="496d0d5c-a78a-451a-8118-98f7f7531ce6">Paying truck drivers top dollar also makes sense because Walmart doesn’t employ <em>that </em>many of them. The company has about 14,000 truck drivers and 1.6 million associates. Each of those truck drivers holds a lot of power over the shopping experience of a Walmart store.</p>







<p data-beyondwords-marker="c20b4b36-e0fb-40bf-903e-a72e55e39c2c">“One associate here or there can have a positive impact, but it’s not going to change the economics of the store,” Fishman said. “A truck driver is going to really matter. They have an outsized impact on the way the company runs.”</p>







<p data-beyondwords-marker="02affaa7-8d8e-40d0-9f62-78ba5916c91b">Paying six figures to 14,000 employees may seem reasonable enough for Walmart. “It’s not even 1% of their staff,” Fishman said.&nbsp;</p>







<h2 data-beyondwords-marker="6b526b1b-f9d6-45f7-a9dd-ad3cbacd6f36" id="h-walmart-is-remodeling-some-of-its-trucker-policies-nbsp">Walmart is remodeling some of its trucker policies&nbsp;</h2>







<p data-beyondwords-marker="54e57326-54f8-4676-8405-95c53e368041">Walmart is now changing its truck driver hiring policies. Until 2022, the company required 30 months of driver experience before one could be considered for the company driver role. That year, the company began piloting a program that allowed Walmart associates to go to a 12-week driver training program and become fleet drivers. Walmart expanded the program nationwide. (Outside applicants still need 30 months of training, and not every associate who applies is admitted to the program.)</p>







<p data-beyondwords-marker="30895f29-e1f1-48ee-9bfc-e988adf6e84f">“We started the Associate-to-Driver program because we wanted to tap into our own talent pool of incredible associates and give them opportunity to develop their career,” the Walmart spokesperson said in a written statement. “It’s been a great opportunity for our associates to continue to grow their careers without having to leave the company.”</p>







<p data-beyondwords-marker="e66e080b-8d9c-4d90-a713-a6a1dc07585f">The spokesperson said the company requires all trainees to pass the same skills assessment as external hires. Then, they’re partnered with a mentor for six weeks of continued training.</p>







<p data-beyondwords-marker="75919ed4-01fc-4c8d-b730-920a1b1959a1">It’s a sensible move for Walmart to train from within; its current CEO, Doug McMillon, started as an hourly associate. “I think it’s a recognition that [you value] your own employees better than somebody walking in off the street,” GIbson said.</p>







<h2 data-beyondwords-marker="854eb036-4cec-4872-8e90-68962d48b2f9" id="h-the-truck-driver-shortage-debate-appears-again">The truck driver shortage debate appears… again</h2>







<p data-beyondwords-marker="1ff6c81e-3834-4dfe-99fc-c9fca4791852">Some Walmart drivers aren’t delighted.&nbsp;</p>







<p data-beyondwords-marker="8b5ea380-9f56-4e72-9694-63386a852ed9">The Texas-based Walmart truck driver, who joined the company two years ago, said the retailer could attract more drivers by raising its pay. “Raise the driver’s pay and you’ll retain and attract [experienced drivers],” he said.</p>







<p data-beyondwords-marker="d6bf850d-68e8-4c6d-96df-7a9321012c30">Another Texas-based truck driver, who joined Walmart seven years ago, said he fears it’s a sign that Walmart is approaching trucking in the same way as large for-hire fleets, which see typical turnover rates around 94%.</p>







<p data-beyondwords-marker="93bb122a-e2a5-44c5-9161-b4c37f59340c">“Back in the day, you used to need a decade before you’re even looked at to get on with Walmart,” he said. (The driver asked not to have his name included as he is not authorized to speak on behalf of the company.)</p>







<p data-beyondwords-marker="0ad65c61-0264-400e-b43c-099fb2939f02">Both complaints get at the heart of an ongoing debate in the trucking industry: the so-called <a href="https://www.freightwaves.com/news/why-trucking-embraces-alarming-turnover-rates">truck driver shortage</a>. Trucking employers maintain that they’re unable to hire drivers due to a persistent shortage — caused largely by demographic issues and the lifestyle of trucking. However, researchers (and truck drivers themselves) disagree. Studies suggest the massive turnover seen by large fleets keeps them scrambling to hire new workers; one March 2019 study <a href="https://www.bls.gov/opub/mlr/2019/article/is-the-us-labor-market-for-truck-drivers-broken.htm">published by the Bureau of Labor Statistics</a> concluded that “price signals” would lead to a more stable trucking workforce.</p>







<p data-beyondwords-marker="3b98a943-7726-4bb5-ab95-1ab226690ab4">A company, like Walmart, that pays six figures and offers good benefits should not struggle with turnover. On the other hand, Walmart needs to hire more drivers as the retailer expands operations and current truckers retire. Walmart has hired nearly 6,000 new drivers in the past five years.&nbsp;</p>







<h2 data-beyondwords-marker="84563572-42be-4d95-9545-9cf07299dafe" id="h-experts-believe-walmart-wants-more-control-over-training-its-truckers">Experts believe Walmart wants more control over training its truckers</h2>







<p data-beyondwords-marker="4fbe9cbf-d502-46a9-b3c2-8066c2d5ed68">From the perspective of these supply chain experts, it doesn’t seem like the associate-to-driver program is necessarily a way to cut costs. Gibson said Walmart has been “very aggressive” in recruiting drivers in recent years. It may have simply tapped out of the current supply of drivers.&nbsp;</p>







<p data-beyondwords-marker="f5602cf6-e924-416a-bf64-22aa95726674">“I think this is just the latest in the evolution of the hiring process for Walmart,” Gibson said. “Going internal has been proven to be a good strategy by other organizations.”</p>







<figure data-beyondwords-marker="fdcbfe2b-2b75-4d65-8069-6c6e5f412b11"><img loading="lazy" decoding="async" width="1600" height="900" src="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1.jpeg" alt="" srcset="https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1.jpeg 1600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1-600x338.jpeg 600w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1-1200x675.jpeg 1200w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1-768x432.jpeg 768w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1-1536x864.jpeg 1536w, https://www.freightwaves.com/wp-content/uploads/2024/01/22/image-1-390x220.jpeg 390w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption><em>Many trucking fleets hire new drivers to save money on wages, but that might not be Walmart’s tactic here. (Photo: Jim Allen/FreightWaves)</em></figcaption></figure>



<p data-beyondwords-marker="c1dadc81-21ba-4303-b85e-24e1d869ccca">What’s more, the associate-to-driver program could be a way to better mold the Walmart truck driver.&nbsp;</p>







<p data-beyondwords-marker="a07f3b08-360e-4b0a-a428-4bc8c3035133">“You take somebody who’s been with another company, they’ve developed habits, they’ve developed styles, they know certain systems –&nbsp; for the good and the bad,” Gibson said. “If they’ve developed any bad habits over time, you can train your new drivers the way you want, the way you need on your systems and try to focus on the skills, capabilities and safety issues that are directly of importance to your organization.”</p>







<p data-beyondwords-marker="c697eaa3-f346-4721-b620-abcf0845497c">Fishman agreed. An associate-turned-driver might not bring years of trucking experience, but they certainly <em>get </em>Walmart.&nbsp;</p>



<p data-beyondwords-marker="1dc91d8d-015c-4350-9f36-501cecfb0607">“It’s possible in this wave of hiring that [outside trucking hires] are diluting this Walmart culture,” Fishman said. “Truck drivers are famously independent.”</p>







<p data-beyondwords-marker="110fadae-784c-4ae5-99ff-204956fa13b9"><em>What do you think of Walmart’s trucking fleet? Email </em><a href="https://www.freightwaves.com/cdn-cgi/l/email-protection#cfbdbfbdaaa2aeaca48fa9bdaaa6a8a7bbb8aeb9aabce1aca0a2"><em><span data-cfemail="f5878587909894969eb59387909c929d818294839086db969a98">[email&nbsp;protected]</span></em></a><em> with your thoughts. And don’t forget to </em><a href="http://freightwaves.com/modes"><em>subscribe to MODES</em></a><em>.&nbsp;</em></p>
			</div>
	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What I talk about when I talk about query optimizer (part 1): IR design (180 pts)]]></title>
            <link>https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/</link>
            <guid>39176797</guid>
            <pubDate>Mon, 29 Jan 2024 14:45:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/">https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/</a>, See on <a href="https://news.ycombinator.com/item?id=39176797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I recently came across an insightful article on SQL Query Optimizers by <a href="https://github.com/leiysky">@leiysky</a> on <a href="https://zhuanlan.zhihu.com/p/680046526">Zhihu</a>, and I must say it was excellent! To make it accessible to a wider audience, I have translated the piece into English. Enjoy reading!</p><p>Please note that <a href="https://github.com/leiysky">@leiysky</a> deserves full credit for the quality of this article. Any mistakes are solely due to my inadequate translation skills.</p><p>Alright, let's begin!</p><hr><p>During our recent conversation, <a href="https://github.com/skyzh">Mr. Chi</a> and I discussed his latest project at CMU called <a href="https://github.com/cmu-db/optd">optd</a>, which is a query optimizer library developed using the Cascades framework. We ended up griping together about various design and implementation aspects of database optimizers. It was at that moment when I realized the intriguing nature of certain technical subjects and decided to take note of them.</p><p>So, I've made the decision to launch a series where we'll cover everything about query optimizers—ranging from algorithm basics to engineering techniques, technological evolution to project implementation, and even some insider industry gossip.</p><p>The inspiration of the title comes from <a href="https://en.wikipedia.org/wiki/What_I_Talk_About_When_I_Talk_About_Running">Haruki Murakami's book</a>, which I highly recommend. The book is a collection of essays that Murakami wrote about his experience as a runner. The title is a reference to a collection of short stories by Raymond Carver, "What We Talk About When We Talk About Love", which Murakami translated into Japanese.</p><p>Software development is a skill just as running is, everyone can do it by practising but not everyone will have the same feelings about it. I'd like to share some personal thoughts and experiences about query optimizers, and I hope that you will find them interesting.</p><p>Today, let's begin by discussing the topic of <strong>IR Design</strong>, focusing on common design patterns in optimizers and the underlying considerations.</p><h2 id="what-is-a-query-optimizer">What is a Query Optimizer?</h2><p>Before we officially start the discussion, I'd like to clarify the definition of a query optimizer.</p><p>In general, a query optimizer is a database component that <strong>optimizes the execution plan of queries</strong>. However, different databases have various methods for optimizing queries. For instance, some may directly rewrite the AST, perform transformations during AST lowering, or dynamically rewrite during query execution.</p><p>To unify the concept, I will refer to all parts from the <em>SQL parser</em> to the <em>SQL Executor</em> collectively as the <strong>Query Optimizer</strong>.</p><h2 id="what-is-ir">What is IR?</h2><p>Friends familiar with compilation technology should be very familiar with the term <code>IR</code>. IR stands for Intermediate Representation, which is commonly used in compilers for different programming languages like Rust's HIR &amp; MIR and LLVM's LLVM IR. IR serves as a structural representation of programming languages, enabling the compiler to conduct various analyses and optimizations more effectively.</p><p>If SQL is considered a programming language, then relational databases function as virtual machines that execute SQL, similar to how the JVM executes Java. The query optimizer is responsible for translating SQL statements (Java code) into execution plans (Java bytecode) for the executor (Java runtime) to execute. Consequently, it is essential to design different IRs for SQL when developing a query optimizer.</p><h2 id="what-does-sql-ir-look-like">What does SQL IR look like?</h2><p>Typical database projects are divided into several modules: Parser, Analyzer/Binder, Optimizer, and Executor. These components process SQL statements sequentially to transform them into query results. In our context, the Optimizer includes both the Analyzer and Optimizer modules mentioned earlier.</p><h3 id="ast">AST</h3><p>SQL is a declarative language that mimics natural language syntax. It is based on <a href="https://en.wikipedia.org/wiki/Relational_algebra">relational algebra</a> and can describe operations on sets, mapping them to queries on tabular data (tables).</p><p>To facilitate processing, like the vast majority of compilers, we will first parse SQL language into an AST (Abstract Syntax Tree). A typical SQL AST is illustrated as follows:</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/ast.png" alt="Query AST"></p><p>In the SQL AST, we generally divide nodes into two types: Statement (Stmt) and Expression (Expr). The root node of each SQL AST is always a Statement, which may contain some Clauses as well as Expressions. An Expression is a recursive structure that includes various operators and function calls, and even nested Statements (Subqueries).</p><p>One interesting aspect of SQL is the blurred boundary between Statements and Expressions in SELECT Statements. This occurs because SELECT Statements are recursive and must address operator precedence issues (UNION/EXCEPT/INTERSECT). Additionally, only SELECT Statements can interact with Expressions recursively, which should be considered when designing an SQL AST.</p><h3 id="relational-algebra">Relational Algebra</h3><p>The theoretical foundation of the SQL language is relational algebra, and every query statement corresponds to a representation in relational algebra. For example:</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/relational_algebra.png" alt="Relational algebra"></p><p>Since the expression of relational algebra is also a recursive tree structure, many systems naturally convert SQL AST into an execution plan similar to the one shown below. We refer to each node as an <strong>operator</strong>, and we call the entire operator tree a <strong>query plan</strong>.</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/algebra_plan.png" alt="Algebra plan"></p><p>Of course, there are exceptions among the many systems. For example, IBM, as a pioneering, introduced the Query Graph Model (QGM) in its Starburst system. This representation is quite abstract and hardcodes many properties into QGM, making it exceptionally difficult to understand. Its claimed extensibility is also questionable.</p><p><em>Due to space limitations, I won't elaborate here; if interested, you can read the related papers <a href="https://dl.acm.org/doi/pdf/10.1145/66926.66962">Extensible Query Processing in Starburst</a> and <a href="https://dl.acm.org/doi/pdf/10.1145/141484.130294">Extensible/Rule Based Query Rewrite Optimization in Starburst</a>.</em></p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/QGM.png" alt="QGM"></p><p>Currently, mainstream databases have essentially adopted the representation of relational algebra (such as IBM's <a href="https://en.wikipedia.org/wiki/IBM_System_R">System R</a> and <a href="https://en.wikipedia.org/wiki/IBM_Db2">DB2</a>, Oracle's various database products, <a href="https://en.wikipedia.org/wiki/Microsoft_SQL_Server">Microsoft's SQL Server</a> series, open-source <a href="https://en.wikipedia.org/wiki/PostgreSQL">PostgreSQL</a> and <a href="https://en.wikipedia.org/wiki/MySQL">MySQL</a> 8.0). Based on this foundation, they have developed numerous optimization frameworks and execution frameworks. Therefore, choosing to use the abstraction of relational algebra when designing SQL IR is a foolproof decision.</p><p>By utilizing the various axioms and theorems of relational algebra, we can perform a variety of transformations on SQL IR to achieve optimization while ensuring correctness. Specific optimization rules and algorithms will be discussed in subsequent articles.</p><h2 id="my-best-engineering-practices">(My) Best Engineering Practices</h2><p>There is a cognitive bias known as <em>the curse of knowledge</em>, which occurs when one assumes that others possess the same level of knowledge during communication.</p><p>This phenomenon is quite common in software development. People who have experience writing certain types of code and those who don't often struggle to communicate effectively, even if they share the same theoretical foundation (algorithms, programming languages, or domain knowledge). The reason for this lies in the significant flexibility of software engineering; there are multiple ways to implement the same functionality, each with its own set of challenges.</p><p>To eliminate such communication barriers, various technical fields have developed their own set of idioms or design patterns. New projects built on these practices can avoid a lot of unnecessary trouble. The same is true for the field of databases; however, due to its niche nature and high degree of commercialization, knowledge circulated among the public is very scarce, and engineering practices are scattered across various open-source projects.</p><p>In this article, I will build a SQL IR from scratch based on my own best practices, which will facilitate the progressive sharing of some design considerations. Due to personal preference, I will use Rust to write code. Friends who are not familiar with Rust need not worry; as long as you have a basic understanding of C/C++, you can comprehend the logic behind Rust's code.</p><h3 id="hello-world">Hello, world!</h3><p>When we learn a new programming language, the first program we generally encounter is "hello world".</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>fn</span> <span>main</span>()<span> </span>{<span>
</span></span></span><span><span><span>    </span>println!(<span>"Hello, world!"</span>);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Therefore, we will also start by building our IR from the SQL version of "hello world".</p><div><pre tabindex="0"><code data-lang="sql"><span><span><span>create</span><span> </span><span>table</span><span> </span>t(a<span> </span><span>int</span>);<span>
</span></span></span><span><span><span></span><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> </span>t;<span>
</span></span></span></code></pre></div><p>Translating this SQL statement into relational algebra is very straightforward; we denote it as <code>Get(t)</code>, which means to return all the data in set <code>t</code>. To represent such a query, we can define a simple struct called <code>Get</code>.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>struct</span> <span>Get</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>table: <span>String</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>plan</span>()<span> </span>-&gt; <span>Get</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>// select * from t;
</span></span></span><span><span><span></span><span>    </span>Get<span> </span>{<span>
</span></span></span><span><span><span>        </span>table: <span>"t"</span>.to_string(),<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>This simple SQL IR is now complete. With the <code>Get</code>, we can represent all queries similar to <code>select * from xxx</code>. Isn't it very straightforward?</p><h3 id="select--project">Select &amp; Project</h3><p>Next, we can add more features to this IR, supporting additional SQL clauses. For example:</p><div><pre tabindex="0"><code data-lang="sql"><span><span><span>create</span><span> </span><span>table</span><span> </span>t(a<span> </span><span>int</span>,<span> </span>b<span> </span><span>int</span>);<span>
</span></span></span><span><span><span></span><span>select</span><span> </span>a<span> </span><span>from</span><span> </span>t<span> </span><span>where</span><span> </span>a<span> </span><span>=</span><span> </span><span>1</span>;<span>
</span></span></span></code></pre></div><p>This SQL query, when translated into relational algebra, can be denoted as <code>Project(Select(Get(t), a = 1), a)</code>. The <code>Select</code> operator can filter data based on the provided predicate, while the <code>Project</code> operator can trim the set to obtain the required attribute. To represent such a query, we need to add more struct definitions.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>struct</span> <span>Get</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>table: <span>String</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>Select</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>get: <span>Get</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>predicate: <span>String</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>Project</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>select: <span>Select</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>project: <span>String</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>plan</span>()<span> </span>-&gt; <span>Project</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>// select a from t where a = 1;
</span></span></span><span><span><span></span><span>    </span>Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>select: <span>Select</span><span> </span>{<span>
</span></span></span><span><span><span>            </span>get: <span>Get</span><span> </span>{<span>
</span></span></span><span><span><span>                </span>table: <span>"t"</span>.to_string(),<span>
</span></span></span><span><span><span>            </span>},<span>
</span></span></span><span><span><span>            </span>predicate: <span>"a = 1"</span>.to_string(),<span>
</span></span></span><span><span><span>        </span>},<span>
</span></span></span><span><span><span>        </span>project: <span>"a"</span>.to_string(),<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Upon arriving here, we are confronted with several questions: According to the theorem of relational algebra, can <code>Project</code> act as a child of <code>Select</code>? Given that Select is optional for an SQL query, how should this be reflected in the code?</p><p>To address these issues, we can introduce some features of dynamic dispatch. In C++/Java, inheritance is commonly used to represent an <code>Operator</code>, for example:</p><div><pre tabindex="0"><code data-lang="cpp"><span><span><span>class</span> <span>Operator</span> {};
</span></span><span><span><span>class</span> <span>Get</span> <span>:</span> <span>public</span> Operator {};
</span></span><span><span><span>class</span> <span>Select</span> <span>:</span> <span>public</span> Operator {
</span></span><span><span>    Operator<span>*</span> _child;
</span></span><span><span>};
</span></span><span><span><span>class</span> <span>Project</span> <span>:</span> <span>public</span> Operator {
</span></span><span><span>    Operator<span>*</span> _child;
</span></span><span><span>};
</span></span></code></pre></div><p>In Rust, we have a more convenient option that allows us to enjoy the benefits of both static typing and dynamic dispatch, which is <code>enum</code>. Rust's enum is an ADT (Algebraic Data Type), also known as tagged union, and it can represent our operators very conveniently:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Get<span> </span>{<span>
</span></span></span><span><span><span>        </span>table: <span>String</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Select<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>predicate: <span>String</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>projects: <span>String</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>plan</span>()<span> </span>-&gt; <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>// select a from t where a = 1;
</span></span></span><span><span><span></span><span>    </span>Operator::Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span>::new(Operator::Select<span> </span>{<span>
</span></span></span><span><span><span>            </span>child: <span>Box</span>::new(Operator::Get<span> </span>{<span>
</span></span></span><span><span><span>                </span>table: <span>"t"</span>.to_string(),<span>
</span></span></span><span><span><span>            </span>}),<span>
</span></span></span><span><span><span>            </span>predicate: <span>"a = 1"</span>.to_string(),<span>
</span></span></span><span><span><span>        </span>}),<span>
</span></span></span><span><span><span>        </span>project: <span>"a"</span>.to_string(),<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>With this, we can freely represent operator trees of various shapes, and the design of the IR begins to get on the right track.</p><h3 id="scalar-expression">Scalar expression</h3><p>Although we have introduced the operators <code>Select</code> and <code>Project</code>, the <code>Select Predicate</code> and <code>Project Expression</code> still exist in the form of strings, which cannot meet the requirements for analysis and optimization. Therefore, we need to design an IR for these expressions as well.</p><p>Looking back, after being processed by the Parser, SQL strings are transformed into AST, and the expressions within them become Expr nodes, roughly like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>Expr</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>ColumnRef(ColumnRef),<span>
</span></span></span><span><span><span>    </span>Literal(Literal),<span>
</span></span></span><span><span><span>    </span>Function(Function),<span>
</span></span></span><span><span><span>    </span>BinaryOp(BinaryOp),<span>
</span></span></span><span><span><span>    </span>UnaryOp(UnaryOp),<span>
</span></span></span><span><span><span>    </span>Subquery(SelectStmt),<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>The expression itself is a recursive structure, and the <code>Expr</code> node of AST is also a recursive structure. Can we lazily use the <code>Expr</code> node directly as part of our SQL IR? Let's give it a try first.</p><p>After replacing string with <code>Expr</code>, we can obtain:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Get<span> </span>{<span>
</span></span></span><span><span><span>        </span>table: <span>String</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Select<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>predicate: <span>Expr</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>projects: <span>Vec</span><span>&lt;</span>Expr<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Next, let's try some common analysis using the given SQL statement to see if it works well:</p><div><pre tabindex="0"><code data-lang="sql"><span><span><span>select</span><span> </span>a<span> </span><span>from</span><span> </span>t<span>
</span></span></span><span><span><span></span><span>where</span><span> </span><span>exists</span><span> </span>(<span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> </span>t1<span> </span><span>where</span><span> </span>t.a<span> </span><span>=</span><span> </span>t1.a)<span>
</span></span></span></code></pre></div><ol><li>Q: Which tables and columns does <code>Expr</code> in <code>Project</code> depend on? A: It uses a column called <code>a</code>, but I don't know which table it belongs to, maybe this column doesn't even exist.</li><li>Q: What is the return type of <code>Expr</code> in <code>Project</code>? A: I don't know, there is no type information included in <code>Expr</code>.</li><li>Q: Is the subquery in <code>Select</code> a <a href="https://en.wikipedia.org/wiki/Correlated_subquery">correlated subquery</a>? A: I don't know, the subquery in <code>Expr</code> is just an unprocessed AST.</li></ol><p>Ok, it seems that <code>Expr</code> is not as useful as we imagined. In order to conduct the above analysis, we need to design a more informative IR. To distinguish it from <code>Expr</code>, we will name it <code>ScalarExpr</code>.</p><p>Summarizing the above analysis, our requirements for ScalarExpr are as follows:</p><ol><li>All identifiers must be resolved to fully qualified names.</li><li>Type information needs to be injected and undergo type check.</li><li>All subqueries need to be transformed into SQL IR form.</li></ol><p>Combining the above requirements, along with some desugar, <code>ScalarExpr</code> would look something like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>ScalarExpr</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>ColumnRef(<span>Vec</span><span>&lt;</span>Identifier<span>&gt;</span>,<span> </span>Type),<span>
</span></span></span><span><span><span>    </span>Literal(Value,<span> </span>Type),<span>
</span></span></span><span><span><span>    </span>Function(Signature,<span> </span><span>Vec</span><span>&lt;</span>Self<span>&gt;</span>),<span>
</span></span></span><span><span><span>    </span>Subquery(Quantifier,<span> </span><span>Box</span><span>&lt;</span>Operator<span>&gt;</span>),<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>In this way, the design of the expression's IR is also formed. Let's integrate the entire set of SQL IR together.</p><h3 id="the-ir">The IR</h3><p>After the above design, we have:</p><ul><li><code>Operator</code>, a tree structure capable of flexibly expressing various SQL queries.</li><li><code>ScalarExpr</code>, providing rich semantic information.</li></ul><p>Although some key operators are still missing, such as <code>Join</code>, <code>Union</code>, <code>Aggregate</code>, etc. However, since the overall framework is already very clear, we can follow the same pattern and add them as well.</p><p>After integration, we have a fairly perfect SQL IR.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>ScalarExpr</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>ColumnRef(<span>Vec</span><span>&lt;</span>Identifier<span>&gt;</span>,<span> </span>Type),<span>
</span></span></span><span><span><span>    </span>Literal(Value,<span> </span>Type),<span>
</span></span></span><span><span><span>    </span>Function(Signature,<span> </span><span>Vec</span><span>&lt;</span>Self<span>&gt;</span>),<span>
</span></span></span><span><span><span>    </span>Subquery(Quantifier,<span> </span><span>Box</span><span>&lt;</span>Operator<span>&gt;</span>),<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>enum</span> <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Get<span> </span>{<span>
</span></span></span><span><span><span>        </span>table: <span>String</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Select<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>predicate: <span>ScalarExpr</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>projects: <span>Vec</span><span>&lt;</span>ScalarExpr<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Join<span> </span>{<span>
</span></span></span><span><span><span>        </span>kind: <span>JoinKind</span>,<span>
</span></span></span><span><span><span>        </span>condition: <span>ScalarExpr</span>,<span>
</span></span></span><span><span><span>        </span>left: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>right: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>UnionAll<span> </span>{<span>
</span></span></span><span><span><span>        </span>left: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>right: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Aggregate<span> </span>{<span>
</span></span></span><span><span><span>        </span>group_by: <span>Vec</span><span>&lt;</span>ScalarExpr<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>aggr_exprs: <span>Vec</span><span>&lt;</span>ScalarExpr<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Because it is too perfect, I have decided to give this IR an imposing name - <code>The IR</code>.</p><h3 id="property-derivation">Property Derivation</h3><p>When we want to analyze and optimize IR, we always need to obtain some properties of the IR. We can calculate these properties by writing an analyzer that traverses the entire IR, but this requires a lot of effort to maintain the state of the context in which the IR is located.</p><p>Fortunately, SQL as a declarative query language for data flow is quite simple, and we can use its features to calculate properties.</p><p>The data flow and parent-child relationships between operators in <code>The IR</code> are closely related and presented as a DAG (directed acyclic graph), where all data flows from child nodes to parent nodes.</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/DAG.png" alt="Untitled"></p><p>Under this characteristic, it is simple to compute the property of a certain IR node. It only requires recursively computing the property of each child node and then calculating its own property based on these properties. We refer to this process as <code>property derivation</code>.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>struct</span> <span>Property</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>derive_property</span>(op: <span>&amp;</span><span>Operator</span>)<span> </span>-&gt; <span>Property</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>// Calculate the properties of the children operators.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span>children_property: <span>Vec</span><span>&lt;</span>Property<span>&gt;</span><span> </span><span>=</span><span> </span>op<span>
</span></span></span><span><span><span>        </span>.children()<span>
</span></span></span><span><span><span>        </span>.map(derive_property)<span>
</span></span></span><span><span><span>        </span>.collect();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Calculate property with the children properties.
</span></span></span><span><span><span></span><span>    </span>op.calculate_property(<span>&amp;</span>children_property)<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>In SQL optimization, commonly used properties can be divided into two categories: <code>relational/logical properties</code> that describe the characteristics of a data set and <code>physical properties</code> that describe the physical characteristics of the data.</p><p>Common relational properties include:</p><ul><li>Information about the <code>attributes/columns</code> contained in the dataset</li><li><code>Cardinality</code> of the dataset, indicating the number of records in the dataset</li><li><code>Statistics</code>, representing the data distribution of attributes</li><li><code>Constraints</code>, representing constraints on attributes, such as <code>NOT NULL</code></li><li><code>Functional dependency</code>, indicating the functional dependency relationship between attributes</li></ul><p>Common physical properties include:</p><ul><li>Order</li><li>Degree of parallelism (DOP)</li><li>Data distribution</li><li>Data partition</li></ul><p>Combining the properties of relational algebra, we can describe the differences between types of properties.</p><p>Assuming there are relations <code>R</code> and <code>S</code>: the relational property of <code>R</code> is <code>RP_R</code>, and the physical property is <code>PP_R</code>; the relational property of <code>S</code> is <code>RP_S</code>, and the physical property is <code>PP_S</code>.</p><p>We can obtain:</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/property.svg" alt=""></p><p>It is not difficult to see that the equivalence relationship between two relations can determine the equivalence relationship of relational properties, but the equivalence relationship of physical properties is not affected by the equivalence relationship of relations.</p><p><em>The content about combining properties with specific query optimization algorithms will be discussed in detail in subsequent articles.</em></p><p>With property derivation, we can use theorems from relational algebra to optimize <code>The IR</code> while ensuring correctness.</p><p>So the next question is, what should the property look like?</p><h3 id="relational-properties">Relational properties</h3><p>The most important part of relational property is the representation of attributes. In naive relational algebra, each relation is composed of sets of tuples, and each attribute in a tuple has its own unique name. It is natural for us to directly consider using the tuple schema as the representation of attributes.</p><p>Let's first recall how a table is created.</p><p>In SQL, we use DDL (Data Definition Language) to create and manage various tables. When creating a table, we need to specify its table schema, which includes the specific definition of each column in the table, corresponding to attributes in relational algebra. The structure of the table schema might look something like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>struct</span> <span>TableSchema</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>name: <span>String</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>columns: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>ColumnDefinition</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>name: <span>String</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>column_type: <span>Type</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>not_null: <span>bool</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Since <code>ColumnDefinition</code> and attribute have a one-to-one correspondence, can we directly use <code>ColumnDefinition</code> to represent the property of attribute?</p><p>We can try adding support for attributes in <code>The IR</code> first.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>fn</span> <span>derive_attributes</span>(op: <span>&amp;</span><span>Operator</span>)<span> </span>-&gt; <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>// Calculate the attributes of the children operators.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span>children_attributes: <span>Vec</span><span>&lt;</span><span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;&gt;</span><span> </span><span>=</span><span>
</span></span></span><span><span><span>        </span>op.children().iter().map(derive_attributes).collect();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Calculate attributes with the children attributes.
</span></span></span><span><span><span></span><span>    </span>op.calculate_attributes(<span>&amp;</span>children_attributes)<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>First, we need to make some modifications to <code>The IR</code> and add table schema information for the <code>Get</code> operator.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Get<span> </span>{<span>
</span></span></span><span><span><span>        </span>table: <span>String</span>,<span>
</span></span></span><span><span><span>        </span>schema: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span><span>// Nothing changed for other variants
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Then we implement <code>attribute derivation</code> for the <code>Operator</code>.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>impl</span><span> </span>Operator<span> </span>{<span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>calculate_attributes</span>(<span>&amp;</span>self,<span> </span>children: <span>&amp;</span>[<span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span>])<span> </span>-&gt; <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>match</span><span> </span>self<span> </span>{<span>
</span></span></span><span><span><span>            </span>Operator::Get<span> </span>{<span> </span>schema,<span> </span><span>..</span><span> </span>}<span> </span><span>=&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>                </span><span>let</span><span> </span>attributes<span> </span><span>=</span><span> </span>schema.clone();<span>
</span></span></span><span><span><span>                </span>attributes<span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>            </span>Operator::Select<span> </span>{<span> </span><span>..</span><span> </span>}<span> </span><span>=&gt;</span><span> </span>children[<span>0</span>].clone(),<span>
</span></span></span><span><span><span>            </span>Operator::Join<span> </span>{<span> </span><span>..</span><span> </span>}<span> </span><span>=&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>                </span><span>let</span><span> </span><span>mut</span><span> </span>attributes<span> </span><span>=</span><span> </span>children[<span>0</span>].clone();<span>
</span></span></span><span><span><span>                </span>attributes.extend(children[<span>1</span>].clone());<span>
</span></span></span><span><span><span>                </span>attributes<span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>            </span>Operator::UnionAll<span> </span>{<span> </span><span>..</span><span> </span>}<span> </span><span>=&gt;</span><span> </span>children[<span>0</span>].clone(),<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span>Operator::Project<span> </span>{<span> </span><span>..</span><span> </span>}<span> </span><span>=&gt;</span><span> </span>todo!(),<span>
</span></span></span><span><span><span>            </span>Operator::Aggregate<span> </span>{<span> </span><span>..</span><span> </span>}<span> </span><span>=&gt;</span><span> </span>todo!(),<span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Most of the operator implementations went smoothly, but it can be seen that <code>Project</code> and <code>Aggregate</code> have been marked as todo. At this point, we will find that <code>Project</code> and <code>Aggregate</code> cannot directly generate their own attributes using <code>children attributes</code>.</p><p>Going back to relational algebra, the purpose of <code>Project</code> is to trim the shape of tuples or modify the name of attributes. This kind of SQL expression like <code>SELECT a + 1 AS b FROM t</code> cannot be expressed as a naive <code>Project</code>; as for <code>Aggregate</code>, it is not even present in basic relational algebra, it is an extension to relational algebra.</p><p>The theory of relational algebra no longer exists!</p><p>However, despite this, the project still needs to continue. We need to introduce some <em>village rules</em> to expand the definition of relational algebra. Here we provide the formal definitions of <code>Project</code> and <code>Aggregate</code> in <code>The IR</code>.</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/project.svg" alt=""></p><p><code>Project</code> represents the attributes in relationship <code>R</code> as input, output a tuple consisting of <code>n</code> function mappings <code>f_1</code> to <code>f_n</code>.</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/aggregate.svg" alt=""></p><p><code>Aggregate</code> represents grouping the tuples in relationship <code>R</code> according to <code>m</code> attributes <code>k_1</code> to <code>k_m</code>, and applying <code>n</code> function mappings <code>f_1</code> to <code>f_n</code> on each group, finally outputting the grouped tuples.</p><p>The biggest change in this <em>village rule</em> is the introduction of <code>derived columns</code>. For columns directly from tables in SQL, we call them <code>base table columns</code>; for columns calculated through <code>Project</code>/<code>Aggregate</code>, we call them <code>derived columns</code>.</p><p>Before introducing the concept of <code>derived columns</code>, we could ensure that all data sources would ultimately point to the <code>Get</code> operator. However, after its introduction, this convention was broken and a concept similar to <code>scope</code> in programming languages emerged. We need to be more careful when optimizing.</p><p>After having <em>village rule</em>, we can also achieve <code>attribute derivation</code> for <code>Project</code> and <code>Aggregate</code>. However, at the same time, we also need to make some modifications to the structure of <code>The IR</code>.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>projects: <span>Vec</span><span>&lt;</span>(ScalarExpr,<span> </span><span>String</span>)<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span><span>// Others
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span>Operator<span> </span>{<span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>calculate_attributes</span>(<span>&amp;</span>self,<span> </span>children: <span>&amp;</span>[<span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span>])<span> </span>-&gt; <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>match</span><span> </span>self<span> </span>{<span>
</span></span></span><span><span><span>            </span>Operator::Project<span> </span>{<span> </span>projects,<span> </span><span>..</span><span> </span>}<span> </span><span>=&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>                </span><span>let</span><span> </span>attributes: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span><span>=</span><span> </span>projects<span>
</span></span></span><span><span><span>                    </span>.iter()<span>
</span></span></span><span><span><span>                    </span>.map(<span>|</span>(expr,<span> </span>alias)<span>|</span><span> </span>ColumnDefinition<span> </span>{<span>
</span></span></span><span><span><span>                        </span>name: <span>alias</span>.clone(),<span>
</span></span></span><span><span><span>                        </span>column_type: <span>expr</span>.column_type(),<span>
</span></span></span><span><span><span>                        </span>not_null: <span>expr</span>.nullable(),<span>
</span></span></span><span><span><span>                    </span>})<span>
</span></span></span><span><span><span>                    </span>.collect();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>                </span>attributes<span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>            </span>Operator::Aggregate<span> </span>{<span>
</span></span></span><span><span><span>                </span>group_by,<span>
</span></span></span><span><span><span>                </span>aggr_exprs,<span>
</span></span></span><span><span><span>                </span><span>..</span><span>
</span></span></span><span><span><span>            </span>}<span> </span><span>=&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>                </span><span>let</span><span> </span><span>mut</span><span> </span>attributes: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span><span>=</span><span> </span>group_by<span>
</span></span></span><span><span><span>                    </span>.iter()<span>
</span></span></span><span><span><span>                    </span>.map(<span>|</span>expr<span>|</span><span> </span>ColumnDefinition<span> </span>{<span>
</span></span></span><span><span><span>                        </span>name: <span>expr</span>.name(),<span>
</span></span></span><span><span><span>                        </span>column_type: <span>expr</span>.column_type(),<span>
</span></span></span><span><span><span>                        </span>not_null: <span>expr</span>.nullable(),<span>
</span></span></span><span><span><span>                    </span>})<span>
</span></span></span><span><span><span>                    </span>.collect();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>                </span>attributes.extend(aggr_exprs.iter().map(<span>|</span>expr<span>|</span><span> </span>ColumnDefinition<span> </span>{<span>
</span></span></span><span><span><span>                    </span>name: <span>expr</span>.name(),<span>
</span></span></span><span><span><span>                    </span>column_type: <span>expr</span>.column_type(),<span>
</span></span></span><span><span><span>                    </span>not_null: <span>expr</span>.nullable(),<span>
</span></span></span><span><span><span>                </span>}));<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>                </span>attributes<span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>            </span><span>// Others
</span></span></span><span><span><span></span><span>        </span>}<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>In this way, we can calculate the attributes property for all operators. Come and try it out!</p><p>First, let's take a look at the most common and effective optimization in SQL - <code>predicate pushdown</code>. This optimization can reduce the computational workload of other operators by pushing down the <code>Select</code> operator into other operators, while ensuring that the overall query result remains unchanged. It is very concise and elegant.</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/select_push_down_project.png" alt="Select push down"></p><p>Let's try to implement this optimization on <code>The IR</code>. The idea is very simple, just swap the positions of <code>Select</code> and <code>Project</code> based on the relational algebra theorem. However, since we introduced derived columns, we must check if the predicate in <code>Select</code> depends on the column generated by <code>Project</code>.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>fn</span> <span>push_down_select_project</span>(op: <span>&amp;</span><span>Operator</span>)<span> </span>-&gt; <span>Option</span><span>&lt;</span>Operator<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span>op<span> </span>{<span>
</span></span></span><span><span><span>        </span>Operator::Select<span> </span>{<span>
</span></span></span><span><span><span>            </span>child: <span>project</span><span> </span><span>@</span><span> </span><span>box</span><span> </span>Operator::Project<span> </span>{<span> </span>child,<span> </span>projects<span> </span>},<span>
</span></span></span><span><span><span>            </span>predicate,<span>
</span></span></span><span><span><span>        </span>}<span> </span><span>=&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>            </span><span>let</span><span> </span>project_attributes: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span><span>=</span><span> </span>derive_attributes(<span>&amp;</span>project);<span>
</span></span></span><span><span><span>            </span><span>let</span><span> </span>predicate_used_columns: <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span> </span><span>=</span><span> </span>predicate.used_columns();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>// Check if the predicate uses any column from the project.
</span></span></span><span><span><span></span><span>            </span><span>let</span><span> </span>used_derived_columns<span> </span><span>=</span><span> </span>predicate_used_columns.iter().any(<span>|</span>used_column<span>|</span><span> </span>{<span>
</span></span></span><span><span><span>                </span>project_attributes<span>
</span></span></span><span><span><span>                    </span>.iter()<span>
</span></span></span><span><span><span>                    </span>.any(<span>|</span>attr<span>|</span><span> </span>attr.name<span> </span><span>==</span><span> </span><span>*</span>used_column)<span>
</span></span></span><span><span><span>            </span>});<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>if</span><span> </span>used_derived_columns<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>None</span><span>
</span></span></span><span><span><span>            </span>}<span> </span><span>else</span><span> </span>{<span>
</span></span></span><span><span><span>                </span><span>Some</span>(Operator::Project<span> </span>{<span>
</span></span></span><span><span><span>                    </span>child: <span>Box</span>::new(Operator::Select<span> </span>{<span>
</span></span></span><span><span><span>                        </span>child: <span>child</span>.clone(),<span>
</span></span></span><span><span><span>                        </span>predicate: <span>predicate</span>.clone(),<span>
</span></span></span><span><span><span>                    </span>}),<span>
</span></span></span><span><span><span>                    </span>projects: <span>projects</span>.clone(),<span>
</span></span></span><span><span><span>                </span>})<span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>        </span>_<span> </span><span>=&gt;</span><span> </span><span>None</span>,<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>It seems to be basically usable now, which is delightful. Let's try a more complex example, such as trying SQL with <code>Join</code>:</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/select_push_down_join.png" alt="Select push down"></p><p>Because <code>Join</code> does not generate additional <code>derived columns</code> like <code>Project</code>, the logic for checking will be relatively simpler. Let's first implement an optimization that attempts to push <code>Select</code> down to the left child of <code>Join</code>:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>fn</span> <span>push_down_select_join_left</span>(op: <span>&amp;</span><span>Operator</span>)<span> </span>-&gt; <span>Option</span><span>&lt;</span>Operator<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span>op<span> </span>{<span>
</span></span></span><span><span><span>        </span>Operator::Select<span> </span>{<span>
</span></span></span><span><span><span>            </span>child: <span>join</span><span> </span><span>@</span><span> </span><span>box</span><span> </span>Operator::Join<span> </span>{<span> </span>left,<span> </span>right,<span> </span><span>..</span><span> </span>},<span>
</span></span></span><span><span><span>            </span>predicate,<span>
</span></span></span><span><span><span>        </span>}<span> </span><span>=&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>            </span><span>let</span><span> </span>left_attributes: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span><span>=</span><span> </span>derive_attributes(<span>&amp;</span>left);<span>
</span></span></span><span><span><span>            </span><span>let</span><span> </span>predicate_used_columns: <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span> </span><span>=</span><span> </span>predicate.used_columns();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>// Check if the predicate only uses column from left.
</span></span></span><span><span><span></span><span>            </span><span>let</span><span> </span>only_left<span> </span><span>=</span><span> </span>predicate_used_columns<span>
</span></span></span><span><span><span>                </span>.iter()<span>
</span></span></span><span><span><span>                </span>.all(<span>|</span>used_column<span>|</span><span> </span>left_attributes.iter().any(<span>|</span>attr<span>|</span><span> </span>attr.name<span> </span><span>==</span><span> </span><span>*</span>used_column));<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>if</span><span> </span>only_left<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>Some</span>(Operator::Join<span> </span>{<span>
</span></span></span><span><span><span>                    </span>left: <span>Box</span>::new(Operator::Select<span> </span>{<span>
</span></span></span><span><span><span>                        </span>child: <span>left</span>.clone(),<span>
</span></span></span><span><span><span>                        </span>predicate: <span>predicate</span>.clone(),<span>
</span></span></span><span><span><span>                    </span>}),<span>
</span></span></span><span><span><span>                    </span>right: <span>right</span>.clone(),<span>
</span></span></span><span><span><span>                    </span><span>..</span>join.clone()<span>
</span></span></span><span><span><span>                </span>})<span>
</span></span></span><span><span><span>            </span>}<span> </span><span>else</span><span> </span>{<span>
</span></span></span><span><span><span>                </span><span>None</span><span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>        </span>_<span> </span><span>=&gt;</span><span> </span><span>None</span>,<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>Everything looks great, but the devil often hides in the details. Let's take a look at the output of this example in <code>PostgreSQL</code>:</p><div><pre tabindex="0"><code data-lang="fallback"><span><span>leiysky=# create table t(a int);
</span></span><span><span>CREATE TABLE
</span></span><span><span>leiysky=# create table t1(a int);
</span></span><span><span>CREATE TABLE
</span></span><span><span>leiysky=# insert into t values(1);
</span></span><span><span>INSERT 0 1
</span></span><span><span>leiysky=# insert into t1 values(1);
</span></span><span><span>INSERT 0 1
</span></span><span><span>leiysky=# select * from t, t1 where t.a = 1;
</span></span><span><span> a | a
</span></span><span><span>---+---
</span></span><span><span> 1 | 1
</span></span><span><span>(1 row)
</span></span></code></pre></div><p>The final result returned has two attributes called <code>a</code>. In the current implementation of <code>The IR</code>, we cannot know which side this <code>Select</code> should be pushed down to. Because when we check which side the predicate that depends on <code>a</code> can be pushed down to, we will find that both sides of the <code>Join</code> can satisfy it. Although it is not allowed to have multiple columns with the same name in the same table, there is no such restriction between different tables.</p><p>As the open-source database product with the highest support for ANSI SQL, PostgreSQL naturally handles this kind of problem very well. Through the <code>EXPLAIN</code> statement, we can see that it pushes down the <code>Select</code> to the correct place.</p><div><pre tabindex="0"><code data-lang="fallback"><span><span>leiysky=# explain(verbose) select * from t, t1 where t.a = 1;
</span></span><span><span>                              QUERY PLAN
</span></span><span><span>----------------------------------------------------------------------
</span></span><span><span> Nested Loop  (cost=0.00..491.78 rows=33150 width=8)
</span></span><span><span>   Output: t.a, t1.a
</span></span><span><span>   -&gt;  Seq Scan on public.t1  (cost=0.00..35.50 rows=2550 width=4)
</span></span><span><span>         Output: t1.a
</span></span><span><span>   -&gt;  Materialize  (cost=0.00..41.94 rows=13 width=4)
</span></span><span><span>         Output: t.a
</span></span><span><span>         -&gt;  Seq Scan on public.t  (cost=0.00..41.88 rows=13 width=4)
</span></span><span><span>               Output: t.a
</span></span><span><span>               Filter: (t.a = 1)
</span></span><span><span>(9 rows)
</span></span></code></pre></div><p>As a perfect SQL IR, <code>The IR</code> must also have its own solution. If we carefully observe this query, we will find that the predicate of <code>Select</code> is represented by a qualified name. If an unqualified name is used, PostgreSQL will throw such an error:</p><div><pre tabindex="0"><code data-lang="fallback"><span><span>leiysky=# select * from t, t1 where a = 1;
</span></span><span><span>ERROR:  column reference "a" is ambiguous
</span></span><span><span>LINE 1: select * from t, t1 where a = 1;
</span></span></code></pre></div><p>Because in the current context, <code>a</code> is ambiguous, but <code>t.a</code> is not. Let's try using qualified name to represent attribute property to solve this problem. For this purpose, we need to make some code changes.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>struct</span> <span>QualifiedName</span>(<span>pub</span><span> </span><span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span>);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span>QualifiedName<span> </span>{<span>
</span></span></span><span><span><span>    </span><span>/// If the current name can be used to refer another name
</span></span></span><span><span><span></span><span>    </span><span>pub</span><span> </span><span>fn</span> <span>can_refer</span>(<span>&amp;</span>self,<span> </span>other: <span>&amp;</span><span>Self</span>)<span> </span>-&gt; <span>bool</span> {<span>
</span></span></span><span><span><span>        </span>self.<span>0.</span>len()<span> </span><span>&lt;=</span><span> </span>other.<span>0.</span>len()<span> 
</span></span></span><span><span><span>          </span><span>&amp;&amp;</span><span> </span>self.<span>0.</span>iter().zip(other.<span>0.</span>iter()).all(<span>|</span>(a,<span> </span>b)<span>|</span><span> </span>a<span> </span><span>==</span><span> </span>b)<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>ColumnDefinition</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>/// Use qualified name
</span></span></span><span><span><span></span><span>    </span><span>pub</span><span> </span>name: <span>QualifiedName</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>column_type: <span>Type</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>not_null: <span>bool</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>resolve_attribute</span>(<span>
</span></span></span><span><span><span>    </span>attributes: <span>&amp;</span>[ColumnDefinition],<span>
</span></span></span><span><span><span>    </span>name: <span>&amp;</span><span>QualifiedName</span>,<span>
</span></span></span><span><span><span></span>)<span> </span>-&gt; <span>Option</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span>candidates: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span><span>=</span><span> </span>attributes<span>
</span></span></span><span><span><span>        </span>.iter()<span>
</span></span></span><span><span><span>        </span>.filter(<span>|</span>attr<span>|</span><span> </span>attr.name.can_refer(name))<span>
</span></span></span><span><span><span>        </span>.collect();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>if</span><span> </span>candidates.len()<span> </span><span>==</span><span> </span><span>1</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>Some</span>(candidates[<span>0</span>].clone())<span>
</span></span></span><span><span><span>    </span>}<span> </span><span>else</span><span> </span><span>if</span><span> </span>candidates.len()<span> </span><span>&gt;</span><span> </span><span>1</span><span> </span>{<span>
</span></span></span><span><span><span>        </span>panic!(<span>"Watch out, ambiguous reference found!"</span>)<span>
</span></span></span><span><span><span>    </span>}<span>else</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>None</span><span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>push_down_select_join_left</span>(op: <span>&amp;</span><span>Operator</span>)<span> </span>-&gt; <span>Option</span><span>&lt;</span>Operator<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>match</span><span> </span>op<span> </span>{<span>
</span></span></span><span><span><span>        </span>Operator::Select<span> </span>{<span>
</span></span></span><span><span><span>            </span>child: <span>join</span><span> </span><span>@</span><span> </span><span>box</span><span> </span>Operator::Join<span> </span>{<span> </span>left,<span> </span>right,<span> </span><span>..</span><span> </span>},<span>
</span></span></span><span><span><span>            </span>predicate,<span>
</span></span></span><span><span><span>        </span>}<span> </span><span>=&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>            </span><span>let</span><span> </span>left_attributes: <span>Vec</span><span>&lt;</span>ColumnDefinition<span>&gt;</span><span> </span><span>=</span><span> </span>derive_attributes(<span>&amp;</span>left);<span>
</span></span></span><span><span><span>            </span><span>let</span><span> </span>predicate_used_columns: <span>Vec</span><span>&lt;</span>QualifiedName<span>&gt;</span><span> </span><span>=</span><span> </span>predicate.used_columns();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>// Check if the predicate only uses column from left.
</span></span></span><span><span><span></span><span>            </span><span>let</span><span> </span>only_left<span> </span><span>=</span><span> </span>predicate_used_columns<span>
</span></span></span><span><span><span>                </span>.iter()<span>
</span></span></span><span><span><span>                </span>.all(<span>|</span>used_column<span>|</span><span> </span>resolve_attribute(<span>&amp;</span>left_attributes,<span> </span>used_column).is_some());<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>if</span><span> </span>only_left<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>Some</span>(Operator::Join<span> </span>{<span>
</span></span></span><span><span><span>                    </span>left: <span>Box</span>::new(Operator::Select<span> </span>{<span>
</span></span></span><span><span><span>                        </span>child: <span>left</span>.clone(),<span>
</span></span></span><span><span><span>                        </span>predicate: <span>predicate</span>.clone(),<span>
</span></span></span><span><span><span>                    </span>}),<span>
</span></span></span><span><span><span>                    </span>right: <span>right</span>.clone(),<span>
</span></span></span><span><span><span>                    </span><span>..</span>join.clone()<span>
</span></span></span><span><span><span>                </span>})<span>
</span></span></span><span><span><span>            </span>}<span> </span><span>else</span><span> </span>{<span>
</span></span></span><span><span><span>                </span><span>None</span><span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>        </span>_<span> </span><span>=&gt;</span><span> </span><span>None</span>,<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>In this way, the above problem is solved, and we have the ability to handle complex attribute references. However, there is still a long way to go before achieving a perfect solution. Let's take another example:</p><div><pre tabindex="0"><code data-lang="fallback"><span><span>leiysky=# select * from (select * from t1) as t, t1 where t.a = 1;
</span></span><span><span> a | a
</span></span><span><span>---+---
</span></span><span><span> 1 | 1
</span></span><span><span>(1 row)
</span></span></code></pre></div><p>Although SQL does not allow the use of multiple identical table names in the same <code>FROM</code> clause, we can bypass this by using an <code>inlined view</code> or <code>CTE</code>. According to our current implementation, when processing <code>t.a = 1</code>, we have two <code>t1.a</code> attributes instead of <code>t.a</code> because we did not handle the alias of the inlined view. Therefore, we need to add a <code>Project</code> specifically for renaming attributes.</p><p>So the problem arises again, because we only renamed some columns and treated them as derived columns, which added a lot of burden to our Select pushdown. Therefore, we must modify the definition of <code>The IR</code> and various related codes to serve the mapping of names.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>enum</span> <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span><span>// (Expression, Source name, Alias)
</span></span></span><span><span><span></span><span>        </span>projects: <span>Vec</span><span>&lt;</span>(ScalarExpr,<span> </span>QualifiedName,<span> </span>QualifiedName)<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span><span>// Others
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>These problems can be solved by writing a little more code, but take a look at the next example. I believe that most people will go crazy just like me:</p><div><pre tabindex="0"><code data-lang="fallback"><span><span>leiysky=# select a from t natural join t1;
</span></span><span><span> a
</span></span><span><span>---
</span></span><span><span> 1
</span></span><span><span>(1 row)
</span></span><span><span>
</span></span><span><span>leiysky=# select t.a from t natural join t1;
</span></span><span><span> a
</span></span><span><span>---
</span></span><span><span> 1
</span></span><span><span>(1 row)
</span></span><span><span>
</span></span><span><span>leiysky=# select t1.a from t natural join t1;
</span></span><span><span> a
</span></span><span><span>---
</span></span><span><span> 1
</span></span><span><span>(1 row)
</span></span><span><span>
</span></span><span><span>leiysky=# select * from t natural join t1;
</span></span><span><span> a
</span></span><span><span>---
</span></span><span><span> 1
</span></span><span><span>(1 row)
</span></span><span><span>
</span></span><span><span>leiysky=# select a from t join t1 on t.a = t1.a;
</span></span><span><span>ERROR:  column reference "a" is ambiguous
</span></span><span><span>LINE 1: select a from t join t1 on t.a = t1.a;
</span></span></code></pre></div><p>Of course, we can add all kinds of strange restrictions to the code, create difficult-to-maintain loopholes to maintain this property, and ensure the correctness of these properties while optimizing. But for lazy programmers, finding a simpler design is a better choice.</p><p>Welcome to the Deep Water Zone.</p><h3 id="the-ir-made-simple">The IR made simple</h3><p>The initial version of <code>The IR</code> was very concise and elegant, but in order to achieve more functionality and support more complex requirements, we added a lot of information that we don't want to focus on.</p><p>In general, the ideal state of The IR should be:</p><ul><li>Having a concise algebraic structure</li><li>Operator nodes being completely independent from each other</li><li>Not having to deal with names (only for debugging and display purposes)</li></ul><p>Let's take a moment to reflect, does IR really rely on name? We initially used name to represent attributes mainly based on intuition and reused the table schema. However, there is a lot of useless information embedded in the name, which is of no help to our optimization. It's similar to various symbol names in programming languages that eventually become memory addresses and register numbers during program execution.</p><p>Without a name, attributes cannot be distinguished. Is a name really such an inconvenient thing?</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/name_inconvenient.png" alt="Is Name such a inconvenient thing?"></p><blockquote><p>NOTE: the above image means "Is a name really such an inconvenient thing?"</p></blockquote><p>Ultimately, what we need is to assign a unique id to each attribute, whether it is an integer or a string. Our sole purpose is to differentiate and reference attributes using these ids. All name resolution will be handled in AST lowering; I only want the attribute id!</p><p>After the redesign, we have changed the way attributes are represented and also made some changes to <code>The IR</code>'s definition. By default, we use int64 as the attribute id type.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>type</span> <span>Id</span><span> </span><span>=</span><span> </span><span>i64</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>Attribute</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>id: <span>Id</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>column_type: <span>Type</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>nullable: <span>Type</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>enum</span> <span>ScalarExpr</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>ColumnRef(Id),<span>
</span></span></span><span><span><span>    </span><span>// Others
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>The design of the id generally cannot be separated from the corresponding context. In SQL IR, the common design methods for attribute id can mainly be divided into two categories:</p><ul><li>One is based on the abstraction of tuple attribute that we have used before, using the index of attribute in tuple as its id. We call this kind of id as <code>local id</code>. The characteristic of this design is that the id of the same logical attribute will change with different operators it belongs to. The advantage of this design is that it can be inferred from the operator tree without relying on external states for maintenance. However, a disadvantage is that frequent remapping of ids is required when converting operators.</li><li>Another method is to maintain a global id generator and assign a unique id to all attributes in SQL IR. We call this kind of id as <code>global id</code>. The advantage of this design is that it decouples attributes from tuple schema and allows representation using an unordered collection structure like <code>HashMap&lt;Id, Attribute&gt;</code>. It also helps property derivation through set operations and reduces maintenance complexity. However, a disadvantage is that operator trees using global ids depend on external states and cannot exist independently.</li></ul><p>The use of these two different designs will have a significant impact on the specific implementation of the optimizer.</p><p>For example, regarding this optimization:</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/split_disjunction.png" alt="Split disjuntion"></p><p>When there are suitable indexes available, this optimization can avoid full table scans and improve performance.</p><p>If using the <code>local id</code> design, implementing this optimization is very simple, just need to copy the entire operator tree and finally connect them with <code>UnionAll</code>.</p><p>But if using the <code>global id</code> design, this is a non-trivial operation, even can be said to be very painful. In order to distinguish different attributes, we must generate new IDs for all attributes while copying the operator tree at the same time, and then replace all places that reference these attributes with new IDs. This will cause many troubles when the query is more complex.</p><p>For example, when optimizing join order:</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/commute_join.png" alt="Commute join"></p><p>According to the commutative law of <code>Join</code> operators, we can legally exchange the left and right child of a <code>Join</code>.</p><p>When using <code>global id</code> design, because attributes can be represented as an unordered set, this operation has no impact on property derivation.</p><p>However, when using <code>local id</code> design, this operation becomes extremely painful.</p><p>Apart from optimization-related parts, there are also significant differences in representing <code>correlated subqueries</code>. Correlated subquery is a special type of subquery that can access attributes outside its own scope. We refer to accessing such special attributes as <code>outer reference</code>.</p><p><img src="https://xuanwo.io/2024/02-what-i-talk-about-when-i-talk-about-query-optimizer-part-1/correlated_subquery.png" alt="Correlated subquery"></p><p>Many programming languages also support similar operations, which allow accessing variables that are not defined within the function by binding them to a specific environment. This special type of function is called a <code>closure</code>.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>fn</span> <span>main</span>()<span> </span>{<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span>a<span> </span><span>=</span><span> </span><span>1</span>;<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span>f<span> </span><span>=</span><span> </span><span>||</span><span> </span>{<span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span>b<span> </span><span>=</span><span> </span>a;<span> </span><span>// a is captured from outside
</span></span></span><span><span><span></span><span>        </span>println!(<span>"</span><span>{}</span><span>"</span>,<span> </span>b);<span>
</span></span></span><span><span><span>    </span>};<span> </span><span>// f is a closure
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span>    </span>f();<span> </span><span>// stdout: 1
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>The design using <code>global id</code> can determine whether the subquery is correlated through attribute property calculation. However, when using local id design, we generally need to maintain an additional <code>scope id</code> in the <code>ColumnRef</code> of scalar expression, which is very cumbersome to implement.</p><p><em>Correlated subquery is a very big topic, and we may discuss it in subsequent articles.</em></p><p>It can be seen that both designs have their own advantages and disadvantages. In engineering practice, we need to choose a suitable design based on our own needs. Personally, I think <code>global id</code> is a better design because it can easily solve problems in most cases.</p><p>After the transformation using <code>global id</code>, the code of <code>The IR</code> can be greatly simplified.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>type</span> <span>Id</span><span> </span><span>=</span><span> </span><span>i64</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>Context</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>id_gen: <span>Id</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>struct</span> <span>Attribute</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>id: <span>Id</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>column_type: <span>Type</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>nullable: <span>Type</span>,<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>type</span> <span>AttributeSet</span><span> </span><span>=</span><span> </span>HashMap<span>&lt;</span>Id,<span> </span>Attribute<span>&gt;</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>enum</span> <span>ScalarExpr</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>ColumnRef(Id),<span>
</span></span></span><span><span><span>    </span>Literal(Value,<span> </span>Type),<span>
</span></span></span><span><span><span>    </span>Function(Signature,<span> </span><span>Vec</span><span>&lt;</span>Self<span>&gt;</span>),<span>
</span></span></span><span><span><span>    </span>Subquery(Quantifier,<span> </span><span>Box</span><span>&lt;</span>Operator<span>&gt;</span>),<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>enum</span> <span>Operator</span><span> </span>{<span>
</span></span></span><span><span><span>    </span>Get<span> </span>{<span>
</span></span></span><span><span><span>        </span>table: <span>String</span>,<span>
</span></span></span><span><span><span>        </span>output_columns: <span>AttributeSet</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Select<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>predicate: <span>ScalarExpr</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Project<span> </span>{<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>projects: <span>Vec</span><span>&lt;</span>(ScalarExpr,<span> </span>Id)<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Join<span> </span>{<span>
</span></span></span><span><span><span>        </span>kind: <span>JoinKind</span>,<span>
</span></span></span><span><span><span>        </span>condition: <span>ScalarExpr</span>,<span>
</span></span></span><span><span><span>        </span>left: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>right: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>UnionAll<span> </span>{<span>
</span></span></span><span><span><span>        </span>left: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>right: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span>    </span>Aggregate<span> </span>{<span>
</span></span></span><span><span><span>        </span>group_by: <span>Vec</span><span>&lt;</span>ScalarExpr<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>aggr_exprs: <span>Vec</span><span>&lt;</span>(ScalarExpr,<span> </span>Id)<span>&gt;</span>,<span>
</span></span></span><span><span><span>        </span>child: <span>Box</span><span>&lt;</span>Self<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span>},<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>After transferring the complexity to the AST lowerer, we can confidently say that <code>The IR</code> is now a production-ready SQL IR. It supports all SQL operations and common optimizations, has a user-friendly API, and is also very easy to understand.</p><p>What's more important is that no one understands <code>The IR</code> better than the readers of this article, and any reader can easily extend The IR according to their own needs.</p><h2 id="afterword">Afterword</h2><p>Finally, we have reached the end of this article.</p><p>As the opening of the series, in this article I simply discussed some focal points in SQL IR design without delving into the details of various algorithms.</p><p>However, sharing the design process of IR is an interesting thing. Understanding multiple IRs is like understanding why a roadside tree grows crooked. To someone seeing it for the first time, the tree's unusual shape is puzzling. However, locals who have lived around it are aware of its backstory: when it was young, the tree became bent due to the habit of hanging preserved meat on its branches.</p><p>This little thing is an important reason for the final result, but it is too insignificant to be voluntarily shared by those who know - of course, in reality, no one often cares about the reasons behind it either.</p><p>Database development is a niche field with many engineering practices and experiences. These experiences are rarely circulated among people and I don't want them to disappear with changing times like America's moon landing technology; hence my original intention to write this series of articles came about.</p><p>In the next article, I will share related content about optimizer architecture; please stay tuned.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dr Strangelove at 60 (107 pts)]]></title>
            <link>https://www.bbc.com/culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece</link>
            <guid>39176730</guid>
            <pubDate>Mon, 29 Jan 2024 14:38:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece">https://www.bbc.com/culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece</a>, See on <a href="https://news.ycombinator.com/item?id=39176730">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="culturearticle20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece"><div id="headline-culturearticle20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece"><div><p>(Image credit: </p><!-- --><p>Getty Images</p><!-- --><p>)</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7dd3k.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7dd3k.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7dd3k.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7dd3k.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7dd3k.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7dd3k.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7dd3k.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7dd3k.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Peter Sellers in Dr Strangelove" src="https://ychef.files.bbci.co.uk/976x549/p0h7dd3k.jpg" alt="Peter Sellers in Dr Strangelove" id=""></picture></div></div><div><article><div><p>As Stanley Kubrick's satirical masterpiece Dr Strangelove turns 60, an ongoing mystery endures: who was the real-life inspiration for his demonic central character?</p><div><p>I</p><div><p>In 1999, a reporter from Scientific American asked the 91-year-old physicist Edward Teller whether it was true that <a href="https://www.scientificamerican.com/article/infamy-and-honor-at-the-a/">he had been the real-life template for Dr Strangelove</a>, the chilling scientific adviser played by Peter Sellers in Stanley Kubrick's movie Dr Strangelove or: How I Learned to Stop Worrying and Love the Bomb.</p>
<p>Rumours had been circulating ever since the movie's release on 29 January 1964. After all, Teller had worked with Robert Oppenheimer on the atomic bomb (he is played by Benny Safdie in <a href="https://www.bbc.com/culture/article/20230719-a-magnificent-story-of-a-tragic-american-genius">Christopher Nolan's film</a>) and went on to spearhead the far more powerful hydrogen bomb. He had a terrifying reputation and a Hungarian accent as pronounced as Strangelove's German one. When Teller made headlines again in the 1980s as the brains behind President Reagan's so-called "Star Wars" defence initiative, several newspapers <a href="https://www.newspapers.com/newspage/570682311/">called him</a> "the real Dr Strangelove".</p>
<p><strong>More like this:<br></strong>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.bbc.com/culture/article/20230726-the-one-thing-oppenheimer-gets-wrong">The one thing Oppenheimer gets wrong<br></a>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.bbc.com/culture/article/20190808-was-napoleon-the-greatest-film-never-made">Was Kubrick's Napoleon the greatest film never made?<br></a>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.bbc.com/culture/article/20211112-the-overlooked-masterpiece-warning-of-a-cold-war-apocalypse">The overlooked masterpiece warning of Cold War apocalypse</a></p>
<p>But Teller exploded at the reporter. "My name is not Strangelove," he snapped. "I don't know about Strangelove. I'm not interested in Strangelove. What else can I say?…&nbsp;Look, say it three times more and I throw you out of this office." Teller died in 2003, a year before the publication of Peter Goodchild's biography Edward Teller: The Real Dr Strangelove, on the cover of which he is pictured wearing Sellers' spectacles in a still from the movie. It is unlikely he would have appreciated it.</p></div></div><div id="culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece-p0h7dc81"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7dc81.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7dc81.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7dc81.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7dc81.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7dc81.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7dc81.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7dc81.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7dc81.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Benny Safdie played Edward Teller in Christopher Nolan's Oppenheimer (Credit: Universal)" src="https://ychef.files.bbci.co.uk/976x549/p0h7dc81.jpg" alt="Benny Safdie played Edward Teller in Christopher Nolan's Oppenheimer (Credit: Universal)" id=""></picture><div><p>Benny Safdie played Edward Teller in Christopher Nolan's Oppenheimer (Credit: Universal)</p></div></div><div><p>It might seem strange that a fictional character was required to sell the story of one of the most consequential individuals of the 20th Century, but even now, on its 60th anniversary, Dr Strangelove is synonymous with the politics of nuclear war. Later this year, Armando Iannucci's stage version <a href="https://www.theguardian.com/stage/2023/sep/26/steve-coogan-armando-iannucci-dr-strangelove-play">will open in the West End</a>, with Steve Coogan taking on Peter Sellers' trio of roles.</p></div><div><blockquote><h2>Nothing is as unforgettable as the late-arriving Dr Strangelove himself: the sinister, amoral nuclear scientist</h2></blockquote></div><div><p>Kubrick's masterstroke was to perceive grisly comedy and lethal irony where most people saw only horror. Prior to Dr Strangelove, the only significant movie about world-ending nuclear war was Stanley Kramer's sombre, elegiac On the Beach, from 1959. Kubrick saw the value in making it funny. "If the modern world could be summed up in a single word it would be absurd," he wrote in his notes. "The only truly creative response to this is the comic vision of life." The film is packed with memorable scenes, lines and performances but nothing as unforgettable as the late-arriving Dr Strangelove himself: the sinister, amoral nuclear scientist who devolves into <em>sieg heiling</em> lunacy.</p>
<p>Goodchild's biography is excellent but its subtitle owes more to marketing than accuracy, because Teller was not the only "real" Dr Strangelove. Other possibilities mooted over the years are the mathematician John von Neumann, the nuclear strategist Herman Kahn, the German rocket scientist Wernher von Braun and the foreign policy expert Henry Kissinger. Despite all the speculation, Kubrick never clarified the character's origins. So did he base Strangelove on one of them, all of them, or none of them? Does the real Dr Strangelove even exist?</p>
<p><strong>Kubrick's 'White House Rasputin'</strong></p>
<p>One reason for the mystery is that Strangelove was not present in Kubrick's source material. Writing as Peter Bryant, the Welsh former RAF officer Peter George published a novel in 1958 that was called Two Hours to Doom in the UK and Red Alert in the US. It was inspired by a recent media panic about the possibility that an accidental war could be set in motion by "a nervous, psychotic or fanatical launch officer", as Carl Dreher put it in the Nation.</p>
<p>In Red Alert, a back-up plan to secure the US's nuclear deterrent in the event of the president's death results in a situation where one demented general can order a strike on the USSR that only he can call off. The novel tracks the desperate efforts of the American and Soviet governments to avert a full-scale nuclear exchange. It sold a quarter of a million copies in the US alone.</p></div><div id="culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece-p0h7db6d"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7db6d.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7db6d.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7db6d.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7db6d.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7db6d.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7db6d.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7db6d.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7db6d.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Despite all the speculation, Kubrick (pictured on set) never clarified the character's origins (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0h7db6d.jpg" alt="Despite all the speculation, Kubrick (pictured on set) never clarified the character's origins (Credit: Getty Images)" id=""></picture><div><p>Despite all the speculation, Kubrick (pictured on set) never clarified the character's origins (Credit: Getty Images)</p></div></div><div><p>Kubrick was already plotting a movie about nuclear war when, in 1961, a defence strategist in London gave him George's novel with the disclaimer that such a dire chain of events was impossible. Kubrick didn't care&nbsp;– the story confirmed his belief that the logic of nuclear deterrence was insane&nbsp;– so he optioned the novel, and asked George to collaborate on a screenplay. But Kubrick agonised over whether to make a straight adaptation, a more realistic drama or a satirical comedy. In spring 1962 he came up with a new character, a "White House Rasputin" called Dr Otto Strangelove, who became his gateway to a "<a href="https://faroutmagazine.co.uk/stanley-kubrick-realised-dr-strangelove-was-comedy/">nightmare comedy</a>". Kubrick hired the satirist Terry Southern to spice up the screenplay with jokes about sex and death.</p></div><div><blockquote><h2>The most compelling candidate for a real-life Strangelove is the only one who sounded nothing like him</h2></blockquote></div><div><p>The five potential models for Strangelove&nbsp;– Teller, Von Neumann, Kissinger, Von Braun and Kahn&nbsp;– had superficial similarities. They all worked in weapons development or Cold War strategy, and all but Kahn had thick European accents. Teller and von Neumann, two of the brilliant Hungarian refugees who worked on the Manhattan Project, both argued that the pursuit of knowledge was a scientist's paramount duty, regardless of the consequences. "I do not want the hydrogen bomb because it would kill more people," Teller once insisted. "I wanted the hydrogen bomb because it was <em>new</em>… I am afraid of ignorance."</p></div><div id="culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece-p0h7db9r"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7db9r.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7db9r.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7db9r.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7db9r.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7db9r.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7db9r.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7db9r.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7db9r.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Peter Sellers played the sinister Dr Strangelove along with two other characters in Kubrick's 1964 film (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0h7db9r.jpg" alt="Peter Sellers played the sinister Dr Strangelove along with two other characters in Kubrick's 1964 film (Credit: Getty Images)" id=""></picture><div><p>Peter Sellers played the sinister Dr Strangelove along with two other characters in Kubrick's 1964 film (Credit: Getty Images)</p></div></div><div><p>Of the five, Kissinger is the least plausible inspiration. The future secretary of state was not a national figure in 1964, and was not linked to the character until the 1970s. Von Neumann, the genius – who made foundational contributions to computing, game theory, climate modelling and AI – used a wheelchair (like Strangelove) prior to his death from cancer in 1957 but he was a famously amiable character. Teller was more intimidating, and widely associated with the H-bomb, but nobody involved in the movie brought up his name. Peter Sellers explicitly cited Von Braun (like Strangelove, a former Nazi) but he also claimed that he took the accent from <a href="https://www.bbc.com/culture/article/20200227-weegee-photos-of-crime-scenes-and-people-on-the-margins">Weegee</a>, the celebrated Austrian-American photographer who documented the making of the movie, and the black glove from Rotwang in Fritz Lang's 1927 sci-fi classic Metropolis, one of cinema's first "mad scientists".</p>
<p><strong>The most likely prototype</strong></p>
<p>The most compelling candidate for a real-life Strangelove is the only one who sounded nothing like him. Born in New Jersey in 1922, Herman Kahn was raised in the Bronx. His chewy New York accent, working-class origins and immense girth contributed to his becoming the US's first celebrity nuclear strategist. Journalists compared him to the comedians Jackie Gleason and Zero Mostel, not just physically but temperamentally. "I can be really funny about nuclear war," <a href="https://www.nytimes.com/1968/12/01/archives/oneman-think-tank-oneman-think-tank.html">Kahn bragged</a>.</p>
<p>Kahn became famous in 1960 with the publication of his bestselling book On Thermonuclear War. Kahn, who was wargaming potential conflicts for the US government's RAND Corporation, believed that talking about nuclear war in terms of the end of humanity was dangerous, and that it was reckless not to consider a plan for victory and survival. In his mind, he was both a pragmatist and an optimist. But his book managed to offend hawks and doves alike, not to mention his own colleagues. Some readers found it psychopathic and obscene. <a href="https://www.washingtonpost.com/archive/local/1983/07/08/herman-kahn-dies-leading-strategic-theorist/49d3c849-d180-4fcb-ad3e-b9fad28ee9b2/">One reviewer called it</a> "a moral tract on mass murder: how to plan it, how to commit it, how to get away with it, how to justify it".</p></div><div id="culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece-p0h7db1p"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7db1p.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7db1p.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7db1p.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7db1p.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7db1p.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7db1p.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7db1p.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7db1p.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Foreign policy expert Henry Kissinger was one of the many real people touted as the inspiration for the character (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0h7db1p.jpg" alt="Foreign policy expert Henry Kissinger was one of the many real people touted as the inspiration for the character (Credit: Getty Images)" id=""></picture><div><p>Foreign policy expert Henry Kissinger was one of the many real people touted as the inspiration for the character (Credit: Getty Images)</p></div></div><div><p>Because the scenarios imagined by the think-tank wargamers were a kind of speculative fiction, their research included novels. Kahn approvingly cited Red Alert in On Thermonuclear War. In George's novel, the Soviets have developed an annihilating superweapon: a cluster of bombs, encased in cobalt, that could produce enough radiation to kill everyone on earth. Although the cobalt bomb never existed, it was an object of horrified fascination from the 1950s through to the early 70s, featuring in movies from On the Beach to Beneath the Planet of the Apes. Kahn argued that such a weapon would be a useless deterrent because nobody would ever use it, but he gave it a name that was too dramatic for its own good: the Doomsday Machine.</p>
<p>Kubrick borrowed Kahn's coinage for the cobalt bomb in his movie. General Buck Turgidson (George C Scott) quotes the most hair-raising sections from Kahn's book almost verbatim, Strangelove lifts from the chapter about underground shelters, and President Muffley (Sellers again) references Kahn's most notorious line: "Will the survivors envy the dead?" The word "megadeath", meaning one million deaths per nuclear explosion, was Kahn's invention, too. Strangelove even works at the RAND-like "Bland Corporation" (not all the movie's jokes are good). In one draft of the screenplay, Strangelove complains about the backlash to his Kahn-like book The Facts on Nuclear War. The numerous debts to On Thermonuclear War were not lost on Kahn, who suggested to an aghast Kubrick that he receive a percentage of the movie's box office.</p></div><div id="culture/article/20240129-dr-strangelove-at-60-the-mystery-behind-kubricks-cold-war-masterpiece-p0h7d9yq"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7d9yq.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0h7d9yq.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7d9yq.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0h7d9yq.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7d9yq.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0h7d9yq.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7d9yq.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0h7d9yq.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="The nuclear strategist Herman Kahn makes the most compelling candidate for a real-life Strangelove (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0h7d9yq.jpg" alt="The nuclear strategist Herman Kahn makes the most compelling candidate for a real-life Strangelove (Credit: Getty Images)" id=""></picture><div><p>The nuclear strategist Herman Kahn makes the most compelling candidate for a real-life Strangelove (Credit: Getty Images)</p></div></div><div><p>It's no surprise, then, that when the movie came out, both The Daily Mail and The Times claimed that Kahn was the prototype for Strangelove. But the Spectator <a href="http://archive.spectator.co.uk/article/28th-february-1964/11/dr-strangelove-and-dr-kahn">dismissed the idea</a>: "If Dr Strangelove is the type of the inhuman technician, utterly indifferent to the consequences of the exploitation of his discoveries, not only is Dr Kahn not the prototype of Dr Strangelove. He is almost the exact opposite of him. The difference, to put it succinctly, is that Dr Strangelove is mad and Dr Kahn is sane." Certainly Kahn's gregarious energy was nothing like Strangelove's cold intensity. "How could my son be Dr Strangelove?" protested Kahn's own father in 1968. "He is so warm and considerate."</p>
<p>As it happens, Kahn was definitely the basis for the nuclear strategist Dr Groeteschele in Fail Safe, Sidney Lumet's much more earnest 1964 film about a nuclear strike triggered by a computer error. But the media only cared about Strangelove. "Kubrick is a friend of mine," Kahn told Newsweek. "He told me Dr Strangelove wasn't supposed to be me." Yet three years later <a href="https://www.nytimes.com/1968/12/01/archives/oneman-think-tank-oneman-think-tank.html">he changed his story</a>, claiming that the character was in fact a hybrid of Kissinger, Von Braun and himself. Unlike Teller, he was far from offended by the gossip. It bolstered his celebrity and his income.</p>
<p>As for the other candidates, writes Peter Goodchild, the Strangelove connection was "a stigma… enhancing their links with the nuclear nightmare". Despite his biography's subtitle, Goodchild argues that Strangelove was "clearly a composite", not a caricature of one individual. In fact, the hunt for the "real" Strangelove smudges Kubrick's satirical point.</p>
<p>While researching the movie, Kubrick was shocked by how the experts' professional pride "seemed to completely overcome any personal involvement in the possible destruction of their world". Strangelove is the demonic personification of a way of thinking about war&nbsp;– highly intelligent yet bloodlessly abstracted from the reality of human suffering&nbsp;– that infected many scientists, strategists and politicians during the Cold War, and has not disappeared. He is not a man but an attitude, and attitudes are immortal.</p>
<p><em>Dorian Lynskey is the author of Everything Must Go: The Stories We Tell About the End of the World (April 2024).</em></p>
<p><em>If you liked this story,&nbsp;</em><a href="https://cloud.email.bbc.com/SignUp10_08?&amp;at_bbc_team=studios&amp;at_medium=Onsite&amp;at_objective=acquisition&amp;at_ptr_name=bbc.com&amp;at_link_origin=featuresarticle&amp;at_campaign=essentiallist&amp;at_campaign_type=owned&amp;&amp;" target="_self"><strong>sign up for The Essential List newsletter</strong></a><em>&nbsp;– a handpicked selection of features, videos and can't-miss news delivered to your inbox every Friday.</em></p>
<p><em>If you would like to comment on this story or anything else you have seen on BBC Culture, head over to our&nbsp;</em><a href="https://www.facebook.com/pages/BBC-Culture/237388053065908" target="_blank"><strong><em>Facebook</em></strong></a><em>&nbsp;page or message us on</em>&nbsp;<a href="https://twitter.com/bbc_culture" target="_blank"><strong><em>Twitter</em></strong></a><em>.</em></p></div></div></article></div>;</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: WhisperFusion – Ultra-low latency conversations with an AI chatbot (254 pts)]]></title>
            <link>https://github.com/collabora/WhisperFusion</link>
            <guid>39176570</guid>
            <pubDate>Mon, 29 Jan 2024 14:23:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/collabora/WhisperFusion">https://github.com/collabora/WhisperFusion</a>, See on <a href="https://news.ycombinator.com/item?id=39176570">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:collabora/WhisperFusion" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="EpderkQmzwZWZjtEBp_ci3g30ORawTqe9_L0q6exzAdtpJ23_zD1txVsoHSl6rolLQ9CfNPzCpAmJDq5XZJ2Aw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="collabora/WhisperFusion" data-current-org="collabora" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=lKk0N%2BvSREfLl6Gv8W%2F7Caj1twyYpCG1Ex8qMxYNpFdKkYQR3v0SOfkjJ8cbsn3%2F6a9bw3kfi7IdbeuuaClly9SnUkGUrH5R3WqB7RVBh1oFCj1oHpPM6ppQ8xJEywqNpNRzqYp95C5M2%2BjA4y8M9bbviWM8UEfhiqQ8K43HfkK8AXIG9ocnNVHw%2B9s3Sx20eq7kRE7rZbB3vm6PyCpNmR2D672lYlIr93AzkuoHDQHGXNwTM%2FxdqqOrmRwVOG8L5m4OWehcgu1P4CcjRMPym6zFOriTfhDye5XWKcNgREZUMk6gC3EhUd%2Faw3gvI3N3R4B7ge%2FRQm%2FbETXLYCe8bJ1OJ%2FyHPiT%2F6TVQ%2FvWcB7US5ZfLDPhSfFOeGma7hqRHOavfrNvNFijl7jQFCe2qJjD%2B2sOTkUYmMwXPDCtOm34nwf5DK1s1tykWMGorqlaua32OSOLmdaJlo44A5psBuGLKtTi7qojMgFnphrZc3vdBmBir2mBdAGQIzqTHFTe82knQw%2FP2sxYNjFzDBOXrcehUfhmn5Q%3D%3D--JliSJ25C2HxVFKia--Pc2N8foPDj9yp9W%2BC%2Fb9JQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=collabora%2FWhisperFusion" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/collabora/WhisperFusion&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="0e33672d0f145f127f21cec22948937ab34624b8e062771fc310b88ff5db5c0a" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon and iRobot call off their planned acquisition (253 pts)]]></title>
            <link>https://www.cnbc.com/2024/01/29/amazon-terminates-irobot-deal-vacuum-maker-to-lay-off-31percent-of-staff.html</link>
            <guid>39176297</guid>
            <pubDate>Mon, 29 Jan 2024 13:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/01/29/amazon-terminates-irobot-deal-vacuum-maker-to-lay-off-31percent-of-staff.html">https://www.cnbc.com/2024/01/29/amazon-terminates-irobot-deal-vacuum-maker-to-lay-off-31percent-of-staff.html</a>, See on <a href="https://news.ycombinator.com/item?id=39176297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107339500" data-test="InlineImage"><p>The iRobot headquarters in Bedford, Massachusetts, US, on Friday, June 16, 2023. Amazon.com Inc.'s proposed $1.7 billion deal to buy robot vacuum firm iRobot Corp. was given the all-clear by the UKs antitrust agency. Photographer: Sophie Park/Bloomberg via Getty Images</p><p>Bloomberg | Bloomberg | Getty Images</p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> said on Monday it would not move forward with a planned acquisition of vacuum-maker <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/IRBT/">iRobot</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, with the two companies <a href="https://www.prnewswire.com/news-releases/amazon-and-irobot-agree-to-terminate-pending-acquisition-302046311.html" target="_blank">saying</a> in a release there was "no path to regulatory approval for the deal."</p><p>The Roomba maker also <a href="https://www.prnewswire.com/news-releases/irobot-announces-operational-restructuring-plan-to-position-company-for-the-future-302046345.html" target="_blank">announced</a> it would lay off 31% of its employees, around 350 people, and that its chair and CEO, Colin Angle, would step down effective immediately.</p><p>Shares of iRobot fell 10% in morning trading on the news.</p><p>The fate of the deal was plunged into uncertainty after The Wall Street Journal <a href="https://www.cnbc.com/2024/01/18/irobot-shares-tank-30percent-on-report-eu-plans-to-block-amazon-acquisition.html">reported</a> that the European Union would not offer regulatory approval.</p><p>The European Commission, the executive body of the EU, launched a probe in July, saying that the proposed deal could result in Amazon hindering iRobot rivals from competing on Amazon's online marketplace. The commission argued that Amazon could delist or reduce rival products' prominence in search results or elsewhere.</p><p>"Our in-depth investigation preliminarily showed that the acquisition of iRobot would have enabled Amazon to foreclose iRobot's rivals by restricting or degrading access to the Amazon Stores," Margrethe&nbsp;Vestager, the European Commission's executive vice president, said in a statement. She added that Amazon's control over the marketplace "could have restricted competition in the market for robot vacuum cleaners, leading to higher prices, lower quality, and less innovation for consumers."</p><p>"We're disappointed that Amazon's acquisition of iRobot could not proceed," David Zapolsky, senior vice president and general counsel at Amazon, said in a release.</p><p>iRobot said it would focus on margin improvements, reduce spending on research and development, and pause all work on "non-floorcare" products, including its air purifiers and robotic lawn mowers.</p><p>"The termination of the agreement with Amazon is disappointing, but iRobot now turns toward the future with a focus and commitment to continue building thoughtful robots and intelligent home innovations that make life better," iRobot's Angle said in a release.</p><p>Amazon will pay iRobot a previously agreed upon $94 million breakup fee. The terminated deal, first announced in 2022, would have originally valued iRobot at roughly $1.7 billion.</p><p>The robotic vacuum maker has a market capitalization of under $400 million, following Monday's news and prior reports that the EU would move to block the deal.</p><p>In July, iRobot entered into a $200 million financing facility from the Carlyle Group, in order to fund the company's operations as a stopgap until the Amazon deal closed.</p><p>Amazon declined to provide a comment beyond the release.</p><p>Regulators around the world have moved to scrutinize large technology companies, citing potential anti-competitive effects. Amazon is also one of the subjects of <a href="https://www.cnbc.com/2024/01/25/ftc-looking-into-ai-deals-at-amazon-alphabet-microsoft-openai-.html">a Federal Trade Commission inquiry</a> into the investments and partnerships between Big Tech and artificial intelligence developers such as Anthropic and OpenAI.</p><p>In Europe, both Britain's Competition and Markets Authority and the EU's European Commission have delayed or halted several deals. Those include <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-7"><a href="https://www.cnbc.com/quotes/META/">Meta</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>'s <a href="https://www.cnbc.com/2023/05/23/meta-sells-giphy-to-shutterstock-at-a-loss-in-a-53-million-deal.html">acquisition </a>of Giphy, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-9"><a href="https://www.cnbc.com/quotes/ADBE/">Adobe</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>'s terminated<a href="https://www.cnbc.com/2023/12/18/adobe-and-figma-call-off-20-billion-merger.html"> acquisition </a>of Figma and <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-11"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft's</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> investment <a href="https://www.cnbc.com/2023/12/08/microsofts-investment-in-openai-faces-initial-review-from-uk-cma.html">in OpenAI</a>, as well as Microsoft's <a href="https://www.cnbc.com/2023/10/13/microsoft-closes-activision-blizzard-deal-after-regulatory-review.html">purchase of Activision Blizzard</a>.</p><p><em>— CNBC's Annie Palmer contributed reporting.</em></p><p><strong>WATCH: Amazon-iRobot deal a 'no-brainer'</strong></p></div><div id="Placeholder-ArticleBody-Video-107099722" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000257513" aria-labelledby="Placeholder-ArticleBody-Video-107099722"><p><img src="https://image.cnbcfm.com/api/v1/image/107099723-16597130431659713039-24714965193-1080pnbcnews.jpg?v=1659713042&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Amazon's acquisition of iRobot a no-brainer for company's robotics plans, says WSJ's Stern"><span></span><span></span></p></div><div><p><em><strong>Don't miss these stories from CNBC PRO:</strong></em></p><ul><li><a href="https://www.cnbc.com/2024/01/24/forget-the-magnificent-7-these-nasdaq-stocks-are-next-in-line-to-lead-rally-according-to-the-charts.html">Forget the 'Magnificent 7,' these Nasdaq stocks are next in line to lead the rally, according to the charts</a></li><li><a href="https://www.cnbc.com/2024/01/23/nvidia-is-deeply-overbought-and-due-for-consolidation-says-chart-analyst.html">Nvidia is now 'deeply overbought' and due for 'consolidation,' says chart analyst</a></li><li><a href="https://www.cnbc.com/2024/01/24/zepbound-is-off-to-a-strong-start-but-heres-what-eli-lilly-investors-are-watching.html">Eli Lilly's Zepbound is off to a strong start, but here's what needs to happen to push shares higher</a></li><li><a href="https://www.cnbc.com/2024/01/26/investors-are-shifting-into-this-type-of-bond-fund-at-the-fastest-pace-in-three-years.html">Investors are shifting into this type of bond fund at the fastest pace in three years</a></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Florida House of Representatives approves bill to ban social media for kids < 16 (391 pts)]]></title>
            <link>https://abcnews.go.com/GMA/Family/florida-house-representatives-approves-bill-ban-social-media/story?id=106672586</link>
            <guid>39175883</guid>
            <pubDate>Mon, 29 Jan 2024 13:20:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abcnews.go.com/GMA/Family/florida-house-representatives-approves-bill-ban-social-media/story?id=106672586">https://abcnews.go.com/GMA/Family/florida-house-representatives-approves-bill-ban-social-media/story?id=106672586</a>, See on <a href="https://news.ycombinator.com/item?id=39175883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="prism-article-body"><p>Legislators in the Florida House of Representatives on Wednesday approved what could be the strictest regulation on <a data-testid="prism-linkbase" href="https://www.goodmorningamerica.com/family/story/penelope-cruz-why-kids-dont-social-media-106479786" target="_blank">social media and kids</a> in the country.</p><p>Florida <a data-testid="prism-linkbase" href="https://myfloridahouse.gov/Sections/Bills/billsdetail.aspx?BillId=80134&amp;sui=QATRKlZHGFw=-638416255520920466" target="_blank">House Bill 1</a> would prohibit children under the age of 16 from using most social media platforms, regardless of parental approval.</p><p>The social media platforms the bill would target include any site that tracks user activity, allows children to upload content or uses addictive features designed to cause compulsive use.</p><p>The House passed the bill by a vote of 106 to 13, with many Democrats joining the chamber's Republican majority in support of the bill. It now heads to the Republican-controlled Senate for consideration.</p><p>State Rep. Fiona McFarland, a Republican, described social media as "digital fentanyl" for kids when promoting the bill on the House floor.</p><p>"It's like a digital fentanyl, and even the most plugged-in parent or attuned teen has a hard time shutting the door against these addictive features," McFarland said.</p><p>Another Republican legislator, state Rep. Tyler Sirois, also argued in support of the bill, saying that social media platforms are "taking advantage of kids growing up."</p><p>Most social media platforms currently have a minimum user age of 13.</p><section data-testid="prism-collection"><header><p><h2>Editor’s Picks</h2></p></header></section><p>The bill would allow the termination of social media accounts belonging to kids under 16, including the deletion of information for pre-existing accounts. It would also require that social media sites use "reasonable age verification methods" to verify users' ages.</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO: The Florida State capitol." data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/4147653e-c8f1-4791-be5b-8352124cd09d/fl-state-cap-rf-gty-ml-231204_1701717450664_hpMain.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>The Florida State capitol.</span></span></span></p><p><span>STOCK PHOTO/Getty Images</span></p></div></figcaption></figure></div><p>The bill is opposed by those who argue that it infringes on First Amendment and parental rights.</p><p>Meta, the parent company of Facebook and Instagram, argued that social media regulation should be overseen on on a federal basis, and that parental approval should be sufficient for minors' use of social media, <a data-testid="prism-linkbase" href="https://abcnews.go.com/Health/wireStory/florida-house-passes-bill-ban-social-media-accounts-106655448" target="_blank">according to The Associated Press</a>.</p><p>"Many teens today leverage the internet and apps to responsibly gather information and learn about new opportunities, including part-time jobs, higher education, civic or church gatherings, and military service," Meta representative Caulder Harvill-Childs wrote to the House Judiciary Committee, according to the AP. "By banning teens under 16, Florida risks putting its young people at a disadvantage versus teens elsewhere."</p><p>The legislative action in Florida comes at a time when social media companies, as well as parents, legislators and medical providers, are trying to figure out how to approach social media and kids.</p><p>Meta on Thursday <a data-testid="prism-linkbase" href="https://about.fb.com/news/2024/01/introducing-stricter-message-settings-for-teens-on-instagram-and-facebook/" target="_blank">announced a series of new safety measures</a> aimed at teens, including restricting private messages from strangers and instituting new parental controls.</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO:Stock photo" data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/dbe56266-83ea-439a-9e6f-fa92a1c372ad/Kids-smartphones-gty-jm-240125_1706195412194_hpMain.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>Stock photo</span></span></span></p><p><span>Lakshmiprasad S/Getty Images/iStockphoto</span></p></div></figcaption></figure></div><p>The new safety measures came just one day after New York City Mayor Eric Adams <a data-testid="prism-linkbase" href="https://abcnews.go.com/US/new-york-city-mayor-eric-adams-declares-social/story?id=106647634" target="_blank">classified social media as a "public health hazard</a>" and an "environmental toxin," saying young people must be protected from "harm" online.</p><p>In his State of the City address Wednesday, Adams claimed TikTok, YouTube and Facebook are "fueling a mental health crisis by designing their platforms with addictive and dangerous features."</p><p>"We are the first major American city to take this step and call out the danger of social media like this," the mayor said. "Just as the surgeon general did with tobacco and guns, we are treating social media like other public health hazards and ensuring that tech companies take responsibility for their products."</p><p>Last year, the <a data-testid="prism-linkbase" href="https://www.goodmorningamerica.com/wellness/story/american-psychological-association-issues-advisory-teens-social-media-99228135" target="_blank">American Psychological Association</a> issued first-of-its-kind recommendations intended to help teenagers use social media safely, including setting time limits, encouraging family discussions about social media and parental monitoring.</p><p>The U.S. Surgeon General last year also issued an <a data-testid="prism-linkbase" href="https://www.goodmorningamerica.com/wellness/story/us-surgeon-general-issues-major-advisory-social-media-99514661" target="_blank">advisory warning of an urgent public health issue</a> regarding social media usage and youth mental health.</p><p>In the advisory, released in May, Dr. Vivek H. Murthy called for more research to determine the extent of mental health impacts on young people, including the type of content generating the most harm, societal factors that could protect youth and ways in which social media can be beneficial.</p><p>"To date, the burden of protecting youth has fallen predominantly on children, adolescents and their families," Murthy wrote. "The entire burden of mitigating the risk of harm of social media cannot be placed on the shoulders of children and parents."</p><p>Murthy called on social media companies to prioritize safety and privacy in their product designs and ensure minimum age requirements are enforced. He said he believes 13 is "too early" for kids to be on social media, describing the age as a "time when kids are developing their identity, their sense of self."</p><p>The advisory also outlined how policymakers can enact change in three ways: creating policies limiting access to potentially harmful content, developing curricula about digital and media literacy in schools, and increasing funding for related research.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[—-libcurl (638 pts)]]></title>
            <link>https://everything.curl.dev/libcurl/libcurl</link>
            <guid>39175873</guid>
            <pubDate>Mon, 29 Jan 2024 13:19:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://everything.curl.dev/libcurl/libcurl">https://everything.curl.dev/libcurl/libcurl</a>, See on <a href="https://news.ycombinator.com/item?id=39175873">Hacker News</a></p>
<div id="readability-page-1" class="page"><div spellcheck="false" translate="no"><div data-key="daff5dd5ff7e41708eab25d3419ee91e"><p><span data-key="0f025ecef15f4153ad46d7f5a95380ee"><span data-offset-key="0f025ecef15f4153ad46d7f5a95380ee:0">/********* Sample code generated by the curl command-line tool **********</span></span></p></div><div data-key="5307085a79c94d4bb02dd92321ccadfc"><p><span data-key="a293c80ce6ef48298908ecc9d759da45"><span data-offset-key="a293c80ce6ef48298908ecc9d759da45:0"> * All curl_easy_setopt() options are documented at:</span></span></p></div><div data-key="50230daff08146e39fcd7cb7d037a058"><p><span data-key="e5ed583ada874fcaba91b25b927fe68d"><span data-offset-key="e5ed583ada874fcaba91b25b927fe68d:0"> * https://curl.se/libcurl/c/curl_easy_setopt.html</span></span></p></div><div data-key="85d5fd51143e4a93b694167652c57058"><p><span data-key="b2c2cfd870c34c8082095aac095762c6"><span data-offset-key="b2c2cfd870c34c8082095aac095762c6:0"> ************************************************************************/</span></span></p></div><div data-key="9d7565c41a9645bb92812b6395ae721e"><p><span data-key="dbbe66ed4b7841c2950ba437ce51bb5e"><span data-offset-key="dbbe66ed4b7841c2950ba437ce51bb5e:0">int main(int argc, char *argv[])</span></span></p></div><div data-key="e9bb8973abc441aaacc0ccaa1819e49c"><p><span data-key="d1bdc00067b54603b2c20bd74539f72d"><span data-offset-key="d1bdc00067b54603b2c20bd74539f72d:0">  curl_easy_setopt(hnd, CURLOPT_URL, "http://example.com");</span></span></p></div><div data-key="0dd993c320cb4b14b27cc372bae1b51a"><p><span data-key="2be04c0e3c344046a8c58245de53fc5a"><span data-offset-key="2be04c0e3c344046a8c58245de53fc5a:0">  curl_easy_setopt(hnd, CURLOPT_NOPROGRESS, 1L);</span></span></p></div><div data-key="30523ac9cd2c47b0b599921fee5c8e22"><p><span data-key="5e8eb77d0e924422a808ca23d1542696"><span data-offset-key="5e8eb77d0e924422a808ca23d1542696:0">  curl_easy_setopt(hnd, CURLOPT_USERAGENT, "curl/7.45.0");</span></span></p></div><div data-key="20271606c9c24e3fae57eabea922e513"><p><span data-key="142ff4328c874741bf79ce2a9dfbb4e1"><span data-offset-key="142ff4328c874741bf79ce2a9dfbb4e1:0">  curl_easy_setopt(hnd, CURLOPT_MAXREDIRS, 50L);</span></span></p></div><div data-key="c34ad54198ce4e7085c58a24b2dc01ce"><p><span data-key="e05b2a5a9f9e4e6996de58d89c105484"><span data-offset-key="e05b2a5a9f9e4e6996de58d89c105484:0">  curl_easy_setopt(hnd, CURLOPT_SSH_KNOWNHOSTS,</span></span></p></div><div data-key="3daef237f699490f9de401ea45daad75"><p><span data-key="fc09cb91046e4fbd8ed5d4e301a1c78d"><span data-offset-key="fc09cb91046e4fbd8ed5d4e301a1c78d:0">                   "/home/daniel/.ssh/known_hosts");</span></span></p></div><div data-key="1982749114ef4285a7710255ba553c61"><p><span data-key="1ca86b33439b4d7db41901acc5561773"><span data-offset-key="1ca86b33439b4d7db41901acc5561773:0">  curl_easy_setopt(hnd, CURLOPT_TCP_KEEPALIVE, 1L);</span></span></p></div><div data-key="bd445540a8d249d087a1a319d3f5415b"><p><span data-key="d29cdb2f8aea44b3bd8d399f55898e52"><span data-offset-key="d29cdb2f8aea44b3bd8d399f55898e52:0">  /* Here is a list of options the curl code used that cannot get</span></span></p></div><div data-key="62c055e569d24d54aa228ada2d8a55b7"><p><span data-key="797d45247f2540c1a184b919266cec8c"><span data-offset-key="797d45247f2540c1a184b919266cec8c:0">     generated as source easily. You may select to either not use them or</span></span></p></div><div data-key="14e6b80b43884665a23b3eb9b5828bbd"><p><span data-key="c15fc10190f7494eabe00e85e528e80b"><span data-offset-key="c15fc10190f7494eabe00e85e528e80b:0">  CURLOPT_WRITEDATA set to a objectpointer</span></span></p></div><div data-key="4fb574047c984052bb1b03bb65e267ce"><p><span data-key="a56b41de3be44bab8a5efd6b74c0c41d"><span data-offset-key="a56b41de3be44bab8a5efd6b74c0c41d:0">  CURLOPT_WRITEFUNCTION set to a functionpointer</span></span></p></div><div data-key="88b35a78f38b4084a2730ce547474b43"><p><span data-key="6c0a83350bbd47f990ea28bf50ded54d"><span data-offset-key="6c0a83350bbd47f990ea28bf50ded54d:0">  CURLOPT_READDATA set to a objectpointer</span></span></p></div><div data-key="02d68ef58d984749ab902bc20227e1f2"><p><span data-key="e8cd292c1c8e43fca9828f6eb7aa0f18"><span data-offset-key="e8cd292c1c8e43fca9828f6eb7aa0f18:0">  CURLOPT_READFUNCTION set to a functionpointer</span></span></p></div><div data-key="f3cf5381c9ac4c3aae4dd4b998c7c31b"><p><span data-key="3e0546cbb1a34233af6f3a3cab21889e"><span data-offset-key="3e0546cbb1a34233af6f3a3cab21889e:0">  CURLOPT_SEEKDATA set to a objectpointer</span></span></p></div><div data-key="748d207f5adc49d4864567bad89f4512"><p><span data-key="54e3cb54e3974fe286cfa6c583c8579b"><span data-offset-key="54e3cb54e3974fe286cfa6c583c8579b:0">  CURLOPT_SEEKFUNCTION set to a functionpointer</span></span></p></div><div data-key="cb87e2715393471bb54640c81336f6f0"><p><span data-key="0e9d835bdd24490bbf376840eb71dbfd"><span data-offset-key="0e9d835bdd24490bbf376840eb71dbfd:0">  CURLOPT_ERRORBUFFER set to a objectpointer</span></span></p></div><div data-key="d6a3e8ec3abd4be2888a2535c1fa270c"><p><span data-key="7b5502f6f74f4262937789ab6a00da46"><span data-offset-key="7b5502f6f74f4262937789ab6a00da46:0">  CURLOPT_STDERR set to a objectpointer</span></span></p></div><div data-key="40fa451aa0e847a495c3b46b353d4c78"><p><span data-key="e27d65fea01c4c0db776f634cd7e84ad"><span data-offset-key="e27d65fea01c4c0db776f634cd7e84ad:0">  CURLOPT_HEADERFUNCTION set to a functionpointer</span></span></p></div><div data-key="1b5a82ecad7444049cf59a122c081836"><p><span data-key="b0f3600d73304954a5477afd878c5eee"><span data-offset-key="b0f3600d73304954a5477afd878c5eee:0">  CURLOPT_HEADERDATA set to a objectpointer</span></span></p></div><div data-key="9ed3fab823c844158e713df6f7f31813"><p><span data-key="615f6868b05c4d7093df23dc42e6006b"><span data-offset-key="615f6868b05c4d7093df23dc42e6006b:0">  ret = curl_easy_perform(hnd);</span></span></p></div><div data-key="a03056afb1b44a02a38590334c059f47"><p><span data-key="49d18ac9d6e44c71bdd81accf00c9c40"><span data-offset-key="49d18ac9d6e44c71bdd81accf00c9c40:0">/**** End of sample code ****/</span></span></p></div></div></div>]]></description>
        </item>
    </channel>
</rss>