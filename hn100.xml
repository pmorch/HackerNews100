<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 07 Oct 2025 19:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[German government comes out against Chat Control (271 pts)]]></title>
            <link>https://xcancel.com/paddi_hansen/status/1975595307800142205</link>
            <guid>45506143</guid>
            <pubDate>Tue, 07 Oct 2025 17:31:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xcancel.com/paddi_hansen/status/1975595307800142205">https://xcancel.com/paddi_hansen/status/1975595307800142205</a>, See on <a href="https://news.ycombinator.com/item?id=45506143">Hacker News</a></p>
Couldn't get https://xcancel.com/paddi_hansen/status/1975595307800142205: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[You're Doing Rails Wrong (240 pts)]]></title>
            <link>https://www.bananacurvingmachine.com/articles/you-re-doing-rails-wrong</link>
            <guid>45505692</guid>
            <pubDate>Tue, 07 Oct 2025 17:01:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bananacurvingmachine.com/articles/you-re-doing-rails-wrong">https://www.bananacurvingmachine.com/articles/you-re-doing-rails-wrong</a>, See on <a href="https://news.ycombinator.com/item?id=45505692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><em>Kevin</em>: Hey, have you tried Vite for Rails 8? It’s insanely fast.</p><p><em>John</em>: I’ve heard of it. Isn’t that a build tool? Didn’t Rails already come with one?</p><p><em>K</em>: Well, it did, but Vite is like… modern. You’ll need to install Node, npm, and configure a few scripts, but it’s totally worth it.</p><p><em>J</em>: Wait, Rails needs Node now?</p><p><em>K</em>: Well, yeah — if you want to use React. Everyone’s using React.</p><p><em>J</em>: Didn’t Rails have something for that?</p><p><em>K</em>: It did, but now you’ll want to use Vite with React Refresh so you get instant component reloads. And if you want TypeScript support, you’ll have to configure that too.</p><p><em>J</em>: Sounds… like a lot.</p><p><em>K</em>: Oh, not really. Just install Babel, configure your .babelrc, add vite-plugin-ruby, then you’ll want PostCSS for your styles.</p><p><em>J</em>: PostCSS?</p><p><em>K</em>: Yeah, and then Tailwind, obviously — you don’t want to write CSS like a peasant.</p><p><em>J</em>: Of course not.</p><p><em>K</em>: Then you’ll probably want to add ESLint and Prettier to make sure your code looks clean, and maybe Husky for pre-commit hooks.</p><p><em>J</em>: So... Vite, React, Babel, PostCSS, Tailwind, ESLint, Prettier, Husky. That’s it?</p><p><em>K</em>: Pretty much. Oh, unless you want server-side rendering — then you’ll need Next.js or Remix.</p><p><em>J</em>: Wait, we’re still talking about a Rails app, right?</p><p><em>K</em>: Yeah, but hybrid stacks are the way to go! You could also use StimulusReflex or Hotwire if you want reactive components without JS frameworks.</p><p><em>J</em>: StimulusReflex sounds like a Marvel character.</p><p><em>K</em>: Ha! No, it’s for real-time updates. But you’ll need ActionCable configured, Redis running, and—</p><p><em>J</em>: Redis?</p><p><em>K</em>: Yeah, you need a pub/sub layer. Don’t worry, it’s just another Docker container.</p><p><em>J</em>: Docker too?</p><p><em>K</em>: Yeah, to isolate your dependencies. And if you want everything reproducible, you’ll need Docker Compose, maybe Fly.io for deployment, and a build pipeline with GitHub Actions.</p><p><em>J</em>: That’s... quite a setup.</p><p><em>K</em>: It’s just modern web development, man. Keeps things simple. What are you doing?</p><p><em>J</em>: Just tinkering.</p><p><em>(John runs a single command. The app boots instantly, working forms, instant loading times, blazing fast navigation.)</em></p><p><em>K</em>: Wow, that looks like a pretty complex setup. What stack’s that?</p><p><em>J</em>: Vanilla Rails.</p><p><em>Just F#$%^&amp; use Rails.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Robin Williams' daughter pleads for people to stop sending AI videos of her dad (181 pts)]]></title>
            <link>https://www.bbc.co.uk/news/articles/c0r0erqk18jo</link>
            <guid>45505626</guid>
            <pubDate>Tue, 07 Oct 2025 16:56:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/articles/c0r0erqk18jo">https://www.bbc.co.uk/news/articles/c0r0erqk18jo</a>, See on <a href="https://news.ycombinator.com/item?id=45505626">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="main-content" data-testid="main-content"><article id="urn-bbc-ares--article-c0r0erqk18jo"><header data-component="headline-block"></header><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg.webp 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg.webp 976w" type="image/webp"><img alt="Robin and Zelda Williams pictured at a red carpet for Happy Feet 2 in 2011 in Los Angeles" src="https://ichef.bbci.co.uk/ace/standard/1920/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/6ba0/live/e26fba40-a38b-11f0-9d41-9dadd041fb76.jpg 976w" width="1920" height="1080.0617601646939"></picture></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>Robin and Zelda Williams, pictured in 2011</p></figcaption></figure></div><div data-component="text-block"><p><b>Zelda Williams, the daughter of Robin Williams, has asked people to stop sending her AI-generated videos of her father, the celebrated US actor and comic who died in 2014.</b></p><p>"Please, just stop sending me AI videos of Dad," Zelda Williams posted on her Instagram stories.</p><p>"Stop believing I wanna see it or that I'll understand, I don't and I won't. If you're just trying to troll me, I've seen way worse, I'll restrict and move on. </p><p>"But please, if you've got any decency, just stop doing this to him and to me, to everyone even, full stop. It's dumb, it's a waste of time and energy, and believe me, it's NOT what he'd want."</p></div><div data-component="text-block"><p>This is not the first time Zelda Williams, a film director, has criticised AI versions of her father, who took his own life in 2014 at his Californian home at the age of 63.</p><p>Williams, who was famous for films such as Good Morning Vietnam, Dead Poets Society and Mrs Doubtfire, was understood to have been battling depression at the time of his death.</p><p>In 2023, in an Instagram post supporting a campaign against AI by US media union SAG-Aftra, she described attempts at recreating his voice as "personally disturbing", while also pointing to the wider implications.</p></div><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg.webp 624w" type="image/webp"><img alt="Zelda and Robin Williams smiling together in 2007 at the People's Choice Awards " loading="lazy" src="https://ichef.bbci.co.uk/ace/standard/654/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/29f1/live/f1d83b60-a395-11f0-95e7-93813d968835.jpg 624w" width="654" height="655"></picture></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>Zelda and Robin Williams attended the 2007 People's Choice Awards in Los Angeles</p></figcaption></figure></div><div data-component="text-block"><p>Her post on Tuesday reflects a trend on social media, where images of people who have died are animated, featuring  captions like "bring your loved ones back to life". </p><p>Williams continued: "To watch the legacies of real people be condensed down to 'this vaguely looks and sounds like them so that's enough', just so other people can churn out horrible TikTok slop puppeteering them is maddening," she continued. </p><p>"You're not making art, you're making disgusting, over-processed hotdogs out of the lives of human beings, out of the history of art and music, and then shoving them down someone else's throat hoping they'll give you a little thumbs up and like it. Gross."</p><p>She concluded: "And for the love of EVERY THING, stop calling it 'the future,' AI is just badly recycling and regurgitating the past to be re-consumed. You are taking in the Human Centipede of content, and from the very very end of the line, all while the folks at the front laugh and laugh, consume and consume."</p><p>The Human Centipede is a reference to the 2009 body horror film.</p></div><p data-component="subheadline-block"><h2 id="She-sparks-conversation" tabindex="-1"><span role="text">'She sparks conversation'</span></h2></p><div data-component="text-block"><p>Her latest comments come in the wake of unease following the unveiling of "AI actor", Tilly Norwood. </p><p>Norwood was created by Dutch actor and comedian Eline Van der Velden, who reportedly said she wanted Norwood to become the "next Scarlett Johansson".</p><p>In a statement, SAG-Aftra said Norwood "is not an actor, it's a character generated by a computer program that was trained on the work of countless professional performers.</p><p>"It has no life experience to draw from, no emotion and, from what we've seen, audiences aren't interested in watching computer-generated content untethered from the human experience," the union added.</p><p>Actress Emily Blunt also recently said she found the idea of Norwood terrifying.</p><p>"That is really, really scary, Come on, agencies, don't do that. Please stop. Please stop taking away our human connection," she said on a podcast with Variety.</p><p><a href="https://deadline.com/2025/09/creator-ai-actress-tilly-norwood-statement-backlash-1236564727/">Van der Velden later said in a statement<span>, <!-- -->external</span></a>: "To those who have expressed anger over the creation of my AI character, Tilly Norwood, she is not a replacement for a human being, but a creative work – a piece of art. </p><p>"Like many forms of art before her, she sparks conversation, and that in itself shows the power of creativity."</p></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Police Said They Surveilled Woman Who Had an Abortion for Her 'Safety.' (254 pts)]]></title>
            <link>https://www.404media.co/police-said-they-surveilled-woman-who-had-an-abortion-for-her-safety-court-records-show-they-considered-charging-her-with-a-crime/</link>
            <guid>45505103</guid>
            <pubDate>Tue, 07 Oct 2025 16:18:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/police-said-they-surveilled-woman-who-had-an-abortion-for-her-safety-court-records-show-they-considered-charging-her-with-a-crime/">https://www.404media.co/police-said-they-surveilled-woman-who-had-an-abortion-for-her-safety-court-records-show-they-considered-charging-her-with-a-crime/</a>, See on <a href="https://news.ycombinator.com/item?id=45505103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
      
  <div>
    
    <p>Court records show that the narrative Flock and a Texas Sheriff's Office has told the public isn't the whole story, and that police were conducting a 'death investigation' into the abortion.</p>
  </div>
    <figure>
      <img data-srcset="/content/images/size/w300/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 300w,
                /content/images/size/w600/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 600w,
                /content/images/size/w1000/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 1000w,
                /content/images/size/w2000/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 2000w" data-sizes="(max-width: 800px) 50vw,
                (max-width: 1170px) 60vw,
                1400px" data-src="/content/images/size/w2000/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png" src="https://www.404media.co/content/images/size/w2000/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png" alt="Police Said They Surveilled Woman Who Had an Abortion for Her 'Safety.' Court Records Show They Considered Charging Her With a Crime" srcset="https://www.404media.co/content/images/size/w300/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 300w,
                https://www.404media.co/content/images/size/w600/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 600w,
                https://www.404media.co/content/images/size/w1000/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 1000w,
                https://www.404media.co/content/images/size/w2000/2025/10/CleanShot-2025-10-07-at-05.46.26@2x.png 2000w">
        <figcaption><span>Image: Flock, Collage by Jason Koebler</span></figcaption>
    </figure>
</div>
      <div>
        <article>
          <div>
              <div>
  
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>In May, <a href="https://www.404media.co/a-texas-cop-searched-license-plate-cameras-nationwide-for-a-woman-who-got-an-abortion/"><u>404 Media reported</u></a> that the Johnson County Sheriff’s Office in Texas searched a nationwide network of Flock cameras, a powerful AI-enabled license plate surveillance tool, to look for a woman who self-administered an abortion. At the time, the sheriff told us that the search had nothing to do with criminality and that they were concerned solely about the woman’s safety, specifically the idea that she could be bleeding to death from the abortion. Flock itself said “she was never under criminal investigation by Johnson County. She was being searched for as a missing person, not as a suspect of a crime.”</p>
</div>

<div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div>          </div>
        </article>
      </div>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Timelinize – Privately organize your own data from everywhere, locally (170 pts)]]></title>
            <link>https://timelinize.com</link>
            <guid>45504973</guid>
            <pubDate>Tue, 07 Oct 2025 16:10:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timelinize.com">https://timelinize.com</a>, See on <a href="https://news.ycombinator.com/item?id=45504973">Hacker News</a></p>
<div id="readability-page-1" class="page">
		<header>
	
	
</header>

		<div>
			
			<div>
				<h2>Discover your timeline</h2>
				<p>
						Timelinize <span>("time-lynn-eyes")</span> is an open source personal archival suite, designed for modern family history. It organizes all your data onto a single, unified timeline on your own computer.
					</p>
			</div>
			
			<!-- doodle modified from https://yuanchuan.dev/time-based-css-animations -->
<css-doodle>
	
</css-doodle>
			
		</div>

		<div>
				<p>
					 <iframe src="https://www.youtube-nocookie.com/embed/B7h_oYAZQbo?si=BYJr4PGa-5FLIRaV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
				</p>

				

				<h2>A place for everything...</h2>
				<p>
					Photos, videos, text messages, locations, chats, social media, and more. Timelinize unifies it all.
				</p>
				<p>
					By adding all your data, Timelinize documents your family's life with more detail and privacy, and gives you a more complete view of your story, than standard photo library and journaling apps.
				</p>

				

				<h2>...and everything at home.</h2>
				<p>
					Most apps store your data "in the cloud" and <i>out of your control</i>. What if you lost access to your Google/Apple/Facebook accounts, or your phone? By bringing that data home to your own computer, Timelinize preserves a richer story than any one app or service can do alone.
				</p>
				<p>
					Timelinize isn't a replacement for the apps and services you already use, so you don't need to disrupt your way of life. Instead, it "sits behind" what you already use to become the permanent private archive of your working copy from:
				</p>


				
			</div>

			<div>
					<h2>Explore more</h2>

					<p>
						With several projections for your data, it's easy to keep moments alive that would otherwise be forgotten, rotting on a hard drive in your closet... or in a bigcorp's cloud.
					</p>

					<div>
						<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M12 17v4"></path><path d="M10 20l4 -2"></path><path d="M10 18l4 2"></path><path d="M5 17v4"></path><path d="M3 20l4 -2"></path><path d="M3 18l4 2"></path><path d="M19 17v4"></path><path d="M17 20l4 -2"></path><path d="M17 18l4 2"></path><path d="M9 6a3 3 0 1 0 6 0a3 3 0 0 0 -6 0"></path><path d="M7 14a2 2 0 0 1 2 -2h6a2 2 0 0 1 2 2"></path></svg>
						<p>
							The images below show a real timeline with personal data, so the application was configured to obfuscate images, names, some locations, and other personal information. Your own timeline will appear normally.
						</p>
					</div>

					<div>
						<div>
							<h3>
								<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M4 16l6 -7l5 5l5 -6"></path><path d="M15 14m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0"></path><path d="M10 9m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0"></path><path d="M4 16m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0"></path><path d="M20 8m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0"></path></svg>
								Timeline
							</h3>
							<p>
								The timeline view semantically groups all your data into a single linear layout. Easily see what occurred on a specific day in the order it happened.
							</p>
							<figure>
								<a href="https://timelinize.com/resources/images/timeline.jpg" target="_blank"><img src="https://timelinize.com/resources/images/timeline.jpg"></a>
								<figcaption>A timeline showing: a multimedia message sent, GPS tracks on a map, a text message received, Twitter messages exchanged, and photos/videos taken.</figcaption>
							</figure>
						</div>
						<div>
							<h3>
								<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M12 18.5l-3 -1.5l-6 3v-13l6 -3l6 3l6 -3v7.5"></path><path d="M9 4v13"></path><path d="M15 7v5.5"></path><path d="M21.121 20.121a3 3 0 1 0 -4.242 0c.418 .419 1.125 1.045 2.121 1.879c1.051 -.89 1.759 -1.516 2.121 -1.879z"></path><path d="M19 18v.01"></path></svg>
								Map
							</h3>
							<p>
								Visualize your data on a huge, beautiful map of the world that plots points when and where they happened, even for data that doesn't have coordinates (like text messages and emails).
							</p>
							<figure>
								<a href="https://timelinize.com/resources/images/map.jpg" target="_blank"><img src="https://timelinize.com/resources/images/map.jpg"></a>
								<figcaption>The world map renders your path with a colored line indicating the passage of time.</figcaption>
							</figure>
							<figure>
								<a href="https://timelinize.com/resources/images/map-augment.jpg" target="_blank"><img src="https://timelinize.com/resources/images/map-augment.jpg"></a>
								<figcaption>Because Timelinize is entity-aware, it can even map data points without coordinates, like this text message received while I was at the beach.</figcaption>
							</figure>
						</div>
						<div>
							<h3>
								<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M21 14l-3 -3h-7a1 1 0 0 1 -1 -1v-6a1 1 0 0 1 1 -1h9a1 1 0 0 1 1 1v10"></path><path d="M14 15v2a1 1 0 0 1 -1 1h-7l-3 3v-10a1 1 0 0 1 1 -1h2"></path></svg>
								Conversations
							</h3>
							<p>
								Follow connections with people across all kinds of chats and messages. Combine conversations with people across platforms into one view.
							</p>
							<figure>
								<a href="https://timelinize.com/resources/images/conversation.jpg" target="_blank"><img src="https://timelinize.com/resources/images/conversation.jpg"></a>
								<figcaption>Example of a conversation that unites text messages and Facebook messages.</figcaption>
							</figure>
						</div>
						<div>
							<h3>
								<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M7 3m0 2.667a2.667 2.667 0 0 1 2.667 -2.667h8.666a2.667 2.667 0 0 1 2.667 2.667v8.666a2.667 2.667 0 0 1 -2.667 2.667h-8.666a2.667 2.667 0 0 1 -2.667 -2.667z"></path><path d="M4.012 7.26a2.005 2.005 0 0 0 -1.012 1.737v10c0 1.1 .9 2 2 2h10c.75 0 1.158 -.385 1.5 -1"></path><path d="M17 7h.01"></path><path d="M7 13l3.644 -3.644a1.21 1.21 0 0 1 1.712 0l3.644 3.644"></path><path d="M15 12l1.644 -1.644a1.21 1.21 0 0 1 1.712 0l2.644 2.644"></path></svg>
								Gallery
							</h3>
							<p>
								Browse through a rich display of photos and videos from photo libraries, messages sent and received, and other sources.
							</p>
							<figure>
								<a href="https://timelinize.com/resources/images/gallery.jpg" target="_blank"><img src="https://timelinize.com/resources/images/gallery.jpg"></a>
								<figcaption>You can view images and videos from all data sources in the gallery.</figcaption>
							</figure>
						</div>
					</div>
	
					<h2>The ultimate personal archival suite</h2>

					<div>
						<div>
							<h3>Flexible, high-speed imports</h3>
							<p>
								Add millions of data points to your timeline in a matter of minutes. You get full control over background jobs like imports, thumbnails, and embeddings.
							</p>
						</div>
						<div>
							<figure>
								<a href="https://timelinize.com/resources/images/import.jpg" target="_blank"><img src="https://timelinize.com/resources/images/import.jpg"></a>
								<figcaption>Watch the progress of imports with live charts and tables showing a sample of what is being imported.</figcaption>
							</figure>
						</div>
					</div>
					<div>
						<div>
							<h3>Pictures come alive with motion</h3>
							<p>
								Timelinize supports playing "live photos" (or "motion photos") for photos taken on Apple, Google, and Samsung devices.
							</p>
						</div>
						<p>
							<figure>
								<video src="https://timelinize.com/resources/videos/motion-pictures.mp4" loop="" muted="" autoplay="" playsinline=""></video>
								<figcaption>Live photos can be easily toggled so you can either view the higher-quality still image, or the video snippet.</figcaption>
							</figure>
						</p>
					</div>
					<div>
						<div>
							<h3>Entity-aware processing</h3>
							<p>
								Timelinize specializes in combining data from multiple sets and sources. It can identify people and other entities across data sources by their attributes. If a person or contact appears in multiple data sets, it will automatically merge them if possible. If not, you can easily merge entities with the click of a button.
							</p>
						</div>
						<div>
							<figure>
								<a href="https://timelinize.com/resources/images/merge-entities.jpg" target="_blank"><img src="https://timelinize.com/resources/images/merge-entities.jpg"></a>
								<figcaption>Manually merge duplicate people/contacts in your timeline for optimal comprehension.</figcaption>
							</figure>
						</div>
					</div>
					<div>
						<div>
							<h3>Magically geo-locate data without coordinates</h3>
							<p>
								Because Timelinize is entity-aware, it can project data points onto a map even without coordinate data. If a geolocated point is known for an entity around the same time of others of that entity's data points, it will appear on the map.
							</p>
						</div>
						<div>
							<figure>
								<a href="https://timelinize.com/resources/images/map-augment-2.jpg" target="_blank"><img src="https://timelinize.com/resources/images/map-augment-2.jpg"></a>
								<figcaption>This message from social media has no geocoordinates, but we can still see it on the map when and where it was received.</figcaption>
							</figure>
						</div>
					</div>
					<div>
						<div>
							<h3>Make your map pop</h3>
							<p>
								Customize the map to change its theme, layers, and even make it 3D.
							</p>
						</div>
						<div>
							<figure>
								<a href="https://timelinize.com/resources/images/map-3d.jpg" target="_blank"><img src="https://timelinize.com/resources/images/map-3d.jpg"></a>
								<figcaption>A 3D map with the satellite layer really brings this hike to life and makes it much easier to appreciate.</figcaption>
							</figure>
						</div>
					</div>
					<div>
						<div>
							<h3>See your hot spots at a glance</h3>
							<p>
								The heatmap shows where your data is concentrated. It smoothly blends as you zoom in and out.
							</p>
						</div>
						<div>
							<figure>
								<a href="https://timelinize.com/resources/images/heatmap.jpg" target="_blank"><img src="https://timelinize.com/resources/images/heatmap.jpg"></a>
								<figcaption>Heatmaps are comprised of a sampling of your data points and ensure they all have some visibility.</figcaption>
							</figure>
						</div>
					</div>
					<div>
						<div>
							<h3>Combine data sets</h3>
							<p>
								Customize what defines a duplicate item, and how to handle that, with a fine degree of control—perfect for merging separate, disparate data sets.
							</p>
						</div>
						<div>
							<figure>
								<a href="https://timelinize.com/resources/images/import-settings.jpg" target="_blank"><img src="https://timelinize.com/resources/images/import-settings.jpg"></a>
								<figcaption>Advanced import settings give you a fine degree of control during imports: what makes an item unique, what should be updated, etc?</figcaption>
							</figure>
						</div>
					</div>
					<div>
						<div>
							<h3>Unified conversations</h3>
							<p>
								An implicit conversation is discovered when a data source links items and entities with a "sent to" relation. You can easily view conversations between entities across modalities in a single scroll: chats, emails, messages, texts, and more.
							</p>
						</div>
						<div>
							<figure>
								<a href="https://timelinize.com/resources/images/conversations.jpg" target="_blank"><img src="https://timelinize.com/resources/images/conversations.jpg"></a>
								<figcaption>Conversations are made of anything sent to anyone, grouped by participants.</figcaption>
							</figure>
						</div>
					</div>

				</div>

			<section>
				<div>
					<h2>Features for humans</h2>

					<p>Since I need this to function well for my own family, I have tried to give special attention to less-visible aspects of this application, such as:</p>

					<div>
						<div>
							<h3>Advanced location processor</h3>
							<p>
								Timelinize deduplicates, denoises, clusters, and simplifies location data for optimal preservation, with an algorithm that subjectively performs better than Google Maps Timeline.
							</p>
						</div>
						<div>
							<h3>CLI and HTTP API</h3>
							<p>
								For nerds like me: you can use Timelinize through its CLI, which mirrors all the functions of the HTTP API used by the frontend.
							</p>
						</div>
						<div>
							<h3>Semantic search</h3>
							<p>
								Search for pictures and messages by describing them, or find similar items to what you're viewing.
							</p>
						</div>
						<div>
							<h3>Thumbnails and transcoding</h3>
							<p>
								All items are stored verbatim, then thumbnails are generated for all images and video media, which are stored separately. Your original data is not modified.
							</p>
						</div>
						<div>
							<h3>Flexible schema</h3>
							<p>
								The database schema has been meticulously designed and refined to be as adaptable as possible.
							</p>
						</div>
					</div>

					<h2>A timeline to the future</h2>

					<p>Timelinize will continue to develop and evolve. In the future, I anticipate the following capabilities:</p>

					<div>
						<div>
							<h3>Create using your timeline</h3>
							<p>
								Annotate your timeline, write rich stories with live embeddings from your timeline data, or make physical media like photo books (but with more than just photos!).
							</p>
						</div>
						<div>
							<h3>Augment with public data</h3>
							<p>
								Add context to your timeline with additional public timelines which have weather, local/regional news, and global events.
							</p>
						</div>
						<div>
							<h3>Secure data sharing</h3>
							<p>
								Securely and privately share parts of your timeline with trusted friends and family members, directly from your computer to theirs.
							</p>
						</div>
						<div>
							<h3>Mobile apps and first-class sync</h3>
							<p>
								Right now, Timelinize sits "behind" the apps and platforms you already use. But in the future, you could sync data directly to your timeline as it is originated.
							</p>
						</div>
					</div>

					<h2>Meet your personal timeline</h2>

					<p>Collect your data from <a href="https://timelinize.com/docs/data-preparation#data-sources">various sources</a>. Import it with a few clicks. Within minutes, explore millions of your data points in several intuitive ways.</p>

					<div>
						<div>
							<h3>Self-contained, portable repositories</h3>
							<p>
								Imported data is copied into your timeline folder, ensuring long-term stability and integrity. Timelines are portable—you can copy them or move them to other devices and computers.
							</p>
						</div>
						<div>
							<h3>No proprietary storage scheme</h3>
							<p>
								Your timeline is simply a folder on disk containing a SQLite database alongside your data files. You can freely explore it with other tooling, so you're not locked into Timelinize.
							</p>
						</div>
						<div>
							<h3>Works with data you're already generating</h3>
							<p>
								Unlike writing a journal, you don't have to take extra time to create content. You're already making the data your timeline can display! And it doesn't replace your current workflow or apps.
							</p>
						</div>
					</div>

				</div>

				<iframe src="https://www.youtube-nocookie.com/embed/VRhtEjz6hws?si=H5FqU6QHyDHC4RW-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
			</section>

			<!--
				<p>
					Inquiries: <a href="mailto:%6d%61%74%74%40%64%79%61%6e%69%6d%2e%63%6f%6d" class="email">matt@dya<em>antispam</em>nim<em>.nospam</em>.com</a>
				</p>
			-->


			<!-- All keepsakes, no deepfakes. -->

		
		
	
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[IKEA Catalogs 1951-2021 (171 pts)]]></title>
            <link>https://ikeamuseum.com/en/explore/ikea-catalogue/</link>
            <guid>45504470</guid>
            <pubDate>Tue, 07 Oct 2025 15:35:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ikeamuseum.com/en/explore/ikea-catalogue/">https://ikeamuseum.com/en/explore/ikea-catalogue/</a>, See on <a href="https://news.ycombinator.com/item?id=45504470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    
    <div>
        <div>
                
                <h2>
                    IKEA catalogue                </h2>
                                    
	<div>
		<p>For over 70 years, the IKEA catalogue was produced in Älmhult, constantly growing in number, scope and distribution. From the 1950s when Ingvar Kamprad wrote most of the texts himself, via the poppy, somewhat radical 1970s and all the way into the scaled-down 2000s – the IKEA catalogue always captured the spirit of the time. The 2021 IKEA catalogue was the very last one printed on paper.</p>
		
	</div>
                  
            </div>                    
                        </div>
			<div>
					<div>
					<p>Good question! We know that a lot of people are curious about what the IKEA catalogue has looked like through the ages. The catalogue has always reflected the age and its views on interior design and everyday living, especially in Sweden, but in recent decades also internationally. The catalogue was in print for 70 years, and by digitising all the catalogues we could make them available to everybody. Making the story of IKEA available to as many people as possible is our main task at IKEA Museum. So we hope that the catalogues will bring some joy and nostalgia, and maybe even a few surprises.</p>
				</div>
					<div>
					<p>Just like the perception of the home, the catalogue has changed dramatically since 1951, when it was first published. Look in the older catalogues and you’ll be amazed at what you find. In fact, you’ll probably even have a giggle or two. In the 1950s and 1960s, there are rarely any people in the pictures, and never any children. But in the 1970s there are children playing all over the home, you can see adults smoking and even the occasional political poster on the wall. Browse on to the 1980s IKEA catalogues and the trends have changed again, with shiny fabrics and other fancy materials. In the 1990s homes become more scaled-down and clearly inspired by a Scandinavian tradition. In this way, the IKEA catalogues are a kind of time capsule for you to travel in. And who knows? When we look back at the most recent catalogues in 10 or 20 years’ time, we’ll probably shake our heads and give a sigh.</p>
				</div>
					<div>
					<p>IKEA Museum decided to start with the Swedish catalogue as it has been around the longest. In the future, we hope to be able to digitise catalogues from more countries in more languages. </p>
				</div>
					<div>
					<p>No. The IKEA catalogue has always only shown a selection of what’s available in the stores. The catalogues from the 1970s and onwards show around 30–50 per cent of the entire range. The products that are not featured are generally smaller ones in textiles, decorations and lighting. Temporary collections are rarely included either. But the farther back you go, the higher a percentage of the range can be found in the catalogue.</p>
				</div>
					<div>
					<p>Yes, but the older a product is, the harder it may be to find information about it. If you have a specific question about a product, we’re happy to help you out if we can. But 70 years is a long time, so we can’t promise anything. While you’re waiting for our response you can always browse through the catalogues – the product texts that are there are quite detailed. You can search in the catalogues by product name and product type. There are also various stories about different products on our site, and more are constantly being added.<br>
<a href="https://ikeamuseum.com/en/explore/product-stories/">Browse through stories about IKEA products from 7 decades</a>. </p>
				</div>
					<div>
					<p>IKEA was founded in the 1940s, so why are you showing no catalogues from before 1951?<br>
The first catalogue did not come out until 1951. Before that, IKEA was a mail order company that didn’t sell furniture, but pens, clocks, electric razors, wallets and bags. At that time, the range was only presented in a small mail order brochure called ikéa-nytt (literally ikéa news). Sometimes it was distributed as a supplement in farming paper <i>Jordbrukarnas Föreningsblad</i>, which reached hundreds of thousands of people in the Swedish countryside. From autumn 1948 Ingvar Kamprad started including furniture in the range, and things quickly grew from there. In the 1950 ikéa-nytt, as many as six of the 18 pages featured furniture. And when you look at the 1951 catalogue, you’ll see that there are no more pens and wallets. Ingvar Kamprad was now truly focusing on home furnishing, and shelving the rest.<br>
<a href="https://ikeamuseum.com/en/explore/the-story-of-ikea/ikea-news/">Browse through all issues of ikéa-nytt</a>.</p>
				</div>
					<div>
					<p>Not really. We do have a few copies of each year’s IKEA catalogue in our archives, which we’re saving for posterity. They should be handled as little as possible to keep them in good condition, so we’ve made the catalogues available digitally, both online and on monitors at IKEA Museum. You can browse through those as much as you like!</p>
				</div>
					<div>
					<p>Yes you can. The easiest way to share the catalogues is to click on the arrow at the bottom left corner for each catalogue, or in the left-hand menu once you’ve started browsing through. This will copy a link which you can share on a website or social media. If you would like to download and publish on your own digital platform, you can share a maximum of three complete digital catalogues. Don’t forget to state the copyright details, “© Inter IKEA Systems B.V.”, the catalogue year, and the link <a href="https://ikeamuseum.com/en/explore/ikea-catalogue/">/en/explore/ikea-catalogue/</a> so that anyone interested can find out more. You may not publish the digital catalogues for commercial purposes.</p>
				</div>
					<div>
					<p>Absolutely! You can share up to 30 images from the catalogues on your own digital platform, such as a blog, on Instagram or similar (as long as it’s not for commercial purposes). Don’t forget to state the copyright details, “© Inter IKEA Systems B.V.”, the catalogue year, and the link <a href="https://ikeamuseum.com/en/explore/ikea-catalogue/">/en/explore/ikea-catalogue/</a> so that anyone interested can find out more.</p>
				</div>
					<div>
					<p>Yes! You can find all press material, including images, information about current exhibitions and much more, in the <a href="https://ikeamuseum.com/en/about/press-room/">IKEA Museum press room</a>.</p>
				</div>
					<div>
					<p>At the moment we have a good amount of catalogues in all languages at the museum, and do not need any more. Having said that, please contact us anyway if you’ve been collecting catalogues for several decades, or if you have any other material you think might be of interest to IKEA Museum.</p>
				</div>
					<div>
					<p>Unfortunately not. We sometimes wish we did, as we handle quite a lot of old products that may need putting together and taking apart.</p>
				</div>
			</div>
	    
    <template id="compass-search-result-item">
	<div>
		<a href="/en/explore/ikea-catalogue/%URL%" class="card card--thumbnail-left card--thumbnail-small card--hover-effect ">
			<div>
				<div class="card__thumbnail">
					<img src="/en/explore/ikea-catalogue/%THUMBNAIL%" loading="lazy">
				</div>
			</div>
			<div class="card__text">
				<div class="card__eyebrow fs-15">%EYEBROW%</div>
				<div class="card__heading">
					<span class="strong fs-17">%HEADING%</span>
				</div>
			</div>
		</a>
	</div>
</template>


	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No account? No Windows 11, Microsoft says as another loophole snaps shut (316 pts)]]></title>
            <link>https://www.theregister.com/2025/10/07/windows_11_local_account_loophole/</link>
            <guid>45503726</guid>
            <pubDate>Tue, 07 Oct 2025 14:45:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/10/07/windows_11_local_account_loophole/">https://www.theregister.com/2025/10/07/windows_11_local_account_loophole/</a>, See on <a href="https://news.ycombinator.com/item?id=45503726">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Microsoft is closing a popular loophole that allowed users to install Windows 11 without a Microsoft account.</p>
<p>The change has appeared in <a target="_blank" rel="nofollow" href="https://blogs.windows.com/windows-insider/2025/10/06/announcing-windows-11-insider-preview-build-26220-6772-dev-channel/">recent Insider builds</a> of Windows 11, indicating it is likely to be included in the production version soon.</p>
<p>Microsoft refers to these loopholes as "known mechanisms" and is talking about local commands in this instance. You can learn all about these in our <a target="_blank" href="https://www.theregister.com/2025/08/05/set_up_windows11_local_account/">piece</a> for getting Windows 11 installed with a local account, but suffice to say <code>start ms-cxh:localonly</code> is no more.</p>

    

<p>"While these mechanisms were often used to bypass Microsoft account setup, they also inadvertently skip critical setup screens, potentially causing users to exit OOBE with a device that is not fully configured for use," Microsoft said.</p>

        


        

<p>"Users will need to complete OOBE with internet and a Microsoft account, to ensure [the] device is set up correctly."</p>
<ul>

<li><a href="https://www.theregister.com/2025/10/02/windows_10_statcounter/">Windows 10 refuses to go gentle into that good night</a></li>

<li><a href="https://www.theregister.com/2025/10/01/hundreds_businesses_urge_microsoft_not_end_win10_support/">Hundreds of orgs urge Microsoft: don't kill off free Windows 10 updates</a></li>

<li><a href="https://www.theregister.com/2025/10/01/windows_11_25h2/">Windows 11 25H2 is mostly 24H2 with bits bolted on or ripped out</a></li>

<li><a href="https://www.theregister.com/2025/09/30/windows_11_healthcare/">Healthcare lags in Windows 11 upgrades – and lives may depend on it</a></li>
</ul>
<p>As far as Redmond is concerned, this is all for the user's own good. It is also important to note that managed devices are not directly affected, just hardware that users want to get running with Windows 11 without having to deal with a Microsoft Account during setup.</p>
<p>The change is part of Microsoft's ongoing game of Whac-A-Mole with users trying to find ways of avoiding its online services. In <a target="_blank" href="https://www.theregister.com/2025/03/31/windows_11_insiders/">March</a>, it removed the <code>bypassnro.cmd</code> script that allowed users to get through the Windows 11 setup without needing an internet connection. That time, Microsoft said the change was to "enhance security and user experience of Windows 11."</p>
<p>There remain a number of ways to avoid the Microsoft account requirement during setup, including setting up an unattended installation, but these are more complicated. It is also clear that Microsoft is determined to continue closing loopholes where it can.</p>

        

<p>It is getting increasingly difficult to use Windows 11 on an unmanaged device without a Microsoft account. Users who don't want to sign up should perhaps consider whether it's time to look at an alternative operating system instead. ®</p>                                


                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[3M May Escape Toxic Chemical, PFAS Manufacturing Legacy (129 pts)]]></title>
            <link>https://www.bloomberg.com/features/2025-3m-pfas-toxic-legacy-turnaround/</link>
            <guid>45502748</guid>
            <pubDate>Tue, 07 Oct 2025 13:22:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/features/2025-3m-pfas-toxic-legacy-turnaround/">https://www.bloomberg.com/features/2025-3m-pfas-toxic-legacy-turnaround/</a>, See on <a href="https://news.ycombinator.com/item?id=45502748">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/features/2025-3m-pfas-toxic-legacy-turnaround/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[America is now one big bet on AI (149 pts)]]></title>
            <link>https://www.ft.com/content/6cc87bd9-cb2f-4f82-99c5-c38748986a2e</link>
            <guid>45502706</guid>
            <pubDate>Tue, 07 Oct 2025 13:18:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/6cc87bd9-cb2f-4f82-99c5-c38748986a2e">https://www.ft.com/content/6cc87bd9-cb2f-4f82-99c5-c38748986a2e</a>, See on <a href="https://news.ycombinator.com/item?id=45502706">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="site-content"><div id="barrier-page"><div id="heroOffer-Hero offers-5a5c6ce5-a7a2-4795-bf77-6ed47e08c830" data-component="heroOffer" data-component-unique-name="Hero offers" data-o3-theme="inverse"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><div><h2><span><span>Save 40% on Standard Digital</span></span></h2><p><span><span><span>was </span><span>Dkr4188</span><span> </span><span>now </span><span>Dkr2499</span><span> for your first year</span></span></span></p></div><p><span><span>Save now on essential digital access to quality FT journalism on any device. Saving based on monthly annualised price.</span></span></p></div></div><div id="recommendedOffers-Recommended Offers" data-component="recommendedOffers" data-component-unique-name="Recommended Offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_trial.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Trial</h3></p></div><p><span><span>Dkr10</span><span> for 4 weeks</span></span></p><p><span><span>Then </span><span>Dkr535</span><span> per month. Complete digital access to quality FT journalism on any device. Cancel or change your plan anytime during your trial.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_premium.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Premium Digital</h3></p></div><p><span><span>Dkr535</span><span> per month</span></span></p><p><span><span>Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_bundle.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Print + Premium Digital</h3></p></div><p><span><span>was </span><span>Dkr5999</span><span> </span><span>now </span><span>Dkr5135</span><span> for your first year</span></span></p><p><span><span>Get Premium &amp; FT Weekend Print edition for the price of Premium. Complete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.</span></span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription Options Offers API" data-o3-theme="inverse"><h2>Explore our full range of subscriptions.</h2><div><div><div><h3>For individuals</h3></div><p>Discover all the plans currently available in your country</p></div><div><div><h3> For multiple readers</h3></div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT" data-o3-theme="inverse"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=6cc87bd9-cb2f-4f82-99c5-c38748986a2e" aria-label="Find out why the FT">Find out why</a></p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Erlang ARM32 JIT is born (127 pts)]]></title>
            <link>https://www.grisp.org/blog/posts/2025-10-07-jit-arm32.3</link>
            <guid>45502543</guid>
            <pubDate>Tue, 07 Oct 2025 13:00:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.grisp.org/blog/posts/2025-10-07-jit-arm32.3">https://www.grisp.org/blog/posts/2025-10-07-jit-arm32.3</a>, See on <a href="https://news.ycombinator.com/item?id=45502543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-39a288b8=""><p><em>A blog series recounting our adventures in the quest to port the BEAM JIT to the ARM32-bit architecture.</em></p><p><em>This work is made possible thanks to funding from the <a href="https://www.erlef.org/" target="_blank" rel="noreferrer">Erlang Ecosystem Foundation</a> and the ongoing support of its <a href="https://www.erlef.org/wg/embedded" target="_blank" rel="noreferrer">Embedded Working Group</a>.</em></p><p><img src="https://www.grisp.org/images/blog/eef-logo.svg" alt="EEF Logo" width="100px"></p><hr><h2 id="the-erlang-arm32-jit-is-born" tabindex="-1">The Erlang ARM32 JIT is born! <a href="#the-erlang-arm32-jit-is-born" aria-label="Permalink to &quot;The Erlang ARM32 JIT is born!&quot;">​</a></h2><p>This week we finally achieved our first milestone in developing the ARM32 JIT. We executed our first Erlang function through JITted ARM32 machine code!</p><div><p><span>shell</span></p><pre tabindex="0"><code><span><span>    ~/arm32-jit$</span><span> qemu-arm</span><span> -L</span><span> /usr/arm-linux-gnueabihf</span><span> ./otp/RELEASE/erts-15.0/bin/beam.smp</span><span> -S</span><span> 1:1</span><span> -SDcpu</span><span> 1:1</span><span> -SDio</span><span> 1</span><span> -JDdump</span><span> true</span><span> -JMsingle</span><span>     true</span><span> --</span><span> -root</span><span> /home/arm32-jit/otp/RELEASE</span><span> -progname</span><span> erl</span><span> -home</span><span> /home</span></span>
<span><span>    ~/arm32-jit$</span><span> echo</span><span> $?</span></span>
<span><span>    42</span></span></code></pre></div><p>The BEAM successfully runs and terminates with error code 42! That 42 comes from an Erlang function, just-in-time compiled by our ARM32 JIT!</p><p>Announcement is done! All code is available at <a href="https://github.com/stritzinger/otp/tree/arm32-jit" target="_blank" rel="noreferrer">https://github.com/stritzinger/otp/tree/arm32-jit</a></p><p>Keep reading for a lot of interesting details!</p><h2 id="the-first-piece-of-erlang-code" tabindex="-1">The first piece of Erlang code <a href="#the-first-piece-of-erlang-code" aria-label="Permalink to &quot;The first piece of Erlang code&quot;">​</a></h2><div><p><span>erlang</span></p><pre tabindex="0"><code><span><span>-</span><span>module</span><span>(</span><span>hello</span><span>).</span></span>
<span><span>-</span><span>export</span><span>([</span><span>start</span><span>/</span><span>2</span><span>]).</span></span>
<span></span>
<span><span>start</span><span>(_BootMod, _BootArgs) </span><span>-&gt;</span></span>
<span><span>    halt</span><span>(</span><span>42</span><span>, [{</span><span>flush</span><span>, </span><span>false</span><span>}]).</span></span></code></pre></div><p>This is <code>hello.erl</code> that contains a <code>start/2</code> function. The function head mimics the <code>erl_init:start/2</code> function, which is the entry point of the first Erlang process. We replaced <code>erl_init:start/2</code> with <code>hello:start/2</code> in the <code>erl_init.c</code> module of the BEAM VM. This way, we forced the runtime to execute this Erlang function.</p><p><code>hello:start/2</code> is very simple as it just calls the <code>erlang:halt/2</code>. This function is a <strong>BIF</strong> (Built-in Function) that executes C code, part of the BEAM VM. This code executes an ordered shutdown of the BEAM and allows us to customize the error code, in this case: <code>42</code>.</p><p>(Why <code>{flush, false}</code>? At the time I am writing this, letting it be true causes a segmentation fault EHEH)</p><p>Obviously, we need to compile this Erlang module, but I will also generate the BEAM assembly so we can have a look at what we will have to deal with.</p><div><p><span>erlang</span></p><pre tabindex="0"><code><span><span>{</span><span>module</span><span>, </span><span>hello</span><span>}.  </span><span>%% version = 0</span></span>
<span><span>{</span><span>exports</span><span>, [{</span><span>module_info</span><span>,</span><span>0</span><span>},{</span><span>module_info</span><span>,</span><span>1</span><span>},{</span><span>start</span><span>,</span><span>2</span><span>}]}.</span></span>
<span><span>{</span><span>attributes</span><span>, []}.</span></span>
<span><span>{</span><span>labels</span><span>, </span><span>7</span><span>}.</span></span>
<span></span>
<span><span>{</span><span>function</span><span>, </span><span>start</span><span>, </span><span>2</span><span>, </span><span>2</span><span>}.</span></span>
<span><span>  {</span><span>label</span><span>,</span><span>1</span><span>}.</span></span>
<span><span>    {</span><span>line</span><span>,[{</span><span>location</span><span>,</span><span>"erts/preloaded/src/hello.erl"</span><span>,</span><span>74</span><span>}]}.</span></span>
<span><span>    {</span><span>func_info</span><span>,{</span><span>atom</span><span>,</span><span>hello</span><span>},{</span><span>atom</span><span>,</span><span>start</span><span>},</span><span>2</span><span>}.</span></span>
<span><span>  {</span><span>label</span><span>,</span><span>2</span><span>}.</span></span>
<span><span>    {</span><span>move</span><span>,{</span><span>literal</span><span>,[{</span><span>flush</span><span>,</span><span>false</span><span>}]},{</span><span>x</span><span>,</span><span>1</span><span>}}.</span></span>
<span><span>    {</span><span>move</span><span>,{</span><span>integer</span><span>,</span><span>42</span><span>},{</span><span>x</span><span>,</span><span>0</span><span>}}.</span></span>
<span><span>    {</span><span>line</span><span>,[{</span><span>location</span><span>,</span><span>"erts/preloaded/src/hello.erl"</span><span>,</span><span>76</span><span>}]}.</span></span>
<span><span>    {</span><span>call_ext_only</span><span>,</span><span>2</span><span>,{</span><span>extfunc</span><span>,</span><span>erlang</span><span>,</span><span>halt</span><span>,</span><span>2</span><span>}}.</span></span>
<span></span>
<span><span>{</span><span>function</span><span>, </span><span>module_info</span><span>, </span><span>0</span><span>, </span><span>4</span><span>}.</span></span>
<span><span>  {</span><span>label</span><span>,</span><span>3</span><span>}.</span></span>
<span><span>    {</span><span>line</span><span>,[]}.</span></span>
<span><span>    {</span><span>func_info</span><span>,{</span><span>atom</span><span>,</span><span>hello</span><span>},{</span><span>atom</span><span>,</span><span>module_info</span><span>},</span><span>0</span><span>}.</span></span>
<span><span>  {</span><span>label</span><span>,</span><span>4</span><span>}.</span></span>
<span><span>    {</span><span>move</span><span>,{</span><span>atom</span><span>,</span><span>hello</span><span>},{</span><span>x</span><span>,</span><span>0</span><span>}}.</span></span>
<span><span>    {</span><span>call_ext_only</span><span>,</span><span>1</span><span>,{</span><span>extfunc</span><span>,</span><span>erlang</span><span>,</span><span>get_module_info</span><span>,</span><span>1</span><span>}}.</span></span>
<span></span>
<span><span>{</span><span>function</span><span>, </span><span>module_info</span><span>, </span><span>1</span><span>, </span><span>6</span><span>}.</span></span>
<span><span>  {</span><span>label</span><span>,</span><span>5</span><span>}.</span></span>
<span><span>    {</span><span>line</span><span>,[]}.</span></span>
<span><span>    {</span><span>func_info</span><span>,{</span><span>atom</span><span>,</span><span>hello</span><span>},{</span><span>atom</span><span>,</span><span>module_info</span><span>},</span><span>1</span><span>}.</span></span>
<span><span>  {</span><span>label</span><span>,</span><span>6</span><span>}.</span></span>
<span><span>    {</span><span>move</span><span>,{</span><span>x</span><span>,</span><span>0</span><span>},{</span><span>x</span><span>,</span><span>1</span><span>}}.</span></span>
<span><span>    {</span><span>move</span><span>,{</span><span>atom</span><span>,</span><span>hello</span><span>},{</span><span>x</span><span>,</span><span>0</span><span>}}.</span></span>
<span><span>    {</span><span>call_ext_only</span><span>,</span><span>2</span><span>,{</span><span>extfunc</span><span>,</span><span>erlang</span><span>,</span><span>get_module_info</span><span>,</span><span>2</span><span>}}.</span></span></code></pre></div><p>You can spot the start function and the two standard module_info functions that all Erlang modules have. We do not care much about those right now as we discovered that they are not executed and are not required to work, for now.</p><p>We can see that the core of the start function is just two <code>move</code> operations and one <code>call_ext_only</code>. But bear in mind that the BEAM loader will transmute these <em>Generic</em> BEAM Operations into <em>Specific</em> operations. More complexity will pop up!</p><h2 id="execution" tabindex="-1">Execution <a href="#execution" aria-label="Permalink to &quot;Execution&quot;">​</a></h2><p>We are using <code>qemu-arm</code> to emulate <code>Arm32</code> and we are directly using <code>beam.smp</code> to run the BEAM.</p><div><p><span>shell</span></p><pre tabindex="0"><code><span><span>    ~/arm32-jit$</span><span> qemu-arm</span><span> -L</span><span> /usr/arm-linux-gnueabihf</span><span> ./otp/RELEASE/erts-15.0/bin/beam.smp</span><span> -S</span><span> 1:1</span><span> -SDcpu</span><span> 1:1</span><span> -SDio</span><span> 1</span><span> -JDdump</span><span> true</span><span> -JMsingle</span><span>     true</span><span> --</span><span> -root</span><span> /home/vagrant/arm32-jit/otp/RELEASE</span><span> -progname</span><span> erl</span><span> -home</span><span> /home/vagrant</span></span></code></pre></div><h3 id="jit-initialization" tabindex="-1">JIT initialization <a href="#jit-initialization" aria-label="Permalink to &quot;JIT initialization&quot;">​</a></h3><p>At boot, the BEAM initializes the JIT if enabled. The JIT leverages the AsmJit library to emit all machine code instructions.</p><h4 id="emission-of-all-global-shared-fragments" tabindex="-1">Emission of all global shared fragments <a href="#emission-of-all-global-shared-fragments" aria-label="Permalink to &quot;Emission of all global shared fragments&quot;">​</a></h4><p>There are 90+ code snippets that are shared among all modules. The JIT loads them one single time and sets up jumps to them in every other module. It is like a global library for all modules.</p><p>We skipped most of these because just the shared fragments involved in the <code>hello:start/2</code> execution were needed.</p><h4 id="emission-of-the-erts-beamasm-module" tabindex="-1">Emission of the <em>erts_beamasm</em> module <a href="#emission-of-the-erts-beamasm-module" aria-label="Permalink to &quot;Emission of the *erts_beamasm* module&quot;">​</a></h4><p>As part of the JIT initialization, <code>erts_beamasm</code> is emitted. This module is an internal hardcoded module that exists only when BEAM is using the JIT. It holds 7 fundamental instructions used to manage the Erlang process executions.</p><ul><li>run_process - The main process execution entry point</li><li>normal_exit - Normal process termination</li><li>continue_exit - Continue after exit handling</li><li>exception_trace - Exception tracing functionality</li><li>return_trace - Return value tracing</li><li>return_to_trace - Return to tracing state</li><li>call_trace_return - Call tracing return handling</li></ul><h3 id="preloaded-modules" tabindex="-1">Preloaded modules <a href="#preloaded-modules" aria-label="Permalink to &quot;Preloaded modules&quot;">​</a></h3><p>The <code>hello.erl</code> module has been compiled and put as first and single Erlang module in the list of preloaded modules. Preloaded modules are Erlang fundamental modules that are always loaded by the BEAM before the first Erlang process can start. They implement, in Erlang, the core features of the Erlang Runtime System (ERTS). The OTP build scripts group all <code>ebin</code> files into a single C header that is then linked into the executable. This makes the Erlang binaries available as a static C array in the BEAM source code. These are then loaded one by one after the BEAM VM is initialized.</p><p>Cool, let's nuke all these modules and leave just our <code>hello.erl</code>. It does not need many BEAM instructions and we can easily verify that it executes. To do the substitution we just need to change this build variable in <a href="https://github.com/erlang/otp/commit/fa61ec65e57cfdf96b70514800f7021b83cc7fdc#diff-ffe95702266c55f8aeab7d07a0898c9548fbb390b238145f0abe05399baab62aL749-R749" target="_blank" rel="noreferrer">otp/erts/emulator/Makefile.in</a></p><p>We are running BEAMASM with <code>-JDdump true</code> so <code>asmjit</code> will dump all ARM32 assembly for each module! This is incredibly useful if monitored while executing with a debugger, as we can see the assembler being printed line by line by our code.</p><div><p><span>shell</span></p><pre tabindex="0"><code><span><span>~</span><span>/arm32-jit$ cat hello.asm </span></span>
<span><span>L6:</span></span>
<span><span>.byte</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00</span></span>
<span><span># i_flush_stubs</span></span>
<span><span># func_line_I</span></span>
<span><span># aligned_label_Lt</span></span>
<span><span>label_1:</span></span>
<span><span># i_func_info_IaaI</span></span>
<span><span># hello:start/2</span></span>
<span><span>    blx</span><span> L8</span></span>
<span><span>.byte</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00</span></span>
<span><span>.byte</span><span> 0x0B,</span><span> 0x4F,</span><span> 0x00,</span><span> 0x00,</span><span> 0x0B,</span><span> 0xA4,</span><span> 0x00,</span><span> 0x00,</span><span> 0x02,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00</span></span>
<span><span># aligned_label_Lt</span></span>
<span><span>start/2:</span></span>
<span><span># i_breakpoint_trampoline</span></span>
<span><span>    str</span><span> lr,</span><span> [r7, </span><span>-4</span><span>]</span><span>!</span></span>
<span><span>    b</span><span> L9</span></span>
<span><span>    bl</span><span> L11</span></span>
<span><span>L9:</span></span>
<span><span># i_test_yield</span></span>
<span><span>    adr</span><span> r2,</span><span> start/2</span></span>
<span><span>    subs</span><span> r9,</span><span> r9,</span><span> 1</span></span>
<span><span>    b.le</span><span> L13</span></span>
<span><span># i_move_sd</span></span>
<span><span>    ldr</span><span> r12,</span><span> [L14]</span></span>
<span><span>    str</span><span> r12,</span><span> [r4, </span><span>68]</span></span>
<span><span># i_move_sd</span></span>
<span><span>    movw</span><span> r12,</span><span> 687</span></span>
<span><span>    str</span><span> r12,</span><span> [r4, </span><span>64]</span></span>
<span><span># line_I</span></span>
<span><span># allocate_tt</span></span>
<span><span># call_light_bif_be</span></span>
<span><span>L15:</span></span>
<span><span>    ldr</span><span> r3,</span><span> [L16]</span></span>
<span><span>    movw</span><span> r1,</span><span> 10188</span></span>
<span><span>    movt</span><span> r1,</span><span> 16432</span></span>
<span><span>    adr</span><span> r2,</span><span> L15</span></span>
<span><span># BIF: erlang:halt/2</span></span>
<span><span>    sub</span><span> r12,</span><span> r7,</span><span> 4</span></span>
<span><span>    cmp</span><span> r10,</span><span> r12</span></span>
<span><span>    b.ls</span><span> L17</span></span>
<span><span>    udf</span><span> 48879</span></span>
<span><span>L17:</span></span>
<span><span>    movw</span><span> r12,</span><span> 12424</span></span>
<span><span>    add</span><span> r12,</span><span> r4,</span><span> r12</span></span>
<span><span>    ldr</span><span> r12,</span><span> [r12]</span></span>
<span><span>    cmp</span><span> sp,</span><span> r12</span></span>
<span><span>    b.eq</span><span> L18</span></span>
<span><span>    udf</span><span> 57005</span></span>
<span><span>L18:</span></span>
<span><span>    bl</span><span> L20</span></span>
<span><span># deallocate_t</span></span>
<span><span>    movw</span><span> r0,</span><span> 64676</span></span>
<span><span>    movt</span><span> r0,</span><span> 16480</span></span>
<span><span>    blx</span><span> L22</span></span>
<span><span># return</span></span>
<span><span>    movw</span><span> r0,</span><span> 61636</span></span>
<span><span>    movt</span><span> r0,</span><span> 16480</span></span>
<span><span>    blx</span><span> L22</span></span>
<span><span># i_flush_stubs</span></span>
<span><span># func_line_I</span></span>
<span><span># aligned_label_Lt</span></span>
<span><span>label_3:</span></span>
<span><span># i_func_info_IaaI</span></span>
<span><span># hello:module_info/0</span></span>
<span><span>    blx</span><span> L8</span></span>
<span><span>.byte</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00</span></span>
<span><span>.byte</span><span> 0x0B,</span><span> 0x4F,</span><span> 0x00,</span><span> 0x00,</span><span> 0x4B,</span><span> 0x6B,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00</span></span>
<span><span># aligned_label_Lt</span></span>
<span><span>module_info/0:</span></span>
<span><span># i_breakpoint_trampoline</span></span>
<span><span>    str</span><span> lr,</span><span> [r7, </span><span>-4</span><span>]</span><span>!</span></span>
<span><span>    b</span><span> L23</span></span>
<span><span>    bl</span><span> L11</span></span>
<span><span>L23:</span></span>
<span><span># i_test_yield</span></span>
<span><span>    adr</span><span> r2,</span><span> module_info/0</span></span>
<span><span>    subs</span><span> r9,</span><span> r9,</span><span> 1</span></span>
<span><span>    b.le</span><span> L13</span></span>
<span><span># i_move_sd</span></span>
<span><span>    movw</span><span> r12,</span><span> 20235</span></span>
<span><span>    str</span><span> r12,</span><span> [r4, </span><span>64]</span></span>
<span><span># allocate_tt</span></span>
<span><span># call_light_bif_be</span></span>
<span><span>L24:</span></span>
<span><span>    ldr</span><span> r3,</span><span> [L25]</span></span>
<span><span>    movw</span><span> r1,</span><span> 4772</span></span>
<span><span>    movt</span><span> r1,</span><span> 16425</span></span>
<span><span>    adr</span><span> r2,</span><span> L24</span></span>
<span><span># BIF: erlang:get_module_info/1</span></span>
<span><span>    sub</span><span> r12,</span><span> r7,</span><span> 4</span></span>
<span><span>    cmp</span><span> r10,</span><span> r12</span></span>
<span><span>    b.ls</span><span> L26</span></span>
<span><span>    udf</span><span> 48879</span></span>
<span><span>L26:</span></span>
<span><span>    movw</span><span> r12,</span><span> 12424</span></span>
<span><span>    add</span><span> r12,</span><span> r4,</span><span> r12</span></span>
<span><span>    ldr</span><span> r12,</span><span> [r12]</span></span>
<span><span>    cmp</span><span> sp,</span><span> r12</span></span>
<span><span>    b.eq</span><span> L27</span></span>
<span><span>    udf</span><span> 57005</span></span>
<span><span>L27:</span></span>
<span><span>    bl</span><span> L20</span></span>
<span><span># deallocate_t</span></span>
<span><span>    movw</span><span> r0,</span><span> 64676</span></span>
<span><span>    movt</span><span> r0,</span><span> 16480</span></span>
<span><span>    blx</span><span> L22</span></span>
<span><span># return</span></span>
<span><span>    movw</span><span> r0,</span><span> 61636</span></span>
<span><span>    movt</span><span> r0,</span><span> 16480</span></span>
<span><span>    blx</span><span> L22</span></span>
<span><span># i_flush_stubs</span></span>
<span><span># func_line_I</span></span>
<span><span># aligned_label_Lt</span></span>
<span><span>label_5:</span></span>
<span><span># i_func_info_IaaI</span></span>
<span><span># hello:module_info/1</span></span>
<span><span>    blx</span><span> L8</span></span>
<span><span>.byte</span><span> 0x00,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00</span></span>
<span><span>.byte</span><span> 0x0B,</span><span> 0x4F,</span><span> 0x00,</span><span> 0x00,</span><span> 0x4B,</span><span> 0x6B,</span><span> 0x00,</span><span> 0x00,</span><span> 0x01,</span><span> 0x00,</span><span> 0x00,</span><span> 0x00</span></span>
<span><span># aligned_label_Lt</span></span>
<span><span>module_info/1:</span></span>
<span><span># i_breakpoint_trampoline</span></span>
<span><span>    str</span><span> lr,</span><span> [r7, </span><span>-4</span><span>]</span><span>!</span></span>
<span><span>    b</span><span> L28</span></span>
<span><span>    bl</span><span> L11</span></span>
<span><span>L28:</span></span>
<span><span># i_test_yield</span></span>
<span><span>    adr</span><span> r2,</span><span> module_info/1</span></span>
<span><span>    subs</span><span> r9,</span><span> r9,</span><span> 1</span></span>
<span><span>    b.le</span><span> L13</span></span>
<span><span># i_move_sd</span></span>
<span><span>    ldr</span><span> r12,</span><span> [r4, </span><span>64]</span></span>
<span><span>    str</span><span> r12,</span><span> [r4, </span><span>68]</span></span>
<span><span># i_move_sd</span></span>
<span><span>    movw</span><span> r12,</span><span> 20235</span></span>
<span><span>    str</span><span> r12,</span><span> [r4, </span><span>64]</span></span>
<span><span># allocate_tt</span></span>
<span><span># call_light_bif_be</span></span>
<span><span>L29:</span></span>
<span><span>    ldr</span><span> r3,</span><span> [L30]</span></span>
<span><span>    movw</span><span> r1,</span><span> 4868</span></span>
<span><span>    movt</span><span> r1,</span><span> 16425</span></span>
<span><span>    adr</span><span> r2,</span><span> L29</span></span>
<span><span># BIF: erlang:get_module_info/2</span></span>
<span><span>    sub</span><span> r12,</span><span> r7,</span><span> 4</span></span>
<span><span>    cmp</span><span> r10,</span><span> r12</span></span>
<span><span>    b.ls</span><span> L31</span></span>
<span><span>    udf</span><span> 48879</span></span>
<span><span>L31:</span></span>
<span><span>    movw</span><span> r12,</span><span> 12424</span></span>
<span><span>    add</span><span> r12,</span><span> r4,</span><span> r12</span></span>
<span><span>    ldr</span><span> r12,</span><span> [r12]</span></span>
<span><span>    cmp</span><span> sp,</span><span> r12</span></span>
<span><span>    b.eq</span><span> L32</span></span>
<span><span>    udf</span><span> 57005</span></span>
<span><span>L32:</span></span>
<span><span>    bl</span><span> L20</span></span>
<span><span># deallocate_t</span></span>
<span><span>    movw</span><span> r0,</span><span> 64676</span></span>
<span><span>    movt</span><span> r0,</span><span> 16480</span></span>
<span><span>    blx</span><span> L22</span></span>
<span><span># return</span></span>
<span><span>    movw</span><span> r0,</span><span> 61636</span></span>
<span><span>    movt</span><span> r0,</span><span> 16480</span></span>
<span><span>    blx</span><span> L22</span></span>
<span><span># int_code_end</span></span>
<span><span>L33:</span></span>
<span><span>    movw</span><span> r0,</span><span> 18576</span></span>
<span><span>    movt</span><span> r0,</span><span> 16480</span></span>
<span><span>    blx</span><span> L22</span></span>
<span><span>L13:</span></span>
<span><span>L12:</span></span>
<span><span>    movw</span><span> r12,</span><span> 1968</span></span>
<span><span>    movt</span><span> r12,</span><span> 14656</span></span>
<span><span>    blx</span><span> r12</span></span>
<span><span>L22:</span></span>
<span><span>L21:</span></span>
<span><span>    movw</span><span> r12,</span><span> 29192</span></span>
<span><span>    movt</span><span> r12,</span><span> 16399</span></span>
<span><span>    blx</span><span> r12</span></span>
<span><span>L11:</span></span>
<span><span>L10:</span></span>
<span><span>    movw</span><span> r12,</span><span> 1752</span></span>
<span><span>    movt</span><span> r12,</span><span> 14656</span></span>
<span><span>    blx</span><span> r12</span></span>
<span><span>L20:</span></span>
<span><span>L19:</span></span>
<span><span>    movw</span><span> r12,</span><span> 680</span></span>
<span><span>    movt</span><span> r12,</span><span> 14656</span></span>
<span><span>    blx</span><span> r12</span></span>
<span><span>L8:</span></span>
<span><span>L7:</span></span>
<span><span>    movw</span><span> r12,</span><span> 1824</span></span>
<span><span>    movt</span><span> r12,</span><span> 14656</span></span>
<span><span>    blx</span><span> r12</span></span>
<span><span># Begin stub section</span></span>
<span><span>L14:</span></span>
<span><span>.xword</span><span> 0x000000007FFFFFFF</span></span>
<span><span>L16:</span></span>
<span><span>.xword</span><span> 0x000000007FFFFFFF</span></span>
<span><span>L25:</span></span>
<span><span>.xword</span><span> 0x000000007FFFFFFF</span></span>
<span><span>L30:</span></span>
<span><span>.xword</span><span> 0x000000007FFFFFFF</span></span>
<span><span># End stub section</span></span>
<span><span>L34:</span></span>
<span><span>.section</span><span> .rodata</span><span> {#1}</span></span>
<span><span>md5:</span></span>
<span><span>.byte</span><span> 0x6D,</span><span> 0xC4,</span><span> 0x1E,</span><span> 0xF1,</span><span> 0x13,</span><span> 0x1E,</span><span> 0xBF,</span><span> 0xF2,</span><span> 0x4B,</span><span> 0xF5,</span><span> 0xC0,</span><span> 0x41,</span><span> 0x57,</span><span> 0x86,</span><span> 0xDF,</span><span> 0xD5</span></span>
<span><span>.section</span><span> .text</span><span> {#0}</span></span>
<span><span>; </span><span>CODE_SIZE:</span><span> 632</span></span></code></pre></div><p>Bear in mind, this assembler is not what hello should look like. We are missing a lot of things.</p><p>You can spot many sequences like:</p><div><p><span>asm</span></p><pre tabindex="0"><code><span><span>    movw r0, </span><span>64676</span></span>
<span><span>    movt r0, </span><span>16480</span></span>
<span><span>    blx L22</span><span> # &lt;---- branch to NYI</span></span></code></pre></div><p>This is a call to <code>nyi</code> (Not Yet Implemented) function and the argument loaded to R0 is the pointer to a string that contains the name of the BEAM instruction that should have been emitted instead. You can spot many of these since we are only emitting the code to reach halt. Everything after that is not important now as halt will never return!</p><p>There are many more comments we could make around all the details in this assembler dump, but let's move on.</p><h3 id="jumping-into-jitted-code" tabindex="-1">Jumping into Jitted code! <a href="#jumping-into-jitted-code" aria-label="Permalink to &quot;Jumping into Jitted code!&quot;">​</a></h3><p>Later in the BEAM initialization the first Erlang process will be allocated and started.</p><p>We swap the module and function with hello in <a href="https://github.com/erlang/otp/commit/fa61ec65e57cfdf96b70514800f7021b83cc7fdc#diff-3517781afd08bfe826dcc3babdfa35cdabb9d13011d5dd9ae49922f3996cadb5L395" target="_blank" rel="noreferrer">erts/emulator/beam/erl_init.c</a></p><div><p><span>cpp</span></p><pre tabindex="0"><code><span><span>    erl_spawn_system_process</span><span>(</span><span>&amp;</span><span>parent, am_hello, am_start, args, </span><span>&amp;</span><span>so);</span></span></code></pre></div><p>One BEAM scheduler thread will jump to the <code>process_main</code> function. You can find it <a href="https://github.com/stritzinger/otp/blob/31edb99e9851e9d35b0cf6a3f4ead9a4cc4cfcb6/erts/emulator/beam/jit/arm/32/process_main.cpp#L49" target="_blank" rel="noreferrer">here</a> in the source code. This is emitted by our JIT and is the first emitted code that will run.</p><p>Here we need to handle the Erlang processes scheduling by calling BEAM routines that implement the algorithms of Erlang concurrency, like <a href="https://github.com/stritzinger/otp/blob/eda80cd2fe028c2db6f67bcf97ac50de85c41b2f/erts/emulator/beam/erl_process.c#L9465" target="_blank" rel="noreferrer"><code>erts_schedule</code></a>.</p><p><code>erts_schedule</code> will return the pointer to the <code>Process</code> C structure that holds all information about the process that is going to execute. We then load all necessary data inside registers and then we branch to the exact point where the program execution stopped.</p><h3 id="the-first-erlang-function-call" tabindex="-1">The first Erlang function call <a href="#the-first-erlang-function-call" aria-label="Permalink to &quot;The first Erlang function call&quot;">​</a></h3><p>In this case we are calling <code>hello:start/2</code> so the first instruction to execute is <code>apply_only</code> that does a few things but ends up calling the C <code>apply</code> routine.</p><p>The routine processes the Module-Function-Arity information to get the address where the function code resides in memory.</p><p>What follows is the Erlang function prologue. You can see it in the assembler code section above. For example, all functions have these instructions in their prologue:</p><ul><li>i_breakpoint_trampoline: handle breakpoints for the <code>debugger</code> app</li><li>i_test_yield: checks if the function should yield and go back to the scheduler</li></ul><p>We have minimal or partial implementations of these since we do not really need them. We have to emit them though, as the C++ generated loader functions from the BEAM are expanding the Erlang function call Operation into a more specific and complex function prologue sequence.</p><p>After that, we added support for the <a href="https://github.com/stritzinger/otp/blob/31edb99e9851e9d35b0cf6a3f4ead9a4cc4cfcb6/erts/emulator/beam/jit/arm/32/instr_bif.cpp#L280" target="_blank" rel="noreferrer"><code>call_light_bif</code></a> operation that precedes the call to the halt_2 BIF routine. This implementation is also minimal.</p><p><em>Question for later: did you notice that we put a <code>42</code> as a number in the code? Numeric constants are printed as decimals in the dump, but we cannot spot any 42!?</em></p><p>After the call, we see two other operations:</p><ul><li>dealloc</li><li>return</li></ul><p>These are just calls to NYI as we will never reach this code! So for now, we can skip them...</p><h3 id="let-s-roll-the-jit" tabindex="-1">Let's roll the JIT! <a href="#let-s-roll-the-jit" aria-label="Permalink to &quot;Let's roll the JIT!&quot;">​</a></h3><div><p><span>shell</span></p><pre tabindex="0"><code><span><span>    ~/arm32-jit$</span><span> qemu-arm</span><span> -L</span><span> /usr/arm-linux-gnueabihf</span><span> ./otp/RELEASE/erts-15.0/bin/beam.smp</span><span> -S</span><span> 1:1</span><span> -SDcpu</span><span> 1:1</span><span> -SDio</span><span> 1</span><span> -JDdump</span><span> true</span><span> -JMsingle</span><span>     true</span><span> --</span><span> -root</span><span> /home/arm32-jit/otp/RELEASE</span><span> -progname</span><span> erl</span><span> -home</span><span> /home</span></span>
<span><span>    ~/arm32-jit$</span></span></code></pre></div><p>Impressive, the program returns immediately without even saying <em>"Hi"</em> ... and without Segmentation Fault!!</p><p>But let's check the program return code!</p><pre><code>~/arm32-jit$ echo $?
42
</code></pre><p>We can safely say that number is not there by accident! This is a great achievement as from now on we will be able to incrementally add Erlang instructions.</p><p>Every Erlang line we add will trigger new Opcodes. By emitting them and running the code we will have immediate feedback on everything.</p><p>The next goal now is to complete the <code>hello</code> module to host all possible beam instructions!</p><h4 id="hey-where-is-42" tabindex="-1">Hey where is 42??? <a href="#hey-where-is-42" aria-label="Permalink to &quot;Hey where is 42???&quot;">​</a></h4><p>One interesting thing I spotted looking at the assembly: You cannot find the number <code>42</code> in there. Or actually, you can, it is just hidden in plain sight. To understand you need to know how we are using ARM32 registers.</p><p>In particular the register <code>r4</code>, a callee-saved register. We are using it to store the pointer to the <code>ErtsSchedulerRegisters</code> struct. The <code>ErtsSchedulerRegisters</code> contains the X register array. When a function is called, X registers are used to store the arguments of the call.</p><p>This becomes more obvious if we compare the Erlang assembly to the Arm32 assembly.</p><div><p><span>asm</span></p><pre tabindex="0"><code><span><span># i_move_sd                       &lt;---- {move,{literal,[{flush,false}]},{x,1}}. % List at X[1]</span></span>
<span><span>    ldr </span><span>r12</span><span>, [L14]</span></span>
<span><span>    str</span><span> r12</span><span>, [r4, </span><span>68</span><span>]</span></span>
<span><span># i_move_sd                       &lt;---- {move,{integer,42},{x,0}}. % 42 at X[0]</span></span>
<span><span>    movw </span><span>r12</span><span>, </span><span>687</span><span> </span></span>
<span><span>    str</span><span> r12</span><span>, [r4, </span><span>64</span><span>]</span></span>
<span><span># line_I</span></span>
<span><span># allocate_tt</span></span>
<span><span># call_light_bif_be</span></span>
<span><span>L15:</span></span>
<span><span>    ldr r3, [L16]</span></span>
<span><span>    movw r1, </span><span>10188</span></span>
<span><span>    movt r1, </span><span>16432</span></span>
<span><span>    adr r2, L15</span></span>
<span><span># BIF: erlang:halt/2</span></span>
<span><span># ...</span></span></code></pre></div><p>42 is stored at <code>r4</code>+64.</p><ul><li>r4: pointer to the <code>ErtsSchedulerRegisters</code> struct</li><li>64: base offset from the beginning of the struct to the beginning of the <code>x_reg_array</code></li></ul><p>The list is stored at <code>r4</code>+68.</p><ul><li>68: is the base offset + the size of one <code>Eterm</code> (4 bytes on ARM32)</li></ul><p>But why in assembly do we see 687 and not 42?</p><p>Converting both numbers to hex we get:</p><ul><li>42 -&gt; 2A</li><li>687 -&gt; 2AF !!</li></ul><p>Yep, this is an example of a Tagged Value. If we consult the BEAM book we can learn about the <a href="https://blog.stenmans.org/theBeamBook/#_the_tagging_scheme" target="_blank" rel="noreferrer">Tagging Scheme</a>:</p><ul><li>00 11 Pid</li><li>01 11 Port</li><li>10 11 Immediate 2</li><li>11 11 Small integer</li></ul><p>42 is tagged with <code>1111</code> at the low end. So the BEAM can quickly recognize during a pattern match that this Erlang Term is a Small Integer!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qualcomm to Acquire Arduino (757 pts)]]></title>
            <link>https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i</link>
            <guid>45502541</guid>
            <pubDate>Tue, 07 Oct 2025 13:00:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i">https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i</a>, See on <a href="https://news.ycombinator.com/item?id=45502541">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The evolution of Lua, continued [pdf] (136 pts)]]></title>
            <link>https://www.lua.org/doc/cola.pdf</link>
            <guid>45502502</guid>
            <pubDate>Tue, 07 Oct 2025 12:54:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lua.org/doc/cola.pdf">https://www.lua.org/doc/cola.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45502502">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Like Vercel, but open source and for all language (233 pts)]]></title>
            <link>https://github.com/hunvreus/devpush</link>
            <guid>45501279</guid>
            <pubDate>Tue, 07 Oct 2025 10:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hunvreus/devpush">https://github.com/hunvreus/devpush</a>, See on <a href="https://news.ycombinator.com/item?id=45501279">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">/dev/push</h2><a id="user-content-devpush" aria-label="Permalink: /dev/push" href="#devpush"></a></p>
<p dir="auto">An open-source and self-hostable alternative to Vercel, Render, Netlify and the likes. It allows you to build and deploy any app (Python, Node.js, PHP, ...) with zero-downtime updates, real-time logs, team management, customizable environments and domains, etc.</p>
<themed-picture data-catalyst-inline="true"><picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://camo.githubusercontent.com/eeeab78c32e5fbbe4cfb45a7eade491e0adce97860b647143bf22350baf001f1/68747470733a2f2f64657670752e73682f6173736574732f696d616765732f73637265656e73686f742d6461726b2e706e67" data-canonical-src="https://devpu.sh/assets/images/screenshot-dark.png">
  <source media="(prefers-color-scheme: light)" srcset="https://camo.githubusercontent.com/5da9b4470e9938893365b121b41bf3aeb29d51ad4080a8ec08c6464a1150f8f3/68747470733a2f2f64657670752e73682f6173736574732f696d616765732f73637265656e73686f742d6c696768742e706e67" data-canonical-src="https://devpu.sh/assets/images/screenshot-light.png">
  <img alt="A screenshot of a deployment in /dev/push." src="https://camo.githubusercontent.com/eeeab78c32e5fbbe4cfb45a7eade491e0adce97860b647143bf22350baf001f1/68747470733a2f2f64657670752e73682f6173736574732f696d616765732f73637265656e73686f742d6461726b2e706e67" data-canonical-src="https://devpu.sh/assets/images/screenshot-dark.png">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key features</h2><a id="user-content-key-features" aria-label="Permalink: Key features" href="#key-features"></a></p>
<ul dir="auto">
<li><strong>Git-based deployments</strong>: Push to deploy from GitHub with zero-downtime rollouts and instant rollback.</li>
<li><strong>Multi-language support</strong>: Python, Node.js, PHP... basically anything that can run on Docker.</li>
<li><strong>Environment management</strong>: Multiple environments with branch mapping and encrypted environment variables.</li>
<li><strong>Real-time monitoring</strong>: Live and searchable build and runtime logs.</li>
<li><strong>Team collaboration</strong>: Role-based access control with team invitations and permissions.</li>
<li><strong>Custom domains</strong>: Support for custom domain and automatic Let's Encrypt SSL certificates.</li>
<li><strong>Self-hosted and open source</strong>: Run on your own servers, MIT licensed.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support the project</h2><a id="user-content-support-the-project" aria-label="Permalink: Support the project" href="#support-the-project"></a></p>
<ul dir="auto">
<li><a href="https://github.com/hunvreus/devpush/blob/main/CONTRIBUTING.md">Contribute code</a></li>
<li><a href="https://github.com/hunvreus/devpush/issues">Report issues</a></li>
<li><a href="https://github.com/sponsors/hunvreus">Sponsor me</a></li>
<li><a href="https://github.com/hunvreus/devpush">Star the project on GitHub</a></li>
<li><a href="https://devpu.sh/chat" rel="nofollow">Join the Discord chat</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<ul dir="auto">
<li>User documentation: <a href="https://devpu.sh/docs" rel="nofollow">devpu.sh/docs</a></li>
<li>Technical documentation: <a href="https://github.com/hunvreus/devpush/blob/main/ARCHITECTURE.md">ARCHITECTURE</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<blockquote>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Supported on Ubuntu/Debian. Other distros may work but aren't officially supported (yet).</p>
</blockquote>
<p dir="auto">Log in your server, run the following command and follow instructions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh | sudo bash"><pre>curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh <span>|</span> sudo bash</pre></div>
<p dir="auto">You user must have sudo privileges.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install &amp; Update</h2><a id="user-content-install--update" aria-label="Permalink: Install &amp; Update" href="#install--update"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<p dir="auto">You will need a fresh Ubuntu/Debian server you can SSH into with sudo privileges. We recommend a CPX31 from <a href="https://www.hetzner.com/" rel="nofollow">Hetzner</a>.</p>
<p dir="auto">You can use the provisioning script to get a server up and running:</p>
<ol dir="auto">
<li><strong>Sign in or sign up for a Hetzner account</strong>: <a href="https://console.hetzner.cloud/" rel="nofollow">Hetzner Cloud Console</a></li>
<li><strong>Generate an API token</strong>: <a href="https://docs.hetzner.com/cloud/api/getting-started/generating-api-token/" rel="nofollow">Creating an API token</a></li>
<li><strong>Provision a server</strong> (requires <code>--token</code>; optional: <code>--user</code>, <code>--name</code>, <code>--region</code>, <code>--type</code>):
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/provision-hetzner.sh | bash -s -- --token <hetzner_api_key> [--user <login_user>] [--name <hostname>] [--region <fsn1|nbg1|hel1|ash|hil|sin>] [--type <cpx11|cpx21|cpx31|cpx41|cpx51>]"><pre>curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/provision-hetzner.sh <span>|</span> bash -s -- --token <span>&lt;</span>hetzner_api_key<span>&gt;</span> [--user <span>&lt;</span>login_user<span>&gt;</span>] [--name <span>&lt;</span>hostname<span>&gt;</span>] [--region <span>&lt;</span>fsn1<span>|</span>nbg1<span>|</span>hel1<span>|</span>ash<span>|</span>hil<span>|</span>sin<span>&gt;</span>] [--type <span>&lt;</span>cpx11<span>|</span>cpx21<span>|</span>cpx31<span>|</span>cpx41<span>|</span>cpx<span>51&gt;</span>]</pre></div>
Tip: run <code>curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/provision-hetzner.sh | bash -s -- --help</code> to list regions and types (with specs). Defaults: region <code>hil</code>, type <code>cpx31</code>.</li>
<li><strong>Configure DNS Records</strong>: Go to your DNS provider and create two A records pointing at the server IP for <code>APP_HOSTNAME</code> (e.g. <code>app.devpu.sh</code>) and a wildcard on subdomains of <code>DEPLOY_DOMAIN</code> (e.g. <code>*.devpush.app</code>). If you're using Cloudflare, set SSL/TLS to "Full (strict)" and keep the records proxied.</li>
<li><strong>SSH into your new server</strong>: The provision script will have created a user for you.
<div dir="auto" data-snippet-clipboard-copy-content="ssh <login_user>@<server_ip>"><pre>ssh <span>&lt;</span>login_user<span>&gt;</span>@<span>&lt;</span>server_ip<span>&gt;</span></pre></div>
</li>
<li><strong>Run hardening for system and SSH</strong>:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/harden.sh | sudo bash -s -- --ssh"><pre>curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/harden.sh <span>|</span> sudo bash -s -- --ssh</pre></div>
<p dir="auto">Even if you already have a server, we recommend you harden security (ufw, fail2ban, disabled root SSH, etc). You can do that using <code>scripts/prod/harden.sh</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install</h3><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<ol dir="auto">
<li><strong>SSH into the server</strong>:
<div dir="auto" data-snippet-clipboard-copy-content="ssh <login_user>@<server_ip>"><pre>ssh <span>&lt;</span>login_user<span>&gt;</span>@<span>&lt;</span>server_ip<span>&gt;</span></pre></div>
</li>
<li><strong>Install /dev/push</strong>:
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh | sudo bash"><pre>curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh <span>|</span> sudo bash</pre></div>
</li>
<li><strong>Switch to <code>devpush</code> user</strong>:</li>
</ol>

<ol start="4" dir="auto">
<li><strong>Edit <code>.env</code></strong>:</li>
</ol>

<p dir="auto">Tip: you will need to fill in at least the following: <code>LE_EMAIL</code>, <code>APP_HOSTNAME</code>, <code>DEPLOY_DOMAIN</code>, <code>EMAIL_SENDER_ADDRESS</code>, <code>RESEND_API_KEY</code> and your <a href="#github-app">GitHub app</a> settings (see [environment-variables] for details). <code>SERVER_IP</code>, <code>SECRET_KEY</code>, <code>ENCRYPTION_KEY</code>, <code>POSTGRES_PASSWORD</code> should be pre-filled. <strong>You can ignore all commented out environment variables</strong>.
5. Start services:</p>
<div dir="auto" data-snippet-clipboard-copy-content="scripts/prod/start.sh --migrate"><pre>scripts/prod/start.sh --migrate</pre></div>
<ol start="6" dir="auto">
<li>Visit your URL: <code>https://&lt;APP_HOSTNAME&gt;</code></li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Update</h3><a id="user-content-update" aria-label="Permalink: Update" href="#update"></a></p>
<p dir="auto">The follwing commands must be run as <code>devpush</code> user (<code>su - devpush</code>).</p>
<p dir="auto">In most cases, you can run an update with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="scripts/prod/update.sh --all"><pre>scripts/prod/update.sh --all</pre></div>
<p dir="auto">Alternatively, you can force a full upgrade (<strong>with downtime</strong>) using:</p>
<div dir="auto" data-snippet-clipboard-copy-content="scripts/prod/update.sh --full -y"><pre>scripts/prod/update.sh --full -y</pre></div>
<p dir="auto">You can update specific components:</p>
<div dir="auto" data-snippet-clipboard-copy-content="scripts/prod/update.sh --components <component_name>"><pre>scripts/prod/update.sh --components <span>&lt;</span>component_name<span>&gt;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<blockquote>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Development scripts target macOS for now.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install</h3><a id="user-content-install-1" aria-label="Permalink: Install" href="#install-1"></a></p>
<ol dir="auto">
<li>Install Colima and the Loki Docker plugin:

</li>
<li>Set up environment variables:

</li>
<li>Start the stack (streams logs):

<ul dir="auto">
<li>Add <code>--prune</code> to prune dangling images before build</li>
<li>Add <code>--cache</code> to use the build cache (default is no cache)</li>
</ul>
</li>
<li>Initialize your database once containers are up:
<div dir="auto" data-snippet-clipboard-copy-content="scripts/dev/db-migrate.sh"><pre>scripts/dev/db-migrate.sh</pre></div>
</li>
</ol>
<p dir="auto">See the <a href="#scripts">scripts</a> section for more dev utilities.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Update</h3><a id="user-content-update-1" aria-label="Permalink: Update" href="#update-1"></a></p>
<ul dir="auto">
<li>The app is mounted inside containers, so code changes reflect immediately. Some SSE endpoints may require closing browser tabs to trigger a reload.</li>
<li>The workers require a restart:
<div dir="auto" data-snippet-clipboard-copy-content="docker-compose restart worker-arq"><pre>docker-compose restart worker-arq</pre></div>
</li>
<li>To apply migrations:
<div dir="auto" data-snippet-clipboard-copy-content="scripts/dev/db-migrate.sh"><pre>scripts/dev/db-migrate.sh</pre></div>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Scripts</h2><a id="user-content-scripts" aria-label="Permalink: Scripts" href="#scripts"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Area</th>
<th>Script</th>
<th>What it does</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dev</td>
<td><code>scripts/dev/install.sh</code></td>
<td>Setup Colima and install Loki Docker plugin</td>
</tr>
<tr>
<td>Dev</td>
<td><code>scripts/dev/start.sh</code></td>
<td>Start stack with logs (foreground); supports <code>--prune</code>, <code>--cache</code></td>
</tr>
<tr>
<td>Dev</td>
<td><code>scripts/dev/build-runners.sh</code></td>
<td>Build runner images (default no cache; <code>--cache</code> to enable)</td>
</tr>
<tr>
<td>Dev</td>
<td><code>scripts/dev/db-generate.sh</code></td>
<td>Generate Alembic migration (prompts for message)</td>
</tr>
<tr>
<td>Dev</td>
<td><code>scripts/dev/db-migrate.sh</code></td>
<td>Apply Alembic migrations</td>
</tr>
<tr>
<td>Dev</td>
<td><code>scripts/dev/db-reset.sh</code></td>
<td>Drop and recreate <code>public</code> schema in DB</td>
</tr>
<tr>
<td>Dev</td>
<td><code>scripts/dev/clean.sh</code></td>
<td>Stop stack and clean dev data (<code>--hard</code> for global)</td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/provision-hetzner.sh</code></td>
<td>Provision a Hetzner server (API token, regions from API, fixed sizes)</td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/install.sh</code></td>
<td>Server setup: Docker, Loki plugin, user, clone repo, create <code>.env</code></td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/harden.sh</code></td>
<td>System hardening (UFW, fail2ban, unattended-upgrades); add <code>--ssh</code> to harden SSH</td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/start.sh</code></td>
<td>Start services; optional <code>--migrate</code></td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/stop.sh</code></td>
<td>Stop services (<code>--down</code> for hard stop)</td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/restart.sh</code></td>
<td>Restart services; optional <code>--migrate</code></td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/update.sh</code></td>
<td>Update by tag; <code>--all</code> (app+workers), <code>--full</code> (downtime), or <code>--components</code></td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/db-migrate.sh</code></td>
<td>Apply DB migrations in production</td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/check-env.sh</code></td>
<td>Validate required keys exist in <code>.env</code></td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/update/app.sh</code></td>
<td>Blue‑green update for app</td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/update/worker-arq.sh</code></td>
<td>Drain‑aware blue‑green update for <code>worker-arq</code></td>
</tr>
<tr>
<td>Prod</td>
<td><code>scripts/prod/update/worker-monitor.sh</code></td>
<td>Blue‑green update for <code>worker-monitor</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Environment variables</h2><a id="user-content-environment-variables" aria-label="Permalink: Environment variables" href="#environment-variables"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Comments</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>APP_NAME</code></td>
<td>App name.</td>
<td><code>/dev/push</code></td>
</tr>
<tr>
<td><code>APP_DESCRIPTION</code></td>
<td>App description.</td>
<td><code>Deploy your Python app without touching a server.</code></td>
</tr>
<tr>
<td><code>URL_SCHEME</code></td>
<td><code>http</code> (development) or <code>https</code> (production).</td>
<td><code>https</code></td>
</tr>
<tr>
<td><code>LE_EMAIL</code></td>
<td>Email used to register the Let's Encrypt (ACME) account in Traefik; receives certificate issuance/renewal/expiry notifications.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>APP_HOSTNAME</code></td>
<td>Domain for the app (e.g. <code>app.devpu.sh</code>).</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>DEPLOY_DOMAIN</code></td>
<td>Domain used for deployments (e.g. <code>devpush.app</code> if you want your deployments available at <code>*.devpush.app</code>).</td>
<td><code>APP_HOSTNAME</code></td>
</tr>
<tr>
<td><code>SERVER_IP</code></td>
<td>Public IP of the server</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>SECRET_KEY</code></td>
<td>App secret for sessions/CSRF. Generate: <code>openssl rand -hex 32</code></td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>ENCRYPTION_KEY</code></td>
<td>Fernet key (urlsafe base64, 32 bytes). Generate: `openssl rand -base64 32</td>
<td>tr '+/' '-_'</td>
</tr>
<tr>
<td><code>EMAIL_LOGO</code></td>
<td>URL for email logo image. Only helpful for testing, as the app will use <code>app/logo-email.png</code> if left empty.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>EMAIL_SENDER_NAME</code></td>
<td>Name displayed as email sender for invites/login.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>EMAIL_SENDER_ADDRESS</code></td>
<td>Email sender used for invites/login.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>RESEND_API_KEY</code></td>
<td>API key for <a href="https://resend.com/" rel="nofollow">Resend</a>.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GITHUB_APP_ID</code></td>
<td>GitHub App ID.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GITHUB_APP_NAME</code></td>
<td>GitHub App name.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GITHUB_APP_PRIVATE_KEY</code></td>
<td>GitHub App private key (PEM format).</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GITHUB_APP_WEBHOOK_SECRET</code></td>
<td>GitHub webhook secret for verifying webhook payloads.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GITHUB_APP_CLIENT_ID</code></td>
<td>GitHub OAuth app client ID.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GITHUB_APP_CLIENT_SECRET</code></td>
<td>GitHub OAuth app client secret.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GOOGLE_CLIENT_ID</code></td>
<td>Google OAuth client ID.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>GOOGLE_CLIENT_SECRET</code></td>
<td>Google OAuth client secret.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>POSTGRES_DB</code></td>
<td>PostgreSQL database name.</td>
<td><code>devpush</code></td>
</tr>
<tr>
<td><code>POSTGRES_USER</code></td>
<td>PostgreSQL username.</td>
<td><code>devpush-app</code></td>
</tr>
<tr>
<td><code>POSTGRES_PASSWORD</code></td>
<td>PostgreSQL password. Generate: `openssl rand -base64 24</td>
<td>tr -d '\n'`</td>
</tr>
<tr>
<td><code>REDIS_URL</code></td>
<td>Redis connection URL.</td>
<td><code>redis://redis:6379</code></td>
</tr>
<tr>
<td><code>DOCKER_HOST</code></td>
<td>Docker daemon host address.</td>
<td><code>tcp://docker-proxy:2375</code></td>
</tr>
<tr>
<td><code>UPLOAD_DIR</code></td>
<td>Directory for file uploads.</td>
<td><code>/app/upload</code></td>
</tr>
<tr>
<td><code>TRAEFIK_CONFIG_DIR</code></td>
<td>Traefik configuration directory.</td>
<td><code>/data/traefik</code></td>
</tr>
<tr>
<td><code>DEFAULT_CPU_QUOTA</code></td>
<td>Default CPU quota for containers (microseconds).</td>
<td><code>100000</code></td>
</tr>
<tr>
<td><code>DEFAULT_MEMORY_MB</code></td>
<td>Default memory limit for containers (MB).</td>
<td><code>4096</code></td>
</tr>
<tr>
<td><code>JOB_TIMEOUT</code></td>
<td>Job timeout in seconds.</td>
<td><code>320</code></td>
</tr>
<tr>
<td><code>JOB_COMPLETION_WAIT</code></td>
<td>Job completion wait time in seconds.</td>
<td><code>300</code></td>
</tr>
<tr>
<td><code>DEPLOYMENT_TIMEOUT</code></td>
<td>Deployment timeout in seconds.</td>
<td><code>300</code></td>
</tr>
<tr>
<td><code>LOG_LEVEL</code></td>
<td>Logging level.</td>
<td><code>WARNING</code></td>
</tr>
<tr>
<td><code>DB_ECHO</code></td>
<td>Enable SQL query logging.</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>ENV</code></td>
<td>Environment (development/production).</td>
<td><code>development</code></td>
</tr>
<tr>
<td><code>ACCESS_DENIED_MESSAGE</code></td>
<td>Message shown to users who are denied access based on  <a href="#sign-in-access-control">sign-in access control</a>.</td>
<td><code>Sign-in not allowed for this email.</code></td>
</tr>
<tr>
<td><code>ACCESS_DENIED_WEBHOOK</code></td>
<td>Optional webhook to receive denied events (read more about <a href="#sign-in-access-control">Sign-in access control</a>).</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>LOGIN_HEADER</code></td>
<td>HTML snippet displayed above the login form.</td>
<td><code>""</code></td>
</tr>
<tr>
<td><code>TOASTER_HEADER</code></td>
<td>HTML snippet displayed at the top of the toaster (useful to display a permanent toast on all pages).</td>
<td><code>""</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">GitHub App</h2><a id="user-content-github-app" aria-label="Permalink: GitHub App" href="#github-app"></a></p>
<p dir="auto">You will need to configure a GitHub App with the following settings:</p>
<ul dir="auto">
<li><strong>Identifying and authorizing users</strong>:
<ul dir="auto">
<li><strong>Callback URL</strong>: add two callback URLs with your domain:
<ul dir="auto">
<li><a href="https://example.com/api/github/authorize/callback" rel="nofollow">https://example.com/api/github/authorize/callback</a></li>
<li><a href="https://example.com/auth/github/callback" rel="nofollow">https://example.com/auth/github/callback</a></li>
</ul>
</li>
<li><strong>Expire user authorization tokens</strong>: No</li>
</ul>
</li>
<li><strong>Post installation</strong>:
<ul dir="auto">
<li><strong>Setup URL</strong>: <a href="https://example.com/api/github/install/callback" rel="nofollow">https://example.com/api/github/install/callback</a></li>
<li><strong>Redirect on update</strong>: Yes</li>
</ul>
</li>
<li><strong>Webhook</strong>:
<ul dir="auto">
<li><strong>Active</strong>: Yes</li>
<li><strong>Webhook URL</strong>: <a href="https://example.com/api/github/webhook" rel="nofollow">https://example.com/api/github/webhook</a></li>
</ul>
</li>
<li><strong>Permissions</strong>:
<ul dir="auto">
<li><strong>Repository permissions</strong>
<ul dir="auto">
<li><strong>Administration</strong>: Read and write</li>
<li><strong>Checks</strong>: Read and write</li>
<li><strong>Commit statuses</strong>: Read and write</li>
<li><strong>Contents</strong>: Read and write</li>
<li><strong>Deployments</strong>: Read and write</li>
<li><strong>Issues</strong>: Read and write</li>
<li><strong>Metadata</strong>: Read-only</li>
<li><strong>Pull requests</strong>: Read and write</li>
<li><strong>Webhook</strong>: Read and write</li>
</ul>
</li>
<li><strong>Account permissions</strong>:
<ul dir="auto">
<li><strong>Email addresses</strong>: Read-only</li>
</ul>
</li>
</ul>
</li>
<li><strong>Subscribe to events</strong>:
<ul dir="auto">
<li>Installation target</li>
<li>Push</li>
<li>Repository</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sign-in access control</h2><a id="user-content-sign-in-access-control" aria-label="Permalink: Sign-in access control" href="#sign-in-access-control"></a></p>
<p dir="auto">Provide an access rules file to restrict who can sign up/sign in.</p>
<ul dir="auto">
<li><strong>Development</strong>: edit <code>./access.json</code>. If missing, running <code>scripts/dev/start.sh</code> will sed an allow‑all file.</li>
<li><strong>Production</strong>: edit <code>/srv/devpush/access.json</code> on the server.</li>
</ul>
<p dir="auto">Rules format (any/all may be used):</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;emails&quot;: [&quot;alice@example.com&quot;],
  &quot;domains&quot;: [&quot;example.com&quot;],
  &quot;globs&quot;: [&quot;*@corp.local&quot;, &quot;*.dept.example.com&quot;],
  &quot;regex&quot;: [&quot;^[^@]+@(eng|research)\\.example\\.com$&quot;]
}"><pre>{
  <span>"emails"</span>: [<span><span>"</span>alice@example.com<span>"</span></span>],
  <span>"domains"</span>: [<span><span>"</span>example.com<span>"</span></span>],
  <span>"globs"</span>: [<span><span>"</span>*@corp.local<span>"</span></span>, <span><span>"</span>*.dept.example.com<span>"</span></span>],
  <span>"regex"</span>: [<span><span>"</span>^[^@]+@(eng|research)<span>\\</span>.example<span>\\</span>.com$<span>"</span></span>]
}</pre></div>
<p dir="auto">Globs use shell-style wildcards; regex are Python patterns. If the file is missing or empty, all valid emails are allowed.</p>
<p dir="auto">Additionally, if you set the <code>ACCESS_DENIED_WEBHOOK</code> <a href="#environment-variables">environment variable</a>, denied sign-in attempts will be posted to the provided URL with the following payload:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;email&quot;: &quot;user@example.com&quot;,
  &quot;provider&quot;: &quot;google&quot;,
  &quot;ip&quot;: &quot;203.0.113.10&quot;,
  &quot;user_agent&quot;: &quot;Mozilla/5.0&quot;
}"><pre>{
  <span>"email"</span>: <span><span>"</span>user@example.com<span>"</span></span>,
  <span>"provider"</span>: <span><span>"</span>google<span>"</span></span>,
  <span>"ip"</span>: <span><span>"</span>203.0.113.10<span>"</span></span>,
  <span>"user_agent"</span>: <span><span>"</span>Mozilla/5.0<span>"</span></span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/hunvreus/devpush/blob/main/LICENSE.md">MIT</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobel Prize in Physics 2025 (318 pts)]]></title>
            <link>https://www.nobelprize.org/prizes/physics/2025/popular-information/</link>
            <guid>45501189</guid>
            <pubDate>Tue, 07 Oct 2025 09:50:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nobelprize.org/prizes/physics/2025/popular-information/">https://www.nobelprize.org/prizes/physics/2025/popular-information/</a>, See on <a href="https://news.ycombinator.com/item?id=45501189">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

			<section>
	


	<article>

		<header>
			<h2>
				Popular information			</h2>
		</header>

		


												<p><a href="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025.pdf" target="_blank" rel="noreferrer noopener">Popular science background: Quantum properties on a human scale (pdf)</a><br><a href="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025-swedish.pdf" target="_blank" rel="noreferrer noopener">Populärvetenskaplig information: Kvantegenskaper på mänsklig skala (pdf)</a></p>
																														<figure><img fetchpriority="high" decoding="async" width="2048" height="978" src="https://www.nobelprize.org/images/174599-large-2x.jpg" alt="Logo The Royal Swedish Academy of Sciences"></figure>
																														<h2>Quantum properties on a human scale</h2>
																														<p>The Nobel Prize laureates in physics for 2025, <strong>John Clarke</strong>, <strong>Michel H. Devoret</strong> and <strong>John M. Martinis</strong>, used a series of experiments to demonstrate that the bizarre properties of the quantum world can be made concrete in a system big enough to be held in the hand. Their superconducting electrical system could tunnel from one state to another, as if it were passing straight through a wall. They also showed that the system absorbed and emitted energy in doses of specific sizes, just as predicted by quantum mechanics.</p>
																														<h3>A series of groundbreaking experiments</h3>
																														<figure><img decoding="async" width="1024" height="768" src="https://www.nobelprize.org/uploads/2025/10/fig_fy_25_4x3-1024x768.jpg" alt="Nobel Prize in Physics 2025"><figcaption><span>© Johan Jarnestad/The Royal Swedish Academy of Sciences</span></figcaption></figure>
																														<p>Quantum mechanics describes properties that are significant on a scale that involves single particles. In quantum physics, these phenomena are called <em>microscopic</em>, even when they are much smaller than can be seen using an optical microscope. This contrasts with <em>macroscopic</em> phenom­ena, which consist of a large number of particles. For example, an everyday ball is built up of an astronomical amount of molecules and displays no quantum mechanical effects. We know that the ball will bounce back every time it is thrown at a wall. A single particle, however, will sometimes pass straight through an equivalent barrier in its microscopic world and appear on the other side. This quantum mechanical phenomenon is called <em>tunnelling</em>.</p>
																														<p>This year’s Nobel Prize in Physics recognises experiments that demonstrated how quantum tunnelling can be observed on a macroscopic scale, involving many particles. In 1984 and 1985, John Clarke, Michel Devoret and John Martinis conducted a series of experiments at the University of California, Berkeley. They built an electrical circuit with two superconductors, components that can conduct a current without any electrical resistance. They separated these with a thin layer of material that did not conduct any current at all. In this experiment, they showed that they could control and investigate a phenomenon in which all the charged particles in the superconductor behave in unison, as if they are a single particle that fills the entire circuit.</p>
																														<figure><img decoding="async" width="1024" height="274" src="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025-figure2-1024x274.jpg" alt="Illustration"><figcaption>Figure 2. When you throw a ball at a wall, you can be sure it will bounce back at you. You would be extremely surprised if the ball suddenly appeared on the other side of a solid wall. This is exactly the type of phenomenon that has given quantum physics a reputation for being bizarre and unintuitive.&nbsp;<span>©Johan Jarnestad/The Royal Swedish Academy of Sciences</span></figcaption></figure>
																														<p>This particle-like system is trapped in a state in which current flows without any voltage – a state from which it does not have enough energy to escape. In the experiment, the system shows its quantum character by using tunnelling to escape the zero-voltage state, generating an electrical voltage. The laureates were also able to show that the system is quantised, which means it only absorbs or emits energy in specific amounts.</p>
																														<figure><img decoding="async" width="1024" height="568" src="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025-figure3-1024x568.jpg" alt="Illustration"><figcaption>Figure 3. Initially, the experiment has no voltage at all. It is as if there is a lever in the off position, and something is blocking from being moved to on. Without the effects of quantum mechanics, this state would remain unchanged. Suddenly, a voltage appears. This is as if the lever has moved from off to on, despite the barrier between the two. What happened in the experiment is called macroscopic quantum tunnelling.&nbsp;<span>©Johan Jarnestad/The Royal Swedish Academy of Sciences</span></figcaption></figure>
																														<h3>Tunnels and crossings</h3>
																														<p>To help them, the laureates had concepts and experimental tools that had been developed over decades. Together with the theory of relativity, quantum physics is the foundation of what has come to be called modern physics, and researchers have spent the last century exploring what it entails.</p>
																														<p>Individual particles’ ability to tunnel is well known. In 1928, the physicist George Gamow realised that tunnelling is the reason why some heavy atomic nuclei tend to decay in a particular manner. The interaction between the forces in the nucleus creates a barrier around it, holding in the particles it contains. However, despite this, a small piece of the atomic nucleus can sometimes split off, move outside the barrier and escape – leaving behind a nucleus that has been transformed into another element. Without tunnelling, this type of nuclear decay could not occur.</p>
																														<p>Tunnelling is a quantum mechanical process, which entails that chance plays a role. Some types of atomic nuclei have a tall, wide barrier, so it can take a long while for a piece of the nucleus to appear outside it, while other types decay more easily. If we only look at a single atom, we cannot predict when this will happen, but by watching the decay of a large number of nuclei of the same type, we can measure an expected time before tunnelling occurs. The most common way of describing this is through the concept of half-life, which is how long it takes for half the nuclei in a sample to decay.</p>
																														<figure><img decoding="async" width="1024" height="276" src="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025-figure4-1024x276.jpg" alt="Illustration"><figcaption>Figure 4. Physicists have known for almost a century that tunnelling is necessary for a particular type of nuclear decay (alpha decay). A tiny piece of the atom’s nucleus breaks free and appears outside it.&nbsp;<span>©Johan Jarnestad/The Royal Swedish Academy of Sciences</span></figcaption></figure>
																														<p>Physicists were quick to wonder whether it would be possible to investigate a type of tunnelling that involves more than one particle at a time. One approach to new types of experiments originated in a phenomenon that arises when some materials get extremely cold.</p>
																														<p>In an ordinary conductive material, current flows because there are electrons that are free to move through the entire material. In some materials, the individual electrons that push their way through the conductor may become organised, forming a synchronised dance that flows without any resistance. The material has become a superconductor and the electrons are joined together as pairs. These are called Cooper pairs, after <a href="https://www.nobelprize.org/prizes/physics/1972/cooper/facts/">Leon Cooper</a> who, along with <a href="https://www.nobelprize.org/prizes/physics/1956/bardeen/facts/">John Bardeen</a> and <a href="https://www.nobelprize.org/prizes/physics/1972/schrieffer/facts/">Robert Schrieffer</a>, provided a detailed description of how superconductors work (<a href="https://www.nobelprize.org/prizes/physics/1972/summary/">Nobel Prize in Physics 1972</a>).</p>
																														<p>Cooper pairs behave completely differently to ordinary electrons. Electrons have a great deal of integrity and like to stay at a distance from each other – two electrons cannot be in the same place if they have the same properties. We can see this in an atom, for example, where the electrons divide themselves into different energy levels, called shells. However, when the electrons in a superconductor join up as pairs, they lose a bit of their individuality; while two separate electrons are always distinct, two Cooper pairs can be exactly the same. This means the Cooper pairs in a superconductor can be described as a single unit, one quantum mechanical system. In the language of quantum mechanics, they are then described as a single <em>wave function</em>. This wave function describes the probability of observing the system in a given state and with given properties.</p>
																														<figure><img decoding="async" width="1024" height="697" src="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025-figure5-1024x697.jpg" alt="Illustration"><figcaption>Figure 5. In a normal conductor, the electrons jostle with each other and with the material. When a material becomes a superconductor, the electrons join up as pairs, Cooper pairs, and form a current where there is no resistance. The gap in the illustration marks the Josephson junction. Cooper pairs can behave as if they were all a single particle that fills the entire electrical circuit. Quantum mechanics describes this collective state using a shared wave function. The properties of this wave function play the leading role in the laureates’ experiment.&nbsp;<span>©Johan Jarnestad/The Royal Swedish Academy of Sciences</span></figcaption></figure>
																														<p>If two superconductors are joined together with a thin insulating barrier between them, it creates a Josephson junction. This component is named after <a href="https://www.nobelprize.org/prizes/physics/1973/josephson/facts/">Brian Josephson</a>, who performed quantum mechanical calculations for the junction. He discovered that interesting phenomena arise when the wave functions on each side of the junction are considered (<a href="https://www.nobelprize.org/prizes/physics/1973/summary/">Nobel Prize in Physics 1973</a>). The Josephson junction rapidly found areas of application, including in precise measurements of fundamental physical constants and magnetic fields.</p>
																														<p>The construction also provided tools for exploring the fundamentals of quantum physics in a new way. One person who did so was <a href="https://www.nobelprize.org/prizes/physics/2003/leggett/facts/">Anthony Leggett</a> (<a href="https://www.nobelprize.org/prizes/physics/2003/summary/">Nobel Prize in Physics 2003</a>), whose theoretical work on macroscopic quantum tunnelling at a Josephson junction inspired new types of experiments.</p>
																														<h3>The research group starts its work</h3>
																														<p>These subjects were a perfect match for John Clarke’s research interests. He was a professor at the University of California, Berkeley, in the US, where he had moved after completing his doctoral degree at the University of Cambridge, UK, in 1968. At UC Berkeley he built up his research group and specialised in exploring a range of phenomena using superconductors and the Josephson junction.</p>
																														<p>By the mid-1980s, Michel Devoret had joined John Clarke’s research group as a postdoc, after receiving his doctorate in Paris. This group also included the doctoral student John Martinis. Together, they took on the challenge of demonstrating macroscopic quantum tunnelling. Vast amounts of care and precision were necessary to screen the experimental setup from all the interference that could affect it. They succeeded in refining and measuring all the properties of their electrical circuit, allowing them to understand it in detail.</p>
																														<p>To measure the quantum phenomena, they fed a weak current into the Josephson junction and measured the voltage, which is related to the electrical resistance in the circuit. The voltage over the Josephson junction was initially zero, as expected. This is because the wave function for the system is enclosed in a state that does not allow a voltage to arise. Then they studied how long it took for the system to tunnel out of this state, causing a voltage. Because quantum mechanics entails an element of chance, they took numerous measurements and plotted their results as graphs, from which they could read the duration of the zero-voltage state. This is similar to how measurements of the half-lives of atomic nuclei are based on statistics of numerous instances of decay.</p>
																														<figure><img decoding="async" width="1024" height="351" src="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025-figure6-1024x351.jpg" alt="Illustration"><figcaption>Figure 6. John Clarke, Michel Devoret and John Martinis constructed an experiment using a superconducting electrical circuit. The chip that held this circuit was about a centimetre in size. Previously, tunnelling and energy quantisation had been studied in systems that had just a few particles; here, these phenomena appeared in a quantum mechanical system with billions of Cooper pairs that filled the entire superconductor on the chip. In this way, the experiment took quantum mechanical effects from a microscopic scale to a macroscopic one.&nbsp;<span>©Johan Jarnestad/The Royal Swedish Academy of Sciences</span></figcaption></figure>
																														<p>The tunnelling demonstrates how the experimental setup’s Cooper pairs, in their synchronised dance, behave like a single giant particle. The researchers obtained further confirmation of this when they saw that the system had quantised energy levels. Quantum mechanics was named after the observation that the energy in microscopic processes is divided into separate packages, quanta. The laureates introduced microwaves of varying wavelengths into the zero-voltage state. Some of these were absorbed, and the system then moved to a higher energy level. This showed that the zero-voltage state had a shorter duration when the system contained more energy – which is exactly what quantum mechanics predicts. A microscopic particle shut behind a barrier functions in the same way.</p>
																														<figure><img decoding="async" width="1024" height="446" src="https://www.nobelprize.org/uploads/2025/10/popular-physicsprize2025-figure7-1024x446.jpg" alt="Illustration"><figcaption>Figure 7. A quantum mechanical system behind a barrier can have varying amounts of energy, but it can only absorb or emit specific amounts of this energy. The system is quantised. Tunnelling occurs more easily at a higher energy level than at a lower one so, statistically, a system with more energy is held captive for less time than one with less energy.&nbsp;<span>©Johan Jarnestad/The Royal Swedish Academy of Sciences</span></figcaption></figure>
																														<h3>Practical and theoretical benefit</h3>
																														<p>This experiment has consequences for the understanding of quantum mechanics. Other types of quantum mechanical effects that are demonstrated on the macroscopic scale are composed of many tiny individual pieces and their separate quantum properties. The microscopic components are then combined to cause macroscopic phenomena such as lasers, superconductors and superfluid liquids. However, this experiment instead created a macroscopic effect – a measurable voltage – from a state that is in itself macroscopic, in the form of a common wave function for vast numbers of particles.</p>
																														<p>Theorists like Anthony Leggett have compared the laureates’ macroscopic quantum system with <a href="https://www.nobelprize.org/prizes/physics/1933/schrodinger/facts/">Erwin Schrödinger</a>’s famous thought experiment featuring a cat in a box, where the cat would be both alive and dead if we did not look inside. (Erwin Schrödinger received the <a href="https://www.nobelprize.org/prizes/physics/1933/summary/">Nobel Prize in Physics 1933</a>.) The intention of his thought experiment was to show the absurdity of this situation, because the special properties of quantum mechanics are often erased at a macroscopic scale. The quantum properties of an entire cat cannot be demonstrated in a laboratory experiment.</p>
																														<p>However, Legget has argued that the series of experiments conducted by John Clarke, Michel Devoret and John Martinis showed that there are phenomena that involve vast numbers of particles which together behave just as quantum mechanics predicts. The macroscopic system that consists of many Cooper pairs is still many orders of magnitude smaller than a kitten – but because the experiment measures the quantum mechanical properties that apply to the system as a whole, for a quantum physicist it is fairly similar to Schrödinger’s imaginary cat.</p>
																														<p>This type of macroscopic quantum state offers new potential for experiments using the phenomena that govern the microscopic world of particles. It can be regarded as a form of artificial atom on a large scale – an atom with cables and sockets that can be connected into new test set-ups or utilised in new quantum technology. For example, artificial atoms are used to simulate other quantum systems and aid in understanding them.</p>
																														<p>Another example is the quantum computer experiment subsequently performed by Martinis, in which he utilised exactly the energy quantisation that he and the other two laureates had demon­strated. He used a circuit with quantised states as information-bearing units – a quantum bit. The lowest energy state and the first step upward functioned as zero and one, respectively. Superconducting circuits are one of the techniques being explored in attempts to construct a future quantum computer.</p>
																														<p>This year’s laureates have thus contributed to both practical benefit in physics laboratories and to providing new information for the theoretical understanding of our physical world.</p>
																														<hr>
																														<h3>Further reading</h3>
																														<p>Additional information on this year’s prizes, including a scientific background in English, is available on the website of the Royal Swedish Academy of Sciences, <em>www.kva.se</em>, and at <em>www.nobelprize.org</em>, where you can watch video from the press conferences, the Nobel Prize lectures and more. Information on exhibitions and activities related to the Nobel Prizes and the prize in economic sciences is available at <em>www.nobelprizemuseum.se</em>.</p>
																														<hr>
																														<h3>The Royal Swedish Academy of Sciences has decided to award the Nobel Prize in Physics 2025 to</h3>
																														<p><strong>JOHN CLARKE<br></strong>Born 1942 in Cambridge, UK. PhD 1968 from University of Cambridge, UK. Professor at University of California, Berkeley, USA.</p>
																														<p><strong>MICHEL H. DEVORET<br></strong>Born 1953 in Paris, France. PhD 1982 from Paris-Sud University, France. Professor at Yale University, New Haven, CT and University of California, Santa Barbara, USA.</p>
																														<p><strong>JOHN M. MARTINIS<br></strong>Born 1958. PhD 1987 from University of Californa, Berkeley, USA. Professor at University of California, Santa Barbara, USA.</p>
																														<p><em>“for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit”</em></p>
																														<hr>
																														<p><strong>Science Editors</strong>: Ulf Danielsson, Göran Johansson and Eva Lindroth, the Nobel Committee for Physics<br><strong>Text</strong>: Anna Davour<br><strong>Translation</strong>: Clare Barnes<br><strong>Illustrations</strong>: Johan Jarnestad<br><strong>Editor</strong>: Sara Gustavsson<br>© The Royal Swedish Academy of Sciences</p>
																											

		
		
<div>
	<p><a href="#content">
		Back to top	</a></p><svg width="18px" height="15px" viewBox="0 0 20 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" role="image" aria-labelledby="back-to-top-title  back-to-top-desc">
	<title id="back-to-top-title">Back To Top</title>
	<desc id="back-to-top-desc">Takes users back to the top of the page</desc>
	<g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
		<g transform="translate(-474.000000, -9998.000000)" fill="#2E2A25">
			<g transform="translate(474.000000, 9998.000000)">
				<g transform="translate(10.000000, 10.000000) rotate(45.000000) translate(-10.000000, -10.000000) translate(3.000000, 3.000000)">
					<rect x="0" y="0" width="2" height="14"></rect>
					<rect x="0" y="0" width="14" height="2"></rect>
				</g>
				<rect x="9" y="3" width="2" height="14"></rect>
			</g>
		</g>
	</g>
</svg>
</div>

	</article>
	<!--This has been added for backwards compatibility-->
	</section>

<section>

	


			<article>

			<div>
				<header>
					
					
				</header>

				
									<p>Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.</p>
				
							</div>

							<figure>
					<a href="https://www.nobelprize.org/"><picture><source data-srcset="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" media="(max-width: 479px)"><source data-srcset="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" media="(max-width: 979px)"><source data-srcset="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" media="(min-width: 980px)"><img src="https://www.nobelprize.org/uploads/2025/09/Announcement_Recommended_Live.jpg" alt="Watch the 2025 Nobel Prize announcements live" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></picture></a>				</figure>
			
					</article>
	</section>

<section>

	

	<form id="68e4f9549a827" method="GET" action="">

		<p><label for="mobile-dropdown">
				Select the category or categories you would like to filter by			</label>

			

		</p>

		<div>
			<p><label>Select the category or categories you would like to filter by</label></p><p><label for="physics">
						
						<span>
							Physics						</span>
					</label>
				</p>

			
				<p><label for="chemistry">
						
						<span>
							Chemistry						</span>
					</label>
				</p>

			
				<p><label for="medicine">
						
						<span>
							Medicine						</span>
					</label>
				</p>

			
				<p><label for="literature">
						
						<span>
							Literature						</span>
					</label>
				</p>

			
				<p><label for="peace">
						
						<span>
							Peace						</span>
					</label>
				</p>

			
				<p><label for="economic-sciences">
						
						<span>
							Economic Sciences						</span>
					</label>
				</p>

					</div>

		<p>

			<label for="increment-input">
				Choose a year you would like to search in			</label>

			

			
		</p>

		
	</form>

</section>






		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A mechanic offered a reason why no one wants to work in the industry (145 pts)]]></title>
            <link>https://www.motor1.com/news/774805/ford-ceo-complains-shortage-mechanics/</link>
            <guid>45500699</guid>
            <pubDate>Tue, 07 Oct 2025 08:27:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.motor1.com/news/774805/ford-ceo-complains-shortage-mechanics/">https://www.motor1.com/news/774805/ford-ceo-complains-shortage-mechanics/</a>, See on <a href="https://news.ycombinator.com/item?id=45500699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                                    
                        <p>Ford’s CEO recently said that there is a shortage of mechanics in the US. A mechanic says he knows exactly why it’s hard to find good help these days—and that car companies themselves may be to blame.</p>
<p>Wiktor Ivanovko posted a video to his <em>Facebook</em> page. It starts with a clip of comments made by Ford CEO Jim Farley to <em>Yahoo Finance</em> about how a lack of skilled mechanics is impacting the auto industry.</p>
<p>"This morning when I woke up, there were 6,000 bays in our dealerships," Farley says in the clip.</p>
<p><em>Yahoo Finance</em> editor Brian Sozzi asks, "Why is there a shortage of these workers?"</p>
<p>"Well, it’s a complicated problem, but—" Farley says as the video cuts out.</p>
<h2><span><svg><use xlink:href=""></use></svg></span>Response to Ford CEO's Skilled Workers Comments</h2>
<p>Clearly, Ivanovko thinks he’s got an idea why Ford is struggling to hire skilled mechanics. And it doesn’t have to do with lack of trained workers. It’s all about engineering and flat-rate pay for repairs under warranty.</p>
<p>“You’ll have to do this oil pan gasket on this F-250,” Ivanovko says, mimicking a <a href="https://www.motor1.com/news/774640/performance-sports-car-sales-q3-2025/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22774640%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22performance-sports-car-sales-q3-2025%22%7D">Ford</a> dealership manager. “You’ll have to pull the cab off of the frame to do it. And it’s under warranty, so it pays like .6 [hours]. Why don’t you want to work for me?”</p><div contenteditable="false" draggable="true">
			<p>Viral bits from across the social media landscape</p>
			<p>Our team of experts tracks what's trending so you don't have to—from viral videos to online debates that have everyone talking.</p>
		</div>
<div contenteditable="false" draggable="true" data-widget="video"><p><img draggable="false" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAJCAYAAAA7KqwyAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAABpJREFUeNpi/P//PwMlgImBQjBqwLAwACDAAOVfAw9/ZDvcAAAAAElFTkSuQmCC" alt=""></p><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/daC2V2NHAuI?autoplay=1&amp;mute=1&amp;si=WxWdXJaVsLWV1bsl" title="YouTube video player" width="560" loading="lazy"> </iframe></p> </div>
<p>Estimates vary, but online consensus is that it will take at least a few hours to remove the cab of a truck, and upwards of an entire day. But if the warranty pays a flat rate of just 40 minutes for a repair that requires removing the cab first, the mechanic is essentially losing time and money.</p>
<p>Many self-identified mechanics who commented on Ivanovko’s post blamed the engineers who design vehicles for making them difficult to work on.</p>
<p>“Engineers should design them to be worked on. Not to speed up the assembly process,” wrote one.</p>
<h2><span><svg><use xlink:href=""></use></svg></span>Why Is Ford Struggling to Hire Skilled Mechanics?</h2>
<p>While Ford has 6,000 open positions, Farley estimated that the overall economy needs another 400,000 mechanic technicians. He blamed the gap on decreased productivity over the past 20 years, the lack of glamour associated with the position, and excessive regulation.</p>
<p>According to <em><a href="https://www.marketwatch.com/insurance-services/car-warranty/auto-tech-shortage/" target="_blank" rel="noopener">MarketWatch</a></em>, the automotive industry is indeed short nearly half a million mechanics. While Farley focused on public perception of working people as a primary driver of this shortage, analysts attributed it to a lack of mechanics graduating from school, a wave of retirements by older generations of mechanics, and the fact that new vehicles generally last longer than older ones.</p>
<p>Mechanics on a <em>Reddit</em> <a href="https://www.reddit.com/r/AutoMechanics/comments/1in1sdk/theres_a_mechanic_shortage_according_to_fox_news/" target="_blank" rel="noopener">thread</a> posted to r/AutoMechanics earlier this year note the study and dedication needed to learn the trade, the long hours, and the physical aspect of the job. Add to that the fact that it’s <a href="https://www.cbsnews.com/miami/news/rising-car-repair-costs-squeeze-drivers-and-small-shops/" target="_blank" rel="noopener">more expensive</a> than ever to run an auto body shop, and you’ve got a recipe for a shortage.</p>
<p>However, there are signs this trend might be reversing, including an <a href="https://www.washingtontimes.com/news/2024/jul/3/trade-school-enrollments-boom-as-high-school-grads/" target="_blank" rel="noopener">increased number</a> of mechanic graduates entering the job market.</p>
<h2><span><svg><use xlink:href=""></use></svg></span>Viewers React to Ivanovko’s Ford Response</h2>
<p>In the comments, viewers reacted to Ivanovko’s retort to the Ford CEO. Many said his criticism is justified.</p>
<p>“Always been a strong believer that if you want to be an engineer, you should have to work in the trade for no less than two years,” wrote one viewer. “So they understand what it takes.”</p>
<p>“And you have to buy all of your own tools to do it,” agreed a second viewer.</p>
<p>A third viewer added, “I’m not a mechanic, but maybe make vehicles that are less of a hassle to work on and this goes for all vehicle manufacturers.”</p>
<p><em>Motor1</em> contacted Ivanovko via Instagram direct message for comment. We’ll update this if he responds.</p>

<section contenteditable="false" draggable="true" data-widget="related-content" data-widget-size="content" data-params="%7B%22type_id%22%3A0%2C%22title_id%22%3A%22%22%2C%22items%22%3A%5B%7B%22article_edition_id%22%3A%22774702%22%2C%22title%22%3A%22'Not%20This%20Guy%20Again%3A'%20Advance%20Auto%20Parts%20Worker%20Calls%20Out%20Customers%20Who%20Buy%20Windshield%20Wipers%20and%20Refuse%20This%20Free%20Store%20Add-On%22%2C%22alias%22%3A%22advance-auto-parts-windshield-wipers%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FOoMZwo%2Fs5%2Fadvance-auto-parts-worker-calls-out-customers-who-buy-windshield-wipers-and-refuse-this-free-store-add-on.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22774503%22%2C%22title%22%3A%22Man%20Takes%20GMC%20Truck%20to%20Utah%20Mechanic.%20Then%20He's%20Told%20This%20One%20Mistake%20Will%20Cost%20%2415%2C000%20to%20Fix%22%2C%22alias%22%3A%22gmc-diesel-truck-15k-def-fix%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FwlWk4V%2Fs5%2Fone-mistake-will-cost-15-000.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22774267%22%2C%22title%22%3A%22Colorado%20Mechanic%20Reveals%20the%20Biggest%20Lie%20Customers%20Tell.%20Why%20Your%20Mechanic%20Isn't%20Buying%20It%22%2C%22alias%22%3A%22colorado-mechanic-reveals-customers-biggest-lie%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FlElGzO%2Fs5%2Fcolorado-mechanic-reveals-the-biggest-lie-customers-tell.-here-s-why-your-mechanic-isn-t-buying-it.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22774265%22%2C%22title%22%3A%22Georgia%20Mechanic%20Calls%20Out%20Shop%20That%20Replaced%20Tire%20With%20Wrong%20Size.%20Then%20He%20Reveals%20How%20to%20Tell%20What%20Size%20You%20Need%22%2C%22alias%22%3A%22how-to-check-tire-size%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2F404YwY%2Fs5%2Ftire-label-on-cars.jpg%22%7D%7D%5D%7D"> <p>More From Motor1</p>  </section>                                                                        <!-- new gallery place, attached gallery -->
                        
                                                                            
                                                    

                                                    

                                                            
                                                        
                                                                
                            
                            
                            
                                                            
                                
                            
                                
                                                            
                                                                         </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deloitte to refund the Australian government after using AI in $440k report (393 pts)]]></title>
            <link>https://www.theguardian.com/australia-news/2025/oct/06/deloitte-to-pay-money-back-to-albanese-government-after-using-ai-in-440000-report</link>
            <guid>45500485</guid>
            <pubDate>Tue, 07 Oct 2025 07:51:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/australia-news/2025/oct/06/deloitte-to-pay-money-back-to-albanese-government-after-using-ai-in-440000-report">https://www.theguardian.com/australia-news/2025/oct/06/deloitte-to-pay-money-back-to-albanese-government-after-using-ai-in-440000-report</a>, See on <a href="https://news.ycombinator.com/item?id=45500485">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Deloitte will provide a partial refund to the federal government over a $440,000 report that contained several errors, after admitting it used generative artificial intelligence to help produce it.</p><p>The Department of Employment and Workplace Relations (DEWR) confirmed Deloitte would repay the final instalment under its contract, which will be made public after the transaction is finalised. It comes as one Labor senator accused the consultancy firm of having a “human intelligence problem”.</p><p>Deloitte was commissioned by the department to review the targeted compliance framework and its IT system, used to automate penalties in the welfare system if <a href="https://www.theguardian.com/australia-news/article/2024/may/16/centrelink-mutual-obligations-budget-changes-jobseeker-suspensions" data-link-name="in body link">mutual obligations</a> weren’t met by jobseekers, in December 2024.</p><p><a href="https://www.theguardian.com/email-newsletters?CMP=copyembed&amp;CMP=emailbutton" data-link-name="in body link"><sub>Sign up: AU Breaking News email</sub></a></p><p>The subsequent report found widespread issues, including a lack of “traceability” between the rules of the framework and the legislation behind it, as well as “system defects”. It said an IT system was “driven by punitive assumptions of participant non-compliance”.</p><p>It was first published on 4 July. It was re-uploaded to the DEWR website on Friday, after the <a href="https://www.afr.com/companies/professional-services/academics-raise-alarm-over-suspected-ai-use-in-deloitte-report-20250822-p5mp0f" data-link-name="in body link">Australian Financial Review</a> in August reported that multiple errors had been found, including nonexistent references and citations.</p><figure id="6d2d999f-8ada-4138-b34e-710e6806c7f3" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:6,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Labor asks Deloitte to design universal childcare system as PM eyes political legacy&quot;,&quot;elementId&quot;:&quot;6d2d999f-8ada-4138-b34e-710e6806c7f3&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/australia-news/2025/aug/11/labor-asks-deloitte-to-design-universal-childcare-system-as-pm-eyes-political-legacy&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>University of Sydney academic, Dr Christopher Rudge, who first highlighted the errors, said the report contained “hallucinations” where AI models may fill in gaps, misinterpret data, or try to guess answers.</p><p>“Instead of just substituting one hallucinated fake reference for a new ‘real’ reference, they’ve substituted the fake hallucinated references and in the new version, there’s like five, six or seven or eight in their place,” he said.</p><p>“So what that suggests is that the original claim made in the body of the report wasn’t based on any one particular evidentiary source.”</p><p>The updated review noted a “small number of corrections to references and footnotes”, but the department has said there have been no changes to the review’s recommendations.</p><p>“Deloitte conducted the independent assurance review and has confirmed some footnotes and references were incorrect,” a spokesperson for the department said.</p><p>“The substance of the independent review is retained, and there are no changes to the recommendations.”</p><p>In the updated version of the report, Deloitte added reference to the use of generative AI in its appendix. It states that a part of the report “included the use of a generative artificial intelligence (AI) large language model (Azure OpenAI GPT – 4o) based tool chain licensed by DEWR and hosted on DEWR’s Azure tenancy.”</p><p>Deloitte did not state that artificial intelligence was the reason behind the errors in its original report. It also stood by the original findings of the review.</p><p>“The updates made in no way impact or affect the substantive content, findings and recommendations in the report,” it stated in the amended version.</p><p>A spokesperson for Deloitte said “the matter has been resolved directly with the client”.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-17">skip past newsletter promotion</a><p id="EmailSignup-skip-link-17" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Rudge said that, despite his criticism, he hesitates to say the whole report should be “regarded as illegitimate”, because the conclusions concur with other widespread evidence.</p><p>Labor senator Deborah O’Neill, who was on a senate inquiry into the integrity of consulting firms, said it looked like “AI is being left to do the heavy lifting”.</p><p>“Deloitte has a human intelligence problem. This would be laughable if it wasn’t so lamentable. A partial refund looks like a partial apology for substandard work,” she said.</p><p>“Anyone looking to contract these firms should be asking exactly who is doing the work they are paying for, and having that expertise and no AI use verified.</p><p>“Perhaps instead of a big consulting firm, procurers would be better off signing up for a ChatGPT subscription.”</p><p>The <a href="https://www.afr.com/companies/professional-services/deloitte-to-refund-government-after-admitting-ai-errors-in-440k-report-20251005-p5n05p" data-link-name="in body link">AFR found several incorrect references</a> in the original report, including nonexistent reports by professors at the University of Sydney and the Lund University in Sweden.</p><p>The paper also reported a made-up reference to a court decision in a <a href="https://www.theguardian.com/australia-news/centrelink-debt-recovery" data-link-name="in body link">robodebt</a> case, Deanna Amato v Commonwealth. Deloitte wrote in its final report that the update “amend[ed] the summary of the Amato proceeding which contained errors”.</p><figure id="0f9f16f6-acb2-496d-a5b5-1fbace13548b" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.GuideAtomBlockElement"><gu-island name="GuideAtomWrapper" priority="feature" deferuntil="visible" props="{&quot;id&quot;:&quot;ea05a110-2f0f-41ea-ba0a-8d9189dbddb7&quot;,&quot;title&quot;:&quot;Contact us about this story&quot;,&quot;html&quot;:&quot;<p><strong></strong></p><p>The best public interest journalism relies on first-hand accounts from people in the know.</p><p></p><p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p><p><strong>Secure Messaging in the Guardian app</strong></p><p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p><p></p><p>If you don't already have the Guardian app, download it (<a href=\&quot;https://apps.apple.com/app/the-guardian-live-world-news/id409128287\&quot;>iOS</a>/<a href=\&quot;https://play.google.com/store/apps/details?id=com.guardian\&quot;>Android</a>) and go to the menu. Select ‘Secure Messaging’. </p><p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p><p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href=\&quot;https://www.theguardian.com/securedrop\&quot;>SecureDrop platform</a>.</p><p></p><p>Finally, our guide at <a href=\&quot;https://www.theguardian.com/tips\&quot;>theguardian.com/tips</a>&amp;nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&amp;nbsp;</p>&quot;,&quot;image&quot;:&quot;https://i.guim.co.uk/img/media/ae475ccca7c94a4565f6b500a485479f08098383/788_0_4000_4000/4000.jpg?width=620&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=45fd162100b331bf1618e364c5c69452&quot;,&quot;credit&quot;:&quot;Illustration: Guardian Design / Rich Cousins&quot;}"><div data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-atom-type="guide"><details data-atom-id="ea05a110-2f0f-41ea-ba0a-8d9189dbddb7" data-snippet-type="guide"><summary><span>Quick Guide</span><h4>Contact us about this story</h4><span><span><span></span>Show</span></span></summary><div><p><img src="https://i.guim.co.uk/img/media/ae475ccca7c94a4565f6b500a485479f08098383/788_0_4000_4000/4000.jpg?width=620&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=45fd162100b331bf1618e364c5c69452" alt=""></p><div><p>The best public interest journalism relies on first-hand accounts from people in the know.</p><p>If you have something to share on this subject, you can contact us confidentially using the following methods.</p><p><strong>Secure Messaging in the Guardian app</strong></p><p>The Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.</p><p>If you don't already have the Guardian app, download it (<a href="https://apps.apple.com/app/the-guardian-live-world-news/id409128287">iOS</a>/<a href="https://play.google.com/store/apps/details?id=com.guardian">Android</a>) and go to the menu. Select ‘Secure Messaging’. </p><p><strong>SecureDrop, instant messengers, email, telephone and post</strong></p><p>If you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our <a href="https://www.theguardian.com/securedrop">SecureDrop platform</a>.</p><p>Finally, our guide at <a href="https://www.theguardian.com/tips">theguardian.com/tips</a>&nbsp;lists several ways to contact us securely, and discusses the pros and cons of each.&nbsp;</p></div><div><p>Illustration: Guardian Design / Rich Cousins</p></div></div></details></div></gu-island></figure><figure id="4d4dd026-b15b-49b1-842a-6a1b28d125a7" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.EmbedBlockElement"><gu-island name="UnsafeEmbedBlockComponent" priority="feature" deferuntil="visible" props="{&quot;html&quot;:&quot;<script src=\&quot;https://uploads.guim.co.uk/2025/01/21/article-button.js\&quot;><script>&quot;,&quot;alt&quot;:&quot;pointer&quot;,&quot;index&quot;:26,&quot;isTracking&quot;:false,&quot;isMainMedia&quot;:false,&quot;source&quot;:&quot;The Guardian&quot;,&quot;sourceDomain&quot;:&quot;uploads.guim.co.uk&quot;}"></gu-island></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California law forces Netflix, Hulu to turn down ad volumes (288 pts)]]></title>
            <link>https://www.politico.com/news/2025/10/06/dial-it-down-california-forces-netflix-hulu-to-lower-ad-volume-00595663</link>
            <guid>45499281</guid>
            <pubDate>Tue, 07 Oct 2025 04:03:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.politico.com/news/2025/10/06/dial-it-down-california-forces-netflix-hulu-to-lower-ad-volume-00595663">https://www.politico.com/news/2025/10/06/dial-it-down-california-forces-netflix-hulu-to-lower-ad-volume-00595663</a>, See on <a href="https://news.ycombinator.com/item?id=45499281">Hacker News</a></p>
Couldn't get https://www.politico.com/news/2025/10/06/dial-it-down-california-forces-netflix-hulu-to-lower-ad-volume-00595663: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Pdoc – Generate API documentation for Python projects (107 pts)]]></title>
            <link>https://pdoc.dev/</link>
            <guid>45499170</guid>
            <pubDate>Tue, 07 Oct 2025 03:40:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pdoc.dev/">https://pdoc.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=45499170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
                <code>pdoc</code> auto-generates API documentation that follows your project's Python module hierarchy.
                It requires no configuration, has first-class support for type annotations,
                cross-links between identifiers, comes with an integrated live-reloading web server,
                and understands numpydoc or Google-style docstrings.
            </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The least amount of CSS for a decent looking site (2023) (687 pts)]]></title>
            <link>https://thecascade.dev/article/least-amount-of-css/</link>
            <guid>45497624</guid>
            <pubDate>Mon, 06 Oct 2025 23:47:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thecascade.dev/article/least-amount-of-css/">https://thecascade.dev/article/least-amount-of-css/</a>, See on <a href="https://news.ycombinator.com/item?id=45497624">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <header> 
    <!-- {heroImage && <BlogImage 
      src={heroImage} 
      widths={[350, 700]} 
      sizes="(max-width: 800px) 650px, 900px, 1600px" 
      aspectRatio="16:9" 
      formats={['avif', 'webp']} 
      alt={heroAlt}/>} 
     -->
    

    <p><strong>Summary:</strong> People often over-engineer solutions, and it leads to them running into problems with their CSS. In this article, we'll take a look at the least amount of CSS that you need to make a decent looking page.</p>
    
    
    
    

    </header>

    

<lite-youtube videoid="wBKT2KN_Y9s"></lite-youtube>






    
  
  <p>The fun part of making a website is that if you write your HTML and nothing else, you have a responsive website.</p>
<p>Granted, if you have images they can cause some overflow issues.</p>
<p>So we can start things off by fixing that:</p>
<pre><code is:raw=""><span>img</span> <span>{</span>
  <span>max-width</span><span>:</span> 100%<span>;</span>
  <span>display</span><span>:</span> block<span>;</span>
<span>}</span></code></pre>
<p>It’s possible you have videos or SVGs that are also causing problems (less likely with SVGs though), so if you need, you can expand upon this a little bit.</p>
<pre><code is:raw=""><span>img,
svg,
video</span> <span>{</span>
  <span>max-width</span><span>:</span> 100%<span>;</span>
  <span>display</span><span>:</span> block<span>;</span>
<span>}</span></code></pre>
<h2 id="improving-the-typography">Improving the typography</h2>
<p>The first thing we can do is change the font family since the default is never very exciting.</p>
<p>We’ll just use a basic <code>system-ui</code> for this example. It has pretty good support these days, and looks good on every system without having to worry about loading in any extra fonts.</p>
<p>In general, the font-size is a little small as well, so we can bump it up, and the default line-height is always a bit tight, so anything within the 1.5 to 1.7 range should do:</p>
<pre><code is:raw=""><span>body</span> <span>{</span>
  <span>font-family</span><span>:</span> System UI<span>;</span>
  <span>font-size</span><span>:</span> 1.25rem<span>;</span>
  <span>line-height</span><span>:</span> 1.5<span>;</span>
<span>}</span></code></pre>
<p>Though not perfect, this is already a huge improvement over the regular defaults.</p>
<h2 id="adding-dark-mode-support">Adding Dark Mode Support</h2>
<p>Many people love dark mode, so let’s enable it based on a user’s system preferences.</p>
<p>We can do this by using the <code>color-scheme</code> property:</p>
<pre><code is:raw=""><span>html</span> <span>{</span>
  <span>color-scheme</span><span>:</span> light dark<span>;</span>
<span>}</span></code></pre>
<p>This will set the user-agent-styles to either a light or dark theme, based on the users system preferences.</p>
<p>If you’d prefer, we can do this without CSS as well!</p>
<pre><code is:raw=""><span><span><span>&lt;</span>html</span> <span>lang</span><span><span>=</span><span>"</span>en<span>"</span></span> <span>color-scheme</span><span><span>=</span><span>"</span>light dark<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre>
<h3 id="a-small-note-on-following-the-system-preferences">A small note on following the system preferences</h3>
<p>While this is really handy, it is a best practice to allow users to manually toggle the color-scheme as well.</p>
<p>Some people prefer a dark system theme, but light website themes, and vice-versa.</p>
<h2 id="restraining-content-width">Restraining Content Width</h2>
<p>Line-length is one of the most important things when it comes to the readability of text.</p>
<p>We generally <a href="https://practicaltypography.com/line-length.html">want to try and fall somewhere in the 45-90 characters per line range</a> (for body text, not headlines).</p>
<p>To make the website more readable, we’ll limit the content width using a <code>main</code> element and some CSS magic:</p>
<pre><code is:raw=""><span>main</span> <span>{</span>
  <span>max-width</span><span>:</span> <span>min</span><span>(</span>70ch<span>,</span> 100% - 4rem<span>)</span><span>;</span>
  <span>margin-inline</span><span>:</span> auto<span>;</span>
<span>}</span></code></pre>
<p>The <code>min()</code> function here will pick whatever is smallest, either <code>70ch</code> or <code>100% - 4rem</code>. Because we are inside a <code>min()</code> function, we don’t need to use a <code>calc()</code>.</p>
<p>Whatever the output from that min() function, the width is less than 100%, so the page will be stuck to the left side of the viewport.</p>
<p>We can then use margin-inline: auto to center it, as this acts on the margins on the inline axis, so in any horizontal writing modes, that means both the margin-left and margin-right are auto.</p>
<p>You might want to switch out the main selector for a .container or .wrapper so you can have more control over where you use it.</p>
<p>And with that, our final CSS file looks like this:</p>
<pre><code is:raw=""><span>html</span> <span>{</span>
  <span>color-scheme</span><span>:</span> light dark<span>;</span>
<span>}</span>

<span>body</span> <span>{</span>
  <span>font-family</span><span>:</span> system-ui<span>;</span>
  <span>font-size</span><span>:</span> 1.25rem<span>;</span>
  <span>line-height</span><span>:</span> 1.5<span>;</span>
<span>}</span>

<span>img,
svg,
video</span> <span>{</span>
  <span>max-width</span><span>:</span> 100%<span>;</span>
  <span>display</span><span>:</span> block<span>;</span>
<span>}</span>

<span>main</span> <span>{</span>
  <span>max-width</span><span>:</span> <span>min</span><span>(</span>70ch<span>,</span> 100% - 4rem<span>)</span><span>;</span>
  <span>margin-inline</span><span>:</span> auto<span>;</span>
<span>}</span></code></pre>
<h2 id="build-on-top-of-this">Build on top of this</h2>
<p>This is just a quick start to get things off the ground, though it could be used for a very simple page as well.</p>
<p>For the most part, though, you’ll probably want to build on top of this, but it should be able to act as a nice jumping off point!</p>

     
    
    
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft is plugging more holes that let you use Windows 11 without MS account (537 pts)]]></title>
            <link>https://www.theverge.com/news/793579/microsoft-windows-11-local-account-bypass-workaround-changes</link>
            <guid>45497384</guid>
            <pubDate>Mon, 06 Oct 2025 23:15:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/793579/microsoft-windows-11-local-account-bypass-workaround-changes">https://www.theverge.com/news/793579/microsoft-windows-11-local-account-bypass-workaround-changes</a>, See on <a href="https://news.ycombinator.com/item?id=45497384">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://www.theverge.com/authors/tom-warren"><img alt="Tom Warren" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/197777/profilephoto.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/197777/profilephoto.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/197777/profilephoto.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></a></p><div><p><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span id="follow-author-standard_article_details-dmcyOmF1dGhvclByb2ZpbGU6MTY0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span></span><span>Tom Warren</span></span></span></p> <p><span>is a senior editor and author of <a href="https://www.theverge.com/notepad-microsoft-newsletter"><i>Notepad</i></a>, who has been covering all things Microsoft, PC, and tech for over 20 years.</span></p></div></div><div id="zephr-anchor"><p>Microsoft is cracking down on bypass methods that let Windows 11 installs use a local account, and avoid an internet requirement during the setup process. In a new <a href="https://blogs.windows.com/windows-insider/2025/10/06/announcing-windows-11-insider-preview-build-26220-6772-dev-channel/">Windows 11 test build</a> released today, Microsoft says it’s removing known workarounds for creating local accounts as they can apparently cause issues during the setup process.</p><p>“We are removing known mechanisms for creating a local account in the Windows Setup experience (OOBE),” says Amanda Langowski, the lead for the Windows Insider Program. “While these mechanisms were often used to bypass Microsoft account setup, they also inadvertently skip critical setup screens, potentially causing users to exit OOBE with a device that is not fully configured for use.”</p><p>The changes mean Windows 11 users will need to complete the OOBE screens with an internet connection and Microsoft account in future versions of the OS.</p><p>Microsoft already <a href="https://www.theverge.com/news/638967/microsoft-windows-11-account-internet-bypass-blocked">removed the “bypassnro” workaround</a> earlier this year, and today’s changes also disable the “start ms-cxh:localonly” command that <a href="https://x.com/witherornot1337/status/1906050664741937328">Windows 11 users discovered</a> after Microsoft’s previous changes. Using this command now resets the OOBE process and it fails to bypass the Microsoft account requirement.</p><p>These workarounds have been widely used to avoid a Microsoft account or internet access on Windows 11 Pro and Home installs in recent years. They’re easy to use, so you don’t have to create a custom unattended answer file to force Windows 11 to create a local account.</p><p>A lot of Windows users simply want to avoid using a Microsoft account or just want to customize the user folder name that Windows 11 creates from the email address of a Microsoft account. Thankfully, Microsoft is now adding a way to name your default user folder during the setup process, although you’ll need to use a command to get a custom folder name. Hopefully this will eventually become a simple option during the setup process.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6MTY0"><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Tom Warren</span></span></span></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RediShell: Critical remote code execution vulnerability in Redis (117 pts)]]></title>
            <link>https://www.wiz.io/blog/wiz-research-redis-rce-cve-2025-49844</link>
            <guid>45497027</guid>
            <pubDate>Mon, 06 Oct 2025 22:30:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wiz.io/blog/wiz-research-redis-rce-cve-2025-49844">https://www.wiz.io/blog/wiz-research-redis-rce-cve-2025-49844</a>, See on <a href="https://news.ycombinator.com/item?id=45497027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2><a id="executive-summary-0"></a>Executive summary</h2><p>Wiz Research has uncovered a critical Remote Code Execution (RCE) vulnerability, CVE-2025-49844 which we've dubbed <strong>#RediShell</strong>, in the widely used Redis in-memory data structure store. The vulnerability has been assigned a <a href="https://github.com/redis/redis/security/advisories/GHSA-4789-qfc9-5f9q"><u>CVSS score of 10.0</u></a> - the highest possible severity (note that we have seen this listed as a 9.9 in some places, depending on the source).</p><p>The vulnerability exploits a Use-After-Free (UAF) memory corruption bug that has existed for approximately 13 years in the Redis source code. This flaw allows a post auth attacker to send a specially crafted malicious Lua script (a feature supported by default in Redis) to escape from the Lua sandbox and achieve arbitrary native code execution on the Redis host. This grants an attacker full access to the host system, enabling them to exfiltrate, wipe, or encrypt sensitive data, hijack resources, and facilitate lateral movement within cloud environments.</p><figure></figure><div><p>Given that Redis is used in an estimated 75% of cloud environments, the potential impact is extensive. Organizations are strongly urged to patch instances immediately by prioritizing those that are exposed to the internet.</p><p>On October 3, Redis </p><a href="https://redis.io/blog/security-advisory-cve-2025-49844/"><u>released a security advisory</u></a><p> along with a patched version of Redis. We extend our gratitude to the entire Redis team for their collaboration throughout the disclosure process. We greatly appreciate their transparency, responsiveness, and partnership during this engagement.</p><p>In this post, we will provide a high-level overview of our discovery and its implications. Given the prevalence and sensitivity of this vulnerability, we will defer some of the technical details to a future installment, omitting exploit information for now to allow impacted organizations sufficient time to address the vulnerability.</p><p>Organizations utilizing Redis are strongly encouraged to update their Redis instances to the latest version immediately.</p></div><h2><a id="vulnerability-meets-ubiquity-the-redis-risk-multiplier-5"></a>Vulnerability Meets Ubiquity: The Redis Risk Multiplier</h2><p>The newly disclosed RediShell (CVE-2025-49844) vulnerability in Redis has been assigned a CVSS score of 10.0 - a rating rarely seen, with only around 300 vulnerabilities receiving it in the past year. It’s also the first Redis vulnerability to be rated as critical. The score reflects not just the technical severity of remote code execution, but also how Redis is commonly used and deployed. Redis is widely used in cloud environments for caching, session management, and pub/sub messaging. While Redis has had a strong security history, the combination of this flaw and common deployment practices significantly increases its potential impact.</p><h2><a id="scope-7"></a>Scope</h2><p>Wiz Research discovered a Remote Code Execution vulnerability CVE-2025-49844 affecting the widely used Redis database. The vulnerability is a Use-After-Free (UAF) memory corruption that allows an attacker to send a malicious Lua script that leads to arbitrary code execution outside Redis’s Lua interpreter sandbox, gaining access to the host.</p><p>The urgency with which you should address this vulnerability depends on how Redis was installed and its exposure level.</p><h3><a id="exposure-analysis-10"></a>Exposure Analysis</h3><p>Our analysis across cloud environments revealed the extensive scope of this vulnerability:</p><ul><li><p><strong>Approximately 330,000 Redis instances</strong> are exposed to the internet at the time of this blog post</p></li><li><p><strong>About 60,000 instances</strong> have no authentication configured&nbsp;&nbsp;</p></li><li><p><strong>57% of cloud environments</strong> install Redis as container images, many without proper security hardening</p></li></ul><figure></figure><h3><a id="risk-assessment-14"></a>Risk Assessment</h3><p><strong>Critical Risk - Internet-Exposed + Unauthenticated:</strong></p><p><a href="https://hub.docker.com/_/redis"><u>The official Redis container</u></a>, by default, does not require authentication. Our analysis shows that 57% of cloud environments install Redis as an image. If not installed carefully, these instances may lack authentication entirely. The combination of no authentication and exposure to the internet is highly dangerous, allowing anyone to query the Redis instance and, specifically, send Lua scripts (which are enabled by default). This enables attackers to exploit the vulnerability and achieve RCE within the environment.</p><p><strong>High Risk - Internal Network Exposure:</strong></p><p>More Redis instances are exposed to internal networks where authentication may not be prioritized, allowing any host in the local network to connect to the database server. An attacker with a foothold in the cloud environment could gain access to sensitive data and exploit the vulnerability to run arbitrary code for lateral movement into sensitive networks.</p><h2><a id="attack-flow-and-impact-19"></a>Attack Flow and Impact</h2><p>The attack sequence demonstrates how an attacker can exploit RediShell (CVE-2025-49844) to achieve comprehensive system compromise:</p><p>Initial Exploitation</p><ul><li><p>Attacker sends a malicious Lua script to exploit the use-after-free vulnerability</p></li></ul><p>Sandbox Escape</p><ul><li><p>Script escapes the Lua sandbox and achieves arbitrary code execution</p></li><li><p>Establishes reverse shell for persistent access</p></li></ul><p>System Compromise</p><ul><li><p>Steals credentials (.ssh keys, IAM tokens, certificates)</p></li><li><p>Installs malware or crypto miners</p></li><li><p>Exfiltrates sensitive data from Redis and host</p></li></ul><p>Lateral Movement</p><ul><li><p>Uses stolen IAM tokens to access other cloud services</p></li><li><p>Escalates privileges and moves to additional systems</p></li></ul><h2><a id="the-result-host-remote-code-execution-30"></a>The Result: Host Remote Code Execution</h2><figure></figure><p><strong>**We recommend that all Redis users upgrade their instances immediately, as this vulnerability poses a significant risk.**</strong></p><h2><a id="disclosure-timeline-33"></a>Disclosure Timeline</h2><ul><li><p><strong>May 16, 2025</strong>: Initial vulnerability report sent to Redis in Pwn2Own Berlin.</p></li><li><p><strong>Oct 3, 2025</strong>: Redis publishes the security bulletin and assigned CVE-2025-49844.</p></li><li><p><strong>Oct 6, 2025</strong>: Wiz Research publishes this blog post.</p></li></ul><h2><a id="recommended-actions-35"></a><br>Recommended Actions</h2><ol><li><p><strong>Update Redis Immediately:</strong> Upgrade to the latest patched version. Prioritize any internet-exposed or unauthenticated instances.</p></li><li><p><strong>Security Hardening:</strong></p></li><li><p><strong>Enable Redis Authentication:</strong> Use the requirepass directive.</p></li><li><p><strong>Disable Unnecessary Commands:</strong> This includes Lua scripting if it's not being used. You can achieve this by revoking user scripting permissions via Redis ACLs or by disabling scripting commands.</p></li><li><p><strong>Run with Minimal Privileges:</strong> Operate Redis using a non-root user account.</p></li><li><p><strong>Enable Logging and Monitoring:</strong> Activate Redis logging and monitoring to track activity and identify potential issues.</p></li><li><p><strong>Implement Network-Level Access Controls:</strong> Utilize firewalls and Virtual Private Clouds (VPCs).</p></li><li><p><strong>Restrict Redis Access:</strong> Limit access to authorized networks only.</p></li></ol><h2><a id="how-wiz-can-help-37"></a>How Wiz can help</h2><p>Wiz customers can use the pre-built query and advisory in the Wiz Threat Center to assess the risk in their environment.</p><figure></figure><p>Wiz identifies both internal and publicly exposed Redis instances in your environment affected by CVE-2025-49844, and alerts you to instances that have been misconfigured to allow unauthenticated access or use weak or default passwords.</p><figure></figure><h2><a id="conclusion-treat-with-urgency-42"></a>Conclusion: treat with urgency </h2><p>RediShell (CVE-2025-49844) represents a critical security vulnerability that affects all Redis versions due to its root cause in the underlying Lua interpreter. With hundreds of thousands of exposed instances worldwide, this vulnerability poses a significant threat to organizations across all industries.</p><p>The combination of widespread deployment, default insecure configurations, and the severity of the vulnerability creates an urgent need for immediate remediation. Organizations must prioritize updating their Redis instances and implementing proper security controls to protect against exploitation.</p><p>This vulnerability also highlights how deeply today’s cloud environments depend on open-source technologies like Redis. That shared reliance is what motivated us, alongside other cloud providers, to launch<a href="https://www.zeroday.cloud/"> <u>ZeroDay.Cloud</u>,</a> a community-driven effort to identify and responsibly disclose critical zero-day vulnerabilities in the open-source software powering the cloud. Redis, along with other core open-source technologies, is part of that effort.</p><p>Wiz Research will continue to monitor the threat landscape and provide additional technical details in future publications so that organizations have time to implement necessary security measures.</p><p>For technical questions about this research, please contact: research@wiz.io</p><p>---</p><p>This research was conducted by the Wiz Research team. We thank the Redis security team for their professional handling of this disclosure and their commitment to user security.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CodeMender: an AI agent for code security (183 pts)]]></title>
            <link>https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/</link>
            <guid>45496533</guid>
            <pubDate>Mon, 06 Oct 2025 21:28:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/">https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/</a>, See on <a href="https://news.ycombinator.com/item?id=45496533">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      
  <article>
    
    
  
  
  
    
      

      
      
        
          
            <div>
              
                
                
                  
                  
<div>
    <div>
      <p>Responsibility &amp; Safety</p>
      <h2>Introducing CodeMender: an AI agent for code security</h2>

      
    <dl>
      
        <dt>Published</dt>
        <dd><time datetime="2025-10-06">6 October 2025</time></dd>
      
      
        <dt>Authors</dt>
        
      
    </dl>
  

      
    </div>

    
      
    
    
    <picture>
      <source media="(min-width: 1024px)" type="image/webp" width="1072" height="603" srcset="https://lh3.googleusercontent.com/qQXJtLUbwdtnv5JrIinBUj-JgdjB-aA65EWcYSWxiLGoYPj8jTSmTAE2mmEpk530JlkLnV21krL-KdOH6N1NghVnAKTmQLobB7PNKaSFHyjmawjgKw=w1072-h603-n-nu-rw 1x, https://lh3.googleusercontent.com/qQXJtLUbwdtnv5JrIinBUj-JgdjB-aA65EWcYSWxiLGoYPj8jTSmTAE2mmEpk530JlkLnV21krL-KdOH6N1NghVnAKTmQLobB7PNKaSFHyjmawjgKw=w2144-h1206-n-nu-rw 2x"><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/qQXJtLUbwdtnv5JrIinBUj-JgdjB-aA65EWcYSWxiLGoYPj8jTSmTAE2mmEpk530JlkLnV21krL-KdOH6N1NghVnAKTmQLobB7PNKaSFHyjmawjgKw=w928-h522-n-nu-rw 1x, https://lh3.googleusercontent.com/qQXJtLUbwdtnv5JrIinBUj-JgdjB-aA65EWcYSWxiLGoYPj8jTSmTAE2mmEpk530JlkLnV21krL-KdOH6N1NghVnAKTmQLobB7PNKaSFHyjmawjgKw=w1856-h1044-n-nu-rw 2x"><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/qQXJtLUbwdtnv5JrIinBUj-JgdjB-aA65EWcYSWxiLGoYPj8jTSmTAE2mmEpk530JlkLnV21krL-KdOH6N1NghVnAKTmQLobB7PNKaSFHyjmawjgKw=w528-h297-n-nu-rw 1x, https://lh3.googleusercontent.com/qQXJtLUbwdtnv5JrIinBUj-JgdjB-aA65EWcYSWxiLGoYPj8jTSmTAE2mmEpk530JlkLnV21krL-KdOH6N1NghVnAKTmQLobB7PNKaSFHyjmawjgKw=w1056-h594-n-nu-rw 2x">
      <img alt="A glowing, pixelated blue and pink ribbon curves across a light blue background. The ribbon appears to be made of individual squares, with some of the pink squares near the center breaking away and scattering, suggesting a dynamic process of change or repair." height="603" src="https://lh3.googleusercontent.com/qQXJtLUbwdtnv5JrIinBUj-JgdjB-aA65EWcYSWxiLGoYPj8jTSmTAE2mmEpk530JlkLnV21krL-KdOH6N1NghVnAKTmQLobB7PNKaSFHyjmawjgKw=w1072-h603-n-nu" width="1072">
    </picture>
    
  
    
  </div>
                
              
                
                
                  
                  <div>
  <p data-block-key="bx9s8">Using advanced AI to fix critical software vulnerabilities</p><p data-block-key="7jiud">Today, we’re sharing early results from our research on CodeMender, a new AI-powered agent that improves code security automatically.</p><p data-block-key="e8ggo">Software vulnerabilities are notoriously difficult and time-consuming for developers to find and fix, even with traditional, automated methods like fuzzing. Our AI-based efforts like <a href="https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html" rel="noopener" target="_blank">Big Sleep</a> and <a href="https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html" rel="noopener" target="_blank">OSS-Fuzz</a> have demonstrated AI’s ability to find new zero-day vulnerabilities in well-tested software. As we achieve more breakthroughs in AI-powered vulnerability discovery, it will become increasingly difficult for humans alone to keep up.</p><p data-block-key="16s9k">CodeMender helps solve this problem by taking a comprehensive approach to code security that’s both reactive, instantly patching new vulnerabilities, and proactive, rewriting and securing existing code and eliminating entire classes of vulnerabilities in the process. Over the past six months that we’ve been building CodeMender, we have already upstreamed 72 security fixes to open source projects, including some as large as 4.5 million lines of code.</p><p data-block-key="flpqu">By automatically creating and applying high-quality security patches, CodeMender’s AI-powered agent helps developers and maintainers focus on what they do best — building good software.</p><h2 data-block-key="ddl7e">CodeMender in action</h2><p data-block-key="2oqaj">CodeMender operates by leveraging the thinking capabilities of recent <a href="https://blog.google/products/gemini/gemini-2-5-deep-think/" rel="noopener" target="_blank">Gemini Deep Think</a> models to produce an autonomous agent capable of debugging and fixing complex vulnerabilities.</p><p data-block-key="5jo5">To do this, the CodeMender agent is equipped with robust tools that let it reason about code before making changes, and automatically validate those changes to make sure they’re correct and don’t cause regressions.</p>
</div>
                
              
                
                
                  
                  





<figure aria-label="Animation showing CodeMender’s process for fixing vulnerabilities." aria-describedby="caption-166fca69-5b27-40eb-8c43-c5ddc638fe22">
  

  <figcaption>
      <p data-block-key="hrdy6">Animation showing CodeMender’s process for fixing vulnerabilities.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="bx9s8">While large language models are rapidly improving, mistakes in code security could be costly. CodeMender’s automatic validation process ensures that code changes are correct across many dimensions by only surfacing for human review high-quality patches that, for example, fix the root cause of the issue, are functionally correct, cause no regressions and follow style guidelines.</p><p data-block-key="elveb">As part of our research, we also developed new techniques and tools that let CodeMender reason about code and validate changes more effectively. This includes:</p><ul><li data-block-key="5pp0s"><strong>Advanced program analysis:</strong> We developed tools based on advanced program analysis that include static analysis, dynamic analysis, differential testing, fuzzing and SMT solvers. Using these tools to systematically scrutinize code patterns, control flow and data flow, CodeMender can better identify the root causes of security flaws and architectural weaknesses.</li><li data-block-key="bth6s"><strong>Multi-agent systems:</strong> We developed special-purpose agents that enable CodeMender to tackle specific aspects of an underlying problem. For example, CodeMender uses a large language model-based critique tool that highlights the differences between the original and modified code in order to verify that the proposed changes do not introduce regressions, and self-correct as needed.</li></ul><h2 data-block-key="3719q">Fixing vulnerabilities</h2><p data-block-key="1f6os">To effectively patch a vulnerability, and prevent it from re-emerging, Code Mender uses a debugger, source code browser, and other tools to pinpoint root causes and devise patches. We have added two examples of CodeMender patching vulnerabilities in the video carousel below.</p><p data-block-key="1594o"><strong>Example #1: Identifying the root cause of a vulnerability</strong></p><p data-block-key="c3frf">Here’s a snippet of the agent's reasoning about the root cause for a CodeMender-generated patch, after analyzing the results of debugger output and a code search tool.</p><p data-block-key="7h86h">Although the final patch in this example only changed a few lines of code, the root cause of the vulnerability was not immediately clear. In this case, the crash report showed a heap buffer overflow, but the actual problem was elsewhere — an incorrect stack management of Extensible Markup Language (XML) elements during parsing.</p><p data-block-key="b8f29"><strong>Example #2: Agent is able to create non-trivial patches</strong></p><p data-block-key="au7ng">In this example, the CodeMender agent was able to come up with a non-trivial patch that deals with a complex object lifetime issue.</p><p data-block-key="38qf8">The agent was not only able to figure out the root cause of the vulnerability, but was also able to modify a completely custom system for generating C code within the project.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-f0c4e90a-9d3e-4fa4-8a22-68cdfd27b94f">
  
  
  
</gdm-carousel>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="c9bkr">Proactively rewriting existing code for better security</h2><p data-block-key="5nipp">We also designed CodeMender to proactively rewrite existing code to use more secure data structures and APIs.</p><p data-block-key="9nv9f">For example, we deployed CodeMender to apply <a href="https://clang.llvm.org/docs/BoundsSafety.html" rel="noopener" target="_blank">-fbounds-safety</a> annotations to parts of a widely used image compression library called <a href="https://github.com/webmproject/libwebp" rel="noopener" target="_blank">libwebp</a>. When <strong>-fbounds-safety</strong> annotations are applied, the compiler adds bounds checks to the code to prevent an attacker from exploiting a buffer overflow or underflow to execute arbitrary code.</p><p data-block-key="7pqtv">A few years ago, a heap buffer overflow vulnerability in libwebp (<a href="https://www.cve.org/CVERecord?id=CVE-2023-4863" rel="noopener" target="_blank">CVE-2023-4863</a>) was used by a threat actor as part of <a href="https://citizenlab.ca/2023/09/blastpass-nso-group-iphone-zero-click-zero-day-exploit-captured-in-the-wild/" rel="noopener" target="_blank">a zero-click iOS exploit</a>. With <strong>-fbounds-safety</strong> annotations, this vulnerability, along with most other buffer overflows in the project where we've applied annotations, would’ve been rendered unexploitable forever.</p><p data-block-key="3gflt">In the video carousel below we show examples of the agent’s decision-making process, including the validation steps.</p>
</div>
                
              
                
                
                  
                  <div>
  <p data-block-key="c9bkr"><strong>Example #1: Agent’s reasoning steps</strong></p><p data-block-key="460ho">In this example, the CodeMender agent is asked to address the following <strong>-fbounds-safety</strong> error on <strong>bit_depths</strong> pointer:</p>
</div>
                
              
                
                
                  
                  





<figure>
  

  
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="tpfo0"><strong>Example #2: Agent automatically corrects errors and test failures</strong></p><p data-block-key="2d3fo">Another of CodeMender’s key features is its ability to automatically correct new errors and any test failures that arise from its own annotations. Here is an example of the agent recovering from a compilation error.</p><p data-block-key="b7787"><strong>Example #3: Agent validates the changes</strong></p><p data-block-key="773d9">In this example, the CodeMender agent modifies a function and then uses the LLM judge tool configured for functional equivalence to verify that the functionality remains intact. When the tool detects a failure, the agent self-corrects based on the LLM judge's feedback.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-d6bae008-9da6-4432-8ad7-afee5f4e1cdb">
  
  
  
</gdm-carousel>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="c9bkr">Making software secure for everyone</h2><p data-block-key="2fsdp">While our early results with CodeMender are promising, we’re taking a cautious approach, focusing on reliability. Currently, all patches generated by CodeMender are reviewed by human researchers before they’re submitted upstream.</p><p data-block-key="8i56">Using CodeMender, we've already begun submitting patches to various critical open-source libraries, many of which have already been accepted and upstreamed. We’re gradually ramping up this process to ensure quality and systematically address feedback from the open-source community.</p><p data-block-key="eak4p">We’ll also be gradually reaching out to interested maintainers of critical open source projects with CodeMender-generated patches. By iterating on feedback from this process, we hope to release CodeMender as a tool that can be used by all software developers to keep their codebases secure.</p><p data-block-key="faorg">We will have a number of techniques and results to share, which we intend to publish as technical papers and reports in the coming months. With CodeMender, we've only just begun to explore AI’s incredible potential to enhance software security for everyone.</p>
</div>
                
              
                
                
                  
                  <div>
      <p data-block-key="kr04z"><strong>Acknowledgements</strong></p><p data-block-key="bu4vg">Credits (listed in alphabetical order):</p><p data-block-key="1rh2v">Alex Rebert, Arman Hasanzadeh, Carlo Lemos, Charles Sutton, Dongge Liu, Gogul Balakrishnan, Hiep Chu, James Zern, Koushik Sen, Lihao Liang, Max Shavrick, Oliver Chang and Petros Maniatis.</p>
    </div>
                
              
                
                
                  
                  



  
    
  

                
              
            </div>
          
        
      

      
    
  
  

  

  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valorant's 128-Tick Servers (211 pts)]]></title>
            <link>https://technology.riotgames.com/news/valorants-128-tick-servers</link>
            <guid>45496146</guid>
            <pubDate>Mon, 06 Oct 2025 20:47:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://technology.riotgames.com/news/valorants-128-tick-servers">https://technology.riotgames.com/news/valorants-128-tick-servers</a>, See on <a href="https://news.ycombinator.com/item?id=45496146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded"><p dir="ltr">Hi, I’m Brent “Brentmeister” Randall and I’m an engineer on the Gameplay Integrity team for <em>VALORANT</em>. My team is responsible for <em>VALORANT</em>’s build system, automation framework, game client performance, and server performance. In this article, I’ll be focusing on that last topic - I’ll be telling the technical story behind our search for optimal server performance.</p>
<p dir="ltr">From very early on in development, we knew that <em>VALORANT</em> would have very strict server performance requirements. I hope I can give you some insight into why that is, and how we accomplished our ambitious goals. When we started, a server frame took 50ms, and by the end we reached sub-2ms per frame - all by looking at code optimization, hardware tweaks, and OS tunings.</p>
<p dir="ltr">Let’s go on a journey together.</p>
<h2 dir="ltr">The Importance of Netcode</h2>
<p dir="ltr">All online shooters (even <em>VALORANT</em>) have some amount of peeker’s advantage. We’ve done <a href="https://www.youtube.com/watch?v=_Cu97mr7zcM" target="_blank">a video blog</a> on netcode and peeker’s advantage, and a previous <a href="https://technology.riotgames.com/news/peeking-valorants-netcode" target="_blank">Tech Blog article</a> on the same.&nbsp;</p>
<p dir="ltr">To provide a short summary - in <em>VALORANT</em>, a key part of the gameplay is taking strategic positions and holding them. Holding positions can become impossible if other players can run around a corner and kill the defender before the defender can react due to latency. That latency is partly based on the network and partly based on the server tick rate. To give defenders the time they need to react to aggressors, we determined that <em>VALORANT</em> would require 128-tick servers. If you’re interested in how we came to that conclusion, our tech blog post on <a href="https://technology.riotgames.com/news/peeking-valorants-netcode" target="_blank">peeker’s advantage</a> covers it in detail.</p>
<h2 dir="ltr">Code Optimization</h2>
<p dir="ltr">When we think about hosting servers at a 128-tick rate, our biggest constraint is CPU resources. We need to be able to process an entire frame within 7.8125ms, but if we do that, a single game would take up an entire CPU core!&nbsp;</p>
<p dir="ltr">This diagram demonstrates how many games we can run per core:</p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick1.png"></p>
<p dir="ltr">Utilizing 1 full core per game would make it prohibitively expensive to host our game servers at scale, considering we knew we wanted to offer 128-tick for free and not as a premium service players had to pay for. After crunching the numbers, we knew we needed to do better than 3 games per core (gpc). To put this in perspective, we generally run 36 core hosts, so each physical game server needed to host 108 games or 1080 players. Even 3 gpc was a massive investment, but Riot leadership understood and supported our ambitious server performance goals.</p>
<p dir="ltr">Let’s take that 7.8125ms, divide it by 3 gpc, and we end up with 2.6ms. But wait - we also need to reserve 10% for overhead of the OS, scheduling, and other software running on the host. After these calculations, we end up with a target budget of just 2.34ms per frame. When we looked at <em>VALORANT</em>’s initial data, we were at 50ms; we had a long way to go. This was going to be an effort that needed to involve the entire development team.</p>
<h2 dir="ltr">Breaking The Problem Down</h2>
<p dir="ltr">“Make the server 20x faster” isn’t a very tractable problem, so we applied the single best tool in software engineering: Break a big intimidating problem down into smaller solvable problems. We needed to figure out where those 50ms were being spent so that we could start shaving it down. We sat down with the <em>VALORANT</em> technical leads and discussed what the big areas of CPU cost likely were and came up with a list of categories:&nbsp;</p>
<ul>
<li dir="ltr">
<p dir="ltr">replication</p>
</li>
<li dir="ltr">
<p dir="ltr">FoW</p>
</li>
<li dir="ltr">
<p dir="ltr">network</p>
</li>
<li dir="ltr">
<p dir="ltr">animation</p>
</li>
<li dir="ltr">
<p dir="ltr">gameplay</p>
</li>
<li dir="ltr">
<p dir="ltr">movement</p>
</li>
<li dir="ltr">
<p dir="ltr">equippable</p>
</li>
<li dir="ltr">
<p dir="ltr">character</p>
</li>
<li dir="ltr">
<p dir="ltr">physics&nbsp;&nbsp;</p>
</li>
<li dir="ltr">
<p dir="ltr">other</p>
</li>
</ul>
<p dir="ltr">Armed with this list, we built a system that allowed programmers to easily mark up game code and categorize them appropriately. Every line of code that executes is scoped to one of the above buckets using a macro system, and we added a concept of subsystems for finer grained analysis of larger systems. We called the system <strong>ValSubsystemTelemetry</strong>.</p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick-2.png"></p>
<p dir="ltr">As the game runs, these scopes let us track how much time we’re spending in each category.</p>
<h2 dir="ltr">Leveraging Riot Tech: Analytics Platform</h2>
<p dir="ltr">So now we’ve got a library and we’re generating all this data. What do we do with it?&nbsp;</p>
<p dir="ltr">Part of working for a larger studio like Riot means we’re able to leverage existing tools and tech that other teams develop and support. In this case, for example, a central team at Riot had developed a technology called the Analytics Platform. This tool allows programmers at Riot to publish data to our big data warehouse and then build visualizations around it.</p>
<p dir="ltr">Here are some of the ways we visualize performance data on <em>VALORANT</em>:</p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick-3.png"><br>
<em>Average server frame time per round</em></p>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick4.png"><em>Average processing time of each VALSubsystem</em></p>
<p dir="ltr">Without data like this, it’s easy for non-performant code or content changes to make it into the game undetected.&nbsp;We might go weeks before these sorts of changes stack up to a breaking point where developers or players notice things slowing down.&nbsp;&nbsp;</p>
<p dir="ltr">Digging back through weeks of changelists to find culprits is costly work, but it’s a much easier task when you’ve been tracking performance data all along. In the second image above, for example, we can see that there’s a problem between change numbers 445887 and 446832 that caused replication (the orange line) to take longer. This type of visualization allows us to look through a much smaller set of changes and quickly assign an engineer to resolve the issue.</p>
<h2 dir="ltr">Performance Budgets for Subsystems</h2>
<p dir="ltr">Now that we had the visualizations set up for data verifications, we were able to set budgets for each subsystem and follow up on any discrepancies. The <em>VALORANT</em> tech leads got together again and discussed what reasonable budgets would be for each of the systems. This was largely informed by where the systems were at that time, and what opportunities for optimization existed in systems according to the experts. From there, each team and expert had a goal in mind and we could work in parallel to get the performance to a shippable state.</p>
<p dir="ltr">Here we can see some of the early data organized by the categories mentioned above:</p>
<p><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick_5.png">Let’s take a look at two specific sections to demonstrate how we whittled down performance costs. First we’ll focus on replication because it was the system that needed the biggest change. Then we’ll take a look at animation, because the changes we had to make are highly representative of the types of solutions we made across all categories.</p>
<h3 dir="ltr">Replication</h3>
<p dir="ltr"><a href="https://docs.unrealengine.com/en-US/Gameplay/Networking/Actors/Properties/index.html" target="_blank">Property Replication</a>, which we often just call replication for short, is a system in Unreal Engine 4 (UE4) that allows for network synchronization of state between server and clients. It’s a great system for quickly prototyping new characters/abilities/features that require networking with clients. A developer can simply markup a variable as “replicated” and it will automatically be synced between the server and clients.</p>
<p dir="ltr">Unfortunately, it’s also pretty slow. It requires scanning through every variable marked as replicated every frame, then comparing it to each of the 10 clients’ last known states, and then packaging any deltas to send to the client. This is effectively random access across memory and is really cache-intensive, slow work. Regardless of state changes, the variables are still checked. I consider “polling” systems like this a performance anti-pattern.</p>
<p dir="ltr">The fix is to utilize another UE4 networking tool: Remote Procedure Calls (<a href="https://docs.unrealengine.com/en-US/Gameplay/Networking/Actors/RPCs/index.html#:~:text=RPCs%20(Remote%20Procedure%20Calls)%20are,other%20over%20a%20network%20connection." target="_blank">RPCs</a>). RPCs allow the server to call functions over the network that execute on one or more of the clients. Using RPCs on state changing gameplay events limit the performance cost to the frame on which the state change occurs. This “push” model is far more performant. The downside is that designers and engineers have to think more carefully about placement of RPCs and handling cases like reconnect. However, we found in many cases changing from a replicated variable to an RPC offered a 100x to 10000x performance improvement!</p>
<p dir="ltr">As an example, consider player health. One way to network player health would be to mark player health as replicated. Each frame, the game server would check if the value has changed and if so notify the correct clients. With&nbsp;an RPC, you would likely send a “ShotHit” event from the server with the damage value. Clients would stay in sync by applying that damage to the player's health themselves.</p>
<h3 dir="ltr">Animation</h3>
<p dir="ltr">Animation was a huge cost for us on the server side. To properly figure out if a shot hit or not, we need to run the same animations on the server that players see on their clients. Hit registration in <em>VALORANT</em> works by saving player positions and animation state in a historical buffer. When the server receives a shot packet from the client, it rewinds the player positions and animation state using the historical buffer to calculate if the shot hit. Initially we were computing animation and filling this buffer every frame. However, after careful testing and comparisons we found that we could animate every 4th frame. In the event of a rewind we could <a href="https://codepen.io/rachsmith/post/animation-tip-lerp" target="_blank">lerp</a> between the saved animations. This effectively cut animation costs down by 75%.&nbsp;</p>
<p dir="ltr">Another important realization was that amortized server performance is the most important type of performance at scale. Imagine a <em>VALORANT</em> server running about 150 games. At any given time, ~50 of those games are going to be in the buy phase. Players will be purchasing equipment safely behind their spawn barriers and no shots can hurt them. We realized we don’t even need to do any server-side animation during the buy phase, we could just turn it off. So that’s exactly what we did - if you look at the server view, players are just in the idle pose during the buy phase. This helped&nbsp;reduce costs of the animation system over the course of a round by another 33%!</p>
<p><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick_6.png"></p>
<p dir="ltr"><em>The red wireframe shows the server’s non-animated hitbox vs the client’s blue.</em></p>
<h2 dir="ltr">Real World Performance</h2>
<p dir="ltr">Now you’ve got a taste of how we optimized the code - but performance is more than code. It’s also the platform you’re running on. So let’s discuss something that was causing huge issues with performance - the OS and hardware.</p>
<p dir="ltr">To properly test how our game was going to perform in the real world, we needed to fashion a load test. We had to know how the server would perform with 100+ instances all running on the same CPU. Building the load test was critical for successfully launching&nbsp;<em>VALORANT</em>. It allowed us to predict exactly how many cores we would need per player, and allowed us to solve a number of issues that only appeared at high load. Turns out, it’s not as simple as the 7.8ms / 3 games per core that I mentioned before.</p>
<p dir="ltr"><em>(Editor's note: You can read more about <a href="https://technology.riotgames.com/news/scalability-and-load-testing-valorant" target="_blank">load lesting for VALORANT</a> here!)</em></p>
<p dir="ltr">First, let’s take a look at this chart. It graphs frame time on the Y-axis and number of instances on the X-axis.<img alt="" src="https://technology.riotgames.com/sites/default/files/128tick7.png"></p>
<p dir="ltr">So with only a single instance running, we hit a glorious 1.5ms... but once we’ve got 168 instances running, we’re hovering around 5.7ms.&nbsp;</p>
<p dir="ltr">Oh no - what’s going on here? To understand why this happened and how we resolved it, we’ll have to first take a look at modern CPU architecture.</p>
<h2 dir="ltr">CPU Architecture</h2>
<p dir="ltr"><img alt="" src="https://technology.riotgames.com/sites/default/files/128tick8.png"></p>
<p dir="ltr">Take a look at the image above, and you’ll notice several important things. Each core has its own L1/L2 caches, but the larger L3 cache is shared between cores. With only one server running on the host, it gets to hog the L3 cache all to itself, which results in fewer misses - meaning the CPU core spends less time waiting on a memory request. That's why our low load scenarios had our servers running blazing fast, but they start to slow down as the cache grows more and more contended with each instance. We did some measurements with a team of cloud computing experts at Intel to make sure we weren’t hitting thermal limits or other factors, and narrowed it down simply to cache performance.</p>
<h2 dir="ltr">Collaborating with Intel</h2>
<p dir="ltr">Luckily, Intel had a few tricks up their sleeves from their platform measuring and analysis tools. We were still running on the older Intel Xeon E5 processors, which made use of an inclusive cache. Basically, inclusive means that each cache line present in the L2 cache <em>must</em> be present in the L3 cache as well. If a line gets evicted from the L3 cache, it gets evicted from the L2 cache as well! That means that even though each L2 cache was separate, it was possible cores were thrashing one another’s L2 cache by causing evictions in L3 cache.</p>
<p dir="ltr">Totally unfair, don’t you think? With the Intel Xeon Scalable processors, Intel moved to a non-inclusive cache, completely eliminating this problem. Moving to the more modern Xeon Scalable processors showed major performance gains for our server application. We still see the effects of L3 contention but we saw roughly a 30% increase in performance, even using similar clock speeds.</p>
<h3 dir="ltr">Non-Uniform Memory Access</h3>
<p dir="ltr">We wanted to push our memory performance even further. First, you’ll need to understand another aspect of modern CPU architecture called Non-Uniform Memory Access (<a href="https://whatis.techtarget.com/definition/NUMA-non-uniform-memory-access#:~:text=NUMA%20(non%2Duniform%20memory%20access)%20is%20a%20method%20of,symmetric%20multiprocessing%20(%20SMP%20)%20system." target="_blank">NUMA</a>). On server architectures, you often run dual (or more) socket CPUs. Each of these sockets has direct access to a portion of the system’s RAM, and shares data through an interconnect. This allows for increased memory bandwidth (2x more connections), but the interconnect can become a bottleneck. Revisiting the diagram above, you can see a simplified layout of a NUMA architecture with two sockets. If only the operating system could make sure to allocate memory and CPU resources to keep interconnect traffic down...&nbsp;</p>
<p dir="ltr">Well, it turns out that many modern OS are NUMA-aware and <em>can</em> do this. On Linux, for example, one way to do this is to use <a href="https://linux.die.net/man/8/numactl" target="_blank">numactl</a> when starting a process. On <em>VALORANT,</em> we start game server instances back and forth between nodes like this:</p>
<p dir="ltr"><code>numactl --cpunodebind={gameid % 2} --membind={gameid % 2} ShooterGameServer</code></p>
<p dir="ltr">Making maximum use of the architecture with such a small change led to a performance boost of around 5%. We turned our memory access from about 50% NUMA local to 97-99% NUMA local! In addition to the 5%, performance was much more consistent between server instances.</p>
<h3 dir="ltr">OS Scheduler</h3>
<p dir="ltr">During our time monitoring the game server host, we saw an interesting pattern where cores would hover at around 90-96% usage but never reach 100% - even when the host was loaded to 2x the number of games it should be able to host. We suspected the OS scheduler was the cause, so we used Intel’s PMU profiling tool, Adaptive Optimization, along with the <a href="https://perf.wiki.kernel.org/index.php/Main_Page" target="_blank"><em>perf</em></a> utility on Linux to dig into scheduler events. Utilizing Linux also meant we had the chance to review the source code for the scheduler as well.</p>
<p dir="ltr">Through our investigations, we learned that modern Linux uses the Completely Fair Scheduler (<a href="https://www.linuxjournal.com/node/10267" target="_blank">CFS</a>). The scheduler is really clever and has a number of optimizations. One optimization is that it tries to keep processes on the same core, preventing them from migrating to run on other cores. One reason it may do this could be to allow processes to reuse still hot cache lines. Another reason might be to prevent unnecessarily waking up idle cores to do small amounts of work. The migration cost would basically keep the process waiting on a busy core for a length of time before considering allowing it to migrate it to an available core. The default value for this in our Linux distro was .5ms.</p>
<p dir="ltr">In <em>VALORANT</em>’s case, .5ms is a meaningful chunk of our 2.34ms budget. You could process nearly a 1/4th of a frame in that time! There’s 0% chance that any of the game server’s memory is still going to be hot in cache. While an individual game server idles in between frames, the other game servers are utilizing the cache to its fullest extent. By lowering the migration cost setting to 0, we guarantee that the scheduler immediately migrates a game server that needs to run to any available core on the system. Doing this lets us make much better use of CPU resources on the system and granted another 4% performance boost. Additionally, we saw the amount of time individual cores spent idle drop to nearly 0% under load.</p>
<h3 dir="ltr">C-States</h3>
<p dir="ltr">Another area where we found straightforward wins was in controlling the <a href="https://www.dell.com/support/article/en-us/qna41893/what-is-the-c-state?lang=en" target="_blank">C-State</a> that we allowed the CPU to enter. When a multi-core CPU runs, it allows cores to enter different power states. Under reduced load, cores will often enter lower states to conserve power. However, once load increases, it takes time for those cores to swap to higher power states. In highly cyclical workloads - like a bunch of game servers processing frames then sleeping - the CPU ends up swapping power states frequently. Each swap has a latency that negatively affects performance. By limiting our process to the higher C-States (C0, C1 and C1E), we were able to host another 1-3% games stably. It particularly stabilized performance of 60-90% loaded servers where the reduced workload was allowing many cores to frequently idle.</p>
<h3 dir="ltr">Hyperthreading</h3>
<p dir="ltr">Hyperthreading is a CPU architectural technique where a single physical core can host two simultaneous threads. With hyperthreading, certain parts of the core are shared (like caches), and certain parts (like different compute units) are duplicated.&nbsp;</p>
<p dir="ltr">It ultimately depends on the specific CPU you’re looking at. Early on in development, we had 25ms frame times and we found that turning off hyperthreading yielded 20ms frame times. Performance increased across the board by 25%! However, our friends at Intel were skeptical. Given our load, we could potentially squeeze out more out of the hardware by making use of the virtual cores that hyperthreading offers. When we flipped hyperthreading back on, we saw performance increase by 25%.&nbsp;</p>
<p dir="ltr">How did this happen? Along the way we had reduced server frame time to well below our 7.8125ms target. We migrated to the Intel Xeon Scalable processors architecture which improved cache and hyperthreading performance. We tweaked the scheduler to make better use of available cores. We disabled C-States below C1E for better core latency and many other optimizations.</p>
<h4 dir="ltr">The Importance of Measuring</h4>
<p dir="ltr">The lesson here is that each application's performance profile and considerations are different. Even the same application a year later can have drastically different performance needs. The only way to be sure is to create a reproducible test and <strong>measure</strong>.&nbsp;</p>
<p dir="ltr">If you just make a list of “performance tweaks” you might learn about in, say, a game dev blog post on the internet, and execute them without considering your application’s specific needs and considerations, you might hurt performance more than you help it.&nbsp;</p>
<h2 dir="ltr">Other Performance Optimizations</h2>
<h3 dir="ltr">Clocksource</h3>
<p dir="ltr">Games tend to frequently mark the passing of time. This is generally done by making system calls to the OS via the <a href="https://www.kernel.org/doc/Documentation/timers/timekeeping.txt#:~:text=The%20purpose%20of%20the%20clock,exactly%20what%20time%20it%20is.&amp;text=It%20may%20stop%20during%20system%20suspend" target="_blank">clocksource</a>. An OS running in hypervisor environments (like AWS) might use virtualized clock sources that are less performant. On our AWS nodes, we were initially using the Xen clocksource provided by the Xen hypervisor. We changed to the tsc clocksource which is provided by the CPU instruction&nbsp;rdtsc. For our game servers, we were able to get about a 1-3% boost in performance by moving our clocksource.</p>
<h3 dir="ltr">Ghost Story: It Only Happens on Prod</h3>
<p dir="ltr">As we neared our ship date we noticed that one of our game server load test&nbsp;hosts performed worse than the others. It was identical hardware and the only difference was that it was running our full deployment stack. Load tests run on this box generated <strong>double to triple </strong>the number of hitches or slow frames than ones running on hardware that I provisioned by hand. We investigated several angles - could it be the AWS hypervisor,&nbsp;configuration differences, or even just bad hardware? Nothing was panning out.&nbsp;</p>
<p dir="ltr">Eventually we decided to look again at the Linux scheduler with <em>perf sched</em> to just see if we could find some differences on how the processes were running. We found out that every 5 seconds like clockwork, 72 processes would start called scheduler_1 … scheduler_72. One for each virtual core. These would start and immediately kick any running game server off the cores. On highly loaded game servers, this caused a cascading number of hitches. It turned&nbsp;out that Mesos, which we were using for our deployments, utilized Telegraf for metrics, which made DNS requests every 5 seconds, which were hijacked by dcos_net, an Erlang application.&nbsp;</p>
<p dir="ltr">Erlang has a configurable for how many threads its scheduler is allowed to spawn. The default is one thread per core on the system, hence the 72 processes. Once we set this to a more reasonable default like 4, the problem disappeared overnight. The lesson here is that it’s vitally important to measure performance in a configuration that matches your production environment!</p>
<h2 dir="ltr">Conclusion</h2>
<p dir="ltr">Ultimately, it’s easy to miss the forest for the trees. Even in this quick fly-by through some of our performance efforts, the technical minutiae can stack up quickly. It’s easy to get lost in tiny details, tweaks, and oddities.</p>
<p dir="ltr">You’ve really got to continually revisit and reinforce the holistic performance goals you have in mind. Make sure you align the entire team around your goals so that you can enlist the right help from your team at the right time.&nbsp;</p>
<p dir="ltr">Code optimization is a big portion of performance, but you need to be able to break down your application performance into discrete chunks. And don’t forget about optimizing the environment (hardware and operating system) to host your application in the most efficient way.&nbsp;</p>
<p dir="ltr">Above all measure, measure, <strong>measure</strong>. <em>VALORANT</em>’s measurements ultimately allowed us to launch while predicting our server hardware needs within 1%. This resulted in a smooth launch experience and free 128-tick servers for our players.</p>
<p dir="ltr">I’d like to end with a special thanks to the Intel team who worked with us to investigate the hardware and OS tunings.</p>
<ul dir="ltr">
<li>Kim McLaughlin</li>
<li>Harshad S Sane</li>
<li>Dory Simaan</li>
<li>Prabha Viswanathan</li>
</ul>
<p dir="ltr">Their insight and contributions were invaluable for helping us meet our performance goals.</p>
<p dir="ltr">Thanks for reading! If you have any questions or comments, please post them below.&nbsp;</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>