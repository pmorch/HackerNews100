(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 12 Nov 2025 00:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[X5.1 solar flare, G4 geomagnetic storm watch (122 pts)]]></title>
            <link>https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html</link>
            <guid>45893004</guid>
            <pubDate>Tue, 11 Nov 2025 21:18:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html">https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html</a>, See on <a href="https://news.ycombinator.com/item?id=45893004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="SWL_Page">
                    <div>
                        
                        
<h3>X5.1 solar flare, G4 geomagnetic storm watch</h3><p>Tuesday, 11 November 2025 19:07 UTC</p><p><img src="https://www.spaceweatherlive.com/images/news/593-header.jpg" loading="lazy" alt="X5.1 solar flare, G4 geomagnetic storm watch" width="900" height="450"></p><p>Here she blows! Sunspot region 4274 produced its strongest solar flare thus far since it appeared on the east limb and the sixth strongest solar flare of the current solar cycle. An impressive long duration and highly eruptive X5.1 (R3-strong) solar flare peaked this morning at 10:04 UTC.</p><p>It became quickly clear that the eruption would be followed by an impressive coronal mass ejection (CME). The resulting coronal wave following the solar explosion as well as the coronal dimming observed as the CME was propelled into space were of a spectacular magnitude as can be seen in the animation below provided by <a href="https://x.com/halocme" target="_blank" rel="noopener">halocme</a>.</p><blockquote data-media-max-width="560"><p dir="ltr" lang="en">Another eruption from AR12474, associated with an X5.1 flare. It has become a full halo CME. I am truly impressed by how fast and global this coronal wave is. The CME will arrive on November 13, but because of earlier CMEs it will be challenging to isolate the ICME from this. <a href="https://t.co/H6eNjzQUGz">pic.twitter.com/H6eNjzQUGz</a></p>— Halo CME (@halocme) <a href="https://twitter.com/halocme/status/1988253760179548649?ref_src=twsrc%5Etfw">November 11, 2025</a></blockquote><p>Taking a look at coronagraph imagery provided by GOES-19 CCOR-1 we see the gorgeous fast halo coronal mass ejection as it propagates away from the Sun. It doesn't take a rocket scientist to come to the conclusion that this plasma cloud of course has an earth-directed component and it is pretty clear that this will be a strong impact when it arrives at our planet. This rightfully so prompted the NOAA SWPC to issue a G4 or greater geomagnetic storm watch for tomorrow as the cloud could impact our planet as early as 16 UTC on 12 November. Not only is the CME fast but it will also travel trough an area with high ambient solar wind speed and low density thanks to two other CMEs released earlier by this region. More about that below.</p><figure><img src="https://www.spaceweatherlive.com/images/news/2025/593-cme.gif"><figcaption>Coronal mass ejection launched during today's X5.1 solar flare as captured by the coronagraph from GOES-19.</figcaption></figure><p>If the solar wind and interplanetary magnetic field values at Earth are favorable this could result in a geomagnetic storm which is strong enough for aurora to become visible from locations as far south as northern France, Germany, Ukraine, Switzerland and Austria. In the US it could become visible as far south as Nevada and Arkansas. No guarantees of course, this is space weather we are talking about but be sure to download the SpaceWeatherLive app to your mobile device, turn on the alerts and keep an eye on the solar wind data from ACE and DSCOVR!</p><p>We also want to remind you that we still have two coronal mass ejections on their way to Earth. These are not as impressive as this X5.1 CME but these two plasma clouds will likely arrive within the next 6 to 18 hours. This is a tricky one as they could arrive as one impact or two impacts close intill each other. More information in <a href="https://www.spaceweatherlive.com/en/news/view/592/20251110-x1-2-solar-flare-with-earth-directed-cme.html" target="_blank" rel="noopener">yesterday's news</a>.</p><div> <p><em>Thank you for reading this article! Did you have any trouble with the technical terms used in this article? Our help section is the place to be where you can find in-depth <a href="https://www.spaceweatherlive.com/en/help.html">articles</a>, a <a href="https://www.spaceweatherlive.com/en/faq.html">FAQ</a> and a list with common <a href="https://www.spaceweatherlive.com/en/acronyms-and-abbreviations.html">abbreviations</a>. Still puzzled? Just post on our <a href="https://community.spaceweatherlive.com/">forum</a> where we will help you the best we can! <span> Never want to miss out on a space weather event or one of our news articles again? Subscribe to our <a href="https://www.spaceweatherlive.com/en/mailinglist.html">mailing list</a>, follow us on <a href="https://twitter.com/_SpaceWeather_">Twitter</a> and <a href="https://www.facebook.com/SpaceWeatherLive/">Facebook</a> and download the SpaceWeatherLive app for <a href="https://play.google.com/store/apps/details?id=com.spaceweatherlive.app">Android</a> and <a href="https://itunes.apple.com/us/app/spaceweatherlive/id1435501021?mt=8">iOS</a>! </span> </em> </p></div>
                        
                    </div>
                                            <div>
                                                          <div>  <p>A lot of people come to SpaceWeatherLive to follow the Solar activity or if there is a chance to see the aurora, but with more traffic comes higher costs to keep the servers online. If you like SpaceWeatherLive and want to support the project you can choose a subscription for an ad-free site or consider a donation. With your help we can keep SpaceWeatherLive online!</p>  <p><a href="https://shop.spaceweatherlive.com/" target="_blank"><img src="https://www.spaceweatherlive.com/images/SWL_Shop.png" alt="Support SpaceWeatherLive with our merchandise" width="600" height="200"></a> </p> <p><a href="https://shop.spaceweatherlive.com/" target="_blank"> <b>Check out our merchandise</b></a></p></div><div><table><thead><tr><th colspan="2">Spotless days</th></tr></thead><tbody><tr><td>Last spotless day</td><td>2022/06/08</td></tr></tbody></table><table><thead><tr><th colspan="2">Monthly mean Sunspot Number</th></tr></thead><tbody><tr><td>October 2025</td><td>114.6 <span> -15.2</span></td></tr><tr><td>November 2025</td><td>91.9 <span> -22.7</span></td></tr><tr><td>Last 30 days</td><td>96.2 <span> -34.6</span></td></tr></tbody></table><h4>This day in history*</h4><div><table><thead><tr><th></th><th></th><th>Dst</th><th>G</th></tr></thead><tbody><tr><td>1</td><td><a href="https://www.spaceweatherlive.com/en/archive/2004/11/11.html">2004</a></td><td>-106</td><td><span>G1</span></td></tr><tr><td>2</td><td>1981</td><td>-78</td><td><span>G2</span></td></tr><tr><td>3</td><td>1974</td><td>-72</td><td><span>G3</span></td></tr><tr><td>4</td><td><a href="https://www.spaceweatherlive.com/en/archive/2013/11/11.html">2013</a></td><td>-68</td><td><span>G1</span></td></tr><tr><td>5</td><td>1991</td><td>-64</td><td><span>G1</span></td></tr></tbody></table><p>*since 1994</p></div></div>                           </div>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Collaboration sucks (267 pts)]]></title>
            <link>https://newsletter.posthog.com/p/collaboration-sucks</link>
            <guid>45892394</guid>
            <pubDate>Tue, 11 Nov 2025 20:27:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.posthog.com/p/collaboration-sucks">https://newsletter.posthog.com/p/collaboration-sucks</a>, See on <a href="https://news.ycombinator.com/item?id=45892394">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2y1b!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2y1b!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg" width="1456" height="1048" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1048,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:801531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://newsletter.posthog.com/i/178280989?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2y1b!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>“If you want to go fast, go alone; if you want to go far, go together”</p><p>This phrase will slowly kill your company and I’m here to prove it.</p><p>Imagine you are driving a car. It’s often useful to have someone give you directions, point out gas stations, and recommend stops for snacks. This is a helpful amount of collaboration.</p><p>An unhelpful amount of collaboration is getting out of your car to ask pedestrians if they like your car, swapping drivers every 10 minutes, or having someone constantly commenting on your driving.</p><p>In the first scenario, you get the right amount of feedback to get to your destination as fast as possible. In the second, you get more feedback, but it slows you down. You run the risk of not making it to the place you want to go.</p><p>The second scenario is also the one most startups (or companies, really) end up in because of ✨ collaboration ✨.</p><p>As PostHog grows, I’ve seen more and more collaboration that doesn’t add value or adds far too little value for the time lost collaborating. So much so we made “collaboration sucks” the topic of the week during a recent company all hands.</p><p><span>“You’re the driver” is a </span><a href="https://posthog.com/handbook/values?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">key value</a><span> for us at PostHog. We aim to hire people who are great at their jobs and get out of their way. No deadlines, minimal coordination, and no managers telling you what to do.</span></p><p><span>In return, we ask for extraordinarily high ownership and the ability to get a lot done by </span><em>yourself.</em><span> Marketers ship code, salespeople answer technical questions without backup, and </span><a href="https://posthog.com/blog/what-is-a-product-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">product engineers</a><span> work across the stack.</span></p><p>This means there is almost always someone better at what you are doing than you are. It is tempting to get them, or anybody really, involved and ✨ collaborate ✨, but collaboration forces the driver to slow down and explain stuff (background, context, their thinking).</p><p>This tendency reveals itself in a few key phrases:</p><ul><li><p>“Curious what X thinks”</p></li><li><p>“Would love to hear Y’s take on this”</p></li><li><p>“We should work with Z on this”</p></li></ul><p><span>This </span><em>sometimes</em><span> leads to valuable insights, but </span><em>always</em><span> slows the driver down. It erodes their motivation, confidence, and effectiveness, and ultimately leads us to ship less.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!MoTP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!MoTP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 424w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 848w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1272w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png" width="714" height="328.5576923076923" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:670,&quot;width&quot;:1456,&quot;resizeWidth&quot;:714,&quot;bytes&quot;:463445,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.posthog.com/i/178280989?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!MoTP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 424w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 848w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1272w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Everyone is to blame.</p><ul><li><p><span>People want to be helpful. For example, when someone posts their work-in-progress in Slack, others feel obliged to give feedback because we have a </span><a href="https://posthog.com/handbook/people/feedback?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">culture of feedback</a><span>.</span></p></li><li><p>On the flip side, people don’t ask for feedback from specific people because it doesn’t feel inclusive, even though it would help.</p></li><li><p>People aren’t specific enough about what feedback they need. This creates more space for collaboration to sneak in. A discussion about building a specific feature can devolve into reevaluating the entire product roadmap if you let it.</p></li><li><p>When someone has a good idea, the response often defaults to “let’s discuss” rather than “ok, do it.” As proof, we have 175 mentions of “let’s discuss” in Slack.</p></li><li><p><span>People just want to talk about stuff because they </span><s>are too busy</s><span> can’t be bothered to act on it. We drift from our ideal of a pull request to an issue/RFC to Slack (we are mostly here) to “let’s discuss”.</span></p></li><li><p>It’s not clear who the owner is (or no one wants to own what’s being discussed).</p></li><li><p>It is annoying, but sometimes a single person can’t ship certain things front to back to a high-enough quality and we can’t just ship and iterate. We can fix broken code, but we can’t resend a newsletter.</p></li></ul><p>So if collaboration is your enemy, how do you defeat it? Here’s what we say:</p><ul><li><p>Default to shipping. Pull requests &gt; issues &gt; Slack messages.</p></li><li><p>Every time you see ✨ collaboration ✨ happening, speak up and destroy it. Say “there are too many people involved. X, you are the driver, you decide.” (This is a great way to make friends btw).</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!CtaP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CtaP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg" width="1456" height="870" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:870,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;How to make friends and crush collaboration&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="How to make friends and crush collaboration" title="How to make friends and crush collaboration" srcset="https://substackcdn.com/image/fetch/$s_!CtaP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Graphic design is my passion</figcaption></figure></div><ul><li><p>Tag who you specifically want input from and what you want from them, not just throw things out there into the void.</p></li><li><p>Prefer to give feedback after something has shipped (but before the next iteration) rather than reviewing it before it ships. Front-loading your feedback can turn it into a quasi-approval process.</p></li><li><p><span>If you are a team lead, or leader of leads, who has been asked for feedback, consider being more </span><a href="https://www.youtube.com/shorts/DjvVN4Vp_r0" rel="">you can just do stuff</a><span>.</span></p></li><li><p>When it’s your thing, you are the “informed captain.” Listen to feedback, but know it’s ultimately up to you to decide what to do, not the people giving feedback.</p></li></ul><p><span>Unfortunately for me, not all collaboration can be rooted out, and even I will admit that some collaboration is useful. </span><a href="https://www.linkedin.com/in/ianvanagas/" rel="">Ian</a><span> and </span><a href="https://www.linkedin.com/in/andyvandervell/" rel="">Andy</a><span> edited this newsletter after all. </span></p><p><span>The point is, if you aren’t actively attempting to collaborate less, you are probably collaborating too much by default and hurting your ability to go far, fast.</span><em><p><span>Words by </span><a href="https://www.linkedin.com/in/wololo/" rel="">Charles Cook</a><span>, who also hates sparkling water, presumably because the bubbles are too collaborative.</span></p></em></p><ul><li><p><strong><a href="https://posthog.com/careers/ai-product-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">AI Product Engineer</a></strong><span> working on PostHog AI, LLM Analytics or Array teams.</span></p></li><li><p><span>Backend Engineer for </span><strong><a href="https://posthog.com/careers/backend-engineer-feature-flags?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Feature Flags</a></strong><span> and </span><strong><a href="https://posthog.com/careers/backend-engineer-ingestion?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Ingestion</a></strong><span> teams</span></p></li><li><p><strong><a href="https://posthog.com/careers/influencer-wrangler?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Influencer Wrangler</a></strong><span> on the Marketing team</span></p></li><li><p><strong><a href="https://posthog.com/careers/yc-technical-onboarding-specialist-onsite?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">YC Technical Onboarding Specialist </a></strong><span>on the Onboarding team (San Fran based)</span></p></li><li><p><strong><a href="https://posthog.com/careers/clickhouse-operations-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">ClickHouse Operations Engineer</a></strong><span> on the ClickHouse team</span></p></li></ul><ul><li><p><strong><a href="https://posthog.com/blog/workflows-alpha?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Workflows are now in Alpha and I already broke mine</a><span> – Sara Miteva</span></strong></p></li><li><p><strong><a href="https://notes.mtb.xyz/p/your-data-model-is-your-destiny?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Your data model is your destiny</a><span> –&nbsp;Matt Brown</span></strong></p></li><li><p><strong><a href="https://www.dylanamartin.com/2025/11/07/spinning-plates.html?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Spinning Plates</a><span> – Dylan Martin</span></strong></p></li><li><p><strong><a href="https://www.youtube.com/watch?v=yKgfk8lTQuE?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">1000x: The Power of an Interface for Performance</a><span> (video) – Joran Dirk Greef</span></strong></p></li></ul><div id="youtube2-bs_v-xY7Nqw" data-attrs="{&quot;videoId&quot;:&quot;bs_v-xY7Nqw&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/bs_v-xY7Nqw?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A modern 35mm film scanner for home (116 pts)]]></title>
            <link>https://www.soke.engineering/</link>
            <guid>45891907</guid>
            <pubDate>Tue, 11 Nov 2025 19:48:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.soke.engineering/">https://www.soke.engineering/</a>, See on <a href="https://news.ycombinator.com/item?id=45891907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div webpageid="augiA20Il" data-layout-template="true" id="main" data-framer-hydrate-v2="{&quot;routeId&quot;:&quot;augiA20Il&quot;,&quot;localeId&quot;:&quot;default&quot;,&quot;breakpoints&quot;:[{&quot;hash&quot;:&quot;72rtr7&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1200px)&quot;},{&quot;hash&quot;:&quot;1gly80&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 810px) and (max-width: 1199.98px)&quot;},{&quot;hash&quot;:&quot;1teekcz&quot;,&quot;mediaQuery&quot;:&quot;(max-width: 809.98px)&quot;},{&quot;hash&quot;:&quot;4e4xff&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1440px)&quot;},{&quot;hash&quot;:&quot;wthtfe&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 810px) and (max-width: 1439.98px)&quot;},{&quot;hash&quot;:&quot;1l7dlx4&quot;,&quot;mediaQuery&quot;:&quot;(max-width: 809.98px)&quot;}]}" data-framer-ssr-released-at="2025-11-10T14:50:19.351Z" data-framer-page-optimized-at="2025-11-11T21:36:56.978Z" data-framer-generated-page=""><nav data-framer-appear-id="h121gk" data-framer-layout-hint-center-x="true" data-framer-name="Navbar"></nav><div data-framer-root=""><header data-framer-name="Hero-Section" id="hero-section"><div data-framer-name="Container"><figure as="figure" data-framer-name="img"><p><img decoding="async" width="1237" height="1110" src="https://framerusercontent.com/images/Z8ymSbSlFHFYqnxs7knHRxMBqo.png?width=1237&amp;height=1110" alt=""></p></figure></div></header><header data-framer-name="Hero-Section" id="hero-section-1"><div data-framer-name="Container"><div data-framer-name="Left-Text"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo"><span>The New Era of </span><br><span>Film Scanning</span></h2></p><div data-framer-name="Highlights"><p><!--$--><h2><span>Knokke  - a high-resolution 35 mm film scanner built for photographers who demand speed, quality and control.</span></h2><!--/$--></p></div></div><div data-framer-name="Variant 1" data-highlight="true" tabindex="0" data-framer-appear-id="1wbnzl8" id="1wbnzl8"><p><svg style="width:100%;height:100%;transform-origin:center" viewBox="0 0 100 100" overflow="visible"><path id="curve-wnxkz4" d="M 0 50 L 0 50 A 1 1 0 0 1 100 50 L 100 50 L 100 50 A 1 1 0 0 1 0 50 L 0 50" stroke-width="none" fill="transparent"></path><text><textPath href="#curve-wnxkz4" startOffset="0" dominant-baseline="Text Top" style="letter-spacing:0.02em;font-family:&quot;IBM Plex Mono&quot;, monospace;font-size:14px;font-style:normal;font-weight:500;line-height:1em;fill:var(--token-ba5469a1-3890-44cc-aaeb-d6b7e143f20d, rgb(244, 244, 245))">Watch the video - Watch the video -</textPath></text></svg></p></div></div></header><header data-framer-name="Hero-Section" id="hero-section-2"><div data-framer-name="Container"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo"><span>The New Era of </span><br><span>Film Scanning</span></h2></p><p><!--$--><h2><span>Knokke - a high-resolution 35 mm film scanner built for photographers who demand speed, quality, and control.</span></h2><!--/$--></p></div><div data-framer-appear-id="truicp" data-framer-name="Image"><figure as="figure" data-framer-name="img"><p><img decoding="async" width="1237" height="1110" src="https://framerusercontent.com/images/Z8ymSbSlFHFYqnxs7knHRxMBqo.png?width=1237&amp;height=1110" alt=""></p></figure></div></header><div data-framer-name="Proof Section" id="proof"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo">Knokke redefines film scanning by bringing modern imaging, optics, and software into a beautifully engineered device.</h2></p></div><div data-framer-name="Product Section" id="features"><div data-framer-name="Components/Product item"><p>The modern 35 mm film scanner that captures a full roll in under just a few minutes while capturing every frame at 4064 DPI and 48bit colour. Its custom optics and state-of-the-art sensor deliver benchmark setting quality and speed at a price only Knokke can offer.</p></div><div data-framer-component-type="RichTextContainer" data-framer-name="Product 2"><p>Built for the 21st century, Knokke runs on Korova, a lean C++ application that's native to Linux, macOS, and Windows—so you can forget vintage PCs and enjoy a plug-and-play workflow that lets you focus on your photos.</p><p>Each frame can have custom scan settings, repeatable across multiple scans for consistent results and tailored workflows. The scanner can also skip directly to requested frames, massively accelerating scanning time and enabling fast access to key shots without unnecessary delay.</p></div></div><div data-framer-name="Features Section"><div data-framer-name="Image"><p><img decoding="async" loading="lazy" width="5152" height="7728" sizes="(min-width: 1200px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), 100vw), (min-width: 810px) and (max-width: 1199.98px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), 100vw, 254px), (max-width: 809.98px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), min(100vw - 32px, 1200px), 100vw)" srcset="https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=1024&amp;width=5152&amp;height=7728 682w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=2048&amp;width=5152&amp;height=7728 1365w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=4096&amp;width=5152&amp;height=7728 2730w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?width=5152&amp;height=7728 5152w" src="https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?width=5152&amp;height=7728" alt="" data-framer-original-sizes="max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px)"></p></div><div data-framer-name="Heading"><p id="w8drg9" data-framer-component-type="RichTextContainer"><h3 data-styles-preset="gUnjFa38F">Engineered for Individual Users and Lab Professionals</h3></p><div data-framer-name="Grid"><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">01</h6></p><p data-framer-component-type="RichTextContainer"><h6>Quality</h6></p></div><p>Knokke’s premium build and precision engineering ensure lasting, reliable performance.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">02</h6></p><p data-framer-component-type="RichTextContainer"><h6>Speed</h6></p></div><p>Knokke’s high scan speed and streamlined workflow keep you moving.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">03</h6></p><p data-framer-component-type="RichTextContainer"><h6>Full Control</h6></p></div><p>Knokke lets you fine-tune every detail with flexible settings and precise color control.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">04</h6></p><p data-framer-component-type="RichTextContainer"><h6>Future Proof</h6></p></div><p>Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.</p></div></div></div></div><div data-framer-name="CTA-Section" id="cta-section"><div data-framer-name="Left"><p data-framer-component-type="RichTextContainer"><h2>Price at Launch</h2></p></div><div data-framer-name="Right"><div data-framer-name="Price"><p><!--$--><h2><span>999€</span></h2><!--/$--></p><p><strong>Includes scanner + software</strong></p></div><div data-framer-name="Features"><div data-framer-name="Row"><p><!--$--><h2><span>4064 dpi resolution</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>5 min per roll</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>48-bit colour depth</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>120 dB Dynamic Range</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>LED Matrix</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>RGB LED backlight</span></h2><!--/$--></p></div></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg to Google: Fund Us or Stop Sending Bugs (436 pts)]]></title>
            <link>https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/</link>
            <guid>45891016</guid>
            <pubDate>Tue, 11 Nov 2025 18:32:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/">https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/</a>, See on <a href="https://news.ycombinator.com/item?id=45891016">Hacker News</a></p>
Couldn't get https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Cache-friendly, low-memory Lanczos algorithm in Rust (101 pts)]]></title>
            <link>https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/</link>
            <guid>45889891</guid>
            <pubDate>Tue, 11 Nov 2025 17:08:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/">https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/</a>, See on <a href="https://news.ycombinator.com/item?id=45889891">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article"> <p>The standard Lanczos method for computing matrix functions has a brutal memory requirement: storing an <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> basis matrix that grows with every iteration. For a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>500.000</mn></mrow><annotation encoding="application/x-tex">500.000</annotation></semantics></math></span></span>-variable problem needing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn></mrow><annotation encoding="application/x-tex">1000</annotation></semantics></math></span></span> iterations, that’s roughly 4 GB just for the basis.</p>
<p>In this post, we will explore one of the most straightforward solutions to this problem: a two-pass variant of the Lanczos algorithm that only requires <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span> memory at the cost of doubling the number of matrix-vector products. The surprising part is that when implemented carefully, the two-pass version isn’t just memory-efficient—it can be faster for certain problems. We will dig into why.</p>
<ul>
<li>All code is available on GitHub: <a href="https://github.com/lukefleed/two-pass-lanczos">two-pass-lanczos</a></li>
<li>The full technical report with proofs and additional experiments: <a href="https://github.com/lukefleed/two-pass-lanczos/raw/master/tex/report.pdf">report.pdf</a></li>
</ul>
<hr>
<h2 id="table-of-contents">Table of Contents</h2>
<details><summary>Open Table of Contents</summary>
<ul>
<li><a href="#computing-matrix-functions">Computing Matrix Functions</a>
<ul>
<li><a href="#krylov-projection">Krylov Projection</a>
<ul>
<li><a href="#building-an-orthonormal-basis">Building an Orthonormal Basis</a></li>
<li><a href="#solving-in-the-reduced-space">Solving in the Reduced Space</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#the-lanczos-algorithm">The Lanczos Algorithm</a>
<ul>
<li><a href="#three-term-recurrence">Three-Term Recurrence</a></li>
<li><a href="#reconstructing-the-solution">Reconstructing the Solution</a></li>
</ul>
</li>
<li><a href="#two-pass-algorithm">Two-Pass Algorithm</a>
<ul>
<li><a href="#first-pass-compute-the-projected-problem">First Pass: Compute the Projected Problem</a></li>
<li><a href="#second-pass-reconstruct-and-accumulate">Second Pass: Reconstruct and Accumulate</a>
<ul>
<li><a href="#a-subtle-numerical-point">A Subtle Numerical Point</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#implementation">Implementation</a>
<ul>
<li><a href="#recurrence-step">Recurrence Step</a></li>
<li><a href="#an-iterator-for-state-management">An Iterator for State Management</a></li>
<li><a href="#first-pass-computing-the-decomposition">First Pass: Computing the Decomposition</a></li>
<li><a href="#second-pass-reconstructing-the-solution">Second Pass: Reconstructing the Solution</a></li>
<li><a href="#the-public-api">The Public API</a>
<ul>
<li><a href="#example-solving-a-linear-system">Example: Solving a Linear System</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#some-interesting-results">Some interesting results</a>
<ul>
<li><a href="#memory-and-computation-trade-off">Memory and Computation Trade-off</a>
<ul>
<li><a href="#memory-usage">Memory Usage</a></li>
<li><a href="#runtime-where-theory-breaks">Runtime: Where Theory Breaks</a></li>
<li><a href="#medium-scale-behavior">Medium-Scale Behavior</a></li>
<li><a href="#what-about-dense-matrices">What About Dense Matrices?</a></li>
</ul>
</li>
<li><a href="#scalability">Scalability</a></li>
</ul>
</li>
</ul>
</details>
<h2 id="computing-matrix-functions">Computing Matrix Functions</h2>
<p>Let’s consider the problem of computing the action of matrix functions on a vector:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">x</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{x} = f(\mathbf{A})\mathbf{b}</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is a large sparse Hermitian matrix and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> is a matrix function defined on the spectrum of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. This is a problem that appears pretty often in scientific computing: solving linear systems corresponds to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span>, exponential integrators for PDEs use <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>t</mi><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(z) = \exp(tz)</annotation></semantics></math></span></span>, and many other problems require functions like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>−</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1/2}</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>sign</mtext><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(z) = \text{sign}(z)</annotation></semantics></math></span></span>.</p>
<p>Indeed, there are a lot problems with computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> directly. First of all, even if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is sparse, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> is generally dense. Storing it explicitly is out of the question for large problems. Even if we could store it, computing it directly would require algorithms like the Schur-Parlett method that scale as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^3)</annotation></semantics></math></span></span>, which is impractical for large <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>.</p>
<p>However we know that given any matrix function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> defined on the spectrum of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>, we can express <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> as a polynomial in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> of degree at most <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> (the size of the matrix) such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>p</mi><mi>n</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A}) = p_{n}(\mathbf{A})</annotation></semantics></math></span></span> (this is a consequence of the Cayley-Hamilton theorem). This polynomial interpolates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> and its derivatives in the Hermitian sense at the eigenvalues of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>.</p>
<p>This gives us a good and a bad news: the good news is that, well, we can express <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> as a polynomial in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. The bad news is that the degree of this polynomial can be as high as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>, which is huge for large problems. The idea is then to find a low-degree polynomial approximation to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> that is <em>good enough</em> for our purposes. If we can find a polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span></span> of degree <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>≪</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \ll n</annotation></semantics></math></span></span> such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mo>≈</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_k(\mathbf{A}) \approx f(\mathbf{A})</annotation></semantics></math></span></span>, then we can approximate the solution as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi><mo>≈</mo><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></munderover><msub><mi>c</mi><mi>i</mi></msub><msup><mi mathvariant="bold">A</mi><mi>i</mi></msup><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">f(\mathbf{A})\mathbf{b} \approx p_k(\mathbf{A})\mathbf{b} = \sum_{i=0}^k c_i \mathbf{A}^i \mathbf{b}</annotation></semantics></math></span></span></span>
<p>This polynomial only involves vectors within a specific subspace.</p>
<h2 id="krylov-projection">Krylov Projection</h2>
<p>We can notice that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">p_k(\mathbf{A})\mathbf{b}</annotation></semantics></math></span></span> only depends on vectors in the Krylov subspace of order <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span></p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">K</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>span</mtext><mo stretchy="false">{</mo><mi mathvariant="bold">b</mi><mo separator="true">,</mo><mrow><mi mathvariant="bold">A</mi><mi mathvariant="bold">b</mi></mrow><mo separator="true">,</mo><msup><mi mathvariant="bold">A</mi><mn>2</mn></msup><mi mathvariant="bold">b</mi><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msup><mi mathvariant="bold">A</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msup><mi mathvariant="bold">b</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{K}_k(\mathbf{A}, \mathbf{b}) = \text{span}\{\mathbf{b}, \mathbf{Ab}, \mathbf{A}^2\mathbf{b}, \ldots, \mathbf{A}^{k-1}\mathbf{b}\}</annotation></semantics></math></span></span></span>
<p>This is fortunate: we can compute an approximate solution by staying within this space, which only requires repeated matrix-vector products with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. For large sparse matrices, that’s the only operation we can do efficiently anyway.</p>
<blockquote>
<p>We don’t need to construct <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">A</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{A}^j</annotation></semantics></math></span></span> explicitly. We compute iteratively: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo stretchy="false">(</mo><msup><mi mathvariant="bold">A</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msup><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{A}(\mathbf{A}^{j-1}\mathbf{b})</annotation></semantics></math></span></span>.</p>
</blockquote>
<p>But there’s a problem: the raw vectors <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msup><mi mathvariant="bold">A</mi><mi>j</mi></msup><mi mathvariant="bold">b</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\mathbf{A}^j\mathbf{b}\}</annotation></semantics></math></span></span> form a terrible basis. They quickly become nearly parallel, making any computation numerically unstable. We need an orthonormal basis.</p>
<h3 id="building-an-orthonormal-basis">Building an Orthonormal Basis</h3>
<p>The standard method is the Arnoldi process, which is Gram-Schmidt applied to Krylov subspaces. We start by normalizing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo>=</mo><mi mathvariant="bold">b</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1 = \mathbf{b} / \|\mathbf{b}\|_2</annotation></semantics></math></span></span>. Then, iteratively:</p>
<ol>
<li>Compute a new candidate: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{w}_j = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></li>
<li>Orthogonalize against all existing basis vectors:</li>
</ol>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><mo>=</mo><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>j</mi></munderover><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">v</mi><mi>i</mi><mi>H</mi></msubsup><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_j = \mathbf{w}_j - \sum_{i=1}^j (\mathbf{v}_i^H \mathbf{w}_j) \mathbf{v}_i</annotation></semantics></math></span></span></span>
<ol start="3">
<li>Normalize: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi mathvariant="normal">∥</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1} = \tilde{\mathbf{v}}_j / \|\tilde{\mathbf{v}}_j\|_2</annotation></semantics></math></span></span></li>
</ol>
<p>The coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>i</mi><mi>H</mi></msubsup><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_{ij} = \mathbf{v}_i^H \mathbf{w}_j</annotation></semantics></math></span></span> become entries of a projected matrix. After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we have:</p>
<ul>
<li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">v</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{V}_k = [\mathbf{v}_1, \ldots, \mathbf{v}_k]</annotation></semantics></math></span></span>: an orthonormal basis for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">K</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{K}_k(\mathbf{A}, \mathbf{b})</annotation></semantics></math></span></span></li>
<li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k</annotation></semantics></math></span></span>: an upper Hessenberg matrix representing the projection of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> onto this subspace</li>
</ul>
<p>We can express this relationship with the Arnoldi decomposition:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo>+</mo><msub><mi>h</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>k</mi></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><msubsup><mi mathvariant="bold">e</mi><mi>k</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{A}\mathbf{V}_k = \mathbf{V}_k \mathbf{H}_k + h_{k+1,k} \mathbf{v}_{k+1} \mathbf{e}_k^T</annotation></semantics></math></span></span></span>
<h3 id="solving-in-the-reduced-space">Solving in the Reduced Space</h3>
<p>Now we approximate our original problem by solving it in the small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-dimensional space. Using the Full Orthogonal Method (FOM), we enforce that the residual is orthogonal to
the Krylov subspace. This gives:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span> is computed as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{H}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span></span>
<p>The heavy lifting is now on computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{H}_k)</annotation></semantics></math></span></span>, a small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k \times k</annotation></semantics></math></span></span> matrix.
Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>≪</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \ll n</annotation></semantics></math></span></span>, we can afford direct methods like Schur-Parlett (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k^3)</annotation></semantics></math></span></span>).</p>
<blockquote>
<p>For <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span> (linear systems), this reduces to solving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k \mathbf{y}_k = \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> with LU decomposition.</p>
</blockquote>
<h2 id="the-lanczos-algorithm">The Lanczos Algorithm</h2>
<p>When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian (or symmetric in the real case), the general Arnoldi
process simplifies dramatically. We can prove that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">V</mi><mi>k</mi><mi>H</mi></msubsup><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k = \mathbf{V}_k^H \mathbf{A} \mathbf{V}_k</annotation></semantics></math></span></span> must also be Hermitian. A matrix that is both upper Hessenberg <em>and</em> Hermitian must be real, symmetric, and tridiagonal. This is a <em>huge</em> simplification.</p>
<p>In the literature, this projected matrix is denoted <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> to highlight its
tridiagonal structure:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>α</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>β</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>β</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>α</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>β</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>β</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">⋱</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">⋱</mo></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">⋱</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>α</mi><mi>k</mi></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{T}_k = \begin{pmatrix}
\alpha_1 &amp; \beta_1 &amp; &amp; \\
\beta_1 &amp; \alpha_2 &amp; \beta_2 &amp; \\
&amp; \beta_2 &amp; \ddots &amp; \ddots \\
&amp; &amp; \ddots &amp; \alpha_k
\end{pmatrix}</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\alpha_j \in \mathbb{R}</annotation></semantics></math></span></span> are the diagonal elements and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\beta_j \in \mathbb{R}</annotation></semantics></math></span></span> are the off-diagonals (subdiagonals from the orthogonalization).</p>
<h2 id="three-term-recurrence">Three-Term Recurrence</h2>
<p>This tridiagonal structure leads to a beautiful simplification. To build the next basis
vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span>, we don’t need the entire history of vectors. We only need
the two previous ones. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian, this guarantees that
any new vector is <em>automatically</em> orthogonal to all earlier vectors (beyond the previous two). So we can skip the full orthogonalization and use a simple three-term recurrence:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>=</mo><msub><mi>β</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>α</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>+</mo><msub><mi>β</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{A}\mathbf{v}_j = \beta_{j-1}\mathbf{v}_{j-1} + \alpha_j \mathbf{v}_j + \beta_j \mathbf{v}_{j+1}</annotation></semantics></math></span></span></span>
<p>Rearranging gives us an algorithm to compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span> directly:</p>
<ol>
<li>Compute the candidate: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_{j+1} = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></li>
<li>Extract the diagonal coefficient: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>j</mi><mi>H</mi></msubsup><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_j = \mathbf{v}_j^H w_{j+1}</annotation></semantics></math></span></span></li>
<li>Orthogonalize against the two previous vectors:</li>
</ol>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>α</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>−</mo><msub><mi>β</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_{j+1} = w_{j+1} - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<ol start="4">
<li>Normalize: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="normal">∥</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\beta_j = \|\tilde{\mathbf{v}}_{j+1}\|_2</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1} = \tilde{\mathbf{v}}_{j+1} / \beta_j</annotation></semantics></math></span></span></li>
</ol>
<p>This is known as the Lanczos algorithm. It’s more efficient than Arnoldi because each iteration only orthogonalizes against two previous vectors instead of all prior ones.</p>
<h2 id="reconstructing-the-solution">Reconstructing the Solution</h2>
<p>After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we end up with the tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> and all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> basis vectors <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">v</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{V}_k = [\mathbf{v}_1, \ldots, \mathbf{v}_k]</annotation></semantics></math></span></span>. We can then reconstruct the approximate solution as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> is solved from the small tridiagonal matrix.</p>
<p>There is a timing problem however: we cannot compute the coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span>
until all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations are complete. The full matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> is only available
at the end, so we must store every basis vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> along the way, leading to a memory cost of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span>.</p>
<p>So we’re left with a choice: whether we store all the basis vectors and solve the problem in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> passes, or find a way to avoid storing them. There is a middle ground.</p>
<blockquote>
<p>There are also techniques to compress the basis vectors, have a look <a href="https://arxiv.org/abs/2403.04390">here</a></p>
</blockquote>
<h2 id="two-pass-algorithm">Two-Pass Algorithm</h2>
<p>Here’s where we break the timing deadlock. The insight that we don’t actually need to store the basis vectors if we can afford to compute them twice</p>
<p>Think about what we have after the first pass. We’ve computed all the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> coefficients that compose the entire tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span>. These numbers are small compared to the full basis. What if we kept only these scalars, discarded all the vectors, and then replayed the Lanczos recurrence a second time? We’d regenerate the same basis, and this time we’d use it to build the solution.</p>
<p>This comes at a cost. We run Lanczos twice, so we pay for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. But we only ever store a constant number of vectors in memory, no <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span> basis matrix. The memory complexity drops to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span>.</p>
<p>It sounds like a bad trade at first. But as we’ll see later, the cache behavior of this
two-pass approach can actually make it as fast (or even faster) on real hardware if well optimized.</p>
<h2 id="first-pass-compute-the-projected-problem">First Pass: Compute the Projected Problem</h2>
<p>We initialize <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo>=</mo><mi mathvariant="bold">b</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1 = \mathbf{b} / \|\mathbf{b}\|_2</annotation></semantics></math></span></span> and set <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\beta_0 = 0</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>0</mn></msub><mo>=</mo><mn mathvariant="bold">0</mn></mrow><annotation encoding="application/x-tex">\mathbf{v}_0 = \mathbf{0}</annotation></semantics></math></span></span>.Then we run the standard Lanczos recurrence:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>j</mi><mi>H</mi></msubsup><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j = \mathbf{v}_j^H w_j</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mi>j</mi></msub><mo>−</mo><msub><mi>α</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>−</mo><msub><mi>β</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_{j+1} = w_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="normal">∥</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j = \|\tilde{\mathbf{v}}_{j+1}\|_2, \quad \mathbf{v}_{j+1} = \tilde{\mathbf{v}}_{j+1} / \beta_j</annotation></semantics></math></span></span></span>
<p>At each step, we record <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. But we <em>do not</em> store <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span>.
Instead, we discard it immediately after computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span>. In this way we only keep in memory at most just three vectors at any time (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j-1}</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span>, and the working vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span></span>).</p>
<p>After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we have the full set <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>β</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>α</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mi>β</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_1, \beta_1, \ldots, \alpha_k, \beta_k\}</annotation></semantics></math></span></span>. These <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span></span> scalars define the tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span>. We can now solve:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span></span>
<p>This is the solution in the reduced space. Now that we have the coefficients we need to build <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>.</p>
<h2 id="second-pass-reconstruct-and-accumulate">Second Pass: Reconstruct and Accumulate</h2>
<p>With <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span> in memory, we replay the Lanczos recurrence <em>exactly as before</em>. We start with the same initialization (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\beta_0</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_0</annotation></semantics></math></span></span>) and apply the same sequence of operations, using the stored scalars <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> to reconstruct each basis vector on demand. We can write some rust-like <em>pseudocode</em> for this second pass to get a feel for it:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> x_k</span><span> =</span><span> vec!</span><span>[</span><span>0</span><span>.</span><span>0</span><span>; </span><span>n</span><span>];</span></span>
<span><span>let</span><span> mut</span><span> v_prev</span><span> =</span><span> vec!</span><span>[</span><span>0</span><span>.</span><span>0</span><span>; </span><span>n</span><span>];</span></span>
<span><span>let</span><span> mut</span><span> v_curr</span><span> =</span><span> b</span><span>.</span><span>clone</span><span>() </span><span>/</span><span> b_norm</span><span>;</span></span>
<span></span>
<span><span>for</span><span> j</span><span> in</span><span> 1</span><span>..=</span><span>k</span><span> {</span></span>
<span><span>    let</span><span> w</span><span> =</span><span> A</span><span> @</span><span> v_curr</span><span>;  </span><span>// Matrix-vector product</span></span>
<span></span>
<span><span>    // We don't recompute alpha/beta; we already have them from pass 1</span></span>
<span><span>    let</span><span> alpha_j</span><span> =</span><span> alphas</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>];</span></span>
<span><span>    let</span><span> beta_prev</span><span> =</span><span> j</span><span> &gt;</span><span> 1</span><span> ?</span><span> betas</span><span>[</span><span>j</span><span> -</span><span> 2</span><span>] </span><span>:</span><span> 0</span><span>.</span><span>0</span><span>;</span></span>
<span></span>
<span><span>    // Accumulate the solution</span></span>
<span><span>    x_k</span><span> +=</span><span> y_k</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>] </span><span>*</span><span> v_curr</span><span>;</span></span>
<span></span>
<span><span>    // Regenerate the next basis vector for the *next* iteration</span></span>
<span><span>    let</span><span> v_next</span><span> =</span><span> (</span><span>w</span><span> -</span><span> alpha_j</span><span> *</span><span> v_curr</span><span> -</span><span> beta_prev</span><span> *</span><span> v_prev</span><span>) </span><span>/</span><span> betas</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>];</span></span>
<span></span>
<span><span>    // Slide the window forward</span></span>
<span><span>    v_prev</span><span> =</span><span> v_curr</span><span>;</span></span>
<span><span>    v_curr</span><span> =</span><span> v_next</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>This loop regenerates each <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> on demand and immediately uses it to update the solution.
Once we’ve accumulated <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">(\mathbf{y}_k)_j \mathbf{v}_j</annotation></semantics></math></span></span> into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>, we discard the vector. We never store the full basis.</p>
<h3 id="a-subtle-numerical-point">A Subtle Numerical Point</h3>
<p>There is one detail worth noting: floating-point arithmetic is deterministic. When we replay the Lanczos recurrence in the second pass with the exact same inputs and the exact same order of operations, we get bitwise-identical vectors. The <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> regenerated in pass 2 are identical to the ones computed in pass 1.</p>
<p>However, the order in which we accumulate the solution differs. In a standard Lanczos,
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span> is built as a single matrix-vector product: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> (a <code>gemv</code> call in BLAS). In the two-pass method, it’s built as a loop of scaled vector additions (a series of <code>axpy</code> calls). These operations accumulate rounding error differently, so the final solution differs slightly, typically by machine epsilon. This rarely matters in practice, and convergence is unaffected.</p>
<h2 id="implementation">Implementation</h2>
<p>Building this in Rust forces us to think concretely about where data lives and how it flows through the cache hierarchy. We need to control memory layout, decide when allocations happen, and choose abstractions that cost us nothing at runtime.</p>
<p>For linear algebra, we reach for <a href="https://github.com/sarah-ek/faer-rs"><code>faer</code></a>. Three design choices in this library matter for what we’re building:</p>
<ul>
<li><strong>Stack allocation via <code>MemStack</code>:</strong> Pre-allocated scratch space that lives for the entire computation. The hot path becomes allocation-free.</li>
<li><strong>Matrix-free operators:</strong> The <code>LinOp</code> trait defines an operator by its action (<code>apply</code>) without materializing a matrix. For large sparse problems, this is the only viable approach.</li>
<li><strong>SIMD-friendly loops:</strong> The <code>zip!</code> macro generates code that compiles to packed instructions.</li>
</ul>
<h2 id="recurrence-step">Recurrence Step</h2>
<p>Our starting point is the Lanczos three-term recurrence that we derived earlier:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>−</mo><msub><mi>α</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>−</mo><msub><mi>β</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\beta_j \mathbf{v}_{j+1} = \mathbf{A}\mathbf{v}_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<p>We can translate this into a recurrence step function. The signature looks like this:</p>
<pre tabindex="0" data-language="rust"><code><span><span>fn</span><span> lanczos_recurrence_step</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    mut</span><span> w</span><span>:</span><span> MatMut</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_curr</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_prev</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> (T</span><span>::</span><span>Real</span><span>, </span><span>Option</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;)</span></span></code></pre>
<p>The function is generic over the field type <code>T</code> (<code>f64</code>, <code>c64</code>, etc.) and the operator type <code>O</code>. It operates on matrix views (<code>MatMut</code> and <code>MatRef</code>) to avoid unnecessary data copies. The return type gives us the diagonal element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and, <em>if no breakdown occurs</em>, the off-diagonal <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>.</p>
<p>Now we can implement the body by following the math. The first step is the most expensive:</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 1. Apply operator: w = A * v_curr</span></span>
<span><span>operator</span><span>.</span><span>apply</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>, Par</span><span>::</span><span>Seq</span><span>, </span><span>stack</span><span>);</span></span></code></pre>
<p>The matrix-vector product dominates the computational cost. Everything else is secondary.</p>
<p>Next, we orthogonalize against <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j-1}</annotation></semantics></math></span></span>. This is where we benefit from <code>faer</code>’s design. The <code>zip!</code> macro fuses this operation into a single loop that the compiler vectorizes into SIMD instructions.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 2. Orthogonalize against v_{j-1}: w -= β_{j-1} * v_{j-1}</span></span>
<span><span>let</span><span> beta_prev_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>beta_prev</span><span>);</span></span>
<span><span>zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_prev</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_prev_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>    *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>beta_prev_scaled</span><span>, </span><span>v_prev_i</span><span>));</span></span>
<span><span>});</span></span></code></pre>
<p>With <code>w</code> partially orthogonalized, we can compute the diagonal coefficient via an inner product. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> is guaranteed real.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 3. Compute α_j = v_j^H * w</span></span>
<span><span>let</span><span> alpha</span><span> =</span><span> T</span><span>::</span><span>real_part_impl</span><span>(</span><span>&amp;</span><span>(</span><span>v_curr</span><span>.</span><span>adjoint</span><span>() </span><span>*</span><span> w</span><span>.</span><span>rb</span><span>())[(</span><span>0</span><span>, </span><span>0</span><span>)]);</span></span></code></pre>
<p>We complete the orthogonalization against <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> with another <code>zip!</code> loop.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 4. Orthogonalize against v_j: w -= α_j * v_j</span></span>
<span><span>let</span><span> alpha_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>alpha</span><span>);</span></span>
<span><span>zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_curr_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>    *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>alpha_scaled</span><span>, </span><span>v_curr_i</span><span>));</span></span>
<span><span>});</span></span></code></pre>
<p>Now <code>w</code> holds the unnormalized next basis vector. We compute its norm to get <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. If this norm is numerically zero, the Krylov subspace is invariant, the iteration has reached its natural stopping point. This is called breakdown.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 5. Compute β_j = ||w||_2 and check for breakdown</span></span>
<span><span>let</span><span> beta</span><span> =</span><span> w</span><span>.</span><span>rb</span><span>()</span><span>.</span><span>norm_l2</span><span>();</span></span>
<span><span>let</span><span> tolerance</span><span> =</span><span> breakdown_tolerance</span><span>::</span><span>&lt;T</span><span>::</span><span>Real</span><span>&gt;();</span></span>
<span></span>
<span><span>if</span><span> beta</span><span> &lt;=</span><span> tolerance</span><span> {</span></span>
<span><span>    (</span><span>alpha</span><span>, </span><span>None</span><span>)</span></span>
<span><span>} </span><span>else</span><span> {</span></span>
<span><span>    (</span><span>alpha</span><span>, </span><span>Some</span><span>(</span><span>beta</span><span>))</span></span>
<span><span>}</span></span></code></pre>
<p>The function returns <code>None</code> for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> when breakdown occurs, signaling to the caller that no further iterations should proceed.</p>
<h2 id="an-iterator-for-state-management">An Iterator for State Management</h2>
<p>The recurrence step is a pure function, but calling it in a loop is both inefficient and awkward. We’d need to manually pass vectors in and out of each iteration. More critically, we’d create copies when we should be reusing memory.</p>
<p>The iterator pattern solves this. We create a struct that encapsulates the state:</p>
<pre tabindex="0" data-language="rust"><code><span><span>struct</span><span> LanczosIteration</span><span>&lt;'</span><span>a</span><span>, </span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt; {</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>'</span><span>a</span><span> O</span><span>,</span></span>
<span><span>    v_prev</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,       </span><span>// v_{j-1}</span></span>
<span><span>    v_curr</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,       </span><span>// v_j</span></span>
<span><span>    work</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,         </span><span>// Workspace for the next vector</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,   </span><span>// β_{j-1}</span></span>
<span><span>    // ... iteration counters</span></span>
<span><span>}</span></span></code></pre>
<p>The main design choice here is that vectors are <strong>owned</strong> (<code>Mat&lt;T&gt;</code>), not borrowed. This enables an optimization in the <code>next_step</code> method. After computing the next vector and normalizing it into <code>work</code>, we cycle the state without allocating or copying:</p>
<pre tabindex="0" data-language="rust"><code><span><span>// Inside next_step, after normalization...</span></span>
<span><span>core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_prev, </span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_curr);</span></span>
<span><span>core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_curr, </span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>work);</span></span></code></pre>
<p>On x86-64, swapping two <code>Mat&lt;T&gt;</code> structures (fat pointers) compiles to three <code>mov</code> instructions. The pointers change, but no vector data moves. After the swap, <code>v_prev</code> points to what <code>v_curr</code> held, <code>v_curr</code> points to <code>work</code>’s allocation, and <code>work</code> points to the old <code>v_prev</code> data. In the next iteration, <code>work</code> gets reused.</p>
<p>We keep exactly three n-dimensional vectors live in memory. The same allocations cycle through the computation, staying hot in L1 cache. This is the core reason the two-pass method can be faster than expected, the working set never leaves cache.</p>
<h2 id="first-pass-computing-the-decomposition">First Pass: Computing the Decomposition</h2>
<p>The first pass runs the Lanczos iteration and collects the coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>α</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>β</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span>. Basis vectors are discarded after each step.</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_pass_one</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>impl</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    k</span><span>:</span><span> usize</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>LanczosDecomposition</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;, </span><span>LanczosError</span><span>&gt; {</span></span>
<span><span>    // ...</span></span>
<span><span>}</span></span></code></pre>
<p>We allocate vectors for the coefficients with a capacity hint to avoid reallocations:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> alphas</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>k</span><span>);</span></span>
<span><span>let</span><span> mut</span><span> betas</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>k</span><span> -</span><span> 1</span><span>);</span></span></code></pre>
<p>Then we construct the iterator. This allocates the three work vectors once. After this point, the hot path is allocation-free:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> lanczos_iter</span><span> =</span><span> LanczosIteration</span><span>::</span><span>new</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>k</span><span>, </span><span>b_norm</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>for</span><span> i</span><span> in</span><span> 0</span><span>..</span><span>k</span><span> {</span></span>
<span><span>    if</span><span> let</span><span> Some</span><span>(</span><span>step</span><span>) </span><span>=</span><span> lanczos_iter</span><span>.</span><span>next_step</span><span>(</span><span>stack</span><span>) {</span></span>
<span><span>        alphas</span><span>.</span><span>push</span><span>(</span><span>step</span><span>.</span><span>alpha);</span></span>
<span><span>        steps_taken</span><span> +=</span><span> 1</span><span>;</span></span>
<span></span>
<span><span>        let</span><span> tolerance</span><span> =</span><span> breakdown_tolerance</span><span>::</span><span>&lt;T</span><span>::</span><span>Real</span><span>&gt;();</span></span>
<span><span>        if</span><span> step</span><span>.</span><span>beta </span><span>&lt;=</span><span> tolerance</span><span> {</span></span>
<span><span>            break</span><span>;</span></span>
<span><span>        }</span></span>
<span></span>
<span><span>        if</span><span> i</span><span> &lt;</span><span> k</span><span> -</span><span> 1</span><span> {</span></span>
<span><span>            betas</span><span>.</span><span>push</span><span>(</span><span>step</span><span>.</span><span>beta);</span></span>
<span><span>        }</span></span>
<span><span>    } </span><span>else</span><span> {</span></span>
<span><span>        break</span><span>;</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre>
<p>The check for breakdown stops the iteration when the residual becomes numerically zero. This means we’ve found an invariant subspace and there’s no value in continuing.</p>
<p>At the end, we collect the scalars into a <code>LanczosDecomposition</code> struct. The memory footprint throughout this pass is constant: three n-dimensional vectors plus two small arrays that grow to at most <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> elements.</p>
<h2 id="second-pass-reconstructing-the-solution">Second Pass: Reconstructing the Solution</h2>
<p>Now we face a different problem. We have the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>α</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>β</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span> coefficients from the first pass and the coefficient vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> from solving the projected problem. We need to reconstruct the solution:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \sum_{j=1}^k (\mathbf{y}_k)_j \mathbf{v}_j</annotation></semantics></math></span></span></span>
<p>without storing the full basis matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span>.</p>
<p>The recurrence step in this pass is structurally similar to the first pass, but with a key difference: we no longer compute inner products or norms. We already know the coefficients, so the step becomes pure reconstruction.</p>
<pre tabindex="0" data-language="rust"><code><span><span>fn</span><span> lanczos_reconstruction_step</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    mut</span><span> w</span><span>:</span><span> MatMut</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_curr</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_prev</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    alpha_j</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) {</span></span>
<span><span>    // Apply operator</span></span>
<span><span>    operator</span><span>.</span><span>apply</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>, Par</span><span>::</span><span>Seq</span><span>, </span><span>stack</span><span>);</span></span>
<span></span>
<span><span>    // Orthogonalize using stored α_j and β_{j-1}</span></span>
<span><span>    let</span><span> beta_prev_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>beta_prev</span><span>);</span></span>
<span><span>    zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_prev</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_prev_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>beta_prev_scaled</span><span>, </span><span>v_prev_i</span><span>));</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    let</span><span> alpha_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>alpha_j</span><span>);</span></span>
<span><span>    zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_curr_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>alpha_scaled</span><span>, </span><span>v_curr_i</span><span>));</span></span>
<span><span>    });</span></span>
<span><span>}</span></span></code></pre>
<p>This is cheaper than the first-pass recurrence. We’ve eliminated the inner products that computed <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and the norm calculation for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. What remains is pure orthogonalization and the operator application.</p>
<p><code>lanczos_pass_two</code> implements this reconstruction. We initialize the three work vectors and the solution accumulator:</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_pass_two</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>impl</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    decomposition</span><span>:</span><span> &amp;</span><span>LanczosDecomposition</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;,</span></span>
<span><span>    y_k</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>LanczosError</span><span>&gt; {</span></span>
<span><span>    let</span><span> mut</span><span> v_prev</span><span> =</span><span> Mat</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>);</span></span>
<span><span>    let</span><span> inv_norm</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>T</span><span>::</span><span>Real</span><span>::</span><span>recip_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>b_norm));</span></span>
<span><span>    let</span><span> mut</span><span> v_curr</span><span> =</span><span> b</span><span> *</span><span> Scale</span><span>(</span><span>inv_norm</span><span>);  </span><span>// v_1</span></span>
<span></span>
<span><span>    let</span><span> mut</span><span> work</span><span> =</span><span> Mat</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>);</span></span>
<span></span>
<span><span>    // Initialize solution with first component</span></span>
<span><span>    let</span><span> mut</span><span> x_k</span><span> =</span><span> &amp;</span><span>v_curr</span><span> *</span><span> Scale</span><span>(T</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>y_k</span><span>[(</span><span>0</span><span>, </span><span>0</span><span>)]));</span></span></code></pre>
<p>We build the solution incrementally by starting with the first basis vector scaled by its coefficient. The main loop then regenerates each subsequent vector: we regenerate each subsequent basis vector, normalize it using the stored <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>, and immediately accumulate its contribution:</p>
<pre tabindex="0" data-language="rust"><code><span><span>for</span><span> j</span><span> in</span><span> 0</span><span>..</span><span>decomposition</span><span>.</span><span>steps_taken </span><span>-</span><span> 1</span><span> {</span></span>
<span><span>    let</span><span> alpha_j</span><span> =</span><span> T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>alphas[</span><span>j</span><span>]);</span></span>
<span><span>    let</span><span> beta_j</span><span> =</span><span> T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas[</span><span>j</span><span>]);</span></span>
<span><span>    let</span><span> beta_prev</span><span> =</span><span> if</span><span> j</span><span> ==</span><span> 0</span><span> {</span></span>
<span><span>        T</span><span>::</span><span>Real</span><span>::</span><span>zero_impl</span><span>()</span></span>
<span><span>    } </span><span>else</span><span> {</span></span>
<span><span>        T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas[</span><span>j</span><span> -</span><span> 1</span><span>])</span></span>
<span><span>    };</span></span>
<span></span>
<span><span>    // 1. Regenerate the unnormalized next vector</span></span>
<span><span>    lanczos_reconstruction_step</span><span>(</span></span>
<span><span>        operator</span><span>,</span></span>
<span><span>        work</span><span>.</span><span>as_mut</span><span>(),</span></span>
<span><span>        v_curr</span><span>.</span><span>as_ref</span><span>(),</span></span>
<span><span>        v_prev</span><span>.</span><span>as_ref</span><span>(),</span></span>
<span><span>        alpha_j</span><span>,</span></span>
<span><span>        beta_prev</span><span>,</span></span>
<span><span>        stack</span><span>,</span></span>
<span><span>    );</span></span>
<span></span>
<span><span>    // 2. Normalize using stored β_j</span></span>
<span><span>    let</span><span> inv_beta</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>T</span><span>::</span><span>Real</span><span>::</span><span>recip_impl</span><span>(</span><span>&amp;</span><span>beta_j</span><span>));</span></span>
<span><span>    zip!</span><span>(</span><span>work</span><span>.</span><span>as_mut</span><span>())</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> mul</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>inv_beta</span><span>);</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    // 3. Accumulate: x_k += y_{j+1} * v_{j+1}</span></span>
<span><span>    let</span><span> coeff</span><span> =</span><span> T</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>y_k</span><span>[(</span><span>j</span><span> +</span><span> 1</span><span>, </span><span>0</span><span>)]);</span></span>
<span><span>    zip!</span><span>(</span><span>x_k</span><span>.</span><span>as_mut</span><span>(), </span><span>work</span><span>.</span><span>as_ref</span><span>())</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>x_i</span><span>, </span><span>v_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>x_i</span><span> =</span><span> add</span><span>(</span><span>x_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>coeff</span><span>, </span><span>v_i</span><span>));</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    // 4. Cycle vectors for the next iteration</span></span>
<span><span>    core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> v_prev</span><span>, </span><span>&amp;</span><span>mut</span><span> v_curr</span><span>);</span></span>
<span><span>    core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> v_curr</span><span>, </span><span>&amp;</span><span>mut</span><span> work</span><span>);</span></span>
<span><span>}</span></span></code></pre>
<p>The accumulation <code>x_k += y_{j+1} * v_{j+1}</code> is implemented as a fused multiply-add in the <code>zip!</code> loop. On hardware with FMA support, this becomes a single instruction per element, not three separate operations.</p>
<p>Note that we accumulate the solution incrementally. After each iteration, <code>x_k</code> contains a partial result. We cycle through the same three vectors (<code>v_prev</code>, <code>v_curr</code>, <code>work</code>), keeping the working set small and resident in L1 cache.</p>
<p>Compare this to the standard method’s final reconstruction step: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span>. This is a dense matrix-vector product where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span>. When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> are both large, this matrix no longer fits in cache. The CPU must stream it from main memory, paying the cost of memory latency. Each element requires a load, multiply, and accumulate, but the load operations dominate—the CPU stalls waiting for data.</p>
<p>In our two-pass reconstruction, the operator <code>$\mathbf{A}$</code> is applied <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> times, but against vectors that stay in cache. The memory bandwidth is spent on reading the sparse structure of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> and the vector elements, not on scanning a dense <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> matrix.</p>
<p>This is the reason the two-pass method can be faster on real hardware despite performing twice as many matrix-vector products. The cache behavior of the reconstruction phase overwhelms the savings of storing the basis.</p>
<h2 id="the-public-api">The Public API</h2>
<p>We can wrap the two passes into a single entry point:</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_two_pass</span><span>&lt;</span><span>T</span><span>, </span><span>O</span><span>, </span><span>F</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    k</span><span>:</span><span> usize</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>    mut</span><span> f_tk_solver</span><span>:</span><span> F</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>LanczosError</span><span>&gt;</span></span>
<span><span>where</span></span>
<span><span>    T</span><span>:</span><span> ComplexField</span><span>,</span></span>
<span><span>    O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    F</span><span>:</span><span> FnMut</span><span>(</span><span>&amp;</span><span>[T</span><span>::</span><span>Real</span><span>], </span><span>&amp;</span><span>[T</span><span>::</span><span>Real</span><span>]) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>anyhow</span><span>::</span><span>Error</span><span>&gt;,</span></span>
<span><span>{</span></span>
<span><span>    // First pass: compute T_k coefficients</span></span>
<span><span>    let</span><span> decomposition</span><span> =</span><span> lanczos_pass_one</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>k</span><span>, </span><span>stack</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    if</span><span> decomposition</span><span>.</span><span>steps_taken </span><span>==</span><span> 0</span><span> {</span></span>
<span><span>        return</span><span> Ok</span><span>(</span><span>Mat</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>));</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    // Solve projected problem: y_k' = f(T_k) * e_1</span></span>
<span><span>    let</span><span> y_k_prime</span><span> =</span><span> f_tk_solver</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>alphas, </span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    // Scale by ||b||</span></span>
<span><span>    let</span><span> y_k</span><span> =</span><span> &amp;</span><span>y_k_prime</span><span> *</span><span> Scale</span><span>(T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>b_norm));</span></span>
<span></span>
<span><span>    // Second pass: reconstruct solution</span></span>
<span><span>    lanczos_pass_two</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>&amp;</span><span>decomposition</span><span>, </span><span>y_k</span><span>.</span><span>as_ref</span><span>(), </span><span>stack</span><span>)</span></span>
<span><span>}</span></span></code></pre>
<p>The design separates concerns. The <code>f_tk_solver</code> closure is where we inject the specific matrix function. We compute the Lanczos decomposition, then pass the coefficients to the user-provided solver, which computes <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">y</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k' = f(\mathbf{T}_k) \mathbf{e}_1</annotation></semantics></math></span></span> for whatever function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> is needed. This decoupling means we handle linear solves, matrix exponentials, or any other function without modifying the core algorithm.</p>
<p>The caller provides <code>f_tk_solver</code> as a closure. It receives the raw <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>α</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>β</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span> arrays and must return the coefficient vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">y</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{y}_k'</annotation></semantics></math></span></span>. We then scale it by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\|\mathbf{b}\|_2</annotation></semantics></math></span></span> and pass everything to the second pass.</p>
<h3 id="example-solving-a-linear-system">Example: Solving a Linear System</h3>
<p>To see this in practice, consider solving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="bold">A</mi><mi mathvariant="bold">x</mi></mrow><mo>=</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{Ax} = \mathbf{b}</annotation></semantics></math></span></span>. We compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span>, which means the <code>f_tk_solver</code> must solve the small tridiagonal system <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><msup><mi mathvariant="bold">y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k \mathbf{y}' = \mathbf{e}_1</annotation></semantics></math></span></span>.</p>
<p>Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> is tridiagonal, we can exploit its structure. A sparse LU factorization solves it in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span></span> time instead of the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k^3)</annotation></semantics></math></span></span> cost of a dense method.</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> f_tk_solver</span><span> =</span><span> |</span><span>alphas</span><span>:</span><span> &amp;</span><span>[</span><span>f64</span><span>], </span><span>betas</span><span>:</span><span> &amp;</span><span>[</span><span>f64</span><span>]</span><span>|</span><span> -&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>f64</span><span>&gt;, </span><span>anyhow</span><span>::</span><span>Error</span><span>&gt; {</span></span>
<span><span>    let</span><span> steps</span><span> =</span><span> alphas</span><span>.</span><span>len</span><span>();</span></span>
<span><span>    if</span><span> steps</span><span> ==</span><span> 0</span><span> {</span></span>
<span><span>        return</span><span> Ok</span><span>(</span><span>Mat</span><span>::</span><span>zeros</span><span>(</span><span>0</span><span>, </span><span>1</span><span>));</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    // 1. Assemble T_k from coefficients using triplet format</span></span>
<span><span>    let</span><span> mut</span><span> triplets</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>3</span><span> *</span><span> steps</span><span> -</span><span> 2</span><span>);</span></span>
<span><span>    for</span><span> (</span><span>i</span><span>, </span><span>&amp;</span><span>alpha</span><span>) </span><span>in</span><span> alphas</span><span>.</span><span>iter</span><span>()</span><span>.</span><span>enumerate</span><span>() {</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span>, </span><span>col</span><span>:</span><span> i</span><span>, </span><span>val</span><span>:</span><span> alpha</span><span> });</span></span>
<span><span>    }</span></span>
<span><span>    for</span><span> (</span><span>i</span><span>, </span><span>&amp;</span><span>beta</span><span>) </span><span>in</span><span> betas</span><span>.</span><span>iter</span><span>()</span><span>.</span><span>enumerate</span><span>() {</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span>, </span><span>col</span><span>:</span><span> i</span><span> +</span><span> 1</span><span>, </span><span>val</span><span>:</span><span> beta</span><span> });</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span> +</span><span> 1</span><span>, </span><span>col</span><span>:</span><span> i</span><span>, </span><span>val</span><span>:</span><span> beta</span><span> });</span></span>
<span><span>    }</span></span>
<span><span>    let</span><span> t_k_sparse</span><span> =</span><span> SparseColMat</span><span>::</span><span>try_new_from_triplets</span><span>(</span><span>steps</span><span>, </span><span>steps</span><span>, </span><span>&amp;</span><span>triplets</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    // 2. Construct e_1</span></span>
<span><span>    let</span><span> mut</span><span> e1</span><span> =</span><span> Mat</span><span>::</span><span>zeros</span><span>(</span><span>steps</span><span>, </span><span>1</span><span>);</span></span>
<span><span>    e1</span><span>.</span><span>as_mut</span><span>()[(</span><span>0</span><span>, </span><span>0</span><span>)] </span><span>=</span><span> 1</span><span>.</span><span>0</span><span>;</span></span>
<span></span>
<span><span>    // 3. Solve T_k * y' = e_1 via sparse LU</span></span>
<span><span>    Ok</span><span>(</span><span>t_k_sparse</span><span>.</span><span>as_ref</span><span>()</span><span>.</span><span>sp_lu</span><span>()</span><span>?.</span><span>solve</span><span>(</span><span>e1</span><span>.</span><span>as_ref</span><span>()))</span></span>
<span><span>};</span></span></code></pre>
<p>The closure takes the coefficient arrays, constructs the sparse tridiagonal matrix, and solves the system. The triplet format lets us build the matrix efficiently without knowing its structure in advance. The sparse LU solver leverages the tridiagonal structure to avoid dense factorization.</p>
<h2 id="some-interesting-results">Some interesting results</h2>
<p>Now that we have a working implementation we can run some tests. The core idea of what we have done is simple: trade flops for better memory access. But does this trade actually pay off on real hardware? To find out, we need a reliable way to benchmark it.</p>
<p>For the data, we know that the performance of any Krylov method is tied to the operator’s spectral properties. We need a way to generate a family of test problems where we can precisely control the size, sparsity, and numerical difficulty. A great way to do this is with Karush-Kuhn-Tucker (KKT) systems, which are sparse, symmetric, and have a specific block structure.</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>D</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msup><mi>E</mi><mi>T</mi></msup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>E</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">A =
\begin{pmatrix}
    D &amp; E^T \\
    E &amp; 0
\end{pmatrix}</annotation></semantics></math></span></span></span>
<p>This structure gives us two critical knobs to turn. First, with the <a href="https://commalab.di.unipi.it/files/Data/MCF/netgen.tgz">netgen</a> utility, we can control the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span></span> matrix, which lets us dial in the problem dimension, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>. Second, we build the diagonal block D with random entries from a range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><msub><mi>C</mi><mi>D</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[1, C_D]</annotation></semantics></math></span></span>. This parameter, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">C_D</annotation></semantics></math></span></span>, gives us direct control over the numerical difficulty of the problem.</p>
<p>For a symmetric matrix like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span>, the 2-norm condition number, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>κ</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\kappa_2(D)</annotation></semantics></math></span></span>, is the ratio of its largest to its smallest eigenvalue: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>κ</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>λ</mi><mi>max</mi><mo>⁡</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msub><mi>λ</mi><mi>min</mi><mo>⁡</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\kappa_2(D) = \lambda_{\max}(D) / \lambda_{\min}(D)</annotation></semantics></math></span></span>. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span> is diagonal, its eigenvalues are simply its diagonal entries. We are drawing these entries from a uniform distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><msub><mi>C</mi><mi>D</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">U[1, C_D]</annotation></semantics></math></span></span>, so we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mi>max</mi><mo>⁡</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>≈</mo><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_{\max}(D) \approx C_D</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mi>min</mi><mo>⁡</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>≈</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda_{\min}(D) \approx 1</annotation></semantics></math></span></span>. This means we get direct control, as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>κ</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>≈</mo><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">\kappa_2(D) \approx C_D</annotation></semantics></math></span></span>.The spectral properties of this block heavily influence the spectrum of the entire matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. A large condition number in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span> leads to a more ill-conditioned system for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. The convergence rate of Krylov methods like Lanczos is fundamentally governed by the distribution of the operator’s eigenvalues. An ill-conditioned matrix, with a wide spread of eigenvalues, will require more iterations, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>, to reach the desired accuracy. By simply adjusting the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">C_D</annotation></semantics></math></span></span> parameter, we can generate everything from well-conditioned problems that converge quickly to ill-conditioned ones that force us to run a large number of iterations. This is exactly what we need to rigorously test our implementation.</p>
<h2 id="memory-and-computation-trade-off">Memory and Computation Trade-off</h2>
<p>We measure the algorithm against two hypotheses on a large sparse problem with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>500</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=500,000</annotation></semantics></math></span></span>, varying the number of iterations <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>.</p>
<p><strong>Hypothesis 1 (Memory):</strong> The one-pass method stores the full basis <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> with complexity <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span>. We expect its memory to grow linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. The two-pass method operates with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span> memory, so it should have a flat profile.</p>
<p><strong>Hypothesis 2 (Runtime):</strong> The two-pass method performs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. If all else were equal, we’d expect it to run twice as slow.</p>
<h3 id="memory-usage">Memory Usage</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs500k_rho3_memory.png" alt="Memory vs Iterations"></p>
<p>The memory data confirms Hypothesis 1 exactly. The one-pass method’s footprint scales as a straight line—each additional iteration adds one vector to the basis. The two-pass method remains flat. No allocation growth happens after initialization.</p>
<h3 id="runtime-where-theory-breaks">Runtime: Where Theory Breaks</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs500k_rho3_time.png" alt="Runtime vs Iterations"></p>
<p>The runtime data contradicts Hypothesis 2. The two-pass method is slower, but never by a factor of two. For small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>, the gap is minimal. As <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> grows, the two-pass runtime diverges slowly from the one-pass method, not by doubling, but by a much smaller margin.</p>
<p>This difference comes from memory access patterns. Both methods perform matrix-vector products, but they differ in how they reconstruct the solution.</p>
<p>The one-pass method computes <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> in a single dense matrix-vector product. When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> are large, the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> basis matrix exceeds all cache levels. The CPU cannot keep the data resident; instead, it streams <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> from main memory. This is a memory-bandwidth-bound operation. The processor stalls, waiting for each load to complete. Instruction-level parallelism collapses.</p>
<p>The two-pass method reconstructs the solution incrementally. At each iteration, it operates on exactly three n-dimensional vectors: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mtext>prev</mtext></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{\text{prev}}</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mtext>curr</mtext></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{\text{curr}}</annotation></semantics></math></span></span>, and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>. This working set fits in L1 cache. The processor performs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products (each one reading the sparse operator, then applying it to a cached vector), but the solution accumulation happens entirely within cache. The additional matrix-vector products are cheaper than the memory latency of the standard method.</p>
<p>The cost of re-computing basis vectors is less than the latency cost of scanning an <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> dense matrix from main memory.</p>
<h3 id="medium-scale-behavior">Medium-Scale Behavior</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs50k_rho3_time.png" alt="Medium Scale Runtime vs Iterations">
<img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs50k_rho3_memory.png" alt="Medium Scale Memory Usage vs Iterations"></p>
<p>At <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>50</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=50,000</annotation></semantics></math></span></span> we can observe an equilibrium. The two methods have nearly identical runtime. The standard method’s <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> matrix is smaller; it fits partially in cache. The cache-miss penalty here becomes manageable. The two-pass method still has the advantage of cache-local accumulation, but the difference is marginal.</p>
<h3 id="what-about-dense-matrices">What About Dense Matrices?</h3>
<p>To be sure of our hypothesis, we can test it directly using a dense matrix of size <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>10</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=10,000</annotation></semantics></math></span></span>. For dense problems, the matrix-vector product is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span>, it dominates all other costs. Memory latency will become negligible relative to the compute work and the cache efficiency advantage should disappear.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/dense-tradeoff.png" alt="Dense Matrix Runtime vs Iterations"></p>
<p>We can see that the two-pass method runs almost exactly twice as slow as the one-pass method. The slope ratio is <em>exactly</em> 2:1. In a compute-bound regime, the extra matrix-vector products cannot be hidden by cache effects. Here, the theoretical trade-off holds perfectly.</p>
<h2 id="scalability">Scalability</h2>
<p>Now, let’s fix the iteration count at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>500</mn></mrow><annotation encoding="application/x-tex">k=500</annotation></semantics></math></span></span> and vary <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">50,000</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>500</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">500,000</annotation></semantics></math></span></span> to measure scalability. Based on what we have seen before, we would expect the two-pass memory to scale linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> but with a small constant factor (three vectors, plus scalars). The one-pass method should also scale linearly, but with a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-dependent slope.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/scalability_k500_rho3_memory.png" alt="Scalability Memory Usage"></p>
<p>Here we have to use a logarithmic y-axis to show both curves; the two-pass line is so flat relative to the one-pass line that it’s otherwise invisible.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/scalability_k500_rho3_time.png" alt="Scalability Runtime"></p>
<p>Runtime scales linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> for both methods, as expected. Below <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>150</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=150,000</annotation></semantics></math></span></span>, the two methods have similar performance. This is the regime where both basis and working set fit in cache, or where the problem is small enough that memory latency is not the bottleneck.</p>
<p>As <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> increases beyond <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>150</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">150,000</annotation></semantics></math></span></span>, the matrix-vector product time dominates. The sparse structure of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> ensures that each matvec requires multiple memory accesses per element. For the one-pass method, the final reconstruction of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> begins to cost more as the matrix grows. For the two-pass method, performing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products means the matvec cost accumulates more rapidly. The divergence is gradual, not sharp, because the advantage of cache locality in accumulation persists—but it cannot overcome the fundamental cost of doubling the number of expensive operations.</p>
<hr>
<p>Well, that’s it. If you want to have a better look at the code or use it, it’s all open source:</p>
<ul>
<li><a href="https://github.com/lukefleed/two-pass-lanczos">Github Repository</a></li>
<li><a href="https://github.com/lukefleed/two-pass-lanczos/raw/master/tex/report.pdf">LaTeX Report</a></li>
</ul>
<p>This was more of an exploration than a production-ready library, so expect rough edges. But I hope it gives an interesting perspective on how algorithm engineering and low-level implementation details can alter what seems like a straightforward trade-off on a blackboard.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iPod Socks (226 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/IPod_Socks</link>
            <guid>45889602</guid>
            <pubDate>Tue, 11 Nov 2025 16:52:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/IPod_Socks">https://en.wikipedia.org/wiki/IPod_Socks</a>, See on <a href="https://news.ycombinator.com/item?id=45889602">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/IPod_Socks: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox Expands Fingerprint Protections (260 pts)]]></title>
            <link>https://blog.mozilla.org/en/firefox/fingerprinting-protections/</link>
            <guid>45888891</guid>
            <pubDate>Tue, 11 Nov 2025 16:04:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/firefox/fingerprinting-protections/">https://blog.mozilla.org/en/firefox/fingerprinting-protections/</a>, See on <a href="https://news.ycombinator.com/item?id=45888891">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-82478">
  

  <div>
    




<p>With Firefox 145, we’re rolling out major privacy upgrades that take on browser fingerprinting — a pervasive and hidden tracking technique that lets websites identify you even when cookies are blocked or you’re in private browsing. These protections build on Mozilla’s long-term goal of building a healthier, transparent and privacy-preserving web ecosystem.</p>



<p>Fingerprinting builds a secret digital ID of you by collecting subtle details of your setup — ranging from your time zone to your operating system settings — that together create a “fingerprint” identifiable across websites and across browser sessions. Having a unique fingerprint means fingerprinters can continuously identify you invisibly, allowing bad actors to track you without your knowledge or consent. Online fingerprinting is able to track you for months, even when you use any browser’s private browsing mode.</p>



<p>Protecting people’s privacy has always been core to Firefox. <a href="https://blog.mozilla.org/security/2020/01/07/firefox-72-fingerprinting/">Since 2020</a>, Firefox’s built-in <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a> (ETP) has blocked known trackers and other invasive practices, while features like <a href="https://mzl.la/3db2drC">Total Cookie Protection</a> and now expanded fingerprinting defenses demonstrate a broader goal: prioritizing your online freedom through innovative privacy-by-design. Since 2021, Firefox has been incrementally enhancing anti-fingerprinting protections targeting the most common pieces of information collected for suspected fingerprinting uses.</p>



<p>Today, we are excited to announce the completion of the second phase of defenses against fingerprinters that linger across all your browsing but aren’t in the known tracker lists. With these fingerprinting protections, the amount of Firefox users trackable by fingerprinters is reduced by half.</p>



<h2>How we built stronger defenses</h2>



<p>Drawing from a global analysis of how real people’s browsers can be fingerprinted, Mozilla has developed new, unique and powerful defenses against real-world fingerprinting techniques. Firefox is the first browser with this level of insight into fingerprinting and the most effective deployed defenses to reduce it. Like <a href="https://blog.mozilla.org/en/mozilla/firefox-rolls-out-total-cookie-protection-by-default-to-all-users-worldwide/">Total Cookie Protection</a>, one of our most innovative privacy features, these new defenses are debuting in Private Browsing Mode and ETP Strict mode initially, while we work to enable them by default.</p>



<figure><img decoding="async" fetchpriority="high" width="1024" height="633" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png" alt="" title="Chart" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-300x186.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-768x475.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1000x618.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>How Firefox protects you</h2>



<p>These fingerprinting protections work on multiple layers, building on Firefox’s already robust privacy features. For example, Firefox has long blocked known tracking and fingerprinting scripts as part of its <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a>.&nbsp;</p>



<p>Beyond blocking trackers, Firefox also limits the information it makes available to websites — a privacy-by-design approach — that preemptively shrinks your fingerprint. Browsers provide a way for websites to ask for information that enables legitimate website features, e.g. your graphics hardware information, which allows sites to optimize games for your computer.&nbsp; But trackers can also ask for that information, for no other reason than to help build a fingerprint of your browser and track you across the web.&nbsp;&nbsp;</p>



<p>Since 2021, Firefox has been incrementally advancing fingerprinting protections, covering the most pervasive fingerprinting techniques. These include things like how your graphics card draws images, which fonts your computer has, and even tiny differences in how it performs math. The first phase plugged the biggest and most-common leaks of fingerprinting information.</p>



<p>Recent Firefox releases have tackled the next-largest leaks of user information used by online fingerprinters. This ranges from strengthening the font protections to preventing websites from getting to know your hardware details like the number of cores your processor has, the number of simultaneous fingers your touchscreen supports, and the dimensions of your dock or taskbar. The full list of detailed protections is <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">available in our documentation</a>.</p>



<p>Our research shows these improvements <strong>cut the percentage of users seen as unique by almost half</strong>.</p>



<figure><img decoding="async" width="1024" height="1024" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png" alt="" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-300x300.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-150x150.png 150w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-768x768.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-1000x1000.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-800x800.png 800w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Firefox’s new protections are a balance of disrupting fingerprinters while maintaining web usability. More aggressive fingerprinting blocking might sound better, but is guaranteed to break legitimate website features. For instance, calendar, scheduling, and conferencing tools legitimately need your real time zone. Firefox’s approach is to target the most leaky fingerprinting vectors (the tricks and scripts used by trackers) while preserving functionality many sites need to work normally. The end result is a set of layered defenses that significantly reduce tracking without downgrading your browsing experience. More details are available about both the <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">specific behaviors</a> and how to <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-can-i-tell-if-this-protection-broke-something">recognize a problem</a> on a site and <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-do-i-disable-this-protection-for-a-website">disable protections</a> for that site alone, so you always stay in control. The goal: strong privacy protections that don’t get in your way.</p>



<h2>What’s next for your privacy</h2>



<p>If you open a Private Browsing window or use ETP Strict mode, Firefox is already working behind the scenes to make you harder to track. The latest phase of Firefox’s fingerprinting protections marks an important milestone in our mission to deliver: smart privacy protections that work automatically — no further extensions or configurations needed.&nbsp;As we head into the future, Firefox remains committed to fighting for your privacy, so you get to enjoy the web on your terms. <a href="https://firefox.com/">Upgrade to the latest Firefox and take back control of your privacy</a>.</p>



<a href="https://www.mozilla.org/firefox/new/?utm_source=blog.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=blog-nav">
  <p><img width="800" height="800" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png 800w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-150x150.png 150w" sizes="(max-width: 800px) 100vw, 800px">  </p>
  <div>
     <h3>Take control of your internet</h3>      <p><span>Download Firefox</span>   </p></div>
</a>
  </div>

</article><!-- #post-82478 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canada loses its measles-free status, with US on track to follow (200 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cy7e2lv4r8xo</link>
            <guid>45888697</guid>
            <pubDate>Tue, 11 Nov 2025 15:50:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cy7e2lv4r8xo">https://www.bbc.com/news/articles/cy7e2lv4r8xo</a>, See on <a href="https://news.ycombinator.com/item?id=45888697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="byline-new" data-component="byline-block"><p><span data-testid="byline-new-contributors"><div data-testid="byline-new-contributors-contributor-0"><p><span>Nadine Yousif</span><span data-testid="byline-new-contributors-contributor-0-role-location">Senior Canada reporter</span></p></div></span></p></div><div data-component="text-block"><p>Canada has lost its measles elimination status, said the Pan American Health Organization (Paho) on Monday, after failing to curb an outbreak of the virus for 12 consecutive months.</p><p>Because Canada is no longer deemed measles-free, the Americas region as a whole has lost its elimination status, although individually the other countries are still considered to have stamped out the disease.</p><p>The US, however, risks losing its status as well if it does not stop an ongoing outbreak by January. Related cases have now been reported in Utah, Arizona and South Carolina.</p><p>Canada's outbreak began last October, with health officials attributing it to fewer people being vaccinated against measles.</p></div><div data-component="text-block"><p>At a news conference on Monday, Paho officials appealed to Canadian governments and the public to ramp up vaccinations, noting that 95% of the population needs to be immunised to stop the spread of measles.</p><p>"This loss represents a setback, but it is also reversible," said Dr Jarbas Barbosa, the health organisation's director.</p><ul><li><a target="_self" href="https://www.bbc.com/news/articles/c4g8d39gdr0o">How Canada became the centre of a measles outbreak in North America</a></li><li><a target="_self" href="https://www.bbc.com/news/articles/cwy747kdzdzo">More than 150 children quarantined as US measles cases hit 33-year high</a></li></ul><p>The Public Health Agency of Canada said in its own statement that it is collaborating with Paho and regional health authorities to improve vaccine rates and strengthen data sharing. </p><p>Prior to Monday, Canada had been declared measles-free for three decades. It can regain its elimination status if it can curb spread of the measles strain associated with the current outbreak for at least 12 months. </p><p>The country has reported more than 5,000 measles cases in 2025, with most of them in the provinces of Ontario and Alberta. That is three times the 1,681 cases reported in the US, despite Canada's much smaller population. </p><p>The bulk of the outbreak has been in "under-vaccinated communities", Canadian health officials have said. </p><p>Vaccination rates in Alberta, one of the provinces hit hard by the outbreak, are lower than the 95% threshold, according to provincial data. </p><p>One region, the South Zone, located south of the province's largest city Calgary, reported only 68% of children under the age of two were immunised against measles as of 2024.</p><p>The MMR vaccine is the most effective way to fight off the dangerous virus, which can lead to pneumonia, brain swelling and death. The jabs are 97% effective and also immunise against mumps and rubella.</p><p>Canadian immunologist Dawn Bowdish told the BBC that there are many reasons behind the low vaccination rates, including lack of access to general practitioners, the absence of a national vaccination registry that Canadians could use to check their immunisation status, and the spread of misinformation. </p><p>She also noted a lack of public health outreach to communities that have been hesitant or distrustful of vaccines.</p><p>"It highlights how many of our systems broke down to get us to this point," said Prof Bowdish of McMaster University in Hamilton, Ontario. </p><p>"I hope that it will be a wake-up call to policymakers, and that it will be enough of a national embarrassment that we remedy some of those systemic issues," she added</p><p>The Americas is the first and only region in the world to have been declared measles-free, starting in 2016. That status was then briefly lifted after outbreaks in Venezuela and Brazil. The two countries regained elimination status in 2024, in part through coordinated vaccine efforts where millions were immunised. </p><p>But measles has since spread again, now in North America. </p><p>Along with Canada and the United States, Mexico has also seen a surge in cases and now ranks among the top 10 countries with the largest outbreaks, according to the US Centers for Disease Control and Prevention.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pikaday: A friendly guide to front-end date pickers (118 pts)]]></title>
            <link>https://pikaday.dbushell.com</link>
            <guid>45887957</guid>
            <pubDate>Tue, 11 Nov 2025 14:58:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pikaday.dbushell.com">https://pikaday.dbushell.com</a>, See on <a href="https://news.ycombinator.com/item?id=45887957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <div>
        <h2>Who needs a JavaScript date picker?</h2>
        <p>
          The answer, in most cases, is nobody!
          Complex UI leads to more errors and abandoned forms.
          There can be easier ways to pick a date than a calendar widget.
          This guide provides alternate ideas and aims to send developers on a path towards <mark>user-friendly interfaces</mark>.
        </p>
      </div>

    <section id="native">
      <div>
        <h2>Native date and time inputs</h2>
        <p>
          If you absolutely must use a calendar widget then it’s wise to use the native input.
          All modern <a href="https://caniuse.com/input-datetime" target="_blank">browsers support</a> native date and time inputs.
        </p>
      </div>
      
      

      <div>
        <h2>Why use native inputs</h2>
        <p>Native inputs are super easy to implement with one line of code. The web browser handles many important details for developers:</p>
        <ul>
          <li>Accessibility <sup><a href="#accessibility-issues">(mostly*)</a></sup></li>
          <li>Performance</li>
          <li>Internationalisation</li>
        </ul>
        <p>
          Let browsers do the hard work!
          Browsers allow keyboard users to type numbers in sequence.
          Most browsers provide alternate UI for time and date selection like the classic calendar widget.
          They're not perfect but do you trust a JavaScript library to do better?
        </p>
      </div>

      

      
    </section>

    <section id="separate">
      <div>
        <h2>Separate inputs</h2>
        <p>
          A single date picker can be tricky to operate. For memorable dates using separate inputs can improve usability.
          The example below is based on <a href="https://design-system.service.gov.uk/components/date-input/" target="_blank">GOV.UK date input component</a>.
        </p>
        
      </div>
      <div>
        <h3>Select elements</h3>
        <p>
          If only a limited set of data is valid then using <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/select" target="_blank">select elements</a> may be suitable.
          They can require fewer interactions to use and they eliminate typing errors.
        </p>
      </div>
      <div>
        <div>
          <form>
            <fieldset>
              <legend>
                <h3>Select expiry date</h3>
              </legend>
              <p><label for="expiry-month">Month</label>
                
              </p>
              <p><label for="expiry-year">Year</label>
                
              </p>
            </fieldset>
          </form>
          <p>
            Numeric month labels can be helpful but take care in how they’re written.
            Screen readers may mistakenly announce “1 January” as “the 1st of January”, for example.
          </p>
        </div>
        <div>
          <form>
            <fieldset>
              <legend>
                <h3>Select departure time</h3>
              </legend>
              <p><label for="departure-date">I’m leaving</label>
                
              </p>
              <p><label for="departure-hour">Hour</label>
                
              </p>
              <p><label for="departure-minutes">Minutes</label>
                
              </p>
            </fieldset>
          </form>
          <p>Travel booking often has a fixed schedule with limited time options, such as every 15 minutes.
            Relative dates like “Today” and “Tomorrow” can be easier to understand.</p>
        </div>
      </div>
      
    </section>

    <section id="masked">

      <div>
        <h2>Masked inputs</h2>
        <p>
          Another common alternative to date pickers is a single input with a placeholder mask.
          This can be used for full or partial dates.
          JavaScript can enhancement the experience.
        </p>
      </div>

      

      <div>
        <p>
          The examples above provide client-side validation with errors such as <em>“Please enter a valid day for February (1 to 28)”</em>.
          Valid dates are confirmed in full and formatted with the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl/DateTimeFormat" target="_blank"><code>Intl</code> API</a>.
        </p>
        <p>
            <strong>Caution!</strong> Updating input values with JavaScript can break native undo/redo.
          </p>
      </div>

      <div>
        <p>
          It’s even possible to visually combined mutliple inputs using CSS to appear as one.
        </p>
        
      </div>

      
    </section>

    <div id="ranges">
        <h2>Ranges and limited options</h2>
        <p>
          JavaScript date pickers that support range selection across two calendars are difficult to use, especially without a pointer.
          Consider providing two inputs instead to <mark>reduce complexity</mark>.
          If users are required to select an available date then a group of <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/input/radio" target="_blank"><code>radio</code> inputs</a> can do the job.
        </p>
        <p><small><b>The example below illustrates the idea but is not fully interactive.</b></small></p>
        
        <p>
          There are many design variations of this pattern.
          This idea is to replace complicated UI with a series of simple tasks.
          Such a pattern can be implemented as a multi-page form with
          JavaScript used to enhance it into a single page interactive experience.
        </p>
      </div>

    <section id="faq">
      <div>
        <h2>Frequently asked questions</h2>
        <details id="faq-frameworks">
          <summary><h3>What if I use a JavaScript framework like React?</h3></summary>
          <p>
              All good JavaScript frameworks allow you to use native HTML elements.
              Not everything needs to be a custom component.
              Native <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLInputElement#events" target="_blank">input events</a> can integrate with framework callbacks.
              Use attributes like <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLInputElement/value"><code>value</code></a> for two-way state binding.
            </p>
        </details>
        <details id="faq-styles">
          <summary><h3>How do I style the native date picker?</h3></summary>
          <p>
              The on-page <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/input/date" target="_blank"><code>input</code> element</a>
              can be partially styled but other parts are not stylable.
              That is a good thing! Native system UI is familiar to the user.
              The design will differ based on operating system and input method.
              Date pickers even look different across browsers and that's fine too, you don't need to add yet another design to the mix!
            </p>
        </details>
        <details id="faq-stakeholders">
          <summary><h3>A stakeholder is demanding a JavaScript date picker, how do I dissuade them?</h3></summary>
          <p>
              Remember: the end goal is a successful form submission. Complex and fragile UI leads to more errors.
              All date pickers have accessibility issues. Combining basic inputs can be more user-friendly.
              Untested JavaScript UI may fall foul of regulation like the <a href="https://en.wikipedia.org/wiki/European_Accessibility_Act" target="_blank">European Accessibility Act</a>.
              Keep it simple for success!
            </p>
        </details>
        <details id="faq-accessibility">
          <summary><h3>How do I test and guarantee accessibility?</h3></summary>
          <div>
            <p>
              It’s critical to understand the relevant <a href="https://www.w3.org/TR/WCAG22/" target="_blank">accessibility guidelines</a>.
              You don’t need to memorise WCAG but there are no shortcuts to learning the important parts.
              Leverage existing web standards to avoid mistakes trying to code custom UI.
            </p>
            <p>
              Browser dev tools have built-in <a href="https://developer.chrome.com/docs/devtools/accessibility/reference" target="_blank">accessibility features</a> to help identify mistakes.
              However, no tool is perfect. The only way to know for sure is to conduct user testing.
            </p>
            <p>
              <a href="https://overlayfactsheet.com/" target="_blank">Accessibility overlays</a> are <strong>strongly discouraged</strong> and can make matters worse.
            </p>
          </div>
        </details>
        <details id="faq-resources">
          <summary><h3>Where can I learn more about date picker accessibility?</h3></summary>
          <div>
            <ul>
              <li><a href="https://www.hassellinclusion.com/blog/collecting-dates-accessible/" target="_blank">Collecting dates in an accessible way</a> by <strong>Graham Armfield</strong></li>
              <li><a href="https://www.youtube.com/watch?v=D2Gy2WN4Iys&amp;list=PLn7dsvRdQEfFfYUgq0wVLXlVN7yQUUWd-" target="_blank">What makes an accessible date picker? Is it even possible?</a> by <strong>Russ Weakley</strong></li>
              <li><a href="https://adrianroselli.com/2019/07/maybe-you-dont-need-a-date-picker.html" target="_blank">Maybe You Don’t Need a Date Picker</a> by <strong>Adrian Roselli</strong></li>
              <li><a href="https://www.w3.org/WAI/ARIA/apg/patterns/dialog-modal/examples/datepicker-dialog/" target="_blank">Date Picker Dialog Example</a> by <strong>ARIA Authoring Practices Guide</strong></li>
              <li><a href="https://www.smashingmagazine.com/2017/07/designing-perfect-date-time-picker/" target="_blank">Designing The Perfect Date And Time Picker</a> by <strong>Vitaly Friedman</strong></li>
            </ul>
          </div>
        </details>
        <details id="faq-recommend">
          <summary><h3>This is all great but can you please recommend a JavaScript date picker?</h3></summary>
          <p>
              Sorry, no! There is no universal solution and <mark>all date pickers have issues</mark>.
              I hope this guide has given you the knowledge to evaluate your own requirements.
              Try to achieve your goal in the simplest way.
              A date picker is probably not the answer.
            </p>
        </details>
      </div>
      <div>
        <p><strong>Before you go!</strong> Remember to test and gather feedback from real users :)</p>
        <p>This guide is a work in progress, <a href="https://dbushell.com/contact/" target="_blank">feedback is welcome!</a></p>
      </div>
    </section>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling HNSWs (141 pts)]]></title>
            <link>https://antirez.com/news/156</link>
            <guid>45887466</guid>
            <pubDate>Tue, 11 Nov 2025 14:11:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/156">https://antirez.com/news/156</a>, See on <a href="https://news.ycombinator.com/item?id=45887466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-comment-id="156-" id="156-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 8 hours ago. 23212 views.  </span><pre>I’m taking a few weeks of pause on my HNSWs developments (now working on some other data structure, news soon). At this point, the new type I added to Redis is stable and complete enough, it’s the perfect moment to reason about what I learned about HNSWs, and turn it into a blog post. That kind of brain dump that was so common pre-AI era, and now has become, maybe, a bit more rare. Well, after almost one year of thinking and implementing HNSWs and vector similarity stuff, it is time for some writing. However this is not going to be an intro on HNSWs: too many are present already. This is the “extra mile” instead. If you know HNSWs, I want to share with you my more “advanced” findings, especially in the context of making them fast enough to allow for a “Redis” experience: you know, Redis is designed for low latency and high performance, and HNSWs are kinda resistant to that, so there were challenges to expose HNSWs as an abstract data structure.

This blog post will be split into several sections. Think of them as pages of the same book, different chapters of the same experience. Oh and, by the way, I already wrote and subsequently lost this blog post :D [long, sad story about MacOS and bad habits – I hadn’t lost something like that since the 90s, during blackouts], so here most of the problem will be to recall what I wrote a few days ago and, while I’m at it, to better rephrase what I didn’t like very much.

## A few words about the state of HNSW

Before digging into the HNSWs internals and optimizations, I want to say a few things about HNSWs. The original paper introducing HNSWs is a great piece of computer science literature, and HNSWs are amazing data structures, but: I don’t believe they are the last word for searching, in a greedy way, for nearby vectors according to a distance function. The paper gives the feeling it lacks some “pieces”, almost like if the researchers, given six months more, had a lot more to explore and say. For instance, I modified the paper myself, extending it in order to support removal of entries, actual removals, not just tombstone deletions where the element is marked as gone and collected later: deleting items is totally missing from the paper. Similarly, there are, right now, efforts in order to really check if the “H” in the HNSWs is really needed, and if instead a flat data structure with just one layer would perform more or less the same (I hope I’ll cover more about this in the future: my feeling is that the truth is in the middle, and that it makes sense to modify the level selection function to just have levels greater than a given threshold).

All this to say that, if you are into data structures research, I believe that a great area is to imagine evolutions and refinements of HNSWs, without getting trapped within the idea that the evolutions are only in the sense of: let’s do it, but for disk (see Microsoft efforts), or the like. Ok, enough with the premise, let’s go to the actual low level stuff :)

## Scaling memory

Redis is an in-memory system, and both HNSWs and vectors have the unfortunate quality of being very space-hungry. There are three reasons for this: 1. HNSWs have a lot of pointers, like 16, 32 or more pointers (this is a tunable parameter of HNSWs) to neighbor nodes. 2. HNSWs have many levels, being a skiplist-alike data structure. This exacerbates the first problem. 3. HNSW’s satellite data is a vector of floating point numbers, so, in the vanilla case, 4 bytes per component, and normally you can have 300-3000 components, this is the usual range.

So, what are the lessons learned here? There are folks that compress pointers, since it is very likely that many pointers (8 bytes in 64 bit systems) will have the highest four bytes all the same. This is smart, I didn’t implement it yet, because in Redis I need to go fast, and this is a tradeoff between space and time: but maybe it is worth it, maybe not. I’ll dig more. 

However, if you do the math, the fact that there are many layers is not *so* terrible as it looks. On average, the multiple layers per node make the situation worse by just ~1.3x (if the probability of level increase is 0.25 in the level selection function), since many nodes will be just at layer 0. But still 1.3 is more than 1, and if that “H” in HNSWs really is not *so* useful… [Spoiler, what I found is that the seek time if you have everything at layer 0 is greater, the main loop for the greedy search will start from less optimal places and it will eventually reach the right cluster, but will take more computation time. However this is just early results.]

So here the *real* low hanging fruit is: vector quantization. What I found is that if you use 8 bit quantization what you get is an almost 4x speedup, a 4x reduction of your vectors (but not a 4x reduction of the whole node: the pointers are still there, and they take a lot of space), and a recall that is virtually the same in real world use cases. This is the reason why Redis Vector Sets use 8 bit quantization by default. You can specify, via VADD options, that you want full precision vectors or binary quantized vectors, where we just take the sign, but I’m skeptical about using both full size vectors and binary quantized vectors. Before talking about them, let’s see what kind of quantization I used for 8 bit.

What I do is to compute the maximum absolute value of the component of each vector (so quantization is per-vector), then I use signed 8 bit values to represent the quant from -127 to 127. This is not as good as storing both min and max value, but it is faster when computing cosine similarity, since I can do this:

    /* Each vector is quantized from [-max_abs, +max_abs] to [-127, 127]
     * where range = 2*max_abs. */
    const float scale_product = (range_a/127) * (range_b/127);

Then I multiply things together in the integer domain with (actually in the code the main loop is unrolled and uses multiple accumulators, to make modern CPUs more busy)

    for (; i &lt; dim; i++) dot0 += ((int32_t)x[i]) * ((int32_t)y[i]);

And finally we can return back to the floating point distance with:

    float dotf = dot0 * scale_product;

Check the vectors_distance_q8() for more information, but I believe you got the idea: it is very simple to go from the integer quants domain to the unquantized dotproduct with trivial operations.

So, 8 bit quantization is a great deal, and full precision was a *needed* feature, because there will be people doing things with vectors generated in a way where each small amount makes a difference (no, with learned vectors this is not the case…) but, why binary quantization? Because I wanted users to have a simple way to not waste space when their *original* information is already binary. Imagine you have a set of users and they have yes/no properties, and you want to find similar users, items, whatever. Well: this is where binary quantization should be used, it’s just, again, an option of the VADD command.

## Scaling speed: threading and locality

Oh, you know, I have to tell you something about myself: I’m not a fan of threaded systems when it is possible to do a lot with a single core, and then use multiple cores in a shared-nothing architecture. But HNSWs are different. They are *slow*, and they are accessed almost always in read-only ways, at least in most use cases. For this reason, my Vector Sets implementation is fully threaded. Not just reads, even writes are partially threaded, and you may wonder how this is possible without it resulting in a mess, especially in a system like Redis, where keys can be accessed in different ways by the background saving process, the clients, and so forth.


Well, to start, let’s focus on reads. What happens is that as long as nobody is writing in the data structure, we can spawn threads that do the greedy collection of near vectors and return back the results to the blocked client. However, my implementation of HNSWs was written from scratch, I mean, from the empty C file opened with vim, it has 0% of shared code with the two implementations most other systems use, so there are a few “novelties”. One of such different things is that in order to avoid re-visiting already visited nodes, I use an integer stored in each node that is called “epoch”, instead of using another data structure to mark (like, in a hash table) nodes already visited. This is quite slow, I believe. The epoch instead is local to the node, and the global data structure increments the epoch for each search. So in the context of each search, we are sure that we can find epochs that are just &lt;= the current epoch, and the current epoch can be used to mark visited nodes.

But with threads, there are multiple searches occurring at the same time! And, yep, what I needed was an array of epochs:

typedef struct hnswNode {
    uint32_t level;         /* Node's maximum level */
    … many other stuff …
    uint64_t visited_epoch[HNSW_MAX_THREADS];
}

That’s what you can read in hnsw.h. This is, again, a space-time tradeoff, and again time won against space.

So, how was it possible to have threaded writes? The trick is that in HNSW inserts, a lot of time is spent looking for neighbors candidates. So writes are split into a reading-half and commit-half, only the second needs a write lock, and there are a few tricks to make sure that the candidates we accumulated during the first part are discarded if the HNSW changed in the meantime, and some nodes may no longer be valid. There is, however, another problem. What about the user deleting the key, while background threads are working on the value? For this scenario, we have a function that waits for background operations to return before actually reclaiming the object. With these tricks, it is easy to get 50k ops/sec on real world vector workloads, and these are numbers I got from redis-benchmark itself, with all the overhead involved. The raw numbers of the flat HNSW library itself are much higher.

## Scaling memory: reclaiming it properly

Before talking about how to scale HNSWs into big use cases with multiple instances involved, and why Redis Vector Sets expose the actual data structure in the face of the user (I believe programmers are smart and don’t need babysitting, but it’s not *just* that), I want to go back and talk again about memory, because there is an interesting story to tell about this specific aspect.

Most HNSWs implementations are not able to reclaim memory directly when you delete a node from the graph. I believe there are two main reasons for that:

1. People misunderstand the original HNSW paper in a specific way: they believe links can be NOT reciprocal among neighbors. And there is a specific reason why they think so.

2. The paper does not say anything about deletion of nodes and how to fix the graph after nodes go away and we get missing links in the “web” of connections.

The first problem is a combination (I believe) of lack of clarity in the paper and the fact that, while implementing HNSWs, people face a specific problem: when inserting a new node, and good neighbors are searched among existing nodes, often the candidates already have the maximum number of outgoing links. What to do, in this case? The issue is often resolved by linking unidirectionally from the new node we are inserting to the candidates that are already “full” of outgoing links. However, when you need to delete a node, you can no longer resolve all its incoming links, so you can’t really reclaim memory. You mark it as deleted with a flag, and later sometimes there is some rebuilding of the graph to “garbage collect” stale nodes, sometimes memory is just leaked.

So, to start, my implementation in Redis does things differently by forcing links to be bidirectional. If A links to B, B links to A. But, how to do so, given that A may be busy? Well, this gets into complicated territory but what happens is that heuristics are used in order to drop links from existing nodes, with other neighbors that are well connected, and if our node is a better candidate even for the target node, and if this is not true there are other ways to force a new node to have at least a minimal number of links, always trying to satisfy the small world property of the graph.

This way, when Redis deletes a node from a Vector Set, it always has a way to remove all the pointers to it. However, what to do with the remaining nodes that now are missing a link? What I do is to create a distance matrix among them, in order to try to link the old node neighbors among them, trying to minimize the average distance. Basically for each pair of i,j nodes in our matrix, we calculate how good is their connection (how similar their vectors are) and how badly linking them affects the *remaining* possible pairs (since there could be elements left without good pairs, if we link two specific nodes). After we build this matrix of scores, we then proceed with a greedy pairing step.

This works so well that you can build a large HNSW with millions of elements, later delete 95% of all your elements, and the remaining graph still has good recall and no isolated nodes and so forth.

That is what I mean when I say that there is space in HNSWs for new papers to continue the work.

## Scaling HNSWs to multiple processes

When I started to work at Redis Vector Sets, there was already a vector similarity implementation in Redis-land, specifically as an index type of RediSearch, and this is how most people think at HNSWs: a form of indexing of existing data.

Yet I wanted to provide Redis with a new HNSW implementation exposed in a completely different way. Guess how? As a data structure, of course. And this tells a story about how Redis-shaped is my head after so many years, or maybe it was Redis-shaped since the start, and it is Redis that is shaped after my head, since I immediately envisioned how to design a Redis data structure that exposed HNSWs to the users, directly, and I was puzzled that the work with vectors in Redis was not performed exactly like that.

At the same time, when I handed my design document to my colleagues at Redis, I can’t say that they immediately “saw” it as an obvious thing. My reasoning was: vectors are like scores in Redis Sorted Sets, except they are not scalar scores where you have a total order. Yet you can VADD, VREM, elements, and then you can call VSIM instead of ZRANGE in order to have *similar* elements. This made sense not just as an API, but I thought of HNSWs as strongly composable, and not linked to a specific use case (not specific to text embeddings, or image embeddings, or even *learned* embeddings necessarily). You do:

    VADD my_vector_set VALUES [… components …] my_element_string

So whatever is in your components, Redis doesn't care, when you call VSIM it will report similar elements.

But this also means that, if you have different vectors about the same use case split in different instances / keys, you can ask VSIM for the same query vector into all the instances, and add the WITHSCORES option (that returns the cosine distance) and merge the results client-side, and you have magically scaled your hundred of millions of vectors into multiple instances, splitting your dataset N times [One interesting thing about such a use case is that you can query the N instances in parallel using multiplexing, if your client library is smart enough].

Another very notable thing about HNSWs exposed in this raw way, is that you can finally scale writes very easily. Just hash your element modulo N, and target the resulting Redis key/instance. Multiple instances can absorb the (slow, but still fast for HNSW standards) writes at the same time, parallelizing an otherwise very slow process.

This way of exposing HNSWs also scales down in a very significant way: sometimes you want an HNSW for each user / item / product / whatever you are working with. This is very hard to model if you have an index on top of something, but it is trivial if your HNSWs are data structures. You just can have a Vector Set key for each of your items, with just a handful of elements. And of course, like with any other Redis key, you can set an expiration time on the key, so that it will be removed automatically later.

All this can be condensed into a rule that I believe should be more present in our industry: many programmers are smart, and if instead of creating a magic system they have no access to, you show them the data structure, the tradeoffs, they can build more things, and model their use cases in specific ways. And your system will be simpler, too.

## Scaling loading times

If I don’t use threading, my HNSW library can add word2vec (300 components for each vector) into an HNSW at 5000 elements/second if I use a single thread, and can query the resulting HNSW at 90k queries per second. As you can see there is a large gap.

This means that loading back an HNSW with many millions of elements from a Redis dump file into memory would take a lot of time. And this time would impact replication as well. Not great. But, this is true only if we add elements from the disk to the memory in the most trivial way, that is storing “element,vector” on disk and then trying to rebuild the HNSW in memory. There is another lesson to learn here. When you use HNSWs, you need to serialize the nodes and the neighbors as they are, so you can rebuild everything in memory just allocating stuff and turning neighbors IDs into pointers. This resulted in a 100x speedup.

But do you really believe the story ends here? Hehe. Recently Redis has stronger security features and avoids doing bad things even when the RDB file is corrupted by an attacker. So what I needed to do was to make sure the HNSW is valid after loading, regardless of the errors and corruption in the serialized data structure. This involved many tricks, but I want to take the freedom to just dump one comment I wrote here, as I believe the reciprocal check is particularly cool:

    /* Second pass: fix pointers of all the neighbors links.
     * As we scan and fix the links, we also compute the accumulator
     * register "reciprocal", that is used in order to guarantee that all
     * the links are reciprocal.
     *
     * This is how it works, we hash (using a strong hash function) the
     * following key for each link that we see from A to B (or vice versa):
     *
     *      hash(salt || A || B || link-level)
     *
     * We always sort A and B, so the same link from A to B and from B to A
     * will hash the same. Then we xor the result into the 128 bit accumulator.
     * If each link has its own backlink, the accumulator is guaranteed to
     * be zero at the end.
     *
     * Collisions are extremely unlikely to happen, and an external attacker
     * can't easily control the hash function output, since the salt is
     * unknown, and also there would be to control the pointers.
     *
     * This algorithm is O(1) for each node so it is basically free for
     * us, as we scan the list of nodes, and runs on constant and very
     * small memory. */


## Scaling use cases: JSON filters

I remember the day when the first working implementation of Vector Sets felt complete. Everything worked as expected and it was the starting point to start with the refinements and the extra features.

However in the past weeks and months I internally received the feedback that most use cases need some form of mixed search: you want near vectors to a given query vector (like most similar movies to something) but also with some kind of filtering (only released between 2000 and 2010). My feeling is that you need to query for different parameters less often than product people believe, and that most of the time you can obtain this more efficiently by adding, in this specific case, each year to a different vector set key (this is another instance of the composability of HNSWs expressed as data structures versus a kind of index).

However I was thinking about the main loop of the HNSW greedy search, that is something like this:

// Simplified HNSW greedy search algorithm. Don’t trust it too much.
while(candidates.len() &gt; 0) {
    c = candidates.pop_nearest(query);
    worst_distance = results.get_worst_dist(query);
    if (distance(query,c) &gt; worst_distance) break;
    foreach (neighbor from c) {
        if (neighbor.already_visited()) continue;
        neighbor.mark_as_visited();
        if (results.has_space() OR neighbor.distance(query) &lt; worst_distance) {
            candidates.add(neighbor);
            results.add(neighbor);
        }
    }
}
return results;

So I started to play with the idea of adding a JSON set of metadata for each node. What if, once I have things like {“year”: 1999}, this was enough to filter while I perform the greedy search? Sure, the search needed to be bound, but there is a key insight here: I want, to start, elements that are *near* to the query vector, so I don’t really need to explore the whole graph if the condition on the JSON attributes is not satisfied by many nodes. I’ll let the user specify the effort, and anyway very far away results that match the filter are useless.

So that’s yet another way how my HNSW differs: it supports filtering by expressions similar to the ones you could write inside an “if” statement of a programming language. And your elements in the Vector Set can be associated with JSON blobs, expressing their properties. Then you can do things like:


    VSIM movies VALUES … your vector components here… FILTER '.year &gt;= 1980 and .year &lt; 1990'

## A few words on memory usage

HNSW’s fatal issue is — in theory — that they are normally served from memory. Actually, you can implement HNSWs on disk, even if there are better data structures from the point of view of disk access latencies. However, in the specific case of Redis and Vector Sets the idea is to provide something that is very fast, easy to work with: the flexibility of in-memory data structures help with that. So the question boils down to: is the memory usage really so bad?

Loading the 3 million Word2Vec entries into Redis with the default int8 quantization takes 3GB of RAM, 1kb for each entry. Many use cases have just a few tens of million of entries, or a lot less. And what you get back from HNSWs, if well implemented, and in memory, is very good performance, which is crucial in a data structure and in a workload that is in itself slow by definition. In my MacBook I get 48k ops per second with redis-benchmark and VSIM against this key (holding the word2vec dataset). My feeling is that the memory usage of in-memory HNSWs is very acceptable for many use cases. And even in the use cases where you want the bulk of your vectors on disk, even if there is to pay for slower performance, your hot set should likely be served from RAM.

This is one of the reasons why I believe that, to be active in HNSW research is a good idea: I don’t think they will be replaced anytime soon for most use cases. It seems more likely that we will continue to have different data structures that are ideal for RAM and for disk depending on the use cases and data size. Moreover, what I saw recently, even just scanning the Hacker News front page, is people with a few millions of items fighting with systems that are slower or more complicated than needed. HNSWs and carefully exposing them in the right way can avoid all that.

## Conclusions

I like HNSWs, and working and implementing them was a real pleasure. I believe vectors are a great fit for Redis, even in an AI-less world (for instance, a few months ago I used them in order to fingerprint Hacker News users, replicating an old work published on HN in the past). HNSWs are simply too cool and powerful for a number of use cases, and with AI, and learned embeddings, all this escalates to a myriad of potential use cases. However, like most features in Redis, I expect that a lot of time will pass before people realize they are useful and powerful and how to use them (no, it’s not just a matter of RAG). This happened also with Streams: finally there is mass adoption, after so many years.

If instead you are more interested in HNSW and the implementation I wrote, I believe the code is quite accessible, and heavily commented:

<a rel="nofollow" href="https://github.com/redis/redis/blob/unstable/modules/vector-sets/hnsw.c">https://github.com/redis/redis/blob/unstable/modules/vector-sets/hnsw.c</a>

If you want to learn more about Redis Vector Sets, please feel free to read the README file I wrote myself. There is also the official Redis documentation, but I suggest you start from here:

<a rel="nofollow" href="https://github.com/redis/redis/tree/unstable/modules/vector-sets">https://github.com/redis/redis/tree/unstable/modules/vector-sets</a>

Thanks for reading such a long blog post! And have a nice day.</pre></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Widespread distribution of bacteria containing PETases across global oceans (101 pts)]]></title>
            <link>https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false</link>
            <guid>45886479</guid>
            <pubDate>Tue, 11 Nov 2025 12:22:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false">https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false</a>, See on <a href="https://news.ycombinator.com/item?id=45886479">Hacker News</a></p>
Couldn't get https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI may not use lyrics without license, German court rules (201 pts)]]></title>
            <link>https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</link>
            <guid>45886131</guid>
            <pubDate>Tue, 11 Nov 2025 11:20:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/">https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</a>, See on <a href="https://news.ycombinator.com/item?id=45886131">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[iPhone Pocket (415 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</link>
            <guid>45885813</guid>
            <pubDate>Tue, 11 Nov 2025 10:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/">https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</a>, See on <a href="https://news.ycombinator.com/item?id=45885813">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        

        <div>
                
                
                
                    <h2>
                        
    
        Introducing iPhone Pocket: a&nbsp;beautiful way to wear and carry iPhone
    

                    </h2>
                
            </div>

        <div>
                
                
                    Born out of a collaboration between ISSEY&nbsp;MIYAKE and Apple, iPhone&nbsp;Pocket features a singular 3D-knitted construction designed to fit any iPhone
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, Two users pose with iPhone Pocket in lemon and black.">
        <div>
             
              
              <div>
                iPhone Pocket, born out of a collaboration between ISSEY MIYAKE and Apple, will be available at select Apple Store locations beginning Friday, November 14.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero_big" aria-label="Download media, Two users pose with iPhone Pocket in lemon and black."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <div>ISSEY MIYAKE and Apple today unveiled <a href="https://www.apple.com/shop/product/HS8R2ZM/A" target="_blank">iPhone Pocket</a>. Inspired by the concept of “a piece of cloth,” its singular 3D-knitted construction is designed to fit any iPhone as well as all pocketable items. Beginning Friday, November 14, it will be available at select Apple Store locations and on <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S.
</div>
                 
             
                 <div>iPhone Pocket features a ribbed open structure with the qualities of the original pleats by ISSEY MIYAKE. Born from the idea of creating an additional pocket, its understated design fully encloses iPhone, expanding to fit more of a user’s everyday items. When stretched, the open textile subtly reveals its contents and allows users to peek at their iPhone display. iPhone Pocket can be worn in a variety of ways — handheld, tied onto bags, or worn directly on the body. Featuring a playful color palette, the short strap design is available in eight colors, and the long strap design in three colors.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-options">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" href="#gallery-500f573744cb93b53ae8377ed0858f3f" data-ac-gallery-trigger="gallery-500f573744cb93b53ae8377ed0858f3f"><span>All eight colors of iPhone Pocket short strap design.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" href="#gallery-c4b99bd83aa685e677f8cc92bd31c905" data-ac-gallery-trigger="gallery-c4b99bd83aa685e677f8cc92bd31c905"><span>All three colors of iPhone Pocket long strap design.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-500f573744cb93b53ae8377ed0858f3f" aria-labelledby="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:short-strap-design">
                                
                                <div>
                                    <div>Featuring a playful color palette, the short strap design is available in eight colors: lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors_big" aria-label="Download media, All eight colors of iPhone Pocket short strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-c4b99bd83aa685e677f8cc92bd31c905" aria-labelledby="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:long-strap-design">
                                
                                <div>
                                    <div>The long strap design is available in three colors: sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors_big" aria-label="Download media, All three colors of iPhone Pocket long strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <div>“The design of iPhone Pocket speaks to the bond between iPhone and its user, while keeping in mind that an Apple product is designed to be universal in aesthetic and versatile in use,” shared Yoshiyuki Miyamae, design director of MIYAKE DESIGN STUDIO. “iPhone Pocket explores the concept of ‘the joy of wearing iPhone in your own way.’ The simplicity of its design echoes what we practice at ISSEY MIYAKE — the idea of leaving things less defined to allow for possibilities and personal interpretation.”
</div>
                 
             
                 <div>“Apple and ISSEY MIYAKE share a design approach that celebrates craftsmanship, simplicity, and delight,” said Molly Anderson, Apple’s vice president of Industrial Design. “This clever extra pocket exemplifies those ideas and is a natural accompaniment to our products. The color palette of iPhone Pocket was intentionally designed to mix and match with all our iPhone models and colors — allowing users to create their own personalized combination. Its recognizable silhouette offers a beautiful new way to carry your iPhone, AirPods, and favorite everyday items.”
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-combos">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" href="#gallery-0413a35321ffe4dbd41592bfeb2b2797" data-ac-gallery-trigger="gallery-0413a35321ffe4dbd41592bfeb2b2797"><span>iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" href="#gallery-395d51cadfd7a3c84bd5bd1de138f580" data-ac-gallery-trigger="gallery-395d51cadfd7a3c84bd5bd1de138f580"><span>iPhone Pocket in sapphire paired with iPhone Air in sky blue.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" href="#gallery-d57c53d12e0866bde9b77fabca8692fb" data-ac-gallery-trigger="gallery-d57c53d12e0866bde9b77fabca8692fb"><span>iPhone Pocket in purple paired with iPhone 17 in lavender.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-0413a35321ffe4dbd41592bfeb2b2797" aria-labelledby="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon-and-cosmic-orange-iphone-17-pro">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro_big" aria-label="Download media, iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-395d51cadfd7a3c84bd5bd1de138f580" aria-labelledby="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:sapphire-and-sky-blue-iphone-air">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air_big" aria-label="Download media, iPhone Pocket in sapphire paired with iPhone Air in sky blue."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-d57c53d12e0866bde9b77fabca8692fb" aria-labelledby="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple-and-lavender-iphone-17">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01_big" aria-label="Download media, iPhone Pocket in purple paired with iPhone 17 in lavender."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Piece of Cloth</strong>
</h2>
                 
             
                 <div>Crafted in Japan, iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE. The design drew inspiration from the concept of “a piece of cloth” and reinterpreted the everyday utility of the brand’s iconic pleated clothing. The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="singular-construction">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" href="#gallery-8c54c3d4fde598029a7c6b36d27e85a3" data-ac-gallery-trigger="gallery-8c54c3d4fde598029a7c6b36d27e85a3"><span>A user poses with iPhone Pocket in peacock.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" href="#gallery-8ec946387230a363dbe25e38306bce4d" data-ac-gallery-trigger="gallery-8ec946387230a363dbe25e38306bce4d"><span>A user poses with iPhone Pocket in cinnamon.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" href="#gallery-1b5cfe3976c01fb7746de0602809af8b" data-ac-gallery-trigger="gallery-1b5cfe3976c01fb7746de0602809af8b"><span>iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" href="#gallery-2fe4cea23e1e990c69431e909557f742" data-ac-gallery-trigger="gallery-2fe4cea23e1e990c69431e909557f742"><span>iPhone Pocket in black.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" href="#gallery-8f771a17f3ddef3f19c8c979d8ed6291" data-ac-gallery-trigger="gallery-8f771a17f3ddef3f19c8c979d8ed6291"><span>iPhone Pocket in lemon and mandarin.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" href="#gallery-56d430360d60f74d93b475a57eb36ebd" data-ac-gallery-trigger="gallery-56d430360d60f74d93b475a57eb36ebd"><span>iPhone Pocket in purple.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-8c54c3d4fde598029a7c6b36d27e85a3" aria-labelledby="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:peacock">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock_inline" aria-label="Download media, A user poses with iPhone Pocket in peacock."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8ec946387230a363dbe25e38306bce4d" aria-labelledby="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon_inline" aria-label="Download media, A user poses with iPhone Pocket in cinnamon."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-1b5cfe3976c01fb7746de0602809af8b" aria-labelledby="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:pink-and-black-issey-miyake-bag">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag_inline" aria-label="Download media, iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-2fe4cea23e1e990c69431e909557f742" aria-labelledby="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:black">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro_inline" aria-label="Download media, iPhone Pocket in black."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8f771a17f3ddef3f19c8c979d8ed6291" aria-labelledby="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:lemon-and-mandarin">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air_inline" aria-label="Download media, iPhone Pocket in lemon and mandarin."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-56d430360d60f74d93b475a57eb36ebd" aria-labelledby="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02_inline" aria-label="Download media, iPhone Pocket in purple."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Availability</strong>
</h2>
                 
             
                 <div>iPhone Pocket is a limited-edition release. The short strap design is available in lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black; the long strap design is available in sapphire, cinnamon, and black. iPhone Pocket in the short strap design retails at $149.95 (U.S.), and the long strap design at $229.95 (U.S.).
</div>
                 
             
                 <div>Customers can purchase iPhone Pocket beginning Friday, November 14, at select Apple Store locations and <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S. Just in time for the holidays, Apple Specialists in stores and online can help customers mix and match different lengths and colors with their iPhone, style iPhone Pocket, and purchase their new favorite accessory.
</div>
                 
             
                 <div><ul>
<li>Apple Canton Road, Hong Kong</li>
<li>Apple Ginza, Tokyo</li>
<li>Apple Jing’an, Shanghai</li>
<li>Apple Marché Saint-Germain, Paris</li>
<li>Apple Myeongdong, Seoul</li>
<li>Apple Orchard Road, Singapore</li>
<li>Apple Piazza Liberty, Milan</li>
<li>Apple Regent Street, London</li>
<li>Apple SoHo, New York City</li>
<li>Apple Xinyi A13, Taipei</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why effort scales superlinearly with the perceived quality of creative work (127 pts)]]></title>
            <link>https://markusstrasser.org/creative-work-landscapes.html</link>
            <guid>45885242</guid>
            <pubDate>Tue, 11 Nov 2025 08:29:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://markusstrasser.org/creative-work-landscapes.html">https://markusstrasser.org/creative-work-landscapes.html</a>, See on <a href="https://news.ycombinator.com/item?id=45885242">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <p><!--[--><time datetime="2025-11-02T00:00:00.000Z">November 2, 2025</time><!--]--> <!--[--><span>· 1 min read</span><!--]--> <!--[--><span>·</span><!--]--> Send your thoughts via <a target="_blank" href="https://twitter.com/mkstra"><!---->twitter</a> or <a target="_blank" href="mailto:strasser.ms@gmail.com"><!---->mail</a>. <!--[!--><!--]--></p> <p><span>Abstract claim:</span> <em>The act of creation is fractal exploration–exploitation under optimal feedback control.
		When resolution increases the portion of parameter space that doesn't make the artifact
		worse (<em>acceptance volume</em>) collapses. Verification latency and rate–distortion
		combine into a precision tax that scales superlinearly with perceived quality.</em></p> <p>When I make something good, I often spend most of my time making thousands of
	high-precision edits on an artifact that I thought should have been finished hours ago.
	Previously, I called this 'last-mile edits', but that was the wrong mental image.</p> <p>"Last mile" implies executing a known plan with diminishing returns but "last mile" at one
	level just becomes "early exploration" at higher resolution at the next level. Instead of
	treating exploration (idea) and exploitation (execution) as temporally separated phases,
	they nest recursively. That nested search is where the effort goes.</p> <p>Once you commit to D minor, this scene, that argument structure you've constrained the
	search space and now you search again within it.</p> <p>Take some of my quicker five-minute, gestural sketches below. You'd think they break this
	nested search dynamic but with a closer look it becomes clear that I just front-loaded my
	taxes by caching motor heuristics.</p> <figure id="figure-1"><!--[!--><!--]--> <p><img src="https://markusstrasser.org/media/art/sketches-masonry.jpg" alt="Five-minute gestural sketches showing practiced circular strokes and face-like abstractions"></p> <!--[--><figcaption><a href="#figure-1">Figure
				1</a>: <!--[-->A closer look shows the same set of practiced, comfortable gestures that click with my hand shape. They gravitate toward broad, confident circular strokes and shorter straight lines, just short enough to keep them stable. I'm executing cached heuristics, not exploring. I revert to face-like abstractions and focus on having the center hold. I do not like when *The Center Does Not Hold*.<!--]--></figcaption><!--]--></figure><!----> <p>Domains and modalities differ in how wide and forgiving their basins are and how quickly
	you can verify the edit (<em>feedback latency</em>). Music timing has a narrow basin at the
	micro-level (<em>±20 ms can kill a groove</em>) but can be more forgiving higher up: key
	and pitch changes can be interchangeable without loss of quality, not often though. Prose
	has a wide basin (many phrasings work). Abstract, contemporary art has extremely wide
	basin, so much so that nobody with any self-respect even bothers anymore. Renaissance
	paintings have more constraints and less distortion tolerance.</p> <table><thead><tr><th>Modality</th><th>Basin</th><th>Verifier</th><th>Speed</th></tr></thead><tbody><tr><td>Text (prose)</td><td>Wide</td><td>Human read</td><td>Minutes</td></tr><tr><td>Code</td><td>Wide (design) / Narrow (syntax)</td><td>Compiler/tests</td><td>ms-seconds</td></tr><tr><td>Music timing</td><td>Narrow</td><td>Ear–body</td><td>~20-40ms</td></tr><tr><td>Line drawing</td><td>Narrow</td><td>Eye–hand</td><td>~100ms</td></tr></tbody></table> <p>Let's take the following optimization landscape and assume it's for the process of writing
	a song. To make it simpler, let's constrain like this: We've written the lyrics and picked
	a BPM of 80.</p> <p>The wider, more forgiving hill corresponds to choosing C major on the macro level, but
	there might be a higher, sharper peak in E minor that's trickier—i.e., it demands more
	precision edits.</p> <figure id="figure-2"><!--[!--><!--]--> <p><img src="https://markusstrasser.org/media/essays/creative-work-landscapes/logseq-screenshot.png" alt="3D optimization landscape with Z-axis representing quality"></p> <!--[--><figcaption><a href="#figure-2">Figure
				2</a>: <!--[-->Z-axis is quality (warmer = better). X and Y are arbitrary parameters.<!--]--></figcaption><!--]--></figure><!----> <p>Wide basins let coarse proposals land. This is where almost all generative AI outputs live and the oxygen is still plenty. Near a sharp peak, the <strong>acceptance volume<span><sup>a</sup></span> <!----><!----> shrinks rapidly</strong> and you can’t reliably see micro-improvements without averaging more evidence or trials. The controller (often the hand) makes many tiny corrections after some latency. Rinse and repeat until the piece sits on a hard-to-vary peak.</p> <p>That's why effort seems like it scales superlinearly as perceived quality rises. Judging
	the intermediate artifact takes more time and most edits (the search) make it worse.
	Geometrically bad edits become more likely and land you lower in the landscape.</p> <p>Craft, then, is the slog of closing ever-less-perceivable gaps.</p> <h2 id="faqs"><a href="#faqs">FAQs</a></h2> <p><strong>Don't bands sometimes record a banger song in an hour together?</strong></p> <p>The tower-climbing happened during practice (*muscle memory*), not recording. Jazz is closer to real-time exploration and mistakes are more accepted and expected.</p> <p><strong>Drawing takes forever because you're exploring AND refining simultaneously.</strong></p> <p>We don't "rehearse" a specific drawing, we solve a novel problem in real-time. There's no cached motor sequence to execute.</p> <div><p><strong>BibTeX Citation</strong></p><pre><code>@misc{strasser2025,
  author = {Strasser, Markus},
  title = {Why Effort Scales Superlinearly with the Perceived Quality of Creative Work},
  year = {2025},
  url = {https://markusstrasser.org/},
  note = {Accessed: 2025-11-11}
}</code></pre></div><!----><!----></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SoftBank sells its entire stake in Nvidia for $5.83B (297 pts)]]></title>
            <link>https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</link>
            <guid>45884937</guid>
            <pubDate>Tue, 11 Nov 2025 07:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html">https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</a>, See on <a href="https://news.ycombinator.com/item?id=45884937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108065851" data-test="InlineImage"><p>Nvidia CEO Jensen Huang (L) and the CEO of the SoftBank Group Masayoshi Son pose during an AI event in Tokyo on November 13, 2024.</p><p>Akio Kon | Bloomberg | Getty Images</p></div><div><p><a id="107312506" href="https://www.cnbc.com/quotes/" type="security" brand="cnbc" section="[object Object]" contentclassification="">SoftBank</a> said Tuesday it has sold its entire stake in U.S. chipmaker <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> for $5.83 billion as the Japanese giant looks to capitalize on its <a href="https://www.cnbc.com/2025/06/27/softbank-ceo-says-he-wanted-to-be-openai-early-investor.html">"all in"</a> bet on ChatGPT maker OpenAI. </p><p>The firm said in its earnings statement that it sold 32.1 million Nvidia shares in October. It also disclosed that it sold part of its T-Mobile stake for $9.17 billion.</p><p>"We want to provide a lot of investment opportunities for investors, while we can still maintain financial strength," said SoftBank's Chief Financial Officer Yoshimitsu Goto during an investor presentation. </p><p>"So through those options and tools we make sure that we are ready for funding in a very safe manner," he said in comments translated by the company, adding that the stake sales were part of the firm's strategy for "asset monetization."</p><p>Nvidia shares dipped 0.95% in premarket trade on Tuesday.</p><p>While the Nvidia exit may come as a surprise to some investors, it's not the first time SoftBank has cashed out of the American AI chip darling.</p><p>SoftBank's Vision Fund was an early backer of Nvidia, <a href="https://www.cnbc.com/2017/05/24/the-stock-markets-hottest-stock-nvidia-just-got-a-big-new-backer.html">reportedly amassing</a> a $4 billion stake in 2017 before <a href="https://www.cnbc.com/2019/02/06/softbank-vision-fund-sells-nvidia-stake.html">selling all</a> of its holdings in January 2019. Despite its latest sale, SoftBank's business interests remain heavily intertwined with Nvidia's.</p></div><div id="Placeholder-ArticleBody-Video-108212821" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000392166" aria-labelledby="Placeholder-ArticleBody-Video-108212821"><p><img src="https://image.cnbcfm.com/api/v1/image/108212822-17605971971760597195-42119380833-1080pnbcnews.jpg?v=1760597197&amp;w=750&amp;h=422&amp;vtcrop=y" alt="ABB CEO: Softbank will be good home for robotics business"><span></span><span></span></p></div><div><p>That Tokyo-based company is involved in a number of AI ventures that rely on Nvidia's technology, including the $500 billion Stargate project for data centers in the U.S.</p><p>"This should not be seen, in our view, as a cautious or negative stance on Nvidia, but rather in the context of SoftBank needing at least $30.5bn of capital for investments in the Oct-Dec quarter, including $22.5bn for OpenAI and $6.5bn for Ampere," Rolf Bulk, equity research analyst at New Street Research, told CNBC.</p><p>That amounts to "more in a single quarter than it has invested in aggregate over the two prior years combined," Bulk said.</p><p>Morningstar's Dan Baker added that he doesn't see the move as representing a fundamental shift in strategy for the company.</p><p>"[SoftBank] made a point of saying that it wasn't any view on NVIDIA... At the end of the day, they are using the money to invest in other AI related companies," he said.</p></div><h2><a id="headline0"></a>Vision fund posts blowout $19 billion gain</h2><div><p>The stake sales and a blowout gain of $19 billion from SoftBank's Vision Fund helped the company <a href="https://www.cnbc.com/2025/11/11/softbank-earnings-report-2q.html">double its profit</a> in its fiscal second quarter.</p><p>The Vision Fund has been aggressively pushing into artificial intelligence, investing and acquiring firms throughout the AI value chain from chips to large language models and robotics.</p><p>"The reason we were able to have this result is because of September last year, that was the first time we invested in OpenAI," said SoftBank's Goto. He added that OpenAI's <a href="https://www.cnbc.com/2025/10/02/openai-share-sale-500-billion-valuation.html">latest valuation milestone of $500 billion</a> marks one of the largest valuations in the world, according to fair value.  </p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Softbank's shares this year</p></div><div><p>The Japanese conglomerate's stock has slumped in the past week as <a href="https://www.cnbc.com/2025/11/07/ai-valuation-fears-grip-investors-as-tech-bubble-concerns-heighten.html">concerns of an AI bubble</a> sent jitters through global markets. </p><p>"Our share price recently has been going up and down dynamically… we want to provide as many invest opportunities as possible," said Goto Tuesday, adding that the company's announced four-for-one stock split is part of its strategy to provide as many investment opportunities for shareholders as possible.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI documentation you can talk to, for every repo (149 pts)]]></title>
            <link>https://deepwiki.com/</link>
            <guid>45884169</guid>
            <pubDate>Tue, 11 Nov 2025 04:38:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepwiki.com/">https://deepwiki.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45884169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="138"><a href="https://deepwiki.com/bregman-arie/devops-exercises"><div><div><p><span>bregman-arie</span>/<span>devops-exercises</span></p></div><p>Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions</p><div><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256"><path d="M239.18,97.26A16.38,16.38,0,0,0,224.92,86l-59-4.76L143.14,26.15a16.36,16.36,0,0,0-30.27,0L90.11,81.23,31.08,86a16.46,16.46,0,0,0-9.37,28.86l45,38.83L53,211.75a16.38,16.38,0,0,0,24.5,17.82L128,198.49l50.53,31.08A16.4,16.4,0,0,0,203,211.75l-13.76-58.07,45-38.83A16.43,16.43,0,0,0,239.18,97.26Zm-15.34,5.47-48.7,42a8,8,0,0,0-2.56,7.91l14.88,62.8a.37.37,0,0,1-.17.48c-.18.14-.23.11-.38,0l-54.72-33.65a8,8,0,0,0-8.38,0L69.09,215.94c-.15.09-.19.12-.38,0a.37.37,0,0,1-.17-.48l14.88-62.8a8,8,0,0,0-2.56-7.91l-48.7-42c-.12-.1-.23-.19-.13-.5s.18-.27.33-.29l63.92-5.16A8,8,0,0,0,103,91.86l24.62-59.61c.08-.17.11-.25.35-.25s.27.08.35.25L153,91.86a8,8,0,0,0,6.75,4.92l63.92,5.16c.15,0,.24,0,.33.29S224,102.63,223.84,102.73Z"></path></svg><p><span>74.0k</span></p></div></div></a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hiring a developer as a small indie studio in 2025 (119 pts)]]></title>
            <link>https://www.ballardgames.com/tales/hiring-dev-2025/</link>
            <guid>45883995</guid>
            <pubDate>Tue, 11 Nov 2025 04:04:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ballardgames.com/tales/hiring-dev-2025/">https://www.ballardgames.com/tales/hiring-dev-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45883995">Hacker News</a></p>
Couldn't get https://www.ballardgames.com/tales/hiring-dev-2025/: Error: unsuitable certificate purpose]]></description>
        </item>
        <item>
            <title><![CDATA[The 'Toy Story' You Remember (1089 pts)]]></title>
            <link>https://animationobsessive.substack.com/p/the-toy-story-you-remember</link>
            <guid>45883788</guid>
            <pubDate>Tue, 11 Nov 2025 03:17:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://animationobsessive.substack.com/p/the-toy-story-you-remember">https://animationobsessive.substack.com/p/the-toy-story-you-remember</a>, See on <a href="https://news.ycombinator.com/item?id=45883788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!oYAZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 424w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 848w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png" width="1456" height="782" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:782,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1780036,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 424w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 848w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>A still from </span><em>Toy Story</em><span> on 35 mm film</span></figcaption></figure></div><p><strong>Welcome!</strong><span> Glad you could join us for another Sunday edition of the </span><em>Animation Obsessive</em><span> newsletter. This is our slate:</span></p><ul><li><p><strong>1)</strong><span> Digital animation on film stock.</span></p></li><li><p><strong>2)</strong><span> Animation newsbits.</span></p></li></ul><p>With that, let’s go!</p><p><em>Toy Story</em><span> used to look different. It’s a little tricky to explain.</span></p><p><span>Back in 1995, CG animation was </span><em>the</em><span> topic in the industry, and Pixar was central to the hype. The studio had already </span><a href="https://animationobsessive.substack.com/p/when-disney-went-digital" rel="">shifted Disney to computers</a><span> and won the first Oscar for a CG short (</span><em><a href="https://www.youtube.com/watch?v=DWi2WTqD59A" rel="">Tin Toy</a></em><span>). Giant movies like </span><em>Jurassic Park</em><span> incorporated Pixar’s software.</span></p><p><span>The next step was </span><em>Toy Story</em><span>, billed as the first animated feature to go all-CG.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-1-178330349" target="_self" rel="">1</a></span><span> Even after Pixar’s successes, that was a risk. Would a fully digital movie sell tickets? </span></p><p><span>It clearly worked out. </span><em>Toy Story</em><span> appeared 30 years ago this month — and its popularity created the animation world that exists now. A new process took over the business.</span></p><p><span>But not </span><em>entirely</em><span> new — not at first. There was something old about </span><em>Toy Story</em><span>’s tech, too, back in 1995. Pixar made the thing with computers, but it still needed to screen in theaters. And computers couldn’t really </span><em>do</em><span> that yet. From its early years, Pixar had relied on physical film stock. According to authors Bill Kinder and Bobbie O’Steen:</span></p><blockquote><p><span>[Pixar’s Ed]</span><em> Catmull recognized that his studio’s pixels needed to merge with that world-standard distribution freeway, 35 mm film. Computer chips were not fast enough, nor disks large enough, nor compression sophisticated enough to display even 30 minutes of standard-definition motion pictures. It was axiomatic that for a filmgoing audience to be going to a film, it would be a... film.</em><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-2-178330349" target="_self" rel="">2</a></span></p></blockquote><p><em>Toy Story</em><span> was a transitional project. Since Pixar couldn’t send digital data to theaters, every one of the movie’s frames was printed on analog film. When </span><em>Toy Story</em><span> originally hit home video, that 35 mm version was its source. Only years later, after technology advanced, did Pixar start doing digital transfers — cutting out the middleman. And </span><em>Toy Story</em><span>’s look changed with the era.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-3-178330349" target="_self" rel="">3</a></span><span> </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!rk4n!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!rk4n!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 424w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 848w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png" width="1456" height="1688" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1688,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4835256,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!rk4n!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 424w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 848w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Toy Story</em><span>’s original release on 35 mm (top), and the version currently streaming on Disney+ (bottom). See the film’s trailer on 35 mm </span><a href="https://www.youtube.com/watch?v=LoBFN_V66P0" rel="">here</a><span>.</span></figcaption></figure></div><p><span>While making </span><em>Toy Story</em><span>, Pixar’s team knew that the grain, softness, colors and contrasts of analog film weren’t visible on its monitors. They were different mediums. </span></p><p><span>So, to get the right look, the studio had to keep that final, physical output in mind. The digital colors were tailored with an awareness that they would change after printing. “Greens go dark really fast, while the reds stay pretty true,” said </span><em>Toy Story</em><span>’s art director, Ralph Eggleston. “Blues have to be less saturated to look fully saturated on film, while the oranges look really bad on computer screens, but look really great on film.”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-4-178330349" target="_self" rel="">4</a></span></p><p>The team checked its work along the way. In the words of Pixar’s William Reeves:</p><blockquote><p><em>During production, we’re working mostly from computer monitors. We’re rarely seeing the images on film. So, we have five or six extremely high-resolution monitors that have better color and picture quality. We put those in general work areas, so people can go and see how their work looks. Then, when we record, we try to calibrate to the film stock, so the image we have on the monitor looks the same as what we’ll get on film.</em></p></blockquote><p><span>Behind the final images was a “painstaking transfer process,” according to the press. Leading it was David DiFrancesco, one of Pixar’s early MVPs, who began working with Ed Catmull before Pixar even existed. He broke ground in film printing — specifically, in putting digital images on analog film.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-5-178330349" target="_self" rel="">5</a></span></p><p><span>He and his team in Pixar’s photoscience department used their expertise here. Their tools were “commercial grade” film printers, DiFrancesco noted: modified Solitaire Cine II machines. He’d invented more advanced stuff, but it wasn’t viable for a project of </span><em>Toy Story</em><span>’s size. Using the best equipment would’ve taken “several terabytes of data,” he said.</span></p><p><span>Their system was fairly straightforward. Every frame of </span><em>Toy Story</em><span>’s negative was exposed, three times, in front of a CRT screen that displayed the movie. “Since all film and video images are composed of combinations of red, green and blue light, the frame is separated into its discrete red, green and blue elements,” noted the studio. Exposures, filtered through each color, were layered to create each frame.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-6-178330349" target="_self" rel="">6</a></span><span> </span></p><p><span>It reportedly took nine hours to print 30 seconds of </span><em>Toy Story</em><span>. But it had to be done: it was the only way to screen the film.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!5nPg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!5nPg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 424w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 848w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1272w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png" width="1456" height="882" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:882,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2072015,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!5nPg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 424w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 848w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1272w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Examples of green, blue and red exposures, and the final scene on 35 mm film. Courtesy of the </span><em>Ultimate Toy Box</em><span> DVD.</span></figcaption></figure></div><p>In 1999, Pixar made history again.</p><p><span>Its second feature, </span><em>A Bug’s Life</em><span>, reached theaters in 1998. Once more, the studio designed its visuals for analog film (</span><a href="https://www.youtube.com/watch?v=izmlSjjOEdo" rel="">see the trailer on 35 mm</a><span>). Its people knew the ins-and-outs of this process, down to the amount of detail that film stock could accept and a projector could show. That’s partly how they got away with the movie’s tiny 2048×862 resolution, for example.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-7-178330349" target="_self" rel="">7</a></span></p><p><span>Still, the team struggled with one thing: the dip in image quality when film got converted to home video. That’s how </span><em>Toy Story</em><span> was released, but there </span><em>had</em><span> to be a better way.</span></p><p><span>For the home version of</span><em> A Bug’s Life</em><span>, Pixar devised a method of “go[ing] from our digital image within our system … straight to video,” John Lasseter said. He called it “a real pure version of our movie straight from our computers.” </span><em>A Bug’s Life</em><span> became the first digital-to-digital transfer on DVD. Compared to the theatrical release, the look had changed. It was sharp and grainless, and the colors were kind of different.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-8-178330349" target="_self" rel="">8</a></span></p><p><span>A digital transfer of </span><em>Toy Story</em><span> followed in the early 2000s. And it wasn’t </span><em>quite</em><span> the same movie that viewers had seen in the ‘90s. “The colors are vivid and lifelike, [and] not a hint of grain or artifacts can be found,” raved one reviewer. It was a crisp, blazingly bright, digital image now — totally different from the softness, texture and deep, muted warmth of physical film, on which </span><em>Toy Story </em><span>was created to be seen.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!P-J7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!P-J7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 424w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 848w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png" width="1456" height="1676" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1676,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3528708,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!P-J7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 424w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 848w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Toy Story</em><span> on 35 mm (top) and the Disney+ edition (bottom)</span></figcaption></figure></div><p><span>Quickly, digital transfers became a standard thing. Among others by Pixar, </span><em>The Incredibles</em><span> puts off a very different vibe between its theatrical and later releases (see </span><a href="https://www.youtube.com/watch?v=M_nSbqsLmEk" rel="">the 35 mm trailer</a><span> for reference). </span></p><p>Pixar wasn’t the only studio to make the leap, either. Disney did as well. </p><p><span>Like </span><em>Toy Story</em><span>, the Disney renaissance work of the ‘90s was transitional. </span><em>The Lion King</em><span>, </span><em>Mulan</em><span> and the rest existed as </span><a href="https://animationobsessive.substack.com/p/when-disney-went-digital" rel="">files in computer systems</a><span> — and the idea was always to record them on analog film at the end. Early home releases were based on those 35 mm versions. Later releases, like the ones Disney streams today, were direct transfers of the digital data. </span></p><p><span>At times, especially in the colors, they’re almost unrecognizable. And the images feel less cohesive — like something’s missing that was </span><em>supposed</em><span> to bring all the elements together. These aren’t quite the same films that ruled the ‘90s.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6IkD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6IkD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 424w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 848w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1272w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png" width="1456" height="1633" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1633,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4330548,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6IkD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 424w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 848w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1272w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Aladdin</em><span> on 35 mm film (top) versus Blu-ray (bottom). See a clip from the film on 35 mm </span><a href="https://www.youtube.com/watch?v=AuhNnovKXLA" rel="">here</a><span>.</span></figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!qdDU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!qdDU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 424w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 848w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png" width="1456" height="1662" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1662,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4506414,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!qdDU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 424w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 848w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>The Lion King</em><span> on 35 mm film (top) versus Blu-ray. See a clip from the film on 35 mm </span><a href="https://www.youtube.com/watch?v=uivXq3tXOhg" rel="">here</a><span>.</span></figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!T9lv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!T9lv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 424w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 848w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1272w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png" width="1456" height="1702" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1702,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3824553,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!T9lv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 424w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 848w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1272w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Mulan</em><span> on 35 mm film (top) versus Blu-ray. See the film’s trailer on 35 mm </span><a href="https://www.youtube.com/watch?v=2z2KsFZs-8I" rel="">here</a><span>.</span></figcaption></figure></div><p><span>For a number of years, there’s been talk in film-preservation circles about </span><em>Toy Story</em><span> and the Disney renaissance. This work sits in an odd place. The world was still pretty analog when the computer animation boom arrived: out of necessity, these projects became hybrids of new and old. What’s the</span><em> right </em><span>way to see digital movies that were designed for 35 mm film?</span></p><p><span>The studios themselves haven’t quite figured it out. On Disney+, the colors of </span><em>Toy Story</em><span> feel a bit raw — searing greens that were meant to darken on film, for example. Meanwhile, the newer </span><em>Toy Story</em><span> Blu-ray shares more in common with the original colors, but it’s still an altered, colder look.</span></p><p><span>When digital transfers first showed up, people were thrilled, including at Pixar. Movies became “crisper, clearer and more stunning on home video systems” than in theaters, some claimed.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-9-178330349" target="_self" rel="">9</a></span><span> Even so, it’s a little disquieting to think that </span><em>Toy Story</em><span>, the film that built our current world, is barely available in the form that wowed audiences of the ‘90s. The same goes for many other movies from the transitional era.</span></p><p><span>The good news is that this conversation gets bigger all the time. In those film-preservation circles, a dedicated few are trying to save the old work. More and more </span><a href="https://www.youtube.com/watch?v=BMvgu_KdpjA" rel="">comparison videos</a><span> are popping up on YouTube. If you get the chance to see one of the old Disney or Pixar films on 35 mm, it’s always worthwhile.</span></p><p><span>These companies, ultimately, decide how </span><em>Toy Story</em><span> looks today. Still, for some, it’s nice to see the original version of the film again — the version Pixar originally intended to make. It’s evidence that the film </span><em>did</em><span> feel</span><em> </em><span>different back then. The memories were real.</span></p><ul><li><p><em>I Am Frankelda</em><span> continues its strong performance in </span><strong>Mexican</strong><span> theaters. Analyst Edgar Apanco </span><a href="https://x.com/elapanco/status/1987639735091921274" rel="">reports</a><span> that 658,000 people have gone to see it, surpassing the popular </span><em>Chainsaw Man</em><span> movie. Revenues are </span><a href="https://x.com/elapanco/status/1987660916633325574" rel="">over $2.15 million</a><span> and climbing — having fallen </span><a href="https://palomaynacho.com/blog/chainsaw-y-frankelda-se-enfrentan-en-un-halloween-complicado/" rel="">just 17%</a><span> in week two, and an estimated 20% in week three.</span></p></li><li><p><span>In </span><strong>Japan</strong><span>, Goro Miyazaki </span><a href="https://ghibli.jpn.org/news/goro-talk-4/" rel="">revealed</a><span> that his father is still going to Studio Ghibli to draw for a few hours each day.</span></p></li><li><p><span>An exhibition in </span><strong>Taiwan</strong><span> </span><a href="https://reading.udn.com/read/story/124410/9126552" rel="">brought</a><span> the films of Karel Zeman to the country, reportedly for the first time. </span><em>The Fabulous Baron Munchausen</em><span> and </span><em>Invention for Destruction</em><span> are showing, among others.</span></p></li><li><p><span>In </span><strong>Nigeria</strong><span>, animator Gabriel Ugbodaga had </span><a href="https://www.arise.tv/gabriel-ugbodaga-nigeria-has-enough-animation-talent-what-we-lack-is-training-and-exposure/" rel="">a televised interview</a><span> about his well-received film </span><em>Vainglorious</em><span> (</span><a href="https://www.youtube.com/watch?v=6tVVWgz1cEk" rel="">watch</a><span>) and the state of the country’s industry. “When it comes to 2D hand-drawn animation,” he said, “there’s a lot of talent in Nigeria.”</span></p></li><li><p><span>If you missed that </span><em>Baahubali: The Eternal War</em><span> teaser this week, </span><a href="https://www.youtube.com/watch?v=RdUPs9e1bUk" rel="">see it here</a><span>. It’s an </span><strong>Indian</strong><span> feature presented by S. S. Rajamouli (</span><em>RRR</em><span>).</span></p></li><li><p><span>In </span><strong>Germany</strong><span>, Werner Herzog’s animated film </span><em>The Twilight World</em><span> </span><a href="https://cineuropa.org/en/newsdetail/485526" rel="">picked up</a><span> “€100,000 for production preparation support,” reports </span><em>Cineuropa</em><span>.</span></p></li><li><p><em>Infinity Castle</em><span> will reach </span><strong>China</strong><span> next weekend, and forecasters </span><a href="https://cn.investing.com/news/stock-market-news/article-3066545" rel="">believe</a><span> it could earn a billion yuan (over $140 million) and become the highest-grossing anime film in the country.</span></p></li><li><p><span>Also </span><a href="https://weibo.com/7985578740/Qcrf6p4D6" rel="">happening</a><span> in </span><strong>China</strong><span> next weekend: the latest edition of Feinaki Beijing Animation Week. The festival posted </span><a href="https://www.bilibili.com/video/BV1rMyzBxE9w/" rel="">55 trailers</a><span> for its selections this year.</span></p></li><li><p><span>The </span><strong>Japanese</strong><span> journalist Atsushi Matsumoto is raising concerns that the anime boom of the 2020s </span><a href="https://news.yahoo.co.jp/expert/articles/55f696fd42ce9a821f4bf682327f452bf3b7245c" rel="">could be a bubble</a><span>. (Meanwhile, despite huge industry profits, analysis suggests that studio closures are </span><a href="https://prtimes.jp/main/html/rd/p/000001179.000043465.html" rel="">set to rise</a><span> for the third year in a row.)</span></p></li><li><p><span>In</span><strong> America</strong><span>, for those in New York, there’s an interesting series of stop-motion screenings </span><a href="https://www.eastman.org/stop-motion-artform" rel="">at the Eastman Museum</a><span> this month — including </span><em>The Wolf House</em><span>.</span></p></li><li><p><span>Last of all: we wrote about a handful of </span><a href="https://animationobsessive.substack.com/p/free-films-worth-seeing" rel="">recent, free films worth seeing</a><span>. </span></p></li></ul><p><em><strong>Until next time!</strong></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I hate screenshots of text (322 pts)]]></title>
            <link>https://parkscomputing.com/page/i-hate-screenshots-of-text</link>
            <guid>45883124</guid>
            <pubDate>Tue, 11 Nov 2025 01:36:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://parkscomputing.com/page/i-hate-screenshots-of-text">https://parkscomputing.com/page/i-hate-screenshots-of-text</a>, See on <a href="https://news.ycombinator.com/item?id=45883124">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        




<article>
    
    <div>
        
<p>During the course of a regular working day, I receive a lot of screenshots like this from well-meaning colleagues:</p>
<p> <img src="https://parkscomputing.com/images/screenshots.png" alt="A screenshot of some text">
</p><p>It's almost always in a chat about some issue that occurred in the code, or perhaps code that's somehow related to the code in the screenshot, or… well, how am I supposed to even know? Upon seeing this code, I might think, “How is <code>slug</code> defined? Is <code>slug</code> being used to create the <code>baseUrl</code>? Why is the domain name hard-coded in that URL? What happens if an exception is thrown? <em>What module is this code even in?</em>”</p>
<p>I have to either very carefully type some of the code into a search box or (these days) get my coding agent to find the relevant module for me.</p>
<p>Why couldn't my colleague have just used copy &amp; paste? I could have seen a bit more of the context, even if the same lines were selected, and I could copy-and-paste <em>that</em> text into my IDE's search function so much more easily.</p>
<p>In fact, why couldn't they just send me the file, or even a link to the file (since everybody and their dog use GitHub, anyway).</p>
<p>It gets worse. Sometimes, I'll get a screenshot of an error log. “Hey, Paul, the build is failing. Can you look at this?”</p>
<p> <img src="https://parkscomputing.com/images/screenshots-errors2.png" alt="A screenshot of some build errors">
</p><p>What were you building? What line did it fail on? <em>What even was the error?</em></p>
<p>Of course, if I do a full rebuild of everything on my workstation, it'll succeed.</p>
<p>It would have been SO easy to just copy all of the error log, or even dump the log into a file, and just send me that.</p>
<p> <img src="https://parkscomputing.com/images/banging-head-against-wall-cracked.gif" alt="Me reading a screenshot of some build errors">
</p><p>Please, don't take screenshots of text unless it's to demonstrate a cosmetic issue related to the display of the text, or there is truly something relevant about the content of the screenshot that would be lost in a purely textual context.</p>

    </div>
</article>



    

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Warren Buffett's final shareholder letter [pdf] (377 pts)]]></title>
            <link>https://berkshirehathaway.com/news/nov1025.pdf</link>
            <guid>45882837</guid>
            <pubDate>Tue, 11 Nov 2025 00:51:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://berkshirehathaway.com/news/nov1025.pdf">https://berkshirehathaway.com/news/nov1025.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45882837">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>