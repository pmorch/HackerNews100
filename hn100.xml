<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 22 Aug 2024 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: InstantDB – A Modern Firebase (120 pts)]]></title>
            <link>https://github.com/instantdb/instant</link>
            <guid>41322281</guid>
            <pubDate>Thu, 22 Aug 2024 17:08:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/instantdb/instant">https://github.com/instantdb/instant</a>, See on <a href="https://news.ycombinator.com/item?id=41322281">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://instantdb.com/" rel="nofollow">
    <themed-picture data-catalyst-inline="true"><picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://camo.githubusercontent.com/2af63e8197df473d79408acf76aa06b72d1bd76f0a851f8983a8b487ee7faf6b/68747470733a2f2f696e7374616e7464622e636f6d2f726561646d65732f6c6f676f5f776974685f746578745f6461726b5f6d6f64652e737667" data-canonical-src="https://instantdb.com/readmes/logo_with_text_dark_mode.svg">
      <img alt="Shows the Instant logo" src="https://camo.githubusercontent.com/fcbab3cc92cfb8b401f1b4ecbc4d31ac2e0323c368b1425689b3e294f5f24ad6/68747470733a2f2f696e7374616e7464622e636f6d2f726561646d65732f6c6f676f5f776974685f746578745f6c696768745f6d6f64652e737667" data-canonical-src="https://instantdb.com/readmes/logo_with_text_light_mode.svg">
    </picture></themed-picture>
  </a>
</p>
<p dir="auto">
  <a href="https://discord.com/invite/VU53p7uQcE" rel="nofollow">
    <img height="20" src="https://camo.githubusercontent.com/8fc18af31e1f1939c19c29462d1e29a0a9bbacb77c7a3ec147be30efde001827/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f31303331393537343833323433313838323335" data-canonical-src="https://img.shields.io/discord/1031957483243188235">
  </a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/89f509177e307d8b573fe98e36deae42e2498fa84230420f8f26ab09359f0a2c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e7374616e7464622f696e7374616e74"><img src="https://camo.githubusercontent.com/89f509177e307d8b573fe98e36deae42e2498fa84230420f8f26ab09359f0a2c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e7374616e7464622f696e7374616e74" alt="stars" data-canonical-src="https://img.shields.io/github/stars/instantdb/instant"></a>
</p>
<p dir="auto">
   <a href="https://instantdb.com/docs" rel="nofollow">Get Started</a> · 
   <a href="https://instantdb.com/examples" rel="nofollow">Examples</a> · 
   <a href="https://instantdb.com/tutorial" rel="nofollow">Try the Demo</a> · 
   <a href="https://instantdb.com/docs" rel="nofollow">Docs</a> · 
   <a href="https://discord.com/invite/VU53p7uQcE" rel="nofollow">Discord</a>
</p><p dir="auto">Instant is a client-side database that makes it easy to build real-time and collaborative apps like Notion or Figma.</p>
<p dir="auto">You write <a href="https://www.instantdb.com/docs/instaql" rel="nofollow">relational queries</a> in the shape of the data you want and Instant handles all the data fetching, permission checking, and offline caching. When you <a href="https://www.instantdb.com/docs/instaml" rel="nofollow">change data</a>, optimistic updates and rollbacks are handled for you as well. Plus, every query is multiplayer by default.</p>
<p dir="auto">We also support <a href="https://www.instantdb.com/docs/presence-and-topics" rel="nofollow">ephemeral</a> updates, like cursors, or who's online. Currently we have SDKs for <a href="https://www.instantdb.com/docs/start-vanilla" rel="nofollow">Javascript</a>, <a href="https://www.instantdb.com/docs/" rel="nofollow">React</a>, and <a href="https://www.instantdb.com/docs/start-rn" rel="nofollow">React Native</a>.</p>
<p dir="auto">How does it look? Here's a barebones chat app in about 10 lines:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// ༼ つ ◕_◕ ༽つ Real-time Chat
// ----------------------------------
// * Updates instantly
// * Multiplayer
// * Works offline
function Chat() {
  // 1. Read
  const { isLoading, error, data } = useQuery({
    messages: {},
  });

  // 2. Write
  const addMessage = (message) => {
    transact(tx.messages[id()].update(message));
  }

  // 3. Render!
  return <UI data={data} onAdd={addMessage} />
}"><pre><span>// ༼ つ ◕_◕ ༽つ Real-time Chat</span>
<span>// ----------------------------------</span>
<span>// * Updates instantly</span>
<span>// * Multiplayer</span>
<span>// * Works offline</span>
<span>function</span> <span>Chat</span><span>(</span><span>)</span> <span>{</span>
  <span>// 1. Read</span>
  <span>const</span> <span>{</span> isLoading<span>,</span> error<span>,</span> data <span>}</span> <span>=</span> <span>useQuery</span><span>(</span><span>{</span>
    <span>messages</span>: <span>{</span><span>}</span><span>,</span>
  <span>}</span><span>)</span><span>;</span>

  <span>// 2. Write</span>
  <span>const</span> <span>addMessage</span> <span>=</span> <span>(</span><span>message</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>transact</span><span>(</span><span>tx</span><span>.</span><span>messages</span><span>[</span><span>id</span><span>(</span><span>)</span><span>]</span><span>.</span><span>update</span><span>(</span><span>message</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  <span>// 3. Render!</span>
  <span>return</span> <span>&lt;</span><span>UI</span> <span>data</span><span>=</span><span>{</span><span>data</span><span>}</span> <span>onAdd</span><span>=</span><span>{</span><span>addMessage</span><span>}</span> <span>/</span><span>&gt;</span>
<span>}</span></pre></div>
<p dir="auto">Want to see for yourself? <a href="https://instantdb.com/tutorial" rel="nofollow">try a demo in your browser.</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">Writing modern apps are full of schleps. Most of the time you start with the server: stand up databases, caches, ORMs, and endpoints. Then you write client-side code: stores, selectors, mutators. Finally you paint a screen. If you add multiplayer you need to think about stateful servers, and if you support offline mode, you need to think about IndexedDB and transaction queues.</p>
<p dir="auto">To make things worse, whenever you add a new feature, you go through the same song and dance over and over again: add models, write endpoints, stores, selectors, and finally the UI.</p>
<p dir="auto">Could it be better?</p>
<p dir="auto">In 2021, <strong>we realized that most of the schleps we face as UI engineers are actually database problems problems in disguise.</strong> (We got into greater detail <a href="https://instantdb.com/essays/next_firebase" rel="nofollow">in this essay</a>)</p>
<p dir="auto">
  <a href="#">
    <img alt="Shows how Instant compresses schleps" src="https://camo.githubusercontent.com/5767f96f66d7e1d87f07bfeab64f3590a30e11792bdeca79001247f8c70e6412/68747470733a2f2f696e7374616e7464622e636f6d2f726561646d65732f636f6d7072657373696f6e2e737667" data-canonical-src="https://instantdb.com/readmes/compression.svg">
  </a>
</p>
<p dir="auto">If you had a database on the client, you wouldn't need to think about stores, selectors, endpoints, or local caches: just write queries. If these queries were multiplayer by default, you wouldn't have to worry about stateful servers. And if your database supported rollback, you'd get optimistic updates for free.</p>
<p dir="auto">So we built Instant. Instant gives you a database you can use in the client, so you can focus on what’s important: building a great UX for your users, and doing it quickly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architectural Overview</h2><a id="user-content-architectural-overview" aria-label="Permalink: Architectural Overview" href="#architectural-overview"></a></p>
<p dir="auto">Here's how Instant works at a high level:</p>
<p dir="auto">
  <a href="#">
    <img alt="Shows how Instant compresses schleps" src="https://camo.githubusercontent.com/9f9534e626714562bc04bbfc0d2d2a2295a9375ec44c5467b9ff7474395aba86/68747470733a2f2f696e7374616e7464622e636f6d2f726561646d65732f6172636869746563747572652e737667" data-canonical-src="https://instantdb.com/readmes/architecture.svg">
  </a>
</p>
<p dir="auto">Under the hood, we store all user data as triples in one big Postgres database. A multi-tenant setup lets us offer a free tier that never pauses.</p>
<p dir="auto">A sync server written in Clojure talks to Postgres. We wrote a query engine that understands datalog and <a href="https://www.instantdb.com/docs/instaql" rel="nofollow">InstaQL</a>, a relational language that looks a lot like GraphQL:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// give me all users, their posts and comments
{ users: { posts: { comments: {} } } }"><pre><span>// give me all users, their posts and comments</span>
<span>{</span> <span>users</span>: <span>{</span> <span>posts</span>: <span>{</span> <span>comments</span>: <span>{</span><span>}</span> <span>}</span> <span>}</span> <span>}</span></pre></div>
<p dir="auto">Taking inspiration from <a href="https://asana.com/inside-asana/worldstore-distributed-caching-reactivity-part-1" rel="nofollow">Asana’s WorldStore</a> and <a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/#syncing-object-properties" rel="nofollow">Figma’s LiveGraph</a>, we tail postgres’ WAL to detect novelty and invalidate relevant queries.</p>
<p dir="auto">For the frontend, we wrote a client-side triple store. The SDK handles persisting a cache of recent queries to IndexedDB on web, and AsyncStorage in React Native.</p>
<p dir="auto">All data goes through a permission system powered by Google's <a href="https://github.com/google/cel-java">CEL library</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">The easiest way to get started with Instant is by signing up on instantdb.com. <a href="https://instantdb.com/docs" rel="nofollow">You can create a functional app in 5 minute or less.</a>.</p>
<p dir="auto">If you have any questions, you can jump in on our <a href="https://discord.com/invite/VU53p7uQcE" rel="nofollow">discord</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You can start by joining our <a href="https://discord.com/invite/VU53p7uQcE" rel="nofollow">discord</a> and introducing yourself. Even if you don't contribute code, we always love feedback.</p>
<p dir="auto">If you want to make changes, start by reading the <a href="https://github.com/instantdb/instant/blob/main/client"><code>client</code></a> and <a href="https://github.com/instantdb/instant/blob/main/server"><code>server</code></a> READMEs. There you'll find instructions to start Instant locally.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Continuous reinvention: A brief history of block storage at AWS (160 pts)]]></title>
            <link>https://www.allthingsdistributed.com/2024/08/continuous-reinvention-a-brief-history-of-block-storage-at-aws.html</link>
            <guid>41321063</guid>
            <pubDate>Thu, 22 Aug 2024 14:59:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.allthingsdistributed.com/2024/08/continuous-reinvention-a-brief-history-of-block-storage-at-aws.html">https://www.allthingsdistributed.com/2024/08/continuous-reinvention-a-brief-history-of-block-storage-at-aws.html</a>, See on <a href="https://news.ycombinator.com/item?id=41321063">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header></header><hr><section><p><time itemprop="datePublished" datetime="2024-08-22">August 22, 2024</time> • 4800 words</p><span itemprop="articleBody"><p><em><a href="https://www.linkedin.com/in/msolson/">Marc Olson</a> has been part of the team shaping Elastic Block Store (EBS) for over a decade. In that time, he’s helped to drive the dramatic evolution of EBS from a simple block storage service relying on shared drives to a massive network storage system that delivers over 140 trillion daily operations.</em></p><p><em>In this post, Marc provides a fascinating insider’s perspective on the journey of EBS. He shares hard-won lessons in areas such as queueing theory, the importance of comprehensive instrumentation, and the value of incrementalism versus radical changes. Most importantly, he emphasizes how constraints can often breed creative solutions. It’s an insightful look at how one of AWS’s foundational services has evolved to meet the needs of our customers (and the pace at which they’re innovating).</em></p><p><em>–W</em></p><hr><center><h2>Continuous reinvention: A brief history of block storage at AWS</h2></center><p>I’ve built system software for most of my career, and before joining AWS it was mostly in the networking and security spaces. When I joined AWS nearly 13 years ago, I entered a new domain—storage—and stepped into a new challenge. Even back then the scale of AWS dwarfed anything I had worked on, but many of the same techniques I had picked up until that point remained applicable—distilling problems down to first principles, and using successive iteration to incrementally solve problems and improve performance.</p><p>If you look around at AWS services today, you’ll find a mature set of core building blocks, but it wasn’t always this way. <a href="https://www.allthingsdistributed.com/2008/08/amazon_ebs_elastic_block_store.html">EBS launched on August 20, 2008</a>, nearly two years after EC2 became available in beta, with a simple idea to provide network attached block storage for EC2 instances. We had one or two storage experts, and a few distributed systems folks, and a solid knowledge of computer systems and networks. How hard could it be? In retrospect, if we knew at the time how much we didn’t know, we may not have even started the project!</p><p>Since I’ve been at EBS, I’ve had the opportunity to be part of the team that’s evolved EBS from a product built using shared hard disk drives (HDDs), to one that is capable of delivering hundreds of thousands of IOPS (IO operations per second) to a single EC2 instance. It’s remarkable to reflect on this because EBS is capable of delivering more IOPS to a single instance today than it could deliver to an entire Availability Zone (AZ) in the early years on top of HDDs. Even more amazingly, today EBS in aggregate delivers over 140 trillion operations daily across a distributed SSD fleet. But we definitely didn’t do it overnight, or in one big bang, or even perfectly. When I started on the EBS team, I initially worked on the EBS client, which is the piece of software responsible for converting instance IO requests into EBS storage operations. Since then I’ve worked on almost every component of EBS and have been delighted to have had the opportunity to participate so directly in the evolution and growth of EBS.</p><p>As a storage system, EBS is a bit unique. It’s unique because our primary workload is system disks for EC2 instances, motivated by the hard disks that used to sit inside physical datacenter servers. A lot of storage services place durability as their primary design goal, and are willing to degrade performance or availability in order to protect bytes. EBS customers care about durability, and we provide the primitives to help them achieve high durability with io2 Block Express volumes and volume snapshots, but they also care a lot about the performance and availability of EBS volumes. EBS is so closely tied as a storage primitive for EC2, that the performance and availability of EBS volumes tends to translate almost directly to the performance and availability of the EC2 experience, and by extension the experience of running applications and services that are built using EC2. The story of EBS is the story of understanding and evolving performance in a very large-scale distributed system that spans layers from guest operating systems at the top, all the way down to custom SSD designs at the bottom. In this post I’d like to tell you about the journey that we’ve taken, including some memorable lessons that may be applicable to your systems. After all, systems performance is a complex and really challenging area, and it’s a complex language across many domains.</p><h2 id="queueing-theory-briefly">Queueing theory, briefly <a href="#queueing-theory-briefly"></a></h2><p>Before we dive too deep, let’s take a step back and look at how computer systems interact with storage. The high-level basics haven’t changed through the years—a storage device is connected to a bus which is connected to the CPU. The CPU queues requests that travel the bus to the device. The storage device either retrieves the data from CPU memory and (eventually) places it onto a durable substrate, or retrieves the data from the durable media, and then transfers it to the CPU’s memory.</p><figure><img src="https://www.allthingsdistributed.com/images/mo-computer-arch.png" alt="Architecture with direct attached disk" loading="lazy"><figcaption>High-level computer architecture with direct attached disk</figcaption></figure><p>You can think of this like a bank. You walk into the bank with a deposit, but first you have to traverse a queue before you can speak with a bank teller who can help you with your transaction. In a perfect world, the number of patrons entering the bank arrive at the exact rate at which their request can be handled, and you never have to stand in a queue. But the real world isn’t perfect. The real world is asynchronous. It’s more likely that a few people enter the bank at the same time. Perhaps they have arrived on the same streetcar or train. When a group of people all walk into the back at the same time, some of them are going to have to wait for the teller to process the transactions ahead of them.</p><p>As we think about the time to complete each transaction, and empty the queue, the average time waiting in line (latency) across all customers may look acceptable, but the first person in the queue had the best experience, while the last had a much longer delay. There are a number of things the bank can do to improve the experience for all customers. The bank could add more tellers to process more requests in parallel, it could rearrange the teller workflows so that each transaction takes less time, lowering both the total time and the average time, or it could create different queues for either latency insensitive customers or consolidating transactions that may be faster to keep the queue low. But each of these options comes at an additional cost—hiring more tellers for a peak that may never occur, or adding more real estate to create separate queues. While imperfect, unless you have infinite resources, queues are necessary to absorb peak load.</p><figure><img src="https://www.allthingsdistributed.com/images/mo-simplified-ec2-ebs-queueing.png" alt="Simple diagram of EC2 and EBS queueing from 2012" loading="lazy"><figcaption>Simplified diagram of EC2 and EBS queueing (c. 2012)</figcaption></figure><p>In network storage systems, we have several queues in the stack, including those between the operating system kernel and the storage adapter, the host storage adapter to the storage fabric, the target storage adapter, and the storage media. In legacy network storage systems, there may be different vendors for each component, and different ways that they think about servicing the queue. You may be using a dedicated, lossless network fabric like fiber channel, or using iSCSI or NFS over TCP, either with the operating system network stack, or a custom driver. In either case, tuning the storage network often takes specialized knowledge, separate from tuning the application or the storage media.</p><p>When we first built EBS in 2008, the storage market was largely HDDs, and the latency of our service was dominated by the latency of this storage media. Last year, Andy Warfield went in-depth about the <a href="https://www.allthingsdistributed.com/2023/07/building-and-operating-a-pretty-big-storage-system.html#technical-scale-scale-and-the-physics-of-storage">fascinating mechanical engineering behind HDDs</a>. As an engineer, I still marvel at everything that goes into a hard drive, but at the end of the day they are mechanical devices and physics limits their performance. There’s a stack of platters that are spinning at high velocity. These platters have tracks that contain the data. Relative to the size of a track (&lt;100 nanometers), there’s a large arm that swings back and forth to find the right track to read or write your data. Because of the physics involved, the IOPS performance of a hard drive has remained relatively constant for the last few decades at approximately 120-150 operations per second, or 6-8 ms average IO latency. One of the biggest challenges with HDDs is that tail latencies can easily drift into the hundreds of milliseconds with the impact of queueing and command reordering in the drive.</p><p>We didn’t have to worry much about the network getting in the way since end-to-end EBS latency was dominated by HDDs and measured in the 10s of milliseconds. Even our early data center networks were beefy enough to handle our user’s latency and throughput expectations. The addition of 10s of microseconds on the network was a small fraction of overall latency.</p><p>Compounding this latency, hard drive performance is also variable depending on the other transactions in the queue. Smaller requests that are scattered randomly on the media take longer to find and access than several large requests that are all next to each other. This random performance led to wildly inconsistent behavior. Early on, we knew that we needed to spread customers across many disks to achieve reasonable performance. This had a benefit, it dropped the peak outlier latency for the hottest workloads, but unfortunately it spread the inconsistent behavior out so that it impacted many customers.</p><p>When one workload impacts another, we call this a “noisy neighbor.” Noisy neighbors turned out to be a critical problem for the business. As AWS evolved, we learned that we had to focus ruthlessly on a high-quality customer experience, and that inevitably meant that we needed to achieve strong performance isolation to avoid noisy neighbors causing interference with other customer workloads.</p><p>At the scale of AWS, we often run into challenges that are hard and complex due to the scale and breadth of our systems, and our focus on maintaining the customer experience. Surprisingly, the fixes are often quite simple once you deeply understand the system, and have enormous impact due to the scaling factors at play. We were able to make some improvements by changing scheduling algorithms to the drives and balancing customer workloads across even more spindles. But all of this only resulted in small incremental gains. We weren’t really hitting the breakthrough that truly eliminated noisy neighbors. Customer workloads were too unpredictable to achieve the consistency we knew they needed. We needed to explore something completely different.</p><h2 id="set-long-term-goals-but-dont-be-afraid-to-improve-incrementally">Set long term goals, but don’t be afraid to improve incrementally <a href="#set-long-term-goals-but-dont-be-afraid-to-improve-incrementally"></a></h2><p>Around the time I started at AWS in 2011, solid state disks (SSDs) became more mainstream, and were available in sizes that started to make them attractive to us. In an SSD, there is no physical arm to move to retrieve data—random requests are nearly as fast as sequential requests—and there are multiple channels between the controller and NAND chips to get to the data. If we revisit the bank example from earlier, replacing an HDD with an SSD is like building a bank the size of a football stadium and staffing it with superhumans that can complete transactions orders of magnitude faster. A year later we started using SSDs, and haven’t looked back.</p><p>We started with a small, but meaningful milestone: we built a new storage server type built on SSDs, and a new EBS volume type called Provisioned IOPS. Launching a new volume type is no small task, and it also limits the workloads that can take advantage of it. For EBS, there was an immediate improvement, but it wasn’t everything we expected.</p><p>We thought that just dropping SSDs in to replace HDDs would solve almost all of our problems, and it certainly did address the problems that came from the mechanics of hard drives. But what surprised us was that the system didn’t improve nearly as much as we had hoped and noisy neighbors weren’t automatically fixed. We had to turn our attention to the rest of our stack—the network and our software—that the improved storage media suddenly put a spotlight on.</p><p>Even though we needed to make these changes, we went ahead and launched in August 2012 with a maximum of 1,000 IOPS, 10x better than existing EBS standard volumes, and ~2-3 ms average latency, a 5-10x improvement with significantly improved outlier control. Our customers were excited for an EBS volume that they could begin to build their mission critical applications on, but we still weren’t satisfied and we realized that the performance engineering work in our system was really just beginning. But to do that, we had to measure our system.</p><h2 id="if-you-cant-measure-it-you-cant-manage-it">If you can’t measure it, you can’t manage it <a href="#if-you-cant-measure-it-you-cant-manage-it"></a></h2><p>At this point in EBS’s history (2012), we only had rudimentary telemetry. To know what to fix, we had to know what was broken, and then prioritize those fixes based on effort and rewards. Our first step was to build a method to instrument every IO at multiple points in every subsystem—in our client initiator, network stack, storage durability engine, and in our operating system. In addition to monitoring customer workloads, we also built a set of canary tests that run continuously and allowed us to monitor impact of changes—both positive and negative—under well-known workloads.</p><p>With our new telemetry we identified a few major areas for initial investment. We knew we needed to reduce the number of queues in the entire system. Additionally, the Xen hypervisor had served us well in EC2, but as a general-purpose hypervisor, it had different design goals and many more features than we needed for EC2. We suspected that with some investment we could reduce complexity of the IO path in the hypervisor, leading to improved performance. Moreover, we needed to optimize the network software, and in our core durability engine we needed to do a lot of work organizationally and in code, including on-disk data layout, cache line optimization, and fully embracing an asynchronous programming model.</p><p>A really consistent lesson at AWS is that system performance issues almost universally span a lot of layers in our hardware and software stack, but even great engineers tend to have jobs that focus their attention on specific narrower areas. While the much celebrated ideal of a “full stack engineer” is valuable, in deep and complex systems it’s often even more valuable to create cohorts of experts who can collaborate and get really creative across the entire stack and all their individual areas of depth.</p><p>By this point, we already had separate teams for the storage server and for the client, so we were able to focus on these two areas in parallel. We also enlisted the help of the EC2 hypervisor engineers and formed a cross-AWS network performance cohort. We started to build a blueprint of both short-term, tactical fixes and longer-term architectural changes.</p><h2 id="divide-and-conquer">Divide and conquer <a href="#divide-and-conquer"></a></h2><figure><img src="https://www.allthingsdistributed.com/images/mo-physalia.png" alt="Whiteboard showing how the team removed the contronl from from the IO path with Physalia" loading="lazy"><figcaption>Removing the control plane from the IO path with Physalia</figcaption></figure><p>When I was an undergraduate student, while I loved most of my classes, there were a couple that I had a love-hate relationship with. “Algorithms” was taught at a graduate level at my university for both undergraduates and graduates. I found the coursework intense, but I eventually fell in love with the topic, and <a href="https://www.amazon.com/dp/026204630X">Introduction to Algorithms</a>, commonly referred to as CLR, is one of the few textbooks I retained, and still occasionally reference. What I didn’t realize until I joined Amazon, and seems obvious in hindsight, is that you can design an organization much the same way you can design a software system. Different algorithms have different benefits and tradeoffs in how your organization functions. Where practical, Amazon chooses a divide and conquer approach, and keeps teams small and focused on a self-contained component with well-defined APIs.</p><p>This works well when applied to components of a retail website and control plane systems, but it’s less intuitive in how you could build a high-performance data plane this way, and at the same time improve performance. In the EBS storage server, we reorganized our monolithic development team into small teams focused on specific areas, such as data replication, durability, and snapshot hydration. Each team focused on their unique challenges, dividing the performance optimization into smaller sized bites. These teams are able to iterate and commit their changes independently—made possible by rigorous testing that we’ve built up over time. It was important for us to make continual progress for our customers, so we started with a blueprint for where we wanted to go, and then began the work of separating out components while deploying incremental changes.</p><p>The best part of incremental delivery is that you can make a change and observe its impact before making the next change. If something doesn’t work like you expected, then it’s easy to unwind it and go in a different direction. In our case, the blueprint that we laid out in 2013 ended up looking nothing like what EBS looks like today, but it gave us a direction to start moving toward. For example, back then we never would have imagined that Amazon would one day <a href="https://aws.amazon.com/blogs/aws/aws-nitro-ssd-high-performance-storage-for-your-i-o-intensive-applications/">build its own SSDs</a>, with a technology stack that could be tailored specifically to the needs of EBS.</p><h2 id="always-question-your-assumptions">Always question your assumptions! <a href="#always-question-your-assumptions"></a></h2><p>Challenging our assumptions led to improvements in every single part of the stack.</p><p>We started with software virtualization. Until late 2017 all EC2 instances ran on the Xen hypervisor. With devices in Xen, there is a ring queue setup that allows guest instances, or domains, to share information with a privileged driver domain (dom0) for the purposes of IO and other emulated devices. The EBS client ran in dom0 as a kernel block device. If we follow an IO request from the instance, just to get off of the EC2 host there are many queues: the instance block device queue, the Xen ring, the dom0 kernel block device queue, and the EBS client network queue. In most systems, performance issues are compounding, and it’s helpful to focus on components in isolation.</p><p>One of the first things that we did was to write several “loopback” devices so that we could isolate each queue to gauge the impact of the Xen ring, the dom0 block device stack, and the network. We were almost immediately surprised that with almost no latency in the dom0 device driver, when multiple instances tried to drive IO, they would interact with each other enough that the goodput of the entire system would slow down. We had found another noisy neighbor! Embarrassingly, we had launched EC2 with the Xen defaults for the number of block device queues and queue entries, which were set many years prior based on the limited storage hardware that was available to the Cambridge lab building Xen. This was very unexpected, especially when we realized that it limited us to only 64 IO outstanding requests for an entire host, not per device—certainly not enough for our most demanding workloads.</p><p>We fixed the main issues with software virtualization, but even that wasn’t enough. In 2013, we were well into the development of our first <a href="https://www.allthingsdistributed.com/2020/09/reinventing-virtualization-with-nitro.html">Nitro offload card</a> dedicated to networking. With this first card, we moved the processing of VPC, our software defined network, from the Xen dom0 kernel, into a dedicated hardware pipeline. By isolating the packet processing data plane from the hypervisor, we no longer needed to steal CPU cycles from customer instances to drive network traffic. Instead, we leveraged Xen’s ability to pass a virtual PCI device directly to the instance.</p><p>This was a fantastic win for latency and efficiency, so we decided to do the same thing for EBS storage. By moving more processing to hardware, we removed several operating system queues in the hypervisor, even if we weren’t ready to pass the device directly to the instance just yet. Even without passthrough, by offloading more of the interrupt driven work, the hypervisor spent less time servicing the requests—the hardware itself had dedicated interrupt processing functions. This second Nitro card also had hardware capability to handle EBS encrypted volumes with no impact to EBS volume performance. Leveraging our hardware for encryption also meant that the encryption key material is kept separate from the hypervisor, which further protects customer data.</p><figure><img src="https://www.allthingsdistributed.com/images/mo-network-tuning.png" alt="Diagram showing experiments in network tuning to improve throughput and reduce latency" loading="lazy"><figcaption>Experimenting with network tuning to improve throughput and reduce latency</figcaption></figure><p>Moving EBS to Nitro was a huge win, but it almost immediately shifted the overhead to the network itself. Here the problem seemed simple on the surface. We just needed to tune our wire protocol with the latest and greatest data center TCP tuning parameters, while choosing the best congestion control algorithm. There were a few shifts that were working against us: AWS was experimenting with different data center cabling topology, and our AZs, once a single data center, were growing beyond those boundaries. Our tuning would be beneficial, as in the example above, where adding a small amount of random latency to requests to storage servers counter-intuitively reduced the average latency and the outliers due to the smoothing effect it has on the network. These changes were ultimately short lived as we continuously increased the performance and scale of our system, and we had to continually measure and monitor to make sure we didn’t regress.</p><p>Knowing that we would need something better than TCP, in 2014 we started laying the foundation for Scalable Relatable Diagram (SRD) with “<a href="https://ieeexplore.ieee.org/document/9167399">A Cloud-Optimized Transport Protocol for Elastic and Scalable HPC</a>”. Early on we set a few requirements, including a protocol that could improve our ability to recover and route around failures, and we wanted something that could be easily offloaded into hardware. As we were investigating, we made two key observations: 1/ we didn’t need to design for the general internet, but we could focus specifically on our data center network designs, and 2/ in storage, the execution of IO requests that are in flight could be reordered. We didn’t need to pay the penalty of TCP’s strict in-order delivery guarantees, but could instead send different requests down different network paths, and execute them upon arrival. Any barriers could be handled at the client before they were sent on the network. What we ended up with is a protocol that’s useful not just for storage, but for networking, too. When used in <a href="https://aws.amazon.com/about-aws/whats-new/2022/11/elastic-network-adapter-ena-express-amazon-ec2-instances/">Elastic Network Adapter (ENA) Express</a>, SRD improves the performance of your TCP stacks in your guest. SRD can drive the network at higher utilization by taking advantage of multiple network paths and reducing the overflow and queues in the intermediate network devices.</p><p>Performance improvements are never about a single focus. It’s a discipline of continuously challenging your assumptions, measuring and understanding, and shifting focus to the most meaningful opportunities.</p><h2 id="constraints-breed-innovation">Constraints breed innovation <a href="#constraints-breed-innovation"></a></h2><p>We weren’t satisfied that only a relatively small number of volumes and customers had better performance. We wanted to bring the benefits of SSDs to everyone. This is an area where scale makes things difficult. We had a large fleet of thousands of storage servers running millions of non-provisioned IOPS customer volumes. Some of those same volumes still exist today. It would be an expensive proposition to throw away all of that hardware and replace it.</p><p>There was empty space in the chassis, but the only location that didn’t cause disruption in the cooling airflow was between the motherboard and the fans. The nice thing about SSDs is that they are typically small and light, but we couldn’t have them flopping around loose in the chassis. After some trial and error—and help from our material scientists—we found heat resistant, industrial strength hook and loop fastening tape, which also let us service these SSDs for the remaining life of the servers.</p><figure><img src="https://www.allthingsdistributed.com/images/mo-manual-ssd.png" alt="An SSD in one of our servers" loading="lazy"><figcaption>Yes, we manually put an SSD into every server!</figcaption></figure><p>Armed with this knowledge, and a lot of human effort, over the course of a few months in 2013, EBS was able to put a single SSD into each and every one of those thousands of servers. We made a small change to our software that staged new writes onto that SSD, allowing us to return completion back to your application, and then flushed the writes to the slower hard disk asynchronously. And we did this with no disruption to customers—we were converting a propeller aircraft to a jet while it was in flight. The thing that made this possible is that we designed our system from the start with non-disruptive maintenance events in mind. We could retarget EBS volumes to new storage servers, and update software or rebuild the empty servers as needed.</p><p>This ability to migrate customer volumes to new storage servers has come in handy several times throughout EBS’s history as we’ve identified new, more efficient data structures for our on-disk format, or brought in new hardware to replace the old hardware. There are volumes still active from the first few months of EBS’s launch in 2008. These volumes have likely been on hundreds of different servers and multiple generations of hardware as we’ve updated and rebuilt our fleet, all without impacting the workloads on those volumes.</p><h2 id="reflecting-on-scaling-performance">Reflecting on scaling performance <a href="#reflecting-on-scaling-performance"></a></h2><p>There’s one more journey over this time that I’d like to share, and that’s a personal one. Most of my career prior to Amazon had been in either early startup or similarly small company cultures. I had built managed services, and even distributed systems out of necessity, but I had never worked on anything close to the scale of EBS, even the EBS of 2011, both in technology and organization size. I was used to solving problems by myself, or maybe with one or two other equally motivated engineers.</p><p>I really enjoy going super deep into problems and attacking them until they’re complete, but there was a pivotal moment when a colleague that I trusted pointed out that I was becoming a performance bottleneck for our organization. As an engineer who had grown to be an expert in the system, but also who cared really, really deeply about all aspects of EBS, I found myself on every escalation and also wanting to review every commit and every proposed design change. If we were going to be successful, then I had to learn how to scale myself–I wasn’t going to solve this with just ownership and bias for action.</p><p>This led to even more experimentation, but not in the code. I knew I was working with other smart folks, but I also needed to take a step back and think about how to make them effective. One of my favorite tools to come out of this was peer debugging. I remember a session with a handful of engineers in one of our lounge rooms, with code and a few terminals projected on a wall. One of the engineers exclaimed, “Uhhhh, there’s no way that’s right!” and we had found something that had been nagging us for a while. We had overlooked where and how we were locking updates to critical data structures. Our design didn’t usually cause issues, but occasionally we would see slow responses to requests, and fixing this removed one source of jitter. We don’t always use this technique, but the neat thing is that we are able to combine our shared systems knowledge when things get really tricky.</p><p>Through all of this, I realized that empowering people, giving them the ability to safely experiment, can often lead to results that are even better than what was expected. I’ve spent a large portion of my career since then focusing on ways to remove roadblocks, but leave the guardrails in place, pushing engineers out of their comfort zone. There’s a bit of psychology to engineering leadership that I hadn’t appreciated. I never expected that one of the most rewarding parts of my career would be encouraging and nurturing others, watching them own and solve problems, and most importantly celebrating the wins with them!</p><h2 id="conclusion">Conclusion <a href="#conclusion"></a></h2><p>Reflecting back on where we started, we knew we could do better, but we weren’t sure how much better. We chose to approach the problem, not as a big monolithic change, but as a series of incremental improvements over time. This allowed us to deliver customer value sooner, and course correct as we learned more about changing customer workloads. We’ve improved the shape of the EBS latency experience from one averaging more than 10 ms per IO operation to consistent sub-millisecond IO operations with our highest performing io2 Block Express volumes. We accomplished all this without taking the service offline to deliver a new architecture.</p><p>We know we’re not done. Our customers will always want more, and that challenge is what keeps us motivated to innovate and iterate.</p><ul><li><a href="https://www.allthingsdistributed.com/2023/07/building-and-operating-a-pretty-big-storage-system.html?utm_campaign=related+posts&amp;utm_source=brief-history-ebs">Building and operating a pretty big storage system called S3</a></li><li><a href="https://www.allthingsdistributed.com/2023/11/standing-on-the-shoulders-of-giants-colm-on-constant-work.html?utm_campaign=related+posts&amp;utm_source=brief-history-ebs">Reliability, constant work, and a good cup of coffee</a></li><li><a href="https://www.allthingsdistributed.com/2022/11/amazon-1998-distributed-computing-manifesto.html?utm_campaign=related+posts&amp;utm_source=brief-history-ebs">The Distributed Computing Manifesto</a></li></ul></span></section><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beastie Boys dismantled their gold record plaque,it didn't contain their music (110 pts)]]></title>
            <link>https://djmag.com/news/beastie-boys-dismantled-their-pauls-boutique-gold-record-plaque-find-it-didnt-contain-their</link>
            <guid>41319955</guid>
            <pubDate>Thu, 22 Aug 2024 13:20:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://djmag.com/news/beastie-boys-dismantled-their-pauls-boutique-gold-record-plaque-find-it-didnt-contain-their">https://djmag.com/news/beastie-boys-dismantled-their-pauls-boutique-gold-record-plaque-find-it-didnt-contain-their</a>, See on <a href="https://news.ycombinator.com/item?id=41319955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="text">
<p><span><span><span><span><span><span><span>Beastie Boys have shared the story of how they discovered that the gold record plaque they received after the certification of ‘Paul’s Boutique’ didn’t actually contain a pressing of their own music.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>Ad-Rock (Adam Horovitz) and Mike D (Michael Diamond) from <a href="https://djmag.com/news/beastie-boys-announce-special-edition-check-your-head-30th-anniversary-reissue" rel="noopener" target="_blank">the New York hip-hop innovators</a> recently revealed the issue with their gold record plaque for the seminal 1989 album during an interview on the Conan O’Brien Needs a Friend podcast.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>The certification came when ‘Paul’s Boutique’ sold 500,000 copies just two months after its release. However, when the bandmates closely examined the plaque years later, they noticed that the record displayed inside did not contain the same amount of tracks as the album’s tracklisting.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>“So we’re at our studio here in California and I was smoking the pot,” Ad-Rock said, recalling the discovery. “This was a long time ago. We had a gold record on the wall, it was our record, ‘</span></span><span><span>Paul’s Boutique’</span></span><span><span>. I was looking at it and I could see it had our label and I could see that it had like nine songs on the one side. But I was looking at the actual gold record and it only had four songs on it.”</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>Curious about the discrepancy, the band decided to break the glass and remove the record from the plaque. Upon inspection, they found that instead of ‘</span></span><span><span>Paul’s Boutique’,</span></span><span><span>&nbsp;the vinyl contained piano versions of songs like Barry Manilow’s music and Morris Albert’s ‘Feelings’.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>When asked by O’Brien if this was common for all gold record plaques, Ad-Rock replied, “I don’t know about anybody else...” while Mike D speculated that major stars like Barbra Streisand or Donna Summer probably received plaques with their actual records.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>While the plaque didn’t feature their music, '</span></span><span><span>Paul’s Boutique'</span></span><span><span> continued to gain recognition after its gold certification. The album was certified platinum in 1995 and reached double platinum status in 1999.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>Listen to the podcast below.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span><span>Revisit Ben Cardew’s </span></span></span></span></span></span></span><span><span><span><span><span><span><span>Solid Gold</span></span><span><span> feature on how Beastie Boys' cult classic second album was a high-water mark <a href="https://djmag.com/features/solid-gold-beastie-boys-pauls-boutique" rel="noopener" target="_blank">for rich sampling and undiluted fun</a>.</span></span></span></span></span></span></span></p>
<p>From May, <a href="https://djmag.com/features/how-beastie-boys-ill-communication-set-benchmark-90s-eclecticism" rel="noopener" target="_blank">read DJ Mag’s feature</a> on how the legendary band's fourth album, ‘<span><span>Ill Communication’,&nbsp;</span></span><span><span>set a benchmark for ’90s eclecticism.</span></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Async2 – The .NET Runtime Async experiment concludes (120 pts)]]></title>
            <link>https://steven-giesel.com/blogPost/59752c38-9c99-4641-9853-9cfa97bb2d29</link>
            <guid>41319224</guid>
            <pubDate>Thu, 22 Aug 2024 11:52:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steven-giesel.com/blogPost/59752c38-9c99-4641-9853-9cfa97bb2d29">https://steven-giesel.com/blogPost/59752c38-9c99-4641-9853-9cfa97bb2d29</a>, See on <a href="https://news.ycombinator.com/item?id=41319224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div b-gj8cwnhyng=""><p>The .NET team has been working on a new experiment called async2, which is a new implementation of the async/await pattern that is designed to be more efficient and more flexible than the current implementation. It started with green threads and ended with an experiment that moves <code>async</code> and <code>await</code> to the runtime. This post will cover the journey of <code>async2</code> and the conclusion of the experiment.</p>
<h2 id="where-all-began-green-threads">Where all began - Green threads</h2>
<p>Let's start here: <a href="https://github.com/dotnet/runtimelab/issues/2398"><em>"Green Thread Experiment Results"</em></a>. The team invested in an experiment to evaluate the feasibility of using green threads in the .NET runtime. But wait a second, what are green threads?</p>
<h3 id="green-threads">Green threads</h3>
<p>Green threads are user-space threads that are managed by a runtime library or a virtual machine (VM) instead of the operating system.<sup>Source: <a href="https://en.wikipedia.org/wiki/Green_thread">Wikipedia</a></sup> They are lightweight and can be created and managed more quickly than kernel threads. Green threads are also known as "coroutines" or "fibers" in other programming languages. The idea is that you, as a developer, don't have to worry about threads.</p>
<p>Currently, with threads and to some extend with <code>async</code>/<code>await</code>, a new stack is created. You can easily see that in your favourite IDE, if you debug:</p>
<p><img src="https://linkdotnetblog.azureedge.net/blog/20240812_Async2/stacks.webp" alt="stack"></p>
<p>Green threads are different. <a href="https://stackoverflow.com/a/19098856/1892523">The memory of a green thread is allocated on the heap</a>. But all of this comes with a cost: As they aren't managed by the OS, they can't take advantage of multiple cores inherently. But for I/O-bound operations, they are a good fit.</p>
<h3 id="abandoning-green-threads">Abandoning green threads</h3>
<p>The key-challenges were (which lead to the abandonment of the green threads experiment):</p>
<ul>
<li>Complex interaction between green threads and existing async model</li>
<li>Interop with native code was complex and slower than using regular threads</li>
<li>Compatibility issues with security mitigations like shadow stacks</li>
<li>Uncertainty about whether it would be possible to make green threads faster than async in important scenarios, given the effort required for improvement.</li>
</ul>
<p>This lead to the conclusion that green threads are not the right way to go for the .NET runtime and gave birth to the <code>async2</code> experiment. From here on out, I will keep the term <code>async2</code> for the experiment, as it is the codename for the experiment.</p>
<h2 id="async2-the.net-runtime-async-experiment"><code>async2</code> - The .NET Runtime Async experiment</h2>
<p>Now, <code>async2</code> is obviously only a codename. The goal of the experiment was to move <code>async</code> and <code>await</code> to the runtime. The main motivation behind this was to make <code>async</code> more efficient and more flexible. As <code>async</code> is already used as an identifier in C#, the team decided to use <code>async2</code> as a codename for the experiment. <strong>If</strong> that thing ever makes it into the runtime, it will be called <code>async</code> - so it will be a replacement for the current <code>async</code> implementation. But let's start at the beginning.</p>
<h3 id="async-is-a-compiler-feature"><code>async</code> is a compiler feature</h3>
<p>I talked about this from time to time in my blog posts. For example:</p>
<ul>
<li><a href="https://steven-giesel.com/blogPost/720a48fd-0abe-4c32-83ac-26926d501895/the-state-machine-in-c-with-asyncawait"><em>"The state machine in C# with async/await"</em></a></li>
<li><a href="https://steven-giesel.com/blogPost/69dc05d1-9c8a-4002-9d0a-faf4d2375bce/c-lowering"><em>"C# Lowering"</em></a></li>
</ul>
<p>The current implementation of <code>async</code> and <code>await</code> is a compiler feature. The compiler generates a state machine for the <code>async</code> method. The runtime doesn't know anything about <code>async</code> and <code>await</code>. There is no trace of an <code>async</code>-like keyword in IL or in the JIT-compiled code. And that is where the experiment started.</p>
<p>Starting point is this nice GitHub issue: <a href="https://github.com/dotnet/runtime/issues/94620">"<em>.NET 9 Runtime Async Experiment</em>"</a>, which basically describes the whole experiment in more detail with an ongoing discussion from the community.</p>
<h3 id="async-is-a-runtime-feature"><code>async</code> is a runtime feature</h3>
<p>The goal of the experiment was to move <code>async</code> and <code>await</code> to the runtime. This would allow the runtime to have more control over the pattern itself. With that there would be also some different semantics:</p>
<h3 id="async2-and-executioncontext-and-synchronizationcontext"><code>async2</code> and <code>ExecutionContext</code> and <code>SynchronizationContext</code></h3>
<p><code>async2</code> would not have save or restore of <code>SynchronizationContext</code> and <code>ExecutionContext</code> at function boundaries, instead allowing callers to observe changes. With the <code>ExecutionContext</code>, this would shift a big change in how <code>AsyncLocal</code> behaves.</p>
<p>Today, <code>AsyncLocal</code> is used to store data that flows with the logical call context. It gets copied to the new context. That said, if a function deep down the call stack changes the value of an <code>AsyncLocal</code>, the caller will <strong>not</strong> see the updated value, only functions further down the logical async flow. Here an example:</p>
<pre><code>await new AsyncLocalTest().DoOuter();

public class AsyncLocalTest
{
    private readonly AsyncLocal&lt;string&gt; _asyncLocal = new();

    public async Task DoOuter()
    {
        _asyncLocal.Value = "Outer";
        Console.WriteLine($"DoOuter: {_asyncLocal.Value}");
        await DoInner();
        Console.WriteLine($"DoOuter: {_asyncLocal.Value}");
    }

    private async Task DoInner()
    {
        _asyncLocal.Value = "Inner";
        Console.WriteLine($"DoInner: {_asyncLocal.Value}");
        await Task.Yield();
        Console.WriteLine($"DoInner: {_asyncLocal.Value}");
    }
}
</code></pre>
<p>The output of this code is:</p>
<pre><code>DoOuter: Outer
DoInner: Inner
DoInner: Inner
DoOuter: Outer
</code></pre>
<p>With <code>async2</code> those changes are not "reverted" which would lead to a different output:</p>
<pre><code>DoOuter: Outer
DoInner: Inner
DoInner: Inner
DoOuter: Inner
</code></pre>
<h3 id="comparison-with-the-current-implementation-and-some-results">Comparison with the current implementation and some results</h3>
<p>The whole document, that describes all the details, can be found here: <a href="https://github.com/dotnet/runtimelab/blob/feature/async2-experiment/docs/design/features/runtime-handled-tasks.md">https://github.com/dotnet/runtimelab/blob/feature/async2-experiment/docs/design/features/runtime-handled-tasks.md</a></p>
<p>The team found out that the approach of putting <code>async</code> into the JIT might yield the best results overall. Here a basic overview:</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th><code>async</code></th>
<th><code>async2</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Performance</td>
<td>Generally slower than <code>async2</code>, especially for deep call stacks</td>
<td>Generally faster than <code>async</code>, with performance comparable to synchronous code in non-suspended scenarios</td>
</tr>
<tr>
<td>Exception Handling</td>
<td>Slow and inefficient, causing GC pauses and impacting responsive performance of applications</td>
<td>Improved EH handling, reducing the impact on application responsiveness</td>
</tr>
<tr>
<td>Stack Depth Limitation</td>
<td>Limited by stack depth, which can cause issues for deep call stacks</td>
<td>No explicit limitations on stack depth, allowing <code>async2</code> to handle deeper call stacks more efficiently</td>
</tr>
<tr>
<td>Memory Consumption</td>
<td>Generally lower than <code>async2</code>, especially in scenarios with many suspended tasks</td>
<td>Higher memory consumption due to capturing entire stack frames and registers, but still acceptable compared to other factors like pause times</td>
</tr>
</tbody>
</table>
<h2 id="where-do-we-go-from-here">Where do we go from here?</h2>
<p>As the name suggests, this is just an experiment, that may lead to a replacement of <code>async</code> <strong>in some years</strong>. Yes, <strong>years</strong>. It might take a while until this is production-ready. And for the transition phase, there has to be interop for <code>async</code> ↔ <code>async2</code>. Anyway - a very good starting point and I am looking forward to the future of <code>async2</code>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No "Hello", No "Quick Call", and No Meetings Without an Agenda (212 pts)]]></title>
            <link>https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/</link>
            <guid>41318408</guid>
            <pubDate>Thu, 22 Aug 2024 09:46:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/">https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/</a>, See on <a href="https://news.ycombinator.com/item?id=41318408">Hacker News</a></p>
Couldn't get https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[What is an SBAT and why does everyone suddenly care (272 pts)]]></title>
            <link>https://mjg59.dreamwidth.org/70348.html</link>
            <guid>41318222</guid>
            <pubDate>Thu, 22 Aug 2024 09:11:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mjg59.dreamwidth.org/70348.html">https://mjg59.dreamwidth.org/70348.html</a>, See on <a href="https://news.ycombinator.com/item?id=41318222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Short version: <a href="https://github.com/rhboot/shim/blob/main/SBAT.md">Secure Boot Advanced Targeting</a> and if that's enough for you you can skip the rest you're welcome.</p><p>Long version: When UEFI Secure Boot was specified, everyone involved was, well, a touch naive. The basic security model of Secure Boot is that all the code that ends up running in a kernel-level privileged environment should be validated before execution - the firmware verifies the bootloader, the bootloader verifies the kernel, the kernel verifies any additional runtime loaded kernel code, and now we have a trusted environment to impose any other security policy we want. Obviously people might screw up, but the spec included a way to revoke any signed components that turned out not to be trustworthy: simply add the hash of the untrustworthy code to a variable, and then refuse to load anything with that hash even if it's signed with a trusted key.</p><p>Unfortunately, as it turns out, scale. Every Linux distribution that works in the Secure Boot ecosystem generates their own bootloader binaries, and each of them has a different hash. If there's a vulnerability identified in the source code for said bootloader, there's a large number of different binaries that need to be revoked. And, well, the storage available to store the variable containing all these hashes is limited. There's simply not enough space to add a new set of hashes every time it turns out that grub (a bootloader initially written for a simpler time when there was no boot security and which has several separate image parsers and also a font parser and look you know where this is going) has another mechanism for a hostile actor to cause it to execute arbitrary code, so another solution was needed.</p><p>And that solution is SBAT. The general concept behind SBAT is pretty straightforward. Every important component in the boot chain declares a security generation that's incorporated into the signed binary. When a vulnerability is identified and fixed, that generation is incremented. An update can then be pushed that defines a minimum generation - boot components will look at the next item in the chain, compare its name and generation number to the ones stored in a firmware variable, and decide whether or not to execute it based on that. Instead of having to revoke a large number of individual hashes, it becomes possible to push one update that simply says "Any version of grub with a security generation below this number is considered untrustworthy".</p><p>So why is this suddenly relevant? SBAT was developed collaboratively between the Linux community and Microsoft, and Microsoft chose to push a Windows update that told systems not to trust versions of grub with a security generation below a certain level. This was because those versions of grub had genuine security vulnerabilities that would allow an attacker to compromise the Windows secure boot chain, and we've seen real world examples of malware wanting to do that (<a href="https://media.defense.gov/2023/Jun/22/2003245723/-1/-1/0/CSI_BlackLotus_Mitigation_Guide.PDF">Black Lotus</a> did so using a vulnerability in the Windows bootloader, but a vulnerability in grub would be just as viable for this). Viewed purely from a security perspective, this was a legitimate thing to want to do.</p><p>(An aside: the "Something has gone seriously wrong" message that's associated with people having a bad time as a result of this update? That's a message from <a href="https://github.com/rhboot/shim/">shim</a>, not any Microsoft code. Shim pays attention to SBAT updates in order to avoid violating the security assumptions made by other bootloaders on the system, so even though it was Microsoft that pushed the SBAT update, it's the Linux bootloader that refuses to run old versions of grub as a result. This is absolutely working as intended)</p><p>The problem we've ended up in is that several Linux distributions had not shipped versions of grub with a newer security generation, and so those versions of grub are assumed to be insecure (it's worth noting that grub is signed by individual distributions, not Microsoft, so there's no externally introduced lag here). Microsoft's stated intention was that Windows Update would only apply the SBAT update to systems that were Windows-only, and any dual-boot setups would instead be left vulnerable to attack until the installed distro updated its grub and shipped an SBAT update itself. Unfortunately, as is now obvious, that didn't work as intended and at least some dual-boot setups applied the update and that distribution's Shim refused to boot that distribution's grub.</p><p>What's the summary? Microsoft (understandably) didn't want it to be possible to attack Windows by using a vulnerable version of grub that could be tricked into executing arbitrary code and then introduce a bootkit into the Windows kernel during boot. Microsoft did this by pushing a Windows Update that updated the SBAT variable to indicate that known-vulnerable versions of grub shouldn't be allowed to boot on those systems. The distribution-provided Shim first-stage bootloader read this variable, read the SBAT section from the installed copy of grub, realised these conflicted, and refused to boot grub with the "Something has gone seriously wrong" message. This update was not supposed to apply to dual-boot systems, but did anyway. Basically:</p><p>1) Microsoft applied an update to systems where that update shouldn't have been applied<br>2) Some Linux distros failed to update their grub code and SBAT security generation when exploitable security vulnerabilities were identified in grub</p><p>The outcome is that some people can't boot their systems. I think there's plenty of blame here. Microsoft should have done more testing to ensure that dual-boot setups could be identified accurately. But also distributions shipping signed bootloaders should make sure that they're updating those and updating the security generation to match, because otherwise they're shipping a vector that can be used to attack other operating systems and that's kind of a violation of the social contract around all of this.</p><p>It's unfortunate that the victims here are largely end users faced with a system that suddenly refuses to boot the OS they want to boot. That should never happen. I don't think asking arbitrary end users whether they want secure boot updates is likely to result in good outcomes, and while I vaguely tend towards UEFI Secure Boot not being something that benefits most end users it's also a thing you really don't want to discover you want after the fact so I have sympathy for it being default on, so I do sympathise with Microsoft's choices here, other than the failed attempt to avoid the update on dual boot systems.</p><p>Anyway. I was extremely involved in the implementation of this for Linux back in 2012 and wrote the first prototype of Shim (which is now a massively better bootloader maintained by a wider set of people and that I haven't touched in years), so if you want to blame an individual please do feel free to blame me. This is something that shouldn't have happened, and unless you're either Microsoft or a Linux distribution it's not your fault. I'm sorry.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A Ghidra extension for exporting parts of a program as object files (172 pts)]]></title>
            <link>https://github.com/boricj/ghidra-delinker-extension</link>
            <guid>41318133</guid>
            <pubDate>Thu, 22 Aug 2024 08:54:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/boricj/ghidra-delinker-extension">https://github.com/boricj/ghidra-delinker-extension</a>, See on <a href="https://news.ycombinator.com/item?id=41318133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Object file exporter extension for Ghidra</h2><a id="user-content-object-file-exporter-extension-for-ghidra" aria-label="Permalink: Object file exporter extension for Ghidra" href="#object-file-exporter-extension-for-ghidra"></a></p>
<p dir="auto">This Ghidra extension enables exporting parts of a program as object files. These object files have valid metadata (symbols, relocation tables…) and as such can be reused directly by a toolchain for further processing.</p>
<p dir="auto">Use-cases include:</p>
<ul dir="auto">
<li><a href="https://boricj.net/tenchu1/2024/05/31/part-11.html" rel="nofollow">Advanced binary patching</a>, by leveraging the linker to mend both original and modified parts together instead of doing this work by hand&nbsp;;</li>
<li><a href="https://boricj.net/atari-jaguar-sdk/2024/01/02/part-5.html" rel="nofollow">Software ports</a>, by isolating system-independent code from a program and replacing the rest&nbsp;;</li>
<li>Converting <a href="https://boricj.net/atari-jaguar-sdk/2023/12/18/part-3.html" rel="nofollow">programs</a> or object files from one file format to another&nbsp;;</li>
<li><a href="https://boricj.net/tenchu1/2024/03/11/part-5.html" rel="nofollow">Creating</a> <a href="https://boricj.net/tenchu1/2024/03/18/part-6.html" rel="nofollow">libraries</a>, by extracting parts of a program and reusing them in another context&nbsp;;</li>
<li>Decompilation projects, by splitting a program into multiple object files and reimplementing these <em>Ship of Theseus</em>-style&nbsp;;</li>
<li>…</li>
</ul>
<p dir="auto">Matrix of supported instruction set architectures and object files:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th></th>
<th>x86</th>
<th>MIPS</th>
</tr>
</thead>
<tbody>
<tr>
<td>COFF</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>ELF</td>
<td>✅</td>
<td>✅</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building (CLI)</h2><a id="user-content-building-cli" aria-label="Permalink: Building (CLI)" href="#building-cli"></a></p>
<ul dir="auto">
<li>Clone this repository&nbsp;;</li>
<li>Define the <code>GHIDRA_INSTALL_DIR</code> environment variable to point to your Ghidra installation directory&nbsp;;</li>
<li>Run <code>gradle buildExtension</code>.</li>
</ul>
<p dir="auto">The Ghidra extension archive will be created inside the <code>dist/</code> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ul dir="auto">
<li>Download the extension from the <a href="https://github.com/boricj/ghidra-delinker-extension/releases">releases page</a> or build it locally&nbsp;;</li>
<li>Install the extension in your Ghidra instance with <code>File &gt; Install Extensions…</code>&nbsp;;</li>
<li>Enable the <code>RelocationTableSynthesizedPlugin</code> plugin with <code>File &gt; Configure</code> inside a CodeBrowser window.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li>Select a set of addresses in the Listing view&nbsp;;</li>
<li>Run the <code>Relocation table synthesizer</code> analyzer (available in one-shot mode)&nbsp;;</li>
<li>Invoke a relocatable object file exporter with <code>File &gt; Export Program…</code></li>
</ol>
<p dir="auto">The reconstructed relocations can be viewed with <code>Window &gt; Relocation table (synthesized)</code>.</p>
<ul dir="auto">
<li><g-emoji alias="warning">⚠️</g-emoji> The <em>relocation table synthesizer</em> analyzer relies on a fully populated Ghidra database (with correctly declared symbols, data types and references) in order to work. <strong>Incorrect or missing information may lead to broken or undiscovered relocations</strong> during the analysis.</li>
<li><g-emoji alias="warning">⚠️</g-emoji> The object file exporters rely on the results of the <em>relocation table synthesizer</em> analyzer in order to work. When in doubt, <strong>run this analyzer right before exporting an object file</strong> to make sure the relocation table contents are up-to-date with the current state of the program.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How does it work?</h2><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">Object files are made of three parts:</p>
<ul dir="auto">
<li>Relocatable section bytes&nbsp;;</li>
<li>A symbol table&nbsp;;</li>
<li>A relocation table.</li>
</ul>
<p dir="auto">When a linker is invoked to generate an executable from a bunch of object files, it will:</p>
<ul dir="auto">
<li>Lay out their sections in memory&nbsp;;</li>
<li>Compute the addresses of the symbols in the virtual address space&nbsp;;</li>
<li>Apply the relocations based on the final addresses of the symbols onto the section bytes.</li>
</ul>
<p dir="auto">Normally the relocation table is discarded after this process, as well as the symbol table if debugging symbols aren't kept, leaving only the un-relocatable section bytes.
However, through careful analysis this data can be recreated, which allows us to then effectively <em>delink</em> the program back into object files.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hardware Virtualization (117 pts)]]></title>
            <link>https://www.haiku-os.org/blog/dalme/2024-08-19_gsoc_2024_hardware_virtualization_final_report/</link>
            <guid>41318033</guid>
            <pubDate>Thu, 22 Aug 2024 08:33:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.haiku-os.org/blog/dalme/2024-08-19_gsoc_2024_hardware_virtualization_final_report/">https://www.haiku-os.org/blog/dalme/2024-08-19_gsoc_2024_hardware_virtualization_final_report/</a>, See on <a href="https://news.ycombinator.com/item?id=41318033">Hacker News</a></p>
Couldn't get https://www.haiku-os.org/blog/dalme/2024-08-19_gsoc_2024_hardware_virtualization_final_report/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[SwiftUI for Mac 2024 (117 pts)]]></title>
            <link>https://troz.net/post/2024/swiftui-mac-2024/</link>
            <guid>41318000</guid>
            <pubDate>Thu, 22 Aug 2024 08:27:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://troz.net/post/2024/swiftui-mac-2024/">https://troz.net/post/2024/swiftui-mac-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=41318000">Hacker News</a></p>
Couldn't get https://troz.net/post/2024/swiftui-mac-2024/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Isaiah – open-source and self-hosted app to manage everything Docker (131 pts)]]></title>
            <link>https://github.com/will-moss/isaiah</link>
            <guid>41317988</guid>
            <pubDate>Thu, 22 Aug 2024 08:25:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/will-moss/isaiah">https://github.com/will-moss/isaiah</a>, See on <a href="https://news.ycombinator.com/item?id=41317988">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Isaiah</h2><a id="user-content-isaiah" aria-label="Permalink: Isaiah" href="#isaiah"></a></p>
    <p dir="auto">
      Self-hostable clone of lazydocker for the web.<br>Manage your Docker fleet with ease
    </p>
    <p dir="auto">
      <a href="#table-of-contents">Table of Contents</a> -
      <a href="#deployment-and-examples">Install</a> -
      <a href="#configuration">Configure</a>
    </p>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-1.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-1.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-2.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-2.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-3.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-3.png"></a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-4.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-4.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-5.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-5.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-6.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-6.png"></a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-7.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-7.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-8.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-8.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-9.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-9.png"></a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-10.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-10.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-11.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-11.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-12.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-12.png"></a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-13.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-13.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-14.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-14.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/will-moss/isaiah/blob/master/assets/CAPTURE-15.png"><img width="1604" src="https://github.com/will-moss/isaiah/raw/master/assets/CAPTURE-15.png"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#deployment-and-examples">Deployment and Examples</a>
<ul dir="auto">
<li><a href="#deploy-with-docker">Deploy with Docker</a></li>
<li><a href="#deploy-with-docker-compose">Deploy with Docker Compose</a></li>
<li><a href="#deploy-as-a-standalone-application">Deploy as a standalone application</a>
<ul dir="auto">
<li><a href="#using-an-existing-binary">Using an existing binary</a></li>
<li><a href="#building-the-binary-manually">Building the binary manually</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#multi-node-deployment">Multi-node deployment</a>
<ul dir="auto">
<li><a href="#general-information">General information</a></li>
<li><a href="#setup">Setup</a></li>
</ul>
</li>
<li><a href="#multi-host-deployment">Multi-host deployment</a>
<ul dir="auto">
<li><a href="#general-information-1">General information</a></li>
<li><a href="#setup-1">Setup</a></li>
</ul>
</li>
<li><a href="#forward-proxy-authentication--trusted-sso">Forward Proxy Authentication / Trusted SSO</a></li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#theming">Theming</a></li>
<li><a href="#troubleshoot">Troubleshoot</a></li>
<li><a href="#security">Security</a></li>
<li><a href="#disclaimer">Disclaimer</a></li>
<li><a href="#contribute">Contribute</a></li>
<li><a href="#credits">Credits</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">Isaiah is a self-hostable service that enables you to manage all your Docker resources on a remote server. It is an attempt at recreating the <a href="https://github.com/jesseduffield/lazydocker">lazydocker</a> command-line application from scratch, while making it available as a web application without compromising on the features.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Isaiah has all these features implemented :</p>
<ul dir="auto">
<li>For stacks :
<ul dir="auto">
<li>Bulk update</li>
<li>Up, Down, Pause, Unpause, Restart, Update</li>
<li>Create and Edit stacks using <code>docker-compose.yml</code> files in your browser</li>
<li>Inspect (live logs, <code>docker-compose.yml</code>, services)</li>
</ul>
</li>
<li>For containers :
<ul dir="auto">
<li>Bulk stop, Bulk remove, Prune</li>
<li>Remove, Pause, Unpause, Restart, Rename, Update, Edit, Open in browser</li>
<li>Open a shell inside the container (from your browser)</li>
<li>Inspect (live logs, stats, env, full configuration, top)</li>
</ul>
</li>
<li>For images :
<ul dir="auto">
<li>Prune</li>
<li>Remove</li>
<li>Run (create and start a container using the image)</li>
<li>Open on Docker Hub</li>
<li>Pull a new image (from Docker Hub)</li>
<li>Bulk pull all latest images (from Docker Hub)</li>
<li>Inspect (full configuration, layers)</li>
</ul>
</li>
<li>For volumes :
<ul dir="auto">
<li>Prune</li>
<li>Remove</li>
<li>Browse volume files (from your browser, via shell)</li>
<li>Inspect (full configuration)</li>
</ul>
</li>
<li>For networks :
<ul dir="auto">
<li>Prune</li>
<li>Remove</li>
<li>Inspect (full configuration)</li>
</ul>
</li>
<li>Built-in automatic Docker host discovery</li>
<li>Built-in authentication by master password (supplied raw or sha256-hashed)</li>
<li>Built-in authentication by forward proxy authentication headers (e.g. Authelia / Trusted SSO)</li>
<li>Built-in terminal emulator (with support for opening a shell on the server)</li>
<li>Responsive for Desktop, Tablet, and Mobile</li>
<li>Support for multiple layouts</li>
<li>Support for custom CSS theming (with variables for colors already defined)</li>
<li>Support for keyboard navigation</li>
<li>Support for mouse navigation</li>
<li>Support for search through Docker resources and container logs</li>
<li>Support for ascending and descending sort by any supported field</li>
<li>Support for customizable user settings (line-wrap, timestamps, prompt, etc.)</li>
<li>Support for custom Docker Host / Context.</li>
<li>Support for extensive configuration with <code>.env</code></li>
<li>Support for HTTP and HTTPS</li>
<li>Support for standalone / proxy / multi-node / multi-host deployment</li>
</ul>
<p dir="auto">On top of these, one may appreciate the following characteristics :</p>
<ul dir="auto">
<li>Written in Go (for the server) and Vanilla JS (for the client)</li>
<li>Holds in a ~4 MB single file executable</li>
<li>Holds in a ~4 MB Docker image</li>
<li>Works exclusively over Websocket, with very little bandwidth usage</li>
<li>Uses the official Docker SDK for 100% of the Docker features</li>
</ul>
<p dir="auto">For more information, read about <a href="#configuration">Configuration</a> and <a href="#deployment-and-examples">Deployment</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Deployment and Examples</h2><a id="user-content-deployment-and-examples" aria-label="Permalink: Deployment and Examples" href="#deployment-and-examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy with Docker</h3><a id="user-content-deploy-with-docker" aria-label="Permalink: Deploy with Docker" href="#deploy-with-docker"></a></p>
<p dir="auto">You can run Isaiah with Docker on the command line very quickly.</p>
<p dir="auto">You can use the following commands :</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create a .env file
touch .env

# Edit .env file ...

# Option 1 : Run Isaiah attached to the terminal (useful for debugging)
docker run \
  --env-file .env \
  -v /var/run/docker.sock:/var/run/docker.sock:ro \
  -p <YOUR-PORT-MAPPING> \
  mosswill/isaiah

# Option 2 : Run Isaiah as a daemon
docker run \
  -d \
  --env-file .env \
  -v /var/run/docker.sock:/var/run/docker.sock:ro \
  -p <YOUR-PORT-MAPPING> \
  mosswill/isaiah

# Option 3 : Quick run with default settings
docker run -v /var/run/docker.sock:/var/run/docker.sock:ro -p 3000:3000 mosswill/isaiah"><pre><span><span>#</span> Create a .env file</span>
touch .env

<span><span>#</span> Edit .env file ...</span>

<span><span>#</span> Option 1 : Run Isaiah attached to the terminal (useful for debugging)</span>
docker run \
  --env-file .env \
  -v /var/run/docker.sock:/var/run/docker.sock:ro \
  -p <span>&lt;</span>YOUR-PORT-MAPPING<span>&gt;</span> \
  mosswill/isaiah

<span><span>#</span> Option 2 : Run Isaiah as a daemon</span>
docker run \
  -d \
  --env-file .env \
  -v /var/run/docker.sock:/var/run/docker.sock:ro \
  -p <span>&lt;</span>YOUR-PORT-MAPPING<span>&gt;</span> \
  mosswill/isaiah

<span><span>#</span> Option 3 : Quick run with default settings</span>
docker run -v /var/run/docker.sock:/var/run/docker.sock:ro -p 3000:3000 mosswill/isaiah</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy with Docker Compose</h3><a id="user-content-deploy-with-docker-compose" aria-label="Permalink: Deploy with Docker Compose" href="#deploy-with-docker-compose"></a></p>
<p dir="auto">To help you get started quickly, multiple example <code>docker-compose</code> files are located in the <a href="https://github.com/will-moss/isaiah/blob/master/examples">"examples/"</a> directory.</p>
<p dir="auto">Here's a description of every example :</p>
<ul dir="auto">
<li>
<p dir="auto"><code>docker-compose.simple.yml</code>: Run Isaiah as a front-facing service on port 80., with environment variables supplied in the <code>docker-compose</code> file directly.</p>
</li>
<li>
<p dir="auto"><code>docker-compose.volume.yml</code>: Run Isaiah as a front-facing service on port 80, with environment variables supplied as a <code>.env</code> file mounted as a volume.</p>
</li>
<li>
<p dir="auto"><code>docker-compose.ssl.yml</code>:  Run Isaiah as a front-facing service on port 443, listening for HTTPS requests, with certificate and private key provided as mounted volumes.</p>
</li>
<li>
<p dir="auto"><code>docker-compose.proxy.yml</code>: A full setup with Isaiah running on port 80, behind a proxy listening on port 443.</p>
</li>
<li>
<p dir="auto"><code>docker-compose.traefik.yml</code>: A sample setup with Isaiah running on port 80, behind a Traefik proxy listening on port 443.</p>
</li>
<li>
<p dir="auto"><code>docker-compose.agent.yml</code>: A sample setup with Isaiah operating as an Agent in a multi-node deployment.</p>
</li>
<li>
<p dir="auto"><code>docker-compose.host.yml</code>: A sample setup with Isaiah expecting to communicate with other hosts in a multi-host deployment.</p>
</li>
</ul>
<p dir="auto">When your <code>docker-compose</code> file is on point, you can use the following commands :</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Option 1 : Run Isaiah in the current terminal (useful for debugging)
docker-compose up

# Option 2 : Run Isaiah in a detached terminal (most common)
docker-compose up -d

# Show the logs written by Isaiah (useful for debugging)
docker logs <NAME-OF-YOUR-CONTAINER>"><pre><span><span>#</span> Option 1 : Run Isaiah in the current terminal (useful for debugging)</span>
docker-compose up

<span><span>#</span> Option 2 : Run Isaiah in a detached terminal (most common)</span>
docker-compose up -d

<span><span>#</span> Show the logs written by Isaiah (useful for debugging)</span>
docker logs <span>&lt;</span>NAME-OF-YOUR-CONTAINER<span>&gt;</span></pre></div>
<blockquote>
<p dir="auto">Warning : Always make sure that your Docker Unix socket is mounted, else Isaiah won't be able to communicate with the Docker API.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy as a standalone application</h3><a id="user-content-deploy-as-a-standalone-application" aria-label="Permalink: Deploy as a standalone application" href="#deploy-as-a-standalone-application"></a></p>
<p dir="auto">You can deploy Isaiah as a standalone application, either by downloading an existing binary that fits your architecture,
or by building the binary yourself on your machine.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using an existing binary</h4><a id="user-content-using-an-existing-binary" aria-label="Permalink: Using an existing binary" href="#using-an-existing-binary"></a></p>
<p dir="auto">An install script was created to help you install Isaiah in one line, from your terminal :</p>
<blockquote>
<p dir="auto">As always, check the content of every file you pipe in bash</p>
</blockquote>
<div dir="auto" data-snippet-clipboard-copy-content="curl https://raw.githubusercontent.com/will-moss/isaiah/master/scripts/remote-install.sh | bash"><pre>curl https://raw.githubusercontent.com/will-moss/isaiah/master/scripts/remote-install.sh <span>|</span> bash</pre></div>
<p dir="auto">This script will try to automatically download a binary that matches your operating system and architecture, and put it
in your <code>/usr/[local/]bin/</code> directory to ease running it. Later on, you can run :</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create a new .env file
touch .env

# Edit .env file ...

# Run Isaiah
isaiah"><pre><span><span>#</span> Create a new .env file</span>
touch .env

<span><span>#</span> Edit .env file ...</span>

<span><span>#</span> Run Isaiah</span>
isaiah</pre></div>
<p dir="auto">In case you feel uncomfortable running the install script, you can head to the <code>Releases</code>, find the binary that meets your system, and install it yourself.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Building the binary manually</h4><a id="user-content-building-the-binary-manually" aria-label="Permalink: Building the binary manually" href="#building-the-binary-manually"></a></p>
<p dir="auto">In this case, make sure that your system meets the following requirements :</p>
<ul dir="auto">
<li>You have Go 1.21 installed</li>
<li>You have Node 20+ installed along with npm and npx</li>
</ul>
<p dir="auto">When all the prerequisites are met, you can run the following commands in your terminal :</p>
<blockquote>
<p dir="auto">As always, check the content of everything you run inside your terminal</p>
</blockquote>
<div dir="auto" data-snippet-clipboard-copy-content="# Retrieve the code
git clone https://github.com/will-moss/isaiah
cd isaiah

# Run the local install script
./scripts/local-install.sh

# Move anywhere else, and create a dedicated directory
cd ~
mkdir isaiah-config
cd isaiah-config

# Create a new .env file
touch .env

# Edit .env file ...

# Option 1 : Run Isaiah in the current terminal
isaiah

# Option 2 : Run Isaiah as a background process
isaiah &amp;

# Option 3 : Run Isaiah using screen
screen -S isaiah
isaiah
<CTRL+A> <D>

# Optional : Remove the cloned repository
# cd <back to the cloned repository>
# rm -rf ./isaiah"><pre><span><span>#</span> Retrieve the code</span>
git clone https://github.com/will-moss/isaiah
<span>cd</span> isaiah

<span><span>#</span> Run the local install script</span>
./scripts/local-install.sh

<span><span>#</span> Move anywhere else, and create a dedicated directory</span>
<span>cd</span> <span>~</span>
mkdir isaiah-config
<span>cd</span> isaiah-config

<span><span>#</span> Create a new .env file</span>
touch .env

<span><span>#</span> Edit .env file ...</span>

<span><span>#</span> Option 1 : Run Isaiah in the current terminal</span>
isaiah

<span><span>#</span> Option 2 : Run Isaiah as a background process</span>
isaiah <span>&amp;</span>

<span><span>#</span> Option 3 : Run Isaiah using screen</span>
screen -S isaiah
isaiah
<span>&lt;</span>CTRL+A<span>&gt;</span> <span>&lt;</span>D<span>&gt;</span>

<span><span>#</span> Optional : Remove the cloned repository</span>
<span><span>#</span> cd &lt;back to the cloned repository&gt;</span>
<span><span>#</span> rm -rf ./isaiah</span></pre></div>
<p dir="auto">The local install script will try to perform a production build on your machine, and move <code>isaiah</code> to your <code>/usr/[local/]bin/</code> directory
to ease running it. In more details, the following actions are performed :</p>
<ul dir="auto">
<li>Local install of Babel, LightningCSS, Less, and Terser</li>
<li>Prefixing, Transpilation, and Minification of CSS and JS assets</li>
<li>Building of the Go source code into a single-file executable (with CSS and JS embed)</li>
<li>Cleaning of the artifacts generated during the previous steps</li>
<li>Removal of the previous <code>isaiah</code> executable, if any in <code>/usr/[local/]bin/</code></li>
<li>Moving the new <code>isaiah</code> executable in <code>/usr/[local/]bin</code> with <code>755</code> permissions.</li>
</ul>
<p dir="auto">If you encounter any issue during this process, please feel free to tweak the install script or reach out by opening an issue.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Multi-node deployment</h2><a id="user-content-multi-node-deployment" aria-label="Permalink: Multi-node deployment" href="#multi-node-deployment"></a></p>
<p dir="auto">Using Isaiah, you can manage multiple nodes with their own distinct Docker resources from a single dashboard.</p>
<p dir="auto">Before delving into that part, please get familiar with the general information below.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">General information</h3><a id="user-content-general-information" aria-label="Permalink: General information" href="#general-information"></a></p>
<p dir="auto">You may find these information useful during your setup and reading :</p>
<ul dir="auto">
<li>Isaiah distinguishes two types of nodes : <code>Master</code> and <code>Agent</code>.</li>
<li>The word <code>node</code> refers to any machine (virtual or not) holding Docker resources.</li>
<li>The <code>Master</code> node has three responsabilities :
<ul dir="auto">
<li>Serving the web interface.</li>
<li>Managing the Docker resources inside the environment on which it is already installed.</li>
<li>Acting as a central proxy between the client (you) and the remote Agent nodes.</li>
</ul>
</li>
<li>The <code>Master</code> node has the following characteristics :
<ul dir="auto">
<li>There should be only one Master node in a multi-node deployment.</li>
<li>The Master node should be the only part of your deployment that is publicly exposed on the network.</li>
</ul>
</li>
<li>The <code>Agent</code> nodes have the following characteristics :
<ul dir="auto">
<li>They are headless instances of Isaiah, and they can't exist without a Master node.</li>
<li>As with the Master node, they have their own authentication if you don't disable it explicitly.</li>
<li>On startup, they perform registration with their Master node using as a Websocket client</li>
<li>For as long as the Master node is alive, a Websocket connection remains established between them.</li>
<li>The Agent node should never be publicly exposed on the network.</li>
<li>The Agent node never communicates with the client (you). Everything remains between the nodes.</li>
<li>There is no limit to how many Agent nodes can connect to a Master node.</li>
</ul>
</li>
</ul>
<p dir="auto">In other words, one <code>Master</code> acts as a <code>Proxy</code> between the <code>Client</code> and the <code>Agents</code>.<br>
For example, when a <code>Client</code> wants to stop a Docker container inside an <code>Agent</code>, the <code>Client</code> first requests it from <code>Master</code>.
Then, <code>Master</code> forwards it to the designated <code>Agent</code>.
When the <code>Agent</code> has finished, they reply to <code>Master</code>, and <code>Master</code> forwards that response to the initial <code>Client</code>.</p>
<p dir="auto">Schematically, it looks like this :</p>
<ul dir="auto">
<li>Client ------------&gt; Master : Stop container C-123 on Agent AG-777</li>
<li>Master ------------&gt; Agent  : Stop container C-123</li>
<li>Agent  ------------&gt; Master : Container C-123 was stopped</li>
<li>Master ------------&gt; Client : Container C-123 was stopped on Agent AG-777</li>
</ul>
<p dir="auto">Now that we understand how everything works, let's see how to set up a multi-node deployment.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setup</h3><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">First, please ensure the following :</p>
<ul dir="auto">
<li>Your <code>Master</code> node is running, exposed on the network, and available in your web browser</li>
<li>Your <code>Agent</code> node has Isaiah installed and configured with the following settings :
<ul dir="auto">
<li><code>SERVER_ROLE</code> equal to <code>Agent</code></li>
<li><code>MASTER_HOST</code> configured to reach the <code>Master</code> node</li>
<li><code>MASTER_SECRET</code> equal to the <code>AUTHENTICATION_SECRET</code> setting on the <code>Master</code> node, or empty when authentication is disabled</li>
<li><code>AGENT_NAME</code> equal to a unique string of your choice</li>
</ul>
</li>
</ul>
<p dir="auto">Then, launch Isaiah on each <code>Agent</code> node, and you should see logs indicating whether connection with <code>Master</code> was established. Eventually, you will see <code>Master</code> or <code>The name of your agent</code> in the lower right corner of your screen as agents register.</p>
<p dir="auto">If encounter any issue, please read the <a href="#troubleshoot">Troubleshoot</a> section.</p>
<blockquote>
<p dir="auto">You may want to note that you don't need to expose ports on the machine / Docker container running Isaiah when it is configured as an Agent.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Multi-host deployment</h2><a id="user-content-multi-host-deployment" aria-label="Permalink: Multi-host deployment" href="#multi-host-deployment"></a></p>
<p dir="auto">Using Isaiah, you can manage multiple hosts with their own distinct Docker resources from a single dashboard.</p>
<p dir="auto">Before delving into that part, please get familiar with the general information below.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">General information</h3><a id="user-content-general-information-1" aria-label="Permalink: General information" href="#general-information-1"></a></p>
<p dir="auto">The big difference between multi-node and multi-host deployments is that you won't need to install Isaiah on every single node
if you are using multi-host. In this setup, Isaiah is installed only on one server, and communicates with other Docker hosts
directly over TCP / Unix sockets. It makes it easier to manage multiple remote Docker environments without having to setup Isaiah
on all of them.</p>
<p dir="auto">Please note that, in a multi-host setup, there must be a direct access between the main host (where Isaiah is running)
and the other ones. Usually, they should be on the same network, or visible through a secured gateway / VPN / filesystem mount.</p>
<p dir="auto">Let's see how to set up a multi-host deployment.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setup</h3><a id="user-content-setup-1" aria-label="Permalink: Setup" href="#setup-1"></a></p>
<p dir="auto">In order to help you get started, a <a href="https://github.com/will-moss/isaiah/blob/master/app/sample.docker_hosts">sample file</a> was created.</p>
<p dir="auto">First, please ensure the following :</p>
<ul dir="auto">
<li>Your <code>Master</code> host is running, exposed on the network, and available in your web browser</li>
<li>Your <code>Master</code> host has the setting <code>MULTI_HOST_ENABLED</code> set to <code>true</code>.</li>
<li>Your <code>Master</code> host has access to the other Docker hosts over TCP / Unix socket.</li>
</ul>
<p dir="auto">Second, please create a <code>docker_hosts</code> file next to Isaiah's executable, using the sample file cited above:</p>
<ul dir="auto">
<li>Every line should contain two strings separated by a single space.</li>
<li>The first string is the name of your host, and the second string is the path to reach it.</li>
<li>The path to your host should look like this : [PROTOCOL]://[URI]</li>
<li>Example 1 : Local unix:///var/run/docker.sock</li>
<li>Example 2 : Remote tcp://my-domain.tld:4382</li>
</ul>
<blockquote>
<p dir="auto">If you're using Docker, you can mount the file at the root of the filesystem, as in :<br>
<code>docker ... -v my_docker_hosts:/docker_hosts ...</code></p>
</blockquote>
<p dir="auto">Finally, launch Isaiah on the Master host, and you should see logs indicating whether connection with remote hosts was established.
Eventually, you will see <code>Master</code> with <code>The name of your host</code> in the lower right corner of your screen.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Forward Proxy Authentication / Trusted SSO</h2><a id="user-content-forward-proxy-authentication--trusted-sso" aria-label="Permalink: Forward Proxy Authentication / Trusted SSO" href="#forward-proxy-authentication--trusted-sso"></a></p>
<p dir="auto">If you wish to deploy Isaiah behind a secure proxy or authentication portal, you must configure Forward Proxy Authentication.</p>
<p dir="auto">This will enable you to :</p>
<ul dir="auto">
<li>Log in, once and for all, into your authentication portal.</li>
<li>Connect to Isaiah without having to type your <code>AUTHENTICATION_SECRET</code> every time.</li>
<li>Protect Isaiah using your authentication proxy rather than the current mechanism (cleartext / hashed password).</li>
<li>Manage the access to Isaiah from your authentication portal rather than through your <code>.env</code> configuration.</li>
</ul>
<p dir="auto">Before proceeding, please ensure the following :</p>
<ul dir="auto">
<li>Your proxy supports HTTP/2 and Websockets.</li>
<li>Your proxy can communicate with Isaiah on the network.</li>
<li>Your proxy forwards authentication headers to Isaiah (but not to the browser).</li>
</ul>
<blockquote>
  <br>
  For example, if you're using Nginx Proxy Manager (NPM), you should do the following :
  <ul dir="auto">
    <li>In the tab "Details"</li>
    <ul dir="auto">
      <li>Tick the box "Websockets support"</li>
      <li>Tick the box "HTTP/2 support"</li>
      <li>Tick the box "Block common exploits"</li>
      <li>Tick the box "Force SSL"</li>
   </ul>
   <br>
   <li>In the tab "Advanced"</li>
   <ul dir="auto">
      <li>In your custom location block, add the lines :</li>
      <ul dir="auto">
        <li>proxy_set_header Upgrade $http_upgrade;</li>
        <li>proxy_set_header Connection "upgrade";</li>
      </ul>
    </ul>
  </ul>
  <br>
</blockquote>
<p dir="auto">Then, configure Isaiah using the following variables :</p>
<ul dir="auto">
<li>Set <code>FORWARD_PROXY_AUTHENTICATION_ENABLED</code> to <code>true</code>.</li>
<li>Set <code>FORWARD_PROXY_AUTHENTICATION_HEADER_KEY</code> to the name of the forwarded authentication header your proxy sends to Isaiah.</li>
<li>Set <code>FORWARD_PROXY_AUTHENTICATION_HEADER_VALUE</code> to the value of the header that Isaiah should expect (or use <code>*</code> if all values are accepted).</li>
</ul>
<blockquote>
<p dir="auto">By default, Isaiah is configured to work with Authelia out of the box. Hence, you can just set <code>FORWARD_PROXY_AUTHENTICATION_ENABLED</code> to <code>true</code> and be done with it.</p>
</blockquote>
<p dir="auto">If everything was properly set up, you will encounter the following flow :</p>
<ul dir="auto">
<li>Navigate to <code>isaiah.your-domain.tld</code>.</li>
<li>Get redirected to <code>authentication-portal.your-domain.tld</code>.</li>
<li>Fill in your credentials.</li>
<li>Authentication was successful.</li>
<li>Get redirected to <code>isaiah.your-domain.tld</code>.</li>
<li>Isaiah <strong>does not</strong> prompt you for the password, you're automatically logged in.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">To run Isaiah, you will need to set the following environment variables in a <code>.env</code> file located next to your executable :</p>
<blockquote>
<p dir="auto"><strong>Note :</strong> Regular environment variables provided on the commandline work too</p>
</blockquote>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SSL_ENABLED</code></td>
<td><code>boolean</code></td>
<td>Whether HTTPS should be used in place of HTTP. When configured, Isaiah will look for <code>certificate.pem</code> and <code>key.pem</code> next to the executable for configuring SSL. Note that if Isaiah is behind a proxy that already handles SSL, this should be set to <code>false</code>.</td>
<td>False</td>
</tr>
<tr>
<td><code>SERVER_PORT</code></td>
<td><code>integer</code></td>
<td>The port Isaiah listens on.</td>
<td>3000</td>
</tr>
<tr>
<td><code>SERVER_MAX_READ_SIZE</code></td>
<td><code>integer</code></td>
<td>The maximum size (in bytes) per message that Isaiah will accept over Websocket. Note that, in a multi-node deployment, you may need to incrase the value of that setting. (Shouldn't be modified, unless your server randomly restarts the Websocket session for no obvious reason)</td>
<td>100000</td>
</tr>
<tr>
<td><code>AUTHENTICATION_ENABLED</code></td>
<td><code>boolean</code></td>
<td>Whether a password is required to access Isaiah. (Recommended)</td>
<td>True</td>
</tr>
<tr>
<td><code>AUTHENTICATION_SECRET</code></td>
<td><code>string</code></td>
<td>The master password used to secure your Isaiah instance against malicious actors.</td>
<td>one-very-long-and-mysterious-secret</td>
</tr>
<tr>
<td><code>AUTHENTICATION_HASH</code></td>
<td><code>string</code></td>
<td>The master password's hash (sha256 format) used to secure your Isaiah instance against malicious actors. Use this setting instead of <code>AUTHENTICATION_SECRET</code> if you feel uncomfortable providing a cleartext password.</td>
<td>Empty</td>
</tr>
<tr>
<td><code>DISPLAY_CONFIRMATIONS</code></td>
<td><code>boolean</code></td>
<td>Whether the web interface should display a confirmation message after every succesful operation.</td>
<td>True</td>
</tr>
<tr>
<td><code>TABS_ENABLED</code></td>
<td><code>string</code></td>
<td>Comma-separated list of tabs to display in the interface. (Case-insensitive) (Available: Stacks, Containers, Images, Volumes, Networks)</td>
<td>stacks,containers,images,volumes,networks</td>
</tr>
<tr>
<td><code>COLUMNS_CONTAINERS</code></td>
<td><code>string</code></td>
<td>Comma-separated list of fields to display in the <code>Containers</code> panel. (Case-sensitive) (Available: ID, State, ExitCode, Name, Image, Created)</td>
<td>State,ExitCode,Name,Image</td>
</tr>
<tr>
<td><code>COLUMNS_IMAGES</code></td>
<td><code>string</code></td>
<td>Comma-separated list of fields to display in the <code>Images</code> panel. (Case-sensitive) (Available: ID, Name, Version, Size)</td>
<td>Name,Version,Size</td>
</tr>
<tr>
<td><code>COLUMNS_VOLUMES</code></td>
<td><code>string</code></td>
<td>Comma-separated list of fields to display in the <code>Volumes</code> panel. (Case-sensitive) (Available: Name, Driver, MountPoint)</td>
<td>Driver,Name</td>
</tr>
<tr>
<td><code>COLUMNS_NETWORKS</code></td>
<td><code>string</code></td>
<td>Comma-separated list of fields to display in the <code>Networks</code> panel. (Case-sensitive) (Available: ID, Name, Driver)</td>
<td>Driver,Name</td>
</tr>
<tr>
<td><code>COLUMNS_STACKS</code></td>
<td><code>string</code></td>
<td>Comma-separated list of fields to display in the <code>Stacks</code> panel. (Case-sensitive) (Available: Name, Status)</td>
<td>Status,Name</td>
</tr>
<tr>
<td><code>SORTBY_CONTAINERS</code></td>
<td><code>string</code></td>
<td>Field used to sort the rows in the <code>Containers</code> panel. (Case-sensitive) (Available: ID, State, ExitCode, Name, Image, Created)</td>
<td>Empty</td>
</tr>
<tr>
<td><code>SORTBY_IMAGES</code></td>
<td><code>string</code></td>
<td>Field used to sort the rows in the <code>Images</code> panel. (Case-sensitive) (Available: ID, Name, Version, Size)</td>
<td>Empty</td>
</tr>
<tr>
<td><code>SORTBY_VOLUMES</code></td>
<td><code>string</code></td>
<td>Field used to sort the rows in the <code>Volumes</code> panel. (Case-sensitive) (Available: Name, Driver, MountPoint)</td>
<td>Empty</td>
</tr>
<tr>
<td><code>SORTBY_NETWORKS</code></td>
<td><code>string</code></td>
<td>Field used to sort the rows in the <code>Networks</code> panel. (Case-sensitive) (Available: Id, Name, Driver)</td>
<td>Empty</td>
</tr>
<tr>
<td><code>SORTBY_STACKS</code></td>
<td><code>string</code></td>
<td>Field used to sort the rows in the <code>Stacks</code> panel. (Case-sensitive) (Available: Name, Status)</td>
<td>Empty</td>
</tr>
<tr>
<td><code>CONTAINER_HEALTH_STYLE</code></td>
<td><code>string</code></td>
<td>Style used to display the containers' health state. (Available: long, short, icon)</td>
<td>long</td>
</tr>
<tr>
<td><code>CONTAINER_LOGS_TAIL</code></td>
<td><code>integer</code></td>
<td>Number of lines to retrieve when requesting the last container logs</td>
<td>50</td>
</tr>
<tr>
<td><code>CONTAINER_LOGS_SINCE</code></td>
<td><code>string</code></td>
<td>The amount of time from now to use for retrieving the last container logs</td>
<td>60m</td>
</tr>
<tr>
<td><code>STACKS_DIRECTORY</code></td>
<td><code>string</code></td>
<td>The path to the directory that will be used to store the <code>docker-compose.yml</code> files generated while creating and editing stacks. It must be a valid path to an existing and writable directory.</td>
<td><code>.</code> (current directory)</td>
</tr>
<tr>
<td><code>TTY_SERVER_COMMAND</code></td>
<td><code>string</code></td>
<td>The command used to spawn a new shell inside the server where Isaiah is running</td>
<td><code>/bin/sh -i</code></td>
</tr>
<tr>
<td><code>TTY_CONTAINER_COMMAND</code></td>
<td><code>string</code></td>
<td>The command used to spawn a new shell inside the containers that Isaiah manages</td>
<td><code>/bin/sh -c eval $(grep ^$(id -un): /etc/passwd | cut -d : -f 7-) -i</code></td>
</tr>
<tr>
<td><code>CUSTOM_DOCKER_HOST</code></td>
<td><code>string</code></td>
<td>The host to use in place of the one defined by the DOCKER_HOST default variable</td>
<td>Empty</td>
</tr>
<tr>
<td><code>CUSTOM_DOCKER_CONTEXT</code></td>
<td><code>string</code></td>
<td>The Docker context to use in place of the current Docker context set on the system</td>
<td>Empty</td>
</tr>
<tr>
<td><code>SKIP_VERIFICATIONS</code></td>
<td><code>boolean</code></td>
<td>Whether Isaiah should skip startup verification checks before running the HTTP(S) server. (Not recommended)</td>
<td>False</td>
</tr>
<tr>
<td><code>SERVER_ROLE</code></td>
<td><code>string</code></td>
<td>For multi-node deployments only. The role of the current instance of Isaiah. Can be either <code>Master</code> or <code>Agent</code> and is case-sensitive.</td>
<td>Master</td>
</tr>
<tr>
<td><code>MASTER_HOST</code></td>
<td><code>string</code></td>
<td>For multi-node deployments only. The host used to reach the Master node, specifying the IP address or the hostname, and the port if applicable (e.g. my-server.tld:3000).</td>
<td>Empty</td>
</tr>
<tr>
<td><code>MASTER_SECRET</code></td>
<td><code>string</code></td>
<td>For multi-node deployments only. The secret password used to authenticate on the Master node. Note that it should equal the <code>AUTHENTICATION_SECRET</code> setting on the Master node.</td>
<td>Empty</td>
</tr>
<tr>
<td><code>AGENT_NAME</code></td>
<td><code>string</code></td>
<td>For multi-node deployments only. The name associated with the Agent node as it is displayed on the web interface. It should be unique for each Agent.</td>
<td>Empty</td>
</tr>
<tr>
<td><code>MULTI_HOST_ENABLED</code></td>
<td><code>boolean</code></td>
<td>Whether Isaiah should be run in multi-host mode. When enabled, make sure to have your <code>docker_hosts</code> file next to the executable.</td>
<td>False</td>
</tr>
<tr>
<td><code>FORWARD_PROXY_AUTHENTICATION_ENABLED</code></td>
<td><code>boolean</code></td>
<td>Whether Isaiah should accept authentication headers from a forward proxy.</td>
<td>False</td>
</tr>
<tr>
<td><code>FORWARD_PROXY_AUTHENTICATION_HEADER_KEY</code></td>
<td><code>string</code></td>
<td>The name of the authentication header sent by the forward proxy after a succesful authentication.</td>
<td>Remote-User</td>
</tr>
<tr>
<td><code>FORWARD_PROXY_AUTHENTICATION_HEADER_VALUE</code></td>
<td><code>string</code></td>
<td>The value accepted by Isaiah for the authentication header. Using <code>*</code> means that all values are accepted (except emptiness). This parameter can be used to enforce that only a specific user or group can access Isaiah (e.g. <code>admins</code> or <code>john</code>).</td>
<td>*</td>
</tr>
<tr>
<td><code>CLIENT_PREFERENCE_XXX</code></td>
<td><code>string</code></td>
<td>Please read <a href="#the-web-interface-does-not-save-my-preferences">this troubleshooting paragraph</a>. These settings enable you to define your client preferences on the server, for when your browser can't use the <code>localStorage</code> due to limitations, or private browsing.</td>
<td>Empty</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto"><strong>Note :</strong> Boolean values are case-insensitive, and can be represented via "ON" / "OFF" / "TRUE" / "FALSE" / 0 / 1.</p>
</blockquote>
<blockquote>
<p dir="auto"><strong>Note :</strong> To sort rows in reverse using the <code>SORTBY_</code> parameters, prepend your field with the minus symbol, as in <code>-Name</code></p>
</blockquote>
<blockquote>
<p dir="auto"><strong>Note :</strong> Use either <code>AUTHENTICATION_SECRET</code> or <code>AUTHENTICATION_HASH</code> but not both at the same time.</p>
</blockquote>
<blockquote>
<p dir="auto"><strong>Note</strong> : You can generate a sha256 hash using an online tool, or using the following commands :
<strong>On OSX</strong> : <code>echo -n your-secret | shasum -a 256</code>
<strong>On Linux</strong> : <code>echo -n your-secret | sha256sum</code></p>
</blockquote>
<p dir="auto">Additionally, once Isaiah is fully set up and running, you can open the Parameters Manager by pressing the <code>X</code> key.
Using this interface, you can toggle the following options based on your preferences :</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>enableMenuPrompt</code></td>
<td>Whether an extra prompt should warn you before trying to stop / pause / restart a Docker container.</td>
</tr>
<tr>
<td><code>enableLogLinesWrap</code></td>
<td>Whether log lines streamed from Docker containers should be wrapped (as opposed to extend beyond your screen).</td>
</tr>
<tr>
<td><code>enableTimestampDisplay</code></td>
<td>Whether log lines' timestamps coming from Docker containers should be displayed.</td>
</tr>
<tr>
<td><code>enableOverviewOnLaunch</code></td>
<td>Whether an overview panel should show first before anything when launching Isaiah in your browser.</td>
</tr>
<tr>
<td><code>enableLogLinesStrippedBackground</code></td>
<td>Whether alternated log lines should have a brighter background to enhance readability.</td>
</tr>
<tr>
<td><code>enableJumpFuzzySearch</code></td>
<td>Whether, in Jump mode, fuzzy search should be used, as opposed to default substring search.</td>
</tr>
<tr>
<td><code>enableSyntaxHightlight</code></td>
<td>Whether syntax highlighting should be enabled (when viewing docker-compose.yml files).</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto">Note : You must have Isaiah open in your browser and be authenticated to access these options. Once set up, these options will be saved to your localStorage.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Theming</h2><a id="user-content-theming" aria-label="Permalink: Theming" href="#theming"></a></p>
<p dir="auto">You can customize Isaiah's web interface using your own custom CSS. At runtime, Isaiah will look for a file named <code>custom.css</code> right next to the executable.
If this file exists, it will be loaded in your browser and it will override any existing CSS rule.</p>
<p dir="auto">In order to help you get started, a <a href="https://github.com/will-moss/isaiah/blob/master/app/sample.custom.css">sample file</a> was created.
It shows how to modify the CSS variables responsible for the colors of the interface. (All the values are the ones used by default)
You can copy that file, update it, and rename it to <code>custom.css</code>.</p>
<p dir="auto">If you're using Docker, you should mount a <code>custom.css</code> file at the root of your container's filesystem.
Example : <code>docker ... -v my-custom.css:/custom.css ...</code></p>
<p dir="auto">Finally, you will find below a table that describes what each CSS color variable means :</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>color-terminal-background</code></td>
<td>Background of the interface</td>
</tr>
<tr>
<td><code>color-terminal-base</code></td>
<td>Texts of the interface</td>
</tr>
<tr>
<td><code>color-terminal-accent</code></td>
<td>Elements that are interactive or must catch the attention</td>
</tr>
<tr>
<td><code>color-terminal-accent-selected</code></td>
<td>Panel's title when the panel is in focus</td>
</tr>
<tr>
<td><code>color-terminal-hover</code></td>
<td>Panel's rows that are in focus / hover</td>
</tr>
<tr>
<td><code>color-terminal-border</code></td>
<td>Panels' borders color</td>
</tr>
<tr>
<td><code>color-terminal-danger</code></td>
<td>The color used to convey danger / failure</td>
</tr>
<tr>
<td><code>color-terminal-warning</code></td>
<td>Connection indicator when connection is lost</td>
</tr>
<tr>
<td><code>color-terminal-accent-alternative</code></td>
<td>Connection indicator when connection is established</td>
</tr>
<tr>
<td><code>color-terminal-log-row-alternative</code></td>
<td>The color used as background for each odd row in the logs tab</td>
</tr>
<tr>
<td><code>color-terminal-json-key</code></td>
<td>The color used to distinguish keys from values in the inspector when displaying a long configuration</td>
</tr>
<tr>
<td><code>color-terminal-json-value</code></td>
<td>The color used to distinguish values from keys in the inspector when displaying a long configuration</td>
</tr>
<tr>
<td><code>color-terminal-cell-failure</code></td>
<td>Container health state when exited</td>
</tr>
<tr>
<td><code>color-terminal-cell-success</code></td>
<td>Container health state when running</td>
</tr>
<tr>
<td><code>color-terminal-cell-paused</code></td>
<td>Container health state when paused</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">On a side note, creating custom layouts using only CSS isn't implemented yet as it requires interaction with Javascript.
That said, implementing this feature should be quick and simple since the way layouts are managed currently is already modular.</p>
<p dir="auto">Ultimately, please note that Isaiah already comes with three themes : dawn, moon, and the default one.
The first two themes are based on Rosé Pine, and new themes may be implemented later.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshoot</h2><a id="user-content-troubleshoot" aria-label="Permalink: Troubleshoot" href="#troubleshoot"></a></p>
<p dir="auto">Should you encounter any issue running Isaiah, please refer to the following common problems with their solutions.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Isaiah is unreachable over HTTP / HTTPS</h4><a id="user-content-isaiah-is-unreachable-over-http--https" aria-label="Permalink: Isaiah is unreachable over HTTP / HTTPS" href="#isaiah-is-unreachable-over-http--https"></a></p>
<p dir="auto">Please make sure that the following requirements are met :</p>
<ul dir="auto">
<li>
<p dir="auto">If Isaiah runs as a standalone application without proxy :</p>
<ul dir="auto">
<li>Make sure your server / firewall accepts incoming connections on Isaiah's port.</li>
<li>Make sure your DNS configuration is correct. (Usually, such record should suffice : <code>A isaiah XXX.XXX.XXX.XXX</code> for <code>https://isaiah.your-server-tld</code>)</li>
<li>Make sure your <code>.env</code> file is well configured according to the <a href="#configuration">Configuration</a> section.</li>
</ul>
</li>
<li>
<p dir="auto">If Isaiah runs on Docker :</p>
<ul dir="auto">
<li>Perform the previous (standalone) verifications first.</li>
<li>Make sure you mounted your server's Docker Unix socket onto the container that runs Isaiah (/var/run/docker.sock)</li>
<li>Make sure your Docker container is accessible remotely</li>
</ul>
</li>
<li>
<p dir="auto">If Isaiah runs behind a proxy :</p>
<ul dir="auto">
<li>Perform the previous (standalone) verifications first.</li>
<li>Make sure that <code>SERVER_PORT</code> (Isaiah's port) are well set in <code>.env</code>.</li>
<li>Check your proxy forwarding rules.</li>
</ul>
</li>
</ul>
<p dir="auto">In any case, the crucial part is <a href="#configuration">Configuration</a> and making sure your Docker / Proxy setup is correct as well.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">The emulated shell behaves unconsistently or displays unexpected characters</h4><a id="user-content-the-emulated-shell-behaves-unconsistently-or-displays-unexpected-characters" aria-label="Permalink: The emulated shell behaves unconsistently or displays unexpected characters" href="#the-emulated-shell-behaves-unconsistently-or-displays-unexpected-characters"></a></p>
<p dir="auto">Please note that the emulated shell works by performing the following steps :</p>
<ul dir="auto">
<li>Open a headless terminal on the remote server / inside the remote Docker container.</li>
<li>Capture standard output, standard error, and bind standard input to the web interface.</li>
<li>Display standard output and standard error on the web interface as they are streamed over Websocket from the terminal.</li>
</ul>
<p dir="auto">According to this implementation, the remote terminal never receives key presses. It only receives commands.</p>
<p dir="auto">Also, the following techniques are used to try to enhance the user experience on the web interface :</p>
<ul dir="auto">
<li>Enable clearing the shell (HTML) screen via "Ctrl+L" (while the real terminal remains untouched)</li>
<li>Enable quitting the (HTML) shell via "Ctrl+D" (by sending an "exit" command to the real terminal)</li>
<li>Handle "command mirror" by appending "# ISAIAH" to every command sent by the user (to distinguish it from command output)</li>
<li>Handle both "\r" and "\n" newline characters</li>
<li>Use a time-based approach to detect when a command is finished if it doesn't output anything that shows clear ending</li>
<li>Remove all escape sequences meant for coloring the terminal output</li>
<li>Handle up and down arrow keys to cycle through commands history locally</li>
</ul>
<p dir="auto">Therefore it appears that, unless we use a VNC-like solution, the emulation can neither be enhanced nor use keyboard-based features (such as tab completion).</p>
<p dir="auto">Unless a contributor points the project in the right direction, and as far as my skills go, I personally believe that the current implementation has reached its maximum potential.</p>
<p dir="auto">I leave here a few ideas that I believe could be implemented, but may require more knowledge, time, testing :</p>
<ul dir="auto">
<li>Convert escape sequences to CSS colors</li>
<li>Wrap every command in a "block" (begin - command - end) to easily distinguish user-sent commands from output</li>
<li>Sending to the real terminal the key presses captured from the web (a.k.a sending key presses to a running process)</li>
</ul>
<p dir="auto">Ultimately, please also note that in a multi-node / multi-host setup, the extra network latency and unexpected buffering from remote terminals may cause additional display artifacts.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">An error happens when spawning a new shell on the server / inside a Docker container</h4><a id="user-content-an-error-happens-when-spawning-a-new-shell-on-the-server--inside-a-docker-container" aria-label="Permalink: An error happens when spawning a new shell on the server / inside a Docker container" href="#an-error-happens-when-spawning-a-new-shell-on-the-server--inside-a-docker-container"></a></p>
<p dir="auto">The default commands used to spawn a shell, although being more or less standard, may not fit your environment.
In this case, please edit the <code>TTY_SERVER_COMMAND</code> and <code>TTY_CONTAINER_COMMAND</code> settings to define a command that works better in your setup.</p>
<p dir="auto">Also, please note that if you have deployed Isaiah using Docker, trying to open a system shell (<code>S</code> key) will not work.
Isaiah being confined to its Docker container, it won't be able to open a shell out of it (on your hosting system).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">The connection with the remote server randomly stops or restarts</h4><a id="user-content-the-connection-with-the-remote-server-randomly-stops-or-restarts" aria-label="Permalink: The connection with the remote server randomly stops or restarts" href="#the-connection-with-the-remote-server-randomly-stops-or-restarts"></a></p>
<p dir="auto">This is a known incident that happens when the Websocket server receives a data message that exceeds its maximum read size.
You should be able to fix that by updating the <code>SERVER_MAX_READ_SIZE</code> setting to a higher value (default is 100,000 bytes).
This operation shouldn't cause any problem or impact performances.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">I can neither click nor use the keyboard, nothing happens</h4><a id="user-content-i-can-neither-click-nor-use-the-keyboard-nothing-happens" aria-label="Permalink: I can neither click nor use the keyboard, nothing happens" href="#i-can-neither-click-nor-use-the-keyboard-nothing-happens"></a></p>
<p dir="auto">In such a case, please check the icon in the lower right corner.
If you see an orange warning symbol, it means that the connection with the server was lost.
When the connection is lost, all inputs are disabled, until the connection is reestablished (a new attempt is performed every second).</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">The interface is stuck loading indefinitely</h4><a id="user-content-the-interface-is-stuck-loading-indefinitely" aria-label="Permalink: The interface is stuck loading indefinitely" href="#the-interface-is-stuck-loading-indefinitely"></a></p>
<p dir="auto">This incident arises when a crash occurs while inside a shell or performing a Docker command.
The quickest "fix" for that is to refresh your browser tab (Ctrl+R/Cmd+R).</p>
<p dir="auto">The real "fix" (if any) could be to implement a "timeout" (client-side or server-side) after which, the "loading" state is automatically discarded</p>
<p dir="auto">If you encounter this incident consistently, please reach out by opening an issue so we look deeper into that part</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">The web interface seems to randomly crash and restart</h4><a id="user-content-the-web-interface-seems-to-randomly-crash-and-restart" aria-label="Permalink: The web interface seems to randomly crash and restart" href="#the-web-interface-seems-to-randomly-crash-and-restart"></a></p>
<p dir="auto">If you haven't already, please read about the <code>SERVER_MAX_READ_SIZE</code> setting in the <a href="#configuration">Configuration</a> section.</p>
<p dir="auto">That incident occurs when the Websocket messages sent from the client to the server are too big.
The server's reaction to overly large messages sent over Websocket is to close the connection with the client.
When that happens, Isaiah (as a client in your browser) automatically reopens a connection with the server, hence explaining the "crash-restart" cycle.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">The web interface does not save my preferences</h4><a id="user-content-the-web-interface-does-not-save-my-preferences" aria-label="Permalink: The web interface does not save my preferences" href="#the-web-interface-does-not-save-my-preferences"></a></p>
<p dir="auto">First, please ensure that your browser supports the <code>localStorage</code> API.</p>
<p dir="auto">Second, please ensure that you're not using the <code>private browsing</code> or <code>incognito</code> or <code>anonymous browsing</code> mode. This mode will
turn off the <code>localStorage</code>, hence disabling the user preferences saved by Isaiah in your browser.</p>
<p dir="auto">If you wish to use Isaiah inside a private browser window while still having your preferences stored somewhere, use the
<code>CLIENT_PREFERENCE_XXX</code> settings in your deployment. These settings will be stored server-side, and understood by your browser
without ever using <code>localStorage</code>, hence circumventing the limitation of the private browsing mode.</p>
<p dir="auto">All the preferences described in the second table of <a href="#configuration">Configuration</a> are available server-side, using their uppercased-underscore counterpart.
See below :</p>
<ul dir="auto">
<li><code>theme</code> becomes <code>CLIENT_PREFERENCE_THEME</code></li>
<li><code>enableOverviewOnLaunch</code> becomes <code>CLIENT_PREFERENCE_ENABLE_OVERVIEW_ON_LAUNCH</code></li>
<li><code>enableMenuPrompt</code> becomes <code>CLIENT_PREFERENCE_ENABLE_MENU_PROMPT</code></li>
<li><code>enableLogLinesWrap</code> becomes <code>CLIENT_PREFERENCE_ENABLE_LOG_LINES_WRAP</code></li>
<li><code>enableJumpFuzzySearch</code> becomes <code>CLIENT_PREFERENCE_ENABLE_JUMP_FUZZY_SEARCH</code></li>
<li><code>enableTimestampDisplay</code> becomes <code>CLIENT_PREFERENCE_ENABLE_TIMESTAMP_DISPLAY</code></li>
<li><code>enableLogLinesStrippedBackground</code> becomes <code>CLIENT_PREFERENCE_ENABLE_LOG_LINES_STRIPPED_BACKGROUND</code></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">A feature that works on desktop is missing from the mobile user interface</h4><a id="user-content-a-feature-that-works-on-desktop-is-missing-from-the-mobile-user-interface" aria-label="Permalink: A feature that works on desktop is missing from the mobile user interface" href="#a-feature-that-works-on-desktop-is-missing-from-the-mobile-user-interface"></a></p>
<p dir="auto">Please note that you can horizontally scroll the mobile controls located in the bottom part of your screen to reveal all of them.
If, for any reason, you still encounter a case when a feature is missing on your mobile device, please open an issue
indicating the browser you're using, your screen's viewport size, and the model of your phone.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">In a multi-node deployment, the agent's registration with master is stuck loading indefinitely</h4><a id="user-content-in-a-multi-node-deployment-the-agents-registration-with-master-is-stuck-loading-indefinitely" aria-label="Permalink: In a multi-node deployment, the agent's registration with master is stuck loading indefinitely" href="#in-a-multi-node-deployment-the-agents-registration-with-master-is-stuck-loading-indefinitely"></a></p>
<p dir="auto">This issue arises when the authentication settings between Master and Agent nodes are incompatible.<br>
To fix it, please make sure that :</p>
<ul dir="auto">
<li>When authentication is enabled on Master, the Agent has a <code>MASTER_SECRET</code> setting defined.</li>
<li>When authentication is disabled on Master, the Agent has no <code>MASTER_SECRET</code> setting defined.</li>
</ul>
<p dir="auto">Also don't forget to restart your nodes when changing settings.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Something else</h4><a id="user-content-something-else" aria-label="Permalink: Something else" href="#something-else"></a></p>
<p dir="auto">Please feel free to open an issue, explaining what happens, and describing your environment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">Due to the very nature of Isaiah, I can't emphasize enough how important it is to harden your server :</p>
<ul dir="auto">
<li>Always enable the authentication (with <code>AUTHENTICATION_ENABLED</code> and <code>AUTHENTICATION_SECRET</code> settings) unless you have your own authentication mechanism built into a proxy.</li>
<li>Always use a long and secure password to prevent any malicious actor from taking over your Isaiah instance.</li>
<li>You may also consider putting Isaiah on a private network accessible only through a VPN.</li>
</ul>
<p dir="auto">Keep in mind that any breach or misconfiguration on your end could allow a malicious actor to fully take over your server.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">I believe that, although we're both in the open-source sphere and have all the best intentions, it is important to state the following :</p>
<ul dir="auto">
<li>Isaiah isn't a competitor or any attempt at replacing the lazydocker project. Funnily enough, I'm myself more comfortable running lazydocker through SSH rather than in a browser.</li>
<li>I've browsed almost all the open issues on lazydocker, and tried to implement and improve what I could (hence the <code>TTY_CONTAINER_COMMAND</code> variable, as an example, or even the Image pulling feature).</li>
<li>Isaiah was built from absolute zero (for both the server and the client), and was ultimately completed using knowledge from lazydocker that I'm personally missing (e.g. the container states and icons).</li>
<li>Before creating Isaiah, I tried to "serve lazydocker over websocket" (trying to send keypresses to the lazydocker process, and retrieving the output via Websocket), but didn't succeed, hence the full rewrite.</li>
<li>I also tried to start Isaiah from the lazydocker codebase and implement a web interface on top of it, but it seemed impractical or simply beyond my skills, hence the full rewrite.</li>
</ul>
<p dir="auto">Ultimately, thanks to the people behind lazydocker both for the amazing project (that I'm using daily) and for paving the way for Isaiah.</p>
<p dir="auto">PS : Please also note that Isaiah isn't exactly 100% feature-equivalent with lazydocker (e.g. charts are missing)
PS2 : What spurred me to build Isaiah in the first place is a bunch of comments on the Reddit self-hosted community, stating that Portainer and other available solutions were too heavy or hard to use. A Redditor said that having lazydocker over the web would be amazing, so I thought I'd do just that.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribute</h2><a id="user-content-contribute" aria-label="Permalink: Contribute" href="#contribute"></a></p>
<p dir="auto">This is one of my first ever open-source projects, and I'm not a Docker / Github / Docker Hub / Git guru yet.</p>
<p dir="auto">If you can help in any way, please do! I'm looking forward to learning from you.</p>
<p dir="auto">From the top of my head, I'm sure there's already improvement to be made on :</p>
<ul dir="auto">
<li>Terminology (using the proper words to describe technical stuff)</li>
<li>Coding practices (e.g. writing better comments, avoiding monkey patches)</li>
<li>Shell emulation (e.g. improving on what's done already)</li>
<li>Release process (e.g. making explicit commits, pushing Docker images properly to Docker Hub)</li>
<li>Github settings (e.g. using discussions, wiki, etc.)</li>
<li>And more!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">Hey hey ! It's always a good idea to say thank you and mention the people and projects that help us move forward.</p>
<p dir="auto">Big thanks to the individuals / teams behind these projects :</p>
<ul dir="auto">
<li><a href="https://github.com/jesseduffield/lazydocker">laydocker</a> : Isaiah wouldn't exist if Lazydocker hadn't been created prior, and to say that it is an absolutely incredible and very advanced project is an understatement.</li>
<li><a href="https://github.com/tailwindlabs/heroicons">Heroicons</a> : For the great icons.</li>
<li><a href="https://github.com/olahol/melody">Melody</a> : For the awesome Websocket implementation in Go.</li>
<li><a href="https://github.com/goreleaser/goreleaser">GoReleaser</a> : For the amazing release tool.</li>
<li><a href="https://github.com/krisk/fuse">Fuse</a> : For the amazing fuzzy-search library.</li>
<li>The countless others!</li>
</ul>
<p dir="auto">And don't forget to mention Isaiah if it makes your life easier!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mourning and moving on: rituals for leaving a career (2014) (174 pts)]]></title>
            <link>https://franceshocutt.com/2014/09/10/on-mourning-and-moving-on-rituals-for-leaving-a-career/</link>
            <guid>41317280</guid>
            <pubDate>Thu, 22 Aug 2024 06:03:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://franceshocutt.com/2014/09/10/on-mourning-and-moving-on-rituals-for-leaving-a-career/">https://franceshocutt.com/2014/09/10/on-mourning-and-moving-on-rituals-for-leaving-a-career/</a>, See on <a href="https://news.ycombinator.com/item?id=41317280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><a href="http://modelviewculture.com/pieces/i-didn-t-want-to-lean-out">I decided to leave what had been a promising career in organic chemistry</a> about a year ago. Deciding to leave my program, and then to leave the field entirely, was one of the hardest decisions I have made. I had more resources than many in my position: savings and financial support, enough work experience to feel confident that I was making a realistic decision, and supportive friends and mentors. Still, that decision meant that I lost my plans, my confidence in my career trajectory, and my identity as a practicing scientist.</p>
<p>One of my biggest losses was a clear(ish) path forward. In chemistry, and particularly in academia, your mentors and your observations help you form a mental career map of sorts. Undergrad (graduation) leads to a bench job or graduate school (the latter may be much like that bench job, but with worse management and less compensation); the bench job leads to a dead end (in Big Pharma, at least), an “alternate career path”, or to graduate school. Graduate school traditionally leads to academia, industry, or work at national labs (or that “alternate career path”). Academia has the postdoc-to-postdoc-to-tenure track path; “industry” covers a lot of territory, but there is an expectation of moving either laterally or vertically within and between various companies (<a href="http://chemjobber.blogspot.com/">assuming there are jobs</a>); and similarly, there are opportunities for career progress and moving up the ladder in national labs. None of these are easy paths, of course, but I was surrounded by the institutional knowledge that they were possible.</p>
<p>When I left, I left the territory that my maps covered. That same institutional knowledge whispered that leaving a program is failing; that “alternate career paths” are well and good for those who couldn’t hack it on the “normal” paths; that a master’s degree is an admission of inferiority, not a proud acheivement. I had never judged my friends and partners who had left their own programs and changed fields, but it was somehow different when it was me.</p>
<p>Humans aren’t very good with change. We create meaning around the stress and soften transitions with rituals and rites of passage. Each of the change-points on the map I described would have been marked with a ritual: graduations, heading to happy hour after quals, the <a href="http://www.mcsweeneys.net/articles/faq-the-snake-fight-portion-of-your-thesis-defense">ritual challenge</a> of the <a href="http://xkcd.com/1403/">thesis defense</a> and the addition of “Dr.” to one’s full name, a handshake and congratulations on a raise or promotion, ordering business cards with a new title, heading to lunch with coworkers when a new coworker arrives or when one leaves for grad school, going through the arcane and labryinthine process of setting up accounts and office space at a new institution. We go through rituals to enter a program, and the process of graduate school itself is arguably a rite of passage that culminates in a final challenge, renaming, and shared food and drink. There is nothing to smooth the process of choosing to leave.</p>
<p>When I made my final decision to leave, I could feel what I was losing and that I needed to mourn. My grandmother had died at the beginning of the year, so grief, and irreversible change were already on my mind. My family grieved by coming together to share food, drink, stories, and ritual. None of those elements need to be restricted to mourning a death. I wanted the support of my community for this loss as well. </p>
<p>I invited my friends to a wake of sorts. No one ended up coming in mourning wear, but a dear friend brought me funeral lilies with a sheepish expression and that set the tone for the evening. We ate, we drank, and we chatted. Eventually I talked a bit about the choice I’d made, why I’d invited them, and my hopes for my future. My friends shared their hopes, reassurances, and anger on my behalf and their own wishes. I led a series of toasts and curses for what I’d been through and what I wished were different. I acknowledged what I had gotten from that part of my life. I cried for what I’d experienced and what I’d lost.</p>
<p>Those of us who leave the paths “everyone” knows are no less brave and resourceful than those who follow them. I’ve posted the invitation I sent out for the “wake” I held below the cut. If you think that anything I’ve shared here might help you navigate your own changes, please take whatever is helpful, change it to fit you, and pass it on. We can map and mark our new paths together.</p>
<p><span id="more-140"></span><br>
Greetings, all:</p>
<p>You are formally invited to</p>
<p>A WAKE</p>
<p>for</p>
<p>THE RESEARCH SCIENCE CAREER</p>
<p>of</p>
<p>FRANCES HOCUTT</p>
<p>FRIDAY from 7 PM to MIDNIGHT</p>
<p>I have decided to permanently leave the UW chemistry department and,<br>
most likely, the field of organic chemistry. This is a significant<br>
personal loss. I have been interested in and good at organic chemistry<br>
for the last decade and had been planning to use those skills in a<br>
research career to figure out more about the world and change it for<br>
the better with SCIENCE! I have finally decided that the culture of<br>
the field is too toxic for me to want to continue and I have chosen to<br>
leave to pursue other interests.</p>
<p>You are all invited to help me mourn this loss, to celebrate the good<br>
things I’ll be taking forward from it, and to look ahead at where I’m<br>
going next. I will provide: delicious coconut lentil curry with rice,<br>
caramel sauce and chocolate ganache to put on things, and a few<br>
beverages (alcoholic and not). Please bring some combination of: food,<br>
board games, delightful music, projects to work on, more delicious<br>
beverages, things to put caramel on, and your awesome selves. Kids are<br>
welcome but please be aware there are cats and my house is not<br>
kid-proofed. Please do not bring foods with peanuts or tree nuts in<br>
them.</p>
<p>I ask that those of you currently connected to the chemistry<br>
department keep this information private. I am still trying to work<br>
some things out with the department and would prefer to handle<br>
informing people there myself.</p>
<p>Please do RSVP so I can get a rough head-count, but feel free to show<br>
up at any time during the evening. Dressing in your personal version<br>
of mourning wear, the more over-the-top the better, is highly<br>
encouraged but not required.</p>
<p>Frances</p>

			
			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Celebrating 6 years since Valve announced Steam Play Proton for Linux (306 pts)]]></title>
            <link>https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/</link>
            <guid>41316999</guid>
            <pubDate>Thu, 22 Aug 2024 05:05:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/">https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=41316999">Hacker News</a></p>
Couldn't get https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Designing my own watch (2020) (203 pts)]]></title>
            <link>https://willem.com/blog/2020-11-30_designing-my-own-watch/</link>
            <guid>41316598</guid>
            <pubDate>Thu, 22 Aug 2024 03:41:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://willem.com/blog/2020-11-30_designing-my-own-watch/">https://willem.com/blog/2020-11-30_designing-my-own-watch/</a>, See on <a href="https://news.ycombinator.com/item?id=41316598">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="content">
	
	<h2 itemprop="subheading">Timeless timepiece, both functional and comfortable</h2>
	
	<p>Last month a very special package arrived from Switzerland, containing my custom made wrist watch. I decided to sell all my big brand watches and have them replaced by something unique, tailored to my personal preferences. This is the story of my watch.</p>

	<a name="continue" id="continue"></a>
	<h3>Watches</h3><p>There is something magical in these miniature machines that sit on peoples' wrists: watches. They are technical marvels that often are much more than mere tools to tell time. </p><p>Some are status symbols, some are pieces of art, some are fitness tools and others are digital companions. But most of all, a watch is something truly personal: you wear it on<i> your</i> body. With smartphones and computers everywhere, nobody really needs a watch to tell time. Wearing a watch is a deliberate choice, one I like to carefully consider.</p><a name="Some of my watches over the years" title="Some of my watches over the years" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_3000px.png"><figure><img alt="Some of my watches over the years" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_500px.png" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_500px.png 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_640px.png 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_720px.png 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_750px.png 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_960px.png 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1000px.png 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1080px.png 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1125px.png 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1440px.png 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1536px.png 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1920px.png 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Some of my watches over the years</figcaption></figure></a><p>Over the years I have worn many different watches and each of them has its own story and reason. Yet none of them felt like a perfect fit<i> for me</i>. </p><p>You'll be surprised how hard it is to<i> precisely</i> define what you<i> really</i> want. I took my time (pun intended) to distill a list of features that would define<i> my perfect watch</i>:</p><ul><li><b>analogue display:</b> like the natural passing of time I like the hands of a watch to sweep by as time progresses</li><li><b>simple:</b> devoid of any unnecessary distractions I like my watch to be (visually) focussed on its function</li><li><b>autonomous:</b> in line with how I value my own independence, I like my watch to be capable of running all by itself, without the need to charge or wind it manually</li><li><b>waterproof:</b> as I don't fear rain while <a href="https://willem.com/blog/bike/" title="riding my bike" target="_blank">riding my bike</a> and as I do like to swim, my watch should be capable of dealing with water, too!</li><li><b>day and night:</b> with a young kid, the distinction between night and day becomes fuzzy every now and then.., any bearing the watch can provide in total darkness is welcome!</li><li><b>timeless:</b> in a world where <a href="https://willem.com/blog/2018-01-08_lessons-from-a-takeaway-plastic-bag/" title="things become obsolete rapidly" target="_blank">things become obsolete rapidly</a>, I love to think of my watch as something more timeless, like a piece of art</li><li><b>inconspicuous:</b> I wear my watch for myself, I don't want it to attract any unnecessary attention</li><li><b>honest:</b> it should be true to the nature of the material, I don't like to hide things behind layers of superficial markup</li></ul><h3>ochs und junior</h3><p>Then I stumbled upon <a href="https://www.ochsundjunior.swiss/" title="ochs und junior" target="_blank">ochs und junior</a>, a small watch company from Switzerland. Founded in 2006 by Ludwig Oechslin, <a href="https://www.instagram.com/beatweinmann/" title="Beat Weinmann" target="_blank">Beat Weinmann</a> and Kurt König, they undertook an intense construction and design process to create their watches. While the company is in a <a href="https://www.ochsundjunior.swiss/news/" title="state of transformation" target="_blank">state of transformation</a> at the moment, they're still producing the watches that earned them their reputation.</p><a name="Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend" title="Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_3000px.jpg"><figure><img alt="Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend</figcaption></figure></a><p>Their wrist watches use fewer parts to deliver mechanical complications, displaying other things than just the time. The watches are designed by <a href="https://en.wikipedia.org/wiki/Ludwig_Oechslin" title="Ludwig Oechslin" target="_blank">Ludwig Oechslin</a>, a renowned, recognised and awarded watchmaker, inventor and designer. He got widely known for his restoration of the astronomical clock in the Vatican Library, known as the Farnese Clock, and for the time he spent as Director of the International Museum of Horology in La Chaux-de-Fonds, Switzerland. He is obsessed with reducing the number of parts because simpler mechanics are more reliable and easier to manufacture and service.</p><p>This focus on removing unnecessary complexity is something that I totally value. It is something that I try to attain in everything I do, design and work with. Like my <a href="https://willem.com/blog/2020-03-25_designing-and-implementing-a-micro-payment-system/" title="coffee button" target="_blank">coffee button</a> or my <a href="https://willem.com/blog/2020-04-30_minimalistic-road-bike-with-gates-carbon-drive/" title="road bike" target="_blank">road bike</a>. I knew immediately that this was the company that would be able to build my watch.</p><p>After contacting the company, we had several phone calls and email exchanges to discuss my ideas. Over the years they have made some very spectacular examples, yet I wanted to stay true to my wish list. When the sky is the limit, it's hard to stay on the ground - yet that's what I tried to do when creating this  understated piece of art.</p><a name="Timeless timepiece: an annual calendar watch, custom made to my specifications" title="Timeless timepiece: an annual calendar watch, custom made to my specifications" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_3000px.jpg"><figure><img alt="Timeless timepiece: an annual calendar watch, custom made to my specifications" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Timeless timepiece: an annual calendar watch, custom made to my specifications</figcaption></figure></a><p>My watch is made from titanium (which is light and durable), it's small (36MM diameter), it's waterproof (with a screw-down crown), the hands are luminous (visible in the dark), it has an automatic movement (not requiring batteries or manual winding) and its colours are true to the material (no painted surfaces).</p><p>The watch is a so-called "annual calendar", which means it can show the correct date with only one manual adjustment per year (during February). An annual calendar "knows" the difference between short and longer months. In haute horlogerie this is a higher end complication, sometimes requiring more than hundredth additional parts. Thanks to Oechslin's brilliant design, this watch only uses only 3 additional parts!</p><a name="The annual calendar complication using just 3 additional parts" title="The annual calendar complication using just 3 additional parts" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_3000px.jpg"><figure><img alt="The annual calendar complication using just 3 additional parts" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The annual calendar complication using just 3 additional parts</figcaption></figure></a><a name="How to read the time, month, date and weekday" title="How to read the time, month, date and weekday" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_3000px.jpg"><figure><img alt="How to read the time, month, date and weekday" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>How to read the time, month, date and weekday</figcaption></figure></a><p>As an hidden luxury (it is only noticeable by the wearer), the watch is made lighter by milling away any excess material. While some people prefer a certain heft to communicate (material) value, I appreciate lightweightness as it improves comfort (especially when you're active). </p><a name="Milling away material to make the watch lighter" title="Milling away material to make the watch lighter" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_3000px.jpg"><figure><img alt="Milling away material to make the watch lighter" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Milling away material to make the watch lighter</figcaption></figure></a><a name="Before (left) and after (right) milling away material" title="Before (left) and after (right) milling away material" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_3000px.jpg"><figure><img alt="Before (left) and after (right) milling away material" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Before (left) and after (right) milling away material</figcaption></figure></a><p>During the design process I remained in contact with the company. Every now and then I received images from the workshop, keeping me in the loop as things progressed. </p><a name="The 3D model of my watch case" title="The 3D model of my watch case" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_3000px.jpg"><figure><img alt="The 3D model of my watch case" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The 3D model of my watch case</figcaption></figure></a><a name="The super luminova makes the watch clearly readable in darkness" title="The super luminova makes the watch clearly readable in darkness" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_3000px.jpg"><figure><img alt="The super luminova makes the watch clearly readable in darkness" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The super luminova makes the watch clearly readable in darkness</figcaption></figure></a><a name="While the subtile contrast allows my watch to fly under the radar during the day " title="While the subtile contrast allows my watch to fly under the radar during the day " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_3000px.jpg"><figure><img alt="While the subtile contrast allows my watch to fly under the radar during the day " src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>While the subtile contrast allows my watch to fly under the radar during the day </figcaption></figure></a><a name="The " maestro"="" himself="" working="" on="" my="" watch="" -="" this="" feels="" like="" i="" have="" picture="" of="" rembrandt="" painting="" very="" own="" nachtwatch!="" "="" title="The " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_3000px.jpg"><figure><img alt="The " maestro"="" himself="" working="" on="" my="" watch="" -="" this="" feels="" like="" i="" have="" picture="" of="" rembrandt="" painting="" very="" own="" nachtwatch!="" "="" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The "maestro" himself working on my watch - this feels like I have picture of Rembrandt painting my very own Nachtwatch! </figcaption></figure></a><a name="Before leaving Switzerland the watch is tested and calibrated to make sure it is working well" title="Before leaving Switzerland the watch is tested and calibrated to make sure it is working well" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_3000px.jpg"><figure><img alt="Before leaving Switzerland the watch is tested and calibrated to make sure it is working well" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Before leaving Switzerland the watch is tested and calibrated to make sure it is working well</figcaption></figure></a><h3>Delivery day!</h3><p>After waiting patiently for a few months, I received my watch per mail last month. Normally you're welcome to pick it up in person, but due to all the COVID-19 restrictions I opted for parcel delivery. If you hate paying (import) tax you might want to reconsider this... the Dutch customs' office wanted their part of my piggy bank before releasing my package for import. </p><a name="My son offered an helping hand while importing his future heirloom piece" title="My son offered an helping hand while importing his future heirloom piece" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_3000px.jpg"><figure><img alt="My son offered an helping hand while importing his future heirloom piece" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>My son offered an helping hand while importing his future heirloom piece</figcaption></figure></a><a name="It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this" title="It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_3000px.jpg"><figure><img alt="It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this</figcaption></figure></a><a name="Like a kid in the candy store - happy me!" title="Like a kid in the candy store - happy me!" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_3000px.jpg"><figure><img alt="Like a kid in the candy store - happy me!" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Like a kid in the candy store - happy me!</figcaption></figure></a><a name="The natural colours work well with light" title="The natural colours work well with light" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_3000px.jpg"><figure><img alt="The natural colours work well with light" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The natural colours work well with light</figcaption></figure></a><a name="The sturgeon leather strap is waterproof by nature" title="The sturgeon leather strap is waterproof by nature" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_3000px.jpg"><figure><img alt="The sturgeon leather strap is waterproof by nature" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The sturgeon leather strap is waterproof by nature</figcaption></figure></a><a name="The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)" title="The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_3000px.jpg"><figure><img alt="The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)</figcaption></figure></a><a name="The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm" title="The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_3000px.jpg"><figure><img alt="The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm</figcaption></figure></a><a name="The dial is spectacular in an " under="" the="" radar="" way"="" -="" there="" is="" an="" incredible="" depth="" that="" hard="" to="" capture="" in="" a="" photo="" (i="" tried="" anyway!)"="" title="The dial is spectacular in an " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_3000px.jpg"><figure><img alt="The dial is spectacular in an " under="" the="" radar="" way"="" -="" there="" is="" an="" incredible="" depth="" that="" hard="" to="" capture="" in="" a="" photo="" (i="" tried="" anyway!)"="" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The dial is spectacular in an "under the radar way" - there is an incredible depth that is hard to capture in a photo (I tried anyway!)</figcaption></figure></a><a name="The 36MM size is perfect on my wrist" title="The 36MM size is perfect on my wrist" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_3000px.jpg"><figure><img alt="The 36MM size is perfect on my wrist" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The 36MM size is perfect on my wrist</figcaption></figure></a><a name="Changing the strap is easy and transforms the watch - because the watch itself is rather neutral" title="Changing the strap is easy and transforms the watch - because the watch itself is rather neutral" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_3000px.jpg"><figure><img alt="Changing the strap is easy and transforms the watch - because the watch itself is rather neutral" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Changing the strap is easy and transforms the watch - because the watch itself is rather neutral</figcaption></figure></a><a name="The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!" title="The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_3000px.jpg"><figure><img alt="The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!</figcaption></figure></a><a name="The carbon buckle hardly adds any weight" title="The carbon buckle hardly adds any weight" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_3000px.jpg"><figure><img alt="The carbon buckle hardly adds any weight" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The carbon buckle hardly adds any weight</figcaption></figure></a><a name="Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap" title="Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_3000px.jpg"><figure><img alt="Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap</figcaption></figure></a><a name="In line with the " light"-case="" of="" my="" watch,="" the="" buckle="" this="" strap="" is="" milled="" to="" remove="" any="" unneeded="" weight"="" title="In line with the " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_3000px.jpg"><figure><img alt="In line with the " light"-case="" of="" my="" watch,="" the="" buckle="" this="" strap="" is="" milled="" to="" remove="" any="" unneeded="" weight"="" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>In line with the "LIGHT"-case of my watch, the buckle of this strap is milled to remove any unneeded weight</figcaption></figure></a><h3>Conclusion</h3><p>While there are many reasons to choose a watch, I wanted my watch to be perfect<i> for me</i>. In a fast moving world where things get replaced rapidly by newer fads, spending time and money on a timeless timepiece felt right.</p><p>Don't be afraid to make decisions for yourself. Wear the watch you want to wear. If it doesn't exists, don't panic. Thanks to the wonders of our connected world, you can find people that will help you!</p><a name="Wear the watch you want - if it doesn't exist you can create it!" title="Wear the watch you want - if it doesn't exist you can create it!" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_3000px.jpg"><figure><img alt="Wear the watch you want - if it doesn't exist you can create it!" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Wear the watch you want - if it doesn't exist you can create it!</figcaption></figure></a>

	

	

<div id="support">
	<h2>Did you enjoy this post?</h2>
	<p>If you found this content useful, <br>consider showing your appreciation<br>
   		by buying me a coffee ❤️😋: </p>
	

</div> 



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A 20-part deep dive into how linkers work (2008) (203 pts)]]></title>
            <link>https://lwn.net/Articles/276782/</link>
            <guid>41316342</guid>
            <pubDate>Thu, 22 Aug 2024 02:47:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/276782/">https://lwn.net/Articles/276782/</a>, See on <a href="https://news.ycombinator.com/item?id=41316342">Hacker News</a></p>
Couldn't get https://lwn.net/Articles/276782/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Bum Farto (113 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Bum_Farto</link>
            <guid>41316067</guid>
            <pubDate>Thu, 22 Aug 2024 02:05:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Bum_Farto">https://en.wikipedia.org/wiki/Bum_Farto</a>, See on <a href="https://news.ycombinator.com/item?id=41316067">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/Bum_Farto: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[SIMD Matters: Graph Coloring (166 pts)]]></title>
            <link>https://box2d.org/posts/2024/08/simd-matters/</link>
            <guid>41315359</guid>
            <pubDate>Wed, 21 Aug 2024 23:55:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://box2d.org/posts/2024/08/simd-matters/">https://box2d.org/posts/2024/08/simd-matters/</a>, See on <a href="https://news.ycombinator.com/item?id=41315359">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            

            

            <div>
                <h2 id="simd-in-game-development">SIMD in game development</h2>
<p>Often in game development we talk about <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a>. It is the holy grail of CPU performance, often out of reach. The conventional wisdom is that it is difficult to achieve real gains from SIMD.</p>
<p>It is tempting to build a math library around SIMD hoping to get some performance gains. However, it often has no proven benefit. It just feels good to be using something we know <em>can</em> improve performance. But sometimes SIMD can get in the way.</p>
<p>For example, game play programmers often do a lot of piecemeal vector math. They are not chopping 8 carrots at once. Instead they are trying to get a movement ability to work well on the player. Like swinging on a rope or swimming in water. These require vector math, but this code cannot be gathered into SIMD instructions in a meaningful way. We cannot force a game to have 8 players swinging on a rope at the same time.</p>
<p>Game physics is often similar. The user wants to create or destroy a single body. The ray casts are issued from the game separately and point in different directions.</p>
<p>Even if there are many similar things being computed, it can be difficult to gather these objects and push them through some algorithm simultaneously. For example, in game physics one of the most expensive computations is computing the contact forces between colliding bodies. When there are many bodies there can be a huge number of contact points.</p>
<p>This large pyramid has 5050 bodies and a whopping 14950 contact pairs, each with two contact points. Each contact point has a non-penetration force and a friction force. That is 59800 forces to be computed! Further these forces need to be computed several times per time step as part of the <em>Soft Step</em> solver. Read more <a href="https://box2d.org/posts/2024/02/solver2d/">here</a>.</p>
<p><img src="https://box2d.org/images/large_pyramid_benchmark.png" alt="Large Pyramid"><em>A pyramid of 5050 bodies</em></p>
<p>Another problem is that each constraint operates on different bodies. So even if constraints are organized contiguously in an array for faster iteration, the bodies need to be randomly accessed. This random access is the ultimately the bottleneck in game physics.</p>
<h2 id="graph-coloring">Graph coloring</h2>
<p>For Box2D version 3.0 I decided to finally try using SIMD as it is <strong>meant to be used</strong> for solving contacts. Making contacts solve faster could yield large performance gains so I decided it would be worth the effort.</p>
<p>But how can I gather 4 or 8 contact pairs to be solved simultaneously? The key is <a href="https://en.wikipedia.org/wiki/Graph_coloring">graph coloring</a>. The idea is to have a handful of colors to be assigned to all the contact constraints. For example, suppose I have 6 colors and I want to assign all the contacts to one of those 6 colors. Contact constraints act upon two bodies at a time. With graph coloring the restriction is that within a single color a body can only appear once or not at all.</p>
<p>This small pyramid shows an example of graph coloring. Each contact constraint has two contact points with the same color. There are four colors: red, orange, yellow, and green. If you look at a color, such as orange, you can see that it only touches a box once per contact point pair. This is the magic of graph coloring and enables me to solve multiple contact constraints simultaneously without a <a href="https://en.wikipedia.org/wiki/Race_condition">race condition</a>.</p>
<p><img src="https://box2d.org/images/graph_color_small.png" alt="Graph Coloring"><em>Graph coloring of a small pyramid</em></p>
<p>Graph coloring can scale to very large scenarios. The image below shows the graph coloring of the contact points on the large pyramid. You can see in the text the number of contact constraints per color.</p>
<ul>
<li>color 1 : 2524</li>
<li>color 2 : 2508</li>
<li>color 3 : 2465</li>
<li>color 4 : 2376</li>
<li>color 5 : 2286</li>
<li>color 6 : 2107</li>
<li>color 7 : 652</li>
<li>color 8 : 32</li>
</ul>
<p><img src="https://box2d.org/images/graph_color.png" alt="Large Pyramid Graph Coloring"><em>Graph coloring of the large pyramid</em></p>
<p>These colors group together constraints that can be solved simultaneously using SIMD. For example, color 1 has 2524 contact constraints. Each of these constraints is between two bodies. The graph coloring ensures that none of the same bodies appear more than once in all 2524 contact constraints. This means all 2524 constraints can be solved simultaneously.</p>
<p>But isn’t graph coloring very complex and slow? Contacts come and go all the time in rigid body simulation. Do I need to recompute the graph colors every time a contact is added or removed?</p>
<p>First of all, there is a lot of intimidating <a href="https://en.wikipedia.org/wiki/Four_color_theorem">theory</a> around graph coloring and it seems at first that some complex algorithms must be applied to do graph color properly. This is not true at all! A simple <a href="https://en.wikipedia.org/wiki/Greedy_algorithm">greedy algorithm</a> is sufficient for game physics.</p>
<p>Box2D maintains a <a href="https://en.wikipedia.org/wiki/Bit_array">bitsets</a> for each graph color. Each bit corresponds to a body index. When a contact constraint is created, the graph color bitsets are examined. The constraint is assigned to the first color with a bitset that doesn’t have either body bit set to 1. Once the constraint is assigned to a color, those two body bits are set to 1. This is a very fast operation.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>b2AddContactToGraph</span>(b2ConstraintGraph<span>*</span> graph, b2Contact<span>*</span> contact)
</span></span><span><span>{
</span></span><span><span>    <span>int</span> indexA <span>=</span> contact<span>-&gt;</span>bodyIndexA;
</span></span><span><span>    <span>int</span> indexB <span>=</span> contact<span>-&gt;</span>bodyIndexB;
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> graph<span>-&gt;</span>colorCount; <span>++</span>i)
</span></span><span><span>    {
</span></span><span><span>        b2GraphColor<span>*</span> color <span>=</span> graph<span>-&gt;</span>color <span>+</span> i;
</span></span><span><span>        <span>if</span> (<span>b2GetBit</span>(color<span>-&gt;</span>bodySet, indexA))
</span></span><span><span>        {
</span></span><span><span>            <span>// advance to next color
</span></span></span><span><span><span></span>            <span>continue</span>;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>if</span> (<span>b2GetBit</span>(color<span>-&gt;</span>bodySet, indexB))
</span></span><span><span>        {
</span></span><span><span>            <span>// advance to next color
</span></span></span><span><span><span></span>            <span>continue</span>;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>// available color found!
</span></span></span><span><span><span></span>        <span>b2SetBit</span>(color<span>-&gt;</span>bodySet, indexA);
</span></span><span><span>        <span>b2SetBit</span>(color<span>-&gt;</span>bodySet, indexB);
</span></span><span><span>
</span></span><span><span>        contact<span>-&gt;</span>colorIndex <span>=</span> i;
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>Even though bitsets are fast, it would be better not to redo the graph coloring every time step. So Box2D persists the graph coloring across time steps. When a contact constraint is created the color is determined and the body bits are turned on. When a constraint is removed the corresponding two body bits are cleared.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>b2RemoveContactFromGraph</span>(b2ConstraintGraph<span>*</span> graph, b2Contact<span>*</span> contact)
</span></span><span><span>{
</span></span><span><span>    <span>int</span> indexA <span>=</span> contact<span>-&gt;</span>bodyIndexA;
</span></span><span><span>    <span>int</span> indexB <span>=</span> contact<span>-&gt;</span>bodyIndexB;
</span></span><span><span>
</span></span><span><span>    b2GraphColor<span>*</span> color <span>=</span> graph<span>-&gt;</span>color <span>+</span> contact<span>-&gt;</span>colorIndex;
</span></span><span><span>    <span>b2ClearBit</span>(color<span>-&gt;</span>bodySet, contact<span>-&gt;</span>bodyIndexA);
</span></span><span><span>    <span>b2ClearBit</span>(color<span>-&gt;</span>bodySet, contact<span>-&gt;</span>bodyIndexB);
</span></span><span><span>    contact<span>-&gt;</span>colorIndex <span>=</span> B2_NULL_INDEX;
</span></span><span><span>}
</span></span></code></pre></div><p>There are a couple more details. When bodies go to sleep they are removed from the graph coloring and when they wake they are added back according to the constraints that connect them. Also static bodies are never set in the bitsets because static bodies are not modified by the contact solver. This reduces the number of colors needed.</p>
<h2 id="going-wide">Going WIDE</h2>
<p>So now that I have 2524 contact constraints I can solve simultaneously, how do I do that? Well there are no SIMD units that are 2524 floats wide. So I break these into 4 or 8 constraint blocks (SSE2/Neon or AVX2). These <em>wide</em> constraints can be solved like a single scalar constraint. The math looks almost identical.</p>
<p>There is some delicate plumbing needed to make this happen. In particular, I need to gather 4 or 8 pairs of bodies for each wide constraint. I gather the body velocities and put them in <em>wide</em> floats (4 or 8 floats).</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>// wide float
</span></span></span><span><span><span></span><span>typedef</span> b2FloatW <span>__m128</span>;
</span></span><span><span>
</span></span><span><span><span>// wide vector
</span></span></span><span><span><span></span><span>struct</span> b2Vec2W
</span></span><span><span>{
</span></span><span><span>    b2FloatW X;
</span></span><span><span>    b2FloatW Y;
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>// wide body
</span></span></span><span><span><span></span><span>struct</span> b2BodyW
</span></span><span><span>{
</span></span><span><span>    b2Vec2W linearVelocity;
</span></span><span><span>    b2FloatW angularVelocity;
</span></span><span><span>};
</span></span></code></pre></div><p>I grab 4 or 8 bodies and stuff their velocities into a single <em>wide</em> body. Then the wide constraint operates on wide bodies and all the math looks similar to scalar math. For example, the wide dot product is just two multiplications and one addition, doing 4 or 8 dot products simultaneously.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>// wide dot product
</span></span></span><span><span><span></span>b2FloatW <span>b2DotW</span>(b2Vec2W a, b2Vec2W b)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>b2AddW</span>(<span>b2MulW</span>(a.X, b.X), <span>b2MulW</span>(a.Y, b.Y));
</span></span><span><span>}
</span></span></code></pre></div><p>This is the way SIMD is <strong>meant to be used</strong>. But there is sure a lot of setup work to make this possible!</p>
<p>After the wide constraint is solved, the wide body velocities are <em>scattered</em> to the individual scalar bodies. These <a href="https://en.wikipedia.org/wiki/Gather/scatter_(vector_addressing)">gather/scatter</a> operations are needed to make this all work. Each instruction set SSE2/Neon/AVX2 has custom instructions that help with this. None of it is super intuitive but it is well documented not too difficult to setup.</p>
<h2 id="does-it-matter">Does it matter?</h2>
<p>I did all this work to enable SIMD processing. Did it help? Box2D has a benchmarking console application to help answer this question. I implemented SSE2, Neon, and AVX SIMD instruction sets in the Box2D contact solver. I also implemented a <strong>scalar</strong> reference implementation. I have 5 benchmarks scenarios that push Box2D in various ways. See the benchmark results <a href="https://box2d.org/files/benchmark_results.html">here</a>.</p>
<p>I ran these benchmarks on an AMD 7950X (AVX2, SSE2, scalar) and an Apple M2 (Neon).</p>
<p><img src="https://box2d.org/images/large_pyramid_results.png" alt="Large Pyramid Results"><em>Large pyramid benchmark results</em></p>
<p>The joint grid benchmark doesn’t use SIMD instructions at all, so you can ignore that one. But the other ones all stress the contact solver.</p>
<p>The large pyramid benchmark with 4 workers has the following numbers:</p>
<ul>
<li>AVX2 : 1117 fps = 0.90 ms</li>
<li>Neon : 1058 fps = 0.95 ms</li>
<li>SSE2 : 982 fps = 1.02 ms</li>
<li>scalar (AMD): 524 fps = 1.91 ms</li>
<li>scalar (M2): 679 fps = 1.47 ms</li>
</ul>
<p>From this I draw the following conclusions:</p>
<ol>
<li>SSE2 is about 2x faster than scalar</li>
<li>AVX2 is about 14% faster than SSE2</li>
<li>The Apple M2 smokes!</li>
</ol>
<p>Another consideration is that all collision is done with scalar math. So more gains could be made if I figure out how to use SIMD for collision as well.</p>
<p>The bottom line is that making good use of SIMD can be a lot of work but it is worth the effort because it can make games run significantly faster and handle more rigid bodies.</p>
<h2 id="what-about-compiler-vectorization">What about compiler vectorization?</h2>
<p>An interesting side result from this experiment relates to compiler vectorization. In my scalar reference implementation I defined the wide float as a structure of 4 floats.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>// wide float for reference scalar implementation
</span></span></span><span><span><span></span><span>struct</span> b2FloatW { <span>float</span> x, y, z, w };
</span></span></code></pre></div><p>I also implemented all the wide math functions to work with this. It seems that I have arranged all the data perfectly for the compiler to use <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">automatic vectorization</a>. But it seems this doesn’t really happen to a sufficient degree to compete with my hand written SSE2. This is a bit ironic because on x64 all math <strong>is</strong> SIMD math, it is just inefficient SIMD math.</p>
<h2 id="references">References</h2>
<p><a href="https://www.bepuentertainment.com/">Bepu Physics</a> uses graph coloring and SIMD. While I had known about this technique for some time, the high performance of Bepu has inspired me.</p>
<p><a href="http://web.eecs.umich.edu/~msmelyan/papers/physsim_onmanycore_itj.pdf">High-Performance Physical Simulations on Next-Generation Architecture with Many Cores</a>. This is the earliest reference I know of that suggests using graph coloring to speed up rigid body physics calculations.</p>
<p>Graph coloring is used in many areas of simulation. For example, it is very useful for <a href="https://gamma.cs.unc.edu/CDCD/main.pdf">cloth simulation</a>. The nice thing about cloth simulation is that typically the graph coloring can be pre-computed.</p>
<h2 id="update">Update</h2>
<ul>
<li>added milliseconds to comparison</li>
<li>added M2 scalar results</li>
</ul>

            </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm Tired of Fixing Customers' AI Generated Code (445 pts)]]></title>
            <link>https://medium.com/@thetateman/im-tired-of-fixing-customers-ai-generated-code-94816bde4ceb</link>
            <guid>41315138</guid>
            <pubDate>Wed, 21 Aug 2024 23:16:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@thetateman/im-tired-of-fixing-customers-ai-generated-code-94816bde4ceb">https://medium.com/@thetateman/im-tired-of-fixing-customers-ai-generated-code-94816bde4ceb</a>, See on <a href="https://news.ycombinator.com/item?id=41315138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@thetateman?source=post_page-----94816bde4ceb--------------------------------"><div aria-hidden="false"><p><img alt="Tate Smith" src="https://miro.medium.com/v2/resize:fill:88:88/1*i8DvUi3xBFiTI_jQDk3MYg.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="30f3">(Not an anti-AI post — Copilot is great, I use it all the time.)</p><p id="cc58">Early this year I built some cryptocurrency trading and data gathering tools for personal use and to get more experience in Rust programming. While asking questions in various groupchats, it didn’t take too long to see that lots of other people were demanding similar tools — and would be willing to pay for them. Pretty soon after that realization, I had some API endpoints set up where people could access the data for free and submit trades for a small commission.</p><p id="3136">I started getting a few customers, a very cool experience since this was the first time people were paying for software I built myself! I started a Telegram channel for feature announcements and support, which worked well at first. But, as my customer base slowly grew, support began taking up more and more of my time. I know this is the case for any SAAS startup, so the increasing support burden was hardly a surprise, and, after all, more customers is a good problem to have! What became irritating was not the quantity, but the quality of the support requests I was receiving.</p><p id="ad0b">My API is just a few well documented endpoints. If you can figure out how to send a POST request using any programming language, you should have no problem using it. But that seems to be too high a bar for the new generation of prompt-engineer coders. Since opening my support channel, I have fielded many a “Help! My trading bot is not working!!” support request. More often than not, I will be sent customer code that is mostly fine, but has some error that should be glaringly obvious to anyone who has read the documentation and has some programming ability. Often this takes the form of trying to access an endpoint that does not exist, or read a property off the API response that does not exist. After probing a bit more, my suspicions are usually confirmed — ChatGPT hallucinated that endpoint or property, and the customer I’m talking to has little to no programming knowledge. If they are just trying to build a simple script I’ll help them out, and fix the hallucinations — it’s not much effort and creates a potentially paying customer. Often, though, the customer is envisioning a more complex application, and I just have to tell them, “Sorry, you’re going to have to hire a professional developer for this.” The worst is when a request starts out simple — I help them fix one hallucination — but then that customer wants to build more complex logic, and somehow I’ve set the expectation that I will provide unlimited free support forever. I’ve gotten a number of angry messages from customers who essentially want me to build their whole app for free.</p><p id="2841">I’m sure these challenges sound familiar to anyone who has run support for a SAAS business, but AI programming tools have exacerbated the problem. Helping a customer solve challenges is often super rewarding, but only when I can remove roadblocks for customers who can do most of the work themselves. When customers offload software engineering to AI because they don’t have the capability themselves, they still need to find a developer to fix the bugs that AI creates. I don’t want to be that developer!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euphemisms are best changed frequently (2016) (127 pts)]]></title>
            <link>https://aeon.co/essays/euphemisms-are-like-underwear-best-changed-frequently</link>
            <guid>41315126</guid>
            <pubDate>Wed, 21 Aug 2024 23:14:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aeon.co/essays/euphemisms-are-like-underwear-best-changed-frequently">https://aeon.co/essays/euphemisms-are-like-underwear-best-changed-frequently</a>, See on <a href="https://news.ycombinator.com/item?id=41315126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>What we would today call <em>cash assistance for the differently abled</em> could in a different era permissibly have been called <em>welfare for cripples</em>. The terms <em>welfare</em> and <em>crippled</em> sound somewhere between loaded and abusive today, and yet once were considered civil by educated, sensitive people. There actually was an organisation called the International Society for the Welfare of Cripples established in 1922.</p>
<p>However, in 1960 it was retitled the International Society for the Rehabilitation of the Disabled. As appropriate as that seems from our vantage point, it demonstrated a general tendency towards which we often roll our eyes. ‘Okay, what are we supposed to call it now?’ we sometimes think, as terms considered proper for a group or phenomenon seem to change every generation or so. The implication is that we find this rolling terminology a bit much – why can’t the names of things just stay put? On <em>disabled</em>, for example, what was wrong with <em>handicapped</em>, and why must we now move on to <em>differently abled</em>? Isn’t all of this kind of like Puff Daddy to P Diddy?</p>
<p>No, actually. What the cognitive psychologist and linguist Steven Pinker has artfully termed ‘the euphemism treadmill’ is not a tic or a stunt. It is an inevitable and, more to the point, healthy process, necessary in view of the eternal gulf between language and opinion. We think of euphemisms as one-time events, where one prissily coins a way of saying something that detracts from something unpleasant about it. That serves perfectly well as a definition of what euphemism is, but misses the point that euphemism tends to require regular renewal. This is because thought changes more slowly than we can change the words for it, and has a way of catching up with our new coinages. Since that is likely eternal, we must accept that we’ll change our terms just like we change our underwear, as a part of linguistic life in a civilised society.</p>
<p><span>T</span>he reason for this rolling semantic renewal is that the meanings of words are, in actual usage, messier than their dictionary definitions, cast in the tidy eternity of print, might make them seem. We store words in our brains amid webs of association, with experiences, impressions and other words. As a result, a word is always redolent of various associations, metaphorical extensions, beyond its core meaning.</p>
<p>For example, <em>generous</em> once meant noble, with no connection to sharing. It’s what William Shakespeare meant when he used the term. So when Edmund in <em>King Lear</em> defends himself against dismissal as low-born by insisting that</p>
<blockquote>… my dimensions are as well compact,<br>My mind as generous, and my shape as true,<br>As honest madam’s issue</blockquote>
<p>it can throw us a bit, making us wonder how a mind can be generous, and we find it a bit curious that someone would defend himself against a charge of bastardy by pointing out his magnanimity. However, in earlier societies, the noble person was often responsible for a degree of charity to the ordinary population, such that magnanimity was a trait associated with nobility. Over time, especially as formal nobility itself had ever less importance (think of the fate of the Crawleys in <em>Downton Abbey</em>), the meaning of <em>magnanimity</em> changed from a resonance of <em>generous</em> to the meaning it has today.</p>
<p>A word, then, is like a bell tone, with a central pitch seasoned by overtones. As the tone fades away, the overtones can hang in the air. Words are similar, with opinion, assumption and, more to the point, bias as equivalents to the overtones. <em>Crippled</em> began as a sympathetic term. However, a sad reality of human society is that there are negative associations and even dismissal harboured against those with disabilities. Thus <em>crippled</em> became accreted with those overtones, so to speak, to the point that <em>handicapped</em> was fashioned as a replacement term free from such baggage.</p>
<p>what a warm, charitable word <em>welfare</em> is at its core, and how much static and bile we must peel away to hear it that way again</p>
<p>However, because humans stayed human, it was impossible that <em>handicapped</em> would not, over time, become accreted with similar gunk. Enter <em>disabled</em>, which is now long-lived enough that many process it, too, as harbouring shades of abuse, which conditions a replacement such as <em>differently abled</em>. Notably, the International Society for the Rehabilitation of the Disabled later changed its name again to Rehabilitation, International; today, the organisation prefers to be known simply as ‘RI’, bypassing the inconvenience of actual words altogether. The story has been similar for <em>retarded</em> being replaced by <em>cognitively impaired</em>; for <em>welfare</em>, which today is more often referred to as <em>cash assistance</em>; or by the faceless initials of programmes disbursing it, such as TANF (Temporary Assistance for Needy Families).</p>
<p>Opinion can permeate a euphemism to such an extent that it becomes difficult to conceive of how it once sounded. <em>Welfare</em> was a replacement for what was once commonly referred to as <em>home relief</em>. The empathy in that term was soon blunted by associations with the people granted relief, such that older generations will recall <em>home relief</em> practically uttered as a negative epithet by the 1950s and ’60s. Meanwhile, reflect on what a warm, charitable word <em>welfare</em> is at its core, and how much static and bile we must peel away to hear it that way again. Similar is <em>affirmative action</em>: a term that 50 years ago resounded with a clean, stalwart clang of high-minded social justice now sounds freighted, sour, vague and tired to many on both sides of the political spectrum. <em>Racial preferences</em> was an attempt at a replacement – and note its similar fate.</p>
<p>As a lad decades ago, I worked briefly in the production of a magazine about <em>family planning</em>. Unfamiliar with the terminology, I spent months in this job before fully understanding that <em>family planning</em> referred to contraception, not just people musing over when they ‘planned’ to have children. Why the obliqueness? Because <em>family planning</em> was a replacement euphemism for <em>birth control</em>, coined in 1914 by the US contraception activist Margaret Sanger. Note that <em>birth control</em> was in itself as elliptical and abstract a terminology as <em>family planning.</em> Yet today, <em>birth control</em> summons the concrete image of a contraceptive pill or other device. It was inevitable that this would become the case for <em>birth control</em> given the controversy over its use.</p>
<p>This sheds light on the linguist George Lakoff’s briefly acclaimed proposal during the George W Bush administration that Democrats could regain influence by changing the terms for things reviled by Republicans. Taxes could be <em>membership fees</em>; trial lawyers could be <em>public protection attorneys</em>. As fresh as this idea seemed, it could have only worked temporarily, as the history of words such as <em>welfare</em> demonstrates. The nature of language and humanity is such that, after about 20 years, those criticising taxation rates would have come to process and discuss ‘membership fees’ with the same contempt with which they once discussed ‘taxes’, just as it has got to the point that <em>custodian</em> now has roughly the same feel as <em>janitor</em>, for which it emerged as a euphemism in the 1940s. <em>Custodian</em> makes one think not of ‘custody’ but of a mop.</p>
<p><span>T</span>hought will always catch up with the word. Make no mistake, the thoughts can be ones that many would consider welcome. A hundred years ago, in industry, <em>efficiency</em> was associated with the ‘scientific management’ theories of Frederick Taylor, the US mechanical engineer and one of the first management consultants, in search of the maximum output from factory labourers. However, as this kind of efficiency often led to the need for fewer workers, a question arose as to whom the efficiency was intended most to benefit.</p>
<p>Today, <em>efficiency</em> carries a faintly minatory air, in contrast to its first neutral, and then glamorous, feel as the 20th century got underway. <em>Downsizing</em>, an attempt to euphemise the dismissal of workers for the purposes of the bottom line, rapidly lost any impartial connotation it was crafted to purvey. In the mid-20th century, <em>urban renewal</em> was a term of art for what on the ground displaced millions of Americans, often from low-income but stable neighbourhoods deemed ‘slums’ and razed down. Today, that reality has been aired amply and publicly, such that <em>urban renewal</em> calls to mind a bulldozer mowing down innocent people’s homes. Notably, there seems to be no replacement term for <em>urban renewal</em>, partly because the policies of urban czars such as New York’s city planner Robert Moses have been so thoroughly repudiated that public officials no longer espouse any similar doctrine. Ultimately, words alone cannot do this: <em>urban renewal</em> itself began as a euphemism for the more direct <em>slum clearance</em>, but the practice only burgeoned for decades thereafter. It took thought changing to truly transform.</p>
<p>‘Innovation’ has been fashionable for long enough among corporate and political types that it has taken on their hucksterish associations</p>
<p>The euphemism treadmill, then, is neither just a form of bureaucratese, nor of identity politics. It is a symptom of the fact that, however much we would like it to be otherwise, it’s easier to change language than to change thought. Moreover, the euphemism treadmill is neither new nor does it churn faster than it once did. When you ask someone <em>Where’s the men’s?,</em> you are using a replacement for the <em>restroom</em> that can summon a vision of a certain undersanitised room in the back of a Wendy’s fast-food restaurant. Yet the very idea of it being a ‘rest’ room began as an exquisite attempt to wave away miasmic associations after <em>bathroom</em> ceased to do the job any better than had <em>toilet</em> or <em>lavatory</em>, deflecting attention to grooming and cleansing over what else happens in the room. Historically, <em>lavatory</em> is first attested in 1864, <em>restroom</em> followed hot on its heels a few decades later, at the turn of the 20th century, and then <em>men’s room</em> came into fashion in the 1920s.</p>
<p>This means that, in a linguistically mature society, we should expect that the terms we introduce to help us kick off new ways of thinking will require periodic replacement, like tyres. In our moment, <em>special-needs student</em> would appear about due for a swap-out. Meanwhile, the term <em>innovation</em> has been fashionable for just long enough among corporate and political types that it has taken on their hucksterish associations. <em>Invention</em>, for their purposes, would be better, although by about 2035 we can assume that this word too will sound, from the mouths of that era’s managers and mayors, equally fulsome.</p>
<p>Reality persists. It’s language we have control over – at least, for a while.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Play will no longer pay to discover vulnerabilities in Android apps (123 pts)]]></title>
            <link>https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/</link>
            <guid>41315068</guid>
            <pubDate>Wed, 21 Aug 2024 23:06:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/">https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/</a>, See on <a href="https://news.ycombinator.com/item?id=41315068">Hacker News</a></p>
Couldn't get https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Bioaccumulation of Microplastics in Decedent Human Brains (128 pts)]]></title>
            <link>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/</link>
            <guid>41314674</guid>
            <pubDate>Wed, 21 Aug 2024 22:07:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/</a>, See on <a href="https://news.ycombinator.com/item?id=41314674">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
    <article>
        <section>
         
    <ul>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/">Journal List</a>
                </li>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Res%20Sq%22[jour]">Research Square</a>
                </li>
            
                <li aria-current="page">
                    PMC11100893
                </li>
            
    </ul>
 

        </section>
        
  

        
        <div id="mc" role="document"><!--main-content--><div data-jigconfig="smoothScroll: false, allHeadingLevels: ['h2'], headingExclude: ':hidden,.nomenu'"><div><div><p>Version 1. <span id="pmcmata">Res Sq.</span> Preprint. 2024 May 6.</p></div><div><p><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Campen%20M%5BAuthor%5D" co-rid="_co_idm140287073396832" co-class="co-affbox">Matthew Campen</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Nihart%20A%5BAuthor%5D" co-rid="_co_idm140287138113648" co-class="co-affbox">Alexander Nihart</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Garcia%20M%5BAuthor%5D" co-rid="_co_idm140287070400336" co-class="co-affbox">Marcus Garcia</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Liu%20R%5BAuthor%5D" co-rid="_co_idm140287070521552" co-class="co-affbox">Rui Liu</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Olewine%20M%5BAuthor%5D" co-rid="_co_idm140287072016768" co-class="co-affbox">Marian Olewine</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Castillo%20E%5BAuthor%5D" co-rid="_co_idm140287077058752" co-class="co-affbox">Eliseo Castillo</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Bleske%20B%5BAuthor%5D" co-rid="_co_idm140287077057152" co-class="co-affbox">Barry Bleske</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Scott%20J%5BAuthor%5D" co-rid="_co_idm140287077087232" co-class="co-affbox">Justin Scott</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Howard%20T%5BAuthor%5D" co-rid="_co_idm140287073604784" co-class="co-affbox">Tamara Howard</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Gonzalez-Estrella%20J%5BAuthor%5D" co-rid="_co_idm140287075701440" co-class="co-affbox">Jorge Gonzalez-Estrella</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Adolphi%20N%5BAuthor%5D" co-rid="_co_idm140287079550448" co-class="co-affbox">Natalie Adolphi</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Gallego%20D%5BAuthor%5D" co-rid="_co_idm140287078865264" co-class="co-affbox">Daniel Gallego</a>, and  <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Hayek%20EE%5BAuthor%5D" co-rid="_co_idm140287148974224" co-class="co-affbox">Eliane El Hayek</a></p></div></div><div id="ABS1" lang="en"><h2 id="ABS1title">Abstract</h2><!--article-meta--><p id="P1">Rising global concentrations of environmental micro- and nanoplastics (MNPs) drive concerns for human exposure and health outcomes. Applying pyrolysis gas chromatography-mass spectrometry (Py-GC/MS) methods to isolate and quantify MNPs from human samples, we compared MNP accumulation in kidneys, livers, and brains. Autopsy samples from the Office of the Medical Investigator in Albuquerque, NM, collected in 2016 and in 2024, were digested for Py-GC/MS analysis of 12 polymers. Brains exhibited higher concentrations of MNPs than liver or kidney samples. All organs exhibited significant increases from 2016 to 2024. Polyethylene was the predominant polymer; the relative proportion of polyethylene MNPs was greater in brain samples than in liver or kidney. Transmission electron microscopy verified the nanoscale nature of isolated particles, which largely appeared to be aged, shard-like plastics remnants across a wide range of sizes. Results demonstrate that MNPs are selectively accumulated into the human brain and concentrations are rising over time.</p><p><strong>Keywords: </strong><span>Polymer, neuronal, autopsy, liver, kidney, nanoplastics</span></p></div><div id="body-a.f"><p id="P2">The ubiquitous presence of plastics, especially polymer-derived particulates ranging from 500 micrometers in diameter down to 1 nanometer, defined as micro- and nanoplastics (MNP), is a defining feature of the Anthropocene epoch<sup><a href="#R1" rid="R1">1</a></sup>. The extent to which microplastics cause harm or toxicity is unclear, although recent studies associated MNP presence in carotid atheromas with increased inflammation and risk of future adverse cardiovascular events<sup><a href="#R2" rid="R2">2</a>,<a href="#R3" rid="R3">3</a></sup>. In controlled exposure studies, MNPs clearly enhance or drive toxic outcomes<sup><a href="#R4" rid="R4">4</a>–<a href="#R6" rid="R6">6</a></sup>. The mantra of the field of toxicology – “dose makes the poison” (Paracelsus) – renders such discoveries as easily anticipated; what is not clearly understood is the internal dose in humans.</p><p id="P3">To date, several studies have utilized visualization and spectroscopic methods to identify and count particulates in organs such as the lungs, intestine<sup><a href="#R7" rid="R7">7</a></sup>, and placenta<sup><a href="#R8" rid="R8">8</a></sup>. These methods are often limited to larger (&gt;1–5μm) particulates, thus nanoplastics are excluded from the quantitation. As a novel approach, pyrolysis gas chromatography-mass spectrometry (Py-GC/MS) has been applied to blood<sup><a href="#R9" rid="R9">9</a></sup>, placentas<sup><a href="#R10" rid="R10">10</a></sup> and recently major blood vessels<sup><a href="#R2" rid="R2">2</a>,<a href="#R3" rid="R3">3</a></sup> in a manner that appears more cumulative and quantitative, and less biased than visual identification methods. Py-GC/MS data between labs has been comparable, providing confidence in this method for human tissue analysis<sup><a href="#R2" rid="R2">2</a>,<a href="#R9" rid="R9">9</a>,<a href="#R10" rid="R10">10</a></sup>. We applied Py-GC/MS to assess the relative distribution of MNPs in major organ systems from human decedent livers, kidneys, and brains.</p></div><div id="S1"><h2 id="S1title">METHODS</h2><div id="S2"><h3 id="S2title">Human Tissue Samples:</h3><p id="P4">We obtained de-identified, post-mortem human liver, kidney, and brain (frontal cortex) samples, retrospectively, in cooperation with and approval from the University of New Mexico Office of the Medical Investigator (OMI) in Albuquerque, New Mexico, under the guidance of a trained forensic pathologist (DFG) who selected consistent regions from all organs. Samples were available from 2016 and 2024; the same collection protocol was used for 2016 and 2024. Small pieces of representative organs (3 to 5 cm<sup><a href="#R2" rid="R2">2</a></sup>) are routinely collected at autopsy and placed in a small container with 10% formalin. Limited demographic data was available due to the conditions of specimen approval. In the 2016 samples, 17 samples were from males and 10 were from females. In 2024, 13 samples were from males and 11 were from females. The mean (and standard deviation) age of 2016 decedents was 50.0 (±11.4) years and 52.3 (±16.8) years for the 2024 decedents.</p></div><div id="S3"><h3 id="S3title">Py-GC/MS Detection of Polymer Solids:</h3><p id="P5">Formalin-fixed tissue samples (approximately 500mg) were digested with 10% potassium hydroxide for 3d at 40°C with intermittent manual mixing to ensure even and thorough digestion. Fully digested samples were then ultracentrifuged at 100,000g × 4h to generate a pellet enriched in solid materials resistant to such digestion, principally polymer-based solids<sup><a href="#R10" rid="R10">10</a></sup>. A 1–2 mg portion of the resulting pellet was then analyzed by single-shot Py-GC/MS and compared to a microplastics-CaCO<sub>3</sub> standard containing 12 specific polymers: Polyethylene (PE), Polyvinyl chloride (PVC), Nylon 66 (N66), Styrene-butadiene (SBR), Acrylonitrile Butadiene Styrene (ABS), Polyethylene terephthalate (PET), Nylon 6 (N6), Poly(methyl methacrylate) (PMMA), Polyurethane (PU), Polycarbonate (PC), Polypropylene (PP), Polystyrene (PS). Polymer spectra were identified via the F-Search MPs v2.1 software (Frontier Labs). Resulting data were normalized to original sample weight to render a mass concentration (μg/g).</p></div><div id="S4"><h3 id="S4title">Data Analysis:</h3><p id="P6">Statistical analysis was performed using GraphPad Prism v10.0.03. Details of statistical analysis are provided in the data supplement.</p></div></div><div id="S5"><h2 id="S5title">RESULTS and DISCUSSION</h2><p id="P7">Py-GC/MS has proven to be an informative and reliable method to determine plastics concentrations in liquid and solid tissue samples, with ample assurance of accuracy, quality, and rigor<sup><a href="#R2" rid="R2">2</a>,<a href="#R3" rid="R3">3</a>,<a href="#R9" rid="R9">9</a>,<a href="#R10" rid="R10">10</a></sup>. Decedent liver and kidney MNP concentrations were similar, with means of 465 and 666 μg/g, respectively, from 2024 samples (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1A</span></a>). These were higher than previously published data for human placentas (126 μg/g)<sup><a href="#R10" rid="R10">10</a></sup>, but comparable to testes (329 μg/g)<sup><a href="#R11" rid="R11">11</a></sup>. Liver samples had significantly higher concentrations in 2024 than in 2016 samples (145 μg/g; p&lt;0.001). The brain samples, all derived from the frontal cortex, revealed substantially higher concentrations than liver or kidney, at 3,057 μg/g in 2016 samples and 4,806 μg/g (0.48%, by weight) in 2024 samples, ranging as high as 8,861 μg/g. Five brain samples from 2016 (highlighted in orange, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1A</span></a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>​</span><span>B</span></a>) were analyzed independently by colleagues at Oklahoma State University, and those values were consistent with our findings.</p><!--fig ft0--><!--fig mode=article f1--><div id="F1" co-legend-rid="lgnd_F1"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div data-largeobj="" data-largeobj-link-rid="largeobj_idm140287073274816"><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=11100893_nihpp-rs4345687v1-f0001.jpg" target="tileshopwindow" rel="noopener"><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is nihpp-rs4345687v1-f0001.jpg" title="Click on image to zoom" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/bin/nihpp-rs4345687v1-f0001.jpg"></a></div><div id="lgnd_F1"><!--caption a7--><p id="P17">Overview of total MNP concentrations from all decedent samples from liver, kidney, and brain. <strong>A.</strong> All data shown, with the bar representing arithmetic mean value and the standard deviation. Orange colored symbols in the 2016 brain samples were analyzed independently at Oklahoma State University. Asterisks indicate significant differences temporal changes (from 2016 to 2024) using a nonparametric t-test (Mann Whitney). Brain concentrations were also significantly higher than liver and kidney, by ANOVA. <strong>B.</strong> Using only polyethylene data, similar trends were noted, although the kidney concentrations did not increase in the 2024 samples. <strong>C.</strong> Overall distribution of 12 different polymers suggests a greater accumulation of polyethylene in the brain relative to liver or kidney. Polyethylene (PE), Polyvinyl chloride (PVC), Nylon 66 (N66), Styrene-butadiene (SBR), Acrylonitrile Butadiene Styrene (ABS), Polyethylene terephthalate (PET), Nylon 6 (N6), Poly(methyl methacrylate) (PMMA), Polyurethane (PU), Polycarbonate (PC), Polypropylene (PP), Polystyrene (PS). <strong>D.</strong> Distribution trends for PE across each organ and collection date, including 5 additional samples (on the right) from the 2016 brain collections that were analysed by Attenuated Total Reflectance-Fourier-transform infrared spectroscopy (FTIR).</p></div></div><p id="P8">A non-parametric analysis of variance (Kruskal-Wallis) confirmed that MNP concentrations in brains were significantly greater than all other tissues (P&lt;0.0001). Furthermore, from 2016 to 2024, there was a significant increase in MNP concentrations in both livers and brains. The predominant polymer found in all tissues was polyethylene, which independently displayed similarly increasing trends from 2016 to 2024 in the liver and brain (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1B</span></a>). The proportion of polyethylene in the brain (74%) appeared significantly greater relative to other polymers in comparison to the liver and kidney (44–57%), although kidney samples from 2024 also had increased relative PE (71%; <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1C</span></a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>​</span><span>D</span></a>). This was also confirmed with ATR-FTIR spectroscopic analysis from 5 brain samples (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1D</span></a>).</p><p id="P9">Because we suspected that much of the MNPs measured were actually in the nanoscale range, transmission electron microscopy (TEM) was conducted on the dispersed pellets obtained from kidney, liver, and brain (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2" co-legend-rid="lgnd_F2"><span>Figure 2</span></a>; see methods supplement). While TEM does not provide spectroscopic identification to confirm particulate composition, we observed common shapes and sizes among the numerous samples and tissue types. Notably, there were innumerable particulates with shard-like appearance, often less than 200 nm in length. Currently, MNP uptake and distribution pathways are incompletely understood; this new appreciation of the size and shape aids in our appreciation of potential mechanisms. Importantly, these observations bring into question the relevance of the many recent studies utilizing polystyrene microspheres<sup><a href="#R4" rid="R4">4</a>,<a href="#R12" rid="R12">12</a></sup>, as polystyrene was infrequently detected in human tissues and MNPs were rarely spherical.</p><!--fig ft0--><!--fig mode=article f1--><div id="F2" co-legend-rid="lgnd_F2"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div data-largeobj="" data-largeobj-link-rid="largeobj_idm140287077828624"><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=11100893_nihpp-rs4345687v1-f0002.jpg" target="tileshopwindow" rel="noopener"><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is nihpp-rs4345687v1-f0002.jpg" title="Click on image to zoom" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/bin/nihpp-rs4345687v1-f0002.jpg"></a></div><div id="lgnd_F2"><!--caption a7--><p id="P18">Example TEM images of solid nanoparticulates derived from kidney (left), liver (center), and brain (right) samples. While TEM does not permit spectroscopic identification of particulate molecular composition, the bulk of particulates that were predominantly polymer as assessed by ATR-FTIR appear to be of these sizes and shapes. Shard-like appearances, with dimensions ranging from micrometer to nanometer sizes, suggest an aged, friable polymer composition.</p></div></div><p id="P10">The concentrations in liver and kidney were not as high (relative to brains) as we would have suspected, as these are “front line” organs for xenobiotic uptake and clearance. That said, the lipophilic nature of plastics may make them easily handled by the liver, which has a major role in uptake and repackaging of dietary triglycerides and cholesterol. A recent study found higher MNP numbers in the cirrhotic liver compared to the healthy liver; whether the microplastics promote disease or are simply accumulating along with intracellular fats has not been elucidated<sup><a href="#R13" rid="R13">13</a></sup>.</p><p id="P11">Following this logic, the human brain has the second highest lipid content in the body, with only adipose tissue being higher; brain MNP concentrations are comparable to recently published Py-GC/MS data from carotid plaques, which are also a lipid depot<sup><a href="#R3" rid="R3">3</a></sup>. Furthermore, the brain receives a high blood flow, approximately 25–30% of the cardiac output, and has a tremendous metabolism. The blood-brain barrier poses a notorious challenge. However, modeling of transfer across cellular membranes suggests the uptake is dependent on the association of particulates with cholesterol and, furthermore, that particles &lt;1μm rapidly traversed the blood-brain barrier within 2h of ingestion in mice<sup><a href="#R14" rid="R14">14</a></sup>. Longer-term gavage studies similarly found that larger (5 μm) polystyrene microspheres could access the brain and promote metabolomic alterations<sup><a href="#R15" rid="R15">15</a></sup>. Lastly, clearance rates from the brain are unknown for polymer particulates. The lack of correlation with the decedent age suggests that an equilibrium occurs and may depend on genetic, dietary, and lifestyle factors that ultimately contribute to the wide between-subject variability in MNP concentrations. In zebrafish exposed to constant concentrations, nanoplastics uptake increased to a stable plateau and cleared after exposure<sup><a href="#R16" rid="R16">16</a></sup>; however, the maximal concentrations were increased proportionately with higher exposure concentrations. While the time course for kinetics is assuredly longer in humans, we postulate that the exponentially increasing environmental concentrations of MNPs<sup><a href="#R1" rid="R1">1</a>,<a href="#R17" rid="R17">17</a></sup> will analogously increase internal maximal concentrations, which is corroborated by our finding that total plastics mass concentration in brains increased over 50% in the past 8 years.</p></div><div id="S6"><h2 id="S6title">LIMITATIONS</h2><p id="P12">The present data are derived from novel analytical chemistry methods that have yet to be widely adopted and refined. Several quality control steps ensure that external contaminants are not incorporated into the sample calculations, including KOH blank samples and measurement of the polymer composition of all plastic tubes and pipette tips that are essential in the digestion and measurement process. Notably, given the consistent nature of handling and processing across varying organ samples (<em>i.e</em>., brain, liver, kidney), the dramatic, selective accumulation of MNPs in the brain cannot be dismissed as an artefact of contamination. Furthermore, the far longer duration of samples in plastic stock jars from 2016 (84–96 months) compared to those samples from 2024 (1–3 months) and the significantly lower plastics content in 2016 samples suggests that contamination from fresh plastics is not a concern to the conclusions from these data.</p><p id="P13">Both laboratories (UNM and OSU) observed a within-sample coefficient of variation of approximately 25%. This does not alter the conclusions regarding the temporal trends of selective accumulation in brains, given the magnitude of those effects. However, we believe several steps may be valuable to improve the precision of Py-GC/MS output, which in turn should improve assessment of health outcomes for future studies. There may be value in limiting assessments to the nanoscale range, which could incorporate longer ultracentrifugation times as well as a filtration of &gt;1 μm particulates. Ambient air particulate matter research provides some justification that “smaller is worse”, which led to the transition from air quality standards based on particles &lt;10 μm in diameter to those &lt;2.5 μm, which aligned more closely with health outcomes<sup><a href="#R18" rid="R18">18</a></sup>. Additionally, the Py-GC/MS method is limited to small sample weights (~1–2mg), which presents challenges for sampling and weighing accuracy when even small portions of tissue (~500 mg) generate large polymer-containing pellets; however, larger sample sizes may not be feasible due to the rapid combustion required for this approach. Lastly, by obtaining only a single sample from each organ for each subject, distribution heterogeneity within tissues remains uncharacterized.</p></div><div id="S7"><h2 id="S7title">CONCLUSIONS</h2><p id="P14">MNP concentrations in decedent brain samples ranged from 7-to-30 times the concentrations seen in livers or kidneys. With independent confirmation from another laboratory and visual evidence from FTIR and TEM approaches, we have high confidence that MNPs selectively accumulate in the brain, with the majority being nanometer-scale, shard-like particulates. However, linking MNP concentration data to health outcomes in larger cohorts will require refinements to the technique, more complex study designs, and larger cohorts. The parallels between the present data showing an increasing trend in MNP concentrations in the brain with exponentially rising environmental presence of microplastics<sup><a href="#R19" rid="R19">19</a>–<a href="#R21" rid="R21">21</a></sup> and increasing global rates of age-corrected Alzheimer’s disease and related dementia<sup><a href="#R22" rid="R22">22</a>–<a href="#R25" rid="R25">25</a></sup>, given the potential role of anionic nanoplastics in protein aggregation<sup><a href="#R26" rid="R26">26</a></sup>, add urgency to understanding the impacts of MNP on human health.</p></div><div id="S8"><h2 id="S8title">Funding/Support:</h2><p id="P15">This research was funded by NIH P20 GM130422 (MJC), R01 ES032037 (EFC), R01 ES014639 (MJC), K12 GM088021 (MAG), P50 MD015706 (EEH), P30ES032755 (BB), and R15 ES034901 (JGE).</p></div><div id="fn-group-a.g.b"><h2 id="fn-group-a.g.btitle">Footnotes</h2><!--back/fn-group--><div><p id="P16"><strong>Statement of Interests:</strong> The authors declare no conflicts of interest with the content of this manuscript.</p></div></div><div id="article-aaff-info"><h2 id="article-aaff-infotitle">Contributor Information</h2><p><span>Matthew Campen, </span><span id="A1"> University of New Mexico.</span></p><p><span>Alexander Nihart, </span><span id="A2"> University of New Mexico.</span></p><p><span>Marcus Garcia, </span><span id="A3"> University of New Mexico.</span></p><p><span>Rui Liu, </span><span id="A4"> University of New Mexico.</span></p><p><span>Marian Olewine, </span><span id="A5"> University of New Mexico.</span></p><p><span>Eliseo Castillo, </span><span id="A6"> University of New Mexico.</span></p><p><span>Barry Bleske, </span><span id="A7"> University of New Mexico.</span></p><p><span>Justin Scott, </span><span id="A8"> Oklahoma State University.</span></p><p><span>Tamara Howard, </span><span id="A9"> University of New Mexico Health Sciences Center.</span></p><p><span>Jorge Gonzalez-Estrella, </span><span id="A10"> Oklahoma State University.</span></p><p><span>Natalie Adolphi, </span><span id="A11"> New Mexico Office of the Medical Investigator.</span></p><p><span>Daniel Gallego, </span><span id="A12"> New Mexico Office of the Medical Investigator.</span></p><p><span>Eliane El Hayek, </span><span id="A13"> University of New Mexico.</span></p></div><div id="ref-list-a.g.c"><h2 id="ref-list-a.g.ctitle">REFERENCES</h2><div id="reference-list"><p>1. <span>Stubbins A., Law K. L., Munoz S. E., Bianchi T. S. &amp; Zhu L.
<span>Plastics in the Earth system</span>. <span>Science</span>
<span>373</span>, 51–55, doi: 10.1126/science.abb0354 (2021).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/34210876" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1126%2Fscience.abb0354" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Science&amp;title=Plastics+in+the+Earth+system&amp;author=A.+Stubbins&amp;author=K.+L.+Law&amp;author=S.+E.+Munoz&amp;author=T.+S.+Bianchi&amp;author=L.+Zhu&amp;volume=373&amp;publication_year=2021&amp;pages=51-55&amp;pmid=34210876&amp;doi=10.1126/science.abb0354&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>2. <span>Liu S.
et al. 
<span>Microplastics in three types of human arteries detected by pyrolysis-gas chromatography/mass spectrometry (Py-GC/MS)</span>. <span>J Hazard Mater</span>
<span>469</span>, 133855, doi: 10.1016/j.jhazmat.2024.133855 (2024).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/38428296" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jhazmat.2024.133855" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hazard+Mater&amp;title=Microplastics+in+three+types+of+human+arteries+detected+by+pyrolysis-gas+chromatography/mass+spectrometry+(Py-GC/MS)&amp;author=S.+Liu&amp;volume=469&amp;publication_year=2024&amp;pages=133855&amp;pmid=38428296&amp;doi=10.1016/j.jhazmat.2024.133855&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>3. <span>Marfella R.
et al. 
<span>Microplastics and Nanoplastics in Atheromas and Cardiovascular Events</span>. <span>N Engl J Med</span>
<span>390</span>, 900–910, doi: 10.1056/NEJMoa2309822 (2024).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11009876/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38446676" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1056%2FNEJMoa2309822" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Microplastics+and+Nanoplastics+in+Atheromas+and+Cardiovascular+Events&amp;author=R.+Marfella&amp;volume=390&amp;publication_year=2024&amp;pages=900-910&amp;pmid=38446676&amp;doi=10.1056/NEJMoa2309822&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>4. <span>El Hayek E.
et al. 
<span>Photoaging of polystyrene microspheres causes oxidative alterations to surface physicochemistry and enhances airway epithelial toxicity</span>. <span>Toxicol Sci</span>
<span>193</span>, 90–102, doi: 10.1093/toxsci/kfad023 (2023).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10176241/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/36881996" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1093%2Ftoxsci%2Fkfad023" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Toxicol+Sci&amp;title=Photoaging+of+polystyrene+microspheres+causes+oxidative+alterations+to+surface+physicochemistry+and+enhances+airway+epithelial+toxicity&amp;author=E.+El+Hayek&amp;volume=193&amp;publication_year=2023&amp;pages=90-102&amp;pmid=36881996&amp;doi=10.1093/toxsci/kfad023&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>5. <span>Dong C. D.
et al. 
<span>Polystyrene microplastic particles: In vitro pulmonary toxicity assessment</span>. <span>J Hazard Mater</span>
<span>385</span>, 121575, doi: 10.1016/j.jhazmat.2019.121575 (2020).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/31727530" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jhazmat.2019.121575" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hazard+Mater&amp;title=Polystyrene+microplastic+particles:+In+vitro+pulmonary+toxicity+assessment&amp;author=C.+D.+Dong&amp;volume=385&amp;publication_year=2020&amp;pages=121575&amp;pmid=31727530&amp;doi=10.1016/j.jhazmat.2019.121575&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>6. <span>Dibbon K. C.
et al. 
<span>Polystyrene micro- and nanoplastics cause placental dysfunction in mice1</span>. <span>Biol Reprod</span>, doi: 10.1093/biolre/ioad126 (2023). [<a href="https://pubmed.ncbi.nlm.nih.gov/37724921" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1093%2Fbiolre%2Fioad126" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Biol+Reprod&amp;title=Polystyrene+micro-+and+nanoplastics+cause+placental+dysfunction+in+mice1&amp;author=K.+C.+Dibbon&amp;publication_year=2023&amp;doi=10.1093/biolre/ioad126&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>7. <span>Zhu L.
et al. 
<span>Tissue accumulation of microplastics and potential health risks in human</span>. <span>Sci Total Environ</span>
<span>915</span>, 170004, doi: 10.1016/j.scitotenv.2024.170004 (2024).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/38220018" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.scitotenv.2024.170004" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Total+Environ&amp;title=Tissue+accumulation+of+microplastics+and+potential+health+risks+in+human&amp;author=L.+Zhu&amp;volume=915&amp;publication_year=2024&amp;pages=170004&amp;pmid=38220018&amp;doi=10.1016/j.scitotenv.2024.170004&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>8. <span>Ragusa A.
et al. 
<span>Plasticenta: First evidence of microplastics in human placenta</span>. <span>Environ Int</span>
<span>146</span>, 106274, doi: 10.1016/j.envint.2020.106274 (2021).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/33395930" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.envint.2020.106274" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Environ+Int&amp;title=Plasticenta:+First+evidence+of+microplastics+in+human+placenta&amp;author=A.+Ragusa&amp;volume=146&amp;publication_year=2021&amp;pages=106274&amp;pmid=33395930&amp;doi=10.1016/j.envint.2020.106274&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>9. <span>Leslie H. A.
et al. 
<span>Discovery and quantification of plastic particle pollution in human blood</span>. <span>Environ Int</span>
<span>163</span>, 107199, doi: 10.1016/j.envint.2022.107199 (2022).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/35367073" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.envint.2022.107199" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Environ+Int&amp;title=Discovery+and+quantification+of+plastic+particle+pollution+in+human+blood&amp;author=H.+A.+Leslie&amp;volume=163&amp;publication_year=2022&amp;pages=107199&amp;pmid=35367073&amp;doi=10.1016/j.envint.2022.107199&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>10. <span>Garcia M. A.
et al. 
<span>Quantitation and identification of microplastics accumulation in human placental specimens using pyrolysis gas chromatography mass spectrometry</span>. <span>Toxicol Sci</span>, doi: 10.1093/toxsci/kfae021 (2024). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11057519/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38366932" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1093%2Ftoxsci%2Fkfae021" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Toxicol+Sci&amp;title=Quantitation+and+identification+of+microplastics+accumulation+in+human+placental+specimens+using+pyrolysis+gas+chromatography+mass+spectrometry&amp;author=M.+A.+Garcia&amp;publication_year=2024&amp;doi=10.1093/toxsci/kfae021&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>11. <span>Hu C.
et al. 
<span>Unveiling the Hidden Threat: Microplastic Presence in Dog and Human Testis and Its Potential Association with Sperm Count</span>. <span>Toxicol Sci</span> (2024). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11285152/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38745431" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Toxicol+Sci&amp;title=Unveiling+the+Hidden+Threat:+Microplastic+Presence+in+Dog+and+Human+Testis+and+Its+Potential+Association+with+Sperm+Count&amp;author=C.+Hu&amp;publication_year=2024&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>12. <span>Garcia M. M.
et al. 
<span>In Vivo Tissue Distribution of Polystyrene or Mixed Polymer Microspheres and Metabolomic Analysis after Oral Exposure in Mice</span>. <span>Environ Health Perspect</span>
<span>132</span>, 47005, doi: 10.1289/EHP13435 (2024).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11005960/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38598326" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1289%2FEHP13435" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Environ+Health+Perspect&amp;title=In+Vivo+Tissue+Distribution+of+Polystyrene+or+Mixed+Polymer+Microspheres+and+Metabolomic+Analysis+after+Oral+Exposure+in+Mice&amp;author=M.+M.+Garcia&amp;volume=132&amp;publication_year=2024&amp;pages=47005&amp;pmid=38598326&amp;doi=10.1289/EHP13435&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>13. <span>Horvatits T.
et al. 
<span>Microplastics detected in cirrhotic liver tissue</span>. <span>EBioMedicine</span>
<span>82</span>, 104147, doi: 10.1016/j.ebiom.2022.104147 (2022).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9386716/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/35835713" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.ebiom.2022.104147" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=EBioMedicine&amp;title=Microplastics+detected+in+cirrhotic+liver+tissue&amp;author=T.+Horvatits&amp;volume=82&amp;publication_year=2022&amp;pages=104147&amp;pmid=35835713&amp;doi=10.1016/j.ebiom.2022.104147&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>14. <span>Kopatz V.
et al. 
<span>Micro- and Nanoplastics Breach the Blood-Brain Barrier (BBB): Biomolecular Corona’s Role Revealed</span>. <span>Nanomaterials (Basel)</span>
<span>13</span>, doi: 10.3390/nano13081404 (2023). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10141840/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/37110989" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fnano13081404" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Nanomaterials+(Basel)&amp;title=Micro-+and+Nanoplastics+Breach+the+Blood-Brain+Barrier+(BBB):+Biomolecular+Corona%E2%80%99s+Role+Revealed&amp;author=V.+Kopatz&amp;volume=13&amp;publication_year=2023&amp;doi=10.3390/nano13081404&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>15. <span>Garcia M. M.
et al. 
<span>In Vivo Tissue Distribution of Microplastics and Systemic Metabolomic Alterations After Gastrointestinal Exposure</span>. <span>bioRxiv</span>, doi: 10.1101/2023.06.02.542598 (2023). [<a href="https://doi.org/10.1101%2F2023.06.02.542598" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=bioRxiv&amp;title=In+Vivo+Tissue+Distribution+of+Microplastics+and+Systemic+Metabolomic+Alterations+After+Gastrointestinal+Exposure&amp;author=M.+M.+Garcia&amp;publication_year=2023&amp;doi=10.1101/2023.06.02.542598&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>16. <span>Habumugisha T., Zhang Z., Fang C., Yan C. &amp; Zhang X.
<span>Uptake, bioaccumulation, biodistribution and depuration of polystyrene nanoplastics in zebrafish (Danio rerio)</span>. <span>Sci Total Environ</span>
<span>893</span>, 164840, doi: 10.1016/j.scitotenv.2023.164840 (2023).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/37321508" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.scitotenv.2023.164840" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Total+Environ&amp;title=Uptake,+bioaccumulation,+biodistribution+and+depuration+of+polystyrene+nanoplastics+in+zebrafish+(Danio+rerio)&amp;author=T.+Habumugisha&amp;author=Z.+Zhang&amp;author=C.+Fang&amp;author=C.+Yan&amp;author=X.+Zhang&amp;volume=893&amp;publication_year=2023&amp;pages=164840&amp;pmid=37321508&amp;doi=10.1016/j.scitotenv.2023.164840&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>17. <span>Landrigan P. J.
<span>Plastics, Fossil Carbon, and the Heart</span>. <span>N Engl J Med</span>
<span>390</span>, 948–950, doi: 10.1056/NEJMe2400683 (2024).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/38446681" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1056%2FNEJMe2400683" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Plastics,+Fossil+Carbon,+and+the+Heart&amp;author=P.+J.+Landrigan&amp;volume=390&amp;publication_year=2024&amp;pages=948-950&amp;pmid=38446681&amp;doi=10.1056/NEJMe2400683&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>18. <span>Dockery D. W.
et al. 
<span>An association between air pollution and mortality in six U.S. cities</span>. <span>N Engl J Med</span>
<span>329</span>, 1753–1759, doi: 10.1056/NEJM199312093292401 (1993).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/8179653" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1056%2FNEJM199312093292401" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=An+association+between+air+pollution+and+mortality+in+six+U.S.+cities&amp;author=D.+W.+Dockery&amp;volume=329&amp;publication_year=1993&amp;pages=1753-1759&amp;pmid=8179653&amp;doi=10.1056/NEJM199312093292401&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>19. <span>Wang C. H., Zhao J. &amp; Xing B. S.
<span>Environmental source, fate, and toxicity of microplastics</span>. <span>J Hazard Mater</span>
<span>407</span>, doi:ARTN 124357 10.1016/j.jhazmat.2020.124357 (2021). [<a href="https://pubmed.ncbi.nlm.nih.gov/33158648" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jhazmat.2020.124357" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hazard+Mater&amp;title=Environmental+source,+fate,+and+toxicity+of+microplastics&amp;author=C.+H.+Wang&amp;author=J.+Zhao&amp;author=B.+S.+Xing&amp;volume=407&amp;publication_year=2021&amp;doi=10.1016/j.jhazmat.2020.124357&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>20. <span>Geyer R., Jambeck J. R. &amp; Law K. L.
<span>Production, use, and fate of all plastics ever made</span>. <span>Sci Adv</span>
<span>3</span>, doi:ARTN e1700782 10.1126/sciadv.1700782 (2017). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5517107/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28776036" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1126%2Fsciadv.1700782" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Adv&amp;title=Production,+use,+and+fate+of+all+plastics+ever+made&amp;author=R.+Geyer&amp;author=J.+R.+Jambeck&amp;author=K.+L.+Law&amp;volume=3&amp;publication_year=2017&amp;doi=10.1126/sciadv.1700782&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>21. <span>Landrigan P. J.
et al. 
<span>The Minderoo-Monaco Commission on Plastics and Human Health</span>. <span>Ann Glob Health</span>
<span>89</span>, 23, doi: 10.5334/aogh.4056 (2023).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10038118/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/36969097" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.5334%2Faogh.4056" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Ann+Glob+Health&amp;title=The+Minderoo-Monaco+Commission+on+Plastics+and+Human+Health&amp;author=P.+J.+Landrigan&amp;volume=89&amp;publication_year=2023&amp;pages=23&amp;pmid=36969097&amp;doi=10.5334/aogh.4056&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>22. <span>van Bussel E. F.
et al. 
<span>Dementia incidence trend over 1992–2014 in the Netherlands: Analysis of primary care data</span>. <span>PLoS Med</span>
<span>14</span>, e1002235, doi: 10.1371/journal.pmed.1002235 (2017).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5340347/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28267788" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1371%2Fjournal.pmed.1002235" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=PLoS+Med&amp;title=Dementia+incidence+trend+over+1992%E2%80%932014+in+the+Netherlands:+Analysis+of+primary+care+data&amp;author=E.+F.+van+Bussel&amp;volume=14&amp;publication_year=2017&amp;pages=e1002235&amp;pmid=28267788&amp;doi=10.1371/journal.pmed.1002235&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>23. <span>Collaborators G. U. N. D.
et al. 
<span>Burden of Neurological Disorders Across the US From 1990–2017: A Global Burden of Disease Study</span>. <span>JAMA Neurol</span>
<span>78</span>, 165–176, doi: 10.1001/jamaneurol.2020.4152 (2021).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7607495/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/33136137" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1001%2Fjamaneurol.2020.4152" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA+Neurol&amp;title=Burden+of+Neurological+Disorders+Across+the+US+From+1990%E2%80%932017:+A+Global+Burden+of+Disease+Study&amp;author=G.+U.+N.+D.+Collaborators&amp;volume=78&amp;publication_year=2021&amp;pages=165-176&amp;pmid=33136137&amp;doi=10.1001/jamaneurol.2020.4152&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>24. <span>Huang Y., Li Y., Pan H. &amp; Han L.
<span>Global, regional, and national burden of neurological disorders in 204 countries and territories worldwide</span>. <span>J Glob Health</span>
<span>13</span>, 04160, doi: 10.7189/jogh.13.04160 (2023).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10685084/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38018250" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.7189%2Fjogh.13.04160" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Glob+Health&amp;title=Global,+regional,+and+national+burden+of+neurological+disorders+in+204+countries+and+territories+worldwide&amp;author=Y.+Huang&amp;author=Y.+Li&amp;author=H.+Pan&amp;author=L.+Han&amp;volume=13&amp;publication_year=2023&amp;pages=04160&amp;pmid=38018250&amp;doi=10.7189/jogh.13.04160&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>25. <span>Zhu Z., Zheng Z., Zhou C., Cao L. &amp; Zhao G.
<span>Trends in Prevalence and Disability-Adjusted Life-Years of Alzheimer’s Disease and Other Dementias in China from 1990 to 2019</span>. <span>Neuroepidemiology</span>
<span>57</span>, 206–217, doi: 10.1159/000530593 (2023).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/37231950" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1159%2F000530593" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Neuroepidemiology&amp;title=Trends+in+Prevalence+and+Disability-Adjusted+Life-Years+of+Alzheimer%E2%80%99s+Disease+and+Other+Dementias+in+China+from+1990+to+2019&amp;author=Z.+Zhu&amp;author=Z.+Zheng&amp;author=C.+Zhou&amp;author=L.+Cao&amp;author=G.+Zhao&amp;volume=57&amp;publication_year=2023&amp;pages=206-217&amp;pmid=37231950&amp;doi=10.1159/000530593&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>26. <span>Liu Z.
et al. 
<span>Anionic nanoplastic contaminants promote Parkinson’s disease-associated alpha-synuclein aggregation</span>. <span>Sci Adv</span> 9, eadi8716, doi: 10.1126/sciadv.adi8716 (2023). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10656074/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/37976362" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1126%2Fsciadv.adi8716" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Adv&amp;title=Anionic+nanoplastic+contaminants+promote+Parkinson%E2%80%99s+disease-associated+alpha-synuclein+aggregation&amp;author=Z.+Liu&amp;publication_year=2023&amp;doi=10.1126/sciadv.adi8716&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p></div></div></div><!--post-content--><div><hr><p>Articles from <span>Research Square</span> are provided here courtesy of <strong>American Journal Experts</strong></p><hr></div></div>
    </article>
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Crypto 'pig butchering' scam wrecks bank, sends ex-CEO to prison for 24 years (106 pts)]]></title>
            <link>https://www.cnbc.com/2024/08/21/cryptocurrency-shan-hanes-pig-butchering-scam.html</link>
            <guid>41314542</guid>
            <pubDate>Wed, 21 Aug 2024 21:52:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/08/21/cryptocurrency-shan-hanes-pig-butchering-scam.html">https://www.cnbc.com/2024/08/21/cryptocurrency-shan-hanes-pig-butchering-scam.html</a>, See on <a href="https://news.ycombinator.com/item?id=41314542">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The former CEO of a small <a href="https://kansasreflector.com/2023/08/11/huge-scam-in-rural-kansas-town-fells-fourth-u-s-bank-in-2023/" target="_blank">Kansas bank</a> was sentenced to more than 24 years in <a href="https://www.justice.gov/usao-ks/pr/former-ceo-failed-bank-sentenced-prison" target="_blank">prison</a> for looting the bank of $47 million — which he sent to <a href="https://www.cnbc.com/2021/11/16/us-selling-seized-cryptocurrency-in-bitconnect-fraud-case.html">cryptocurrency</a> wallets controlled by scammers who had duped him in a "<a href="https://www.fincen.gov/news/news-releases/fincen-issues-alert-prevalent-virtual-currency-investment-scam-commonly-known" target="_blank">pig butchering</a>" scheme that appealed to his greed, <a href="https://www.cnbc.com/2024/05/14/trump-aide-steve-bannon-prosecutors-ask-judge-to-lift-jail-stay.html">federal prosecutors</a> said.</p><p>The massive embezzlement by ex-CEO <a href="https://storage.courtlistener.com/recap/gov.uscourts.ksd.151122/gov.uscourts.ksd.151122.1.0.pdf" target="_blank">Shan Hanes</a> in a series of wire transfers over just eight weeks last year led to the collapse and <a href="https://www.fdic.gov/news/press-releases/2023/pr23058.html" target="_blank">FDIC</a> takeover of <a href="https://oig.federalreserve.gov/reports/board-material-loss-review-heartland-tri-state-bank-feb2024.pdf" target="_blank">Heartland Tri-State Bank</a> in Elkhart, one of only five U.S. banks that <a href="https://oig.federalreserve.gov/releases/news-statement-heartland-ceo-sentence-aug2024.htm" target="_blank">failed</a> in 2023.</p><p>Hanes, 53, also swindled funds from a local <a href="https://www.cnbc.com/2020/01/24/new-orleans-saints-helped-catholic-church-on-clergy-sex-abuse-pr.html">church</a> and investment club — and a daughter's college savings account — to transfer money, purportedly to buy cryptocurrency as the scammers insisted they needed more funds to unlock the supposed returns on his investments, according to records from <a href="https://ksd.uscourts.gov/wichita" target="_blank">U.S. District Court in Wichita</a>, Kansas.</p><p>But Hanes never realized any profit, and lost all of the money he stole, as a result of the scam.</p><p>Judge John Broomes on Monday sentenced Hanes to 293 months in prison — 29 months more than what prosecutors requested after he pleaded guilty in May to a single count of embezzlement by a bank officer.</p><p>During the sentencing hearing, "I called his actions 'pure evil,' " said Brian Mitchell, who for years was Hanes' next-door neighbor in Elkhart, a town of 2,000 or so people in southwestern Kansas, north of the Oklahoma panhandle.</p><p>Mitchell, whose farm and movie theater chain businesses banked at Heartland Tri-State, said there were around 30 shareholders in the bank who attended Hanes' sentencing, more than a year after their stock value was wiped out in the failure.</p><p>"There were people who lost 70, 80% of their retirement" as a result of Hanes' actions, Mitchell told CNBC on Wednesday in a phone interview.</p><p>One local woman is "struggling to afford a nursing home" for her 93-year-old mother, while another woman "can't retire" now because of the crime, Mitchell said.</p><p>Mitchell, who was not a shareholder but who belonged to the investment club victimized by the CEO, said Hanes showed little, if any, remorse for his actions, despite hearing victims tell the judge about the effects of his crime.</p><p>"Shan was facing the judge, and he just looked over his left shoulder for a second, and didn't make eye contact, and said, 'Sorry,' " Mitchell recalled, describing the scene in the courtroom.</p><p>"And that was it."</p><p>But Hanes had a look of "absolute shock" on his face when Broomes imposed the stiff sentence and ordered the former bank chief taken into custody immediately, Mitchell said.</p><p>Mitchell said that for years he considered Hanes a "good guy," who like other people in Elkhart pitched in to help others in the small community when they needed help, and preached at his local church. Hanes also testified several times before Congress about community banking.</p><p>But prosecutors and bank regulators said that Hanes, who has three daughters with his school teacher wife, began stealing after being targeted in a pig-butchering scheme in late 2022.</p><p>That scheme was described in a court filing as "a scammer convincing a victim (a pig) to invest in supposedly legitimate virtual currency investment opportunities and then steals the victim's money — butchering the pig."</p><p>Hanes, who had served on the board of the American Bankers Association, and been chairman of the Kansas Bankers Association, in December 2022 began making transactions to buy cryptocurrency, which "appeared to be precipitated by communication with an unidentified co-conspirator on the electronic messaging app 'WhatsApp,' " prosecutors wrote in a court filing.</p><p>"To date, the true identity of the co-conspirator, or conspirators, remain unknown," the filing notes.</p><p>Hanes initially used personal funds to buy crypto, but in early 20233&nbsp;he stole $40,000 from Elkhart&nbsp;Church of Christ and $10,000 from the Santa Fe Investment Club, according to prosecutors and a defense filing.</p><p>He also used $60,000 taken from a daughter's college fund, and nearly $1 million in stock from the Elkhart Financial Corporation, his lawyer said in a filing.</p><p>In May 2023, he began to make wire transfers from Heartland Tri-State Bank to accounts controlled by scammers, at first with a $5,000 transfer.</p><p>Two weeks later, on May 30, Hanes wired $1.5 million and a day after that, he sent another transfer of the same amount the following day, filings show.</p><p>Three days later he directed two wire transfers totaling $6.7 million to be sent by the bank to the crypto wallet, and a whopping $10 million less than two weeks later, and another $3.3 million days afterward.</p><p>Hanes told bank employees to execute the wire transfers, and "made many misrepresentations to various people" to get access to the funds so they could be transferred, prosecutors wrote. Heartland Tri-State employees circumvented the bank's own wire policy and daily limits to approve Hanes' wire transfers, according to a report by the Office of the Inspector General of the Board of Governors of the Federal Reserve System.</p><p>"We believe that the CEO's dominant role in the bank and prominent role in the community contributed to a reluctance on the part of Heartland employees to question or report the alleged fraudulent activities earlier," that report said.</p><p>Prosecutors wrote that the series of 11 wire transfers from Hanes to the scammer "illustrate a common pattern" in pig-butchering schemes.</p><p>"First, there is an initial 'investment' followed by another transaction required to secure or guarantee those funds," prosecutors wrote. "Further 'investments' may be made, but always require another need for funds, to guarantee or unfreeze the earlier transfers. This pattern is clearly represented in the defendant's embezzlement."</p><p>Mitchell confirmed that to CNBC, saying that he got a call from Hanes at 7:40 a.m. on July 5, 2023.</p><p>"He said, 'Brian, 'I need your help, and you're the only guy who can help me,' " Mitchell recounted.</p><p>Mitchell, who had survived prostate cancer two decades ago, said he thought Hanes was calling him to say that he had the same type of cancer.</p><p>But when Mitchell showed up at Heartland Tri-State to meet Hanes, before the bank had officially opened to customers that morning, the CEO told him something much different — and stranger.</p><p>"The first thing he says is, 'Brian, I need to borrow $12 million for ten days, and I'll give you $1 million for loaning it to me,' " Mitchell recalled. "I'm sitting there and I said, am I in a bank in Elkhart, Kansas, or in an alley with a loan shark in Chicago."</p><p>When he asked Hanes what he wanted the money for, Hanes "pulls out his phone and acts like he's logging in and he shows me this account that has $40 million, $42 million," Mitchell said. "He said, 'Brian, I've got this money and it's in cryptocurrency, and I need $12 million to help verify the funds.' "</p><p>Hanes then hold him he had been in touch with a banker in Denver named "Jim" and "another guy in Oklahoma" and they had invested in crypto held in Coinbase accounts, where they had made a lot of money, Mitchell said.</p><p>"I told him, 'You're in a scam, dude. You're in a scam,' " Mitchell said. "I stopped him and said, 'Is this bank money you're playing with?' And he said, 'No, Brian.' "</p><p>Hanes kept telling him he needed the $12 million to "activate" the funds he had already transferred to the crypto account, which he said was in Hong Kong, Mitchell recalled.</p><p>"I said, 'Get on a plane, go to Hong Kong, hire an interpreter, and go get a bank check' " for the funds supposedly held there, Mitchell said. "Then I said, 'I'm not going to loan you the money.' I said, 'You're in a scam, walk away.'"</p><p>But later that same day, after Mitchell rebuffed his entreaties, Hanes had bank employees wire $8 million to the scammers' accounts, prosecutors said in a court filing.</p><p>Two days after that, Hanes had employees wire the scammers another $4.4 million.</p><p>In the meantime, Mitchell, who was unaware of those transfers during that period, said that after meeting with the CEO he was worried that Hanes would get access to customers' deposits at the bank and transfer the $12 million that he had asked for.</p><p>"We kept checking our lines of credit," Mitchell said.</p><p>"The next week, I was in the bank, and one of the employees caught me, she just looked so stressed," Mitchell said. The woman told him that Hanes had wired money out of the bank.</p><p>"I said, 'Don't say another word to me... I've got to talk to a board member,'" Mitchell said.</p><p>"And I talked to a board member that night, and he went to talk to an attorney that night," Mitchell recalled.</p><p>Hanes was fired within days.</p><p>About two weeks later, on July 28, 2023, Heartland Tri-State was closed by the Kansas Office of the State Bank Commissioner was taken over by the Federal Deposit Insurance Corp.</p><p>Shareholders were wiped out, but depositors did not lose any money, as Dream First Bank, National Association, of Syracuse, Kansas, assumed all deposits.</p><p>Heartland Tri-State had nearly $140 million in total assets and $130 million in total deposits as of the prior March.</p><p>Word quickly spread that a scam had led to the bank's failure, but Hanes' involvement in it did not come to light for months.</p><p>Hanes remained uncharged until last February when federal prosecutors accused him of embezzlement. He was separately charged in Morton County, Kansas, state court in a 28-count complaint related to looting the bank.</p><p>Hanes was under house arrest until his sentencing in federal court this week.</p><p>"I talked to him last month when he was out mowing his yard," Mitchell said.</p><p>Hanes, who had traveled at one point to Perth, Australia while being scammed to try to recover the funds he transferred, told Mitchell that he believed there had been a way to recover the money up to the point he was arrested.</p></div><div id="RegularArticle-RelatedContent-1"><h2>Read more CNBC politics coverage</h2><div><ul><li><a href="https://www.cnbc.com/2024/08/21/biden-dnc-harris-democrats-future-speeches.html">Biden gets few mentions from Democrats eager to turn the page at DNC day 2</a></li><li><a href="https://www.cnbc.com/2024/08/21/obama-says-america-is-ready-for-a-new-chapter-with-harris-walz.html">Obama says 'America is ready for a new chapter' with Harris, Walz</a></li><li><a href="https://www.cnbc.com/2024/08/20/arizona-montana-abortion-rights-constitutional-measures-on-ballots.html">Arizona, Montana put abortion rights constitutional measures on November ballots</a></li><li><a href="https://www.cnbc.com/2024/08/20/rfk-jr-campaign-trump-alliance-shanahan.html">RFK Jr. campaign eyes joining forces with Trump, running mate Shanahan says</a></li></ul></div></div><div><p>"He said ... 'If I just had another two months I could get the money back,'" Mitchell recalled.</p><p>Mitchell said that at Hanes' sentencing, Judge Broomes asked Hanes several questions about his actions, but, "He didn't really have any good answers."</p><p>Broomes later looked at the victims in the courtroom's gallery before announcing Hanes' sentence.</p><p>"He said ... 'I want you to forgive Shan. I know that he's hurt you, I know this, but I want you to move on, and I want you to find some joy in your life. Let me discipline him,'" Mitchell recalled.</p><p>Broomes also told Hanes that although several people had noted how intelligent the former CEO was, "If you were that intelligent you would have stopped this," Mitchell recounted.</p><p>Hanes' lawyer John Stang, who did not respond to a request for comment, in a sentencing submission wrote, "Mr. Hanes made some very bad choices after being caught up in an extremely well-run<br>cryptocurrency scam."</p><p>"He was the pig that was butchered," Stang wrote. "Mr. Hanes's vulnerability to the Pig Butcher scheme caused him to make some very bad decisions, for which he is truly sorry for causing damage to the bank and loss to the Stockholders."</p><p>Kansas U.S. Attorney Kate Brubacher, in a statement, said, "Hanes' greed knew no bounds. He trespassed his professional obligations, his personal relationships, and federal law."</p><p>"Not only did Shan Hanes betray Heartland Bank and its investors, but his illegal schemes also jeopardized confidence in financial institutions," Brubacher said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do low-level optimizations matter? Faster quicksort with cmov (2020) (148 pts)]]></title>
            <link>http://cantrip.org/sortfast.html</link>
            <guid>41314039</guid>
            <pubDate>Wed, 21 Aug 2024 20:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://cantrip.org/sortfast.html">http://cantrip.org/sortfast.html</a>, See on <a href="https://news.ycombinator.com/item?id=41314039">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

   <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
   <meta name="viewport" content="width=device-width, user-scalable=no">
   <title></title>



<h3 id="do-low-level-optimizations-matter">Do Low-level Optimizations Matter?</h3>
<p><em>by Nathan Myers, ncm at cantrip dot org, 2020-01-09</em></p>
<p>Collectively, we have been thinking about sorting for longer than we have had computers. There is still an active literature <a href="#fn1" id="fnref1"><sup>1</sup></a>,<a href="#fn2" id="fnref2"><sup>2</sup></a>,<a href="#fn3" id="fnref3"><sup>3</sup></a>. We are taught that how the counts of comparisons and swaps vary with problem size is what matters: as problems get bigger, order dominates, and anything else is buried in the noise. We learn that the best in-place sorts run in time around <em>kN lg2(N)</em>, and a better sort algorithm has a smaller <em>k</em>, or is better-behaved for chosen input.</p>
<p>We ought to be able to sort pretty fast, by now, using a Standard Library sort. Sorting is real work: if you need it to go faster, you probably need to spend more on hardware. You can’t cheat on that.</p>
<p>Or can you? The classic sorting research was conducted on machines from many generations ago. While today’s are made to seem similar from the outside, inside they are very, very different. Do we still understand what affects sorting speed today? Maybe the rules have changed.</p>
<h3 id="laboratory">Laboratory</h3>
<p>Trying out ideas with Standard Library sort implementations can be tricky; as they have been tuned, they have become complicated. Results can be confusing. We need a laboratory: simple sorts, and simple data<a href="#fn4" id="fnref4"><sup>4</sup></a>. So, let us begin with a file of a hundred-million totally random integers:</p>
<pre><code>  $ dd if=/dev/urandom count=100 bs=4000000 of=1e8ints</code></pre>
<p>This is objectively the worst case, containing the greatest possible entropy; but also the best case, hiding no surprises. We can map this file into our process, and the OS will copy it from the file buffer cache, the work showing up as <code>sys</code> time. All the rest of the run time is spent on nothing but sorting.</p>
<p>Next, we need a baseline, using <code>std::sort</code>, for reference:</p>
<pre><code>  #include &lt;sys/mman.h&gt;
  #include &lt;fcntl.h&gt;
  #include &lt;algorithm&gt;

  static const int size = 100'000'000;

  int main(int, char**) {
    int fd = ::open("1e8ints", O_RDONLY);
    int perms = PROT_READ|PROT_WRITE;
    int flags = MAP_PRIVATE|MAP_POPULATE|MAP_NORESERVE;
    auto* a = (int*) ::mmap(
      nullptr, size * sizeof(int), perms, flags, fd, 0);

    std::sort(a, a + size);

    return a[0] == a[size - 1];
  }</code></pre>
<p>The <code>return</code> statement keeps the compiler from optimizing away the whole program. Trying it<a href="#fn5" id="fnref5"><sup>5</sup></a>:</p>
<pre><code>  $ g++ -O3 -march=native sort_base.cc &amp;&amp; time ./a.out

  real  0m7.365
  user  0m7.257
  sys   0m0.108s</code></pre>
<p>We see about <code>73ns</code> per element. <em>lg2(1e8)</em> is about 27, making <em>k</em> a bit less than <code>3ns</code>. Each time <code>std::sort</code> looks at an element, it spends, on average, <code>3ns</code>, presumably on shuffling it from memory to cache to register to ALU, and maybe back to cache and to memory. This happens 27 times before the element ends up where it belongs. (Nobody said, in school, that <em>k</em> has a unit, but for our purposes, it’s nanoseconds.)</p>
<h4 id="reality-check">Reality Check</h4>
<p>Just for a reality check, let’s plug in a radix sort. It is an unfair comparison, on several axes, but it suggests a hard upper bound on the kind of improvement we can reasonably hope for. This function distributes elements to one of 256 buckets, and then copies them back, in stable bucket order, and again for the next byte.</p>
<pre><code>  #include &lt;vector&gt;
  #include &lt;cstring&gt;

  void sort_radix256(unsigned* begin, unsigned* end) {
    std::vector&lt;int&gt; buckets[256];
    for (auto&amp; v : buckets) v.reserve((end - begin)/128);
    for (int byte = 0; byte != sizeof(unsigned); ++byte) {
      for (unsigned* p = begin; p != end; ++p) {
        buckets[*p &amp; 0xff].push_back((*p &gt;&gt; 8) | (*p &lt;&lt; 24));
      }
      unsigned* p = begin;
      for (auto&amp; v : buckets) {
        std::memcpy(p, v.data(), v.size() * sizeof(unsigned));
        p += v.size();
        v.clear();
  } } }

  - auto* a = (int*) ::mmap(
  + auto* a = (unsigned*) ::mmap(

  - std::sort(a, a + size);
  + sort_radix256(a, a + size);

  real  0m1.193s
  user  0m0.985s
  sys   0m0.208s</code></pre>
<p>We see the OS spending extra time initializing memory (two thirds of it to zeroes), because radix sorting is not done in place. The rest of the time is spent copying the input to buckets and back, four passes in all, <code>2.5ns</code> per element per pass. When you can use it, and for big enough N, radix sort always wins, because it’s O(N): in this case, 4N. Notably, the sequence of instructions is almost the same, no matter what the values of the elements are. All that varies is which bucket each element goes into.</p>
<p>This radix sort would be easy to make even faster. Instead, let us make one that is slower, but that shares important qualities with in-place sorts. Instead of 256 buckets, this will use just two. The first pass picks a bucket according to the low bit, the next pass uses the next bit, and on around.</p>
<pre><code>  void sort_radix2(unsigned* begin, unsigned* end) {
    std::vector&lt;unsigned&gt; a_buckets[2];
    for (auto&amp; v : a_buckets) v.reserve((end - begin)/3);
    int i = 0;
    for (; i &lt; (end - begin) / 2; ++i) a_buckets[0].push_back(begin[i]);
    for (; i &lt; (end - begin); ++i) a_buckets[1].push_back(begin[i]);

    std::vector&lt;unsigned&gt; b_buckets[2];
    for (auto&amp; v : b_buckets) v.reserve((end - begin)/3);

    for (int bit = 0; bit != 8 * sizeof(unsigned); ++bit) {
      for (int j = 0; j != 2; ++j) {
        for (unsigned v : a_buckets[j]) {
          b_buckets[v &amp; 0x1].push_back((v &gt;&gt; 1) | (v &lt;&lt; 31));
        }
      }
      std::swap(a_buckets[0], b_buckets[0]), b_buckets[0].clear();
      std::swap(a_buckets[1], b_buckets[1]), b_buckets[1].clear();
    }

    for (auto bucket : a_buckets)
      for (unsigned v : bucket) *begin++ = v;
  }

  - sort_radix256(a, a + size);
  + sort_radix2(a, a + size);

  real  0m4.759s
  user  0m4.543s
  sys   0m0.216s
</code></pre>
<p>It’s slower, because it examines each element 32 times. It’s not <em>N lg2(N)</em>, but <em>32N</em>. This <code>4.5s</code> is remarkably close to our <code>std::sort</code> baseline, <code>7.3s</code>. Maybe we can think of the difference between <code>4.5s</code> and our baseline as what we pay for the generality of <code>std::sort</code>? <em>32N</em> is not far from <em>27N</em>. Should we take <code>4.5s</code> <code>*</code> <em>27/32</em> <em>=</em> <code>3.8s</code> as an ultimate stretch goal?</p>
<h4 id="starting-point-quicksort">Starting Point: <code>quicksort</code></h4>
<p>Let’s see how well we can do with a regular sorting algorithm. Start by pasting in a bog-standard quicksort<a href="#fn6" id="fnref6"><sup>6</sup></a>:</p>
<pre><code>  int* partition(int* begin, int* end) {
    int pivot = end[-1];
    int* left = begin;
    for (int* right = begin; right &lt; end - 1; ++right) {
      if (*right &lt;= pivot) {
        int tmp = *left; *left = *right, *right = tmp;
        ++left;
      }
    }
    int tmp = *left; *left = end[-1], end[-1] = tmp;
    return left;
  }

  void quicksort(int* begin, int* end) {
    while (end - begin &gt; 1) {
      int* mid = partition(begin, end);
      quicksort(begin, mid);
      begin = mid + 1;
  } }

  - auto* a = (unsigned*) ::mmap(
  + auto* a = (int*) ::mmap(

  - radix_sort2(a, a + size);
  + quicksort(a, a + size);

  real  0m8.309s
  user  0m8.193s
  sys   0m0.116s</code></pre>
<p>This is really not bad. The <code>std::sort</code> in the standard library, at <code>7.3s</code>, is a lot more code than we see here, but it has to perform well on tricky cases we won’t be testing.</p>
<h4 id="what-is-new">What Is New?</h4>
<p>What is different in modern CPUs from the machines the algorithms we use were originally tuned for? Well, lots. Today they have up to a half-billion transistors per core, not just the thousands originally used to execute a notably similar instruction set. (Imagine, in each generation, being asked to find a way to use another million, ten million, hundred million! more transistors, to get better benchmark times.)</p>
<p>We have many more caches, registers, instruction decoders, and functional units–barrel shifters, multipliers, ALUs<a href="#fn7" id="fnref7"><sup>7</sup></a>. There’s even a little just-in-time compiler, <em>in hardware</em>, to translate complex-instruction sequences into simpler ones, with its own peephole optimizer, and a cache of its output. A small-enough loop can execute entirely from that cache.</p>
<p>One thing wholly new is the <em>branch predictor</em><a href="#fn8" id="fnref8"><sup>8</sup></a>. Technically, it’s another cache, one that accumulates a history of which way was chosen on each of the last M conditional branch points encountered during execution. (The number M is secret.) Branch prediction matters because of something else that’s wholly new: <em>speculative execution</em><a href="#fn9" id="fnref9"><sup>9</sup></a>.</p>
<p>When regular execution needs to stop and wait on a result, speculative execution can run on ahead, stuffing pipelines with work from upcoming loop iterations. Because the values needed to decide which way a conditional branch will go haven’t been computed yet, it has to <em>guess</em>, based on the pattern of what has happened before at that instruction address. When the branch predictor guesses wrong, a lot of work may need to be discarded, but whenever it guesses right, that work has already been done when regular execution gets there.</p>
<p>These days, often, most of the work gets done speculatively, so it is vitally important to guess right. Branch predictors have become astonishingly good at discovering patterns in our code, and guessing right. Nowadays, they use a neural net to identify such patterns; the branch prediction cache holds sets of coefficients for the neural net.</p>
<p>Branching on random data, though, is the worst case for any branch predictor, no matter how smart, because it can never find more regularity than the data has. Here, it guesses wrong half the time, and work is done and then discarded. The pipelines never fill, and functional units sit idle.</p>
<h4 id="adaptation">Adaptation</h4>
<p>If we want to better adapt our algorithm to the way a modern CPU works, we need to protect speculative execution against randomness in our data. Our only available course is to eliminate conditional branches that depend on that data.</p>
<p>So, let’s see what our conditional branches are doing. In this quicksort, there are only three conditional branches.</p>
<p>The first check, at the top of <code>quicksort</code> itself:</p>
<pre><code>    while (end - begin &gt; 1) {</code></pre>
<p>detects when recursion has bottomed out. It evaluates to <code>true</code> half the time, on a complicated schedule, but it is evaluated only about N times, and hardly depends on the input.</p>
<p>The second:</p>
<pre><code>    for (int* right = begin; right &lt; end - 1; ++right) {</code></pre>
<p>controls the loop in <code>partition</code> that walks through a subrange of the input. It runs about <em>N lg2(N)</em> times, but usually it’s taken. It, too, doesn’t depend much on input values. It gets hard to predict only when <code>begin</code> is very close to <code>end</code>, a small multiple of N times.</p>
<p>The third conditional branch:</p>
<pre><code>      if (*right &lt;= pivot) {</code></pre>
<p>happens <em>N lg2(N)</em> times, too, but it depends directly on the values of elements in the input, <em>every time</em>. To prevent missed branch predictions, we must find a way to avoid that branch. We need identically the same sequence of instructions executed in the true <em>and</em> the false case–and just have <em>nothing change</em>, in the false case.</p>
<p>The portable way to do this is to turn the result of the comparison into a regular value, and then do ordinary arithmetic with it. Sometimes, we can use the boolean value itself, as is. Perhaps the simplest possible example is:</p>
<pre><code>  if (a &lt; b) ++i;</code></pre>
<p>which can always be transformed, via conversion to <code>int</code>, to:</p>
<pre><code>  i += (a &lt; b);</code></pre>
<p>A more general method is to convert the boolean value into a mask value, of all zeroes or all ones. Then we can use bitwise operations to produce different results for the all-zeroes and the all-ones cases. For a slightly more complicated example, here we add up two seconds/nanoseconds pairs:</p>
<pre><code>  secs = secs1 + secs2, nsecs = nsecs1 + nsecs2;
  if (nsecs &gt;= 1'000'000'000) {
    ++secs, nsecs -= 1'000'000'000;
  }</code></pre>
<p>This transforms to:</p>
<pre><code>  secs = secs1 + secs2, nsecs = nsecs1 + nsecs2;
  int carry = (nsecs &gt;= 1'000'000'000);
  secs += carry, nsecs -= ((-carry) &amp; 1'000'000'000);</code></pre>
<p>With a carry, <code>(-carry)</code> is 111…111, and it subtracts a billion; with no carry, <code>(-carry)</code> is zero, and it subtracts zero.</p>
<h4 id="a-new-primitive-swap_if">A New Primitive, <code>swap_if</code></h4>
<p>How can we use this method in our sort? First, let us make a <code>swap_if</code>:</p>
<pre><code>  inline bool swap_if(bool c, int&amp; a, int&amp; b) {
    int ta = a, mask = -c;  // false -&gt; 0, true -&gt; 111..111
    a = (b &amp; mask) | (ta &amp; ~mask);
    b = (ta &amp; mask) | (b &amp; ~mask);
    return c;
  }</code></pre>
<p>In our <code>partition</code> function, then, we can transform</p>
<pre><code>    if (*right &lt;= pivot) {
      int tmp = *left; *left = *right, *right = tmp;
      ++left;
    }</code></pre>
<p>into just</p>
<pre><code>    left += swap_if(*right &lt;= pivot, *left, *right);</code></pre>
<p>This expands to more code, and all of it runs on every iteration, not just half of them, as before. But now, there is no branch to predict, or to mis-predict. It is just straight-line code.</p>
<p>Trying it:</p>
<pre><code>  $ g++ -O3 -march=native sort_swap_if.cc &amp;&amp; time ./a.out

  real  0m5.792s
  user  0m5.679s
  sys   0m0.112s</code></pre>
<p>This is excellent! <code>5.7s</code> is 1.44x better than before, and 1.29x as fast as <code>std::sort</code>.</p>
<p>Another way to make a value control what happens is indexing. (We have already seen an example of this, in the second radix sort presented above.) The boolean value is used as an array index:</p>
<pre><code>    int v[2] = { a, b };
    b = v[1-c], a = v[c];

  real  0m4.576s
  user  0m4.459s
  sys   0m0.116s</code></pre>
<p>Even better! This is 1.84x as fast as the naïve quicksort, even though the values have to take a detour through L1 cache so they can have addresses. This version is easily generalized to types that are not just a machine word:</p>
<pre><code>  template &lt;typename T&gt;
  bool swap_if(bool c, T&amp; a, T&amp; b) {
    T v[2] = { std::move(a), std::move(b) };
    b = std::move(v[1-c]), a = std::move(v[c]);
    return c;
  }</code></pre>
<p>When <code>T</code> is <code>int</code>, compilers generate identical code for the template version,</p>
<p>For completeness, there is also:</p>
<pre><code>    uint64_t both = (uint64_t(uint32_t(a)) &lt;&lt; 32) | uint32_t(b);
    int shift = c * 32;
    both = (both &lt;&lt; shift) | (both &gt;&gt; (64 - shift));
    a = int(uint32_t(both &amp; 0xffffffff)), b = int(both &gt;&gt; 32);</code></pre>
<p>The line with the shifts turns into a single “rotate” instruction. But this is not faster than the indexed version: it runs in <code>4.8s</code>.</p>
<h4 id="cmov-considered-disturbing"><code>cmov</code> Considered Disturbing</h4>
<p>How does the first, “and-and-or”, version do on Clang:</p>
<pre><code>  $ clang++ -O3 -march=native sort_swap_if.cc &amp;&amp; time ./a.out

  real  0m3.551s
  user  0m3.430s
  sys   0m0.120s</code></pre>
<p><em>HOLY CRAP! <code>3.4s</code>? What just happened?</em></p>
<p>Weren’t we just guessing that <code>3.8s</code> was as fast as we should ever hope to get? This is 2.4x as fast as quicksort, and more than 2x as fast as <code>std::sort</code>! This raises <em>so many</em> questions.</p>
<p>First, why the big difference between G++ and Clang? A quick detour through Godbolt<a href="#fn10" id="fnref10"><sup>10</sup></a> reveals what is going on. G++ actually generated the four “<code>and</code>”, and two “<code>or</code>” instructions seen in <code>swap_if</code>. But Clang’s optimizer recognized what we were trying to do with the masks, and replaced it all with a pair of simple <code>cmov</code>, conditional-move, instructions. (On top of that, it unrolled the loop in <code>partition</code>.)</p>
<p>What is the <code>cmov</code> instruction? It has been in ARM forever. Back in 2000, AMD included <code>cmov</code> in its 64-bit x86 ISA extensions. Then, Intel had to adopt them when Itanium flopped.</p>
<p><code>cmov</code> just copies a value from one place to another–register to register, register to memory, memory to register–but <em>only if</em> a condition-code flag has been set, such as by a recent comparison instruction. Since <code>cmov</code> replaces a conditional branch, the result of the comparison doesn’t need to be predicted. The execution unit doesn’t know <em>which</em> value it will end up with, but it knows where it will be, and can schedule copying that out to cache, and eventually memory, and run on ahead, without discarding anything.</p>
<p>Why doesn’t G++ generate <code>cmov</code> instructions? Older releases did, in fact, often enough to generate bug reports<a href="#fn11" id="fnref11"><sup>11</sup></a>. It turned out that, any time a subsequent loop iteration depends on the result, and the branch would have been predicted correctly, <code>cmov</code> may be slower than a branch, sometimes <em>much</em> slower. <code>cmov</code> can stall speculation all by itself.</p>
<p>The latest designs from Intel and AMD are said to avoid the <code>cmov</code> pipeline stall, often, but Gcc has not caught up with them yet.</p>
<p>For more on <code>cmov</code> and pessimization in G++, follow links in <a href="#fn12" id="fnref12"><sup>12</sup></a>.</p>
<p>In this case, though, nothing later depends on the result–it just gets stored, and the loop moves on–so this is a poster-child case for using <code>cmov</code>.</p>
<p>Clang, it turns out, can turn a simpler definition of <code>swap_if</code> into <code>cmov</code> instructions:</p>
<pre><code>    int ta = a, tb = b;
    a = c ? tb : ta;
    b = c ? ta : tb;</code></pre>
<p>But for this, G++ just generates a badly-predicted branch. I have not discovered a way to persuade G++ to produce <code>cmov</code> instructions (not even in old releases, and not even with the new <code>__builtin_expect_with_probability</code> intrinsic, probability 0.5). Even “profile-guided optimization” doesn’t help. (In the Linux kernel, wherever a <code>cmov</code> is needed, a macro expands directly to assembly code.) Looking into G++, it appears that it refuses to emit a <code>cmov</code> if anything else follows it in the “basic block”, even if what follows ought to be another <code>cmov</code> <a href="#fn13" id="fnref13"><sup>13</sup></a>.</p>
<h4 id="faster-than-pessimized-radix-sort">Faster Than (Pessimized) Radix Sort?</h4>
<p>Another big question: how could the Clanged version be even faster than our target time? This might come back to <code>cmov</code>, again. Radix sort always performs the same number of copy operations. So, also, do our first three versions of <code>swap_if</code>, as compiled by G++. But with <code>cmov</code>, only <em>half</em> of the swap operations end up needing to copy the pair of words out to L1 cache<a href="#fn14" id="fnref14"><sup>14</sup></a>,<a href="#fn15" id="fnref15"><sup>15</sup></a>, and thereby, perhaps, delay reading the next pair from it. There may be other reasons: radix sort sweeps majestically, sequentially through the whole sequence, relying on the prefetcher to keep ahead of it, while quicksort spends much of its time noodling around with values in L1 cache.</p>
<p>In the original quicksort, <em>k</em> was almost <code>3ns</code>, but now it is just <code>1.3ns</code>. More than <em>half</em> of the time we thought was being spent on honest computation was wasted, sitting stalled on branch mis-predictions! Who knows how much is still wasted? (Actually, the CPU knows: it keeps a count of how many of various cache misses happened, and you can read those out, given some care, with <code>perf</code><a href="#fn16" id="fnref16"><sup>16</sup></a>.)</p>
<h4 id="next">Next</h4>
<p>What can we do with what we’ve discovered? Sure, we can make our own programs faster, particularly if we are using Clang. But it would be better if we could make all programs faster.</p>
<p>We could propose a new library function, <code>std::swap_if</code>. Then, implementers could ensure it uses <code>cmov</code> for machine-word types (including pointers and floating-point values, and even small objects like <code>std::string_view</code>), and use it in their sorting and partitioning code. We could use it in our own programs, too. But for it to do much good, we would need to get it into a Standard, and then persuade many people to change a lot of code.</p>
<p>The experience with Clang’s optimizer hints at an alternative: Why can’t compilers recognize the sequence we did, and perform their own transformation?</p>
<p>This would be way better; just recompile, and all code gets faster, some a <em>lot</em> faster, with no need to rewrite any of it. The <code>std::sort</code> implementions in libstdc++ and libc++ are quite a bit more complicated than our toy quicksort, but maybe a compiler could spot places to transform that look unpromising to us.</p>
<p>Getting this optimization into compilers depends on those few who can add a new optimization to G++’s or Clang’s code generator taking time away from other optimization work. Doesn’t a 2x improvement over current <code>std::sort</code> automatically deserve that kind of attention? But it might not be so easy: too often, <code>cmov</code> is <em>slower</em>. The optimizer doesn’t just need to recognize when it <em>could</em> substitute <code>cmov</code> for a branch, it needs to decide whether it <em>should</em>.</p>
<p>While the optimizer knows whether anything depends on the result, it doesn’t know whether the input would have patterns that the branch predictor could tease out. Such an optimization would need a great deal of testing to ensure it doesn’t pessimize (too much) code.</p>
<p>Still, Clang, at least, seems to be all-in on plugging in <code>cmov</code> where it seems to make sense. It just needs to learn to recognize the conditionally-swapping and the conditionally-incrementing cases. It should be able to compose those into the transformation used here, and thence to <code>cmov</code>.</p>
<h4 id="conclusion">Conclusion</h4>
<p>What can we conclude from this discovery? Before we conclude anything, we should remind ourselves of its limitations. The tests run were on completely random data. Truly random data seldom occurs in real life. If there is a pattern in the data, the branch predictor might be able to find and exploit it. Shouldn’t it get that chance, sometimes?</p>
<p>Furthermore, the idea was tested on only the simplest possible elements, where both comparing and swapping were as cheap as they ever can be. While sorting word-sized objects is still an important use case, real sorting problems often have very different time budgets. We never changed the number or kind of comparisons performed, but the first big improvements doubled the number of copies; then the final improvement halved them again. A copy is a quarter or a third of a swap, but a dramatic change in their number had comparatively little effect on run time.</p>
<p>For many object types, the self-moves seen in the simplest, conditional-expression <code>swap_if</code> version are not permitted. For a production library, we might need to specialize on whether self-moves are allowed.</p>
<p>Our deep takeaway might be that counting comparisons and swaps ignores what are, today, the actually expensive operations: cache misses, of all kinds. Despite the millions of transistors devoted to the task, caches miss, sometimes systematically. Any time the number of misses, of all kinds, is not directly proportional to the number of operations counted, an analysis may produce the wrong answer, and lead us to bad choices.</p>
<p>But a lesson for the working programmer might be that, sometimes, you know the problem better than the compiler or cache systems, and measuring can lead you to simple code changes<a href="#fn17" id="fnref17"><sup>17</sup></a> that avoid costly misses, with sometimes dramatic results.</p>
<h4 id="recommendations">Recommendations</h4>
<p>Do these results suggest improvements to our Standard Library?</p>
<p>In C++, a factor of two in performance matters. We need two versions of each of the Standard sort, partition, binary search, merge, and heap algorithms that constitute nearly half of <code>&lt;algorithm&gt;</code><a href="#fn18" id="fnref18"><sup>18</sup></a>: one set that shields the branch predictor, and a second set that exposes the branch predictor to any patterns it can tease out. But this does <em>not</em> mean we need that many new named library functions! Instead, we can bind the choice to an optional property of the comparison predicate. The default should be to shield the branch predictor, at least for small types, because the consequence of failing to protect it can be so severe.</p>
<p>A branchless <code>std::swap_if</code> would be good to have in the Standard Library<a href="#fn19" id="fnref19"><sup>19</sup></a>, even after optimizers learn to generate it themselves, because optimizers are sometimes too cautious. We should consider carefully, also, whether <code>std::count_if</code> merits attention.</p>
<h4 id="more-to-come">More to Come</h4>
<p>Is that everything? Just the one weird trick?</p>
<p>No! This was <em>just one example</em>. Modern CPU chips are packed to the rafters with dodgy gimcracks. They have pre-fetchers, micro-op caches with micro-op fusion, register renaming, a shadow return-address stack, pipelines everywhere, atomic interlocks, translation lookaside buffers, hugepages, vector units. Caches collude with one another over private buses.</p>
<p>It all makes many programs go faster than they have any business going, but not necessarily <em>your</em> program. A better algorithm is no longer enough to get top performance; your program needs to join in the dance of the million-transistor accelerators. Anybody who insists C is close to the machine is, at best, deluded.</p>
<p>Can the dance of the gimcracks drive <em>k</em> south of one nanosecond? Stay tuned<a href="#fn20" id="fnref20"><sup>20</sup></a>.</p>
<p>Finally: If you control a budget, and depend on the performance of software, it might be a good use of that budget to help improve compilers and standard libraries in the ways suggested.</p>
<p><em>The author thanks Andrei Alexandrescu for a most thorough and helpful review of an early, and very different, draft of this article.</em></p>
<section>
<hr>
<ol>
<li id="fn1"><p><a href="https://arxiv.org/abs/1811.01259">https://arxiv.org/abs/1811.01259</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><a href="https://arxiv.org/abs/1810.12047">https://arxiv.org/abs/1810.12047</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="https://arxiv.org/abs/1604.06697">https://arxiv.org/abs/1604.06697</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="https://gitlab.com/ncmncm/sortfast/">https://gitlab.com/ncmncm/sortfast/</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Programs were run an an i7-7820X SkylakeX.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>I call this bog-standard, but the quicksorts most easily found online are always oddly pessimized, both more complicated <em>and</em> slower. This one uses the “Lomuto partition”, which is simpler than Hoare’s.)<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p><a href="https://www.agner.org/optimize/microarchitecture.pdf">https://www.agner.org/optimize/microarchitecture.pdf</a><a href="#fnref7">↩</a></p></li>
<li id="fn8"><p><a href="https://danluu/branch-prediction/">https://danluu/branch-prediction/</a><a href="#fnref8">↩</a></p></li>
<li id="fn9"><p><a href="https://en.wikipedia.org/wiki/Speculative_execution">https://en.wikipedia.org/wiki/Speculative_execution</a><a href="#fnref9">↩</a></p></li>
<li id="fn10"><p><a href="https://godbolt.org/z/k4iZAB">https://godbolt.org/z/k4iZAB</a><a href="#fnref10">↩</a></p></li>
<li id="fn11"><p><a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56309">https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56309</a><a href="#fnref11">↩</a></p></li>
<li id="fn12"><p><a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=85559">https://gcc.gnu.org/bugzilla/show_bug.cgi?id=85559</a><a href="#fnref12">↩</a></p></li>
<li id="fn13"><p><a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=93165">https://gcc.gnu.org/bugzilla/show_bug.cgi?id=93165</a><a href="#fnref13">↩</a></p></li>
<li id="fn14"><p><a href="https://gist.github.com/jboner/2841832">https://gist.github.com/jboner/2841832</a><a href="#fnref14">↩</a></p></li>
<li id="fn15"><p><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.957">https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.957</a><a href="#fnref15">↩</a></p></li>
<li id="fn16"><p><a href="http://www.brendangregg.com/perf.html">http://www.brendangregg.com/perf.html</a><a href="#fnref16">↩</a></p></li>
<li id="fn17"><p><a href="https://www.agner.org/optimize/optimizing_cpp.pdf">https://www.agner.org/optimize/optimizing_cpp.pdf</a><a href="#fnref17">↩</a></p></li>
<li id="fn18"><p><a href="https://en.cppreference.com/w/cpp/algorithm">https://en.cppreference.com/w/cpp/algorithm</a><a href="#fnref18">↩</a></p></li>
<li id="fn19"><p><a href="https://cantrip.org/swap_if.pdf">https://cantrip.org/swap_if.pdf</a><a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Little optimization pun there.<a href="#fnref20">↩</a></p></li>
</ol>
</section>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euclid's Proof that √2 is Irrational (153 pts)]]></title>
            <link>https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html</link>
            <guid>41314031</guid>
            <pubDate>Wed, 21 Aug 2024 20:39:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html">https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html</a>, See on <a href="https://news.ycombinator.com/item?id=41314031">Hacker News</a></p>
Couldn't get https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[US hospital told family their daughter had checked out when in fact she'd died (364 pts)]]></title>
            <link>https://www.theguardian.com/us-news/article/2024/aug/21/sacramento-hospital-patient-death-checked-out</link>
            <guid>41313740</guid>
            <pubDate>Wed, 21 Aug 2024 20:07:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/article/2024/aug/21/sacramento-hospital-patient-death-checked-out">https://www.theguardian.com/us-news/article/2024/aug/21/sacramento-hospital-patient-death-checked-out</a>, See on <a href="https://news.ycombinator.com/item?id=41313740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Jessie Peterson’s family spent a year searching for her after they were told that she had checked herself out of a <a href="https://www.theguardian.com/us-news/california" data-link-name="in body link" data-component="auto-linked-tag">California</a> hospital against medical advice – before they learned that she had been dead all along.</p><p>The 31-year-old died in the care of Mercy San Juan medical center in Sacramento in April 2023. The hospital shipped her body to a storage facility and did not inform her mother and sisters. The family only learned her fate the following April after months of trying to find her, according to a civil lawsuit against the hospital.</p><p>In the lawsuit, filed earlier this month, the family described the hospital’s conduct as “malicious and outrageous” and accused the facility of negligence, the negligent handling of a corpse and negligent infliction of emotional distress.</p><p>“Mercy San Juan hospital failed in its most fundamental duty to notify Jessie’s family of her death,” the lawsuit states. “Mercy San Juan stored<strong> </strong>Jessie in an off-site warehouse morgue and she was left to decompose for nearly a year while her family relentlessly inquired about her whereabouts.”</p><p>Peterson, whom her family described in the lawsuit as “loving and energetic”, had type 1 diabetes. She was experiencing a diabetic episode when she was admitted to Mercy San Juan on 6 April 2023. Her mother, Ginger Congi, stated that Peterson had called her two days later asking for a ride because she would be leaving the hospital, according to the lawsuit.</p><p>Congi was later told that Peterson had left the hospital against medical advice, and her medical records indicate she was discharged on 8 April. After her sudden disappearance, the family spent months “relentlessly” searching for her, posting flyers, speaking with unhoused residents in the area, and contacting police and the coroner’s office, according to the lawsuit.</p><p>On 12 April 2024, more than a year after Peterson was last seen, the Sacramento county detective’s office informed the family that she had been found dead at Mercy San Juan, the suit states. According to her death certificate, which was completed in April 2024, Peterson died of cardiopulmonary arrest at age 31.</p><figure id="4fa9fbba-5a61-436c-a35b-3aac46440d98" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Outside of building." src="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267.10355718085106" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Mercy medical center.</span> Photograph: Chris Allan/Alamy</figcaption></figure><p>Peterson’s sister went to the coroner’s office seeking her remains, but a worker told her that the office did not have Peterson’s body and directed her to contact the hospital. Mercy San Juan was not responsive to efforts to contact them, according to the lawsuit, and a mortuary eventually informed Congi that Peterson’s body had been found in one of the hospital’s off-site storage facilities.</p><p>Her body was so decomposed the family could not obtain her fingerprints or hold an open casket funeral, and an autopsy that could have indicated whether there had been medical malpractice associated with her death was “rendered impossible”, according to the lawsuit.</p><p>“Defendants’ failure to issue a timely certificate of death, failure to notify Jessie’s next of kin, failure to allow an autopsy, and mishandling of Jessie’s remains [was] negligent, careless, and heartless,” the lawsuit states. “Defendants violated their own promise of dignity and respect for the people in their care. Defendants’ conduct is so egregious and malicious to shock the conscious and punitive damages should be awarded.”</p><p>The family is seeking more than $5m in damages, as well as “five times the jury’s award of actual damages to punish defendants for their outrageous and inexcusable negligence” and attorneys’ fees.</p><p>Dignity Health, which operates Mercy San Juan, said in a statement: “We extend our deepest sympathies to the family during this difficult time. We are unable to comment on pending litigation.”</p></div></div>]]></description>
        </item>
    </channel>
</rss>